<!DOCTYPE html>
<html>
  <head>
    <title>Plist HTML Viewer</title>

    <meta charset="UTF-8">

    <style type="text/css">
      .CodeMirror{font-family:monospace;height:300px;color:#000;direction:ltr}.CodeMirror-lines{padding:4px 0}.CodeMirror pre{padding:0 4px}.CodeMirror-gutter-filler,.CodeMirror-scrollbar-filler{background-color:#fff}.CodeMirror-gutters{border-right:1px solid #ddd;background-color:#f7f7f7;white-space:nowrap}.CodeMirror-linenumber{padding:0 3px 0 5px;min-width:20px;text-align:right;color:#999;white-space:nowrap}.CodeMirror-guttermarker{color:#000}.CodeMirror-guttermarker-subtle{color:#999}.CodeMirror-cursor{border-left:1px solid #000;border-right:none;width:0}.CodeMirror div.CodeMirror-secondarycursor{border-left:1px solid silver}.cm-fat-cursor .CodeMirror-cursor{width:auto;border:0!important;background:#7e7}.cm-fat-cursor div.CodeMirror-cursors{z-index:1}.cm-animate-fat-cursor{width:auto;border:0;-webkit-animation:blink 1.06s steps(1) infinite;-moz-animation:blink 1.06s steps(1) infinite;animation:blink 1.06s steps(1) infinite;background-color:#7e7}@-moz-keyframes blink{50%{background-color:transparent}}@-webkit-keyframes blink{50%{background-color:transparent}}@keyframes blink{50%{background-color:transparent}}.cm-tab{display:inline-block;text-decoration:inherit}.CodeMirror-rulers{position:absolute;left:0;right:0;top:-50px;bottom:-20px;overflow:hidden}.CodeMirror-ruler{border-left:1px solid #ccc;top:0;bottom:0;position:absolute}.cm-s-default .cm-header{color:#00f}.cm-s-default .cm-quote{color:#090}.cm-negative{color:#d44}.cm-positive{color:#292}.cm-header,.cm-strong{font-weight:700}.cm-em{font-style:italic}.cm-link{text-decoration:underline}.cm-strikethrough{text-decoration:line-through}.cm-s-default .cm-keyword{color:#708}.cm-s-default .cm-atom{color:#219}.cm-s-default .cm-number{color:#164}.cm-s-default .cm-def{color:#00f}.cm-s-default .cm-variable-2{color:#05a}.cm-s-default .cm-type,.cm-s-default .cm-variable-3{color:#085}.cm-s-default .cm-comment{color:#a50}.cm-s-default .cm-string{color:#a11}.cm-s-default .cm-string-2{color:#f50}.cm-s-default .cm-meta{color:#555}.cm-s-default .cm-qualifier{color:#555}.cm-s-default .cm-builtin{color:#30a}.cm-s-default .cm-bracket{color:#997}.cm-s-default .cm-tag{color:#170}.cm-s-default .cm-attribute{color:#00c}.cm-s-default .cm-hr{color:#999}.cm-s-default .cm-link{color:#00c}.cm-s-default .cm-error{color:red}.cm-invalidchar{color:red}.CodeMirror-composing{border-bottom:2px solid}div.CodeMirror span.CodeMirror-matchingbracket{color:#0f0}div.CodeMirror span.CodeMirror-nonmatchingbracket{color:#f22}.CodeMirror-matchingtag{background:rgba(255,150,0,.3)}.CodeMirror-activeline-background{background:#e8f2ff}.CodeMirror{position:relative;overflow:hidden;background:#fff}.CodeMirror-scroll{overflow:scroll!important;margin-bottom:-30px;margin-right:-30px;padding-bottom:30px;height:100%;outline:0;position:relative}.CodeMirror-sizer{position:relative;border-right:30px solid transparent}.CodeMirror-gutter-filler,.CodeMirror-hscrollbar,.CodeMirror-scrollbar-filler,.CodeMirror-vscrollbar{position:absolute;z-index:6;display:none}.CodeMirror-vscrollbar{right:0;top:0;overflow-x:hidden;overflow-y:scroll}.CodeMirror-hscrollbar{bottom:0;left:0;overflow-y:hidden;overflow-x:scroll}.CodeMirror-scrollbar-filler{right:0;bottom:0}.CodeMirror-gutter-filler{left:0;bottom:0}.CodeMirror-gutters{position:absolute;left:0;top:0;min-height:100%;z-index:3}.CodeMirror-gutter{white-space:normal;height:100%;display:inline-block;vertical-align:top;margin-bottom:-30px}.CodeMirror-gutter-wrapper{position:absolute;z-index:4;background:0 0!important;border:none!important}.CodeMirror-gutter-background{position:absolute;top:0;bottom:0;z-index:4}.CodeMirror-gutter-elt{position:absolute;cursor:default;z-index:4}.CodeMirror-gutter-wrapper ::selection{background-color:transparent}.CodeMirror-gutter-wrapper ::-moz-selection{background-color:transparent}.CodeMirror-lines{cursor:text;min-height:1px}.CodeMirror pre{-moz-border-radius:0;-webkit-border-radius:0;border-radius:0;border-width:0;background:0 0;font-family:inherit;font-size:inherit;margin:0;white-space:pre;word-wrap:normal;line-height:inherit;color:inherit;z-index:2;position:relative;overflow:visible;-webkit-tap-highlight-color:transparent;-webkit-font-variant-ligatures:contextual;font-variant-ligatures:contextual}.CodeMirror-wrap pre{word-wrap:break-word;white-space:pre-wrap;word-break:normal}.CodeMirror-linebackground{position:absolute;left:0;right:0;top:0;bottom:0;z-index:0}.CodeMirror-linewidget{position:relative;z-index:2;overflow:auto}.CodeMirror-rtl pre{direction:rtl}.CodeMirror-code{outline:0}.CodeMirror-gutter,.CodeMirror-gutters,.CodeMirror-linenumber,.CodeMirror-scroll,.CodeMirror-sizer{-moz-box-sizing:content-box;box-sizing:content-box}.CodeMirror-measure{position:absolute;width:100%;height:0;overflow:hidden;visibility:hidden}.CodeMirror-cursor{position:absolute;pointer-events:none}.CodeMirror-measure pre{position:static}div.CodeMirror-cursors{visibility:hidden;position:relative;z-index:3}div.CodeMirror-dragcursors{visibility:visible}.CodeMirror-focused div.CodeMirror-cursors{visibility:visible}.CodeMirror-selected{background:#d9d9d9}.CodeMirror-focused .CodeMirror-selected{background:#d7d4f0}.CodeMirror-crosshair{cursor:crosshair}.CodeMirror-line::selection,.CodeMirror-line>span::selection,.CodeMirror-line>span>span::selection{background:#d7d4f0}.CodeMirror-line::-moz-selection,.CodeMirror-line>span::-moz-selection,.CodeMirror-line>span>span::-moz-selection{background:#d7d4f0}.cm-searching{background-color:#ffa;background-color:rgba(255,255,0,.4)}.cm-force-border{padding-right:.1px}@media print{.CodeMirror div.CodeMirror-cursors{visibility:hidden}}.cm-tab-wrap-hack:after{content:''}span.CodeMirror-selectedtext{background:0 0}
/*# sourceMappingURL=codemirror.min.css.map */

      .severity-low {
  background-color: #669603;
}

.severity-low:after {
  content : 'L';
}

.severity-unspecified {
  background-color: #666666;
}

.severity-unspecified:after {
  content : 'U';
}

.severity-style {
  background-color: #9932cc;
}

.severity-style:after {
  content : 'S';
}

.severity-medium {
  background-color: #a9d323;
  color: black;
}

.severity-medium:after {
  content : 'M';
}

.severity-high {
  background-color: #ffa800;
}

.severity-high:after {
  content : 'H';
}

.severity-critical {
  background-color: #e92625;
}

.severity-critical:after {
  content : 'C';
}

i[class*="severity-"] {
  line-height: normal;
  text-transform: capitalize;
  font-size: 0.8em;
  font-weight: bold;
  color: white;
  display: inline-block;
  width: 16px;
  height: 16px;
  text-align: center;
  font-family: sans-serif;
}

      html, body {
  width: 100%;
  height: 100%;
  padding: 0px;
  margin: 0px;
}

div.container {
  padding: 10px;
}

#content {
  height: 100%;
  display: block;
  overflow: hidden;
}

#content > div {
  margin: 10px;
  overflow: hidden;
  border: 1px solid #ddd;
  border-radius: 3px;
  overflow: hidden;
  height: 97%;
}

.button {
  background-color: #f1f1f1;
  text-decoration: none;
  display: inline-block;
  padding: 8px 16px;
  color: black;
  cursor: pointer;
}

.button:hover {
  background-color: #ddd;
  color: black;
}

.review-status {
  color: white;
  text-align: center;
}

.review-status-confirmed {
  background-color: #e92625;
}

.review-status-false-positive {
  background-color: grey;
}

.review-status-intentional {
  background-color: #669603;
}

      div.container {
  width: 100%;
  height: 100%;
  padding: 0px;
}

#editor-wrapper {
  margin: 10px;
}

#side-bar {
  float: left;
  width: 260px;
  margin: 0px;
}

#report-nav ul {
  list-style-type: none;
  padding: 0;
  margin: 0;
  overflow-y: auto;
  height: 100%;
}

#report-nav ul > li {
  padding: .4em;
  background-color: #fff;
  border-bottom: 1px solid rgba(0,0,0,.125);
  text-align: left;
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

#report-nav ul > li.active {
  background-color: #427ea9;
  color: white;
}

#report-nav ul > li:hover {
  background-color: #427ea9;
  color: white;
  cursor: pointer;
}

#report-nav ul a {
  text-decoration: none;
}

#report-nav i[class*="severity-"] {
  margin-right: 5px;
}

.header {
  border-bottom: 1px solid lightgrey;
  font-family: monospace;
  padding: 10px;
  background-color: #fafbfc;
  border-bottom: 1px solid #e1e4e8;
  border-top-left-radius: 2px;
  border-top-right-radius: 2px;
}

#report-nav .header {
  font-weight: bold;
}

#editor-wrapper .header > div {
  padding-top: 2px;
}

#file-path,
#checker-name {
  color: #195ea2;
}

#review-status {
  padding: 0px 5px;
}

#file-path {
  font-family: monospace;
}

.check-msg {
  display: inline-block;
  padding: 3px 6px;
  margin: 1px;
  -webkit-border-radius: 5px;
  -moz-border-radius: 5px;
  border-radius: 5px;
}

.check-msg.info {
  color: #00546f;
  background-color: #bfdfe9;
  border: 1px solid #87a8b3;
}

.check-msg.error {
  background-color: #f2dede;
  color: #a94442;
  border: 1px solid #ebcccc;
}

.check-msg.macro {
  background-color: #d7dac2;
  color: #4f5c6d;
  border: 1px solid #d7dac2;
}

.check-msg.note {
  background-color: #d7d7d7;
  color: #4f5c6d;
  border: 1px solid #bfbfbf;
}

.check-msg.current {
  border: 2px dashed #3692ff;
}

.check-msg .tag {
  padding: 1px 5px;
  text-align: center;
  border-radius: 2px;
  margin-right: 5px;
  text-decoration: inherit;
}

.check-msg .tag.macro {
  background-color: #83876a;
  color: white;
  text-transform: capitalize;
}

.check-msg .tag.note {
  background-color: #9299a1;
  color: white;
  text-transform: capitalize;
}

.checker-enum {
  color: white;
  padding: 1px 5px;
  text-align: center;
  border-radius: 25px;
  margin-right: 5px;
  text-decoration: inherit;
}

.checker-enum.info {
  background-color: #427ea9;
}

.checker-enum.error {
  background-color: #a94442;
}

.arrow {
  border: solid black;
  border-width: 0 3px 3px 0;
  display: inline-block;
  padding: 3px;
  cursor: pointer;
  margin: 0px 5px;
}

.arrow:hover {
  border: solid #437ea8;
  border-width: 0 3px 3px 0;
}

.left-arrow {
  transform: rotate(135deg);
  -webkit-transform: rotate(135deg);
}

.right-arrow {
  transform: rotate(-45deg);
  -webkit-transform: rotate(-45deg);
}

    </style>

    <script type="text/javascript">
      function setNonCompatibleBrowserMessage() {
  document.body.innerHTML =
    '<h2 style="margin-left: 20px;">Your browser is not compatible with CodeChecker Viewer!</h2> \
     <p style="margin-left: 20px;">The version required for the following browsers are:</p> \
     <ul style="margin-left: 20px;"> \
     <li>Internet Explorer: version 9 or newer</li> \
     <li>Firefox: version 22.0 or newer</li> \
     </ul>';
}

// http://stackoverflow.com/questions/5916900/how-can-you-detect-the-version-of-a-browser
var browserVersion = (function(){
  var ua = navigator.userAgent, tem,
    M = ua.match(/(opera|chrome|safari|firefox|msie|trident(?=\/))\/?\s*(\d+)/i) || [];

  if (/trident/i.test(M[1])) {
    tem = /\brv[ :]+(\d+)/g.exec(ua) || [];
    return 'IE ' + (tem[1] || '');
  }

  if (M[1] === 'Chrome') {
    tem = ua.match(/\b(OPR|Edge)\/(\d+)/);
    if (tem != null) return tem.slice(1).join(' ').replace('OPR', 'Opera');
  }

  M = M[2] ? [M[1], M[2]] : [navigator.appName, navigator.appVersion, '-?'];
  if ((tem = ua.match(/version\/(\d+)/i)) != null) M.splice(1, 1, tem[1]);
    return M.join(' ');
})();

var pos = browserVersion.indexOf(' ');
var browser = browserVersion.substr(0, pos);
var version = parseInt(browserVersion.substr(pos + 1));

var browserCompatible
  = browser === 'Firefox'
  ? version >= 22
  : browser === 'IE'
  ? version >= 9
  : true;


      /* MIT License

Copyright (C) 2017 by Marijn Haverbeke <marijnh@gmail.com> and others

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
 */
      !function(e,t){"object"==typeof exports&&"undefined"!=typeof module?module.exports=t():"function"==typeof define&&define.amd?define(t):e.CodeMirror=t()}(this,function(){"use strict";function e(e){return new RegExp("(^|\\s)"+e+"(?:$|\\s)\\s*")}function t(e){for(var t=e.childNodes.length;t>0;--t)e.removeChild(e.firstChild);return e}function r(e,r){return t(e).appendChild(r)}function n(e,t,r,n){var i=document.createElement(e);if(r&&(i.className=r),n&&(i.style.cssText=n),"string"==typeof t)i.appendChild(document.createTextNode(t));else if(t)for(var o=0;o<t.length;++o)i.appendChild(t[o]);return i}function i(e,t,r,i){var o=n(e,t,r,i);return o.setAttribute("role","presentation"),o}function o(e,t){if(3==t.nodeType&&(t=t.parentNode),e.contains)return e.contains(t);do{if(11==t.nodeType&&(t=t.host),t==e)return!0}while(t=t.parentNode)}function l(){var e;try{e=document.activeElement}catch(t){e=document.body||null}for(;e&&e.shadowRoot&&e.shadowRoot.activeElement;)e=e.shadowRoot.activeElement;return e}function s(t,r){var n=t.className;e(r).test(n)||(t.className+=(n?" ":"")+r)}function a(t,r){for(var n=t.split(" "),i=0;i<n.length;i++)n[i]&&!e(n[i]).test(r)&&(r+=" "+n[i]);return r}function u(e){var t=Array.prototype.slice.call(arguments,1);return function(){return e.apply(null,t)}}function c(e,t,r){t||(t={});for(var n in e)!e.hasOwnProperty(n)||!1===r&&t.hasOwnProperty(n)||(t[n]=e[n]);return t}function f(e,t,r,n,i){null==t&&-1==(t=e.search(/[^\s\u00a0]/))&&(t=e.length);for(var o=n||0,l=i||0;;){var s=e.indexOf("\t",o);if(s<0||s>=t)return l+(t-o);l+=s-o,l+=r-l%r,o=s+1}}function h(e,t){for(var r=0;r<e.length;++r)if(e[r]==t)return r;return-1}function d(e,t,r){for(var n=0,i=0;;){var o=e.indexOf("\t",n);-1==o&&(o=e.length);var l=o-n;if(o==e.length||i+l>=t)return n+Math.min(l,t-i);if(i+=o-n,i+=r-i%r,n=o+1,i>=t)return n}}function p(e){for(;Kl.length<=e;)Kl.push(g(Kl)+" ");return Kl[e]}function g(e){return e[e.length-1]}function v(e,t){for(var r=[],n=0;n<e.length;n++)r[n]=t(e[n],n);return r}function m(e,t,r){for(var n=0,i=r(t);n<e.length&&r(e[n])<=i;)n++;e.splice(n,0,t)}function y(){}function b(e,t){var r;return Object.create?r=Object.create(e):(y.prototype=e,r=new y),t&&c(t,r),r}function w(e){return/\w/.test(e)||e>""&&(e.toUpperCase()!=e.toLowerCase()||jl.test(e))}function x(e,t){return t?!!(t.source.indexOf("\\w")>-1&&w(e))||t.test(e):w(e)}function C(e){for(var t in e)if(e.hasOwnProperty(t)&&e[t])return!1;return!0}function S(e){return e.charCodeAt(0)>=768&&Xl.test(e)}function L(e,t,r){for(;(r<0?t>0:t<e.length)&&S(e.charAt(t));)t+=r;return t}function k(e,t,r){for(var n=t>r?-1:1;;){if(t==r)return t;var i=(t+r)/2,o=n<0?Math.ceil(i):Math.floor(i);if(o==t)return e(o)?t:r;e(o)?r=o:t=o+n}}function T(e,t,r){var o=this;this.input=r,o.scrollbarFiller=n("div",null,"CodeMirror-scrollbar-filler"),o.scrollbarFiller.setAttribute("cm-not-content","true"),o.gutterFiller=n("div",null,"CodeMirror-gutter-filler"),o.gutterFiller.setAttribute("cm-not-content","true"),o.lineDiv=i("div",null,"CodeMirror-code"),o.selectionDiv=n("div",null,null,"position: relative; z-index: 1"),o.cursorDiv=n("div",null,"CodeMirror-cursors"),o.measure=n("div",null,"CodeMirror-measure"),o.lineMeasure=n("div",null,"CodeMirror-measure"),o.lineSpace=i("div",[o.measure,o.lineMeasure,o.selectionDiv,o.cursorDiv,o.lineDiv],null,"position: relative; outline: none");var l=i("div",[o.lineSpace],"CodeMirror-lines");o.mover=n("div",[l],null,"position: relative"),o.sizer=n("div",[o.mover],"CodeMirror-sizer"),o.sizerWidth=null,o.heightForcer=n("div",null,null,"position: absolute; height: "+Rl+"px; width: 1px;"),o.gutters=n("div",null,"CodeMirror-gutters"),o.lineGutter=null,o.scroller=n("div",[o.sizer,o.heightForcer,o.gutters],"CodeMirror-scroll"),o.scroller.setAttribute("tabIndex","-1"),o.wrapper=n("div",[o.scrollbarFiller,o.gutterFiller,o.scroller],"CodeMirror"),gl&&vl<8&&(o.gutters.style.zIndex=-1,o.scroller.style.paddingRight=0),ml||fl&&Tl||(o.scroller.draggable=!0),e&&(e.appendChild?e.appendChild(o.wrapper):e(o.wrapper)),o.viewFrom=o.viewTo=t.first,o.reportedViewFrom=o.reportedViewTo=t.first,o.view=[],o.renderedView=null,o.externalMeasured=null,o.viewOffset=0,o.lastWrapHeight=o.lastWrapWidth=0,o.updateLineNumbers=null,o.nativeBarWidth=o.barHeight=o.barWidth=0,o.scrollbarsClipped=!1,o.lineNumWidth=o.lineNumInnerWidth=o.lineNumChars=null,o.alignWidgets=!1,o.cachedCharWidth=o.cachedTextHeight=o.cachedPaddingH=null,o.maxLine=null,o.maxLineLength=0,o.maxLineChanged=!1,o.wheelDX=o.wheelDY=o.wheelStartX=o.wheelStartY=null,o.shift=!1,o.selForContextMenu=null,o.activeTouch=null,r.init(o)}function M(e,t){if((t-=e.first)<0||t>=e.size)throw new Error("There is no line "+(t+e.first)+" in the document.");for(var r=e;!r.lines;)for(var n=0;;++n){var i=r.children[n],o=i.chunkSize();if(t<o){r=i;break}t-=o}return r.lines[t]}function N(e,t,r){var n=[],i=t.line;return e.iter(t.line,r.line+1,function(e){var o=e.text;i==r.line&&(o=o.slice(0,r.ch)),i==t.line&&(o=o.slice(t.ch)),n.push(o),++i}),n}function O(e,t,r){var n=[];return e.iter(t,r,function(e){n.push(e.text)}),n}function A(e,t){var r=t-e.height;if(r)for(var n=e;n;n=n.parent)n.height+=r}function W(e){if(null==e.parent)return null;for(var t=e.parent,r=h(t.lines,e),n=t.parent;n;t=n,n=n.parent)for(var i=0;n.children[i]!=t;++i)r+=n.children[i].chunkSize();return r+t.first}function D(e,t){var r=e.first;e:do{for(var n=0;n<e.children.length;++n){var i=e.children[n],o=i.height;if(t<o){e=i;continue e}t-=o,r+=i.chunkSize()}return r}while(!e.lines);for(var l=0;l<e.lines.length;++l){var s=e.lines[l].height;if(t<s)break;t-=s}return r+l}function H(e,t){return t>=e.first&&t<e.first+e.size}function F(e,t){return String(e.lineNumberFormatter(t+e.firstLineNumber))}function E(e,t,r){if(void 0===r&&(r=null),!(this instanceof E))return new E(e,t,r);this.line=e,this.ch=t,this.sticky=r}function P(e,t){return e.line-t.line||e.ch-t.ch}function I(e,t){return e.sticky==t.sticky&&0==P(e,t)}function z(e){return E(e.line,e.ch)}function R(e,t){return P(e,t)<0?t:e}function B(e,t){return P(e,t)<0?e:t}function G(e,t){return Math.max(e.first,Math.min(t,e.first+e.size-1))}function U(e,t){if(t.line<e.first)return E(e.first,0);var r=e.first+e.size-1;return t.line>r?E(r,M(e,r).text.length):V(t,M(e,t.line).text.length)}function V(e,t){var r=e.ch;return null==r||r>t?E(e.line,t):r<0?E(e.line,0):e}function K(e,t){for(var r=[],n=0;n<t.length;n++)r[n]=U(e,t[n]);return r}function j(){Yl=!0}function X(){_l=!0}function Y(e,t,r){this.marker=e,this.from=t,this.to=r}function _(e,t){if(e)for(var r=0;r<e.length;++r){var n=e[r];if(n.marker==t)return n}}function $(e,t){for(var r,n=0;n<e.length;++n)e[n]!=t&&(r||(r=[])).push(e[n]);return r}function q(e,t){e.markedSpans=e.markedSpans?e.markedSpans.concat([t]):[t],t.marker.attachLine(e)}function Z(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t)||o.from==t&&"bookmark"==l.type&&(!r||!o.marker.insertLeft)){var s=null==o.to||(l.inclusiveRight?o.to>=t:o.to>t);(n||(n=[])).push(new Y(l,o.from,s?null:o.to))}}return n}function Q(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.to||(l.inclusiveRight?o.to>=t:o.to>t)||o.from==t&&"bookmark"==l.type&&(!r||o.marker.insertLeft)){var s=null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t);(n||(n=[])).push(new Y(l,s?null:o.from-t,null==o.to?null:o.to-t))}}return n}function J(e,t){if(t.full)return null;var r=H(e,t.from.line)&&M(e,t.from.line).markedSpans,n=H(e,t.to.line)&&M(e,t.to.line).markedSpans;if(!r&&!n)return null;var i=t.from.ch,o=t.to.ch,l=0==P(t.from,t.to),s=Z(r,i,l),a=Q(n,o,l),u=1==t.text.length,c=g(t.text).length+(u?i:0);if(s)for(var f=0;f<s.length;++f){var h=s[f];if(null==h.to){var d=_(a,h.marker);d?u&&(h.to=null==d.to?null:d.to+c):h.to=i}}if(a)for(var p=0;p<a.length;++p){var v=a[p];null!=v.to&&(v.to+=c),null==v.from?_(s,v.marker)||(v.from=c,u&&(s||(s=[])).push(v)):(v.from+=c,u&&(s||(s=[])).push(v))}s&&(s=ee(s)),a&&a!=s&&(a=ee(a));var m=[s];if(!u){var y,b=t.text.length-2;if(b>0&&s)for(var w=0;w<s.length;++w)null==s[w].to&&(y||(y=[])).push(new Y(s[w].marker,null,null));for(var x=0;x<b;++x)m.push(y);m.push(a)}return m}function ee(e){for(var t=0;t<e.length;++t){var r=e[t];null!=r.from&&r.from==r.to&&!1!==r.marker.clearWhenEmpty&&e.splice(t--,1)}return e.length?e:null}function te(e,t,r){var n=null;if(e.iter(t.line,r.line+1,function(e){if(e.markedSpans)for(var t=0;t<e.markedSpans.length;++t){var r=e.markedSpans[t].marker;!r.readOnly||n&&-1!=h(n,r)||(n||(n=[])).push(r)}}),!n)return null;for(var i=[{from:t,to:r}],o=0;o<n.length;++o)for(var l=n[o],s=l.find(0),a=0;a<i.length;++a){var u=i[a];if(!(P(u.to,s.from)<0||P(u.from,s.to)>0)){var c=[a,1],f=P(u.from,s.from),d=P(u.to,s.to);(f<0||!l.inclusiveLeft&&!f)&&c.push({from:u.from,to:s.from}),(d>0||!l.inclusiveRight&&!d)&&c.push({from:s.to,to:u.to}),i.splice.apply(i,c),a+=c.length-3}}return i}function re(e){var t=e.markedSpans;if(t){for(var r=0;r<t.length;++r)t[r].marker.detachLine(e);e.markedSpans=null}}function ne(e,t){if(t){for(var r=0;r<t.length;++r)t[r].marker.attachLine(e);e.markedSpans=t}}function ie(e){return e.inclusiveLeft?-1:0}function oe(e){return e.inclusiveRight?1:0}function le(e,t){var r=e.lines.length-t.lines.length;if(0!=r)return r;var n=e.find(),i=t.find(),o=P(n.from,i.from)||ie(e)-ie(t);if(o)return-o;var l=P(n.to,i.to)||oe(e)-oe(t);return l||t.id-e.id}function se(e,t){var r,n=_l&&e.markedSpans;if(n)for(var i=void 0,o=0;o<n.length;++o)(i=n[o]).marker.collapsed&&null==(t?i.from:i.to)&&(!r||le(r,i.marker)<0)&&(r=i.marker);return r}function ae(e){return se(e,!0)}function ue(e){return se(e,!1)}function ce(e,t,r,n,i){var o=M(e,t),l=_l&&o.markedSpans;if(l)for(var s=0;s<l.length;++s){var a=l[s];if(a.marker.collapsed){var u=a.marker.find(0),c=P(u.from,r)||ie(a.marker)-ie(i),f=P(u.to,n)||oe(a.marker)-oe(i);if(!(c>=0&&f<=0||c<=0&&f>=0)&&(c<=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.to,r)>=0:P(u.to,r)>0)||c>=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.from,n)<=0:P(u.from,n)<0)))return!0}}}function fe(e){for(var t;t=ae(e);)e=t.find(-1,!0).line;return e}function he(e){for(var t;t=ue(e);)e=t.find(1,!0).line;return e}function de(e){for(var t,r;t=ue(e);)e=t.find(1,!0).line,(r||(r=[])).push(e);return r}function pe(e,t){var r=M(e,t),n=fe(r);return r==n?t:W(n)}function ge(e,t){if(t>e.lastLine())return t;var r,n=M(e,t);if(!ve(e,n))return t;for(;r=ue(n);)n=r.find(1,!0).line;return W(n)+1}function ve(e,t){var r=_l&&t.markedSpans;if(r)for(var n=void 0,i=0;i<r.length;++i)if((n=r[i]).marker.collapsed){if(null==n.from)return!0;if(!n.marker.widgetNode&&0==n.from&&n.marker.inclusiveLeft&&me(e,t,n))return!0}}function me(e,t,r){if(null==r.to){var n=r.marker.find(1,!0);return me(e,n.line,_(n.line.markedSpans,r.marker))}if(r.marker.inclusiveRight&&r.to==t.text.length)return!0;for(var i=void 0,o=0;o<t.markedSpans.length;++o)if((i=t.markedSpans[o]).marker.collapsed&&!i.marker.widgetNode&&i.from==r.to&&(null==i.to||i.to!=r.from)&&(i.marker.inclusiveLeft||r.marker.inclusiveRight)&&me(e,t,i))return!0}function ye(e){for(var t=0,r=(e=fe(e)).parent,n=0;n<r.lines.length;++n){var i=r.lines[n];if(i==e)break;t+=i.height}for(var o=r.parent;o;r=o,o=r.parent)for(var l=0;l<o.children.length;++l){var s=o.children[l];if(s==r)break;t+=s.height}return t}function be(e){if(0==e.height)return 0;for(var t,r=e.text.length,n=e;t=ae(n);){var i=t.find(0,!0);n=i.from.line,r+=i.from.ch-i.to.ch}for(n=e;t=ue(n);){var o=t.find(0,!0);r-=n.text.length-o.from.ch,r+=(n=o.to.line).text.length-o.to.ch}return r}function we(e){var t=e.display,r=e.doc;t.maxLine=M(r,r.first),t.maxLineLength=be(t.maxLine),t.maxLineChanged=!0,r.iter(function(e){var r=be(e);r>t.maxLineLength&&(t.maxLineLength=r,t.maxLine=e)})}function xe(e,t,r,n){if(!e)return n(t,r,"ltr",0);for(var i=!1,o=0;o<e.length;++o){var l=e[o];(l.from<r&&l.to>t||t==r&&l.to==t)&&(n(Math.max(l.from,t),Math.min(l.to,r),1==l.level?"rtl":"ltr",o),i=!0)}i||n(t,r,"ltr")}function Ce(e,t,r){var n;$l=null;for(var i=0;i<e.length;++i){var o=e[i];if(o.from<t&&o.to>t)return i;o.to==t&&(o.from!=o.to&&"before"==r?n=i:$l=i),o.from==t&&(o.from!=o.to&&"before"!=r?n=i:$l=i)}return null!=n?n:$l}function Se(e,t){var r=e.order;return null==r&&(r=e.order=ql(e.text,t)),r}function Le(e,t){return e._handlers&&e._handlers[t]||Zl}function ke(e,t,r){if(e.removeEventListener)e.removeEventListener(t,r,!1);else if(e.detachEvent)e.detachEvent("on"+t,r);else{var n=e._handlers,i=n&&n[t];if(i){var o=h(i,r);o>-1&&(n[t]=i.slice(0,o).concat(i.slice(o+1)))}}}function Te(e,t){var r=Le(e,t);if(r.length)for(var n=Array.prototype.slice.call(arguments,2),i=0;i<r.length;++i)r[i].apply(null,n)}function Me(e,t,r){return"string"==typeof t&&(t={type:t,preventDefault:function(){this.defaultPrevented=!0}}),Te(e,r||t.type,e,t),He(t)||t.codemirrorIgnore}function Ne(e){var t=e._handlers&&e._handlers.cursorActivity;if(t)for(var r=e.curOp.cursorActivityHandlers||(e.curOp.cursorActivityHandlers=[]),n=0;n<t.length;++n)-1==h(r,t[n])&&r.push(t[n])}function Oe(e,t){return Le(e,t).length>0}function Ae(e){e.prototype.on=function(e,t){Ql(this,e,t)},e.prototype.off=function(e,t){ke(this,e,t)}}function We(e){e.preventDefault?e.preventDefault():e.returnValue=!1}function De(e){e.stopPropagation?e.stopPropagation():e.cancelBubble=!0}function He(e){return null!=e.defaultPrevented?e.defaultPrevented:0==e.returnValue}function Fe(e){We(e),De(e)}function Ee(e){return e.target||e.srcElement}function Pe(e){var t=e.which;return null==t&&(1&e.button?t=1:2&e.button?t=3:4&e.button&&(t=2)),Ml&&e.ctrlKey&&1==t&&(t=3),t}function Ie(e){if(null==Il){var t=n("span","​");r(e,n("span",[t,document.createTextNode("x")])),0!=e.firstChild.offsetHeight&&(Il=t.offsetWidth<=1&&t.offsetHeight>2&&!(gl&&vl<8))}var i=Il?n("span","​"):n("span"," ",null,"display: inline-block; width: 1px; margin-right: -1px");return i.setAttribute("cm-text",""),i}function ze(e){if(null!=zl)return zl;var n=r(e,document.createTextNode("AخA")),i=Wl(n,0,1).getBoundingClientRect(),o=Wl(n,1,2).getBoundingClientRect();return t(e),!(!i||i.left==i.right)&&(zl=o.right-i.right<3)}function Re(e){if(null!=ns)return ns;var t=r(e,n("span","x")),i=t.getBoundingClientRect(),o=Wl(t,0,1).getBoundingClientRect();return ns=Math.abs(i.left-o.left)>1}function Be(e,t){arguments.length>2&&(t.dependencies=Array.prototype.slice.call(arguments,2)),is[e]=t}function Ge(e){if("string"==typeof e&&os.hasOwnProperty(e))e=os[e];else if(e&&"string"==typeof e.name&&os.hasOwnProperty(e.name)){var t=os[e.name];"string"==typeof t&&(t={name:t}),(e=b(t,e)).name=t.name}else{if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+xml$/.test(e))return Ge("application/xml");if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+json$/.test(e))return Ge("application/json")}return"string"==typeof e?{name:e}:e||{name:"null"}}function Ue(e,t){t=Ge(t);var r=is[t.name];if(!r)return Ue(e,"text/plain");var n=r(e,t);if(ls.hasOwnProperty(t.name)){var i=ls[t.name];for(var o in i)i.hasOwnProperty(o)&&(n.hasOwnProperty(o)&&(n["_"+o]=n[o]),n[o]=i[o])}if(n.name=t.name,t.helperType&&(n.helperType=t.helperType),t.modeProps)for(var l in t.modeProps)n[l]=t.modeProps[l];return n}function Ve(e,t){c(t,ls.hasOwnProperty(e)?ls[e]:ls[e]={})}function Ke(e,t){if(!0===t)return t;if(e.copyState)return e.copyState(t);var r={};for(var n in t){var i=t[n];i instanceof Array&&(i=i.concat([])),r[n]=i}return r}function je(e,t){for(var r;e.innerMode&&(r=e.innerMode(t))&&r.mode!=e;)t=r.state,e=r.mode;return r||{mode:e,state:t}}function Xe(e,t,r){return!e.startState||e.startState(t,r)}function Ye(e,t,r,n){var i=[e.state.modeGen],o={};tt(e,t.text,e.doc.mode,r,function(e,t){return i.push(e,t)},o,n);for(var l=r.state,s=0;s<e.state.overlays.length;++s)!function(n){var l=e.state.overlays[n],s=1,a=0;r.state=!0,tt(e,t.text,l.mode,r,function(e,t){for(var r=s;a<e;){var n=i[s];n>e&&i.splice(s,1,e,i[s+1],n),s+=2,a=Math.min(e,n)}if(t)if(l.opaque)i.splice(r,s-r,e,"overlay "+t),s=r+2;else for(;r<s;r+=2){var o=i[r+1];i[r+1]=(o?o+" ":"")+"overlay "+t}},o)}(s);return r.state=l,{styles:i,classes:o.bgClass||o.textClass?o:null}}function _e(e,t,r){if(!t.styles||t.styles[0]!=e.state.modeGen){var n=$e(e,W(t)),i=t.text.length>e.options.maxHighlightLength&&Ke(e.doc.mode,n.state),o=Ye(e,t,n);i&&(n.state=i),t.stateAfter=n.save(!i),t.styles=o.styles,o.classes?t.styleClasses=o.classes:t.styleClasses&&(t.styleClasses=null),r===e.doc.highlightFrontier&&(e.doc.modeFrontier=Math.max(e.doc.modeFrontier,++e.doc.highlightFrontier))}return t.styles}function $e(e,t,r){var n=e.doc,i=e.display;if(!n.mode.startState)return new us(n,!0,t);var o=rt(e,t,r),l=o>n.first&&M(n,o-1).stateAfter,s=l?us.fromSaved(n,l,o):new us(n,Xe(n.mode),o);return n.iter(o,t,function(r){qe(e,r.text,s);var n=s.line;r.stateAfter=n==t-1||n%5==0||n>=i.viewFrom&&n<i.viewTo?s.save():null,s.nextLine()}),r&&(n.modeFrontier=s.line),s}function qe(e,t,r,n){var i=e.doc.mode,o=new ss(t,e.options.tabSize,r);for(o.start=o.pos=n||0,""==t&&Ze(i,r.state);!o.eol();)Qe(i,o,r.state),o.start=o.pos}function Ze(e,t){if(e.blankLine)return e.blankLine(t);if(e.innerMode){var r=je(e,t);return r.mode.blankLine?r.mode.blankLine(r.state):void 0}}function Qe(e,t,r,n){for(var i=0;i<10;i++){n&&(n[0]=je(e,r).mode);var o=e.token(t,r);if(t.pos>t.start)return o}throw new Error("Mode "+e.name+" failed to advance stream.")}function Je(e,t,r,n){var i,o,l=e.doc,s=l.mode,a=M(l,(t=U(l,t)).line),u=$e(e,t.line,r),c=new ss(a.text,e.options.tabSize,u);for(n&&(o=[]);(n||c.pos<t.ch)&&!c.eol();)c.start=c.pos,i=Qe(s,c,u.state),n&&o.push(new cs(c,i,Ke(l.mode,u.state)));return n?o:new cs(c,i,u.state)}function et(e,t){if(e)for(;;){var r=e.match(/(?:^|\s+)line-(background-)?(\S+)/);if(!r)break;e=e.slice(0,r.index)+e.slice(r.index+r[0].length);var n=r[1]?"bgClass":"textClass";null==t[n]?t[n]=r[2]:new RegExp("(?:^|s)"+r[2]+"(?:$|s)").test(t[n])||(t[n]+=" "+r[2])}return e}function tt(e,t,r,n,i,o,l){var s=r.flattenSpans;null==s&&(s=e.options.flattenSpans);var a,u=0,c=null,f=new ss(t,e.options.tabSize,n),h=e.options.addModeClass&&[null];for(""==t&&et(Ze(r,n.state),o);!f.eol();){if(f.pos>e.options.maxHighlightLength?(s=!1,l&&qe(e,t,n,f.pos),f.pos=t.length,a=null):a=et(Qe(r,f,n.state,h),o),h){var d=h[0].name;d&&(a="m-"+(a?d+" "+a:d))}if(!s||c!=a){for(;u<f.start;)i(u=Math.min(f.start,u+5e3),c);c=a}f.start=f.pos}for(;u<f.pos;){var p=Math.min(f.pos,u+5e3);i(p,c),u=p}}function rt(e,t,r){for(var n,i,o=e.doc,l=r?-1:t-(e.doc.mode.innerMode?1e3:100),s=t;s>l;--s){if(s<=o.first)return o.first;var a=M(o,s-1),u=a.stateAfter;if(u&&(!r||s+(u instanceof as?u.lookAhead:0)<=o.modeFrontier))return s;var c=f(a.text,null,e.options.tabSize);(null==i||n>c)&&(i=s-1,n=c)}return i}function nt(e,t){if(e.modeFrontier=Math.min(e.modeFrontier,t),!(e.highlightFrontier<t-10)){for(var r=e.first,n=t-1;n>r;n--){var i=M(e,n).stateAfter;if(i&&(!(i instanceof as)||n+i.lookAhead<t)){r=n+1;break}}e.highlightFrontier=Math.min(e.highlightFrontier,r)}}function it(e,t,r,n){e.text=t,e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null),null!=e.order&&(e.order=null),re(e),ne(e,r);var i=n?n(e):1;i!=e.height&&A(e,i)}function ot(e){e.parent=null,re(e)}function lt(e,t){if(!e||/^\s*$/.test(e))return null;var r=t.addModeClass?ps:ds;return r[e]||(r[e]=e.replace(/\S+/g,"cm-$&"))}function st(e,t){var r=i("span",null,null,ml?"padding-right: .1px":null),n={pre:i("pre",[r],"CodeMirror-line"),content:r,col:0,pos:0,cm:e,trailingSpace:!1,splitSpaces:(gl||ml)&&e.getOption("lineWrapping")};t.measure={};for(var o=0;o<=(t.rest?t.rest.length:0);o++){var l=o?t.rest[o-1]:t.line,s=void 0;n.pos=0,n.addToken=ut,ze(e.display.measure)&&(s=Se(l,e.doc.direction))&&(n.addToken=ft(n.addToken,s)),n.map=[],dt(l,n,_e(e,l,t!=e.display.externalMeasured&&W(l))),l.styleClasses&&(l.styleClasses.bgClass&&(n.bgClass=a(l.styleClasses.bgClass,n.bgClass||"")),l.styleClasses.textClass&&(n.textClass=a(l.styleClasses.textClass,n.textClass||""))),0==n.map.length&&n.map.push(0,0,n.content.appendChild(Ie(e.display.measure))),0==o?(t.measure.map=n.map,t.measure.cache={}):((t.measure.maps||(t.measure.maps=[])).push(n.map),(t.measure.caches||(t.measure.caches=[])).push({}))}if(ml){var u=n.content.lastChild;(/\bcm-tab\b/.test(u.className)||u.querySelector&&u.querySelector(".cm-tab"))&&(n.content.className="cm-tab-wrap-hack")}return Te(e,"renderLine",e,t.line,n.pre),n.pre.className&&(n.textClass=a(n.pre.className,n.textClass||"")),n}function at(e){var t=n("span","•","cm-invalidchar");return t.title="\\u"+e.charCodeAt(0).toString(16),t.setAttribute("aria-label",t.title),t}function ut(e,t,r,i,o,l,s){if(t){var a,u=e.splitSpaces?ct(t,e.trailingSpace):t,c=e.cm.state.specialChars,f=!1;if(c.test(t)){a=document.createDocumentFragment();for(var h=0;;){c.lastIndex=h;var d=c.exec(t),g=d?d.index-h:t.length-h;if(g){var v=document.createTextNode(u.slice(h,h+g));gl&&vl<9?a.appendChild(n("span",[v])):a.appendChild(v),e.map.push(e.pos,e.pos+g,v),e.col+=g,e.pos+=g}if(!d)break;h+=g+1;var m=void 0;if("\t"==d[0]){var y=e.cm.options.tabSize,b=y-e.col%y;(m=a.appendChild(n("span",p(b),"cm-tab"))).setAttribute("role","presentation"),m.setAttribute("cm-text","\t"),e.col+=b}else"\r"==d[0]||"\n"==d[0]?((m=a.appendChild(n("span","\r"==d[0]?"␍":"␤","cm-invalidchar"))).setAttribute("cm-text",d[0]),e.col+=1):((m=e.cm.options.specialCharPlaceholder(d[0])).setAttribute("cm-text",d[0]),gl&&vl<9?a.appendChild(n("span",[m])):a.appendChild(m),e.col+=1);e.map.push(e.pos,e.pos+1,m),e.pos++}}else e.col+=t.length,a=document.createTextNode(u),e.map.push(e.pos,e.pos+t.length,a),gl&&vl<9&&(f=!0),e.pos+=t.length;if(e.trailingSpace=32==u.charCodeAt(t.length-1),r||i||o||f||s){var w=r||"";i&&(w+=i),o&&(w+=o);var x=n("span",[a],w,s);return l&&(x.title=l),e.content.appendChild(x)}e.content.appendChild(a)}}function ct(e,t){if(e.length>1&&!/  /.test(e))return e;for(var r=t,n="",i=0;i<e.length;i++){var o=e.charAt(i);" "!=o||!r||i!=e.length-1&&32!=e.charCodeAt(i+1)||(o=" "),n+=o,r=" "==o}return n}function ft(e,t){return function(r,n,i,o,l,s,a){i=i?i+" cm-force-border":"cm-force-border";for(var u=r.pos,c=u+n.length;;){for(var f=void 0,h=0;h<t.length&&!((f=t[h]).to>u&&f.from<=u);h++);if(f.to>=c)return e(r,n,i,o,l,s,a);e(r,n.slice(0,f.to-u),i,o,null,s,a),o=null,n=n.slice(f.to-u),u=f.to}}}function ht(e,t,r,n){var i=!n&&r.widgetNode;i&&e.map.push(e.pos,e.pos+t,i),!n&&e.cm.display.input.needsContentAttribute&&(i||(i=e.content.appendChild(document.createElement("span"))),i.setAttribute("cm-marker",r.id)),i&&(e.cm.display.input.setUneditable(i),e.content.appendChild(i)),e.pos+=t,e.trailingSpace=!1}function dt(e,t,r){var n=e.markedSpans,i=e.text,o=0;if(n)for(var l,s,a,u,c,f,h,d=i.length,p=0,g=1,v="",m=0;;){if(m==p){a=u=c=f=s="",h=null,m=1/0;for(var y=[],b=void 0,w=0;w<n.length;++w){var x=n[w],C=x.marker;"bookmark"==C.type&&x.from==p&&C.widgetNode?y.push(C):x.from<=p&&(null==x.to||x.to>p||C.collapsed&&x.to==p&&x.from==p)?(null!=x.to&&x.to!=p&&m>x.to&&(m=x.to,u=""),C.className&&(a+=" "+C.className),C.css&&(s=(s?s+";":"")+C.css),C.startStyle&&x.from==p&&(c+=" "+C.startStyle),C.endStyle&&x.to==m&&(b||(b=[])).push(C.endStyle,x.to),C.title&&!f&&(f=C.title),C.collapsed&&(!h||le(h.marker,C)<0)&&(h=x)):x.from>p&&m>x.from&&(m=x.from)}if(b)for(var S=0;S<b.length;S+=2)b[S+1]==m&&(u+=" "+b[S]);if(!h||h.from==p)for(var L=0;L<y.length;++L)ht(t,0,y[L]);if(h&&(h.from||0)==p){if(ht(t,(null==h.to?d+1:h.to)-p,h.marker,null==h.from),null==h.to)return;h.to==p&&(h=!1)}}if(p>=d)break;for(var k=Math.min(d,m);;){if(v){var T=p+v.length;if(!h){var M=T>k?v.slice(0,k-p):v;t.addToken(t,M,l?l+a:a,c,p+M.length==m?u:"",f,s)}if(T>=k){v=v.slice(k-p),p=k;break}p=T,c=""}v=i.slice(o,o=r[g++]),l=lt(r[g++],t.cm.options)}}else for(var N=1;N<r.length;N+=2)t.addToken(t,i.slice(o,o=r[N]),lt(r[N+1],t.cm.options))}function pt(e,t,r){this.line=t,this.rest=de(t),this.size=this.rest?W(g(this.rest))-r+1:1,this.node=this.text=null,this.hidden=ve(e,t)}function gt(e,t,r){for(var n,i=[],o=t;o<r;o=n){var l=new pt(e.doc,M(e.doc,o),o);n=o+l.size,i.push(l)}return i}function vt(e){gs?gs.ops.push(e):e.ownsGroup=gs={ops:[e],delayedCallbacks:[]}}function mt(e){var t=e.delayedCallbacks,r=0;do{for(;r<t.length;r++)t[r].call(null);for(var n=0;n<e.ops.length;n++){var i=e.ops[n];if(i.cursorActivityHandlers)for(;i.cursorActivityCalled<i.cursorActivityHandlers.length;)i.cursorActivityHandlers[i.cursorActivityCalled++].call(null,i.cm)}}while(r<t.length)}function yt(e,t){var r=e.ownsGroup;if(r)try{mt(r)}finally{gs=null,t(r)}}function bt(e,t){var r=Le(e,t);if(r.length){var n,i=Array.prototype.slice.call(arguments,2);gs?n=gs.delayedCallbacks:vs?n=vs:(n=vs=[],setTimeout(wt,0));for(var o=0;o<r.length;++o)!function(e){n.push(function(){return r[e].apply(null,i)})}(o)}}function wt(){var e=vs;vs=null;for(var t=0;t<e.length;++t)e[t]()}function xt(e,t,r,n){for(var i=0;i<t.changes.length;i++){var o=t.changes[i];"text"==o?kt(e,t):"gutter"==o?Mt(e,t,r,n):"class"==o?Tt(e,t):"widget"==o&&Nt(e,t,n)}t.changes=null}function Ct(e){return e.node==e.text&&(e.node=n("div",null,null,"position: relative"),e.text.parentNode&&e.text.parentNode.replaceChild(e.node,e.text),e.node.appendChild(e.text),gl&&vl<8&&(e.node.style.zIndex=2)),e.node}function St(e,t){var r=t.bgClass?t.bgClass+" "+(t.line.bgClass||""):t.line.bgClass;if(r&&(r+=" CodeMirror-linebackground"),t.background)r?t.background.className=r:(t.background.parentNode.removeChild(t.background),t.background=null);else if(r){var i=Ct(t);t.background=i.insertBefore(n("div",null,r),i.firstChild),e.display.input.setUneditable(t.background)}}function Lt(e,t){var r=e.display.externalMeasured;return r&&r.line==t.line?(e.display.externalMeasured=null,t.measure=r.measure,r.built):st(e,t)}function kt(e,t){var r=t.text.className,n=Lt(e,t);t.text==t.node&&(t.node=n.pre),t.text.parentNode.replaceChild(n.pre,t.text),t.text=n.pre,n.bgClass!=t.bgClass||n.textClass!=t.textClass?(t.bgClass=n.bgClass,t.textClass=n.textClass,Tt(e,t)):r&&(t.text.className=r)}function Tt(e,t){St(e,t),t.line.wrapClass?Ct(t).className=t.line.wrapClass:t.node!=t.text&&(t.node.className="");var r=t.textClass?t.textClass+" "+(t.line.textClass||""):t.line.textClass;t.text.className=r||""}function Mt(e,t,r,i){if(t.gutter&&(t.node.removeChild(t.gutter),t.gutter=null),t.gutterBackground&&(t.node.removeChild(t.gutterBackground),t.gutterBackground=null),t.line.gutterClass){var o=Ct(t);t.gutterBackground=n("div",null,"CodeMirror-gutter-background "+t.line.gutterClass,"left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px; width: "+i.gutterTotalWidth+"px"),e.display.input.setUneditable(t.gutterBackground),o.insertBefore(t.gutterBackground,t.text)}var l=t.line.gutterMarkers;if(e.options.lineNumbers||l){var s=Ct(t),a=t.gutter=n("div",null,"CodeMirror-gutter-wrapper","left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px");if(e.display.input.setUneditable(a),s.insertBefore(a,t.text),t.line.gutterClass&&(a.className+=" "+t.line.gutterClass),!e.options.lineNumbers||l&&l["CodeMirror-linenumbers"]||(t.lineNumber=a.appendChild(n("div",F(e.options,r),"CodeMirror-linenumber CodeMirror-gutter-elt","left: "+i.gutterLeft["CodeMirror-linenumbers"]+"px; width: "+e.display.lineNumInnerWidth+"px"))),l)for(var u=0;u<e.options.gutters.length;++u){var c=e.options.gutters[u],f=l.hasOwnProperty(c)&&l[c];f&&a.appendChild(n("div",[f],"CodeMirror-gutter-elt","left: "+i.gutterLeft[c]+"px; width: "+i.gutterWidth[c]+"px"))}}}function Nt(e,t,r){t.alignable&&(t.alignable=null);for(var n=t.node.firstChild,i=void 0;n;n=i)i=n.nextSibling,"CodeMirror-linewidget"==n.className&&t.node.removeChild(n);At(e,t,r)}function Ot(e,t,r,n){var i=Lt(e,t);return t.text=t.node=i.pre,i.bgClass&&(t.bgClass=i.bgClass),i.textClass&&(t.textClass=i.textClass),Tt(e,t),Mt(e,t,r,n),At(e,t,n),t.node}function At(e,t,r){if(Wt(e,t.line,t,r,!0),t.rest)for(var n=0;n<t.rest.length;n++)Wt(e,t.rest[n],t,r,!1)}function Wt(e,t,r,i,o){if(t.widgets)for(var l=Ct(r),s=0,a=t.widgets;s<a.length;++s){var u=a[s],c=n("div",[u.node],"CodeMirror-linewidget");u.handleMouseEvents||c.setAttribute("cm-ignore-events","true"),Dt(u,c,r,i),e.display.input.setUneditable(c),o&&u.above?l.insertBefore(c,r.gutter||r.text):l.appendChild(c),bt(u,"redraw")}}function Dt(e,t,r,n){if(e.noHScroll){(r.alignable||(r.alignable=[])).push(t);var i=n.wrapperWidth;t.style.left=n.fixedPos+"px",e.coverGutter||(i-=n.gutterTotalWidth,t.style.paddingLeft=n.gutterTotalWidth+"px"),t.style.width=i+"px"}e.coverGutter&&(t.style.zIndex=5,t.style.position="relative",e.noHScroll||(t.style.marginLeft=-n.gutterTotalWidth+"px"))}function Ht(e){if(null!=e.height)return e.height;var t=e.doc.cm;if(!t)return 0;if(!o(document.body,e.node)){var i="position: relative;";e.coverGutter&&(i+="margin-left: -"+t.display.gutters.offsetWidth+"px;"),e.noHScroll&&(i+="width: "+t.display.wrapper.clientWidth+"px;"),r(t.display.measure,n("div",[e.node],null,i))}return e.height=e.node.parentNode.offsetHeight}function Ft(e,t){for(var r=Ee(t);r!=e.wrapper;r=r.parentNode)if(!r||1==r.nodeType&&"true"==r.getAttribute("cm-ignore-events")||r.parentNode==e.sizer&&r!=e.mover)return!0}function Et(e){return e.lineSpace.offsetTop}function Pt(e){return e.mover.offsetHeight-e.lineSpace.offsetHeight}function It(e){if(e.cachedPaddingH)return e.cachedPaddingH;var t=r(e.measure,n("pre","x")),i=window.getComputedStyle?window.getComputedStyle(t):t.currentStyle,o={left:parseInt(i.paddingLeft),right:parseInt(i.paddingRight)};return isNaN(o.left)||isNaN(o.right)||(e.cachedPaddingH=o),o}function zt(e){return Rl-e.display.nativeBarWidth}function Rt(e){return e.display.scroller.clientWidth-zt(e)-e.display.barWidth}function Bt(e){return e.display.scroller.clientHeight-zt(e)-e.display.barHeight}function Gt(e,t,r){var n=e.options.lineWrapping,i=n&&Rt(e);if(!t.measure.heights||n&&t.measure.width!=i){var o=t.measure.heights=[];if(n){t.measure.width=i;for(var l=t.text.firstChild.getClientRects(),s=0;s<l.length-1;s++){var a=l[s],u=l[s+1];Math.abs(a.bottom-u.bottom)>2&&o.push((a.bottom+u.top)/2-r.top)}}o.push(r.bottom-r.top)}}function Ut(e,t,r){if(e.line==t)return{map:e.measure.map,cache:e.measure.cache};for(var n=0;n<e.rest.length;n++)if(e.rest[n]==t)return{map:e.measure.maps[n],cache:e.measure.caches[n]};for(var i=0;i<e.rest.length;i++)if(W(e.rest[i])>r)return{map:e.measure.maps[i],cache:e.measure.caches[i],before:!0}}function Vt(e,t){var n=W(t=fe(t)),i=e.display.externalMeasured=new pt(e.doc,t,n);i.lineN=n;var o=i.built=st(e,i);return i.text=o.pre,r(e.display.lineMeasure,o.pre),i}function Kt(e,t,r,n){return Yt(e,Xt(e,t),r,n)}function jt(e,t){if(t>=e.display.viewFrom&&t<e.display.viewTo)return e.display.view[Lr(e,t)];var r=e.display.externalMeasured;return r&&t>=r.lineN&&t<r.lineN+r.size?r:void 0}function Xt(e,t){var r=W(t),n=jt(e,r);n&&!n.text?n=null:n&&n.changes&&(xt(e,n,r,br(e)),e.curOp.forceUpdate=!0),n||(n=Vt(e,t));var i=Ut(n,t,r);return{line:t,view:n,rect:null,map:i.map,cache:i.cache,before:i.before,hasHeights:!1}}function Yt(e,t,r,n,i){t.before&&(r=-1);var o,l=r+(n||"");return t.cache.hasOwnProperty(l)?o=t.cache[l]:(t.rect||(t.rect=t.view.text.getBoundingClientRect()),t.hasHeights||(Gt(e,t.view,t.rect),t.hasHeights=!0),(o=qt(e,t,r,n)).bogus||(t.cache[l]=o)),{left:o.left,right:o.right,top:i?o.rtop:o.top,bottom:i?o.rbottom:o.bottom}}function _t(e,t,r){for(var n,i,o,l,s,a,u=0;u<e.length;u+=3)if(s=e[u],a=e[u+1],t<s?(i=0,o=1,l="left"):t<a?o=(i=t-s)+1:(u==e.length-3||t==a&&e[u+3]>t)&&(i=(o=a-s)-1,t>=a&&(l="right")),null!=i){if(n=e[u+2],s==a&&r==(n.insertLeft?"left":"right")&&(l=r),"left"==r&&0==i)for(;u&&e[u-2]==e[u-3]&&e[u-1].insertLeft;)n=e[2+(u-=3)],l="left";if("right"==r&&i==a-s)for(;u<e.length-3&&e[u+3]==e[u+4]&&!e[u+5].insertLeft;)n=e[(u+=3)+2],l="right";break}return{node:n,start:i,end:o,collapse:l,coverStart:s,coverEnd:a}}function $t(e,t){var r=ms;if("left"==t)for(var n=0;n<e.length&&(r=e[n]).left==r.right;n++);else for(var i=e.length-1;i>=0&&(r=e[i]).left==r.right;i--);return r}function qt(e,t,r,n){var i,o=_t(t.map,r,n),l=o.node,s=o.start,a=o.end,u=o.collapse;if(3==l.nodeType){for(var c=0;c<4;c++){for(;s&&S(t.line.text.charAt(o.coverStart+s));)--s;for(;o.coverStart+a<o.coverEnd&&S(t.line.text.charAt(o.coverStart+a));)++a;if((i=gl&&vl<9&&0==s&&a==o.coverEnd-o.coverStart?l.parentNode.getBoundingClientRect():$t(Wl(l,s,a).getClientRects(),n)).left||i.right||0==s)break;a=s,s-=1,u="right"}gl&&vl<11&&(i=Zt(e.display.measure,i))}else{s>0&&(u=n="right");var f;i=e.options.lineWrapping&&(f=l.getClientRects()).length>1?f["right"==n?f.length-1:0]:l.getBoundingClientRect()}if(gl&&vl<9&&!s&&(!i||!i.left&&!i.right)){var h=l.parentNode.getClientRects()[0];i=h?{left:h.left,right:h.left+yr(e.display),top:h.top,bottom:h.bottom}:ms}for(var d=i.top-t.rect.top,p=i.bottom-t.rect.top,g=(d+p)/2,v=t.view.measure.heights,m=0;m<v.length-1&&!(g<v[m]);m++);var y=m?v[m-1]:0,b=v[m],w={left:("right"==u?i.right:i.left)-t.rect.left,right:("left"==u?i.left:i.right)-t.rect.left,top:y,bottom:b};return i.left||i.right||(w.bogus=!0),e.options.singleCursorHeightPerLine||(w.rtop=d,w.rbottom=p),w}function Zt(e,t){if(!window.screen||null==screen.logicalXDPI||screen.logicalXDPI==screen.deviceXDPI||!Re(e))return t;var r=screen.logicalXDPI/screen.deviceXDPI,n=screen.logicalYDPI/screen.deviceYDPI;return{left:t.left*r,right:t.right*r,top:t.top*n,bottom:t.bottom*n}}function Qt(e){if(e.measure&&(e.measure.cache={},e.measure.heights=null,e.rest))for(var t=0;t<e.rest.length;t++)e.measure.caches[t]={}}function Jt(e){e.display.externalMeasure=null,t(e.display.lineMeasure);for(var r=0;r<e.display.view.length;r++)Qt(e.display.view[r])}function er(e){Jt(e),e.display.cachedCharWidth=e.display.cachedTextHeight=e.display.cachedPaddingH=null,e.options.lineWrapping||(e.display.maxLineChanged=!0),e.display.lineNumChars=null}function tr(){return bl&&kl?-(document.body.getBoundingClientRect().left-parseInt(getComputedStyle(document.body).marginLeft)):window.pageXOffset||(document.documentElement||document.body).scrollLeft}function rr(){return bl&&kl?-(document.body.getBoundingClientRect().top-parseInt(getComputedStyle(document.body).marginTop)):window.pageYOffset||(document.documentElement||document.body).scrollTop}function nr(e){var t=0;if(e.widgets)for(var r=0;r<e.widgets.length;++r)e.widgets[r].above&&(t+=Ht(e.widgets[r]));return t}function ir(e,t,r,n,i){if(!i){var o=nr(t);r.top+=o,r.bottom+=o}if("line"==n)return r;n||(n="local");var l=ye(t);if("local"==n?l+=Et(e.display):l-=e.display.viewOffset,"page"==n||"window"==n){var s=e.display.lineSpace.getBoundingClientRect();l+=s.top+("window"==n?0:rr());var a=s.left+("window"==n?0:tr());r.left+=a,r.right+=a}return r.top+=l,r.bottom+=l,r}function or(e,t,r){if("div"==r)return t;var n=t.left,i=t.top;if("page"==r)n-=tr(),i-=rr();else if("local"==r||!r){var o=e.display.sizer.getBoundingClientRect();n+=o.left,i+=o.top}var l=e.display.lineSpace.getBoundingClientRect();return{left:n-l.left,top:i-l.top}}function lr(e,t,r,n,i){return n||(n=M(e.doc,t.line)),ir(e,n,Kt(e,n,t.ch,i),r)}function sr(e,t,r,n,i,o){function l(t,l){var s=Yt(e,i,t,l?"right":"left",o);return l?s.left=s.right:s.right=s.left,ir(e,n,s,r)}function s(e,t,r){var n=1==a[t].level;return l(r?e-1:e,n!=r)}n=n||M(e.doc,t.line),i||(i=Xt(e,n));var a=Se(n,e.doc.direction),u=t.ch,c=t.sticky;if(u>=n.text.length?(u=n.text.length,c="before"):u<=0&&(u=0,c="after"),!a)return l("before"==c?u-1:u,"before"==c);var f=Ce(a,u,c),h=$l,d=s(u,f,"before"==c);return null!=h&&(d.other=s(u,h,"before"!=c)),d}function ar(e,t){var r=0;t=U(e.doc,t),e.options.lineWrapping||(r=yr(e.display)*t.ch);var n=M(e.doc,t.line),i=ye(n)+Et(e.display);return{left:r,right:r,top:i,bottom:i+n.height}}function ur(e,t,r,n,i){var o=E(e,t,r);return o.xRel=i,n&&(o.outside=!0),o}function cr(e,t,r){var n=e.doc;if((r+=e.display.viewOffset)<0)return ur(n.first,0,null,!0,-1);var i=D(n,r),o=n.first+n.size-1;if(i>o)return ur(n.first+n.size-1,M(n,o).text.length,null,!0,1);t<0&&(t=0);for(var l=M(n,i);;){var s=pr(e,l,i,t,r),a=ue(l),u=a&&a.find(0,!0);if(!a||!(s.ch>u.from.ch||s.ch==u.from.ch&&s.xRel>0))return s;i=W(l=u.to.line)}}function fr(e,t,r,n){n-=nr(t);var i=t.text.length,o=k(function(t){return Yt(e,r,t-1).bottom<=n},i,0);return i=k(function(t){return Yt(e,r,t).top>n},o,i),{begin:o,end:i}}function hr(e,t,r,n){return r||(r=Xt(e,t)),fr(e,t,r,ir(e,t,Yt(e,r,n),"line").top)}function dr(e,t,r,n){return!(e.bottom<=r)&&(e.top>r||(n?e.left:e.right)>t)}function pr(e,t,r,n,i){i-=ye(t);var o=Xt(e,t),l=nr(t),s=0,a=t.text.length,u=!0,c=Se(t,e.doc.direction);if(c){var f=(e.options.lineWrapping?vr:gr)(e,t,r,o,c,n,i);s=(u=1!=f.level)?f.from:f.to-1,a=u?f.to:f.from-1}var h,d,p=null,g=null,v=k(function(t){var r=Yt(e,o,t);return r.top+=l,r.bottom+=l,!!dr(r,n,i,!1)&&(r.top<=i&&r.left<=n&&(p=t,g=r),!0)},s,a),m=!1;if(g){var y=n-g.left<g.right-n,b=y==u;v=p+(b?0:1),d=b?"after":"before",h=y?g.left:g.right}else{u||v!=a&&v!=s||v++,d=0==v?"after":v==t.text.length?"before":Yt(e,o,v-(u?1:0)).bottom+l<=i==u?"after":"before";var w=sr(e,E(r,v,d),"line",t,o);h=w.left,m=i<w.top||i>=w.bottom}return v=L(t.text,v,1),ur(r,v,d,m,n-h)}function gr(e,t,r,n,i,o,l){var s=k(function(s){var a=i[s],u=1!=a.level;return dr(sr(e,E(r,u?a.to:a.from,u?"before":"after"),"line",t,n),o,l,!0)},0,i.length-1),a=i[s];if(s>0){var u=1!=a.level,c=sr(e,E(r,u?a.from:a.to,u?"after":"before"),"line",t,n);dr(c,o,l,!0)&&c.top>l&&(a=i[s-1])}return a}function vr(e,t,r,n,i,o,l){for(var s=fr(e,t,n,l),a=s.begin,u=s.end,c=null,f=null,h=0;h<i.length;h++){var d=i[h];if(!(d.from>=u||d.to<=a)){var p=Yt(e,n,1!=d.level?Math.min(u,d.to)-1:Math.max(a,d.from)).right,g=p<o?o-p+1e9:p-o;(!c||f>g)&&(c=d,f=g)}}return c||(c=i[i.length-1]),c.from<a&&(c={from:a,to:c.to,level:c.level}),c.to>u&&(c={from:c.from,to:u,level:c.level}),c}function mr(e){if(null!=e.cachedTextHeight)return e.cachedTextHeight;if(null==hs){hs=n("pre");for(var i=0;i<49;++i)hs.appendChild(document.createTextNode("x")),hs.appendChild(n("br"));hs.appendChild(document.createTextNode("x"))}r(e.measure,hs);var o=hs.offsetHeight/50;return o>3&&(e.cachedTextHeight=o),t(e.measure),o||1}function yr(e){if(null!=e.cachedCharWidth)return e.cachedCharWidth;var t=n("span","xxxxxxxxxx"),i=n("pre",[t]);r(e.measure,i);var o=t.getBoundingClientRect(),l=(o.right-o.left)/10;return l>2&&(e.cachedCharWidth=l),l||10}function br(e){for(var t=e.display,r={},n={},i=t.gutters.clientLeft,o=t.gutters.firstChild,l=0;o;o=o.nextSibling,++l)r[e.options.gutters[l]]=o.offsetLeft+o.clientLeft+i,n[e.options.gutters[l]]=o.clientWidth;return{fixedPos:wr(t),gutterTotalWidth:t.gutters.offsetWidth,gutterLeft:r,gutterWidth:n,wrapperWidth:t.wrapper.clientWidth}}function wr(e){return e.scroller.getBoundingClientRect().left-e.sizer.getBoundingClientRect().left}function xr(e){var t=mr(e.display),r=e.options.lineWrapping,n=r&&Math.max(5,e.display.scroller.clientWidth/yr(e.display)-3);return function(i){if(ve(e.doc,i))return 0;var o=0;if(i.widgets)for(var l=0;l<i.widgets.length;l++)i.widgets[l].height&&(o+=i.widgets[l].height);return r?o+(Math.ceil(i.text.length/n)||1)*t:o+t}}function Cr(e){var t=e.doc,r=xr(e);t.iter(function(e){var t=r(e);t!=e.height&&A(e,t)})}function Sr(e,t,r,n){var i=e.display;if(!r&&"true"==Ee(t).getAttribute("cm-not-content"))return null;var o,l,s=i.lineSpace.getBoundingClientRect();try{o=t.clientX-s.left,l=t.clientY-s.top}catch(t){return null}var a,u=cr(e,o,l);if(n&&1==u.xRel&&(a=M(e.doc,u.line).text).length==u.ch){var c=f(a,a.length,e.options.tabSize)-a.length;u=E(u.line,Math.max(0,Math.round((o-It(e.display).left)/yr(e.display))-c))}return u}function Lr(e,t){if(t>=e.display.viewTo)return null;if((t-=e.display.viewFrom)<0)return null;for(var r=e.display.view,n=0;n<r.length;n++)if((t-=r[n].size)<0)return n}function kr(e){e.display.input.showSelection(e.display.input.prepareSelection())}function Tr(e,t){void 0===t&&(t=!0);for(var r=e.doc,n={},i=n.cursors=document.createDocumentFragment(),o=n.selection=document.createDocumentFragment(),l=0;l<r.sel.ranges.length;l++)if(t||l!=r.sel.primIndex){var s=r.sel.ranges[l];if(!(s.from().line>=e.display.viewTo||s.to().line<e.display.viewFrom)){var a=s.empty();(a||e.options.showCursorWhenSelecting)&&Mr(e,s.head,i),a||Or(e,s,o)}}return n}function Mr(e,t,r){var i=sr(e,t,"div",null,null,!e.options.singleCursorHeightPerLine),o=r.appendChild(n("div"," ","CodeMirror-cursor"));if(o.style.left=i.left+"px",o.style.top=i.top+"px",o.style.height=Math.max(0,i.bottom-i.top)*e.options.cursorHeight+"px",i.other){var l=r.appendChild(n("div"," ","CodeMirror-cursor CodeMirror-secondarycursor"));l.style.display="",l.style.left=i.other.left+"px",l.style.top=i.other.top+"px",l.style.height=.85*(i.other.bottom-i.other.top)+"px"}}function Nr(e,t){return e.top-t.top||e.left-t.left}function Or(e,t,r){function i(e,t,r,i){t<0&&(t=0),t=Math.round(t),i=Math.round(i),a.appendChild(n("div",null,"CodeMirror-selected","position: absolute; left: "+e+"px;\n                             top: "+t+"px; width: "+(null==r?f-e:r)+"px;\n                             height: "+(i-t)+"px"))}function o(t,r,n){function o(r,n){return lr(e,E(t,r),"div",u,n)}var l,a,u=M(s,t),h=u.text.length,d=Se(u,s.direction);return xe(d,r||0,null==n?h:n,function(t,s,p,g){var v=o(t,"ltr"==p?"left":"right"),m=o(s-1,"ltr"==p?"right":"left");if("ltr"==p){var y=null==r&&0==t?c:v.left,b=null==n&&s==h?f:m.right;m.top-v.top<=3?i(y,m.top,b-y,m.bottom):(i(y,v.top,null,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top),i(c,m.top,m.right,m.bottom))}else if(t<s){var w=null==r&&0==t?f:v.right,x=null==n&&s==h?c:m.left;if(m.top-v.top<=3)i(x,m.top,w-x,m.bottom);else{var C=c;if(g){var S=hr(e,u,null,t).end;C=o(S-(/\s/.test(u.text.charAt(S-1))?2:1),"left").left}i(C,v.top,w-C,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top);var L=null;d.length,L=o(hr(e,u,null,s).begin,"right").right-x,i(x,m.top,L,m.bottom)}}(!l||Nr(v,l)<0)&&(l=v),Nr(m,l)<0&&(l=m),(!a||Nr(v,a)<0)&&(a=v),Nr(m,a)<0&&(a=m)}),{start:l,end:a}}var l=e.display,s=e.doc,a=document.createDocumentFragment(),u=It(e.display),c=u.left,f=Math.max(l.sizerWidth,Rt(e)-l.sizer.offsetLeft)-u.right,h=t.from(),d=t.to();if(h.line==d.line)o(h.line,h.ch,d.ch);else{var p=M(s,h.line),g=M(s,d.line),v=fe(p)==fe(g),m=o(h.line,h.ch,v?p.text.length+1:null).end,y=o(d.line,v?0:null,d.ch).start;v&&(m.top<y.top-2?(i(m.right,m.top,null,m.bottom),i(c,y.top,y.left,y.bottom)):i(m.right,m.top,y.left-m.right,m.bottom)),m.bottom<y.top&&i(c,m.bottom,null,y.top)}r.appendChild(a)}function Ar(e){if(e.state.focused){var t=e.display;clearInterval(t.blinker);var r=!0;t.cursorDiv.style.visibility="",e.options.cursorBlinkRate>0?t.blinker=setInterval(function(){return t.cursorDiv.style.visibility=(r=!r)?"":"hidden"},e.options.cursorBlinkRate):e.options.cursorBlinkRate<0&&(t.cursorDiv.style.visibility="hidden")}}function Wr(e){e.state.focused||(e.display.input.focus(),Hr(e))}function Dr(e){e.state.delayingBlurEvent=!0,setTimeout(function(){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1,Fr(e))},100)}function Hr(e,t){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1),"nocursor"!=e.options.readOnly&&(e.state.focused||(Te(e,"focus",e,t),e.state.focused=!0,s(e.display.wrapper,"CodeMirror-focused"),e.curOp||e.display.selForContextMenu==e.doc.sel||(e.display.input.reset(),ml&&setTimeout(function(){return e.display.input.reset(!0)},20)),e.display.input.receivedFocus()),Ar(e))}function Fr(e,t){e.state.delayingBlurEvent||(e.state.focused&&(Te(e,"blur",e,t),e.state.focused=!1,Fl(e.display.wrapper,"CodeMirror-focused")),clearInterval(e.display.blinker),setTimeout(function(){e.state.focused||(e.display.shift=!1)},150))}function Er(e){for(var t=e.display,r=t.lineDiv.offsetTop,n=0;n<t.view.length;n++){var i=t.view[n],o=void 0;if(!i.hidden){if(gl&&vl<8){var l=i.node.offsetTop+i.node.offsetHeight;o=l-r,r=l}else{var s=i.node.getBoundingClientRect();o=s.bottom-s.top}var a=i.line.height-o;if(o<2&&(o=mr(t)),(a>.005||a<-.005)&&(A(i.line,o),Pr(i.line),i.rest))for(var u=0;u<i.rest.length;u++)Pr(i.rest[u])}}}function Pr(e){if(e.widgets)for(var t=0;t<e.widgets.length;++t)e.widgets[t].height=e.widgets[t].node.parentNode.offsetHeight}function Ir(e,t,r){var n=r&&null!=r.top?Math.max(0,r.top):e.scroller.scrollTop;n=Math.floor(n-Et(e));var i=r&&null!=r.bottom?r.bottom:n+e.wrapper.clientHeight,o=D(t,n),l=D(t,i);if(r&&r.ensure){var s=r.ensure.from.line,a=r.ensure.to.line;s<o?(o=s,l=D(t,ye(M(t,s))+e.wrapper.clientHeight)):Math.min(a,t.lastLine())>=l&&(o=D(t,ye(M(t,a))-e.wrapper.clientHeight),l=a)}return{from:o,to:Math.max(l,o+1)}}function zr(e){var t=e.display,r=t.view;if(t.alignWidgets||t.gutters.firstChild&&e.options.fixedGutter){for(var n=wr(t)-t.scroller.scrollLeft+e.doc.scrollLeft,i=t.gutters.offsetWidth,o=n+"px",l=0;l<r.length;l++)if(!r[l].hidden){e.options.fixedGutter&&(r[l].gutter&&(r[l].gutter.style.left=o),r[l].gutterBackground&&(r[l].gutterBackground.style.left=o));var s=r[l].alignable;if(s)for(var a=0;a<s.length;a++)s[a].style.left=o}e.options.fixedGutter&&(t.gutters.style.left=n+i+"px")}}function Rr(e){if(!e.options.lineNumbers)return!1;var t=e.doc,r=F(e.options,t.first+t.size-1),i=e.display;if(r.length!=i.lineNumChars){var o=i.measure.appendChild(n("div",[n("div",r)],"CodeMirror-linenumber CodeMirror-gutter-elt")),l=o.firstChild.offsetWidth,s=o.offsetWidth-l;return i.lineGutter.style.width="",i.lineNumInnerWidth=Math.max(l,i.lineGutter.offsetWidth-s)+1,i.lineNumWidth=i.lineNumInnerWidth+s,i.lineNumChars=i.lineNumInnerWidth?r.length:-1,i.lineGutter.style.width=i.lineNumWidth+"px",Wn(e),!0}return!1}function Br(e,t){if(!Me(e,"scrollCursorIntoView")){var r=e.display,i=r.sizer.getBoundingClientRect(),o=null;if(t.top+i.top<0?o=!0:t.bottom+i.top>(window.innerHeight||document.documentElement.clientHeight)&&(o=!1),null!=o&&!Sl){var l=n("div","​",null,"position: absolute;\n                         top: "+(t.top-r.viewOffset-Et(e.display))+"px;\n                         height: "+(t.bottom-t.top+zt(e)+r.barHeight)+"px;\n                         left: "+t.left+"px; width: "+Math.max(2,t.right-t.left)+"px;");e.display.lineSpace.appendChild(l),l.scrollIntoView(o),e.display.lineSpace.removeChild(l)}}}function Gr(e,t,r,n){null==n&&(n=0);var i;e.options.lineWrapping||t!=r||(r="before"==(t=t.ch?E(t.line,"before"==t.sticky?t.ch-1:t.ch,"after"):t).sticky?E(t.line,t.ch+1,"before"):t);for(var o=0;o<5;o++){var l=!1,s=sr(e,t),a=r&&r!=t?sr(e,r):s,u=Vr(e,i={left:Math.min(s.left,a.left),top:Math.min(s.top,a.top)-n,right:Math.max(s.left,a.left),bottom:Math.max(s.bottom,a.bottom)+n}),c=e.doc.scrollTop,f=e.doc.scrollLeft;if(null!=u.scrollTop&&(qr(e,u.scrollTop),Math.abs(e.doc.scrollTop-c)>1&&(l=!0)),null!=u.scrollLeft&&(Qr(e,u.scrollLeft),Math.abs(e.doc.scrollLeft-f)>1&&(l=!0)),!l)break}return i}function Ur(e,t){var r=Vr(e,t);null!=r.scrollTop&&qr(e,r.scrollTop),null!=r.scrollLeft&&Qr(e,r.scrollLeft)}function Vr(e,t){var r=e.display,n=mr(e.display);t.top<0&&(t.top=0);var i=e.curOp&&null!=e.curOp.scrollTop?e.curOp.scrollTop:r.scroller.scrollTop,o=Bt(e),l={};t.bottom-t.top>o&&(t.bottom=t.top+o);var s=e.doc.height+Pt(r),a=t.top<n,u=t.bottom>s-n;if(t.top<i)l.scrollTop=a?0:t.top;else if(t.bottom>i+o){var c=Math.min(t.top,(u?s:t.bottom)-o);c!=i&&(l.scrollTop=c)}var f=e.curOp&&null!=e.curOp.scrollLeft?e.curOp.scrollLeft:r.scroller.scrollLeft,h=Rt(e)-(e.options.fixedGutter?r.gutters.offsetWidth:0),d=t.right-t.left>h;return d&&(t.right=t.left+h),t.left<10?l.scrollLeft=0:t.left<f?l.scrollLeft=Math.max(0,t.left-(d?0:10)):t.right>h+f-3&&(l.scrollLeft=t.right+(d?0:10)-h),l}function Kr(e,t){null!=t&&(_r(e),e.curOp.scrollTop=(null==e.curOp.scrollTop?e.doc.scrollTop:e.curOp.scrollTop)+t)}function jr(e){_r(e);var t=e.getCursor();e.curOp.scrollToPos={from:t,to:t,margin:e.options.cursorScrollMargin}}function Xr(e,t,r){null==t&&null==r||_r(e),null!=t&&(e.curOp.scrollLeft=t),null!=r&&(e.curOp.scrollTop=r)}function Yr(e,t){_r(e),e.curOp.scrollToPos=t}function _r(e){var t=e.curOp.scrollToPos;t&&(e.curOp.scrollToPos=null,$r(e,ar(e,t.from),ar(e,t.to),t.margin))}function $r(e,t,r,n){var i=Vr(e,{left:Math.min(t.left,r.left),top:Math.min(t.top,r.top)-n,right:Math.max(t.right,r.right),bottom:Math.max(t.bottom,r.bottom)+n});Xr(e,i.scrollLeft,i.scrollTop)}function qr(e,t){Math.abs(e.doc.scrollTop-t)<2||(fl||On(e,{top:t}),Zr(e,t,!0),fl&&On(e),Cn(e,100))}function Zr(e,t,r){t=Math.min(e.display.scroller.scrollHeight-e.display.scroller.clientHeight,t),(e.display.scroller.scrollTop!=t||r)&&(e.doc.scrollTop=t,e.display.scrollbars.setScrollTop(t),e.display.scroller.scrollTop!=t&&(e.display.scroller.scrollTop=t))}function Qr(e,t,r,n){t=Math.min(t,e.display.scroller.scrollWidth-e.display.scroller.clientWidth),(r?t==e.doc.scrollLeft:Math.abs(e.doc.scrollLeft-t)<2)&&!n||(e.doc.scrollLeft=t,zr(e),e.display.scroller.scrollLeft!=t&&(e.display.scroller.scrollLeft=t),e.display.scrollbars.setScrollLeft(t))}function Jr(e){var t=e.display,r=t.gutters.offsetWidth,n=Math.round(e.doc.height+Pt(e.display));return{clientHeight:t.scroller.clientHeight,viewHeight:t.wrapper.clientHeight,scrollWidth:t.scroller.scrollWidth,clientWidth:t.scroller.clientWidth,viewWidth:t.wrapper.clientWidth,barLeft:e.options.fixedGutter?r:0,docHeight:n,scrollHeight:n+zt(e)+t.barHeight,nativeBarWidth:t.nativeBarWidth,gutterWidth:r}}function en(e,t){t||(t=Jr(e));var r=e.display.barWidth,n=e.display.barHeight;tn(e,t);for(var i=0;i<4&&r!=e.display.barWidth||n!=e.display.barHeight;i++)r!=e.display.barWidth&&e.options.lineWrapping&&Er(e),tn(e,Jr(e)),r=e.display.barWidth,n=e.display.barHeight}function tn(e,t){var r=e.display,n=r.scrollbars.update(t);r.sizer.style.paddingRight=(r.barWidth=n.right)+"px",r.sizer.style.paddingBottom=(r.barHeight=n.bottom)+"px",r.heightForcer.style.borderBottom=n.bottom+"px solid transparent",n.right&&n.bottom?(r.scrollbarFiller.style.display="block",r.scrollbarFiller.style.height=n.bottom+"px",r.scrollbarFiller.style.width=n.right+"px"):r.scrollbarFiller.style.display="",n.bottom&&e.options.coverGutterNextToScrollbar&&e.options.fixedGutter?(r.gutterFiller.style.display="block",r.gutterFiller.style.height=n.bottom+"px",r.gutterFiller.style.width=t.gutterWidth+"px"):r.gutterFiller.style.display=""}function rn(e){e.display.scrollbars&&(e.display.scrollbars.clear(),e.display.scrollbars.addClass&&Fl(e.display.wrapper,e.display.scrollbars.addClass)),e.display.scrollbars=new ws[e.options.scrollbarStyle](function(t){e.display.wrapper.insertBefore(t,e.display.scrollbarFiller),Ql(t,"mousedown",function(){e.state.focused&&setTimeout(function(){return e.display.input.focus()},0)}),t.setAttribute("cm-not-content","true")},function(t,r){"horizontal"==r?Qr(e,t):qr(e,t)},e),e.display.scrollbars.addClass&&s(e.display.wrapper,e.display.scrollbars.addClass)}function nn(e){e.curOp={cm:e,viewChanged:!1,startHeight:e.doc.height,forceUpdate:!1,updateInput:null,typing:!1,changeObjs:null,cursorActivityHandlers:null,cursorActivityCalled:0,selectionChanged:!1,updateMaxLine:!1,scrollLeft:null,scrollTop:null,scrollToPos:null,focus:!1,id:++xs},vt(e.curOp)}function on(e){yt(e.curOp,function(e){for(var t=0;t<e.ops.length;t++)e.ops[t].cm.curOp=null;ln(e)})}function ln(e){for(var t=e.ops,r=0;r<t.length;r++)sn(t[r]);for(var n=0;n<t.length;n++)an(t[n]);for(var i=0;i<t.length;i++)un(t[i]);for(var o=0;o<t.length;o++)cn(t[o]);for(var l=0;l<t.length;l++)fn(t[l])}function sn(e){var t=e.cm,r=t.display;Ln(t),e.updateMaxLine&&we(t),e.mustUpdate=e.viewChanged||e.forceUpdate||null!=e.scrollTop||e.scrollToPos&&(e.scrollToPos.from.line<r.viewFrom||e.scrollToPos.to.line>=r.viewTo)||r.maxLineChanged&&t.options.lineWrapping,e.update=e.mustUpdate&&new Cs(t,e.mustUpdate&&{top:e.scrollTop,ensure:e.scrollToPos},e.forceUpdate)}function an(e){e.updatedDisplay=e.mustUpdate&&Mn(e.cm,e.update)}function un(e){var t=e.cm,r=t.display;e.updatedDisplay&&Er(t),e.barMeasure=Jr(t),r.maxLineChanged&&!t.options.lineWrapping&&(e.adjustWidthTo=Kt(t,r.maxLine,r.maxLine.text.length).left+3,t.display.sizerWidth=e.adjustWidthTo,e.barMeasure.scrollWidth=Math.max(r.scroller.clientWidth,r.sizer.offsetLeft+e.adjustWidthTo+zt(t)+t.display.barWidth),e.maxScrollLeft=Math.max(0,r.sizer.offsetLeft+e.adjustWidthTo-Rt(t))),(e.updatedDisplay||e.selectionChanged)&&(e.preparedSelection=r.input.prepareSelection())}function cn(e){var t=e.cm;null!=e.adjustWidthTo&&(t.display.sizer.style.minWidth=e.adjustWidthTo+"px",e.maxScrollLeft<t.doc.scrollLeft&&Qr(t,Math.min(t.display.scroller.scrollLeft,e.maxScrollLeft),!0),t.display.maxLineChanged=!1);var r=e.focus&&e.focus==l();e.preparedSelection&&t.display.input.showSelection(e.preparedSelection,r),(e.updatedDisplay||e.startHeight!=t.doc.height)&&en(t,e.barMeasure),e.updatedDisplay&&Dn(t,e.barMeasure),e.selectionChanged&&Ar(t),t.state.focused&&e.updateInput&&t.display.input.reset(e.typing),r&&Wr(e.cm)}function fn(e){var t=e.cm,r=t.display,n=t.doc;e.updatedDisplay&&Nn(t,e.update),null==r.wheelStartX||null==e.scrollTop&&null==e.scrollLeft&&!e.scrollToPos||(r.wheelStartX=r.wheelStartY=null),null!=e.scrollTop&&Zr(t,e.scrollTop,e.forceScroll),null!=e.scrollLeft&&Qr(t,e.scrollLeft,!0,!0),e.scrollToPos&&Br(t,Gr(t,U(n,e.scrollToPos.from),U(n,e.scrollToPos.to),e.scrollToPos.margin));var i=e.maybeHiddenMarkers,o=e.maybeUnhiddenMarkers;if(i)for(var l=0;l<i.length;++l)i[l].lines.length||Te(i[l],"hide");if(o)for(var s=0;s<o.length;++s)o[s].lines.length&&Te(o[s],"unhide");r.wrapper.offsetHeight&&(n.scrollTop=t.display.scroller.scrollTop),e.changeObjs&&Te(t,"changes",t,e.changeObjs),e.update&&e.update.finish()}function hn(e,t){if(e.curOp)return t();nn(e);try{return t()}finally{on(e)}}function dn(e,t){return function(){if(e.curOp)return t.apply(e,arguments);nn(e);try{return t.apply(e,arguments)}finally{on(e)}}}function pn(e){return function(){if(this.curOp)return e.apply(this,arguments);nn(this);try{return e.apply(this,arguments)}finally{on(this)}}}function gn(e){return function(){var t=this.cm;if(!t||t.curOp)return e.apply(this,arguments);nn(t);try{return e.apply(this,arguments)}finally{on(t)}}}function vn(e,t,r,n){null==t&&(t=e.doc.first),null==r&&(r=e.doc.first+e.doc.size),n||(n=0);var i=e.display;if(n&&r<i.viewTo&&(null==i.updateLineNumbers||i.updateLineNumbers>t)&&(i.updateLineNumbers=t),e.curOp.viewChanged=!0,t>=i.viewTo)_l&&pe(e.doc,t)<i.viewTo&&yn(e);else if(r<=i.viewFrom)_l&&ge(e.doc,r+n)>i.viewFrom?yn(e):(i.viewFrom+=n,i.viewTo+=n);else if(t<=i.viewFrom&&r>=i.viewTo)yn(e);else if(t<=i.viewFrom){var o=bn(e,r,r+n,1);o?(i.view=i.view.slice(o.index),i.viewFrom=o.lineN,i.viewTo+=n):yn(e)}else if(r>=i.viewTo){var l=bn(e,t,t,-1);l?(i.view=i.view.slice(0,l.index),i.viewTo=l.lineN):yn(e)}else{var s=bn(e,t,t,-1),a=bn(e,r,r+n,1);s&&a?(i.view=i.view.slice(0,s.index).concat(gt(e,s.lineN,a.lineN)).concat(i.view.slice(a.index)),i.viewTo+=n):yn(e)}var u=i.externalMeasured;u&&(r<u.lineN?u.lineN+=n:t<u.lineN+u.size&&(i.externalMeasured=null))}function mn(e,t,r){e.curOp.viewChanged=!0;var n=e.display,i=e.display.externalMeasured;if(i&&t>=i.lineN&&t<i.lineN+i.size&&(n.externalMeasured=null),!(t<n.viewFrom||t>=n.viewTo)){var o=n.view[Lr(e,t)];if(null!=o.node){var l=o.changes||(o.changes=[]);-1==h(l,r)&&l.push(r)}}}function yn(e){e.display.viewFrom=e.display.viewTo=e.doc.first,e.display.view=[],e.display.viewOffset=0}function bn(e,t,r,n){var i,o=Lr(e,t),l=e.display.view;if(!_l||r==e.doc.first+e.doc.size)return{index:o,lineN:r};for(var s=e.display.viewFrom,a=0;a<o;a++)s+=l[a].size;if(s!=t){if(n>0){if(o==l.length-1)return null;i=s+l[o].size-t,o++}else i=s-t;t+=i,r+=i}for(;pe(e.doc,r)!=r;){if(o==(n<0?0:l.length-1))return null;r+=n*l[o-(n<0?1:0)].size,o+=n}return{index:o,lineN:r}}function wn(e,t,r){var n=e.display;0==n.view.length||t>=n.viewTo||r<=n.viewFrom?(n.view=gt(e,t,r),n.viewFrom=t):(n.viewFrom>t?n.view=gt(e,t,n.viewFrom).concat(n.view):n.viewFrom<t&&(n.view=n.view.slice(Lr(e,t))),n.viewFrom=t,n.viewTo<r?n.view=n.view.concat(gt(e,n.viewTo,r)):n.viewTo>r&&(n.view=n.view.slice(0,Lr(e,r)))),n.viewTo=r}function xn(e){for(var t=e.display.view,r=0,n=0;n<t.length;n++){var i=t[n];i.hidden||i.node&&!i.changes||++r}return r}function Cn(e,t){e.doc.highlightFrontier<e.display.viewTo&&e.state.highlight.set(t,u(Sn,e))}function Sn(e){var t=e.doc;if(!(t.highlightFrontier>=e.display.viewTo)){var r=+new Date+e.options.workTime,n=$e(e,t.highlightFrontier),i=[];t.iter(n.line,Math.min(t.first+t.size,e.display.viewTo+500),function(o){if(n.line>=e.display.viewFrom){var l=o.styles,s=o.text.length>e.options.maxHighlightLength?Ke(t.mode,n.state):null,a=Ye(e,o,n,!0);s&&(n.state=s),o.styles=a.styles;var u=o.styleClasses,c=a.classes;c?o.styleClasses=c:u&&(o.styleClasses=null);for(var f=!l||l.length!=o.styles.length||u!=c&&(!u||!c||u.bgClass!=c.bgClass||u.textClass!=c.textClass),h=0;!f&&h<l.length;++h)f=l[h]!=o.styles[h];f&&i.push(n.line),o.stateAfter=n.save(),n.nextLine()}else o.text.length<=e.options.maxHighlightLength&&qe(e,o.text,n),o.stateAfter=n.line%5==0?n.save():null,n.nextLine();if(+new Date>r)return Cn(e,e.options.workDelay),!0}),t.highlightFrontier=n.line,t.modeFrontier=Math.max(t.modeFrontier,n.line),i.length&&hn(e,function(){for(var t=0;t<i.length;t++)mn(e,i[t],"text")})}}function Ln(e){var t=e.display;!t.scrollbarsClipped&&t.scroller.offsetWidth&&(t.nativeBarWidth=t.scroller.offsetWidth-t.scroller.clientWidth,t.heightForcer.style.height=zt(e)+"px",t.sizer.style.marginBottom=-t.nativeBarWidth+"px",t.sizer.style.borderRightWidth=zt(e)+"px",t.scrollbarsClipped=!0)}function kn(e){if(e.hasFocus())return null;var t=l();if(!t||!o(e.display.lineDiv,t))return null;var r={activeElt:t};if(window.getSelection){var n=window.getSelection();n.anchorNode&&n.extend&&o(e.display.lineDiv,n.anchorNode)&&(r.anchorNode=n.anchorNode,r.anchorOffset=n.anchorOffset,r.focusNode=n.focusNode,r.focusOffset=n.focusOffset)}return r}function Tn(e){if(e&&e.activeElt&&e.activeElt!=l()&&(e.activeElt.focus(),e.anchorNode&&o(document.body,e.anchorNode)&&o(document.body,e.focusNode))){var t=window.getSelection(),r=document.createRange();r.setEnd(e.anchorNode,e.anchorOffset),r.collapse(!1),t.removeAllRanges(),t.addRange(r),t.extend(e.focusNode,e.focusOffset)}}function Mn(e,r){var n=e.display,i=e.doc;if(r.editorIsHidden)return yn(e),!1;if(!r.force&&r.visible.from>=n.viewFrom&&r.visible.to<=n.viewTo&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo)&&n.renderedView==n.view&&0==xn(e))return!1;Rr(e)&&(yn(e),r.dims=br(e));var o=i.first+i.size,l=Math.max(r.visible.from-e.options.viewportMargin,i.first),s=Math.min(o,r.visible.to+e.options.viewportMargin);n.viewFrom<l&&l-n.viewFrom<20&&(l=Math.max(i.first,n.viewFrom)),n.viewTo>s&&n.viewTo-s<20&&(s=Math.min(o,n.viewTo)),_l&&(l=pe(e.doc,l),s=ge(e.doc,s));var a=l!=n.viewFrom||s!=n.viewTo||n.lastWrapHeight!=r.wrapperHeight||n.lastWrapWidth!=r.wrapperWidth;wn(e,l,s),n.viewOffset=ye(M(e.doc,n.viewFrom)),e.display.mover.style.top=n.viewOffset+"px";var u=xn(e);if(!a&&0==u&&!r.force&&n.renderedView==n.view&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo))return!1;var c=kn(e);return u>4&&(n.lineDiv.style.display="none"),An(e,n.updateLineNumbers,r.dims),u>4&&(n.lineDiv.style.display=""),n.renderedView=n.view,Tn(c),t(n.cursorDiv),t(n.selectionDiv),n.gutters.style.height=n.sizer.style.minHeight=0,a&&(n.lastWrapHeight=r.wrapperHeight,n.lastWrapWidth=r.wrapperWidth,Cn(e,400)),n.updateLineNumbers=null,!0}function Nn(e,t){for(var r=t.viewport,n=!0;(n&&e.options.lineWrapping&&t.oldDisplayWidth!=Rt(e)||(r&&null!=r.top&&(r={top:Math.min(e.doc.height+Pt(e.display)-Bt(e),r.top)}),t.visible=Ir(e.display,e.doc,r),!(t.visible.from>=e.display.viewFrom&&t.visible.to<=e.display.viewTo)))&&Mn(e,t);n=!1){Er(e);var i=Jr(e);kr(e),en(e,i),Dn(e,i),t.force=!1}t.signal(e,"update",e),e.display.viewFrom==e.display.reportedViewFrom&&e.display.viewTo==e.display.reportedViewTo||(t.signal(e,"viewportChange",e,e.display.viewFrom,e.display.viewTo),e.display.reportedViewFrom=e.display.viewFrom,e.display.reportedViewTo=e.display.viewTo)}function On(e,t){var r=new Cs(e,t);if(Mn(e,r)){Er(e),Nn(e,r);var n=Jr(e);kr(e),en(e,n),Dn(e,n),r.finish()}}function An(e,r,n){function i(t){var r=t.nextSibling;return ml&&Ml&&e.display.currentWheelTarget==t?t.style.display="none":t.parentNode.removeChild(t),r}for(var o=e.display,l=e.options.lineNumbers,s=o.lineDiv,a=s.firstChild,u=o.view,c=o.viewFrom,f=0;f<u.length;f++){var d=u[f];if(d.hidden);else if(d.node&&d.node.parentNode==s){for(;a!=d.node;)a=i(a);var p=l&&null!=r&&r<=c&&d.lineNumber;d.changes&&(h(d.changes,"gutter")>-1&&(p=!1),xt(e,d,c,n)),p&&(t(d.lineNumber),d.lineNumber.appendChild(document.createTextNode(F(e.options,c)))),a=d.node.nextSibling}else{var g=Ot(e,d,c,n);s.insertBefore(g,a)}c+=d.size}for(;a;)a=i(a)}function Wn(e){var t=e.display.gutters.offsetWidth;e.display.sizer.style.marginLeft=t+"px"}function Dn(e,t){e.display.sizer.style.minHeight=t.docHeight+"px",e.display.heightForcer.style.top=t.docHeight+"px",e.display.gutters.style.height=t.docHeight+e.display.barHeight+zt(e)+"px"}function Hn(e){var r=e.display.gutters,i=e.options.gutters;t(r);for(var o=0;o<i.length;++o){var l=i[o],s=r.appendChild(n("div",null,"CodeMirror-gutter "+l));"CodeMirror-linenumbers"==l&&(e.display.lineGutter=s,s.style.width=(e.display.lineNumWidth||1)+"px")}r.style.display=o?"":"none",Wn(e)}function Fn(e){var t=h(e.gutters,"CodeMirror-linenumbers");-1==t&&e.lineNumbers?e.gutters=e.gutters.concat(["CodeMirror-linenumbers"]):t>-1&&!e.lineNumbers&&(e.gutters=e.gutters.slice(0),e.gutters.splice(t,1))}function En(e){var t=e.wheelDeltaX,r=e.wheelDeltaY;return null==t&&e.detail&&e.axis==e.HORIZONTAL_AXIS&&(t=e.detail),null==r&&e.detail&&e.axis==e.VERTICAL_AXIS?r=e.detail:null==r&&(r=e.wheelDelta),{x:t,y:r}}function Pn(e){var t=En(e);return t.x*=Ls,t.y*=Ls,t}function In(e,t){var r=En(t),n=r.x,i=r.y,o=e.display,l=o.scroller,s=l.scrollWidth>l.clientWidth,a=l.scrollHeight>l.clientHeight;if(n&&s||i&&a){if(i&&Ml&&ml)e:for(var u=t.target,c=o.view;u!=l;u=u.parentNode)for(var f=0;f<c.length;f++)if(c[f].node==u){e.display.currentWheelTarget=u;break e}if(n&&!fl&&!wl&&null!=Ls)return i&&a&&qr(e,Math.max(0,l.scrollTop+i*Ls)),Qr(e,Math.max(0,l.scrollLeft+n*Ls)),(!i||i&&a)&&We(t),void(o.wheelStartX=null);if(i&&null!=Ls){var h=i*Ls,d=e.doc.scrollTop,p=d+o.wrapper.clientHeight;h<0?d=Math.max(0,d+h-50):p=Math.min(e.doc.height,p+h+50),On(e,{top:d,bottom:p})}Ss<20&&(null==o.wheelStartX?(o.wheelStartX=l.scrollLeft,o.wheelStartY=l.scrollTop,o.wheelDX=n,o.wheelDY=i,setTimeout(function(){if(null!=o.wheelStartX){var e=l.scrollLeft-o.wheelStartX,t=l.scrollTop-o.wheelStartY,r=t&&o.wheelDY&&t/o.wheelDY||e&&o.wheelDX&&e/o.wheelDX;o.wheelStartX=o.wheelStartY=null,r&&(Ls=(Ls*Ss+r)/(Ss+1),++Ss)}},200)):(o.wheelDX+=n,o.wheelDY+=i))}}function zn(e,t){var r=e[t];e.sort(function(e,t){return P(e.from(),t.from())}),t=h(e,r);for(var n=1;n<e.length;n++){var i=e[n],o=e[n-1];if(P(o.to(),i.from())>=0){var l=B(o.from(),i.from()),s=R(o.to(),i.to()),a=o.empty()?i.from()==i.head:o.from()==o.head;n<=t&&--t,e.splice(--n,2,new Ts(a?s:l,a?l:s))}}return new ks(e,t)}function Rn(e,t){return new ks([new Ts(e,t||e)],0)}function Bn(e){return e.text?E(e.from.line+e.text.length-1,g(e.text).length+(1==e.text.length?e.from.ch:0)):e.to}function Gn(e,t){if(P(e,t.from)<0)return e;if(P(e,t.to)<=0)return Bn(t);var r=e.line+t.text.length-(t.to.line-t.from.line)-1,n=e.ch;return e.line==t.to.line&&(n+=Bn(t).ch-t.to.ch),E(r,n)}function Un(e,t){for(var r=[],n=0;n<e.sel.ranges.length;n++){var i=e.sel.ranges[n];r.push(new Ts(Gn(i.anchor,t),Gn(i.head,t)))}return zn(r,e.sel.primIndex)}function Vn(e,t,r){return e.line==t.line?E(r.line,e.ch-t.ch+r.ch):E(r.line+(e.line-t.line),e.ch)}function Kn(e,t,r){for(var n=[],i=E(e.first,0),o=i,l=0;l<t.length;l++){var s=t[l],a=Vn(s.from,i,o),u=Vn(Bn(s),i,o);if(i=s.to,o=u,"around"==r){var c=e.sel.ranges[l],f=P(c.head,c.anchor)<0;n[l]=new Ts(f?u:a,f?a:u)}else n[l]=new Ts(a,a)}return new ks(n,e.sel.primIndex)}function jn(e){e.doc.mode=Ue(e.options,e.doc.modeOption),Xn(e)}function Xn(e){e.doc.iter(function(e){e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null)}),e.doc.modeFrontier=e.doc.highlightFrontier=e.doc.first,Cn(e,100),e.state.modeGen++,e.curOp&&vn(e)}function Yn(e,t){return 0==t.from.ch&&0==t.to.ch&&""==g(t.text)&&(!e.cm||e.cm.options.wholeLineUpdateBefore)}function _n(e,t,r,n){function i(e){return r?r[e]:null}function o(e,r,i){it(e,r,i,n),bt(e,"change",e,t)}function l(e,t){for(var r=[],o=e;o<t;++o)r.push(new fs(u[o],i(o),n));return r}var s=t.from,a=t.to,u=t.text,c=M(e,s.line),f=M(e,a.line),h=g(u),d=i(u.length-1),p=a.line-s.line;if(t.full)e.insert(0,l(0,u.length)),e.remove(u.length,e.size-u.length);else if(Yn(e,t)){var v=l(0,u.length-1);o(f,f.text,d),p&&e.remove(s.line,p),v.length&&e.insert(s.line,v)}else if(c==f)if(1==u.length)o(c,c.text.slice(0,s.ch)+h+c.text.slice(a.ch),d);else{var m=l(1,u.length-1);m.push(new fs(h+c.text.slice(a.ch),d,n)),o(c,c.text.slice(0,s.ch)+u[0],i(0)),e.insert(s.line+1,m)}else if(1==u.length)o(c,c.text.slice(0,s.ch)+u[0]+f.text.slice(a.ch),i(0)),e.remove(s.line+1,p);else{o(c,c.text.slice(0,s.ch)+u[0],i(0)),o(f,h+f.text.slice(a.ch),d);var y=l(1,u.length-1);p>1&&e.remove(s.line+1,p-1),e.insert(s.line+1,y)}bt(e,"change",e,t)}function $n(e,t,r){function n(e,i,o){if(e.linked)for(var l=0;l<e.linked.length;++l){var s=e.linked[l];if(s.doc!=i){var a=o&&s.sharedHist;r&&!a||(t(s.doc,a),n(s.doc,e,a))}}}n(e,null,!0)}function qn(e,t){if(t.cm)throw new Error("This document is already in use.");e.doc=t,t.cm=e,Cr(e),jn(e),Zn(e),e.options.lineWrapping||we(e),e.options.mode=t.modeOption,vn(e)}function Zn(e){("rtl"==e.doc.direction?s:Fl)(e.display.lineDiv,"CodeMirror-rtl")}function Qn(e){hn(e,function(){Zn(e),vn(e)})}function Jn(e){this.done=[],this.undone=[],this.undoDepth=1/0,this.lastModTime=this.lastSelTime=0,this.lastOp=this.lastSelOp=null,this.lastOrigin=this.lastSelOrigin=null,this.generation=this.maxGeneration=e||1}function ei(e,t){var r={from:z(t.from),to:Bn(t),text:N(e,t.from,t.to)};return si(e,r,t.from.line,t.to.line+1),$n(e,function(e){return si(e,r,t.from.line,t.to.line+1)},!0),r}function ti(e){for(;e.length&&g(e).ranges;)e.pop()}function ri(e,t){return t?(ti(e.done),g(e.done)):e.done.length&&!g(e.done).ranges?g(e.done):e.done.length>1&&!e.done[e.done.length-2].ranges?(e.done.pop(),g(e.done)):void 0}function ni(e,t,r,n){var i=e.history;i.undone.length=0;var o,l,s=+new Date;if((i.lastOp==n||i.lastOrigin==t.origin&&t.origin&&("+"==t.origin.charAt(0)&&e.cm&&i.lastModTime>s-e.cm.options.historyEventDelay||"*"==t.origin.charAt(0)))&&(o=ri(i,i.lastOp==n)))l=g(o.changes),0==P(t.from,t.to)&&0==P(t.from,l.to)?l.to=Bn(t):o.changes.push(ei(e,t));else{var a=g(i.done);for(a&&a.ranges||li(e.sel,i.done),o={changes:[ei(e,t)],generation:i.generation},i.done.push(o);i.done.length>i.undoDepth;)i.done.shift(),i.done[0].ranges||i.done.shift()}i.done.push(r),i.generation=++i.maxGeneration,i.lastModTime=i.lastSelTime=s,i.lastOp=i.lastSelOp=n,i.lastOrigin=i.lastSelOrigin=t.origin,l||Te(e,"historyAdded")}function ii(e,t,r,n){var i=t.charAt(0);return"*"==i||"+"==i&&r.ranges.length==n.ranges.length&&r.somethingSelected()==n.somethingSelected()&&new Date-e.history.lastSelTime<=(e.cm?e.cm.options.historyEventDelay:500)}function oi(e,t,r,n){var i=e.history,o=n&&n.origin;r==i.lastSelOp||o&&i.lastSelOrigin==o&&(i.lastModTime==i.lastSelTime&&i.lastOrigin==o||ii(e,o,g(i.done),t))?i.done[i.done.length-1]=t:li(t,i.done),i.lastSelTime=+new Date,i.lastSelOrigin=o,i.lastSelOp=r,n&&!1!==n.clearRedo&&ti(i.undone)}function li(e,t){var r=g(t);r&&r.ranges&&r.equals(e)||t.push(e)}function si(e,t,r,n){var i=t["spans_"+e.id],o=0;e.iter(Math.max(e.first,r),Math.min(e.first+e.size,n),function(r){r.markedSpans&&((i||(i=t["spans_"+e.id]={}))[o]=r.markedSpans),++o})}function ai(e){if(!e)return null;for(var t,r=0;r<e.length;++r)e[r].marker.explicitlyCleared?t||(t=e.slice(0,r)):t&&t.push(e[r]);return t?t.length?t:null:e}function ui(e,t){var r=t["spans_"+e.id];if(!r)return null;for(var n=[],i=0;i<t.text.length;++i)n.push(ai(r[i]));return n}function ci(e,t){var r=ui(e,t),n=J(e,t);if(!r)return n;if(!n)return r;for(var i=0;i<r.length;++i){var o=r[i],l=n[i];if(o&&l)e:for(var s=0;s<l.length;++s){for(var a=l[s],u=0;u<o.length;++u)if(o[u].marker==a.marker)continue e;o.push(a)}else l&&(r[i]=l)}return r}function fi(e,t,r){for(var n=[],i=0;i<e.length;++i){var o=e[i];if(o.ranges)n.push(r?ks.prototype.deepCopy.call(o):o);else{var l=o.changes,s=[];n.push({changes:s});for(var a=0;a<l.length;++a){var u=l[a],c=void 0;if(s.push({from:u.from,to:u.to,text:u.text}),t)for(var f in u)(c=f.match(/^spans_(\d+)$/))&&h(t,Number(c[1]))>-1&&(g(s)[f]=u[f],delete u[f])}}}return n}function hi(e,t,r,n){if(n){var i=e.anchor;if(r){var o=P(t,i)<0;o!=P(r,i)<0?(i=t,t=r):o!=P(t,r)<0&&(t=r)}return new Ts(i,t)}return new Ts(r||t,t)}function di(e,t,r,n,i){null==i&&(i=e.cm&&(e.cm.display.shift||e.extend)),bi(e,new ks([hi(e.sel.primary(),t,r,i)],0),n)}function pi(e,t,r){for(var n=[],i=e.cm&&(e.cm.display.shift||e.extend),o=0;o<e.sel.ranges.length;o++)n[o]=hi(e.sel.ranges[o],t[o],null,i);bi(e,zn(n,e.sel.primIndex),r)}function gi(e,t,r,n){var i=e.sel.ranges.slice(0);i[t]=r,bi(e,zn(i,e.sel.primIndex),n)}function vi(e,t,r,n){bi(e,Rn(t,r),n)}function mi(e,t,r){var n={ranges:t.ranges,update:function(t){var r=this;this.ranges=[];for(var n=0;n<t.length;n++)r.ranges[n]=new Ts(U(e,t[n].anchor),U(e,t[n].head))},origin:r&&r.origin};return Te(e,"beforeSelectionChange",e,n),e.cm&&Te(e.cm,"beforeSelectionChange",e.cm,n),n.ranges!=t.ranges?zn(n.ranges,n.ranges.length-1):t}function yi(e,t,r){var n=e.history.done,i=g(n);i&&i.ranges?(n[n.length-1]=t,wi(e,t,r)):bi(e,t,r)}function bi(e,t,r){wi(e,t,r),oi(e,e.sel,e.cm?e.cm.curOp.id:NaN,r)}function wi(e,t,r){(Oe(e,"beforeSelectionChange")||e.cm&&Oe(e.cm,"beforeSelectionChange"))&&(t=mi(e,t,r)),xi(e,Si(e,t,r&&r.bias||(P(t.primary().head,e.sel.primary().head)<0?-1:1),!0)),r&&!1===r.scroll||!e.cm||jr(e.cm)}function xi(e,t){t.equals(e.sel)||(e.sel=t,e.cm&&(e.cm.curOp.updateInput=e.cm.curOp.selectionChanged=!0,Ne(e.cm)),bt(e,"cursorActivity",e))}function Ci(e){xi(e,Si(e,e.sel,null,!1))}function Si(e,t,r,n){for(var i,o=0;o<t.ranges.length;o++){var l=t.ranges[o],s=t.ranges.length==e.sel.ranges.length&&e.sel.ranges[o],a=ki(e,l.anchor,s&&s.anchor,r,n),u=ki(e,l.head,s&&s.head,r,n);(i||a!=l.anchor||u!=l.head)&&(i||(i=t.ranges.slice(0,o)),i[o]=new Ts(a,u))}return i?zn(i,t.primIndex):t}function Li(e,t,r,n,i){var o=M(e,t.line);if(o.markedSpans)for(var l=0;l<o.markedSpans.length;++l){var s=o.markedSpans[l],a=s.marker;if((null==s.from||(a.inclusiveLeft?s.from<=t.ch:s.from<t.ch))&&(null==s.to||(a.inclusiveRight?s.to>=t.ch:s.to>t.ch))){if(i&&(Te(a,"beforeCursorEnter"),a.explicitlyCleared)){if(o.markedSpans){--l;continue}break}if(!a.atomic)continue;if(r){var u=a.find(n<0?1:-1),c=void 0;if((n<0?a.inclusiveRight:a.inclusiveLeft)&&(u=Ti(e,u,-n,u&&u.line==t.line?o:null)),u&&u.line==t.line&&(c=P(u,r))&&(n<0?c<0:c>0))return Li(e,u,t,n,i)}var f=a.find(n<0?-1:1);return(n<0?a.inclusiveLeft:a.inclusiveRight)&&(f=Ti(e,f,n,f.line==t.line?o:null)),f?Li(e,f,t,n,i):null}}return t}function ki(e,t,r,n,i){var o=n||1,l=Li(e,t,r,o,i)||!i&&Li(e,t,r,o,!0)||Li(e,t,r,-o,i)||!i&&Li(e,t,r,-o,!0);return l||(e.cantEdit=!0,E(e.first,0))}function Ti(e,t,r,n){return r<0&&0==t.ch?t.line>e.first?U(e,E(t.line-1)):null:r>0&&t.ch==(n||M(e,t.line)).text.length?t.line<e.first+e.size-1?E(t.line+1,0):null:new E(t.line,t.ch+r)}function Mi(e){e.setSelection(E(e.firstLine(),0),E(e.lastLine()),Gl)}function Ni(e,t,r){var n={canceled:!1,from:t.from,to:t.to,text:t.text,origin:t.origin,cancel:function(){return n.canceled=!0}};return r&&(n.update=function(t,r,i,o){t&&(n.from=U(e,t)),r&&(n.to=U(e,r)),i&&(n.text=i),void 0!==o&&(n.origin=o)}),Te(e,"beforeChange",e,n),e.cm&&Te(e.cm,"beforeChange",e.cm,n),n.canceled?null:{from:n.from,to:n.to,text:n.text,origin:n.origin}}function Oi(e,t,r){if(e.cm){if(!e.cm.curOp)return dn(e.cm,Oi)(e,t,r);if(e.cm.state.suppressEdits)return}if(!(Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"))||(t=Ni(e,t,!0))){var n=Yl&&!r&&te(e,t.from,t.to);if(n)for(var i=n.length-1;i>=0;--i)Ai(e,{from:n[i].from,to:n[i].to,text:i?[""]:t.text,origin:t.origin});else Ai(e,t)}}function Ai(e,t){if(1!=t.text.length||""!=t.text[0]||0!=P(t.from,t.to)){var r=Un(e,t);ni(e,t,r,e.cm?e.cm.curOp.id:NaN),Hi(e,t,r,J(e,t));var n=[];$n(e,function(e,r){r||-1!=h(n,e.history)||(zi(e.history,t),n.push(e.history)),Hi(e,t,null,J(e,t))})}}function Wi(e,t,r){if(!e.cm||!e.cm.state.suppressEdits||r){for(var n,i=e.history,o=e.sel,l="undo"==t?i.done:i.undone,s="undo"==t?i.undone:i.done,a=0;a<l.length&&(n=l[a],r?!n.ranges||n.equals(e.sel):n.ranges);a++);if(a!=l.length){for(i.lastOrigin=i.lastSelOrigin=null;(n=l.pop()).ranges;){if(li(n,s),r&&!n.equals(e.sel))return void bi(e,n,{clearRedo:!1});o=n}var u=[];li(o,s),s.push({changes:u,generation:i.generation}),i.generation=n.generation||++i.maxGeneration;for(var c=Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"),f=n.changes.length-1;f>=0;--f){var d=function(r){var i=n.changes[r];if(i.origin=t,c&&!Ni(e,i,!1))return l.length=0,{};u.push(ei(e,i));var o=r?Un(e,i):g(l);Hi(e,i,o,ci(e,i)),!r&&e.cm&&e.cm.scrollIntoView({from:i.from,to:Bn(i)});var s=[];$n(e,function(e,t){t||-1!=h(s,e.history)||(zi(e.history,i),s.push(e.history)),Hi(e,i,null,ci(e,i))})}(f);if(d)return d.v}}}}function Di(e,t){if(0!=t&&(e.first+=t,e.sel=new ks(v(e.sel.ranges,function(e){return new Ts(E(e.anchor.line+t,e.anchor.ch),E(e.head.line+t,e.head.ch))}),e.sel.primIndex),e.cm)){vn(e.cm,e.first,e.first-t,t);for(var r=e.cm.display,n=r.viewFrom;n<r.viewTo;n++)mn(e.cm,n,"gutter")}}function Hi(e,t,r,n){if(e.cm&&!e.cm.curOp)return dn(e.cm,Hi)(e,t,r,n);if(t.to.line<e.first)Di(e,t.text.length-1-(t.to.line-t.from.line));else if(!(t.from.line>e.lastLine())){if(t.from.line<e.first){var i=t.text.length-1-(e.first-t.from.line);Di(e,i),t={from:E(e.first,0),to:E(t.to.line+i,t.to.ch),text:[g(t.text)],origin:t.origin}}var o=e.lastLine();t.to.line>o&&(t={from:t.from,to:E(o,M(e,o).text.length),text:[t.text[0]],origin:t.origin}),t.removed=N(e,t.from,t.to),r||(r=Un(e,t)),e.cm?Fi(e.cm,t,n):_n(e,t,n),wi(e,r,Gl)}}function Fi(e,t,r){var n=e.doc,i=e.display,o=t.from,l=t.to,s=!1,a=o.line;e.options.lineWrapping||(a=W(fe(M(n,o.line))),n.iter(a,l.line+1,function(e){if(e==i.maxLine)return s=!0,!0})),n.sel.contains(t.from,t.to)>-1&&Ne(e),_n(n,t,r,xr(e)),e.options.lineWrapping||(n.iter(a,o.line+t.text.length,function(e){var t=be(e);t>i.maxLineLength&&(i.maxLine=e,i.maxLineLength=t,i.maxLineChanged=!0,s=!1)}),s&&(e.curOp.updateMaxLine=!0)),nt(n,o.line),Cn(e,400);var u=t.text.length-(l.line-o.line)-1;t.full?vn(e):o.line!=l.line||1!=t.text.length||Yn(e.doc,t)?vn(e,o.line,l.line+1,u):mn(e,o.line,"text");var c=Oe(e,"changes"),f=Oe(e,"change");if(f||c){var h={from:o,to:l,text:t.text,removed:t.removed,origin:t.origin};f&&bt(e,"change",e,h),c&&(e.curOp.changeObjs||(e.curOp.changeObjs=[])).push(h)}e.display.selForContextMenu=null}function Ei(e,t,r,n,i){if(n||(n=r),P(n,r)<0){var o;r=(o=[n,r])[0],n=o[1]}"string"==typeof t&&(t=e.splitLines(t)),Oi(e,{from:r,to:n,text:t,origin:i})}function Pi(e,t,r,n){r<e.line?e.line+=n:t<e.line&&(e.line=t,e.ch=0)}function Ii(e,t,r,n){for(var i=0;i<e.length;++i){var o=e[i],l=!0;if(o.ranges){o.copied||((o=e[i]=o.deepCopy()).copied=!0);for(var s=0;s<o.ranges.length;s++)Pi(o.ranges[s].anchor,t,r,n),Pi(o.ranges[s].head,t,r,n)}else{for(var a=0;a<o.changes.length;++a){var u=o.changes[a];if(r<u.from.line)u.from=E(u.from.line+n,u.from.ch),u.to=E(u.to.line+n,u.to.ch);else if(t<=u.to.line){l=!1;break}}l||(e.splice(0,i+1),i=0)}}}function zi(e,t){var r=t.from.line,n=t.to.line,i=t.text.length-(n-r)-1;Ii(e.done,r,n,i),Ii(e.undone,r,n,i)}function Ri(e,t,r,n){var i=t,o=t;return"number"==typeof t?o=M(e,G(e,t)):i=W(t),null==i?null:(n(o,i)&&e.cm&&mn(e.cm,i,r),o)}function Bi(e){var t=this;this.lines=e,this.parent=null;for(var r=0,n=0;n<e.length;++n)e[n].parent=t,r+=e[n].height;this.height=r}function Gi(e){var t=this;this.children=e;for(var r=0,n=0,i=0;i<e.length;++i){var o=e[i];r+=o.chunkSize(),n+=o.height,o.parent=t}this.size=r,this.height=n,this.parent=null}function Ui(e,t,r){ye(t)<(e.curOp&&e.curOp.scrollTop||e.doc.scrollTop)&&Kr(e,r)}function Vi(e,t,r,n){var i=new Ms(e,r,n),o=e.cm;return o&&i.noHScroll&&(o.display.alignWidgets=!0),Ri(e,t,"widget",function(t){var r=t.widgets||(t.widgets=[]);if(null==i.insertAt?r.push(i):r.splice(Math.min(r.length-1,Math.max(0,i.insertAt)),0,i),i.line=t,o&&!ve(e,t)){var n=ye(t)<e.scrollTop;A(t,t.height+Ht(i)),n&&Kr(o,i.height),o.curOp.forceUpdate=!0}return!0}),bt(o,"lineWidgetAdded",o,i,"number"==typeof t?t:W(t)),i}function Ki(e,t,r,n,o){if(n&&n.shared)return ji(e,t,r,n,o);if(e.cm&&!e.cm.curOp)return dn(e.cm,Ki)(e,t,r,n,o);var l=new Os(e,o),s=P(t,r);if(n&&c(n,l,!1),s>0||0==s&&!1!==l.clearWhenEmpty)return l;if(l.replacedWith&&(l.collapsed=!0,l.widgetNode=i("span",[l.replacedWith],"CodeMirror-widget"),n.handleMouseEvents||l.widgetNode.setAttribute("cm-ignore-events","true"),n.insertLeft&&(l.widgetNode.insertLeft=!0)),l.collapsed){if(ce(e,t.line,t,r,l)||t.line!=r.line&&ce(e,r.line,t,r,l))throw new Error("Inserting collapsed marker partially overlapping an existing one");X()}l.addToHistory&&ni(e,{from:t,to:r,origin:"markText"},e.sel,NaN);var a,u=t.line,f=e.cm;if(e.iter(u,r.line+1,function(e){f&&l.collapsed&&!f.options.lineWrapping&&fe(e)==f.display.maxLine&&(a=!0),l.collapsed&&u!=t.line&&A(e,0),q(e,new Y(l,u==t.line?t.ch:null,u==r.line?r.ch:null)),++u}),l.collapsed&&e.iter(t.line,r.line+1,function(t){ve(e,t)&&A(t,0)}),l.clearOnEnter&&Ql(l,"beforeCursorEnter",function(){return l.clear()}),l.readOnly&&(j(),(e.history.done.length||e.history.undone.length)&&e.clearHistory()),l.collapsed&&(l.id=++Ns,l.atomic=!0),f){if(a&&(f.curOp.updateMaxLine=!0),l.collapsed)vn(f,t.line,r.line+1);else if(l.className||l.title||l.startStyle||l.endStyle||l.css)for(var h=t.line;h<=r.line;h++)mn(f,h,"text");l.atomic&&Ci(f.doc),bt(f,"markerAdded",f,l)}return l}function ji(e,t,r,n,i){(n=c(n)).shared=!1;var o=[Ki(e,t,r,n,i)],l=o[0],s=n.widgetNode;return $n(e,function(e){s&&(n.widgetNode=s.cloneNode(!0)),o.push(Ki(e,U(e,t),U(e,r),n,i));for(var a=0;a<e.linked.length;++a)if(e.linked[a].isParent)return;l=g(o)}),new As(o,l)}function Xi(e){return e.findMarks(E(e.first,0),e.clipPos(E(e.lastLine())),function(e){return e.parent})}function Yi(e,t){for(var r=0;r<t.length;r++){var n=t[r],i=n.find(),o=e.clipPos(i.from),l=e.clipPos(i.to);if(P(o,l)){var s=Ki(e,o,l,n.primary,n.primary.type);n.markers.push(s),s.parent=n}}}function _i(e){for(var t=0;t<e.length;t++)!function(t){var r=e[t],n=[r.primary.doc];$n(r.primary.doc,function(e){return n.push(e)});for(var i=0;i<r.markers.length;i++){var o=r.markers[i];-1==h(n,o.doc)&&(o.parent=null,r.markers.splice(i--,1))}}(t)}function $i(e){var t=this;if(Qi(t),!Me(t,e)&&!Ft(t.display,e)){We(e),gl&&(Hs=+new Date);var r=Sr(t,e,!0),n=e.dataTransfer.files;if(r&&!t.isReadOnly())if(n&&n.length&&window.FileReader&&window.File)for(var i=n.length,o=Array(i),l=0,s=0;s<i;++s)!function(e,n){if(!t.options.allowDropFileTypes||-1!=h(t.options.allowDropFileTypes,e.type)){var s=new FileReader;s.onload=dn(t,function(){var e=s.result;if(/[\x00-\x08\x0e-\x1f]{2}/.test(e)&&(e=""),o[n]=e,++l==i){var a={from:r=U(t.doc,r),to:r,text:t.doc.splitLines(o.join(t.doc.lineSeparator())),origin:"paste"};Oi(t.doc,a),yi(t.doc,Rn(r,Bn(a)))}}),s.readAsText(e)}}(n[s],s);else{if(t.state.draggingText&&t.doc.sel.contains(r)>-1)return t.state.draggingText(e),void setTimeout(function(){return t.display.input.focus()},20);try{var a=e.dataTransfer.getData("Text");if(a){var u;if(t.state.draggingText&&!t.state.draggingText.copy&&(u=t.listSelections()),wi(t.doc,Rn(r,r)),u)for(var c=0;c<u.length;++c)Ei(t.doc,"",u[c].anchor,u[c].head,"drag");t.replaceSelection(a,"around","paste"),t.display.input.focus()}}catch(e){}}}}function qi(e,t){if(gl&&(!e.state.draggingText||+new Date-Hs<100))Fe(t);else if(!Me(e,t)&&!Ft(e.display,t)&&(t.dataTransfer.setData("Text",e.getSelection()),t.dataTransfer.effectAllowed="copyMove",t.dataTransfer.setDragImage&&!xl)){var r=n("img",null,null,"position: fixed; left: 0; top: 0;");r.src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==",wl&&(r.width=r.height=1,e.display.wrapper.appendChild(r),r._top=r.offsetTop),t.dataTransfer.setDragImage(r,0,0),wl&&r.parentNode.removeChild(r)}}function Zi(e,t){var i=Sr(e,t);if(i){var o=document.createDocumentFragment();Mr(e,i,o),e.display.dragCursor||(e.display.dragCursor=n("div",null,"CodeMirror-cursors CodeMirror-dragcursors"),e.display.lineSpace.insertBefore(e.display.dragCursor,e.display.cursorDiv)),r(e.display.dragCursor,o)}}function Qi(e){e.display.dragCursor&&(e.display.lineSpace.removeChild(e.display.dragCursor),e.display.dragCursor=null)}function Ji(e){if(document.getElementsByClassName)for(var t=document.getElementsByClassName("CodeMirror"),r=0;r<t.length;r++){var n=t[r].CodeMirror;n&&e(n)}}function eo(){Fs||(to(),Fs=!0)}function to(){var e;Ql(window,"resize",function(){null==e&&(e=setTimeout(function(){e=null,Ji(ro)},100))}),Ql(window,"blur",function(){return Ji(Fr)})}function ro(e){var t=e.display;t.lastWrapHeight==t.wrapper.clientHeight&&t.lastWrapWidth==t.wrapper.clientWidth||(t.cachedCharWidth=t.cachedTextHeight=t.cachedPaddingH=null,t.scrollbarsClipped=!1,e.setSize())}function no(e){var t=e.split(/-(?!$)/);e=t[t.length-1];for(var r,n,i,o,l=0;l<t.length-1;l++){var s=t[l];if(/^(cmd|meta|m)$/i.test(s))o=!0;else if(/^a(lt)?$/i.test(s))r=!0;else if(/^(c|ctrl|control)$/i.test(s))n=!0;else{if(!/^s(hift)?$/i.test(s))throw new Error("Unrecognized modifier name: "+s);i=!0}}return r&&(e="Alt-"+e),n&&(e="Ctrl-"+e),o&&(e="Cmd-"+e),i&&(e="Shift-"+e),e}function io(e){var t={};for(var r in e)if(e.hasOwnProperty(r)){var n=e[r];if(/^(name|fallthrough|(de|at)tach)$/.test(r))continue;if("..."==n){delete e[r];continue}for(var i=v(r.split(" "),no),o=0;o<i.length;o++){var l=void 0,s=void 0;o==i.length-1?(s=i.join(" "),l=n):(s=i.slice(0,o+1).join(" "),l="...");var a=t[s];if(a){if(a!=l)throw new Error("Inconsistent bindings for "+s)}else t[s]=l}delete e[r]}for(var u in t)e[u]=t[u];return e}function oo(e,t,r,n){var i=(t=uo(t)).call?t.call(e,n):t[e];if(!1===i)return"nothing";if("..."===i)return"multi";if(null!=i&&r(i))return"handled";if(t.fallthrough){if("[object Array]"!=Object.prototype.toString.call(t.fallthrough))return oo(e,t.fallthrough,r,n);for(var o=0;o<t.fallthrough.length;o++){var l=oo(e,t.fallthrough[o],r,n);if(l)return l}}}function lo(e){var t="string"==typeof e?e:Es[e.keyCode];return"Ctrl"==t||"Alt"==t||"Shift"==t||"Mod"==t}function so(e,t,r){var n=e;return t.altKey&&"Alt"!=n&&(e="Alt-"+e),(Dl?t.metaKey:t.ctrlKey)&&"Ctrl"!=n&&(e="Ctrl-"+e),(Dl?t.ctrlKey:t.metaKey)&&"Cmd"!=n&&(e="Cmd-"+e),!r&&t.shiftKey&&"Shift"!=n&&(e="Shift-"+e),e}function ao(e,t){if(wl&&34==e.keyCode&&e.char)return!1;var r=Es[e.keyCode];return null!=r&&!e.altGraphKey&&so(r,e,t)}function uo(e){return"string"==typeof e?Rs[e]:e}function co(e,t){for(var r=e.doc.sel.ranges,n=[],i=0;i<r.length;i++){for(var o=t(r[i]);n.length&&P(o.from,g(n).to)<=0;){var l=n.pop();if(P(l.from,o.from)<0){o.from=l.from;break}}n.push(o)}hn(e,function(){for(var t=n.length-1;t>=0;t--)Ei(e.doc,"",n[t].from,n[t].to,"+delete");jr(e)})}function fo(e,t,r){var n=L(e.text,t+r,r);return n<0||n>e.text.length?null:n}function ho(e,t,r){var n=fo(e,t.ch,r);return null==n?null:new E(t.line,n,r<0?"after":"before")}function po(e,t,r,n,i){if(e){var o=Se(r,t.doc.direction);if(o){var l,s=i<0?g(o):o[0],a=i<0==(1==s.level)?"after":"before";if(s.level>0){var u=Xt(t,r);l=i<0?r.text.length-1:0;var c=Yt(t,u,l).top;l=k(function(e){return Yt(t,u,e).top==c},i<0==(1==s.level)?s.from:s.to-1,l),"before"==a&&(l=fo(r,l,1))}else l=i<0?s.to:s.from;return new E(n,l,a)}}return new E(n,i<0?r.text.length:0,i<0?"before":"after")}function go(e,t,r,n){var i=Se(t,e.doc.direction);if(!i)return ho(t,r,n);r.ch>=t.text.length?(r.ch=t.text.length,r.sticky="before"):r.ch<=0&&(r.ch=0,r.sticky="after");var o=Ce(i,r.ch,r.sticky),l=i[o];if("ltr"==e.doc.direction&&l.level%2==0&&(n>0?l.to>r.ch:l.from<r.ch))return ho(t,r,n);var s,a=function(e,r){return fo(t,e instanceof E?e.ch:e,r)},u=function(r){return e.options.lineWrapping?(s=s||Xt(e,t),hr(e,t,s,r)):{begin:0,end:t.text.length}},c=u("before"==r.sticky?a(r,-1):r.ch);if("rtl"==e.doc.direction||1==l.level){var f=1==l.level==n<0,h=a(r,f?1:-1);if(null!=h&&(f?h<=l.to&&h<=c.end:h>=l.from&&h>=c.begin)){var d=f?"before":"after";return new E(r.line,h,d)}}var p=function(e,t,n){for(var o=function(e,t){return t?new E(r.line,a(e,1),"before"):new E(r.line,e,"after")};e>=0&&e<i.length;e+=t){var l=i[e],s=t>0==(1!=l.level),u=s?n.begin:a(n.end,-1);if(l.from<=u&&u<l.to)return o(u,s);if(u=s?l.from:a(l.to,-1),n.begin<=u&&u<n.end)return o(u,s)}},g=p(o+n,n,c);if(g)return g;var v=n>0?c.end:a(c.begin,-1);return null==v||n>0&&v==t.text.length||!(g=p(n>0?0:i.length-1,n,u(v)))?null:g}function vo(e,t){var r=M(e.doc,t),n=fe(r);return n!=r&&(t=W(n)),po(!0,e,n,t,1)}function mo(e,t){var r=M(e.doc,t),n=he(r);return n!=r&&(t=W(n)),po(!0,e,r,t,-1)}function yo(e,t){var r=vo(e,t.line),n=M(e.doc,r.line),i=Se(n,e.doc.direction);if(!i||0==i[0].level){var o=Math.max(0,n.text.search(/\S/)),l=t.line==r.line&&t.ch<=o&&t.ch;return E(r.line,l?0:o,r.sticky)}return r}function bo(e,t,r){if("string"==typeof t&&!(t=Bs[t]))return!1;e.display.input.ensurePolled();var n=e.display.shift,i=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),r&&(e.display.shift=!1),i=t(e)!=Bl}finally{e.display.shift=n,e.state.suppressEdits=!1}return i}function wo(e,t,r){for(var n=0;n<e.state.keyMaps.length;n++){var i=oo(t,e.state.keyMaps[n],r,e);if(i)return i}return e.options.extraKeys&&oo(t,e.options.extraKeys,r,e)||oo(t,e.options.keyMap,r,e)}function xo(e,t,r,n){var i=e.state.keySeq;if(i){if(lo(t))return"handled";Gs.set(50,function(){e.state.keySeq==i&&(e.state.keySeq=null,e.display.input.reset())}),t=i+" "+t}var o=wo(e,t,n);return"multi"==o&&(e.state.keySeq=t),"handled"==o&&bt(e,"keyHandled",e,t,r),"handled"!=o&&"multi"!=o||(We(r),Ar(e)),i&&!o&&/\'$/.test(t)?(We(r),!0):!!o}function Co(e,t){var r=ao(t,!0);return!!r&&(t.shiftKey&&!e.state.keySeq?xo(e,"Shift-"+r,t,function(t){return bo(e,t,!0)})||xo(e,r,t,function(t){if("string"==typeof t?/^go[A-Z]/.test(t):t.motion)return bo(e,t)}):xo(e,r,t,function(t){return bo(e,t)}))}function So(e,t,r){return xo(e,"'"+r+"'",t,function(t){return bo(e,t,!0)})}function Lo(e){var t=this;if(t.curOp.focus=l(),!Me(t,e)){gl&&vl<11&&27==e.keyCode&&(e.returnValue=!1);var r=e.keyCode;t.display.shift=16==r||e.shiftKey;var n=Co(t,e);wl&&(Us=n?r:null,!n&&88==r&&!rs&&(Ml?e.metaKey:e.ctrlKey)&&t.replaceSelection("",null,"cut")),18!=r||/\bCodeMirror-crosshair\b/.test(t.display.lineDiv.className)||ko(t)}}function ko(e){function t(e){18!=e.keyCode&&e.altKey||(Fl(r,"CodeMirror-crosshair"),ke(document,"keyup",t),ke(document,"mouseover",t))}var r=e.display.lineDiv;s(r,"CodeMirror-crosshair"),Ql(document,"keyup",t),Ql(document,"mouseover",t)}function To(e){16==e.keyCode&&(this.doc.sel.shift=!1),Me(this,e)}function Mo(e){var t=this;if(!(Ft(t.display,e)||Me(t,e)||e.ctrlKey&&!e.altKey||Ml&&e.metaKey)){var r=e.keyCode,n=e.charCode;if(wl&&r==Us)return Us=null,void We(e);if(!wl||e.which&&!(e.which<10)||!Co(t,e)){var i=String.fromCharCode(null==n?r:n);"\b"!=i&&(So(t,e,i)||t.display.input.onKeyPress(e))}}}function No(e,t){var r=+new Date;return js&&js.compare(r,e,t)?(Ks=js=null,"triple"):Ks&&Ks.compare(r,e,t)?(js=new Vs(r,e,t),Ks=null,"double"):(Ks=new Vs(r,e,t),js=null,"single")}function Oo(e){var t=this,r=t.display;if(!(Me(t,e)||r.activeTouch&&r.input.supportsTouch()))if(r.input.ensurePolled(),r.shift=e.shiftKey,Ft(r,e))ml||(r.scroller.draggable=!1,setTimeout(function(){return r.scroller.draggable=!0},100));else if(!zo(t,e)){var n=Sr(t,e),i=Pe(e),o=n?No(n,i):"single";window.focus(),1==i&&t.state.selectingText&&t.state.selectingText(e),n&&Ao(t,i,n,o,e)||(1==i?n?Do(t,n,o,e):Ee(e)==r.scroller&&We(e):2==i?(n&&di(t.doc,n),setTimeout(function(){return r.input.focus()},20)):3==i&&(Hl?Ro(t,e):Dr(t)))}}function Ao(e,t,r,n,i){var o="Click";return"double"==n?o="Double"+o:"triple"==n&&(o="Triple"+o),o=(1==t?"Left":2==t?"Middle":"Right")+o,xo(e,so(o,i),i,function(t){if("string"==typeof t&&(t=Bs[t]),!t)return!1;var n=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),n=t(e,r)!=Bl}finally{e.state.suppressEdits=!1}return n})}function Wo(e,t,r){var n=e.getOption("configureMouse"),i=n?n(e,t,r):{};if(null==i.unit){var o=Nl?r.shiftKey&&r.metaKey:r.altKey;i.unit=o?"rectangle":"single"==t?"char":"double"==t?"word":"line"}return(null==i.extend||e.doc.extend)&&(i.extend=e.doc.extend||r.shiftKey),null==i.addNew&&(i.addNew=Ml?r.metaKey:r.ctrlKey),null==i.moveOnDrag&&(i.moveOnDrag=!(Ml?r.altKey:r.ctrlKey)),i}function Do(e,t,r,n){gl?setTimeout(u(Wr,e),0):e.curOp.focus=l();var i,o=Wo(e,r,n),s=e.doc.sel;e.options.dragDrop&&Jl&&!e.isReadOnly()&&"single"==r&&(i=s.contains(t))>-1&&(P((i=s.ranges[i]).from(),t)<0||t.xRel>0)&&(P(i.to(),t)>0||t.xRel<0)?Ho(e,n,t,o):Eo(e,n,t,o)}function Ho(e,t,r,n){var i=e.display,o=!1,l=dn(e,function(t){ml&&(i.scroller.draggable=!1),e.state.draggingText=!1,ke(document,"mouseup",l),ke(document,"mousemove",s),ke(i.scroller,"dragstart",a),ke(i.scroller,"drop",l),o||(We(t),n.addNew||di(e.doc,r,null,null,n.extend),ml||gl&&9==vl?setTimeout(function(){document.body.focus(),i.input.focus()},20):i.input.focus())}),s=function(e){o=o||Math.abs(t.clientX-e.clientX)+Math.abs(t.clientY-e.clientY)>=10},a=function(){return o=!0};ml&&(i.scroller.draggable=!0),e.state.draggingText=l,l.copy=!n.moveOnDrag,i.scroller.dragDrop&&i.scroller.dragDrop(),Ql(document,"mouseup",l),Ql(document,"mousemove",s),Ql(i.scroller,"dragstart",a),Ql(i.scroller,"drop",l),Dr(e),setTimeout(function(){return i.input.focus()},20)}function Fo(e,t,r){if("char"==r)return new Ts(t,t);if("word"==r)return e.findWordAt(t);if("line"==r)return new Ts(E(t.line,0),U(e.doc,E(t.line+1,0)));var n=r(e,t);return new Ts(n.from,n.to)}function Eo(e,t,r,n){function i(t){if(0!=P(m,t))if(m=t,"rectangle"==n.unit){for(var i=[],o=e.options.tabSize,l=f(M(u,r.line).text,r.ch,o),s=f(M(u,t.line).text,t.ch,o),a=Math.min(l,s),g=Math.max(l,s),v=Math.min(r.line,t.line),y=Math.min(e.lastLine(),Math.max(r.line,t.line));v<=y;v++){var b=M(u,v).text,w=d(b,a,o);a==g?i.push(new Ts(E(v,w),E(v,w))):b.length>w&&i.push(new Ts(E(v,w),E(v,d(b,g,o))))}i.length||i.push(new Ts(r,r)),bi(u,zn(p.ranges.slice(0,h).concat(i),h),{origin:"*mouse",scroll:!1}),e.scrollIntoView(t)}else{var x,C=c,S=Fo(e,t,n.unit),L=C.anchor;P(S.anchor,L)>0?(x=S.head,L=B(C.from(),S.anchor)):(x=S.anchor,L=R(C.to(),S.head));var k=p.ranges.slice(0);k[h]=Po(e,new Ts(U(u,L),x)),bi(u,zn(k,h),Ul)}}function o(t){var r=++b,s=Sr(e,t,!0,"rectangle"==n.unit);if(s)if(0!=P(s,m)){e.curOp.focus=l(),i(s);var c=Ir(a,u);(s.line>=c.to||s.line<c.from)&&setTimeout(dn(e,function(){b==r&&o(t)}),150)}else{var f=t.clientY<y.top?-20:t.clientY>y.bottom?20:0;f&&setTimeout(dn(e,function(){b==r&&(a.scroller.scrollTop+=f,o(t))}),50)}}function s(t){e.state.selectingText=!1,b=1/0,We(t),a.input.focus(),ke(document,"mousemove",w),ke(document,"mouseup",x),u.history.lastSelOrigin=null}var a=e.display,u=e.doc;We(t);var c,h,p=u.sel,g=p.ranges;if(n.addNew&&!n.extend?(h=u.sel.contains(r),c=h>-1?g[h]:new Ts(r,r)):(c=u.sel.primary(),h=u.sel.primIndex),"rectangle"==n.unit)n.addNew||(c=new Ts(r,r)),r=Sr(e,t,!0,!0),h=-1;else{var v=Fo(e,r,n.unit);c=n.extend?hi(c,v.anchor,v.head,n.extend):v}n.addNew?-1==h?(h=g.length,bi(u,zn(g.concat([c]),h),{scroll:!1,origin:"*mouse"})):g.length>1&&g[h].empty()&&"char"==n.unit&&!n.extend?(bi(u,zn(g.slice(0,h).concat(g.slice(h+1)),0),{scroll:!1,origin:"*mouse"}),p=u.sel):gi(u,h,c,Ul):(h=0,bi(u,new ks([c],0),Ul),p=u.sel);var m=r,y=a.wrapper.getBoundingClientRect(),b=0,w=dn(e,function(e){Pe(e)?o(e):s(e)}),x=dn(e,s);e.state.selectingText=x,Ql(document,"mousemove",w),Ql(document,"mouseup",x)}function Po(e,t){var r=t.anchor,n=t.head,i=M(e.doc,r.line);if(0==P(r,n)&&r.sticky==n.sticky)return t;var o=Se(i);if(!o)return t;var l=Ce(o,r.ch,r.sticky),s=o[l];if(s.from!=r.ch&&s.to!=r.ch)return t;var a=l+(s.from==r.ch==(1!=s.level)?0:1);if(0==a||a==o.length)return t;var u;if(n.line!=r.line)u=(n.line-r.line)*("ltr"==e.doc.direction?1:-1)>0;else{var c=Ce(o,n.ch,n.sticky),f=c-l||(n.ch-r.ch)*(1==s.level?-1:1);u=c==a-1||c==a?f<0:f>0}var h=o[a+(u?-1:0)],d=u==(1==h.level),p=d?h.from:h.to,g=d?"after":"before";return r.ch==p&&r.sticky==g?t:new Ts(new E(r.line,p,g),n)}function Io(e,t,r,n){var i,o;if(t.touches)i=t.touches[0].clientX,o=t.touches[0].clientY;else try{i=t.clientX,o=t.clientY}catch(t){return!1}if(i>=Math.floor(e.display.gutters.getBoundingClientRect().right))return!1;n&&We(t);var l=e.display,s=l.lineDiv.getBoundingClientRect();if(o>s.bottom||!Oe(e,r))return He(t);o-=s.top-l.viewOffset;for(var a=0;a<e.options.gutters.length;++a){var u=l.gutters.childNodes[a];if(u&&u.getBoundingClientRect().right>=i)return Te(e,r,e,D(e.doc,o),e.options.gutters[a],t),He(t)}}function zo(e,t){return Io(e,t,"gutterClick",!0)}function Ro(e,t){Ft(e.display,t)||Bo(e,t)||Me(e,t,"contextmenu")||e.display.input.onContextMenu(t)}function Bo(e,t){return!!Oe(e,"gutterContextMenu")&&Io(e,t,"gutterContextMenu",!1)}function Go(e){e.display.wrapper.className=e.display.wrapper.className.replace(/\s*cm-s-\S+/g,"")+e.options.theme.replace(/(^|\s)\s*/g," cm-s-"),er(e)}function Uo(e){Hn(e),vn(e),zr(e)}function Vo(e,t,r){if(!t!=!(r&&r!=Xs)){var n=e.display.dragFunctions,i=t?Ql:ke;i(e.display.scroller,"dragstart",n.start),i(e.display.scroller,"dragenter",n.enter),i(e.display.scroller,"dragover",n.over),i(e.display.scroller,"dragleave",n.leave),i(e.display.scroller,"drop",n.drop)}}function Ko(e){e.options.lineWrapping?(s(e.display.wrapper,"CodeMirror-wrap"),e.display.sizer.style.minWidth="",e.display.sizerWidth=null):(Fl(e.display.wrapper,"CodeMirror-wrap"),we(e)),Cr(e),vn(e),er(e),setTimeout(function(){return en(e)},100)}function jo(e,t){var r=this;if(!(this instanceof jo))return new jo(e,t);this.options=t=t?c(t):{},c(Ys,t,!1),Fn(t);var n=t.value;"string"==typeof n&&(n=new Ds(n,t.mode,null,t.lineSeparator,t.direction)),this.doc=n;var i=new jo.inputStyles[t.inputStyle](this),o=this.display=new T(e,n,i);o.wrapper.CodeMirror=this,Hn(this),Go(this),t.lineWrapping&&(this.display.wrapper.className+=" CodeMirror-wrap"),rn(this),this.state={keyMaps:[],overlays:[],modeGen:0,overwrite:!1,delayingBlurEvent:!1,focused:!1,suppressEdits:!1,pasteIncoming:!1,cutIncoming:!1,selectingText:!1,draggingText:!1,highlight:new Pl,keySeq:null,specialChars:null},t.autofocus&&!Tl&&o.input.focus(),gl&&vl<11&&setTimeout(function(){return r.display.input.reset(!0)},20),Xo(this),eo(),nn(this),this.curOp.forceUpdate=!0,qn(this,n),t.autofocus&&!Tl||this.hasFocus()?setTimeout(u(Hr,this),20):Fr(this);for(var l in _s)_s.hasOwnProperty(l)&&_s[l](r,t[l],Xs);Rr(this),t.finishInit&&t.finishInit(this);for(var s=0;s<$s.length;++s)$s[s](r);on(this),ml&&t.lineWrapping&&"optimizelegibility"==getComputedStyle(o.lineDiv).textRendering&&(o.lineDiv.style.textRendering="auto")}function Xo(e){function t(){i.activeTouch&&(o=setTimeout(function(){return i.activeTouch=null},1e3),(l=i.activeTouch).end=+new Date)}function r(e){if(1!=e.touches.length)return!1;var t=e.touches[0];return t.radiusX<=1&&t.radiusY<=1}function n(e,t){if(null==t.left)return!0;var r=t.left-e.left,n=t.top-e.top;return r*r+n*n>400}var i=e.display;Ql(i.scroller,"mousedown",dn(e,Oo)),gl&&vl<11?Ql(i.scroller,"dblclick",dn(e,function(t){if(!Me(e,t)){var r=Sr(e,t);if(r&&!zo(e,t)&&!Ft(e.display,t)){We(t);var n=e.findWordAt(r);di(e.doc,n.anchor,n.head)}}})):Ql(i.scroller,"dblclick",function(t){return Me(e,t)||We(t)}),Hl||Ql(i.scroller,"contextmenu",function(t){return Ro(e,t)});var o,l={end:0};Ql(i.scroller,"touchstart",function(t){if(!Me(e,t)&&!r(t)&&!zo(e,t)){i.input.ensurePolled(),clearTimeout(o);var n=+new Date;i.activeTouch={start:n,moved:!1,prev:n-l.end<=300?l:null},1==t.touches.length&&(i.activeTouch.left=t.touches[0].pageX,i.activeTouch.top=t.touches[0].pageY)}}),Ql(i.scroller,"touchmove",function(){i.activeTouch&&(i.activeTouch.moved=!0)}),Ql(i.scroller,"touchend",function(r){var o=i.activeTouch;if(o&&!Ft(i,r)&&null!=o.left&&!o.moved&&new Date-o.start<300){var l,s=e.coordsChar(i.activeTouch,"page");l=!o.prev||n(o,o.prev)?new Ts(s,s):!o.prev.prev||n(o,o.prev.prev)?e.findWordAt(s):new Ts(E(s.line,0),U(e.doc,E(s.line+1,0))),e.setSelection(l.anchor,l.head),e.focus(),We(r)}t()}),Ql(i.scroller,"touchcancel",t),Ql(i.scroller,"scroll",function(){i.scroller.clientHeight&&(qr(e,i.scroller.scrollTop),Qr(e,i.scroller.scrollLeft,!0),Te(e,"scroll",e))}),Ql(i.scroller,"mousewheel",function(t){return In(e,t)}),Ql(i.scroller,"DOMMouseScroll",function(t){return In(e,t)}),Ql(i.wrapper,"scroll",function(){return i.wrapper.scrollTop=i.wrapper.scrollLeft=0}),i.dragFunctions={enter:function(t){Me(e,t)||Fe(t)},over:function(t){Me(e,t)||(Zi(e,t),Fe(t))},start:function(t){return qi(e,t)},drop:dn(e,$i),leave:function(t){Me(e,t)||Qi(e)}};var s=i.input.getField();Ql(s,"keyup",function(t){return To.call(e,t)}),Ql(s,"keydown",dn(e,Lo)),Ql(s,"keypress",dn(e,Mo)),Ql(s,"focus",function(t){return Hr(e,t)}),Ql(s,"blur",function(t){return Fr(e,t)})}function Yo(e,t,r,n){var i,o=e.doc;null==r&&(r="add"),"smart"==r&&(o.mode.indent?i=$e(e,t).state:r="prev");var l=e.options.tabSize,s=M(o,t),a=f(s.text,null,l);s.stateAfter&&(s.stateAfter=null);var u,c=s.text.match(/^\s*/)[0];if(n||/\S/.test(s.text)){if("smart"==r&&((u=o.mode.indent(i,s.text.slice(c.length),s.text))==Bl||u>150)){if(!n)return;r="prev"}}else u=0,r="not";"prev"==r?u=t>o.first?f(M(o,t-1).text,null,l):0:"add"==r?u=a+e.options.indentUnit:"subtract"==r?u=a-e.options.indentUnit:"number"==typeof r&&(u=a+r),u=Math.max(0,u);var h="",d=0;if(e.options.indentWithTabs)for(var g=Math.floor(u/l);g;--g)d+=l,h+="\t";if(d<u&&(h+=p(u-d)),h!=c)return Ei(o,h,E(t,0),E(t,c.length),"+input"),s.stateAfter=null,!0;for(var v=0;v<o.sel.ranges.length;v++){var m=o.sel.ranges[v];if(m.head.line==t&&m.head.ch<c.length){var y=E(t,c.length);gi(o,v,new Ts(y,y));break}}}function _o(e){qs=e}function $o(e,t,r,n,i){var o=e.doc;e.display.shift=!1,n||(n=o.sel);var l=e.state.pasteIncoming||"paste"==i,s=es(t),a=null;if(l&&n.ranges.length>1)if(qs&&qs.text.join("\n")==t){if(n.ranges.length%qs.text.length==0){a=[];for(var u=0;u<qs.text.length;u++)a.push(o.splitLines(qs.text[u]))}}else s.length==n.ranges.length&&e.options.pasteLinesPerSelection&&(a=v(s,function(e){return[e]}));for(var c,f=n.ranges.length-1;f>=0;f--){var h=n.ranges[f],d=h.from(),p=h.to();h.empty()&&(r&&r>0?d=E(d.line,d.ch-r):e.state.overwrite&&!l?p=E(p.line,Math.min(M(o,p.line).text.length,p.ch+g(s).length)):qs&&qs.lineWise&&qs.text.join("\n")==t&&(d=p=E(d.line,0))),c=e.curOp.updateInput;var m={from:d,to:p,text:a?a[f%a.length]:s,origin:i||(l?"paste":e.state.cutIncoming?"cut":"+input")};Oi(e.doc,m),bt(e,"inputRead",e,m)}t&&!l&&Zo(e,t),jr(e),e.curOp.updateInput=c,e.curOp.typing=!0,e.state.pasteIncoming=e.state.cutIncoming=!1}function qo(e,t){var r=e.clipboardData&&e.clipboardData.getData("Text");if(r)return e.preventDefault(),t.isReadOnly()||t.options.disableInput||hn(t,function(){return $o(t,r,0,null,"paste")}),!0}function Zo(e,t){if(e.options.electricChars&&e.options.smartIndent)for(var r=e.doc.sel,n=r.ranges.length-1;n>=0;n--){var i=r.ranges[n];if(!(i.head.ch>100||n&&r.ranges[n-1].head.line==i.head.line)){var o=e.getModeAt(i.head),l=!1;if(o.electricChars){for(var s=0;s<o.electricChars.length;s++)if(t.indexOf(o.electricChars.charAt(s))>-1){l=Yo(e,i.head.line,"smart");break}}else o.electricInput&&o.electricInput.test(M(e.doc,i.head.line).text.slice(0,i.head.ch))&&(l=Yo(e,i.head.line,"smart"));l&&bt(e,"electricInput",e,i.head.line)}}}function Qo(e){for(var t=[],r=[],n=0;n<e.doc.sel.ranges.length;n++){var i=e.doc.sel.ranges[n].head.line,o={anchor:E(i,0),head:E(i+1,0)};r.push(o),t.push(e.getRange(o.anchor,o.head))}return{text:t,ranges:r}}function Jo(e,t){e.setAttribute("autocorrect","off"),e.setAttribute("autocapitalize","off"),e.setAttribute("spellcheck",!!t)}function el(){var e=n("textarea",null,null,"position: absolute; bottom: -1em; padding: 0; width: 1px; height: 1em; outline: none"),t=n("div",[e],null,"overflow: hidden; position: relative; width: 3px; height: 0px;");return ml?e.style.width="1000px":e.setAttribute("wrap","off"),Ll&&(e.style.border="1px solid black"),Jo(e),t}function tl(e,t,r,n,i){function o(){var n=t.line+r;return!(n<e.first||n>=e.first+e.size)&&(t=new E(n,t.ch,t.sticky),u=M(e,n))}function l(n){var l;if(null==(l=i?go(e.cm,u,t,r):ho(u,t,r))){if(n||!o())return!1;t=po(i,e.cm,u,t.line,r)}else t=l;return!0}var s=t,a=r,u=M(e,t.line);if("char"==n)l();else if("column"==n)l(!0);else if("word"==n||"group"==n)for(var c=null,f="group"==n,h=e.cm&&e.cm.getHelper(t,"wordChars"),d=!0;!(r<0)||l(!d);d=!1){var p=u.text.charAt(t.ch)||"\n",g=x(p,h)?"w":f&&"\n"==p?"n":!f||/\s/.test(p)?null:"p";if(!f||d||g||(g="s"),c&&c!=g){r<0&&(r=1,l(),t.sticky="after");break}if(g&&(c=g),r>0&&!l(!d))break}var v=ki(e,t,s,a,!0);return I(s,v)&&(v.hitSide=!0),v}function rl(e,t,r,n){var i,o=e.doc,l=t.left;if("page"==n){var s=Math.min(e.display.wrapper.clientHeight,window.innerHeight||document.documentElement.clientHeight),a=Math.max(s-.5*mr(e.display),3);i=(r>0?t.bottom:t.top)+r*a}else"line"==n&&(i=r>0?t.bottom+3:t.top-3);for(var u;(u=cr(e,l,i)).outside;){if(r<0?i<=0:i>=o.height){u.hitSide=!0;break}i+=5*r}return u}function nl(e,t){var r=jt(e,t.line);if(!r||r.hidden)return null;var n=M(e.doc,t.line),i=Ut(r,n,t.line),o=Se(n,e.doc.direction),l="left";o&&(l=Ce(o,t.ch)%2?"right":"left");var s=_t(i.map,t.ch,l);return s.offset="right"==s.collapse?s.end:s.start,s}function il(e){for(var t=e;t;t=t.parentNode)if(/CodeMirror-gutter-wrapper/.test(t.className))return!0;return!1}function ol(e,t){return t&&(e.bad=!0),e}function ll(e,t,r,n,i){function o(e){return function(t){return t.id==e}}function l(){c&&(u+=f,c=!1)}function s(e){e&&(l(),u+=e)}function a(t){if(1==t.nodeType){var r=t.getAttribute("cm-text");if(null!=r)return void s(r||t.textContent.replace(/\u200b/g,""));var u,h=t.getAttribute("cm-marker");if(h){var d=e.findMarks(E(n,0),E(i+1,0),o(+h));return void(d.length&&(u=d[0].find(0))&&s(N(e.doc,u.from,u.to).join(f)))}if("false"==t.getAttribute("contenteditable"))return;var p=/^(pre|div|p)$/i.test(t.nodeName);p&&l();for(var g=0;g<t.childNodes.length;g++)a(t.childNodes[g]);p&&(c=!0)}else 3==t.nodeType&&s(t.nodeValue)}for(var u="",c=!1,f=e.doc.lineSeparator();a(t),t!=r;)t=t.nextSibling;return u}function sl(e,t,r){var n;if(t==e.display.lineDiv){if(!(n=e.display.lineDiv.childNodes[r]))return ol(e.clipPos(E(e.display.viewTo-1)),!0);t=null,r=0}else for(n=t;;n=n.parentNode){if(!n||n==e.display.lineDiv)return null;if(n.parentNode&&n.parentNode==e.display.lineDiv)break}for(var i=0;i<e.display.view.length;i++){var o=e.display.view[i];if(o.node==n)return al(o,t,r)}}function al(e,t,r){function n(t,r,n){for(var i=-1;i<(f?f.length:0);i++)for(var o=i<0?c.map:f[i],l=0;l<o.length;l+=3){var s=o[l+2];if(s==t||s==r){var a=W(i<0?e.line:e.rest[i]),u=o[l]+n;return(n<0||s!=t)&&(u=o[l+(n?1:0)]),E(a,u)}}}var i=e.text.firstChild,l=!1;if(!t||!o(i,t))return ol(E(W(e.line),0),!0);if(t==i&&(l=!0,t=i.childNodes[r],r=0,!t)){var s=e.rest?g(e.rest):e.line;return ol(E(W(s),s.text.length),l)}var a=3==t.nodeType?t:null,u=t;for(a||1!=t.childNodes.length||3!=t.firstChild.nodeType||(a=t.firstChild,r&&(r=a.nodeValue.length));u.parentNode!=i;)u=u.parentNode;var c=e.measure,f=c.maps,h=n(a,u,r);if(h)return ol(h,l);for(var d=u.nextSibling,p=a?a.nodeValue.length-r:0;d;d=d.nextSibling){if(h=n(d,d.firstChild,0))return ol(E(h.line,h.ch-p),l);p+=d.textContent.length}for(var v=u.previousSibling,m=r;v;v=v.previousSibling){if(h=n(v,v.firstChild,-1))return ol(E(h.line,h.ch+m),l);m+=v.textContent.length}}var ul=navigator.userAgent,cl=navigator.platform,fl=/gecko\/\d/i.test(ul),hl=/MSIE \d/.test(ul),dl=/Trident\/(?:[7-9]|\d{2,})\..*rv:(\d+)/.exec(ul),pl=/Edge\/(\d+)/.exec(ul),gl=hl||dl||pl,vl=gl&&(hl?document.documentMode||6:+(pl||dl)[1]),ml=!pl&&/WebKit\//.test(ul),yl=ml&&/Qt\/\d+\.\d+/.test(ul),bl=!pl&&/Chrome\//.test(ul),wl=/Opera\//.test(ul),xl=/Apple Computer/.test(navigator.vendor),Cl=/Mac OS X 1\d\D([8-9]|\d\d)\D/.test(ul),Sl=/PhantomJS/.test(ul),Ll=!pl&&/AppleWebKit/.test(ul)&&/Mobile\/\w+/.test(ul),kl=/Android/.test(ul),Tl=Ll||kl||/webOS|BlackBerry|Opera Mini|Opera Mobi|IEMobile/i.test(ul),Ml=Ll||/Mac/.test(cl),Nl=/\bCrOS\b/.test(ul),Ol=/win/i.test(cl),Al=wl&&ul.match(/Version\/(\d*\.\d*)/);Al&&(Al=Number(Al[1])),Al&&Al>=15&&(wl=!1,ml=!0);var Wl,Dl=Ml&&(yl||wl&&(null==Al||Al<12.11)),Hl=fl||gl&&vl>=9,Fl=function(t,r){var n=t.className,i=e(r).exec(n);if(i){var o=n.slice(i.index+i[0].length);t.className=n.slice(0,i.index)+(o?i[1]+o:"")}};Wl=document.createRange?function(e,t,r,n){var i=document.createRange();return i.setEnd(n||e,r),i.setStart(e,t),i}:function(e,t,r){var n=document.body.createTextRange();try{n.moveToElementText(e.parentNode)}catch(e){return n}return n.collapse(!0),n.moveEnd("character",r),n.moveStart("character",t),n};var El=function(e){e.select()};Ll?El=function(e){e.selectionStart=0,e.selectionEnd=e.value.length}:gl&&(El=function(e){try{e.select()}catch(e){}});var Pl=function(){this.id=null};Pl.prototype.set=function(e,t){clearTimeout(this.id),this.id=setTimeout(t,e)};var Il,zl,Rl=30,Bl={toString:function(){return"CodeMirror.Pass"}},Gl={scroll:!1},Ul={origin:"*mouse"},Vl={origin:"+move"},Kl=[""],jl=/[\u00df\u0587\u0590-\u05f4\u0600-\u06ff\u3040-\u309f\u30a0-\u30ff\u3400-\u4db5\u4e00-\u9fcc\uac00-\ud7af]/,Xl=/[\u0300-\u036f\u0483-\u0489\u0591-\u05bd\u05bf\u05c1\u05c2\u05c4\u05c5\u05c7\u0610-\u061a\u064b-\u065e\u0670\u06d6-\u06dc\u06de-\u06e4\u06e7\u06e8\u06ea-\u06ed\u0711\u0730-\u074a\u07a6-\u07b0\u07eb-\u07f3\u0816-\u0819\u081b-\u0823\u0825-\u0827\u0829-\u082d\u0900-\u0902\u093c\u0941-\u0948\u094d\u0951-\u0955\u0962\u0963\u0981\u09bc\u09be\u09c1-\u09c4\u09cd\u09d7\u09e2\u09e3\u0a01\u0a02\u0a3c\u0a41\u0a42\u0a47\u0a48\u0a4b-\u0a4d\u0a51\u0a70\u0a71\u0a75\u0a81\u0a82\u0abc\u0ac1-\u0ac5\u0ac7\u0ac8\u0acd\u0ae2\u0ae3\u0b01\u0b3c\u0b3e\u0b3f\u0b41-\u0b44\u0b4d\u0b56\u0b57\u0b62\u0b63\u0b82\u0bbe\u0bc0\u0bcd\u0bd7\u0c3e-\u0c40\u0c46-\u0c48\u0c4a-\u0c4d\u0c55\u0c56\u0c62\u0c63\u0cbc\u0cbf\u0cc2\u0cc6\u0ccc\u0ccd\u0cd5\u0cd6\u0ce2\u0ce3\u0d3e\u0d41-\u0d44\u0d4d\u0d57\u0d62\u0d63\u0dca\u0dcf\u0dd2-\u0dd4\u0dd6\u0ddf\u0e31\u0e34-\u0e3a\u0e47-\u0e4e\u0eb1\u0eb4-\u0eb9\u0ebb\u0ebc\u0ec8-\u0ecd\u0f18\u0f19\u0f35\u0f37\u0f39\u0f71-\u0f7e\u0f80-\u0f84\u0f86\u0f87\u0f90-\u0f97\u0f99-\u0fbc\u0fc6\u102d-\u1030\u1032-\u1037\u1039\u103a\u103d\u103e\u1058\u1059\u105e-\u1060\u1071-\u1074\u1082\u1085\u1086\u108d\u109d\u135f\u1712-\u1714\u1732-\u1734\u1752\u1753\u1772\u1773\u17b7-\u17bd\u17c6\u17c9-\u17d3\u17dd\u180b-\u180d\u18a9\u1920-\u1922\u1927\u1928\u1932\u1939-\u193b\u1a17\u1a18\u1a56\u1a58-\u1a5e\u1a60\u1a62\u1a65-\u1a6c\u1a73-\u1a7c\u1a7f\u1b00-\u1b03\u1b34\u1b36-\u1b3a\u1b3c\u1b42\u1b6b-\u1b73\u1b80\u1b81\u1ba2-\u1ba5\u1ba8\u1ba9\u1c2c-\u1c33\u1c36\u1c37\u1cd0-\u1cd2\u1cd4-\u1ce0\u1ce2-\u1ce8\u1ced\u1dc0-\u1de6\u1dfd-\u1dff\u200c\u200d\u20d0-\u20f0\u2cef-\u2cf1\u2de0-\u2dff\u302a-\u302f\u3099\u309a\ua66f-\ua672\ua67c\ua67d\ua6f0\ua6f1\ua802\ua806\ua80b\ua825\ua826\ua8c4\ua8e0-\ua8f1\ua926-\ua92d\ua947-\ua951\ua980-\ua982\ua9b3\ua9b6-\ua9b9\ua9bc\uaa29-\uaa2e\uaa31\uaa32\uaa35\uaa36\uaa43\uaa4c\uaab0\uaab2-\uaab4\uaab7\uaab8\uaabe\uaabf\uaac1\uabe5\uabe8\uabed\udc00-\udfff\ufb1e\ufe00-\ufe0f\ufe20-\ufe26\uff9e\uff9f]/,Yl=!1,_l=!1,$l=null,ql=function(){function e(e){return e<=247?r.charAt(e):1424<=e&&e<=1524?"R":1536<=e&&e<=1785?n.charAt(e-1536):1774<=e&&e<=2220?"r":8192<=e&&e<=8203?"w":8204==e?"b":"L"}function t(e,t,r){this.level=e,this.from=t,this.to=r}var r="bbbbbbbbbtstwsbbbbbbbbbbbbbbssstwNN%%%NNNNNN,N,N1111111111NNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNbbbbbbsbbbbbbbbbbbbbbbbbbbbbbbbbb,N%%%%NNNNLNNNNN%%11NLNNN1LNNNNNLLLLLLLLLLLLLLLLLLLLLLLNLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLN",n="nnnnnnNNr%%r,rNNmmmmmmmmmmmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmmmmmmmmmmmmmmmnnnnnnnnnn%nnrrrmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmnNmmmmmmrrmmNmmmmrr1111111111",i=/[\u0590-\u05f4\u0600-\u06ff\u0700-\u08ac]/,o=/[stwN]/,l=/[LRr]/,s=/[Lb1n]/,a=/[1n]/;return function(r,n){var u="ltr"==n?"L":"R";if(0==r.length||"ltr"==n&&!i.test(r))return!1;for(var c=r.length,f=[],h=0;h<c;++h)f.push(e(r.charCodeAt(h)));for(var d=0,p=u;d<c;++d){var v=f[d];"m"==v?f[d]=p:p=v}for(var m=0,y=u;m<c;++m){var b=f[m];"1"==b&&"r"==y?f[m]="n":l.test(b)&&(y=b,"r"==b&&(f[m]="R"))}for(var w=1,x=f[0];w<c-1;++w){var C=f[w];"+"==C&&"1"==x&&"1"==f[w+1]?f[w]="1":","!=C||x!=f[w+1]||"1"!=x&&"n"!=x||(f[w]=x),x=C}for(var S=0;S<c;++S){var L=f[S];if(","==L)f[S]="N";else if("%"==L){var k=void 0;for(k=S+1;k<c&&"%"==f[k];++k);for(var T=S&&"!"==f[S-1]||k<c&&"1"==f[k]?"1":"N",M=S;M<k;++M)f[M]=T;S=k-1}}for(var N=0,O=u;N<c;++N){var A=f[N];"L"==O&&"1"==A?f[N]="L":l.test(A)&&(O=A)}for(var W=0;W<c;++W)if(o.test(f[W])){var D=void 0;for(D=W+1;D<c&&o.test(f[D]);++D);for(var H="L"==(W?f[W-1]:u),F=H==("L"==(D<c?f[D]:u))?H?"L":"R":u,E=W;E<D;++E)f[E]=F;W=D-1}for(var P,I=[],z=0;z<c;)if(s.test(f[z])){var R=z;for(++z;z<c&&s.test(f[z]);++z);I.push(new t(0,R,z))}else{var B=z,G=I.length;for(++z;z<c&&"L"!=f[z];++z);for(var U=B;U<z;)if(a.test(f[U])){B<U&&I.splice(G,0,new t(1,B,U));var V=U;for(++U;U<z&&a.test(f[U]);++U);I.splice(G,0,new t(2,V,U)),B=U}else++U;B<z&&I.splice(G,0,new t(1,B,z))}return 1==I[0].level&&(P=r.match(/^\s+/))&&(I[0].from=P[0].length,I.unshift(new t(0,0,P[0].length))),1==g(I).level&&(P=r.match(/\s+$/))&&(g(I).to-=P[0].length,I.push(new t(0,c-P[0].length,c))),"rtl"==n?I.reverse():I}}(),Zl=[],Ql=function(e,t,r){if(e.addEventListener)e.addEventListener(t,r,!1);else if(e.attachEvent)e.attachEvent("on"+t,r);else{var n=e._handlers||(e._handlers={});n[t]=(n[t]||Zl).concat(r)}},Jl=function(){if(gl&&vl<9)return!1;var e=n("div");return"draggable"in e||"dragDrop"in e}(),es=3!="\n\nb".split(/\n/).length?function(e){for(var t=0,r=[],n=e.length;t<=n;){var i=e.indexOf("\n",t);-1==i&&(i=e.length);var o=e.slice(t,"\r"==e.charAt(i-1)?i-1:i),l=o.indexOf("\r");-1!=l?(r.push(o.slice(0,l)),t+=l+1):(r.push(o),t=i+1)}return r}:function(e){return e.split(/\r\n?|\n/)},ts=window.getSelection?function(e){try{return e.selectionStart!=e.selectionEnd}catch(e){return!1}}:function(e){var t;try{t=e.ownerDocument.selection.createRange()}catch(e){}return!(!t||t.parentElement()!=e)&&0!=t.compareEndPoints("StartToEnd",t)},rs=function(){var e=n("div");return"oncopy"in e||(e.setAttribute("oncopy","return;"),"function"==typeof e.oncopy)}(),ns=null,is={},os={},ls={},ss=function(e,t,r){this.pos=this.start=0,this.string=e,this.tabSize=t||8,this.lastColumnPos=this.lastColumnValue=0,this.lineStart=0,this.lineOracle=r};ss.prototype.eol=function(){return this.pos>=this.string.length},ss.prototype.sol=function(){return this.pos==this.lineStart},ss.prototype.peek=function(){return this.string.charAt(this.pos)||void 0},ss.prototype.next=function(){if(this.pos<this.string.length)return this.string.charAt(this.pos++)},ss.prototype.eat=function(e){var t=this.string.charAt(this.pos);if("string"==typeof e?t==e:t&&(e.test?e.test(t):e(t)))return++this.pos,t},ss.prototype.eatWhile=function(e){for(var t=this.pos;this.eat(e););return this.pos>t},ss.prototype.eatSpace=function(){for(var e=this,t=this.pos;/[\s\u00a0]/.test(this.string.charAt(this.pos));)++e.pos;return this.pos>t},ss.prototype.skipToEnd=function(){this.pos=this.string.length},ss.prototype.skipTo=function(e){var t=this.string.indexOf(e,this.pos);if(t>-1)return this.pos=t,!0},ss.prototype.backUp=function(e){this.pos-=e},ss.prototype.column=function(){return this.lastColumnPos<this.start&&(this.lastColumnValue=f(this.string,this.start,this.tabSize,this.lastColumnPos,this.lastColumnValue),this.lastColumnPos=this.start),this.lastColumnValue-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.indentation=function(){return f(this.string,null,this.tabSize)-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.match=function(e,t,r){if("string"!=typeof e){var n=this.string.slice(this.pos).match(e);return n&&n.index>0?null:(n&&!1!==t&&(this.pos+=n[0].length),n)}var i=function(e){return r?e.toLowerCase():e};if(i(this.string.substr(this.pos,e.length))==i(e))return!1!==t&&(this.pos+=e.length),!0},ss.prototype.current=function(){return this.string.slice(this.start,this.pos)},ss.prototype.hideFirstChars=function(e,t){this.lineStart+=e;try{return t()}finally{this.lineStart-=e}},ss.prototype.lookAhead=function(e){var t=this.lineOracle;return t&&t.lookAhead(e)};var as=function(e,t){this.state=e,this.lookAhead=t},us=function(e,t,r,n){this.state=t,this.doc=e,this.line=r,this.maxLookAhead=n||0};us.prototype.lookAhead=function(e){var t=this.doc.getLine(this.line+e);return null!=t&&e>this.maxLookAhead&&(this.maxLookAhead=e),t},us.prototype.nextLine=function(){this.line++,this.maxLookAhead>0&&this.maxLookAhead--},us.fromSaved=function(e,t,r){return t instanceof as?new us(e,Ke(e.mode,t.state),r,t.lookAhead):new us(e,Ke(e.mode,t),r)},us.prototype.save=function(e){var t=!1!==e?Ke(this.doc.mode,this.state):this.state;return this.maxLookAhead>0?new as(t,this.maxLookAhead):t};var cs=function(e,t,r){this.start=e.start,this.end=e.pos,this.string=e.current(),this.type=t||null,this.state=r},fs=function(e,t,r){this.text=e,ne(this,t),this.height=r?r(this):1};fs.prototype.lineNo=function(){return W(this)},Ae(fs);var hs,ds={},ps={},gs=null,vs=null,ms={left:0,right:0,top:0,bottom:0},ys=function(e,t,r){this.cm=r;var i=this.vert=n("div",[n("div",null,null,"min-width: 1px")],"CodeMirror-vscrollbar"),o=this.horiz=n("div",[n("div",null,null,"height: 100%; min-height: 1px")],"CodeMirror-hscrollbar");e(i),e(o),Ql(i,"scroll",function(){i.clientHeight&&t(i.scrollTop,"vertical")}),Ql(o,"scroll",function(){o.clientWidth&&t(o.scrollLeft,"horizontal")}),this.checkedZeroWidth=!1,gl&&vl<8&&(this.horiz.style.minHeight=this.vert.style.minWidth="18px")};ys.prototype.update=function(e){var t=e.scrollWidth>e.clientWidth+1,r=e.scrollHeight>e.clientHeight+1,n=e.nativeBarWidth;if(r){this.vert.style.display="block",this.vert.style.bottom=t?n+"px":"0";var i=e.viewHeight-(t?n:0);this.vert.firstChild.style.height=Math.max(0,e.scrollHeight-e.clientHeight+i)+"px"}else this.vert.style.display="",this.vert.firstChild.style.height="0";if(t){this.horiz.style.display="block",this.horiz.style.right=r?n+"px":"0",this.horiz.style.left=e.barLeft+"px";var o=e.viewWidth-e.barLeft-(r?n:0);this.horiz.firstChild.style.width=Math.max(0,e.scrollWidth-e.clientWidth+o)+"px"}else this.horiz.style.display="",this.horiz.firstChild.style.width="0";return!this.checkedZeroWidth&&e.clientHeight>0&&(0==n&&this.zeroWidthHack(),this.checkedZeroWidth=!0),{right:r?n:0,bottom:t?n:0}},ys.prototype.setScrollLeft=function(e){this.horiz.scrollLeft!=e&&(this.horiz.scrollLeft=e),this.disableHoriz&&this.enableZeroWidthBar(this.horiz,this.disableHoriz,"horiz")},ys.prototype.setScrollTop=function(e){this.vert.scrollTop!=e&&(this.vert.scrollTop=e),this.disableVert&&this.enableZeroWidthBar(this.vert,this.disableVert,"vert")},ys.prototype.zeroWidthHack=function(){var e=Ml&&!Cl?"12px":"18px";this.horiz.style.height=this.vert.style.width=e,this.horiz.style.pointerEvents=this.vert.style.pointerEvents="none",this.disableHoriz=new Pl,this.disableVert=new Pl},ys.prototype.enableZeroWidthBar=function(e,t,r){function n(){var i=e.getBoundingClientRect();("vert"==r?document.elementFromPoint(i.right-1,(i.top+i.bottom)/2):document.elementFromPoint((i.right+i.left)/2,i.bottom-1))!=e?e.style.pointerEvents="none":t.set(1e3,n)}e.style.pointerEvents="auto",t.set(1e3,n)},ys.prototype.clear=function(){var e=this.horiz.parentNode;e.removeChild(this.horiz),e.removeChild(this.vert)};var bs=function(){};bs.prototype.update=function(){return{bottom:0,right:0}},bs.prototype.setScrollLeft=function(){},bs.prototype.setScrollTop=function(){},bs.prototype.clear=function(){};var ws={native:ys,null:bs},xs=0,Cs=function(e,t,r){var n=e.display;this.viewport=t,this.visible=Ir(n,e.doc,t),this.editorIsHidden=!n.wrapper.offsetWidth,this.wrapperHeight=n.wrapper.clientHeight,this.wrapperWidth=n.wrapper.clientWidth,this.oldDisplayWidth=Rt(e),this.force=r,this.dims=br(e),this.events=[]};Cs.prototype.signal=function(e,t){Oe(e,t)&&this.events.push(arguments)},Cs.prototype.finish=function(){for(var e=this,t=0;t<this.events.length;t++)Te.apply(null,e.events[t])};var Ss=0,Ls=null;gl?Ls=-.53:fl?Ls=15:bl?Ls=-.7:xl&&(Ls=-1/3);var ks=function(e,t){this.ranges=e,this.primIndex=t};ks.prototype.primary=function(){return this.ranges[this.primIndex]},ks.prototype.equals=function(e){var t=this;if(e==this)return!0;if(e.primIndex!=this.primIndex||e.ranges.length!=this.ranges.length)return!1;for(var r=0;r<this.ranges.length;r++){var n=t.ranges[r],i=e.ranges[r];if(!I(n.anchor,i.anchor)||!I(n.head,i.head))return!1}return!0},ks.prototype.deepCopy=function(){for(var e=this,t=[],r=0;r<this.ranges.length;r++)t[r]=new Ts(z(e.ranges[r].anchor),z(e.ranges[r].head));return new ks(t,this.primIndex)},ks.prototype.somethingSelected=function(){for(var e=this,t=0;t<this.ranges.length;t++)if(!e.ranges[t].empty())return!0;return!1},ks.prototype.contains=function(e,t){var r=this;t||(t=e);for(var n=0;n<this.ranges.length;n++){var i=r.ranges[n];if(P(t,i.from())>=0&&P(e,i.to())<=0)return n}return-1};var Ts=function(e,t){this.anchor=e,this.head=t};Ts.prototype.from=function(){return B(this.anchor,this.head)},Ts.prototype.to=function(){return R(this.anchor,this.head)},Ts.prototype.empty=function(){return this.head.line==this.anchor.line&&this.head.ch==this.anchor.ch},Bi.prototype={chunkSize:function(){return this.lines.length},removeInner:function(e,t){for(var r=this,n=e,i=e+t;n<i;++n){var o=r.lines[n];r.height-=o.height,ot(o),bt(o,"delete")}this.lines.splice(e,t)},collapse:function(e){e.push.apply(e,this.lines)},insertInner:function(e,t,r){var n=this;this.height+=r,this.lines=this.lines.slice(0,e).concat(t).concat(this.lines.slice(e));for(var i=0;i<t.length;++i)t[i].parent=n},iterN:function(e,t,r){for(var n=this,i=e+t;e<i;++e)if(r(n.lines[e]))return!0}},Gi.prototype={chunkSize:function(){return this.size},removeInner:function(e,t){var r=this;this.size-=t;for(var n=0;n<this.children.length;++n){var i=r.children[n],o=i.chunkSize();if(e<o){var l=Math.min(t,o-e),s=i.height;if(i.removeInner(e,l),r.height-=s-i.height,o==l&&(r.children.splice(n--,1),i.parent=null),0==(t-=l))break;e=0}else e-=o}if(this.size-t<25&&(this.children.length>1||!(this.children[0]instanceof Bi))){var a=[];this.collapse(a),this.children=[new Bi(a)],this.children[0].parent=this}},collapse:function(e){for(var t=this,r=0;r<this.children.length;++r)t.children[r].collapse(e)},insertInner:function(e,t,r){var n=this;this.size+=t.length,this.height+=r;for(var i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<=l){if(o.insertInner(e,t,r),o.lines&&o.lines.length>50){for(var s=o.lines.length%25+25,a=s;a<o.lines.length;){var u=new Bi(o.lines.slice(a,a+=25));o.height-=u.height,n.children.splice(++i,0,u),u.parent=n}o.lines=o.lines.slice(0,s),n.maybeSpill()}break}e-=l}},maybeSpill:function(){if(!(this.children.length<=10)){var e=this;do{var t=new Gi(e.children.splice(e.children.length-5,5));if(e.parent){e.size-=t.size,e.height-=t.height;var r=h(e.parent.children,e);e.parent.children.splice(r+1,0,t)}else{var n=new Gi(e.children);n.parent=e,e.children=[n,t],e=n}t.parent=e.parent}while(e.children.length>10);e.parent.maybeSpill()}},iterN:function(e,t,r){for(var n=this,i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<l){var s=Math.min(t,l-e);if(o.iterN(e,s,r))return!0;if(0==(t-=s))break;e=0}else e-=l}}};var Ms=function(e,t,r){var n=this;if(r)for(var i in r)r.hasOwnProperty(i)&&(n[i]=r[i]);this.doc=e,this.node=t};Ms.prototype.clear=function(){var e=this,t=this.doc.cm,r=this.line.widgets,n=this.line,i=W(n);if(null!=i&&r){for(var o=0;o<r.length;++o)r[o]==e&&r.splice(o--,1);r.length||(n.widgets=null);var l=Ht(this);A(n,Math.max(0,n.height-l)),t&&(hn(t,function(){Ui(t,n,-l),mn(t,i,"widget")}),bt(t,"lineWidgetCleared",t,this,i))}},Ms.prototype.changed=function(){var e=this,t=this.height,r=this.doc.cm,n=this.line;this.height=null;var i=Ht(this)-t;i&&(A(n,n.height+i),r&&hn(r,function(){r.curOp.forceUpdate=!0,Ui(r,n,i),bt(r,"lineWidgetChanged",r,e,W(n))}))},Ae(Ms);var Ns=0,Os=function(e,t){this.lines=[],this.type=t,this.doc=e,this.id=++Ns};Os.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){var t=this.doc.cm,r=t&&!t.curOp;if(r&&nn(t),Oe(this,"clear")){var n=this.find();n&&bt(this,"clear",n.from,n.to)}for(var i=null,o=null,l=0;l<this.lines.length;++l){var s=e.lines[l],a=_(s.markedSpans,e);t&&!e.collapsed?mn(t,W(s),"text"):t&&(null!=a.to&&(o=W(s)),null!=a.from&&(i=W(s))),s.markedSpans=$(s.markedSpans,a),null==a.from&&e.collapsed&&!ve(e.doc,s)&&t&&A(s,mr(t.display))}if(t&&this.collapsed&&!t.options.lineWrapping)for(var u=0;u<this.lines.length;++u){var c=fe(e.lines[u]),f=be(c);f>t.display.maxLineLength&&(t.display.maxLine=c,t.display.maxLineLength=f,t.display.maxLineChanged=!0)}null!=i&&t&&this.collapsed&&vn(t,i,o+1),this.lines.length=0,this.explicitlyCleared=!0,this.atomic&&this.doc.cantEdit&&(this.doc.cantEdit=!1,t&&Ci(t.doc)),t&&bt(t,"markerCleared",t,this,i,o),r&&on(t),this.parent&&this.parent.clear()}},Os.prototype.find=function(e,t){var r=this;null==e&&"bookmark"==this.type&&(e=1);for(var n,i,o=0;o<this.lines.length;++o){var l=r.lines[o],s=_(l.markedSpans,r);if(null!=s.from&&(n=E(t?l:W(l),s.from),-1==e))return n;if(null!=s.to&&(i=E(t?l:W(l),s.to),1==e))return i}return n&&{from:n,to:i}},Os.prototype.changed=function(){var e=this,t=this.find(-1,!0),r=this,n=this.doc.cm;t&&n&&hn(n,function(){var i=t.line,o=W(t.line),l=jt(n,o);if(l&&(Qt(l),n.curOp.selectionChanged=n.curOp.forceUpdate=!0),n.curOp.updateMaxLine=!0,!ve(r.doc,i)&&null!=r.height){var s=r.height;r.height=null;var a=Ht(r)-s;a&&A(i,i.height+a)}bt(n,"markerChanged",n,e)})},Os.prototype.attachLine=function(e){if(!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;t.maybeHiddenMarkers&&-1!=h(t.maybeHiddenMarkers,this)||(t.maybeUnhiddenMarkers||(t.maybeUnhiddenMarkers=[])).push(this)}this.lines.push(e)},Os.prototype.detachLine=function(e){if(this.lines.splice(h(this.lines,e),1),!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;(t.maybeHiddenMarkers||(t.maybeHiddenMarkers=[])).push(this)}},Ae(Os);var As=function(e,t){var r=this;this.markers=e,this.primary=t;for(var n=0;n<e.length;++n)e[n].parent=r};As.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){this.explicitlyCleared=!0;for(var t=0;t<this.markers.length;++t)e.markers[t].clear();bt(this,"clear")}},As.prototype.find=function(e,t){return this.primary.find(e,t)},Ae(As);var Ws=0,Ds=function(e,t,r,n,i){if(!(this instanceof Ds))return new Ds(e,t,r,n,i);null==r&&(r=0),Gi.call(this,[new Bi([new fs("",null)])]),this.first=r,this.scrollTop=this.scrollLeft=0,this.cantEdit=!1,this.cleanGeneration=1,this.modeFrontier=this.highlightFrontier=r;var o=E(r,0);this.sel=Rn(o),this.history=new Jn(null),this.id=++Ws,this.modeOption=t,this.lineSep=n,this.direction="rtl"==i?"rtl":"ltr",this.extend=!1,"string"==typeof e&&(e=this.splitLines(e)),_n(this,{from:o,to:o,text:e}),bi(this,Rn(o),Gl)};Ds.prototype=b(Gi.prototype,{constructor:Ds,iter:function(e,t,r){r?this.iterN(e-this.first,t-e,r):this.iterN(this.first,this.first+this.size,e)},insert:function(e,t){for(var r=0,n=0;n<t.length;++n)r+=t[n].height;this.insertInner(e-this.first,t,r)},remove:function(e,t){this.removeInner(e-this.first,t)},getValue:function(e){var t=O(this,this.first,this.first+this.size);return!1===e?t:t.join(e||this.lineSeparator())},setValue:gn(function(e){var t=E(this.first,0),r=this.first+this.size-1;Oi(this,{from:t,to:E(r,M(this,r).text.length),text:this.splitLines(e),origin:"setValue",full:!0},!0),this.cm&&Xr(this.cm,0,0),bi(this,Rn(t),Gl)}),replaceRange:function(e,t,r,n){Ei(this,e,t=U(this,t),r=r?U(this,r):t,n)},getRange:function(e,t,r){var n=N(this,U(this,e),U(this,t));return!1===r?n:n.join(r||this.lineSeparator())},getLine:function(e){var t=this.getLineHandle(e);return t&&t.text},getLineHandle:function(e){if(H(this,e))return M(this,e)},getLineNumber:function(e){return W(e)},getLineHandleVisualStart:function(e){return"number"==typeof e&&(e=M(this,e)),fe(e)},lineCount:function(){return this.size},firstLine:function(){return this.first},lastLine:function(){return this.first+this.size-1},clipPos:function(e){return U(this,e)},getCursor:function(e){var t=this.sel.primary();return null==e||"head"==e?t.head:"anchor"==e?t.anchor:"end"==e||"to"==e||!1===e?t.to():t.from()},listSelections:function(){return this.sel.ranges},somethingSelected:function(){return this.sel.somethingSelected()},setCursor:gn(function(e,t,r){vi(this,U(this,"number"==typeof e?E(e,t||0):e),null,r)}),setSelection:gn(function(e,t,r){vi(this,U(this,e),U(this,t||e),r)}),extendSelection:gn(function(e,t,r){di(this,U(this,e),t&&U(this,t),r)}),extendSelections:gn(function(e,t){pi(this,K(this,e),t)}),extendSelectionsBy:gn(function(e,t){pi(this,K(this,v(this.sel.ranges,e)),t)}),setSelections:gn(function(e,t,r){var n=this;if(e.length){for(var i=[],o=0;o<e.length;o++)i[o]=new Ts(U(n,e[o].anchor),U(n,e[o].head));null==t&&(t=Math.min(e.length-1,this.sel.primIndex)),bi(this,zn(i,t),r)}}),addSelection:gn(function(e,t,r){var n=this.sel.ranges.slice(0);n.push(new Ts(U(this,e),U(this,t||e))),bi(this,zn(n,n.length-1),r)}),getSelection:function(e){for(var t,r=this,n=this.sel.ranges,i=0;i<n.length;i++){var o=N(r,n[i].from(),n[i].to());t=t?t.concat(o):o}return!1===e?t:t.join(e||this.lineSeparator())},getSelections:function(e){for(var t=this,r=[],n=this.sel.ranges,i=0;i<n.length;i++){var o=N(t,n[i].from(),n[i].to());!1!==e&&(o=o.join(e||t.lineSeparator())),r[i]=o}return r},replaceSelection:function(e,t,r){for(var n=[],i=0;i<this.sel.ranges.length;i++)n[i]=e;this.replaceSelections(n,t,r||"+input")},replaceSelections:gn(function(e,t,r){for(var n=this,i=[],o=this.sel,l=0;l<o.ranges.length;l++){var s=o.ranges[l];i[l]={from:s.from(),to:s.to(),text:n.splitLines(e[l]),origin:r}}for(var a=t&&"end"!=t&&Kn(this,i,t),u=i.length-1;u>=0;u--)Oi(n,i[u]);a?yi(this,a):this.cm&&jr(this.cm)}),undo:gn(function(){Wi(this,"undo")}),redo:gn(function(){Wi(this,"redo")}),undoSelection:gn(function(){Wi(this,"undo",!0)}),redoSelection:gn(function(){Wi(this,"redo",!0)}),setExtending:function(e){this.extend=e},getExtending:function(){return this.extend},historySize:function(){for(var e=this.history,t=0,r=0,n=0;n<e.done.length;n++)e.done[n].ranges||++t;for(var i=0;i<e.undone.length;i++)e.undone[i].ranges||++r;return{undo:t,redo:r}},clearHistory:function(){this.history=new Jn(this.history.maxGeneration)},markClean:function(){this.cleanGeneration=this.changeGeneration(!0)},changeGeneration:function(e){return e&&(this.history.lastOp=this.history.lastSelOp=this.history.lastOrigin=null),this.history.generation},isClean:function(e){return this.history.generation==(e||this.cleanGeneration)},getHistory:function(){return{done:fi(this.history.done),undone:fi(this.history.undone)}},setHistory:function(e){var t=this.history=new Jn(this.history.maxGeneration);t.done=fi(e.done.slice(0),null,!0),t.undone=fi(e.undone.slice(0),null,!0)},setGutterMarker:gn(function(e,t,r){return Ri(this,e,"gutter",function(e){var n=e.gutterMarkers||(e.gutterMarkers={});return n[t]=r,!r&&C(n)&&(e.gutterMarkers=null),!0})}),clearGutter:gn(function(e){var t=this;this.iter(function(r){r.gutterMarkers&&r.gutterMarkers[e]&&Ri(t,r,"gutter",function(){return r.gutterMarkers[e]=null,C(r.gutterMarkers)&&(r.gutterMarkers=null),!0})})}),lineInfo:function(e){var t;if("number"==typeof e){if(!H(this,e))return null;if(t=e,!(e=M(this,e)))return null}else if(null==(t=W(e)))return null;return{line:t,handle:e,text:e.text,gutterMarkers:e.gutterMarkers,textClass:e.textClass,bgClass:e.bgClass,wrapClass:e.wrapClass,widgets:e.widgets}},addLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass";if(t[i]){if(e(n).test(t[i]))return!1;t[i]+=" "+n}else t[i]=n;return!0})}),removeLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass",o=t[i];if(!o)return!1;if(null==n)t[i]=null;else{var l=o.match(e(n));if(!l)return!1;var s=l.index+l[0].length;t[i]=o.slice(0,l.index)+(l.index&&s!=o.length?" ":"")+o.slice(s)||null}return!0})}),addLineWidget:gn(function(e,t,r){return Vi(this,e,t,r)}),removeLineWidget:function(e){e.clear()},markText:function(e,t,r){return Ki(this,U(this,e),U(this,t),r,r&&r.type||"range")},setBookmark:function(e,t){var r={replacedWith:t&&(null==t.nodeType?t.widget:t),insertLeft:t&&t.insertLeft,clearWhenEmpty:!1,shared:t&&t.shared,handleMouseEvents:t&&t.handleMouseEvents};return e=U(this,e),Ki(this,e,e,r,"bookmark")},findMarksAt:function(e){var t=[],r=M(this,(e=U(this,e)).line).markedSpans;if(r)for(var n=0;n<r.length;++n){var i=r[n];(null==i.from||i.from<=e.ch)&&(null==i.to||i.to>=e.ch)&&t.push(i.marker.parent||i.marker)}return t},findMarks:function(e,t,r){e=U(this,e),t=U(this,t);var n=[],i=e.line;return this.iter(e.line,t.line+1,function(o){var l=o.markedSpans;if(l)for(var s=0;s<l.length;s++){var a=l[s];null!=a.to&&i==e.line&&e.ch>=a.to||null==a.from&&i!=e.line||null!=a.from&&i==t.line&&a.from>=t.ch||r&&!r(a.marker)||n.push(a.marker.parent||a.marker)}++i}),n},getAllMarks:function(){var e=[];return this.iter(function(t){var r=t.markedSpans;if(r)for(var n=0;n<r.length;++n)null!=r[n].from&&e.push(r[n].marker)}),e},posFromIndex:function(e){var t,r=this.first,n=this.lineSeparator().length;return this.iter(function(i){var o=i.text.length+n;if(o>e)return t=e,!0;e-=o,++r}),U(this,E(r,t))},indexFromPos:function(e){var t=(e=U(this,e)).ch;if(e.line<this.first||e.ch<0)return 0;var r=this.lineSeparator().length;return this.iter(this.first,e.line,function(e){t+=e.text.length+r}),t},copy:function(e){var t=new Ds(O(this,this.first,this.first+this.size),this.modeOption,this.first,this.lineSep,this.direction);return t.scrollTop=this.scrollTop,t.scrollLeft=this.scrollLeft,t.sel=this.sel,t.extend=!1,e&&(t.history.undoDepth=this.history.undoDepth,t.setHistory(this.getHistory())),t},linkedDoc:function(e){e||(e={});var t=this.first,r=this.first+this.size;null!=e.from&&e.from>t&&(t=e.from),null!=e.to&&e.to<r&&(r=e.to);var n=new Ds(O(this,t,r),e.mode||this.modeOption,t,this.lineSep,this.direction);return e.sharedHist&&(n.history=this.history),(this.linked||(this.linked=[])).push({doc:n,sharedHist:e.sharedHist}),n.linked=[{doc:this,isParent:!0,sharedHist:e.sharedHist}],Yi(n,Xi(this)),n},unlinkDoc:function(e){var t=this;if(e instanceof jo&&(e=e.doc),this.linked)for(var r=0;r<this.linked.length;++r)if(t.linked[r].doc==e){t.linked.splice(r,1),e.unlinkDoc(t),_i(Xi(t));break}if(e.history==this.history){var n=[e.id];$n(e,function(e){return n.push(e.id)},!0),e.history=new Jn(null),e.history.done=fi(this.history.done,n),e.history.undone=fi(this.history.undone,n)}},iterLinkedDocs:function(e){$n(this,e)},getMode:function(){return this.mode},getEditor:function(){return this.cm},splitLines:function(e){return this.lineSep?e.split(this.lineSep):es(e)},lineSeparator:function(){return this.lineSep||"\n"},setDirection:gn(function(e){"rtl"!=e&&(e="ltr"),e!=this.direction&&(this.direction=e,this.iter(function(e){return e.order=null}),this.cm&&Qn(this.cm))})}),Ds.prototype.eachLine=Ds.prototype.iter;for(var Hs=0,Fs=!1,Es={3:"Enter",8:"Backspace",9:"Tab",13:"Enter",16:"Shift",17:"Ctrl",18:"Alt",19:"Pause",20:"CapsLock",27:"Esc",32:"Space",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"Left",38:"Up",39:"Right",40:"Down",44:"PrintScrn",45:"Insert",46:"Delete",59:";",61:"=",91:"Mod",92:"Mod",93:"Mod",106:"*",107:"=",109:"-",110:".",111:"/",127:"Delete",173:"-",186:";",187:"=",188:",",189:"-",190:".",191:"/",192:"`",219:"[",220:"\\",221:"]",222:"'",63232:"Up",63233:"Down",63234:"Left",63235:"Right",63272:"Delete",63273:"Home",63275:"End",63276:"PageUp",63277:"PageDown",63302:"Insert"},Ps=0;Ps<10;Ps++)Es[Ps+48]=Es[Ps+96]=String(Ps);for(var Is=65;Is<=90;Is++)Es[Is]=String.fromCharCode(Is);for(var zs=1;zs<=12;zs++)Es[zs+111]=Es[zs+63235]="F"+zs;var Rs={};Rs.basic={Left:"goCharLeft",Right:"goCharRight",Up:"goLineUp",Down:"goLineDown",End:"goLineEnd",Home:"goLineStartSmart",PageUp:"goPageUp",PageDown:"goPageDown",Delete:"delCharAfter",Backspace:"delCharBefore","Shift-Backspace":"delCharBefore",Tab:"defaultTab","Shift-Tab":"indentAuto",Enter:"newlineAndIndent",Insert:"toggleOverwrite",Esc:"singleSelection"},Rs.pcDefault={"Ctrl-A":"selectAll","Ctrl-D":"deleteLine","Ctrl-Z":"undo","Shift-Ctrl-Z":"redo","Ctrl-Y":"redo","Ctrl-Home":"goDocStart","Ctrl-End":"goDocEnd","Ctrl-Up":"goLineUp","Ctrl-Down":"goLineDown","Ctrl-Left":"goGroupLeft","Ctrl-Right":"goGroupRight","Alt-Left":"goLineStart","Alt-Right":"goLineEnd","Ctrl-Backspace":"delGroupBefore","Ctrl-Delete":"delGroupAfter","Ctrl-S":"save","Ctrl-F":"find","Ctrl-G":"findNext","Shift-Ctrl-G":"findPrev","Shift-Ctrl-F":"replace","Shift-Ctrl-R":"replaceAll","Ctrl-[":"indentLess","Ctrl-]":"indentMore","Ctrl-U":"undoSelection","Shift-Ctrl-U":"redoSelection","Alt-U":"redoSelection",fallthrough:"basic"},Rs.emacsy={"Ctrl-F":"goCharRight","Ctrl-B":"goCharLeft","Ctrl-P":"goLineUp","Ctrl-N":"goLineDown","Alt-F":"goWordRight","Alt-B":"goWordLeft","Ctrl-A":"goLineStart","Ctrl-E":"goLineEnd","Ctrl-V":"goPageDown","Shift-Ctrl-V":"goPageUp","Ctrl-D":"delCharAfter","Ctrl-H":"delCharBefore","Alt-D":"delWordAfter","Alt-Backspace":"delWordBefore","Ctrl-K":"killLine","Ctrl-T":"transposeChars","Ctrl-O":"openLine"},Rs.macDefault={"Cmd-A":"selectAll","Cmd-D":"deleteLine","Cmd-Z":"undo","Shift-Cmd-Z":"redo","Cmd-Y":"redo","Cmd-Home":"goDocStart","Cmd-Up":"goDocStart","Cmd-End":"goDocEnd","Cmd-Down":"goDocEnd","Alt-Left":"goGroupLeft","Alt-Right":"goGroupRight","Cmd-Left":"goLineLeft","Cmd-Right":"goLineRight","Alt-Backspace":"delGroupBefore","Ctrl-Alt-Backspace":"delGroupAfter","Alt-Delete":"delGroupAfter","Cmd-S":"save","Cmd-F":"find","Cmd-G":"findNext","Shift-Cmd-G":"findPrev","Cmd-Alt-F":"replace","Shift-Cmd-Alt-F":"replaceAll","Cmd-[":"indentLess","Cmd-]":"indentMore","Cmd-Backspace":"delWrappedLineLeft","Cmd-Delete":"delWrappedLineRight","Cmd-U":"undoSelection","Shift-Cmd-U":"redoSelection","Ctrl-Up":"goDocStart","Ctrl-Down":"goDocEnd",fallthrough:["basic","emacsy"]},Rs.default=Ml?Rs.macDefault:Rs.pcDefault;var Bs={selectAll:Mi,singleSelection:function(e){return e.setSelection(e.getCursor("anchor"),e.getCursor("head"),Gl)},killLine:function(e){return co(e,function(t){if(t.empty()){var r=M(e.doc,t.head.line).text.length;return t.head.ch==r&&t.head.line<e.lastLine()?{from:t.head,to:E(t.head.line+1,0)}:{from:t.head,to:E(t.head.line,r)}}return{from:t.from(),to:t.to()}})},deleteLine:function(e){return co(e,function(t){return{from:E(t.from().line,0),to:U(e.doc,E(t.to().line+1,0))}})},delLineLeft:function(e){return co(e,function(e){return{from:E(e.from().line,0),to:e.from()}})},delWrappedLineLeft:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5;return{from:e.coordsChar({left:0,top:r},"div"),to:t.from()}})},delWrappedLineRight:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5,n=e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div");return{from:t.from(),to:n}})},undo:function(e){return e.undo()},redo:function(e){return e.redo()},undoSelection:function(e){return e.undoSelection()},redoSelection:function(e){return e.redoSelection()},goDocStart:function(e){return e.extendSelection(E(e.firstLine(),0))},goDocEnd:function(e){return e.extendSelection(E(e.lastLine()))},goLineStart:function(e){return e.extendSelectionsBy(function(t){return vo(e,t.head.line)},{origin:"+move",bias:1})},goLineStartSmart:function(e){return e.extendSelectionsBy(function(t){return yo(e,t.head)},{origin:"+move",bias:1})},goLineEnd:function(e){return e.extendSelectionsBy(function(t){return mo(e,t.head.line)},{origin:"+move",bias:-1})},goLineRight:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div")},Vl)},goLineLeft:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:0,top:r},"div")},Vl)},goLineLeftSmart:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5,n=e.coordsChar({left:0,top:r},"div");return n.ch<e.getLine(n.line).search(/\S/)?yo(e,t.head):n},Vl)},goLineUp:function(e){return e.moveV(-1,"line")},goLineDown:function(e){return e.moveV(1,"line")},goPageUp:function(e){return e.moveV(-1,"page")},goPageDown:function(e){return e.moveV(1,"page")},goCharLeft:function(e){return e.moveH(-1,"char")},goCharRight:function(e){return e.moveH(1,"char")},goColumnLeft:function(e){return e.moveH(-1,"column")},goColumnRight:function(e){return e.moveH(1,"column")},goWordLeft:function(e){return e.moveH(-1,"word")},goGroupRight:function(e){return e.moveH(1,"group")},goGroupLeft:function(e){return e.moveH(-1,"group")},goWordRight:function(e){return e.moveH(1,"word")},delCharBefore:function(e){return e.deleteH(-1,"char")},delCharAfter:function(e){return e.deleteH(1,"char")},delWordBefore:function(e){return e.deleteH(-1,"word")},delWordAfter:function(e){return e.deleteH(1,"word")},delGroupBefore:function(e){return e.deleteH(-1,"group")},delGroupAfter:function(e){return e.deleteH(1,"group")},indentAuto:function(e){return e.indentSelection("smart")},indentMore:function(e){return e.indentSelection("add")},indentLess:function(e){return e.indentSelection("subtract")},insertTab:function(e){return e.replaceSelection("\t")},insertSoftTab:function(e){for(var t=[],r=e.listSelections(),n=e.options.tabSize,i=0;i<r.length;i++){var o=r[i].from(),l=f(e.getLine(o.line),o.ch,n);t.push(p(n-l%n))}e.replaceSelections(t)},defaultTab:function(e){e.somethingSelected()?e.indentSelection("add"):e.execCommand("insertTab")},transposeChars:function(e){return hn(e,function(){for(var t=e.listSelections(),r=[],n=0;n<t.length;n++)if(t[n].empty()){var i=t[n].head,o=M(e.doc,i.line).text;if(o)if(i.ch==o.length&&(i=new E(i.line,i.ch-1)),i.ch>0)i=new E(i.line,i.ch+1),e.replaceRange(o.charAt(i.ch-1)+o.charAt(i.ch-2),E(i.line,i.ch-2),i,"+transpose");else if(i.line>e.doc.first){var l=M(e.doc,i.line-1).text;l&&(i=new E(i.line,1),e.replaceRange(o.charAt(0)+e.doc.lineSeparator()+l.charAt(l.length-1),E(i.line-1,l.length-1),i,"+transpose"))}r.push(new Ts(i,i))}e.setSelections(r)})},newlineAndIndent:function(e){return hn(e,function(){for(var t=e.listSelections(),r=t.length-1;r>=0;r--)e.replaceRange(e.doc.lineSeparator(),t[r].anchor,t[r].head,"+input");t=e.listSelections();for(var n=0;n<t.length;n++)e.indentLine(t[n].from().line,null,!0);jr(e)})},openLine:function(e){return e.replaceSelection("\n","start")},toggleOverwrite:function(e){return e.toggleOverwrite()}},Gs=new Pl,Us=null,Vs=function(e,t,r){this.time=e,this.pos=t,this.button=r};Vs.prototype.compare=function(e,t,r){return this.time+400>e&&0==P(t,this.pos)&&r==this.button};var Ks,js,Xs={toString:function(){return"CodeMirror.Init"}},Ys={},_s={};jo.defaults=Ys,jo.optionHandlers=_s;var $s=[];jo.defineInitHook=function(e){return $s.push(e)};var qs=null,Zs=function(e){this.cm=e,this.lastAnchorNode=this.lastAnchorOffset=this.lastFocusNode=this.lastFocusOffset=null,this.polling=new Pl,this.composing=null,this.gracePeriod=!1,this.readDOMTimeout=null};Zs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()}),"cut"==e.type&&i.replaceSelection("",null,"cut");else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type&&i.operation(function(){i.setSelections(t.ranges,0,Gl),i.replaceSelection("",null,"cut")})}if(e.clipboardData){e.clipboardData.clearData();var r=qs.text.join("\n");if(e.clipboardData.setData("Text",r),e.clipboardData.getData("Text")==r)return void e.preventDefault()}var l=el(),s=l.firstChild;i.display.lineSpace.insertBefore(l,i.display.lineSpace.firstChild),s.value=qs.text.join("\n");var a=document.activeElement;El(s),setTimeout(function(){i.display.lineSpace.removeChild(l),a.focus(),a==o&&n.showPrimarySelection()},50)}}var r=this,n=this,i=n.cm,o=n.div=e.lineDiv;Jo(o,i.options.spellcheck),Ql(o,"paste",function(e){Me(i,e)||qo(e,i)||vl<=11&&setTimeout(dn(i,function(){return r.updateFromDOM()}),20)}),Ql(o,"compositionstart",function(e){r.composing={data:e.data,done:!1}}),Ql(o,"compositionupdate",function(e){r.composing||(r.composing={data:e.data,done:!1})}),Ql(o,"compositionend",function(e){r.composing&&(e.data!=r.composing.data&&r.readFromDOMSoon(),r.composing.done=!0)}),Ql(o,"touchstart",function(){return n.forceCompositionEnd()}),Ql(o,"input",function(){r.composing||r.readFromDOMSoon()}),Ql(o,"copy",t),Ql(o,"cut",t)},Zs.prototype.prepareSelection=function(){var e=Tr(this.cm,!1);return e.focus=this.cm.state.focused,e},Zs.prototype.showSelection=function(e,t){e&&this.cm.display.view.length&&((e.focus||t)&&this.showPrimarySelection(),this.showMultipleSelections(e))},Zs.prototype.showPrimarySelection=function(){var e=window.getSelection(),t=this.cm,r=t.doc.sel.primary(),n=r.from(),i=r.to();if(t.display.viewTo==t.display.viewFrom||n.line>=t.display.viewTo||i.line<t.display.viewFrom)e.removeAllRanges();else{var o=sl(t,e.anchorNode,e.anchorOffset),l=sl(t,e.focusNode,e.focusOffset);if(!o||o.bad||!l||l.bad||0!=P(B(o,l),n)||0!=P(R(o,l),i)){var s=t.display.view,a=n.line>=t.display.viewFrom&&nl(t,n)||{node:s[0].measure.map[2],offset:0},u=i.line<t.display.viewTo&&nl(t,i);if(!u){var c=s[s.length-1].measure,f=c.maps?c.maps[c.maps.length-1]:c.map;u={node:f[f.length-1],offset:f[f.length-2]-f[f.length-3]}}if(a&&u){var h,d=e.rangeCount&&e.getRangeAt(0);try{h=Wl(a.node,a.offset,u.offset,u.node)}catch(e){}h&&(!fl&&t.state.focused?(e.collapse(a.node,a.offset),h.collapsed||(e.removeAllRanges(),e.addRange(h))):(e.removeAllRanges(),e.addRange(h)),d&&null==e.anchorNode?e.addRange(d):fl&&this.startGracePeriod()),this.rememberSelection()}else e.removeAllRanges()}}},Zs.prototype.startGracePeriod=function(){var e=this;clearTimeout(this.gracePeriod),this.gracePeriod=setTimeout(function(){e.gracePeriod=!1,e.selectionChanged()&&e.cm.operation(function(){return e.cm.curOp.selectionChanged=!0})},20)},Zs.prototype.showMultipleSelections=function(e){r(this.cm.display.cursorDiv,e.cursors),r(this.cm.display.selectionDiv,e.selection)},Zs.prototype.rememberSelection=function(){var e=window.getSelection();this.lastAnchorNode=e.anchorNode,this.lastAnchorOffset=e.anchorOffset,this.lastFocusNode=e.focusNode,this.lastFocusOffset=e.focusOffset},Zs.prototype.selectionInEditor=function(){var e=window.getSelection();if(!e.rangeCount)return!1;var t=e.getRangeAt(0).commonAncestorContainer;return o(this.div,t)},Zs.prototype.focus=function(){"nocursor"!=this.cm.options.readOnly&&(this.selectionInEditor()||this.showSelection(this.prepareSelection(),!0),this.div.focus())},Zs.prototype.blur=function(){this.div.blur()},Zs.prototype.getField=function(){return this.div},Zs.prototype.supportsTouch=function(){return!0},Zs.prototype.receivedFocus=function(){function e(){t.cm.state.focused&&(t.pollSelection(),t.polling.set(t.cm.options.pollInterval,e))}var t=this;this.selectionInEditor()?this.pollSelection():hn(this.cm,function(){return t.cm.curOp.selectionChanged=!0}),this.polling.set(this.cm.options.pollInterval,e)},Zs.prototype.selectionChanged=function(){var e=window.getSelection();return e.anchorNode!=this.lastAnchorNode||e.anchorOffset!=this.lastAnchorOffset||e.focusNode!=this.lastFocusNode||e.focusOffset!=this.lastFocusOffset},Zs.prototype.pollSelection=function(){if(null==this.readDOMTimeout&&!this.gracePeriod&&this.selectionChanged()){var e=window.getSelection(),t=this.cm;if(kl&&bl&&this.cm.options.gutters.length&&il(e.anchorNode))return this.cm.triggerOnKeyDown({type:"keydown",keyCode:8,preventDefault:Math.abs}),this.blur(),void this.focus();if(!this.composing){this.rememberSelection();var r=sl(t,e.anchorNode,e.anchorOffset),n=sl(t,e.focusNode,e.focusOffset);r&&n&&hn(t,function(){bi(t.doc,Rn(r,n),Gl),(r.bad||n.bad)&&(t.curOp.selectionChanged=!0)})}}},Zs.prototype.pollContent=function(){null!=this.readDOMTimeout&&(clearTimeout(this.readDOMTimeout),this.readDOMTimeout=null);var e=this.cm,t=e.display,r=e.doc.sel.primary(),n=r.from(),i=r.to();if(0==n.ch&&n.line>e.firstLine()&&(n=E(n.line-1,M(e.doc,n.line-1).length)),i.ch==M(e.doc,i.line).text.length&&i.line<e.lastLine()&&(i=E(i.line+1,0)),n.line<t.viewFrom||i.line>t.viewTo-1)return!1;var o,l,s;n.line==t.viewFrom||0==(o=Lr(e,n.line))?(l=W(t.view[0].line),s=t.view[0].node):(l=W(t.view[o].line),s=t.view[o-1].node.nextSibling);var a,u,c=Lr(e,i.line);if(c==t.view.length-1?(a=t.viewTo-1,u=t.lineDiv.lastChild):(a=W(t.view[c+1].line)-1,u=t.view[c+1].node.previousSibling),!s)return!1;for(var f=e.doc.splitLines(ll(e,s,u,l,a)),h=N(e.doc,E(l,0),E(a,M(e.doc,a).text.length));f.length>1&&h.length>1;)if(g(f)==g(h))f.pop(),h.pop(),a--;else{if(f[0]!=h[0])break;f.shift(),h.shift(),l++}for(var d=0,p=0,v=f[0],m=h[0],y=Math.min(v.length,m.length);d<y&&v.charCodeAt(d)==m.charCodeAt(d);)++d;for(var b=g(f),w=g(h),x=Math.min(b.length-(1==f.length?d:0),w.length-(1==h.length?d:0));p<x&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)++p;if(1==f.length&&1==h.length&&l==n.line)for(;d&&d>n.ch&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)d--,p++;f[f.length-1]=b.slice(0,b.length-p).replace(/^\u200b+/,""),f[0]=f[0].slice(d).replace(/\u200b+$/,"");var C=E(l,d),S=E(a,h.length?g(h).length-p:0);return f.length>1||f[0]||P(C,S)?(Ei(e.doc,f,C,S,"+input"),!0):void 0},Zs.prototype.ensurePolled=function(){this.forceCompositionEnd()},Zs.prototype.reset=function(){this.forceCompositionEnd()},Zs.prototype.forceCompositionEnd=function(){this.composing&&(clearTimeout(this.readDOMTimeout),this.composing=null,this.updateFromDOM(),this.div.blur(),this.div.focus())},Zs.prototype.readFromDOMSoon=function(){var e=this;null==this.readDOMTimeout&&(this.readDOMTimeout=setTimeout(function(){if(e.readDOMTimeout=null,e.composing){if(!e.composing.done)return;e.composing=null}e.updateFromDOM()},80))},Zs.prototype.updateFromDOM=function(){var e=this;!this.cm.isReadOnly()&&this.pollContent()||hn(this.cm,function(){return vn(e.cm)})},Zs.prototype.setUneditable=function(e){e.contentEditable="false"},Zs.prototype.onKeyPress=function(e){0!=e.charCode&&(e.preventDefault(),this.cm.isReadOnly()||dn(this.cm,$o)(this.cm,String.fromCharCode(null==e.charCode?e.keyCode:e.charCode),0))},Zs.prototype.readOnlyChanged=function(e){this.div.contentEditable=String("nocursor"!=e)},Zs.prototype.onContextMenu=function(){},Zs.prototype.resetPosition=function(){},Zs.prototype.needsContentAttribute=!0;var Qs=function(e){this.cm=e,this.prevInput="",this.pollingFast=!1,this.polling=new Pl,this.hasSelection=!1,this.composing=null};Qs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()});else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type?i.setSelections(t.ranges,null,Gl):(n.prevInput="",l.value=t.text.join("\n"),El(l))}"cut"==e.type&&(i.state.cutIncoming=!0)}}var r=this,n=this,i=this.cm,o=this.wrapper=el(),l=this.textarea=o.firstChild;e.wrapper.insertBefore(o,e.wrapper.firstChild),Ll&&(l.style.width="0px"),Ql(l,"input",function(){gl&&vl>=9&&r.hasSelection&&(r.hasSelection=null),n.poll()}),Ql(l,"paste",function(e){Me(i,e)||qo(e,i)||(i.state.pasteIncoming=!0,n.fastPoll())}),Ql(l,"cut",t),Ql(l,"copy",t),Ql(e.scroller,"paste",function(t){Ft(e,t)||Me(i,t)||(i.state.pasteIncoming=!0,n.focus())}),Ql(e.lineSpace,"selectstart",function(t){Ft(e,t)||We(t)}),Ql(l,"compositionstart",function(){var e=i.getCursor("from");n.composing&&n.composing.range.clear(),n.composing={start:e,range:i.markText(e,i.getCursor("to"),{className:"CodeMirror-composing"})}}),Ql(l,"compositionend",function(){n.composing&&(n.poll(),n.composing.range.clear(),n.composing=null)})},Qs.prototype.prepareSelection=function(){var e=this.cm,t=e.display,r=e.doc,n=Tr(e);if(e.options.moveInputWithCursor){var i=sr(e,r.sel.primary().head,"div"),o=t.wrapper.getBoundingClientRect(),l=t.lineDiv.getBoundingClientRect();n.teTop=Math.max(0,Math.min(t.wrapper.clientHeight-10,i.top+l.top-o.top)),n.teLeft=Math.max(0,Math.min(t.wrapper.clientWidth-10,i.left+l.left-o.left))}return n},Qs.prototype.showSelection=function(e){var t=this.cm.display;r(t.cursorDiv,e.cursors),r(t.selectionDiv,e.selection),null!=e.teTop&&(this.wrapper.style.top=e.teTop+"px",this.wrapper.style.left=e.teLeft+"px")},Qs.prototype.reset=function(e){if(!this.contextMenuPending&&!this.composing){var t=this.cm;if(t.somethingSelected()){this.prevInput="";var r=t.getSelection();this.textarea.value=r,t.state.focused&&El(this.textarea),gl&&vl>=9&&(this.hasSelection=r)}else e||(this.prevInput=this.textarea.value="",gl&&vl>=9&&(this.hasSelection=null))}},Qs.prototype.getField=function(){return this.textarea},Qs.prototype.supportsTouch=function(){return!1},Qs.prototype.focus=function(){if("nocursor"!=this.cm.options.readOnly&&(!Tl||l()!=this.textarea))try{this.textarea.focus()}catch(e){}},Qs.prototype.blur=function(){this.textarea.blur()},Qs.prototype.resetPosition=function(){this.wrapper.style.top=this.wrapper.style.left=0},Qs.prototype.receivedFocus=function(){this.slowPoll()},Qs.prototype.slowPoll=function(){var e=this;this.pollingFast||this.polling.set(this.cm.options.pollInterval,function(){e.poll(),e.cm.state.focused&&e.slowPoll()})},Qs.prototype.fastPoll=function(){function e(){r.poll()||t?(r.pollingFast=!1,r.slowPoll()):(t=!0,r.polling.set(60,e))}var t=!1,r=this;r.pollingFast=!0,r.polling.set(20,e)},Qs.prototype.poll=function(){var e=this,t=this.cm,r=this.textarea,n=this.prevInput;if(this.contextMenuPending||!t.state.focused||ts(r)&&!n&&!this.composing||t.isReadOnly()||t.options.disableInput||t.state.keySeq)return!1;var i=r.value;if(i==n&&!t.somethingSelected())return!1;if(gl&&vl>=9&&this.hasSelection===i||Ml&&/[\uf700-\uf7ff]/.test(i))return t.display.input.reset(),!1;if(t.doc.sel==t.display.selForContextMenu){var o=i.charCodeAt(0);if(8203!=o||n||(n="​"),8666==o)return this.reset(),this.cm.execCommand("undo")}for(var l=0,s=Math.min(n.length,i.length);l<s&&n.charCodeAt(l)==i.charCodeAt(l);)++l;return hn(t,function(){$o(t,i.slice(l),n.length-l,null,e.composing?"*compose":null),i.length>1e3||i.indexOf("\n")>-1?r.value=e.prevInput="":e.prevInput=i,e.composing&&(e.composing.range.clear(),e.composing.range=t.markText(e.composing.start,t.getCursor("to"),{className:"CodeMirror-composing"}))}),!0},Qs.prototype.ensurePolled=function(){this.pollingFast&&this.poll()&&(this.pollingFast=!1)},Qs.prototype.onKeyPress=function(){gl&&vl>=9&&(this.hasSelection=null),this.fastPoll()},Qs.prototype.onContextMenu=function(e){function t(){if(null!=l.selectionStart){var e=i.somethingSelected(),t="​"+(e?l.value:"");l.value="⇚",l.value=t,n.prevInput=e?"":"​",l.selectionStart=1,l.selectionEnd=t.length,o.selForContextMenu=i.doc.sel}}function r(){if(n.contextMenuPending=!1,n.wrapper.style.cssText=c,l.style.cssText=u,gl&&vl<9&&o.scrollbars.setScrollTop(o.scroller.scrollTop=a),null!=l.selectionStart){(!gl||gl&&vl<9)&&t();var e=0,r=function(){o.selForContextMenu==i.doc.sel&&0==l.selectionStart&&l.selectionEnd>0&&"​"==n.prevInput?dn(i,Mi)(i):e++<10?o.detectingSelectAll=setTimeout(r,500):(o.selForContextMenu=null,o.input.reset())};o.detectingSelectAll=setTimeout(r,200)}}var n=this,i=n.cm,o=i.display,l=n.textarea,s=Sr(i,e),a=o.scroller.scrollTop;if(s&&!wl){i.options.resetSelectionOnContextMenu&&-1==i.doc.sel.contains(s)&&dn(i,bi)(i.doc,Rn(s),Gl);var u=l.style.cssText,c=n.wrapper.style.cssText;n.wrapper.style.cssText="position: absolute";var f=n.wrapper.getBoundingClientRect();l.style.cssText="position: absolute; width: 30px; height: 30px;\n      top: "+(e.clientY-f.top-5)+"px; left: "+(e.clientX-f.left-5)+"px;\n      z-index: 1000; background: "+(gl?"rgba(255, 255, 255, .05)":"transparent")+";\n      outline: none; border-width: 0; outline: none; overflow: hidden; opacity: .05; filter: alpha(opacity=5);";var h;if(ml&&(h=window.scrollY),o.input.focus(),ml&&window.scrollTo(null,h),o.input.reset(),i.somethingSelected()||(l.value=n.prevInput=" "),n.contextMenuPending=!0,o.selForContextMenu=i.doc.sel,clearTimeout(o.detectingSelectAll),gl&&vl>=9&&t(),Hl){Fe(e);var d=function(){ke(window,"mouseup",d),setTimeout(r,20)};Ql(window,"mouseup",d)}else setTimeout(r,50)}},Qs.prototype.readOnlyChanged=function(e){e||this.reset(),this.textarea.disabled="nocursor"==e},Qs.prototype.setUneditable=function(){},Qs.prototype.needsContentAttribute=!1,function(e){function t(t,n,i,o){e.defaults[t]=n,i&&(r[t]=o?function(e,t,r){r!=Xs&&i(e,t,r)}:i)}var r=e.optionHandlers;e.defineOption=t,e.Init=Xs,t("value","",function(e,t){return e.setValue(t)},!0),t("mode",null,function(e,t){e.doc.modeOption=t,jn(e)},!0),t("indentUnit",2,jn,!0),t("indentWithTabs",!1),t("smartIndent",!0),t("tabSize",4,function(e){Xn(e),er(e),vn(e)},!0),t("lineSeparator",null,function(e,t){if(e.doc.lineSep=t,t){var r=[],n=e.doc.first;e.doc.iter(function(e){for(var i=0;;){var o=e.text.indexOf(t,i);if(-1==o)break;i=o+t.length,r.push(E(n,o))}n++});for(var i=r.length-1;i>=0;i--)Ei(e.doc,t,r[i],E(r[i].line,r[i].ch+t.length))}}),t("specialChars",/[\u0000-\u001f\u007f-\u009f\u00ad\u061c\u200b-\u200f\u2028\u2029\ufeff]/g,function(e,t,r){e.state.specialChars=new RegExp(t.source+(t.test("\t")?"":"|\t"),"g"),r!=Xs&&e.refresh()}),t("specialCharPlaceholder",at,function(e){return e.refresh()},!0),t("electricChars",!0),t("inputStyle",Tl?"contenteditable":"textarea",function(){throw new Error("inputStyle can not (yet) be changed in a running editor")},!0),t("spellcheck",!1,function(e,t){return e.getInputField().spellcheck=t},!0),t("rtlMoveVisually",!Ol),t("wholeLineUpdateBefore",!0),t("theme","default",function(e){Go(e),Uo(e)},!0),t("keyMap","default",function(e,t,r){var n=uo(t),i=r!=Xs&&uo(r);i&&i.detach&&i.detach(e,n),n.attach&&n.attach(e,i||null)}),t("extraKeys",null),t("configureMouse",null),t("lineWrapping",!1,Ko,!0),t("gutters",[],function(e){Fn(e.options),Uo(e)},!0),t("fixedGutter",!0,function(e,t){e.display.gutters.style.left=t?wr(e.display)+"px":"0",e.refresh()},!0),t("coverGutterNextToScrollbar",!1,function(e){return en(e)},!0),t("scrollbarStyle","native",function(e){rn(e),en(e),e.display.scrollbars.setScrollTop(e.doc.scrollTop),e.display.scrollbars.setScrollLeft(e.doc.scrollLeft)},!0),t("lineNumbers",!1,function(e){Fn(e.options),Uo(e)},!0),t("firstLineNumber",1,Uo,!0),t("lineNumberFormatter",function(e){return e},Uo,!0),t("showCursorWhenSelecting",!1,kr,!0),t("resetSelectionOnContextMenu",!0),t("lineWiseCopyCut",!0),t("pasteLinesPerSelection",!0),t("readOnly",!1,function(e,t){"nocursor"==t&&(Fr(e),e.display.input.blur()),e.display.input.readOnlyChanged(t)}),t("disableInput",!1,function(e,t){t||e.display.input.reset()},!0),t("dragDrop",!0,Vo),t("allowDropFileTypes",null),t("cursorBlinkRate",530),t("cursorScrollMargin",0),t("cursorHeight",1,kr,!0),t("singleCursorHeightPerLine",!0,kr,!0),t("workTime",100),t("workDelay",100),t("flattenSpans",!0,Xn,!0),t("addModeClass",!1,Xn,!0),t("pollInterval",100),t("undoDepth",200,function(e,t){return e.doc.history.undoDepth=t}),t("historyEventDelay",1250),t("viewportMargin",10,function(e){return e.refresh()},!0),t("maxHighlightLength",1e4,Xn,!0),t("moveInputWithCursor",!0,function(e,t){t||e.display.input.resetPosition()}),t("tabindex",null,function(e,t){return e.display.input.getField().tabIndex=t||""}),t("autofocus",null),t("direction","ltr",function(e,t){return e.doc.setDirection(t)},!0)}(jo),function(e){var t=e.optionHandlers,r=e.helpers={};e.prototype={constructor:e,focus:function(){window.focus(),this.display.input.focus()},setOption:function(e,r){var n=this.options,i=n[e];n[e]==r&&"mode"!=e||(n[e]=r,t.hasOwnProperty(e)&&dn(this,t[e])(this,r,i),Te(this,"optionChange",this,e))},getOption:function(e){return this.options[e]},getDoc:function(){return this.doc},addKeyMap:function(e,t){this.state.keyMaps[t?"push":"unshift"](uo(e))},removeKeyMap:function(e){for(var t=this.state.keyMaps,r=0;r<t.length;++r)if(t[r]==e||t[r].name==e)return t.splice(r,1),!0},addOverlay:pn(function(t,r){var n=t.token?t:e.getMode(this.options,t);if(n.startState)throw new Error("Overlays may not be stateful.");m(this.state.overlays,{mode:n,modeSpec:t,opaque:r&&r.opaque,priority:r&&r.priority||0},function(e){return e.priority}),this.state.modeGen++,vn(this)}),removeOverlay:pn(function(e){for(var t=this,r=this.state.overlays,n=0;n<r.length;++n){var i=r[n].modeSpec;if(i==e||"string"==typeof e&&i.name==e)return r.splice(n,1),t.state.modeGen++,void vn(t)}}),indentLine:pn(function(e,t,r){"string"!=typeof t&&"number"!=typeof t&&(t=null==t?this.options.smartIndent?"smart":"prev":t?"add":"subtract"),H(this.doc,e)&&Yo(this,e,t,r)}),indentSelection:pn(function(e){for(var t=this,r=this.doc.sel.ranges,n=-1,i=0;i<r.length;i++){var o=r[i];if(o.empty())o.head.line>n&&(Yo(t,o.head.line,e,!0),n=o.head.line,i==t.doc.sel.primIndex&&jr(t));else{var l=o.from(),s=o.to(),a=Math.max(n,l.line);n=Math.min(t.lastLine(),s.line-(s.ch?0:1))+1;for(var u=a;u<n;++u)Yo(t,u,e);var c=t.doc.sel.ranges;0==l.ch&&r.length==c.length&&c[i].from().ch>0&&gi(t.doc,i,new Ts(l,c[i].to()),Gl)}}}),getTokenAt:function(e,t){return Je(this,e,t)},getLineTokens:function(e,t){return Je(this,E(e),t,!0)},getTokenTypeAt:function(e){e=U(this.doc,e);var t,r=_e(this,M(this.doc,e.line)),n=0,i=(r.length-1)/2,o=e.ch;if(0==o)t=r[2];else for(;;){var l=n+i>>1;if((l?r[2*l-1]:0)>=o)i=l;else{if(!(r[2*l+1]<o)){t=r[2*l+2];break}n=l+1}}var s=t?t.indexOf("overlay "):-1;return s<0?t:0==s?null:t.slice(0,s-1)},getModeAt:function(t){var r=this.doc.mode;return r.innerMode?e.innerMode(r,this.getTokenAt(t).state).mode:r},getHelper:function(e,t){return this.getHelpers(e,t)[0]},getHelpers:function(e,t){var n=this,i=[];if(!r.hasOwnProperty(t))return i;var o=r[t],l=this.getModeAt(e);if("string"==typeof l[t])o[l[t]]&&i.push(o[l[t]]);else if(l[t])for(var s=0;s<l[t].length;s++){var a=o[l[t][s]];a&&i.push(a)}else l.helperType&&o[l.helperType]?i.push(o[l.helperType]):o[l.name]&&i.push(o[l.name]);for(var u=0;u<o._global.length;u++){var c=o._global[u];c.pred(l,n)&&-1==h(i,c.val)&&i.push(c.val)}return i},getStateAfter:function(e,t){var r=this.doc;return e=G(r,null==e?r.first+r.size-1:e),$e(this,e+1,t).state},cursorCoords:function(e,t){var r,n=this.doc.sel.primary();return r=null==e?n.head:"object"==typeof e?U(this.doc,e):e?n.from():n.to(),sr(this,r,t||"page")},charCoords:function(e,t){return lr(this,U(this.doc,e),t||"page")},coordsChar:function(e,t){return e=or(this,e,t||"page"),cr(this,e.left,e.top)},lineAtHeight:function(e,t){return e=or(this,{top:e,left:0},t||"page").top,D(this.doc,e+this.display.viewOffset)},heightAtLine:function(e,t,r){var n,i=!1;if("number"==typeof e){var o=this.doc.first+this.doc.size-1;e<this.doc.first?e=this.doc.first:e>o&&(e=o,i=!0),n=M(this.doc,e)}else n=e;return ir(this,n,{top:0,left:0},t||"page",r||i).top+(i?this.doc.height-ye(n):0)},defaultTextHeight:function(){return mr(this.display)},defaultCharWidth:function(){return yr(this.display)},getViewport:function(){return{from:this.display.viewFrom,to:this.display.viewTo}},addWidget:function(e,t,r,n,i){var o=this.display,l=(e=sr(this,U(this.doc,e))).bottom,s=e.left;if(t.style.position="absolute",t.setAttribute("cm-ignore-events","true"),this.display.input.setUneditable(t),o.sizer.appendChild(t),"over"==n)l=e.top;else if("above"==n||"near"==n){var a=Math.max(o.wrapper.clientHeight,this.doc.height),u=Math.max(o.sizer.clientWidth,o.lineSpace.clientWidth);("above"==n||e.bottom+t.offsetHeight>a)&&e.top>t.offsetHeight?l=e.top-t.offsetHeight:e.bottom+t.offsetHeight<=a&&(l=e.bottom),s+t.offsetWidth>u&&(s=u-t.offsetWidth)}t.style.top=l+"px",t.style.left=t.style.right="","right"==i?(s=o.sizer.clientWidth-t.offsetWidth,t.style.right="0px"):("left"==i?s=0:"middle"==i&&(s=(o.sizer.clientWidth-t.offsetWidth)/2),t.style.left=s+"px"),r&&Ur(this,{left:s,top:l,right:s+t.offsetWidth,bottom:l+t.offsetHeight})},triggerOnKeyDown:pn(Lo),triggerOnKeyPress:pn(Mo),triggerOnKeyUp:To,triggerOnMouseDown:pn(Oo),execCommand:function(e){if(Bs.hasOwnProperty(e))return Bs[e].call(null,this)},triggerElectric:pn(function(e){Zo(this,e)}),findPosH:function(e,t,r,n){var i=this,o=1;t<0&&(o=-1,t=-t);for(var l=U(this.doc,e),s=0;s<t&&!(l=tl(i.doc,l,o,r,n)).hitSide;++s);return l},moveH:pn(function(e,t){var r=this;this.extendSelectionsBy(function(n){return r.display.shift||r.doc.extend||n.empty()?tl(r.doc,n.head,e,t,r.options.rtlMoveVisually):e<0?n.from():n.to()},Vl)}),deleteH:pn(function(e,t){var r=this.doc.sel,n=this.doc;r.somethingSelected()?n.replaceSelection("",null,"+delete"):co(this,function(r){var i=tl(n,r.head,e,t,!1);return e<0?{from:i,to:r.head}:{from:r.head,to:i}})}),findPosV:function(e,t,r,n){var i=this,o=1,l=n;t<0&&(o=-1,t=-t);for(var s=U(this.doc,e),a=0;a<t;++a){var u=sr(i,s,"div");if(null==l?l=u.left:u.left=l,(s=rl(i,u,o,r)).hitSide)break}return s},moveV:pn(function(e,t){var r=this,n=this.doc,i=[],o=!this.display.shift&&!n.extend&&n.sel.somethingSelected();if(n.extendSelectionsBy(function(l){if(o)return e<0?l.from():l.to();var s=sr(r,l.head,"div");null!=l.goalColumn&&(s.left=l.goalColumn),i.push(s.left);var a=rl(r,s,e,t);return"page"==t&&l==n.sel.primary()&&Kr(r,lr(r,a,"div").top-s.top),a},Vl),i.length)for(var l=0;l<n.sel.ranges.length;l++)n.sel.ranges[l].goalColumn=i[l]}),findWordAt:function(e){var t=M(this.doc,e.line).text,r=e.ch,n=e.ch;if(t){var i=this.getHelper(e,"wordChars");"before"!=e.sticky&&n!=t.length||!r?++n:--r;for(var o=t.charAt(r),l=x(o,i)?function(e){return x(e,i)}:/\s/.test(o)?function(e){return/\s/.test(e)}:function(e){return!/\s/.test(e)&&!x(e)};r>0&&l(t.charAt(r-1));)--r;for(;n<t.length&&l(t.charAt(n));)++n}return new Ts(E(e.line,r),E(e.line,n))},toggleOverwrite:function(e){null!=e&&e==this.state.overwrite||((this.state.overwrite=!this.state.overwrite)?s(this.display.cursorDiv,"CodeMirror-overwrite"):Fl(this.display.cursorDiv,"CodeMirror-overwrite"),Te(this,"overwriteToggle",this,this.state.overwrite))},hasFocus:function(){return this.display.input.getField()==l()},isReadOnly:function(){return!(!this.options.readOnly&&!this.doc.cantEdit)},scrollTo:pn(function(e,t){Xr(this,e,t)}),getScrollInfo:function(){var e=this.display.scroller;return{left:e.scrollLeft,top:e.scrollTop,height:e.scrollHeight-zt(this)-this.display.barHeight,width:e.scrollWidth-zt(this)-this.display.barWidth,clientHeight:Bt(this),clientWidth:Rt(this)}},scrollIntoView:pn(function(e,t){null==e?(e={from:this.doc.sel.primary().head,to:null},null==t&&(t=this.options.cursorScrollMargin)):"number"==typeof e?e={from:E(e,0),to:null}:null==e.from&&(e={from:e,to:null}),e.to||(e.to=e.from),e.margin=t||0,null!=e.from.line?Yr(this,e):$r(this,e.from,e.to,e.margin)}),setSize:pn(function(e,t){var r=this,n=function(e){return"number"==typeof e||/^\d+$/.test(String(e))?e+"px":e};null!=e&&(this.display.wrapper.style.width=n(e)),null!=t&&(this.display.wrapper.style.height=n(t)),this.options.lineWrapping&&Jt(this);var i=this.display.viewFrom;this.doc.iter(i,this.display.viewTo,function(e){if(e.widgets)for(var t=0;t<e.widgets.length;t++)if(e.widgets[t].noHScroll){mn(r,i,"widget");break}++i}),this.curOp.forceUpdate=!0,Te(this,"refresh",this)}),operation:function(e){return hn(this,e)},startOperation:function(){return nn(this)},endOperation:function(){return on(this)},refresh:pn(function(){var e=this.display.cachedTextHeight;vn(this),this.curOp.forceUpdate=!0,er(this),Xr(this,this.doc.scrollLeft,this.doc.scrollTop),Wn(this),(null==e||Math.abs(e-mr(this.display))>.5)&&Cr(this),Te(this,"refresh",this)}),swapDoc:pn(function(e){var t=this.doc;return t.cm=null,qn(this,e),er(this),this.display.input.reset(),Xr(this,e.scrollLeft,e.scrollTop),this.curOp.forceScroll=!0,bt(this,"swapDoc",this,t),t}),getInputField:function(){return this.display.input.getField()},getWrapperElement:function(){return this.display.wrapper},getScrollerElement:function(){return this.display.scroller},getGutterElement:function(){return this.display.gutters}},Ae(e),e.registerHelper=function(t,n,i){r.hasOwnProperty(t)||(r[t]=e[t]={_global:[]}),r[t][n]=i},e.registerGlobalHelper=function(t,n,i,o){e.registerHelper(t,n,o),r[t]._global.push({pred:i,val:o})}}(jo);var Js="iter insert remove copy getEditor constructor".split(" ");for(var ea in Ds.prototype)Ds.prototype.hasOwnProperty(ea)&&h(Js,ea)<0&&(jo.prototype[ea]=function(e){return function(){return e.apply(this.doc,arguments)}}(Ds.prototype[ea]));return Ae(Ds),jo.inputStyles={textarea:Qs,contenteditable:Zs},jo.defineMode=function(e){jo.defaults.mode||"null"==e||(jo.defaults.mode=e),Be.apply(this,arguments)},jo.defineMIME=function(e,t){os[e]=t},jo.defineMode("null",function(){return{token:function(e){return e.skipToEnd()}}}),jo.defineMIME("text/plain","null"),jo.defineExtension=function(e,t){jo.prototype[e]=t},jo.defineDocExtension=function(e,t){Ds.prototype[e]=t},jo.fromTextArea=function(e,t){function r(){e.value=a.getValue()}if(t=t?c(t):{},t.value=e.value,!t.tabindex&&e.tabIndex&&(t.tabindex=e.tabIndex),!t.placeholder&&e.placeholder&&(t.placeholder=e.placeholder),null==t.autofocus){var n=l();t.autofocus=n==e||null!=e.getAttribute("autofocus")&&n==document.body}var i;if(e.form&&(Ql(e.form,"submit",r),!t.leaveSubmitMethodAlone)){var o=e.form;i=o.submit;try{var s=o.submit=function(){r(),o.submit=i,o.submit(),o.submit=s}}catch(e){}}t.finishInit=function(t){t.save=r,t.getTextArea=function(){return e},t.toTextArea=function(){t.toTextArea=isNaN,r(),e.parentNode.removeChild(t.getWrapperElement()),e.style.display="",e.form&&(ke(e.form,"submit",r),"function"==typeof e.form.submit&&(e.form.submit=i))}},e.style.display="none";var a=jo(function(t){return e.parentNode.insertBefore(t,e.nextSibling)},t);return a},function(e){e.off=ke,e.on=Ql,e.wheelEventPixels=Pn,e.Doc=Ds,e.splitLines=es,e.countColumn=f,e.findColumn=d,e.isWordChar=w,e.Pass=Bl,e.signal=Te,e.Line=fs,e.changeEnd=Bn,e.scrollbarModel=ws,e.Pos=E,e.cmpPos=P,e.modes=is,e.mimeModes=os,e.resolveMode=Ge,e.getMode=Ue,e.modeExtensions=ls,e.extendMode=Ve,e.copyState=Ke,e.startState=Xe,e.innerMode=je,e.commands=Bs,e.keyMap=Rs,e.keyName=ao,e.isModifierKey=lo,e.lookupKey=oo,e.normalizeKeyMap=io,e.StringStream=ss,e.SharedTextMarker=As,e.TextMarker=Os,e.LineWidget=Ms,e.e_preventDefault=We,e.e_stopPropagation=De,e.e_stop=Fe,e.addClass=s,e.contains=o,e.rmClass=Fl,e.keyNames=Es}(jo),jo.version="5.30.0",jo});
      !function(e){"object"==typeof exports&&"object"==typeof module?e(require("../../lib/codemirror")):"function"==typeof define&&define.amd?define(["../../lib/codemirror"],e):e(CodeMirror)}(function(e){"use strict";function t(e,t,n,r,o,a){this.indented=e,this.column=t,this.type=n,this.info=r,this.align=o,this.prev=a}function n(e,n,r,o){var a=e.indented;return e.context&&"statement"==e.context.type&&"statement"!=r&&(a=e.context.indented),e.context=new t(a,n,r,o,null,e.context)}function r(e){var t=e.context.type;return")"!=t&&"]"!=t&&"}"!=t||(e.indented=e.context.indented),e.context=e.context.prev}function o(e,t,n){return"variable"==t.prevToken||"type"==t.prevToken||(!!/\S(?:[^- ]>|[*\]])\s*$|\*$/.test(e.string.slice(0,n))||(!(!t.typeAtEndOfLine||e.column()!=e.indentation())||void 0))}function a(e){for(;;){if(!e||"top"==e.type)return!0;if("}"==e.type&&"namespace"!=e.prev.info)return!1;e=e.prev}}function i(e){for(var t={},n=e.split(" "),r=0;r<n.length;++r)t[n[r]]=!0;return t}function l(e,t){return"function"==typeof e?e(t):e.propertyIsEnumerable(t)}function s(e,t){if(!t.startOfLine)return!1;for(var n,r=null;n=e.peek();){if("\\"==n&&e.match(/^.$/)){r=s;break}if("/"==n&&e.match(/^\/[\/\*]/,!1))break;e.next()}return t.tokenize=r,"meta"}function c(e,t){return"type"==t.prevToken&&"type"}function u(e){return e.eatWhile(/[\w\.']/),"number"}function d(e,t){if(e.backUp(1),e.match(/(R|u8R|uR|UR|LR)/)){var n=e.match(/"([^\s\\()]{0,16})\(/);return!!n&&(t.cpp11RawStringDelim=n[1],t.tokenize=m,m(e,t))}return e.match(/(u8|u|U|L)/)?!!e.match(/["']/,!1)&&"string":(e.next(),!1)}function f(e){var t=/(\w+)::~?(\w+)$/.exec(e);return t&&t[1]==t[2]}function p(e,t){for(var n;null!=(n=e.next());)if('"'==n&&!e.eat('"')){t.tokenize=null;break}return"string"}function m(e,t){var n=t.cpp11RawStringDelim.replace(/[^\w\s]/g,"\\$&");return e.match(new RegExp(".*?\\)"+n+'"'))?t.tokenize=null:e.skipToEnd(),"string"}function h(t,n){function r(e){if(e)for(var t in e)e.hasOwnProperty(t)&&o.push(t)}"string"==typeof t&&(t=[t]);var o=[];r(n.keywords),r(n.types),r(n.builtin),r(n.atoms),o.length&&(n.helperType=t[0],e.registerHelper("hintWords",t[0],o));for(var a=0;a<t.length;++a)e.defineMIME(t[a],n)}function g(e,t){for(var n=!1;!e.eol();){if(!n&&e.match('"""')){t.tokenize=null;break}n="\\"==e.next()&&!n}return"string"}function y(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!e&&!o&&t.match('"')){a=!0;break}if(e&&t.match('"""')){a=!0;break}r=t.next(),!o&&"$"==r&&t.match("{")&&t.skipTo("}"),o=!o&&"\\"==r&&!e}return!a&&e||(n.tokenize=null),"string"}}function x(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!o&&t.match('"')&&("single"==e||t.match('""'))){a=!0;break}if(!o&&t.match("``")){w=x(e),a=!0;break}r=t.next(),o="single"==e&&!o&&"\\"==r}return a&&(n.tokenize=null),"string"}}e.defineMode("clike",function(i,s){function c(e,t){var n=e.next();if(S[n]){var r=S[n](e,t);if(!1!==r)return r}if('"'==n||"'"==n)return t.tokenize=u(n),t.tokenize(e,t);if(D.test(n))return p=n,null;if(L.test(n)){if(e.backUp(1),e.match(I))return"number";e.next()}if("/"==n){if(e.eat("*"))return t.tokenize=d,d(e,t);if(e.eat("/"))return e.skipToEnd(),"comment"}if(F.test(n)){for(;!e.match(/^\/[\/*]/,!1)&&e.eat(F););return"operator"}if(e.eatWhile(z),P)for(;e.match(P);)e.eatWhile(z);var o=e.current();return l(x,o)?(l(w,o)&&(p="newstatement"),l(v,o)&&(m=!0),"keyword"):l(b,o)?"type":l(k,o)?(l(w,o)&&(p="newstatement"),"builtin"):l(_,o)?"atom":"variable"}function u(e){return function(t,n){for(var r,o=!1,a=!1;null!=(r=t.next());){if(r==e&&!o){a=!0;break}o=!o&&"\\"==r}return(a||!o&&!C)&&(n.tokenize=null),"string"}}function d(e,t){for(var n,r=!1;n=e.next();){if("/"==n&&r){t.tokenize=null;break}r="*"==n}return"comment"}function f(e,t){s.typeFirstDefinitions&&e.eol()&&a(t.context)&&(t.typeAtEndOfLine=o(e,t,e.pos))}var p,m,h=i.indentUnit,g=s.statementIndentUnit||h,y=s.dontAlignCalls,x=s.keywords||{},b=s.types||{},k=s.builtin||{},w=s.blockKeywords||{},v=s.defKeywords||{},_=s.atoms||{},S=s.hooks||{},C=s.multiLineStrings,T=!1!==s.indentStatements,M=!1!==s.indentSwitch,P=s.namespaceSeparator,D=s.isPunctuationChar||/[\[\]{}\(\),;\:\.]/,L=s.numberStart||/[\d\.]/,I=s.number||/^(?:0x[a-f\d]+|0b[01]+|(?:\d+\.?\d*|\.\d+)(?:e[-+]?\d+)?)(u|ll?|l|f)?/i,F=s.isOperatorChar||/[+\-*&%=<>!?|\/]/,z=s.isIdentifierChar||/[\w\$_\xa1-\uffff]/;return{startState:function(e){return{tokenize:null,context:new t((e||0)-h,0,"top",null,!1),indented:0,startOfLine:!0,prevToken:null}},token:function(e,t){var i=t.context;if(e.sol()&&(null==i.align&&(i.align=!1),t.indented=e.indentation(),t.startOfLine=!0),e.eatSpace())return f(e,t),null;p=m=null;var l=(t.tokenize||c)(e,t);if("comment"==l||"meta"==l)return l;if(null==i.align&&(i.align=!0),";"==p||":"==p||","==p&&e.match(/^\s*(?:\/\/.*)?$/,!1))for(;"statement"==t.context.type;)r(t);else if("{"==p)n(t,e.column(),"}");else if("["==p)n(t,e.column(),"]");else if("("==p)n(t,e.column(),")");else if("}"==p){for(;"statement"==i.type;)i=r(t);for("}"==i.type&&(i=r(t));"statement"==i.type;)i=r(t)}else p==i.type?r(t):T&&(("}"==i.type||"top"==i.type)&&";"!=p||"statement"==i.type&&"newstatement"==p)&&n(t,e.column(),"statement",e.current());if("variable"==l&&("def"==t.prevToken||s.typeFirstDefinitions&&o(e,t,e.start)&&a(t.context)&&e.match(/^\s*\(/,!1))&&(l="def"),S.token){var u=S.token(e,t,l);void 0!==u&&(l=u)}return"def"==l&&!1===s.styleDefs&&(l="variable"),t.startOfLine=!1,t.prevToken=m?"def":l||p,f(e,t),l},indent:function(t,n){if(t.tokenize!=c&&null!=t.tokenize||t.typeAtEndOfLine)return e.Pass;var r=t.context,o=n&&n.charAt(0);if("statement"==r.type&&"}"==o&&(r=r.prev),s.dontIndentStatements)for(;"statement"==r.type&&s.dontIndentStatements.test(r.info);)r=r.prev;if(S.indent){var a=S.indent(t,r,n);if("number"==typeof a)return a}var i=o==r.type,l=r.prev&&"switch"==r.prev.info;if(s.allmanIndentation&&/[{(]/.test(o)){for(;"top"!=r.type&&"}"!=r.type;)r=r.prev;return r.indented}return"statement"==r.type?r.indented+("{"==o?0:g):!r.align||y&&")"==r.type?")"!=r.type||i?r.indented+(i?0:h)+(i||!l||/^(?:case|default)\b/.test(n)?0:h):r.indented+g:r.column+(i?0:1)},electricInput:M?/^\s*(?:case .*?:|default:|\{\}?|\})$/:/^\s*[{}]$/,blockCommentStart:"/*",blockCommentEnd:"*/",lineComment:"//",fold:"brace"}});var b="auto if break case register continue return default do sizeof static else struct switch extern typedef union for goto while enum const volatile",k="int long char short double float unsigned signed void size_t ptrdiff_t";h(["text/x-csrc","text/x-c","text/x-chdr"],{name:"clike",keywords:i(b),types:i(k+" bool _Complex _Bool float_t double_t intptr_t intmax_t int8_t int16_t int32_t int64_t uintptr_t uintmax_t uint8_t uint16_t uint32_t uint64_t"),blockKeywords:i("case do else for if switch while struct"),defKeywords:i("struct"),typeFirstDefinitions:!0,atoms:i("null true false"),hooks:{"#":s,"*":c},modeProps:{fold:["brace","include"]}}),h(["text/x-c++src","text/x-c++hdr"],{name:"clike",keywords:i(b+" asm dynamic_cast namespace reinterpret_cast try explicit new static_cast typeid catch operator template typename class friend private this using const_cast inline public throw virtual delete mutable protected alignas alignof constexpr decltype nullptr noexcept thread_local final static_assert override"),types:i(k+" bool wchar_t"),blockKeywords:i("catch class do else finally for if struct switch try while"),defKeywords:i("class namespace struct enum union"),typeFirstDefinitions:!0,atoms:i("true false null"),dontIndentStatements:/^template$/,isIdentifierChar:/[\w\$_~\xa1-\uffff]/,hooks:{"#":s,"*":c,u:d,U:d,L:d,R:d,0:u,1:u,2:u,3:u,4:u,5:u,6:u,7:u,8:u,9:u,token:function(e,t,n){if("variable"==n&&"("==e.peek()&&(";"==t.prevToken||null==t.prevToken||"}"==t.prevToken)&&f(e.current()))return"def"}},namespaceSeparator:"::",modeProps:{fold:["brace","include"]}}),h("text/x-java",{name:"clike",keywords:i("abstract assert break case catch class const continue default do else enum extends final finally float for goto if implements import instanceof interface native new package private protected public return static strictfp super switch synchronized this throw throws transient try volatile while @interface"),types:i("byte short int long float double boolean char void Boolean Byte Character Double Float Integer Long Number Object Short String StringBuffer StringBuilder Void"),blockKeywords:i("catch class do else finally for if switch try while"),defKeywords:i("class interface package enum @interface"),typeFirstDefinitions:!0,atoms:i("true false null"),number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,hooks:{"@":function(e){return!e.match("interface",!1)&&(e.eatWhile(/[\w\$_]/),"meta")}},modeProps:{fold:["brace","import"]}}),h("text/x-csharp",{name:"clike",keywords:i("abstract as async await base break case catch checked class const continue default delegate do else enum event explicit extern finally fixed for foreach goto if implicit in interface internal is lock namespace new operator out override params private protected public readonly ref return sealed sizeof stackalloc static struct switch this throw try typeof unchecked unsafe using virtual void volatile while add alias ascending descending dynamic from get global group into join let orderby partial remove select set value var yield"),types:i("Action Boolean Byte Char DateTime DateTimeOffset Decimal Double Func Guid Int16 Int32 Int64 Object SByte Single String Task TimeSpan UInt16 UInt32 UInt64 bool byte char decimal double short int long object sbyte float string ushort uint ulong"),blockKeywords:i("catch class do else finally for foreach if struct switch try while"),defKeywords:i("class interface namespace struct var"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"@":function(e,t){return e.eat('"')?(t.tokenize=p,p(e,t)):(e.eatWhile(/[\w\$_]/),"meta")}}}),h("text/x-scala",{name:"clike",keywords:i("abstract case catch class def do else extends final finally for forSome if implicit import lazy match new null object override package private protected return sealed super this throw trait try type val var while with yield _ assert assume require print println printf readLine readBoolean readByte readShort readChar readInt readLong readFloat readDouble"),types:i("AnyVal App Application Array BufferedIterator BigDecimal BigInt Char Console Either Enumeration Equiv Error Exception Fractional Function IndexedSeq Int Integral Iterable Iterator List Map Numeric Nil NotNull Option Ordered Ordering PartialFunction PartialOrdering Product Proxy Range Responder Seq Serializable Set Specializable Stream StringBuilder StringContext Symbol Throwable Traversable TraversableOnce Tuple Unit Vector Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),multiLineStrings:!0,blockKeywords:i("catch class enum do else finally for forSome if match switch try while"),defKeywords:i("class enum def object package trait type val var"),atoms:i("true false null"),indentStatements:!1,indentSwitch:!1,isOperatorChar:/[+\-*&%=<>!?|\/#:@]/,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return!!e.match('""')&&(t.tokenize=g,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},"=":function(e,n){var r=n.context;return!("}"!=r.type||!r.align||!e.eat(">"))&&(n.context=new t(r.indented,r.column,r.type,r.info,null,r.prev),"operator")}},modeProps:{closeBrackets:{triples:'"'}}}),h("text/x-kotlin",{name:"clike",keywords:i("package as typealias class interface this super val var fun for is in This throw return break continue object if else while do try when !in !is as? file import where by get set abstract enum open inner override private public internal protected catch finally out final vararg reified dynamic companion constructor init sealed field property receiver param sparam lateinit data inline noinline tailrec external annotation crossinline const operator infix suspend"),types:i("Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),intendSwitch:!1,indentStatements:!1,multiLineStrings:!0,number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,blockKeywords:i("catch class do else finally for if where try while enum"),defKeywords:i("class val var object package interface fun"),atoms:i("true false null this"),hooks:{'"':function(e,t){return t.tokenize=y(e.match('""')),t.tokenize(e,t)}},modeProps:{closeBrackets:{triples:'"'}}}),h(["x-shader/x-vertex","x-shader/x-fragment"],{name:"clike",keywords:i("sampler1D sampler2D sampler3D samplerCube sampler1DShadow sampler2DShadow const attribute uniform varying break continue discard return for while do if else struct in out inout"),types:i("float int bool void vec2 vec3 vec4 ivec2 ivec3 ivec4 bvec2 bvec3 bvec4 mat2 mat3 mat4"),blockKeywords:i("for while do if else struct"),builtin:i("radians degrees sin cos tan asin acos atan pow exp log exp2 sqrt inversesqrt abs sign floor ceil fract mod min max clamp mix step smoothstep length distance dot cross normalize ftransform faceforward reflect refract matrixCompMult lessThan lessThanEqual greaterThan greaterThanEqual equal notEqual any all not texture1D texture1DProj texture1DLod texture1DProjLod texture2D texture2DProj texture2DLod texture2DProjLod texture3D texture3DProj texture3DLod texture3DProjLod textureCube textureCubeLod shadow1D shadow2D shadow1DProj shadow2DProj shadow1DLod shadow2DLod shadow1DProjLod shadow2DProjLod dFdx dFdy fwidth noise1 noise2 noise3 noise4"),atoms:i("true false gl_FragColor gl_SecondaryColor gl_Normal gl_Vertex gl_MultiTexCoord0 gl_MultiTexCoord1 gl_MultiTexCoord2 gl_MultiTexCoord3 gl_MultiTexCoord4 gl_MultiTexCoord5 gl_MultiTexCoord6 gl_MultiTexCoord7 gl_FogCoord gl_PointCoord gl_Position gl_PointSize gl_ClipVertex gl_FrontColor gl_BackColor gl_FrontSecondaryColor gl_BackSecondaryColor gl_TexCoord gl_FogFragCoord gl_FragCoord gl_FrontFacing gl_FragData gl_FragDepth gl_ModelViewMatrix gl_ProjectionMatrix gl_ModelViewProjectionMatrix gl_TextureMatrix gl_NormalMatrix gl_ModelViewMatrixInverse gl_ProjectionMatrixInverse gl_ModelViewProjectionMatrixInverse gl_TexureMatrixTranspose gl_ModelViewMatrixInverseTranspose gl_ProjectionMatrixInverseTranspose gl_ModelViewProjectionMatrixInverseTranspose gl_TextureMatrixInverseTranspose gl_NormalScale gl_DepthRange gl_ClipPlane gl_Point gl_FrontMaterial gl_BackMaterial gl_LightSource gl_LightModel gl_FrontLightModelProduct gl_BackLightModelProduct gl_TextureColor gl_EyePlaneS gl_EyePlaneT gl_EyePlaneR gl_EyePlaneQ gl_FogParameters gl_MaxLights gl_MaxClipPlanes gl_MaxTextureUnits gl_MaxTextureCoords gl_MaxVertexAttribs gl_MaxVertexUniformComponents gl_MaxVaryingFloats gl_MaxVertexTextureImageUnits gl_MaxTextureImageUnits gl_MaxFragmentUniformComponents gl_MaxCombineTextureImageUnits gl_MaxDrawBuffers"),indentSwitch:!1,hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-nesc",{name:"clike",keywords:i(b+"as atomic async call command component components configuration event generic implementation includes interface module new norace nx_struct nx_union post provides signal task uses abstract extends"),types:i(k),blockKeywords:i("case do else for if switch while struct"),atoms:i("null true false"),hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-objectivec",{name:"clike",keywords:i(b+"inline restrict _Bool _Complex _Imaginary BOOL Class bycopy byref id IMP in inout nil oneway out Protocol SEL self super atomic nonatomic retain copy readwrite readonly"),types:i(k),atoms:i("YES NO NULL NILL ON OFF true false"),hooks:{"@":function(e){return e.eatWhile(/[\w\$]/),"keyword"},"#":s,indent:function(e,t,n){if("statement"==t.type&&/^@\w/.test(n))return t.indented}},modeProps:{fold:"brace"}}),h("text/x-squirrel",{name:"clike",keywords:i("base break clone continue const default delete enum extends function in class foreach local resume return this throw typeof yield constructor instanceof static"),types:i(k),blockKeywords:i("case catch class else for foreach if switch try while"),defKeywords:i("function local class"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"#":s},modeProps:{fold:["brace","include"]}});var w=null;h("text/x-ceylon",{name:"clike",keywords:i("abstracts alias assembly assert assign break case catch class continue dynamic else exists extends finally for function given if import in interface is let module new nonempty object of out outer package return satisfies super switch then this throw try value void while"),types:function(e){var t=e.charAt(0);return t===t.toUpperCase()&&t!==t.toLowerCase()},blockKeywords:i("case catch class dynamic else finally for function if interface module new object switch try while"),defKeywords:i("class dynamic function interface module object package value"),builtin:i("abstract actual aliased annotation by default deprecated doc final formal late license native optional sealed see serializable shared suppressWarnings tagged throws variable"),isPunctuationChar:/[\[\]{}\(\),;\:\.`]/,isOperatorChar:/[+\-*&%=<>!?|^~:\/]/,numberStart:/[\d#$]/,number:/^(?:#[\da-fA-F_]+|\$[01_]+|[\d_]+[kMGTPmunpf]?|[\d_]+\.[\d_]+(?:[eE][-+]?\d+|[kMGTPmunpf]|)|)/i,multiLineStrings:!0,typeFirstDefinitions:!0,atoms:i("true false null larger smaller equal empty finished"),indentSwitch:!1,styleDefs:!1,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return t.tokenize=x(e.match('""')?"triple":"single"),t.tokenize(e,t)},"`":function(e,t){return!(!w||!e.match("`"))&&(t.tokenize=w,w=null,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},token:function(e,t,n){if(("variable"==n||"type"==n)&&"."==t.prevToken)return"variable-2"}},modeProps:{fold:["brace","import"],closeBrackets:{triples:'"'}}})});
      // -------------------------------------------------------------------------
//  Part of the CodeChecker project, under the Apache License v2.0 with
//  LLVM Exceptions. See LICENSE for license information.
//  SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
// -------------------------------------------------------------------------

var BugViewer = {
  _files : [],
  _reports : [],
  _lineWidgets : [],
  _navigationMenuItems : [],
  _sourceFileData : null,
  _currentReport : null,
  _lastBugEvent  : null,

  init : function (files, reports) {
    this._files = files;
    this._reports = reports;

    this.initEscapeChars();
  },

  initEscapeChars : function () {
    this.escapeChars = {
      ' ' : 'nbsp',
      '<' : 'lt',
      '>' : 'gt',
      '"' : 'quot',
      '&' : 'amp'
    };

    var regexString = '[';
    for (var key in this.escapeChars) {
      regexString += key;
    }
    regexString += ']';

    this.escapeRegExp = new RegExp( regexString, 'g');
  },

  escapeHTML : function (str) {
    var that = this;

    return str.replace(this.escapeRegExp, function (m) {
      return '&' + that.escapeChars[m] + ';';
    });
  },

  initByUrl : function () {
    if (!this._reports) return;

    var state = {};
    window.location.hash.substr(1).split('&').forEach(function (s) {
      var parts = s.split('=');
      state[parts[0]] = parts[1];
    });

    for (var key in this._reports) {
      var report = this._reports[key];
      if (report.reportHash === state['reportHash']) {
        this.navigate(report);
        return;
      }
    }

    this.navigate(this._reports[0]);
  },

  create : function () {
    this._content = document.getElementById('editor-wrapper');
    this._filepath = document.getElementById('file-path');
    this._checkerName = document.getElementById('checker-name');
    this._reviewStatusWrapper =
      document.getElementById('review-status-wrapper');
    this._reviewStatus = document.getElementById('review-status');
    this._editor = document.getElementById('editor');

    this._codeMirror = CodeMirror(this._editor, {
      mode: 'text/x-c++src',
      matchBrackets : true,
      lineNumbers : true,
      readOnly : true,
      foldGutter : true,
      extraKeys : {},
      viewportMargin : 100
    });

    this._createNavigationMenu();
  },

  navigate : function (report, item) {
    if (!item) {
      var items = this._navigationMenuItems.filter(function (navItem) {
        return navItem.report.reportHash === report.reportHash;
      });

      if (!items.length) return;

      item = items[0].widget;
    }

    this._selectedReport.classList.remove('active');
    this._selectedReport = item;
    this._selectedReport.classList.add('active');
    this.setReport(report);
  },

  _createNavigationMenu : function () {
    var that = this;

    var nav = document.getElementById('report-nav');
    var list = document.createElement('ul');
    this._reports.forEach(function (report) {
      var events = report['events'];
      var lastBugEvent = events[events.length - 1];
      var item = document.createElement('li');

      var severity = document.createElement('i');
      severity.className = 'severity-' + report.severity.toLowerCase();

      item.appendChild(severity);
      item.appendChild(document.createTextNode(lastBugEvent.message));

      item.addEventListener('click', function () {
        that.navigate(report, item);
      })
      list.appendChild(item);
      that._navigationMenuItems.push({ report : report, widget : item });
    });

    if (!this._selectedReport && list.childNodes.length) {
      this._selectedReport = list.childNodes[0];
      this._selectedReport.classList.add('active');
    }

    nav.appendChild(list);
  },

  setReport : function (report) {
    this._currentReport = report;
    var events = report['events'];
    var lastBugEvent = events[events.length - 1];
    this.setCurrentBugEvent(lastBugEvent, events.length - 1);
    this.setCheckerName(report.checkerName);
    this.setReviewStatus(report.reviewStatus);

    window.location.hash = '#reportHash=' + report.reportHash;
  },

  setCurrentBugEvent : function (event, idx) {
    this._currentBugEvent = event;
    this.setSourceFileData(this._files[event.location.file]);
    this.drawBugPath();

    this.jumpTo(event.location.line, 0);
    this.highlightBugEvent(event, idx);
  },

  highlightBugEvent : function (event, idx) {
    this._lineWidgets.forEach(function (widget) {
      var lineIdx = widget.node.getAttribute('idx');
      if (parseInt(lineIdx) === idx) {
        widget.node.classList.add('current');
      }
    });
  },

  setCheckerName : function (checkerName) {
    this._checkerName.innerHTML = checkerName;
  },

  setReviewStatus : function (status) {
    if (status) {
      var className =
        'review-status-' + status.toLowerCase().split(' ').join('-');
      this._reviewStatus.className = "review-status " + className;

      this._reviewStatus.innerHTML = status;
      this._reviewStatusWrapper.style.display = 'block';
    } else {
      this._reviewStatusWrapper.style.display = 'none';
    }
  },

  setSourceFileData : function (file) {
    if (this._sourceFileData && file.id === this._sourceFileData.id) {
      return;
    }

    this._sourceFileData = file;
    this._filepath.innerHTML = file.path;
    this._codeMirror.doc.setValue(file.content);
    this._refresh();
  },

  _refresh : function () {
    var that = this;
    setTimeout(function () {
      var fullHeight = parseInt(that._content.clientHeight);
      var headerHeight = that._filepath.clientHeight;

      that._codeMirror.setSize('auto', fullHeight - headerHeight);
      that._codeMirror.refresh();
    }, 200);
  },

  clearBubbles : function () {
    this._lineWidgets.forEach(function (widget) { widget.clear(); });
    this._lineWidgets = [];
  },

  getMessage : function (event, kind) {
    if (kind === 'macro') {
      var name = 'macro expansion' + (event.name ? ': ' + event.name : '');

      return '<span class="tag macro">' + name + '</span>'
        + this.escapeHTML(event.expansion).replace(/(?:\r\n|\r|\n)/g, '<br>');
    } else if (kind === 'note') {
      return '<span class="tag note">note</span>'
        +  this.escapeHTML(event.message).replace(/(?:\r\n|\r|\n)/g, '<br>');
    }
  },

  addExtraPathEvents : function (events, kind) {
    var that = this;

    if (!events) {
      return;
    }

    events.forEach(function (event) {
      if (event.location.file !== that._currentBugEvent.location.file) {
        return;
      }

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + kind);

      var msg = document.createElement('span');
      msg.innerHTML = that.getMessage(event, kind);
      element.appendChild(msg);

      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  drawBugPath : function () {
    var that = this;

    this.clearBubbles();

    this.addExtraPathEvents(this._currentReport.macros, 'macro');
    this.addExtraPathEvents(this._currentReport.notes, 'note');

    // Processing bug path events.
    var currentEvents = this._currentReport.events;
    currentEvents.forEach(function (event, step) {
      if (event.location.file !== that._currentBugEvent.location.file)
        return;

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';
      var type = step === currentEvents.length - 1 ? 'error' : 'info';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + type);
      element.setAttribute('idx', step);

      var enumeration = document.createElement('span');
      enumeration.setAttribute('class', 'checker-enum ' + type);
      enumeration.innerHTML = step + 1;

      if (currentEvents.length > 1)
        element.appendChild(enumeration);

      var prevBugEvent = step - 1;
      if (step > 0) {
        var prevBug = document.createElement('span');
        prevBug.setAttribute('class', 'arrow left-arrow');
        prevBug.addEventListener('click', function () {
          var event = currentEvents[prevBugEvent];
          that.setCurrentBugEvent(event, prevBugEvent);
        });
        element.appendChild(prevBug);
      }

      var msg = document.createElement('span');
      msg.innerHTML = that.escapeHTML(event.message)
        .replace(/(?:\r\n|\r|\n)/g, '<br>');

      element.appendChild(msg);

      var nextBugEvent = step + 1;
      if (nextBugEvent < currentEvents.length) {
        var nextBug = document.createElement('span');
        nextBug.setAttribute('class', 'arrow right-arrow');
        nextBug.addEventListener('click', function () {
          var event = currentEvents[nextBugEvent];
          that.setCurrentBugEvent(event, nextBugEvent);
        });
        element.appendChild(nextBug);
      }


      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  jumpTo : function (line, column) {
    var that = this;

    setTimeout(function () {
      var selPosPixel
        = that._codeMirror.charCoords({ line : line, ch : column }, 'local');
      var editorSize = {
        width  : that._editor.clientWidth,
        height : that._editor.clientHeight
      };

      that._codeMirror.scrollIntoView({
        top    : selPosPixel.top - 100,
        bottom : selPosPixel.top + editorSize.height - 150,
        left   : selPosPixel.left < editorSize.width - 100
               ? 0
               : selPosPixel.left - 50,
        right  : selPosPixel.left < editorSize.width - 100
               ? 10
               : selPosPixel.left + editorSize.width - 100
      });
    }, 0);
  }
}


      var data = {"files": {"1": {"id": 1, "path": "/src/include/linux/printk.h", "content": "/* SPDX-License-Identifier: GPL-2.0 */\n#ifndef __KERNEL_PRINTK__\n#define __KERNEL_PRINTK__\n\n#include <stdarg.h>\n#include <linux/init.h>\n#include <linux/kern_levels.h>\n#include <linux/linkage.h>\n#include <linux/cache.h>\n#include <linux/ratelimit_types.h>\n\nextern const char linux_banner[];\nextern const char linux_proc_banner[];\n\nextern int oops_in_progress;\t/* If set, an oops, panic(), BUG() or die() is in progress */\n\n#define PRINTK_MAX_SINGLE_HEADER_LEN 2\n\nstatic inline int printk_get_level(const char *buffer)\n{\n\tif (buffer[0] == KERN_SOH_ASCII && buffer[1]) {\n\t\tswitch (buffer[1]) {\n\t\tcase '0' ... '7':\n\t\tcase 'c':\t/* KERN_CONT */\n\t\t\treturn buffer[1];\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic inline const char *printk_skip_level(const char *buffer)\n{\n\tif (printk_get_level(buffer))\n\t\treturn buffer + 2;\n\n\treturn buffer;\n}\n\nstatic inline const char *printk_skip_headers(const char *buffer)\n{\n\twhile (printk_get_level(buffer))\n\t\tbuffer = printk_skip_level(buffer);\n\n\treturn buffer;\n}\n\n#define CONSOLE_EXT_LOG_MAX\t8192\n\n/* printk's without a loglevel use this.. */\n#define MESSAGE_LOGLEVEL_DEFAULT CONFIG_MESSAGE_LOGLEVEL_DEFAULT\n\n/* We show everything that is MORE important than this.. */\n#define CONSOLE_LOGLEVEL_SILENT  0 /* Mum's the word */\n#define CONSOLE_LOGLEVEL_MIN\t 1 /* Minimum loglevel we let people use */\n#define CONSOLE_LOGLEVEL_DEBUG\t10 /* issue debug messages */\n#define CONSOLE_LOGLEVEL_MOTORMOUTH 15\t/* You can't shut this one up */\n\n/*\n * Default used to be hard-coded at 7, quiet used to be hardcoded at 4,\n * we're now allowing both to be set from kernel config.\n */\n#define CONSOLE_LOGLEVEL_DEFAULT CONFIG_CONSOLE_LOGLEVEL_DEFAULT\n#define CONSOLE_LOGLEVEL_QUIET\t CONFIG_CONSOLE_LOGLEVEL_QUIET\n\nextern int console_printk[];\n\n#define console_loglevel (console_printk[0])\n#define default_message_loglevel (console_printk[1])\n#define minimum_console_loglevel (console_printk[2])\n#define default_console_loglevel (console_printk[3])\n\nstatic inline void console_silent(void)\n{\n\tconsole_loglevel = CONSOLE_LOGLEVEL_SILENT;\n}\n\nstatic inline void console_verbose(void)\n{\n\tif (console_loglevel)\n\t\tconsole_loglevel = CONSOLE_LOGLEVEL_MOTORMOUTH;\n}\n\n/* strlen(\"ratelimit\") + 1 */\n#define DEVKMSG_STR_MAX_SIZE 10\nextern char devkmsg_log_str[];\nstruct ctl_table;\n\nextern int suppress_printk;\n\nstruct va_format {\n\tconst char *fmt;\n\tva_list *va;\n};\n\n/*\n * FW_BUG\n * Add this to a message where you are sure the firmware is buggy or behaves\n * really stupid or out of spec. Be aware that the responsible BIOS developer\n * should be able to fix this issue or at least get a concrete idea of the\n * problem by reading your message without the need of looking at the kernel\n * code.\n *\n * Use it for definite and high priority BIOS bugs.\n *\n * FW_WARN\n * Use it for not that clear (e.g. could the kernel messed up things already?)\n * and medium priority BIOS bugs.\n *\n * FW_INFO\n * Use this one if you want to tell the user or vendor about something\n * suspicious, but generally harmless related to the firmware.\n *\n * Use it for information or very low priority BIOS bugs.\n */\n#define FW_BUG\t\t\"[Firmware Bug]: \"\n#define FW_WARN\t\t\"[Firmware Warn]: \"\n#define FW_INFO\t\t\"[Firmware Info]: \"\n\n/*\n * HW_ERR\n * Add this to a message for hardware errors, so that user can report\n * it to hardware vendor instead of LKML or software vendor.\n */\n#define HW_ERR\t\t\"[Hardware Error]: \"\n\n/*\n * DEPRECATED\n * Add this to a message whenever you want to warn user space about the use\n * of a deprecated aspect of an API so they can stop using it\n */\n#define DEPRECATED\t\"[Deprecated]: \"\n\n/*\n * Dummy printk for disabled debugging statements to use whilst maintaining\n * gcc's format checking.\n */\n#define no_printk(fmt, ...)\t\t\t\t\\\n({\t\t\t\t\t\t\t\\\n\tif (0)\t\t\t\t\t\t\\\n\t\tprintk(fmt, ##__VA_ARGS__);\t\t\\\n\t0;\t\t\t\t\t\t\\\n})\n\n#ifdef CONFIG_EARLY_PRINTK\nextern asmlinkage __printf(1, 2)\nvoid early_printk(const char *fmt, ...);\n#else\nstatic inline __printf(1, 2) __cold\nvoid early_printk(const char *s, ...) { }\n#endif\n\n#ifdef CONFIG_PRINTK_NMI\nextern void printk_nmi_enter(void);\nextern void printk_nmi_exit(void);\nextern void printk_nmi_direct_enter(void);\nextern void printk_nmi_direct_exit(void);\n#else\nstatic inline void printk_nmi_enter(void) { }\nstatic inline void printk_nmi_exit(void) { }\nstatic inline void printk_nmi_direct_enter(void) { }\nstatic inline void printk_nmi_direct_exit(void) { }\n#endif /* PRINTK_NMI */\n\nstruct dev_printk_info;\n\n#ifdef CONFIG_PRINTK\nasmlinkage __printf(4, 0)\nint vprintk_emit(int facility, int level,\n\t\t const struct dev_printk_info *dev_info,\n\t\t const char *fmt, va_list args);\n\nasmlinkage __printf(1, 0)\nint vprintk(const char *fmt, va_list args);\n\nasmlinkage __printf(1, 2) __cold\nint printk(const char *fmt, ...);\n\n/*\n * Special printk facility for scheduler/timekeeping use only, _DO_NOT_USE_ !\n */\n__printf(1, 2) __cold int printk_deferred(const char *fmt, ...);\n\n/*\n * Please don't use printk_ratelimit(), because it shares ratelimiting state\n * with all other unrelated printk_ratelimit() callsites.  Instead use\n * printk_ratelimited() or plain old __ratelimit().\n */\nextern int __printk_ratelimit(const char *func);\n#define printk_ratelimit() __printk_ratelimit(__func__)\nextern bool printk_timed_ratelimit(unsigned long *caller_jiffies,\n\t\t\t\t   unsigned int interval_msec);\n\nextern int printk_delay_msec;\nextern int dmesg_restrict;\n\nextern int\ndevkmsg_sysctl_set_loglvl(struct ctl_table *table, int write, void *buf,\n\t\t\t  size_t *lenp, loff_t *ppos);\n\nextern void wake_up_klogd(void);\n\nchar *log_buf_addr_get(void);\nu32 log_buf_len_get(void);\nvoid log_buf_vmcoreinfo_setup(void);\nvoid __init setup_log_buf(int early);\n__printf(1, 2) void dump_stack_set_arch_desc(const char *fmt, ...);\nvoid dump_stack_print_info(const char *log_lvl);\nvoid show_regs_print_info(const char *log_lvl);\nextern asmlinkage void dump_stack(void) __cold;\nextern void printk_safe_flush(void);\nextern void printk_safe_flush_on_panic(void);\n#else\nstatic inline __printf(1, 0)\nint vprintk(const char *s, va_list args)\n{\n\treturn 0;\n}\nstatic inline __printf(1, 2) __cold\nint printk(const char *s, ...)\n{\n\treturn 0;\n}\nstatic inline __printf(1, 2) __cold\nint printk_deferred(const char *s, ...)\n{\n\treturn 0;\n}\nstatic inline int printk_ratelimit(void)\n{\n\treturn 0;\n}\nstatic inline bool printk_timed_ratelimit(unsigned long *caller_jiffies,\n\t\t\t\t\t  unsigned int interval_msec)\n{\n\treturn false;\n}\n\nstatic inline void wake_up_klogd(void)\n{\n}\n\nstatic inline char *log_buf_addr_get(void)\n{\n\treturn NULL;\n}\n\nstatic inline u32 log_buf_len_get(void)\n{\n\treturn 0;\n}\n\nstatic inline void log_buf_vmcoreinfo_setup(void)\n{\n}\n\nstatic inline void setup_log_buf(int early)\n{\n}\n\nstatic inline __printf(1, 2) void dump_stack_set_arch_desc(const char *fmt, ...)\n{\n}\n\nstatic inline void dump_stack_print_info(const char *log_lvl)\n{\n}\n\nstatic inline void show_regs_print_info(const char *log_lvl)\n{\n}\n\nstatic inline void dump_stack(void)\n{\n}\n\nstatic inline void printk_safe_flush(void)\n{\n}\n\nstatic inline void printk_safe_flush_on_panic(void)\n{\n}\n#endif\n\nextern int kptr_restrict;\n\n/**\n * pr_fmt - used by the pr_*() macros to generate the printk format string\n * @fmt: format string passed from a pr_*() macro\n *\n * This macro can be used to generate a unified format string for pr_*()\n * macros. A common use is to prefix all pr_*() messages in a file with a common\n * string. For example, defining this at the top of a source file:\n *\n *        #define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n *\n * would prefix all pr_info, pr_emerg... messages in the file with the module\n * name.\n */\n#ifndef pr_fmt\n#define pr_fmt(fmt) fmt\n#endif\n\n/**\n * pr_emerg - Print an emergency-level message\n * @fmt: format string\n * @...: arguments for the format string\n *\n * This macro expands to a printk with KERN_EMERG loglevel. It uses pr_fmt() to\n * generate the format string.\n */\n#define pr_emerg(fmt, ...) \\\n\tprintk(KERN_EMERG pr_fmt(fmt), ##__VA_ARGS__)\n/**\n * pr_alert - Print an alert-level message\n * @fmt: format string\n * @...: arguments for the format string\n *\n * This macro expands to a printk with KERN_ALERT loglevel. It uses pr_fmt() to\n * generate the format string.\n */\n#define pr_alert(fmt, ...) \\\n\tprintk(KERN_ALERT pr_fmt(fmt), ##__VA_ARGS__)\n/**\n * pr_crit - Print a critical-level message\n * @fmt: format string\n * @...: arguments for the format string\n *\n * This macro expands to a printk with KERN_CRIT loglevel. It uses pr_fmt() to\n * generate the format string.\n */\n#define pr_crit(fmt, ...) \\\n\tprintk(KERN_CRIT pr_fmt(fmt), ##__VA_ARGS__)\n/**\n * pr_err - Print an error-level message\n * @fmt: format string\n * @...: arguments for the format string\n *\n * This macro expands to a printk with KERN_ERR loglevel. It uses pr_fmt() to\n * generate the format string.\n */\n#define pr_err(fmt, ...) \\\n\tprintk(KERN_ERR pr_fmt(fmt), ##__VA_ARGS__)\n/**\n * pr_warn - Print a warning-level message\n * @fmt: format string\n * @...: arguments for the format string\n *\n * This macro expands to a printk with KERN_WARNING loglevel. It uses pr_fmt()\n * to generate the format string.\n */\n#define pr_warn(fmt, ...) \\\n\tprintk(KERN_WARNING pr_fmt(fmt), ##__VA_ARGS__)\n/**\n * pr_notice - Print a notice-level message\n * @fmt: format string\n * @...: arguments for the format string\n *\n * This macro expands to a printk with KERN_NOTICE loglevel. It uses pr_fmt() to\n * generate the format string.\n */\n#define pr_notice(fmt, ...) \\\n\tprintk(KERN_NOTICE pr_fmt(fmt), ##__VA_ARGS__)\n/**\n * pr_info - Print an info-level message\n * @fmt: format string\n * @...: arguments for the format string\n *\n * This macro expands to a printk with KERN_INFO loglevel. It uses pr_fmt() to\n * generate the format string.\n */\n#define pr_info(fmt, ...) \\\n\tprintk(KERN_INFO pr_fmt(fmt), ##__VA_ARGS__)\n\n/**\n * pr_cont - Continues a previous log message in the same line.\n * @fmt: format string\n * @...: arguments for the format string\n *\n * This macro expands to a printk with KERN_CONT loglevel. It should only be\n * used when continuing a log message with no newline ('\\n') enclosed. Otherwise\n * it defaults back to KERN_DEFAULT loglevel.\n */\n#define pr_cont(fmt, ...) \\\n\tprintk(KERN_CONT fmt, ##__VA_ARGS__)\n\n/**\n * pr_devel - Print a debug-level message conditionally\n * @fmt: format string\n * @...: arguments for the format string\n *\n * This macro expands to a printk with KERN_DEBUG loglevel if DEBUG is\n * defined. Otherwise it does nothing.\n *\n * It uses pr_fmt() to generate the format string.\n */\n#ifdef DEBUG\n#define pr_devel(fmt, ...) \\\n\tprintk(KERN_DEBUG pr_fmt(fmt), ##__VA_ARGS__)\n#else\n#define pr_devel(fmt, ...) \\\n\tno_printk(KERN_DEBUG pr_fmt(fmt), ##__VA_ARGS__)\n#endif\n\n\n/* If you are writing a driver, please use dev_dbg instead */\n#if defined(CONFIG_DYNAMIC_DEBUG) || \\\n\t(defined(CONFIG_DYNAMIC_DEBUG_CORE) && defined(DYNAMIC_DEBUG_MODULE))\n#include <linux/dynamic_debug.h>\n\n/**\n * pr_debug - Print a debug-level message conditionally\n * @fmt: format string\n * @...: arguments for the format string\n *\n * This macro expands to dynamic_pr_debug() if CONFIG_DYNAMIC_DEBUG is\n * set. Otherwise, if DEBUG is defined, it's equivalent to a printk with\n * KERN_DEBUG loglevel. If DEBUG is not defined it does nothing.\n *\n * It uses pr_fmt() to generate the format string (dynamic_pr_debug() uses\n * pr_fmt() internally).\n */\n#define pr_debug(fmt, ...)\t\t\t\\\n\tdynamic_pr_debug(fmt, ##__VA_ARGS__)\n#elif defined(DEBUG)\n#define pr_debug(fmt, ...) \\\n\tprintk(KERN_DEBUG pr_fmt(fmt), ##__VA_ARGS__)\n#else\n#define pr_debug(fmt, ...) \\\n\tno_printk(KERN_DEBUG pr_fmt(fmt), ##__VA_ARGS__)\n#endif\n\n/*\n * Print a one-time message (analogous to WARN_ONCE() et al):\n */\n\n#ifdef CONFIG_PRINTK\n#define printk_once(fmt, ...)\t\t\t\t\t\\\n({\t\t\t\t\t\t\t\t\\\n\tstatic bool __section(\".data.once\") __print_once;\t\\\n\tbool __ret_print_once = !__print_once;\t\t\t\\\n\t\t\t\t\t\t\t\t\\\n\tif (!__print_once) {\t\t\t\t\t\\\n\t\t__print_once = true;\t\t\t\t\\\n\t\tprintk(fmt, ##__VA_ARGS__);\t\t\t\\\n\t}\t\t\t\t\t\t\t\\\n\tunlikely(__ret_print_once);\t\t\t\t\\\n})\n#define printk_deferred_once(fmt, ...)\t\t\t\t\\\n({\t\t\t\t\t\t\t\t\\\n\tstatic bool __section(\".data.once\") __print_once;\t\\\n\tbool __ret_print_once = !__print_once;\t\t\t\\\n\t\t\t\t\t\t\t\t\\\n\tif (!__print_once) {\t\t\t\t\t\\\n\t\t__print_once = true;\t\t\t\t\\\n\t\tprintk_deferred(fmt, ##__VA_ARGS__);\t\t\\\n\t}\t\t\t\t\t\t\t\\\n\tunlikely(__ret_print_once);\t\t\t\t\\\n})\n#else\n#define printk_once(fmt, ...)\t\t\t\t\t\\\n\tno_printk(fmt, ##__VA_ARGS__)\n#define printk_deferred_once(fmt, ...)\t\t\t\t\\\n\tno_printk(fmt, ##__VA_ARGS__)\n#endif\n\n#define pr_emerg_once(fmt, ...)\t\t\t\t\t\\\n\tprintk_once(KERN_EMERG pr_fmt(fmt), ##__VA_ARGS__)\n#define pr_alert_once(fmt, ...)\t\t\t\t\t\\\n\tprintk_once(KERN_ALERT pr_fmt(fmt), ##__VA_ARGS__)\n#define pr_crit_once(fmt, ...)\t\t\t\t\t\\\n\tprintk_once(KERN_CRIT pr_fmt(fmt), ##__VA_ARGS__)\n#define pr_err_once(fmt, ...)\t\t\t\t\t\\\n\tprintk_once(KERN_ERR pr_fmt(fmt), ##__VA_ARGS__)\n#define pr_warn_once(fmt, ...)\t\t\t\t\t\\\n\tprintk_once(KERN_WARNING pr_fmt(fmt), ##__VA_ARGS__)\n#define pr_notice_once(fmt, ...)\t\t\t\t\\\n\tprintk_once(KERN_NOTICE pr_fmt(fmt), ##__VA_ARGS__)\n#define pr_info_once(fmt, ...)\t\t\t\t\t\\\n\tprintk_once(KERN_INFO pr_fmt(fmt), ##__VA_ARGS__)\n/* no pr_cont_once, don't do that... */\n\n#if defined(DEBUG)\n#define pr_devel_once(fmt, ...)\t\t\t\t\t\\\n\tprintk_once(KERN_DEBUG pr_fmt(fmt), ##__VA_ARGS__)\n#else\n#define pr_devel_once(fmt, ...)\t\t\t\t\t\\\n\tno_printk(KERN_DEBUG pr_fmt(fmt), ##__VA_ARGS__)\n#endif\n\n/* If you are writing a driver, please use dev_dbg instead */\n#if defined(DEBUG)\n#define pr_debug_once(fmt, ...)\t\t\t\t\t\\\n\tprintk_once(KERN_DEBUG pr_fmt(fmt), ##__VA_ARGS__)\n#else\n#define pr_debug_once(fmt, ...)\t\t\t\t\t\\\n\tno_printk(KERN_DEBUG pr_fmt(fmt), ##__VA_ARGS__)\n#endif\n\n/*\n * ratelimited messages with local ratelimit_state,\n * no local ratelimit_state used in the !PRINTK case\n */\n#ifdef CONFIG_PRINTK\n#define printk_ratelimited(fmt, ...)\t\t\t\t\t\\\n({\t\t\t\t\t\t\t\t\t\\\n\tstatic DEFINE_RATELIMIT_STATE(_rs,\t\t\t\t\\\n\t\t\t\t      DEFAULT_RATELIMIT_INTERVAL,\t\\\n\t\t\t\t      DEFAULT_RATELIMIT_BURST);\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tif (__ratelimit(&_rs))\t\t\t\t\t\t\\\n\t\tprintk(fmt, ##__VA_ARGS__);\t\t\t\t\\\n})\n#else\n#define printk_ratelimited(fmt, ...)\t\t\t\t\t\\\n\tno_printk(fmt, ##__VA_ARGS__)\n#endif\n\n#define pr_emerg_ratelimited(fmt, ...)\t\t\t\t\t\\\n\tprintk_ratelimited(KERN_EMERG pr_fmt(fmt), ##__VA_ARGS__)\n#define pr_alert_ratelimited(fmt, ...)\t\t\t\t\t\\\n\tprintk_ratelimited(KERN_ALERT pr_fmt(fmt), ##__VA_ARGS__)\n#define pr_crit_ratelimited(fmt, ...)\t\t\t\t\t\\\n\tprintk_ratelimited(KERN_CRIT pr_fmt(fmt), ##__VA_ARGS__)\n#define pr_err_ratelimited(fmt, ...)\t\t\t\t\t\\\n\tprintk_ratelimited(KERN_ERR pr_fmt(fmt), ##__VA_ARGS__)\n#define pr_warn_ratelimited(fmt, ...)\t\t\t\t\t\\\n\tprintk_ratelimited(KERN_WARNING pr_fmt(fmt), ##__VA_ARGS__)\n#define pr_notice_ratelimited(fmt, ...)\t\t\t\t\t\\\n\tprintk_ratelimited(KERN_NOTICE pr_fmt(fmt), ##__VA_ARGS__)\n#define pr_info_ratelimited(fmt, ...)\t\t\t\t\t\\\n\tprintk_ratelimited(KERN_INFO pr_fmt(fmt), ##__VA_ARGS__)\n/* no pr_cont_ratelimited, don't do that... */\n\n#if defined(DEBUG)\n#define pr_devel_ratelimited(fmt, ...)\t\t\t\t\t\\\n\tprintk_ratelimited(KERN_DEBUG pr_fmt(fmt), ##__VA_ARGS__)\n#else\n#define pr_devel_ratelimited(fmt, ...)\t\t\t\t\t\\\n\tno_printk(KERN_DEBUG pr_fmt(fmt), ##__VA_ARGS__)\n#endif\n\n/* If you are writing a driver, please use dev_dbg instead */\n#if defined(CONFIG_DYNAMIC_DEBUG) || \\\n\t(defined(CONFIG_DYNAMIC_DEBUG_CORE) && defined(DYNAMIC_DEBUG_MODULE))\n/* descriptor check is first to prevent flooding with \"callbacks suppressed\" */\n#define pr_debug_ratelimited(fmt, ...)\t\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tstatic DEFINE_RATELIMIT_STATE(_rs,\t\t\t\t\\\n\t\t\t\t      DEFAULT_RATELIMIT_INTERVAL,\t\\\n\t\t\t\t      DEFAULT_RATELIMIT_BURST);\t\t\\\n\tDEFINE_DYNAMIC_DEBUG_METADATA(descriptor, pr_fmt(fmt));\t\t\\\n\tif (DYNAMIC_DEBUG_BRANCH(descriptor) &&\t\t\t\t\\\n\t    __ratelimit(&_rs))\t\t\t\t\t\t\\\n\t\t__dynamic_pr_debug(&descriptor, pr_fmt(fmt), ##__VA_ARGS__);\t\\\n} while (0)\n#elif defined(DEBUG)\n#define pr_debug_ratelimited(fmt, ...)\t\t\t\t\t\\\n\tprintk_ratelimited(KERN_DEBUG pr_fmt(fmt), ##__VA_ARGS__)\n#else\n#define pr_debug_ratelimited(fmt, ...) \\\n\tno_printk(KERN_DEBUG pr_fmt(fmt), ##__VA_ARGS__)\n#endif\n\nextern const struct file_operations kmsg_fops;\n\nenum {\n\tDUMP_PREFIX_NONE,\n\tDUMP_PREFIX_ADDRESS,\n\tDUMP_PREFIX_OFFSET\n};\nextern int hex_dump_to_buffer(const void *buf, size_t len, int rowsize,\n\t\t\t      int groupsize, char *linebuf, size_t linebuflen,\n\t\t\t      bool ascii);\n#ifdef CONFIG_PRINTK\nextern void print_hex_dump(const char *level, const char *prefix_str,\n\t\t\t   int prefix_type, int rowsize, int groupsize,\n\t\t\t   const void *buf, size_t len, bool ascii);\n#else\nstatic inline void print_hex_dump(const char *level, const char *prefix_str,\n\t\t\t\t  int prefix_type, int rowsize, int groupsize,\n\t\t\t\t  const void *buf, size_t len, bool ascii)\n{\n}\nstatic inline void print_hex_dump_bytes(const char *prefix_str, int prefix_type,\n\t\t\t\t\tconst void *buf, size_t len)\n{\n}\n\n#endif\n\n#if defined(CONFIG_DYNAMIC_DEBUG) || \\\n\t(defined(CONFIG_DYNAMIC_DEBUG_CORE) && defined(DYNAMIC_DEBUG_MODULE))\n#define print_hex_dump_debug(prefix_str, prefix_type, rowsize,\t\\\n\t\t\t     groupsize, buf, len, ascii)\t\\\n\tdynamic_hex_dump(prefix_str, prefix_type, rowsize,\t\\\n\t\t\t groupsize, buf, len, ascii)\n#elif defined(DEBUG)\n#define print_hex_dump_debug(prefix_str, prefix_type, rowsize,\t\t\\\n\t\t\t     groupsize, buf, len, ascii)\t\t\\\n\tprint_hex_dump(KERN_DEBUG, prefix_str, prefix_type, rowsize,\t\\\n\t\t       groupsize, buf, len, ascii)\n#else\nstatic inline void print_hex_dump_debug(const char *prefix_str, int prefix_type,\n\t\t\t\t\tint rowsize, int groupsize,\n\t\t\t\t\tconst void *buf, size_t len, bool ascii)\n{\n}\n#endif\n\n/**\n * print_hex_dump_bytes - shorthand form of print_hex_dump() with default params\n * @prefix_str: string to prefix each line with;\n *  caller supplies trailing spaces for alignment if desired\n * @prefix_type: controls whether prefix of an offset, address, or none\n *  is printed (%DUMP_PREFIX_OFFSET, %DUMP_PREFIX_ADDRESS, %DUMP_PREFIX_NONE)\n * @buf: data blob to dump\n * @len: number of bytes in the @buf\n *\n * Calls print_hex_dump(), with log level of KERN_DEBUG,\n * rowsize of 16, groupsize of 1, and ASCII output included.\n */\n#define print_hex_dump_bytes(prefix_str, prefix_type, buf, len)\t\\\n\tprint_hex_dump_debug(prefix_str, prefix_type, 16, 1, buf, len, true)\n\n#endif\n"}, "0": {"id": 0, "path": "/src/drivers/scsi/sg.c", "content": "// SPDX-License-Identifier: GPL-2.0-or-later\n/*\n *  History:\n *  Started: Aug 9 by Lawrence Foard (entropy@world.std.com),\n *           to allow user process control of SCSI devices.\n *  Development Sponsored by Killy Corp. NY NY\n *\n * Original driver (sg.c):\n *        Copyright (C) 1992 Lawrence Foard\n * Version 2 and 3 extensions to driver:\n *        Copyright (C) 1998 - 2014 Douglas Gilbert\n */\n\nstatic int sg_version_num = 30536;\t/* 2 digits for each component */\n#define SG_VERSION_STR \"3.5.36\"\n\n/*\n *  D. P. Gilbert (dgilbert@interlog.com), notes:\n *      - scsi logging is available via SCSI_LOG_TIMEOUT macros. First\n *        the kernel/module needs to be built with CONFIG_SCSI_LOGGING\n *        (otherwise the macros compile to empty statements).\n *\n */\n#include <linux/module.h>\n\n#include <linux/fs.h>\n#include <linux/kernel.h>\n#include <linux/sched.h>\n#include <linux/string.h>\n#include <linux/mm.h>\n#include <linux/errno.h>\n#include <linux/mtio.h>\n#include <linux/ioctl.h>\n#include <linux/slab.h>\n#include <linux/fcntl.h>\n#include <linux/init.h>\n#include <linux/poll.h>\n#include <linux/moduleparam.h>\n#include <linux/cdev.h>\n#include <linux/idr.h>\n#include <linux/seq_file.h>\n#include <linux/blkdev.h>\n#include <linux/delay.h>\n#include <linux/blktrace_api.h>\n#include <linux/mutex.h>\n#include <linux/atomic.h>\n#include <linux/ratelimit.h>\n#include <linux/uio.h>\n#include <linux/cred.h> /* for sg_check_file_access() */\n\n#include \"scsi.h\"\n#include <scsi/scsi_dbg.h>\n#include <scsi/scsi_host.h>\n#include <scsi/scsi_driver.h>\n#include <scsi/scsi_ioctl.h>\n#include <scsi/sg.h>\n\n#include \"scsi_logging.h\"\n\n#ifdef CONFIG_SCSI_PROC_FS\n#include <linux/proc_fs.h>\nstatic char *sg_version_date = \"20140603\";\n\nstatic int sg_proc_init(void);\n#endif\n\n#define SG_ALLOW_DIO_DEF 0\n\n#define SG_MAX_DEVS 32768\n\n/* SG_MAX_CDB_SIZE should be 260 (spc4r37 section 3.1.30) however the type\n * of sg_io_hdr::cmd_len can only represent 255. All SCSI commands greater\n * than 16 bytes are \"variable length\" whose length is a multiple of 4\n */\n#define SG_MAX_CDB_SIZE 252\n\n#define SG_DEFAULT_TIMEOUT mult_frac(SG_DEFAULT_TIMEOUT_USER, HZ, USER_HZ)\n\nint sg_big_buff = SG_DEF_RESERVED_SIZE;\n/* N.B. This variable is readable and writeable via\n   /proc/scsi/sg/def_reserved_size . Each time sg_open() is called a buffer\n   of this size (or less if there is not enough memory) will be reserved\n   for use by this file descriptor. [Deprecated usage: this variable is also\n   readable via /proc/sys/kernel/sg-big-buff if the sg driver is built into\n   the kernel (i.e. it is not a module).] */\nstatic int def_reserved_size = -1;\t/* picks up init parameter */\nstatic int sg_allow_dio = SG_ALLOW_DIO_DEF;\n\nstatic int scatter_elem_sz = SG_SCATTER_SZ;\nstatic int scatter_elem_sz_prev = SG_SCATTER_SZ;\n\n#define SG_SECTOR_SZ 512\n\nstatic int sg_add_device(struct device *, struct class_interface *);\nstatic void sg_remove_device(struct device *, struct class_interface *);\n\nstatic DEFINE_IDR(sg_index_idr);\nstatic DEFINE_RWLOCK(sg_index_lock);\t/* Also used to lock\n\t\t\t\t\t\t\t   file descriptor list for device */\n\nstatic struct class_interface sg_interface = {\n\t.add_dev        = sg_add_device,\n\t.remove_dev     = sg_remove_device,\n};\n\ntypedef struct sg_scatter_hold { /* holding area for scsi scatter gather info */\n\tunsigned short k_use_sg; /* Count of kernel scatter-gather pieces */\n\tunsigned sglist_len; /* size of malloc'd scatter-gather list ++ */\n\tunsigned bufflen;\t/* Size of (aggregate) data buffer */\n\tstruct page **pages;\n\tint page_order;\n\tchar dio_in_use;\t/* 0->indirect IO (or mmap), 1->dio */\n\tunsigned char cmd_opcode; /* first byte of command */\n} Sg_scatter_hold;\n\nstruct sg_device;\t\t/* forward declarations */\nstruct sg_fd;\n\ntypedef struct sg_request {\t/* SG_MAX_QUEUE requests outstanding per file */\n\tstruct list_head entry;\t/* list entry */\n\tstruct sg_fd *parentfp;\t/* NULL -> not in use */\n\tSg_scatter_hold data;\t/* hold buffer, perhaps scatter list */\n\tsg_io_hdr_t header;\t/* scsi command+info, see <scsi/sg.h> */\n\tunsigned char sense_b[SCSI_SENSE_BUFFERSIZE];\n\tchar res_used;\t\t/* 1 -> using reserve buffer, 0 -> not ... */\n\tchar orphan;\t\t/* 1 -> drop on sight, 0 -> normal */\n\tchar sg_io_owned;\t/* 1 -> packet belongs to SG_IO */\n\t/* done protected by rq_list_lock */\n\tchar done;\t\t/* 0->before bh, 1->before read, 2->read */\n\tstruct request *rq;\n\tstruct bio *bio;\n\tstruct execute_work ew;\n} Sg_request;\n\ntypedef struct sg_fd {\t\t/* holds the state of a file descriptor */\n\tstruct list_head sfd_siblings;  /* protected by device's sfd_lock */\n\tstruct sg_device *parentdp;\t/* owning device */\n\twait_queue_head_t read_wait;\t/* queue read until command done */\n\trwlock_t rq_list_lock;\t/* protect access to list in req_arr */\n\tstruct mutex f_mutex;\t/* protect against changes in this fd */\n\tint timeout;\t\t/* defaults to SG_DEFAULT_TIMEOUT      */\n\tint timeout_user;\t/* defaults to SG_DEFAULT_TIMEOUT_USER */\n\tSg_scatter_hold reserve;\t/* buffer held for this file descriptor */\n\tstruct list_head rq_list; /* head of request list */\n\tstruct fasync_struct *async_qp;\t/* used by asynchronous notification */\n\tSg_request req_arr[SG_MAX_QUEUE];\t/* used as singly-linked list */\n\tchar force_packid;\t/* 1 -> pack_id input to read(), 0 -> ignored */\n\tchar cmd_q;\t\t/* 1 -> allow command queuing, 0 -> don't */\n\tunsigned char next_cmd_len; /* 0: automatic, >0: use on next write() */\n\tchar keep_orphan;\t/* 0 -> drop orphan (def), 1 -> keep for read() */\n\tchar mmap_called;\t/* 0 -> mmap() never called on this fd */\n\tchar res_in_use;\t/* 1 -> 'reserve' array in use */\n\tstruct kref f_ref;\n\tstruct execute_work ew;\n} Sg_fd;\n\ntypedef struct sg_device { /* holds the state of each scsi generic device */\n\tstruct scsi_device *device;\n\twait_queue_head_t open_wait;    /* queue open() when O_EXCL present */\n\tstruct mutex open_rel_lock;     /* held when in open() or release() */\n\tint sg_tablesize;\t/* adapter's max scatter-gather table size */\n\tu32 index;\t\t/* device index number */\n\tstruct list_head sfds;\n\trwlock_t sfd_lock;      /* protect access to sfd list */\n\tatomic_t detaching;     /* 0->device usable, 1->device detaching */\n\tbool exclude;\t\t/* 1->open(O_EXCL) succeeded and is active */\n\tint open_cnt;\t\t/* count of opens (perhaps < num(sfds) ) */\n\tchar sgdebug;\t\t/* 0->off, 1->sense, 9->dump dev, 10-> all devs */\n\tstruct gendisk *disk;\n\tstruct cdev * cdev;\t/* char_dev [sysfs: /sys/cdev/major/sg<n>] */\n\tstruct kref d_ref;\n} Sg_device;\n\n/* tasklet or soft irq callback */\nstatic void sg_rq_end_io(struct request *rq, blk_status_t status);\nstatic int sg_start_req(Sg_request *srp, unsigned char *cmd);\nstatic int sg_finish_rem_req(Sg_request * srp);\nstatic int sg_build_indirect(Sg_scatter_hold * schp, Sg_fd * sfp, int buff_size);\nstatic ssize_t sg_new_read(Sg_fd * sfp, char __user *buf, size_t count,\n\t\t\t   Sg_request * srp);\nstatic ssize_t sg_new_write(Sg_fd *sfp, struct file *file,\n\t\t\tconst char __user *buf, size_t count, int blocking,\n\t\t\tint read_only, int sg_io_owned, Sg_request **o_srp);\nstatic int sg_common_write(Sg_fd * sfp, Sg_request * srp,\n\t\t\t   unsigned char *cmnd, int timeout, int blocking);\nstatic int sg_read_oxfer(Sg_request * srp, char __user *outp, int num_read_xfer);\nstatic void sg_remove_scat(Sg_fd * sfp, Sg_scatter_hold * schp);\nstatic void sg_build_reserve(Sg_fd * sfp, int req_size);\nstatic void sg_link_reserve(Sg_fd * sfp, Sg_request * srp, int size);\nstatic void sg_unlink_reserve(Sg_fd * sfp, Sg_request * srp);\nstatic Sg_fd *sg_add_sfp(Sg_device * sdp);\nstatic void sg_remove_sfp(struct kref *);\nstatic Sg_request *sg_get_rq_mark(Sg_fd * sfp, int pack_id);\nstatic Sg_request *sg_add_request(Sg_fd * sfp);\nstatic int sg_remove_request(Sg_fd * sfp, Sg_request * srp);\nstatic Sg_device *sg_get_dev(int dev);\nstatic void sg_device_destroy(struct kref *kref);\n\n#define SZ_SG_HEADER sizeof(struct sg_header)\n#define SZ_SG_IO_HDR sizeof(sg_io_hdr_t)\n#define SZ_SG_IOVEC sizeof(sg_iovec_t)\n#define SZ_SG_REQ_INFO sizeof(sg_req_info_t)\n\n#define sg_printk(prefix, sdp, fmt, a...) \\\n\tsdev_prefix_printk(prefix, (sdp)->device,\t\t\\\n\t\t\t   (sdp)->disk->disk_name, fmt, ##a)\n\n/*\n * The SCSI interfaces that use read() and write() as an asynchronous variant of\n * ioctl(..., SG_IO, ...) are fundamentally unsafe, since there are lots of ways\n * to trigger read() and write() calls from various contexts with elevated\n * privileges. This can lead to kernel memory corruption (e.g. if these\n * interfaces are called through splice()) and privilege escalation inside\n * userspace (e.g. if a process with access to such a device passes a file\n * descriptor to a SUID binary as stdin/stdout/stderr).\n *\n * This function provides protection for the legacy API by restricting the\n * calling context.\n */\nstatic int sg_check_file_access(struct file *filp, const char *caller)\n{\n\tif (filp->f_cred != current_real_cred()) {\n\t\tpr_err_once(\"%s: process %d (%s) changed security contexts after opening file descriptor, this is not allowed.\\n\",\n\t\t\tcaller, task_tgid_vnr(current), current->comm);\n\t\treturn -EPERM;\n\t}\n\tif (uaccess_kernel()) {\n\t\tpr_err_once(\"%s: process %d (%s) called from kernel context, this is not allowed.\\n\",\n\t\t\tcaller, task_tgid_vnr(current), current->comm);\n\t\treturn -EACCES;\n\t}\n\treturn 0;\n}\n\nstatic int sg_allow_access(struct file *filp, unsigned char *cmd)\n{\n\tstruct sg_fd *sfp = filp->private_data;\n\n\tif (sfp->parentdp->device->type == TYPE_SCANNER)\n\t\treturn 0;\n\n\treturn blk_verify_command(cmd, filp->f_mode);\n}\n\nstatic int\nopen_wait(Sg_device *sdp, int flags)\n{\n\tint retval = 0;\n\n\tif (flags & O_EXCL) {\n\t\twhile (sdp->open_cnt > 0) {\n\t\t\tmutex_unlock(&sdp->open_rel_lock);\n\t\t\tretval = wait_event_interruptible(sdp->open_wait,\n\t\t\t\t\t(atomic_read(&sdp->detaching) ||\n\t\t\t\t\t !sdp->open_cnt));\n\t\t\tmutex_lock(&sdp->open_rel_lock);\n\n\t\t\tif (retval) /* -ERESTARTSYS */\n\t\t\t\treturn retval;\n\t\t\tif (atomic_read(&sdp->detaching))\n\t\t\t\treturn -ENODEV;\n\t\t}\n\t} else {\n\t\twhile (sdp->exclude) {\n\t\t\tmutex_unlock(&sdp->open_rel_lock);\n\t\t\tretval = wait_event_interruptible(sdp->open_wait,\n\t\t\t\t\t(atomic_read(&sdp->detaching) ||\n\t\t\t\t\t !sdp->exclude));\n\t\t\tmutex_lock(&sdp->open_rel_lock);\n\n\t\t\tif (retval) /* -ERESTARTSYS */\n\t\t\t\treturn retval;\n\t\t\tif (atomic_read(&sdp->detaching))\n\t\t\t\treturn -ENODEV;\n\t\t}\n\t}\n\n\treturn retval;\n}\n\n/* Returns 0 on success, else a negated errno value */\nstatic int\nsg_open(struct inode *inode, struct file *filp)\n{\n\tint dev = iminor(inode);\n\tint flags = filp->f_flags;\n\tstruct request_queue *q;\n\tSg_device *sdp;\n\tSg_fd *sfp;\n\tint retval;\n\n\tnonseekable_open(inode, filp);\n\tif ((flags & O_EXCL) && (O_RDONLY == (flags & O_ACCMODE)))\n\t\treturn -EPERM; /* Can't lock it with read only access */\n\tsdp = sg_get_dev(dev);\n\tif (IS_ERR(sdp))\n\t\treturn PTR_ERR(sdp);\n\n\tSCSI_LOG_TIMEOUT(3, sg_printk(KERN_INFO, sdp,\n\t\t\t\t      \"sg_open: flags=0x%x\\n\", flags));\n\n\t/* This driver's module count bumped by fops_get in <linux/fs.h> */\n\t/* Prevent the device driver from vanishing while we sleep */\n\tretval = scsi_device_get(sdp->device);\n\tif (retval)\n\t\tgoto sg_put;\n\n\tretval = scsi_autopm_get_device(sdp->device);\n\tif (retval)\n\t\tgoto sdp_put;\n\n\t/* scsi_block_when_processing_errors() may block so bypass\n\t * check if O_NONBLOCK. Permits SCSI commands to be issued\n\t * during error recovery. Tread carefully. */\n\tif (!((flags & O_NONBLOCK) ||\n\t      scsi_block_when_processing_errors(sdp->device))) {\n\t\tretval = -ENXIO;\n\t\t/* we are in error recovery for this device */\n\t\tgoto error_out;\n\t}\n\n\tmutex_lock(&sdp->open_rel_lock);\n\tif (flags & O_NONBLOCK) {\n\t\tif (flags & O_EXCL) {\n\t\t\tif (sdp->open_cnt > 0) {\n\t\t\t\tretval = -EBUSY;\n\t\t\t\tgoto error_mutex_locked;\n\t\t\t}\n\t\t} else {\n\t\t\tif (sdp->exclude) {\n\t\t\t\tretval = -EBUSY;\n\t\t\t\tgoto error_mutex_locked;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tretval = open_wait(sdp, flags);\n\t\tif (retval) /* -ERESTARTSYS or -ENODEV */\n\t\t\tgoto error_mutex_locked;\n\t}\n\n\t/* N.B. at this point we are holding the open_rel_lock */\n\tif (flags & O_EXCL)\n\t\tsdp->exclude = true;\n\n\tif (sdp->open_cnt < 1) {  /* no existing opens */\n\t\tsdp->sgdebug = 0;\n\t\tq = sdp->device->request_queue;\n\t\tsdp->sg_tablesize = queue_max_segments(q);\n\t}\n\tsfp = sg_add_sfp(sdp);\n\tif (IS_ERR(sfp)) {\n\t\tretval = PTR_ERR(sfp);\n\t\tgoto out_undo;\n\t}\n\n\tfilp->private_data = sfp;\n\tsdp->open_cnt++;\n\tmutex_unlock(&sdp->open_rel_lock);\n\n\tretval = 0;\nsg_put:\n\tkref_put(&sdp->d_ref, sg_device_destroy);\n\treturn retval;\n\nout_undo:\n\tif (flags & O_EXCL) {\n\t\tsdp->exclude = false;   /* undo if error */\n\t\twake_up_interruptible(&sdp->open_wait);\n\t}\nerror_mutex_locked:\n\tmutex_unlock(&sdp->open_rel_lock);\nerror_out:\n\tscsi_autopm_put_device(sdp->device);\nsdp_put:\n\tscsi_device_put(sdp->device);\n\tgoto sg_put;\n}\n\n/* Release resources associated with a successful sg_open()\n * Returns 0 on success, else a negated errno value */\nstatic int\nsg_release(struct inode *inode, struct file *filp)\n{\n\tSg_device *sdp;\n\tSg_fd *sfp;\n\n\tif ((!(sfp = (Sg_fd *) filp->private_data)) || (!(sdp = sfp->parentdp)))\n\t\treturn -ENXIO;\n\tSCSI_LOG_TIMEOUT(3, sg_printk(KERN_INFO, sdp, \"sg_release\\n\"));\n\n\tmutex_lock(&sdp->open_rel_lock);\n\tscsi_autopm_put_device(sdp->device);\n\tkref_put(&sfp->f_ref, sg_remove_sfp);\n\tsdp->open_cnt--;\n\n\t/* possibly many open()s waiting on exlude clearing, start many;\n\t * only open(O_EXCL)s wait on 0==open_cnt so only start one */\n\tif (sdp->exclude) {\n\t\tsdp->exclude = false;\n\t\twake_up_interruptible_all(&sdp->open_wait);\n\t} else if (0 == sdp->open_cnt) {\n\t\twake_up_interruptible(&sdp->open_wait);\n\t}\n\tmutex_unlock(&sdp->open_rel_lock);\n\treturn 0;\n}\n\nstatic int get_sg_io_pack_id(int *pack_id, void __user *buf, size_t count)\n{\n\tstruct sg_header __user *old_hdr = buf;\n\tint reply_len;\n\n\tif (count >= SZ_SG_HEADER) {\n\t\t/* negative reply_len means v3 format, otherwise v1/v2 */\n\t\tif (get_user(reply_len, &old_hdr->reply_len))\n\t\t\treturn -EFAULT;\n\n\t\tif (reply_len >= 0)\n\t\t\treturn get_user(*pack_id, &old_hdr->pack_id);\n\n\t\tif (in_compat_syscall() &&\n\t\t    count >= sizeof(struct compat_sg_io_hdr)) {\n\t\t\tstruct compat_sg_io_hdr __user *hp = buf;\n\n\t\t\treturn get_user(*pack_id, &hp->pack_id);\n\t\t}\n\n\t\tif (count >= sizeof(struct sg_io_hdr)) {\n\t\t\tstruct sg_io_hdr __user *hp = buf;\n\n\t\t\treturn get_user(*pack_id, &hp->pack_id);\n\t\t}\n\t}\n\n\t/* no valid header was passed, so ignore the pack_id */\n\t*pack_id = -1;\n\treturn 0;\n}\n\nstatic ssize_t\nsg_read(struct file *filp, char __user *buf, size_t count, loff_t * ppos)\n{\n\tSg_device *sdp;\n\tSg_fd *sfp;\n\tSg_request *srp;\n\tint req_pack_id = -1;\n\tsg_io_hdr_t *hp;\n\tstruct sg_header *old_hdr;\n\tint retval;\n\n\t/*\n\t * This could cause a response to be stranded. Close the associated\n\t * file descriptor to free up any resources being held.\n\t */\n\tretval = sg_check_file_access(filp, __func__);\n\tif (retval)\n\t\treturn retval;\n\n\tif ((!(sfp = (Sg_fd *) filp->private_data)) || (!(sdp = sfp->parentdp)))\n\t\treturn -ENXIO;\n\tSCSI_LOG_TIMEOUT(3, sg_printk(KERN_INFO, sdp,\n\t\t\t\t      \"sg_read: count=%d\\n\", (int) count));\n\n\tif (sfp->force_packid)\n\t\tretval = get_sg_io_pack_id(&req_pack_id, buf, count);\n\tif (retval)\n\t\treturn retval;\n\n\tsrp = sg_get_rq_mark(sfp, req_pack_id);\n\tif (!srp) {\t\t/* now wait on packet to arrive */\n\t\tif (atomic_read(&sdp->detaching))\n\t\t\treturn -ENODEV;\n\t\tif (filp->f_flags & O_NONBLOCK)\n\t\t\treturn -EAGAIN;\n\t\tretval = wait_event_interruptible(sfp->read_wait,\n\t\t\t(atomic_read(&sdp->detaching) ||\n\t\t\t(srp = sg_get_rq_mark(sfp, req_pack_id))));\n\t\tif (atomic_read(&sdp->detaching))\n\t\t\treturn -ENODEV;\n\t\tif (retval)\n\t\t\t/* -ERESTARTSYS as signal hit process */\n\t\t\treturn retval;\n\t}\n\tif (srp->header.interface_id != '\\0')\n\t\treturn sg_new_read(sfp, buf, count, srp);\n\n\thp = &srp->header;\n\told_hdr = kzalloc(SZ_SG_HEADER, GFP_KERNEL);\n\tif (!old_hdr)\n\t\treturn -ENOMEM;\n\n\told_hdr->reply_len = (int) hp->timeout;\n\told_hdr->pack_len = old_hdr->reply_len; /* old, strange behaviour */\n\told_hdr->pack_id = hp->pack_id;\n\told_hdr->twelve_byte =\n\t    ((srp->data.cmd_opcode >= 0xc0) && (12 == hp->cmd_len)) ? 1 : 0;\n\told_hdr->target_status = hp->masked_status;\n\told_hdr->host_status = hp->host_status;\n\told_hdr->driver_status = hp->driver_status;\n\tif ((CHECK_CONDITION & hp->masked_status) ||\n\t    (DRIVER_SENSE & hp->driver_status))\n\t\tmemcpy(old_hdr->sense_buffer, srp->sense_b,\n\t\t       sizeof (old_hdr->sense_buffer));\n\tswitch (hp->host_status) {\n\t/* This setup of 'result' is for backward compatibility and is best\n\t   ignored by the user who should use target, host + driver status */\n\tcase DID_OK:\n\tcase DID_PASSTHROUGH:\n\tcase DID_SOFT_ERROR:\n\t\told_hdr->result = 0;\n\t\tbreak;\n\tcase DID_NO_CONNECT:\n\tcase DID_BUS_BUSY:\n\tcase DID_TIME_OUT:\n\t\told_hdr->result = EBUSY;\n\t\tbreak;\n\tcase DID_BAD_TARGET:\n\tcase DID_ABORT:\n\tcase DID_PARITY:\n\tcase DID_RESET:\n\tcase DID_BAD_INTR:\n\t\told_hdr->result = EIO;\n\t\tbreak;\n\tcase DID_ERROR:\n\t\told_hdr->result = (srp->sense_b[0] == 0 && \n\t\t\t\t  hp->masked_status == GOOD) ? 0 : EIO;\n\t\tbreak;\n\tdefault:\n\t\told_hdr->result = EIO;\n\t\tbreak;\n\t}\n\n\t/* Now copy the result back to the user buffer.  */\n\tif (count >= SZ_SG_HEADER) {\n\t\tif (copy_to_user(buf, old_hdr, SZ_SG_HEADER)) {\n\t\t\tretval = -EFAULT;\n\t\t\tgoto free_old_hdr;\n\t\t}\n\t\tbuf += SZ_SG_HEADER;\n\t\tif (count > old_hdr->reply_len)\n\t\t\tcount = old_hdr->reply_len;\n\t\tif (count > SZ_SG_HEADER) {\n\t\t\tif (sg_read_oxfer(srp, buf, count - SZ_SG_HEADER)) {\n\t\t\t\tretval = -EFAULT;\n\t\t\t\tgoto free_old_hdr;\n\t\t\t}\n\t\t}\n\t} else\n\t\tcount = (old_hdr->result == 0) ? 0 : -EIO;\n\tsg_finish_rem_req(srp);\n\tsg_remove_request(sfp, srp);\n\tretval = count;\nfree_old_hdr:\n\tkfree(old_hdr);\n\treturn retval;\n}\n\nstatic ssize_t\nsg_new_read(Sg_fd * sfp, char __user *buf, size_t count, Sg_request * srp)\n{\n\tsg_io_hdr_t *hp = &srp->header;\n\tint err = 0, err2;\n\tint len;\n\n\tif (in_compat_syscall()) {\n\t\tif (count < sizeof(struct compat_sg_io_hdr)) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto err_out;\n\t\t}\n\t} else if (count < SZ_SG_IO_HDR) {\n\t\terr = -EINVAL;\n\t\tgoto err_out;\n\t}\n\thp->sb_len_wr = 0;\n\tif ((hp->mx_sb_len > 0) && hp->sbp) {\n\t\tif ((CHECK_CONDITION & hp->masked_status) ||\n\t\t    (DRIVER_SENSE & hp->driver_status)) {\n\t\t\tint sb_len = SCSI_SENSE_BUFFERSIZE;\n\t\t\tsb_len = (hp->mx_sb_len > sb_len) ? sb_len : hp->mx_sb_len;\n\t\t\tlen = 8 + (int) srp->sense_b[7];\t/* Additional sense length field */\n\t\t\tlen = (len > sb_len) ? sb_len : len;\n\t\t\tif (copy_to_user(hp->sbp, srp->sense_b, len)) {\n\t\t\t\terr = -EFAULT;\n\t\t\t\tgoto err_out;\n\t\t\t}\n\t\t\thp->sb_len_wr = len;\n\t\t}\n\t}\n\tif (hp->masked_status || hp->host_status || hp->driver_status)\n\t\thp->info |= SG_INFO_CHECK;\n\terr = put_sg_io_hdr(hp, buf);\nerr_out:\n\terr2 = sg_finish_rem_req(srp);\n\tsg_remove_request(sfp, srp);\n\treturn err ? : err2 ? : count;\n}\n\nstatic ssize_t\nsg_write(struct file *filp, const char __user *buf, size_t count, loff_t * ppos)\n{\n\tint mxsize, cmd_size, k;\n\tint input_size, blocking;\n\tunsigned char opcode;\n\tSg_device *sdp;\n\tSg_fd *sfp;\n\tSg_request *srp;\n\tstruct sg_header old_hdr;\n\tsg_io_hdr_t *hp;\n\tunsigned char cmnd[SG_MAX_CDB_SIZE];\n\tint retval;\n\n\tretval = sg_check_file_access(filp, __func__);\n\tif (retval)\n\t\treturn retval;\n\n\tif ((!(sfp = (Sg_fd *) filp->private_data)) || (!(sdp = sfp->parentdp)))\n\t\treturn -ENXIO;\n\tSCSI_LOG_TIMEOUT(3, sg_printk(KERN_INFO, sdp,\n\t\t\t\t      \"sg_write: count=%d\\n\", (int) count));\n\tif (atomic_read(&sdp->detaching))\n\t\treturn -ENODEV;\n\tif (!((filp->f_flags & O_NONBLOCK) ||\n\t      scsi_block_when_processing_errors(sdp->device)))\n\t\treturn -ENXIO;\n\n\tif (count < SZ_SG_HEADER)\n\t\treturn -EIO;\n\tif (copy_from_user(&old_hdr, buf, SZ_SG_HEADER))\n\t\treturn -EFAULT;\n\tblocking = !(filp->f_flags & O_NONBLOCK);\n\tif (old_hdr.reply_len < 0)\n\t\treturn sg_new_write(sfp, filp, buf, count,\n\t\t\t\t    blocking, 0, 0, NULL);\n\tif (count < (SZ_SG_HEADER + 6))\n\t\treturn -EIO;\t/* The minimum scsi command length is 6 bytes. */\n\n\tbuf += SZ_SG_HEADER;\n\tif (get_user(opcode, buf))\n\t\treturn -EFAULT;\n\n\tif (!(srp = sg_add_request(sfp))) {\n\t\tSCSI_LOG_TIMEOUT(1, sg_printk(KERN_INFO, sdp,\n\t\t\t\t\t      \"sg_write: queue full\\n\"));\n\t\treturn -EDOM;\n\t}\n\tmutex_lock(&sfp->f_mutex);\n\tif (sfp->next_cmd_len > 0) {\n\t\tcmd_size = sfp->next_cmd_len;\n\t\tsfp->next_cmd_len = 0;\t/* reset so only this write() effected */\n\t} else {\n\t\tcmd_size = COMMAND_SIZE(opcode);\t/* based on SCSI command group */\n\t\tif ((opcode >= 0xc0) && old_hdr.twelve_byte)\n\t\t\tcmd_size = 12;\n\t}\n\tmutex_unlock(&sfp->f_mutex);\n\tSCSI_LOG_TIMEOUT(4, sg_printk(KERN_INFO, sdp,\n\t\t\"sg_write:   scsi opcode=0x%02x, cmd_size=%d\\n\", (int) opcode, cmd_size));\n/* Determine buffer size.  */\n\tinput_size = count - cmd_size;\n\tmxsize = (input_size > old_hdr.reply_len) ? input_size : old_hdr.reply_len;\n\tmxsize -= SZ_SG_HEADER;\n\tinput_size -= SZ_SG_HEADER;\n\tif (input_size < 0) {\n\t\tsg_remove_request(sfp, srp);\n\t\treturn -EIO;\t/* User did not pass enough bytes for this command. */\n\t}\n\thp = &srp->header;\n\thp->interface_id = '\\0';\t/* indicator of old interface tunnelled */\n\thp->cmd_len = (unsigned char) cmd_size;\n\thp->iovec_count = 0;\n\thp->mx_sb_len = 0;\n\tif (input_size > 0)\n\t\thp->dxfer_direction = (old_hdr.reply_len > SZ_SG_HEADER) ?\n\t\t    SG_DXFER_TO_FROM_DEV : SG_DXFER_TO_DEV;\n\telse\n\t\thp->dxfer_direction = (mxsize > 0) ? SG_DXFER_FROM_DEV : SG_DXFER_NONE;\n\thp->dxfer_len = mxsize;\n\tif ((hp->dxfer_direction == SG_DXFER_TO_DEV) ||\n\t    (hp->dxfer_direction == SG_DXFER_TO_FROM_DEV))\n\t\thp->dxferp = (char __user *)buf + cmd_size;\n\telse\n\t\thp->dxferp = NULL;\n\thp->sbp = NULL;\n\thp->timeout = old_hdr.reply_len;\t/* structure abuse ... */\n\thp->flags = input_size;\t/* structure abuse ... */\n\thp->pack_id = old_hdr.pack_id;\n\thp->usr_ptr = NULL;\n\tif (copy_from_user(cmnd, buf, cmd_size)) {\n\t\tsg_remove_request(sfp, srp);\n\t\treturn -EFAULT;\n\t}\n\t/*\n\t * SG_DXFER_TO_FROM_DEV is functionally equivalent to SG_DXFER_FROM_DEV,\n\t * but is is possible that the app intended SG_DXFER_TO_DEV, because there\n\t * is a non-zero input_size, so emit a warning.\n\t */\n\tif (hp->dxfer_direction == SG_DXFER_TO_FROM_DEV) {\n\t\tprintk_ratelimited(KERN_WARNING\n\t\t\t\t   \"sg_write: data in/out %d/%d bytes \"\n\t\t\t\t   \"for SCSI command 0x%x-- guessing \"\n\t\t\t\t   \"data in;\\n   program %s not setting \"\n\t\t\t\t   \"count and/or reply_len properly\\n\",\n\t\t\t\t   old_hdr.reply_len - (int)SZ_SG_HEADER,\n\t\t\t\t   input_size, (unsigned int) cmnd[0],\n\t\t\t\t   current->comm);\n\t}\n\tk = sg_common_write(sfp, srp, cmnd, sfp->timeout, blocking);\n\treturn (k < 0) ? k : count;\n}\n\nstatic ssize_t\nsg_new_write(Sg_fd *sfp, struct file *file, const char __user *buf,\n\t\t size_t count, int blocking, int read_only, int sg_io_owned,\n\t\t Sg_request **o_srp)\n{\n\tint k;\n\tSg_request *srp;\n\tsg_io_hdr_t *hp;\n\tunsigned char cmnd[SG_MAX_CDB_SIZE];\n\tint timeout;\n\tunsigned long ul_timeout;\n\n\tif (count < SZ_SG_IO_HDR)\n\t\treturn -EINVAL;\n\n\tsfp->cmd_q = 1;\t/* when sg_io_hdr seen, set command queuing on */\n\tif (!(srp = sg_add_request(sfp))) {\n\t\tSCSI_LOG_TIMEOUT(1, sg_printk(KERN_INFO, sfp->parentdp,\n\t\t\t\t\t      \"sg_new_write: queue full\\n\"));\n\t\treturn -EDOM;\n\t}\n\tsrp->sg_io_owned = sg_io_owned;\n\thp = &srp->header;\n\tif (get_sg_io_hdr(hp, buf)) {\n\t\tsg_remove_request(sfp, srp);\n\t\treturn -EFAULT;\n\t}\n\tif (hp->interface_id != 'S') {\n\t\tsg_remove_request(sfp, srp);\n\t\treturn -ENOSYS;\n\t}\n\tif (hp->flags & SG_FLAG_MMAP_IO) {\n\t\tif (hp->dxfer_len > sfp->reserve.bufflen) {\n\t\t\tsg_remove_request(sfp, srp);\n\t\t\treturn -ENOMEM;\t/* MMAP_IO size must fit in reserve buffer */\n\t\t}\n\t\tif (hp->flags & SG_FLAG_DIRECT_IO) {\n\t\t\tsg_remove_request(sfp, srp);\n\t\t\treturn -EINVAL;\t/* either MMAP_IO or DIRECT_IO (not both) */\n\t\t}\n\t\tif (sfp->res_in_use) {\n\t\t\tsg_remove_request(sfp, srp);\n\t\t\treturn -EBUSY;\t/* reserve buffer already being used */\n\t\t}\n\t}\n\tul_timeout = msecs_to_jiffies(srp->header.timeout);\n\ttimeout = (ul_timeout < INT_MAX) ? ul_timeout : INT_MAX;\n\tif ((!hp->cmdp) || (hp->cmd_len < 6) || (hp->cmd_len > sizeof (cmnd))) {\n\t\tsg_remove_request(sfp, srp);\n\t\treturn -EMSGSIZE;\n\t}\n\tif (copy_from_user(cmnd, hp->cmdp, hp->cmd_len)) {\n\t\tsg_remove_request(sfp, srp);\n\t\treturn -EFAULT;\n\t}\n\tif (read_only && sg_allow_access(file, cmnd)) {\n\t\tsg_remove_request(sfp, srp);\n\t\treturn -EPERM;\n\t}\n\tk = sg_common_write(sfp, srp, cmnd, timeout, blocking);\n\tif (k < 0)\n\t\treturn k;\n\tif (o_srp)\n\t\t*o_srp = srp;\n\treturn count;\n}\n\nstatic int\nsg_common_write(Sg_fd * sfp, Sg_request * srp,\n\t\tunsigned char *cmnd, int timeout, int blocking)\n{\n\tint k, at_head;\n\tSg_device *sdp = sfp->parentdp;\n\tsg_io_hdr_t *hp = &srp->header;\n\n\tsrp->data.cmd_opcode = cmnd[0];\t/* hold opcode of command */\n\thp->status = 0;\n\thp->masked_status = 0;\n\thp->msg_status = 0;\n\thp->info = 0;\n\thp->host_status = 0;\n\thp->driver_status = 0;\n\thp->resid = 0;\n\tSCSI_LOG_TIMEOUT(4, sg_printk(KERN_INFO, sfp->parentdp,\n\t\t\t\"sg_common_write:  scsi opcode=0x%02x, cmd_size=%d\\n\",\n\t\t\t(int) cmnd[0], (int) hp->cmd_len));\n\n\tif (hp->dxfer_len >= SZ_256M) {\n\t\tsg_remove_request(sfp, srp);\n\t\treturn -EINVAL;\n\t}\n\n\tk = sg_start_req(srp, cmnd);\n\tif (k) {\n\t\tSCSI_LOG_TIMEOUT(1, sg_printk(KERN_INFO, sfp->parentdp,\n\t\t\t\"sg_common_write: start_req err=%d\\n\", k));\n\t\tsg_finish_rem_req(srp);\n\t\tsg_remove_request(sfp, srp);\n\t\treturn k;\t/* probably out of space --> ENOMEM */\n\t}\n\tif (atomic_read(&sdp->detaching)) {\n\t\tif (srp->bio) {\n\t\t\tscsi_req_free_cmd(scsi_req(srp->rq));\n\t\t\tblk_put_request(srp->rq);\n\t\t\tsrp->rq = NULL;\n\t\t}\n\n\t\tsg_finish_rem_req(srp);\n\t\tsg_remove_request(sfp, srp);\n\t\treturn -ENODEV;\n\t}\n\n\thp->duration = jiffies_to_msecs(jiffies);\n\tif (hp->interface_id != '\\0' &&\t/* v3 (or later) interface */\n\t    (SG_FLAG_Q_AT_TAIL & hp->flags))\n\t\tat_head = 0;\n\telse\n\t\tat_head = 1;\n\n\tsrp->rq->timeout = timeout;\n\tkref_get(&sfp->f_ref); /* sg_rq_end_io() does kref_put(). */\n\tblk_execute_rq_nowait(sdp->disk, srp->rq, at_head, sg_rq_end_io);\n\treturn 0;\n}\n\nstatic int srp_done(Sg_fd *sfp, Sg_request *srp)\n{\n\tunsigned long flags;\n\tint ret;\n\n\tread_lock_irqsave(&sfp->rq_list_lock, flags);\n\tret = srp->done;\n\tread_unlock_irqrestore(&sfp->rq_list_lock, flags);\n\treturn ret;\n}\n\nstatic int max_sectors_bytes(struct request_queue *q)\n{\n\tunsigned int max_sectors = queue_max_sectors(q);\n\n\tmax_sectors = min_t(unsigned int, max_sectors, INT_MAX >> 9);\n\n\treturn max_sectors << 9;\n}\n\nstatic void\nsg_fill_request_table(Sg_fd *sfp, sg_req_info_t *rinfo)\n{\n\tSg_request *srp;\n\tint val;\n\tunsigned int ms;\n\n\tval = 0;\n\tlist_for_each_entry(srp, &sfp->rq_list, entry) {\n\t\tif (val >= SG_MAX_QUEUE)\n\t\t\tbreak;\n\t\trinfo[val].req_state = srp->done + 1;\n\t\trinfo[val].problem =\n\t\t\tsrp->header.masked_status &\n\t\t\tsrp->header.host_status &\n\t\t\tsrp->header.driver_status;\n\t\tif (srp->done)\n\t\t\trinfo[val].duration =\n\t\t\t\tsrp->header.duration;\n\t\telse {\n\t\t\tms = jiffies_to_msecs(jiffies);\n\t\t\trinfo[val].duration =\n\t\t\t\t(ms > srp->header.duration) ?\n\t\t\t\t(ms - srp->header.duration) : 0;\n\t\t}\n\t\trinfo[val].orphan = srp->orphan;\n\t\trinfo[val].sg_io_owned = srp->sg_io_owned;\n\t\trinfo[val].pack_id = srp->header.pack_id;\n\t\trinfo[val].usr_ptr = srp->header.usr_ptr;\n\t\tval++;\n\t}\n}\n\n#ifdef CONFIG_COMPAT\nstruct compat_sg_req_info { /* used by SG_GET_REQUEST_TABLE ioctl() */\n\tchar req_state;\n\tchar orphan;\n\tchar sg_io_owned;\n\tchar problem;\n\tint pack_id;\n\tcompat_uptr_t usr_ptr;\n\tunsigned int duration;\n\tint unused;\n};\n\nstatic int put_compat_request_table(struct compat_sg_req_info __user *o,\n\t\t\t\t    struct sg_req_info *rinfo)\n{\n\tint i;\n\tfor (i = 0; i < SG_MAX_QUEUE; i++) {\n\t\tif (copy_to_user(o + i, rinfo + i, offsetof(sg_req_info_t, usr_ptr)) ||\n\t\t    put_user((uintptr_t)rinfo[i].usr_ptr, &o[i].usr_ptr) ||\n\t\t    put_user(rinfo[i].duration, &o[i].duration) ||\n\t\t    put_user(rinfo[i].unused, &o[i].unused))\n\t\t\treturn -EFAULT;\n\t}\n\treturn 0;\n}\n#endif\n\nstatic long\nsg_ioctl_common(struct file *filp, Sg_device *sdp, Sg_fd *sfp,\n\t\tunsigned int cmd_in, void __user *p)\n{\n\tint __user *ip = p;\n\tint result, val, read_only;\n\tSg_request *srp;\n\tunsigned long iflags;\n\n\tSCSI_LOG_TIMEOUT(3, sg_printk(KERN_INFO, sdp,\n\t\t\t\t   \"sg_ioctl: cmd=0x%x\\n\", (int) cmd_in));\n\tread_only = (O_RDWR != (filp->f_flags & O_ACCMODE));\n\n\tswitch (cmd_in) {\n\tcase SG_IO:\n\t\tif (atomic_read(&sdp->detaching))\n\t\t\treturn -ENODEV;\n\t\tif (!scsi_block_when_processing_errors(sdp->device))\n\t\t\treturn -ENXIO;\n\t\tresult = sg_new_write(sfp, filp, p, SZ_SG_IO_HDR,\n\t\t\t\t 1, read_only, 1, &srp);\n\t\tif (result < 0)\n\t\t\treturn result;\n\t\tresult = wait_event_interruptible(sfp->read_wait,\n\t\t\t(srp_done(sfp, srp) || atomic_read(&sdp->detaching)));\n\t\tif (atomic_read(&sdp->detaching))\n\t\t\treturn -ENODEV;\n\t\twrite_lock_irq(&sfp->rq_list_lock);\n\t\tif (srp->done) {\n\t\t\tsrp->done = 2;\n\t\t\twrite_unlock_irq(&sfp->rq_list_lock);\n\t\t\tresult = sg_new_read(sfp, p, SZ_SG_IO_HDR, srp);\n\t\t\treturn (result < 0) ? result : 0;\n\t\t}\n\t\tsrp->orphan = 1;\n\t\twrite_unlock_irq(&sfp->rq_list_lock);\n\t\treturn result;\t/* -ERESTARTSYS because signal hit process */\n\tcase SG_SET_TIMEOUT:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tif (val < 0)\n\t\t\treturn -EIO;\n\t\tif (val >= mult_frac((s64)INT_MAX, USER_HZ, HZ))\n\t\t\tval = min_t(s64, mult_frac((s64)INT_MAX, USER_HZ, HZ),\n\t\t\t\t    INT_MAX);\n\t\tsfp->timeout_user = val;\n\t\tsfp->timeout = mult_frac(val, HZ, USER_HZ);\n\n\t\treturn 0;\n\tcase SG_GET_TIMEOUT:\t/* N.B. User receives timeout as return value */\n\t\t\t\t/* strange ..., for backward compatibility */\n\t\treturn sfp->timeout_user;\n\tcase SG_SET_FORCE_LOW_DMA:\n\t\t/*\n\t\t * N.B. This ioctl never worked properly, but failed to\n\t\t * return an error value. So returning '0' to keep compability\n\t\t * with legacy applications.\n\t\t */\n\t\treturn 0;\n\tcase SG_GET_LOW_DMA:\n\t\treturn put_user((int) sdp->device->host->unchecked_isa_dma, ip);\n\tcase SG_GET_SCSI_ID:\n\t\t{\n\t\t\tsg_scsi_id_t v;\n\n\t\t\tif (atomic_read(&sdp->detaching))\n\t\t\t\treturn -ENODEV;\n\t\t\tmemset(&v, 0, sizeof(v));\n\t\t\tv.host_no = sdp->device->host->host_no;\n\t\t\tv.channel = sdp->device->channel;\n\t\t\tv.scsi_id = sdp->device->id;\n\t\t\tv.lun = sdp->device->lun;\n\t\t\tv.scsi_type = sdp->device->type;\n\t\t\tv.h_cmd_per_lun = sdp->device->host->cmd_per_lun;\n\t\t\tv.d_queue_depth = sdp->device->queue_depth;\n\t\t\tif (copy_to_user(p, &v, sizeof(sg_scsi_id_t)))\n\t\t\t\treturn -EFAULT;\n\t\t\treturn 0;\n\t\t}\n\tcase SG_SET_FORCE_PACK_ID:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tsfp->force_packid = val ? 1 : 0;\n\t\treturn 0;\n\tcase SG_GET_PACK_ID:\n\t\tread_lock_irqsave(&sfp->rq_list_lock, iflags);\n\t\tlist_for_each_entry(srp, &sfp->rq_list, entry) {\n\t\t\tif ((1 == srp->done) && (!srp->sg_io_owned)) {\n\t\t\t\tread_unlock_irqrestore(&sfp->rq_list_lock,\n\t\t\t\t\t\t       iflags);\n\t\t\t\treturn put_user(srp->header.pack_id, ip);\n\t\t\t}\n\t\t}\n\t\tread_unlock_irqrestore(&sfp->rq_list_lock, iflags);\n\t\treturn put_user(-1, ip);\n\tcase SG_GET_NUM_WAITING:\n\t\tread_lock_irqsave(&sfp->rq_list_lock, iflags);\n\t\tval = 0;\n\t\tlist_for_each_entry(srp, &sfp->rq_list, entry) {\n\t\t\tif ((1 == srp->done) && (!srp->sg_io_owned))\n\t\t\t\t++val;\n\t\t}\n\t\tread_unlock_irqrestore(&sfp->rq_list_lock, iflags);\n\t\treturn put_user(val, ip);\n\tcase SG_GET_SG_TABLESIZE:\n\t\treturn put_user(sdp->sg_tablesize, ip);\n\tcase SG_SET_RESERVED_SIZE:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n                if (val < 0)\n                        return -EINVAL;\n\t\tval = min_t(int, val,\n\t\t\t    max_sectors_bytes(sdp->device->request_queue));\n\t\tmutex_lock(&sfp->f_mutex);\n\t\tif (val != sfp->reserve.bufflen) {\n\t\t\tif (sfp->mmap_called ||\n\t\t\t    sfp->res_in_use) {\n\t\t\t\tmutex_unlock(&sfp->f_mutex);\n\t\t\t\treturn -EBUSY;\n\t\t\t}\n\n\t\t\tsg_remove_scat(sfp, &sfp->reserve);\n\t\t\tsg_build_reserve(sfp, val);\n\t\t}\n\t\tmutex_unlock(&sfp->f_mutex);\n\t\treturn 0;\n\tcase SG_GET_RESERVED_SIZE:\n\t\tval = min_t(int, sfp->reserve.bufflen,\n\t\t\t    max_sectors_bytes(sdp->device->request_queue));\n\t\treturn put_user(val, ip);\n\tcase SG_SET_COMMAND_Q:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tsfp->cmd_q = val ? 1 : 0;\n\t\treturn 0;\n\tcase SG_GET_COMMAND_Q:\n\t\treturn put_user((int) sfp->cmd_q, ip);\n\tcase SG_SET_KEEP_ORPHAN:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tsfp->keep_orphan = val;\n\t\treturn 0;\n\tcase SG_GET_KEEP_ORPHAN:\n\t\treturn put_user((int) sfp->keep_orphan, ip);\n\tcase SG_NEXT_CMD_LEN:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tif (val > SG_MAX_CDB_SIZE)\n\t\t\treturn -ENOMEM;\n\t\tsfp->next_cmd_len = (val > 0) ? val : 0;\n\t\treturn 0;\n\tcase SG_GET_VERSION_NUM:\n\t\treturn put_user(sg_version_num, ip);\n\tcase SG_GET_ACCESS_COUNT:\n\t\t/* faked - we don't have a real access count anymore */\n\t\tval = (sdp->device ? 1 : 0);\n\t\treturn put_user(val, ip);\n\tcase SG_GET_REQUEST_TABLE:\n\t\t{\n\t\t\tsg_req_info_t *rinfo;\n\n\t\t\trinfo = kcalloc(SG_MAX_QUEUE, SZ_SG_REQ_INFO,\n\t\t\t\t\tGFP_KERNEL);\n\t\t\tif (!rinfo)\n\t\t\t\treturn -ENOMEM;\n\t\t\tread_lock_irqsave(&sfp->rq_list_lock, iflags);\n\t\t\tsg_fill_request_table(sfp, rinfo);\n\t\t\tread_unlock_irqrestore(&sfp->rq_list_lock, iflags);\n\t#ifdef CONFIG_COMPAT\n\t\t\tif (in_compat_syscall())\n\t\t\t\tresult = put_compat_request_table(p, rinfo);\n\t\t\telse\n\t#endif\n\t\t\t\tresult = copy_to_user(p, rinfo,\n\t\t\t\t\t\t      SZ_SG_REQ_INFO * SG_MAX_QUEUE);\n\t\t\tresult = result ? -EFAULT : 0;\n\t\t\tkfree(rinfo);\n\t\t\treturn result;\n\t\t}\n\tcase SG_EMULATED_HOST:\n\t\tif (atomic_read(&sdp->detaching))\n\t\t\treturn -ENODEV;\n\t\treturn put_user(sdp->device->host->hostt->emulated, ip);\n\tcase SCSI_IOCTL_SEND_COMMAND:\n\t\tif (atomic_read(&sdp->detaching))\n\t\t\treturn -ENODEV;\n\t\treturn sg_scsi_ioctl(sdp->device->request_queue, NULL, filp->f_mode, p);\n\tcase SG_SET_DEBUG:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tsdp->sgdebug = (char) val;\n\t\treturn 0;\n\tcase BLKSECTGET:\n\t\treturn put_user(max_sectors_bytes(sdp->device->request_queue),\n\t\t\t\tip);\n\tcase BLKTRACESETUP:\n\t\treturn blk_trace_setup(sdp->device->request_queue,\n\t\t\t\t       sdp->disk->disk_name,\n\t\t\t\t       MKDEV(SCSI_GENERIC_MAJOR, sdp->index),\n\t\t\t\t       NULL, p);\n\tcase BLKTRACESTART:\n\t\treturn blk_trace_startstop(sdp->device->request_queue, 1);\n\tcase BLKTRACESTOP:\n\t\treturn blk_trace_startstop(sdp->device->request_queue, 0);\n\tcase BLKTRACETEARDOWN:\n\t\treturn blk_trace_remove(sdp->device->request_queue);\n\tcase SCSI_IOCTL_GET_IDLUN:\n\tcase SCSI_IOCTL_GET_BUS_NUMBER:\n\tcase SCSI_IOCTL_PROBE_HOST:\n\tcase SG_GET_TRANSFORM:\n\tcase SG_SCSI_RESET:\n\t\tif (atomic_read(&sdp->detaching))\n\t\t\treturn -ENODEV;\n\t\tbreak;\n\tdefault:\n\t\tif (read_only)\n\t\t\treturn -EPERM;\t/* don't know so take safe approach */\n\t\tbreak;\n\t}\n\n\tresult = scsi_ioctl_block_when_processing_errors(sdp->device,\n\t\t\tcmd_in, filp->f_flags & O_NDELAY);\n\tif (result)\n\t\treturn result;\n\n\treturn -ENOIOCTLCMD;\n}\n\nstatic long\nsg_ioctl(struct file *filp, unsigned int cmd_in, unsigned long arg)\n{\n\tvoid __user *p = (void __user *)arg;\n\tSg_device *sdp;\n\tSg_fd *sfp;\n\tint ret;\n\n\tif ((!(sfp = (Sg_fd *) filp->private_data)) || (!(sdp = sfp->parentdp)))\n\t\treturn -ENXIO;\n\n\tret = sg_ioctl_common(filp, sdp, sfp, cmd_in, p);\n\tif (ret != -ENOIOCTLCMD)\n\t\treturn ret;\n\n\treturn scsi_ioctl(sdp->device, cmd_in, p);\n}\n\n#ifdef CONFIG_COMPAT\nstatic long sg_compat_ioctl(struct file *filp, unsigned int cmd_in, unsigned long arg)\n{\n\tvoid __user *p = compat_ptr(arg);\n\tSg_device *sdp;\n\tSg_fd *sfp;\n\tint ret;\n\n\tif ((!(sfp = (Sg_fd *) filp->private_data)) || (!(sdp = sfp->parentdp)))\n\t\treturn -ENXIO;\n\n\tret = sg_ioctl_common(filp, sdp, sfp, cmd_in, p);\n\tif (ret != -ENOIOCTLCMD)\n\t\treturn ret;\n\n\treturn scsi_compat_ioctl(sdp->device, cmd_in, p);\n}\n#endif\n\nstatic __poll_t\nsg_poll(struct file *filp, poll_table * wait)\n{\n\t__poll_t res = 0;\n\tSg_device *sdp;\n\tSg_fd *sfp;\n\tSg_request *srp;\n\tint count = 0;\n\tunsigned long iflags;\n\n\tsfp = filp->private_data;\n\tif (!sfp)\n\t\treturn EPOLLERR;\n\tsdp = sfp->parentdp;\n\tif (!sdp)\n\t\treturn EPOLLERR;\n\tpoll_wait(filp, &sfp->read_wait, wait);\n\tread_lock_irqsave(&sfp->rq_list_lock, iflags);\n\tlist_for_each_entry(srp, &sfp->rq_list, entry) {\n\t\t/* if any read waiting, flag it */\n\t\tif ((0 == res) && (1 == srp->done) && (!srp->sg_io_owned))\n\t\t\tres = EPOLLIN | EPOLLRDNORM;\n\t\t++count;\n\t}\n\tread_unlock_irqrestore(&sfp->rq_list_lock, iflags);\n\n\tif (atomic_read(&sdp->detaching))\n\t\tres |= EPOLLHUP;\n\telse if (!sfp->cmd_q) {\n\t\tif (0 == count)\n\t\t\tres |= EPOLLOUT | EPOLLWRNORM;\n\t} else if (count < SG_MAX_QUEUE)\n\t\tres |= EPOLLOUT | EPOLLWRNORM;\n\tSCSI_LOG_TIMEOUT(3, sg_printk(KERN_INFO, sdp,\n\t\t\t\t      \"sg_poll: res=0x%x\\n\", (__force u32) res));\n\treturn res;\n}\n\nstatic int\nsg_fasync(int fd, struct file *filp, int mode)\n{\n\tSg_device *sdp;\n\tSg_fd *sfp;\n\n\tif ((!(sfp = (Sg_fd *) filp->private_data)) || (!(sdp = sfp->parentdp)))\n\t\treturn -ENXIO;\n\tSCSI_LOG_TIMEOUT(3, sg_printk(KERN_INFO, sdp,\n\t\t\t\t      \"sg_fasync: mode=%d\\n\", mode));\n\n\treturn fasync_helper(fd, filp, mode, &sfp->async_qp);\n}\n\nstatic vm_fault_t\nsg_vma_fault(struct vm_fault *vmf)\n{\n\tstruct vm_area_struct *vma = vmf->vma;\n\tSg_fd *sfp;\n\tunsigned long offset, len, sa;\n\tSg_scatter_hold *rsv_schp;\n\tint k, length;\n\n\tif ((NULL == vma) || (!(sfp = (Sg_fd *) vma->vm_private_data)))\n\t\treturn VM_FAULT_SIGBUS;\n\trsv_schp = &sfp->reserve;\n\toffset = vmf->pgoff << PAGE_SHIFT;\n\tif (offset >= rsv_schp->bufflen)\n\t\treturn VM_FAULT_SIGBUS;\n\tSCSI_LOG_TIMEOUT(3, sg_printk(KERN_INFO, sfp->parentdp,\n\t\t\t\t      \"sg_vma_fault: offset=%lu, scatg=%d\\n\",\n\t\t\t\t      offset, rsv_schp->k_use_sg));\n\tsa = vma->vm_start;\n\tlength = 1 << (PAGE_SHIFT + rsv_schp->page_order);\n\tfor (k = 0; k < rsv_schp->k_use_sg && sa < vma->vm_end; k++) {\n\t\tlen = vma->vm_end - sa;\n\t\tlen = (len < length) ? len : length;\n\t\tif (offset < len) {\n\t\t\tstruct page *page = nth_page(rsv_schp->pages[k],\n\t\t\t\t\t\t     offset >> PAGE_SHIFT);\n\t\t\tget_page(page);\t/* increment page count */\n\t\t\tvmf->page = page;\n\t\t\treturn 0; /* success */\n\t\t}\n\t\tsa += len;\n\t\toffset -= len;\n\t}\n\n\treturn VM_FAULT_SIGBUS;\n}\n\nstatic const struct vm_operations_struct sg_mmap_vm_ops = {\n\t.fault = sg_vma_fault,\n};\n\nstatic int\nsg_mmap(struct file *filp, struct vm_area_struct *vma)\n{\n\tSg_fd *sfp;\n\tunsigned long req_sz, len, sa;\n\tSg_scatter_hold *rsv_schp;\n\tint k, length;\n\tint ret = 0;\n\n\tif ((!filp) || (!vma) || (!(sfp = (Sg_fd *) filp->private_data)))\n\t\treturn -ENXIO;\n\treq_sz = vma->vm_end - vma->vm_start;\n\tSCSI_LOG_TIMEOUT(3, sg_printk(KERN_INFO, sfp->parentdp,\n\t\t\t\t      \"sg_mmap starting, vm_start=%p, len=%d\\n\",\n\t\t\t\t      (void *) vma->vm_start, (int) req_sz));\n\tif (vma->vm_pgoff)\n\t\treturn -EINVAL;\t/* want no offset */\n\trsv_schp = &sfp->reserve;\n\tmutex_lock(&sfp->f_mutex);\n\tif (req_sz > rsv_schp->bufflen) {\n\t\tret = -ENOMEM;\t/* cannot map more than reserved buffer */\n\t\tgoto out;\n\t}\n\n\tsa = vma->vm_start;\n\tlength = 1 << (PAGE_SHIFT + rsv_schp->page_order);\n\tfor (k = 0; k < rsv_schp->k_use_sg && sa < vma->vm_end; k++) {\n\t\tlen = vma->vm_end - sa;\n\t\tlen = (len < length) ? len : length;\n\t\tsa += len;\n\t}\n\n\tsfp->mmap_called = 1;\n\tvma->vm_flags |= VM_IO | VM_DONTEXPAND | VM_DONTDUMP;\n\tvma->vm_private_data = sfp;\n\tvma->vm_ops = &sg_mmap_vm_ops;\nout:\n\tmutex_unlock(&sfp->f_mutex);\n\treturn ret;\n}\n\nstatic void\nsg_rq_end_io_usercontext(struct work_struct *work)\n{\n\tstruct sg_request *srp = container_of(work, struct sg_request, ew.work);\n\tstruct sg_fd *sfp = srp->parentfp;\n\n\tsg_finish_rem_req(srp);\n\tsg_remove_request(sfp, srp);\n\tkref_put(&sfp->f_ref, sg_remove_sfp);\n}\n\n/*\n * This function is a \"bottom half\" handler that is called by the mid\n * level when a command is completed (or has failed).\n */\nstatic void\nsg_rq_end_io(struct request *rq, blk_status_t status)\n{\n\tstruct sg_request *srp = rq->end_io_data;\n\tstruct scsi_request *req = scsi_req(rq);\n\tSg_device *sdp;\n\tSg_fd *sfp;\n\tunsigned long iflags;\n\tunsigned int ms;\n\tchar *sense;\n\tint result, resid, done = 1;\n\n\tif (WARN_ON(srp->done != 0))\n\t\treturn;\n\n\tsfp = srp->parentfp;\n\tif (WARN_ON(sfp == NULL))\n\t\treturn;\n\n\tsdp = sfp->parentdp;\n\tif (unlikely(atomic_read(&sdp->detaching)))\n\t\tpr_info(\"%s: device detaching\\n\", __func__);\n\n\tsense = req->sense;\n\tresult = req->result;\n\tresid = req->resid_len;\n\n\tSCSI_LOG_TIMEOUT(4, sg_printk(KERN_INFO, sdp,\n\t\t\t\t      \"sg_cmd_done: pack_id=%d, res=0x%x\\n\",\n\t\t\t\t      srp->header.pack_id, result));\n\tsrp->header.resid = resid;\n\tms = jiffies_to_msecs(jiffies);\n\tsrp->header.duration = (ms > srp->header.duration) ?\n\t\t\t\t(ms - srp->header.duration) : 0;\n\tif (0 != result) {\n\t\tstruct scsi_sense_hdr sshdr;\n\n\t\tsrp->header.status = 0xff & result;\n\t\tsrp->header.masked_status = status_byte(result);\n\t\tsrp->header.msg_status = msg_byte(result);\n\t\tsrp->header.host_status = host_byte(result);\n\t\tsrp->header.driver_status = driver_byte(result);\n\t\tif ((sdp->sgdebug > 0) &&\n\t\t    ((CHECK_CONDITION == srp->header.masked_status) ||\n\t\t     (COMMAND_TERMINATED == srp->header.masked_status)))\n\t\t\t__scsi_print_sense(sdp->device, __func__, sense,\n\t\t\t\t\t   SCSI_SENSE_BUFFERSIZE);\n\n\t\t/* Following if statement is a patch supplied by Eric Youngdale */\n\t\tif (driver_byte(result) != 0\n\t\t    && scsi_normalize_sense(sense, SCSI_SENSE_BUFFERSIZE, &sshdr)\n\t\t    && !scsi_sense_is_deferred(&sshdr)\n\t\t    && sshdr.sense_key == UNIT_ATTENTION\n\t\t    && sdp->device->removable) {\n\t\t\t/* Detected possible disc change. Set the bit - this */\n\t\t\t/* may be used if there are filesystems using this device */\n\t\t\tsdp->device->changed = 1;\n\t\t}\n\t}\n\n\tif (req->sense_len)\n\t\tmemcpy(srp->sense_b, req->sense, SCSI_SENSE_BUFFERSIZE);\n\n\t/* Rely on write phase to clean out srp status values, so no \"else\" */\n\n\t/*\n\t * Free the request as soon as it is complete so that its resources\n\t * can be reused without waiting for userspace to read() the\n\t * result.  But keep the associated bio (if any) around until\n\t * blk_rq_unmap_user() can be called from user context.\n\t */\n\tsrp->rq = NULL;\n\tscsi_req_free_cmd(scsi_req(rq));\n\tblk_put_request(rq);\n\n\twrite_lock_irqsave(&sfp->rq_list_lock, iflags);\n\tif (unlikely(srp->orphan)) {\n\t\tif (sfp->keep_orphan)\n\t\t\tsrp->sg_io_owned = 0;\n\t\telse\n\t\t\tdone = 0;\n\t}\n\tsrp->done = done;\n\twrite_unlock_irqrestore(&sfp->rq_list_lock, iflags);\n\n\tif (likely(done)) {\n\t\t/* Now wake up any sg_read() that is waiting for this\n\t\t * packet.\n\t\t */\n\t\twake_up_interruptible(&sfp->read_wait);\n\t\tkill_fasync(&sfp->async_qp, SIGPOLL, POLL_IN);\n\t\tkref_put(&sfp->f_ref, sg_remove_sfp);\n\t} else {\n\t\tINIT_WORK(&srp->ew.work, sg_rq_end_io_usercontext);\n\t\tschedule_work(&srp->ew.work);\n\t}\n}\n\nstatic const struct file_operations sg_fops = {\n\t.owner = THIS_MODULE,\n\t.read = sg_read,\n\t.write = sg_write,\n\t.poll = sg_poll,\n\t.unlocked_ioctl = sg_ioctl,\n#ifdef CONFIG_COMPAT\n\t.compat_ioctl = sg_compat_ioctl,\n#endif\n\t.open = sg_open,\n\t.mmap = sg_mmap,\n\t.release = sg_release,\n\t.fasync = sg_fasync,\n\t.llseek = no_llseek,\n};\n\nstatic struct class *sg_sysfs_class;\n\nstatic int sg_sysfs_valid = 0;\n\nstatic Sg_device *\nsg_alloc(struct gendisk *disk, struct scsi_device *scsidp)\n{\n\tstruct request_queue *q = scsidp->request_queue;\n\tSg_device *sdp;\n\tunsigned long iflags;\n\tint error;\n\tu32 k;\n\n\tsdp = kzalloc(sizeof(Sg_device), GFP_KERNEL);\n\tif (!sdp) {\n\t\tsdev_printk(KERN_WARNING, scsidp, \"%s: kmalloc Sg_device \"\n\t\t\t    \"failure\\n\", __func__);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\n\tidr_preload(GFP_KERNEL);\n\twrite_lock_irqsave(&sg_index_lock, iflags);\n\n\terror = idr_alloc(&sg_index_idr, sdp, 0, SG_MAX_DEVS, GFP_NOWAIT);\n\tif (error < 0) {\n\t\tif (error == -ENOSPC) {\n\t\t\tsdev_printk(KERN_WARNING, scsidp,\n\t\t\t\t    \"Unable to attach sg device type=%d, minor number exceeds %d\\n\",\n\t\t\t\t    scsidp->type, SG_MAX_DEVS - 1);\n\t\t\terror = -ENODEV;\n\t\t} else {\n\t\t\tsdev_printk(KERN_WARNING, scsidp, \"%s: idr \"\n\t\t\t\t    \"allocation Sg_device failure: %d\\n\",\n\t\t\t\t    __func__, error);\n\t\t}\n\t\tgoto out_unlock;\n\t}\n\tk = error;\n\n\tSCSI_LOG_TIMEOUT(3, sdev_printk(KERN_INFO, scsidp,\n\t\t\t\t\t\"sg_alloc: dev=%d \\n\", k));\n\tsprintf(disk->disk_name, \"sg%d\", k);\n\tdisk->first_minor = k;\n\tsdp->disk = disk;\n\tsdp->device = scsidp;\n\tmutex_init(&sdp->open_rel_lock);\n\tINIT_LIST_HEAD(&sdp->sfds);\n\tinit_waitqueue_head(&sdp->open_wait);\n\tatomic_set(&sdp->detaching, 0);\n\trwlock_init(&sdp->sfd_lock);\n\tsdp->sg_tablesize = queue_max_segments(q);\n\tsdp->index = k;\n\tkref_init(&sdp->d_ref);\n\terror = 0;\n\nout_unlock:\n\twrite_unlock_irqrestore(&sg_index_lock, iflags);\n\tidr_preload_end();\n\n\tif (error) {\n\t\tkfree(sdp);\n\t\treturn ERR_PTR(error);\n\t}\n\treturn sdp;\n}\n\nstatic int\nsg_add_device(struct device *cl_dev, struct class_interface *cl_intf)\n{\n\tstruct scsi_device *scsidp = to_scsi_device(cl_dev->parent);\n\tstruct gendisk *disk;\n\tSg_device *sdp = NULL;\n\tstruct cdev * cdev = NULL;\n\tint error;\n\tunsigned long iflags;\n\n\tdisk = alloc_disk(1);\n\tif (!disk) {\n\t\tpr_warn(\"%s: alloc_disk failed\\n\", __func__);\n\t\treturn -ENOMEM;\n\t}\n\tdisk->major = SCSI_GENERIC_MAJOR;\n\n\terror = -ENOMEM;\n\tcdev = cdev_alloc();\n\tif (!cdev) {\n\t\tpr_warn(\"%s: cdev_alloc failed\\n\", __func__);\n\t\tgoto out;\n\t}\n\tcdev->owner = THIS_MODULE;\n\tcdev->ops = &sg_fops;\n\n\tsdp = sg_alloc(disk, scsidp);\n\tif (IS_ERR(sdp)) {\n\t\tpr_warn(\"%s: sg_alloc failed\\n\", __func__);\n\t\terror = PTR_ERR(sdp);\n\t\tgoto out;\n\t}\n\n\terror = cdev_add(cdev, MKDEV(SCSI_GENERIC_MAJOR, sdp->index), 1);\n\tif (error)\n\t\tgoto cdev_add_err;\n\n\tsdp->cdev = cdev;\n\tif (sg_sysfs_valid) {\n\t\tstruct device *sg_class_member;\n\n\t\tsg_class_member = device_create(sg_sysfs_class, cl_dev->parent,\n\t\t\t\t\t\tMKDEV(SCSI_GENERIC_MAJOR,\n\t\t\t\t\t\t      sdp->index),\n\t\t\t\t\t\tsdp, \"%s\", disk->disk_name);\n\t\tif (IS_ERR(sg_class_member)) {\n\t\t\tpr_err(\"%s: device_create failed\\n\", __func__);\n\t\t\terror = PTR_ERR(sg_class_member);\n\t\t\tgoto cdev_add_err;\n\t\t}\n\t\terror = sysfs_create_link(&scsidp->sdev_gendev.kobj,\n\t\t\t\t\t  &sg_class_member->kobj, \"generic\");\n\t\tif (error)\n\t\t\tpr_err(\"%s: unable to make symlink 'generic' back \"\n\t\t\t       \"to sg%d\\n\", __func__, sdp->index);\n\t} else\n\t\tpr_warn(\"%s: sg_sys Invalid\\n\", __func__);\n\n\tsdev_printk(KERN_NOTICE, scsidp, \"Attached scsi generic sg%d \"\n\t\t    \"type %d\\n\", sdp->index, scsidp->type);\n\n\tdev_set_drvdata(cl_dev, sdp);\n\n\treturn 0;\n\ncdev_add_err:\n\twrite_lock_irqsave(&sg_index_lock, iflags);\n\tidr_remove(&sg_index_idr, sdp->index);\n\twrite_unlock_irqrestore(&sg_index_lock, iflags);\n\tkfree(sdp);\n\nout:\n\tput_disk(disk);\n\tif (cdev)\n\t\tcdev_del(cdev);\n\treturn error;\n}\n\nstatic void\nsg_device_destroy(struct kref *kref)\n{\n\tstruct sg_device *sdp = container_of(kref, struct sg_device, d_ref);\n\tunsigned long flags;\n\n\t/* CAUTION!  Note that the device can still be found via idr_find()\n\t * even though the refcount is 0.  Therefore, do idr_remove() BEFORE\n\t * any other cleanup.\n\t */\n\n\twrite_lock_irqsave(&sg_index_lock, flags);\n\tidr_remove(&sg_index_idr, sdp->index);\n\twrite_unlock_irqrestore(&sg_index_lock, flags);\n\n\tSCSI_LOG_TIMEOUT(3,\n\t\tsg_printk(KERN_INFO, sdp, \"sg_device_destroy\\n\"));\n\n\tput_disk(sdp->disk);\n\tkfree(sdp);\n}\n\nstatic void\nsg_remove_device(struct device *cl_dev, struct class_interface *cl_intf)\n{\n\tstruct scsi_device *scsidp = to_scsi_device(cl_dev->parent);\n\tSg_device *sdp = dev_get_drvdata(cl_dev);\n\tunsigned long iflags;\n\tSg_fd *sfp;\n\tint val;\n\n\tif (!sdp)\n\t\treturn;\n\t/* want sdp->detaching non-zero as soon as possible */\n\tval = atomic_inc_return(&sdp->detaching);\n\tif (val > 1)\n\t\treturn; /* only want to do following once per device */\n\n\tSCSI_LOG_TIMEOUT(3, sg_printk(KERN_INFO, sdp,\n\t\t\t\t      \"%s\\n\", __func__));\n\n\tread_lock_irqsave(&sdp->sfd_lock, iflags);\n\tlist_for_each_entry(sfp, &sdp->sfds, sfd_siblings) {\n\t\twake_up_interruptible_all(&sfp->read_wait);\n\t\tkill_fasync(&sfp->async_qp, SIGPOLL, POLL_HUP);\n\t}\n\twake_up_interruptible_all(&sdp->open_wait);\n\tread_unlock_irqrestore(&sdp->sfd_lock, iflags);\n\n\tsysfs_remove_link(&scsidp->sdev_gendev.kobj, \"generic\");\n\tdevice_destroy(sg_sysfs_class, MKDEV(SCSI_GENERIC_MAJOR, sdp->index));\n\tcdev_del(sdp->cdev);\n\tsdp->cdev = NULL;\n\n\tkref_put(&sdp->d_ref, sg_device_destroy);\n}\n\nmodule_param_named(scatter_elem_sz, scatter_elem_sz, int, S_IRUGO | S_IWUSR);\nmodule_param_named(def_reserved_size, def_reserved_size, int,\n\t\t   S_IRUGO | S_IWUSR);\nmodule_param_named(allow_dio, sg_allow_dio, int, S_IRUGO | S_IWUSR);\n\nMODULE_AUTHOR(\"Douglas Gilbert\");\nMODULE_DESCRIPTION(\"SCSI generic (sg) driver\");\nMODULE_LICENSE(\"GPL\");\nMODULE_VERSION(SG_VERSION_STR);\nMODULE_ALIAS_CHARDEV_MAJOR(SCSI_GENERIC_MAJOR);\n\nMODULE_PARM_DESC(scatter_elem_sz, \"scatter gather element \"\n                \"size (default: max(SG_SCATTER_SZ, PAGE_SIZE))\");\nMODULE_PARM_DESC(def_reserved_size, \"size of buffer reserved for each fd\");\nMODULE_PARM_DESC(allow_dio, \"allow direct I/O (default: 0 (disallow))\");\n\nstatic int __init\ninit_sg(void)\n{\n\tint rc;\n\n\tif (scatter_elem_sz < PAGE_SIZE) {\n\t\tscatter_elem_sz = PAGE_SIZE;\n\t\tscatter_elem_sz_prev = scatter_elem_sz;\n\t}\n\tif (def_reserved_size >= 0)\n\t\tsg_big_buff = def_reserved_size;\n\telse\n\t\tdef_reserved_size = sg_big_buff;\n\n\trc = register_chrdev_region(MKDEV(SCSI_GENERIC_MAJOR, 0), \n\t\t\t\t    SG_MAX_DEVS, \"sg\");\n\tif (rc)\n\t\treturn rc;\n        sg_sysfs_class = class_create(THIS_MODULE, \"scsi_generic\");\n        if ( IS_ERR(sg_sysfs_class) ) {\n\t\trc = PTR_ERR(sg_sysfs_class);\n\t\tgoto err_out;\n        }\n\tsg_sysfs_valid = 1;\n\trc = scsi_register_interface(&sg_interface);\n\tif (0 == rc) {\n#ifdef CONFIG_SCSI_PROC_FS\n\t\tsg_proc_init();\n#endif\t\t\t\t/* CONFIG_SCSI_PROC_FS */\n\t\treturn 0;\n\t}\n\tclass_destroy(sg_sysfs_class);\nerr_out:\n\tunregister_chrdev_region(MKDEV(SCSI_GENERIC_MAJOR, 0), SG_MAX_DEVS);\n\treturn rc;\n}\n\nstatic void __exit\nexit_sg(void)\n{\n#ifdef CONFIG_SCSI_PROC_FS\n\tremove_proc_subtree(\"scsi/sg\", NULL);\n#endif\t\t\t\t/* CONFIG_SCSI_PROC_FS */\n\tscsi_unregister_interface(&sg_interface);\n\tclass_destroy(sg_sysfs_class);\n\tsg_sysfs_valid = 0;\n\tunregister_chrdev_region(MKDEV(SCSI_GENERIC_MAJOR, 0),\n\t\t\t\t SG_MAX_DEVS);\n\tidr_destroy(&sg_index_idr);\n}\n\nstatic int\nsg_start_req(Sg_request *srp, unsigned char *cmd)\n{\n\tint res;\n\tstruct request *rq;\n\tstruct scsi_request *req;\n\tSg_fd *sfp = srp->parentfp;\n\tsg_io_hdr_t *hp = &srp->header;\n\tint dxfer_len = (int) hp->dxfer_len;\n\tint dxfer_dir = hp->dxfer_direction;\n\tunsigned int iov_count = hp->iovec_count;\n\tSg_scatter_hold *req_schp = &srp->data;\n\tSg_scatter_hold *rsv_schp = &sfp->reserve;\n\tstruct request_queue *q = sfp->parentdp->device->request_queue;\n\tstruct rq_map_data *md, map_data;\n\tint rw = hp->dxfer_direction == SG_DXFER_TO_DEV ? WRITE : READ;\n\tunsigned char *long_cmdp = NULL;\n\n\tSCSI_LOG_TIMEOUT(4, sg_printk(KERN_INFO, sfp->parentdp,\n\t\t\t\t      \"sg_start_req: dxfer_len=%d\\n\",\n\t\t\t\t      dxfer_len));\n\n\tif (hp->cmd_len > BLK_MAX_CDB) {\n\t\tlong_cmdp = kzalloc(hp->cmd_len, GFP_KERNEL);\n\t\tif (!long_cmdp)\n\t\t\treturn -ENOMEM;\n\t}\n\n\t/*\n\t * NOTE\n\t *\n\t * With scsi-mq enabled, there are a fixed number of preallocated\n\t * requests equal in number to shost->can_queue.  If all of the\n\t * preallocated requests are already in use, then blk_get_request()\n\t * will sleep until an active command completes, freeing up a request.\n\t * Although waiting in an asynchronous interface is less than ideal, we\n\t * do not want to use BLK_MQ_REQ_NOWAIT here because userspace might\n\t * not expect an EWOULDBLOCK from this condition.\n\t */\n\trq = blk_get_request(q, hp->dxfer_direction == SG_DXFER_TO_DEV ?\n\t\t\tREQ_OP_SCSI_OUT : REQ_OP_SCSI_IN, 0);\n\tif (IS_ERR(rq)) {\n\t\tkfree(long_cmdp);\n\t\treturn PTR_ERR(rq);\n\t}\n\treq = scsi_req(rq);\n\n\tif (hp->cmd_len > BLK_MAX_CDB)\n\t\treq->cmd = long_cmdp;\n\tmemcpy(req->cmd, cmd, hp->cmd_len);\n\treq->cmd_len = hp->cmd_len;\n\n\tsrp->rq = rq;\n\trq->end_io_data = srp;\n\treq->retries = SG_DEFAULT_RETRIES;\n\n\tif ((dxfer_len <= 0) || (dxfer_dir == SG_DXFER_NONE))\n\t\treturn 0;\n\n\tif (sg_allow_dio && hp->flags & SG_FLAG_DIRECT_IO &&\n\t    dxfer_dir != SG_DXFER_UNKNOWN && !iov_count &&\n\t    !sfp->parentdp->device->host->unchecked_isa_dma &&\n\t    blk_rq_aligned(q, (unsigned long)hp->dxferp, dxfer_len))\n\t\tmd = NULL;\n\telse\n\t\tmd = &map_data;\n\n\tif (md) {\n\t\tmutex_lock(&sfp->f_mutex);\n\t\tif (dxfer_len <= rsv_schp->bufflen &&\n\t\t    !sfp->res_in_use) {\n\t\t\tsfp->res_in_use = 1;\n\t\t\tsg_link_reserve(sfp, srp, dxfer_len);\n\t\t} else if (hp->flags & SG_FLAG_MMAP_IO) {\n\t\t\tres = -EBUSY; /* sfp->res_in_use == 1 */\n\t\t\tif (dxfer_len > rsv_schp->bufflen)\n\t\t\t\tres = -ENOMEM;\n\t\t\tmutex_unlock(&sfp->f_mutex);\n\t\t\treturn res;\n\t\t} else {\n\t\t\tres = sg_build_indirect(req_schp, sfp, dxfer_len);\n\t\t\tif (res) {\n\t\t\t\tmutex_unlock(&sfp->f_mutex);\n\t\t\t\treturn res;\n\t\t\t}\n\t\t}\n\t\tmutex_unlock(&sfp->f_mutex);\n\n\t\tmd->pages = req_schp->pages;\n\t\tmd->page_order = req_schp->page_order;\n\t\tmd->nr_entries = req_schp->k_use_sg;\n\t\tmd->offset = 0;\n\t\tmd->null_mapped = hp->dxferp ? 0 : 1;\n\t\tif (dxfer_dir == SG_DXFER_TO_FROM_DEV)\n\t\t\tmd->from_user = 1;\n\t\telse\n\t\t\tmd->from_user = 0;\n\t}\n\n\tif (iov_count) {\n\t\tstruct iovec *iov = NULL;\n\t\tstruct iov_iter i;\n\n\t\tres = import_iovec(rw, hp->dxferp, iov_count, 0, &iov, &i);\n\t\tif (res < 0)\n\t\t\treturn res;\n\n\t\tiov_iter_truncate(&i, hp->dxfer_len);\n\t\tif (!iov_iter_count(&i)) {\n\t\t\tkfree(iov);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tres = blk_rq_map_user_iov(q, rq, md, &i, GFP_ATOMIC);\n\t\tkfree(iov);\n\t} else\n\t\tres = blk_rq_map_user(q, rq, md, hp->dxferp,\n\t\t\t\t      hp->dxfer_len, GFP_ATOMIC);\n\n\tif (!res) {\n\t\tsrp->bio = rq->bio;\n\n\t\tif (!md) {\n\t\t\treq_schp->dio_in_use = 1;\n\t\t\thp->info |= SG_INFO_DIRECT_IO;\n\t\t}\n\t}\n\treturn res;\n}\n\nstatic int\nsg_finish_rem_req(Sg_request *srp)\n{\n\tint ret = 0;\n\n\tSg_fd *sfp = srp->parentfp;\n\tSg_scatter_hold *req_schp = &srp->data;\n\n\tSCSI_LOG_TIMEOUT(4, sg_printk(KERN_INFO, sfp->parentdp,\n\t\t\t\t      \"sg_finish_rem_req: res_used=%d\\n\",\n\t\t\t\t      (int) srp->res_used));\n\tif (srp->bio)\n\t\tret = blk_rq_unmap_user(srp->bio);\n\n\tif (srp->rq) {\n\t\tscsi_req_free_cmd(scsi_req(srp->rq));\n\t\tblk_put_request(srp->rq);\n\t}\n\n\tif (srp->res_used)\n\t\tsg_unlink_reserve(sfp, srp);\n\telse\n\t\tsg_remove_scat(sfp, req_schp);\n\n\treturn ret;\n}\n\nstatic int\nsg_build_sgat(Sg_scatter_hold * schp, const Sg_fd * sfp, int tablesize)\n{\n\tint sg_bufflen = tablesize * sizeof(struct page *);\n\tgfp_t gfp_flags = GFP_ATOMIC | __GFP_NOWARN;\n\n\tschp->pages = kzalloc(sg_bufflen, gfp_flags);\n\tif (!schp->pages)\n\t\treturn -ENOMEM;\n\tschp->sglist_len = sg_bufflen;\n\treturn tablesize;\t/* number of scat_gath elements allocated */\n}\n\nstatic int\nsg_build_indirect(Sg_scatter_hold * schp, Sg_fd * sfp, int buff_size)\n{\n\tint ret_sz = 0, i, k, rem_sz, num, mx_sc_elems;\n\tint sg_tablesize = sfp->parentdp->sg_tablesize;\n\tint blk_size = buff_size, order;\n\tgfp_t gfp_mask = GFP_ATOMIC | __GFP_COMP | __GFP_NOWARN | __GFP_ZERO;\n\tstruct sg_device *sdp = sfp->parentdp;\n\n\tif (blk_size < 0)\n\t\treturn -EFAULT;\n\tif (0 == blk_size)\n\t\t++blk_size;\t/* don't know why */\n\t/* round request up to next highest SG_SECTOR_SZ byte boundary */\n\tblk_size = ALIGN(blk_size, SG_SECTOR_SZ);\n\tSCSI_LOG_TIMEOUT(4, sg_printk(KERN_INFO, sfp->parentdp,\n\t\t\"sg_build_indirect: buff_size=%d, blk_size=%d\\n\",\n\t\tbuff_size, blk_size));\n\n\t/* N.B. ret_sz carried into this block ... */\n\tmx_sc_elems = sg_build_sgat(schp, sfp, sg_tablesize);\n\tif (mx_sc_elems < 0)\n\t\treturn mx_sc_elems;\t/* most likely -ENOMEM */\n\n\tnum = scatter_elem_sz;\n\tif (unlikely(num != scatter_elem_sz_prev)) {\n\t\tif (num < PAGE_SIZE) {\n\t\t\tscatter_elem_sz = PAGE_SIZE;\n\t\t\tscatter_elem_sz_prev = PAGE_SIZE;\n\t\t} else\n\t\t\tscatter_elem_sz_prev = num;\n\t}\n\n\tif (sdp->device->host->unchecked_isa_dma)\n\t\tgfp_mask |= GFP_DMA;\n\n\torder = get_order(num);\nretry:\n\tret_sz = 1 << (PAGE_SHIFT + order);\n\n\tfor (k = 0, rem_sz = blk_size; rem_sz > 0 && k < mx_sc_elems;\n\t     k++, rem_sz -= ret_sz) {\n\n\t\tnum = (rem_sz > scatter_elem_sz_prev) ?\n\t\t\tscatter_elem_sz_prev : rem_sz;\n\n\t\tschp->pages[k] = alloc_pages(gfp_mask, order);\n\t\tif (!schp->pages[k])\n\t\t\tgoto out;\n\n\t\tif (num == scatter_elem_sz_prev) {\n\t\t\tif (unlikely(ret_sz > scatter_elem_sz_prev)) {\n\t\t\t\tscatter_elem_sz = ret_sz;\n\t\t\t\tscatter_elem_sz_prev = ret_sz;\n\t\t\t}\n\t\t}\n\n\t\tSCSI_LOG_TIMEOUT(5, sg_printk(KERN_INFO, sfp->parentdp,\n\t\t\t\t \"sg_build_indirect: k=%d, num=%d, ret_sz=%d\\n\",\n\t\t\t\t k, num, ret_sz));\n\t}\t\t/* end of for loop */\n\n\tschp->page_order = order;\n\tschp->k_use_sg = k;\n\tSCSI_LOG_TIMEOUT(5, sg_printk(KERN_INFO, sfp->parentdp,\n\t\t\t \"sg_build_indirect: k_use_sg=%d, rem_sz=%d\\n\",\n\t\t\t k, rem_sz));\n\n\tschp->bufflen = blk_size;\n\tif (rem_sz > 0)\t/* must have failed */\n\t\treturn -ENOMEM;\n\treturn 0;\nout:\n\tfor (i = 0; i < k; i++)\n\t\t__free_pages(schp->pages[i], order);\n\n\tif (--order >= 0)\n\t\tgoto retry;\n\n\treturn -ENOMEM;\n}\n\nstatic void\nsg_remove_scat(Sg_fd * sfp, Sg_scatter_hold * schp)\n{\n\tSCSI_LOG_TIMEOUT(4, sg_printk(KERN_INFO, sfp->parentdp,\n\t\t\t \"sg_remove_scat: k_use_sg=%d\\n\", schp->k_use_sg));\n\tif (schp->pages && schp->sglist_len > 0) {\n\t\tif (!schp->dio_in_use) {\n\t\t\tint k;\n\n\t\t\tfor (k = 0; k < schp->k_use_sg && schp->pages[k]; k++) {\n\t\t\t\tSCSI_LOG_TIMEOUT(5,\n\t\t\t\t\tsg_printk(KERN_INFO, sfp->parentdp,\n\t\t\t\t\t\"sg_remove_scat: k=%d, pg=0x%p\\n\",\n\t\t\t\t\tk, schp->pages[k]));\n\t\t\t\t__free_pages(schp->pages[k], schp->page_order);\n\t\t\t}\n\n\t\t\tkfree(schp->pages);\n\t\t}\n\t}\n\tmemset(schp, 0, sizeof (*schp));\n}\n\nstatic int\nsg_read_oxfer(Sg_request * srp, char __user *outp, int num_read_xfer)\n{\n\tSg_scatter_hold *schp = &srp->data;\n\tint k, num;\n\n\tSCSI_LOG_TIMEOUT(4, sg_printk(KERN_INFO, srp->parentfp->parentdp,\n\t\t\t \"sg_read_oxfer: num_read_xfer=%d\\n\",\n\t\t\t num_read_xfer));\n\tif ((!outp) || (num_read_xfer <= 0))\n\t\treturn 0;\n\n\tnum = 1 << (PAGE_SHIFT + schp->page_order);\n\tfor (k = 0; k < schp->k_use_sg && schp->pages[k]; k++) {\n\t\tif (num > num_read_xfer) {\n\t\t\tif (copy_to_user(outp, page_address(schp->pages[k]),\n\t\t\t\t\t   num_read_xfer))\n\t\t\t\treturn -EFAULT;\n\t\t\tbreak;\n\t\t} else {\n\t\t\tif (copy_to_user(outp, page_address(schp->pages[k]),\n\t\t\t\t\t   num))\n\t\t\t\treturn -EFAULT;\n\t\t\tnum_read_xfer -= num;\n\t\t\tif (num_read_xfer <= 0)\n\t\t\t\tbreak;\n\t\t\toutp += num;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void\nsg_build_reserve(Sg_fd * sfp, int req_size)\n{\n\tSg_scatter_hold *schp = &sfp->reserve;\n\n\tSCSI_LOG_TIMEOUT(4, sg_printk(KERN_INFO, sfp->parentdp,\n\t\t\t \"sg_build_reserve: req_size=%d\\n\", req_size));\n\tdo {\n\t\tif (req_size < PAGE_SIZE)\n\t\t\treq_size = PAGE_SIZE;\n\t\tif (0 == sg_build_indirect(schp, sfp, req_size))\n\t\t\treturn;\n\t\telse\n\t\t\tsg_remove_scat(sfp, schp);\n\t\treq_size >>= 1;\t/* divide by 2 */\n\t} while (req_size > (PAGE_SIZE / 2));\n}\n\nstatic void\nsg_link_reserve(Sg_fd * sfp, Sg_request * srp, int size)\n{\n\tSg_scatter_hold *req_schp = &srp->data;\n\tSg_scatter_hold *rsv_schp = &sfp->reserve;\n\tint k, num, rem;\n\n\tsrp->res_used = 1;\n\tSCSI_LOG_TIMEOUT(4, sg_printk(KERN_INFO, sfp->parentdp,\n\t\t\t \"sg_link_reserve: size=%d\\n\", size));\n\trem = size;\n\n\tnum = 1 << (PAGE_SHIFT + rsv_schp->page_order);\n\tfor (k = 0; k < rsv_schp->k_use_sg; k++) {\n\t\tif (rem <= num) {\n\t\t\treq_schp->k_use_sg = k + 1;\n\t\t\treq_schp->sglist_len = rsv_schp->sglist_len;\n\t\t\treq_schp->pages = rsv_schp->pages;\n\n\t\t\treq_schp->bufflen = size;\n\t\t\treq_schp->page_order = rsv_schp->page_order;\n\t\t\tbreak;\n\t\t} else\n\t\t\trem -= num;\n\t}\n\n\tif (k >= rsv_schp->k_use_sg)\n\t\tSCSI_LOG_TIMEOUT(1, sg_printk(KERN_INFO, sfp->parentdp,\n\t\t\t\t \"sg_link_reserve: BAD size\\n\"));\n}\n\nstatic void\nsg_unlink_reserve(Sg_fd * sfp, Sg_request * srp)\n{\n\tSg_scatter_hold *req_schp = &srp->data;\n\n\tSCSI_LOG_TIMEOUT(4, sg_printk(KERN_INFO, srp->parentfp->parentdp,\n\t\t\t\t      \"sg_unlink_reserve: req->k_use_sg=%d\\n\",\n\t\t\t\t      (int) req_schp->k_use_sg));\n\treq_schp->k_use_sg = 0;\n\treq_schp->bufflen = 0;\n\treq_schp->pages = NULL;\n\treq_schp->page_order = 0;\n\treq_schp->sglist_len = 0;\n\tsrp->res_used = 0;\n\t/* Called without mutex lock to avoid deadlock */\n\tsfp->res_in_use = 0;\n}\n\nstatic Sg_request *\nsg_get_rq_mark(Sg_fd * sfp, int pack_id)\n{\n\tSg_request *resp;\n\tunsigned long iflags;\n\n\twrite_lock_irqsave(&sfp->rq_list_lock, iflags);\n\tlist_for_each_entry(resp, &sfp->rq_list, entry) {\n\t\t/* look for requests that are ready + not SG_IO owned */\n\t\tif ((1 == resp->done) && (!resp->sg_io_owned) &&\n\t\t    ((-1 == pack_id) || (resp->header.pack_id == pack_id))) {\n\t\t\tresp->done = 2;\t/* guard against other readers */\n\t\t\twrite_unlock_irqrestore(&sfp->rq_list_lock, iflags);\n\t\t\treturn resp;\n\t\t}\n\t}\n\twrite_unlock_irqrestore(&sfp->rq_list_lock, iflags);\n\treturn NULL;\n}\n\n/* always adds to end of list */\nstatic Sg_request *\nsg_add_request(Sg_fd * sfp)\n{\n\tint k;\n\tunsigned long iflags;\n\tSg_request *rp = sfp->req_arr;\n\n\twrite_lock_irqsave(&sfp->rq_list_lock, iflags);\n\tif (!list_empty(&sfp->rq_list)) {\n\t\tif (!sfp->cmd_q)\n\t\t\tgoto out_unlock;\n\n\t\tfor (k = 0; k < SG_MAX_QUEUE; ++k, ++rp) {\n\t\t\tif (!rp->parentfp)\n\t\t\t\tbreak;\n\t\t}\n\t\tif (k >= SG_MAX_QUEUE)\n\t\t\tgoto out_unlock;\n\t}\n\tmemset(rp, 0, sizeof (Sg_request));\n\trp->parentfp = sfp;\n\trp->header.duration = jiffies_to_msecs(jiffies);\n\tlist_add_tail(&rp->entry, &sfp->rq_list);\n\twrite_unlock_irqrestore(&sfp->rq_list_lock, iflags);\n\treturn rp;\nout_unlock:\n\twrite_unlock_irqrestore(&sfp->rq_list_lock, iflags);\n\treturn NULL;\n}\n\n/* Return of 1 for found; 0 for not found */\nstatic int\nsg_remove_request(Sg_fd * sfp, Sg_request * srp)\n{\n\tunsigned long iflags;\n\tint res = 0;\n\n\tif (!sfp || !srp || list_empty(&sfp->rq_list))\n\t\treturn res;\n\twrite_lock_irqsave(&sfp->rq_list_lock, iflags);\n\tif (!list_empty(&srp->entry)) {\n\t\tlist_del(&srp->entry);\n\t\tsrp->parentfp = NULL;\n\t\tres = 1;\n\t}\n\twrite_unlock_irqrestore(&sfp->rq_list_lock, iflags);\n\treturn res;\n}\n\nstatic Sg_fd *\nsg_add_sfp(Sg_device * sdp)\n{\n\tSg_fd *sfp;\n\tunsigned long iflags;\n\tint bufflen;\n\n\tsfp = kzalloc(sizeof(*sfp), GFP_ATOMIC | __GFP_NOWARN);\n\tif (!sfp)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tinit_waitqueue_head(&sfp->read_wait);\n\trwlock_init(&sfp->rq_list_lock);\n\tINIT_LIST_HEAD(&sfp->rq_list);\n\tkref_init(&sfp->f_ref);\n\tmutex_init(&sfp->f_mutex);\n\tsfp->timeout = SG_DEFAULT_TIMEOUT;\n\tsfp->timeout_user = SG_DEFAULT_TIMEOUT_USER;\n\tsfp->force_packid = SG_DEF_FORCE_PACK_ID;\n\tsfp->cmd_q = SG_DEF_COMMAND_Q;\n\tsfp->keep_orphan = SG_DEF_KEEP_ORPHAN;\n\tsfp->parentdp = sdp;\n\twrite_lock_irqsave(&sdp->sfd_lock, iflags);\n\tif (atomic_read(&sdp->detaching)) {\n\t\twrite_unlock_irqrestore(&sdp->sfd_lock, iflags);\n\t\tkfree(sfp);\n\t\treturn ERR_PTR(-ENODEV);\n\t}\n\tlist_add_tail(&sfp->sfd_siblings, &sdp->sfds);\n\twrite_unlock_irqrestore(&sdp->sfd_lock, iflags);\n\tSCSI_LOG_TIMEOUT(3, sg_printk(KERN_INFO, sdp,\n\t\t\t\t      \"sg_add_sfp: sfp=0x%p\\n\", sfp));\n\tif (unlikely(sg_big_buff != def_reserved_size))\n\t\tsg_big_buff = def_reserved_size;\n\n\tbufflen = min_t(int, sg_big_buff,\n\t\t\tmax_sectors_bytes(sdp->device->request_queue));\n\tsg_build_reserve(sfp, bufflen);\n\tSCSI_LOG_TIMEOUT(3, sg_printk(KERN_INFO, sdp,\n\t\t\t\t      \"sg_add_sfp: bufflen=%d, k_use_sg=%d\\n\",\n\t\t\t\t      sfp->reserve.bufflen,\n\t\t\t\t      sfp->reserve.k_use_sg));\n\n\tkref_get(&sdp->d_ref);\n\t__module_get(THIS_MODULE);\n\treturn sfp;\n}\n\nstatic void\nsg_remove_sfp_usercontext(struct work_struct *work)\n{\n\tstruct sg_fd *sfp = container_of(work, struct sg_fd, ew.work);\n\tstruct sg_device *sdp = sfp->parentdp;\n\tSg_request *srp;\n\tunsigned long iflags;\n\n\t/* Cleanup any responses which were never read(). */\n\twrite_lock_irqsave(&sfp->rq_list_lock, iflags);\n\twhile (!list_empty(&sfp->rq_list)) {\n\t\tsrp = list_first_entry(&sfp->rq_list, Sg_request, entry);\n\t\tsg_finish_rem_req(srp);\n\t\tlist_del(&srp->entry);\n\t\tsrp->parentfp = NULL;\n\t}\n\twrite_unlock_irqrestore(&sfp->rq_list_lock, iflags);\n\n\tif (sfp->reserve.bufflen > 0) {\n\t\tSCSI_LOG_TIMEOUT(6, sg_printk(KERN_INFO, sdp,\n\t\t\t\t\"sg_remove_sfp:    bufflen=%d, k_use_sg=%d\\n\",\n\t\t\t\t(int) sfp->reserve.bufflen,\n\t\t\t\t(int) sfp->reserve.k_use_sg));\n\t\tsg_remove_scat(sfp, &sfp->reserve);\n\t}\n\n\tSCSI_LOG_TIMEOUT(6, sg_printk(KERN_INFO, sdp,\n\t\t\t\"sg_remove_sfp: sfp=0x%p\\n\", sfp));\n\tkfree(sfp);\n\n\tscsi_device_put(sdp->device);\n\tkref_put(&sdp->d_ref, sg_device_destroy);\n\tmodule_put(THIS_MODULE);\n}\n\nstatic void\nsg_remove_sfp(struct kref *kref)\n{\n\tstruct sg_fd *sfp = container_of(kref, struct sg_fd, f_ref);\n\tstruct sg_device *sdp = sfp->parentdp;\n\tunsigned long iflags;\n\n\twrite_lock_irqsave(&sdp->sfd_lock, iflags);\n\tlist_del(&sfp->sfd_siblings);\n\twrite_unlock_irqrestore(&sdp->sfd_lock, iflags);\n\n\tINIT_WORK(&sfp->ew.work, sg_remove_sfp_usercontext);\n\tschedule_work(&sfp->ew.work);\n}\n\n#ifdef CONFIG_SCSI_PROC_FS\nstatic int\nsg_idr_max_id(int id, void *p, void *data)\n{\n\tint *k = data;\n\n\tif (*k < id)\n\t\t*k = id;\n\n\treturn 0;\n}\n\nstatic int\nsg_last_dev(void)\n{\n\tint k = -1;\n\tunsigned long iflags;\n\n\tread_lock_irqsave(&sg_index_lock, iflags);\n\tidr_for_each(&sg_index_idr, sg_idr_max_id, &k);\n\tread_unlock_irqrestore(&sg_index_lock, iflags);\n\treturn k + 1;\t\t/* origin 1 */\n}\n#endif\n\n/* must be called with sg_index_lock held */\nstatic Sg_device *sg_lookup_dev(int dev)\n{\n\treturn idr_find(&sg_index_idr, dev);\n}\n\nstatic Sg_device *\nsg_get_dev(int dev)\n{\n\tstruct sg_device *sdp;\n\tunsigned long flags;\n\n\tread_lock_irqsave(&sg_index_lock, flags);\n\tsdp = sg_lookup_dev(dev);\n\tif (!sdp)\n\t\tsdp = ERR_PTR(-ENXIO);\n\telse if (atomic_read(&sdp->detaching)) {\n\t\t/* If sdp->detaching, then the refcount may already be 0, in\n\t\t * which case it would be a bug to do kref_get().\n\t\t */\n\t\tsdp = ERR_PTR(-ENODEV);\n\t} else\n\t\tkref_get(&sdp->d_ref);\n\tread_unlock_irqrestore(&sg_index_lock, flags);\n\n\treturn sdp;\n}\n\n#ifdef CONFIG_SCSI_PROC_FS\nstatic int sg_proc_seq_show_int(struct seq_file *s, void *v);\n\nstatic int sg_proc_single_open_adio(struct inode *inode, struct file *file);\nstatic ssize_t sg_proc_write_adio(struct file *filp, const char __user *buffer,\n\t\t\t          size_t count, loff_t *off);\nstatic const struct proc_ops adio_proc_ops = {\n\t.proc_open\t= sg_proc_single_open_adio,\n\t.proc_read\t= seq_read,\n\t.proc_lseek\t= seq_lseek,\n\t.proc_write\t= sg_proc_write_adio,\n\t.proc_release\t= single_release,\n};\n\nstatic int sg_proc_single_open_dressz(struct inode *inode, struct file *file);\nstatic ssize_t sg_proc_write_dressz(struct file *filp, \n\t\tconst char __user *buffer, size_t count, loff_t *off);\nstatic const struct proc_ops dressz_proc_ops = {\n\t.proc_open\t= sg_proc_single_open_dressz,\n\t.proc_read\t= seq_read,\n\t.proc_lseek\t= seq_lseek,\n\t.proc_write\t= sg_proc_write_dressz,\n\t.proc_release\t= single_release,\n};\n\nstatic int sg_proc_seq_show_version(struct seq_file *s, void *v);\nstatic int sg_proc_seq_show_devhdr(struct seq_file *s, void *v);\nstatic int sg_proc_seq_show_dev(struct seq_file *s, void *v);\nstatic void * dev_seq_start(struct seq_file *s, loff_t *pos);\nstatic void * dev_seq_next(struct seq_file *s, void *v, loff_t *pos);\nstatic void dev_seq_stop(struct seq_file *s, void *v);\nstatic const struct seq_operations dev_seq_ops = {\n\t.start = dev_seq_start,\n\t.next  = dev_seq_next,\n\t.stop  = dev_seq_stop,\n\t.show  = sg_proc_seq_show_dev,\n};\n\nstatic int sg_proc_seq_show_devstrs(struct seq_file *s, void *v);\nstatic const struct seq_operations devstrs_seq_ops = {\n\t.start = dev_seq_start,\n\t.next  = dev_seq_next,\n\t.stop  = dev_seq_stop,\n\t.show  = sg_proc_seq_show_devstrs,\n};\n\nstatic int sg_proc_seq_show_debug(struct seq_file *s, void *v);\nstatic const struct seq_operations debug_seq_ops = {\n\t.start = dev_seq_start,\n\t.next  = dev_seq_next,\n\t.stop  = dev_seq_stop,\n\t.show  = sg_proc_seq_show_debug,\n};\n\nstatic int\nsg_proc_init(void)\n{\n\tstruct proc_dir_entry *p;\n\n\tp = proc_mkdir(\"scsi/sg\", NULL);\n\tif (!p)\n\t\treturn 1;\n\n\tproc_create(\"allow_dio\", S_IRUGO | S_IWUSR, p, &adio_proc_ops);\n\tproc_create_seq(\"debug\", S_IRUGO, p, &debug_seq_ops);\n\tproc_create(\"def_reserved_size\", S_IRUGO | S_IWUSR, p, &dressz_proc_ops);\n\tproc_create_single(\"device_hdr\", S_IRUGO, p, sg_proc_seq_show_devhdr);\n\tproc_create_seq(\"devices\", S_IRUGO, p, &dev_seq_ops);\n\tproc_create_seq(\"device_strs\", S_IRUGO, p, &devstrs_seq_ops);\n\tproc_create_single(\"version\", S_IRUGO, p, sg_proc_seq_show_version);\n\treturn 0;\n}\n\n\nstatic int sg_proc_seq_show_int(struct seq_file *s, void *v)\n{\n\tseq_printf(s, \"%d\\n\", *((int *)s->private));\n\treturn 0;\n}\n\nstatic int sg_proc_single_open_adio(struct inode *inode, struct file *file)\n{\n\treturn single_open(file, sg_proc_seq_show_int, &sg_allow_dio);\n}\n\nstatic ssize_t \nsg_proc_write_adio(struct file *filp, const char __user *buffer,\n\t\t   size_t count, loff_t *off)\n{\n\tint err;\n\tunsigned long num;\n\n\tif (!capable(CAP_SYS_ADMIN) || !capable(CAP_SYS_RAWIO))\n\t\treturn -EACCES;\n\terr = kstrtoul_from_user(buffer, count, 0, &num);\n\tif (err)\n\t\treturn err;\n\tsg_allow_dio = num ? 1 : 0;\n\treturn count;\n}\n\nstatic int sg_proc_single_open_dressz(struct inode *inode, struct file *file)\n{\n\treturn single_open(file, sg_proc_seq_show_int, &sg_big_buff);\n}\n\nstatic ssize_t \nsg_proc_write_dressz(struct file *filp, const char __user *buffer,\n\t\t     size_t count, loff_t *off)\n{\n\tint err;\n\tunsigned long k = ULONG_MAX;\n\n\tif (!capable(CAP_SYS_ADMIN) || !capable(CAP_SYS_RAWIO))\n\t\treturn -EACCES;\n\n\terr = kstrtoul_from_user(buffer, count, 0, &k);\n\tif (err)\n\t\treturn err;\n\tif (k <= 1048576) {\t/* limit \"big buff\" to 1 MB */\n\t\tsg_big_buff = k;\n\t\treturn count;\n\t}\n\treturn -ERANGE;\n}\n\nstatic int sg_proc_seq_show_version(struct seq_file *s, void *v)\n{\n\tseq_printf(s, \"%d\\t%s [%s]\\n\", sg_version_num, SG_VERSION_STR,\n\t\t   sg_version_date);\n\treturn 0;\n}\n\nstatic int sg_proc_seq_show_devhdr(struct seq_file *s, void *v)\n{\n\tseq_puts(s, \"host\\tchan\\tid\\tlun\\ttype\\topens\\tqdepth\\tbusy\\tonline\\n\");\n\treturn 0;\n}\n\nstruct sg_proc_deviter {\n\tloff_t\tindex;\n\tsize_t\tmax;\n};\n\nstatic void * dev_seq_start(struct seq_file *s, loff_t *pos)\n{\n\tstruct sg_proc_deviter * it = kmalloc(sizeof(*it), GFP_KERNEL);\n\n\ts->private = it;\n\tif (! it)\n\t\treturn NULL;\n\n\tit->index = *pos;\n\tit->max = sg_last_dev();\n\tif (it->index >= it->max)\n\t\treturn NULL;\n\treturn it;\n}\n\nstatic void * dev_seq_next(struct seq_file *s, void *v, loff_t *pos)\n{\n\tstruct sg_proc_deviter * it = s->private;\n\n\t*pos = ++it->index;\n\treturn (it->index < it->max) ? it : NULL;\n}\n\nstatic void dev_seq_stop(struct seq_file *s, void *v)\n{\n\tkfree(s->private);\n}\n\nstatic int sg_proc_seq_show_dev(struct seq_file *s, void *v)\n{\n\tstruct sg_proc_deviter * it = (struct sg_proc_deviter *) v;\n\tSg_device *sdp;\n\tstruct scsi_device *scsidp;\n\tunsigned long iflags;\n\n\tread_lock_irqsave(&sg_index_lock, iflags);\n\tsdp = it ? sg_lookup_dev(it->index) : NULL;\n\tif ((NULL == sdp) || (NULL == sdp->device) ||\n\t    (atomic_read(&sdp->detaching)))\n\t\tseq_puts(s, \"-1\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1\\n\");\n\telse {\n\t\tscsidp = sdp->device;\n\t\tseq_printf(s, \"%d\\t%d\\t%d\\t%llu\\t%d\\t%d\\t%d\\t%d\\t%d\\n\",\n\t\t\t      scsidp->host->host_no, scsidp->channel,\n\t\t\t      scsidp->id, scsidp->lun, (int) scsidp->type,\n\t\t\t      1,\n\t\t\t      (int) scsidp->queue_depth,\n\t\t\t      (int) scsi_device_busy(scsidp),\n\t\t\t      (int) scsi_device_online(scsidp));\n\t}\n\tread_unlock_irqrestore(&sg_index_lock, iflags);\n\treturn 0;\n}\n\nstatic int sg_proc_seq_show_devstrs(struct seq_file *s, void *v)\n{\n\tstruct sg_proc_deviter * it = (struct sg_proc_deviter *) v;\n\tSg_device *sdp;\n\tstruct scsi_device *scsidp;\n\tunsigned long iflags;\n\n\tread_lock_irqsave(&sg_index_lock, iflags);\n\tsdp = it ? sg_lookup_dev(it->index) : NULL;\n\tscsidp = sdp ? sdp->device : NULL;\n\tif (sdp && scsidp && (!atomic_read(&sdp->detaching)))\n\t\tseq_printf(s, \"%8.8s\\t%16.16s\\t%4.4s\\n\",\n\t\t\t   scsidp->vendor, scsidp->model, scsidp->rev);\n\telse\n\t\tseq_puts(s, \"<no active device>\\n\");\n\tread_unlock_irqrestore(&sg_index_lock, iflags);\n\treturn 0;\n}\n\n/* must be called while holding sg_index_lock */\nstatic void sg_proc_debug_helper(struct seq_file *s, Sg_device * sdp)\n{\n\tint k, new_interface, blen, usg;\n\tSg_request *srp;\n\tSg_fd *fp;\n\tconst sg_io_hdr_t *hp;\n\tconst char * cp;\n\tunsigned int ms;\n\n\tk = 0;\n\tlist_for_each_entry(fp, &sdp->sfds, sfd_siblings) {\n\t\tk++;\n\t\tread_lock(&fp->rq_list_lock); /* irqs already disabled */\n\t\tseq_printf(s, \"   FD(%d): timeout=%dms bufflen=%d \"\n\t\t\t   \"(res)sgat=%d low_dma=%d\\n\", k,\n\t\t\t   jiffies_to_msecs(fp->timeout),\n\t\t\t   fp->reserve.bufflen,\n\t\t\t   (int) fp->reserve.k_use_sg,\n\t\t\t   (int) sdp->device->host->unchecked_isa_dma);\n\t\tseq_printf(s, \"   cmd_q=%d f_packid=%d k_orphan=%d closed=0\\n\",\n\t\t\t   (int) fp->cmd_q, (int) fp->force_packid,\n\t\t\t   (int) fp->keep_orphan);\n\t\tlist_for_each_entry(srp, &fp->rq_list, entry) {\n\t\t\thp = &srp->header;\n\t\t\tnew_interface = (hp->interface_id == '\\0') ? 0 : 1;\n\t\t\tif (srp->res_used) {\n\t\t\t\tif (new_interface &&\n\t\t\t\t    (SG_FLAG_MMAP_IO & hp->flags))\n\t\t\t\t\tcp = \"     mmap>> \";\n\t\t\t\telse\n\t\t\t\t\tcp = \"     rb>> \";\n\t\t\t} else {\n\t\t\t\tif (SG_INFO_DIRECT_IO_MASK & hp->info)\n\t\t\t\t\tcp = \"     dio>> \";\n\t\t\t\telse\n\t\t\t\t\tcp = \"     \";\n\t\t\t}\n\t\t\tseq_puts(s, cp);\n\t\t\tblen = srp->data.bufflen;\n\t\t\tusg = srp->data.k_use_sg;\n\t\t\tseq_puts(s, srp->done ?\n\t\t\t\t ((1 == srp->done) ?  \"rcv:\" : \"fin:\")\n\t\t\t\t  : \"act:\");\n\t\t\tseq_printf(s, \" id=%d blen=%d\",\n\t\t\t\t   srp->header.pack_id, blen);\n\t\t\tif (srp->done)\n\t\t\t\tseq_printf(s, \" dur=%d\", hp->duration);\n\t\t\telse {\n\t\t\t\tms = jiffies_to_msecs(jiffies);\n\t\t\t\tseq_printf(s, \" t_o/elap=%d/%d\",\n\t\t\t\t\t(new_interface ? hp->timeout :\n\t\t\t\t\t\t  jiffies_to_msecs(fp->timeout)),\n\t\t\t\t\t(ms > hp->duration ? ms - hp->duration : 0));\n\t\t\t}\n\t\t\tseq_printf(s, \"ms sgat=%d op=0x%02x\\n\", usg,\n\t\t\t\t   (int) srp->data.cmd_opcode);\n\t\t}\n\t\tif (list_empty(&fp->rq_list))\n\t\t\tseq_puts(s, \"     No requests active\\n\");\n\t\tread_unlock(&fp->rq_list_lock);\n\t}\n}\n\nstatic int sg_proc_seq_show_debug(struct seq_file *s, void *v)\n{\n\tstruct sg_proc_deviter * it = (struct sg_proc_deviter *) v;\n\tSg_device *sdp;\n\tunsigned long iflags;\n\n\tif (it && (0 == it->index))\n\t\tseq_printf(s, \"max_active_device=%d  def_reserved_size=%d\\n\",\n\t\t\t   (int)it->max, sg_big_buff);\n\n\tread_lock_irqsave(&sg_index_lock, iflags);\n\tsdp = it ? sg_lookup_dev(it->index) : NULL;\n\tif (NULL == sdp)\n\t\tgoto skip;\n\tread_lock(&sdp->sfd_lock);\n\tif (!list_empty(&sdp->sfds)) {\n\t\tseq_printf(s, \" >>> device=%s \", sdp->disk->disk_name);\n\t\tif (atomic_read(&sdp->detaching))\n\t\t\tseq_puts(s, \"detaching pending close \");\n\t\telse if (sdp->device) {\n\t\t\tstruct scsi_device *scsidp = sdp->device;\n\n\t\t\tseq_printf(s, \"%d:%d:%d:%llu   em=%d\",\n\t\t\t\t   scsidp->host->host_no,\n\t\t\t\t   scsidp->channel, scsidp->id,\n\t\t\t\t   scsidp->lun,\n\t\t\t\t   scsidp->host->hostt->emulated);\n\t\t}\n\t\tseq_printf(s, \" sg_tablesize=%d excl=%d open_cnt=%d\\n\",\n\t\t\t   sdp->sg_tablesize, sdp->exclude, sdp->open_cnt);\n\t\tsg_proc_debug_helper(s, sdp);\n\t}\n\tread_unlock(&sdp->sfd_lock);\nskip:\n\tread_unlock_irqrestore(&sg_index_lock, iflags);\n\treturn 0;\n}\n\n#endif\t\t\t\t/* CONFIG_SCSI_PROC_FS */\n\nmodule_init(init_sg);\nmodule_exit(exit_sg);\n"}, "2": {"id": 2, "path": "/src/include/linux/cred.h", "content": "/* SPDX-License-Identifier: GPL-2.0-or-later */\n/* Credentials management - see Documentation/security/credentials.rst\n *\n * Copyright (C) 2008 Red Hat, Inc. All Rights Reserved.\n * Written by David Howells (dhowells@redhat.com)\n */\n\n#ifndef _LINUX_CRED_H\n#define _LINUX_CRED_H\n\n#include <linux/capability.h>\n#include <linux/init.h>\n#include <linux/key.h>\n#include <linux/atomic.h>\n#include <linux/uidgid.h>\n#include <linux/sched.h>\n#include <linux/sched/user.h>\n\nstruct cred;\nstruct inode;\n\n/*\n * COW Supplementary groups list\n */\nstruct group_info {\n\tatomic_t\tusage;\n\tint\t\tngroups;\n\tkgid_t\t\tgid[];\n} __randomize_layout;\n\n/**\n * get_group_info - Get a reference to a group info structure\n * @group_info: The group info to reference\n *\n * This gets a reference to a set of supplementary groups.\n *\n * If the caller is accessing a task's credentials, they must hold the RCU read\n * lock when reading.\n */\nstatic inline struct group_info *get_group_info(struct group_info *gi)\n{\n\tatomic_inc(&gi->usage);\n\treturn gi;\n}\n\n/**\n * put_group_info - Release a reference to a group info structure\n * @group_info: The group info to release\n */\n#define put_group_info(group_info)\t\t\t\\\ndo {\t\t\t\t\t\t\t\\\n\tif (atomic_dec_and_test(&(group_info)->usage))\t\\\n\t\tgroups_free(group_info);\t\t\\\n} while (0)\n\n#ifdef CONFIG_MULTIUSER\nextern struct group_info *groups_alloc(int);\nextern void groups_free(struct group_info *);\n\nextern int in_group_p(kgid_t);\nextern int in_egroup_p(kgid_t);\nextern int groups_search(const struct group_info *, kgid_t);\n\nextern int set_current_groups(struct group_info *);\nextern void set_groups(struct cred *, struct group_info *);\nextern bool may_setgroups(void);\nextern void groups_sort(struct group_info *);\n#else\nstatic inline void groups_free(struct group_info *group_info)\n{\n}\n\nstatic inline int in_group_p(kgid_t grp)\n{\n        return 1;\n}\nstatic inline int in_egroup_p(kgid_t grp)\n{\n        return 1;\n}\nstatic inline int groups_search(const struct group_info *group_info, kgid_t grp)\n{\n\treturn 1;\n}\n#endif\n\n/*\n * The security context of a task\n *\n * The parts of the context break down into two categories:\n *\n *  (1) The objective context of a task.  These parts are used when some other\n *\ttask is attempting to affect this one.\n *\n *  (2) The subjective context.  These details are used when the task is acting\n *\tupon another object, be that a file, a task, a key or whatever.\n *\n * Note that some members of this structure belong to both categories - the\n * LSM security pointer for instance.\n *\n * A task has two security pointers.  task->real_cred points to the objective\n * context that defines that task's actual details.  The objective part of this\n * context is used whenever that task is acted upon.\n *\n * task->cred points to the subjective context that defines the details of how\n * that task is going to act upon another object.  This may be overridden\n * temporarily to point to another security context, but normally points to the\n * same context as task->real_cred.\n */\nstruct cred {\n\tatomic_t\tusage;\n#ifdef CONFIG_DEBUG_CREDENTIALS\n\tatomic_t\tsubscribers;\t/* number of processes subscribed */\n\tvoid\t\t*put_addr;\n\tunsigned\tmagic;\n#define CRED_MAGIC\t0x43736564\n#define CRED_MAGIC_DEAD\t0x44656144\n#endif\n\tkuid_t\t\tuid;\t\t/* real UID of the task */\n\tkgid_t\t\tgid;\t\t/* real GID of the task */\n\tkuid_t\t\tsuid;\t\t/* saved UID of the task */\n\tkgid_t\t\tsgid;\t\t/* saved GID of the task */\n\tkuid_t\t\teuid;\t\t/* effective UID of the task */\n\tkgid_t\t\tegid;\t\t/* effective GID of the task */\n\tkuid_t\t\tfsuid;\t\t/* UID for VFS ops */\n\tkgid_t\t\tfsgid;\t\t/* GID for VFS ops */\n\tunsigned\tsecurebits;\t/* SUID-less security management */\n\tkernel_cap_t\tcap_inheritable; /* caps our children can inherit */\n\tkernel_cap_t\tcap_permitted;\t/* caps we're permitted */\n\tkernel_cap_t\tcap_effective;\t/* caps we can actually use */\n\tkernel_cap_t\tcap_bset;\t/* capability bounding set */\n\tkernel_cap_t\tcap_ambient;\t/* Ambient capability set */\n#ifdef CONFIG_KEYS\n\tunsigned char\tjit_keyring;\t/* default keyring to attach requested\n\t\t\t\t\t * keys to */\n\tstruct key\t*session_keyring; /* keyring inherited over fork */\n\tstruct key\t*process_keyring; /* keyring private to this process */\n\tstruct key\t*thread_keyring; /* keyring private to this thread */\n\tstruct key\t*request_key_auth; /* assumed request_key authority */\n#endif\n#ifdef CONFIG_SECURITY\n\tvoid\t\t*security;\t/* subjective LSM security */\n#endif\n\tstruct user_struct *user;\t/* real user ID subscription */\n\tstruct user_namespace *user_ns; /* user_ns the caps and keyrings are relative to. */\n\tstruct group_info *group_info;\t/* supplementary groups for euid/fsgid */\n\t/* RCU deletion */\n\tunion {\n\t\tint non_rcu;\t\t\t/* Can we skip RCU deletion? */\n\t\tstruct rcu_head\trcu;\t\t/* RCU deletion hook */\n\t};\n} __randomize_layout;\n\nextern void __put_cred(struct cred *);\nextern void exit_creds(struct task_struct *);\nextern int copy_creds(struct task_struct *, unsigned long);\nextern const struct cred *get_task_cred(struct task_struct *);\nextern struct cred *cred_alloc_blank(void);\nextern struct cred *prepare_creds(void);\nextern struct cred *prepare_exec_creds(void);\nextern int commit_creds(struct cred *);\nextern void abort_creds(struct cred *);\nextern const struct cred *override_creds(const struct cred *);\nextern void revert_creds(const struct cred *);\nextern struct cred *prepare_kernel_cred(struct task_struct *);\nextern int change_create_files_as(struct cred *, struct inode *);\nextern int set_security_override(struct cred *, u32);\nextern int set_security_override_from_ctx(struct cred *, const char *);\nextern int set_create_files_as(struct cred *, struct inode *);\nextern int cred_fscmp(const struct cred *, const struct cred *);\nextern void __init cred_init(void);\n\n/*\n * check for validity of credentials\n */\n#ifdef CONFIG_DEBUG_CREDENTIALS\nextern void __invalid_creds(const struct cred *, const char *, unsigned);\nextern void __validate_process_creds(struct task_struct *,\n\t\t\t\t     const char *, unsigned);\n\nextern bool creds_are_invalid(const struct cred *cred);\n\nstatic inline void __validate_creds(const struct cred *cred,\n\t\t\t\t    const char *file, unsigned line)\n{\n\tif (unlikely(creds_are_invalid(cred)))\n\t\t__invalid_creds(cred, file, line);\n}\n\n#define validate_creds(cred)\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\\\n\t__validate_creds((cred), __FILE__, __LINE__);\t\\\n} while(0)\n\n#define validate_process_creds()\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\\\n\t__validate_process_creds(current, __FILE__, __LINE__);\t\\\n} while(0)\n\nextern void validate_creds_for_do_exit(struct task_struct *);\n#else\nstatic inline void validate_creds(const struct cred *cred)\n{\n}\nstatic inline void validate_creds_for_do_exit(struct task_struct *tsk)\n{\n}\nstatic inline void validate_process_creds(void)\n{\n}\n#endif\n\nstatic inline bool cap_ambient_invariant_ok(const struct cred *cred)\n{\n\treturn cap_issubset(cred->cap_ambient,\n\t\t\t    cap_intersect(cred->cap_permitted,\n\t\t\t\t\t  cred->cap_inheritable));\n}\n\n/**\n * get_new_cred - Get a reference on a new set of credentials\n * @cred: The new credentials to reference\n *\n * Get a reference on the specified set of new credentials.  The caller must\n * release the reference.\n */\nstatic inline struct cred *get_new_cred(struct cred *cred)\n{\n\tatomic_inc(&cred->usage);\n\treturn cred;\n}\n\n/**\n * get_cred - Get a reference on a set of credentials\n * @cred: The credentials to reference\n *\n * Get a reference on the specified set of credentials.  The caller must\n * release the reference.  If %NULL is passed, it is returned with no action.\n *\n * This is used to deal with a committed set of credentials.  Although the\n * pointer is const, this will temporarily discard the const and increment the\n * usage count.  The purpose of this is to attempt to catch at compile time the\n * accidental alteration of a set of credentials that should be considered\n * immutable.\n */\nstatic inline const struct cred *get_cred(const struct cred *cred)\n{\n\tstruct cred *nonconst_cred = (struct cred *) cred;\n\tif (!cred)\n\t\treturn cred;\n\tvalidate_creds(cred);\n\tnonconst_cred->non_rcu = 0;\n\treturn get_new_cred(nonconst_cred);\n}\n\nstatic inline const struct cred *get_cred_rcu(const struct cred *cred)\n{\n\tstruct cred *nonconst_cred = (struct cred *) cred;\n\tif (!cred)\n\t\treturn NULL;\n\tif (!atomic_inc_not_zero(&nonconst_cred->usage))\n\t\treturn NULL;\n\tvalidate_creds(cred);\n\tnonconst_cred->non_rcu = 0;\n\treturn cred;\n}\n\n/**\n * put_cred - Release a reference to a set of credentials\n * @cred: The credentials to release\n *\n * Release a reference to a set of credentials, deleting them when the last ref\n * is released.  If %NULL is passed, nothing is done.\n *\n * This takes a const pointer to a set of credentials because the credentials\n * on task_struct are attached by const pointers to prevent accidental\n * alteration of otherwise immutable credential sets.\n */\nstatic inline void put_cred(const struct cred *_cred)\n{\n\tstruct cred *cred = (struct cred *) _cred;\n\n\tif (cred) {\n\t\tvalidate_creds(cred);\n\t\tif (atomic_dec_and_test(&(cred)->usage))\n\t\t\t__put_cred(cred);\n\t}\n}\n\n/**\n * current_cred - Access the current task's subjective credentials\n *\n * Access the subjective credentials of the current task.  RCU-safe,\n * since nobody else can modify it.\n */\n#define current_cred() \\\n\trcu_dereference_protected(current->cred, 1)\n\n/**\n * current_real_cred - Access the current task's objective credentials\n *\n * Access the objective credentials of the current task.  RCU-safe,\n * since nobody else can modify it.\n */\n#define current_real_cred() \\\n\trcu_dereference_protected(current->real_cred, 1)\n\n/**\n * __task_cred - Access a task's objective credentials\n * @task: The task to query\n *\n * Access the objective credentials of a task.  The caller must hold the RCU\n * readlock.\n *\n * The result of this function should not be passed directly to get_cred();\n * rather get_task_cred() should be used instead.\n */\n#define __task_cred(task)\t\\\n\trcu_dereference((task)->real_cred)\n\n/**\n * get_current_cred - Get the current task's subjective credentials\n *\n * Get the subjective credentials of the current task, pinning them so that\n * they can't go away.  Accessing the current task's credentials directly is\n * not permitted.\n */\n#define get_current_cred()\t\t\t\t\\\n\t(get_cred(current_cred()))\n\n/**\n * get_current_user - Get the current task's user_struct\n *\n * Get the user record of the current task, pinning it so that it can't go\n * away.\n */\n#define get_current_user()\t\t\t\t\\\n({\t\t\t\t\t\t\t\\\n\tstruct user_struct *__u;\t\t\t\\\n\tconst struct cred *__cred;\t\t\t\\\n\t__cred = current_cred();\t\t\t\\\n\t__u = get_uid(__cred->user);\t\t\t\\\n\t__u;\t\t\t\t\t\t\\\n})\n\n/**\n * get_current_groups - Get the current task's supplementary group list\n *\n * Get the supplementary group list of the current task, pinning it so that it\n * can't go away.\n */\n#define get_current_groups()\t\t\t\t\\\n({\t\t\t\t\t\t\t\\\n\tstruct group_info *__groups;\t\t\t\\\n\tconst struct cred *__cred;\t\t\t\\\n\t__cred = current_cred();\t\t\t\\\n\t__groups = get_group_info(__cred->group_info);\t\\\n\t__groups;\t\t\t\t\t\\\n})\n\n#define task_cred_xxx(task, xxx)\t\t\t\\\n({\t\t\t\t\t\t\t\\\n\t__typeof__(((struct cred *)NULL)->xxx) ___val;\t\\\n\trcu_read_lock();\t\t\t\t\\\n\t___val = __task_cred((task))->xxx;\t\t\\\n\trcu_read_unlock();\t\t\t\t\\\n\t___val;\t\t\t\t\t\t\\\n})\n\n#define task_uid(task)\t\t(task_cred_xxx((task), uid))\n#define task_euid(task)\t\t(task_cred_xxx((task), euid))\n\n#define current_cred_xxx(xxx)\t\t\t\\\n({\t\t\t\t\t\t\\\n\tcurrent_cred()->xxx;\t\t\t\\\n})\n\n#define current_uid()\t\t(current_cred_xxx(uid))\n#define current_gid()\t\t(current_cred_xxx(gid))\n#define current_euid()\t\t(current_cred_xxx(euid))\n#define current_egid()\t\t(current_cred_xxx(egid))\n#define current_suid()\t\t(current_cred_xxx(suid))\n#define current_sgid()\t\t(current_cred_xxx(sgid))\n#define current_fsuid() \t(current_cred_xxx(fsuid))\n#define current_fsgid() \t(current_cred_xxx(fsgid))\n#define current_cap()\t\t(current_cred_xxx(cap_effective))\n#define current_user()\t\t(current_cred_xxx(user))\n\nextern struct user_namespace init_user_ns;\n#ifdef CONFIG_USER_NS\n#define current_user_ns()\t(current_cred_xxx(user_ns))\n#else\nstatic inline struct user_namespace *current_user_ns(void)\n{\n\treturn &init_user_ns;\n}\n#endif\n\n\n#define current_uid_gid(_uid, _gid)\t\t\\\ndo {\t\t\t\t\t\t\\\n\tconst struct cred *__cred;\t\t\\\n\t__cred = current_cred();\t\t\\\n\t*(_uid) = __cred->uid;\t\t\t\\\n\t*(_gid) = __cred->gid;\t\t\t\\\n} while(0)\n\n#define current_euid_egid(_euid, _egid)\t\t\\\ndo {\t\t\t\t\t\t\\\n\tconst struct cred *__cred;\t\t\\\n\t__cred = current_cred();\t\t\\\n\t*(_euid) = __cred->euid;\t\t\\\n\t*(_egid) = __cred->egid;\t\t\\\n} while(0)\n\n#define current_fsuid_fsgid(_fsuid, _fsgid)\t\\\ndo {\t\t\t\t\t\t\\\n\tconst struct cred *__cred;\t\t\\\n\t__cred = current_cred();\t\t\\\n\t*(_fsuid) = __cred->fsuid;\t\t\\\n\t*(_fsgid) = __cred->fsgid;\t\t\\\n} while(0)\n\n#endif /* _LINUX_CRED_H */\n"}, "3": {"id": 3, "path": "/src/include/linux/rcupdate.h", "content": "/* SPDX-License-Identifier: GPL-2.0+ */\n/*\n * Read-Copy Update mechanism for mutual exclusion\n *\n * Copyright IBM Corporation, 2001\n *\n * Author: Dipankar Sarma <dipankar@in.ibm.com>\n *\n * Based on the original work by Paul McKenney <paulmck@vnet.ibm.com>\n * and inputs from Rusty Russell, Andrea Arcangeli and Andi Kleen.\n * Papers:\n * http://www.rdrop.com/users/paulmck/paper/rclockpdcsproof.pdf\n * http://lse.sourceforge.net/locking/rclock_OLS.2001.05.01c.sc.pdf (OLS2001)\n *\n * For detailed explanation of Read-Copy Update mechanism see -\n *\t\thttp://lse.sourceforge.net/locking/rcupdate.html\n *\n */\n\n#ifndef __LINUX_RCUPDATE_H\n#define __LINUX_RCUPDATE_H\n\n#include <linux/types.h>\n#include <linux/compiler.h>\n#include <linux/atomic.h>\n#include <linux/irqflags.h>\n#include <linux/preempt.h>\n#include <linux/bottom_half.h>\n#include <linux/lockdep.h>\n#include <asm/processor.h>\n#include <linux/cpumask.h>\n\n#define ULONG_CMP_GE(a, b)\t(ULONG_MAX / 2 >= (a) - (b))\n#define ULONG_CMP_LT(a, b)\t(ULONG_MAX / 2 < (a) - (b))\n#define ulong2long(a)\t\t(*(long *)(&(a)))\n#define USHORT_CMP_GE(a, b)\t(USHRT_MAX / 2 >= (unsigned short)((a) - (b)))\n#define USHORT_CMP_LT(a, b)\t(USHRT_MAX / 2 < (unsigned short)((a) - (b)))\n\n/* Exported common interfaces */\nvoid call_rcu(struct rcu_head *head, rcu_callback_t func);\nvoid rcu_barrier_tasks(void);\nvoid rcu_barrier_tasks_rude(void);\nvoid synchronize_rcu(void);\n\n#ifdef CONFIG_PREEMPT_RCU\n\nvoid __rcu_read_lock(void);\nvoid __rcu_read_unlock(void);\n\n/*\n * Defined as a macro as it is a very low level header included from\n * areas that don't even know about current.  This gives the rcu_read_lock()\n * nesting depth, but makes sense only if CONFIG_PREEMPT_RCU -- in other\n * types of kernel builds, the rcu_read_lock() nesting depth is unknowable.\n */\n#define rcu_preempt_depth() (current->rcu_read_lock_nesting)\n\n#else /* #ifdef CONFIG_PREEMPT_RCU */\n\n#ifdef CONFIG_TINY_RCU\n#define rcu_read_unlock_strict() do { } while (0)\n#else\nvoid rcu_read_unlock_strict(void);\n#endif\n\nstatic inline void __rcu_read_lock(void)\n{\n\tpreempt_disable();\n}\n\nstatic inline void __rcu_read_unlock(void)\n{\n\tpreempt_enable();\n\trcu_read_unlock_strict();\n}\n\nstatic inline int rcu_preempt_depth(void)\n{\n\treturn 0;\n}\n\n#endif /* #else #ifdef CONFIG_PREEMPT_RCU */\n\n/* Internal to kernel */\nvoid rcu_init(void);\nextern int rcu_scheduler_active __read_mostly;\nvoid rcu_sched_clock_irq(int user);\nvoid rcu_report_dead(unsigned int cpu);\nvoid rcutree_migrate_callbacks(int cpu);\n\n#ifdef CONFIG_TASKS_RCU_GENERIC\nvoid rcu_init_tasks_generic(void);\n#else\nstatic inline void rcu_init_tasks_generic(void) { }\n#endif\n\n#ifdef CONFIG_RCU_STALL_COMMON\nvoid rcu_sysrq_start(void);\nvoid rcu_sysrq_end(void);\n#else /* #ifdef CONFIG_RCU_STALL_COMMON */\nstatic inline void rcu_sysrq_start(void) { }\nstatic inline void rcu_sysrq_end(void) { }\n#endif /* #else #ifdef CONFIG_RCU_STALL_COMMON */\n\n#ifdef CONFIG_NO_HZ_FULL\nvoid rcu_user_enter(void);\nvoid rcu_user_exit(void);\n#else\nstatic inline void rcu_user_enter(void) { }\nstatic inline void rcu_user_exit(void) { }\n#endif /* CONFIG_NO_HZ_FULL */\n\n#ifdef CONFIG_RCU_NOCB_CPU\nvoid rcu_init_nohz(void);\nint rcu_nocb_cpu_offload(int cpu);\nint rcu_nocb_cpu_deoffload(int cpu);\nvoid rcu_nocb_flush_deferred_wakeup(void);\n#else /* #ifdef CONFIG_RCU_NOCB_CPU */\nstatic inline void rcu_init_nohz(void) { }\nstatic inline int rcu_nocb_cpu_offload(int cpu) { return -EINVAL; }\nstatic inline int rcu_nocb_cpu_deoffload(int cpu) { return 0; }\nstatic inline void rcu_nocb_flush_deferred_wakeup(void) { }\n#endif /* #else #ifdef CONFIG_RCU_NOCB_CPU */\n\n/**\n * RCU_NONIDLE - Indicate idle-loop code that needs RCU readers\n * @a: Code that RCU needs to pay attention to.\n *\n * RCU read-side critical sections are forbidden in the inner idle loop,\n * that is, between the rcu_idle_enter() and the rcu_idle_exit() -- RCU\n * will happily ignore any such read-side critical sections.  However,\n * things like powertop need tracepoints in the inner idle loop.\n *\n * This macro provides the way out:  RCU_NONIDLE(do_something_with_RCU())\n * will tell RCU that it needs to pay attention, invoke its argument\n * (in this example, calling the do_something_with_RCU() function),\n * and then tell RCU to go back to ignoring this CPU.  It is permissible\n * to nest RCU_NONIDLE() wrappers, but not indefinitely (but the limit is\n * on the order of a million or so, even on 32-bit systems).  It is\n * not legal to block within RCU_NONIDLE(), nor is it permissible to\n * transfer control either into or out of RCU_NONIDLE()'s statement.\n */\n#define RCU_NONIDLE(a) \\\n\tdo { \\\n\t\trcu_irq_enter_irqson(); \\\n\t\tdo { a; } while (0); \\\n\t\trcu_irq_exit_irqson(); \\\n\t} while (0)\n\n/*\n * Note a quasi-voluntary context switch for RCU-tasks's benefit.\n * This is a macro rather than an inline function to avoid #include hell.\n */\n#ifdef CONFIG_TASKS_RCU_GENERIC\n\n# ifdef CONFIG_TASKS_RCU\n# define rcu_tasks_classic_qs(t, preempt)\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tif (!(preempt) && READ_ONCE((t)->rcu_tasks_holdout))\t\\\n\t\t\tWRITE_ONCE((t)->rcu_tasks_holdout, false);\t\\\n\t} while (0)\nvoid call_rcu_tasks(struct rcu_head *head, rcu_callback_t func);\nvoid synchronize_rcu_tasks(void);\n# else\n# define rcu_tasks_classic_qs(t, preempt) do { } while (0)\n# define call_rcu_tasks call_rcu\n# define synchronize_rcu_tasks synchronize_rcu\n# endif\n\n# ifdef CONFIG_TASKS_RCU_TRACE\n# define rcu_tasks_trace_qs(t)\t\t\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tif (!likely(READ_ONCE((t)->trc_reader_checked)) &&\t\\\n\t\t    !unlikely(READ_ONCE((t)->trc_reader_nesting))) {\t\\\n\t\t\tsmp_store_release(&(t)->trc_reader_checked, true); \\\n\t\t\tsmp_mb(); /* Readers partitioned by store. */\t\\\n\t\t}\t\t\t\t\t\t\t\\\n\t} while (0)\n# else\n# define rcu_tasks_trace_qs(t) do { } while (0)\n# endif\n\n#define rcu_tasks_qs(t, preempt)\t\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\trcu_tasks_classic_qs((t), (preempt));\t\t\t\t\\\n\trcu_tasks_trace_qs((t));\t\t\t\t\t\\\n} while (0)\n\n# ifdef CONFIG_TASKS_RUDE_RCU\nvoid call_rcu_tasks_rude(struct rcu_head *head, rcu_callback_t func);\nvoid synchronize_rcu_tasks_rude(void);\n# endif\n\n#define rcu_note_voluntary_context_switch(t) rcu_tasks_qs(t, false)\nvoid exit_tasks_rcu_start(void);\nvoid exit_tasks_rcu_finish(void);\n#else /* #ifdef CONFIG_TASKS_RCU_GENERIC */\n#define rcu_tasks_qs(t, preempt) do { } while (0)\n#define rcu_note_voluntary_context_switch(t) do { } while (0)\n#define call_rcu_tasks call_rcu\n#define synchronize_rcu_tasks synchronize_rcu\nstatic inline void exit_tasks_rcu_start(void) { }\nstatic inline void exit_tasks_rcu_finish(void) { }\n#endif /* #else #ifdef CONFIG_TASKS_RCU_GENERIC */\n\n/**\n * cond_resched_tasks_rcu_qs - Report potential quiescent states to RCU\n *\n * This macro resembles cond_resched(), except that it is defined to\n * report potential quiescent states to RCU-tasks even if the cond_resched()\n * machinery were to be shut off, as some advocate for PREEMPTION kernels.\n */\n#define cond_resched_tasks_rcu_qs() \\\ndo { \\\n\trcu_tasks_qs(current, false); \\\n\tcond_resched(); \\\n} while (0)\n\n/*\n * Infrastructure to implement the synchronize_() primitives in\n * TREE_RCU and rcu_barrier_() primitives in TINY_RCU.\n */\n\n#if defined(CONFIG_TREE_RCU)\n#include <linux/rcutree.h>\n#elif defined(CONFIG_TINY_RCU)\n#include <linux/rcutiny.h>\n#else\n#error \"Unknown RCU implementation specified to kernel configuration\"\n#endif\n\n/*\n * The init_rcu_head_on_stack() and destroy_rcu_head_on_stack() calls\n * are needed for dynamic initialization and destruction of rcu_head\n * on the stack, and init_rcu_head()/destroy_rcu_head() are needed for\n * dynamic initialization and destruction of statically allocated rcu_head\n * structures.  However, rcu_head structures allocated dynamically in the\n * heap don't need any initialization.\n */\n#ifdef CONFIG_DEBUG_OBJECTS_RCU_HEAD\nvoid init_rcu_head(struct rcu_head *head);\nvoid destroy_rcu_head(struct rcu_head *head);\nvoid init_rcu_head_on_stack(struct rcu_head *head);\nvoid destroy_rcu_head_on_stack(struct rcu_head *head);\n#else /* !CONFIG_DEBUG_OBJECTS_RCU_HEAD */\nstatic inline void init_rcu_head(struct rcu_head *head) { }\nstatic inline void destroy_rcu_head(struct rcu_head *head) { }\nstatic inline void init_rcu_head_on_stack(struct rcu_head *head) { }\nstatic inline void destroy_rcu_head_on_stack(struct rcu_head *head) { }\n#endif\t/* #else !CONFIG_DEBUG_OBJECTS_RCU_HEAD */\n\n#if defined(CONFIG_HOTPLUG_CPU) && defined(CONFIG_PROVE_RCU)\nbool rcu_lockdep_current_cpu_online(void);\n#else /* #if defined(CONFIG_HOTPLUG_CPU) && defined(CONFIG_PROVE_RCU) */\nstatic inline bool rcu_lockdep_current_cpu_online(void) { return true; }\n#endif /* #else #if defined(CONFIG_HOTPLUG_CPU) && defined(CONFIG_PROVE_RCU) */\n\nextern struct lockdep_map rcu_lock_map;\nextern struct lockdep_map rcu_bh_lock_map;\nextern struct lockdep_map rcu_sched_lock_map;\nextern struct lockdep_map rcu_callback_map;\n\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\n\nstatic inline void rcu_lock_acquire(struct lockdep_map *map)\n{\n\tlock_acquire(map, 0, 0, 2, 0, NULL, _THIS_IP_);\n}\n\nstatic inline void rcu_lock_release(struct lockdep_map *map)\n{\n\tlock_release(map, _THIS_IP_);\n}\n\nint debug_lockdep_rcu_enabled(void);\nint rcu_read_lock_held(void);\nint rcu_read_lock_bh_held(void);\nint rcu_read_lock_sched_held(void);\nint rcu_read_lock_any_held(void);\n\n#else /* #ifdef CONFIG_DEBUG_LOCK_ALLOC */\n\n# define rcu_lock_acquire(a)\t\tdo { } while (0)\n# define rcu_lock_release(a)\t\tdo { } while (0)\n\nstatic inline int rcu_read_lock_held(void)\n{\n\treturn 1;\n}\n\nstatic inline int rcu_read_lock_bh_held(void)\n{\n\treturn 1;\n}\n\nstatic inline int rcu_read_lock_sched_held(void)\n{\n\treturn !preemptible();\n}\n\nstatic inline int rcu_read_lock_any_held(void)\n{\n\treturn !preemptible();\n}\n\n#endif /* #else #ifdef CONFIG_DEBUG_LOCK_ALLOC */\n\n#ifdef CONFIG_PROVE_RCU\n\n/**\n * RCU_LOCKDEP_WARN - emit lockdep splat if specified condition is met\n * @c: condition to check\n * @s: informative message\n */\n#define RCU_LOCKDEP_WARN(c, s)\t\t\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tstatic bool __section(\".data.unlikely\") __warned;\t\\\n\t\tif (debug_lockdep_rcu_enabled() && !__warned && (c)) {\t\\\n\t\t\t__warned = true;\t\t\t\t\\\n\t\t\tlockdep_rcu_suspicious(__FILE__, __LINE__, s);\t\\\n\t\t}\t\t\t\t\t\t\t\\\n\t} while (0)\n\n#if defined(CONFIG_PROVE_RCU) && !defined(CONFIG_PREEMPT_RCU)\nstatic inline void rcu_preempt_sleep_check(void)\n{\n\tRCU_LOCKDEP_WARN(lock_is_held(&rcu_lock_map),\n\t\t\t \"Illegal context switch in RCU read-side critical section\");\n}\n#else /* #ifdef CONFIG_PROVE_RCU */\nstatic inline void rcu_preempt_sleep_check(void) { }\n#endif /* #else #ifdef CONFIG_PROVE_RCU */\n\n#define rcu_sleep_check()\t\t\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\trcu_preempt_sleep_check();\t\t\t\t\\\n\t\tif (!IS_ENABLED(CONFIG_PREEMPT_RT))\t\t\t\\\n\t\t    RCU_LOCKDEP_WARN(lock_is_held(&rcu_bh_lock_map),\t\\\n\t\t\t\t \"Illegal context switch in RCU-bh read-side critical section\"); \\\n\t\tRCU_LOCKDEP_WARN(lock_is_held(&rcu_sched_lock_map),\t\\\n\t\t\t\t \"Illegal context switch in RCU-sched read-side critical section\"); \\\n\t} while (0)\n\n#else /* #ifdef CONFIG_PROVE_RCU */\n\n#define RCU_LOCKDEP_WARN(c, s) do { } while (0 && (c))\n#define rcu_sleep_check() do { } while (0)\n\n#endif /* #else #ifdef CONFIG_PROVE_RCU */\n\n/*\n * Helper functions for rcu_dereference_check(), rcu_dereference_protected()\n * and rcu_assign_pointer().  Some of these could be folded into their\n * callers, but they are left separate in order to ease introduction of\n * multiple pointers markings to match different RCU implementations\n * (e.g., __srcu), should this make sense in the future.\n */\n\n#ifdef __CHECKER__\n#define rcu_check_sparse(p, space) \\\n\t((void)(((typeof(*p) space *)p) == p))\n#else /* #ifdef __CHECKER__ */\n#define rcu_check_sparse(p, space)\n#endif /* #else #ifdef __CHECKER__ */\n\n#define __rcu_access_pointer(p, space) \\\n({ \\\n\ttypeof(*p) *_________p1 = (typeof(*p) *__force)READ_ONCE(p); \\\n\trcu_check_sparse(p, space); \\\n\t((typeof(*p) __force __kernel *)(_________p1)); \\\n})\n#define __rcu_dereference_check(p, c, space) \\\n({ \\\n\t/* Dependency order vs. p above. */ \\\n\ttypeof(*p) *________p1 = (typeof(*p) *__force)READ_ONCE(p); \\\n\tRCU_LOCKDEP_WARN(!(c), \"suspicious rcu_dereference_check() usage\"); \\\n\trcu_check_sparse(p, space); \\\n\t((typeof(*p) __force __kernel *)(________p1)); \\\n})\n#define __rcu_dereference_protected(p, c, space) \\\n({ \\\n\tRCU_LOCKDEP_WARN(!(c), \"suspicious rcu_dereference_protected() usage\"); \\\n\trcu_check_sparse(p, space); \\\n\t((typeof(*p) __force __kernel *)(p)); \\\n})\n#define rcu_dereference_raw(p) \\\n({ \\\n\t/* Dependency order vs. p above. */ \\\n\ttypeof(p) ________p1 = READ_ONCE(p); \\\n\t((typeof(*p) __force __kernel *)(________p1)); \\\n})\n\n/**\n * RCU_INITIALIZER() - statically initialize an RCU-protected global variable\n * @v: The value to statically initialize with.\n */\n#define RCU_INITIALIZER(v) (typeof(*(v)) __force __rcu *)(v)\n\n/**\n * rcu_assign_pointer() - assign to RCU-protected pointer\n * @p: pointer to assign to\n * @v: value to assign (publish)\n *\n * Assigns the specified value to the specified RCU-protected\n * pointer, ensuring that any concurrent RCU readers will see\n * any prior initialization.\n *\n * Inserts memory barriers on architectures that require them\n * (which is most of them), and also prevents the compiler from\n * reordering the code that initializes the structure after the pointer\n * assignment.  More importantly, this call documents which pointers\n * will be dereferenced by RCU read-side code.\n *\n * In some special cases, you may use RCU_INIT_POINTER() instead\n * of rcu_assign_pointer().  RCU_INIT_POINTER() is a bit faster due\n * to the fact that it does not constrain either the CPU or the compiler.\n * That said, using RCU_INIT_POINTER() when you should have used\n * rcu_assign_pointer() is a very bad thing that results in\n * impossible-to-diagnose memory corruption.  So please be careful.\n * See the RCU_INIT_POINTER() comment header for details.\n *\n * Note that rcu_assign_pointer() evaluates each of its arguments only\n * once, appearances notwithstanding.  One of the \"extra\" evaluations\n * is in typeof() and the other visible only to sparse (__CHECKER__),\n * neither of which actually execute the argument.  As with most cpp\n * macros, this execute-arguments-only-once property is important, so\n * please be careful when making changes to rcu_assign_pointer() and the\n * other macros that it invokes.\n */\n#define rcu_assign_pointer(p, v)\t\t\t\t\t      \\\ndo {\t\t\t\t\t\t\t\t\t      \\\n\tuintptr_t _r_a_p__v = (uintptr_t)(v);\t\t\t\t      \\\n\trcu_check_sparse(p, __rcu);\t\t\t\t\t      \\\n\t\t\t\t\t\t\t\t\t      \\\n\tif (__builtin_constant_p(v) && (_r_a_p__v) == (uintptr_t)NULL)\t      \\\n\t\tWRITE_ONCE((p), (typeof(p))(_r_a_p__v));\t\t      \\\n\telse\t\t\t\t\t\t\t\t      \\\n\t\tsmp_store_release(&p, RCU_INITIALIZER((typeof(p))_r_a_p__v)); \\\n} while (0)\n\n/**\n * rcu_replace_pointer() - replace an RCU pointer, returning its old value\n * @rcu_ptr: RCU pointer, whose old value is returned\n * @ptr: regular pointer\n * @c: the lockdep conditions under which the dereference will take place\n *\n * Perform a replacement, where @rcu_ptr is an RCU-annotated\n * pointer and @c is the lockdep argument that is passed to the\n * rcu_dereference_protected() call used to read that pointer.  The old\n * value of @rcu_ptr is returned, and @rcu_ptr is set to @ptr.\n */\n#define rcu_replace_pointer(rcu_ptr, ptr, c)\t\t\t\t\\\n({\t\t\t\t\t\t\t\t\t\\\n\ttypeof(ptr) __tmp = rcu_dereference_protected((rcu_ptr), (c));\t\\\n\trcu_assign_pointer((rcu_ptr), (ptr));\t\t\t\t\\\n\t__tmp;\t\t\t\t\t\t\t\t\\\n})\n\n/**\n * rcu_access_pointer() - fetch RCU pointer with no dereferencing\n * @p: The pointer to read\n *\n * Return the value of the specified RCU-protected pointer, but omit the\n * lockdep checks for being in an RCU read-side critical section.  This is\n * useful when the value of this pointer is accessed, but the pointer is\n * not dereferenced, for example, when testing an RCU-protected pointer\n * against NULL.  Although rcu_access_pointer() may also be used in cases\n * where update-side locks prevent the value of the pointer from changing,\n * you should instead use rcu_dereference_protected() for this use case.\n *\n * It is also permissible to use rcu_access_pointer() when read-side\n * access to the pointer was removed at least one grace period ago, as\n * is the case in the context of the RCU callback that is freeing up\n * the data, or after a synchronize_rcu() returns.  This can be useful\n * when tearing down multi-linked structures after a grace period\n * has elapsed.\n */\n#define rcu_access_pointer(p) __rcu_access_pointer((p), __rcu)\n\n/**\n * rcu_dereference_check() - rcu_dereference with debug checking\n * @p: The pointer to read, prior to dereferencing\n * @c: The conditions under which the dereference will take place\n *\n * Do an rcu_dereference(), but check that the conditions under which the\n * dereference will take place are correct.  Typically the conditions\n * indicate the various locking conditions that should be held at that\n * point.  The check should return true if the conditions are satisfied.\n * An implicit check for being in an RCU read-side critical section\n * (rcu_read_lock()) is included.\n *\n * For example:\n *\n *\tbar = rcu_dereference_check(foo->bar, lockdep_is_held(&foo->lock));\n *\n * could be used to indicate to lockdep that foo->bar may only be dereferenced\n * if either rcu_read_lock() is held, or that the lock required to replace\n * the bar struct at foo->bar is held.\n *\n * Note that the list of conditions may also include indications of when a lock\n * need not be held, for example during initialisation or destruction of the\n * target struct:\n *\n *\tbar = rcu_dereference_check(foo->bar, lockdep_is_held(&foo->lock) ||\n *\t\t\t\t\t      atomic_read(&foo->usage) == 0);\n *\n * Inserts memory barriers on architectures that require them\n * (currently only the Alpha), prevents the compiler from refetching\n * (and from merging fetches), and, more importantly, documents exactly\n * which pointers are protected by RCU and checks that the pointer is\n * annotated as __rcu.\n */\n#define rcu_dereference_check(p, c) \\\n\t__rcu_dereference_check((p), (c) || rcu_read_lock_held(), __rcu)\n\n/**\n * rcu_dereference_bh_check() - rcu_dereference_bh with debug checking\n * @p: The pointer to read, prior to dereferencing\n * @c: The conditions under which the dereference will take place\n *\n * This is the RCU-bh counterpart to rcu_dereference_check().\n */\n#define rcu_dereference_bh_check(p, c) \\\n\t__rcu_dereference_check((p), (c) || rcu_read_lock_bh_held(), __rcu)\n\n/**\n * rcu_dereference_sched_check() - rcu_dereference_sched with debug checking\n * @p: The pointer to read, prior to dereferencing\n * @c: The conditions under which the dereference will take place\n *\n * This is the RCU-sched counterpart to rcu_dereference_check().\n */\n#define rcu_dereference_sched_check(p, c) \\\n\t__rcu_dereference_check((p), (c) || rcu_read_lock_sched_held(), \\\n\t\t\t\t__rcu)\n\n/*\n * The tracing infrastructure traces RCU (we want that), but unfortunately\n * some of the RCU checks causes tracing to lock up the system.\n *\n * The no-tracing version of rcu_dereference_raw() must not call\n * rcu_read_lock_held().\n */\n#define rcu_dereference_raw_check(p) __rcu_dereference_check((p), 1, __rcu)\n\n/**\n * rcu_dereference_protected() - fetch RCU pointer when updates prevented\n * @p: The pointer to read, prior to dereferencing\n * @c: The conditions under which the dereference will take place\n *\n * Return the value of the specified RCU-protected pointer, but omit\n * the READ_ONCE().  This is useful in cases where update-side locks\n * prevent the value of the pointer from changing.  Please note that this\n * primitive does *not* prevent the compiler from repeating this reference\n * or combining it with other references, so it should not be used without\n * protection of appropriate locks.\n *\n * This function is only for update-side use.  Using this function\n * when protected only by rcu_read_lock() will result in infrequent\n * but very ugly failures.\n */\n#define rcu_dereference_protected(p, c) \\\n\t__rcu_dereference_protected((p), (c), __rcu)\n\n\n/**\n * rcu_dereference() - fetch RCU-protected pointer for dereferencing\n * @p: The pointer to read, prior to dereferencing\n *\n * This is a simple wrapper around rcu_dereference_check().\n */\n#define rcu_dereference(p) rcu_dereference_check(p, 0)\n\n/**\n * rcu_dereference_bh() - fetch an RCU-bh-protected pointer for dereferencing\n * @p: The pointer to read, prior to dereferencing\n *\n * Makes rcu_dereference_check() do the dirty work.\n */\n#define rcu_dereference_bh(p) rcu_dereference_bh_check(p, 0)\n\n/**\n * rcu_dereference_sched() - fetch RCU-sched-protected pointer for dereferencing\n * @p: The pointer to read, prior to dereferencing\n *\n * Makes rcu_dereference_check() do the dirty work.\n */\n#define rcu_dereference_sched(p) rcu_dereference_sched_check(p, 0)\n\n/**\n * rcu_pointer_handoff() - Hand off a pointer from RCU to other mechanism\n * @p: The pointer to hand off\n *\n * This is simply an identity function, but it documents where a pointer\n * is handed off from RCU to some other synchronization mechanism, for\n * example, reference counting or locking.  In C11, it would map to\n * kill_dependency().  It could be used as follows::\n *\n *\trcu_read_lock();\n *\tp = rcu_dereference(gp);\n *\tlong_lived = is_long_lived(p);\n *\tif (long_lived) {\n *\t\tif (!atomic_inc_not_zero(p->refcnt))\n *\t\t\tlong_lived = false;\n *\t\telse\n *\t\t\tp = rcu_pointer_handoff(p);\n *\t}\n *\trcu_read_unlock();\n */\n#define rcu_pointer_handoff(p) (p)\n\n/**\n * rcu_read_lock() - mark the beginning of an RCU read-side critical section\n *\n * When synchronize_rcu() is invoked on one CPU while other CPUs\n * are within RCU read-side critical sections, then the\n * synchronize_rcu() is guaranteed to block until after all the other\n * CPUs exit their critical sections.  Similarly, if call_rcu() is invoked\n * on one CPU while other CPUs are within RCU read-side critical\n * sections, invocation of the corresponding RCU callback is deferred\n * until after the all the other CPUs exit their critical sections.\n *\n * Note, however, that RCU callbacks are permitted to run concurrently\n * with new RCU read-side critical sections.  One way that this can happen\n * is via the following sequence of events: (1) CPU 0 enters an RCU\n * read-side critical section, (2) CPU 1 invokes call_rcu() to register\n * an RCU callback, (3) CPU 0 exits the RCU read-side critical section,\n * (4) CPU 2 enters a RCU read-side critical section, (5) the RCU\n * callback is invoked.  This is legal, because the RCU read-side critical\n * section that was running concurrently with the call_rcu() (and which\n * therefore might be referencing something that the corresponding RCU\n * callback would free up) has completed before the corresponding\n * RCU callback is invoked.\n *\n * RCU read-side critical sections may be nested.  Any deferred actions\n * will be deferred until the outermost RCU read-side critical section\n * completes.\n *\n * You can avoid reading and understanding the next paragraph by\n * following this rule: don't put anything in an rcu_read_lock() RCU\n * read-side critical section that would block in a !PREEMPTION kernel.\n * But if you want the full story, read on!\n *\n * In non-preemptible RCU implementations (pure TREE_RCU and TINY_RCU),\n * it is illegal to block while in an RCU read-side critical section.\n * In preemptible RCU implementations (PREEMPT_RCU) in CONFIG_PREEMPTION\n * kernel builds, RCU read-side critical sections may be preempted,\n * but explicit blocking is illegal.  Finally, in preemptible RCU\n * implementations in real-time (with -rt patchset) kernel builds, RCU\n * read-side critical sections may be preempted and they may also block, but\n * only when acquiring spinlocks that are subject to priority inheritance.\n */\nstatic __always_inline void rcu_read_lock(void)\n{\n\t__rcu_read_lock();\n\t__acquire(RCU);\n\trcu_lock_acquire(&rcu_lock_map);\n\tRCU_LOCKDEP_WARN(!rcu_is_watching(),\n\t\t\t \"rcu_read_lock() used illegally while idle\");\n}\n\n/*\n * So where is rcu_write_lock()?  It does not exist, as there is no\n * way for writers to lock out RCU readers.  This is a feature, not\n * a bug -- this property is what provides RCU's performance benefits.\n * Of course, writers must coordinate with each other.  The normal\n * spinlock primitives work well for this, but any other technique may be\n * used as well.  RCU does not care how the writers keep out of each\n * others' way, as long as they do so.\n */\n\n/**\n * rcu_read_unlock() - marks the end of an RCU read-side critical section.\n *\n * In most situations, rcu_read_unlock() is immune from deadlock.\n * However, in kernels built with CONFIG_RCU_BOOST, rcu_read_unlock()\n * is responsible for deboosting, which it does via rt_mutex_unlock().\n * Unfortunately, this function acquires the scheduler's runqueue and\n * priority-inheritance spinlocks.  This means that deadlock could result\n * if the caller of rcu_read_unlock() already holds one of these locks or\n * any lock that is ever acquired while holding them.\n *\n * That said, RCU readers are never priority boosted unless they were\n * preempted.  Therefore, one way to avoid deadlock is to make sure\n * that preemption never happens within any RCU read-side critical\n * section whose outermost rcu_read_unlock() is called with one of\n * rt_mutex_unlock()'s locks held.  Such preemption can be avoided in\n * a number of ways, for example, by invoking preempt_disable() before\n * critical section's outermost rcu_read_lock().\n *\n * Given that the set of locks acquired by rt_mutex_unlock() might change\n * at any time, a somewhat more future-proofed approach is to make sure\n * that that preemption never happens within any RCU read-side critical\n * section whose outermost rcu_read_unlock() is called with irqs disabled.\n * This approach relies on the fact that rt_mutex_unlock() currently only\n * acquires irq-disabled locks.\n *\n * The second of these two approaches is best in most situations,\n * however, the first approach can also be useful, at least to those\n * developers willing to keep abreast of the set of locks acquired by\n * rt_mutex_unlock().\n *\n * See rcu_read_lock() for more information.\n */\nstatic inline void rcu_read_unlock(void)\n{\n\tRCU_LOCKDEP_WARN(!rcu_is_watching(),\n\t\t\t \"rcu_read_unlock() used illegally while idle\");\n\t__release(RCU);\n\t__rcu_read_unlock();\n\trcu_lock_release(&rcu_lock_map); /* Keep acq info for rls diags. */\n}\n\n/**\n * rcu_read_lock_bh() - mark the beginning of an RCU-bh critical section\n *\n * This is equivalent of rcu_read_lock(), but also disables softirqs.\n * Note that anything else that disables softirqs can also serve as\n * an RCU read-side critical section.\n *\n * Note that rcu_read_lock_bh() and the matching rcu_read_unlock_bh()\n * must occur in the same context, for example, it is illegal to invoke\n * rcu_read_unlock_bh() from one task if the matching rcu_read_lock_bh()\n * was invoked from some other task.\n */\nstatic inline void rcu_read_lock_bh(void)\n{\n\tlocal_bh_disable();\n\t__acquire(RCU_BH);\n\trcu_lock_acquire(&rcu_bh_lock_map);\n\tRCU_LOCKDEP_WARN(!rcu_is_watching(),\n\t\t\t \"rcu_read_lock_bh() used illegally while idle\");\n}\n\n/**\n * rcu_read_unlock_bh() - marks the end of a softirq-only RCU critical section\n *\n * See rcu_read_lock_bh() for more information.\n */\nstatic inline void rcu_read_unlock_bh(void)\n{\n\tRCU_LOCKDEP_WARN(!rcu_is_watching(),\n\t\t\t \"rcu_read_unlock_bh() used illegally while idle\");\n\trcu_lock_release(&rcu_bh_lock_map);\n\t__release(RCU_BH);\n\tlocal_bh_enable();\n}\n\n/**\n * rcu_read_lock_sched() - mark the beginning of a RCU-sched critical section\n *\n * This is equivalent of rcu_read_lock(), but disables preemption.\n * Read-side critical sections can also be introduced by anything else\n * that disables preemption, including local_irq_disable() and friends.\n *\n * Note that rcu_read_lock_sched() and the matching rcu_read_unlock_sched()\n * must occur in the same context, for example, it is illegal to invoke\n * rcu_read_unlock_sched() from process context if the matching\n * rcu_read_lock_sched() was invoked from an NMI handler.\n */\nstatic inline void rcu_read_lock_sched(void)\n{\n\tpreempt_disable();\n\t__acquire(RCU_SCHED);\n\trcu_lock_acquire(&rcu_sched_lock_map);\n\tRCU_LOCKDEP_WARN(!rcu_is_watching(),\n\t\t\t \"rcu_read_lock_sched() used illegally while idle\");\n}\n\n/* Used by lockdep and tracing: cannot be traced, cannot call lockdep. */\nstatic inline notrace void rcu_read_lock_sched_notrace(void)\n{\n\tpreempt_disable_notrace();\n\t__acquire(RCU_SCHED);\n}\n\n/**\n * rcu_read_unlock_sched() - marks the end of a RCU-classic critical section\n *\n * See rcu_read_lock_sched() for more information.\n */\nstatic inline void rcu_read_unlock_sched(void)\n{\n\tRCU_LOCKDEP_WARN(!rcu_is_watching(),\n\t\t\t \"rcu_read_unlock_sched() used illegally while idle\");\n\trcu_lock_release(&rcu_sched_lock_map);\n\t__release(RCU_SCHED);\n\tpreempt_enable();\n}\n\n/* Used by lockdep and tracing: cannot be traced, cannot call lockdep. */\nstatic inline notrace void rcu_read_unlock_sched_notrace(void)\n{\n\t__release(RCU_SCHED);\n\tpreempt_enable_notrace();\n}\n\n/**\n * RCU_INIT_POINTER() - initialize an RCU protected pointer\n * @p: The pointer to be initialized.\n * @v: The value to initialized the pointer to.\n *\n * Initialize an RCU-protected pointer in special cases where readers\n * do not need ordering constraints on the CPU or the compiler.  These\n * special cases are:\n *\n * 1.\tThis use of RCU_INIT_POINTER() is NULLing out the pointer *or*\n * 2.\tThe caller has taken whatever steps are required to prevent\n *\tRCU readers from concurrently accessing this pointer *or*\n * 3.\tThe referenced data structure has already been exposed to\n *\treaders either at compile time or via rcu_assign_pointer() *and*\n *\n *\ta.\tYou have not made *any* reader-visible changes to\n *\t\tthis structure since then *or*\n *\tb.\tIt is OK for readers accessing this structure from its\n *\t\tnew location to see the old state of the structure.  (For\n *\t\texample, the changes were to statistical counters or to\n *\t\tother state where exact synchronization is not required.)\n *\n * Failure to follow these rules governing use of RCU_INIT_POINTER() will\n * result in impossible-to-diagnose memory corruption.  As in the structures\n * will look OK in crash dumps, but any concurrent RCU readers might\n * see pre-initialized values of the referenced data structure.  So\n * please be very careful how you use RCU_INIT_POINTER()!!!\n *\n * If you are creating an RCU-protected linked structure that is accessed\n * by a single external-to-structure RCU-protected pointer, then you may\n * use RCU_INIT_POINTER() to initialize the internal RCU-protected\n * pointers, but you must use rcu_assign_pointer() to initialize the\n * external-to-structure pointer *after* you have completely initialized\n * the reader-accessible portions of the linked structure.\n *\n * Note that unlike rcu_assign_pointer(), RCU_INIT_POINTER() provides no\n * ordering guarantees for either the CPU or the compiler.\n */\n#define RCU_INIT_POINTER(p, v) \\\n\tdo { \\\n\t\trcu_check_sparse(p, __rcu); \\\n\t\tWRITE_ONCE(p, RCU_INITIALIZER(v)); \\\n\t} while (0)\n\n/**\n * RCU_POINTER_INITIALIZER() - statically initialize an RCU protected pointer\n * @p: The pointer to be initialized.\n * @v: The value to initialized the pointer to.\n *\n * GCC-style initialization for an RCU-protected pointer in a structure field.\n */\n#define RCU_POINTER_INITIALIZER(p, v) \\\n\t\t.p = RCU_INITIALIZER(v)\n\n/*\n * Does the specified offset indicate that the corresponding rcu_head\n * structure can be handled by kvfree_rcu()?\n */\n#define __is_kvfree_rcu_offset(offset) ((offset) < 4096)\n\n/**\n * kfree_rcu() - kfree an object after a grace period.\n * @ptr: pointer to kfree for both single- and double-argument invocations.\n * @rhf: the name of the struct rcu_head within the type of @ptr,\n *       but only for double-argument invocations.\n *\n * Many rcu callbacks functions just call kfree() on the base structure.\n * These functions are trivial, but their size adds up, and furthermore\n * when they are used in a kernel module, that module must invoke the\n * high-latency rcu_barrier() function at module-unload time.\n *\n * The kfree_rcu() function handles this issue.  Rather than encoding a\n * function address in the embedded rcu_head structure, kfree_rcu() instead\n * encodes the offset of the rcu_head structure within the base structure.\n * Because the functions are not allowed in the low-order 4096 bytes of\n * kernel virtual memory, offsets up to 4095 bytes can be accommodated.\n * If the offset is larger than 4095 bytes, a compile-time error will\n * be generated in kvfree_rcu_arg_2(). If this error is triggered, you can\n * either fall back to use of call_rcu() or rearrange the structure to\n * position the rcu_head structure into the first 4096 bytes.\n *\n * Note that the allowable offset might decrease in the future, for example,\n * to allow something like kmem_cache_free_rcu().\n *\n * The BUILD_BUG_ON check must not involve any function calls, hence the\n * checks are done in macros here.\n */\n#define kfree_rcu(ptr, rhf...) kvfree_rcu(ptr, ## rhf)\n\n/**\n * kvfree_rcu() - kvfree an object after a grace period.\n *\n * This macro consists of one or two arguments and it is\n * based on whether an object is head-less or not. If it\n * has a head then a semantic stays the same as it used\n * to be before:\n *\n *     kvfree_rcu(ptr, rhf);\n *\n * where @ptr is a pointer to kvfree(), @rhf is the name\n * of the rcu_head structure within the type of @ptr.\n *\n * When it comes to head-less variant, only one argument\n * is passed and that is just a pointer which has to be\n * freed after a grace period. Therefore the semantic is\n *\n *     kvfree_rcu(ptr);\n *\n * where @ptr is a pointer to kvfree().\n *\n * Please note, head-less way of freeing is permitted to\n * use from a context that has to follow might_sleep()\n * annotation. Otherwise, please switch and embed the\n * rcu_head structure within the type of @ptr.\n */\n#define kvfree_rcu(...) KVFREE_GET_MACRO(__VA_ARGS__,\t\t\\\n\tkvfree_rcu_arg_2, kvfree_rcu_arg_1)(__VA_ARGS__)\n\n#define KVFREE_GET_MACRO(_1, _2, NAME, ...) NAME\n#define kvfree_rcu_arg_2(ptr, rhf)\t\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\ttypeof (ptr) ___p = (ptr);\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tif (___p) {\t\t\t\t\t\t\t\t\t\\\n\t\tBUILD_BUG_ON(!__is_kvfree_rcu_offset(offsetof(typeof(*(ptr)), rhf)));\t\\\n\t\tkvfree_call_rcu(&((___p)->rhf), (rcu_callback_t)(unsigned long)\t\t\\\n\t\t\t(offsetof(typeof(*(ptr)), rhf)));\t\t\t\t\\\n\t}\t\t\t\t\t\t\t\t\t\t\\\n} while (0)\n\n#define kvfree_rcu_arg_1(ptr)\t\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\\\n\ttypeof(ptr) ___p = (ptr);\t\t\t\t\\\n\t\t\t\t\t\t\t\t\\\n\tif (___p)\t\t\t\t\t\t\\\n\t\tkvfree_call_rcu(NULL, (rcu_callback_t) (___p));\t\\\n} while (0)\n\n/*\n * Place this after a lock-acquisition primitive to guarantee that\n * an UNLOCK+LOCK pair acts as a full barrier.  This guarantee applies\n * if the UNLOCK and LOCK are executed by the same CPU or if the\n * UNLOCK and LOCK operate on the same lock variable.\n */\n#ifdef CONFIG_ARCH_WEAK_RELEASE_ACQUIRE\n#define smp_mb__after_unlock_lock()\tsmp_mb()  /* Full ordering for lock. */\n#else /* #ifdef CONFIG_ARCH_WEAK_RELEASE_ACQUIRE */\n#define smp_mb__after_unlock_lock()\tdo { } while (0)\n#endif /* #else #ifdef CONFIG_ARCH_WEAK_RELEASE_ACQUIRE */\n\n\n/* Has the specified rcu_head structure been handed to call_rcu()? */\n\n/**\n * rcu_head_init - Initialize rcu_head for rcu_head_after_call_rcu()\n * @rhp: The rcu_head structure to initialize.\n *\n * If you intend to invoke rcu_head_after_call_rcu() to test whether a\n * given rcu_head structure has already been passed to call_rcu(), then\n * you must also invoke this rcu_head_init() function on it just after\n * allocating that structure.  Calls to this function must not race with\n * calls to call_rcu(), rcu_head_after_call_rcu(), or callback invocation.\n */\nstatic inline void rcu_head_init(struct rcu_head *rhp)\n{\n\trhp->func = (rcu_callback_t)~0L;\n}\n\n/**\n * rcu_head_after_call_rcu() - Has this rcu_head been passed to call_rcu()?\n * @rhp: The rcu_head structure to test.\n * @f: The function passed to call_rcu() along with @rhp.\n *\n * Returns @true if the @rhp has been passed to call_rcu() with @func,\n * and @false otherwise.  Emits a warning in any other case, including\n * the case where @rhp has already been invoked after a grace period.\n * Calls to this function must not race with callback invocation.  One way\n * to avoid such races is to enclose the call to rcu_head_after_call_rcu()\n * in an RCU read-side critical section that includes a read-side fetch\n * of the pointer to the structure containing @rhp.\n */\nstatic inline bool\nrcu_head_after_call_rcu(struct rcu_head *rhp, rcu_callback_t f)\n{\n\trcu_callback_t func = READ_ONCE(rhp->func);\n\n\tif (func == f)\n\t\treturn true;\n\tWARN_ON_ONCE(func != (rcu_callback_t)~0L);\n\treturn false;\n}\n\n/* kernel/ksysfs.c definitions */\nextern int rcu_expedited;\nextern int rcu_normal;\n\n#endif /* __LINUX_RCUPDATE_H */\n"}, "4": {"id": 4, "path": "/src/drivers/scsi/scsi_logging.h", "content": "/* SPDX-License-Identifier: GPL-2.0 */\n#ifndef _SCSI_LOGGING_H\n#define _SCSI_LOGGING_H\n\n\n/*\n * This defines the scsi logging feature.  It is a means by which the user can\n * select how much information they get about various goings on, and it can be\n * really useful for fault tracing.  The logging word is divided into 10 3-bit\n * bitfields, each of which describes a loglevel.  The division of things is\n * somewhat arbitrary, and the division of the word could be changed if it\n * were really needed for any reason.  The numbers below are the only place\n * where these are specified.  For a first go-around, 3 bits is more than\n * enough, since this gives 8 levels of logging (really 7, since 0 is always\n * off).  Cutting to 2 bits might be wise at some point.\n */\n\n#define SCSI_LOG_ERROR_SHIFT              0\n#define SCSI_LOG_TIMEOUT_SHIFT            3\n#define SCSI_LOG_SCAN_SHIFT               6\n#define SCSI_LOG_MLQUEUE_SHIFT            9\n#define SCSI_LOG_MLCOMPLETE_SHIFT         12\n#define SCSI_LOG_LLQUEUE_SHIFT            15\n#define SCSI_LOG_LLCOMPLETE_SHIFT         18\n#define SCSI_LOG_HLQUEUE_SHIFT            21\n#define SCSI_LOG_HLCOMPLETE_SHIFT         24\n#define SCSI_LOG_IOCTL_SHIFT              27\n\n#define SCSI_LOG_ERROR_BITS               3\n#define SCSI_LOG_TIMEOUT_BITS             3\n#define SCSI_LOG_SCAN_BITS                3\n#define SCSI_LOG_MLQUEUE_BITS             3\n#define SCSI_LOG_MLCOMPLETE_BITS          3\n#define SCSI_LOG_LLQUEUE_BITS             3\n#define SCSI_LOG_LLCOMPLETE_BITS          3\n#define SCSI_LOG_HLQUEUE_BITS             3\n#define SCSI_LOG_HLCOMPLETE_BITS          3\n#define SCSI_LOG_IOCTL_BITS               3\n\nextern unsigned int scsi_logging_level;\n\n#ifdef CONFIG_SCSI_LOGGING\n\n#define SCSI_LOG_LEVEL(SHIFT, BITS)\t\t\t\t\\\n        ((scsi_logging_level >> (SHIFT)) & ((1 << (BITS)) - 1))\n\n#define SCSI_CHECK_LOGGING(SHIFT, BITS, LEVEL, CMD)\t\t\\\ndo {\t\t\t\t\t\t\t\t\\\n        if (unlikely((SCSI_LOG_LEVEL(SHIFT, BITS)) > (LEVEL)))\t\\\n\t\tdo {\t\t\t\t\t\t\\\n\t\t\tCMD;\t\t\t\t\t\\\n\t\t} while (0);\t\t\t\t\t\\\n} while (0)\n#else\n#define SCSI_LOG_LEVEL(SHIFT, BITS) 0\n#define SCSI_CHECK_LOGGING(SHIFT, BITS, LEVEL, CMD) do { } while (0)\n#endif /* CONFIG_SCSI_LOGGING */\n\n/*\n * These are the macros that are actually used throughout the code to\n * log events.  If logging isn't enabled, they are no-ops and will be\n * completely absent from the user's code.\n */\n#define SCSI_LOG_ERROR_RECOVERY(LEVEL,CMD)  \\\n        SCSI_CHECK_LOGGING(SCSI_LOG_ERROR_SHIFT, SCSI_LOG_ERROR_BITS, LEVEL,CMD);\n#define SCSI_LOG_TIMEOUT(LEVEL,CMD)  \\\n        SCSI_CHECK_LOGGING(SCSI_LOG_TIMEOUT_SHIFT, SCSI_LOG_TIMEOUT_BITS, LEVEL,CMD);\n#define SCSI_LOG_SCAN_BUS(LEVEL,CMD)  \\\n        SCSI_CHECK_LOGGING(SCSI_LOG_SCAN_SHIFT, SCSI_LOG_SCAN_BITS, LEVEL,CMD);\n#define SCSI_LOG_MLQUEUE(LEVEL,CMD)  \\\n        SCSI_CHECK_LOGGING(SCSI_LOG_MLQUEUE_SHIFT, SCSI_LOG_MLQUEUE_BITS, LEVEL,CMD);\n#define SCSI_LOG_MLCOMPLETE(LEVEL,CMD)  \\\n        SCSI_CHECK_LOGGING(SCSI_LOG_MLCOMPLETE_SHIFT, SCSI_LOG_MLCOMPLETE_BITS, LEVEL,CMD);\n#define SCSI_LOG_LLQUEUE(LEVEL,CMD)  \\\n        SCSI_CHECK_LOGGING(SCSI_LOG_LLQUEUE_SHIFT, SCSI_LOG_LLQUEUE_BITS, LEVEL,CMD);\n#define SCSI_LOG_LLCOMPLETE(LEVEL,CMD)  \\\n        SCSI_CHECK_LOGGING(SCSI_LOG_LLCOMPLETE_SHIFT, SCSI_LOG_LLCOMPLETE_BITS, LEVEL,CMD);\n#define SCSI_LOG_HLQUEUE(LEVEL,CMD)  \\\n        SCSI_CHECK_LOGGING(SCSI_LOG_HLQUEUE_SHIFT, SCSI_LOG_HLQUEUE_BITS, LEVEL,CMD);\n#define SCSI_LOG_HLCOMPLETE(LEVEL,CMD)  \\\n        SCSI_CHECK_LOGGING(SCSI_LOG_HLCOMPLETE_SHIFT, SCSI_LOG_HLCOMPLETE_BITS, LEVEL,CMD);\n#define SCSI_LOG_IOCTL(LEVEL,CMD)  \\\n        SCSI_CHECK_LOGGING(SCSI_LOG_IOCTL_SHIFT, SCSI_LOG_IOCTL_BITS, LEVEL,CMD);\n\n#endif /* _SCSI_LOGGING_H */\n"}, "5": {"id": 5, "path": "/src/include/asm-generic/atomic-instrumented.h", "content": "// SPDX-License-Identifier: GPL-2.0\n\n// Generated by scripts/atomic/gen-atomic-instrumented.sh\n// DO NOT MODIFY THIS FILE DIRECTLY\n\n/*\n * This file provides wrappers with KASAN instrumentation for atomic operations.\n * To use this functionality an arch's atomic.h file needs to define all\n * atomic operations with arch_ prefix (e.g. arch_atomic_read()) and include\n * this file at the end. This file provides atomic_read() that forwards to\n * arch_atomic_read() for actual atomic operation.\n * Note: if an arch atomic operation is implemented by means of other atomic\n * operations (e.g. atomic_read()/atomic_cmpxchg() loop), then it needs to use\n * arch_ variants (i.e. arch_atomic_read()/arch_atomic_cmpxchg()) to avoid\n * double instrumentation.\n */\n#ifndef _ASM_GENERIC_ATOMIC_INSTRUMENTED_H\n#define _ASM_GENERIC_ATOMIC_INSTRUMENTED_H\n\n#include <linux/build_bug.h>\n#include <linux/compiler.h>\n#include <linux/instrumented.h>\n\nstatic __always_inline int\natomic_read(const atomic_t *v)\n{\n\tinstrument_atomic_read(v, sizeof(*v));\n\treturn arch_atomic_read(v);\n}\n#define atomic_read atomic_read\n\n#if defined(arch_atomic_read_acquire)\nstatic __always_inline int\natomic_read_acquire(const atomic_t *v)\n{\n\tinstrument_atomic_read(v, sizeof(*v));\n\treturn arch_atomic_read_acquire(v);\n}\n#define atomic_read_acquire atomic_read_acquire\n#endif\n\nstatic __always_inline void\natomic_set(atomic_t *v, int i)\n{\n\tinstrument_atomic_write(v, sizeof(*v));\n\tarch_atomic_set(v, i);\n}\n#define atomic_set atomic_set\n\n#if defined(arch_atomic_set_release)\nstatic __always_inline void\natomic_set_release(atomic_t *v, int i)\n{\n\tinstrument_atomic_write(v, sizeof(*v));\n\tarch_atomic_set_release(v, i);\n}\n#define atomic_set_release atomic_set_release\n#endif\n\nstatic __always_inline void\natomic_add(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\tarch_atomic_add(i, v);\n}\n#define atomic_add atomic_add\n\n#if !defined(arch_atomic_add_return_relaxed) || defined(arch_atomic_add_return)\nstatic __always_inline int\natomic_add_return(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_add_return(i, v);\n}\n#define atomic_add_return atomic_add_return\n#endif\n\n#if defined(arch_atomic_add_return_acquire)\nstatic __always_inline int\natomic_add_return_acquire(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_add_return_acquire(i, v);\n}\n#define atomic_add_return_acquire atomic_add_return_acquire\n#endif\n\n#if defined(arch_atomic_add_return_release)\nstatic __always_inline int\natomic_add_return_release(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_add_return_release(i, v);\n}\n#define atomic_add_return_release atomic_add_return_release\n#endif\n\n#if defined(arch_atomic_add_return_relaxed)\nstatic __always_inline int\natomic_add_return_relaxed(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_add_return_relaxed(i, v);\n}\n#define atomic_add_return_relaxed atomic_add_return_relaxed\n#endif\n\n#if !defined(arch_atomic_fetch_add_relaxed) || defined(arch_atomic_fetch_add)\nstatic __always_inline int\natomic_fetch_add(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_add(i, v);\n}\n#define atomic_fetch_add atomic_fetch_add\n#endif\n\n#if defined(arch_atomic_fetch_add_acquire)\nstatic __always_inline int\natomic_fetch_add_acquire(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_add_acquire(i, v);\n}\n#define atomic_fetch_add_acquire atomic_fetch_add_acquire\n#endif\n\n#if defined(arch_atomic_fetch_add_release)\nstatic __always_inline int\natomic_fetch_add_release(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_add_release(i, v);\n}\n#define atomic_fetch_add_release atomic_fetch_add_release\n#endif\n\n#if defined(arch_atomic_fetch_add_relaxed)\nstatic __always_inline int\natomic_fetch_add_relaxed(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_add_relaxed(i, v);\n}\n#define atomic_fetch_add_relaxed atomic_fetch_add_relaxed\n#endif\n\nstatic __always_inline void\natomic_sub(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\tarch_atomic_sub(i, v);\n}\n#define atomic_sub atomic_sub\n\n#if !defined(arch_atomic_sub_return_relaxed) || defined(arch_atomic_sub_return)\nstatic __always_inline int\natomic_sub_return(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_sub_return(i, v);\n}\n#define atomic_sub_return atomic_sub_return\n#endif\n\n#if defined(arch_atomic_sub_return_acquire)\nstatic __always_inline int\natomic_sub_return_acquire(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_sub_return_acquire(i, v);\n}\n#define atomic_sub_return_acquire atomic_sub_return_acquire\n#endif\n\n#if defined(arch_atomic_sub_return_release)\nstatic __always_inline int\natomic_sub_return_release(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_sub_return_release(i, v);\n}\n#define atomic_sub_return_release atomic_sub_return_release\n#endif\n\n#if defined(arch_atomic_sub_return_relaxed)\nstatic __always_inline int\natomic_sub_return_relaxed(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_sub_return_relaxed(i, v);\n}\n#define atomic_sub_return_relaxed atomic_sub_return_relaxed\n#endif\n\n#if !defined(arch_atomic_fetch_sub_relaxed) || defined(arch_atomic_fetch_sub)\nstatic __always_inline int\natomic_fetch_sub(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_sub(i, v);\n}\n#define atomic_fetch_sub atomic_fetch_sub\n#endif\n\n#if defined(arch_atomic_fetch_sub_acquire)\nstatic __always_inline int\natomic_fetch_sub_acquire(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_sub_acquire(i, v);\n}\n#define atomic_fetch_sub_acquire atomic_fetch_sub_acquire\n#endif\n\n#if defined(arch_atomic_fetch_sub_release)\nstatic __always_inline int\natomic_fetch_sub_release(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_sub_release(i, v);\n}\n#define atomic_fetch_sub_release atomic_fetch_sub_release\n#endif\n\n#if defined(arch_atomic_fetch_sub_relaxed)\nstatic __always_inline int\natomic_fetch_sub_relaxed(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_sub_relaxed(i, v);\n}\n#define atomic_fetch_sub_relaxed atomic_fetch_sub_relaxed\n#endif\n\n#if defined(arch_atomic_inc)\nstatic __always_inline void\natomic_inc(atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\tarch_atomic_inc(v);\n}\n#define atomic_inc atomic_inc\n#endif\n\n#if defined(arch_atomic_inc_return)\nstatic __always_inline int\natomic_inc_return(atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_inc_return(v);\n}\n#define atomic_inc_return atomic_inc_return\n#endif\n\n#if defined(arch_atomic_inc_return_acquire)\nstatic __always_inline int\natomic_inc_return_acquire(atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_inc_return_acquire(v);\n}\n#define atomic_inc_return_acquire atomic_inc_return_acquire\n#endif\n\n#if defined(arch_atomic_inc_return_release)\nstatic __always_inline int\natomic_inc_return_release(atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_inc_return_release(v);\n}\n#define atomic_inc_return_release atomic_inc_return_release\n#endif\n\n#if defined(arch_atomic_inc_return_relaxed)\nstatic __always_inline int\natomic_inc_return_relaxed(atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_inc_return_relaxed(v);\n}\n#define atomic_inc_return_relaxed atomic_inc_return_relaxed\n#endif\n\n#if defined(arch_atomic_fetch_inc)\nstatic __always_inline int\natomic_fetch_inc(atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_inc(v);\n}\n#define atomic_fetch_inc atomic_fetch_inc\n#endif\n\n#if defined(arch_atomic_fetch_inc_acquire)\nstatic __always_inline int\natomic_fetch_inc_acquire(atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_inc_acquire(v);\n}\n#define atomic_fetch_inc_acquire atomic_fetch_inc_acquire\n#endif\n\n#if defined(arch_atomic_fetch_inc_release)\nstatic __always_inline int\natomic_fetch_inc_release(atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_inc_release(v);\n}\n#define atomic_fetch_inc_release atomic_fetch_inc_release\n#endif\n\n#if defined(arch_atomic_fetch_inc_relaxed)\nstatic __always_inline int\natomic_fetch_inc_relaxed(atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_inc_relaxed(v);\n}\n#define atomic_fetch_inc_relaxed atomic_fetch_inc_relaxed\n#endif\n\n#if defined(arch_atomic_dec)\nstatic __always_inline void\natomic_dec(atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\tarch_atomic_dec(v);\n}\n#define atomic_dec atomic_dec\n#endif\n\n#if defined(arch_atomic_dec_return)\nstatic __always_inline int\natomic_dec_return(atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_dec_return(v);\n}\n#define atomic_dec_return atomic_dec_return\n#endif\n\n#if defined(arch_atomic_dec_return_acquire)\nstatic __always_inline int\natomic_dec_return_acquire(atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_dec_return_acquire(v);\n}\n#define atomic_dec_return_acquire atomic_dec_return_acquire\n#endif\n\n#if defined(arch_atomic_dec_return_release)\nstatic __always_inline int\natomic_dec_return_release(atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_dec_return_release(v);\n}\n#define atomic_dec_return_release atomic_dec_return_release\n#endif\n\n#if defined(arch_atomic_dec_return_relaxed)\nstatic __always_inline int\natomic_dec_return_relaxed(atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_dec_return_relaxed(v);\n}\n#define atomic_dec_return_relaxed atomic_dec_return_relaxed\n#endif\n\n#if defined(arch_atomic_fetch_dec)\nstatic __always_inline int\natomic_fetch_dec(atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_dec(v);\n}\n#define atomic_fetch_dec atomic_fetch_dec\n#endif\n\n#if defined(arch_atomic_fetch_dec_acquire)\nstatic __always_inline int\natomic_fetch_dec_acquire(atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_dec_acquire(v);\n}\n#define atomic_fetch_dec_acquire atomic_fetch_dec_acquire\n#endif\n\n#if defined(arch_atomic_fetch_dec_release)\nstatic __always_inline int\natomic_fetch_dec_release(atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_dec_release(v);\n}\n#define atomic_fetch_dec_release atomic_fetch_dec_release\n#endif\n\n#if defined(arch_atomic_fetch_dec_relaxed)\nstatic __always_inline int\natomic_fetch_dec_relaxed(atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_dec_relaxed(v);\n}\n#define atomic_fetch_dec_relaxed atomic_fetch_dec_relaxed\n#endif\n\nstatic __always_inline void\natomic_and(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\tarch_atomic_and(i, v);\n}\n#define atomic_and atomic_and\n\n#if !defined(arch_atomic_fetch_and_relaxed) || defined(arch_atomic_fetch_and)\nstatic __always_inline int\natomic_fetch_and(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_and(i, v);\n}\n#define atomic_fetch_and atomic_fetch_and\n#endif\n\n#if defined(arch_atomic_fetch_and_acquire)\nstatic __always_inline int\natomic_fetch_and_acquire(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_and_acquire(i, v);\n}\n#define atomic_fetch_and_acquire atomic_fetch_and_acquire\n#endif\n\n#if defined(arch_atomic_fetch_and_release)\nstatic __always_inline int\natomic_fetch_and_release(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_and_release(i, v);\n}\n#define atomic_fetch_and_release atomic_fetch_and_release\n#endif\n\n#if defined(arch_atomic_fetch_and_relaxed)\nstatic __always_inline int\natomic_fetch_and_relaxed(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_and_relaxed(i, v);\n}\n#define atomic_fetch_and_relaxed atomic_fetch_and_relaxed\n#endif\n\n#if defined(arch_atomic_andnot)\nstatic __always_inline void\natomic_andnot(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\tarch_atomic_andnot(i, v);\n}\n#define atomic_andnot atomic_andnot\n#endif\n\n#if defined(arch_atomic_fetch_andnot)\nstatic __always_inline int\natomic_fetch_andnot(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_andnot(i, v);\n}\n#define atomic_fetch_andnot atomic_fetch_andnot\n#endif\n\n#if defined(arch_atomic_fetch_andnot_acquire)\nstatic __always_inline int\natomic_fetch_andnot_acquire(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_andnot_acquire(i, v);\n}\n#define atomic_fetch_andnot_acquire atomic_fetch_andnot_acquire\n#endif\n\n#if defined(arch_atomic_fetch_andnot_release)\nstatic __always_inline int\natomic_fetch_andnot_release(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_andnot_release(i, v);\n}\n#define atomic_fetch_andnot_release atomic_fetch_andnot_release\n#endif\n\n#if defined(arch_atomic_fetch_andnot_relaxed)\nstatic __always_inline int\natomic_fetch_andnot_relaxed(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_andnot_relaxed(i, v);\n}\n#define atomic_fetch_andnot_relaxed atomic_fetch_andnot_relaxed\n#endif\n\nstatic __always_inline void\natomic_or(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\tarch_atomic_or(i, v);\n}\n#define atomic_or atomic_or\n\n#if !defined(arch_atomic_fetch_or_relaxed) || defined(arch_atomic_fetch_or)\nstatic __always_inline int\natomic_fetch_or(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_or(i, v);\n}\n#define atomic_fetch_or atomic_fetch_or\n#endif\n\n#if defined(arch_atomic_fetch_or_acquire)\nstatic __always_inline int\natomic_fetch_or_acquire(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_or_acquire(i, v);\n}\n#define atomic_fetch_or_acquire atomic_fetch_or_acquire\n#endif\n\n#if defined(arch_atomic_fetch_or_release)\nstatic __always_inline int\natomic_fetch_or_release(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_or_release(i, v);\n}\n#define atomic_fetch_or_release atomic_fetch_or_release\n#endif\n\n#if defined(arch_atomic_fetch_or_relaxed)\nstatic __always_inline int\natomic_fetch_or_relaxed(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_or_relaxed(i, v);\n}\n#define atomic_fetch_or_relaxed atomic_fetch_or_relaxed\n#endif\n\nstatic __always_inline void\natomic_xor(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\tarch_atomic_xor(i, v);\n}\n#define atomic_xor atomic_xor\n\n#if !defined(arch_atomic_fetch_xor_relaxed) || defined(arch_atomic_fetch_xor)\nstatic __always_inline int\natomic_fetch_xor(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_xor(i, v);\n}\n#define atomic_fetch_xor atomic_fetch_xor\n#endif\n\n#if defined(arch_atomic_fetch_xor_acquire)\nstatic __always_inline int\natomic_fetch_xor_acquire(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_xor_acquire(i, v);\n}\n#define atomic_fetch_xor_acquire atomic_fetch_xor_acquire\n#endif\n\n#if defined(arch_atomic_fetch_xor_release)\nstatic __always_inline int\natomic_fetch_xor_release(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_xor_release(i, v);\n}\n#define atomic_fetch_xor_release atomic_fetch_xor_release\n#endif\n\n#if defined(arch_atomic_fetch_xor_relaxed)\nstatic __always_inline int\natomic_fetch_xor_relaxed(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_xor_relaxed(i, v);\n}\n#define atomic_fetch_xor_relaxed atomic_fetch_xor_relaxed\n#endif\n\n#if !defined(arch_atomic_xchg_relaxed) || defined(arch_atomic_xchg)\nstatic __always_inline int\natomic_xchg(atomic_t *v, int i)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_xchg(v, i);\n}\n#define atomic_xchg atomic_xchg\n#endif\n\n#if defined(arch_atomic_xchg_acquire)\nstatic __always_inline int\natomic_xchg_acquire(atomic_t *v, int i)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_xchg_acquire(v, i);\n}\n#define atomic_xchg_acquire atomic_xchg_acquire\n#endif\n\n#if defined(arch_atomic_xchg_release)\nstatic __always_inline int\natomic_xchg_release(atomic_t *v, int i)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_xchg_release(v, i);\n}\n#define atomic_xchg_release atomic_xchg_release\n#endif\n\n#if defined(arch_atomic_xchg_relaxed)\nstatic __always_inline int\natomic_xchg_relaxed(atomic_t *v, int i)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_xchg_relaxed(v, i);\n}\n#define atomic_xchg_relaxed atomic_xchg_relaxed\n#endif\n\n#if !defined(arch_atomic_cmpxchg_relaxed) || defined(arch_atomic_cmpxchg)\nstatic __always_inline int\natomic_cmpxchg(atomic_t *v, int old, int new)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_cmpxchg(v, old, new);\n}\n#define atomic_cmpxchg atomic_cmpxchg\n#endif\n\n#if defined(arch_atomic_cmpxchg_acquire)\nstatic __always_inline int\natomic_cmpxchg_acquire(atomic_t *v, int old, int new)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_cmpxchg_acquire(v, old, new);\n}\n#define atomic_cmpxchg_acquire atomic_cmpxchg_acquire\n#endif\n\n#if defined(arch_atomic_cmpxchg_release)\nstatic __always_inline int\natomic_cmpxchg_release(atomic_t *v, int old, int new)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_cmpxchg_release(v, old, new);\n}\n#define atomic_cmpxchg_release atomic_cmpxchg_release\n#endif\n\n#if defined(arch_atomic_cmpxchg_relaxed)\nstatic __always_inline int\natomic_cmpxchg_relaxed(atomic_t *v, int old, int new)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_cmpxchg_relaxed(v, old, new);\n}\n#define atomic_cmpxchg_relaxed atomic_cmpxchg_relaxed\n#endif\n\n#if defined(arch_atomic_try_cmpxchg)\nstatic __always_inline bool\natomic_try_cmpxchg(atomic_t *v, int *old, int new)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\tinstrument_atomic_read_write(old, sizeof(*old));\n\treturn arch_atomic_try_cmpxchg(v, old, new);\n}\n#define atomic_try_cmpxchg atomic_try_cmpxchg\n#endif\n\n#if defined(arch_atomic_try_cmpxchg_acquire)\nstatic __always_inline bool\natomic_try_cmpxchg_acquire(atomic_t *v, int *old, int new)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\tinstrument_atomic_read_write(old, sizeof(*old));\n\treturn arch_atomic_try_cmpxchg_acquire(v, old, new);\n}\n#define atomic_try_cmpxchg_acquire atomic_try_cmpxchg_acquire\n#endif\n\n#if defined(arch_atomic_try_cmpxchg_release)\nstatic __always_inline bool\natomic_try_cmpxchg_release(atomic_t *v, int *old, int new)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\tinstrument_atomic_read_write(old, sizeof(*old));\n\treturn arch_atomic_try_cmpxchg_release(v, old, new);\n}\n#define atomic_try_cmpxchg_release atomic_try_cmpxchg_release\n#endif\n\n#if defined(arch_atomic_try_cmpxchg_relaxed)\nstatic __always_inline bool\natomic_try_cmpxchg_relaxed(atomic_t *v, int *old, int new)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\tinstrument_atomic_read_write(old, sizeof(*old));\n\treturn arch_atomic_try_cmpxchg_relaxed(v, old, new);\n}\n#define atomic_try_cmpxchg_relaxed atomic_try_cmpxchg_relaxed\n#endif\n\n#if defined(arch_atomic_sub_and_test)\nstatic __always_inline bool\natomic_sub_and_test(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_sub_and_test(i, v);\n}\n#define atomic_sub_and_test atomic_sub_and_test\n#endif\n\n#if defined(arch_atomic_dec_and_test)\nstatic __always_inline bool\natomic_dec_and_test(atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_dec_and_test(v);\n}\n#define atomic_dec_and_test atomic_dec_and_test\n#endif\n\n#if defined(arch_atomic_inc_and_test)\nstatic __always_inline bool\natomic_inc_and_test(atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_inc_and_test(v);\n}\n#define atomic_inc_and_test atomic_inc_and_test\n#endif\n\n#if defined(arch_atomic_add_negative)\nstatic __always_inline bool\natomic_add_negative(int i, atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_add_negative(i, v);\n}\n#define atomic_add_negative atomic_add_negative\n#endif\n\n#if defined(arch_atomic_fetch_add_unless)\nstatic __always_inline int\natomic_fetch_add_unless(atomic_t *v, int a, int u)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_fetch_add_unless(v, a, u);\n}\n#define atomic_fetch_add_unless atomic_fetch_add_unless\n#endif\n\n#if defined(arch_atomic_add_unless)\nstatic __always_inline bool\natomic_add_unless(atomic_t *v, int a, int u)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_add_unless(v, a, u);\n}\n#define atomic_add_unless atomic_add_unless\n#endif\n\n#if defined(arch_atomic_inc_not_zero)\nstatic __always_inline bool\natomic_inc_not_zero(atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_inc_not_zero(v);\n}\n#define atomic_inc_not_zero atomic_inc_not_zero\n#endif\n\n#if defined(arch_atomic_inc_unless_negative)\nstatic __always_inline bool\natomic_inc_unless_negative(atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_inc_unless_negative(v);\n}\n#define atomic_inc_unless_negative atomic_inc_unless_negative\n#endif\n\n#if defined(arch_atomic_dec_unless_positive)\nstatic __always_inline bool\natomic_dec_unless_positive(atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_dec_unless_positive(v);\n}\n#define atomic_dec_unless_positive atomic_dec_unless_positive\n#endif\n\n#if defined(arch_atomic_dec_if_positive)\nstatic __always_inline int\natomic_dec_if_positive(atomic_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic_dec_if_positive(v);\n}\n#define atomic_dec_if_positive atomic_dec_if_positive\n#endif\n\nstatic __always_inline s64\natomic64_read(const atomic64_t *v)\n{\n\tinstrument_atomic_read(v, sizeof(*v));\n\treturn arch_atomic64_read(v);\n}\n#define atomic64_read atomic64_read\n\n#if defined(arch_atomic64_read_acquire)\nstatic __always_inline s64\natomic64_read_acquire(const atomic64_t *v)\n{\n\tinstrument_atomic_read(v, sizeof(*v));\n\treturn arch_atomic64_read_acquire(v);\n}\n#define atomic64_read_acquire atomic64_read_acquire\n#endif\n\nstatic __always_inline void\natomic64_set(atomic64_t *v, s64 i)\n{\n\tinstrument_atomic_write(v, sizeof(*v));\n\tarch_atomic64_set(v, i);\n}\n#define atomic64_set atomic64_set\n\n#if defined(arch_atomic64_set_release)\nstatic __always_inline void\natomic64_set_release(atomic64_t *v, s64 i)\n{\n\tinstrument_atomic_write(v, sizeof(*v));\n\tarch_atomic64_set_release(v, i);\n}\n#define atomic64_set_release atomic64_set_release\n#endif\n\nstatic __always_inline void\natomic64_add(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\tarch_atomic64_add(i, v);\n}\n#define atomic64_add atomic64_add\n\n#if !defined(arch_atomic64_add_return_relaxed) || defined(arch_atomic64_add_return)\nstatic __always_inline s64\natomic64_add_return(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_add_return(i, v);\n}\n#define atomic64_add_return atomic64_add_return\n#endif\n\n#if defined(arch_atomic64_add_return_acquire)\nstatic __always_inline s64\natomic64_add_return_acquire(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_add_return_acquire(i, v);\n}\n#define atomic64_add_return_acquire atomic64_add_return_acquire\n#endif\n\n#if defined(arch_atomic64_add_return_release)\nstatic __always_inline s64\natomic64_add_return_release(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_add_return_release(i, v);\n}\n#define atomic64_add_return_release atomic64_add_return_release\n#endif\n\n#if defined(arch_atomic64_add_return_relaxed)\nstatic __always_inline s64\natomic64_add_return_relaxed(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_add_return_relaxed(i, v);\n}\n#define atomic64_add_return_relaxed atomic64_add_return_relaxed\n#endif\n\n#if !defined(arch_atomic64_fetch_add_relaxed) || defined(arch_atomic64_fetch_add)\nstatic __always_inline s64\natomic64_fetch_add(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_add(i, v);\n}\n#define atomic64_fetch_add atomic64_fetch_add\n#endif\n\n#if defined(arch_atomic64_fetch_add_acquire)\nstatic __always_inline s64\natomic64_fetch_add_acquire(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_add_acquire(i, v);\n}\n#define atomic64_fetch_add_acquire atomic64_fetch_add_acquire\n#endif\n\n#if defined(arch_atomic64_fetch_add_release)\nstatic __always_inline s64\natomic64_fetch_add_release(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_add_release(i, v);\n}\n#define atomic64_fetch_add_release atomic64_fetch_add_release\n#endif\n\n#if defined(arch_atomic64_fetch_add_relaxed)\nstatic __always_inline s64\natomic64_fetch_add_relaxed(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_add_relaxed(i, v);\n}\n#define atomic64_fetch_add_relaxed atomic64_fetch_add_relaxed\n#endif\n\nstatic __always_inline void\natomic64_sub(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\tarch_atomic64_sub(i, v);\n}\n#define atomic64_sub atomic64_sub\n\n#if !defined(arch_atomic64_sub_return_relaxed) || defined(arch_atomic64_sub_return)\nstatic __always_inline s64\natomic64_sub_return(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_sub_return(i, v);\n}\n#define atomic64_sub_return atomic64_sub_return\n#endif\n\n#if defined(arch_atomic64_sub_return_acquire)\nstatic __always_inline s64\natomic64_sub_return_acquire(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_sub_return_acquire(i, v);\n}\n#define atomic64_sub_return_acquire atomic64_sub_return_acquire\n#endif\n\n#if defined(arch_atomic64_sub_return_release)\nstatic __always_inline s64\natomic64_sub_return_release(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_sub_return_release(i, v);\n}\n#define atomic64_sub_return_release atomic64_sub_return_release\n#endif\n\n#if defined(arch_atomic64_sub_return_relaxed)\nstatic __always_inline s64\natomic64_sub_return_relaxed(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_sub_return_relaxed(i, v);\n}\n#define atomic64_sub_return_relaxed atomic64_sub_return_relaxed\n#endif\n\n#if !defined(arch_atomic64_fetch_sub_relaxed) || defined(arch_atomic64_fetch_sub)\nstatic __always_inline s64\natomic64_fetch_sub(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_sub(i, v);\n}\n#define atomic64_fetch_sub atomic64_fetch_sub\n#endif\n\n#if defined(arch_atomic64_fetch_sub_acquire)\nstatic __always_inline s64\natomic64_fetch_sub_acquire(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_sub_acquire(i, v);\n}\n#define atomic64_fetch_sub_acquire atomic64_fetch_sub_acquire\n#endif\n\n#if defined(arch_atomic64_fetch_sub_release)\nstatic __always_inline s64\natomic64_fetch_sub_release(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_sub_release(i, v);\n}\n#define atomic64_fetch_sub_release atomic64_fetch_sub_release\n#endif\n\n#if defined(arch_atomic64_fetch_sub_relaxed)\nstatic __always_inline s64\natomic64_fetch_sub_relaxed(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_sub_relaxed(i, v);\n}\n#define atomic64_fetch_sub_relaxed atomic64_fetch_sub_relaxed\n#endif\n\n#if defined(arch_atomic64_inc)\nstatic __always_inline void\natomic64_inc(atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\tarch_atomic64_inc(v);\n}\n#define atomic64_inc atomic64_inc\n#endif\n\n#if defined(arch_atomic64_inc_return)\nstatic __always_inline s64\natomic64_inc_return(atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_inc_return(v);\n}\n#define atomic64_inc_return atomic64_inc_return\n#endif\n\n#if defined(arch_atomic64_inc_return_acquire)\nstatic __always_inline s64\natomic64_inc_return_acquire(atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_inc_return_acquire(v);\n}\n#define atomic64_inc_return_acquire atomic64_inc_return_acquire\n#endif\n\n#if defined(arch_atomic64_inc_return_release)\nstatic __always_inline s64\natomic64_inc_return_release(atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_inc_return_release(v);\n}\n#define atomic64_inc_return_release atomic64_inc_return_release\n#endif\n\n#if defined(arch_atomic64_inc_return_relaxed)\nstatic __always_inline s64\natomic64_inc_return_relaxed(atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_inc_return_relaxed(v);\n}\n#define atomic64_inc_return_relaxed atomic64_inc_return_relaxed\n#endif\n\n#if defined(arch_atomic64_fetch_inc)\nstatic __always_inline s64\natomic64_fetch_inc(atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_inc(v);\n}\n#define atomic64_fetch_inc atomic64_fetch_inc\n#endif\n\n#if defined(arch_atomic64_fetch_inc_acquire)\nstatic __always_inline s64\natomic64_fetch_inc_acquire(atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_inc_acquire(v);\n}\n#define atomic64_fetch_inc_acquire atomic64_fetch_inc_acquire\n#endif\n\n#if defined(arch_atomic64_fetch_inc_release)\nstatic __always_inline s64\natomic64_fetch_inc_release(atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_inc_release(v);\n}\n#define atomic64_fetch_inc_release atomic64_fetch_inc_release\n#endif\n\n#if defined(arch_atomic64_fetch_inc_relaxed)\nstatic __always_inline s64\natomic64_fetch_inc_relaxed(atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_inc_relaxed(v);\n}\n#define atomic64_fetch_inc_relaxed atomic64_fetch_inc_relaxed\n#endif\n\n#if defined(arch_atomic64_dec)\nstatic __always_inline void\natomic64_dec(atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\tarch_atomic64_dec(v);\n}\n#define atomic64_dec atomic64_dec\n#endif\n\n#if defined(arch_atomic64_dec_return)\nstatic __always_inline s64\natomic64_dec_return(atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_dec_return(v);\n}\n#define atomic64_dec_return atomic64_dec_return\n#endif\n\n#if defined(arch_atomic64_dec_return_acquire)\nstatic __always_inline s64\natomic64_dec_return_acquire(atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_dec_return_acquire(v);\n}\n#define atomic64_dec_return_acquire atomic64_dec_return_acquire\n#endif\n\n#if defined(arch_atomic64_dec_return_release)\nstatic __always_inline s64\natomic64_dec_return_release(atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_dec_return_release(v);\n}\n#define atomic64_dec_return_release atomic64_dec_return_release\n#endif\n\n#if defined(arch_atomic64_dec_return_relaxed)\nstatic __always_inline s64\natomic64_dec_return_relaxed(atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_dec_return_relaxed(v);\n}\n#define atomic64_dec_return_relaxed atomic64_dec_return_relaxed\n#endif\n\n#if defined(arch_atomic64_fetch_dec)\nstatic __always_inline s64\natomic64_fetch_dec(atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_dec(v);\n}\n#define atomic64_fetch_dec atomic64_fetch_dec\n#endif\n\n#if defined(arch_atomic64_fetch_dec_acquire)\nstatic __always_inline s64\natomic64_fetch_dec_acquire(atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_dec_acquire(v);\n}\n#define atomic64_fetch_dec_acquire atomic64_fetch_dec_acquire\n#endif\n\n#if defined(arch_atomic64_fetch_dec_release)\nstatic __always_inline s64\natomic64_fetch_dec_release(atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_dec_release(v);\n}\n#define atomic64_fetch_dec_release atomic64_fetch_dec_release\n#endif\n\n#if defined(arch_atomic64_fetch_dec_relaxed)\nstatic __always_inline s64\natomic64_fetch_dec_relaxed(atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_dec_relaxed(v);\n}\n#define atomic64_fetch_dec_relaxed atomic64_fetch_dec_relaxed\n#endif\n\nstatic __always_inline void\natomic64_and(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\tarch_atomic64_and(i, v);\n}\n#define atomic64_and atomic64_and\n\n#if !defined(arch_atomic64_fetch_and_relaxed) || defined(arch_atomic64_fetch_and)\nstatic __always_inline s64\natomic64_fetch_and(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_and(i, v);\n}\n#define atomic64_fetch_and atomic64_fetch_and\n#endif\n\n#if defined(arch_atomic64_fetch_and_acquire)\nstatic __always_inline s64\natomic64_fetch_and_acquire(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_and_acquire(i, v);\n}\n#define atomic64_fetch_and_acquire atomic64_fetch_and_acquire\n#endif\n\n#if defined(arch_atomic64_fetch_and_release)\nstatic __always_inline s64\natomic64_fetch_and_release(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_and_release(i, v);\n}\n#define atomic64_fetch_and_release atomic64_fetch_and_release\n#endif\n\n#if defined(arch_atomic64_fetch_and_relaxed)\nstatic __always_inline s64\natomic64_fetch_and_relaxed(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_and_relaxed(i, v);\n}\n#define atomic64_fetch_and_relaxed atomic64_fetch_and_relaxed\n#endif\n\n#if defined(arch_atomic64_andnot)\nstatic __always_inline void\natomic64_andnot(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\tarch_atomic64_andnot(i, v);\n}\n#define atomic64_andnot atomic64_andnot\n#endif\n\n#if defined(arch_atomic64_fetch_andnot)\nstatic __always_inline s64\natomic64_fetch_andnot(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_andnot(i, v);\n}\n#define atomic64_fetch_andnot atomic64_fetch_andnot\n#endif\n\n#if defined(arch_atomic64_fetch_andnot_acquire)\nstatic __always_inline s64\natomic64_fetch_andnot_acquire(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_andnot_acquire(i, v);\n}\n#define atomic64_fetch_andnot_acquire atomic64_fetch_andnot_acquire\n#endif\n\n#if defined(arch_atomic64_fetch_andnot_release)\nstatic __always_inline s64\natomic64_fetch_andnot_release(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_andnot_release(i, v);\n}\n#define atomic64_fetch_andnot_release atomic64_fetch_andnot_release\n#endif\n\n#if defined(arch_atomic64_fetch_andnot_relaxed)\nstatic __always_inline s64\natomic64_fetch_andnot_relaxed(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_andnot_relaxed(i, v);\n}\n#define atomic64_fetch_andnot_relaxed atomic64_fetch_andnot_relaxed\n#endif\n\nstatic __always_inline void\natomic64_or(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\tarch_atomic64_or(i, v);\n}\n#define atomic64_or atomic64_or\n\n#if !defined(arch_atomic64_fetch_or_relaxed) || defined(arch_atomic64_fetch_or)\nstatic __always_inline s64\natomic64_fetch_or(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_or(i, v);\n}\n#define atomic64_fetch_or atomic64_fetch_or\n#endif\n\n#if defined(arch_atomic64_fetch_or_acquire)\nstatic __always_inline s64\natomic64_fetch_or_acquire(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_or_acquire(i, v);\n}\n#define atomic64_fetch_or_acquire atomic64_fetch_or_acquire\n#endif\n\n#if defined(arch_atomic64_fetch_or_release)\nstatic __always_inline s64\natomic64_fetch_or_release(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_or_release(i, v);\n}\n#define atomic64_fetch_or_release atomic64_fetch_or_release\n#endif\n\n#if defined(arch_atomic64_fetch_or_relaxed)\nstatic __always_inline s64\natomic64_fetch_or_relaxed(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_or_relaxed(i, v);\n}\n#define atomic64_fetch_or_relaxed atomic64_fetch_or_relaxed\n#endif\n\nstatic __always_inline void\natomic64_xor(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\tarch_atomic64_xor(i, v);\n}\n#define atomic64_xor atomic64_xor\n\n#if !defined(arch_atomic64_fetch_xor_relaxed) || defined(arch_atomic64_fetch_xor)\nstatic __always_inline s64\natomic64_fetch_xor(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_xor(i, v);\n}\n#define atomic64_fetch_xor atomic64_fetch_xor\n#endif\n\n#if defined(arch_atomic64_fetch_xor_acquire)\nstatic __always_inline s64\natomic64_fetch_xor_acquire(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_xor_acquire(i, v);\n}\n#define atomic64_fetch_xor_acquire atomic64_fetch_xor_acquire\n#endif\n\n#if defined(arch_atomic64_fetch_xor_release)\nstatic __always_inline s64\natomic64_fetch_xor_release(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_xor_release(i, v);\n}\n#define atomic64_fetch_xor_release atomic64_fetch_xor_release\n#endif\n\n#if defined(arch_atomic64_fetch_xor_relaxed)\nstatic __always_inline s64\natomic64_fetch_xor_relaxed(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_xor_relaxed(i, v);\n}\n#define atomic64_fetch_xor_relaxed atomic64_fetch_xor_relaxed\n#endif\n\n#if !defined(arch_atomic64_xchg_relaxed) || defined(arch_atomic64_xchg)\nstatic __always_inline s64\natomic64_xchg(atomic64_t *v, s64 i)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_xchg(v, i);\n}\n#define atomic64_xchg atomic64_xchg\n#endif\n\n#if defined(arch_atomic64_xchg_acquire)\nstatic __always_inline s64\natomic64_xchg_acquire(atomic64_t *v, s64 i)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_xchg_acquire(v, i);\n}\n#define atomic64_xchg_acquire atomic64_xchg_acquire\n#endif\n\n#if defined(arch_atomic64_xchg_release)\nstatic __always_inline s64\natomic64_xchg_release(atomic64_t *v, s64 i)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_xchg_release(v, i);\n}\n#define atomic64_xchg_release atomic64_xchg_release\n#endif\n\n#if defined(arch_atomic64_xchg_relaxed)\nstatic __always_inline s64\natomic64_xchg_relaxed(atomic64_t *v, s64 i)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_xchg_relaxed(v, i);\n}\n#define atomic64_xchg_relaxed atomic64_xchg_relaxed\n#endif\n\n#if !defined(arch_atomic64_cmpxchg_relaxed) || defined(arch_atomic64_cmpxchg)\nstatic __always_inline s64\natomic64_cmpxchg(atomic64_t *v, s64 old, s64 new)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_cmpxchg(v, old, new);\n}\n#define atomic64_cmpxchg atomic64_cmpxchg\n#endif\n\n#if defined(arch_atomic64_cmpxchg_acquire)\nstatic __always_inline s64\natomic64_cmpxchg_acquire(atomic64_t *v, s64 old, s64 new)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_cmpxchg_acquire(v, old, new);\n}\n#define atomic64_cmpxchg_acquire atomic64_cmpxchg_acquire\n#endif\n\n#if defined(arch_atomic64_cmpxchg_release)\nstatic __always_inline s64\natomic64_cmpxchg_release(atomic64_t *v, s64 old, s64 new)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_cmpxchg_release(v, old, new);\n}\n#define atomic64_cmpxchg_release atomic64_cmpxchg_release\n#endif\n\n#if defined(arch_atomic64_cmpxchg_relaxed)\nstatic __always_inline s64\natomic64_cmpxchg_relaxed(atomic64_t *v, s64 old, s64 new)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_cmpxchg_relaxed(v, old, new);\n}\n#define atomic64_cmpxchg_relaxed atomic64_cmpxchg_relaxed\n#endif\n\n#if defined(arch_atomic64_try_cmpxchg)\nstatic __always_inline bool\natomic64_try_cmpxchg(atomic64_t *v, s64 *old, s64 new)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\tinstrument_atomic_read_write(old, sizeof(*old));\n\treturn arch_atomic64_try_cmpxchg(v, old, new);\n}\n#define atomic64_try_cmpxchg atomic64_try_cmpxchg\n#endif\n\n#if defined(arch_atomic64_try_cmpxchg_acquire)\nstatic __always_inline bool\natomic64_try_cmpxchg_acquire(atomic64_t *v, s64 *old, s64 new)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\tinstrument_atomic_read_write(old, sizeof(*old));\n\treturn arch_atomic64_try_cmpxchg_acquire(v, old, new);\n}\n#define atomic64_try_cmpxchg_acquire atomic64_try_cmpxchg_acquire\n#endif\n\n#if defined(arch_atomic64_try_cmpxchg_release)\nstatic __always_inline bool\natomic64_try_cmpxchg_release(atomic64_t *v, s64 *old, s64 new)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\tinstrument_atomic_read_write(old, sizeof(*old));\n\treturn arch_atomic64_try_cmpxchg_release(v, old, new);\n}\n#define atomic64_try_cmpxchg_release atomic64_try_cmpxchg_release\n#endif\n\n#if defined(arch_atomic64_try_cmpxchg_relaxed)\nstatic __always_inline bool\natomic64_try_cmpxchg_relaxed(atomic64_t *v, s64 *old, s64 new)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\tinstrument_atomic_read_write(old, sizeof(*old));\n\treturn arch_atomic64_try_cmpxchg_relaxed(v, old, new);\n}\n#define atomic64_try_cmpxchg_relaxed atomic64_try_cmpxchg_relaxed\n#endif\n\n#if defined(arch_atomic64_sub_and_test)\nstatic __always_inline bool\natomic64_sub_and_test(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_sub_and_test(i, v);\n}\n#define atomic64_sub_and_test atomic64_sub_and_test\n#endif\n\n#if defined(arch_atomic64_dec_and_test)\nstatic __always_inline bool\natomic64_dec_and_test(atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_dec_and_test(v);\n}\n#define atomic64_dec_and_test atomic64_dec_and_test\n#endif\n\n#if defined(arch_atomic64_inc_and_test)\nstatic __always_inline bool\natomic64_inc_and_test(atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_inc_and_test(v);\n}\n#define atomic64_inc_and_test atomic64_inc_and_test\n#endif\n\n#if defined(arch_atomic64_add_negative)\nstatic __always_inline bool\natomic64_add_negative(s64 i, atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_add_negative(i, v);\n}\n#define atomic64_add_negative atomic64_add_negative\n#endif\n\n#if defined(arch_atomic64_fetch_add_unless)\nstatic __always_inline s64\natomic64_fetch_add_unless(atomic64_t *v, s64 a, s64 u)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_fetch_add_unless(v, a, u);\n}\n#define atomic64_fetch_add_unless atomic64_fetch_add_unless\n#endif\n\n#if defined(arch_atomic64_add_unless)\nstatic __always_inline bool\natomic64_add_unless(atomic64_t *v, s64 a, s64 u)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_add_unless(v, a, u);\n}\n#define atomic64_add_unless atomic64_add_unless\n#endif\n\n#if defined(arch_atomic64_inc_not_zero)\nstatic __always_inline bool\natomic64_inc_not_zero(atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_inc_not_zero(v);\n}\n#define atomic64_inc_not_zero atomic64_inc_not_zero\n#endif\n\n#if defined(arch_atomic64_inc_unless_negative)\nstatic __always_inline bool\natomic64_inc_unless_negative(atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_inc_unless_negative(v);\n}\n#define atomic64_inc_unless_negative atomic64_inc_unless_negative\n#endif\n\n#if defined(arch_atomic64_dec_unless_positive)\nstatic __always_inline bool\natomic64_dec_unless_positive(atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_dec_unless_positive(v);\n}\n#define atomic64_dec_unless_positive atomic64_dec_unless_positive\n#endif\n\n#if defined(arch_atomic64_dec_if_positive)\nstatic __always_inline s64\natomic64_dec_if_positive(atomic64_t *v)\n{\n\tinstrument_atomic_read_write(v, sizeof(*v));\n\treturn arch_atomic64_dec_if_positive(v);\n}\n#define atomic64_dec_if_positive atomic64_dec_if_positive\n#endif\n\n#if !defined(arch_xchg_relaxed) || defined(arch_xchg)\n#define xchg(ptr, ...) \\\n({ \\\n\ttypeof(ptr) __ai_ptr = (ptr); \\\n\tinstrument_atomic_write(__ai_ptr, sizeof(*__ai_ptr)); \\\n\tarch_xchg(__ai_ptr, __VA_ARGS__); \\\n})\n#endif\n\n#if defined(arch_xchg_acquire)\n#define xchg_acquire(ptr, ...) \\\n({ \\\n\ttypeof(ptr) __ai_ptr = (ptr); \\\n\tinstrument_atomic_write(__ai_ptr, sizeof(*__ai_ptr)); \\\n\tarch_xchg_acquire(__ai_ptr, __VA_ARGS__); \\\n})\n#endif\n\n#if defined(arch_xchg_release)\n#define xchg_release(ptr, ...) \\\n({ \\\n\ttypeof(ptr) __ai_ptr = (ptr); \\\n\tinstrument_atomic_write(__ai_ptr, sizeof(*__ai_ptr)); \\\n\tarch_xchg_release(__ai_ptr, __VA_ARGS__); \\\n})\n#endif\n\n#if defined(arch_xchg_relaxed)\n#define xchg_relaxed(ptr, ...) \\\n({ \\\n\ttypeof(ptr) __ai_ptr = (ptr); \\\n\tinstrument_atomic_write(__ai_ptr, sizeof(*__ai_ptr)); \\\n\tarch_xchg_relaxed(__ai_ptr, __VA_ARGS__); \\\n})\n#endif\n\n#if !defined(arch_cmpxchg_relaxed) || defined(arch_cmpxchg)\n#define cmpxchg(ptr, ...) \\\n({ \\\n\ttypeof(ptr) __ai_ptr = (ptr); \\\n\tinstrument_atomic_write(__ai_ptr, sizeof(*__ai_ptr)); \\\n\tarch_cmpxchg(__ai_ptr, __VA_ARGS__); \\\n})\n#endif\n\n#if defined(arch_cmpxchg_acquire)\n#define cmpxchg_acquire(ptr, ...) \\\n({ \\\n\ttypeof(ptr) __ai_ptr = (ptr); \\\n\tinstrument_atomic_write(__ai_ptr, sizeof(*__ai_ptr)); \\\n\tarch_cmpxchg_acquire(__ai_ptr, __VA_ARGS__); \\\n})\n#endif\n\n#if defined(arch_cmpxchg_release)\n#define cmpxchg_release(ptr, ...) \\\n({ \\\n\ttypeof(ptr) __ai_ptr = (ptr); \\\n\tinstrument_atomic_write(__ai_ptr, sizeof(*__ai_ptr)); \\\n\tarch_cmpxchg_release(__ai_ptr, __VA_ARGS__); \\\n})\n#endif\n\n#if defined(arch_cmpxchg_relaxed)\n#define cmpxchg_relaxed(ptr, ...) \\\n({ \\\n\ttypeof(ptr) __ai_ptr = (ptr); \\\n\tinstrument_atomic_write(__ai_ptr, sizeof(*__ai_ptr)); \\\n\tarch_cmpxchg_relaxed(__ai_ptr, __VA_ARGS__); \\\n})\n#endif\n\n#if !defined(arch_cmpxchg64_relaxed) || defined(arch_cmpxchg64)\n#define cmpxchg64(ptr, ...) \\\n({ \\\n\ttypeof(ptr) __ai_ptr = (ptr); \\\n\tinstrument_atomic_write(__ai_ptr, sizeof(*__ai_ptr)); \\\n\tarch_cmpxchg64(__ai_ptr, __VA_ARGS__); \\\n})\n#endif\n\n#if defined(arch_cmpxchg64_acquire)\n#define cmpxchg64_acquire(ptr, ...) \\\n({ \\\n\ttypeof(ptr) __ai_ptr = (ptr); \\\n\tinstrument_atomic_write(__ai_ptr, sizeof(*__ai_ptr)); \\\n\tarch_cmpxchg64_acquire(__ai_ptr, __VA_ARGS__); \\\n})\n#endif\n\n#if defined(arch_cmpxchg64_release)\n#define cmpxchg64_release(ptr, ...) \\\n({ \\\n\ttypeof(ptr) __ai_ptr = (ptr); \\\n\tinstrument_atomic_write(__ai_ptr, sizeof(*__ai_ptr)); \\\n\tarch_cmpxchg64_release(__ai_ptr, __VA_ARGS__); \\\n})\n#endif\n\n#if defined(arch_cmpxchg64_relaxed)\n#define cmpxchg64_relaxed(ptr, ...) \\\n({ \\\n\ttypeof(ptr) __ai_ptr = (ptr); \\\n\tinstrument_atomic_write(__ai_ptr, sizeof(*__ai_ptr)); \\\n\tarch_cmpxchg64_relaxed(__ai_ptr, __VA_ARGS__); \\\n})\n#endif\n\n#if !defined(arch_try_cmpxchg_relaxed) || defined(arch_try_cmpxchg)\n#define try_cmpxchg(ptr, oldp, ...) \\\n({ \\\n\ttypeof(ptr) __ai_ptr = (ptr); \\\n\ttypeof(oldp) __ai_oldp = (oldp); \\\n\tinstrument_atomic_write(__ai_ptr, sizeof(*__ai_ptr)); \\\n\tinstrument_atomic_write(__ai_oldp, sizeof(*__ai_oldp)); \\\n\tarch_try_cmpxchg(__ai_ptr, __ai_oldp, __VA_ARGS__); \\\n})\n#endif\n\n#if defined(arch_try_cmpxchg_acquire)\n#define try_cmpxchg_acquire(ptr, oldp, ...) \\\n({ \\\n\ttypeof(ptr) __ai_ptr = (ptr); \\\n\ttypeof(oldp) __ai_oldp = (oldp); \\\n\tinstrument_atomic_write(__ai_ptr, sizeof(*__ai_ptr)); \\\n\tinstrument_atomic_write(__ai_oldp, sizeof(*__ai_oldp)); \\\n\tarch_try_cmpxchg_acquire(__ai_ptr, __ai_oldp, __VA_ARGS__); \\\n})\n#endif\n\n#if defined(arch_try_cmpxchg_release)\n#define try_cmpxchg_release(ptr, oldp, ...) \\\n({ \\\n\ttypeof(ptr) __ai_ptr = (ptr); \\\n\ttypeof(oldp) __ai_oldp = (oldp); \\\n\tinstrument_atomic_write(__ai_ptr, sizeof(*__ai_ptr)); \\\n\tinstrument_atomic_write(__ai_oldp, sizeof(*__ai_oldp)); \\\n\tarch_try_cmpxchg_release(__ai_ptr, __ai_oldp, __VA_ARGS__); \\\n})\n#endif\n\n#if defined(arch_try_cmpxchg_relaxed)\n#define try_cmpxchg_relaxed(ptr, oldp, ...) \\\n({ \\\n\ttypeof(ptr) __ai_ptr = (ptr); \\\n\ttypeof(oldp) __ai_oldp = (oldp); \\\n\tinstrument_atomic_write(__ai_ptr, sizeof(*__ai_ptr)); \\\n\tinstrument_atomic_write(__ai_oldp, sizeof(*__ai_oldp)); \\\n\tarch_try_cmpxchg_relaxed(__ai_ptr, __ai_oldp, __VA_ARGS__); \\\n})\n#endif\n\n#define cmpxchg_local(ptr, ...) \\\n({ \\\n\ttypeof(ptr) __ai_ptr = (ptr); \\\n\tinstrument_atomic_write(__ai_ptr, sizeof(*__ai_ptr)); \\\n\tarch_cmpxchg_local(__ai_ptr, __VA_ARGS__); \\\n})\n\n#define cmpxchg64_local(ptr, ...) \\\n({ \\\n\ttypeof(ptr) __ai_ptr = (ptr); \\\n\tinstrument_atomic_write(__ai_ptr, sizeof(*__ai_ptr)); \\\n\tarch_cmpxchg64_local(__ai_ptr, __VA_ARGS__); \\\n})\n\n#define sync_cmpxchg(ptr, ...) \\\n({ \\\n\ttypeof(ptr) __ai_ptr = (ptr); \\\n\tinstrument_atomic_write(__ai_ptr, sizeof(*__ai_ptr)); \\\n\tarch_sync_cmpxchg(__ai_ptr, __VA_ARGS__); \\\n})\n\n#define cmpxchg_double(ptr, ...) \\\n({ \\\n\ttypeof(ptr) __ai_ptr = (ptr); \\\n\tinstrument_atomic_write(__ai_ptr, 2 * sizeof(*__ai_ptr)); \\\n\tarch_cmpxchg_double(__ai_ptr, __VA_ARGS__); \\\n})\n\n\n#define cmpxchg_double_local(ptr, ...) \\\n({ \\\n\ttypeof(ptr) __ai_ptr = (ptr); \\\n\tinstrument_atomic_write(__ai_ptr, 2 * sizeof(*__ai_ptr)); \\\n\tarch_cmpxchg_double_local(__ai_ptr, __VA_ARGS__); \\\n})\n\n#endif /* _ASM_GENERIC_ATOMIC_INSTRUMENTED_H */\n// 4bec382e44520f4d8267e42620054db26a659ea3\n"}, "6": {"id": 6, "path": "/src/include/linux/uaccess.h", "content": "/* SPDX-License-Identifier: GPL-2.0 */\n#ifndef __LINUX_UACCESS_H__\n#define __LINUX_UACCESS_H__\n\n#include <linux/fault-inject-usercopy.h>\n#include <linux/instrumented.h>\n#include <linux/minmax.h>\n#include <linux/sched.h>\n#include <linux/thread_info.h>\n\n#include <asm/uaccess.h>\n\n#ifdef CONFIG_SET_FS\n/*\n * Force the uaccess routines to be wired up for actual userspace access,\n * overriding any possible set_fs(KERNEL_DS) still lingering around.  Undone\n * using force_uaccess_end below.\n */\nstatic inline mm_segment_t force_uaccess_begin(void)\n{\n\tmm_segment_t fs = get_fs();\n\n\tset_fs(USER_DS);\n\treturn fs;\n}\n\nstatic inline void force_uaccess_end(mm_segment_t oldfs)\n{\n\tset_fs(oldfs);\n}\n#else /* CONFIG_SET_FS */\ntypedef struct {\n\t/* empty dummy */\n} mm_segment_t;\n\n#ifndef TASK_SIZE_MAX\n#define TASK_SIZE_MAX\t\t\tTASK_SIZE\n#endif\n\n#define uaccess_kernel()\t\t(false)\n#define user_addr_max()\t\t\t(TASK_SIZE_MAX)\n\nstatic inline mm_segment_t force_uaccess_begin(void)\n{\n\treturn (mm_segment_t) { };\n}\n\nstatic inline void force_uaccess_end(mm_segment_t oldfs)\n{\n}\n#endif /* CONFIG_SET_FS */\n\n/*\n * Architectures should provide two primitives (raw_copy_{to,from}_user())\n * and get rid of their private instances of copy_{to,from}_user() and\n * __copy_{to,from}_user{,_inatomic}().\n *\n * raw_copy_{to,from}_user(to, from, size) should copy up to size bytes and\n * return the amount left to copy.  They should assume that access_ok() has\n * already been checked (and succeeded); they should *not* zero-pad anything.\n * No KASAN or object size checks either - those belong here.\n *\n * Both of these functions should attempt to copy size bytes starting at from\n * into the area starting at to.  They must not fetch or store anything\n * outside of those areas.  Return value must be between 0 (everything\n * copied successfully) and size (nothing copied).\n *\n * If raw_copy_{to,from}_user(to, from, size) returns N, size - N bytes starting\n * at to must become equal to the bytes fetched from the corresponding area\n * starting at from.  All data past to + size - N must be left unmodified.\n *\n * If copying succeeds, the return value must be 0.  If some data cannot be\n * fetched, it is permitted to copy less than had been fetched; the only\n * hard requirement is that not storing anything at all (i.e. returning size)\n * should happen only when nothing could be copied.  In other words, you don't\n * have to squeeze as much as possible - it is allowed, but not necessary.\n *\n * For raw_copy_from_user() to always points to kernel memory and no faults\n * on store should happen.  Interpretation of from is affected by set_fs().\n * For raw_copy_to_user() it's the other way round.\n *\n * Both can be inlined - it's up to architectures whether it wants to bother\n * with that.  They should not be used directly; they are used to implement\n * the 6 functions (copy_{to,from}_user(), __copy_{to,from}_user_inatomic())\n * that are used instead.  Out of those, __... ones are inlined.  Plain\n * copy_{to,from}_user() might or might not be inlined.  If you want them\n * inlined, have asm/uaccess.h define INLINE_COPY_{TO,FROM}_USER.\n *\n * NOTE: only copy_from_user() zero-pads the destination in case of short copy.\n * Neither __copy_from_user() nor __copy_from_user_inatomic() zero anything\n * at all; their callers absolutely must check the return value.\n *\n * Biarch ones should also provide raw_copy_in_user() - similar to the above,\n * but both source and destination are __user pointers (affected by set_fs()\n * as usual) and both source and destination can trigger faults.\n */\n\nstatic __always_inline __must_check unsigned long\n__copy_from_user_inatomic(void *to, const void __user *from, unsigned long n)\n{\n\tinstrument_copy_from_user(to, from, n);\n\tcheck_object_size(to, n, false);\n\treturn raw_copy_from_user(to, from, n);\n}\n\nstatic __always_inline __must_check unsigned long\n__copy_from_user(void *to, const void __user *from, unsigned long n)\n{\n\tmight_fault();\n\tif (should_fail_usercopy())\n\t\treturn n;\n\tinstrument_copy_from_user(to, from, n);\n\tcheck_object_size(to, n, false);\n\treturn raw_copy_from_user(to, from, n);\n}\n\n/**\n * __copy_to_user_inatomic: - Copy a block of data into user space, with less checking.\n * @to:   Destination address, in user space.\n * @from: Source address, in kernel space.\n * @n:    Number of bytes to copy.\n *\n * Context: User context only.\n *\n * Copy data from kernel space to user space.  Caller must check\n * the specified block with access_ok() before calling this function.\n * The caller should also make sure he pins the user space address\n * so that we don't result in page fault and sleep.\n */\nstatic __always_inline __must_check unsigned long\n__copy_to_user_inatomic(void __user *to, const void *from, unsigned long n)\n{\n\tif (should_fail_usercopy())\n\t\treturn n;\n\tinstrument_copy_to_user(to, from, n);\n\tcheck_object_size(from, n, true);\n\treturn raw_copy_to_user(to, from, n);\n}\n\nstatic __always_inline __must_check unsigned long\n__copy_to_user(void __user *to, const void *from, unsigned long n)\n{\n\tmight_fault();\n\tif (should_fail_usercopy())\n\t\treturn n;\n\tinstrument_copy_to_user(to, from, n);\n\tcheck_object_size(from, n, true);\n\treturn raw_copy_to_user(to, from, n);\n}\n\n#ifdef INLINE_COPY_FROM_USER\nstatic inline __must_check unsigned long\n_copy_from_user(void *to, const void __user *from, unsigned long n)\n{\n\tunsigned long res = n;\n\tmight_fault();\n\tif (!should_fail_usercopy() && likely(access_ok(from, n))) {\n\t\tinstrument_copy_from_user(to, from, n);\n\t\tres = raw_copy_from_user(to, from, n);\n\t}\n\tif (unlikely(res))\n\t\tmemset(to + (n - res), 0, res);\n\treturn res;\n}\n#else\nextern __must_check unsigned long\n_copy_from_user(void *, const void __user *, unsigned long);\n#endif\n\n#ifdef INLINE_COPY_TO_USER\nstatic inline __must_check unsigned long\n_copy_to_user(void __user *to, const void *from, unsigned long n)\n{\n\tmight_fault();\n\tif (should_fail_usercopy())\n\t\treturn n;\n\tif (access_ok(to, n)) {\n\t\tinstrument_copy_to_user(to, from, n);\n\t\tn = raw_copy_to_user(to, from, n);\n\t}\n\treturn n;\n}\n#else\nextern __must_check unsigned long\n_copy_to_user(void __user *, const void *, unsigned long);\n#endif\n\nstatic __always_inline unsigned long __must_check\ncopy_from_user(void *to, const void __user *from, unsigned long n)\n{\n\tif (likely(check_copy_size(to, n, false)))\n\t\tn = _copy_from_user(to, from, n);\n\treturn n;\n}\n\nstatic __always_inline unsigned long __must_check\ncopy_to_user(void __user *to, const void *from, unsigned long n)\n{\n\tif (likely(check_copy_size(from, n, true)))\n\t\tn = _copy_to_user(to, from, n);\n\treturn n;\n}\n#ifdef CONFIG_COMPAT\nstatic __always_inline unsigned long __must_check\ncopy_in_user(void __user *to, const void __user *from, unsigned long n)\n{\n\tmight_fault();\n\tif (access_ok(to, n) && access_ok(from, n))\n\t\tn = raw_copy_in_user(to, from, n);\n\treturn n;\n}\n#endif\n\n#ifndef copy_mc_to_kernel\n/*\n * Without arch opt-in this generic copy_mc_to_kernel() will not handle\n * #MC (or arch equivalent) during source read.\n */\nstatic inline unsigned long __must_check\ncopy_mc_to_kernel(void *dst, const void *src, size_t cnt)\n{\n\tmemcpy(dst, src, cnt);\n\treturn 0;\n}\n#endif\n\nstatic __always_inline void pagefault_disabled_inc(void)\n{\n\tcurrent->pagefault_disabled++;\n}\n\nstatic __always_inline void pagefault_disabled_dec(void)\n{\n\tcurrent->pagefault_disabled--;\n}\n\n/*\n * These routines enable/disable the pagefault handler. If disabled, it will\n * not take any locks and go straight to the fixup table.\n *\n * User access methods will not sleep when called from a pagefault_disabled()\n * environment.\n */\nstatic inline void pagefault_disable(void)\n{\n\tpagefault_disabled_inc();\n\t/*\n\t * make sure to have issued the store before a pagefault\n\t * can hit.\n\t */\n\tbarrier();\n}\n\nstatic inline void pagefault_enable(void)\n{\n\t/*\n\t * make sure to issue those last loads/stores before enabling\n\t * the pagefault handler again.\n\t */\n\tbarrier();\n\tpagefault_disabled_dec();\n}\n\n/*\n * Is the pagefault handler disabled? If so, user access methods will not sleep.\n */\nstatic inline bool pagefault_disabled(void)\n{\n\treturn current->pagefault_disabled != 0;\n}\n\n/*\n * The pagefault handler is in general disabled by pagefault_disable() or\n * when in irq context (via in_atomic()).\n *\n * This function should only be used by the fault handlers. Other users should\n * stick to pagefault_disabled().\n * Please NEVER use preempt_disable() to disable the fault handler. With\n * !CONFIG_PREEMPT_COUNT, this is like a NOP. So the handler won't be disabled.\n * in_atomic() will report different values based on !CONFIG_PREEMPT_COUNT.\n */\n#define faulthandler_disabled() (pagefault_disabled() || in_atomic())\n\n#ifndef ARCH_HAS_NOCACHE_UACCESS\n\nstatic inline __must_check unsigned long\n__copy_from_user_inatomic_nocache(void *to, const void __user *from,\n\t\t\t\t  unsigned long n)\n{\n\treturn __copy_from_user_inatomic(to, from, n);\n}\n\n#endif\t\t/* ARCH_HAS_NOCACHE_UACCESS */\n\nextern __must_check int check_zeroed_user(const void __user *from, size_t size);\n\n/**\n * copy_struct_from_user: copy a struct from userspace\n * @dst:   Destination address, in kernel space. This buffer must be @ksize\n *         bytes long.\n * @ksize: Size of @dst struct.\n * @src:   Source address, in userspace.\n * @usize: (Alleged) size of @src struct.\n *\n * Copies a struct from userspace to kernel space, in a way that guarantees\n * backwards-compatibility for struct syscall arguments (as long as future\n * struct extensions are made such that all new fields are *appended* to the\n * old struct, and zeroed-out new fields have the same meaning as the old\n * struct).\n *\n * @ksize is just sizeof(*dst), and @usize should've been passed by userspace.\n * The recommended usage is something like the following:\n *\n *   SYSCALL_DEFINE2(foobar, const struct foo __user *, uarg, size_t, usize)\n *   {\n *      int err;\n *      struct foo karg = {};\n *\n *      if (usize > PAGE_SIZE)\n *        return -E2BIG;\n *      if (usize < FOO_SIZE_VER0)\n *        return -EINVAL;\n *\n *      err = copy_struct_from_user(&karg, sizeof(karg), uarg, usize);\n *      if (err)\n *        return err;\n *\n *      // ...\n *   }\n *\n * There are three cases to consider:\n *  * If @usize == @ksize, then it's copied verbatim.\n *  * If @usize < @ksize, then the userspace has passed an old struct to a\n *    newer kernel. The rest of the trailing bytes in @dst (@ksize - @usize)\n *    are to be zero-filled.\n *  * If @usize > @ksize, then the userspace has passed a new struct to an\n *    older kernel. The trailing bytes unknown to the kernel (@usize - @ksize)\n *    are checked to ensure they are zeroed, otherwise -E2BIG is returned.\n *\n * Returns (in all cases, some data may have been copied):\n *  * -E2BIG:  (@usize > @ksize) and there are non-zero trailing bytes in @src.\n *  * -EFAULT: access to userspace failed.\n */\nstatic __always_inline __must_check int\ncopy_struct_from_user(void *dst, size_t ksize, const void __user *src,\n\t\t      size_t usize)\n{\n\tsize_t size = min(ksize, usize);\n\tsize_t rest = max(ksize, usize) - size;\n\n\t/* Deal with trailing bytes. */\n\tif (usize < ksize) {\n\t\tmemset(dst + size, 0, rest);\n\t} else if (usize > ksize) {\n\t\tint ret = check_zeroed_user(src + size, rest);\n\t\tif (ret <= 0)\n\t\t\treturn ret ?: -E2BIG;\n\t}\n\t/* Copy the interoperable parts of the struct. */\n\tif (copy_from_user(dst, src, size))\n\t\treturn -EFAULT;\n\treturn 0;\n}\n\nbool copy_from_kernel_nofault_allowed(const void *unsafe_src, size_t size);\n\nlong copy_from_kernel_nofault(void *dst, const void *src, size_t size);\nlong notrace copy_to_kernel_nofault(void *dst, const void *src, size_t size);\n\nlong copy_from_user_nofault(void *dst, const void __user *src, size_t size);\nlong notrace copy_to_user_nofault(void __user *dst, const void *src,\n\t\tsize_t size);\n\nlong strncpy_from_kernel_nofault(char *dst, const void *unsafe_addr,\n\t\tlong count);\n\nlong strncpy_from_user_nofault(char *dst, const void __user *unsafe_addr,\n\t\tlong count);\nlong strnlen_user_nofault(const void __user *unsafe_addr, long count);\n\n/**\n * get_kernel_nofault(): safely attempt to read from a location\n * @val: read into this variable\n * @ptr: address to read from\n *\n * Returns 0 on success, or -EFAULT.\n */\n#define get_kernel_nofault(val, ptr) ({\t\t\t\t\\\n\tconst typeof(val) *__gk_ptr = (ptr);\t\t\t\\\n\tcopy_from_kernel_nofault(&(val), __gk_ptr, sizeof(val));\\\n})\n\n#ifndef user_access_begin\n#define user_access_begin(ptr,len) access_ok(ptr, len)\n#define user_access_end() do { } while (0)\n#define unsafe_op_wrap(op, err) do { if (unlikely(op)) goto err; } while (0)\n#define unsafe_get_user(x,p,e) unsafe_op_wrap(__get_user(x,p),e)\n#define unsafe_put_user(x,p,e) unsafe_op_wrap(__put_user(x,p),e)\n#define unsafe_copy_to_user(d,s,l,e) unsafe_op_wrap(__copy_to_user(d,s,l),e)\nstatic inline unsigned long user_access_save(void) { return 0UL; }\nstatic inline void user_access_restore(unsigned long flags) { }\n#endif\n#ifndef user_write_access_begin\n#define user_write_access_begin user_access_begin\n#define user_write_access_end user_access_end\n#endif\n#ifndef user_read_access_begin\n#define user_read_access_begin user_access_begin\n#define user_read_access_end user_access_end\n#endif\n\n#ifdef CONFIG_HARDENED_USERCOPY\nvoid usercopy_warn(const char *name, const char *detail, bool to_user,\n\t\t   unsigned long offset, unsigned long len);\nvoid __noreturn usercopy_abort(const char *name, const char *detail,\n\t\t\t       bool to_user, unsigned long offset,\n\t\t\t       unsigned long len);\n#endif\n\n#endif\t\t/* __LINUX_UACCESS_H__ */\n"}, "7": {"id": 7, "path": "/src/include/linux/compiler.h", "content": "/* SPDX-License-Identifier: GPL-2.0 */\n#ifndef __LINUX_COMPILER_H\n#define __LINUX_COMPILER_H\n\n#include <linux/compiler_types.h>\n\n#ifndef __ASSEMBLY__\n\n#ifdef __KERNEL__\n\n/*\n * Note: DISABLE_BRANCH_PROFILING can be used by special lowlevel code\n * to disable branch tracing on a per file basis.\n */\n#if defined(CONFIG_TRACE_BRANCH_PROFILING) \\\n    && !defined(DISABLE_BRANCH_PROFILING) && !defined(__CHECKER__)\nvoid ftrace_likely_update(struct ftrace_likely_data *f, int val,\n\t\t\t  int expect, int is_constant);\n\n#define likely_notrace(x)\t__builtin_expect(!!(x), 1)\n#define unlikely_notrace(x)\t__builtin_expect(!!(x), 0)\n\n#define __branch_check__(x, expect, is_constant) ({\t\t\t\\\n\t\t\tlong ______r;\t\t\t\t\t\\\n\t\t\tstatic struct ftrace_likely_data\t\t\\\n\t\t\t\t__aligned(4)\t\t\t\t\\\n\t\t\t\t__section(\"_ftrace_annotated_branch\")\t\\\n\t\t\t\t______f = {\t\t\t\t\\\n\t\t\t\t.data.func = __func__,\t\t\t\\\n\t\t\t\t.data.file = __FILE__,\t\t\t\\\n\t\t\t\t.data.line = __LINE__,\t\t\t\\\n\t\t\t};\t\t\t\t\t\t\\\n\t\t\t______r = __builtin_expect(!!(x), expect);\t\\\n\t\t\tftrace_likely_update(&______f, ______r,\t\t\\\n\t\t\t\t\t     expect, is_constant);\t\\\n\t\t\t______r;\t\t\t\t\t\\\n\t\t})\n\n/*\n * Using __builtin_constant_p(x) to ignore cases where the return\n * value is always the same.  This idea is taken from a similar patch\n * written by Daniel Walker.\n */\n# ifndef likely\n#  define likely(x)\t(__branch_check__(x, 1, __builtin_constant_p(x)))\n# endif\n# ifndef unlikely\n#  define unlikely(x)\t(__branch_check__(x, 0, __builtin_constant_p(x)))\n# endif\n\n#ifdef CONFIG_PROFILE_ALL_BRANCHES\n/*\n * \"Define 'is'\", Bill Clinton\n * \"Define 'if'\", Steven Rostedt\n */\n#define if(cond, ...) if ( __trace_if_var( !!(cond , ## __VA_ARGS__) ) )\n\n#define __trace_if_var(cond) (__builtin_constant_p(cond) ? (cond) : __trace_if_value(cond))\n\n#define __trace_if_value(cond) ({\t\t\t\\\n\tstatic struct ftrace_branch_data\t\t\\\n\t\t__aligned(4)\t\t\t\t\\\n\t\t__section(\"_ftrace_branch\")\t\t\\\n\t\t__if_trace = {\t\t\t\t\\\n\t\t\t.func = __func__,\t\t\\\n\t\t\t.file = __FILE__,\t\t\\\n\t\t\t.line = __LINE__,\t\t\\\n\t\t};\t\t\t\t\t\\\n\t(cond) ?\t\t\t\t\t\\\n\t\t(__if_trace.miss_hit[1]++,1) :\t\t\\\n\t\t(__if_trace.miss_hit[0]++,0);\t\t\\\n})\n\n#endif /* CONFIG_PROFILE_ALL_BRANCHES */\n\n#else\n# define likely(x)\t__builtin_expect(!!(x), 1)\n# define unlikely(x)\t__builtin_expect(!!(x), 0)\n# define likely_notrace(x)\tlikely(x)\n# define unlikely_notrace(x)\tunlikely(x)\n#endif\n\n/* Optimization barrier */\n#ifndef barrier\n/* The \"volatile\" is due to gcc bugs */\n# define barrier() __asm__ __volatile__(\"\": : :\"memory\")\n#endif\n\n#ifndef barrier_data\n/*\n * This version is i.e. to prevent dead stores elimination on @ptr\n * where gcc and llvm may behave differently when otherwise using\n * normal barrier(): while gcc behavior gets along with a normal\n * barrier(), llvm needs an explicit input variable to be assumed\n * clobbered. The issue is as follows: while the inline asm might\n * access any memory it wants, the compiler could have fit all of\n * @ptr into memory registers instead, and since @ptr never escaped\n * from that, it proved that the inline asm wasn't touching any of\n * it. This version works well with both compilers, i.e. we're telling\n * the compiler that the inline asm absolutely may see the contents\n * of @ptr. See also: https://llvm.org/bugs/show_bug.cgi?id=15495\n */\n# define barrier_data(ptr) __asm__ __volatile__(\"\": :\"r\"(ptr) :\"memory\")\n#endif\n\n/* workaround for GCC PR82365 if needed */\n#ifndef barrier_before_unreachable\n# define barrier_before_unreachable() do { } while (0)\n#endif\n\n/* Unreachable code */\n#ifdef CONFIG_STACK_VALIDATION\n/*\n * These macros help objtool understand GCC code flow for unreachable code.\n * The __COUNTER__ based labels are a hack to make each instance of the macros\n * unique, to convince GCC not to merge duplicate inline asm statements.\n */\n#define annotate_reachable() ({\t\t\t\t\t\t\\\n\tasm volatile(\"%c0:\\n\\t\"\t\t\t\t\t\t\\\n\t\t     \".pushsection .discard.reachable\\n\\t\"\t\t\\\n\t\t     \".long %c0b - .\\n\\t\"\t\t\t\t\\\n\t\t     \".popsection\\n\\t\" : : \"i\" (__COUNTER__));\t\t\\\n})\n#define annotate_unreachable() ({\t\t\t\t\t\\\n\tasm volatile(\"%c0:\\n\\t\"\t\t\t\t\t\t\\\n\t\t     \".pushsection .discard.unreachable\\n\\t\"\t\t\\\n\t\t     \".long %c0b - .\\n\\t\"\t\t\t\t\\\n\t\t     \".popsection\\n\\t\" : : \"i\" (__COUNTER__));\t\t\\\n})\n#define ASM_UNREACHABLE\t\t\t\t\t\t\t\\\n\t\"999:\\n\\t\"\t\t\t\t\t\t\t\\\n\t\".pushsection .discard.unreachable\\n\\t\"\t\t\t\t\\\n\t\".long 999b - .\\n\\t\"\t\t\t\t\t\t\\\n\t\".popsection\\n\\t\"\n\n/* Annotate a C jump table to allow objtool to follow the code flow */\n#define __annotate_jump_table __section(\".rodata..c_jump_table\")\n\n#else\n#define annotate_reachable()\n#define annotate_unreachable()\n#define __annotate_jump_table\n#endif\n\n#ifndef ASM_UNREACHABLE\n# define ASM_UNREACHABLE\n#endif\n#ifndef unreachable\n# define unreachable() do {\t\t\\\n\tannotate_unreachable();\t\t\\\n\t__builtin_unreachable();\t\\\n} while (0)\n#endif\n\n/*\n * KENTRY - kernel entry point\n * This can be used to annotate symbols (functions or data) that are used\n * without their linker symbol being referenced explicitly. For example,\n * interrupt vector handlers, or functions in the kernel image that are found\n * programatically.\n *\n * Not required for symbols exported with EXPORT_SYMBOL, or initcalls. Those\n * are handled in their own way (with KEEP() in linker scripts).\n *\n * KENTRY can be avoided if the symbols in question are marked as KEEP() in the\n * linker script. For example an architecture could KEEP() its entire\n * boot/exception vector code rather than annotate each function and data.\n */\n#ifndef KENTRY\n# define KENTRY(sym)\t\t\t\t\t\t\\\n\textern typeof(sym) sym;\t\t\t\t\t\\\n\tstatic const unsigned long __kentry_##sym\t\t\\\n\t__used\t\t\t\t\t\t\t\\\n\t__attribute__((__section__(\"___kentry+\" #sym)))\t\t\\\n\t= (unsigned long)&sym;\n#endif\n\n#ifndef RELOC_HIDE\n# define RELOC_HIDE(ptr, off)\t\t\t\t\t\\\n  ({ unsigned long __ptr;\t\t\t\t\t\\\n     __ptr = (unsigned long) (ptr);\t\t\t\t\\\n    (typeof(ptr)) (__ptr + (off)); })\n#endif\n\n#ifndef OPTIMIZER_HIDE_VAR\n/* Make the optimizer believe the variable can be manipulated arbitrarily. */\n#define OPTIMIZER_HIDE_VAR(var)\t\t\t\t\t\t\\\n\t__asm__ (\"\" : \"=r\" (var) : \"0\" (var))\n#endif\n\n/* Not-quite-unique ID. */\n#ifndef __UNIQUE_ID\n# define __UNIQUE_ID(prefix) __PASTE(__PASTE(__UNIQUE_ID_, prefix), __LINE__)\n#endif\n\n/**\n * data_race - mark an expression as containing intentional data races\n *\n * This data_race() macro is useful for situations in which data races\n * should be forgiven.  One example is diagnostic code that accesses\n * shared variables but is not a part of the core synchronization design.\n *\n * This macro *does not* affect normal code generation, but is a hint\n * to tooling that data races here are to be ignored.\n */\n#define data_race(expr)\t\t\t\t\t\t\t\\\n({\t\t\t\t\t\t\t\t\t\\\n\t__unqual_scalar_typeof(({ expr; })) __v = ({\t\t\t\\\n\t\t__kcsan_disable_current();\t\t\t\t\\\n\t\texpr;\t\t\t\t\t\t\t\\\n\t});\t\t\t\t\t\t\t\t\\\n\t__kcsan_enable_current();\t\t\t\t\t\\\n\t__v;\t\t\t\t\t\t\t\t\\\n})\n\n#endif /* __KERNEL__ */\n\n/*\n * Force the compiler to emit 'sym' as a symbol, so that we can reference\n * it from inline assembler. Necessary in case 'sym' could be inlined\n * otherwise, or eliminated entirely due to lack of references that are\n * visible to the compiler.\n */\n#define __ADDRESSABLE(sym) \\\n\tstatic void * __section(\".discard.addressable\") __used \\\n\t\t__UNIQUE_ID(__PASTE(__addressable_,sym)) = (void *)&sym;\n\n/**\n * offset_to_ptr - convert a relative memory offset to an absolute pointer\n * @off:\tthe address of the 32-bit offset value\n */\nstatic inline void *offset_to_ptr(const int *off)\n{\n\treturn (void *)((unsigned long)off + *off);\n}\n\n#endif /* __ASSEMBLY__ */\n\n/* &a[0] degrades to a pointer: a different type from an array */\n#define __must_be_array(a)\tBUILD_BUG_ON_ZERO(__same_type((a), &(a)[0]))\n\n/*\n * This is needed in functions which generate the stack canary, see\n * arch/x86/kernel/smpboot.c::start_secondary() for an example.\n */\n#define prevent_tail_call_optimization()\tmb()\n\n#include <asm/rwonce.h>\n\n#endif /* __LINUX_COMPILER_H */\n"}, "8": {"id": 8, "path": "/src/arch/x86/include/asm/uaccess.h", "content": "/* SPDX-License-Identifier: GPL-2.0 */\n#ifndef _ASM_X86_UACCESS_H\n#define _ASM_X86_UACCESS_H\n/*\n * User space memory access functions\n */\n#include <linux/compiler.h>\n#include <linux/kasan-checks.h>\n#include <linux/string.h>\n#include <asm/asm.h>\n#include <asm/page.h>\n#include <asm/smap.h>\n#include <asm/extable.h>\n\n/*\n * Test whether a block of memory is a valid user space address.\n * Returns 0 if the range is valid, nonzero otherwise.\n */\nstatic inline bool __chk_range_not_ok(unsigned long addr, unsigned long size, unsigned long limit)\n{\n\t/*\n\t * If we have used \"sizeof()\" for the size,\n\t * we know it won't overflow the limit (but\n\t * it might overflow the 'addr', so it's\n\t * important to subtract the size from the\n\t * limit, not add it to the address).\n\t */\n\tif (__builtin_constant_p(size))\n\t\treturn unlikely(addr > limit - size);\n\n\t/* Arbitrary sizes? Be careful about overflow */\n\taddr += size;\n\tif (unlikely(addr < size))\n\t\treturn true;\n\treturn unlikely(addr > limit);\n}\n\n#define __range_not_ok(addr, size, limit)\t\t\t\t\\\n({\t\t\t\t\t\t\t\t\t\\\n\t__chk_user_ptr(addr);\t\t\t\t\t\t\\\n\t__chk_range_not_ok((unsigned long __force)(addr), size, limit); \\\n})\n\n#ifdef CONFIG_DEBUG_ATOMIC_SLEEP\nstatic inline bool pagefault_disabled(void);\n# define WARN_ON_IN_IRQ()\t\\\n\tWARN_ON_ONCE(!in_task() && !pagefault_disabled())\n#else\n# define WARN_ON_IN_IRQ()\n#endif\n\n/**\n * access_ok - Checks if a user space pointer is valid\n * @addr: User space pointer to start of block to check\n * @size: Size of block to check\n *\n * Context: User context only. This function may sleep if pagefaults are\n *          enabled.\n *\n * Checks if a pointer to a block of memory in user space is valid.\n *\n * Note that, depending on architecture, this function probably just\n * checks that the pointer is in the user space range - after calling\n * this function, memory access functions may still return -EFAULT.\n *\n * Return: true (nonzero) if the memory block may be valid, false (zero)\n * if it is definitely invalid.\n */\n#define access_ok(addr, size)\t\t\t\t\t\\\n({\t\t\t\t\t\t\t\t\t\\\n\tWARN_ON_IN_IRQ();\t\t\t\t\t\t\\\n\tlikely(!__range_not_ok(addr, size, TASK_SIZE_MAX));\t\t\\\n})\n\nextern int __get_user_1(void);\nextern int __get_user_2(void);\nextern int __get_user_4(void);\nextern int __get_user_8(void);\nextern int __get_user_nocheck_1(void);\nextern int __get_user_nocheck_2(void);\nextern int __get_user_nocheck_4(void);\nextern int __get_user_nocheck_8(void);\nextern int __get_user_bad(void);\n\n#define __uaccess_begin() stac()\n#define __uaccess_end()   clac()\n#define __uaccess_begin_nospec()\t\\\n({\t\t\t\t\t\\\n\tstac();\t\t\t\t\\\n\tbarrier_nospec();\t\t\\\n})\n\n/*\n * This is the smallest unsigned integer type that can fit a value\n * (up to 'long long')\n */\n#define __inttype(x) __typeof__(\t\t\\\n\t__typefits(x,char,\t\t\t\\\n\t  __typefits(x,short,\t\t\t\\\n\t    __typefits(x,int,\t\t\t\\\n\t      __typefits(x,long,0ULL)))))\n\n#define __typefits(x,type,not) \\\n\t__builtin_choose_expr(sizeof(x)<=sizeof(type),(unsigned type)0,not)\n\n/*\n * This is used for both get_user() and __get_user() to expand to\n * the proper special function call that has odd calling conventions\n * due to returning both a value and an error, and that depends on\n * the size of the pointer passed in.\n *\n * Careful: we have to cast the result to the type of the pointer\n * for sign reasons.\n *\n * The use of _ASM_DX as the register specifier is a bit of a\n * simplification, as gcc only cares about it as the starting point\n * and not size: for a 64-bit value it will use %ecx:%edx on 32 bits\n * (%ecx being the next register in gcc's x86 register sequence), and\n * %rdx on 64 bits.\n *\n * Clang/LLVM cares about the size of the register, but still wants\n * the base register for something that ends up being a pair.\n */\n#define do_get_user_call(fn,x,ptr)\t\t\t\t\t\\\n({\t\t\t\t\t\t\t\t\t\\\n\tint __ret_gu;\t\t\t\t\t\t\t\\\n\tregister __inttype(*(ptr)) __val_gu asm(\"%\"_ASM_DX);\t\t\\\n\t__chk_user_ptr(ptr);\t\t\t\t\t\t\\\n\tasm volatile(\"call __\" #fn \"_%P4\"\t\t\t\t\\\n\t\t     : \"=a\" (__ret_gu), \"=r\" (__val_gu),\t\t\\\n\t\t\tASM_CALL_CONSTRAINT\t\t\t\t\\\n\t\t     : \"0\" (ptr), \"i\" (sizeof(*(ptr))));\t\t\\\n\t(x) = (__force __typeof__(*(ptr))) __val_gu;\t\t\t\\\n\t__builtin_expect(__ret_gu, 0);\t\t\t\t\t\\\n})\n\n/**\n * get_user - Get a simple variable from user space.\n * @x:   Variable to store result.\n * @ptr: Source address, in user space.\n *\n * Context: User context only. This function may sleep if pagefaults are\n *          enabled.\n *\n * This macro copies a single simple variable from user space to kernel\n * space.  It supports simple types like char and int, but not larger\n * data types like structures or arrays.\n *\n * @ptr must have pointer-to-simple-variable type, and the result of\n * dereferencing @ptr must be assignable to @x without a cast.\n *\n * Return: zero on success, or -EFAULT on error.\n * On error, the variable @x is set to zero.\n */\n#define get_user(x,ptr) ({ might_fault(); do_get_user_call(get_user,x,ptr); })\n\n/**\n * __get_user - Get a simple variable from user space, with less checking.\n * @x:   Variable to store result.\n * @ptr: Source address, in user space.\n *\n * Context: User context only. This function may sleep if pagefaults are\n *          enabled.\n *\n * This macro copies a single simple variable from user space to kernel\n * space.  It supports simple types like char and int, but not larger\n * data types like structures or arrays.\n *\n * @ptr must have pointer-to-simple-variable type, and the result of\n * dereferencing @ptr must be assignable to @x without a cast.\n *\n * Caller must check the pointer with access_ok() before calling this\n * function.\n *\n * Return: zero on success, or -EFAULT on error.\n * On error, the variable @x is set to zero.\n */\n#define __get_user(x,ptr) do_get_user_call(get_user_nocheck,x,ptr)\n\n\n#ifdef CONFIG_X86_32\n#define __put_user_goto_u64(x, addr, label)\t\t\t\\\n\tasm_volatile_goto(\"\\n\"\t\t\t\t\t\\\n\t\t     \"1:\tmovl %%eax,0(%1)\\n\"\t\t\\\n\t\t     \"2:\tmovl %%edx,4(%1)\\n\"\t\t\\\n\t\t     _ASM_EXTABLE_UA(1b, %l2)\t\t\t\\\n\t\t     _ASM_EXTABLE_UA(2b, %l2)\t\t\t\\\n\t\t     : : \"A\" (x), \"r\" (addr)\t\t\t\\\n\t\t     : : label)\n\n#else\n#define __put_user_goto_u64(x, ptr, label) \\\n\t__put_user_goto(x, ptr, \"q\", \"er\", label)\n#endif\n\nextern void __put_user_bad(void);\n\n/*\n * Strange magic calling convention: pointer in %ecx,\n * value in %eax(:%edx), return value in %ecx. clobbers %rbx\n */\nextern void __put_user_1(void);\nextern void __put_user_2(void);\nextern void __put_user_4(void);\nextern void __put_user_8(void);\nextern void __put_user_nocheck_1(void);\nextern void __put_user_nocheck_2(void);\nextern void __put_user_nocheck_4(void);\nextern void __put_user_nocheck_8(void);\n\n/*\n * ptr must be evaluated and assigned to the temporary __ptr_pu before\n * the assignment of x to __val_pu, to avoid any function calls\n * involved in the ptr expression (possibly implicitly generated due\n * to KASAN) from clobbering %ax.\n */\n#define do_put_user_call(fn,x,ptr)\t\t\t\t\t\\\n({\t\t\t\t\t\t\t\t\t\\\n\tint __ret_pu;\t\t\t\t\t\t\t\\\n\tvoid __user *__ptr_pu;\t\t\t\t\t\t\\\n\tregister __typeof__(*(ptr)) __val_pu asm(\"%\"_ASM_AX);\t\t\\\n\t__chk_user_ptr(ptr);\t\t\t\t\t\t\\\n\t__ptr_pu = (ptr);\t\t\t\t\t\t\\\n\t__val_pu = (x);\t\t\t\t\t\t\t\\\n\tasm volatile(\"call __\" #fn \"_%P[size]\"\t\t\t\t\\\n\t\t     : \"=c\" (__ret_pu),\t\t\t\t\t\\\n\t\t\tASM_CALL_CONSTRAINT\t\t\t\t\\\n\t\t     : \"0\" (__ptr_pu),\t\t\t\t\t\\\n\t\t       \"r\" (__val_pu),\t\t\t\t\t\\\n\t\t       [size] \"i\" (sizeof(*(ptr)))\t\t\t\\\n\t\t     :\"ebx\");\t\t\t\t\t\t\\\n\t__builtin_expect(__ret_pu, 0);\t\t\t\t\t\\\n})\n\n/**\n * put_user - Write a simple value into user space.\n * @x:   Value to copy to user space.\n * @ptr: Destination address, in user space.\n *\n * Context: User context only. This function may sleep if pagefaults are\n *          enabled.\n *\n * This macro copies a single simple value from kernel space to user\n * space.  It supports simple types like char and int, but not larger\n * data types like structures or arrays.\n *\n * @ptr must have pointer-to-simple-variable type, and @x must be assignable\n * to the result of dereferencing @ptr.\n *\n * Return: zero on success, or -EFAULT on error.\n */\n#define put_user(x, ptr) ({ might_fault(); do_put_user_call(put_user,x,ptr); })\n\n/**\n * __put_user - Write a simple value into user space, with less checking.\n * @x:   Value to copy to user space.\n * @ptr: Destination address, in user space.\n *\n * Context: User context only. This function may sleep if pagefaults are\n *          enabled.\n *\n * This macro copies a single simple value from kernel space to user\n * space.  It supports simple types like char and int, but not larger\n * data types like structures or arrays.\n *\n * @ptr must have pointer-to-simple-variable type, and @x must be assignable\n * to the result of dereferencing @ptr.\n *\n * Caller must check the pointer with access_ok() before calling this\n * function.\n *\n * Return: zero on success, or -EFAULT on error.\n */\n#define __put_user(x, ptr) do_put_user_call(put_user_nocheck,x,ptr)\n\n#define __put_user_size(x, ptr, size, label)\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\t__chk_user_ptr(ptr);\t\t\t\t\t\t\\\n\tswitch (size) {\t\t\t\t\t\t\t\\\n\tcase 1:\t\t\t\t\t\t\t\t\\\n\t\t__put_user_goto(x, ptr, \"b\", \"iq\", label);\t\t\\\n\t\tbreak;\t\t\t\t\t\t\t\\\n\tcase 2:\t\t\t\t\t\t\t\t\\\n\t\t__put_user_goto(x, ptr, \"w\", \"ir\", label);\t\t\\\n\t\tbreak;\t\t\t\t\t\t\t\\\n\tcase 4:\t\t\t\t\t\t\t\t\\\n\t\t__put_user_goto(x, ptr, \"l\", \"ir\", label);\t\t\\\n\t\tbreak;\t\t\t\t\t\t\t\\\n\tcase 8:\t\t\t\t\t\t\t\t\\\n\t\t__put_user_goto_u64(x, ptr, label);\t\t\t\\\n\t\tbreak;\t\t\t\t\t\t\t\\\n\tdefault:\t\t\t\t\t\t\t\\\n\t\t__put_user_bad();\t\t\t\t\t\\\n\t}\t\t\t\t\t\t\t\t\\\n} while (0)\n\n#ifdef CONFIG_CC_HAS_ASM_GOTO_OUTPUT\n\n#ifdef CONFIG_X86_32\n#define __get_user_asm_u64(x, ptr, label) do {\t\t\t\t\\\n\tunsigned int __gu_low, __gu_high;\t\t\t\t\\\n\tconst unsigned int __user *__gu_ptr;\t\t\t\t\\\n\t__gu_ptr = (const void __user *)(ptr);\t\t\t\t\\\n\t__get_user_asm(__gu_low, ptr, \"l\", \"=r\", label);\t\t\\\n\t__get_user_asm(__gu_high, ptr+1, \"l\", \"=r\", label);\t\t\\\n\t(x) = ((unsigned long long)__gu_high << 32) | __gu_low;\t\t\\\n} while (0)\n#else\n#define __get_user_asm_u64(x, ptr, label)\t\t\t\t\\\n\t__get_user_asm(x, ptr, \"q\", \"=r\", label)\n#endif\n\n#define __get_user_size(x, ptr, size, label)\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\t__chk_user_ptr(ptr);\t\t\t\t\t\t\\\n\tswitch (size) {\t\t\t\t\t\t\t\\\n\tunsigned char x_u8__;\t\t\t\t\t\t\\\n\tcase 1:\t\t\t\t\t\t\t\t\\\n\t\t__get_user_asm(x_u8__, ptr, \"b\", \"=q\", label);\t\t\\\n\t\t(x) = x_u8__;\t\t\t\t\t\t\\\n\t\tbreak;\t\t\t\t\t\t\t\\\n\tcase 2:\t\t\t\t\t\t\t\t\\\n\t\t__get_user_asm(x, ptr, \"w\", \"=r\", label);\t\t\\\n\t\tbreak;\t\t\t\t\t\t\t\\\n\tcase 4:\t\t\t\t\t\t\t\t\\\n\t\t__get_user_asm(x, ptr, \"l\", \"=r\", label);\t\t\\\n\t\tbreak;\t\t\t\t\t\t\t\\\n\tcase 8:\t\t\t\t\t\t\t\t\\\n\t\t__get_user_asm_u64(x, ptr, label);\t\t\t\\\n\t\tbreak;\t\t\t\t\t\t\t\\\n\tdefault:\t\t\t\t\t\t\t\\\n\t\t(x) = __get_user_bad();\t\t\t\t\t\\\n\t}\t\t\t\t\t\t\t\t\\\n} while (0)\n\n#define __get_user_asm(x, addr, itype, ltype, label)\t\t\t\\\n\tasm_volatile_goto(\"\\n\"\t\t\t\t\t\t\\\n\t\t     \"1:\tmov\"itype\" %[umem],%[output]\\n\"\t\t\\\n\t\t     _ASM_EXTABLE_UA(1b, %l2)\t\t\t\t\\\n\t\t     : [output] ltype(x)\t\t\t\t\\\n\t\t     : [umem] \"m\" (__m(addr))\t\t\t\t\\\n\t\t     : : label)\n\n#else // !CONFIG_CC_HAS_ASM_GOTO_OUTPUT\n\n#ifdef CONFIG_X86_32\n#define __get_user_asm_u64(x, ptr, retval)\t\t\t\t\\\n({\t\t\t\t\t\t\t\t\t\\\n\t__typeof__(ptr) __ptr = (ptr);\t\t\t\t\t\\\n\tasm volatile(\"\\n\"\t\t\t\t\t\t\\\n\t\t     \"1:\tmovl %[lowbits],%%eax\\n\"\t\t\\\n\t\t     \"2:\tmovl %[highbits],%%edx\\n\"\t\t\\\n\t\t     \"3:\\n\"\t\t\t\t\t\t\\\n\t\t     \".section .fixup,\\\"ax\\\"\\n\"\t\t\t\t\\\n\t\t     \"4:\tmov %[efault],%[errout]\\n\"\t\t\\\n\t\t     \"\txorl %%eax,%%eax\\n\"\t\t\t\t\\\n\t\t     \"\txorl %%edx,%%edx\\n\"\t\t\t\t\\\n\t\t     \"\tjmp 3b\\n\"\t\t\t\t\t\\\n\t\t     \".previous\\n\"\t\t\t\t\t\\\n\t\t     _ASM_EXTABLE_UA(1b, 4b)\t\t\t\t\\\n\t\t     _ASM_EXTABLE_UA(2b, 4b)\t\t\t\t\\\n\t\t     : [errout] \"=r\" (retval),\t\t\t\t\\\n\t\t       [output] \"=&A\"(x)\t\t\t\t\\\n\t\t     : [lowbits] \"m\" (__m(__ptr)),\t\t\t\\\n\t\t       [highbits] \"m\" __m(((u32 __user *)(__ptr)) + 1),\t\\\n\t\t       [efault] \"i\" (-EFAULT), \"0\" (retval));\t\t\\\n})\n\n#else\n#define __get_user_asm_u64(x, ptr, retval) \\\n\t __get_user_asm(x, ptr, retval, \"q\", \"=r\")\n#endif\n\n#define __get_user_size(x, ptr, size, retval)\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tunsigned char x_u8__;\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tretval = 0;\t\t\t\t\t\t\t\\\n\t__chk_user_ptr(ptr);\t\t\t\t\t\t\\\n\tswitch (size) {\t\t\t\t\t\t\t\\\n\tcase 1:\t\t\t\t\t\t\t\t\\\n\t\t__get_user_asm(x_u8__, ptr, retval, \"b\", \"=q\");\t\t\\\n\t\t(x) = x_u8__;\t\t\t\t\t\t\\\n\t\tbreak;\t\t\t\t\t\t\t\\\n\tcase 2:\t\t\t\t\t\t\t\t\\\n\t\t__get_user_asm(x, ptr, retval, \"w\", \"=r\");\t\t\\\n\t\tbreak;\t\t\t\t\t\t\t\\\n\tcase 4:\t\t\t\t\t\t\t\t\\\n\t\t__get_user_asm(x, ptr, retval, \"l\", \"=r\");\t\t\\\n\t\tbreak;\t\t\t\t\t\t\t\\\n\tcase 8:\t\t\t\t\t\t\t\t\\\n\t\t__get_user_asm_u64(x, ptr, retval);\t\t\t\\\n\t\tbreak;\t\t\t\t\t\t\t\\\n\tdefault:\t\t\t\t\t\t\t\\\n\t\t(x) = __get_user_bad();\t\t\t\t\t\\\n\t}\t\t\t\t\t\t\t\t\\\n} while (0)\n\n#define __get_user_asm(x, addr, err, itype, ltype)\t\t\t\\\n\tasm volatile(\"\\n\"\t\t\t\t\t\t\\\n\t\t     \"1:\tmov\"itype\" %[umem],%[output]\\n\"\t\t\\\n\t\t     \"2:\\n\"\t\t\t\t\t\t\\\n\t\t     \".section .fixup,\\\"ax\\\"\\n\"\t\t\t\t\\\n\t\t     \"3:\tmov %[efault],%[errout]\\n\"\t\t\\\n\t\t     \"\txorl %k[output],%k[output]\\n\"\t\t\t\\\n\t\t     \"\tjmp 2b\\n\"\t\t\t\t\t\\\n\t\t     \".previous\\n\"\t\t\t\t\t\\\n\t\t     _ASM_EXTABLE_UA(1b, 3b)\t\t\t\t\\\n\t\t     : [errout] \"=r\" (err),\t\t\t\t\\\n\t\t       [output] ltype(x)\t\t\t\t\\\n\t\t     : [umem] \"m\" (__m(addr)),\t\t\t\t\\\n\t\t       [efault] \"i\" (-EFAULT), \"0\" (err))\n\n#endif // CONFIG_CC_ASM_GOTO_OUTPUT\n\n/* FIXME: this hack is definitely wrong -AK */\nstruct __large_struct { unsigned long buf[100]; };\n#define __m(x) (*(struct __large_struct __user *)(x))\n\n/*\n * Tell gcc we read from memory instead of writing: this is because\n * we do not write to any memory gcc knows about, so there are no\n * aliasing issues.\n */\n#define __put_user_goto(x, addr, itype, ltype, label)\t\t\t\\\n\tasm_volatile_goto(\"\\n\"\t\t\t\t\t\t\\\n\t\t\"1:\tmov\"itype\" %0,%1\\n\"\t\t\t\t\\\n\t\t_ASM_EXTABLE_UA(1b, %l2)\t\t\t\t\\\n\t\t: : ltype(x), \"m\" (__m(addr))\t\t\t\t\\\n\t\t: : label)\n\nextern unsigned long\ncopy_from_user_nmi(void *to, const void __user *from, unsigned long n);\nextern __must_check long\nstrncpy_from_user(char *dst, const char __user *src, long count);\n\nextern __must_check long strnlen_user(const char __user *str, long n);\n\nunsigned long __must_check clear_user(void __user *mem, unsigned long len);\nunsigned long __must_check __clear_user(void __user *mem, unsigned long len);\n\n#ifdef CONFIG_ARCH_HAS_COPY_MC\nunsigned long __must_check\ncopy_mc_to_kernel(void *to, const void *from, unsigned len);\n#define copy_mc_to_kernel copy_mc_to_kernel\n\nunsigned long __must_check\ncopy_mc_to_user(void *to, const void *from, unsigned len);\n#endif\n\n/*\n * movsl can be slow when source and dest are not both 8-byte aligned\n */\n#ifdef CONFIG_X86_INTEL_USERCOPY\nextern struct movsl_mask {\n\tint mask;\n} ____cacheline_aligned_in_smp movsl_mask;\n#endif\n\n#define ARCH_HAS_NOCACHE_UACCESS 1\n\n#ifdef CONFIG_X86_32\n# include <asm/uaccess_32.h>\n#else\n# include <asm/uaccess_64.h>\n#endif\n\n/*\n * The \"unsafe\" user accesses aren't really \"unsafe\", but the naming\n * is a big fat warning: you have to not only do the access_ok()\n * checking before using them, but you have to surround them with the\n * user_access_begin/end() pair.\n */\nstatic __must_check __always_inline bool user_access_begin(const void __user *ptr, size_t len)\n{\n\tif (unlikely(!access_ok(ptr,len)))\n\t\treturn 0;\n\t__uaccess_begin_nospec();\n\treturn 1;\n}\n#define user_access_begin(a,b)\tuser_access_begin(a,b)\n#define user_access_end()\t__uaccess_end()\n\n#define user_access_save()\tsmap_save()\n#define user_access_restore(x)\tsmap_restore(x)\n\n#define unsafe_put_user(x, ptr, label)\t\\\n\t__put_user_size((__typeof__(*(ptr)))(x), (ptr), sizeof(*(ptr)), label)\n\n#ifdef CONFIG_CC_HAS_ASM_GOTO_OUTPUT\n#define unsafe_get_user(x, ptr, err_label)\t\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\t\\\n\t__inttype(*(ptr)) __gu_val;\t\t\t\t\t\t\\\n\t__get_user_size(__gu_val, (ptr), sizeof(*(ptr)), err_label);\t\t\\\n\t(x) = (__force __typeof__(*(ptr)))__gu_val;\t\t\t\t\\\n} while (0)\n#else // !CONFIG_CC_HAS_ASM_GOTO_OUTPUT\n#define unsafe_get_user(x, ptr, err_label)\t\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\t\\\n\tint __gu_err;\t\t\t\t\t\t\t\t\\\n\t__inttype(*(ptr)) __gu_val;\t\t\t\t\t\t\\\n\t__get_user_size(__gu_val, (ptr), sizeof(*(ptr)), __gu_err);\t\t\\\n\t(x) = (__force __typeof__(*(ptr)))__gu_val;\t\t\t\t\\\n\tif (unlikely(__gu_err)) goto err_label;\t\t\t\t\t\\\n} while (0)\n#endif // CONFIG_CC_HAS_ASM_GOTO_OUTPUT\n\n/*\n * We want the unsafe accessors to always be inlined and use\n * the error labels - thus the macro games.\n */\n#define unsafe_copy_loop(dst, src, len, type, label)\t\t\t\t\\\n\twhile (len >= sizeof(type)) {\t\t\t\t\t\t\\\n\t\tunsafe_put_user(*(type *)(src),(type __user *)(dst),label);\t\\\n\t\tdst += sizeof(type);\t\t\t\t\t\t\\\n\t\tsrc += sizeof(type);\t\t\t\t\t\t\\\n\t\tlen -= sizeof(type);\t\t\t\t\t\t\\\n\t}\n\n#define unsafe_copy_to_user(_dst,_src,_len,label)\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tchar __user *__ucu_dst = (_dst);\t\t\t\t\\\n\tconst char *__ucu_src = (_src);\t\t\t\t\t\\\n\tsize_t __ucu_len = (_len);\t\t\t\t\t\\\n\tunsafe_copy_loop(__ucu_dst, __ucu_src, __ucu_len, u64, label);\t\\\n\tunsafe_copy_loop(__ucu_dst, __ucu_src, __ucu_len, u32, label);\t\\\n\tunsafe_copy_loop(__ucu_dst, __ucu_src, __ucu_len, u16, label);\t\\\n\tunsafe_copy_loop(__ucu_dst, __ucu_src, __ucu_len, u8, label);\t\\\n} while (0)\n\n#define HAVE_GET_KERNEL_NOFAULT\n\n#ifdef CONFIG_CC_HAS_ASM_GOTO_OUTPUT\n#define __get_kernel_nofault(dst, src, type, err_label)\t\t\t\\\n\t__get_user_size(*((type *)(dst)), (__force type __user *)(src),\t\\\n\t\t\tsizeof(type), err_label)\n#else // !CONFIG_CC_HAS_ASM_GOTO_OUTPUT\n#define __get_kernel_nofault(dst, src, type, err_label)\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tint __kr_err;\t\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\t__get_user_size(*((type *)(dst)), (__force type __user *)(src),\t\\\n\t\t\tsizeof(type), __kr_err);\t\t\t\\\n\tif (unlikely(__kr_err))\t\t\t\t\t\t\\\n\t\tgoto err_label;\t\t\t\t\t\t\\\n} while (0)\n#endif // CONFIG_CC_HAS_ASM_GOTO_OUTPUT\n\n#define __put_kernel_nofault(dst, src, type, err_label)\t\t\t\\\n\t__put_user_size(*((type *)(src)), (__force type __user *)(dst),\t\\\n\t\t\tsizeof(type), err_label)\n\n#endif /* _ASM_X86_UACCESS_H */\n\n"}, "9": {"id": 9, "path": "/src/include/linux/ratelimit_types.h", "content": "/* SPDX-License-Identifier: GPL-2.0 */\n#ifndef _LINUX_RATELIMIT_TYPES_H\n#define _LINUX_RATELIMIT_TYPES_H\n\n#include <linux/bits.h>\n#include <linux/param.h>\n#include <linux/spinlock_types.h>\n\n#define DEFAULT_RATELIMIT_INTERVAL\t(5 * HZ)\n#define DEFAULT_RATELIMIT_BURST\t\t10\n\n/* issue num suppressed message on exit */\n#define RATELIMIT_MSG_ON_RELEASE\tBIT(0)\n\nstruct ratelimit_state {\n\traw_spinlock_t\tlock;\t\t/* protect the state */\n\n\tint\t\tinterval;\n\tint\t\tburst;\n\tint\t\tprinted;\n\tint\t\tmissed;\n\tunsigned long\tbegin;\n\tunsigned long\tflags;\n};\n\n#define RATELIMIT_STATE_INIT(name, interval_init, burst_init) {\t\t\\\n\t\t.lock\t\t= __RAW_SPIN_LOCK_UNLOCKED(name.lock),\t\\\n\t\t.interval\t= interval_init,\t\t\t\\\n\t\t.burst\t\t= burst_init,\t\t\t\t\\\n\t}\n\n#define RATELIMIT_STATE_INIT_DISABLED\t\t\t\t\t\\\n\tRATELIMIT_STATE_INIT(ratelimit_state, 0, DEFAULT_RATELIMIT_BURST)\n\n#define DEFINE_RATELIMIT_STATE(name, interval_init, burst_init)\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tstruct ratelimit_state name =\t\t\t\t\t\\\n\t\tRATELIMIT_STATE_INIT(name, interval_init, burst_init)\t\\\n\nextern int ___ratelimit(struct ratelimit_state *rs, const char *func);\n#define __ratelimit(state) ___ratelimit(state, __func__)\n\n#endif /* _LINUX_RATELIMIT_TYPES_H */\n"}, "10": {"id": 10, "path": "/src/include/linux/kernel.h", "content": "/* SPDX-License-Identifier: GPL-2.0 */\n#ifndef _LINUX_KERNEL_H\n#define _LINUX_KERNEL_H\n\n#include <stdarg.h>\n#include <linux/limits.h>\n#include <linux/linkage.h>\n#include <linux/stddef.h>\n#include <linux/types.h>\n#include <linux/compiler.h>\n#include <linux/bitops.h>\n#include <linux/log2.h>\n#include <linux/math.h>\n#include <linux/minmax.h>\n#include <linux/typecheck.h>\n#include <linux/printk.h>\n#include <linux/build_bug.h>\n#include <linux/static_call_types.h>\n#include <asm/byteorder.h>\n\n#include <uapi/linux/kernel.h>\n\n#define STACK_MAGIC\t0xdeadbeef\n\n/**\n * REPEAT_BYTE - repeat the value @x multiple times as an unsigned long value\n * @x: value to repeat\n *\n * NOTE: @x is not checked for > 0xff; larger values produce odd results.\n */\n#define REPEAT_BYTE(x)\t((~0ul / 0xff) * (x))\n\n/* @a is a power of 2 value */\n#define ALIGN(x, a)\t\t__ALIGN_KERNEL((x), (a))\n#define ALIGN_DOWN(x, a)\t__ALIGN_KERNEL((x) - ((a) - 1), (a))\n#define __ALIGN_MASK(x, mask)\t__ALIGN_KERNEL_MASK((x), (mask))\n#define PTR_ALIGN(p, a)\t\t((typeof(p))ALIGN((unsigned long)(p), (a)))\n#define PTR_ALIGN_DOWN(p, a)\t((typeof(p))ALIGN_DOWN((unsigned long)(p), (a)))\n#define IS_ALIGNED(x, a)\t\t(((x) & ((typeof(x))(a) - 1)) == 0)\n\n/* generic data direction definitions */\n#define READ\t\t\t0\n#define WRITE\t\t\t1\n\n/**\n * ARRAY_SIZE - get the number of elements in array @arr\n * @arr: array to be sized\n */\n#define ARRAY_SIZE(arr) (sizeof(arr) / sizeof((arr)[0]) + __must_be_array(arr))\n\n#define u64_to_user_ptr(x) (\t\t\\\n{\t\t\t\t\t\\\n\ttypecheck(u64, (x));\t\t\\\n\t(void __user *)(uintptr_t)(x);\t\\\n}\t\t\t\t\t\\\n)\n\n#define typeof_member(T, m)\ttypeof(((T*)0)->m)\n\n#define _RET_IP_\t\t(unsigned long)__builtin_return_address(0)\n#define _THIS_IP_  ({ __label__ __here; __here: (unsigned long)&&__here; })\n\n/**\n * upper_32_bits - return bits 32-63 of a number\n * @n: the number we're accessing\n *\n * A basic shift-right of a 64- or 32-bit quantity.  Use this to suppress\n * the \"right shift count >= width of type\" warning when that quantity is\n * 32-bits.\n */\n#define upper_32_bits(n) ((u32)(((n) >> 16) >> 16))\n\n/**\n * lower_32_bits - return bits 0-31 of a number\n * @n: the number we're accessing\n */\n#define lower_32_bits(n) ((u32)((n) & 0xffffffff))\n\nstruct completion;\nstruct pt_regs;\nstruct user;\n\n#ifdef CONFIG_PREEMPT_VOLUNTARY\n\nextern int __cond_resched(void);\n# define might_resched() __cond_resched()\n\n#elif defined(CONFIG_PREEMPT_DYNAMIC)\n\nextern int __cond_resched(void);\n\nDECLARE_STATIC_CALL(might_resched, __cond_resched);\n\nstatic __always_inline void might_resched(void)\n{\n\tstatic_call_mod(might_resched)();\n}\n\n#else\n\n# define might_resched() do { } while (0)\n\n#endif /* CONFIG_PREEMPT_* */\n\n#ifdef CONFIG_DEBUG_ATOMIC_SLEEP\nextern void ___might_sleep(const char *file, int line, int preempt_offset);\nextern void __might_sleep(const char *file, int line, int preempt_offset);\nextern void __cant_sleep(const char *file, int line, int preempt_offset);\nextern void __cant_migrate(const char *file, int line);\n\n/**\n * might_sleep - annotation for functions that can sleep\n *\n * this macro will print a stack trace if it is executed in an atomic\n * context (spinlock, irq-handler, ...). Additional sections where blocking is\n * not allowed can be annotated with non_block_start() and non_block_end()\n * pairs.\n *\n * This is a useful debugging help to be able to catch problems early and not\n * be bitten later when the calling function happens to sleep when it is not\n * supposed to.\n */\n# define might_sleep() \\\n\tdo { __might_sleep(__FILE__, __LINE__, 0); might_resched(); } while (0)\n/**\n * cant_sleep - annotation for functions that cannot sleep\n *\n * this macro will print a stack trace if it is executed with preemption enabled\n */\n# define cant_sleep() \\\n\tdo { __cant_sleep(__FILE__, __LINE__, 0); } while (0)\n# define sched_annotate_sleep()\t(current->task_state_change = 0)\n\n/**\n * cant_migrate - annotation for functions that cannot migrate\n *\n * Will print a stack trace if executed in code which is migratable\n */\n# define cant_migrate()\t\t\t\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tif (IS_ENABLED(CONFIG_SMP))\t\t\t\t\\\n\t\t\t__cant_migrate(__FILE__, __LINE__);\t\t\\\n\t} while (0)\n\n/**\n * non_block_start - annotate the start of section where sleeping is prohibited\n *\n * This is on behalf of the oom reaper, specifically when it is calling the mmu\n * notifiers. The problem is that if the notifier were to block on, for example,\n * mutex_lock() and if the process which holds that mutex were to perform a\n * sleeping memory allocation, the oom reaper is now blocked on completion of\n * that memory allocation. Other blocking calls like wait_event() pose similar\n * issues.\n */\n# define non_block_start() (current->non_block_count++)\n/**\n * non_block_end - annotate the end of section where sleeping is prohibited\n *\n * Closes a section opened by non_block_start().\n */\n# define non_block_end() WARN_ON(current->non_block_count-- == 0)\n#else\n  static inline void ___might_sleep(const char *file, int line,\n\t\t\t\t   int preempt_offset) { }\n  static inline void __might_sleep(const char *file, int line,\n\t\t\t\t   int preempt_offset) { }\n# define might_sleep() do { might_resched(); } while (0)\n# define cant_sleep() do { } while (0)\n# define cant_migrate()\t\tdo { } while (0)\n# define sched_annotate_sleep() do { } while (0)\n# define non_block_start() do { } while (0)\n# define non_block_end() do { } while (0)\n#endif\n\n#define might_sleep_if(cond) do { if (cond) might_sleep(); } while (0)\n\n#if defined(CONFIG_MMU) && \\\n\t(defined(CONFIG_PROVE_LOCKING) || defined(CONFIG_DEBUG_ATOMIC_SLEEP))\n#define might_fault() __might_fault(__FILE__, __LINE__)\nvoid __might_fault(const char *file, int line);\n#else\nstatic inline void might_fault(void) { }\n#endif\n\nextern struct atomic_notifier_head panic_notifier_list;\nextern long (*panic_blink)(int state);\n__printf(1, 2)\nvoid panic(const char *fmt, ...) __noreturn __cold;\nvoid nmi_panic(struct pt_regs *regs, const char *msg);\nextern void oops_enter(void);\nextern void oops_exit(void);\nextern bool oops_may_print(void);\nvoid do_exit(long error_code) __noreturn;\nvoid complete_and_exit(struct completion *, long) __noreturn;\n\n/* Internal, do not use. */\nint __must_check _kstrtoul(const char *s, unsigned int base, unsigned long *res);\nint __must_check _kstrtol(const char *s, unsigned int base, long *res);\n\nint __must_check kstrtoull(const char *s, unsigned int base, unsigned long long *res);\nint __must_check kstrtoll(const char *s, unsigned int base, long long *res);\n\n/**\n * kstrtoul - convert a string to an unsigned long\n * @s: The start of the string. The string must be null-terminated, and may also\n *  include a single newline before its terminating null. The first character\n *  may also be a plus sign, but not a minus sign.\n * @base: The number base to use. The maximum supported base is 16. If base is\n *  given as 0, then the base of the string is automatically detected with the\n *  conventional semantics - If it begins with 0x the number will be parsed as a\n *  hexadecimal (case insensitive), if it otherwise begins with 0, it will be\n *  parsed as an octal number. Otherwise it will be parsed as a decimal.\n * @res: Where to write the result of the conversion on success.\n *\n * Returns 0 on success, -ERANGE on overflow and -EINVAL on parsing error.\n * Preferred over simple_strtoul(). Return code must be checked.\n*/\nstatic inline int __must_check kstrtoul(const char *s, unsigned int base, unsigned long *res)\n{\n\t/*\n\t * We want to shortcut function call, but\n\t * __builtin_types_compatible_p(unsigned long, unsigned long long) = 0.\n\t */\n\tif (sizeof(unsigned long) == sizeof(unsigned long long) &&\n\t    __alignof__(unsigned long) == __alignof__(unsigned long long))\n\t\treturn kstrtoull(s, base, (unsigned long long *)res);\n\telse\n\t\treturn _kstrtoul(s, base, res);\n}\n\n/**\n * kstrtol - convert a string to a long\n * @s: The start of the string. The string must be null-terminated, and may also\n *  include a single newline before its terminating null. The first character\n *  may also be a plus sign or a minus sign.\n * @base: The number base to use. The maximum supported base is 16. If base is\n *  given as 0, then the base of the string is automatically detected with the\n *  conventional semantics - If it begins with 0x the number will be parsed as a\n *  hexadecimal (case insensitive), if it otherwise begins with 0, it will be\n *  parsed as an octal number. Otherwise it will be parsed as a decimal.\n * @res: Where to write the result of the conversion on success.\n *\n * Returns 0 on success, -ERANGE on overflow and -EINVAL on parsing error.\n * Preferred over simple_strtol(). Return code must be checked.\n */\nstatic inline int __must_check kstrtol(const char *s, unsigned int base, long *res)\n{\n\t/*\n\t * We want to shortcut function call, but\n\t * __builtin_types_compatible_p(long, long long) = 0.\n\t */\n\tif (sizeof(long) == sizeof(long long) &&\n\t    __alignof__(long) == __alignof__(long long))\n\t\treturn kstrtoll(s, base, (long long *)res);\n\telse\n\t\treturn _kstrtol(s, base, res);\n}\n\nint __must_check kstrtouint(const char *s, unsigned int base, unsigned int *res);\nint __must_check kstrtoint(const char *s, unsigned int base, int *res);\n\nstatic inline int __must_check kstrtou64(const char *s, unsigned int base, u64 *res)\n{\n\treturn kstrtoull(s, base, res);\n}\n\nstatic inline int __must_check kstrtos64(const char *s, unsigned int base, s64 *res)\n{\n\treturn kstrtoll(s, base, res);\n}\n\nstatic inline int __must_check kstrtou32(const char *s, unsigned int base, u32 *res)\n{\n\treturn kstrtouint(s, base, res);\n}\n\nstatic inline int __must_check kstrtos32(const char *s, unsigned int base, s32 *res)\n{\n\treturn kstrtoint(s, base, res);\n}\n\nint __must_check kstrtou16(const char *s, unsigned int base, u16 *res);\nint __must_check kstrtos16(const char *s, unsigned int base, s16 *res);\nint __must_check kstrtou8(const char *s, unsigned int base, u8 *res);\nint __must_check kstrtos8(const char *s, unsigned int base, s8 *res);\nint __must_check kstrtobool(const char *s, bool *res);\n\nint __must_check kstrtoull_from_user(const char __user *s, size_t count, unsigned int base, unsigned long long *res);\nint __must_check kstrtoll_from_user(const char __user *s, size_t count, unsigned int base, long long *res);\nint __must_check kstrtoul_from_user(const char __user *s, size_t count, unsigned int base, unsigned long *res);\nint __must_check kstrtol_from_user(const char __user *s, size_t count, unsigned int base, long *res);\nint __must_check kstrtouint_from_user(const char __user *s, size_t count, unsigned int base, unsigned int *res);\nint __must_check kstrtoint_from_user(const char __user *s, size_t count, unsigned int base, int *res);\nint __must_check kstrtou16_from_user(const char __user *s, size_t count, unsigned int base, u16 *res);\nint __must_check kstrtos16_from_user(const char __user *s, size_t count, unsigned int base, s16 *res);\nint __must_check kstrtou8_from_user(const char __user *s, size_t count, unsigned int base, u8 *res);\nint __must_check kstrtos8_from_user(const char __user *s, size_t count, unsigned int base, s8 *res);\nint __must_check kstrtobool_from_user(const char __user *s, size_t count, bool *res);\n\nstatic inline int __must_check kstrtou64_from_user(const char __user *s, size_t count, unsigned int base, u64 *res)\n{\n\treturn kstrtoull_from_user(s, count, base, res);\n}\n\nstatic inline int __must_check kstrtos64_from_user(const char __user *s, size_t count, unsigned int base, s64 *res)\n{\n\treturn kstrtoll_from_user(s, count, base, res);\n}\n\nstatic inline int __must_check kstrtou32_from_user(const char __user *s, size_t count, unsigned int base, u32 *res)\n{\n\treturn kstrtouint_from_user(s, count, base, res);\n}\n\nstatic inline int __must_check kstrtos32_from_user(const char __user *s, size_t count, unsigned int base, s32 *res)\n{\n\treturn kstrtoint_from_user(s, count, base, res);\n}\n\n/*\n * Use kstrto<foo> instead.\n *\n * NOTE: simple_strto<foo> does not check for the range overflow and,\n *\t depending on the input, may give interesting results.\n *\n * Use these functions if and only if you cannot use kstrto<foo>, because\n * the conversion ends on the first non-digit character, which may be far\n * beyond the supported range. It might be useful to parse the strings like\n * 10x50 or 12:21 without altering original string or temporary buffer in use.\n * Keep in mind above caveat.\n */\n\nextern unsigned long simple_strtoul(const char *,char **,unsigned int);\nextern long simple_strtol(const char *,char **,unsigned int);\nextern unsigned long long simple_strtoull(const char *,char **,unsigned int);\nextern long long simple_strtoll(const char *,char **,unsigned int);\n\nextern int num_to_str(char *buf, int size,\n\t\t      unsigned long long num, unsigned int width);\n\n/* lib/printf utilities */\n\nextern __printf(2, 3) int sprintf(char *buf, const char * fmt, ...);\nextern __printf(2, 0) int vsprintf(char *buf, const char *, va_list);\nextern __printf(3, 4)\nint snprintf(char *buf, size_t size, const char *fmt, ...);\nextern __printf(3, 0)\nint vsnprintf(char *buf, size_t size, const char *fmt, va_list args);\nextern __printf(3, 4)\nint scnprintf(char *buf, size_t size, const char *fmt, ...);\nextern __printf(3, 0)\nint vscnprintf(char *buf, size_t size, const char *fmt, va_list args);\nextern __printf(2, 3) __malloc\nchar *kasprintf(gfp_t gfp, const char *fmt, ...);\nextern __printf(2, 0) __malloc\nchar *kvasprintf(gfp_t gfp, const char *fmt, va_list args);\nextern __printf(2, 0)\nconst char *kvasprintf_const(gfp_t gfp, const char *fmt, va_list args);\n\nextern __scanf(2, 3)\nint sscanf(const char *, const char *, ...);\nextern __scanf(2, 0)\nint vsscanf(const char *, const char *, va_list);\n\nextern int get_option(char **str, int *pint);\nextern char *get_options(const char *str, int nints, int *ints);\nextern unsigned long long memparse(const char *ptr, char **retptr);\nextern bool parse_option_str(const char *str, const char *option);\nextern char *next_arg(char *args, char **param, char **val);\n\nextern int core_kernel_text(unsigned long addr);\nextern int init_kernel_text(unsigned long addr);\nextern int core_kernel_data(unsigned long addr);\nextern int __kernel_text_address(unsigned long addr);\nextern int kernel_text_address(unsigned long addr);\nextern int func_ptr_is_kernel_text(void *ptr);\n\n#ifdef CONFIG_SMP\nextern unsigned int sysctl_oops_all_cpu_backtrace;\n#else\n#define sysctl_oops_all_cpu_backtrace 0\n#endif /* CONFIG_SMP */\n\nextern void bust_spinlocks(int yes);\nextern int panic_timeout;\nextern unsigned long panic_print;\nextern int panic_on_oops;\nextern int panic_on_unrecovered_nmi;\nextern int panic_on_io_nmi;\nextern int panic_on_warn;\nextern unsigned long panic_on_taint;\nextern bool panic_on_taint_nousertaint;\nextern int sysctl_panic_on_rcu_stall;\nextern int sysctl_max_rcu_stall_to_panic;\nextern int sysctl_panic_on_stackoverflow;\n\nextern bool crash_kexec_post_notifiers;\n\n/*\n * panic_cpu is used for synchronizing panic() and crash_kexec() execution. It\n * holds a CPU number which is executing panic() currently. A value of\n * PANIC_CPU_INVALID means no CPU has entered panic() or crash_kexec().\n */\nextern atomic_t panic_cpu;\n#define PANIC_CPU_INVALID\t-1\n\n/*\n * Only to be used by arch init code. If the user over-wrote the default\n * CONFIG_PANIC_TIMEOUT, honor it.\n */\nstatic inline void set_arch_panic_timeout(int timeout, int arch_default_timeout)\n{\n\tif (panic_timeout == arch_default_timeout)\n\t\tpanic_timeout = timeout;\n}\nextern const char *print_tainted(void);\nenum lockdep_ok {\n\tLOCKDEP_STILL_OK,\n\tLOCKDEP_NOW_UNRELIABLE\n};\nextern void add_taint(unsigned flag, enum lockdep_ok);\nextern int test_taint(unsigned flag);\nextern unsigned long get_taint(void);\nextern int root_mountflags;\n\nextern bool early_boot_irqs_disabled;\n\n/*\n * Values used for system_state. Ordering of the states must not be changed\n * as code checks for <, <=, >, >= STATE.\n */\nextern enum system_states {\n\tSYSTEM_BOOTING,\n\tSYSTEM_SCHEDULING,\n\tSYSTEM_RUNNING,\n\tSYSTEM_HALT,\n\tSYSTEM_POWER_OFF,\n\tSYSTEM_RESTART,\n\tSYSTEM_SUSPEND,\n} system_state;\n\n/* This cannot be an enum because some may be used in assembly source. */\n#define TAINT_PROPRIETARY_MODULE\t0\n#define TAINT_FORCED_MODULE\t\t1\n#define TAINT_CPU_OUT_OF_SPEC\t\t2\n#define TAINT_FORCED_RMMOD\t\t3\n#define TAINT_MACHINE_CHECK\t\t4\n#define TAINT_BAD_PAGE\t\t\t5\n#define TAINT_USER\t\t\t6\n#define TAINT_DIE\t\t\t7\n#define TAINT_OVERRIDDEN_ACPI_TABLE\t8\n#define TAINT_WARN\t\t\t9\n#define TAINT_CRAP\t\t\t10\n#define TAINT_FIRMWARE_WORKAROUND\t11\n#define TAINT_OOT_MODULE\t\t12\n#define TAINT_UNSIGNED_MODULE\t\t13\n#define TAINT_SOFTLOCKUP\t\t14\n#define TAINT_LIVEPATCH\t\t\t15\n#define TAINT_AUX\t\t\t16\n#define TAINT_RANDSTRUCT\t\t17\n#define TAINT_FLAGS_COUNT\t\t18\n#define TAINT_FLAGS_MAX\t\t\t((1UL << TAINT_FLAGS_COUNT) - 1)\n\nstruct taint_flag {\n\tchar c_true;\t/* character printed when tainted */\n\tchar c_false;\t/* character printed when not tainted */\n\tbool module;\t/* also show as a per-module taint flag */\n};\n\nextern const struct taint_flag taint_flags[TAINT_FLAGS_COUNT];\n\nextern const char hex_asc[];\n#define hex_asc_lo(x)\thex_asc[((x) & 0x0f)]\n#define hex_asc_hi(x)\thex_asc[((x) & 0xf0) >> 4]\n\nstatic inline char *hex_byte_pack(char *buf, u8 byte)\n{\n\t*buf++ = hex_asc_hi(byte);\n\t*buf++ = hex_asc_lo(byte);\n\treturn buf;\n}\n\nextern const char hex_asc_upper[];\n#define hex_asc_upper_lo(x)\thex_asc_upper[((x) & 0x0f)]\n#define hex_asc_upper_hi(x)\thex_asc_upper[((x) & 0xf0) >> 4]\n\nstatic inline char *hex_byte_pack_upper(char *buf, u8 byte)\n{\n\t*buf++ = hex_asc_upper_hi(byte);\n\t*buf++ = hex_asc_upper_lo(byte);\n\treturn buf;\n}\n\nextern int hex_to_bin(char ch);\nextern int __must_check hex2bin(u8 *dst, const char *src, size_t count);\nextern char *bin2hex(char *dst, const void *src, size_t count);\n\nbool mac_pton(const char *s, u8 *mac);\n\n/*\n * General tracing related utility functions - trace_printk(),\n * tracing_on/tracing_off and tracing_start()/tracing_stop\n *\n * Use tracing_on/tracing_off when you want to quickly turn on or off\n * tracing. It simply enables or disables the recording of the trace events.\n * This also corresponds to the user space /sys/kernel/debug/tracing/tracing_on\n * file, which gives a means for the kernel and userspace to interact.\n * Place a tracing_off() in the kernel where you want tracing to end.\n * From user space, examine the trace, and then echo 1 > tracing_on\n * to continue tracing.\n *\n * tracing_stop/tracing_start has slightly more overhead. It is used\n * by things like suspend to ram where disabling the recording of the\n * trace is not enough, but tracing must actually stop because things\n * like calling smp_processor_id() may crash the system.\n *\n * Most likely, you want to use tracing_on/tracing_off.\n */\n\nenum ftrace_dump_mode {\n\tDUMP_NONE,\n\tDUMP_ALL,\n\tDUMP_ORIG,\n};\n\n#ifdef CONFIG_TRACING\nvoid tracing_on(void);\nvoid tracing_off(void);\nint tracing_is_on(void);\nvoid tracing_snapshot(void);\nvoid tracing_snapshot_alloc(void);\n\nextern void tracing_start(void);\nextern void tracing_stop(void);\n\nstatic inline __printf(1, 2)\nvoid ____trace_printk_check_format(const char *fmt, ...)\n{\n}\n#define __trace_printk_check_format(fmt, args...)\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tif (0)\t\t\t\t\t\t\t\t\\\n\t\t____trace_printk_check_format(fmt, ##args);\t\t\\\n} while (0)\n\n/**\n * trace_printk - printf formatting in the ftrace buffer\n * @fmt: the printf format for printing\n *\n * Note: __trace_printk is an internal function for trace_printk() and\n *       the @ip is passed in via the trace_printk() macro.\n *\n * This function allows a kernel developer to debug fast path sections\n * that printk is not appropriate for. By scattering in various\n * printk like tracing in the code, a developer can quickly see\n * where problems are occurring.\n *\n * This is intended as a debugging tool for the developer only.\n * Please refrain from leaving trace_printks scattered around in\n * your code. (Extra memory is used for special buffers that are\n * allocated when trace_printk() is used.)\n *\n * A little optimization trick is done here. If there's only one\n * argument, there's no need to scan the string for printf formats.\n * The trace_puts() will suffice. But how can we take advantage of\n * using trace_puts() when trace_printk() has only one argument?\n * By stringifying the args and checking the size we can tell\n * whether or not there are args. __stringify((__VA_ARGS__)) will\n * turn into \"()\\0\" with a size of 3 when there are no args, anything\n * else will be bigger. All we need to do is define a string to this,\n * and then take its size and compare to 3. If it's bigger, use\n * do_trace_printk() otherwise, optimize it to trace_puts(). Then just\n * let gcc optimize the rest.\n */\n\n#define trace_printk(fmt, ...)\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\\\n\tchar _______STR[] = __stringify((__VA_ARGS__));\t\\\n\tif (sizeof(_______STR) > 3)\t\t\t\\\n\t\tdo_trace_printk(fmt, ##__VA_ARGS__);\t\\\n\telse\t\t\t\t\t\t\\\n\t\ttrace_puts(fmt);\t\t\t\\\n} while (0)\n\n#define do_trace_printk(fmt, args...)\t\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tstatic const char *trace_printk_fmt __used\t\t\t\\\n\t\t__section(\"__trace_printk_fmt\") =\t\t\t\\\n\t\t__builtin_constant_p(fmt) ? fmt : NULL;\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\t__trace_printk_check_format(fmt, ##args);\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tif (__builtin_constant_p(fmt))\t\t\t\t\t\\\n\t\t__trace_bprintk(_THIS_IP_, trace_printk_fmt, ##args);\t\\\n\telse\t\t\t\t\t\t\t\t\\\n\t\t__trace_printk(_THIS_IP_, fmt, ##args);\t\t\t\\\n} while (0)\n\nextern __printf(2, 3)\nint __trace_bprintk(unsigned long ip, const char *fmt, ...);\n\nextern __printf(2, 3)\nint __trace_printk(unsigned long ip, const char *fmt, ...);\n\n/**\n * trace_puts - write a string into the ftrace buffer\n * @str: the string to record\n *\n * Note: __trace_bputs is an internal function for trace_puts and\n *       the @ip is passed in via the trace_puts macro.\n *\n * This is similar to trace_printk() but is made for those really fast\n * paths that a developer wants the least amount of \"Heisenbug\" effects,\n * where the processing of the print format is still too much.\n *\n * This function allows a kernel developer to debug fast path sections\n * that printk is not appropriate for. By scattering in various\n * printk like tracing in the code, a developer can quickly see\n * where problems are occurring.\n *\n * This is intended as a debugging tool for the developer only.\n * Please refrain from leaving trace_puts scattered around in\n * your code. (Extra memory is used for special buffers that are\n * allocated when trace_puts() is used.)\n *\n * Returns: 0 if nothing was written, positive # if string was.\n *  (1 when __trace_bputs is used, strlen(str) when __trace_puts is used)\n */\n\n#define trace_puts(str) ({\t\t\t\t\t\t\\\n\tstatic const char *trace_printk_fmt __used\t\t\t\\\n\t\t__section(\"__trace_printk_fmt\") =\t\t\t\\\n\t\t__builtin_constant_p(str) ? str : NULL;\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tif (__builtin_constant_p(str))\t\t\t\t\t\\\n\t\t__trace_bputs(_THIS_IP_, trace_printk_fmt);\t\t\\\n\telse\t\t\t\t\t\t\t\t\\\n\t\t__trace_puts(_THIS_IP_, str, strlen(str));\t\t\\\n})\nextern int __trace_bputs(unsigned long ip, const char *str);\nextern int __trace_puts(unsigned long ip, const char *str, int size);\n\nextern void trace_dump_stack(int skip);\n\n/*\n * The double __builtin_constant_p is because gcc will give us an error\n * if we try to allocate the static variable to fmt if it is not a\n * constant. Even with the outer if statement.\n */\n#define ftrace_vprintk(fmt, vargs)\t\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tif (__builtin_constant_p(fmt)) {\t\t\t\t\\\n\t\tstatic const char *trace_printk_fmt __used\t\t\\\n\t\t  __section(\"__trace_printk_fmt\") =\t\t\t\\\n\t\t\t__builtin_constant_p(fmt) ? fmt : NULL;\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\t\t__ftrace_vbprintk(_THIS_IP_, trace_printk_fmt, vargs);\t\\\n\t} else\t\t\t\t\t\t\t\t\\\n\t\t__ftrace_vprintk(_THIS_IP_, fmt, vargs);\t\t\\\n} while (0)\n\nextern __printf(2, 0) int\n__ftrace_vbprintk(unsigned long ip, const char *fmt, va_list ap);\n\nextern __printf(2, 0) int\n__ftrace_vprintk(unsigned long ip, const char *fmt, va_list ap);\n\nextern void ftrace_dump(enum ftrace_dump_mode oops_dump_mode);\n#else\nstatic inline void tracing_start(void) { }\nstatic inline void tracing_stop(void) { }\nstatic inline void trace_dump_stack(int skip) { }\n\nstatic inline void tracing_on(void) { }\nstatic inline void tracing_off(void) { }\nstatic inline int tracing_is_on(void) { return 0; }\nstatic inline void tracing_snapshot(void) { }\nstatic inline void tracing_snapshot_alloc(void) { }\n\nstatic inline __printf(1, 2)\nint trace_printk(const char *fmt, ...)\n{\n\treturn 0;\n}\nstatic __printf(1, 0) inline int\nftrace_vprintk(const char *fmt, va_list ap)\n{\n\treturn 0;\n}\nstatic inline void ftrace_dump(enum ftrace_dump_mode oops_dump_mode) { }\n#endif /* CONFIG_TRACING */\n\n/* This counts to 12. Any more, it will return 13th argument. */\n#define __COUNT_ARGS(_0, _1, _2, _3, _4, _5, _6, _7, _8, _9, _10, _11, _12, _n, X...) _n\n#define COUNT_ARGS(X...) __COUNT_ARGS(, ##X, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0)\n\n#define __CONCAT(a, b) a ## b\n#define CONCATENATE(a, b) __CONCAT(a, b)\n\n/**\n * container_of - cast a member of a structure out to the containing structure\n * @ptr:\tthe pointer to the member.\n * @type:\tthe type of the container struct this is embedded in.\n * @member:\tthe name of the member within the struct.\n *\n */\n#define container_of(ptr, type, member) ({\t\t\t\t\\\n\tvoid *__mptr = (void *)(ptr);\t\t\t\t\t\\\n\tBUILD_BUG_ON_MSG(!__same_type(*(ptr), ((type *)0)->member) &&\t\\\n\t\t\t !__same_type(*(ptr), void),\t\t\t\\\n\t\t\t \"pointer type mismatch in container_of()\");\t\\\n\t((type *)(__mptr - offsetof(type, member))); })\n\n/**\n * container_of_safe - cast a member of a structure out to the containing structure\n * @ptr:\tthe pointer to the member.\n * @type:\tthe type of the container struct this is embedded in.\n * @member:\tthe name of the member within the struct.\n *\n * If IS_ERR_OR_NULL(ptr), ptr is returned unchanged.\n */\n#define container_of_safe(ptr, type, member) ({\t\t\t\t\\\n\tvoid *__mptr = (void *)(ptr);\t\t\t\t\t\\\n\tBUILD_BUG_ON_MSG(!__same_type(*(ptr), ((type *)0)->member) &&\t\\\n\t\t\t !__same_type(*(ptr), void),\t\t\t\\\n\t\t\t \"pointer type mismatch in container_of()\");\t\\\n\tIS_ERR_OR_NULL(__mptr) ? ERR_CAST(__mptr) :\t\t\t\\\n\t\t((type *)(__mptr - offsetof(type, member))); })\n\n/* Rebuild everything on CONFIG_FTRACE_MCOUNT_RECORD */\n#ifdef CONFIG_FTRACE_MCOUNT_RECORD\n# define REBUILD_DUE_TO_FTRACE_MCOUNT_RECORD\n#endif\n\n/* Permissions on a sysfs file: you didn't miss the 0 prefix did you? */\n#define VERIFY_OCTAL_PERMISSIONS(perms)\t\t\t\t\t\t\\\n\t(BUILD_BUG_ON_ZERO((perms) < 0) +\t\t\t\t\t\\\n\t BUILD_BUG_ON_ZERO((perms) > 0777) +\t\t\t\t\t\\\n\t /* USER_READABLE >= GROUP_READABLE >= OTHER_READABLE */\t\t\\\n\t BUILD_BUG_ON_ZERO((((perms) >> 6) & 4) < (((perms) >> 3) & 4)) +\t\\\n\t BUILD_BUG_ON_ZERO((((perms) >> 3) & 4) < ((perms) & 4)) +\t\t\\\n\t /* USER_WRITABLE >= GROUP_WRITABLE */\t\t\t\t\t\\\n\t BUILD_BUG_ON_ZERO((((perms) >> 6) & 2) < (((perms) >> 3) & 2)) +\t\\\n\t /* OTHER_WRITABLE?  Generally considered a bad idea. */\t\t\\\n\t BUILD_BUG_ON_ZERO((perms) & 2) +\t\t\t\t\t\\\n\t (perms))\n#endif\n"}, "11": {"id": 11, "path": "/src/include/linux/build_bug.h", "content": "/* SPDX-License-Identifier: GPL-2.0 */\n#ifndef _LINUX_BUILD_BUG_H\n#define _LINUX_BUILD_BUG_H\n\n#include <linux/compiler.h>\n\n#ifdef __CHECKER__\n#define BUILD_BUG_ON_ZERO(e) (0)\n#else /* __CHECKER__ */\n/*\n * Force a compilation error if condition is true, but also produce a\n * result (of value 0 and type int), so the expression can be used\n * e.g. in a structure initializer (or where-ever else comma expressions\n * aren't permitted).\n */\n#define BUILD_BUG_ON_ZERO(e) ((int)(sizeof(struct { int:(-!!(e)); })))\n#endif /* __CHECKER__ */\n\n/* Force a compilation error if a constant expression is not a power of 2 */\n#define __BUILD_BUG_ON_NOT_POWER_OF_2(n)\t\\\n\tBUILD_BUG_ON(((n) & ((n) - 1)) != 0)\n#define BUILD_BUG_ON_NOT_POWER_OF_2(n)\t\t\t\\\n\tBUILD_BUG_ON((n) == 0 || (((n) & ((n) - 1)) != 0))\n\n/*\n * BUILD_BUG_ON_INVALID() permits the compiler to check the validity of the\n * expression but avoids the generation of any code, even if that expression\n * has side-effects.\n */\n#define BUILD_BUG_ON_INVALID(e) ((void)(sizeof((__force long)(e))))\n\n/**\n * BUILD_BUG_ON_MSG - break compile if a condition is true & emit supplied\n *\t\t      error message.\n * @condition: the condition which the compiler should know is false.\n *\n * See BUILD_BUG_ON for description.\n */\n#define BUILD_BUG_ON_MSG(cond, msg) compiletime_assert(!(cond), msg)\n\n/**\n * BUILD_BUG_ON - break compile if a condition is true.\n * @condition: the condition which the compiler should know is false.\n *\n * If you have some code which relies on certain constants being equal, or\n * some other compile-time-evaluated condition, you should use BUILD_BUG_ON to\n * detect if someone changes it.\n */\n#define BUILD_BUG_ON(condition) \\\n\tBUILD_BUG_ON_MSG(condition, \"BUILD_BUG_ON failed: \" #condition)\n\n/**\n * BUILD_BUG - break compile if used.\n *\n * If you have some code that you expect the compiler to eliminate at\n * build time, you should use BUILD_BUG to detect if it is\n * unexpectedly used.\n */\n#define BUILD_BUG() BUILD_BUG_ON_MSG(1, \"BUILD_BUG failed\")\n\n/**\n * static_assert - check integer constant expression at build time\n *\n * static_assert() is a wrapper for the C11 _Static_assert, with a\n * little macro magic to make the message optional (defaulting to the\n * stringification of the tested expression).\n *\n * Contrary to BUILD_BUG_ON(), static_assert() can be used at global\n * scope, but requires the expression to be an integer constant\n * expression (i.e., it is not enough that __builtin_constant_p() is\n * true for expr).\n *\n * Also note that BUILD_BUG_ON() fails the build if the condition is\n * true, while static_assert() fails the build if the expression is\n * false.\n */\n#define static_assert(expr, ...) __static_assert(expr, ##__VA_ARGS__, #expr)\n#define __static_assert(expr, msg, ...) _Static_assert(expr, msg)\n\n#endif\t/* _LINUX_BUILD_BUG_H */\n"}, "12": {"id": 12, "path": "/src/include/linux/compiler_types.h", "content": "/* SPDX-License-Identifier: GPL-2.0 */\n#ifndef __LINUX_COMPILER_TYPES_H\n#define __LINUX_COMPILER_TYPES_H\n\n#ifndef __ASSEMBLY__\n\n#ifdef __CHECKER__\n/* address spaces */\n# define __kernel\t__attribute__((address_space(0)))\n# define __user\t\t__attribute__((noderef, address_space(__user)))\n# define __iomem\t__attribute__((noderef, address_space(__iomem)))\n# define __percpu\t__attribute__((noderef, address_space(__percpu)))\n# define __rcu\t\t__attribute__((noderef, address_space(__rcu)))\nstatic inline void __chk_user_ptr(const volatile void __user *ptr) { }\nstatic inline void __chk_io_ptr(const volatile void __iomem *ptr) { }\n/* context/locking */\n# define __must_hold(x)\t__attribute__((context(x,1,1)))\n# define __acquires(x)\t__attribute__((context(x,0,1)))\n# define __releases(x)\t__attribute__((context(x,1,0)))\n# define __acquire(x)\t__context__(x,1)\n# define __release(x)\t__context__(x,-1)\n# define __cond_lock(x,c)\t((c) ? ({ __acquire(x); 1; }) : 0)\n/* other */\n# define __force\t__attribute__((force))\n# define __nocast\t__attribute__((nocast))\n# define __safe\t\t__attribute__((safe))\n# define __private\t__attribute__((noderef))\n# define ACCESS_PRIVATE(p, member) (*((typeof((p)->member) __force *) &(p)->member))\n#else /* __CHECKER__ */\n/* address spaces */\n# define __kernel\n# ifdef STRUCTLEAK_PLUGIN\n#  define __user\t__attribute__((user))\n# else\n#  define __user\n# endif\n# define __iomem\n# define __percpu\n# define __rcu\n# define __chk_user_ptr(x)\t(void)0\n# define __chk_io_ptr(x)\t(void)0\n/* context/locking */\n# define __must_hold(x)\n# define __acquires(x)\n# define __releases(x)\n# define __acquire(x)\t(void)0\n# define __release(x)\t(void)0\n# define __cond_lock(x,c) (c)\n/* other */\n# define __force\n# define __nocast\n# define __safe\n# define __private\n# define ACCESS_PRIVATE(p, member) ((p)->member)\n# define __builtin_warning(x, y...) (1)\n#endif /* __CHECKER__ */\n\n/* Indirect macros required for expanded argument pasting, eg. __LINE__. */\n#define ___PASTE(a,b) a##b\n#define __PASTE(a,b) ___PASTE(a,b)\n\n#ifdef __KERNEL__\n\n/* Attributes */\n#include <linux/compiler_attributes.h>\n\n/* Builtins */\n\n/*\n * __has_builtin is supported on gcc >= 10, clang >= 3 and icc >= 21.\n * In the meantime, to support gcc < 10, we implement __has_builtin\n * by hand.\n */\n#ifndef __has_builtin\n#define __has_builtin(x) (0)\n#endif\n\n/* Compiler specific macros. */\n#ifdef __clang__\n#include <linux/compiler-clang.h>\n#elif defined(__INTEL_COMPILER)\n#include <linux/compiler-intel.h>\n#elif defined(__GNUC__)\n/* The above compilers also define __GNUC__, so order is important here. */\n#include <linux/compiler-gcc.h>\n#else\n#error \"Unknown compiler\"\n#endif\n\n/*\n * Some architectures need to provide custom definitions of macros provided\n * by linux/compiler-*.h, and can do so using asm/compiler.h. We include that\n * conditionally rather than using an asm-generic wrapper in order to avoid\n * build failures if any C compilation, which will include this file via an\n * -include argument in c_flags, occurs prior to the asm-generic wrappers being\n * generated.\n */\n#ifdef CONFIG_HAVE_ARCH_COMPILER_H\n#include <asm/compiler.h>\n#endif\n\nstruct ftrace_branch_data {\n\tconst char *func;\n\tconst char *file;\n\tunsigned line;\n\tunion {\n\t\tstruct {\n\t\t\tunsigned long correct;\n\t\t\tunsigned long incorrect;\n\t\t};\n\t\tstruct {\n\t\t\tunsigned long miss;\n\t\t\tunsigned long hit;\n\t\t};\n\t\tunsigned long miss_hit[2];\n\t};\n};\n\nstruct ftrace_likely_data {\n\tstruct ftrace_branch_data\tdata;\n\tunsigned long\t\t\tconstant;\n};\n\n#if defined(CC_USING_HOTPATCH)\n#define notrace\t\t\t__attribute__((hotpatch(0, 0)))\n#elif defined(CC_USING_PATCHABLE_FUNCTION_ENTRY)\n#define notrace\t\t\t__attribute__((patchable_function_entry(0, 0)))\n#else\n#define notrace\t\t\t__attribute__((__no_instrument_function__))\n#endif\n\n/*\n * it doesn't make sense on ARM (currently the only user of __naked)\n * to trace naked functions because then mcount is called without\n * stack and frame pointer being set up and there is no chance to\n * restore the lr register to the value before mcount was called.\n */\n#define __naked\t\t\t__attribute__((__naked__)) notrace\n\n#define __compiler_offsetof(a, b)\t__builtin_offsetof(a, b)\n\n/*\n * Prefer gnu_inline, so that extern inline functions do not emit an\n * externally visible function. This makes extern inline behave as per gnu89\n * semantics rather than c99. This prevents multiple symbol definition errors\n * of extern inline functions at link time.\n * A lot of inline functions can cause havoc with function tracing.\n */\n#define inline inline __gnu_inline __inline_maybe_unused notrace\n\n/*\n * gcc provides both __inline__ and __inline as alternate spellings of\n * the inline keyword, though the latter is undocumented. New kernel\n * code should only use the inline spelling, but some existing code\n * uses __inline__. Since we #define inline above, to ensure\n * __inline__ has the same semantics, we need this #define.\n *\n * However, the spelling __inline is strictly reserved for referring\n * to the bare keyword.\n */\n#define __inline__ inline\n\n/*\n * GCC does not warn about unused static inline functions for -Wunused-function.\n * Suppress the warning in clang as well by using __maybe_unused, but enable it\n * for W=1 build. This will allow clang to find unused functions. Remove the\n * __inline_maybe_unused entirely after fixing most of -Wunused-function warnings.\n */\n#ifdef KBUILD_EXTRA_WARN1\n#define __inline_maybe_unused\n#else\n#define __inline_maybe_unused __maybe_unused\n#endif\n\n/*\n * Rather then using noinline to prevent stack consumption, use\n * noinline_for_stack instead.  For documentation reasons.\n */\n#define noinline_for_stack noinline\n\n/*\n * Sanitizer helper attributes: Because using __always_inline and\n * __no_sanitize_* conflict, provide helper attributes that will either expand\n * to __no_sanitize_* in compilation units where instrumentation is enabled\n * (__SANITIZE_*__), or __always_inline in compilation units without\n * instrumentation (__SANITIZE_*__ undefined).\n */\n#ifdef __SANITIZE_ADDRESS__\n/*\n * We can't declare function 'inline' because __no_sanitize_address conflicts\n * with inlining. Attempt to inline it may cause a build failure.\n *     https://gcc.gnu.org/bugzilla/show_bug.cgi?id=67368\n * '__maybe_unused' allows us to avoid defined-but-not-used warnings.\n */\n# define __no_kasan_or_inline __no_sanitize_address notrace __maybe_unused\n# define __no_sanitize_or_inline __no_kasan_or_inline\n#else\n# define __no_kasan_or_inline __always_inline\n#endif\n\n#define __no_kcsan __no_sanitize_thread\n#ifdef __SANITIZE_THREAD__\n# define __no_sanitize_or_inline __no_kcsan notrace __maybe_unused\n#endif\n\n#ifndef __no_sanitize_or_inline\n#define __no_sanitize_or_inline __always_inline\n#endif\n\n/* Section for code which can't be instrumented at all */\n#define noinstr\t\t\t\t\t\t\t\t\\\n\tnoinline notrace __attribute((__section__(\".noinstr.text\")))\t\\\n\t__no_kcsan __no_sanitize_address\n\n#endif /* __KERNEL__ */\n\n#endif /* __ASSEMBLY__ */\n\n/*\n * The below symbols may be defined for one or more, but not ALL, of the above\n * compilers. We don't consider that to be an error, so set them to nothing.\n * For example, some of them are for compiler specific plugins.\n */\n#ifndef __latent_entropy\n# define __latent_entropy\n#endif\n\n#ifndef __randomize_layout\n# define __randomize_layout __designated_init\n#endif\n\n#ifndef __no_randomize_layout\n# define __no_randomize_layout\n#endif\n\n#ifndef randomized_struct_fields_start\n# define randomized_struct_fields_start\n# define randomized_struct_fields_end\n#endif\n\n#ifndef __noscs\n# define __noscs\n#endif\n\n#ifndef asm_volatile_goto\n#define asm_volatile_goto(x...) asm goto(x)\n#endif\n\n#ifdef CONFIG_CC_HAS_ASM_INLINE\n#define asm_inline asm __inline\n#else\n#define asm_inline asm\n#endif\n\n/* Are two types/vars the same type (ignoring qualifiers)? */\n#define __same_type(a, b) __builtin_types_compatible_p(typeof(a), typeof(b))\n\n/*\n * __unqual_scalar_typeof(x) - Declare an unqualified scalar type, leaving\n *\t\t\t       non-scalar types unchanged.\n */\n/*\n * Prefer C11 _Generic for better compile-times and simpler code. Note: 'char'\n * is not type-compatible with 'signed char', and we define a separate case.\n */\n#define __scalar_type_to_expr_cases(type)\t\t\t\t\\\n\t\tunsigned type:\t(unsigned type)0,\t\t\t\\\n\t\tsigned type:\t(signed type)0\n\n#define __unqual_scalar_typeof(x) typeof(\t\t\t\t\\\n\t\t_Generic((x),\t\t\t\t\t\t\\\n\t\t\t char:\t(char)0,\t\t\t\t\\\n\t\t\t __scalar_type_to_expr_cases(char),\t\t\\\n\t\t\t __scalar_type_to_expr_cases(short),\t\t\\\n\t\t\t __scalar_type_to_expr_cases(int),\t\t\\\n\t\t\t __scalar_type_to_expr_cases(long),\t\t\\\n\t\t\t __scalar_type_to_expr_cases(long long),\t\\\n\t\t\t default: (x)))\n\n/* Is this type a native word size -- useful for atomic operations */\n#define __native_word(t) \\\n\t(sizeof(t) == sizeof(char) || sizeof(t) == sizeof(short) || \\\n\t sizeof(t) == sizeof(int) || sizeof(t) == sizeof(long))\n\n/* Compile time object size, -1 for unknown */\n#ifndef __compiletime_object_size\n# define __compiletime_object_size(obj) -1\n#endif\n#ifndef __compiletime_warning\n# define __compiletime_warning(message)\n#endif\n#ifndef __compiletime_error\n# define __compiletime_error(message)\n#endif\n\n#ifdef __OPTIMIZE__\n# define __compiletime_assert(condition, msg, prefix, suffix)\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\textern void prefix ## suffix(void) __compiletime_error(msg); \\\n\t\tif (!(condition))\t\t\t\t\t\\\n\t\t\tprefix ## suffix();\t\t\t\t\\\n\t} while (0)\n#else\n# define __compiletime_assert(condition, msg, prefix, suffix) do { } while (0)\n#endif\n\n#define _compiletime_assert(condition, msg, prefix, suffix) \\\n\t__compiletime_assert(condition, msg, prefix, suffix)\n\n/**\n * compiletime_assert - break build and emit msg if condition is false\n * @condition: a compile-time constant condition to check\n * @msg:       a message to emit if condition is false\n *\n * In tradition of POSIX assert, this macro will break the build if the\n * supplied condition is *false*, emitting the supplied error message if the\n * compiler has support to do so.\n */\n#define compiletime_assert(condition, msg) \\\n\t_compiletime_assert(condition, msg, __compiletime_assert_, __COUNTER__)\n\n#define compiletime_assert_atomic_type(t)\t\t\t\t\\\n\tcompiletime_assert(__native_word(t),\t\t\t\t\\\n\t\t\"Need native word sized stores/loads for atomicity.\")\n\n/* Helpers for emitting diagnostics in pragmas. */\n#ifndef __diag\n#define __diag(string)\n#endif\n\n#ifndef __diag_GCC\n#define __diag_GCC(version, severity, string)\n#endif\n\n#define __diag_push()\t__diag(push)\n#define __diag_pop()\t__diag(pop)\n\n#define __diag_ignore(compiler, version, option, comment) \\\n\t__diag_ ## compiler(version, ignore, option)\n#define __diag_warn(compiler, version, option, comment) \\\n\t__diag_ ## compiler(version, warn, option)\n#define __diag_error(compiler, version, option, comment) \\\n\t__diag_ ## compiler(version, error, option)\n\n#endif /* __LINUX_COMPILER_TYPES_H */\n"}, "13": {"id": 13, "path": "/src/include/linux/rwlock.h", "content": "#ifndef __LINUX_RWLOCK_H\n#define __LINUX_RWLOCK_H\n\n#ifndef __LINUX_SPINLOCK_H\n# error \"please don't include this file directly\"\n#endif\n\n/*\n * rwlock related methods\n *\n * split out from spinlock.h\n *\n * portions Copyright 2005, Red Hat, Inc., Ingo Molnar\n * Released under the General Public License (GPL).\n */\n\n#ifdef CONFIG_DEBUG_SPINLOCK\n  extern void __rwlock_init(rwlock_t *lock, const char *name,\n\t\t\t    struct lock_class_key *key);\n# define rwlock_init(lock)\t\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\\\n\tstatic struct lock_class_key __key;\t\t\t\\\n\t\t\t\t\t\t\t\t\\\n\t__rwlock_init((lock), #lock, &__key);\t\t\t\\\n} while (0)\n#else\n# define rwlock_init(lock)\t\t\t\t\t\\\n\tdo { *(lock) = __RW_LOCK_UNLOCKED(lock); } while (0)\n#endif\n\n#ifdef CONFIG_DEBUG_SPINLOCK\n extern void do_raw_read_lock(rwlock_t *lock) __acquires(lock);\n#define do_raw_read_lock_flags(lock, flags) do_raw_read_lock(lock)\n extern int do_raw_read_trylock(rwlock_t *lock);\n extern void do_raw_read_unlock(rwlock_t *lock) __releases(lock);\n extern void do_raw_write_lock(rwlock_t *lock) __acquires(lock);\n#define do_raw_write_lock_flags(lock, flags) do_raw_write_lock(lock)\n extern int do_raw_write_trylock(rwlock_t *lock);\n extern void do_raw_write_unlock(rwlock_t *lock) __releases(lock);\n#else\n\n#ifndef arch_read_lock_flags\n# define arch_read_lock_flags(lock, flags)\tarch_read_lock(lock)\n#endif\n\n#ifndef arch_write_lock_flags\n# define arch_write_lock_flags(lock, flags)\tarch_write_lock(lock)\n#endif\n\n# define do_raw_read_lock(rwlock)\tdo {__acquire(lock); arch_read_lock(&(rwlock)->raw_lock); } while (0)\n# define do_raw_read_lock_flags(lock, flags) \\\n\t\tdo {__acquire(lock); arch_read_lock_flags(&(lock)->raw_lock, *(flags)); } while (0)\n# define do_raw_read_trylock(rwlock)\tarch_read_trylock(&(rwlock)->raw_lock)\n# define do_raw_read_unlock(rwlock)\tdo {arch_read_unlock(&(rwlock)->raw_lock); __release(lock); } while (0)\n# define do_raw_write_lock(rwlock)\tdo {__acquire(lock); arch_write_lock(&(rwlock)->raw_lock); } while (0)\n# define do_raw_write_lock_flags(lock, flags) \\\n\t\tdo {__acquire(lock); arch_write_lock_flags(&(lock)->raw_lock, *(flags)); } while (0)\n# define do_raw_write_trylock(rwlock)\tarch_write_trylock(&(rwlock)->raw_lock)\n# define do_raw_write_unlock(rwlock)\tdo {arch_write_unlock(&(rwlock)->raw_lock); __release(lock); } while (0)\n#endif\n\n/*\n * Define the various rw_lock methods.  Note we define these\n * regardless of whether CONFIG_SMP or CONFIG_PREEMPT are set. The various\n * methods are defined as nops in the case they are not required.\n */\n#define read_trylock(lock)\t__cond_lock(lock, _raw_read_trylock(lock))\n#define write_trylock(lock)\t__cond_lock(lock, _raw_write_trylock(lock))\n\n#define write_lock(lock)\t_raw_write_lock(lock)\n#define read_lock(lock)\t\t_raw_read_lock(lock)\n\n#if defined(CONFIG_SMP) || defined(CONFIG_DEBUG_SPINLOCK)\n\n#define read_lock_irqsave(lock, flags)\t\t\t\\\n\tdo {\t\t\t\t\t\t\\\n\t\ttypecheck(unsigned long, flags);\t\\\n\t\tflags = _raw_read_lock_irqsave(lock);\t\\\n\t} while (0)\n#define write_lock_irqsave(lock, flags)\t\t\t\\\n\tdo {\t\t\t\t\t\t\\\n\t\ttypecheck(unsigned long, flags);\t\\\n\t\tflags = _raw_write_lock_irqsave(lock);\t\\\n\t} while (0)\n\n#else\n\n#define read_lock_irqsave(lock, flags)\t\t\t\\\n\tdo {\t\t\t\t\t\t\\\n\t\ttypecheck(unsigned long, flags);\t\\\n\t\t_raw_read_lock_irqsave(lock, flags);\t\\\n\t} while (0)\n#define write_lock_irqsave(lock, flags)\t\t\t\\\n\tdo {\t\t\t\t\t\t\\\n\t\ttypecheck(unsigned long, flags);\t\\\n\t\t_raw_write_lock_irqsave(lock, flags);\t\\\n\t} while (0)\n\n#endif\n\n#define read_lock_irq(lock)\t\t_raw_read_lock_irq(lock)\n#define read_lock_bh(lock)\t\t_raw_read_lock_bh(lock)\n#define write_lock_irq(lock)\t\t_raw_write_lock_irq(lock)\n#define write_lock_bh(lock)\t\t_raw_write_lock_bh(lock)\n#define read_unlock(lock)\t\t_raw_read_unlock(lock)\n#define write_unlock(lock)\t\t_raw_write_unlock(lock)\n#define read_unlock_irq(lock)\t\t_raw_read_unlock_irq(lock)\n#define write_unlock_irq(lock)\t\t_raw_write_unlock_irq(lock)\n\n#define read_unlock_irqrestore(lock, flags)\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\\\n\t\ttypecheck(unsigned long, flags);\t\t\\\n\t\t_raw_read_unlock_irqrestore(lock, flags);\t\\\n\t} while (0)\n#define read_unlock_bh(lock)\t\t_raw_read_unlock_bh(lock)\n\n#define write_unlock_irqrestore(lock, flags)\t\t\\\n\tdo {\t\t\t\t\t\t\\\n\t\ttypecheck(unsigned long, flags);\t\\\n\t\t_raw_write_unlock_irqrestore(lock, flags);\t\\\n\t} while (0)\n#define write_unlock_bh(lock)\t\t_raw_write_unlock_bh(lock)\n\n#define write_trylock_irqsave(lock, flags) \\\n({ \\\n\tlocal_irq_save(flags); \\\n\twrite_trylock(lock) ? \\\n\t1 : ({ local_irq_restore(flags); 0; }); \\\n})\n\n#ifdef arch_rwlock_is_contended\n#define rwlock_is_contended(lock) \\\n\t arch_rwlock_is_contended(&(lock)->raw_lock)\n#else\n#define rwlock_is_contended(lock)\t((void)(lock), 0)\n#endif /* arch_rwlock_is_contended */\n\n#endif /* __LINUX_RWLOCK_H */\n"}, "14": {"id": 14, "path": "/src/include/linux/list.h", "content": "/* SPDX-License-Identifier: GPL-2.0 */\n#ifndef _LINUX_LIST_H\n#define _LINUX_LIST_H\n\n#include <linux/types.h>\n#include <linux/stddef.h>\n#include <linux/poison.h>\n#include <linux/const.h>\n#include <linux/kernel.h>\n\n/*\n * Circular doubly linked list implementation.\n *\n * Some of the internal functions (\"__xxx\") are useful when\n * manipulating whole lists rather than single entries, as\n * sometimes we already know the next/prev entries and we can\n * generate better code by using them directly rather than\n * using the generic single-entry routines.\n */\n\n#define LIST_HEAD_INIT(name) { &(name), &(name) }\n\n#define LIST_HEAD(name) \\\n\tstruct list_head name = LIST_HEAD_INIT(name)\n\n/**\n * INIT_LIST_HEAD - Initialize a list_head structure\n * @list: list_head structure to be initialized.\n *\n * Initializes the list_head to point to itself.  If it is a list header,\n * the result is an empty list.\n */\nstatic inline void INIT_LIST_HEAD(struct list_head *list)\n{\n\tWRITE_ONCE(list->next, list);\n\tlist->prev = list;\n}\n\n#ifdef CONFIG_DEBUG_LIST\nextern bool __list_add_valid(struct list_head *new,\n\t\t\t      struct list_head *prev,\n\t\t\t      struct list_head *next);\nextern bool __list_del_entry_valid(struct list_head *entry);\n#else\nstatic inline bool __list_add_valid(struct list_head *new,\n\t\t\t\tstruct list_head *prev,\n\t\t\t\tstruct list_head *next)\n{\n\treturn true;\n}\nstatic inline bool __list_del_entry_valid(struct list_head *entry)\n{\n\treturn true;\n}\n#endif\n\n/*\n * Insert a new entry between two known consecutive entries.\n *\n * This is only for internal list manipulation where we know\n * the prev/next entries already!\n */\nstatic inline void __list_add(struct list_head *new,\n\t\t\t      struct list_head *prev,\n\t\t\t      struct list_head *next)\n{\n\tif (!__list_add_valid(new, prev, next))\n\t\treturn;\n\n\tnext->prev = new;\n\tnew->next = next;\n\tnew->prev = prev;\n\tWRITE_ONCE(prev->next, new);\n}\n\n/**\n * list_add - add a new entry\n * @new: new entry to be added\n * @head: list head to add it after\n *\n * Insert a new entry after the specified head.\n * This is good for implementing stacks.\n */\nstatic inline void list_add(struct list_head *new, struct list_head *head)\n{\n\t__list_add(new, head, head->next);\n}\n\n\n/**\n * list_add_tail - add a new entry\n * @new: new entry to be added\n * @head: list head to add it before\n *\n * Insert a new entry before the specified head.\n * This is useful for implementing queues.\n */\nstatic inline void list_add_tail(struct list_head *new, struct list_head *head)\n{\n\t__list_add(new, head->prev, head);\n}\n\n/*\n * Delete a list entry by making the prev/next entries\n * point to each other.\n *\n * This is only for internal list manipulation where we know\n * the prev/next entries already!\n */\nstatic inline void __list_del(struct list_head * prev, struct list_head * next)\n{\n\tnext->prev = prev;\n\tWRITE_ONCE(prev->next, next);\n}\n\n/*\n * Delete a list entry and clear the 'prev' pointer.\n *\n * This is a special-purpose list clearing method used in the networking code\n * for lists allocated as per-cpu, where we don't want to incur the extra\n * WRITE_ONCE() overhead of a regular list_del_init(). The code that uses this\n * needs to check the node 'prev' pointer instead of calling list_empty().\n */\nstatic inline void __list_del_clearprev(struct list_head *entry)\n{\n\t__list_del(entry->prev, entry->next);\n\tentry->prev = NULL;\n}\n\nstatic inline void __list_del_entry(struct list_head *entry)\n{\n\tif (!__list_del_entry_valid(entry))\n\t\treturn;\n\n\t__list_del(entry->prev, entry->next);\n}\n\n/**\n * list_del - deletes entry from list.\n * @entry: the element to delete from the list.\n * Note: list_empty() on entry does not return true after this, the entry is\n * in an undefined state.\n */\nstatic inline void list_del(struct list_head *entry)\n{\n\t__list_del_entry(entry);\n\tentry->next = LIST_POISON1;\n\tentry->prev = LIST_POISON2;\n}\n\n/**\n * list_replace - replace old entry by new one\n * @old : the element to be replaced\n * @new : the new element to insert\n *\n * If @old was empty, it will be overwritten.\n */\nstatic inline void list_replace(struct list_head *old,\n\t\t\t\tstruct list_head *new)\n{\n\tnew->next = old->next;\n\tnew->next->prev = new;\n\tnew->prev = old->prev;\n\tnew->prev->next = new;\n}\n\n/**\n * list_replace_init - replace old entry by new one and initialize the old one\n * @old : the element to be replaced\n * @new : the new element to insert\n *\n * If @old was empty, it will be overwritten.\n */\nstatic inline void list_replace_init(struct list_head *old,\n\t\t\t\t     struct list_head *new)\n{\n\tlist_replace(old, new);\n\tINIT_LIST_HEAD(old);\n}\n\n/**\n * list_swap - replace entry1 with entry2 and re-add entry1 at entry2's position\n * @entry1: the location to place entry2\n * @entry2: the location to place entry1\n */\nstatic inline void list_swap(struct list_head *entry1,\n\t\t\t     struct list_head *entry2)\n{\n\tstruct list_head *pos = entry2->prev;\n\n\tlist_del(entry2);\n\tlist_replace(entry1, entry2);\n\tif (pos == entry1)\n\t\tpos = entry2;\n\tlist_add(entry1, pos);\n}\n\n/**\n * list_del_init - deletes entry from list and reinitialize it.\n * @entry: the element to delete from the list.\n */\nstatic inline void list_del_init(struct list_head *entry)\n{\n\t__list_del_entry(entry);\n\tINIT_LIST_HEAD(entry);\n}\n\n/**\n * list_move - delete from one list and add as another's head\n * @list: the entry to move\n * @head: the head that will precede our entry\n */\nstatic inline void list_move(struct list_head *list, struct list_head *head)\n{\n\t__list_del_entry(list);\n\tlist_add(list, head);\n}\n\n/**\n * list_move_tail - delete from one list and add as another's tail\n * @list: the entry to move\n * @head: the head that will follow our entry\n */\nstatic inline void list_move_tail(struct list_head *list,\n\t\t\t\t  struct list_head *head)\n{\n\t__list_del_entry(list);\n\tlist_add_tail(list, head);\n}\n\n/**\n * list_bulk_move_tail - move a subsection of a list to its tail\n * @head: the head that will follow our entry\n * @first: first entry to move\n * @last: last entry to move, can be the same as first\n *\n * Move all entries between @first and including @last before @head.\n * All three entries must belong to the same linked list.\n */\nstatic inline void list_bulk_move_tail(struct list_head *head,\n\t\t\t\t       struct list_head *first,\n\t\t\t\t       struct list_head *last)\n{\n\tfirst->prev->next = last->next;\n\tlast->next->prev = first->prev;\n\n\thead->prev->next = first;\n\tfirst->prev = head->prev;\n\n\tlast->next = head;\n\thead->prev = last;\n}\n\n/**\n * list_is_first -- tests whether @list is the first entry in list @head\n * @list: the entry to test\n * @head: the head of the list\n */\nstatic inline int list_is_first(const struct list_head *list,\n\t\t\t\t\tconst struct list_head *head)\n{\n\treturn list->prev == head;\n}\n\n/**\n * list_is_last - tests whether @list is the last entry in list @head\n * @list: the entry to test\n * @head: the head of the list\n */\nstatic inline int list_is_last(const struct list_head *list,\n\t\t\t\tconst struct list_head *head)\n{\n\treturn list->next == head;\n}\n\n/**\n * list_empty - tests whether a list is empty\n * @head: the list to test.\n */\nstatic inline int list_empty(const struct list_head *head)\n{\n\treturn READ_ONCE(head->next) == head;\n}\n\n/**\n * list_del_init_careful - deletes entry from list and reinitialize it.\n * @entry: the element to delete from the list.\n *\n * This is the same as list_del_init(), except designed to be used\n * together with list_empty_careful() in a way to guarantee ordering\n * of other memory operations.\n *\n * Any memory operations done before a list_del_init_careful() are\n * guaranteed to be visible after a list_empty_careful() test.\n */\nstatic inline void list_del_init_careful(struct list_head *entry)\n{\n\t__list_del_entry(entry);\n\tentry->prev = entry;\n\tsmp_store_release(&entry->next, entry);\n}\n\n/**\n * list_empty_careful - tests whether a list is empty and not being modified\n * @head: the list to test\n *\n * Description:\n * tests whether a list is empty _and_ checks that no other CPU might be\n * in the process of modifying either member (next or prev)\n *\n * NOTE: using list_empty_careful() without synchronization\n * can only be safe if the only activity that can happen\n * to the list entry is list_del_init(). Eg. it cannot be used\n * if another CPU could re-list_add() it.\n */\nstatic inline int list_empty_careful(const struct list_head *head)\n{\n\tstruct list_head *next = smp_load_acquire(&head->next);\n\treturn (next == head) && (next == head->prev);\n}\n\n/**\n * list_rotate_left - rotate the list to the left\n * @head: the head of the list\n */\nstatic inline void list_rotate_left(struct list_head *head)\n{\n\tstruct list_head *first;\n\n\tif (!list_empty(head)) {\n\t\tfirst = head->next;\n\t\tlist_move_tail(first, head);\n\t}\n}\n\n/**\n * list_rotate_to_front() - Rotate list to specific item.\n * @list: The desired new front of the list.\n * @head: The head of the list.\n *\n * Rotates list so that @list becomes the new front of the list.\n */\nstatic inline void list_rotate_to_front(struct list_head *list,\n\t\t\t\t\tstruct list_head *head)\n{\n\t/*\n\t * Deletes the list head from the list denoted by @head and\n\t * places it as the tail of @list, this effectively rotates the\n\t * list so that @list is at the front.\n\t */\n\tlist_move_tail(head, list);\n}\n\n/**\n * list_is_singular - tests whether a list has just one entry.\n * @head: the list to test.\n */\nstatic inline int list_is_singular(const struct list_head *head)\n{\n\treturn !list_empty(head) && (head->next == head->prev);\n}\n\nstatic inline void __list_cut_position(struct list_head *list,\n\t\tstruct list_head *head, struct list_head *entry)\n{\n\tstruct list_head *new_first = entry->next;\n\tlist->next = head->next;\n\tlist->next->prev = list;\n\tlist->prev = entry;\n\tentry->next = list;\n\thead->next = new_first;\n\tnew_first->prev = head;\n}\n\n/**\n * list_cut_position - cut a list into two\n * @list: a new list to add all removed entries\n * @head: a list with entries\n * @entry: an entry within head, could be the head itself\n *\tand if so we won't cut the list\n *\n * This helper moves the initial part of @head, up to and\n * including @entry, from @head to @list. You should\n * pass on @entry an element you know is on @head. @list\n * should be an empty list or a list you do not care about\n * losing its data.\n *\n */\nstatic inline void list_cut_position(struct list_head *list,\n\t\tstruct list_head *head, struct list_head *entry)\n{\n\tif (list_empty(head))\n\t\treturn;\n\tif (list_is_singular(head) &&\n\t\t(head->next != entry && head != entry))\n\t\treturn;\n\tif (entry == head)\n\t\tINIT_LIST_HEAD(list);\n\telse\n\t\t__list_cut_position(list, head, entry);\n}\n\n/**\n * list_cut_before - cut a list into two, before given entry\n * @list: a new list to add all removed entries\n * @head: a list with entries\n * @entry: an entry within head, could be the head itself\n *\n * This helper moves the initial part of @head, up to but\n * excluding @entry, from @head to @list.  You should pass\n * in @entry an element you know is on @head.  @list should\n * be an empty list or a list you do not care about losing\n * its data.\n * If @entry == @head, all entries on @head are moved to\n * @list.\n */\nstatic inline void list_cut_before(struct list_head *list,\n\t\t\t\t   struct list_head *head,\n\t\t\t\t   struct list_head *entry)\n{\n\tif (head->next == entry) {\n\t\tINIT_LIST_HEAD(list);\n\t\treturn;\n\t}\n\tlist->next = head->next;\n\tlist->next->prev = list;\n\tlist->prev = entry->prev;\n\tlist->prev->next = list;\n\thead->next = entry;\n\tentry->prev = head;\n}\n\nstatic inline void __list_splice(const struct list_head *list,\n\t\t\t\t struct list_head *prev,\n\t\t\t\t struct list_head *next)\n{\n\tstruct list_head *first = list->next;\n\tstruct list_head *last = list->prev;\n\n\tfirst->prev = prev;\n\tprev->next = first;\n\n\tlast->next = next;\n\tnext->prev = last;\n}\n\n/**\n * list_splice - join two lists, this is designed for stacks\n * @list: the new list to add.\n * @head: the place to add it in the first list.\n */\nstatic inline void list_splice(const struct list_head *list,\n\t\t\t\tstruct list_head *head)\n{\n\tif (!list_empty(list))\n\t\t__list_splice(list, head, head->next);\n}\n\n/**\n * list_splice_tail - join two lists, each list being a queue\n * @list: the new list to add.\n * @head: the place to add it in the first list.\n */\nstatic inline void list_splice_tail(struct list_head *list,\n\t\t\t\tstruct list_head *head)\n{\n\tif (!list_empty(list))\n\t\t__list_splice(list, head->prev, head);\n}\n\n/**\n * list_splice_init - join two lists and reinitialise the emptied list.\n * @list: the new list to add.\n * @head: the place to add it in the first list.\n *\n * The list at @list is reinitialised\n */\nstatic inline void list_splice_init(struct list_head *list,\n\t\t\t\t    struct list_head *head)\n{\n\tif (!list_empty(list)) {\n\t\t__list_splice(list, head, head->next);\n\t\tINIT_LIST_HEAD(list);\n\t}\n}\n\n/**\n * list_splice_tail_init - join two lists and reinitialise the emptied list\n * @list: the new list to add.\n * @head: the place to add it in the first list.\n *\n * Each of the lists is a queue.\n * The list at @list is reinitialised\n */\nstatic inline void list_splice_tail_init(struct list_head *list,\n\t\t\t\t\t struct list_head *head)\n{\n\tif (!list_empty(list)) {\n\t\t__list_splice(list, head->prev, head);\n\t\tINIT_LIST_HEAD(list);\n\t}\n}\n\n/**\n * list_entry - get the struct for this entry\n * @ptr:\tthe &struct list_head pointer.\n * @type:\tthe type of the struct this is embedded in.\n * @member:\tthe name of the list_head within the struct.\n */\n#define list_entry(ptr, type, member) \\\n\tcontainer_of(ptr, type, member)\n\n/**\n * list_first_entry - get the first element from a list\n * @ptr:\tthe list head to take the element from.\n * @type:\tthe type of the struct this is embedded in.\n * @member:\tthe name of the list_head within the struct.\n *\n * Note, that list is expected to be not empty.\n */\n#define list_first_entry(ptr, type, member) \\\n\tlist_entry((ptr)->next, type, member)\n\n/**\n * list_last_entry - get the last element from a list\n * @ptr:\tthe list head to take the element from.\n * @type:\tthe type of the struct this is embedded in.\n * @member:\tthe name of the list_head within the struct.\n *\n * Note, that list is expected to be not empty.\n */\n#define list_last_entry(ptr, type, member) \\\n\tlist_entry((ptr)->prev, type, member)\n\n/**\n * list_first_entry_or_null - get the first element from a list\n * @ptr:\tthe list head to take the element from.\n * @type:\tthe type of the struct this is embedded in.\n * @member:\tthe name of the list_head within the struct.\n *\n * Note that if the list is empty, it returns NULL.\n */\n#define list_first_entry_or_null(ptr, type, member) ({ \\\n\tstruct list_head *head__ = (ptr); \\\n\tstruct list_head *pos__ = READ_ONCE(head__->next); \\\n\tpos__ != head__ ? list_entry(pos__, type, member) : NULL; \\\n})\n\n/**\n * list_next_entry - get the next element in list\n * @pos:\tthe type * to cursor\n * @member:\tthe name of the list_head within the struct.\n */\n#define list_next_entry(pos, member) \\\n\tlist_entry((pos)->member.next, typeof(*(pos)), member)\n\n/**\n * list_prev_entry - get the prev element in list\n * @pos:\tthe type * to cursor\n * @member:\tthe name of the list_head within the struct.\n */\n#define list_prev_entry(pos, member) \\\n\tlist_entry((pos)->member.prev, typeof(*(pos)), member)\n\n/**\n * list_for_each\t-\titerate over a list\n * @pos:\tthe &struct list_head to use as a loop cursor.\n * @head:\tthe head for your list.\n */\n#define list_for_each(pos, head) \\\n\tfor (pos = (head)->next; pos != (head); pos = pos->next)\n\n/**\n * list_for_each_continue - continue iteration over a list\n * @pos:\tthe &struct list_head to use as a loop cursor.\n * @head:\tthe head for your list.\n *\n * Continue to iterate over a list, continuing after the current position.\n */\n#define list_for_each_continue(pos, head) \\\n\tfor (pos = pos->next; pos != (head); pos = pos->next)\n\n/**\n * list_for_each_prev\t-\titerate over a list backwards\n * @pos:\tthe &struct list_head to use as a loop cursor.\n * @head:\tthe head for your list.\n */\n#define list_for_each_prev(pos, head) \\\n\tfor (pos = (head)->prev; pos != (head); pos = pos->prev)\n\n/**\n * list_for_each_safe - iterate over a list safe against removal of list entry\n * @pos:\tthe &struct list_head to use as a loop cursor.\n * @n:\t\tanother &struct list_head to use as temporary storage\n * @head:\tthe head for your list.\n */\n#define list_for_each_safe(pos, n, head) \\\n\tfor (pos = (head)->next, n = pos->next; pos != (head); \\\n\t\tpos = n, n = pos->next)\n\n/**\n * list_for_each_prev_safe - iterate over a list backwards safe against removal of list entry\n * @pos:\tthe &struct list_head to use as a loop cursor.\n * @n:\t\tanother &struct list_head to use as temporary storage\n * @head:\tthe head for your list.\n */\n#define list_for_each_prev_safe(pos, n, head) \\\n\tfor (pos = (head)->prev, n = pos->prev; \\\n\t     pos != (head); \\\n\t     pos = n, n = pos->prev)\n\n/**\n * list_entry_is_head - test if the entry points to the head of the list\n * @pos:\tthe type * to cursor\n * @head:\tthe head for your list.\n * @member:\tthe name of the list_head within the struct.\n */\n#define list_entry_is_head(pos, head, member)\t\t\t\t\\\n\t(&pos->member == (head))\n\n/**\n * list_for_each_entry\t-\titerate over list of given type\n * @pos:\tthe type * to use as a loop cursor.\n * @head:\tthe head for your list.\n * @member:\tthe name of the list_head within the struct.\n */\n#define list_for_each_entry(pos, head, member)\t\t\t\t\\\n\tfor (pos = list_first_entry(head, typeof(*pos), member);\t\\\n\t     !list_entry_is_head(pos, head, member);\t\t\t\\\n\t     pos = list_next_entry(pos, member))\n\n/**\n * list_for_each_entry_reverse - iterate backwards over list of given type.\n * @pos:\tthe type * to use as a loop cursor.\n * @head:\tthe head for your list.\n * @member:\tthe name of the list_head within the struct.\n */\n#define list_for_each_entry_reverse(pos, head, member)\t\t\t\\\n\tfor (pos = list_last_entry(head, typeof(*pos), member);\t\t\\\n\t     !list_entry_is_head(pos, head, member); \t\t\t\\\n\t     pos = list_prev_entry(pos, member))\n\n/**\n * list_prepare_entry - prepare a pos entry for use in list_for_each_entry_continue()\n * @pos:\tthe type * to use as a start point\n * @head:\tthe head of the list\n * @member:\tthe name of the list_head within the struct.\n *\n * Prepares a pos entry for use as a start point in list_for_each_entry_continue().\n */\n#define list_prepare_entry(pos, head, member) \\\n\t((pos) ? : list_entry(head, typeof(*pos), member))\n\n/**\n * list_for_each_entry_continue - continue iteration over list of given type\n * @pos:\tthe type * to use as a loop cursor.\n * @head:\tthe head for your list.\n * @member:\tthe name of the list_head within the struct.\n *\n * Continue to iterate over list of given type, continuing after\n * the current position.\n */\n#define list_for_each_entry_continue(pos, head, member) \t\t\\\n\tfor (pos = list_next_entry(pos, member);\t\t\t\\\n\t     !list_entry_is_head(pos, head, member);\t\t\t\\\n\t     pos = list_next_entry(pos, member))\n\n/**\n * list_for_each_entry_continue_reverse - iterate backwards from the given point\n * @pos:\tthe type * to use as a loop cursor.\n * @head:\tthe head for your list.\n * @member:\tthe name of the list_head within the struct.\n *\n * Start to iterate over list of given type backwards, continuing after\n * the current position.\n */\n#define list_for_each_entry_continue_reverse(pos, head, member)\t\t\\\n\tfor (pos = list_prev_entry(pos, member);\t\t\t\\\n\t     !list_entry_is_head(pos, head, member);\t\t\t\\\n\t     pos = list_prev_entry(pos, member))\n\n/**\n * list_for_each_entry_from - iterate over list of given type from the current point\n * @pos:\tthe type * to use as a loop cursor.\n * @head:\tthe head for your list.\n * @member:\tthe name of the list_head within the struct.\n *\n * Iterate over list of given type, continuing from current position.\n */\n#define list_for_each_entry_from(pos, head, member) \t\t\t\\\n\tfor (; !list_entry_is_head(pos, head, member);\t\t\t\\\n\t     pos = list_next_entry(pos, member))\n\n/**\n * list_for_each_entry_from_reverse - iterate backwards over list of given type\n *                                    from the current point\n * @pos:\tthe type * to use as a loop cursor.\n * @head:\tthe head for your list.\n * @member:\tthe name of the list_head within the struct.\n *\n * Iterate backwards over list of given type, continuing from current position.\n */\n#define list_for_each_entry_from_reverse(pos, head, member)\t\t\\\n\tfor (; !list_entry_is_head(pos, head, member);\t\t\t\\\n\t     pos = list_prev_entry(pos, member))\n\n/**\n * list_for_each_entry_safe - iterate over list of given type safe against removal of list entry\n * @pos:\tthe type * to use as a loop cursor.\n * @n:\t\tanother type * to use as temporary storage\n * @head:\tthe head for your list.\n * @member:\tthe name of the list_head within the struct.\n */\n#define list_for_each_entry_safe(pos, n, head, member)\t\t\t\\\n\tfor (pos = list_first_entry(head, typeof(*pos), member),\t\\\n\t\tn = list_next_entry(pos, member);\t\t\t\\\n\t     !list_entry_is_head(pos, head, member); \t\t\t\\\n\t     pos = n, n = list_next_entry(n, member))\n\n/**\n * list_for_each_entry_safe_continue - continue list iteration safe against removal\n * @pos:\tthe type * to use as a loop cursor.\n * @n:\t\tanother type * to use as temporary storage\n * @head:\tthe head for your list.\n * @member:\tthe name of the list_head within the struct.\n *\n * Iterate over list of given type, continuing after current point,\n * safe against removal of list entry.\n */\n#define list_for_each_entry_safe_continue(pos, n, head, member) \t\t\\\n\tfor (pos = list_next_entry(pos, member), \t\t\t\t\\\n\t\tn = list_next_entry(pos, member);\t\t\t\t\\\n\t     !list_entry_is_head(pos, head, member);\t\t\t\t\\\n\t     pos = n, n = list_next_entry(n, member))\n\n/**\n * list_for_each_entry_safe_from - iterate over list from current point safe against removal\n * @pos:\tthe type * to use as a loop cursor.\n * @n:\t\tanother type * to use as temporary storage\n * @head:\tthe head for your list.\n * @member:\tthe name of the list_head within the struct.\n *\n * Iterate over list of given type from current point, safe against\n * removal of list entry.\n */\n#define list_for_each_entry_safe_from(pos, n, head, member) \t\t\t\\\n\tfor (n = list_next_entry(pos, member);\t\t\t\t\t\\\n\t     !list_entry_is_head(pos, head, member);\t\t\t\t\\\n\t     pos = n, n = list_next_entry(n, member))\n\n/**\n * list_for_each_entry_safe_reverse - iterate backwards over list safe against removal\n * @pos:\tthe type * to use as a loop cursor.\n * @n:\t\tanother type * to use as temporary storage\n * @head:\tthe head for your list.\n * @member:\tthe name of the list_head within the struct.\n *\n * Iterate backwards over list of given type, safe against removal\n * of list entry.\n */\n#define list_for_each_entry_safe_reverse(pos, n, head, member)\t\t\\\n\tfor (pos = list_last_entry(head, typeof(*pos), member),\t\t\\\n\t\tn = list_prev_entry(pos, member);\t\t\t\\\n\t     !list_entry_is_head(pos, head, member); \t\t\t\\\n\t     pos = n, n = list_prev_entry(n, member))\n\n/**\n * list_safe_reset_next - reset a stale list_for_each_entry_safe loop\n * @pos:\tthe loop cursor used in the list_for_each_entry_safe loop\n * @n:\t\ttemporary storage used in list_for_each_entry_safe\n * @member:\tthe name of the list_head within the struct.\n *\n * list_safe_reset_next is not safe to use in general if the list may be\n * modified concurrently (eg. the lock is dropped in the loop body). An\n * exception to this is if the cursor element (pos) is pinned in the list,\n * and list_safe_reset_next is called after re-taking the lock and before\n * completing the current iteration of the loop body.\n */\n#define list_safe_reset_next(pos, n, member)\t\t\t\t\\\n\tn = list_next_entry(pos, member)\n\n/*\n * Double linked lists with a single pointer list head.\n * Mostly useful for hash tables where the two pointer list head is\n * too wasteful.\n * You lose the ability to access the tail in O(1).\n */\n\n#define HLIST_HEAD_INIT { .first = NULL }\n#define HLIST_HEAD(name) struct hlist_head name = {  .first = NULL }\n#define INIT_HLIST_HEAD(ptr) ((ptr)->first = NULL)\nstatic inline void INIT_HLIST_NODE(struct hlist_node *h)\n{\n\th->next = NULL;\n\th->pprev = NULL;\n}\n\n/**\n * hlist_unhashed - Has node been removed from list and reinitialized?\n * @h: Node to be checked\n *\n * Not that not all removal functions will leave a node in unhashed\n * state.  For example, hlist_nulls_del_init_rcu() does leave the\n * node in unhashed state, but hlist_nulls_del() does not.\n */\nstatic inline int hlist_unhashed(const struct hlist_node *h)\n{\n\treturn !h->pprev;\n}\n\n/**\n * hlist_unhashed_lockless - Version of hlist_unhashed for lockless use\n * @h: Node to be checked\n *\n * This variant of hlist_unhashed() must be used in lockless contexts\n * to avoid potential load-tearing.  The READ_ONCE() is paired with the\n * various WRITE_ONCE() in hlist helpers that are defined below.\n */\nstatic inline int hlist_unhashed_lockless(const struct hlist_node *h)\n{\n\treturn !READ_ONCE(h->pprev);\n}\n\n/**\n * hlist_empty - Is the specified hlist_head structure an empty hlist?\n * @h: Structure to check.\n */\nstatic inline int hlist_empty(const struct hlist_head *h)\n{\n\treturn !READ_ONCE(h->first);\n}\n\nstatic inline void __hlist_del(struct hlist_node *n)\n{\n\tstruct hlist_node *next = n->next;\n\tstruct hlist_node **pprev = n->pprev;\n\n\tWRITE_ONCE(*pprev, next);\n\tif (next)\n\t\tWRITE_ONCE(next->pprev, pprev);\n}\n\n/**\n * hlist_del - Delete the specified hlist_node from its list\n * @n: Node to delete.\n *\n * Note that this function leaves the node in hashed state.  Use\n * hlist_del_init() or similar instead to unhash @n.\n */\nstatic inline void hlist_del(struct hlist_node *n)\n{\n\t__hlist_del(n);\n\tn->next = LIST_POISON1;\n\tn->pprev = LIST_POISON2;\n}\n\n/**\n * hlist_del_init - Delete the specified hlist_node from its list and initialize\n * @n: Node to delete.\n *\n * Note that this function leaves the node in unhashed state.\n */\nstatic inline void hlist_del_init(struct hlist_node *n)\n{\n\tif (!hlist_unhashed(n)) {\n\t\t__hlist_del(n);\n\t\tINIT_HLIST_NODE(n);\n\t}\n}\n\n/**\n * hlist_add_head - add a new entry at the beginning of the hlist\n * @n: new entry to be added\n * @h: hlist head to add it after\n *\n * Insert a new entry after the specified head.\n * This is good for implementing stacks.\n */\nstatic inline void hlist_add_head(struct hlist_node *n, struct hlist_head *h)\n{\n\tstruct hlist_node *first = h->first;\n\tWRITE_ONCE(n->next, first);\n\tif (first)\n\t\tWRITE_ONCE(first->pprev, &n->next);\n\tWRITE_ONCE(h->first, n);\n\tWRITE_ONCE(n->pprev, &h->first);\n}\n\n/**\n * hlist_add_before - add a new entry before the one specified\n * @n: new entry to be added\n * @next: hlist node to add it before, which must be non-NULL\n */\nstatic inline void hlist_add_before(struct hlist_node *n,\n\t\t\t\t    struct hlist_node *next)\n{\n\tWRITE_ONCE(n->pprev, next->pprev);\n\tWRITE_ONCE(n->next, next);\n\tWRITE_ONCE(next->pprev, &n->next);\n\tWRITE_ONCE(*(n->pprev), n);\n}\n\n/**\n * hlist_add_behind - add a new entry after the one specified\n * @n: new entry to be added\n * @prev: hlist node to add it after, which must be non-NULL\n */\nstatic inline void hlist_add_behind(struct hlist_node *n,\n\t\t\t\t    struct hlist_node *prev)\n{\n\tWRITE_ONCE(n->next, prev->next);\n\tWRITE_ONCE(prev->next, n);\n\tWRITE_ONCE(n->pprev, &prev->next);\n\n\tif (n->next)\n\t\tWRITE_ONCE(n->next->pprev, &n->next);\n}\n\n/**\n * hlist_add_fake - create a fake hlist consisting of a single headless node\n * @n: Node to make a fake list out of\n *\n * This makes @n appear to be its own predecessor on a headless hlist.\n * The point of this is to allow things like hlist_del() to work correctly\n * in cases where there is no list.\n */\nstatic inline void hlist_add_fake(struct hlist_node *n)\n{\n\tn->pprev = &n->next;\n}\n\n/**\n * hlist_fake: Is this node a fake hlist?\n * @h: Node to check for being a self-referential fake hlist.\n */\nstatic inline bool hlist_fake(struct hlist_node *h)\n{\n\treturn h->pprev == &h->next;\n}\n\n/**\n * hlist_is_singular_node - is node the only element of the specified hlist?\n * @n: Node to check for singularity.\n * @h: Header for potentially singular list.\n *\n * Check whether the node is the only node of the head without\n * accessing head, thus avoiding unnecessary cache misses.\n */\nstatic inline bool\nhlist_is_singular_node(struct hlist_node *n, struct hlist_head *h)\n{\n\treturn !n->next && n->pprev == &h->first;\n}\n\n/**\n * hlist_move_list - Move an hlist\n * @old: hlist_head for old list.\n * @new: hlist_head for new list.\n *\n * Move a list from one list head to another. Fixup the pprev\n * reference of the first entry if it exists.\n */\nstatic inline void hlist_move_list(struct hlist_head *old,\n\t\t\t\t   struct hlist_head *new)\n{\n\tnew->first = old->first;\n\tif (new->first)\n\t\tnew->first->pprev = &new->first;\n\told->first = NULL;\n}\n\n#define hlist_entry(ptr, type, member) container_of(ptr,type,member)\n\n#define hlist_for_each(pos, head) \\\n\tfor (pos = (head)->first; pos ; pos = pos->next)\n\n#define hlist_for_each_safe(pos, n, head) \\\n\tfor (pos = (head)->first; pos && ({ n = pos->next; 1; }); \\\n\t     pos = n)\n\n#define hlist_entry_safe(ptr, type, member) \\\n\t({ typeof(ptr) ____ptr = (ptr); \\\n\t   ____ptr ? hlist_entry(____ptr, type, member) : NULL; \\\n\t})\n\n/**\n * hlist_for_each_entry\t- iterate over list of given type\n * @pos:\tthe type * to use as a loop cursor.\n * @head:\tthe head for your list.\n * @member:\tthe name of the hlist_node within the struct.\n */\n#define hlist_for_each_entry(pos, head, member)\t\t\t\t\\\n\tfor (pos = hlist_entry_safe((head)->first, typeof(*(pos)), member);\\\n\t     pos;\t\t\t\t\t\t\t\\\n\t     pos = hlist_entry_safe((pos)->member.next, typeof(*(pos)), member))\n\n/**\n * hlist_for_each_entry_continue - iterate over a hlist continuing after current point\n * @pos:\tthe type * to use as a loop cursor.\n * @member:\tthe name of the hlist_node within the struct.\n */\n#define hlist_for_each_entry_continue(pos, member)\t\t\t\\\n\tfor (pos = hlist_entry_safe((pos)->member.next, typeof(*(pos)), member);\\\n\t     pos;\t\t\t\t\t\t\t\\\n\t     pos = hlist_entry_safe((pos)->member.next, typeof(*(pos)), member))\n\n/**\n * hlist_for_each_entry_from - iterate over a hlist continuing from current point\n * @pos:\tthe type * to use as a loop cursor.\n * @member:\tthe name of the hlist_node within the struct.\n */\n#define hlist_for_each_entry_from(pos, member)\t\t\t\t\\\n\tfor (; pos;\t\t\t\t\t\t\t\\\n\t     pos = hlist_entry_safe((pos)->member.next, typeof(*(pos)), member))\n\n/**\n * hlist_for_each_entry_safe - iterate over list of given type safe against removal of list entry\n * @pos:\tthe type * to use as a loop cursor.\n * @n:\t\ta &struct hlist_node to use as temporary storage\n * @head:\tthe head for your list.\n * @member:\tthe name of the hlist_node within the struct.\n */\n#define hlist_for_each_entry_safe(pos, n, head, member) \t\t\\\n\tfor (pos = hlist_entry_safe((head)->first, typeof(*pos), member);\\\n\t     pos && ({ n = pos->member.next; 1; });\t\t\t\\\n\t     pos = hlist_entry_safe(n, typeof(*pos), member))\n\n#endif\n"}, "15": {"id": 15, "path": "/src/include/linux/stddef.h", "content": "/* SPDX-License-Identifier: GPL-2.0 */\n#ifndef _LINUX_STDDEF_H\n#define _LINUX_STDDEF_H\n\n#include <uapi/linux/stddef.h>\n\n#undef NULL\n#define NULL ((void *)0)\n\nenum {\n\tfalse\t= 0,\n\ttrue\t= 1\n};\n\n#undef offsetof\n#ifdef __compiler_offsetof\n#define offsetof(TYPE, MEMBER)\t__compiler_offsetof(TYPE, MEMBER)\n#else\n#define offsetof(TYPE, MEMBER)\t((size_t)&((TYPE *)0)->MEMBER)\n#endif\n\n/**\n * sizeof_field(TYPE, MEMBER)\n *\n * @TYPE: The structure containing the field of interest\n * @MEMBER: The field to return the size of\n */\n#define sizeof_field(TYPE, MEMBER) sizeof((((TYPE *)0)->MEMBER))\n\n/**\n * offsetofend(TYPE, MEMBER)\n *\n * @TYPE: The type of the structure\n * @MEMBER: The member within the structure to get the end offset of\n */\n#define offsetofend(TYPE, MEMBER) \\\n\t(offsetof(TYPE, MEMBER)\t+ sizeof_field(TYPE, MEMBER))\n\n#endif\n"}}, "reports": [{"events": [{"location": {"col": 3, "file": 1, "line": 512}, "message": "expanded from macro 'printk_ratelimited'"}, {"location": {"col": 11, "file": 0, "line": 612}, "message": "Calling 'sg_check_file_access'"}, {"location": {"col": 22, "file": 0, "line": 222}, "message": "Left side of '&&' is false"}, {"location": {"col": 2, "file": 2, "line": 306}, "message": "expanded from macro 'current_real_cred'"}, {"location": {"col": 2, "file": 3, "line": 563}, "message": "expanded from macro 'rcu_dereference_protected'"}, {"location": {"col": 2, "file": 3, "line": 382}, "message": "expanded from macro '__rcu_dereference_protected'"}, {"location": {"col": 48, "file": 3, "line": 346}, "message": "expanded from macro 'RCU_LOCKDEP_WARN'"}, {"location": {"col": 22, "file": 0, "line": 222}, "message": "Loop condition is false.  Exiting loop"}, {"location": {"col": 2, "file": 2, "line": 306}, "message": "expanded from macro 'current_real_cred'"}, {"location": {"col": 2, "file": 3, "line": 563}, "message": "expanded from macro 'rcu_dereference_protected'"}, {"location": {"col": 2, "file": 3, "line": 382}, "message": "expanded from macro '__rcu_dereference_protected'"}, {"location": {"col": 32, "file": 3, "line": 346}, "message": "expanded from macro 'RCU_LOCKDEP_WARN'"}, {"location": {"col": 6, "file": 0, "line": 222}, "message": "Assuming the condition is false"}, {"location": {"col": 2, "file": 0, "line": 222}, "message": "Taking false branch"}, {"location": {"col": 2, "file": 0, "line": 227}, "message": "Taking false branch"}, {"location": {"col": 2, "file": 0, "line": 232}, "message": "Returning zero, which participates in a condition later"}, {"location": {"col": 11, "file": 0, "line": 612}, "message": "Returning from 'sg_check_file_access'"}, {"location": {"col": 6, "file": 0, "line": 613}, "message": "'retval' is 0"}, {"location": {"col": 2, "file": 0, "line": 613}, "message": "Taking false branch"}, {"location": {"col": 9, "file": 0, "line": 616}, "message": "Assuming 'sfp' is non-null"}, {"location": {"col": 6, "file": 0, "line": 616}, "message": "Left side of '||' is false"}, {"location": {"col": 52, "file": 0, "line": 616}, "message": "Assuming 'sdp' is non-null"}, {"location": {"col": 2, "file": 0, "line": 616}, "message": "Taking false branch"}, {"location": {"col": 2, "file": 0, "line": 618}, "message": "Loop condition is false.  Exiting loop"}, {"location": {"col": 9, "file": 4, "line": 67}, "message": "expanded from macro 'SCSI_LOG_TIMEOUT'"}, {"location": {"col": 53, "file": 4, "line": 56}, "message": "expanded from macro 'SCSI_CHECK_LOGGING'"}, {"location": {"col": 6, "file": 0, "line": 620}, "message": "Assuming the condition is false"}, {"location": {"col": 21, "file": 5, "line": 30}, "message": "expanded from macro 'atomic_read'"}, {"location": {"col": 2, "file": 0, "line": 620}, "message": "Taking false branch"}, {"location": {"col": 9, "file": 0, "line": 622}, "message": "Assuming the condition is true"}, {"location": {"col": 37, "file": 0, "line": 622}, "message": "Left side of '||' is true"}, {"location": {"col": 2, "file": 0, "line": 622}, "message": "Taking false branch"}, {"location": {"col": 6, "file": 0, "line": 626}, "message": "Assuming the condition is false"}, {"location": {"col": 2, "file": 0, "line": 626}, "message": "Taking false branch"}, {"location": {"col": 6, "file": 0, "line": 628}, "message": "Calling 'copy_from_user'"}, {"location": {"col": 6, "file": 6, "line": 191}, "message": "Assuming the condition is false"}, {"location": {"col": 38, "file": 7, "line": 77}, "message": "expanded from macro 'likely'"}, {"location": {"col": 2, "file": 6, "line": 191}, "message": "Taking true branch"}, {"location": {"col": 2, "file": 6, "line": 193}, "message": "Returning value (loaded from 'n'), which participates in a condition later"}, {"location": {"col": 6, "file": 0, "line": 628}, "message": "Returning from 'copy_from_user'"}, {"location": {"col": 6, "file": 0, "line": 628}, "message": "Assuming the condition is false"}, {"location": {"col": 2, "file": 0, "line": 628}, "message": "Taking false branch"}, {"location": {"col": 6, "file": 0, "line": 631}, "message": "Assuming field 'reply_len' is >= 0"}, {"location": {"col": 2, "file": 0, "line": 631}, "message": "Taking false branch"}, {"location": {"col": 6, "file": 0, "line": 634}, "message": "Assuming the condition is false"}, {"location": {"col": 2, "file": 0, "line": 634}, "message": "Taking false branch"}, {"location": {"col": 6, "file": 0, "line": 638}, "message": "Assuming the condition is false"}, {"location": {"col": 25, "file": 8, "line": 155}, "message": "expanded from macro 'get_user'"}, {"location": {"col": 2, "file": 0, "line": 638}, "message": "Taking false branch"}, {"location": {"col": 8, "file": 0, "line": 641}, "message": "Assuming 'srp' is non-null"}, {"location": {"col": 2, "file": 0, "line": 641}, "message": "Taking false branch"}, {"location": {"col": 6, "file": 0, "line": 647}, "message": "Assuming field 'next_cmd_len' is <= 0"}, {"location": {"col": 2, "file": 0, "line": 647}, "message": "Taking false branch"}, {"location": {"col": 8, "file": 0, "line": 652}, "message": "Assuming 'opcode' is < 192"}, {"location": {"col": 24, "file": 0, "line": 652}, "message": "Left side of '&&' is false"}, {"location": {"col": 2, "file": 0, "line": 656}, "message": "Loop condition is false.  Exiting loop"}, {"location": {"col": 9, "file": 4, "line": 67}, "message": "expanded from macro 'SCSI_LOG_TIMEOUT'"}, {"location": {"col": 53, "file": 4, "line": 56}, "message": "expanded from macro 'SCSI_CHECK_LOGGING'"}, {"location": {"col": 12, "file": 0, "line": 660}, "message": "Assuming 'input_size' is > field 'reply_len'"}, {"location": {"col": 11, "file": 0, "line": 660}, "message": "'?' condition is true"}, {"location": {"col": 6, "file": 0, "line": 663}, "message": "'input_size' is >= 0"}, {"location": {"col": 2, "file": 0, "line": 663}, "message": "Taking false branch"}, {"location": {"col": 6, "file": 0, "line": 672}, "message": "Assuming 'input_size' is > 0"}, {"location": {"col": 2, "file": 0, "line": 672}, "message": "Taking true branch"}, {"location": {"col": 26, "file": 0, "line": 673}, "message": "Assuming the condition is true"}, {"location": {"col": 25, "file": 0, "line": 673}, "message": "'?' condition is true"}, {"location": {"col": 6, "file": 0, "line": 678}, "message": "Left side of '||' is false"}, {"location": {"col": 2, "file": 0, "line": 678}, "message": "Taking true branch"}, {"location": {"col": 6, "file": 0, "line": 688}, "message": "Calling 'copy_from_user'"}, {"location": {"col": 6, "file": 6, "line": 191}, "message": "Assuming the condition is true"}, {"location": {"col": 38, "file": 7, "line": 77}, "message": "expanded from macro 'likely'"}, {"location": {"col": 2, "file": 6, "line": 191}, "message": "Taking false branch"}, {"location": {"col": 2, "file": 6, "line": 193}, "message": "Returning without writing to '*to'"}, {"location": {"col": 2, "file": 6, "line": 193}, "message": "Returning value (loaded from 'n'), which participates in a condition later"}, {"location": {"col": 6, "file": 0, "line": 688}, "message": "Returning from 'copy_from_user'"}, {"location": {"col": 6, "file": 0, "line": 688}, "message": "Assuming the condition is false"}, {"location": {"col": 2, "file": 0, "line": 688}, "message": "Taking false branch"}, {"location": {"col": 2, "file": 0, "line": 697}, "message": "Taking true branch"}, {"location": {"col": 3, "file": 0, "line": 698}, "message": "Assuming the condition is true"}, {"location": {"col": 6, "file": 1, "line": 511}, "message": "expanded from macro 'printk_ratelimited'"}, {"location": {"col": 28, "file": 9, "line": 41}, "message": "expanded from macro '__ratelimit'"}, {"location": {"col": 3, "file": 0, "line": 698}, "message": "Taking true branch"}, {"location": {"col": 2, "file": 1, "line": 511}, "message": "expanded from macro 'printk_ratelimited'"}, {"location": {"col": 3, "file": 0, "line": 698}, "message": "4th function call argument is an uninitialized value"}, {"location": {"col": 3, "file": 1, "line": 512}, "message": "expanded from macro 'printk_ratelimited'"}, {"location": {"col": 3, "file": 0, "line": 698}, "message": "4th function call argument is an uninitialized value"}], "macros": [], "notes": [], "path": "/src/drivers/scsi/sg.c", "reportHash": "4139ddbf9eeb64b0b785fbbfc79ab7e3", "checkerName": "clang-analyzer-core.CallAndMessage", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 52, "file": 0, "line": 1232}, "message": "Although the value stored to 'sdp' is used in the enclosing expression, the value is never actually read from 'sdp'"}, {"location": {"col": 52, "file": 0, "line": 1232}, "message": "Although the value stored to 'sdp' is used in the enclosing expression, the value is never actually read from 'sdp'"}], "macros": [], "notes": [], "path": "/src/drivers/scsi/sg.c", "reportHash": "5f17d757efbc0f4ee2fea12c752f7dd3", "checkerName": "clang-analyzer-deadcode.DeadStores", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 22, "file": 0, "line": 2215}, "message": "Left side of '&&' is false"}, {"location": {"col": 61, "file": 10, "line": 709}, "message": "expanded from macro 'container_of'"}, {"location": {"col": 22, "file": 0, "line": 2215}, "message": "Taking false branch"}, {"location": {"col": 2, "file": 10, "line": 709}, "message": "expanded from macro 'container_of'"}, {"location": {"col": 37, "file": 11, "line": 39}, "message": "expanded from macro 'BUILD_BUG_ON_MSG'"}, {"location": {"col": 2, "file": 12, "line": 320}, "message": "expanded from macro 'compiletime_assert'"}, {"location": {"col": 2, "file": 12, "line": 308}, "message": "expanded from macro '_compiletime_assert'"}, {"location": {"col": 3, "file": 12, "line": 300}, "message": "expanded from macro '__compiletime_assert'"}, {"location": {"col": 22, "file": 0, "line": 2215}, "message": "Loop condition is false.  Exiting loop"}, {"location": {"col": 2, "file": 10, "line": 709}, "message": "expanded from macro 'container_of'"}, {"location": {"col": 37, "file": 11, "line": 39}, "message": "expanded from macro 'BUILD_BUG_ON_MSG'"}, {"location": {"col": 2, "file": 12, "line": 320}, "message": "expanded from macro 'compiletime_assert'"}, {"location": {"col": 2, "file": 12, "line": 308}, "message": "expanded from macro '_compiletime_assert'"}, {"location": {"col": 2, "file": 12, "line": 298}, "message": "expanded from macro '__compiletime_assert'"}, {"location": {"col": 2, "file": 0, "line": 2221}, "message": "Loop condition is false.  Exiting loop"}, {"location": {"col": 2, "file": 13, "line": 81}, "message": "expanded from macro 'write_lock_irqsave'"}, {"location": {"col": 2, "file": 0, "line": 2222}, "message": "Loop condition is true.  Entering loop body"}, {"location": {"col": 9, "file": 0, "line": 2223}, "message": "Left side of '&&' is false"}, {"location": {"col": 2, "file": 14, "line": 522}, "message": "expanded from macro 'list_first_entry'"}, {"location": {"col": 2, "file": 14, "line": 511}, "message": "expanded from macro 'list_entry'"}, {"location": {"col": 61, "file": 10, "line": 709}, "message": "expanded from macro 'container_of'"}, {"location": {"col": 9, "file": 0, "line": 2223}, "message": "Taking false branch"}, {"location": {"col": 2, "file": 14, "line": 522}, "message": "expanded from macro 'list_first_entry'"}, {"location": {"col": 2, "file": 14, "line": 511}, "message": "expanded from macro 'list_entry'"}, {"location": {"col": 2, "file": 10, "line": 709}, "message": "expanded from macro 'container_of'"}, {"location": {"col": 18, "file": 0, "line": 2091}, "message": "Access to field 'res_in_use' results in a dereference of a null pointer (loaded from variable 'sfp')"}], "macros": [], "notes": [], "path": "/src/drivers/scsi/sg.c", "reportHash": "2044b565c222d256345de41f1926203d", "checkerName": "clang-analyzer-core.NullDereference", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 6, "file": 0, "line": 2602}, "message": "Assuming 'it' is non-null"}, {"location": {"col": 6, "file": 0, "line": 2602}, "message": "Left side of '&&' is true"}, {"location": {"col": 13, "file": 0, "line": 2602}, "message": "Assuming 0 is not equal to field 'index'"}, {"location": {"col": 2, "file": 0, "line": 2602}, "message": "Taking false branch"}, {"location": {"col": 2, "file": 0, "line": 2606}, "message": "Loop condition is false.  Exiting loop"}, {"location": {"col": 2, "file": 13, "line": 76}, "message": "expanded from macro 'read_lock_irqsave'"}, {"location": {"col": 8, "file": 0, "line": 2607}, "message": "'it' is non-null"}, {"location": {"col": 8, "file": 0, "line": 2607}, "message": "'?' condition is true"}, {"location": {"col": 6, "file": 0, "line": 2608}, "message": "Assuming 'sdp' is not equal to NULL"}, {"location": {"col": 14, "file": 15, "line": 8}, "message": "expanded from macro 'NULL'"}, {"location": {"col": 2, "file": 0, "line": 2608}, "message": "Taking false branch"}, {"location": {"col": 2, "file": 0, "line": 2610}, "message": "Value assigned to field 'device'"}, {"location": {"col": 26, "file": 13, "line": 71}, "message": "expanded from macro 'read_lock'"}, {"location": {"col": 6, "file": 0, "line": 2611}, "message": "Assuming the condition is true"}, {"location": {"col": 2, "file": 0, "line": 2611}, "message": "Taking true branch"}, {"location": {"col": 7, "file": 0, "line": 2613}, "message": "Assuming the condition is false"}, {"location": {"col": 21, "file": 5, "line": 30}, "message": "expanded from macro 'atomic_read'"}, {"location": {"col": 3, "file": 0, "line": 2613}, "message": "Taking false branch"}, {"location": {"col": 12, "file": 0, "line": 2615}, "message": "Assuming field 'device' is null"}, {"location": {"col": 8, "file": 0, "line": 2615}, "message": "Taking false branch"}, {"location": {"col": 3, "file": 0, "line": 2626}, "message": "Calling 'sg_proc_debug_helper'"}, {"location": {"col": 2, "file": 0, "line": 2543}, "message": "Left side of '&&' is false"}, {"location": {"col": 13, "file": 14, "line": 628}, "message": "expanded from macro 'list_for_each_entry'"}, {"location": {"col": 2, "file": 14, "line": 522}, "message": "expanded from macro 'list_first_entry'"}, {"location": {"col": 2, "file": 14, "line": 511}, "message": "expanded from macro 'list_entry'"}, {"location": {"col": 61, "file": 10, "line": 709}, "message": "expanded from macro 'container_of'"}, {"location": {"col": 2, "file": 0, "line": 2543}, "message": "Taking false branch"}, {"location": {"col": 13, "file": 14, "line": 628}, "message": "expanded from macro 'list_for_each_entry'"}, {"location": {"col": 2, "file": 14, "line": 522}, "message": "expanded from macro 'list_first_entry'"}, {"location": {"col": 2, "file": 14, "line": 511}, "message": "expanded from macro 'list_entry'"}, {"location": {"col": 13, "file": 0, "line": 2551}, "message": "Access to field 'host' results in a dereference of a null pointer (loaded from field 'device')"}], "macros": [], "notes": [], "path": "/src/drivers/scsi/sg.c", "reportHash": "65d41eae6d9a879123cf07f2716985c6", "checkerName": "clang-analyzer-core.NullDereference", "reviewStatus": null, "severity": "UNSPECIFIED"}]};
      window.onload = function() {
        if (!browserCompatible) {
          setNonCompatibleBrowserMessage();
        } else {
          BugViewer.init(data.files, data.reports);
          BugViewer.create();
          BugViewer.initByUrl();
        }
      };
    </script>
  </head>
  <body>
  <div class="container">
    <div id="content">
      <div id="side-bar">
        <div class="header">
          <a href="index.html" class="button">&#8249; Return to List</a>
        </div>
        <div id="report-nav">
          <div class="header">Reports</div>
        </div>
      </div>
      <div id="editor-wrapper">
        <div class="header">
          <div id="file">
            <span class="label">File:</span>
            <span id="file-path"></span>
          </div>
          <div id="checker">
            <span class="label">Checker name:</span>
            <span id="checker-name"></span>
          </div>
          <div id="review-status-wrapper">
            <span class="label">Review status:</span>
            <span id="review-status"></span>
          </div>
        </div>
        <div id="editor"></div>
      </div>
    </div>
  </div>
  </body>
</html>
