<!DOCTYPE html>
<html>
  <head>
    <title>Plist HTML Viewer</title>

    <meta charset="UTF-8">

    <style type="text/css">
      .CodeMirror{font-family:monospace;height:300px;color:#000;direction:ltr}.CodeMirror-lines{padding:4px 0}.CodeMirror pre{padding:0 4px}.CodeMirror-gutter-filler,.CodeMirror-scrollbar-filler{background-color:#fff}.CodeMirror-gutters{border-right:1px solid #ddd;background-color:#f7f7f7;white-space:nowrap}.CodeMirror-linenumber{padding:0 3px 0 5px;min-width:20px;text-align:right;color:#999;white-space:nowrap}.CodeMirror-guttermarker{color:#000}.CodeMirror-guttermarker-subtle{color:#999}.CodeMirror-cursor{border-left:1px solid #000;border-right:none;width:0}.CodeMirror div.CodeMirror-secondarycursor{border-left:1px solid silver}.cm-fat-cursor .CodeMirror-cursor{width:auto;border:0!important;background:#7e7}.cm-fat-cursor div.CodeMirror-cursors{z-index:1}.cm-animate-fat-cursor{width:auto;border:0;-webkit-animation:blink 1.06s steps(1) infinite;-moz-animation:blink 1.06s steps(1) infinite;animation:blink 1.06s steps(1) infinite;background-color:#7e7}@-moz-keyframes blink{50%{background-color:transparent}}@-webkit-keyframes blink{50%{background-color:transparent}}@keyframes blink{50%{background-color:transparent}}.cm-tab{display:inline-block;text-decoration:inherit}.CodeMirror-rulers{position:absolute;left:0;right:0;top:-50px;bottom:-20px;overflow:hidden}.CodeMirror-ruler{border-left:1px solid #ccc;top:0;bottom:0;position:absolute}.cm-s-default .cm-header{color:#00f}.cm-s-default .cm-quote{color:#090}.cm-negative{color:#d44}.cm-positive{color:#292}.cm-header,.cm-strong{font-weight:700}.cm-em{font-style:italic}.cm-link{text-decoration:underline}.cm-strikethrough{text-decoration:line-through}.cm-s-default .cm-keyword{color:#708}.cm-s-default .cm-atom{color:#219}.cm-s-default .cm-number{color:#164}.cm-s-default .cm-def{color:#00f}.cm-s-default .cm-variable-2{color:#05a}.cm-s-default .cm-type,.cm-s-default .cm-variable-3{color:#085}.cm-s-default .cm-comment{color:#a50}.cm-s-default .cm-string{color:#a11}.cm-s-default .cm-string-2{color:#f50}.cm-s-default .cm-meta{color:#555}.cm-s-default .cm-qualifier{color:#555}.cm-s-default .cm-builtin{color:#30a}.cm-s-default .cm-bracket{color:#997}.cm-s-default .cm-tag{color:#170}.cm-s-default .cm-attribute{color:#00c}.cm-s-default .cm-hr{color:#999}.cm-s-default .cm-link{color:#00c}.cm-s-default .cm-error{color:red}.cm-invalidchar{color:red}.CodeMirror-composing{border-bottom:2px solid}div.CodeMirror span.CodeMirror-matchingbracket{color:#0f0}div.CodeMirror span.CodeMirror-nonmatchingbracket{color:#f22}.CodeMirror-matchingtag{background:rgba(255,150,0,.3)}.CodeMirror-activeline-background{background:#e8f2ff}.CodeMirror{position:relative;overflow:hidden;background:#fff}.CodeMirror-scroll{overflow:scroll!important;margin-bottom:-30px;margin-right:-30px;padding-bottom:30px;height:100%;outline:0;position:relative}.CodeMirror-sizer{position:relative;border-right:30px solid transparent}.CodeMirror-gutter-filler,.CodeMirror-hscrollbar,.CodeMirror-scrollbar-filler,.CodeMirror-vscrollbar{position:absolute;z-index:6;display:none}.CodeMirror-vscrollbar{right:0;top:0;overflow-x:hidden;overflow-y:scroll}.CodeMirror-hscrollbar{bottom:0;left:0;overflow-y:hidden;overflow-x:scroll}.CodeMirror-scrollbar-filler{right:0;bottom:0}.CodeMirror-gutter-filler{left:0;bottom:0}.CodeMirror-gutters{position:absolute;left:0;top:0;min-height:100%;z-index:3}.CodeMirror-gutter{white-space:normal;height:100%;display:inline-block;vertical-align:top;margin-bottom:-30px}.CodeMirror-gutter-wrapper{position:absolute;z-index:4;background:0 0!important;border:none!important}.CodeMirror-gutter-background{position:absolute;top:0;bottom:0;z-index:4}.CodeMirror-gutter-elt{position:absolute;cursor:default;z-index:4}.CodeMirror-gutter-wrapper ::selection{background-color:transparent}.CodeMirror-gutter-wrapper ::-moz-selection{background-color:transparent}.CodeMirror-lines{cursor:text;min-height:1px}.CodeMirror pre{-moz-border-radius:0;-webkit-border-radius:0;border-radius:0;border-width:0;background:0 0;font-family:inherit;font-size:inherit;margin:0;white-space:pre;word-wrap:normal;line-height:inherit;color:inherit;z-index:2;position:relative;overflow:visible;-webkit-tap-highlight-color:transparent;-webkit-font-variant-ligatures:contextual;font-variant-ligatures:contextual}.CodeMirror-wrap pre{word-wrap:break-word;white-space:pre-wrap;word-break:normal}.CodeMirror-linebackground{position:absolute;left:0;right:0;top:0;bottom:0;z-index:0}.CodeMirror-linewidget{position:relative;z-index:2;overflow:auto}.CodeMirror-rtl pre{direction:rtl}.CodeMirror-code{outline:0}.CodeMirror-gutter,.CodeMirror-gutters,.CodeMirror-linenumber,.CodeMirror-scroll,.CodeMirror-sizer{-moz-box-sizing:content-box;box-sizing:content-box}.CodeMirror-measure{position:absolute;width:100%;height:0;overflow:hidden;visibility:hidden}.CodeMirror-cursor{position:absolute;pointer-events:none}.CodeMirror-measure pre{position:static}div.CodeMirror-cursors{visibility:hidden;position:relative;z-index:3}div.CodeMirror-dragcursors{visibility:visible}.CodeMirror-focused div.CodeMirror-cursors{visibility:visible}.CodeMirror-selected{background:#d9d9d9}.CodeMirror-focused .CodeMirror-selected{background:#d7d4f0}.CodeMirror-crosshair{cursor:crosshair}.CodeMirror-line::selection,.CodeMirror-line>span::selection,.CodeMirror-line>span>span::selection{background:#d7d4f0}.CodeMirror-line::-moz-selection,.CodeMirror-line>span::-moz-selection,.CodeMirror-line>span>span::-moz-selection{background:#d7d4f0}.cm-searching{background-color:#ffa;background-color:rgba(255,255,0,.4)}.cm-force-border{padding-right:.1px}@media print{.CodeMirror div.CodeMirror-cursors{visibility:hidden}}.cm-tab-wrap-hack:after{content:''}span.CodeMirror-selectedtext{background:0 0}
/*# sourceMappingURL=codemirror.min.css.map */

      .severity-low {
  background-color: #669603;
}

.severity-low:after {
  content : 'L';
}

.severity-unspecified {
  background-color: #666666;
}

.severity-unspecified:after {
  content : 'U';
}

.severity-style {
  background-color: #9932cc;
}

.severity-style:after {
  content : 'S';
}

.severity-medium {
  background-color: #a9d323;
  color: black;
}

.severity-medium:after {
  content : 'M';
}

.severity-high {
  background-color: #ffa800;
}

.severity-high:after {
  content : 'H';
}

.severity-critical {
  background-color: #e92625;
}

.severity-critical:after {
  content : 'C';
}

i[class*="severity-"] {
  line-height: normal;
  text-transform: capitalize;
  font-size: 0.8em;
  font-weight: bold;
  color: white;
  display: inline-block;
  width: 16px;
  height: 16px;
  text-align: center;
  font-family: sans-serif;
}

      html, body {
  width: 100%;
  height: 100%;
  padding: 0px;
  margin: 0px;
}

div.container {
  padding: 10px;
}

#content {
  height: 100%;
  display: block;
  overflow: hidden;
}

#content > div {
  margin: 10px;
  overflow: hidden;
  border: 1px solid #ddd;
  border-radius: 3px;
  overflow: hidden;
  height: 97%;
}

.button {
  background-color: #f1f1f1;
  text-decoration: none;
  display: inline-block;
  padding: 8px 16px;
  color: black;
  cursor: pointer;
}

.button:hover {
  background-color: #ddd;
  color: black;
}

.review-status {
  color: white;
  text-align: center;
}

.review-status-confirmed {
  background-color: #e92625;
}

.review-status-false-positive {
  background-color: grey;
}

.review-status-intentional {
  background-color: #669603;
}

      div.container {
  width: 100%;
  height: 100%;
  padding: 0px;
}

#editor-wrapper {
  margin: 10px;
}

#side-bar {
  float: left;
  width: 260px;
  margin: 0px;
}

#report-nav ul {
  list-style-type: none;
  padding: 0;
  margin: 0;
  overflow-y: auto;
  height: 100%;
}

#report-nav ul > li {
  padding: .4em;
  background-color: #fff;
  border-bottom: 1px solid rgba(0,0,0,.125);
  text-align: left;
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

#report-nav ul > li.active {
  background-color: #427ea9;
  color: white;
}

#report-nav ul > li:hover {
  background-color: #427ea9;
  color: white;
  cursor: pointer;
}

#report-nav ul a {
  text-decoration: none;
}

#report-nav i[class*="severity-"] {
  margin-right: 5px;
}

.header {
  border-bottom: 1px solid lightgrey;
  font-family: monospace;
  padding: 10px;
  background-color: #fafbfc;
  border-bottom: 1px solid #e1e4e8;
  border-top-left-radius: 2px;
  border-top-right-radius: 2px;
}

#report-nav .header {
  font-weight: bold;
}

#editor-wrapper .header > div {
  padding-top: 2px;
}

#file-path,
#checker-name {
  color: #195ea2;
}

#review-status {
  padding: 0px 5px;
}

#file-path {
  font-family: monospace;
}

.check-msg {
  display: inline-block;
  padding: 3px 6px;
  margin: 1px;
  -webkit-border-radius: 5px;
  -moz-border-radius: 5px;
  border-radius: 5px;
}

.check-msg.info {
  color: #00546f;
  background-color: #bfdfe9;
  border: 1px solid #87a8b3;
}

.check-msg.error {
  background-color: #f2dede;
  color: #a94442;
  border: 1px solid #ebcccc;
}

.check-msg.macro {
  background-color: #d7dac2;
  color: #4f5c6d;
  border: 1px solid #d7dac2;
}

.check-msg.note {
  background-color: #d7d7d7;
  color: #4f5c6d;
  border: 1px solid #bfbfbf;
}

.check-msg.current {
  border: 2px dashed #3692ff;
}

.check-msg .tag {
  padding: 1px 5px;
  text-align: center;
  border-radius: 2px;
  margin-right: 5px;
  text-decoration: inherit;
}

.check-msg .tag.macro {
  background-color: #83876a;
  color: white;
  text-transform: capitalize;
}

.check-msg .tag.note {
  background-color: #9299a1;
  color: white;
  text-transform: capitalize;
}

.checker-enum {
  color: white;
  padding: 1px 5px;
  text-align: center;
  border-radius: 25px;
  margin-right: 5px;
  text-decoration: inherit;
}

.checker-enum.info {
  background-color: #427ea9;
}

.checker-enum.error {
  background-color: #a94442;
}

.arrow {
  border: solid black;
  border-width: 0 3px 3px 0;
  display: inline-block;
  padding: 3px;
  cursor: pointer;
  margin: 0px 5px;
}

.arrow:hover {
  border: solid #437ea8;
  border-width: 0 3px 3px 0;
}

.left-arrow {
  transform: rotate(135deg);
  -webkit-transform: rotate(135deg);
}

.right-arrow {
  transform: rotate(-45deg);
  -webkit-transform: rotate(-45deg);
}

    </style>

    <script type="text/javascript">
      function setNonCompatibleBrowserMessage() {
  document.body.innerHTML =
    '<h2 style="margin-left: 20px;">Your browser is not compatible with CodeChecker Viewer!</h2> \
     <p style="margin-left: 20px;">The version required for the following browsers are:</p> \
     <ul style="margin-left: 20px;"> \
     <li>Internet Explorer: version 9 or newer</li> \
     <li>Firefox: version 22.0 or newer</li> \
     </ul>';
}

// http://stackoverflow.com/questions/5916900/how-can-you-detect-the-version-of-a-browser
var browserVersion = (function(){
  var ua = navigator.userAgent, tem,
    M = ua.match(/(opera|chrome|safari|firefox|msie|trident(?=\/))\/?\s*(\d+)/i) || [];

  if (/trident/i.test(M[1])) {
    tem = /\brv[ :]+(\d+)/g.exec(ua) || [];
    return 'IE ' + (tem[1] || '');
  }

  if (M[1] === 'Chrome') {
    tem = ua.match(/\b(OPR|Edge)\/(\d+)/);
    if (tem != null) return tem.slice(1).join(' ').replace('OPR', 'Opera');
  }

  M = M[2] ? [M[1], M[2]] : [navigator.appName, navigator.appVersion, '-?'];
  if ((tem = ua.match(/version\/(\d+)/i)) != null) M.splice(1, 1, tem[1]);
    return M.join(' ');
})();

var pos = browserVersion.indexOf(' ');
var browser = browserVersion.substr(0, pos);
var version = parseInt(browserVersion.substr(pos + 1));

var browserCompatible
  = browser === 'Firefox'
  ? version >= 22
  : browser === 'IE'
  ? version >= 9
  : true;


      /* MIT License

Copyright (C) 2017 by Marijn Haverbeke <marijnh@gmail.com> and others

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
 */
      !function(e,t){"object"==typeof exports&&"undefined"!=typeof module?module.exports=t():"function"==typeof define&&define.amd?define(t):e.CodeMirror=t()}(this,function(){"use strict";function e(e){return new RegExp("(^|\\s)"+e+"(?:$|\\s)\\s*")}function t(e){for(var t=e.childNodes.length;t>0;--t)e.removeChild(e.firstChild);return e}function r(e,r){return t(e).appendChild(r)}function n(e,t,r,n){var i=document.createElement(e);if(r&&(i.className=r),n&&(i.style.cssText=n),"string"==typeof t)i.appendChild(document.createTextNode(t));else if(t)for(var o=0;o<t.length;++o)i.appendChild(t[o]);return i}function i(e,t,r,i){var o=n(e,t,r,i);return o.setAttribute("role","presentation"),o}function o(e,t){if(3==t.nodeType&&(t=t.parentNode),e.contains)return e.contains(t);do{if(11==t.nodeType&&(t=t.host),t==e)return!0}while(t=t.parentNode)}function l(){var e;try{e=document.activeElement}catch(t){e=document.body||null}for(;e&&e.shadowRoot&&e.shadowRoot.activeElement;)e=e.shadowRoot.activeElement;return e}function s(t,r){var n=t.className;e(r).test(n)||(t.className+=(n?" ":"")+r)}function a(t,r){for(var n=t.split(" "),i=0;i<n.length;i++)n[i]&&!e(n[i]).test(r)&&(r+=" "+n[i]);return r}function u(e){var t=Array.prototype.slice.call(arguments,1);return function(){return e.apply(null,t)}}function c(e,t,r){t||(t={});for(var n in e)!e.hasOwnProperty(n)||!1===r&&t.hasOwnProperty(n)||(t[n]=e[n]);return t}function f(e,t,r,n,i){null==t&&-1==(t=e.search(/[^\s\u00a0]/))&&(t=e.length);for(var o=n||0,l=i||0;;){var s=e.indexOf("\t",o);if(s<0||s>=t)return l+(t-o);l+=s-o,l+=r-l%r,o=s+1}}function h(e,t){for(var r=0;r<e.length;++r)if(e[r]==t)return r;return-1}function d(e,t,r){for(var n=0,i=0;;){var o=e.indexOf("\t",n);-1==o&&(o=e.length);var l=o-n;if(o==e.length||i+l>=t)return n+Math.min(l,t-i);if(i+=o-n,i+=r-i%r,n=o+1,i>=t)return n}}function p(e){for(;Kl.length<=e;)Kl.push(g(Kl)+" ");return Kl[e]}function g(e){return e[e.length-1]}function v(e,t){for(var r=[],n=0;n<e.length;n++)r[n]=t(e[n],n);return r}function m(e,t,r){for(var n=0,i=r(t);n<e.length&&r(e[n])<=i;)n++;e.splice(n,0,t)}function y(){}function b(e,t){var r;return Object.create?r=Object.create(e):(y.prototype=e,r=new y),t&&c(t,r),r}function w(e){return/\w/.test(e)||e>""&&(e.toUpperCase()!=e.toLowerCase()||jl.test(e))}function x(e,t){return t?!!(t.source.indexOf("\\w")>-1&&w(e))||t.test(e):w(e)}function C(e){for(var t in e)if(e.hasOwnProperty(t)&&e[t])return!1;return!0}function S(e){return e.charCodeAt(0)>=768&&Xl.test(e)}function L(e,t,r){for(;(r<0?t>0:t<e.length)&&S(e.charAt(t));)t+=r;return t}function k(e,t,r){for(var n=t>r?-1:1;;){if(t==r)return t;var i=(t+r)/2,o=n<0?Math.ceil(i):Math.floor(i);if(o==t)return e(o)?t:r;e(o)?r=o:t=o+n}}function T(e,t,r){var o=this;this.input=r,o.scrollbarFiller=n("div",null,"CodeMirror-scrollbar-filler"),o.scrollbarFiller.setAttribute("cm-not-content","true"),o.gutterFiller=n("div",null,"CodeMirror-gutter-filler"),o.gutterFiller.setAttribute("cm-not-content","true"),o.lineDiv=i("div",null,"CodeMirror-code"),o.selectionDiv=n("div",null,null,"position: relative; z-index: 1"),o.cursorDiv=n("div",null,"CodeMirror-cursors"),o.measure=n("div",null,"CodeMirror-measure"),o.lineMeasure=n("div",null,"CodeMirror-measure"),o.lineSpace=i("div",[o.measure,o.lineMeasure,o.selectionDiv,o.cursorDiv,o.lineDiv],null,"position: relative; outline: none");var l=i("div",[o.lineSpace],"CodeMirror-lines");o.mover=n("div",[l],null,"position: relative"),o.sizer=n("div",[o.mover],"CodeMirror-sizer"),o.sizerWidth=null,o.heightForcer=n("div",null,null,"position: absolute; height: "+Rl+"px; width: 1px;"),o.gutters=n("div",null,"CodeMirror-gutters"),o.lineGutter=null,o.scroller=n("div",[o.sizer,o.heightForcer,o.gutters],"CodeMirror-scroll"),o.scroller.setAttribute("tabIndex","-1"),o.wrapper=n("div",[o.scrollbarFiller,o.gutterFiller,o.scroller],"CodeMirror"),gl&&vl<8&&(o.gutters.style.zIndex=-1,o.scroller.style.paddingRight=0),ml||fl&&Tl||(o.scroller.draggable=!0),e&&(e.appendChild?e.appendChild(o.wrapper):e(o.wrapper)),o.viewFrom=o.viewTo=t.first,o.reportedViewFrom=o.reportedViewTo=t.first,o.view=[],o.renderedView=null,o.externalMeasured=null,o.viewOffset=0,o.lastWrapHeight=o.lastWrapWidth=0,o.updateLineNumbers=null,o.nativeBarWidth=o.barHeight=o.barWidth=0,o.scrollbarsClipped=!1,o.lineNumWidth=o.lineNumInnerWidth=o.lineNumChars=null,o.alignWidgets=!1,o.cachedCharWidth=o.cachedTextHeight=o.cachedPaddingH=null,o.maxLine=null,o.maxLineLength=0,o.maxLineChanged=!1,o.wheelDX=o.wheelDY=o.wheelStartX=o.wheelStartY=null,o.shift=!1,o.selForContextMenu=null,o.activeTouch=null,r.init(o)}function M(e,t){if((t-=e.first)<0||t>=e.size)throw new Error("There is no line "+(t+e.first)+" in the document.");for(var r=e;!r.lines;)for(var n=0;;++n){var i=r.children[n],o=i.chunkSize();if(t<o){r=i;break}t-=o}return r.lines[t]}function N(e,t,r){var n=[],i=t.line;return e.iter(t.line,r.line+1,function(e){var o=e.text;i==r.line&&(o=o.slice(0,r.ch)),i==t.line&&(o=o.slice(t.ch)),n.push(o),++i}),n}function O(e,t,r){var n=[];return e.iter(t,r,function(e){n.push(e.text)}),n}function A(e,t){var r=t-e.height;if(r)for(var n=e;n;n=n.parent)n.height+=r}function W(e){if(null==e.parent)return null;for(var t=e.parent,r=h(t.lines,e),n=t.parent;n;t=n,n=n.parent)for(var i=0;n.children[i]!=t;++i)r+=n.children[i].chunkSize();return r+t.first}function D(e,t){var r=e.first;e:do{for(var n=0;n<e.children.length;++n){var i=e.children[n],o=i.height;if(t<o){e=i;continue e}t-=o,r+=i.chunkSize()}return r}while(!e.lines);for(var l=0;l<e.lines.length;++l){var s=e.lines[l].height;if(t<s)break;t-=s}return r+l}function H(e,t){return t>=e.first&&t<e.first+e.size}function F(e,t){return String(e.lineNumberFormatter(t+e.firstLineNumber))}function E(e,t,r){if(void 0===r&&(r=null),!(this instanceof E))return new E(e,t,r);this.line=e,this.ch=t,this.sticky=r}function P(e,t){return e.line-t.line||e.ch-t.ch}function I(e,t){return e.sticky==t.sticky&&0==P(e,t)}function z(e){return E(e.line,e.ch)}function R(e,t){return P(e,t)<0?t:e}function B(e,t){return P(e,t)<0?e:t}function G(e,t){return Math.max(e.first,Math.min(t,e.first+e.size-1))}function U(e,t){if(t.line<e.first)return E(e.first,0);var r=e.first+e.size-1;return t.line>r?E(r,M(e,r).text.length):V(t,M(e,t.line).text.length)}function V(e,t){var r=e.ch;return null==r||r>t?E(e.line,t):r<0?E(e.line,0):e}function K(e,t){for(var r=[],n=0;n<t.length;n++)r[n]=U(e,t[n]);return r}function j(){Yl=!0}function X(){_l=!0}function Y(e,t,r){this.marker=e,this.from=t,this.to=r}function _(e,t){if(e)for(var r=0;r<e.length;++r){var n=e[r];if(n.marker==t)return n}}function $(e,t){for(var r,n=0;n<e.length;++n)e[n]!=t&&(r||(r=[])).push(e[n]);return r}function q(e,t){e.markedSpans=e.markedSpans?e.markedSpans.concat([t]):[t],t.marker.attachLine(e)}function Z(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t)||o.from==t&&"bookmark"==l.type&&(!r||!o.marker.insertLeft)){var s=null==o.to||(l.inclusiveRight?o.to>=t:o.to>t);(n||(n=[])).push(new Y(l,o.from,s?null:o.to))}}return n}function Q(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.to||(l.inclusiveRight?o.to>=t:o.to>t)||o.from==t&&"bookmark"==l.type&&(!r||o.marker.insertLeft)){var s=null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t);(n||(n=[])).push(new Y(l,s?null:o.from-t,null==o.to?null:o.to-t))}}return n}function J(e,t){if(t.full)return null;var r=H(e,t.from.line)&&M(e,t.from.line).markedSpans,n=H(e,t.to.line)&&M(e,t.to.line).markedSpans;if(!r&&!n)return null;var i=t.from.ch,o=t.to.ch,l=0==P(t.from,t.to),s=Z(r,i,l),a=Q(n,o,l),u=1==t.text.length,c=g(t.text).length+(u?i:0);if(s)for(var f=0;f<s.length;++f){var h=s[f];if(null==h.to){var d=_(a,h.marker);d?u&&(h.to=null==d.to?null:d.to+c):h.to=i}}if(a)for(var p=0;p<a.length;++p){var v=a[p];null!=v.to&&(v.to+=c),null==v.from?_(s,v.marker)||(v.from=c,u&&(s||(s=[])).push(v)):(v.from+=c,u&&(s||(s=[])).push(v))}s&&(s=ee(s)),a&&a!=s&&(a=ee(a));var m=[s];if(!u){var y,b=t.text.length-2;if(b>0&&s)for(var w=0;w<s.length;++w)null==s[w].to&&(y||(y=[])).push(new Y(s[w].marker,null,null));for(var x=0;x<b;++x)m.push(y);m.push(a)}return m}function ee(e){for(var t=0;t<e.length;++t){var r=e[t];null!=r.from&&r.from==r.to&&!1!==r.marker.clearWhenEmpty&&e.splice(t--,1)}return e.length?e:null}function te(e,t,r){var n=null;if(e.iter(t.line,r.line+1,function(e){if(e.markedSpans)for(var t=0;t<e.markedSpans.length;++t){var r=e.markedSpans[t].marker;!r.readOnly||n&&-1!=h(n,r)||(n||(n=[])).push(r)}}),!n)return null;for(var i=[{from:t,to:r}],o=0;o<n.length;++o)for(var l=n[o],s=l.find(0),a=0;a<i.length;++a){var u=i[a];if(!(P(u.to,s.from)<0||P(u.from,s.to)>0)){var c=[a,1],f=P(u.from,s.from),d=P(u.to,s.to);(f<0||!l.inclusiveLeft&&!f)&&c.push({from:u.from,to:s.from}),(d>0||!l.inclusiveRight&&!d)&&c.push({from:s.to,to:u.to}),i.splice.apply(i,c),a+=c.length-3}}return i}function re(e){var t=e.markedSpans;if(t){for(var r=0;r<t.length;++r)t[r].marker.detachLine(e);e.markedSpans=null}}function ne(e,t){if(t){for(var r=0;r<t.length;++r)t[r].marker.attachLine(e);e.markedSpans=t}}function ie(e){return e.inclusiveLeft?-1:0}function oe(e){return e.inclusiveRight?1:0}function le(e,t){var r=e.lines.length-t.lines.length;if(0!=r)return r;var n=e.find(),i=t.find(),o=P(n.from,i.from)||ie(e)-ie(t);if(o)return-o;var l=P(n.to,i.to)||oe(e)-oe(t);return l||t.id-e.id}function se(e,t){var r,n=_l&&e.markedSpans;if(n)for(var i=void 0,o=0;o<n.length;++o)(i=n[o]).marker.collapsed&&null==(t?i.from:i.to)&&(!r||le(r,i.marker)<0)&&(r=i.marker);return r}function ae(e){return se(e,!0)}function ue(e){return se(e,!1)}function ce(e,t,r,n,i){var o=M(e,t),l=_l&&o.markedSpans;if(l)for(var s=0;s<l.length;++s){var a=l[s];if(a.marker.collapsed){var u=a.marker.find(0),c=P(u.from,r)||ie(a.marker)-ie(i),f=P(u.to,n)||oe(a.marker)-oe(i);if(!(c>=0&&f<=0||c<=0&&f>=0)&&(c<=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.to,r)>=0:P(u.to,r)>0)||c>=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.from,n)<=0:P(u.from,n)<0)))return!0}}}function fe(e){for(var t;t=ae(e);)e=t.find(-1,!0).line;return e}function he(e){for(var t;t=ue(e);)e=t.find(1,!0).line;return e}function de(e){for(var t,r;t=ue(e);)e=t.find(1,!0).line,(r||(r=[])).push(e);return r}function pe(e,t){var r=M(e,t),n=fe(r);return r==n?t:W(n)}function ge(e,t){if(t>e.lastLine())return t;var r,n=M(e,t);if(!ve(e,n))return t;for(;r=ue(n);)n=r.find(1,!0).line;return W(n)+1}function ve(e,t){var r=_l&&t.markedSpans;if(r)for(var n=void 0,i=0;i<r.length;++i)if((n=r[i]).marker.collapsed){if(null==n.from)return!0;if(!n.marker.widgetNode&&0==n.from&&n.marker.inclusiveLeft&&me(e,t,n))return!0}}function me(e,t,r){if(null==r.to){var n=r.marker.find(1,!0);return me(e,n.line,_(n.line.markedSpans,r.marker))}if(r.marker.inclusiveRight&&r.to==t.text.length)return!0;for(var i=void 0,o=0;o<t.markedSpans.length;++o)if((i=t.markedSpans[o]).marker.collapsed&&!i.marker.widgetNode&&i.from==r.to&&(null==i.to||i.to!=r.from)&&(i.marker.inclusiveLeft||r.marker.inclusiveRight)&&me(e,t,i))return!0}function ye(e){for(var t=0,r=(e=fe(e)).parent,n=0;n<r.lines.length;++n){var i=r.lines[n];if(i==e)break;t+=i.height}for(var o=r.parent;o;r=o,o=r.parent)for(var l=0;l<o.children.length;++l){var s=o.children[l];if(s==r)break;t+=s.height}return t}function be(e){if(0==e.height)return 0;for(var t,r=e.text.length,n=e;t=ae(n);){var i=t.find(0,!0);n=i.from.line,r+=i.from.ch-i.to.ch}for(n=e;t=ue(n);){var o=t.find(0,!0);r-=n.text.length-o.from.ch,r+=(n=o.to.line).text.length-o.to.ch}return r}function we(e){var t=e.display,r=e.doc;t.maxLine=M(r,r.first),t.maxLineLength=be(t.maxLine),t.maxLineChanged=!0,r.iter(function(e){var r=be(e);r>t.maxLineLength&&(t.maxLineLength=r,t.maxLine=e)})}function xe(e,t,r,n){if(!e)return n(t,r,"ltr",0);for(var i=!1,o=0;o<e.length;++o){var l=e[o];(l.from<r&&l.to>t||t==r&&l.to==t)&&(n(Math.max(l.from,t),Math.min(l.to,r),1==l.level?"rtl":"ltr",o),i=!0)}i||n(t,r,"ltr")}function Ce(e,t,r){var n;$l=null;for(var i=0;i<e.length;++i){var o=e[i];if(o.from<t&&o.to>t)return i;o.to==t&&(o.from!=o.to&&"before"==r?n=i:$l=i),o.from==t&&(o.from!=o.to&&"before"!=r?n=i:$l=i)}return null!=n?n:$l}function Se(e,t){var r=e.order;return null==r&&(r=e.order=ql(e.text,t)),r}function Le(e,t){return e._handlers&&e._handlers[t]||Zl}function ke(e,t,r){if(e.removeEventListener)e.removeEventListener(t,r,!1);else if(e.detachEvent)e.detachEvent("on"+t,r);else{var n=e._handlers,i=n&&n[t];if(i){var o=h(i,r);o>-1&&(n[t]=i.slice(0,o).concat(i.slice(o+1)))}}}function Te(e,t){var r=Le(e,t);if(r.length)for(var n=Array.prototype.slice.call(arguments,2),i=0;i<r.length;++i)r[i].apply(null,n)}function Me(e,t,r){return"string"==typeof t&&(t={type:t,preventDefault:function(){this.defaultPrevented=!0}}),Te(e,r||t.type,e,t),He(t)||t.codemirrorIgnore}function Ne(e){var t=e._handlers&&e._handlers.cursorActivity;if(t)for(var r=e.curOp.cursorActivityHandlers||(e.curOp.cursorActivityHandlers=[]),n=0;n<t.length;++n)-1==h(r,t[n])&&r.push(t[n])}function Oe(e,t){return Le(e,t).length>0}function Ae(e){e.prototype.on=function(e,t){Ql(this,e,t)},e.prototype.off=function(e,t){ke(this,e,t)}}function We(e){e.preventDefault?e.preventDefault():e.returnValue=!1}function De(e){e.stopPropagation?e.stopPropagation():e.cancelBubble=!0}function He(e){return null!=e.defaultPrevented?e.defaultPrevented:0==e.returnValue}function Fe(e){We(e),De(e)}function Ee(e){return e.target||e.srcElement}function Pe(e){var t=e.which;return null==t&&(1&e.button?t=1:2&e.button?t=3:4&e.button&&(t=2)),Ml&&e.ctrlKey&&1==t&&(t=3),t}function Ie(e){if(null==Il){var t=n("span","​");r(e,n("span",[t,document.createTextNode("x")])),0!=e.firstChild.offsetHeight&&(Il=t.offsetWidth<=1&&t.offsetHeight>2&&!(gl&&vl<8))}var i=Il?n("span","​"):n("span"," ",null,"display: inline-block; width: 1px; margin-right: -1px");return i.setAttribute("cm-text",""),i}function ze(e){if(null!=zl)return zl;var n=r(e,document.createTextNode("AخA")),i=Wl(n,0,1).getBoundingClientRect(),o=Wl(n,1,2).getBoundingClientRect();return t(e),!(!i||i.left==i.right)&&(zl=o.right-i.right<3)}function Re(e){if(null!=ns)return ns;var t=r(e,n("span","x")),i=t.getBoundingClientRect(),o=Wl(t,0,1).getBoundingClientRect();return ns=Math.abs(i.left-o.left)>1}function Be(e,t){arguments.length>2&&(t.dependencies=Array.prototype.slice.call(arguments,2)),is[e]=t}function Ge(e){if("string"==typeof e&&os.hasOwnProperty(e))e=os[e];else if(e&&"string"==typeof e.name&&os.hasOwnProperty(e.name)){var t=os[e.name];"string"==typeof t&&(t={name:t}),(e=b(t,e)).name=t.name}else{if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+xml$/.test(e))return Ge("application/xml");if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+json$/.test(e))return Ge("application/json")}return"string"==typeof e?{name:e}:e||{name:"null"}}function Ue(e,t){t=Ge(t);var r=is[t.name];if(!r)return Ue(e,"text/plain");var n=r(e,t);if(ls.hasOwnProperty(t.name)){var i=ls[t.name];for(var o in i)i.hasOwnProperty(o)&&(n.hasOwnProperty(o)&&(n["_"+o]=n[o]),n[o]=i[o])}if(n.name=t.name,t.helperType&&(n.helperType=t.helperType),t.modeProps)for(var l in t.modeProps)n[l]=t.modeProps[l];return n}function Ve(e,t){c(t,ls.hasOwnProperty(e)?ls[e]:ls[e]={})}function Ke(e,t){if(!0===t)return t;if(e.copyState)return e.copyState(t);var r={};for(var n in t){var i=t[n];i instanceof Array&&(i=i.concat([])),r[n]=i}return r}function je(e,t){for(var r;e.innerMode&&(r=e.innerMode(t))&&r.mode!=e;)t=r.state,e=r.mode;return r||{mode:e,state:t}}function Xe(e,t,r){return!e.startState||e.startState(t,r)}function Ye(e,t,r,n){var i=[e.state.modeGen],o={};tt(e,t.text,e.doc.mode,r,function(e,t){return i.push(e,t)},o,n);for(var l=r.state,s=0;s<e.state.overlays.length;++s)!function(n){var l=e.state.overlays[n],s=1,a=0;r.state=!0,tt(e,t.text,l.mode,r,function(e,t){for(var r=s;a<e;){var n=i[s];n>e&&i.splice(s,1,e,i[s+1],n),s+=2,a=Math.min(e,n)}if(t)if(l.opaque)i.splice(r,s-r,e,"overlay "+t),s=r+2;else for(;r<s;r+=2){var o=i[r+1];i[r+1]=(o?o+" ":"")+"overlay "+t}},o)}(s);return r.state=l,{styles:i,classes:o.bgClass||o.textClass?o:null}}function _e(e,t,r){if(!t.styles||t.styles[0]!=e.state.modeGen){var n=$e(e,W(t)),i=t.text.length>e.options.maxHighlightLength&&Ke(e.doc.mode,n.state),o=Ye(e,t,n);i&&(n.state=i),t.stateAfter=n.save(!i),t.styles=o.styles,o.classes?t.styleClasses=o.classes:t.styleClasses&&(t.styleClasses=null),r===e.doc.highlightFrontier&&(e.doc.modeFrontier=Math.max(e.doc.modeFrontier,++e.doc.highlightFrontier))}return t.styles}function $e(e,t,r){var n=e.doc,i=e.display;if(!n.mode.startState)return new us(n,!0,t);var o=rt(e,t,r),l=o>n.first&&M(n,o-1).stateAfter,s=l?us.fromSaved(n,l,o):new us(n,Xe(n.mode),o);return n.iter(o,t,function(r){qe(e,r.text,s);var n=s.line;r.stateAfter=n==t-1||n%5==0||n>=i.viewFrom&&n<i.viewTo?s.save():null,s.nextLine()}),r&&(n.modeFrontier=s.line),s}function qe(e,t,r,n){var i=e.doc.mode,o=new ss(t,e.options.tabSize,r);for(o.start=o.pos=n||0,""==t&&Ze(i,r.state);!o.eol();)Qe(i,o,r.state),o.start=o.pos}function Ze(e,t){if(e.blankLine)return e.blankLine(t);if(e.innerMode){var r=je(e,t);return r.mode.blankLine?r.mode.blankLine(r.state):void 0}}function Qe(e,t,r,n){for(var i=0;i<10;i++){n&&(n[0]=je(e,r).mode);var o=e.token(t,r);if(t.pos>t.start)return o}throw new Error("Mode "+e.name+" failed to advance stream.")}function Je(e,t,r,n){var i,o,l=e.doc,s=l.mode,a=M(l,(t=U(l,t)).line),u=$e(e,t.line,r),c=new ss(a.text,e.options.tabSize,u);for(n&&(o=[]);(n||c.pos<t.ch)&&!c.eol();)c.start=c.pos,i=Qe(s,c,u.state),n&&o.push(new cs(c,i,Ke(l.mode,u.state)));return n?o:new cs(c,i,u.state)}function et(e,t){if(e)for(;;){var r=e.match(/(?:^|\s+)line-(background-)?(\S+)/);if(!r)break;e=e.slice(0,r.index)+e.slice(r.index+r[0].length);var n=r[1]?"bgClass":"textClass";null==t[n]?t[n]=r[2]:new RegExp("(?:^|s)"+r[2]+"(?:$|s)").test(t[n])||(t[n]+=" "+r[2])}return e}function tt(e,t,r,n,i,o,l){var s=r.flattenSpans;null==s&&(s=e.options.flattenSpans);var a,u=0,c=null,f=new ss(t,e.options.tabSize,n),h=e.options.addModeClass&&[null];for(""==t&&et(Ze(r,n.state),o);!f.eol();){if(f.pos>e.options.maxHighlightLength?(s=!1,l&&qe(e,t,n,f.pos),f.pos=t.length,a=null):a=et(Qe(r,f,n.state,h),o),h){var d=h[0].name;d&&(a="m-"+(a?d+" "+a:d))}if(!s||c!=a){for(;u<f.start;)i(u=Math.min(f.start,u+5e3),c);c=a}f.start=f.pos}for(;u<f.pos;){var p=Math.min(f.pos,u+5e3);i(p,c),u=p}}function rt(e,t,r){for(var n,i,o=e.doc,l=r?-1:t-(e.doc.mode.innerMode?1e3:100),s=t;s>l;--s){if(s<=o.first)return o.first;var a=M(o,s-1),u=a.stateAfter;if(u&&(!r||s+(u instanceof as?u.lookAhead:0)<=o.modeFrontier))return s;var c=f(a.text,null,e.options.tabSize);(null==i||n>c)&&(i=s-1,n=c)}return i}function nt(e,t){if(e.modeFrontier=Math.min(e.modeFrontier,t),!(e.highlightFrontier<t-10)){for(var r=e.first,n=t-1;n>r;n--){var i=M(e,n).stateAfter;if(i&&(!(i instanceof as)||n+i.lookAhead<t)){r=n+1;break}}e.highlightFrontier=Math.min(e.highlightFrontier,r)}}function it(e,t,r,n){e.text=t,e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null),null!=e.order&&(e.order=null),re(e),ne(e,r);var i=n?n(e):1;i!=e.height&&A(e,i)}function ot(e){e.parent=null,re(e)}function lt(e,t){if(!e||/^\s*$/.test(e))return null;var r=t.addModeClass?ps:ds;return r[e]||(r[e]=e.replace(/\S+/g,"cm-$&"))}function st(e,t){var r=i("span",null,null,ml?"padding-right: .1px":null),n={pre:i("pre",[r],"CodeMirror-line"),content:r,col:0,pos:0,cm:e,trailingSpace:!1,splitSpaces:(gl||ml)&&e.getOption("lineWrapping")};t.measure={};for(var o=0;o<=(t.rest?t.rest.length:0);o++){var l=o?t.rest[o-1]:t.line,s=void 0;n.pos=0,n.addToken=ut,ze(e.display.measure)&&(s=Se(l,e.doc.direction))&&(n.addToken=ft(n.addToken,s)),n.map=[],dt(l,n,_e(e,l,t!=e.display.externalMeasured&&W(l))),l.styleClasses&&(l.styleClasses.bgClass&&(n.bgClass=a(l.styleClasses.bgClass,n.bgClass||"")),l.styleClasses.textClass&&(n.textClass=a(l.styleClasses.textClass,n.textClass||""))),0==n.map.length&&n.map.push(0,0,n.content.appendChild(Ie(e.display.measure))),0==o?(t.measure.map=n.map,t.measure.cache={}):((t.measure.maps||(t.measure.maps=[])).push(n.map),(t.measure.caches||(t.measure.caches=[])).push({}))}if(ml){var u=n.content.lastChild;(/\bcm-tab\b/.test(u.className)||u.querySelector&&u.querySelector(".cm-tab"))&&(n.content.className="cm-tab-wrap-hack")}return Te(e,"renderLine",e,t.line,n.pre),n.pre.className&&(n.textClass=a(n.pre.className,n.textClass||"")),n}function at(e){var t=n("span","•","cm-invalidchar");return t.title="\\u"+e.charCodeAt(0).toString(16),t.setAttribute("aria-label",t.title),t}function ut(e,t,r,i,o,l,s){if(t){var a,u=e.splitSpaces?ct(t,e.trailingSpace):t,c=e.cm.state.specialChars,f=!1;if(c.test(t)){a=document.createDocumentFragment();for(var h=0;;){c.lastIndex=h;var d=c.exec(t),g=d?d.index-h:t.length-h;if(g){var v=document.createTextNode(u.slice(h,h+g));gl&&vl<9?a.appendChild(n("span",[v])):a.appendChild(v),e.map.push(e.pos,e.pos+g,v),e.col+=g,e.pos+=g}if(!d)break;h+=g+1;var m=void 0;if("\t"==d[0]){var y=e.cm.options.tabSize,b=y-e.col%y;(m=a.appendChild(n("span",p(b),"cm-tab"))).setAttribute("role","presentation"),m.setAttribute("cm-text","\t"),e.col+=b}else"\r"==d[0]||"\n"==d[0]?((m=a.appendChild(n("span","\r"==d[0]?"␍":"␤","cm-invalidchar"))).setAttribute("cm-text",d[0]),e.col+=1):((m=e.cm.options.specialCharPlaceholder(d[0])).setAttribute("cm-text",d[0]),gl&&vl<9?a.appendChild(n("span",[m])):a.appendChild(m),e.col+=1);e.map.push(e.pos,e.pos+1,m),e.pos++}}else e.col+=t.length,a=document.createTextNode(u),e.map.push(e.pos,e.pos+t.length,a),gl&&vl<9&&(f=!0),e.pos+=t.length;if(e.trailingSpace=32==u.charCodeAt(t.length-1),r||i||o||f||s){var w=r||"";i&&(w+=i),o&&(w+=o);var x=n("span",[a],w,s);return l&&(x.title=l),e.content.appendChild(x)}e.content.appendChild(a)}}function ct(e,t){if(e.length>1&&!/  /.test(e))return e;for(var r=t,n="",i=0;i<e.length;i++){var o=e.charAt(i);" "!=o||!r||i!=e.length-1&&32!=e.charCodeAt(i+1)||(o=" "),n+=o,r=" "==o}return n}function ft(e,t){return function(r,n,i,o,l,s,a){i=i?i+" cm-force-border":"cm-force-border";for(var u=r.pos,c=u+n.length;;){for(var f=void 0,h=0;h<t.length&&!((f=t[h]).to>u&&f.from<=u);h++);if(f.to>=c)return e(r,n,i,o,l,s,a);e(r,n.slice(0,f.to-u),i,o,null,s,a),o=null,n=n.slice(f.to-u),u=f.to}}}function ht(e,t,r,n){var i=!n&&r.widgetNode;i&&e.map.push(e.pos,e.pos+t,i),!n&&e.cm.display.input.needsContentAttribute&&(i||(i=e.content.appendChild(document.createElement("span"))),i.setAttribute("cm-marker",r.id)),i&&(e.cm.display.input.setUneditable(i),e.content.appendChild(i)),e.pos+=t,e.trailingSpace=!1}function dt(e,t,r){var n=e.markedSpans,i=e.text,o=0;if(n)for(var l,s,a,u,c,f,h,d=i.length,p=0,g=1,v="",m=0;;){if(m==p){a=u=c=f=s="",h=null,m=1/0;for(var y=[],b=void 0,w=0;w<n.length;++w){var x=n[w],C=x.marker;"bookmark"==C.type&&x.from==p&&C.widgetNode?y.push(C):x.from<=p&&(null==x.to||x.to>p||C.collapsed&&x.to==p&&x.from==p)?(null!=x.to&&x.to!=p&&m>x.to&&(m=x.to,u=""),C.className&&(a+=" "+C.className),C.css&&(s=(s?s+";":"")+C.css),C.startStyle&&x.from==p&&(c+=" "+C.startStyle),C.endStyle&&x.to==m&&(b||(b=[])).push(C.endStyle,x.to),C.title&&!f&&(f=C.title),C.collapsed&&(!h||le(h.marker,C)<0)&&(h=x)):x.from>p&&m>x.from&&(m=x.from)}if(b)for(var S=0;S<b.length;S+=2)b[S+1]==m&&(u+=" "+b[S]);if(!h||h.from==p)for(var L=0;L<y.length;++L)ht(t,0,y[L]);if(h&&(h.from||0)==p){if(ht(t,(null==h.to?d+1:h.to)-p,h.marker,null==h.from),null==h.to)return;h.to==p&&(h=!1)}}if(p>=d)break;for(var k=Math.min(d,m);;){if(v){var T=p+v.length;if(!h){var M=T>k?v.slice(0,k-p):v;t.addToken(t,M,l?l+a:a,c,p+M.length==m?u:"",f,s)}if(T>=k){v=v.slice(k-p),p=k;break}p=T,c=""}v=i.slice(o,o=r[g++]),l=lt(r[g++],t.cm.options)}}else for(var N=1;N<r.length;N+=2)t.addToken(t,i.slice(o,o=r[N]),lt(r[N+1],t.cm.options))}function pt(e,t,r){this.line=t,this.rest=de(t),this.size=this.rest?W(g(this.rest))-r+1:1,this.node=this.text=null,this.hidden=ve(e,t)}function gt(e,t,r){for(var n,i=[],o=t;o<r;o=n){var l=new pt(e.doc,M(e.doc,o),o);n=o+l.size,i.push(l)}return i}function vt(e){gs?gs.ops.push(e):e.ownsGroup=gs={ops:[e],delayedCallbacks:[]}}function mt(e){var t=e.delayedCallbacks,r=0;do{for(;r<t.length;r++)t[r].call(null);for(var n=0;n<e.ops.length;n++){var i=e.ops[n];if(i.cursorActivityHandlers)for(;i.cursorActivityCalled<i.cursorActivityHandlers.length;)i.cursorActivityHandlers[i.cursorActivityCalled++].call(null,i.cm)}}while(r<t.length)}function yt(e,t){var r=e.ownsGroup;if(r)try{mt(r)}finally{gs=null,t(r)}}function bt(e,t){var r=Le(e,t);if(r.length){var n,i=Array.prototype.slice.call(arguments,2);gs?n=gs.delayedCallbacks:vs?n=vs:(n=vs=[],setTimeout(wt,0));for(var o=0;o<r.length;++o)!function(e){n.push(function(){return r[e].apply(null,i)})}(o)}}function wt(){var e=vs;vs=null;for(var t=0;t<e.length;++t)e[t]()}function xt(e,t,r,n){for(var i=0;i<t.changes.length;i++){var o=t.changes[i];"text"==o?kt(e,t):"gutter"==o?Mt(e,t,r,n):"class"==o?Tt(e,t):"widget"==o&&Nt(e,t,n)}t.changes=null}function Ct(e){return e.node==e.text&&(e.node=n("div",null,null,"position: relative"),e.text.parentNode&&e.text.parentNode.replaceChild(e.node,e.text),e.node.appendChild(e.text),gl&&vl<8&&(e.node.style.zIndex=2)),e.node}function St(e,t){var r=t.bgClass?t.bgClass+" "+(t.line.bgClass||""):t.line.bgClass;if(r&&(r+=" CodeMirror-linebackground"),t.background)r?t.background.className=r:(t.background.parentNode.removeChild(t.background),t.background=null);else if(r){var i=Ct(t);t.background=i.insertBefore(n("div",null,r),i.firstChild),e.display.input.setUneditable(t.background)}}function Lt(e,t){var r=e.display.externalMeasured;return r&&r.line==t.line?(e.display.externalMeasured=null,t.measure=r.measure,r.built):st(e,t)}function kt(e,t){var r=t.text.className,n=Lt(e,t);t.text==t.node&&(t.node=n.pre),t.text.parentNode.replaceChild(n.pre,t.text),t.text=n.pre,n.bgClass!=t.bgClass||n.textClass!=t.textClass?(t.bgClass=n.bgClass,t.textClass=n.textClass,Tt(e,t)):r&&(t.text.className=r)}function Tt(e,t){St(e,t),t.line.wrapClass?Ct(t).className=t.line.wrapClass:t.node!=t.text&&(t.node.className="");var r=t.textClass?t.textClass+" "+(t.line.textClass||""):t.line.textClass;t.text.className=r||""}function Mt(e,t,r,i){if(t.gutter&&(t.node.removeChild(t.gutter),t.gutter=null),t.gutterBackground&&(t.node.removeChild(t.gutterBackground),t.gutterBackground=null),t.line.gutterClass){var o=Ct(t);t.gutterBackground=n("div",null,"CodeMirror-gutter-background "+t.line.gutterClass,"left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px; width: "+i.gutterTotalWidth+"px"),e.display.input.setUneditable(t.gutterBackground),o.insertBefore(t.gutterBackground,t.text)}var l=t.line.gutterMarkers;if(e.options.lineNumbers||l){var s=Ct(t),a=t.gutter=n("div",null,"CodeMirror-gutter-wrapper","left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px");if(e.display.input.setUneditable(a),s.insertBefore(a,t.text),t.line.gutterClass&&(a.className+=" "+t.line.gutterClass),!e.options.lineNumbers||l&&l["CodeMirror-linenumbers"]||(t.lineNumber=a.appendChild(n("div",F(e.options,r),"CodeMirror-linenumber CodeMirror-gutter-elt","left: "+i.gutterLeft["CodeMirror-linenumbers"]+"px; width: "+e.display.lineNumInnerWidth+"px"))),l)for(var u=0;u<e.options.gutters.length;++u){var c=e.options.gutters[u],f=l.hasOwnProperty(c)&&l[c];f&&a.appendChild(n("div",[f],"CodeMirror-gutter-elt","left: "+i.gutterLeft[c]+"px; width: "+i.gutterWidth[c]+"px"))}}}function Nt(e,t,r){t.alignable&&(t.alignable=null);for(var n=t.node.firstChild,i=void 0;n;n=i)i=n.nextSibling,"CodeMirror-linewidget"==n.className&&t.node.removeChild(n);At(e,t,r)}function Ot(e,t,r,n){var i=Lt(e,t);return t.text=t.node=i.pre,i.bgClass&&(t.bgClass=i.bgClass),i.textClass&&(t.textClass=i.textClass),Tt(e,t),Mt(e,t,r,n),At(e,t,n),t.node}function At(e,t,r){if(Wt(e,t.line,t,r,!0),t.rest)for(var n=0;n<t.rest.length;n++)Wt(e,t.rest[n],t,r,!1)}function Wt(e,t,r,i,o){if(t.widgets)for(var l=Ct(r),s=0,a=t.widgets;s<a.length;++s){var u=a[s],c=n("div",[u.node],"CodeMirror-linewidget");u.handleMouseEvents||c.setAttribute("cm-ignore-events","true"),Dt(u,c,r,i),e.display.input.setUneditable(c),o&&u.above?l.insertBefore(c,r.gutter||r.text):l.appendChild(c),bt(u,"redraw")}}function Dt(e,t,r,n){if(e.noHScroll){(r.alignable||(r.alignable=[])).push(t);var i=n.wrapperWidth;t.style.left=n.fixedPos+"px",e.coverGutter||(i-=n.gutterTotalWidth,t.style.paddingLeft=n.gutterTotalWidth+"px"),t.style.width=i+"px"}e.coverGutter&&(t.style.zIndex=5,t.style.position="relative",e.noHScroll||(t.style.marginLeft=-n.gutterTotalWidth+"px"))}function Ht(e){if(null!=e.height)return e.height;var t=e.doc.cm;if(!t)return 0;if(!o(document.body,e.node)){var i="position: relative;";e.coverGutter&&(i+="margin-left: -"+t.display.gutters.offsetWidth+"px;"),e.noHScroll&&(i+="width: "+t.display.wrapper.clientWidth+"px;"),r(t.display.measure,n("div",[e.node],null,i))}return e.height=e.node.parentNode.offsetHeight}function Ft(e,t){for(var r=Ee(t);r!=e.wrapper;r=r.parentNode)if(!r||1==r.nodeType&&"true"==r.getAttribute("cm-ignore-events")||r.parentNode==e.sizer&&r!=e.mover)return!0}function Et(e){return e.lineSpace.offsetTop}function Pt(e){return e.mover.offsetHeight-e.lineSpace.offsetHeight}function It(e){if(e.cachedPaddingH)return e.cachedPaddingH;var t=r(e.measure,n("pre","x")),i=window.getComputedStyle?window.getComputedStyle(t):t.currentStyle,o={left:parseInt(i.paddingLeft),right:parseInt(i.paddingRight)};return isNaN(o.left)||isNaN(o.right)||(e.cachedPaddingH=o),o}function zt(e){return Rl-e.display.nativeBarWidth}function Rt(e){return e.display.scroller.clientWidth-zt(e)-e.display.barWidth}function Bt(e){return e.display.scroller.clientHeight-zt(e)-e.display.barHeight}function Gt(e,t,r){var n=e.options.lineWrapping,i=n&&Rt(e);if(!t.measure.heights||n&&t.measure.width!=i){var o=t.measure.heights=[];if(n){t.measure.width=i;for(var l=t.text.firstChild.getClientRects(),s=0;s<l.length-1;s++){var a=l[s],u=l[s+1];Math.abs(a.bottom-u.bottom)>2&&o.push((a.bottom+u.top)/2-r.top)}}o.push(r.bottom-r.top)}}function Ut(e,t,r){if(e.line==t)return{map:e.measure.map,cache:e.measure.cache};for(var n=0;n<e.rest.length;n++)if(e.rest[n]==t)return{map:e.measure.maps[n],cache:e.measure.caches[n]};for(var i=0;i<e.rest.length;i++)if(W(e.rest[i])>r)return{map:e.measure.maps[i],cache:e.measure.caches[i],before:!0}}function Vt(e,t){var n=W(t=fe(t)),i=e.display.externalMeasured=new pt(e.doc,t,n);i.lineN=n;var o=i.built=st(e,i);return i.text=o.pre,r(e.display.lineMeasure,o.pre),i}function Kt(e,t,r,n){return Yt(e,Xt(e,t),r,n)}function jt(e,t){if(t>=e.display.viewFrom&&t<e.display.viewTo)return e.display.view[Lr(e,t)];var r=e.display.externalMeasured;return r&&t>=r.lineN&&t<r.lineN+r.size?r:void 0}function Xt(e,t){var r=W(t),n=jt(e,r);n&&!n.text?n=null:n&&n.changes&&(xt(e,n,r,br(e)),e.curOp.forceUpdate=!0),n||(n=Vt(e,t));var i=Ut(n,t,r);return{line:t,view:n,rect:null,map:i.map,cache:i.cache,before:i.before,hasHeights:!1}}function Yt(e,t,r,n,i){t.before&&(r=-1);var o,l=r+(n||"");return t.cache.hasOwnProperty(l)?o=t.cache[l]:(t.rect||(t.rect=t.view.text.getBoundingClientRect()),t.hasHeights||(Gt(e,t.view,t.rect),t.hasHeights=!0),(o=qt(e,t,r,n)).bogus||(t.cache[l]=o)),{left:o.left,right:o.right,top:i?o.rtop:o.top,bottom:i?o.rbottom:o.bottom}}function _t(e,t,r){for(var n,i,o,l,s,a,u=0;u<e.length;u+=3)if(s=e[u],a=e[u+1],t<s?(i=0,o=1,l="left"):t<a?o=(i=t-s)+1:(u==e.length-3||t==a&&e[u+3]>t)&&(i=(o=a-s)-1,t>=a&&(l="right")),null!=i){if(n=e[u+2],s==a&&r==(n.insertLeft?"left":"right")&&(l=r),"left"==r&&0==i)for(;u&&e[u-2]==e[u-3]&&e[u-1].insertLeft;)n=e[2+(u-=3)],l="left";if("right"==r&&i==a-s)for(;u<e.length-3&&e[u+3]==e[u+4]&&!e[u+5].insertLeft;)n=e[(u+=3)+2],l="right";break}return{node:n,start:i,end:o,collapse:l,coverStart:s,coverEnd:a}}function $t(e,t){var r=ms;if("left"==t)for(var n=0;n<e.length&&(r=e[n]).left==r.right;n++);else for(var i=e.length-1;i>=0&&(r=e[i]).left==r.right;i--);return r}function qt(e,t,r,n){var i,o=_t(t.map,r,n),l=o.node,s=o.start,a=o.end,u=o.collapse;if(3==l.nodeType){for(var c=0;c<4;c++){for(;s&&S(t.line.text.charAt(o.coverStart+s));)--s;for(;o.coverStart+a<o.coverEnd&&S(t.line.text.charAt(o.coverStart+a));)++a;if((i=gl&&vl<9&&0==s&&a==o.coverEnd-o.coverStart?l.parentNode.getBoundingClientRect():$t(Wl(l,s,a).getClientRects(),n)).left||i.right||0==s)break;a=s,s-=1,u="right"}gl&&vl<11&&(i=Zt(e.display.measure,i))}else{s>0&&(u=n="right");var f;i=e.options.lineWrapping&&(f=l.getClientRects()).length>1?f["right"==n?f.length-1:0]:l.getBoundingClientRect()}if(gl&&vl<9&&!s&&(!i||!i.left&&!i.right)){var h=l.parentNode.getClientRects()[0];i=h?{left:h.left,right:h.left+yr(e.display),top:h.top,bottom:h.bottom}:ms}for(var d=i.top-t.rect.top,p=i.bottom-t.rect.top,g=(d+p)/2,v=t.view.measure.heights,m=0;m<v.length-1&&!(g<v[m]);m++);var y=m?v[m-1]:0,b=v[m],w={left:("right"==u?i.right:i.left)-t.rect.left,right:("left"==u?i.left:i.right)-t.rect.left,top:y,bottom:b};return i.left||i.right||(w.bogus=!0),e.options.singleCursorHeightPerLine||(w.rtop=d,w.rbottom=p),w}function Zt(e,t){if(!window.screen||null==screen.logicalXDPI||screen.logicalXDPI==screen.deviceXDPI||!Re(e))return t;var r=screen.logicalXDPI/screen.deviceXDPI,n=screen.logicalYDPI/screen.deviceYDPI;return{left:t.left*r,right:t.right*r,top:t.top*n,bottom:t.bottom*n}}function Qt(e){if(e.measure&&(e.measure.cache={},e.measure.heights=null,e.rest))for(var t=0;t<e.rest.length;t++)e.measure.caches[t]={}}function Jt(e){e.display.externalMeasure=null,t(e.display.lineMeasure);for(var r=0;r<e.display.view.length;r++)Qt(e.display.view[r])}function er(e){Jt(e),e.display.cachedCharWidth=e.display.cachedTextHeight=e.display.cachedPaddingH=null,e.options.lineWrapping||(e.display.maxLineChanged=!0),e.display.lineNumChars=null}function tr(){return bl&&kl?-(document.body.getBoundingClientRect().left-parseInt(getComputedStyle(document.body).marginLeft)):window.pageXOffset||(document.documentElement||document.body).scrollLeft}function rr(){return bl&&kl?-(document.body.getBoundingClientRect().top-parseInt(getComputedStyle(document.body).marginTop)):window.pageYOffset||(document.documentElement||document.body).scrollTop}function nr(e){var t=0;if(e.widgets)for(var r=0;r<e.widgets.length;++r)e.widgets[r].above&&(t+=Ht(e.widgets[r]));return t}function ir(e,t,r,n,i){if(!i){var o=nr(t);r.top+=o,r.bottom+=o}if("line"==n)return r;n||(n="local");var l=ye(t);if("local"==n?l+=Et(e.display):l-=e.display.viewOffset,"page"==n||"window"==n){var s=e.display.lineSpace.getBoundingClientRect();l+=s.top+("window"==n?0:rr());var a=s.left+("window"==n?0:tr());r.left+=a,r.right+=a}return r.top+=l,r.bottom+=l,r}function or(e,t,r){if("div"==r)return t;var n=t.left,i=t.top;if("page"==r)n-=tr(),i-=rr();else if("local"==r||!r){var o=e.display.sizer.getBoundingClientRect();n+=o.left,i+=o.top}var l=e.display.lineSpace.getBoundingClientRect();return{left:n-l.left,top:i-l.top}}function lr(e,t,r,n,i){return n||(n=M(e.doc,t.line)),ir(e,n,Kt(e,n,t.ch,i),r)}function sr(e,t,r,n,i,o){function l(t,l){var s=Yt(e,i,t,l?"right":"left",o);return l?s.left=s.right:s.right=s.left,ir(e,n,s,r)}function s(e,t,r){var n=1==a[t].level;return l(r?e-1:e,n!=r)}n=n||M(e.doc,t.line),i||(i=Xt(e,n));var a=Se(n,e.doc.direction),u=t.ch,c=t.sticky;if(u>=n.text.length?(u=n.text.length,c="before"):u<=0&&(u=0,c="after"),!a)return l("before"==c?u-1:u,"before"==c);var f=Ce(a,u,c),h=$l,d=s(u,f,"before"==c);return null!=h&&(d.other=s(u,h,"before"!=c)),d}function ar(e,t){var r=0;t=U(e.doc,t),e.options.lineWrapping||(r=yr(e.display)*t.ch);var n=M(e.doc,t.line),i=ye(n)+Et(e.display);return{left:r,right:r,top:i,bottom:i+n.height}}function ur(e,t,r,n,i){var o=E(e,t,r);return o.xRel=i,n&&(o.outside=!0),o}function cr(e,t,r){var n=e.doc;if((r+=e.display.viewOffset)<0)return ur(n.first,0,null,!0,-1);var i=D(n,r),o=n.first+n.size-1;if(i>o)return ur(n.first+n.size-1,M(n,o).text.length,null,!0,1);t<0&&(t=0);for(var l=M(n,i);;){var s=pr(e,l,i,t,r),a=ue(l),u=a&&a.find(0,!0);if(!a||!(s.ch>u.from.ch||s.ch==u.from.ch&&s.xRel>0))return s;i=W(l=u.to.line)}}function fr(e,t,r,n){n-=nr(t);var i=t.text.length,o=k(function(t){return Yt(e,r,t-1).bottom<=n},i,0);return i=k(function(t){return Yt(e,r,t).top>n},o,i),{begin:o,end:i}}function hr(e,t,r,n){return r||(r=Xt(e,t)),fr(e,t,r,ir(e,t,Yt(e,r,n),"line").top)}function dr(e,t,r,n){return!(e.bottom<=r)&&(e.top>r||(n?e.left:e.right)>t)}function pr(e,t,r,n,i){i-=ye(t);var o=Xt(e,t),l=nr(t),s=0,a=t.text.length,u=!0,c=Se(t,e.doc.direction);if(c){var f=(e.options.lineWrapping?vr:gr)(e,t,r,o,c,n,i);s=(u=1!=f.level)?f.from:f.to-1,a=u?f.to:f.from-1}var h,d,p=null,g=null,v=k(function(t){var r=Yt(e,o,t);return r.top+=l,r.bottom+=l,!!dr(r,n,i,!1)&&(r.top<=i&&r.left<=n&&(p=t,g=r),!0)},s,a),m=!1;if(g){var y=n-g.left<g.right-n,b=y==u;v=p+(b?0:1),d=b?"after":"before",h=y?g.left:g.right}else{u||v!=a&&v!=s||v++,d=0==v?"after":v==t.text.length?"before":Yt(e,o,v-(u?1:0)).bottom+l<=i==u?"after":"before";var w=sr(e,E(r,v,d),"line",t,o);h=w.left,m=i<w.top||i>=w.bottom}return v=L(t.text,v,1),ur(r,v,d,m,n-h)}function gr(e,t,r,n,i,o,l){var s=k(function(s){var a=i[s],u=1!=a.level;return dr(sr(e,E(r,u?a.to:a.from,u?"before":"after"),"line",t,n),o,l,!0)},0,i.length-1),a=i[s];if(s>0){var u=1!=a.level,c=sr(e,E(r,u?a.from:a.to,u?"after":"before"),"line",t,n);dr(c,o,l,!0)&&c.top>l&&(a=i[s-1])}return a}function vr(e,t,r,n,i,o,l){for(var s=fr(e,t,n,l),a=s.begin,u=s.end,c=null,f=null,h=0;h<i.length;h++){var d=i[h];if(!(d.from>=u||d.to<=a)){var p=Yt(e,n,1!=d.level?Math.min(u,d.to)-1:Math.max(a,d.from)).right,g=p<o?o-p+1e9:p-o;(!c||f>g)&&(c=d,f=g)}}return c||(c=i[i.length-1]),c.from<a&&(c={from:a,to:c.to,level:c.level}),c.to>u&&(c={from:c.from,to:u,level:c.level}),c}function mr(e){if(null!=e.cachedTextHeight)return e.cachedTextHeight;if(null==hs){hs=n("pre");for(var i=0;i<49;++i)hs.appendChild(document.createTextNode("x")),hs.appendChild(n("br"));hs.appendChild(document.createTextNode("x"))}r(e.measure,hs);var o=hs.offsetHeight/50;return o>3&&(e.cachedTextHeight=o),t(e.measure),o||1}function yr(e){if(null!=e.cachedCharWidth)return e.cachedCharWidth;var t=n("span","xxxxxxxxxx"),i=n("pre",[t]);r(e.measure,i);var o=t.getBoundingClientRect(),l=(o.right-o.left)/10;return l>2&&(e.cachedCharWidth=l),l||10}function br(e){for(var t=e.display,r={},n={},i=t.gutters.clientLeft,o=t.gutters.firstChild,l=0;o;o=o.nextSibling,++l)r[e.options.gutters[l]]=o.offsetLeft+o.clientLeft+i,n[e.options.gutters[l]]=o.clientWidth;return{fixedPos:wr(t),gutterTotalWidth:t.gutters.offsetWidth,gutterLeft:r,gutterWidth:n,wrapperWidth:t.wrapper.clientWidth}}function wr(e){return e.scroller.getBoundingClientRect().left-e.sizer.getBoundingClientRect().left}function xr(e){var t=mr(e.display),r=e.options.lineWrapping,n=r&&Math.max(5,e.display.scroller.clientWidth/yr(e.display)-3);return function(i){if(ve(e.doc,i))return 0;var o=0;if(i.widgets)for(var l=0;l<i.widgets.length;l++)i.widgets[l].height&&(o+=i.widgets[l].height);return r?o+(Math.ceil(i.text.length/n)||1)*t:o+t}}function Cr(e){var t=e.doc,r=xr(e);t.iter(function(e){var t=r(e);t!=e.height&&A(e,t)})}function Sr(e,t,r,n){var i=e.display;if(!r&&"true"==Ee(t).getAttribute("cm-not-content"))return null;var o,l,s=i.lineSpace.getBoundingClientRect();try{o=t.clientX-s.left,l=t.clientY-s.top}catch(t){return null}var a,u=cr(e,o,l);if(n&&1==u.xRel&&(a=M(e.doc,u.line).text).length==u.ch){var c=f(a,a.length,e.options.tabSize)-a.length;u=E(u.line,Math.max(0,Math.round((o-It(e.display).left)/yr(e.display))-c))}return u}function Lr(e,t){if(t>=e.display.viewTo)return null;if((t-=e.display.viewFrom)<0)return null;for(var r=e.display.view,n=0;n<r.length;n++)if((t-=r[n].size)<0)return n}function kr(e){e.display.input.showSelection(e.display.input.prepareSelection())}function Tr(e,t){void 0===t&&(t=!0);for(var r=e.doc,n={},i=n.cursors=document.createDocumentFragment(),o=n.selection=document.createDocumentFragment(),l=0;l<r.sel.ranges.length;l++)if(t||l!=r.sel.primIndex){var s=r.sel.ranges[l];if(!(s.from().line>=e.display.viewTo||s.to().line<e.display.viewFrom)){var a=s.empty();(a||e.options.showCursorWhenSelecting)&&Mr(e,s.head,i),a||Or(e,s,o)}}return n}function Mr(e,t,r){var i=sr(e,t,"div",null,null,!e.options.singleCursorHeightPerLine),o=r.appendChild(n("div"," ","CodeMirror-cursor"));if(o.style.left=i.left+"px",o.style.top=i.top+"px",o.style.height=Math.max(0,i.bottom-i.top)*e.options.cursorHeight+"px",i.other){var l=r.appendChild(n("div"," ","CodeMirror-cursor CodeMirror-secondarycursor"));l.style.display="",l.style.left=i.other.left+"px",l.style.top=i.other.top+"px",l.style.height=.85*(i.other.bottom-i.other.top)+"px"}}function Nr(e,t){return e.top-t.top||e.left-t.left}function Or(e,t,r){function i(e,t,r,i){t<0&&(t=0),t=Math.round(t),i=Math.round(i),a.appendChild(n("div",null,"CodeMirror-selected","position: absolute; left: "+e+"px;\n                             top: "+t+"px; width: "+(null==r?f-e:r)+"px;\n                             height: "+(i-t)+"px"))}function o(t,r,n){function o(r,n){return lr(e,E(t,r),"div",u,n)}var l,a,u=M(s,t),h=u.text.length,d=Se(u,s.direction);return xe(d,r||0,null==n?h:n,function(t,s,p,g){var v=o(t,"ltr"==p?"left":"right"),m=o(s-1,"ltr"==p?"right":"left");if("ltr"==p){var y=null==r&&0==t?c:v.left,b=null==n&&s==h?f:m.right;m.top-v.top<=3?i(y,m.top,b-y,m.bottom):(i(y,v.top,null,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top),i(c,m.top,m.right,m.bottom))}else if(t<s){var w=null==r&&0==t?f:v.right,x=null==n&&s==h?c:m.left;if(m.top-v.top<=3)i(x,m.top,w-x,m.bottom);else{var C=c;if(g){var S=hr(e,u,null,t).end;C=o(S-(/\s/.test(u.text.charAt(S-1))?2:1),"left").left}i(C,v.top,w-C,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top);var L=null;d.length,L=o(hr(e,u,null,s).begin,"right").right-x,i(x,m.top,L,m.bottom)}}(!l||Nr(v,l)<0)&&(l=v),Nr(m,l)<0&&(l=m),(!a||Nr(v,a)<0)&&(a=v),Nr(m,a)<0&&(a=m)}),{start:l,end:a}}var l=e.display,s=e.doc,a=document.createDocumentFragment(),u=It(e.display),c=u.left,f=Math.max(l.sizerWidth,Rt(e)-l.sizer.offsetLeft)-u.right,h=t.from(),d=t.to();if(h.line==d.line)o(h.line,h.ch,d.ch);else{var p=M(s,h.line),g=M(s,d.line),v=fe(p)==fe(g),m=o(h.line,h.ch,v?p.text.length+1:null).end,y=o(d.line,v?0:null,d.ch).start;v&&(m.top<y.top-2?(i(m.right,m.top,null,m.bottom),i(c,y.top,y.left,y.bottom)):i(m.right,m.top,y.left-m.right,m.bottom)),m.bottom<y.top&&i(c,m.bottom,null,y.top)}r.appendChild(a)}function Ar(e){if(e.state.focused){var t=e.display;clearInterval(t.blinker);var r=!0;t.cursorDiv.style.visibility="",e.options.cursorBlinkRate>0?t.blinker=setInterval(function(){return t.cursorDiv.style.visibility=(r=!r)?"":"hidden"},e.options.cursorBlinkRate):e.options.cursorBlinkRate<0&&(t.cursorDiv.style.visibility="hidden")}}function Wr(e){e.state.focused||(e.display.input.focus(),Hr(e))}function Dr(e){e.state.delayingBlurEvent=!0,setTimeout(function(){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1,Fr(e))},100)}function Hr(e,t){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1),"nocursor"!=e.options.readOnly&&(e.state.focused||(Te(e,"focus",e,t),e.state.focused=!0,s(e.display.wrapper,"CodeMirror-focused"),e.curOp||e.display.selForContextMenu==e.doc.sel||(e.display.input.reset(),ml&&setTimeout(function(){return e.display.input.reset(!0)},20)),e.display.input.receivedFocus()),Ar(e))}function Fr(e,t){e.state.delayingBlurEvent||(e.state.focused&&(Te(e,"blur",e,t),e.state.focused=!1,Fl(e.display.wrapper,"CodeMirror-focused")),clearInterval(e.display.blinker),setTimeout(function(){e.state.focused||(e.display.shift=!1)},150))}function Er(e){for(var t=e.display,r=t.lineDiv.offsetTop,n=0;n<t.view.length;n++){var i=t.view[n],o=void 0;if(!i.hidden){if(gl&&vl<8){var l=i.node.offsetTop+i.node.offsetHeight;o=l-r,r=l}else{var s=i.node.getBoundingClientRect();o=s.bottom-s.top}var a=i.line.height-o;if(o<2&&(o=mr(t)),(a>.005||a<-.005)&&(A(i.line,o),Pr(i.line),i.rest))for(var u=0;u<i.rest.length;u++)Pr(i.rest[u])}}}function Pr(e){if(e.widgets)for(var t=0;t<e.widgets.length;++t)e.widgets[t].height=e.widgets[t].node.parentNode.offsetHeight}function Ir(e,t,r){var n=r&&null!=r.top?Math.max(0,r.top):e.scroller.scrollTop;n=Math.floor(n-Et(e));var i=r&&null!=r.bottom?r.bottom:n+e.wrapper.clientHeight,o=D(t,n),l=D(t,i);if(r&&r.ensure){var s=r.ensure.from.line,a=r.ensure.to.line;s<o?(o=s,l=D(t,ye(M(t,s))+e.wrapper.clientHeight)):Math.min(a,t.lastLine())>=l&&(o=D(t,ye(M(t,a))-e.wrapper.clientHeight),l=a)}return{from:o,to:Math.max(l,o+1)}}function zr(e){var t=e.display,r=t.view;if(t.alignWidgets||t.gutters.firstChild&&e.options.fixedGutter){for(var n=wr(t)-t.scroller.scrollLeft+e.doc.scrollLeft,i=t.gutters.offsetWidth,o=n+"px",l=0;l<r.length;l++)if(!r[l].hidden){e.options.fixedGutter&&(r[l].gutter&&(r[l].gutter.style.left=o),r[l].gutterBackground&&(r[l].gutterBackground.style.left=o));var s=r[l].alignable;if(s)for(var a=0;a<s.length;a++)s[a].style.left=o}e.options.fixedGutter&&(t.gutters.style.left=n+i+"px")}}function Rr(e){if(!e.options.lineNumbers)return!1;var t=e.doc,r=F(e.options,t.first+t.size-1),i=e.display;if(r.length!=i.lineNumChars){var o=i.measure.appendChild(n("div",[n("div",r)],"CodeMirror-linenumber CodeMirror-gutter-elt")),l=o.firstChild.offsetWidth,s=o.offsetWidth-l;return i.lineGutter.style.width="",i.lineNumInnerWidth=Math.max(l,i.lineGutter.offsetWidth-s)+1,i.lineNumWidth=i.lineNumInnerWidth+s,i.lineNumChars=i.lineNumInnerWidth?r.length:-1,i.lineGutter.style.width=i.lineNumWidth+"px",Wn(e),!0}return!1}function Br(e,t){if(!Me(e,"scrollCursorIntoView")){var r=e.display,i=r.sizer.getBoundingClientRect(),o=null;if(t.top+i.top<0?o=!0:t.bottom+i.top>(window.innerHeight||document.documentElement.clientHeight)&&(o=!1),null!=o&&!Sl){var l=n("div","​",null,"position: absolute;\n                         top: "+(t.top-r.viewOffset-Et(e.display))+"px;\n                         height: "+(t.bottom-t.top+zt(e)+r.barHeight)+"px;\n                         left: "+t.left+"px; width: "+Math.max(2,t.right-t.left)+"px;");e.display.lineSpace.appendChild(l),l.scrollIntoView(o),e.display.lineSpace.removeChild(l)}}}function Gr(e,t,r,n){null==n&&(n=0);var i;e.options.lineWrapping||t!=r||(r="before"==(t=t.ch?E(t.line,"before"==t.sticky?t.ch-1:t.ch,"after"):t).sticky?E(t.line,t.ch+1,"before"):t);for(var o=0;o<5;o++){var l=!1,s=sr(e,t),a=r&&r!=t?sr(e,r):s,u=Vr(e,i={left:Math.min(s.left,a.left),top:Math.min(s.top,a.top)-n,right:Math.max(s.left,a.left),bottom:Math.max(s.bottom,a.bottom)+n}),c=e.doc.scrollTop,f=e.doc.scrollLeft;if(null!=u.scrollTop&&(qr(e,u.scrollTop),Math.abs(e.doc.scrollTop-c)>1&&(l=!0)),null!=u.scrollLeft&&(Qr(e,u.scrollLeft),Math.abs(e.doc.scrollLeft-f)>1&&(l=!0)),!l)break}return i}function Ur(e,t){var r=Vr(e,t);null!=r.scrollTop&&qr(e,r.scrollTop),null!=r.scrollLeft&&Qr(e,r.scrollLeft)}function Vr(e,t){var r=e.display,n=mr(e.display);t.top<0&&(t.top=0);var i=e.curOp&&null!=e.curOp.scrollTop?e.curOp.scrollTop:r.scroller.scrollTop,o=Bt(e),l={};t.bottom-t.top>o&&(t.bottom=t.top+o);var s=e.doc.height+Pt(r),a=t.top<n,u=t.bottom>s-n;if(t.top<i)l.scrollTop=a?0:t.top;else if(t.bottom>i+o){var c=Math.min(t.top,(u?s:t.bottom)-o);c!=i&&(l.scrollTop=c)}var f=e.curOp&&null!=e.curOp.scrollLeft?e.curOp.scrollLeft:r.scroller.scrollLeft,h=Rt(e)-(e.options.fixedGutter?r.gutters.offsetWidth:0),d=t.right-t.left>h;return d&&(t.right=t.left+h),t.left<10?l.scrollLeft=0:t.left<f?l.scrollLeft=Math.max(0,t.left-(d?0:10)):t.right>h+f-3&&(l.scrollLeft=t.right+(d?0:10)-h),l}function Kr(e,t){null!=t&&(_r(e),e.curOp.scrollTop=(null==e.curOp.scrollTop?e.doc.scrollTop:e.curOp.scrollTop)+t)}function jr(e){_r(e);var t=e.getCursor();e.curOp.scrollToPos={from:t,to:t,margin:e.options.cursorScrollMargin}}function Xr(e,t,r){null==t&&null==r||_r(e),null!=t&&(e.curOp.scrollLeft=t),null!=r&&(e.curOp.scrollTop=r)}function Yr(e,t){_r(e),e.curOp.scrollToPos=t}function _r(e){var t=e.curOp.scrollToPos;t&&(e.curOp.scrollToPos=null,$r(e,ar(e,t.from),ar(e,t.to),t.margin))}function $r(e,t,r,n){var i=Vr(e,{left:Math.min(t.left,r.left),top:Math.min(t.top,r.top)-n,right:Math.max(t.right,r.right),bottom:Math.max(t.bottom,r.bottom)+n});Xr(e,i.scrollLeft,i.scrollTop)}function qr(e,t){Math.abs(e.doc.scrollTop-t)<2||(fl||On(e,{top:t}),Zr(e,t,!0),fl&&On(e),Cn(e,100))}function Zr(e,t,r){t=Math.min(e.display.scroller.scrollHeight-e.display.scroller.clientHeight,t),(e.display.scroller.scrollTop!=t||r)&&(e.doc.scrollTop=t,e.display.scrollbars.setScrollTop(t),e.display.scroller.scrollTop!=t&&(e.display.scroller.scrollTop=t))}function Qr(e,t,r,n){t=Math.min(t,e.display.scroller.scrollWidth-e.display.scroller.clientWidth),(r?t==e.doc.scrollLeft:Math.abs(e.doc.scrollLeft-t)<2)&&!n||(e.doc.scrollLeft=t,zr(e),e.display.scroller.scrollLeft!=t&&(e.display.scroller.scrollLeft=t),e.display.scrollbars.setScrollLeft(t))}function Jr(e){var t=e.display,r=t.gutters.offsetWidth,n=Math.round(e.doc.height+Pt(e.display));return{clientHeight:t.scroller.clientHeight,viewHeight:t.wrapper.clientHeight,scrollWidth:t.scroller.scrollWidth,clientWidth:t.scroller.clientWidth,viewWidth:t.wrapper.clientWidth,barLeft:e.options.fixedGutter?r:0,docHeight:n,scrollHeight:n+zt(e)+t.barHeight,nativeBarWidth:t.nativeBarWidth,gutterWidth:r}}function en(e,t){t||(t=Jr(e));var r=e.display.barWidth,n=e.display.barHeight;tn(e,t);for(var i=0;i<4&&r!=e.display.barWidth||n!=e.display.barHeight;i++)r!=e.display.barWidth&&e.options.lineWrapping&&Er(e),tn(e,Jr(e)),r=e.display.barWidth,n=e.display.barHeight}function tn(e,t){var r=e.display,n=r.scrollbars.update(t);r.sizer.style.paddingRight=(r.barWidth=n.right)+"px",r.sizer.style.paddingBottom=(r.barHeight=n.bottom)+"px",r.heightForcer.style.borderBottom=n.bottom+"px solid transparent",n.right&&n.bottom?(r.scrollbarFiller.style.display="block",r.scrollbarFiller.style.height=n.bottom+"px",r.scrollbarFiller.style.width=n.right+"px"):r.scrollbarFiller.style.display="",n.bottom&&e.options.coverGutterNextToScrollbar&&e.options.fixedGutter?(r.gutterFiller.style.display="block",r.gutterFiller.style.height=n.bottom+"px",r.gutterFiller.style.width=t.gutterWidth+"px"):r.gutterFiller.style.display=""}function rn(e){e.display.scrollbars&&(e.display.scrollbars.clear(),e.display.scrollbars.addClass&&Fl(e.display.wrapper,e.display.scrollbars.addClass)),e.display.scrollbars=new ws[e.options.scrollbarStyle](function(t){e.display.wrapper.insertBefore(t,e.display.scrollbarFiller),Ql(t,"mousedown",function(){e.state.focused&&setTimeout(function(){return e.display.input.focus()},0)}),t.setAttribute("cm-not-content","true")},function(t,r){"horizontal"==r?Qr(e,t):qr(e,t)},e),e.display.scrollbars.addClass&&s(e.display.wrapper,e.display.scrollbars.addClass)}function nn(e){e.curOp={cm:e,viewChanged:!1,startHeight:e.doc.height,forceUpdate:!1,updateInput:null,typing:!1,changeObjs:null,cursorActivityHandlers:null,cursorActivityCalled:0,selectionChanged:!1,updateMaxLine:!1,scrollLeft:null,scrollTop:null,scrollToPos:null,focus:!1,id:++xs},vt(e.curOp)}function on(e){yt(e.curOp,function(e){for(var t=0;t<e.ops.length;t++)e.ops[t].cm.curOp=null;ln(e)})}function ln(e){for(var t=e.ops,r=0;r<t.length;r++)sn(t[r]);for(var n=0;n<t.length;n++)an(t[n]);for(var i=0;i<t.length;i++)un(t[i]);for(var o=0;o<t.length;o++)cn(t[o]);for(var l=0;l<t.length;l++)fn(t[l])}function sn(e){var t=e.cm,r=t.display;Ln(t),e.updateMaxLine&&we(t),e.mustUpdate=e.viewChanged||e.forceUpdate||null!=e.scrollTop||e.scrollToPos&&(e.scrollToPos.from.line<r.viewFrom||e.scrollToPos.to.line>=r.viewTo)||r.maxLineChanged&&t.options.lineWrapping,e.update=e.mustUpdate&&new Cs(t,e.mustUpdate&&{top:e.scrollTop,ensure:e.scrollToPos},e.forceUpdate)}function an(e){e.updatedDisplay=e.mustUpdate&&Mn(e.cm,e.update)}function un(e){var t=e.cm,r=t.display;e.updatedDisplay&&Er(t),e.barMeasure=Jr(t),r.maxLineChanged&&!t.options.lineWrapping&&(e.adjustWidthTo=Kt(t,r.maxLine,r.maxLine.text.length).left+3,t.display.sizerWidth=e.adjustWidthTo,e.barMeasure.scrollWidth=Math.max(r.scroller.clientWidth,r.sizer.offsetLeft+e.adjustWidthTo+zt(t)+t.display.barWidth),e.maxScrollLeft=Math.max(0,r.sizer.offsetLeft+e.adjustWidthTo-Rt(t))),(e.updatedDisplay||e.selectionChanged)&&(e.preparedSelection=r.input.prepareSelection())}function cn(e){var t=e.cm;null!=e.adjustWidthTo&&(t.display.sizer.style.minWidth=e.adjustWidthTo+"px",e.maxScrollLeft<t.doc.scrollLeft&&Qr(t,Math.min(t.display.scroller.scrollLeft,e.maxScrollLeft),!0),t.display.maxLineChanged=!1);var r=e.focus&&e.focus==l();e.preparedSelection&&t.display.input.showSelection(e.preparedSelection,r),(e.updatedDisplay||e.startHeight!=t.doc.height)&&en(t,e.barMeasure),e.updatedDisplay&&Dn(t,e.barMeasure),e.selectionChanged&&Ar(t),t.state.focused&&e.updateInput&&t.display.input.reset(e.typing),r&&Wr(e.cm)}function fn(e){var t=e.cm,r=t.display,n=t.doc;e.updatedDisplay&&Nn(t,e.update),null==r.wheelStartX||null==e.scrollTop&&null==e.scrollLeft&&!e.scrollToPos||(r.wheelStartX=r.wheelStartY=null),null!=e.scrollTop&&Zr(t,e.scrollTop,e.forceScroll),null!=e.scrollLeft&&Qr(t,e.scrollLeft,!0,!0),e.scrollToPos&&Br(t,Gr(t,U(n,e.scrollToPos.from),U(n,e.scrollToPos.to),e.scrollToPos.margin));var i=e.maybeHiddenMarkers,o=e.maybeUnhiddenMarkers;if(i)for(var l=0;l<i.length;++l)i[l].lines.length||Te(i[l],"hide");if(o)for(var s=0;s<o.length;++s)o[s].lines.length&&Te(o[s],"unhide");r.wrapper.offsetHeight&&(n.scrollTop=t.display.scroller.scrollTop),e.changeObjs&&Te(t,"changes",t,e.changeObjs),e.update&&e.update.finish()}function hn(e,t){if(e.curOp)return t();nn(e);try{return t()}finally{on(e)}}function dn(e,t){return function(){if(e.curOp)return t.apply(e,arguments);nn(e);try{return t.apply(e,arguments)}finally{on(e)}}}function pn(e){return function(){if(this.curOp)return e.apply(this,arguments);nn(this);try{return e.apply(this,arguments)}finally{on(this)}}}function gn(e){return function(){var t=this.cm;if(!t||t.curOp)return e.apply(this,arguments);nn(t);try{return e.apply(this,arguments)}finally{on(t)}}}function vn(e,t,r,n){null==t&&(t=e.doc.first),null==r&&(r=e.doc.first+e.doc.size),n||(n=0);var i=e.display;if(n&&r<i.viewTo&&(null==i.updateLineNumbers||i.updateLineNumbers>t)&&(i.updateLineNumbers=t),e.curOp.viewChanged=!0,t>=i.viewTo)_l&&pe(e.doc,t)<i.viewTo&&yn(e);else if(r<=i.viewFrom)_l&&ge(e.doc,r+n)>i.viewFrom?yn(e):(i.viewFrom+=n,i.viewTo+=n);else if(t<=i.viewFrom&&r>=i.viewTo)yn(e);else if(t<=i.viewFrom){var o=bn(e,r,r+n,1);o?(i.view=i.view.slice(o.index),i.viewFrom=o.lineN,i.viewTo+=n):yn(e)}else if(r>=i.viewTo){var l=bn(e,t,t,-1);l?(i.view=i.view.slice(0,l.index),i.viewTo=l.lineN):yn(e)}else{var s=bn(e,t,t,-1),a=bn(e,r,r+n,1);s&&a?(i.view=i.view.slice(0,s.index).concat(gt(e,s.lineN,a.lineN)).concat(i.view.slice(a.index)),i.viewTo+=n):yn(e)}var u=i.externalMeasured;u&&(r<u.lineN?u.lineN+=n:t<u.lineN+u.size&&(i.externalMeasured=null))}function mn(e,t,r){e.curOp.viewChanged=!0;var n=e.display,i=e.display.externalMeasured;if(i&&t>=i.lineN&&t<i.lineN+i.size&&(n.externalMeasured=null),!(t<n.viewFrom||t>=n.viewTo)){var o=n.view[Lr(e,t)];if(null!=o.node){var l=o.changes||(o.changes=[]);-1==h(l,r)&&l.push(r)}}}function yn(e){e.display.viewFrom=e.display.viewTo=e.doc.first,e.display.view=[],e.display.viewOffset=0}function bn(e,t,r,n){var i,o=Lr(e,t),l=e.display.view;if(!_l||r==e.doc.first+e.doc.size)return{index:o,lineN:r};for(var s=e.display.viewFrom,a=0;a<o;a++)s+=l[a].size;if(s!=t){if(n>0){if(o==l.length-1)return null;i=s+l[o].size-t,o++}else i=s-t;t+=i,r+=i}for(;pe(e.doc,r)!=r;){if(o==(n<0?0:l.length-1))return null;r+=n*l[o-(n<0?1:0)].size,o+=n}return{index:o,lineN:r}}function wn(e,t,r){var n=e.display;0==n.view.length||t>=n.viewTo||r<=n.viewFrom?(n.view=gt(e,t,r),n.viewFrom=t):(n.viewFrom>t?n.view=gt(e,t,n.viewFrom).concat(n.view):n.viewFrom<t&&(n.view=n.view.slice(Lr(e,t))),n.viewFrom=t,n.viewTo<r?n.view=n.view.concat(gt(e,n.viewTo,r)):n.viewTo>r&&(n.view=n.view.slice(0,Lr(e,r)))),n.viewTo=r}function xn(e){for(var t=e.display.view,r=0,n=0;n<t.length;n++){var i=t[n];i.hidden||i.node&&!i.changes||++r}return r}function Cn(e,t){e.doc.highlightFrontier<e.display.viewTo&&e.state.highlight.set(t,u(Sn,e))}function Sn(e){var t=e.doc;if(!(t.highlightFrontier>=e.display.viewTo)){var r=+new Date+e.options.workTime,n=$e(e,t.highlightFrontier),i=[];t.iter(n.line,Math.min(t.first+t.size,e.display.viewTo+500),function(o){if(n.line>=e.display.viewFrom){var l=o.styles,s=o.text.length>e.options.maxHighlightLength?Ke(t.mode,n.state):null,a=Ye(e,o,n,!0);s&&(n.state=s),o.styles=a.styles;var u=o.styleClasses,c=a.classes;c?o.styleClasses=c:u&&(o.styleClasses=null);for(var f=!l||l.length!=o.styles.length||u!=c&&(!u||!c||u.bgClass!=c.bgClass||u.textClass!=c.textClass),h=0;!f&&h<l.length;++h)f=l[h]!=o.styles[h];f&&i.push(n.line),o.stateAfter=n.save(),n.nextLine()}else o.text.length<=e.options.maxHighlightLength&&qe(e,o.text,n),o.stateAfter=n.line%5==0?n.save():null,n.nextLine();if(+new Date>r)return Cn(e,e.options.workDelay),!0}),t.highlightFrontier=n.line,t.modeFrontier=Math.max(t.modeFrontier,n.line),i.length&&hn(e,function(){for(var t=0;t<i.length;t++)mn(e,i[t],"text")})}}function Ln(e){var t=e.display;!t.scrollbarsClipped&&t.scroller.offsetWidth&&(t.nativeBarWidth=t.scroller.offsetWidth-t.scroller.clientWidth,t.heightForcer.style.height=zt(e)+"px",t.sizer.style.marginBottom=-t.nativeBarWidth+"px",t.sizer.style.borderRightWidth=zt(e)+"px",t.scrollbarsClipped=!0)}function kn(e){if(e.hasFocus())return null;var t=l();if(!t||!o(e.display.lineDiv,t))return null;var r={activeElt:t};if(window.getSelection){var n=window.getSelection();n.anchorNode&&n.extend&&o(e.display.lineDiv,n.anchorNode)&&(r.anchorNode=n.anchorNode,r.anchorOffset=n.anchorOffset,r.focusNode=n.focusNode,r.focusOffset=n.focusOffset)}return r}function Tn(e){if(e&&e.activeElt&&e.activeElt!=l()&&(e.activeElt.focus(),e.anchorNode&&o(document.body,e.anchorNode)&&o(document.body,e.focusNode))){var t=window.getSelection(),r=document.createRange();r.setEnd(e.anchorNode,e.anchorOffset),r.collapse(!1),t.removeAllRanges(),t.addRange(r),t.extend(e.focusNode,e.focusOffset)}}function Mn(e,r){var n=e.display,i=e.doc;if(r.editorIsHidden)return yn(e),!1;if(!r.force&&r.visible.from>=n.viewFrom&&r.visible.to<=n.viewTo&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo)&&n.renderedView==n.view&&0==xn(e))return!1;Rr(e)&&(yn(e),r.dims=br(e));var o=i.first+i.size,l=Math.max(r.visible.from-e.options.viewportMargin,i.first),s=Math.min(o,r.visible.to+e.options.viewportMargin);n.viewFrom<l&&l-n.viewFrom<20&&(l=Math.max(i.first,n.viewFrom)),n.viewTo>s&&n.viewTo-s<20&&(s=Math.min(o,n.viewTo)),_l&&(l=pe(e.doc,l),s=ge(e.doc,s));var a=l!=n.viewFrom||s!=n.viewTo||n.lastWrapHeight!=r.wrapperHeight||n.lastWrapWidth!=r.wrapperWidth;wn(e,l,s),n.viewOffset=ye(M(e.doc,n.viewFrom)),e.display.mover.style.top=n.viewOffset+"px";var u=xn(e);if(!a&&0==u&&!r.force&&n.renderedView==n.view&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo))return!1;var c=kn(e);return u>4&&(n.lineDiv.style.display="none"),An(e,n.updateLineNumbers,r.dims),u>4&&(n.lineDiv.style.display=""),n.renderedView=n.view,Tn(c),t(n.cursorDiv),t(n.selectionDiv),n.gutters.style.height=n.sizer.style.minHeight=0,a&&(n.lastWrapHeight=r.wrapperHeight,n.lastWrapWidth=r.wrapperWidth,Cn(e,400)),n.updateLineNumbers=null,!0}function Nn(e,t){for(var r=t.viewport,n=!0;(n&&e.options.lineWrapping&&t.oldDisplayWidth!=Rt(e)||(r&&null!=r.top&&(r={top:Math.min(e.doc.height+Pt(e.display)-Bt(e),r.top)}),t.visible=Ir(e.display,e.doc,r),!(t.visible.from>=e.display.viewFrom&&t.visible.to<=e.display.viewTo)))&&Mn(e,t);n=!1){Er(e);var i=Jr(e);kr(e),en(e,i),Dn(e,i),t.force=!1}t.signal(e,"update",e),e.display.viewFrom==e.display.reportedViewFrom&&e.display.viewTo==e.display.reportedViewTo||(t.signal(e,"viewportChange",e,e.display.viewFrom,e.display.viewTo),e.display.reportedViewFrom=e.display.viewFrom,e.display.reportedViewTo=e.display.viewTo)}function On(e,t){var r=new Cs(e,t);if(Mn(e,r)){Er(e),Nn(e,r);var n=Jr(e);kr(e),en(e,n),Dn(e,n),r.finish()}}function An(e,r,n){function i(t){var r=t.nextSibling;return ml&&Ml&&e.display.currentWheelTarget==t?t.style.display="none":t.parentNode.removeChild(t),r}for(var o=e.display,l=e.options.lineNumbers,s=o.lineDiv,a=s.firstChild,u=o.view,c=o.viewFrom,f=0;f<u.length;f++){var d=u[f];if(d.hidden);else if(d.node&&d.node.parentNode==s){for(;a!=d.node;)a=i(a);var p=l&&null!=r&&r<=c&&d.lineNumber;d.changes&&(h(d.changes,"gutter")>-1&&(p=!1),xt(e,d,c,n)),p&&(t(d.lineNumber),d.lineNumber.appendChild(document.createTextNode(F(e.options,c)))),a=d.node.nextSibling}else{var g=Ot(e,d,c,n);s.insertBefore(g,a)}c+=d.size}for(;a;)a=i(a)}function Wn(e){var t=e.display.gutters.offsetWidth;e.display.sizer.style.marginLeft=t+"px"}function Dn(e,t){e.display.sizer.style.minHeight=t.docHeight+"px",e.display.heightForcer.style.top=t.docHeight+"px",e.display.gutters.style.height=t.docHeight+e.display.barHeight+zt(e)+"px"}function Hn(e){var r=e.display.gutters,i=e.options.gutters;t(r);for(var o=0;o<i.length;++o){var l=i[o],s=r.appendChild(n("div",null,"CodeMirror-gutter "+l));"CodeMirror-linenumbers"==l&&(e.display.lineGutter=s,s.style.width=(e.display.lineNumWidth||1)+"px")}r.style.display=o?"":"none",Wn(e)}function Fn(e){var t=h(e.gutters,"CodeMirror-linenumbers");-1==t&&e.lineNumbers?e.gutters=e.gutters.concat(["CodeMirror-linenumbers"]):t>-1&&!e.lineNumbers&&(e.gutters=e.gutters.slice(0),e.gutters.splice(t,1))}function En(e){var t=e.wheelDeltaX,r=e.wheelDeltaY;return null==t&&e.detail&&e.axis==e.HORIZONTAL_AXIS&&(t=e.detail),null==r&&e.detail&&e.axis==e.VERTICAL_AXIS?r=e.detail:null==r&&(r=e.wheelDelta),{x:t,y:r}}function Pn(e){var t=En(e);return t.x*=Ls,t.y*=Ls,t}function In(e,t){var r=En(t),n=r.x,i=r.y,o=e.display,l=o.scroller,s=l.scrollWidth>l.clientWidth,a=l.scrollHeight>l.clientHeight;if(n&&s||i&&a){if(i&&Ml&&ml)e:for(var u=t.target,c=o.view;u!=l;u=u.parentNode)for(var f=0;f<c.length;f++)if(c[f].node==u){e.display.currentWheelTarget=u;break e}if(n&&!fl&&!wl&&null!=Ls)return i&&a&&qr(e,Math.max(0,l.scrollTop+i*Ls)),Qr(e,Math.max(0,l.scrollLeft+n*Ls)),(!i||i&&a)&&We(t),void(o.wheelStartX=null);if(i&&null!=Ls){var h=i*Ls,d=e.doc.scrollTop,p=d+o.wrapper.clientHeight;h<0?d=Math.max(0,d+h-50):p=Math.min(e.doc.height,p+h+50),On(e,{top:d,bottom:p})}Ss<20&&(null==o.wheelStartX?(o.wheelStartX=l.scrollLeft,o.wheelStartY=l.scrollTop,o.wheelDX=n,o.wheelDY=i,setTimeout(function(){if(null!=o.wheelStartX){var e=l.scrollLeft-o.wheelStartX,t=l.scrollTop-o.wheelStartY,r=t&&o.wheelDY&&t/o.wheelDY||e&&o.wheelDX&&e/o.wheelDX;o.wheelStartX=o.wheelStartY=null,r&&(Ls=(Ls*Ss+r)/(Ss+1),++Ss)}},200)):(o.wheelDX+=n,o.wheelDY+=i))}}function zn(e,t){var r=e[t];e.sort(function(e,t){return P(e.from(),t.from())}),t=h(e,r);for(var n=1;n<e.length;n++){var i=e[n],o=e[n-1];if(P(o.to(),i.from())>=0){var l=B(o.from(),i.from()),s=R(o.to(),i.to()),a=o.empty()?i.from()==i.head:o.from()==o.head;n<=t&&--t,e.splice(--n,2,new Ts(a?s:l,a?l:s))}}return new ks(e,t)}function Rn(e,t){return new ks([new Ts(e,t||e)],0)}function Bn(e){return e.text?E(e.from.line+e.text.length-1,g(e.text).length+(1==e.text.length?e.from.ch:0)):e.to}function Gn(e,t){if(P(e,t.from)<0)return e;if(P(e,t.to)<=0)return Bn(t);var r=e.line+t.text.length-(t.to.line-t.from.line)-1,n=e.ch;return e.line==t.to.line&&(n+=Bn(t).ch-t.to.ch),E(r,n)}function Un(e,t){for(var r=[],n=0;n<e.sel.ranges.length;n++){var i=e.sel.ranges[n];r.push(new Ts(Gn(i.anchor,t),Gn(i.head,t)))}return zn(r,e.sel.primIndex)}function Vn(e,t,r){return e.line==t.line?E(r.line,e.ch-t.ch+r.ch):E(r.line+(e.line-t.line),e.ch)}function Kn(e,t,r){for(var n=[],i=E(e.first,0),o=i,l=0;l<t.length;l++){var s=t[l],a=Vn(s.from,i,o),u=Vn(Bn(s),i,o);if(i=s.to,o=u,"around"==r){var c=e.sel.ranges[l],f=P(c.head,c.anchor)<0;n[l]=new Ts(f?u:a,f?a:u)}else n[l]=new Ts(a,a)}return new ks(n,e.sel.primIndex)}function jn(e){e.doc.mode=Ue(e.options,e.doc.modeOption),Xn(e)}function Xn(e){e.doc.iter(function(e){e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null)}),e.doc.modeFrontier=e.doc.highlightFrontier=e.doc.first,Cn(e,100),e.state.modeGen++,e.curOp&&vn(e)}function Yn(e,t){return 0==t.from.ch&&0==t.to.ch&&""==g(t.text)&&(!e.cm||e.cm.options.wholeLineUpdateBefore)}function _n(e,t,r,n){function i(e){return r?r[e]:null}function o(e,r,i){it(e,r,i,n),bt(e,"change",e,t)}function l(e,t){for(var r=[],o=e;o<t;++o)r.push(new fs(u[o],i(o),n));return r}var s=t.from,a=t.to,u=t.text,c=M(e,s.line),f=M(e,a.line),h=g(u),d=i(u.length-1),p=a.line-s.line;if(t.full)e.insert(0,l(0,u.length)),e.remove(u.length,e.size-u.length);else if(Yn(e,t)){var v=l(0,u.length-1);o(f,f.text,d),p&&e.remove(s.line,p),v.length&&e.insert(s.line,v)}else if(c==f)if(1==u.length)o(c,c.text.slice(0,s.ch)+h+c.text.slice(a.ch),d);else{var m=l(1,u.length-1);m.push(new fs(h+c.text.slice(a.ch),d,n)),o(c,c.text.slice(0,s.ch)+u[0],i(0)),e.insert(s.line+1,m)}else if(1==u.length)o(c,c.text.slice(0,s.ch)+u[0]+f.text.slice(a.ch),i(0)),e.remove(s.line+1,p);else{o(c,c.text.slice(0,s.ch)+u[0],i(0)),o(f,h+f.text.slice(a.ch),d);var y=l(1,u.length-1);p>1&&e.remove(s.line+1,p-1),e.insert(s.line+1,y)}bt(e,"change",e,t)}function $n(e,t,r){function n(e,i,o){if(e.linked)for(var l=0;l<e.linked.length;++l){var s=e.linked[l];if(s.doc!=i){var a=o&&s.sharedHist;r&&!a||(t(s.doc,a),n(s.doc,e,a))}}}n(e,null,!0)}function qn(e,t){if(t.cm)throw new Error("This document is already in use.");e.doc=t,t.cm=e,Cr(e),jn(e),Zn(e),e.options.lineWrapping||we(e),e.options.mode=t.modeOption,vn(e)}function Zn(e){("rtl"==e.doc.direction?s:Fl)(e.display.lineDiv,"CodeMirror-rtl")}function Qn(e){hn(e,function(){Zn(e),vn(e)})}function Jn(e){this.done=[],this.undone=[],this.undoDepth=1/0,this.lastModTime=this.lastSelTime=0,this.lastOp=this.lastSelOp=null,this.lastOrigin=this.lastSelOrigin=null,this.generation=this.maxGeneration=e||1}function ei(e,t){var r={from:z(t.from),to:Bn(t),text:N(e,t.from,t.to)};return si(e,r,t.from.line,t.to.line+1),$n(e,function(e){return si(e,r,t.from.line,t.to.line+1)},!0),r}function ti(e){for(;e.length&&g(e).ranges;)e.pop()}function ri(e,t){return t?(ti(e.done),g(e.done)):e.done.length&&!g(e.done).ranges?g(e.done):e.done.length>1&&!e.done[e.done.length-2].ranges?(e.done.pop(),g(e.done)):void 0}function ni(e,t,r,n){var i=e.history;i.undone.length=0;var o,l,s=+new Date;if((i.lastOp==n||i.lastOrigin==t.origin&&t.origin&&("+"==t.origin.charAt(0)&&e.cm&&i.lastModTime>s-e.cm.options.historyEventDelay||"*"==t.origin.charAt(0)))&&(o=ri(i,i.lastOp==n)))l=g(o.changes),0==P(t.from,t.to)&&0==P(t.from,l.to)?l.to=Bn(t):o.changes.push(ei(e,t));else{var a=g(i.done);for(a&&a.ranges||li(e.sel,i.done),o={changes:[ei(e,t)],generation:i.generation},i.done.push(o);i.done.length>i.undoDepth;)i.done.shift(),i.done[0].ranges||i.done.shift()}i.done.push(r),i.generation=++i.maxGeneration,i.lastModTime=i.lastSelTime=s,i.lastOp=i.lastSelOp=n,i.lastOrigin=i.lastSelOrigin=t.origin,l||Te(e,"historyAdded")}function ii(e,t,r,n){var i=t.charAt(0);return"*"==i||"+"==i&&r.ranges.length==n.ranges.length&&r.somethingSelected()==n.somethingSelected()&&new Date-e.history.lastSelTime<=(e.cm?e.cm.options.historyEventDelay:500)}function oi(e,t,r,n){var i=e.history,o=n&&n.origin;r==i.lastSelOp||o&&i.lastSelOrigin==o&&(i.lastModTime==i.lastSelTime&&i.lastOrigin==o||ii(e,o,g(i.done),t))?i.done[i.done.length-1]=t:li(t,i.done),i.lastSelTime=+new Date,i.lastSelOrigin=o,i.lastSelOp=r,n&&!1!==n.clearRedo&&ti(i.undone)}function li(e,t){var r=g(t);r&&r.ranges&&r.equals(e)||t.push(e)}function si(e,t,r,n){var i=t["spans_"+e.id],o=0;e.iter(Math.max(e.first,r),Math.min(e.first+e.size,n),function(r){r.markedSpans&&((i||(i=t["spans_"+e.id]={}))[o]=r.markedSpans),++o})}function ai(e){if(!e)return null;for(var t,r=0;r<e.length;++r)e[r].marker.explicitlyCleared?t||(t=e.slice(0,r)):t&&t.push(e[r]);return t?t.length?t:null:e}function ui(e,t){var r=t["spans_"+e.id];if(!r)return null;for(var n=[],i=0;i<t.text.length;++i)n.push(ai(r[i]));return n}function ci(e,t){var r=ui(e,t),n=J(e,t);if(!r)return n;if(!n)return r;for(var i=0;i<r.length;++i){var o=r[i],l=n[i];if(o&&l)e:for(var s=0;s<l.length;++s){for(var a=l[s],u=0;u<o.length;++u)if(o[u].marker==a.marker)continue e;o.push(a)}else l&&(r[i]=l)}return r}function fi(e,t,r){for(var n=[],i=0;i<e.length;++i){var o=e[i];if(o.ranges)n.push(r?ks.prototype.deepCopy.call(o):o);else{var l=o.changes,s=[];n.push({changes:s});for(var a=0;a<l.length;++a){var u=l[a],c=void 0;if(s.push({from:u.from,to:u.to,text:u.text}),t)for(var f in u)(c=f.match(/^spans_(\d+)$/))&&h(t,Number(c[1]))>-1&&(g(s)[f]=u[f],delete u[f])}}}return n}function hi(e,t,r,n){if(n){var i=e.anchor;if(r){var o=P(t,i)<0;o!=P(r,i)<0?(i=t,t=r):o!=P(t,r)<0&&(t=r)}return new Ts(i,t)}return new Ts(r||t,t)}function di(e,t,r,n,i){null==i&&(i=e.cm&&(e.cm.display.shift||e.extend)),bi(e,new ks([hi(e.sel.primary(),t,r,i)],0),n)}function pi(e,t,r){for(var n=[],i=e.cm&&(e.cm.display.shift||e.extend),o=0;o<e.sel.ranges.length;o++)n[o]=hi(e.sel.ranges[o],t[o],null,i);bi(e,zn(n,e.sel.primIndex),r)}function gi(e,t,r,n){var i=e.sel.ranges.slice(0);i[t]=r,bi(e,zn(i,e.sel.primIndex),n)}function vi(e,t,r,n){bi(e,Rn(t,r),n)}function mi(e,t,r){var n={ranges:t.ranges,update:function(t){var r=this;this.ranges=[];for(var n=0;n<t.length;n++)r.ranges[n]=new Ts(U(e,t[n].anchor),U(e,t[n].head))},origin:r&&r.origin};return Te(e,"beforeSelectionChange",e,n),e.cm&&Te(e.cm,"beforeSelectionChange",e.cm,n),n.ranges!=t.ranges?zn(n.ranges,n.ranges.length-1):t}function yi(e,t,r){var n=e.history.done,i=g(n);i&&i.ranges?(n[n.length-1]=t,wi(e,t,r)):bi(e,t,r)}function bi(e,t,r){wi(e,t,r),oi(e,e.sel,e.cm?e.cm.curOp.id:NaN,r)}function wi(e,t,r){(Oe(e,"beforeSelectionChange")||e.cm&&Oe(e.cm,"beforeSelectionChange"))&&(t=mi(e,t,r)),xi(e,Si(e,t,r&&r.bias||(P(t.primary().head,e.sel.primary().head)<0?-1:1),!0)),r&&!1===r.scroll||!e.cm||jr(e.cm)}function xi(e,t){t.equals(e.sel)||(e.sel=t,e.cm&&(e.cm.curOp.updateInput=e.cm.curOp.selectionChanged=!0,Ne(e.cm)),bt(e,"cursorActivity",e))}function Ci(e){xi(e,Si(e,e.sel,null,!1))}function Si(e,t,r,n){for(var i,o=0;o<t.ranges.length;o++){var l=t.ranges[o],s=t.ranges.length==e.sel.ranges.length&&e.sel.ranges[o],a=ki(e,l.anchor,s&&s.anchor,r,n),u=ki(e,l.head,s&&s.head,r,n);(i||a!=l.anchor||u!=l.head)&&(i||(i=t.ranges.slice(0,o)),i[o]=new Ts(a,u))}return i?zn(i,t.primIndex):t}function Li(e,t,r,n,i){var o=M(e,t.line);if(o.markedSpans)for(var l=0;l<o.markedSpans.length;++l){var s=o.markedSpans[l],a=s.marker;if((null==s.from||(a.inclusiveLeft?s.from<=t.ch:s.from<t.ch))&&(null==s.to||(a.inclusiveRight?s.to>=t.ch:s.to>t.ch))){if(i&&(Te(a,"beforeCursorEnter"),a.explicitlyCleared)){if(o.markedSpans){--l;continue}break}if(!a.atomic)continue;if(r){var u=a.find(n<0?1:-1),c=void 0;if((n<0?a.inclusiveRight:a.inclusiveLeft)&&(u=Ti(e,u,-n,u&&u.line==t.line?o:null)),u&&u.line==t.line&&(c=P(u,r))&&(n<0?c<0:c>0))return Li(e,u,t,n,i)}var f=a.find(n<0?-1:1);return(n<0?a.inclusiveLeft:a.inclusiveRight)&&(f=Ti(e,f,n,f.line==t.line?o:null)),f?Li(e,f,t,n,i):null}}return t}function ki(e,t,r,n,i){var o=n||1,l=Li(e,t,r,o,i)||!i&&Li(e,t,r,o,!0)||Li(e,t,r,-o,i)||!i&&Li(e,t,r,-o,!0);return l||(e.cantEdit=!0,E(e.first,0))}function Ti(e,t,r,n){return r<0&&0==t.ch?t.line>e.first?U(e,E(t.line-1)):null:r>0&&t.ch==(n||M(e,t.line)).text.length?t.line<e.first+e.size-1?E(t.line+1,0):null:new E(t.line,t.ch+r)}function Mi(e){e.setSelection(E(e.firstLine(),0),E(e.lastLine()),Gl)}function Ni(e,t,r){var n={canceled:!1,from:t.from,to:t.to,text:t.text,origin:t.origin,cancel:function(){return n.canceled=!0}};return r&&(n.update=function(t,r,i,o){t&&(n.from=U(e,t)),r&&(n.to=U(e,r)),i&&(n.text=i),void 0!==o&&(n.origin=o)}),Te(e,"beforeChange",e,n),e.cm&&Te(e.cm,"beforeChange",e.cm,n),n.canceled?null:{from:n.from,to:n.to,text:n.text,origin:n.origin}}function Oi(e,t,r){if(e.cm){if(!e.cm.curOp)return dn(e.cm,Oi)(e,t,r);if(e.cm.state.suppressEdits)return}if(!(Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"))||(t=Ni(e,t,!0))){var n=Yl&&!r&&te(e,t.from,t.to);if(n)for(var i=n.length-1;i>=0;--i)Ai(e,{from:n[i].from,to:n[i].to,text:i?[""]:t.text,origin:t.origin});else Ai(e,t)}}function Ai(e,t){if(1!=t.text.length||""!=t.text[0]||0!=P(t.from,t.to)){var r=Un(e,t);ni(e,t,r,e.cm?e.cm.curOp.id:NaN),Hi(e,t,r,J(e,t));var n=[];$n(e,function(e,r){r||-1!=h(n,e.history)||(zi(e.history,t),n.push(e.history)),Hi(e,t,null,J(e,t))})}}function Wi(e,t,r){if(!e.cm||!e.cm.state.suppressEdits||r){for(var n,i=e.history,o=e.sel,l="undo"==t?i.done:i.undone,s="undo"==t?i.undone:i.done,a=0;a<l.length&&(n=l[a],r?!n.ranges||n.equals(e.sel):n.ranges);a++);if(a!=l.length){for(i.lastOrigin=i.lastSelOrigin=null;(n=l.pop()).ranges;){if(li(n,s),r&&!n.equals(e.sel))return void bi(e,n,{clearRedo:!1});o=n}var u=[];li(o,s),s.push({changes:u,generation:i.generation}),i.generation=n.generation||++i.maxGeneration;for(var c=Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"),f=n.changes.length-1;f>=0;--f){var d=function(r){var i=n.changes[r];if(i.origin=t,c&&!Ni(e,i,!1))return l.length=0,{};u.push(ei(e,i));var o=r?Un(e,i):g(l);Hi(e,i,o,ci(e,i)),!r&&e.cm&&e.cm.scrollIntoView({from:i.from,to:Bn(i)});var s=[];$n(e,function(e,t){t||-1!=h(s,e.history)||(zi(e.history,i),s.push(e.history)),Hi(e,i,null,ci(e,i))})}(f);if(d)return d.v}}}}function Di(e,t){if(0!=t&&(e.first+=t,e.sel=new ks(v(e.sel.ranges,function(e){return new Ts(E(e.anchor.line+t,e.anchor.ch),E(e.head.line+t,e.head.ch))}),e.sel.primIndex),e.cm)){vn(e.cm,e.first,e.first-t,t);for(var r=e.cm.display,n=r.viewFrom;n<r.viewTo;n++)mn(e.cm,n,"gutter")}}function Hi(e,t,r,n){if(e.cm&&!e.cm.curOp)return dn(e.cm,Hi)(e,t,r,n);if(t.to.line<e.first)Di(e,t.text.length-1-(t.to.line-t.from.line));else if(!(t.from.line>e.lastLine())){if(t.from.line<e.first){var i=t.text.length-1-(e.first-t.from.line);Di(e,i),t={from:E(e.first,0),to:E(t.to.line+i,t.to.ch),text:[g(t.text)],origin:t.origin}}var o=e.lastLine();t.to.line>o&&(t={from:t.from,to:E(o,M(e,o).text.length),text:[t.text[0]],origin:t.origin}),t.removed=N(e,t.from,t.to),r||(r=Un(e,t)),e.cm?Fi(e.cm,t,n):_n(e,t,n),wi(e,r,Gl)}}function Fi(e,t,r){var n=e.doc,i=e.display,o=t.from,l=t.to,s=!1,a=o.line;e.options.lineWrapping||(a=W(fe(M(n,o.line))),n.iter(a,l.line+1,function(e){if(e==i.maxLine)return s=!0,!0})),n.sel.contains(t.from,t.to)>-1&&Ne(e),_n(n,t,r,xr(e)),e.options.lineWrapping||(n.iter(a,o.line+t.text.length,function(e){var t=be(e);t>i.maxLineLength&&(i.maxLine=e,i.maxLineLength=t,i.maxLineChanged=!0,s=!1)}),s&&(e.curOp.updateMaxLine=!0)),nt(n,o.line),Cn(e,400);var u=t.text.length-(l.line-o.line)-1;t.full?vn(e):o.line!=l.line||1!=t.text.length||Yn(e.doc,t)?vn(e,o.line,l.line+1,u):mn(e,o.line,"text");var c=Oe(e,"changes"),f=Oe(e,"change");if(f||c){var h={from:o,to:l,text:t.text,removed:t.removed,origin:t.origin};f&&bt(e,"change",e,h),c&&(e.curOp.changeObjs||(e.curOp.changeObjs=[])).push(h)}e.display.selForContextMenu=null}function Ei(e,t,r,n,i){if(n||(n=r),P(n,r)<0){var o;r=(o=[n,r])[0],n=o[1]}"string"==typeof t&&(t=e.splitLines(t)),Oi(e,{from:r,to:n,text:t,origin:i})}function Pi(e,t,r,n){r<e.line?e.line+=n:t<e.line&&(e.line=t,e.ch=0)}function Ii(e,t,r,n){for(var i=0;i<e.length;++i){var o=e[i],l=!0;if(o.ranges){o.copied||((o=e[i]=o.deepCopy()).copied=!0);for(var s=0;s<o.ranges.length;s++)Pi(o.ranges[s].anchor,t,r,n),Pi(o.ranges[s].head,t,r,n)}else{for(var a=0;a<o.changes.length;++a){var u=o.changes[a];if(r<u.from.line)u.from=E(u.from.line+n,u.from.ch),u.to=E(u.to.line+n,u.to.ch);else if(t<=u.to.line){l=!1;break}}l||(e.splice(0,i+1),i=0)}}}function zi(e,t){var r=t.from.line,n=t.to.line,i=t.text.length-(n-r)-1;Ii(e.done,r,n,i),Ii(e.undone,r,n,i)}function Ri(e,t,r,n){var i=t,o=t;return"number"==typeof t?o=M(e,G(e,t)):i=W(t),null==i?null:(n(o,i)&&e.cm&&mn(e.cm,i,r),o)}function Bi(e){var t=this;this.lines=e,this.parent=null;for(var r=0,n=0;n<e.length;++n)e[n].parent=t,r+=e[n].height;this.height=r}function Gi(e){var t=this;this.children=e;for(var r=0,n=0,i=0;i<e.length;++i){var o=e[i];r+=o.chunkSize(),n+=o.height,o.parent=t}this.size=r,this.height=n,this.parent=null}function Ui(e,t,r){ye(t)<(e.curOp&&e.curOp.scrollTop||e.doc.scrollTop)&&Kr(e,r)}function Vi(e,t,r,n){var i=new Ms(e,r,n),o=e.cm;return o&&i.noHScroll&&(o.display.alignWidgets=!0),Ri(e,t,"widget",function(t){var r=t.widgets||(t.widgets=[]);if(null==i.insertAt?r.push(i):r.splice(Math.min(r.length-1,Math.max(0,i.insertAt)),0,i),i.line=t,o&&!ve(e,t)){var n=ye(t)<e.scrollTop;A(t,t.height+Ht(i)),n&&Kr(o,i.height),o.curOp.forceUpdate=!0}return!0}),bt(o,"lineWidgetAdded",o,i,"number"==typeof t?t:W(t)),i}function Ki(e,t,r,n,o){if(n&&n.shared)return ji(e,t,r,n,o);if(e.cm&&!e.cm.curOp)return dn(e.cm,Ki)(e,t,r,n,o);var l=new Os(e,o),s=P(t,r);if(n&&c(n,l,!1),s>0||0==s&&!1!==l.clearWhenEmpty)return l;if(l.replacedWith&&(l.collapsed=!0,l.widgetNode=i("span",[l.replacedWith],"CodeMirror-widget"),n.handleMouseEvents||l.widgetNode.setAttribute("cm-ignore-events","true"),n.insertLeft&&(l.widgetNode.insertLeft=!0)),l.collapsed){if(ce(e,t.line,t,r,l)||t.line!=r.line&&ce(e,r.line,t,r,l))throw new Error("Inserting collapsed marker partially overlapping an existing one");X()}l.addToHistory&&ni(e,{from:t,to:r,origin:"markText"},e.sel,NaN);var a,u=t.line,f=e.cm;if(e.iter(u,r.line+1,function(e){f&&l.collapsed&&!f.options.lineWrapping&&fe(e)==f.display.maxLine&&(a=!0),l.collapsed&&u!=t.line&&A(e,0),q(e,new Y(l,u==t.line?t.ch:null,u==r.line?r.ch:null)),++u}),l.collapsed&&e.iter(t.line,r.line+1,function(t){ve(e,t)&&A(t,0)}),l.clearOnEnter&&Ql(l,"beforeCursorEnter",function(){return l.clear()}),l.readOnly&&(j(),(e.history.done.length||e.history.undone.length)&&e.clearHistory()),l.collapsed&&(l.id=++Ns,l.atomic=!0),f){if(a&&(f.curOp.updateMaxLine=!0),l.collapsed)vn(f,t.line,r.line+1);else if(l.className||l.title||l.startStyle||l.endStyle||l.css)for(var h=t.line;h<=r.line;h++)mn(f,h,"text");l.atomic&&Ci(f.doc),bt(f,"markerAdded",f,l)}return l}function ji(e,t,r,n,i){(n=c(n)).shared=!1;var o=[Ki(e,t,r,n,i)],l=o[0],s=n.widgetNode;return $n(e,function(e){s&&(n.widgetNode=s.cloneNode(!0)),o.push(Ki(e,U(e,t),U(e,r),n,i));for(var a=0;a<e.linked.length;++a)if(e.linked[a].isParent)return;l=g(o)}),new As(o,l)}function Xi(e){return e.findMarks(E(e.first,0),e.clipPos(E(e.lastLine())),function(e){return e.parent})}function Yi(e,t){for(var r=0;r<t.length;r++){var n=t[r],i=n.find(),o=e.clipPos(i.from),l=e.clipPos(i.to);if(P(o,l)){var s=Ki(e,o,l,n.primary,n.primary.type);n.markers.push(s),s.parent=n}}}function _i(e){for(var t=0;t<e.length;t++)!function(t){var r=e[t],n=[r.primary.doc];$n(r.primary.doc,function(e){return n.push(e)});for(var i=0;i<r.markers.length;i++){var o=r.markers[i];-1==h(n,o.doc)&&(o.parent=null,r.markers.splice(i--,1))}}(t)}function $i(e){var t=this;if(Qi(t),!Me(t,e)&&!Ft(t.display,e)){We(e),gl&&(Hs=+new Date);var r=Sr(t,e,!0),n=e.dataTransfer.files;if(r&&!t.isReadOnly())if(n&&n.length&&window.FileReader&&window.File)for(var i=n.length,o=Array(i),l=0,s=0;s<i;++s)!function(e,n){if(!t.options.allowDropFileTypes||-1!=h(t.options.allowDropFileTypes,e.type)){var s=new FileReader;s.onload=dn(t,function(){var e=s.result;if(/[\x00-\x08\x0e-\x1f]{2}/.test(e)&&(e=""),o[n]=e,++l==i){var a={from:r=U(t.doc,r),to:r,text:t.doc.splitLines(o.join(t.doc.lineSeparator())),origin:"paste"};Oi(t.doc,a),yi(t.doc,Rn(r,Bn(a)))}}),s.readAsText(e)}}(n[s],s);else{if(t.state.draggingText&&t.doc.sel.contains(r)>-1)return t.state.draggingText(e),void setTimeout(function(){return t.display.input.focus()},20);try{var a=e.dataTransfer.getData("Text");if(a){var u;if(t.state.draggingText&&!t.state.draggingText.copy&&(u=t.listSelections()),wi(t.doc,Rn(r,r)),u)for(var c=0;c<u.length;++c)Ei(t.doc,"",u[c].anchor,u[c].head,"drag");t.replaceSelection(a,"around","paste"),t.display.input.focus()}}catch(e){}}}}function qi(e,t){if(gl&&(!e.state.draggingText||+new Date-Hs<100))Fe(t);else if(!Me(e,t)&&!Ft(e.display,t)&&(t.dataTransfer.setData("Text",e.getSelection()),t.dataTransfer.effectAllowed="copyMove",t.dataTransfer.setDragImage&&!xl)){var r=n("img",null,null,"position: fixed; left: 0; top: 0;");r.src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==",wl&&(r.width=r.height=1,e.display.wrapper.appendChild(r),r._top=r.offsetTop),t.dataTransfer.setDragImage(r,0,0),wl&&r.parentNode.removeChild(r)}}function Zi(e,t){var i=Sr(e,t);if(i){var o=document.createDocumentFragment();Mr(e,i,o),e.display.dragCursor||(e.display.dragCursor=n("div",null,"CodeMirror-cursors CodeMirror-dragcursors"),e.display.lineSpace.insertBefore(e.display.dragCursor,e.display.cursorDiv)),r(e.display.dragCursor,o)}}function Qi(e){e.display.dragCursor&&(e.display.lineSpace.removeChild(e.display.dragCursor),e.display.dragCursor=null)}function Ji(e){if(document.getElementsByClassName)for(var t=document.getElementsByClassName("CodeMirror"),r=0;r<t.length;r++){var n=t[r].CodeMirror;n&&e(n)}}function eo(){Fs||(to(),Fs=!0)}function to(){var e;Ql(window,"resize",function(){null==e&&(e=setTimeout(function(){e=null,Ji(ro)},100))}),Ql(window,"blur",function(){return Ji(Fr)})}function ro(e){var t=e.display;t.lastWrapHeight==t.wrapper.clientHeight&&t.lastWrapWidth==t.wrapper.clientWidth||(t.cachedCharWidth=t.cachedTextHeight=t.cachedPaddingH=null,t.scrollbarsClipped=!1,e.setSize())}function no(e){var t=e.split(/-(?!$)/);e=t[t.length-1];for(var r,n,i,o,l=0;l<t.length-1;l++){var s=t[l];if(/^(cmd|meta|m)$/i.test(s))o=!0;else if(/^a(lt)?$/i.test(s))r=!0;else if(/^(c|ctrl|control)$/i.test(s))n=!0;else{if(!/^s(hift)?$/i.test(s))throw new Error("Unrecognized modifier name: "+s);i=!0}}return r&&(e="Alt-"+e),n&&(e="Ctrl-"+e),o&&(e="Cmd-"+e),i&&(e="Shift-"+e),e}function io(e){var t={};for(var r in e)if(e.hasOwnProperty(r)){var n=e[r];if(/^(name|fallthrough|(de|at)tach)$/.test(r))continue;if("..."==n){delete e[r];continue}for(var i=v(r.split(" "),no),o=0;o<i.length;o++){var l=void 0,s=void 0;o==i.length-1?(s=i.join(" "),l=n):(s=i.slice(0,o+1).join(" "),l="...");var a=t[s];if(a){if(a!=l)throw new Error("Inconsistent bindings for "+s)}else t[s]=l}delete e[r]}for(var u in t)e[u]=t[u];return e}function oo(e,t,r,n){var i=(t=uo(t)).call?t.call(e,n):t[e];if(!1===i)return"nothing";if("..."===i)return"multi";if(null!=i&&r(i))return"handled";if(t.fallthrough){if("[object Array]"!=Object.prototype.toString.call(t.fallthrough))return oo(e,t.fallthrough,r,n);for(var o=0;o<t.fallthrough.length;o++){var l=oo(e,t.fallthrough[o],r,n);if(l)return l}}}function lo(e){var t="string"==typeof e?e:Es[e.keyCode];return"Ctrl"==t||"Alt"==t||"Shift"==t||"Mod"==t}function so(e,t,r){var n=e;return t.altKey&&"Alt"!=n&&(e="Alt-"+e),(Dl?t.metaKey:t.ctrlKey)&&"Ctrl"!=n&&(e="Ctrl-"+e),(Dl?t.ctrlKey:t.metaKey)&&"Cmd"!=n&&(e="Cmd-"+e),!r&&t.shiftKey&&"Shift"!=n&&(e="Shift-"+e),e}function ao(e,t){if(wl&&34==e.keyCode&&e.char)return!1;var r=Es[e.keyCode];return null!=r&&!e.altGraphKey&&so(r,e,t)}function uo(e){return"string"==typeof e?Rs[e]:e}function co(e,t){for(var r=e.doc.sel.ranges,n=[],i=0;i<r.length;i++){for(var o=t(r[i]);n.length&&P(o.from,g(n).to)<=0;){var l=n.pop();if(P(l.from,o.from)<0){o.from=l.from;break}}n.push(o)}hn(e,function(){for(var t=n.length-1;t>=0;t--)Ei(e.doc,"",n[t].from,n[t].to,"+delete");jr(e)})}function fo(e,t,r){var n=L(e.text,t+r,r);return n<0||n>e.text.length?null:n}function ho(e,t,r){var n=fo(e,t.ch,r);return null==n?null:new E(t.line,n,r<0?"after":"before")}function po(e,t,r,n,i){if(e){var o=Se(r,t.doc.direction);if(o){var l,s=i<0?g(o):o[0],a=i<0==(1==s.level)?"after":"before";if(s.level>0){var u=Xt(t,r);l=i<0?r.text.length-1:0;var c=Yt(t,u,l).top;l=k(function(e){return Yt(t,u,e).top==c},i<0==(1==s.level)?s.from:s.to-1,l),"before"==a&&(l=fo(r,l,1))}else l=i<0?s.to:s.from;return new E(n,l,a)}}return new E(n,i<0?r.text.length:0,i<0?"before":"after")}function go(e,t,r,n){var i=Se(t,e.doc.direction);if(!i)return ho(t,r,n);r.ch>=t.text.length?(r.ch=t.text.length,r.sticky="before"):r.ch<=0&&(r.ch=0,r.sticky="after");var o=Ce(i,r.ch,r.sticky),l=i[o];if("ltr"==e.doc.direction&&l.level%2==0&&(n>0?l.to>r.ch:l.from<r.ch))return ho(t,r,n);var s,a=function(e,r){return fo(t,e instanceof E?e.ch:e,r)},u=function(r){return e.options.lineWrapping?(s=s||Xt(e,t),hr(e,t,s,r)):{begin:0,end:t.text.length}},c=u("before"==r.sticky?a(r,-1):r.ch);if("rtl"==e.doc.direction||1==l.level){var f=1==l.level==n<0,h=a(r,f?1:-1);if(null!=h&&(f?h<=l.to&&h<=c.end:h>=l.from&&h>=c.begin)){var d=f?"before":"after";return new E(r.line,h,d)}}var p=function(e,t,n){for(var o=function(e,t){return t?new E(r.line,a(e,1),"before"):new E(r.line,e,"after")};e>=0&&e<i.length;e+=t){var l=i[e],s=t>0==(1!=l.level),u=s?n.begin:a(n.end,-1);if(l.from<=u&&u<l.to)return o(u,s);if(u=s?l.from:a(l.to,-1),n.begin<=u&&u<n.end)return o(u,s)}},g=p(o+n,n,c);if(g)return g;var v=n>0?c.end:a(c.begin,-1);return null==v||n>0&&v==t.text.length||!(g=p(n>0?0:i.length-1,n,u(v)))?null:g}function vo(e,t){var r=M(e.doc,t),n=fe(r);return n!=r&&(t=W(n)),po(!0,e,n,t,1)}function mo(e,t){var r=M(e.doc,t),n=he(r);return n!=r&&(t=W(n)),po(!0,e,r,t,-1)}function yo(e,t){var r=vo(e,t.line),n=M(e.doc,r.line),i=Se(n,e.doc.direction);if(!i||0==i[0].level){var o=Math.max(0,n.text.search(/\S/)),l=t.line==r.line&&t.ch<=o&&t.ch;return E(r.line,l?0:o,r.sticky)}return r}function bo(e,t,r){if("string"==typeof t&&!(t=Bs[t]))return!1;e.display.input.ensurePolled();var n=e.display.shift,i=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),r&&(e.display.shift=!1),i=t(e)!=Bl}finally{e.display.shift=n,e.state.suppressEdits=!1}return i}function wo(e,t,r){for(var n=0;n<e.state.keyMaps.length;n++){var i=oo(t,e.state.keyMaps[n],r,e);if(i)return i}return e.options.extraKeys&&oo(t,e.options.extraKeys,r,e)||oo(t,e.options.keyMap,r,e)}function xo(e,t,r,n){var i=e.state.keySeq;if(i){if(lo(t))return"handled";Gs.set(50,function(){e.state.keySeq==i&&(e.state.keySeq=null,e.display.input.reset())}),t=i+" "+t}var o=wo(e,t,n);return"multi"==o&&(e.state.keySeq=t),"handled"==o&&bt(e,"keyHandled",e,t,r),"handled"!=o&&"multi"!=o||(We(r),Ar(e)),i&&!o&&/\'$/.test(t)?(We(r),!0):!!o}function Co(e,t){var r=ao(t,!0);return!!r&&(t.shiftKey&&!e.state.keySeq?xo(e,"Shift-"+r,t,function(t){return bo(e,t,!0)})||xo(e,r,t,function(t){if("string"==typeof t?/^go[A-Z]/.test(t):t.motion)return bo(e,t)}):xo(e,r,t,function(t){return bo(e,t)}))}function So(e,t,r){return xo(e,"'"+r+"'",t,function(t){return bo(e,t,!0)})}function Lo(e){var t=this;if(t.curOp.focus=l(),!Me(t,e)){gl&&vl<11&&27==e.keyCode&&(e.returnValue=!1);var r=e.keyCode;t.display.shift=16==r||e.shiftKey;var n=Co(t,e);wl&&(Us=n?r:null,!n&&88==r&&!rs&&(Ml?e.metaKey:e.ctrlKey)&&t.replaceSelection("",null,"cut")),18!=r||/\bCodeMirror-crosshair\b/.test(t.display.lineDiv.className)||ko(t)}}function ko(e){function t(e){18!=e.keyCode&&e.altKey||(Fl(r,"CodeMirror-crosshair"),ke(document,"keyup",t),ke(document,"mouseover",t))}var r=e.display.lineDiv;s(r,"CodeMirror-crosshair"),Ql(document,"keyup",t),Ql(document,"mouseover",t)}function To(e){16==e.keyCode&&(this.doc.sel.shift=!1),Me(this,e)}function Mo(e){var t=this;if(!(Ft(t.display,e)||Me(t,e)||e.ctrlKey&&!e.altKey||Ml&&e.metaKey)){var r=e.keyCode,n=e.charCode;if(wl&&r==Us)return Us=null,void We(e);if(!wl||e.which&&!(e.which<10)||!Co(t,e)){var i=String.fromCharCode(null==n?r:n);"\b"!=i&&(So(t,e,i)||t.display.input.onKeyPress(e))}}}function No(e,t){var r=+new Date;return js&&js.compare(r,e,t)?(Ks=js=null,"triple"):Ks&&Ks.compare(r,e,t)?(js=new Vs(r,e,t),Ks=null,"double"):(Ks=new Vs(r,e,t),js=null,"single")}function Oo(e){var t=this,r=t.display;if(!(Me(t,e)||r.activeTouch&&r.input.supportsTouch()))if(r.input.ensurePolled(),r.shift=e.shiftKey,Ft(r,e))ml||(r.scroller.draggable=!1,setTimeout(function(){return r.scroller.draggable=!0},100));else if(!zo(t,e)){var n=Sr(t,e),i=Pe(e),o=n?No(n,i):"single";window.focus(),1==i&&t.state.selectingText&&t.state.selectingText(e),n&&Ao(t,i,n,o,e)||(1==i?n?Do(t,n,o,e):Ee(e)==r.scroller&&We(e):2==i?(n&&di(t.doc,n),setTimeout(function(){return r.input.focus()},20)):3==i&&(Hl?Ro(t,e):Dr(t)))}}function Ao(e,t,r,n,i){var o="Click";return"double"==n?o="Double"+o:"triple"==n&&(o="Triple"+o),o=(1==t?"Left":2==t?"Middle":"Right")+o,xo(e,so(o,i),i,function(t){if("string"==typeof t&&(t=Bs[t]),!t)return!1;var n=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),n=t(e,r)!=Bl}finally{e.state.suppressEdits=!1}return n})}function Wo(e,t,r){var n=e.getOption("configureMouse"),i=n?n(e,t,r):{};if(null==i.unit){var o=Nl?r.shiftKey&&r.metaKey:r.altKey;i.unit=o?"rectangle":"single"==t?"char":"double"==t?"word":"line"}return(null==i.extend||e.doc.extend)&&(i.extend=e.doc.extend||r.shiftKey),null==i.addNew&&(i.addNew=Ml?r.metaKey:r.ctrlKey),null==i.moveOnDrag&&(i.moveOnDrag=!(Ml?r.altKey:r.ctrlKey)),i}function Do(e,t,r,n){gl?setTimeout(u(Wr,e),0):e.curOp.focus=l();var i,o=Wo(e,r,n),s=e.doc.sel;e.options.dragDrop&&Jl&&!e.isReadOnly()&&"single"==r&&(i=s.contains(t))>-1&&(P((i=s.ranges[i]).from(),t)<0||t.xRel>0)&&(P(i.to(),t)>0||t.xRel<0)?Ho(e,n,t,o):Eo(e,n,t,o)}function Ho(e,t,r,n){var i=e.display,o=!1,l=dn(e,function(t){ml&&(i.scroller.draggable=!1),e.state.draggingText=!1,ke(document,"mouseup",l),ke(document,"mousemove",s),ke(i.scroller,"dragstart",a),ke(i.scroller,"drop",l),o||(We(t),n.addNew||di(e.doc,r,null,null,n.extend),ml||gl&&9==vl?setTimeout(function(){document.body.focus(),i.input.focus()},20):i.input.focus())}),s=function(e){o=o||Math.abs(t.clientX-e.clientX)+Math.abs(t.clientY-e.clientY)>=10},a=function(){return o=!0};ml&&(i.scroller.draggable=!0),e.state.draggingText=l,l.copy=!n.moveOnDrag,i.scroller.dragDrop&&i.scroller.dragDrop(),Ql(document,"mouseup",l),Ql(document,"mousemove",s),Ql(i.scroller,"dragstart",a),Ql(i.scroller,"drop",l),Dr(e),setTimeout(function(){return i.input.focus()},20)}function Fo(e,t,r){if("char"==r)return new Ts(t,t);if("word"==r)return e.findWordAt(t);if("line"==r)return new Ts(E(t.line,0),U(e.doc,E(t.line+1,0)));var n=r(e,t);return new Ts(n.from,n.to)}function Eo(e,t,r,n){function i(t){if(0!=P(m,t))if(m=t,"rectangle"==n.unit){for(var i=[],o=e.options.tabSize,l=f(M(u,r.line).text,r.ch,o),s=f(M(u,t.line).text,t.ch,o),a=Math.min(l,s),g=Math.max(l,s),v=Math.min(r.line,t.line),y=Math.min(e.lastLine(),Math.max(r.line,t.line));v<=y;v++){var b=M(u,v).text,w=d(b,a,o);a==g?i.push(new Ts(E(v,w),E(v,w))):b.length>w&&i.push(new Ts(E(v,w),E(v,d(b,g,o))))}i.length||i.push(new Ts(r,r)),bi(u,zn(p.ranges.slice(0,h).concat(i),h),{origin:"*mouse",scroll:!1}),e.scrollIntoView(t)}else{var x,C=c,S=Fo(e,t,n.unit),L=C.anchor;P(S.anchor,L)>0?(x=S.head,L=B(C.from(),S.anchor)):(x=S.anchor,L=R(C.to(),S.head));var k=p.ranges.slice(0);k[h]=Po(e,new Ts(U(u,L),x)),bi(u,zn(k,h),Ul)}}function o(t){var r=++b,s=Sr(e,t,!0,"rectangle"==n.unit);if(s)if(0!=P(s,m)){e.curOp.focus=l(),i(s);var c=Ir(a,u);(s.line>=c.to||s.line<c.from)&&setTimeout(dn(e,function(){b==r&&o(t)}),150)}else{var f=t.clientY<y.top?-20:t.clientY>y.bottom?20:0;f&&setTimeout(dn(e,function(){b==r&&(a.scroller.scrollTop+=f,o(t))}),50)}}function s(t){e.state.selectingText=!1,b=1/0,We(t),a.input.focus(),ke(document,"mousemove",w),ke(document,"mouseup",x),u.history.lastSelOrigin=null}var a=e.display,u=e.doc;We(t);var c,h,p=u.sel,g=p.ranges;if(n.addNew&&!n.extend?(h=u.sel.contains(r),c=h>-1?g[h]:new Ts(r,r)):(c=u.sel.primary(),h=u.sel.primIndex),"rectangle"==n.unit)n.addNew||(c=new Ts(r,r)),r=Sr(e,t,!0,!0),h=-1;else{var v=Fo(e,r,n.unit);c=n.extend?hi(c,v.anchor,v.head,n.extend):v}n.addNew?-1==h?(h=g.length,bi(u,zn(g.concat([c]),h),{scroll:!1,origin:"*mouse"})):g.length>1&&g[h].empty()&&"char"==n.unit&&!n.extend?(bi(u,zn(g.slice(0,h).concat(g.slice(h+1)),0),{scroll:!1,origin:"*mouse"}),p=u.sel):gi(u,h,c,Ul):(h=0,bi(u,new ks([c],0),Ul),p=u.sel);var m=r,y=a.wrapper.getBoundingClientRect(),b=0,w=dn(e,function(e){Pe(e)?o(e):s(e)}),x=dn(e,s);e.state.selectingText=x,Ql(document,"mousemove",w),Ql(document,"mouseup",x)}function Po(e,t){var r=t.anchor,n=t.head,i=M(e.doc,r.line);if(0==P(r,n)&&r.sticky==n.sticky)return t;var o=Se(i);if(!o)return t;var l=Ce(o,r.ch,r.sticky),s=o[l];if(s.from!=r.ch&&s.to!=r.ch)return t;var a=l+(s.from==r.ch==(1!=s.level)?0:1);if(0==a||a==o.length)return t;var u;if(n.line!=r.line)u=(n.line-r.line)*("ltr"==e.doc.direction?1:-1)>0;else{var c=Ce(o,n.ch,n.sticky),f=c-l||(n.ch-r.ch)*(1==s.level?-1:1);u=c==a-1||c==a?f<0:f>0}var h=o[a+(u?-1:0)],d=u==(1==h.level),p=d?h.from:h.to,g=d?"after":"before";return r.ch==p&&r.sticky==g?t:new Ts(new E(r.line,p,g),n)}function Io(e,t,r,n){var i,o;if(t.touches)i=t.touches[0].clientX,o=t.touches[0].clientY;else try{i=t.clientX,o=t.clientY}catch(t){return!1}if(i>=Math.floor(e.display.gutters.getBoundingClientRect().right))return!1;n&&We(t);var l=e.display,s=l.lineDiv.getBoundingClientRect();if(o>s.bottom||!Oe(e,r))return He(t);o-=s.top-l.viewOffset;for(var a=0;a<e.options.gutters.length;++a){var u=l.gutters.childNodes[a];if(u&&u.getBoundingClientRect().right>=i)return Te(e,r,e,D(e.doc,o),e.options.gutters[a],t),He(t)}}function zo(e,t){return Io(e,t,"gutterClick",!0)}function Ro(e,t){Ft(e.display,t)||Bo(e,t)||Me(e,t,"contextmenu")||e.display.input.onContextMenu(t)}function Bo(e,t){return!!Oe(e,"gutterContextMenu")&&Io(e,t,"gutterContextMenu",!1)}function Go(e){e.display.wrapper.className=e.display.wrapper.className.replace(/\s*cm-s-\S+/g,"")+e.options.theme.replace(/(^|\s)\s*/g," cm-s-"),er(e)}function Uo(e){Hn(e),vn(e),zr(e)}function Vo(e,t,r){if(!t!=!(r&&r!=Xs)){var n=e.display.dragFunctions,i=t?Ql:ke;i(e.display.scroller,"dragstart",n.start),i(e.display.scroller,"dragenter",n.enter),i(e.display.scroller,"dragover",n.over),i(e.display.scroller,"dragleave",n.leave),i(e.display.scroller,"drop",n.drop)}}function Ko(e){e.options.lineWrapping?(s(e.display.wrapper,"CodeMirror-wrap"),e.display.sizer.style.minWidth="",e.display.sizerWidth=null):(Fl(e.display.wrapper,"CodeMirror-wrap"),we(e)),Cr(e),vn(e),er(e),setTimeout(function(){return en(e)},100)}function jo(e,t){var r=this;if(!(this instanceof jo))return new jo(e,t);this.options=t=t?c(t):{},c(Ys,t,!1),Fn(t);var n=t.value;"string"==typeof n&&(n=new Ds(n,t.mode,null,t.lineSeparator,t.direction)),this.doc=n;var i=new jo.inputStyles[t.inputStyle](this),o=this.display=new T(e,n,i);o.wrapper.CodeMirror=this,Hn(this),Go(this),t.lineWrapping&&(this.display.wrapper.className+=" CodeMirror-wrap"),rn(this),this.state={keyMaps:[],overlays:[],modeGen:0,overwrite:!1,delayingBlurEvent:!1,focused:!1,suppressEdits:!1,pasteIncoming:!1,cutIncoming:!1,selectingText:!1,draggingText:!1,highlight:new Pl,keySeq:null,specialChars:null},t.autofocus&&!Tl&&o.input.focus(),gl&&vl<11&&setTimeout(function(){return r.display.input.reset(!0)},20),Xo(this),eo(),nn(this),this.curOp.forceUpdate=!0,qn(this,n),t.autofocus&&!Tl||this.hasFocus()?setTimeout(u(Hr,this),20):Fr(this);for(var l in _s)_s.hasOwnProperty(l)&&_s[l](r,t[l],Xs);Rr(this),t.finishInit&&t.finishInit(this);for(var s=0;s<$s.length;++s)$s[s](r);on(this),ml&&t.lineWrapping&&"optimizelegibility"==getComputedStyle(o.lineDiv).textRendering&&(o.lineDiv.style.textRendering="auto")}function Xo(e){function t(){i.activeTouch&&(o=setTimeout(function(){return i.activeTouch=null},1e3),(l=i.activeTouch).end=+new Date)}function r(e){if(1!=e.touches.length)return!1;var t=e.touches[0];return t.radiusX<=1&&t.radiusY<=1}function n(e,t){if(null==t.left)return!0;var r=t.left-e.left,n=t.top-e.top;return r*r+n*n>400}var i=e.display;Ql(i.scroller,"mousedown",dn(e,Oo)),gl&&vl<11?Ql(i.scroller,"dblclick",dn(e,function(t){if(!Me(e,t)){var r=Sr(e,t);if(r&&!zo(e,t)&&!Ft(e.display,t)){We(t);var n=e.findWordAt(r);di(e.doc,n.anchor,n.head)}}})):Ql(i.scroller,"dblclick",function(t){return Me(e,t)||We(t)}),Hl||Ql(i.scroller,"contextmenu",function(t){return Ro(e,t)});var o,l={end:0};Ql(i.scroller,"touchstart",function(t){if(!Me(e,t)&&!r(t)&&!zo(e,t)){i.input.ensurePolled(),clearTimeout(o);var n=+new Date;i.activeTouch={start:n,moved:!1,prev:n-l.end<=300?l:null},1==t.touches.length&&(i.activeTouch.left=t.touches[0].pageX,i.activeTouch.top=t.touches[0].pageY)}}),Ql(i.scroller,"touchmove",function(){i.activeTouch&&(i.activeTouch.moved=!0)}),Ql(i.scroller,"touchend",function(r){var o=i.activeTouch;if(o&&!Ft(i,r)&&null!=o.left&&!o.moved&&new Date-o.start<300){var l,s=e.coordsChar(i.activeTouch,"page");l=!o.prev||n(o,o.prev)?new Ts(s,s):!o.prev.prev||n(o,o.prev.prev)?e.findWordAt(s):new Ts(E(s.line,0),U(e.doc,E(s.line+1,0))),e.setSelection(l.anchor,l.head),e.focus(),We(r)}t()}),Ql(i.scroller,"touchcancel",t),Ql(i.scroller,"scroll",function(){i.scroller.clientHeight&&(qr(e,i.scroller.scrollTop),Qr(e,i.scroller.scrollLeft,!0),Te(e,"scroll",e))}),Ql(i.scroller,"mousewheel",function(t){return In(e,t)}),Ql(i.scroller,"DOMMouseScroll",function(t){return In(e,t)}),Ql(i.wrapper,"scroll",function(){return i.wrapper.scrollTop=i.wrapper.scrollLeft=0}),i.dragFunctions={enter:function(t){Me(e,t)||Fe(t)},over:function(t){Me(e,t)||(Zi(e,t),Fe(t))},start:function(t){return qi(e,t)},drop:dn(e,$i),leave:function(t){Me(e,t)||Qi(e)}};var s=i.input.getField();Ql(s,"keyup",function(t){return To.call(e,t)}),Ql(s,"keydown",dn(e,Lo)),Ql(s,"keypress",dn(e,Mo)),Ql(s,"focus",function(t){return Hr(e,t)}),Ql(s,"blur",function(t){return Fr(e,t)})}function Yo(e,t,r,n){var i,o=e.doc;null==r&&(r="add"),"smart"==r&&(o.mode.indent?i=$e(e,t).state:r="prev");var l=e.options.tabSize,s=M(o,t),a=f(s.text,null,l);s.stateAfter&&(s.stateAfter=null);var u,c=s.text.match(/^\s*/)[0];if(n||/\S/.test(s.text)){if("smart"==r&&((u=o.mode.indent(i,s.text.slice(c.length),s.text))==Bl||u>150)){if(!n)return;r="prev"}}else u=0,r="not";"prev"==r?u=t>o.first?f(M(o,t-1).text,null,l):0:"add"==r?u=a+e.options.indentUnit:"subtract"==r?u=a-e.options.indentUnit:"number"==typeof r&&(u=a+r),u=Math.max(0,u);var h="",d=0;if(e.options.indentWithTabs)for(var g=Math.floor(u/l);g;--g)d+=l,h+="\t";if(d<u&&(h+=p(u-d)),h!=c)return Ei(o,h,E(t,0),E(t,c.length),"+input"),s.stateAfter=null,!0;for(var v=0;v<o.sel.ranges.length;v++){var m=o.sel.ranges[v];if(m.head.line==t&&m.head.ch<c.length){var y=E(t,c.length);gi(o,v,new Ts(y,y));break}}}function _o(e){qs=e}function $o(e,t,r,n,i){var o=e.doc;e.display.shift=!1,n||(n=o.sel);var l=e.state.pasteIncoming||"paste"==i,s=es(t),a=null;if(l&&n.ranges.length>1)if(qs&&qs.text.join("\n")==t){if(n.ranges.length%qs.text.length==0){a=[];for(var u=0;u<qs.text.length;u++)a.push(o.splitLines(qs.text[u]))}}else s.length==n.ranges.length&&e.options.pasteLinesPerSelection&&(a=v(s,function(e){return[e]}));for(var c,f=n.ranges.length-1;f>=0;f--){var h=n.ranges[f],d=h.from(),p=h.to();h.empty()&&(r&&r>0?d=E(d.line,d.ch-r):e.state.overwrite&&!l?p=E(p.line,Math.min(M(o,p.line).text.length,p.ch+g(s).length)):qs&&qs.lineWise&&qs.text.join("\n")==t&&(d=p=E(d.line,0))),c=e.curOp.updateInput;var m={from:d,to:p,text:a?a[f%a.length]:s,origin:i||(l?"paste":e.state.cutIncoming?"cut":"+input")};Oi(e.doc,m),bt(e,"inputRead",e,m)}t&&!l&&Zo(e,t),jr(e),e.curOp.updateInput=c,e.curOp.typing=!0,e.state.pasteIncoming=e.state.cutIncoming=!1}function qo(e,t){var r=e.clipboardData&&e.clipboardData.getData("Text");if(r)return e.preventDefault(),t.isReadOnly()||t.options.disableInput||hn(t,function(){return $o(t,r,0,null,"paste")}),!0}function Zo(e,t){if(e.options.electricChars&&e.options.smartIndent)for(var r=e.doc.sel,n=r.ranges.length-1;n>=0;n--){var i=r.ranges[n];if(!(i.head.ch>100||n&&r.ranges[n-1].head.line==i.head.line)){var o=e.getModeAt(i.head),l=!1;if(o.electricChars){for(var s=0;s<o.electricChars.length;s++)if(t.indexOf(o.electricChars.charAt(s))>-1){l=Yo(e,i.head.line,"smart");break}}else o.electricInput&&o.electricInput.test(M(e.doc,i.head.line).text.slice(0,i.head.ch))&&(l=Yo(e,i.head.line,"smart"));l&&bt(e,"electricInput",e,i.head.line)}}}function Qo(e){for(var t=[],r=[],n=0;n<e.doc.sel.ranges.length;n++){var i=e.doc.sel.ranges[n].head.line,o={anchor:E(i,0),head:E(i+1,0)};r.push(o),t.push(e.getRange(o.anchor,o.head))}return{text:t,ranges:r}}function Jo(e,t){e.setAttribute("autocorrect","off"),e.setAttribute("autocapitalize","off"),e.setAttribute("spellcheck",!!t)}function el(){var e=n("textarea",null,null,"position: absolute; bottom: -1em; padding: 0; width: 1px; height: 1em; outline: none"),t=n("div",[e],null,"overflow: hidden; position: relative; width: 3px; height: 0px;");return ml?e.style.width="1000px":e.setAttribute("wrap","off"),Ll&&(e.style.border="1px solid black"),Jo(e),t}function tl(e,t,r,n,i){function o(){var n=t.line+r;return!(n<e.first||n>=e.first+e.size)&&(t=new E(n,t.ch,t.sticky),u=M(e,n))}function l(n){var l;if(null==(l=i?go(e.cm,u,t,r):ho(u,t,r))){if(n||!o())return!1;t=po(i,e.cm,u,t.line,r)}else t=l;return!0}var s=t,a=r,u=M(e,t.line);if("char"==n)l();else if("column"==n)l(!0);else if("word"==n||"group"==n)for(var c=null,f="group"==n,h=e.cm&&e.cm.getHelper(t,"wordChars"),d=!0;!(r<0)||l(!d);d=!1){var p=u.text.charAt(t.ch)||"\n",g=x(p,h)?"w":f&&"\n"==p?"n":!f||/\s/.test(p)?null:"p";if(!f||d||g||(g="s"),c&&c!=g){r<0&&(r=1,l(),t.sticky="after");break}if(g&&(c=g),r>0&&!l(!d))break}var v=ki(e,t,s,a,!0);return I(s,v)&&(v.hitSide=!0),v}function rl(e,t,r,n){var i,o=e.doc,l=t.left;if("page"==n){var s=Math.min(e.display.wrapper.clientHeight,window.innerHeight||document.documentElement.clientHeight),a=Math.max(s-.5*mr(e.display),3);i=(r>0?t.bottom:t.top)+r*a}else"line"==n&&(i=r>0?t.bottom+3:t.top-3);for(var u;(u=cr(e,l,i)).outside;){if(r<0?i<=0:i>=o.height){u.hitSide=!0;break}i+=5*r}return u}function nl(e,t){var r=jt(e,t.line);if(!r||r.hidden)return null;var n=M(e.doc,t.line),i=Ut(r,n,t.line),o=Se(n,e.doc.direction),l="left";o&&(l=Ce(o,t.ch)%2?"right":"left");var s=_t(i.map,t.ch,l);return s.offset="right"==s.collapse?s.end:s.start,s}function il(e){for(var t=e;t;t=t.parentNode)if(/CodeMirror-gutter-wrapper/.test(t.className))return!0;return!1}function ol(e,t){return t&&(e.bad=!0),e}function ll(e,t,r,n,i){function o(e){return function(t){return t.id==e}}function l(){c&&(u+=f,c=!1)}function s(e){e&&(l(),u+=e)}function a(t){if(1==t.nodeType){var r=t.getAttribute("cm-text");if(null!=r)return void s(r||t.textContent.replace(/\u200b/g,""));var u,h=t.getAttribute("cm-marker");if(h){var d=e.findMarks(E(n,0),E(i+1,0),o(+h));return void(d.length&&(u=d[0].find(0))&&s(N(e.doc,u.from,u.to).join(f)))}if("false"==t.getAttribute("contenteditable"))return;var p=/^(pre|div|p)$/i.test(t.nodeName);p&&l();for(var g=0;g<t.childNodes.length;g++)a(t.childNodes[g]);p&&(c=!0)}else 3==t.nodeType&&s(t.nodeValue)}for(var u="",c=!1,f=e.doc.lineSeparator();a(t),t!=r;)t=t.nextSibling;return u}function sl(e,t,r){var n;if(t==e.display.lineDiv){if(!(n=e.display.lineDiv.childNodes[r]))return ol(e.clipPos(E(e.display.viewTo-1)),!0);t=null,r=0}else for(n=t;;n=n.parentNode){if(!n||n==e.display.lineDiv)return null;if(n.parentNode&&n.parentNode==e.display.lineDiv)break}for(var i=0;i<e.display.view.length;i++){var o=e.display.view[i];if(o.node==n)return al(o,t,r)}}function al(e,t,r){function n(t,r,n){for(var i=-1;i<(f?f.length:0);i++)for(var o=i<0?c.map:f[i],l=0;l<o.length;l+=3){var s=o[l+2];if(s==t||s==r){var a=W(i<0?e.line:e.rest[i]),u=o[l]+n;return(n<0||s!=t)&&(u=o[l+(n?1:0)]),E(a,u)}}}var i=e.text.firstChild,l=!1;if(!t||!o(i,t))return ol(E(W(e.line),0),!0);if(t==i&&(l=!0,t=i.childNodes[r],r=0,!t)){var s=e.rest?g(e.rest):e.line;return ol(E(W(s),s.text.length),l)}var a=3==t.nodeType?t:null,u=t;for(a||1!=t.childNodes.length||3!=t.firstChild.nodeType||(a=t.firstChild,r&&(r=a.nodeValue.length));u.parentNode!=i;)u=u.parentNode;var c=e.measure,f=c.maps,h=n(a,u,r);if(h)return ol(h,l);for(var d=u.nextSibling,p=a?a.nodeValue.length-r:0;d;d=d.nextSibling){if(h=n(d,d.firstChild,0))return ol(E(h.line,h.ch-p),l);p+=d.textContent.length}for(var v=u.previousSibling,m=r;v;v=v.previousSibling){if(h=n(v,v.firstChild,-1))return ol(E(h.line,h.ch+m),l);m+=v.textContent.length}}var ul=navigator.userAgent,cl=navigator.platform,fl=/gecko\/\d/i.test(ul),hl=/MSIE \d/.test(ul),dl=/Trident\/(?:[7-9]|\d{2,})\..*rv:(\d+)/.exec(ul),pl=/Edge\/(\d+)/.exec(ul),gl=hl||dl||pl,vl=gl&&(hl?document.documentMode||6:+(pl||dl)[1]),ml=!pl&&/WebKit\//.test(ul),yl=ml&&/Qt\/\d+\.\d+/.test(ul),bl=!pl&&/Chrome\//.test(ul),wl=/Opera\//.test(ul),xl=/Apple Computer/.test(navigator.vendor),Cl=/Mac OS X 1\d\D([8-9]|\d\d)\D/.test(ul),Sl=/PhantomJS/.test(ul),Ll=!pl&&/AppleWebKit/.test(ul)&&/Mobile\/\w+/.test(ul),kl=/Android/.test(ul),Tl=Ll||kl||/webOS|BlackBerry|Opera Mini|Opera Mobi|IEMobile/i.test(ul),Ml=Ll||/Mac/.test(cl),Nl=/\bCrOS\b/.test(ul),Ol=/win/i.test(cl),Al=wl&&ul.match(/Version\/(\d*\.\d*)/);Al&&(Al=Number(Al[1])),Al&&Al>=15&&(wl=!1,ml=!0);var Wl,Dl=Ml&&(yl||wl&&(null==Al||Al<12.11)),Hl=fl||gl&&vl>=9,Fl=function(t,r){var n=t.className,i=e(r).exec(n);if(i){var o=n.slice(i.index+i[0].length);t.className=n.slice(0,i.index)+(o?i[1]+o:"")}};Wl=document.createRange?function(e,t,r,n){var i=document.createRange();return i.setEnd(n||e,r),i.setStart(e,t),i}:function(e,t,r){var n=document.body.createTextRange();try{n.moveToElementText(e.parentNode)}catch(e){return n}return n.collapse(!0),n.moveEnd("character",r),n.moveStart("character",t),n};var El=function(e){e.select()};Ll?El=function(e){e.selectionStart=0,e.selectionEnd=e.value.length}:gl&&(El=function(e){try{e.select()}catch(e){}});var Pl=function(){this.id=null};Pl.prototype.set=function(e,t){clearTimeout(this.id),this.id=setTimeout(t,e)};var Il,zl,Rl=30,Bl={toString:function(){return"CodeMirror.Pass"}},Gl={scroll:!1},Ul={origin:"*mouse"},Vl={origin:"+move"},Kl=[""],jl=/[\u00df\u0587\u0590-\u05f4\u0600-\u06ff\u3040-\u309f\u30a0-\u30ff\u3400-\u4db5\u4e00-\u9fcc\uac00-\ud7af]/,Xl=/[\u0300-\u036f\u0483-\u0489\u0591-\u05bd\u05bf\u05c1\u05c2\u05c4\u05c5\u05c7\u0610-\u061a\u064b-\u065e\u0670\u06d6-\u06dc\u06de-\u06e4\u06e7\u06e8\u06ea-\u06ed\u0711\u0730-\u074a\u07a6-\u07b0\u07eb-\u07f3\u0816-\u0819\u081b-\u0823\u0825-\u0827\u0829-\u082d\u0900-\u0902\u093c\u0941-\u0948\u094d\u0951-\u0955\u0962\u0963\u0981\u09bc\u09be\u09c1-\u09c4\u09cd\u09d7\u09e2\u09e3\u0a01\u0a02\u0a3c\u0a41\u0a42\u0a47\u0a48\u0a4b-\u0a4d\u0a51\u0a70\u0a71\u0a75\u0a81\u0a82\u0abc\u0ac1-\u0ac5\u0ac7\u0ac8\u0acd\u0ae2\u0ae3\u0b01\u0b3c\u0b3e\u0b3f\u0b41-\u0b44\u0b4d\u0b56\u0b57\u0b62\u0b63\u0b82\u0bbe\u0bc0\u0bcd\u0bd7\u0c3e-\u0c40\u0c46-\u0c48\u0c4a-\u0c4d\u0c55\u0c56\u0c62\u0c63\u0cbc\u0cbf\u0cc2\u0cc6\u0ccc\u0ccd\u0cd5\u0cd6\u0ce2\u0ce3\u0d3e\u0d41-\u0d44\u0d4d\u0d57\u0d62\u0d63\u0dca\u0dcf\u0dd2-\u0dd4\u0dd6\u0ddf\u0e31\u0e34-\u0e3a\u0e47-\u0e4e\u0eb1\u0eb4-\u0eb9\u0ebb\u0ebc\u0ec8-\u0ecd\u0f18\u0f19\u0f35\u0f37\u0f39\u0f71-\u0f7e\u0f80-\u0f84\u0f86\u0f87\u0f90-\u0f97\u0f99-\u0fbc\u0fc6\u102d-\u1030\u1032-\u1037\u1039\u103a\u103d\u103e\u1058\u1059\u105e-\u1060\u1071-\u1074\u1082\u1085\u1086\u108d\u109d\u135f\u1712-\u1714\u1732-\u1734\u1752\u1753\u1772\u1773\u17b7-\u17bd\u17c6\u17c9-\u17d3\u17dd\u180b-\u180d\u18a9\u1920-\u1922\u1927\u1928\u1932\u1939-\u193b\u1a17\u1a18\u1a56\u1a58-\u1a5e\u1a60\u1a62\u1a65-\u1a6c\u1a73-\u1a7c\u1a7f\u1b00-\u1b03\u1b34\u1b36-\u1b3a\u1b3c\u1b42\u1b6b-\u1b73\u1b80\u1b81\u1ba2-\u1ba5\u1ba8\u1ba9\u1c2c-\u1c33\u1c36\u1c37\u1cd0-\u1cd2\u1cd4-\u1ce0\u1ce2-\u1ce8\u1ced\u1dc0-\u1de6\u1dfd-\u1dff\u200c\u200d\u20d0-\u20f0\u2cef-\u2cf1\u2de0-\u2dff\u302a-\u302f\u3099\u309a\ua66f-\ua672\ua67c\ua67d\ua6f0\ua6f1\ua802\ua806\ua80b\ua825\ua826\ua8c4\ua8e0-\ua8f1\ua926-\ua92d\ua947-\ua951\ua980-\ua982\ua9b3\ua9b6-\ua9b9\ua9bc\uaa29-\uaa2e\uaa31\uaa32\uaa35\uaa36\uaa43\uaa4c\uaab0\uaab2-\uaab4\uaab7\uaab8\uaabe\uaabf\uaac1\uabe5\uabe8\uabed\udc00-\udfff\ufb1e\ufe00-\ufe0f\ufe20-\ufe26\uff9e\uff9f]/,Yl=!1,_l=!1,$l=null,ql=function(){function e(e){return e<=247?r.charAt(e):1424<=e&&e<=1524?"R":1536<=e&&e<=1785?n.charAt(e-1536):1774<=e&&e<=2220?"r":8192<=e&&e<=8203?"w":8204==e?"b":"L"}function t(e,t,r){this.level=e,this.from=t,this.to=r}var r="bbbbbbbbbtstwsbbbbbbbbbbbbbbssstwNN%%%NNNNNN,N,N1111111111NNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNbbbbbbsbbbbbbbbbbbbbbbbbbbbbbbbbb,N%%%%NNNNLNNNNN%%11NLNNN1LNNNNNLLLLLLLLLLLLLLLLLLLLLLLNLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLN",n="nnnnnnNNr%%r,rNNmmmmmmmmmmmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmmmmmmmmmmmmmmmnnnnnnnnnn%nnrrrmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmnNmmmmmmrrmmNmmmmrr1111111111",i=/[\u0590-\u05f4\u0600-\u06ff\u0700-\u08ac]/,o=/[stwN]/,l=/[LRr]/,s=/[Lb1n]/,a=/[1n]/;return function(r,n){var u="ltr"==n?"L":"R";if(0==r.length||"ltr"==n&&!i.test(r))return!1;for(var c=r.length,f=[],h=0;h<c;++h)f.push(e(r.charCodeAt(h)));for(var d=0,p=u;d<c;++d){var v=f[d];"m"==v?f[d]=p:p=v}for(var m=0,y=u;m<c;++m){var b=f[m];"1"==b&&"r"==y?f[m]="n":l.test(b)&&(y=b,"r"==b&&(f[m]="R"))}for(var w=1,x=f[0];w<c-1;++w){var C=f[w];"+"==C&&"1"==x&&"1"==f[w+1]?f[w]="1":","!=C||x!=f[w+1]||"1"!=x&&"n"!=x||(f[w]=x),x=C}for(var S=0;S<c;++S){var L=f[S];if(","==L)f[S]="N";else if("%"==L){var k=void 0;for(k=S+1;k<c&&"%"==f[k];++k);for(var T=S&&"!"==f[S-1]||k<c&&"1"==f[k]?"1":"N",M=S;M<k;++M)f[M]=T;S=k-1}}for(var N=0,O=u;N<c;++N){var A=f[N];"L"==O&&"1"==A?f[N]="L":l.test(A)&&(O=A)}for(var W=0;W<c;++W)if(o.test(f[W])){var D=void 0;for(D=W+1;D<c&&o.test(f[D]);++D);for(var H="L"==(W?f[W-1]:u),F=H==("L"==(D<c?f[D]:u))?H?"L":"R":u,E=W;E<D;++E)f[E]=F;W=D-1}for(var P,I=[],z=0;z<c;)if(s.test(f[z])){var R=z;for(++z;z<c&&s.test(f[z]);++z);I.push(new t(0,R,z))}else{var B=z,G=I.length;for(++z;z<c&&"L"!=f[z];++z);for(var U=B;U<z;)if(a.test(f[U])){B<U&&I.splice(G,0,new t(1,B,U));var V=U;for(++U;U<z&&a.test(f[U]);++U);I.splice(G,0,new t(2,V,U)),B=U}else++U;B<z&&I.splice(G,0,new t(1,B,z))}return 1==I[0].level&&(P=r.match(/^\s+/))&&(I[0].from=P[0].length,I.unshift(new t(0,0,P[0].length))),1==g(I).level&&(P=r.match(/\s+$/))&&(g(I).to-=P[0].length,I.push(new t(0,c-P[0].length,c))),"rtl"==n?I.reverse():I}}(),Zl=[],Ql=function(e,t,r){if(e.addEventListener)e.addEventListener(t,r,!1);else if(e.attachEvent)e.attachEvent("on"+t,r);else{var n=e._handlers||(e._handlers={});n[t]=(n[t]||Zl).concat(r)}},Jl=function(){if(gl&&vl<9)return!1;var e=n("div");return"draggable"in e||"dragDrop"in e}(),es=3!="\n\nb".split(/\n/).length?function(e){for(var t=0,r=[],n=e.length;t<=n;){var i=e.indexOf("\n",t);-1==i&&(i=e.length);var o=e.slice(t,"\r"==e.charAt(i-1)?i-1:i),l=o.indexOf("\r");-1!=l?(r.push(o.slice(0,l)),t+=l+1):(r.push(o),t=i+1)}return r}:function(e){return e.split(/\r\n?|\n/)},ts=window.getSelection?function(e){try{return e.selectionStart!=e.selectionEnd}catch(e){return!1}}:function(e){var t;try{t=e.ownerDocument.selection.createRange()}catch(e){}return!(!t||t.parentElement()!=e)&&0!=t.compareEndPoints("StartToEnd",t)},rs=function(){var e=n("div");return"oncopy"in e||(e.setAttribute("oncopy","return;"),"function"==typeof e.oncopy)}(),ns=null,is={},os={},ls={},ss=function(e,t,r){this.pos=this.start=0,this.string=e,this.tabSize=t||8,this.lastColumnPos=this.lastColumnValue=0,this.lineStart=0,this.lineOracle=r};ss.prototype.eol=function(){return this.pos>=this.string.length},ss.prototype.sol=function(){return this.pos==this.lineStart},ss.prototype.peek=function(){return this.string.charAt(this.pos)||void 0},ss.prototype.next=function(){if(this.pos<this.string.length)return this.string.charAt(this.pos++)},ss.prototype.eat=function(e){var t=this.string.charAt(this.pos);if("string"==typeof e?t==e:t&&(e.test?e.test(t):e(t)))return++this.pos,t},ss.prototype.eatWhile=function(e){for(var t=this.pos;this.eat(e););return this.pos>t},ss.prototype.eatSpace=function(){for(var e=this,t=this.pos;/[\s\u00a0]/.test(this.string.charAt(this.pos));)++e.pos;return this.pos>t},ss.prototype.skipToEnd=function(){this.pos=this.string.length},ss.prototype.skipTo=function(e){var t=this.string.indexOf(e,this.pos);if(t>-1)return this.pos=t,!0},ss.prototype.backUp=function(e){this.pos-=e},ss.prototype.column=function(){return this.lastColumnPos<this.start&&(this.lastColumnValue=f(this.string,this.start,this.tabSize,this.lastColumnPos,this.lastColumnValue),this.lastColumnPos=this.start),this.lastColumnValue-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.indentation=function(){return f(this.string,null,this.tabSize)-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.match=function(e,t,r){if("string"!=typeof e){var n=this.string.slice(this.pos).match(e);return n&&n.index>0?null:(n&&!1!==t&&(this.pos+=n[0].length),n)}var i=function(e){return r?e.toLowerCase():e};if(i(this.string.substr(this.pos,e.length))==i(e))return!1!==t&&(this.pos+=e.length),!0},ss.prototype.current=function(){return this.string.slice(this.start,this.pos)},ss.prototype.hideFirstChars=function(e,t){this.lineStart+=e;try{return t()}finally{this.lineStart-=e}},ss.prototype.lookAhead=function(e){var t=this.lineOracle;return t&&t.lookAhead(e)};var as=function(e,t){this.state=e,this.lookAhead=t},us=function(e,t,r,n){this.state=t,this.doc=e,this.line=r,this.maxLookAhead=n||0};us.prototype.lookAhead=function(e){var t=this.doc.getLine(this.line+e);return null!=t&&e>this.maxLookAhead&&(this.maxLookAhead=e),t},us.prototype.nextLine=function(){this.line++,this.maxLookAhead>0&&this.maxLookAhead--},us.fromSaved=function(e,t,r){return t instanceof as?new us(e,Ke(e.mode,t.state),r,t.lookAhead):new us(e,Ke(e.mode,t),r)},us.prototype.save=function(e){var t=!1!==e?Ke(this.doc.mode,this.state):this.state;return this.maxLookAhead>0?new as(t,this.maxLookAhead):t};var cs=function(e,t,r){this.start=e.start,this.end=e.pos,this.string=e.current(),this.type=t||null,this.state=r},fs=function(e,t,r){this.text=e,ne(this,t),this.height=r?r(this):1};fs.prototype.lineNo=function(){return W(this)},Ae(fs);var hs,ds={},ps={},gs=null,vs=null,ms={left:0,right:0,top:0,bottom:0},ys=function(e,t,r){this.cm=r;var i=this.vert=n("div",[n("div",null,null,"min-width: 1px")],"CodeMirror-vscrollbar"),o=this.horiz=n("div",[n("div",null,null,"height: 100%; min-height: 1px")],"CodeMirror-hscrollbar");e(i),e(o),Ql(i,"scroll",function(){i.clientHeight&&t(i.scrollTop,"vertical")}),Ql(o,"scroll",function(){o.clientWidth&&t(o.scrollLeft,"horizontal")}),this.checkedZeroWidth=!1,gl&&vl<8&&(this.horiz.style.minHeight=this.vert.style.minWidth="18px")};ys.prototype.update=function(e){var t=e.scrollWidth>e.clientWidth+1,r=e.scrollHeight>e.clientHeight+1,n=e.nativeBarWidth;if(r){this.vert.style.display="block",this.vert.style.bottom=t?n+"px":"0";var i=e.viewHeight-(t?n:0);this.vert.firstChild.style.height=Math.max(0,e.scrollHeight-e.clientHeight+i)+"px"}else this.vert.style.display="",this.vert.firstChild.style.height="0";if(t){this.horiz.style.display="block",this.horiz.style.right=r?n+"px":"0",this.horiz.style.left=e.barLeft+"px";var o=e.viewWidth-e.barLeft-(r?n:0);this.horiz.firstChild.style.width=Math.max(0,e.scrollWidth-e.clientWidth+o)+"px"}else this.horiz.style.display="",this.horiz.firstChild.style.width="0";return!this.checkedZeroWidth&&e.clientHeight>0&&(0==n&&this.zeroWidthHack(),this.checkedZeroWidth=!0),{right:r?n:0,bottom:t?n:0}},ys.prototype.setScrollLeft=function(e){this.horiz.scrollLeft!=e&&(this.horiz.scrollLeft=e),this.disableHoriz&&this.enableZeroWidthBar(this.horiz,this.disableHoriz,"horiz")},ys.prototype.setScrollTop=function(e){this.vert.scrollTop!=e&&(this.vert.scrollTop=e),this.disableVert&&this.enableZeroWidthBar(this.vert,this.disableVert,"vert")},ys.prototype.zeroWidthHack=function(){var e=Ml&&!Cl?"12px":"18px";this.horiz.style.height=this.vert.style.width=e,this.horiz.style.pointerEvents=this.vert.style.pointerEvents="none",this.disableHoriz=new Pl,this.disableVert=new Pl},ys.prototype.enableZeroWidthBar=function(e,t,r){function n(){var i=e.getBoundingClientRect();("vert"==r?document.elementFromPoint(i.right-1,(i.top+i.bottom)/2):document.elementFromPoint((i.right+i.left)/2,i.bottom-1))!=e?e.style.pointerEvents="none":t.set(1e3,n)}e.style.pointerEvents="auto",t.set(1e3,n)},ys.prototype.clear=function(){var e=this.horiz.parentNode;e.removeChild(this.horiz),e.removeChild(this.vert)};var bs=function(){};bs.prototype.update=function(){return{bottom:0,right:0}},bs.prototype.setScrollLeft=function(){},bs.prototype.setScrollTop=function(){},bs.prototype.clear=function(){};var ws={native:ys,null:bs},xs=0,Cs=function(e,t,r){var n=e.display;this.viewport=t,this.visible=Ir(n,e.doc,t),this.editorIsHidden=!n.wrapper.offsetWidth,this.wrapperHeight=n.wrapper.clientHeight,this.wrapperWidth=n.wrapper.clientWidth,this.oldDisplayWidth=Rt(e),this.force=r,this.dims=br(e),this.events=[]};Cs.prototype.signal=function(e,t){Oe(e,t)&&this.events.push(arguments)},Cs.prototype.finish=function(){for(var e=this,t=0;t<this.events.length;t++)Te.apply(null,e.events[t])};var Ss=0,Ls=null;gl?Ls=-.53:fl?Ls=15:bl?Ls=-.7:xl&&(Ls=-1/3);var ks=function(e,t){this.ranges=e,this.primIndex=t};ks.prototype.primary=function(){return this.ranges[this.primIndex]},ks.prototype.equals=function(e){var t=this;if(e==this)return!0;if(e.primIndex!=this.primIndex||e.ranges.length!=this.ranges.length)return!1;for(var r=0;r<this.ranges.length;r++){var n=t.ranges[r],i=e.ranges[r];if(!I(n.anchor,i.anchor)||!I(n.head,i.head))return!1}return!0},ks.prototype.deepCopy=function(){for(var e=this,t=[],r=0;r<this.ranges.length;r++)t[r]=new Ts(z(e.ranges[r].anchor),z(e.ranges[r].head));return new ks(t,this.primIndex)},ks.prototype.somethingSelected=function(){for(var e=this,t=0;t<this.ranges.length;t++)if(!e.ranges[t].empty())return!0;return!1},ks.prototype.contains=function(e,t){var r=this;t||(t=e);for(var n=0;n<this.ranges.length;n++){var i=r.ranges[n];if(P(t,i.from())>=0&&P(e,i.to())<=0)return n}return-1};var Ts=function(e,t){this.anchor=e,this.head=t};Ts.prototype.from=function(){return B(this.anchor,this.head)},Ts.prototype.to=function(){return R(this.anchor,this.head)},Ts.prototype.empty=function(){return this.head.line==this.anchor.line&&this.head.ch==this.anchor.ch},Bi.prototype={chunkSize:function(){return this.lines.length},removeInner:function(e,t){for(var r=this,n=e,i=e+t;n<i;++n){var o=r.lines[n];r.height-=o.height,ot(o),bt(o,"delete")}this.lines.splice(e,t)},collapse:function(e){e.push.apply(e,this.lines)},insertInner:function(e,t,r){var n=this;this.height+=r,this.lines=this.lines.slice(0,e).concat(t).concat(this.lines.slice(e));for(var i=0;i<t.length;++i)t[i].parent=n},iterN:function(e,t,r){for(var n=this,i=e+t;e<i;++e)if(r(n.lines[e]))return!0}},Gi.prototype={chunkSize:function(){return this.size},removeInner:function(e,t){var r=this;this.size-=t;for(var n=0;n<this.children.length;++n){var i=r.children[n],o=i.chunkSize();if(e<o){var l=Math.min(t,o-e),s=i.height;if(i.removeInner(e,l),r.height-=s-i.height,o==l&&(r.children.splice(n--,1),i.parent=null),0==(t-=l))break;e=0}else e-=o}if(this.size-t<25&&(this.children.length>1||!(this.children[0]instanceof Bi))){var a=[];this.collapse(a),this.children=[new Bi(a)],this.children[0].parent=this}},collapse:function(e){for(var t=this,r=0;r<this.children.length;++r)t.children[r].collapse(e)},insertInner:function(e,t,r){var n=this;this.size+=t.length,this.height+=r;for(var i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<=l){if(o.insertInner(e,t,r),o.lines&&o.lines.length>50){for(var s=o.lines.length%25+25,a=s;a<o.lines.length;){var u=new Bi(o.lines.slice(a,a+=25));o.height-=u.height,n.children.splice(++i,0,u),u.parent=n}o.lines=o.lines.slice(0,s),n.maybeSpill()}break}e-=l}},maybeSpill:function(){if(!(this.children.length<=10)){var e=this;do{var t=new Gi(e.children.splice(e.children.length-5,5));if(e.parent){e.size-=t.size,e.height-=t.height;var r=h(e.parent.children,e);e.parent.children.splice(r+1,0,t)}else{var n=new Gi(e.children);n.parent=e,e.children=[n,t],e=n}t.parent=e.parent}while(e.children.length>10);e.parent.maybeSpill()}},iterN:function(e,t,r){for(var n=this,i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<l){var s=Math.min(t,l-e);if(o.iterN(e,s,r))return!0;if(0==(t-=s))break;e=0}else e-=l}}};var Ms=function(e,t,r){var n=this;if(r)for(var i in r)r.hasOwnProperty(i)&&(n[i]=r[i]);this.doc=e,this.node=t};Ms.prototype.clear=function(){var e=this,t=this.doc.cm,r=this.line.widgets,n=this.line,i=W(n);if(null!=i&&r){for(var o=0;o<r.length;++o)r[o]==e&&r.splice(o--,1);r.length||(n.widgets=null);var l=Ht(this);A(n,Math.max(0,n.height-l)),t&&(hn(t,function(){Ui(t,n,-l),mn(t,i,"widget")}),bt(t,"lineWidgetCleared",t,this,i))}},Ms.prototype.changed=function(){var e=this,t=this.height,r=this.doc.cm,n=this.line;this.height=null;var i=Ht(this)-t;i&&(A(n,n.height+i),r&&hn(r,function(){r.curOp.forceUpdate=!0,Ui(r,n,i),bt(r,"lineWidgetChanged",r,e,W(n))}))},Ae(Ms);var Ns=0,Os=function(e,t){this.lines=[],this.type=t,this.doc=e,this.id=++Ns};Os.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){var t=this.doc.cm,r=t&&!t.curOp;if(r&&nn(t),Oe(this,"clear")){var n=this.find();n&&bt(this,"clear",n.from,n.to)}for(var i=null,o=null,l=0;l<this.lines.length;++l){var s=e.lines[l],a=_(s.markedSpans,e);t&&!e.collapsed?mn(t,W(s),"text"):t&&(null!=a.to&&(o=W(s)),null!=a.from&&(i=W(s))),s.markedSpans=$(s.markedSpans,a),null==a.from&&e.collapsed&&!ve(e.doc,s)&&t&&A(s,mr(t.display))}if(t&&this.collapsed&&!t.options.lineWrapping)for(var u=0;u<this.lines.length;++u){var c=fe(e.lines[u]),f=be(c);f>t.display.maxLineLength&&(t.display.maxLine=c,t.display.maxLineLength=f,t.display.maxLineChanged=!0)}null!=i&&t&&this.collapsed&&vn(t,i,o+1),this.lines.length=0,this.explicitlyCleared=!0,this.atomic&&this.doc.cantEdit&&(this.doc.cantEdit=!1,t&&Ci(t.doc)),t&&bt(t,"markerCleared",t,this,i,o),r&&on(t),this.parent&&this.parent.clear()}},Os.prototype.find=function(e,t){var r=this;null==e&&"bookmark"==this.type&&(e=1);for(var n,i,o=0;o<this.lines.length;++o){var l=r.lines[o],s=_(l.markedSpans,r);if(null!=s.from&&(n=E(t?l:W(l),s.from),-1==e))return n;if(null!=s.to&&(i=E(t?l:W(l),s.to),1==e))return i}return n&&{from:n,to:i}},Os.prototype.changed=function(){var e=this,t=this.find(-1,!0),r=this,n=this.doc.cm;t&&n&&hn(n,function(){var i=t.line,o=W(t.line),l=jt(n,o);if(l&&(Qt(l),n.curOp.selectionChanged=n.curOp.forceUpdate=!0),n.curOp.updateMaxLine=!0,!ve(r.doc,i)&&null!=r.height){var s=r.height;r.height=null;var a=Ht(r)-s;a&&A(i,i.height+a)}bt(n,"markerChanged",n,e)})},Os.prototype.attachLine=function(e){if(!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;t.maybeHiddenMarkers&&-1!=h(t.maybeHiddenMarkers,this)||(t.maybeUnhiddenMarkers||(t.maybeUnhiddenMarkers=[])).push(this)}this.lines.push(e)},Os.prototype.detachLine=function(e){if(this.lines.splice(h(this.lines,e),1),!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;(t.maybeHiddenMarkers||(t.maybeHiddenMarkers=[])).push(this)}},Ae(Os);var As=function(e,t){var r=this;this.markers=e,this.primary=t;for(var n=0;n<e.length;++n)e[n].parent=r};As.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){this.explicitlyCleared=!0;for(var t=0;t<this.markers.length;++t)e.markers[t].clear();bt(this,"clear")}},As.prototype.find=function(e,t){return this.primary.find(e,t)},Ae(As);var Ws=0,Ds=function(e,t,r,n,i){if(!(this instanceof Ds))return new Ds(e,t,r,n,i);null==r&&(r=0),Gi.call(this,[new Bi([new fs("",null)])]),this.first=r,this.scrollTop=this.scrollLeft=0,this.cantEdit=!1,this.cleanGeneration=1,this.modeFrontier=this.highlightFrontier=r;var o=E(r,0);this.sel=Rn(o),this.history=new Jn(null),this.id=++Ws,this.modeOption=t,this.lineSep=n,this.direction="rtl"==i?"rtl":"ltr",this.extend=!1,"string"==typeof e&&(e=this.splitLines(e)),_n(this,{from:o,to:o,text:e}),bi(this,Rn(o),Gl)};Ds.prototype=b(Gi.prototype,{constructor:Ds,iter:function(e,t,r){r?this.iterN(e-this.first,t-e,r):this.iterN(this.first,this.first+this.size,e)},insert:function(e,t){for(var r=0,n=0;n<t.length;++n)r+=t[n].height;this.insertInner(e-this.first,t,r)},remove:function(e,t){this.removeInner(e-this.first,t)},getValue:function(e){var t=O(this,this.first,this.first+this.size);return!1===e?t:t.join(e||this.lineSeparator())},setValue:gn(function(e){var t=E(this.first,0),r=this.first+this.size-1;Oi(this,{from:t,to:E(r,M(this,r).text.length),text:this.splitLines(e),origin:"setValue",full:!0},!0),this.cm&&Xr(this.cm,0,0),bi(this,Rn(t),Gl)}),replaceRange:function(e,t,r,n){Ei(this,e,t=U(this,t),r=r?U(this,r):t,n)},getRange:function(e,t,r){var n=N(this,U(this,e),U(this,t));return!1===r?n:n.join(r||this.lineSeparator())},getLine:function(e){var t=this.getLineHandle(e);return t&&t.text},getLineHandle:function(e){if(H(this,e))return M(this,e)},getLineNumber:function(e){return W(e)},getLineHandleVisualStart:function(e){return"number"==typeof e&&(e=M(this,e)),fe(e)},lineCount:function(){return this.size},firstLine:function(){return this.first},lastLine:function(){return this.first+this.size-1},clipPos:function(e){return U(this,e)},getCursor:function(e){var t=this.sel.primary();return null==e||"head"==e?t.head:"anchor"==e?t.anchor:"end"==e||"to"==e||!1===e?t.to():t.from()},listSelections:function(){return this.sel.ranges},somethingSelected:function(){return this.sel.somethingSelected()},setCursor:gn(function(e,t,r){vi(this,U(this,"number"==typeof e?E(e,t||0):e),null,r)}),setSelection:gn(function(e,t,r){vi(this,U(this,e),U(this,t||e),r)}),extendSelection:gn(function(e,t,r){di(this,U(this,e),t&&U(this,t),r)}),extendSelections:gn(function(e,t){pi(this,K(this,e),t)}),extendSelectionsBy:gn(function(e,t){pi(this,K(this,v(this.sel.ranges,e)),t)}),setSelections:gn(function(e,t,r){var n=this;if(e.length){for(var i=[],o=0;o<e.length;o++)i[o]=new Ts(U(n,e[o].anchor),U(n,e[o].head));null==t&&(t=Math.min(e.length-1,this.sel.primIndex)),bi(this,zn(i,t),r)}}),addSelection:gn(function(e,t,r){var n=this.sel.ranges.slice(0);n.push(new Ts(U(this,e),U(this,t||e))),bi(this,zn(n,n.length-1),r)}),getSelection:function(e){for(var t,r=this,n=this.sel.ranges,i=0;i<n.length;i++){var o=N(r,n[i].from(),n[i].to());t=t?t.concat(o):o}return!1===e?t:t.join(e||this.lineSeparator())},getSelections:function(e){for(var t=this,r=[],n=this.sel.ranges,i=0;i<n.length;i++){var o=N(t,n[i].from(),n[i].to());!1!==e&&(o=o.join(e||t.lineSeparator())),r[i]=o}return r},replaceSelection:function(e,t,r){for(var n=[],i=0;i<this.sel.ranges.length;i++)n[i]=e;this.replaceSelections(n,t,r||"+input")},replaceSelections:gn(function(e,t,r){for(var n=this,i=[],o=this.sel,l=0;l<o.ranges.length;l++){var s=o.ranges[l];i[l]={from:s.from(),to:s.to(),text:n.splitLines(e[l]),origin:r}}for(var a=t&&"end"!=t&&Kn(this,i,t),u=i.length-1;u>=0;u--)Oi(n,i[u]);a?yi(this,a):this.cm&&jr(this.cm)}),undo:gn(function(){Wi(this,"undo")}),redo:gn(function(){Wi(this,"redo")}),undoSelection:gn(function(){Wi(this,"undo",!0)}),redoSelection:gn(function(){Wi(this,"redo",!0)}),setExtending:function(e){this.extend=e},getExtending:function(){return this.extend},historySize:function(){for(var e=this.history,t=0,r=0,n=0;n<e.done.length;n++)e.done[n].ranges||++t;for(var i=0;i<e.undone.length;i++)e.undone[i].ranges||++r;return{undo:t,redo:r}},clearHistory:function(){this.history=new Jn(this.history.maxGeneration)},markClean:function(){this.cleanGeneration=this.changeGeneration(!0)},changeGeneration:function(e){return e&&(this.history.lastOp=this.history.lastSelOp=this.history.lastOrigin=null),this.history.generation},isClean:function(e){return this.history.generation==(e||this.cleanGeneration)},getHistory:function(){return{done:fi(this.history.done),undone:fi(this.history.undone)}},setHistory:function(e){var t=this.history=new Jn(this.history.maxGeneration);t.done=fi(e.done.slice(0),null,!0),t.undone=fi(e.undone.slice(0),null,!0)},setGutterMarker:gn(function(e,t,r){return Ri(this,e,"gutter",function(e){var n=e.gutterMarkers||(e.gutterMarkers={});return n[t]=r,!r&&C(n)&&(e.gutterMarkers=null),!0})}),clearGutter:gn(function(e){var t=this;this.iter(function(r){r.gutterMarkers&&r.gutterMarkers[e]&&Ri(t,r,"gutter",function(){return r.gutterMarkers[e]=null,C(r.gutterMarkers)&&(r.gutterMarkers=null),!0})})}),lineInfo:function(e){var t;if("number"==typeof e){if(!H(this,e))return null;if(t=e,!(e=M(this,e)))return null}else if(null==(t=W(e)))return null;return{line:t,handle:e,text:e.text,gutterMarkers:e.gutterMarkers,textClass:e.textClass,bgClass:e.bgClass,wrapClass:e.wrapClass,widgets:e.widgets}},addLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass";if(t[i]){if(e(n).test(t[i]))return!1;t[i]+=" "+n}else t[i]=n;return!0})}),removeLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass",o=t[i];if(!o)return!1;if(null==n)t[i]=null;else{var l=o.match(e(n));if(!l)return!1;var s=l.index+l[0].length;t[i]=o.slice(0,l.index)+(l.index&&s!=o.length?" ":"")+o.slice(s)||null}return!0})}),addLineWidget:gn(function(e,t,r){return Vi(this,e,t,r)}),removeLineWidget:function(e){e.clear()},markText:function(e,t,r){return Ki(this,U(this,e),U(this,t),r,r&&r.type||"range")},setBookmark:function(e,t){var r={replacedWith:t&&(null==t.nodeType?t.widget:t),insertLeft:t&&t.insertLeft,clearWhenEmpty:!1,shared:t&&t.shared,handleMouseEvents:t&&t.handleMouseEvents};return e=U(this,e),Ki(this,e,e,r,"bookmark")},findMarksAt:function(e){var t=[],r=M(this,(e=U(this,e)).line).markedSpans;if(r)for(var n=0;n<r.length;++n){var i=r[n];(null==i.from||i.from<=e.ch)&&(null==i.to||i.to>=e.ch)&&t.push(i.marker.parent||i.marker)}return t},findMarks:function(e,t,r){e=U(this,e),t=U(this,t);var n=[],i=e.line;return this.iter(e.line,t.line+1,function(o){var l=o.markedSpans;if(l)for(var s=0;s<l.length;s++){var a=l[s];null!=a.to&&i==e.line&&e.ch>=a.to||null==a.from&&i!=e.line||null!=a.from&&i==t.line&&a.from>=t.ch||r&&!r(a.marker)||n.push(a.marker.parent||a.marker)}++i}),n},getAllMarks:function(){var e=[];return this.iter(function(t){var r=t.markedSpans;if(r)for(var n=0;n<r.length;++n)null!=r[n].from&&e.push(r[n].marker)}),e},posFromIndex:function(e){var t,r=this.first,n=this.lineSeparator().length;return this.iter(function(i){var o=i.text.length+n;if(o>e)return t=e,!0;e-=o,++r}),U(this,E(r,t))},indexFromPos:function(e){var t=(e=U(this,e)).ch;if(e.line<this.first||e.ch<0)return 0;var r=this.lineSeparator().length;return this.iter(this.first,e.line,function(e){t+=e.text.length+r}),t},copy:function(e){var t=new Ds(O(this,this.first,this.first+this.size),this.modeOption,this.first,this.lineSep,this.direction);return t.scrollTop=this.scrollTop,t.scrollLeft=this.scrollLeft,t.sel=this.sel,t.extend=!1,e&&(t.history.undoDepth=this.history.undoDepth,t.setHistory(this.getHistory())),t},linkedDoc:function(e){e||(e={});var t=this.first,r=this.first+this.size;null!=e.from&&e.from>t&&(t=e.from),null!=e.to&&e.to<r&&(r=e.to);var n=new Ds(O(this,t,r),e.mode||this.modeOption,t,this.lineSep,this.direction);return e.sharedHist&&(n.history=this.history),(this.linked||(this.linked=[])).push({doc:n,sharedHist:e.sharedHist}),n.linked=[{doc:this,isParent:!0,sharedHist:e.sharedHist}],Yi(n,Xi(this)),n},unlinkDoc:function(e){var t=this;if(e instanceof jo&&(e=e.doc),this.linked)for(var r=0;r<this.linked.length;++r)if(t.linked[r].doc==e){t.linked.splice(r,1),e.unlinkDoc(t),_i(Xi(t));break}if(e.history==this.history){var n=[e.id];$n(e,function(e){return n.push(e.id)},!0),e.history=new Jn(null),e.history.done=fi(this.history.done,n),e.history.undone=fi(this.history.undone,n)}},iterLinkedDocs:function(e){$n(this,e)},getMode:function(){return this.mode},getEditor:function(){return this.cm},splitLines:function(e){return this.lineSep?e.split(this.lineSep):es(e)},lineSeparator:function(){return this.lineSep||"\n"},setDirection:gn(function(e){"rtl"!=e&&(e="ltr"),e!=this.direction&&(this.direction=e,this.iter(function(e){return e.order=null}),this.cm&&Qn(this.cm))})}),Ds.prototype.eachLine=Ds.prototype.iter;for(var Hs=0,Fs=!1,Es={3:"Enter",8:"Backspace",9:"Tab",13:"Enter",16:"Shift",17:"Ctrl",18:"Alt",19:"Pause",20:"CapsLock",27:"Esc",32:"Space",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"Left",38:"Up",39:"Right",40:"Down",44:"PrintScrn",45:"Insert",46:"Delete",59:";",61:"=",91:"Mod",92:"Mod",93:"Mod",106:"*",107:"=",109:"-",110:".",111:"/",127:"Delete",173:"-",186:";",187:"=",188:",",189:"-",190:".",191:"/",192:"`",219:"[",220:"\\",221:"]",222:"'",63232:"Up",63233:"Down",63234:"Left",63235:"Right",63272:"Delete",63273:"Home",63275:"End",63276:"PageUp",63277:"PageDown",63302:"Insert"},Ps=0;Ps<10;Ps++)Es[Ps+48]=Es[Ps+96]=String(Ps);for(var Is=65;Is<=90;Is++)Es[Is]=String.fromCharCode(Is);for(var zs=1;zs<=12;zs++)Es[zs+111]=Es[zs+63235]="F"+zs;var Rs={};Rs.basic={Left:"goCharLeft",Right:"goCharRight",Up:"goLineUp",Down:"goLineDown",End:"goLineEnd",Home:"goLineStartSmart",PageUp:"goPageUp",PageDown:"goPageDown",Delete:"delCharAfter",Backspace:"delCharBefore","Shift-Backspace":"delCharBefore",Tab:"defaultTab","Shift-Tab":"indentAuto",Enter:"newlineAndIndent",Insert:"toggleOverwrite",Esc:"singleSelection"},Rs.pcDefault={"Ctrl-A":"selectAll","Ctrl-D":"deleteLine","Ctrl-Z":"undo","Shift-Ctrl-Z":"redo","Ctrl-Y":"redo","Ctrl-Home":"goDocStart","Ctrl-End":"goDocEnd","Ctrl-Up":"goLineUp","Ctrl-Down":"goLineDown","Ctrl-Left":"goGroupLeft","Ctrl-Right":"goGroupRight","Alt-Left":"goLineStart","Alt-Right":"goLineEnd","Ctrl-Backspace":"delGroupBefore","Ctrl-Delete":"delGroupAfter","Ctrl-S":"save","Ctrl-F":"find","Ctrl-G":"findNext","Shift-Ctrl-G":"findPrev","Shift-Ctrl-F":"replace","Shift-Ctrl-R":"replaceAll","Ctrl-[":"indentLess","Ctrl-]":"indentMore","Ctrl-U":"undoSelection","Shift-Ctrl-U":"redoSelection","Alt-U":"redoSelection",fallthrough:"basic"},Rs.emacsy={"Ctrl-F":"goCharRight","Ctrl-B":"goCharLeft","Ctrl-P":"goLineUp","Ctrl-N":"goLineDown","Alt-F":"goWordRight","Alt-B":"goWordLeft","Ctrl-A":"goLineStart","Ctrl-E":"goLineEnd","Ctrl-V":"goPageDown","Shift-Ctrl-V":"goPageUp","Ctrl-D":"delCharAfter","Ctrl-H":"delCharBefore","Alt-D":"delWordAfter","Alt-Backspace":"delWordBefore","Ctrl-K":"killLine","Ctrl-T":"transposeChars","Ctrl-O":"openLine"},Rs.macDefault={"Cmd-A":"selectAll","Cmd-D":"deleteLine","Cmd-Z":"undo","Shift-Cmd-Z":"redo","Cmd-Y":"redo","Cmd-Home":"goDocStart","Cmd-Up":"goDocStart","Cmd-End":"goDocEnd","Cmd-Down":"goDocEnd","Alt-Left":"goGroupLeft","Alt-Right":"goGroupRight","Cmd-Left":"goLineLeft","Cmd-Right":"goLineRight","Alt-Backspace":"delGroupBefore","Ctrl-Alt-Backspace":"delGroupAfter","Alt-Delete":"delGroupAfter","Cmd-S":"save","Cmd-F":"find","Cmd-G":"findNext","Shift-Cmd-G":"findPrev","Cmd-Alt-F":"replace","Shift-Cmd-Alt-F":"replaceAll","Cmd-[":"indentLess","Cmd-]":"indentMore","Cmd-Backspace":"delWrappedLineLeft","Cmd-Delete":"delWrappedLineRight","Cmd-U":"undoSelection","Shift-Cmd-U":"redoSelection","Ctrl-Up":"goDocStart","Ctrl-Down":"goDocEnd",fallthrough:["basic","emacsy"]},Rs.default=Ml?Rs.macDefault:Rs.pcDefault;var Bs={selectAll:Mi,singleSelection:function(e){return e.setSelection(e.getCursor("anchor"),e.getCursor("head"),Gl)},killLine:function(e){return co(e,function(t){if(t.empty()){var r=M(e.doc,t.head.line).text.length;return t.head.ch==r&&t.head.line<e.lastLine()?{from:t.head,to:E(t.head.line+1,0)}:{from:t.head,to:E(t.head.line,r)}}return{from:t.from(),to:t.to()}})},deleteLine:function(e){return co(e,function(t){return{from:E(t.from().line,0),to:U(e.doc,E(t.to().line+1,0))}})},delLineLeft:function(e){return co(e,function(e){return{from:E(e.from().line,0),to:e.from()}})},delWrappedLineLeft:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5;return{from:e.coordsChar({left:0,top:r},"div"),to:t.from()}})},delWrappedLineRight:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5,n=e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div");return{from:t.from(),to:n}})},undo:function(e){return e.undo()},redo:function(e){return e.redo()},undoSelection:function(e){return e.undoSelection()},redoSelection:function(e){return e.redoSelection()},goDocStart:function(e){return e.extendSelection(E(e.firstLine(),0))},goDocEnd:function(e){return e.extendSelection(E(e.lastLine()))},goLineStart:function(e){return e.extendSelectionsBy(function(t){return vo(e,t.head.line)},{origin:"+move",bias:1})},goLineStartSmart:function(e){return e.extendSelectionsBy(function(t){return yo(e,t.head)},{origin:"+move",bias:1})},goLineEnd:function(e){return e.extendSelectionsBy(function(t){return mo(e,t.head.line)},{origin:"+move",bias:-1})},goLineRight:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div")},Vl)},goLineLeft:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:0,top:r},"div")},Vl)},goLineLeftSmart:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5,n=e.coordsChar({left:0,top:r},"div");return n.ch<e.getLine(n.line).search(/\S/)?yo(e,t.head):n},Vl)},goLineUp:function(e){return e.moveV(-1,"line")},goLineDown:function(e){return e.moveV(1,"line")},goPageUp:function(e){return e.moveV(-1,"page")},goPageDown:function(e){return e.moveV(1,"page")},goCharLeft:function(e){return e.moveH(-1,"char")},goCharRight:function(e){return e.moveH(1,"char")},goColumnLeft:function(e){return e.moveH(-1,"column")},goColumnRight:function(e){return e.moveH(1,"column")},goWordLeft:function(e){return e.moveH(-1,"word")},goGroupRight:function(e){return e.moveH(1,"group")},goGroupLeft:function(e){return e.moveH(-1,"group")},goWordRight:function(e){return e.moveH(1,"word")},delCharBefore:function(e){return e.deleteH(-1,"char")},delCharAfter:function(e){return e.deleteH(1,"char")},delWordBefore:function(e){return e.deleteH(-1,"word")},delWordAfter:function(e){return e.deleteH(1,"word")},delGroupBefore:function(e){return e.deleteH(-1,"group")},delGroupAfter:function(e){return e.deleteH(1,"group")},indentAuto:function(e){return e.indentSelection("smart")},indentMore:function(e){return e.indentSelection("add")},indentLess:function(e){return e.indentSelection("subtract")},insertTab:function(e){return e.replaceSelection("\t")},insertSoftTab:function(e){for(var t=[],r=e.listSelections(),n=e.options.tabSize,i=0;i<r.length;i++){var o=r[i].from(),l=f(e.getLine(o.line),o.ch,n);t.push(p(n-l%n))}e.replaceSelections(t)},defaultTab:function(e){e.somethingSelected()?e.indentSelection("add"):e.execCommand("insertTab")},transposeChars:function(e){return hn(e,function(){for(var t=e.listSelections(),r=[],n=0;n<t.length;n++)if(t[n].empty()){var i=t[n].head,o=M(e.doc,i.line).text;if(o)if(i.ch==o.length&&(i=new E(i.line,i.ch-1)),i.ch>0)i=new E(i.line,i.ch+1),e.replaceRange(o.charAt(i.ch-1)+o.charAt(i.ch-2),E(i.line,i.ch-2),i,"+transpose");else if(i.line>e.doc.first){var l=M(e.doc,i.line-1).text;l&&(i=new E(i.line,1),e.replaceRange(o.charAt(0)+e.doc.lineSeparator()+l.charAt(l.length-1),E(i.line-1,l.length-1),i,"+transpose"))}r.push(new Ts(i,i))}e.setSelections(r)})},newlineAndIndent:function(e){return hn(e,function(){for(var t=e.listSelections(),r=t.length-1;r>=0;r--)e.replaceRange(e.doc.lineSeparator(),t[r].anchor,t[r].head,"+input");t=e.listSelections();for(var n=0;n<t.length;n++)e.indentLine(t[n].from().line,null,!0);jr(e)})},openLine:function(e){return e.replaceSelection("\n","start")},toggleOverwrite:function(e){return e.toggleOverwrite()}},Gs=new Pl,Us=null,Vs=function(e,t,r){this.time=e,this.pos=t,this.button=r};Vs.prototype.compare=function(e,t,r){return this.time+400>e&&0==P(t,this.pos)&&r==this.button};var Ks,js,Xs={toString:function(){return"CodeMirror.Init"}},Ys={},_s={};jo.defaults=Ys,jo.optionHandlers=_s;var $s=[];jo.defineInitHook=function(e){return $s.push(e)};var qs=null,Zs=function(e){this.cm=e,this.lastAnchorNode=this.lastAnchorOffset=this.lastFocusNode=this.lastFocusOffset=null,this.polling=new Pl,this.composing=null,this.gracePeriod=!1,this.readDOMTimeout=null};Zs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()}),"cut"==e.type&&i.replaceSelection("",null,"cut");else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type&&i.operation(function(){i.setSelections(t.ranges,0,Gl),i.replaceSelection("",null,"cut")})}if(e.clipboardData){e.clipboardData.clearData();var r=qs.text.join("\n");if(e.clipboardData.setData("Text",r),e.clipboardData.getData("Text")==r)return void e.preventDefault()}var l=el(),s=l.firstChild;i.display.lineSpace.insertBefore(l,i.display.lineSpace.firstChild),s.value=qs.text.join("\n");var a=document.activeElement;El(s),setTimeout(function(){i.display.lineSpace.removeChild(l),a.focus(),a==o&&n.showPrimarySelection()},50)}}var r=this,n=this,i=n.cm,o=n.div=e.lineDiv;Jo(o,i.options.spellcheck),Ql(o,"paste",function(e){Me(i,e)||qo(e,i)||vl<=11&&setTimeout(dn(i,function(){return r.updateFromDOM()}),20)}),Ql(o,"compositionstart",function(e){r.composing={data:e.data,done:!1}}),Ql(o,"compositionupdate",function(e){r.composing||(r.composing={data:e.data,done:!1})}),Ql(o,"compositionend",function(e){r.composing&&(e.data!=r.composing.data&&r.readFromDOMSoon(),r.composing.done=!0)}),Ql(o,"touchstart",function(){return n.forceCompositionEnd()}),Ql(o,"input",function(){r.composing||r.readFromDOMSoon()}),Ql(o,"copy",t),Ql(o,"cut",t)},Zs.prototype.prepareSelection=function(){var e=Tr(this.cm,!1);return e.focus=this.cm.state.focused,e},Zs.prototype.showSelection=function(e,t){e&&this.cm.display.view.length&&((e.focus||t)&&this.showPrimarySelection(),this.showMultipleSelections(e))},Zs.prototype.showPrimarySelection=function(){var e=window.getSelection(),t=this.cm,r=t.doc.sel.primary(),n=r.from(),i=r.to();if(t.display.viewTo==t.display.viewFrom||n.line>=t.display.viewTo||i.line<t.display.viewFrom)e.removeAllRanges();else{var o=sl(t,e.anchorNode,e.anchorOffset),l=sl(t,e.focusNode,e.focusOffset);if(!o||o.bad||!l||l.bad||0!=P(B(o,l),n)||0!=P(R(o,l),i)){var s=t.display.view,a=n.line>=t.display.viewFrom&&nl(t,n)||{node:s[0].measure.map[2],offset:0},u=i.line<t.display.viewTo&&nl(t,i);if(!u){var c=s[s.length-1].measure,f=c.maps?c.maps[c.maps.length-1]:c.map;u={node:f[f.length-1],offset:f[f.length-2]-f[f.length-3]}}if(a&&u){var h,d=e.rangeCount&&e.getRangeAt(0);try{h=Wl(a.node,a.offset,u.offset,u.node)}catch(e){}h&&(!fl&&t.state.focused?(e.collapse(a.node,a.offset),h.collapsed||(e.removeAllRanges(),e.addRange(h))):(e.removeAllRanges(),e.addRange(h)),d&&null==e.anchorNode?e.addRange(d):fl&&this.startGracePeriod()),this.rememberSelection()}else e.removeAllRanges()}}},Zs.prototype.startGracePeriod=function(){var e=this;clearTimeout(this.gracePeriod),this.gracePeriod=setTimeout(function(){e.gracePeriod=!1,e.selectionChanged()&&e.cm.operation(function(){return e.cm.curOp.selectionChanged=!0})},20)},Zs.prototype.showMultipleSelections=function(e){r(this.cm.display.cursorDiv,e.cursors),r(this.cm.display.selectionDiv,e.selection)},Zs.prototype.rememberSelection=function(){var e=window.getSelection();this.lastAnchorNode=e.anchorNode,this.lastAnchorOffset=e.anchorOffset,this.lastFocusNode=e.focusNode,this.lastFocusOffset=e.focusOffset},Zs.prototype.selectionInEditor=function(){var e=window.getSelection();if(!e.rangeCount)return!1;var t=e.getRangeAt(0).commonAncestorContainer;return o(this.div,t)},Zs.prototype.focus=function(){"nocursor"!=this.cm.options.readOnly&&(this.selectionInEditor()||this.showSelection(this.prepareSelection(),!0),this.div.focus())},Zs.prototype.blur=function(){this.div.blur()},Zs.prototype.getField=function(){return this.div},Zs.prototype.supportsTouch=function(){return!0},Zs.prototype.receivedFocus=function(){function e(){t.cm.state.focused&&(t.pollSelection(),t.polling.set(t.cm.options.pollInterval,e))}var t=this;this.selectionInEditor()?this.pollSelection():hn(this.cm,function(){return t.cm.curOp.selectionChanged=!0}),this.polling.set(this.cm.options.pollInterval,e)},Zs.prototype.selectionChanged=function(){var e=window.getSelection();return e.anchorNode!=this.lastAnchorNode||e.anchorOffset!=this.lastAnchorOffset||e.focusNode!=this.lastFocusNode||e.focusOffset!=this.lastFocusOffset},Zs.prototype.pollSelection=function(){if(null==this.readDOMTimeout&&!this.gracePeriod&&this.selectionChanged()){var e=window.getSelection(),t=this.cm;if(kl&&bl&&this.cm.options.gutters.length&&il(e.anchorNode))return this.cm.triggerOnKeyDown({type:"keydown",keyCode:8,preventDefault:Math.abs}),this.blur(),void this.focus();if(!this.composing){this.rememberSelection();var r=sl(t,e.anchorNode,e.anchorOffset),n=sl(t,e.focusNode,e.focusOffset);r&&n&&hn(t,function(){bi(t.doc,Rn(r,n),Gl),(r.bad||n.bad)&&(t.curOp.selectionChanged=!0)})}}},Zs.prototype.pollContent=function(){null!=this.readDOMTimeout&&(clearTimeout(this.readDOMTimeout),this.readDOMTimeout=null);var e=this.cm,t=e.display,r=e.doc.sel.primary(),n=r.from(),i=r.to();if(0==n.ch&&n.line>e.firstLine()&&(n=E(n.line-1,M(e.doc,n.line-1).length)),i.ch==M(e.doc,i.line).text.length&&i.line<e.lastLine()&&(i=E(i.line+1,0)),n.line<t.viewFrom||i.line>t.viewTo-1)return!1;var o,l,s;n.line==t.viewFrom||0==(o=Lr(e,n.line))?(l=W(t.view[0].line),s=t.view[0].node):(l=W(t.view[o].line),s=t.view[o-1].node.nextSibling);var a,u,c=Lr(e,i.line);if(c==t.view.length-1?(a=t.viewTo-1,u=t.lineDiv.lastChild):(a=W(t.view[c+1].line)-1,u=t.view[c+1].node.previousSibling),!s)return!1;for(var f=e.doc.splitLines(ll(e,s,u,l,a)),h=N(e.doc,E(l,0),E(a,M(e.doc,a).text.length));f.length>1&&h.length>1;)if(g(f)==g(h))f.pop(),h.pop(),a--;else{if(f[0]!=h[0])break;f.shift(),h.shift(),l++}for(var d=0,p=0,v=f[0],m=h[0],y=Math.min(v.length,m.length);d<y&&v.charCodeAt(d)==m.charCodeAt(d);)++d;for(var b=g(f),w=g(h),x=Math.min(b.length-(1==f.length?d:0),w.length-(1==h.length?d:0));p<x&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)++p;if(1==f.length&&1==h.length&&l==n.line)for(;d&&d>n.ch&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)d--,p++;f[f.length-1]=b.slice(0,b.length-p).replace(/^\u200b+/,""),f[0]=f[0].slice(d).replace(/\u200b+$/,"");var C=E(l,d),S=E(a,h.length?g(h).length-p:0);return f.length>1||f[0]||P(C,S)?(Ei(e.doc,f,C,S,"+input"),!0):void 0},Zs.prototype.ensurePolled=function(){this.forceCompositionEnd()},Zs.prototype.reset=function(){this.forceCompositionEnd()},Zs.prototype.forceCompositionEnd=function(){this.composing&&(clearTimeout(this.readDOMTimeout),this.composing=null,this.updateFromDOM(),this.div.blur(),this.div.focus())},Zs.prototype.readFromDOMSoon=function(){var e=this;null==this.readDOMTimeout&&(this.readDOMTimeout=setTimeout(function(){if(e.readDOMTimeout=null,e.composing){if(!e.composing.done)return;e.composing=null}e.updateFromDOM()},80))},Zs.prototype.updateFromDOM=function(){var e=this;!this.cm.isReadOnly()&&this.pollContent()||hn(this.cm,function(){return vn(e.cm)})},Zs.prototype.setUneditable=function(e){e.contentEditable="false"},Zs.prototype.onKeyPress=function(e){0!=e.charCode&&(e.preventDefault(),this.cm.isReadOnly()||dn(this.cm,$o)(this.cm,String.fromCharCode(null==e.charCode?e.keyCode:e.charCode),0))},Zs.prototype.readOnlyChanged=function(e){this.div.contentEditable=String("nocursor"!=e)},Zs.prototype.onContextMenu=function(){},Zs.prototype.resetPosition=function(){},Zs.prototype.needsContentAttribute=!0;var Qs=function(e){this.cm=e,this.prevInput="",this.pollingFast=!1,this.polling=new Pl,this.hasSelection=!1,this.composing=null};Qs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()});else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type?i.setSelections(t.ranges,null,Gl):(n.prevInput="",l.value=t.text.join("\n"),El(l))}"cut"==e.type&&(i.state.cutIncoming=!0)}}var r=this,n=this,i=this.cm,o=this.wrapper=el(),l=this.textarea=o.firstChild;e.wrapper.insertBefore(o,e.wrapper.firstChild),Ll&&(l.style.width="0px"),Ql(l,"input",function(){gl&&vl>=9&&r.hasSelection&&(r.hasSelection=null),n.poll()}),Ql(l,"paste",function(e){Me(i,e)||qo(e,i)||(i.state.pasteIncoming=!0,n.fastPoll())}),Ql(l,"cut",t),Ql(l,"copy",t),Ql(e.scroller,"paste",function(t){Ft(e,t)||Me(i,t)||(i.state.pasteIncoming=!0,n.focus())}),Ql(e.lineSpace,"selectstart",function(t){Ft(e,t)||We(t)}),Ql(l,"compositionstart",function(){var e=i.getCursor("from");n.composing&&n.composing.range.clear(),n.composing={start:e,range:i.markText(e,i.getCursor("to"),{className:"CodeMirror-composing"})}}),Ql(l,"compositionend",function(){n.composing&&(n.poll(),n.composing.range.clear(),n.composing=null)})},Qs.prototype.prepareSelection=function(){var e=this.cm,t=e.display,r=e.doc,n=Tr(e);if(e.options.moveInputWithCursor){var i=sr(e,r.sel.primary().head,"div"),o=t.wrapper.getBoundingClientRect(),l=t.lineDiv.getBoundingClientRect();n.teTop=Math.max(0,Math.min(t.wrapper.clientHeight-10,i.top+l.top-o.top)),n.teLeft=Math.max(0,Math.min(t.wrapper.clientWidth-10,i.left+l.left-o.left))}return n},Qs.prototype.showSelection=function(e){var t=this.cm.display;r(t.cursorDiv,e.cursors),r(t.selectionDiv,e.selection),null!=e.teTop&&(this.wrapper.style.top=e.teTop+"px",this.wrapper.style.left=e.teLeft+"px")},Qs.prototype.reset=function(e){if(!this.contextMenuPending&&!this.composing){var t=this.cm;if(t.somethingSelected()){this.prevInput="";var r=t.getSelection();this.textarea.value=r,t.state.focused&&El(this.textarea),gl&&vl>=9&&(this.hasSelection=r)}else e||(this.prevInput=this.textarea.value="",gl&&vl>=9&&(this.hasSelection=null))}},Qs.prototype.getField=function(){return this.textarea},Qs.prototype.supportsTouch=function(){return!1},Qs.prototype.focus=function(){if("nocursor"!=this.cm.options.readOnly&&(!Tl||l()!=this.textarea))try{this.textarea.focus()}catch(e){}},Qs.prototype.blur=function(){this.textarea.blur()},Qs.prototype.resetPosition=function(){this.wrapper.style.top=this.wrapper.style.left=0},Qs.prototype.receivedFocus=function(){this.slowPoll()},Qs.prototype.slowPoll=function(){var e=this;this.pollingFast||this.polling.set(this.cm.options.pollInterval,function(){e.poll(),e.cm.state.focused&&e.slowPoll()})},Qs.prototype.fastPoll=function(){function e(){r.poll()||t?(r.pollingFast=!1,r.slowPoll()):(t=!0,r.polling.set(60,e))}var t=!1,r=this;r.pollingFast=!0,r.polling.set(20,e)},Qs.prototype.poll=function(){var e=this,t=this.cm,r=this.textarea,n=this.prevInput;if(this.contextMenuPending||!t.state.focused||ts(r)&&!n&&!this.composing||t.isReadOnly()||t.options.disableInput||t.state.keySeq)return!1;var i=r.value;if(i==n&&!t.somethingSelected())return!1;if(gl&&vl>=9&&this.hasSelection===i||Ml&&/[\uf700-\uf7ff]/.test(i))return t.display.input.reset(),!1;if(t.doc.sel==t.display.selForContextMenu){var o=i.charCodeAt(0);if(8203!=o||n||(n="​"),8666==o)return this.reset(),this.cm.execCommand("undo")}for(var l=0,s=Math.min(n.length,i.length);l<s&&n.charCodeAt(l)==i.charCodeAt(l);)++l;return hn(t,function(){$o(t,i.slice(l),n.length-l,null,e.composing?"*compose":null),i.length>1e3||i.indexOf("\n")>-1?r.value=e.prevInput="":e.prevInput=i,e.composing&&(e.composing.range.clear(),e.composing.range=t.markText(e.composing.start,t.getCursor("to"),{className:"CodeMirror-composing"}))}),!0},Qs.prototype.ensurePolled=function(){this.pollingFast&&this.poll()&&(this.pollingFast=!1)},Qs.prototype.onKeyPress=function(){gl&&vl>=9&&(this.hasSelection=null),this.fastPoll()},Qs.prototype.onContextMenu=function(e){function t(){if(null!=l.selectionStart){var e=i.somethingSelected(),t="​"+(e?l.value:"");l.value="⇚",l.value=t,n.prevInput=e?"":"​",l.selectionStart=1,l.selectionEnd=t.length,o.selForContextMenu=i.doc.sel}}function r(){if(n.contextMenuPending=!1,n.wrapper.style.cssText=c,l.style.cssText=u,gl&&vl<9&&o.scrollbars.setScrollTop(o.scroller.scrollTop=a),null!=l.selectionStart){(!gl||gl&&vl<9)&&t();var e=0,r=function(){o.selForContextMenu==i.doc.sel&&0==l.selectionStart&&l.selectionEnd>0&&"​"==n.prevInput?dn(i,Mi)(i):e++<10?o.detectingSelectAll=setTimeout(r,500):(o.selForContextMenu=null,o.input.reset())};o.detectingSelectAll=setTimeout(r,200)}}var n=this,i=n.cm,o=i.display,l=n.textarea,s=Sr(i,e),a=o.scroller.scrollTop;if(s&&!wl){i.options.resetSelectionOnContextMenu&&-1==i.doc.sel.contains(s)&&dn(i,bi)(i.doc,Rn(s),Gl);var u=l.style.cssText,c=n.wrapper.style.cssText;n.wrapper.style.cssText="position: absolute";var f=n.wrapper.getBoundingClientRect();l.style.cssText="position: absolute; width: 30px; height: 30px;\n      top: "+(e.clientY-f.top-5)+"px; left: "+(e.clientX-f.left-5)+"px;\n      z-index: 1000; background: "+(gl?"rgba(255, 255, 255, .05)":"transparent")+";\n      outline: none; border-width: 0; outline: none; overflow: hidden; opacity: .05; filter: alpha(opacity=5);";var h;if(ml&&(h=window.scrollY),o.input.focus(),ml&&window.scrollTo(null,h),o.input.reset(),i.somethingSelected()||(l.value=n.prevInput=" "),n.contextMenuPending=!0,o.selForContextMenu=i.doc.sel,clearTimeout(o.detectingSelectAll),gl&&vl>=9&&t(),Hl){Fe(e);var d=function(){ke(window,"mouseup",d),setTimeout(r,20)};Ql(window,"mouseup",d)}else setTimeout(r,50)}},Qs.prototype.readOnlyChanged=function(e){e||this.reset(),this.textarea.disabled="nocursor"==e},Qs.prototype.setUneditable=function(){},Qs.prototype.needsContentAttribute=!1,function(e){function t(t,n,i,o){e.defaults[t]=n,i&&(r[t]=o?function(e,t,r){r!=Xs&&i(e,t,r)}:i)}var r=e.optionHandlers;e.defineOption=t,e.Init=Xs,t("value","",function(e,t){return e.setValue(t)},!0),t("mode",null,function(e,t){e.doc.modeOption=t,jn(e)},!0),t("indentUnit",2,jn,!0),t("indentWithTabs",!1),t("smartIndent",!0),t("tabSize",4,function(e){Xn(e),er(e),vn(e)},!0),t("lineSeparator",null,function(e,t){if(e.doc.lineSep=t,t){var r=[],n=e.doc.first;e.doc.iter(function(e){for(var i=0;;){var o=e.text.indexOf(t,i);if(-1==o)break;i=o+t.length,r.push(E(n,o))}n++});for(var i=r.length-1;i>=0;i--)Ei(e.doc,t,r[i],E(r[i].line,r[i].ch+t.length))}}),t("specialChars",/[\u0000-\u001f\u007f-\u009f\u00ad\u061c\u200b-\u200f\u2028\u2029\ufeff]/g,function(e,t,r){e.state.specialChars=new RegExp(t.source+(t.test("\t")?"":"|\t"),"g"),r!=Xs&&e.refresh()}),t("specialCharPlaceholder",at,function(e){return e.refresh()},!0),t("electricChars",!0),t("inputStyle",Tl?"contenteditable":"textarea",function(){throw new Error("inputStyle can not (yet) be changed in a running editor")},!0),t("spellcheck",!1,function(e,t){return e.getInputField().spellcheck=t},!0),t("rtlMoveVisually",!Ol),t("wholeLineUpdateBefore",!0),t("theme","default",function(e){Go(e),Uo(e)},!0),t("keyMap","default",function(e,t,r){var n=uo(t),i=r!=Xs&&uo(r);i&&i.detach&&i.detach(e,n),n.attach&&n.attach(e,i||null)}),t("extraKeys",null),t("configureMouse",null),t("lineWrapping",!1,Ko,!0),t("gutters",[],function(e){Fn(e.options),Uo(e)},!0),t("fixedGutter",!0,function(e,t){e.display.gutters.style.left=t?wr(e.display)+"px":"0",e.refresh()},!0),t("coverGutterNextToScrollbar",!1,function(e){return en(e)},!0),t("scrollbarStyle","native",function(e){rn(e),en(e),e.display.scrollbars.setScrollTop(e.doc.scrollTop),e.display.scrollbars.setScrollLeft(e.doc.scrollLeft)},!0),t("lineNumbers",!1,function(e){Fn(e.options),Uo(e)},!0),t("firstLineNumber",1,Uo,!0),t("lineNumberFormatter",function(e){return e},Uo,!0),t("showCursorWhenSelecting",!1,kr,!0),t("resetSelectionOnContextMenu",!0),t("lineWiseCopyCut",!0),t("pasteLinesPerSelection",!0),t("readOnly",!1,function(e,t){"nocursor"==t&&(Fr(e),e.display.input.blur()),e.display.input.readOnlyChanged(t)}),t("disableInput",!1,function(e,t){t||e.display.input.reset()},!0),t("dragDrop",!0,Vo),t("allowDropFileTypes",null),t("cursorBlinkRate",530),t("cursorScrollMargin",0),t("cursorHeight",1,kr,!0),t("singleCursorHeightPerLine",!0,kr,!0),t("workTime",100),t("workDelay",100),t("flattenSpans",!0,Xn,!0),t("addModeClass",!1,Xn,!0),t("pollInterval",100),t("undoDepth",200,function(e,t){return e.doc.history.undoDepth=t}),t("historyEventDelay",1250),t("viewportMargin",10,function(e){return e.refresh()},!0),t("maxHighlightLength",1e4,Xn,!0),t("moveInputWithCursor",!0,function(e,t){t||e.display.input.resetPosition()}),t("tabindex",null,function(e,t){return e.display.input.getField().tabIndex=t||""}),t("autofocus",null),t("direction","ltr",function(e,t){return e.doc.setDirection(t)},!0)}(jo),function(e){var t=e.optionHandlers,r=e.helpers={};e.prototype={constructor:e,focus:function(){window.focus(),this.display.input.focus()},setOption:function(e,r){var n=this.options,i=n[e];n[e]==r&&"mode"!=e||(n[e]=r,t.hasOwnProperty(e)&&dn(this,t[e])(this,r,i),Te(this,"optionChange",this,e))},getOption:function(e){return this.options[e]},getDoc:function(){return this.doc},addKeyMap:function(e,t){this.state.keyMaps[t?"push":"unshift"](uo(e))},removeKeyMap:function(e){for(var t=this.state.keyMaps,r=0;r<t.length;++r)if(t[r]==e||t[r].name==e)return t.splice(r,1),!0},addOverlay:pn(function(t,r){var n=t.token?t:e.getMode(this.options,t);if(n.startState)throw new Error("Overlays may not be stateful.");m(this.state.overlays,{mode:n,modeSpec:t,opaque:r&&r.opaque,priority:r&&r.priority||0},function(e){return e.priority}),this.state.modeGen++,vn(this)}),removeOverlay:pn(function(e){for(var t=this,r=this.state.overlays,n=0;n<r.length;++n){var i=r[n].modeSpec;if(i==e||"string"==typeof e&&i.name==e)return r.splice(n,1),t.state.modeGen++,void vn(t)}}),indentLine:pn(function(e,t,r){"string"!=typeof t&&"number"!=typeof t&&(t=null==t?this.options.smartIndent?"smart":"prev":t?"add":"subtract"),H(this.doc,e)&&Yo(this,e,t,r)}),indentSelection:pn(function(e){for(var t=this,r=this.doc.sel.ranges,n=-1,i=0;i<r.length;i++){var o=r[i];if(o.empty())o.head.line>n&&(Yo(t,o.head.line,e,!0),n=o.head.line,i==t.doc.sel.primIndex&&jr(t));else{var l=o.from(),s=o.to(),a=Math.max(n,l.line);n=Math.min(t.lastLine(),s.line-(s.ch?0:1))+1;for(var u=a;u<n;++u)Yo(t,u,e);var c=t.doc.sel.ranges;0==l.ch&&r.length==c.length&&c[i].from().ch>0&&gi(t.doc,i,new Ts(l,c[i].to()),Gl)}}}),getTokenAt:function(e,t){return Je(this,e,t)},getLineTokens:function(e,t){return Je(this,E(e),t,!0)},getTokenTypeAt:function(e){e=U(this.doc,e);var t,r=_e(this,M(this.doc,e.line)),n=0,i=(r.length-1)/2,o=e.ch;if(0==o)t=r[2];else for(;;){var l=n+i>>1;if((l?r[2*l-1]:0)>=o)i=l;else{if(!(r[2*l+1]<o)){t=r[2*l+2];break}n=l+1}}var s=t?t.indexOf("overlay "):-1;return s<0?t:0==s?null:t.slice(0,s-1)},getModeAt:function(t){var r=this.doc.mode;return r.innerMode?e.innerMode(r,this.getTokenAt(t).state).mode:r},getHelper:function(e,t){return this.getHelpers(e,t)[0]},getHelpers:function(e,t){var n=this,i=[];if(!r.hasOwnProperty(t))return i;var o=r[t],l=this.getModeAt(e);if("string"==typeof l[t])o[l[t]]&&i.push(o[l[t]]);else if(l[t])for(var s=0;s<l[t].length;s++){var a=o[l[t][s]];a&&i.push(a)}else l.helperType&&o[l.helperType]?i.push(o[l.helperType]):o[l.name]&&i.push(o[l.name]);for(var u=0;u<o._global.length;u++){var c=o._global[u];c.pred(l,n)&&-1==h(i,c.val)&&i.push(c.val)}return i},getStateAfter:function(e,t){var r=this.doc;return e=G(r,null==e?r.first+r.size-1:e),$e(this,e+1,t).state},cursorCoords:function(e,t){var r,n=this.doc.sel.primary();return r=null==e?n.head:"object"==typeof e?U(this.doc,e):e?n.from():n.to(),sr(this,r,t||"page")},charCoords:function(e,t){return lr(this,U(this.doc,e),t||"page")},coordsChar:function(e,t){return e=or(this,e,t||"page"),cr(this,e.left,e.top)},lineAtHeight:function(e,t){return e=or(this,{top:e,left:0},t||"page").top,D(this.doc,e+this.display.viewOffset)},heightAtLine:function(e,t,r){var n,i=!1;if("number"==typeof e){var o=this.doc.first+this.doc.size-1;e<this.doc.first?e=this.doc.first:e>o&&(e=o,i=!0),n=M(this.doc,e)}else n=e;return ir(this,n,{top:0,left:0},t||"page",r||i).top+(i?this.doc.height-ye(n):0)},defaultTextHeight:function(){return mr(this.display)},defaultCharWidth:function(){return yr(this.display)},getViewport:function(){return{from:this.display.viewFrom,to:this.display.viewTo}},addWidget:function(e,t,r,n,i){var o=this.display,l=(e=sr(this,U(this.doc,e))).bottom,s=e.left;if(t.style.position="absolute",t.setAttribute("cm-ignore-events","true"),this.display.input.setUneditable(t),o.sizer.appendChild(t),"over"==n)l=e.top;else if("above"==n||"near"==n){var a=Math.max(o.wrapper.clientHeight,this.doc.height),u=Math.max(o.sizer.clientWidth,o.lineSpace.clientWidth);("above"==n||e.bottom+t.offsetHeight>a)&&e.top>t.offsetHeight?l=e.top-t.offsetHeight:e.bottom+t.offsetHeight<=a&&(l=e.bottom),s+t.offsetWidth>u&&(s=u-t.offsetWidth)}t.style.top=l+"px",t.style.left=t.style.right="","right"==i?(s=o.sizer.clientWidth-t.offsetWidth,t.style.right="0px"):("left"==i?s=0:"middle"==i&&(s=(o.sizer.clientWidth-t.offsetWidth)/2),t.style.left=s+"px"),r&&Ur(this,{left:s,top:l,right:s+t.offsetWidth,bottom:l+t.offsetHeight})},triggerOnKeyDown:pn(Lo),triggerOnKeyPress:pn(Mo),triggerOnKeyUp:To,triggerOnMouseDown:pn(Oo),execCommand:function(e){if(Bs.hasOwnProperty(e))return Bs[e].call(null,this)},triggerElectric:pn(function(e){Zo(this,e)}),findPosH:function(e,t,r,n){var i=this,o=1;t<0&&(o=-1,t=-t);for(var l=U(this.doc,e),s=0;s<t&&!(l=tl(i.doc,l,o,r,n)).hitSide;++s);return l},moveH:pn(function(e,t){var r=this;this.extendSelectionsBy(function(n){return r.display.shift||r.doc.extend||n.empty()?tl(r.doc,n.head,e,t,r.options.rtlMoveVisually):e<0?n.from():n.to()},Vl)}),deleteH:pn(function(e,t){var r=this.doc.sel,n=this.doc;r.somethingSelected()?n.replaceSelection("",null,"+delete"):co(this,function(r){var i=tl(n,r.head,e,t,!1);return e<0?{from:i,to:r.head}:{from:r.head,to:i}})}),findPosV:function(e,t,r,n){var i=this,o=1,l=n;t<0&&(o=-1,t=-t);for(var s=U(this.doc,e),a=0;a<t;++a){var u=sr(i,s,"div");if(null==l?l=u.left:u.left=l,(s=rl(i,u,o,r)).hitSide)break}return s},moveV:pn(function(e,t){var r=this,n=this.doc,i=[],o=!this.display.shift&&!n.extend&&n.sel.somethingSelected();if(n.extendSelectionsBy(function(l){if(o)return e<0?l.from():l.to();var s=sr(r,l.head,"div");null!=l.goalColumn&&(s.left=l.goalColumn),i.push(s.left);var a=rl(r,s,e,t);return"page"==t&&l==n.sel.primary()&&Kr(r,lr(r,a,"div").top-s.top),a},Vl),i.length)for(var l=0;l<n.sel.ranges.length;l++)n.sel.ranges[l].goalColumn=i[l]}),findWordAt:function(e){var t=M(this.doc,e.line).text,r=e.ch,n=e.ch;if(t){var i=this.getHelper(e,"wordChars");"before"!=e.sticky&&n!=t.length||!r?++n:--r;for(var o=t.charAt(r),l=x(o,i)?function(e){return x(e,i)}:/\s/.test(o)?function(e){return/\s/.test(e)}:function(e){return!/\s/.test(e)&&!x(e)};r>0&&l(t.charAt(r-1));)--r;for(;n<t.length&&l(t.charAt(n));)++n}return new Ts(E(e.line,r),E(e.line,n))},toggleOverwrite:function(e){null!=e&&e==this.state.overwrite||((this.state.overwrite=!this.state.overwrite)?s(this.display.cursorDiv,"CodeMirror-overwrite"):Fl(this.display.cursorDiv,"CodeMirror-overwrite"),Te(this,"overwriteToggle",this,this.state.overwrite))},hasFocus:function(){return this.display.input.getField()==l()},isReadOnly:function(){return!(!this.options.readOnly&&!this.doc.cantEdit)},scrollTo:pn(function(e,t){Xr(this,e,t)}),getScrollInfo:function(){var e=this.display.scroller;return{left:e.scrollLeft,top:e.scrollTop,height:e.scrollHeight-zt(this)-this.display.barHeight,width:e.scrollWidth-zt(this)-this.display.barWidth,clientHeight:Bt(this),clientWidth:Rt(this)}},scrollIntoView:pn(function(e,t){null==e?(e={from:this.doc.sel.primary().head,to:null},null==t&&(t=this.options.cursorScrollMargin)):"number"==typeof e?e={from:E(e,0),to:null}:null==e.from&&(e={from:e,to:null}),e.to||(e.to=e.from),e.margin=t||0,null!=e.from.line?Yr(this,e):$r(this,e.from,e.to,e.margin)}),setSize:pn(function(e,t){var r=this,n=function(e){return"number"==typeof e||/^\d+$/.test(String(e))?e+"px":e};null!=e&&(this.display.wrapper.style.width=n(e)),null!=t&&(this.display.wrapper.style.height=n(t)),this.options.lineWrapping&&Jt(this);var i=this.display.viewFrom;this.doc.iter(i,this.display.viewTo,function(e){if(e.widgets)for(var t=0;t<e.widgets.length;t++)if(e.widgets[t].noHScroll){mn(r,i,"widget");break}++i}),this.curOp.forceUpdate=!0,Te(this,"refresh",this)}),operation:function(e){return hn(this,e)},startOperation:function(){return nn(this)},endOperation:function(){return on(this)},refresh:pn(function(){var e=this.display.cachedTextHeight;vn(this),this.curOp.forceUpdate=!0,er(this),Xr(this,this.doc.scrollLeft,this.doc.scrollTop),Wn(this),(null==e||Math.abs(e-mr(this.display))>.5)&&Cr(this),Te(this,"refresh",this)}),swapDoc:pn(function(e){var t=this.doc;return t.cm=null,qn(this,e),er(this),this.display.input.reset(),Xr(this,e.scrollLeft,e.scrollTop),this.curOp.forceScroll=!0,bt(this,"swapDoc",this,t),t}),getInputField:function(){return this.display.input.getField()},getWrapperElement:function(){return this.display.wrapper},getScrollerElement:function(){return this.display.scroller},getGutterElement:function(){return this.display.gutters}},Ae(e),e.registerHelper=function(t,n,i){r.hasOwnProperty(t)||(r[t]=e[t]={_global:[]}),r[t][n]=i},e.registerGlobalHelper=function(t,n,i,o){e.registerHelper(t,n,o),r[t]._global.push({pred:i,val:o})}}(jo);var Js="iter insert remove copy getEditor constructor".split(" ");for(var ea in Ds.prototype)Ds.prototype.hasOwnProperty(ea)&&h(Js,ea)<0&&(jo.prototype[ea]=function(e){return function(){return e.apply(this.doc,arguments)}}(Ds.prototype[ea]));return Ae(Ds),jo.inputStyles={textarea:Qs,contenteditable:Zs},jo.defineMode=function(e){jo.defaults.mode||"null"==e||(jo.defaults.mode=e),Be.apply(this,arguments)},jo.defineMIME=function(e,t){os[e]=t},jo.defineMode("null",function(){return{token:function(e){return e.skipToEnd()}}}),jo.defineMIME("text/plain","null"),jo.defineExtension=function(e,t){jo.prototype[e]=t},jo.defineDocExtension=function(e,t){Ds.prototype[e]=t},jo.fromTextArea=function(e,t){function r(){e.value=a.getValue()}if(t=t?c(t):{},t.value=e.value,!t.tabindex&&e.tabIndex&&(t.tabindex=e.tabIndex),!t.placeholder&&e.placeholder&&(t.placeholder=e.placeholder),null==t.autofocus){var n=l();t.autofocus=n==e||null!=e.getAttribute("autofocus")&&n==document.body}var i;if(e.form&&(Ql(e.form,"submit",r),!t.leaveSubmitMethodAlone)){var o=e.form;i=o.submit;try{var s=o.submit=function(){r(),o.submit=i,o.submit(),o.submit=s}}catch(e){}}t.finishInit=function(t){t.save=r,t.getTextArea=function(){return e},t.toTextArea=function(){t.toTextArea=isNaN,r(),e.parentNode.removeChild(t.getWrapperElement()),e.style.display="",e.form&&(ke(e.form,"submit",r),"function"==typeof e.form.submit&&(e.form.submit=i))}},e.style.display="none";var a=jo(function(t){return e.parentNode.insertBefore(t,e.nextSibling)},t);return a},function(e){e.off=ke,e.on=Ql,e.wheelEventPixels=Pn,e.Doc=Ds,e.splitLines=es,e.countColumn=f,e.findColumn=d,e.isWordChar=w,e.Pass=Bl,e.signal=Te,e.Line=fs,e.changeEnd=Bn,e.scrollbarModel=ws,e.Pos=E,e.cmpPos=P,e.modes=is,e.mimeModes=os,e.resolveMode=Ge,e.getMode=Ue,e.modeExtensions=ls,e.extendMode=Ve,e.copyState=Ke,e.startState=Xe,e.innerMode=je,e.commands=Bs,e.keyMap=Rs,e.keyName=ao,e.isModifierKey=lo,e.lookupKey=oo,e.normalizeKeyMap=io,e.StringStream=ss,e.SharedTextMarker=As,e.TextMarker=Os,e.LineWidget=Ms,e.e_preventDefault=We,e.e_stopPropagation=De,e.e_stop=Fe,e.addClass=s,e.contains=o,e.rmClass=Fl,e.keyNames=Es}(jo),jo.version="5.30.0",jo});
      !function(e){"object"==typeof exports&&"object"==typeof module?e(require("../../lib/codemirror")):"function"==typeof define&&define.amd?define(["../../lib/codemirror"],e):e(CodeMirror)}(function(e){"use strict";function t(e,t,n,r,o,a){this.indented=e,this.column=t,this.type=n,this.info=r,this.align=o,this.prev=a}function n(e,n,r,o){var a=e.indented;return e.context&&"statement"==e.context.type&&"statement"!=r&&(a=e.context.indented),e.context=new t(a,n,r,o,null,e.context)}function r(e){var t=e.context.type;return")"!=t&&"]"!=t&&"}"!=t||(e.indented=e.context.indented),e.context=e.context.prev}function o(e,t,n){return"variable"==t.prevToken||"type"==t.prevToken||(!!/\S(?:[^- ]>|[*\]])\s*$|\*$/.test(e.string.slice(0,n))||(!(!t.typeAtEndOfLine||e.column()!=e.indentation())||void 0))}function a(e){for(;;){if(!e||"top"==e.type)return!0;if("}"==e.type&&"namespace"!=e.prev.info)return!1;e=e.prev}}function i(e){for(var t={},n=e.split(" "),r=0;r<n.length;++r)t[n[r]]=!0;return t}function l(e,t){return"function"==typeof e?e(t):e.propertyIsEnumerable(t)}function s(e,t){if(!t.startOfLine)return!1;for(var n,r=null;n=e.peek();){if("\\"==n&&e.match(/^.$/)){r=s;break}if("/"==n&&e.match(/^\/[\/\*]/,!1))break;e.next()}return t.tokenize=r,"meta"}function c(e,t){return"type"==t.prevToken&&"type"}function u(e){return e.eatWhile(/[\w\.']/),"number"}function d(e,t){if(e.backUp(1),e.match(/(R|u8R|uR|UR|LR)/)){var n=e.match(/"([^\s\\()]{0,16})\(/);return!!n&&(t.cpp11RawStringDelim=n[1],t.tokenize=m,m(e,t))}return e.match(/(u8|u|U|L)/)?!!e.match(/["']/,!1)&&"string":(e.next(),!1)}function f(e){var t=/(\w+)::~?(\w+)$/.exec(e);return t&&t[1]==t[2]}function p(e,t){for(var n;null!=(n=e.next());)if('"'==n&&!e.eat('"')){t.tokenize=null;break}return"string"}function m(e,t){var n=t.cpp11RawStringDelim.replace(/[^\w\s]/g,"\\$&");return e.match(new RegExp(".*?\\)"+n+'"'))?t.tokenize=null:e.skipToEnd(),"string"}function h(t,n){function r(e){if(e)for(var t in e)e.hasOwnProperty(t)&&o.push(t)}"string"==typeof t&&(t=[t]);var o=[];r(n.keywords),r(n.types),r(n.builtin),r(n.atoms),o.length&&(n.helperType=t[0],e.registerHelper("hintWords",t[0],o));for(var a=0;a<t.length;++a)e.defineMIME(t[a],n)}function g(e,t){for(var n=!1;!e.eol();){if(!n&&e.match('"""')){t.tokenize=null;break}n="\\"==e.next()&&!n}return"string"}function y(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!e&&!o&&t.match('"')){a=!0;break}if(e&&t.match('"""')){a=!0;break}r=t.next(),!o&&"$"==r&&t.match("{")&&t.skipTo("}"),o=!o&&"\\"==r&&!e}return!a&&e||(n.tokenize=null),"string"}}function x(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!o&&t.match('"')&&("single"==e||t.match('""'))){a=!0;break}if(!o&&t.match("``")){w=x(e),a=!0;break}r=t.next(),o="single"==e&&!o&&"\\"==r}return a&&(n.tokenize=null),"string"}}e.defineMode("clike",function(i,s){function c(e,t){var n=e.next();if(S[n]){var r=S[n](e,t);if(!1!==r)return r}if('"'==n||"'"==n)return t.tokenize=u(n),t.tokenize(e,t);if(D.test(n))return p=n,null;if(L.test(n)){if(e.backUp(1),e.match(I))return"number";e.next()}if("/"==n){if(e.eat("*"))return t.tokenize=d,d(e,t);if(e.eat("/"))return e.skipToEnd(),"comment"}if(F.test(n)){for(;!e.match(/^\/[\/*]/,!1)&&e.eat(F););return"operator"}if(e.eatWhile(z),P)for(;e.match(P);)e.eatWhile(z);var o=e.current();return l(x,o)?(l(w,o)&&(p="newstatement"),l(v,o)&&(m=!0),"keyword"):l(b,o)?"type":l(k,o)?(l(w,o)&&(p="newstatement"),"builtin"):l(_,o)?"atom":"variable"}function u(e){return function(t,n){for(var r,o=!1,a=!1;null!=(r=t.next());){if(r==e&&!o){a=!0;break}o=!o&&"\\"==r}return(a||!o&&!C)&&(n.tokenize=null),"string"}}function d(e,t){for(var n,r=!1;n=e.next();){if("/"==n&&r){t.tokenize=null;break}r="*"==n}return"comment"}function f(e,t){s.typeFirstDefinitions&&e.eol()&&a(t.context)&&(t.typeAtEndOfLine=o(e,t,e.pos))}var p,m,h=i.indentUnit,g=s.statementIndentUnit||h,y=s.dontAlignCalls,x=s.keywords||{},b=s.types||{},k=s.builtin||{},w=s.blockKeywords||{},v=s.defKeywords||{},_=s.atoms||{},S=s.hooks||{},C=s.multiLineStrings,T=!1!==s.indentStatements,M=!1!==s.indentSwitch,P=s.namespaceSeparator,D=s.isPunctuationChar||/[\[\]{}\(\),;\:\.]/,L=s.numberStart||/[\d\.]/,I=s.number||/^(?:0x[a-f\d]+|0b[01]+|(?:\d+\.?\d*|\.\d+)(?:e[-+]?\d+)?)(u|ll?|l|f)?/i,F=s.isOperatorChar||/[+\-*&%=<>!?|\/]/,z=s.isIdentifierChar||/[\w\$_\xa1-\uffff]/;return{startState:function(e){return{tokenize:null,context:new t((e||0)-h,0,"top",null,!1),indented:0,startOfLine:!0,prevToken:null}},token:function(e,t){var i=t.context;if(e.sol()&&(null==i.align&&(i.align=!1),t.indented=e.indentation(),t.startOfLine=!0),e.eatSpace())return f(e,t),null;p=m=null;var l=(t.tokenize||c)(e,t);if("comment"==l||"meta"==l)return l;if(null==i.align&&(i.align=!0),";"==p||":"==p||","==p&&e.match(/^\s*(?:\/\/.*)?$/,!1))for(;"statement"==t.context.type;)r(t);else if("{"==p)n(t,e.column(),"}");else if("["==p)n(t,e.column(),"]");else if("("==p)n(t,e.column(),")");else if("}"==p){for(;"statement"==i.type;)i=r(t);for("}"==i.type&&(i=r(t));"statement"==i.type;)i=r(t)}else p==i.type?r(t):T&&(("}"==i.type||"top"==i.type)&&";"!=p||"statement"==i.type&&"newstatement"==p)&&n(t,e.column(),"statement",e.current());if("variable"==l&&("def"==t.prevToken||s.typeFirstDefinitions&&o(e,t,e.start)&&a(t.context)&&e.match(/^\s*\(/,!1))&&(l="def"),S.token){var u=S.token(e,t,l);void 0!==u&&(l=u)}return"def"==l&&!1===s.styleDefs&&(l="variable"),t.startOfLine=!1,t.prevToken=m?"def":l||p,f(e,t),l},indent:function(t,n){if(t.tokenize!=c&&null!=t.tokenize||t.typeAtEndOfLine)return e.Pass;var r=t.context,o=n&&n.charAt(0);if("statement"==r.type&&"}"==o&&(r=r.prev),s.dontIndentStatements)for(;"statement"==r.type&&s.dontIndentStatements.test(r.info);)r=r.prev;if(S.indent){var a=S.indent(t,r,n);if("number"==typeof a)return a}var i=o==r.type,l=r.prev&&"switch"==r.prev.info;if(s.allmanIndentation&&/[{(]/.test(o)){for(;"top"!=r.type&&"}"!=r.type;)r=r.prev;return r.indented}return"statement"==r.type?r.indented+("{"==o?0:g):!r.align||y&&")"==r.type?")"!=r.type||i?r.indented+(i?0:h)+(i||!l||/^(?:case|default)\b/.test(n)?0:h):r.indented+g:r.column+(i?0:1)},electricInput:M?/^\s*(?:case .*?:|default:|\{\}?|\})$/:/^\s*[{}]$/,blockCommentStart:"/*",blockCommentEnd:"*/",lineComment:"//",fold:"brace"}});var b="auto if break case register continue return default do sizeof static else struct switch extern typedef union for goto while enum const volatile",k="int long char short double float unsigned signed void size_t ptrdiff_t";h(["text/x-csrc","text/x-c","text/x-chdr"],{name:"clike",keywords:i(b),types:i(k+" bool _Complex _Bool float_t double_t intptr_t intmax_t int8_t int16_t int32_t int64_t uintptr_t uintmax_t uint8_t uint16_t uint32_t uint64_t"),blockKeywords:i("case do else for if switch while struct"),defKeywords:i("struct"),typeFirstDefinitions:!0,atoms:i("null true false"),hooks:{"#":s,"*":c},modeProps:{fold:["brace","include"]}}),h(["text/x-c++src","text/x-c++hdr"],{name:"clike",keywords:i(b+" asm dynamic_cast namespace reinterpret_cast try explicit new static_cast typeid catch operator template typename class friend private this using const_cast inline public throw virtual delete mutable protected alignas alignof constexpr decltype nullptr noexcept thread_local final static_assert override"),types:i(k+" bool wchar_t"),blockKeywords:i("catch class do else finally for if struct switch try while"),defKeywords:i("class namespace struct enum union"),typeFirstDefinitions:!0,atoms:i("true false null"),dontIndentStatements:/^template$/,isIdentifierChar:/[\w\$_~\xa1-\uffff]/,hooks:{"#":s,"*":c,u:d,U:d,L:d,R:d,0:u,1:u,2:u,3:u,4:u,5:u,6:u,7:u,8:u,9:u,token:function(e,t,n){if("variable"==n&&"("==e.peek()&&(";"==t.prevToken||null==t.prevToken||"}"==t.prevToken)&&f(e.current()))return"def"}},namespaceSeparator:"::",modeProps:{fold:["brace","include"]}}),h("text/x-java",{name:"clike",keywords:i("abstract assert break case catch class const continue default do else enum extends final finally float for goto if implements import instanceof interface native new package private protected public return static strictfp super switch synchronized this throw throws transient try volatile while @interface"),types:i("byte short int long float double boolean char void Boolean Byte Character Double Float Integer Long Number Object Short String StringBuffer StringBuilder Void"),blockKeywords:i("catch class do else finally for if switch try while"),defKeywords:i("class interface package enum @interface"),typeFirstDefinitions:!0,atoms:i("true false null"),number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,hooks:{"@":function(e){return!e.match("interface",!1)&&(e.eatWhile(/[\w\$_]/),"meta")}},modeProps:{fold:["brace","import"]}}),h("text/x-csharp",{name:"clike",keywords:i("abstract as async await base break case catch checked class const continue default delegate do else enum event explicit extern finally fixed for foreach goto if implicit in interface internal is lock namespace new operator out override params private protected public readonly ref return sealed sizeof stackalloc static struct switch this throw try typeof unchecked unsafe using virtual void volatile while add alias ascending descending dynamic from get global group into join let orderby partial remove select set value var yield"),types:i("Action Boolean Byte Char DateTime DateTimeOffset Decimal Double Func Guid Int16 Int32 Int64 Object SByte Single String Task TimeSpan UInt16 UInt32 UInt64 bool byte char decimal double short int long object sbyte float string ushort uint ulong"),blockKeywords:i("catch class do else finally for foreach if struct switch try while"),defKeywords:i("class interface namespace struct var"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"@":function(e,t){return e.eat('"')?(t.tokenize=p,p(e,t)):(e.eatWhile(/[\w\$_]/),"meta")}}}),h("text/x-scala",{name:"clike",keywords:i("abstract case catch class def do else extends final finally for forSome if implicit import lazy match new null object override package private protected return sealed super this throw trait try type val var while with yield _ assert assume require print println printf readLine readBoolean readByte readShort readChar readInt readLong readFloat readDouble"),types:i("AnyVal App Application Array BufferedIterator BigDecimal BigInt Char Console Either Enumeration Equiv Error Exception Fractional Function IndexedSeq Int Integral Iterable Iterator List Map Numeric Nil NotNull Option Ordered Ordering PartialFunction PartialOrdering Product Proxy Range Responder Seq Serializable Set Specializable Stream StringBuilder StringContext Symbol Throwable Traversable TraversableOnce Tuple Unit Vector Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),multiLineStrings:!0,blockKeywords:i("catch class enum do else finally for forSome if match switch try while"),defKeywords:i("class enum def object package trait type val var"),atoms:i("true false null"),indentStatements:!1,indentSwitch:!1,isOperatorChar:/[+\-*&%=<>!?|\/#:@]/,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return!!e.match('""')&&(t.tokenize=g,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},"=":function(e,n){var r=n.context;return!("}"!=r.type||!r.align||!e.eat(">"))&&(n.context=new t(r.indented,r.column,r.type,r.info,null,r.prev),"operator")}},modeProps:{closeBrackets:{triples:'"'}}}),h("text/x-kotlin",{name:"clike",keywords:i("package as typealias class interface this super val var fun for is in This throw return break continue object if else while do try when !in !is as? file import where by get set abstract enum open inner override private public internal protected catch finally out final vararg reified dynamic companion constructor init sealed field property receiver param sparam lateinit data inline noinline tailrec external annotation crossinline const operator infix suspend"),types:i("Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),intendSwitch:!1,indentStatements:!1,multiLineStrings:!0,number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,blockKeywords:i("catch class do else finally for if where try while enum"),defKeywords:i("class val var object package interface fun"),atoms:i("true false null this"),hooks:{'"':function(e,t){return t.tokenize=y(e.match('""')),t.tokenize(e,t)}},modeProps:{closeBrackets:{triples:'"'}}}),h(["x-shader/x-vertex","x-shader/x-fragment"],{name:"clike",keywords:i("sampler1D sampler2D sampler3D samplerCube sampler1DShadow sampler2DShadow const attribute uniform varying break continue discard return for while do if else struct in out inout"),types:i("float int bool void vec2 vec3 vec4 ivec2 ivec3 ivec4 bvec2 bvec3 bvec4 mat2 mat3 mat4"),blockKeywords:i("for while do if else struct"),builtin:i("radians degrees sin cos tan asin acos atan pow exp log exp2 sqrt inversesqrt abs sign floor ceil fract mod min max clamp mix step smoothstep length distance dot cross normalize ftransform faceforward reflect refract matrixCompMult lessThan lessThanEqual greaterThan greaterThanEqual equal notEqual any all not texture1D texture1DProj texture1DLod texture1DProjLod texture2D texture2DProj texture2DLod texture2DProjLod texture3D texture3DProj texture3DLod texture3DProjLod textureCube textureCubeLod shadow1D shadow2D shadow1DProj shadow2DProj shadow1DLod shadow2DLod shadow1DProjLod shadow2DProjLod dFdx dFdy fwidth noise1 noise2 noise3 noise4"),atoms:i("true false gl_FragColor gl_SecondaryColor gl_Normal gl_Vertex gl_MultiTexCoord0 gl_MultiTexCoord1 gl_MultiTexCoord2 gl_MultiTexCoord3 gl_MultiTexCoord4 gl_MultiTexCoord5 gl_MultiTexCoord6 gl_MultiTexCoord7 gl_FogCoord gl_PointCoord gl_Position gl_PointSize gl_ClipVertex gl_FrontColor gl_BackColor gl_FrontSecondaryColor gl_BackSecondaryColor gl_TexCoord gl_FogFragCoord gl_FragCoord gl_FrontFacing gl_FragData gl_FragDepth gl_ModelViewMatrix gl_ProjectionMatrix gl_ModelViewProjectionMatrix gl_TextureMatrix gl_NormalMatrix gl_ModelViewMatrixInverse gl_ProjectionMatrixInverse gl_ModelViewProjectionMatrixInverse gl_TexureMatrixTranspose gl_ModelViewMatrixInverseTranspose gl_ProjectionMatrixInverseTranspose gl_ModelViewProjectionMatrixInverseTranspose gl_TextureMatrixInverseTranspose gl_NormalScale gl_DepthRange gl_ClipPlane gl_Point gl_FrontMaterial gl_BackMaterial gl_LightSource gl_LightModel gl_FrontLightModelProduct gl_BackLightModelProduct gl_TextureColor gl_EyePlaneS gl_EyePlaneT gl_EyePlaneR gl_EyePlaneQ gl_FogParameters gl_MaxLights gl_MaxClipPlanes gl_MaxTextureUnits gl_MaxTextureCoords gl_MaxVertexAttribs gl_MaxVertexUniformComponents gl_MaxVaryingFloats gl_MaxVertexTextureImageUnits gl_MaxTextureImageUnits gl_MaxFragmentUniformComponents gl_MaxCombineTextureImageUnits gl_MaxDrawBuffers"),indentSwitch:!1,hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-nesc",{name:"clike",keywords:i(b+"as atomic async call command component components configuration event generic implementation includes interface module new norace nx_struct nx_union post provides signal task uses abstract extends"),types:i(k),blockKeywords:i("case do else for if switch while struct"),atoms:i("null true false"),hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-objectivec",{name:"clike",keywords:i(b+"inline restrict _Bool _Complex _Imaginary BOOL Class bycopy byref id IMP in inout nil oneway out Protocol SEL self super atomic nonatomic retain copy readwrite readonly"),types:i(k),atoms:i("YES NO NULL NILL ON OFF true false"),hooks:{"@":function(e){return e.eatWhile(/[\w\$]/),"keyword"},"#":s,indent:function(e,t,n){if("statement"==t.type&&/^@\w/.test(n))return t.indented}},modeProps:{fold:"brace"}}),h("text/x-squirrel",{name:"clike",keywords:i("base break clone continue const default delete enum extends function in class foreach local resume return this throw typeof yield constructor instanceof static"),types:i(k),blockKeywords:i("case catch class else for foreach if switch try while"),defKeywords:i("function local class"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"#":s},modeProps:{fold:["brace","include"]}});var w=null;h("text/x-ceylon",{name:"clike",keywords:i("abstracts alias assembly assert assign break case catch class continue dynamic else exists extends finally for function given if import in interface is let module new nonempty object of out outer package return satisfies super switch then this throw try value void while"),types:function(e){var t=e.charAt(0);return t===t.toUpperCase()&&t!==t.toLowerCase()},blockKeywords:i("case catch class dynamic else finally for function if interface module new object switch try while"),defKeywords:i("class dynamic function interface module object package value"),builtin:i("abstract actual aliased annotation by default deprecated doc final formal late license native optional sealed see serializable shared suppressWarnings tagged throws variable"),isPunctuationChar:/[\[\]{}\(\),;\:\.`]/,isOperatorChar:/[+\-*&%=<>!?|^~:\/]/,numberStart:/[\d#$]/,number:/^(?:#[\da-fA-F_]+|\$[01_]+|[\d_]+[kMGTPmunpf]?|[\d_]+\.[\d_]+(?:[eE][-+]?\d+|[kMGTPmunpf]|)|)/i,multiLineStrings:!0,typeFirstDefinitions:!0,atoms:i("true false null larger smaller equal empty finished"),indentSwitch:!1,styleDefs:!1,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return t.tokenize=x(e.match('""')?"triple":"single"),t.tokenize(e,t)},"`":function(e,t){return!(!w||!e.match("`"))&&(t.tokenize=w,w=null,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},token:function(e,t,n){if(("variable"==n||"type"==n)&&"."==t.prevToken)return"variable-2"}},modeProps:{fold:["brace","import"],closeBrackets:{triples:'"'}}})});
      // -------------------------------------------------------------------------
//  Part of the CodeChecker project, under the Apache License v2.0 with
//  LLVM Exceptions. See LICENSE for license information.
//  SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
// -------------------------------------------------------------------------

var BugViewer = {
  _files : [],
  _reports : [],
  _lineWidgets : [],
  _navigationMenuItems : [],
  _sourceFileData : null,
  _currentReport : null,
  _lastBugEvent  : null,

  init : function (files, reports) {
    this._files = files;
    this._reports = reports;

    this.initEscapeChars();
  },

  initEscapeChars : function () {
    this.escapeChars = {
      ' ' : 'nbsp',
      '<' : 'lt',
      '>' : 'gt',
      '"' : 'quot',
      '&' : 'amp'
    };

    var regexString = '[';
    for (var key in this.escapeChars) {
      regexString += key;
    }
    regexString += ']';

    this.escapeRegExp = new RegExp( regexString, 'g');
  },

  escapeHTML : function (str) {
    var that = this;

    return str.replace(this.escapeRegExp, function (m) {
      return '&' + that.escapeChars[m] + ';';
    });
  },

  initByUrl : function () {
    if (!this._reports) return;

    var state = {};
    window.location.hash.substr(1).split('&').forEach(function (s) {
      var parts = s.split('=');
      state[parts[0]] = parts[1];
    });

    for (var key in this._reports) {
      var report = this._reports[key];
      if (report.reportHash === state['reportHash']) {
        this.navigate(report);
        return;
      }
    }

    this.navigate(this._reports[0]);
  },

  create : function () {
    this._content = document.getElementById('editor-wrapper');
    this._filepath = document.getElementById('file-path');
    this._checkerName = document.getElementById('checker-name');
    this._reviewStatusWrapper =
      document.getElementById('review-status-wrapper');
    this._reviewStatus = document.getElementById('review-status');
    this._editor = document.getElementById('editor');

    this._codeMirror = CodeMirror(this._editor, {
      mode: 'text/x-c++src',
      matchBrackets : true,
      lineNumbers : true,
      readOnly : true,
      foldGutter : true,
      extraKeys : {},
      viewportMargin : 100
    });

    this._createNavigationMenu();
  },

  navigate : function (report, item) {
    if (!item) {
      var items = this._navigationMenuItems.filter(function (navItem) {
        return navItem.report.reportHash === report.reportHash;
      });

      if (!items.length) return;

      item = items[0].widget;
    }

    this._selectedReport.classList.remove('active');
    this._selectedReport = item;
    this._selectedReport.classList.add('active');
    this.setReport(report);
  },

  _createNavigationMenu : function () {
    var that = this;

    var nav = document.getElementById('report-nav');
    var list = document.createElement('ul');
    this._reports.forEach(function (report) {
      var events = report['events'];
      var lastBugEvent = events[events.length - 1];
      var item = document.createElement('li');

      var severity = document.createElement('i');
      severity.className = 'severity-' + report.severity.toLowerCase();

      item.appendChild(severity);
      item.appendChild(document.createTextNode(lastBugEvent.message));

      item.addEventListener('click', function () {
        that.navigate(report, item);
      })
      list.appendChild(item);
      that._navigationMenuItems.push({ report : report, widget : item });
    });

    if (!this._selectedReport && list.childNodes.length) {
      this._selectedReport = list.childNodes[0];
      this._selectedReport.classList.add('active');
    }

    nav.appendChild(list);
  },

  setReport : function (report) {
    this._currentReport = report;
    var events = report['events'];
    var lastBugEvent = events[events.length - 1];
    this.setCurrentBugEvent(lastBugEvent, events.length - 1);
    this.setCheckerName(report.checkerName);
    this.setReviewStatus(report.reviewStatus);

    window.location.hash = '#reportHash=' + report.reportHash;
  },

  setCurrentBugEvent : function (event, idx) {
    this._currentBugEvent = event;
    this.setSourceFileData(this._files[event.location.file]);
    this.drawBugPath();

    this.jumpTo(event.location.line, 0);
    this.highlightBugEvent(event, idx);
  },

  highlightBugEvent : function (event, idx) {
    this._lineWidgets.forEach(function (widget) {
      var lineIdx = widget.node.getAttribute('idx');
      if (parseInt(lineIdx) === idx) {
        widget.node.classList.add('current');
      }
    });
  },

  setCheckerName : function (checkerName) {
    this._checkerName.innerHTML = checkerName;
  },

  setReviewStatus : function (status) {
    if (status) {
      var className =
        'review-status-' + status.toLowerCase().split(' ').join('-');
      this._reviewStatus.className = "review-status " + className;

      this._reviewStatus.innerHTML = status;
      this._reviewStatusWrapper.style.display = 'block';
    } else {
      this._reviewStatusWrapper.style.display = 'none';
    }
  },

  setSourceFileData : function (file) {
    if (this._sourceFileData && file.id === this._sourceFileData.id) {
      return;
    }

    this._sourceFileData = file;
    this._filepath.innerHTML = file.path;
    this._codeMirror.doc.setValue(file.content);
    this._refresh();
  },

  _refresh : function () {
    var that = this;
    setTimeout(function () {
      var fullHeight = parseInt(that._content.clientHeight);
      var headerHeight = that._filepath.clientHeight;

      that._codeMirror.setSize('auto', fullHeight - headerHeight);
      that._codeMirror.refresh();
    }, 200);
  },

  clearBubbles : function () {
    this._lineWidgets.forEach(function (widget) { widget.clear(); });
    this._lineWidgets = [];
  },

  getMessage : function (event, kind) {
    if (kind === 'macro') {
      var name = 'macro expansion' + (event.name ? ': ' + event.name : '');

      return '<span class="tag macro">' + name + '</span>'
        + this.escapeHTML(event.expansion).replace(/(?:\r\n|\r|\n)/g, '<br>');
    } else if (kind === 'note') {
      return '<span class="tag note">note</span>'
        +  this.escapeHTML(event.message).replace(/(?:\r\n|\r|\n)/g, '<br>');
    }
  },

  addExtraPathEvents : function (events, kind) {
    var that = this;

    if (!events) {
      return;
    }

    events.forEach(function (event) {
      if (event.location.file !== that._currentBugEvent.location.file) {
        return;
      }

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + kind);

      var msg = document.createElement('span');
      msg.innerHTML = that.getMessage(event, kind);
      element.appendChild(msg);

      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  drawBugPath : function () {
    var that = this;

    this.clearBubbles();

    this.addExtraPathEvents(this._currentReport.macros, 'macro');
    this.addExtraPathEvents(this._currentReport.notes, 'note');

    // Processing bug path events.
    var currentEvents = this._currentReport.events;
    currentEvents.forEach(function (event, step) {
      if (event.location.file !== that._currentBugEvent.location.file)
        return;

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';
      var type = step === currentEvents.length - 1 ? 'error' : 'info';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + type);
      element.setAttribute('idx', step);

      var enumeration = document.createElement('span');
      enumeration.setAttribute('class', 'checker-enum ' + type);
      enumeration.innerHTML = step + 1;

      if (currentEvents.length > 1)
        element.appendChild(enumeration);

      var prevBugEvent = step - 1;
      if (step > 0) {
        var prevBug = document.createElement('span');
        prevBug.setAttribute('class', 'arrow left-arrow');
        prevBug.addEventListener('click', function () {
          var event = currentEvents[prevBugEvent];
          that.setCurrentBugEvent(event, prevBugEvent);
        });
        element.appendChild(prevBug);
      }

      var msg = document.createElement('span');
      msg.innerHTML = that.escapeHTML(event.message)
        .replace(/(?:\r\n|\r|\n)/g, '<br>');

      element.appendChild(msg);

      var nextBugEvent = step + 1;
      if (nextBugEvent < currentEvents.length) {
        var nextBug = document.createElement('span');
        nextBug.setAttribute('class', 'arrow right-arrow');
        nextBug.addEventListener('click', function () {
          var event = currentEvents[nextBugEvent];
          that.setCurrentBugEvent(event, nextBugEvent);
        });
        element.appendChild(nextBug);
      }


      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  jumpTo : function (line, column) {
    var that = this;

    setTimeout(function () {
      var selPosPixel
        = that._codeMirror.charCoords({ line : line, ch : column }, 'local');
      var editorSize = {
        width  : that._editor.clientWidth,
        height : that._editor.clientHeight
      };

      that._codeMirror.scrollIntoView({
        top    : selPosPixel.top - 100,
        bottom : selPosPixel.top + editorSize.height - 150,
        left   : selPosPixel.left < editorSize.width - 100
               ? 0
               : selPosPixel.left - 50,
        right  : selPosPixel.left < editorSize.width - 100
               ? 10
               : selPosPixel.left + editorSize.width - 100
      });
    }, 0);
  }
}


      var data = {"files": {"0": {"id": 0, "path": "/src/net/ipv6/addrconf.c", "content": "// SPDX-License-Identifier: GPL-2.0-or-later\n/*\n *\tIPv6 Address [auto]configuration\n *\tLinux INET6 implementation\n *\n *\tAuthors:\n *\tPedro Roque\t\t<roque@di.fc.ul.pt>\n *\tAlexey Kuznetsov\t<kuznet@ms2.inr.ac.ru>\n */\n\n/*\n *\tChanges:\n *\n *\tJanos Farkas\t\t\t:\tdelete timer on ifdown\n *\t<chexum@bankinf.banki.hu>\n *\tAndi Kleen\t\t\t:\tkill double kfree on module\n *\t\t\t\t\t\tunload.\n *\tMaciej W. Rozycki\t\t:\tFDDI support\n *\tsekiya@USAGI\t\t\t:\tDon't send too many RS\n *\t\t\t\t\t\tpackets.\n *\tyoshfuji@USAGI\t\t\t:       Fixed interval between DAD\n *\t\t\t\t\t\tpackets.\n *\tYOSHIFUJI Hideaki @USAGI\t:\timproved accuracy of\n *\t\t\t\t\t\taddress validation timer.\n *\tYOSHIFUJI Hideaki @USAGI\t:\tPrivacy Extensions (RFC3041)\n *\t\t\t\t\t\tsupport.\n *\tYuji SEKIYA @USAGI\t\t:\tDon't assign a same IPv6\n *\t\t\t\t\t\taddress on a same interface.\n *\tYOSHIFUJI Hideaki @USAGI\t:\tARCnet support\n *\tYOSHIFUJI Hideaki @USAGI\t:\tconvert /proc/net/if_inet6 to\n *\t\t\t\t\t\tseq_file.\n *\tYOSHIFUJI Hideaki @USAGI\t:\timproved source address\n *\t\t\t\t\t\tselection; consider scope,\n *\t\t\t\t\t\tstatus etc.\n */\n\n#define pr_fmt(fmt) \"IPv6: \" fmt\n\n#include <linux/errno.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/sched/signal.h>\n#include <linux/socket.h>\n#include <linux/sockios.h>\n#include <linux/net.h>\n#include <linux/inet.h>\n#include <linux/in6.h>\n#include <linux/netdevice.h>\n#include <linux/if_addr.h>\n#include <linux/if_arp.h>\n#include <linux/if_arcnet.h>\n#include <linux/if_infiniband.h>\n#include <linux/route.h>\n#include <linux/inetdevice.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#ifdef CONFIG_SYSCTL\n#include <linux/sysctl.h>\n#endif\n#include <linux/capability.h>\n#include <linux/delay.h>\n#include <linux/notifier.h>\n#include <linux/string.h>\n#include <linux/hash.h>\n\n#include <net/net_namespace.h>\n#include <net/sock.h>\n#include <net/snmp.h>\n\n#include <net/6lowpan.h>\n#include <net/firewire.h>\n#include <net/ipv6.h>\n#include <net/protocol.h>\n#include <net/ndisc.h>\n#include <net/ip6_route.h>\n#include <net/addrconf.h>\n#include <net/tcp.h>\n#include <net/ip.h>\n#include <net/netlink.h>\n#include <net/pkt_sched.h>\n#include <net/l3mdev.h>\n#include <linux/if_tunnel.h>\n#include <linux/rtnetlink.h>\n#include <linux/netconf.h>\n#include <linux/random.h>\n#include <linux/uaccess.h>\n#include <asm/unaligned.h>\n\n#include <linux/proc_fs.h>\n#include <linux/seq_file.h>\n#include <linux/export.h>\n\n#define\tINFINITY_LIFE_TIME\t0xFFFFFFFF\n\n#define IPV6_MAX_STRLEN \\\n\tsizeof(\"ffff:ffff:ffff:ffff:ffff:ffff:255.255.255.255\")\n\nstatic inline u32 cstamp_delta(unsigned long cstamp)\n{\n\treturn (cstamp - INITIAL_JIFFIES) * 100UL / HZ;\n}\n\nstatic inline s32 rfc3315_s14_backoff_init(s32 irt)\n{\n\t/* multiply 'initial retransmission time' by 0.9 .. 1.1 */\n\tu64 tmp = (900000 + prandom_u32() % 200001) * (u64)irt;\n\tdo_div(tmp, 1000000);\n\treturn (s32)tmp;\n}\n\nstatic inline s32 rfc3315_s14_backoff_update(s32 rt, s32 mrt)\n{\n\t/* multiply 'retransmission timeout' by 1.9 .. 2.1 */\n\tu64 tmp = (1900000 + prandom_u32() % 200001) * (u64)rt;\n\tdo_div(tmp, 1000000);\n\tif ((s32)tmp > mrt) {\n\t\t/* multiply 'maximum retransmission time' by 0.9 .. 1.1 */\n\t\ttmp = (900000 + prandom_u32() % 200001) * (u64)mrt;\n\t\tdo_div(tmp, 1000000);\n\t}\n\treturn (s32)tmp;\n}\n\n#ifdef CONFIG_SYSCTL\nstatic int addrconf_sysctl_register(struct inet6_dev *idev);\nstatic void addrconf_sysctl_unregister(struct inet6_dev *idev);\n#else\nstatic inline int addrconf_sysctl_register(struct inet6_dev *idev)\n{\n\treturn 0;\n}\n\nstatic inline void addrconf_sysctl_unregister(struct inet6_dev *idev)\n{\n}\n#endif\n\nstatic void ipv6_gen_rnd_iid(struct in6_addr *addr);\n\nstatic int ipv6_generate_eui64(u8 *eui, struct net_device *dev);\nstatic int ipv6_count_addresses(const struct inet6_dev *idev);\nstatic int ipv6_generate_stable_address(struct in6_addr *addr,\n\t\t\t\t\tu8 dad_count,\n\t\t\t\t\tconst struct inet6_dev *idev);\n\n#define IN6_ADDR_HSIZE_SHIFT\t8\n#define IN6_ADDR_HSIZE\t\t(1 << IN6_ADDR_HSIZE_SHIFT)\n/*\n *\tConfigured unicast address hash table\n */\nstatic struct hlist_head inet6_addr_lst[IN6_ADDR_HSIZE];\nstatic DEFINE_SPINLOCK(addrconf_hash_lock);\n\nstatic void addrconf_verify(void);\nstatic void addrconf_verify_rtnl(void);\nstatic void addrconf_verify_work(struct work_struct *);\n\nstatic struct workqueue_struct *addrconf_wq;\nstatic DECLARE_DELAYED_WORK(addr_chk_work, addrconf_verify_work);\n\nstatic void addrconf_join_anycast(struct inet6_ifaddr *ifp);\nstatic void addrconf_leave_anycast(struct inet6_ifaddr *ifp);\n\nstatic void addrconf_type_change(struct net_device *dev,\n\t\t\t\t unsigned long event);\nstatic int addrconf_ifdown(struct net_device *dev, bool unregister);\n\nstatic struct fib6_info *addrconf_get_prefix_route(const struct in6_addr *pfx,\n\t\t\t\t\t\t  int plen,\n\t\t\t\t\t\t  const struct net_device *dev,\n\t\t\t\t\t\t  u32 flags, u32 noflags,\n\t\t\t\t\t\t  bool no_gw);\n\nstatic void addrconf_dad_start(struct inet6_ifaddr *ifp);\nstatic void addrconf_dad_work(struct work_struct *w);\nstatic void addrconf_dad_completed(struct inet6_ifaddr *ifp, bool bump_id,\n\t\t\t\t   bool send_na);\nstatic void addrconf_dad_run(struct inet6_dev *idev, bool restart);\nstatic void addrconf_rs_timer(struct timer_list *t);\nstatic void __ipv6_ifa_notify(int event, struct inet6_ifaddr *ifa);\nstatic void ipv6_ifa_notify(int event, struct inet6_ifaddr *ifa);\n\nstatic void inet6_prefix_notify(int event, struct inet6_dev *idev,\n\t\t\t\tstruct prefix_info *pinfo);\n\nstatic struct ipv6_devconf ipv6_devconf __read_mostly = {\n\t.forwarding\t\t= 0,\n\t.hop_limit\t\t= IPV6_DEFAULT_HOPLIMIT,\n\t.mtu6\t\t\t= IPV6_MIN_MTU,\n\t.accept_ra\t\t= 1,\n\t.accept_redirects\t= 1,\n\t.autoconf\t\t= 1,\n\t.force_mld_version\t= 0,\n\t.mldv1_unsolicited_report_interval = 10 * HZ,\n\t.mldv2_unsolicited_report_interval = HZ,\n\t.dad_transmits\t\t= 1,\n\t.rtr_solicits\t\t= MAX_RTR_SOLICITATIONS,\n\t.rtr_solicit_interval\t= RTR_SOLICITATION_INTERVAL,\n\t.rtr_solicit_max_interval = RTR_SOLICITATION_MAX_INTERVAL,\n\t.rtr_solicit_delay\t= MAX_RTR_SOLICITATION_DELAY,\n\t.use_tempaddr\t\t= 0,\n\t.temp_valid_lft\t\t= TEMP_VALID_LIFETIME,\n\t.temp_prefered_lft\t= TEMP_PREFERRED_LIFETIME,\n\t.regen_max_retry\t= REGEN_MAX_RETRY,\n\t.max_desync_factor\t= MAX_DESYNC_FACTOR,\n\t.max_addresses\t\t= IPV6_MAX_ADDRESSES,\n\t.accept_ra_defrtr\t= 1,\n\t.ra_defrtr_metric\t= IP6_RT_PRIO_USER,\n\t.accept_ra_from_local\t= 0,\n\t.accept_ra_min_hop_limit= 1,\n\t.accept_ra_pinfo\t= 1,\n#ifdef CONFIG_IPV6_ROUTER_PREF\n\t.accept_ra_rtr_pref\t= 1,\n\t.rtr_probe_interval\t= 60 * HZ,\n#ifdef CONFIG_IPV6_ROUTE_INFO\n\t.accept_ra_rt_info_min_plen = 0,\n\t.accept_ra_rt_info_max_plen = 0,\n#endif\n#endif\n\t.proxy_ndp\t\t= 0,\n\t.accept_source_route\t= 0,\t/* we do not accept RH0 by default. */\n\t.disable_ipv6\t\t= 0,\n\t.accept_dad\t\t= 0,\n\t.suppress_frag_ndisc\t= 1,\n\t.accept_ra_mtu\t\t= 1,\n\t.stable_secret\t\t= {\n\t\t.initialized = false,\n\t},\n\t.use_oif_addrs_only\t= 0,\n\t.ignore_routes_with_linkdown = 0,\n\t.keep_addr_on_down\t= 0,\n\t.seg6_enabled\t\t= 0,\n#ifdef CONFIG_IPV6_SEG6_HMAC\n\t.seg6_require_hmac\t= 0,\n#endif\n\t.enhanced_dad           = 1,\n\t.addr_gen_mode\t\t= IN6_ADDR_GEN_MODE_EUI64,\n\t.disable_policy\t\t= 0,\n\t.rpl_seg_enabled\t= 0,\n};\n\nstatic struct ipv6_devconf ipv6_devconf_dflt __read_mostly = {\n\t.forwarding\t\t= 0,\n\t.hop_limit\t\t= IPV6_DEFAULT_HOPLIMIT,\n\t.mtu6\t\t\t= IPV6_MIN_MTU,\n\t.accept_ra\t\t= 1,\n\t.accept_redirects\t= 1,\n\t.autoconf\t\t= 1,\n\t.force_mld_version\t= 0,\n\t.mldv1_unsolicited_report_interval = 10 * HZ,\n\t.mldv2_unsolicited_report_interval = HZ,\n\t.dad_transmits\t\t= 1,\n\t.rtr_solicits\t\t= MAX_RTR_SOLICITATIONS,\n\t.rtr_solicit_interval\t= RTR_SOLICITATION_INTERVAL,\n\t.rtr_solicit_max_interval = RTR_SOLICITATION_MAX_INTERVAL,\n\t.rtr_solicit_delay\t= MAX_RTR_SOLICITATION_DELAY,\n\t.use_tempaddr\t\t= 0,\n\t.temp_valid_lft\t\t= TEMP_VALID_LIFETIME,\n\t.temp_prefered_lft\t= TEMP_PREFERRED_LIFETIME,\n\t.regen_max_retry\t= REGEN_MAX_RETRY,\n\t.max_desync_factor\t= MAX_DESYNC_FACTOR,\n\t.max_addresses\t\t= IPV6_MAX_ADDRESSES,\n\t.accept_ra_defrtr\t= 1,\n\t.ra_defrtr_metric\t= IP6_RT_PRIO_USER,\n\t.accept_ra_from_local\t= 0,\n\t.accept_ra_min_hop_limit= 1,\n\t.accept_ra_pinfo\t= 1,\n#ifdef CONFIG_IPV6_ROUTER_PREF\n\t.accept_ra_rtr_pref\t= 1,\n\t.rtr_probe_interval\t= 60 * HZ,\n#ifdef CONFIG_IPV6_ROUTE_INFO\n\t.accept_ra_rt_info_min_plen = 0,\n\t.accept_ra_rt_info_max_plen = 0,\n#endif\n#endif\n\t.proxy_ndp\t\t= 0,\n\t.accept_source_route\t= 0,\t/* we do not accept RH0 by default. */\n\t.disable_ipv6\t\t= 0,\n\t.accept_dad\t\t= 1,\n\t.suppress_frag_ndisc\t= 1,\n\t.accept_ra_mtu\t\t= 1,\n\t.stable_secret\t\t= {\n\t\t.initialized = false,\n\t},\n\t.use_oif_addrs_only\t= 0,\n\t.ignore_routes_with_linkdown = 0,\n\t.keep_addr_on_down\t= 0,\n\t.seg6_enabled\t\t= 0,\n#ifdef CONFIG_IPV6_SEG6_HMAC\n\t.seg6_require_hmac\t= 0,\n#endif\n\t.enhanced_dad           = 1,\n\t.addr_gen_mode\t\t= IN6_ADDR_GEN_MODE_EUI64,\n\t.disable_policy\t\t= 0,\n\t.rpl_seg_enabled\t= 0,\n};\n\n/* Check if link is ready: is it up and is a valid qdisc available */\nstatic inline bool addrconf_link_ready(const struct net_device *dev)\n{\n\treturn netif_oper_up(dev) && !qdisc_tx_is_noop(dev);\n}\n\nstatic void addrconf_del_rs_timer(struct inet6_dev *idev)\n{\n\tif (del_timer(&idev->rs_timer))\n\t\t__in6_dev_put(idev);\n}\n\nstatic void addrconf_del_dad_work(struct inet6_ifaddr *ifp)\n{\n\tif (cancel_delayed_work(&ifp->dad_work))\n\t\t__in6_ifa_put(ifp);\n}\n\nstatic void addrconf_mod_rs_timer(struct inet6_dev *idev,\n\t\t\t\t  unsigned long when)\n{\n\tif (!timer_pending(&idev->rs_timer))\n\t\tin6_dev_hold(idev);\n\tmod_timer(&idev->rs_timer, jiffies + when);\n}\n\nstatic void addrconf_mod_dad_work(struct inet6_ifaddr *ifp,\n\t\t\t\t   unsigned long delay)\n{\n\tin6_ifa_hold(ifp);\n\tif (mod_delayed_work(addrconf_wq, &ifp->dad_work, delay))\n\t\tin6_ifa_put(ifp);\n}\n\nstatic int snmp6_alloc_dev(struct inet6_dev *idev)\n{\n\tint i;\n\n\tidev->stats.ipv6 = alloc_percpu(struct ipstats_mib);\n\tif (!idev->stats.ipv6)\n\t\tgoto err_ip;\n\n\tfor_each_possible_cpu(i) {\n\t\tstruct ipstats_mib *addrconf_stats;\n\t\taddrconf_stats = per_cpu_ptr(idev->stats.ipv6, i);\n\t\tu64_stats_init(&addrconf_stats->syncp);\n\t}\n\n\n\tidev->stats.icmpv6dev = kzalloc(sizeof(struct icmpv6_mib_device),\n\t\t\t\t\tGFP_KERNEL);\n\tif (!idev->stats.icmpv6dev)\n\t\tgoto err_icmp;\n\tidev->stats.icmpv6msgdev = kzalloc(sizeof(struct icmpv6msg_mib_device),\n\t\t\t\t\t   GFP_KERNEL);\n\tif (!idev->stats.icmpv6msgdev)\n\t\tgoto err_icmpmsg;\n\n\treturn 0;\n\nerr_icmpmsg:\n\tkfree(idev->stats.icmpv6dev);\nerr_icmp:\n\tfree_percpu(idev->stats.ipv6);\nerr_ip:\n\treturn -ENOMEM;\n}\n\nstatic struct inet6_dev *ipv6_add_dev(struct net_device *dev)\n{\n\tstruct inet6_dev *ndev;\n\tint err = -ENOMEM;\n\n\tASSERT_RTNL();\n\n\tif (dev->mtu < IPV6_MIN_MTU)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tndev = kzalloc(sizeof(struct inet6_dev), GFP_KERNEL);\n\tif (!ndev)\n\t\treturn ERR_PTR(err);\n\n\trwlock_init(&ndev->lock);\n\tndev->dev = dev;\n\tINIT_LIST_HEAD(&ndev->addr_list);\n\ttimer_setup(&ndev->rs_timer, addrconf_rs_timer, 0);\n\tmemcpy(&ndev->cnf, dev_net(dev)->ipv6.devconf_dflt, sizeof(ndev->cnf));\n\n\tif (ndev->cnf.stable_secret.initialized)\n\t\tndev->cnf.addr_gen_mode = IN6_ADDR_GEN_MODE_STABLE_PRIVACY;\n\n\tndev->cnf.mtu6 = dev->mtu;\n\tndev->nd_parms = neigh_parms_alloc(dev, &nd_tbl);\n\tif (!ndev->nd_parms) {\n\t\tkfree(ndev);\n\t\treturn ERR_PTR(err);\n\t}\n\tif (ndev->cnf.forwarding)\n\t\tdev_disable_lro(dev);\n\t/* We refer to the device */\n\tdev_hold(dev);\n\n\tif (snmp6_alloc_dev(ndev) < 0) {\n\t\tnetdev_dbg(dev, \"%s: cannot allocate memory for statistics\\n\",\n\t\t\t   __func__);\n\t\tneigh_parms_release(&nd_tbl, ndev->nd_parms);\n\t\tdev_put(dev);\n\t\tkfree(ndev);\n\t\treturn ERR_PTR(err);\n\t}\n\n\tif (snmp6_register_dev(ndev) < 0) {\n\t\tnetdev_dbg(dev, \"%s: cannot create /proc/net/dev_snmp6/%s\\n\",\n\t\t\t   __func__, dev->name);\n\t\tgoto err_release;\n\t}\n\n\t/* One reference from device. */\n\trefcount_set(&ndev->refcnt, 1);\n\n\tif (dev->flags & (IFF_NOARP | IFF_LOOPBACK))\n\t\tndev->cnf.accept_dad = -1;\n\n#if IS_ENABLED(CONFIG_IPV6_SIT)\n\tif (dev->type == ARPHRD_SIT && (dev->priv_flags & IFF_ISATAP)) {\n\t\tpr_info(\"%s: Disabled Multicast RS\\n\", dev->name);\n\t\tndev->cnf.rtr_solicits = 0;\n\t}\n#endif\n\n\tINIT_LIST_HEAD(&ndev->tempaddr_list);\n\tndev->desync_factor = U32_MAX;\n\tif ((dev->flags&IFF_LOOPBACK) ||\n\t    dev->type == ARPHRD_TUNNEL ||\n\t    dev->type == ARPHRD_TUNNEL6 ||\n\t    dev->type == ARPHRD_SIT ||\n\t    dev->type == ARPHRD_NONE) {\n\t\tndev->cnf.use_tempaddr = -1;\n\t}\n\n\tndev->token = in6addr_any;\n\n\tif (netif_running(dev) && addrconf_link_ready(dev))\n\t\tndev->if_flags |= IF_READY;\n\n\tipv6_mc_init_dev(ndev);\n\tndev->tstamp = jiffies;\n\terr = addrconf_sysctl_register(ndev);\n\tif (err) {\n\t\tipv6_mc_destroy_dev(ndev);\n\t\tsnmp6_unregister_dev(ndev);\n\t\tgoto err_release;\n\t}\n\t/* protected by rtnl_lock */\n\trcu_assign_pointer(dev->ip6_ptr, ndev);\n\n\t/* Join interface-local all-node multicast group */\n\tipv6_dev_mc_inc(dev, &in6addr_interfacelocal_allnodes);\n\n\t/* Join all-node multicast group */\n\tipv6_dev_mc_inc(dev, &in6addr_linklocal_allnodes);\n\n\t/* Join all-router multicast group if forwarding is set */\n\tif (ndev->cnf.forwarding && (dev->flags & IFF_MULTICAST))\n\t\tipv6_dev_mc_inc(dev, &in6addr_linklocal_allrouters);\n\n\treturn ndev;\n\nerr_release:\n\tneigh_parms_release(&nd_tbl, ndev->nd_parms);\n\tndev->dead = 1;\n\tin6_dev_finish_destroy(ndev);\n\treturn ERR_PTR(err);\n}\n\nstatic struct inet6_dev *ipv6_find_idev(struct net_device *dev)\n{\n\tstruct inet6_dev *idev;\n\n\tASSERT_RTNL();\n\n\tidev = __in6_dev_get(dev);\n\tif (!idev) {\n\t\tidev = ipv6_add_dev(dev);\n\t\tif (IS_ERR(idev))\n\t\t\treturn idev;\n\t}\n\n\tif (dev->flags&IFF_UP)\n\t\tipv6_mc_up(idev);\n\treturn idev;\n}\n\nstatic int inet6_netconf_msgsize_devconf(int type)\n{\n\tint size =  NLMSG_ALIGN(sizeof(struct netconfmsg))\n\t\t    + nla_total_size(4);\t/* NETCONFA_IFINDEX */\n\tbool all = false;\n\n\tif (type == NETCONFA_ALL)\n\t\tall = true;\n\n\tif (all || type == NETCONFA_FORWARDING)\n\t\tsize += nla_total_size(4);\n#ifdef CONFIG_IPV6_MROUTE\n\tif (all || type == NETCONFA_MC_FORWARDING)\n\t\tsize += nla_total_size(4);\n#endif\n\tif (all || type == NETCONFA_PROXY_NEIGH)\n\t\tsize += nla_total_size(4);\n\n\tif (all || type == NETCONFA_IGNORE_ROUTES_WITH_LINKDOWN)\n\t\tsize += nla_total_size(4);\n\n\treturn size;\n}\n\nstatic int inet6_netconf_fill_devconf(struct sk_buff *skb, int ifindex,\n\t\t\t\t      struct ipv6_devconf *devconf, u32 portid,\n\t\t\t\t      u32 seq, int event, unsigned int flags,\n\t\t\t\t      int type)\n{\n\tstruct nlmsghdr  *nlh;\n\tstruct netconfmsg *ncm;\n\tbool all = false;\n\n\tnlh = nlmsg_put(skb, portid, seq, event, sizeof(struct netconfmsg),\n\t\t\tflags);\n\tif (!nlh)\n\t\treturn -EMSGSIZE;\n\n\tif (type == NETCONFA_ALL)\n\t\tall = true;\n\n\tncm = nlmsg_data(nlh);\n\tncm->ncm_family = AF_INET6;\n\n\tif (nla_put_s32(skb, NETCONFA_IFINDEX, ifindex) < 0)\n\t\tgoto nla_put_failure;\n\n\tif (!devconf)\n\t\tgoto out;\n\n\tif ((all || type == NETCONFA_FORWARDING) &&\n\t    nla_put_s32(skb, NETCONFA_FORWARDING, devconf->forwarding) < 0)\n\t\tgoto nla_put_failure;\n#ifdef CONFIG_IPV6_MROUTE\n\tif ((all || type == NETCONFA_MC_FORWARDING) &&\n\t    nla_put_s32(skb, NETCONFA_MC_FORWARDING,\n\t\t\tdevconf->mc_forwarding) < 0)\n\t\tgoto nla_put_failure;\n#endif\n\tif ((all || type == NETCONFA_PROXY_NEIGH) &&\n\t    nla_put_s32(skb, NETCONFA_PROXY_NEIGH, devconf->proxy_ndp) < 0)\n\t\tgoto nla_put_failure;\n\n\tif ((all || type == NETCONFA_IGNORE_ROUTES_WITH_LINKDOWN) &&\n\t    nla_put_s32(skb, NETCONFA_IGNORE_ROUTES_WITH_LINKDOWN,\n\t\t\tdevconf->ignore_routes_with_linkdown) < 0)\n\t\tgoto nla_put_failure;\n\nout:\n\tnlmsg_end(skb, nlh);\n\treturn 0;\n\nnla_put_failure:\n\tnlmsg_cancel(skb, nlh);\n\treturn -EMSGSIZE;\n}\n\nvoid inet6_netconf_notify_devconf(struct net *net, int event, int type,\n\t\t\t\t  int ifindex, struct ipv6_devconf *devconf)\n{\n\tstruct sk_buff *skb;\n\tint err = -ENOBUFS;\n\n\tskb = nlmsg_new(inet6_netconf_msgsize_devconf(type), GFP_KERNEL);\n\tif (!skb)\n\t\tgoto errout;\n\n\terr = inet6_netconf_fill_devconf(skb, ifindex, devconf, 0, 0,\n\t\t\t\t\t event, 0, type);\n\tif (err < 0) {\n\t\t/* -EMSGSIZE implies BUG in inet6_netconf_msgsize_devconf() */\n\t\tWARN_ON(err == -EMSGSIZE);\n\t\tkfree_skb(skb);\n\t\tgoto errout;\n\t}\n\trtnl_notify(skb, net, 0, RTNLGRP_IPV6_NETCONF, NULL, GFP_KERNEL);\n\treturn;\nerrout:\n\trtnl_set_sk_err(net, RTNLGRP_IPV6_NETCONF, err);\n}\n\nstatic const struct nla_policy devconf_ipv6_policy[NETCONFA_MAX+1] = {\n\t[NETCONFA_IFINDEX]\t= { .len = sizeof(int) },\n\t[NETCONFA_FORWARDING]\t= { .len = sizeof(int) },\n\t[NETCONFA_PROXY_NEIGH]\t= { .len = sizeof(int) },\n\t[NETCONFA_IGNORE_ROUTES_WITH_LINKDOWN]\t= { .len = sizeof(int) },\n};\n\nstatic int inet6_netconf_valid_get_req(struct sk_buff *skb,\n\t\t\t\t       const struct nlmsghdr *nlh,\n\t\t\t\t       struct nlattr **tb,\n\t\t\t\t       struct netlink_ext_ack *extack)\n{\n\tint i, err;\n\n\tif (nlh->nlmsg_len < nlmsg_msg_size(sizeof(struct netconfmsg))) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Invalid header for netconf get request\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!netlink_strict_get_check(skb))\n\t\treturn nlmsg_parse_deprecated(nlh, sizeof(struct netconfmsg),\n\t\t\t\t\t      tb, NETCONFA_MAX,\n\t\t\t\t\t      devconf_ipv6_policy, extack);\n\n\terr = nlmsg_parse_deprecated_strict(nlh, sizeof(struct netconfmsg),\n\t\t\t\t\t    tb, NETCONFA_MAX,\n\t\t\t\t\t    devconf_ipv6_policy, extack);\n\tif (err)\n\t\treturn err;\n\n\tfor (i = 0; i <= NETCONFA_MAX; i++) {\n\t\tif (!tb[i])\n\t\t\tcontinue;\n\n\t\tswitch (i) {\n\t\tcase NETCONFA_IFINDEX:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Unsupported attribute in netconf get request\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int inet6_netconf_get_devconf(struct sk_buff *in_skb,\n\t\t\t\t     struct nlmsghdr *nlh,\n\t\t\t\t     struct netlink_ext_ack *extack)\n{\n\tstruct net *net = sock_net(in_skb->sk);\n\tstruct nlattr *tb[NETCONFA_MAX+1];\n\tstruct inet6_dev *in6_dev = NULL;\n\tstruct net_device *dev = NULL;\n\tstruct sk_buff *skb;\n\tstruct ipv6_devconf *devconf;\n\tint ifindex;\n\tint err;\n\n\terr = inet6_netconf_valid_get_req(in_skb, nlh, tb, extack);\n\tif (err < 0)\n\t\treturn err;\n\n\tif (!tb[NETCONFA_IFINDEX])\n\t\treturn -EINVAL;\n\n\terr = -EINVAL;\n\tifindex = nla_get_s32(tb[NETCONFA_IFINDEX]);\n\tswitch (ifindex) {\n\tcase NETCONFA_IFINDEX_ALL:\n\t\tdevconf = net->ipv6.devconf_all;\n\t\tbreak;\n\tcase NETCONFA_IFINDEX_DEFAULT:\n\t\tdevconf = net->ipv6.devconf_dflt;\n\t\tbreak;\n\tdefault:\n\t\tdev = dev_get_by_index(net, ifindex);\n\t\tif (!dev)\n\t\t\treturn -EINVAL;\n\t\tin6_dev = in6_dev_get(dev);\n\t\tif (!in6_dev)\n\t\t\tgoto errout;\n\t\tdevconf = &in6_dev->cnf;\n\t\tbreak;\n\t}\n\n\terr = -ENOBUFS;\n\tskb = nlmsg_new(inet6_netconf_msgsize_devconf(NETCONFA_ALL), GFP_KERNEL);\n\tif (!skb)\n\t\tgoto errout;\n\n\terr = inet6_netconf_fill_devconf(skb, ifindex, devconf,\n\t\t\t\t\t NETLINK_CB(in_skb).portid,\n\t\t\t\t\t nlh->nlmsg_seq, RTM_NEWNETCONF, 0,\n\t\t\t\t\t NETCONFA_ALL);\n\tif (err < 0) {\n\t\t/* -EMSGSIZE implies BUG in inet6_netconf_msgsize_devconf() */\n\t\tWARN_ON(err == -EMSGSIZE);\n\t\tkfree_skb(skb);\n\t\tgoto errout;\n\t}\n\terr = rtnl_unicast(skb, net, NETLINK_CB(in_skb).portid);\nerrout:\n\tif (in6_dev)\n\t\tin6_dev_put(in6_dev);\n\tif (dev)\n\t\tdev_put(dev);\n\treturn err;\n}\n\nstatic int inet6_netconf_dump_devconf(struct sk_buff *skb,\n\t\t\t\t      struct netlink_callback *cb)\n{\n\tconst struct nlmsghdr *nlh = cb->nlh;\n\tstruct net *net = sock_net(skb->sk);\n\tint h, s_h;\n\tint idx, s_idx;\n\tstruct net_device *dev;\n\tstruct inet6_dev *idev;\n\tstruct hlist_head *head;\n\n\tif (cb->strict_check) {\n\t\tstruct netlink_ext_ack *extack = cb->extack;\n\t\tstruct netconfmsg *ncm;\n\n\t\tif (nlh->nlmsg_len < nlmsg_msg_size(sizeof(*ncm))) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Invalid header for netconf dump request\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (nlmsg_attrlen(nlh, sizeof(*ncm))) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Invalid data after header in netconf dump request\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\ts_h = cb->args[0];\n\ts_idx = idx = cb->args[1];\n\n\tfor (h = s_h; h < NETDEV_HASHENTRIES; h++, s_idx = 0) {\n\t\tidx = 0;\n\t\thead = &net->dev_index_head[h];\n\t\trcu_read_lock();\n\t\tcb->seq = atomic_read(&net->ipv6.dev_addr_genid) ^\n\t\t\t  net->dev_base_seq;\n\t\thlist_for_each_entry_rcu(dev, head, index_hlist) {\n\t\t\tif (idx < s_idx)\n\t\t\t\tgoto cont;\n\t\t\tidev = __in6_dev_get(dev);\n\t\t\tif (!idev)\n\t\t\t\tgoto cont;\n\n\t\t\tif (inet6_netconf_fill_devconf(skb, dev->ifindex,\n\t\t\t\t\t\t       &idev->cnf,\n\t\t\t\t\t\t       NETLINK_CB(cb->skb).portid,\n\t\t\t\t\t\t       nlh->nlmsg_seq,\n\t\t\t\t\t\t       RTM_NEWNETCONF,\n\t\t\t\t\t\t       NLM_F_MULTI,\n\t\t\t\t\t\t       NETCONFA_ALL) < 0) {\n\t\t\t\trcu_read_unlock();\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t\tnl_dump_check_consistent(cb, nlmsg_hdr(skb));\ncont:\n\t\t\tidx++;\n\t\t}\n\t\trcu_read_unlock();\n\t}\n\tif (h == NETDEV_HASHENTRIES) {\n\t\tif (inet6_netconf_fill_devconf(skb, NETCONFA_IFINDEX_ALL,\n\t\t\t\t\t       net->ipv6.devconf_all,\n\t\t\t\t\t       NETLINK_CB(cb->skb).portid,\n\t\t\t\t\t       nlh->nlmsg_seq,\n\t\t\t\t\t       RTM_NEWNETCONF, NLM_F_MULTI,\n\t\t\t\t\t       NETCONFA_ALL) < 0)\n\t\t\tgoto done;\n\t\telse\n\t\t\th++;\n\t}\n\tif (h == NETDEV_HASHENTRIES + 1) {\n\t\tif (inet6_netconf_fill_devconf(skb, NETCONFA_IFINDEX_DEFAULT,\n\t\t\t\t\t       net->ipv6.devconf_dflt,\n\t\t\t\t\t       NETLINK_CB(cb->skb).portid,\n\t\t\t\t\t       nlh->nlmsg_seq,\n\t\t\t\t\t       RTM_NEWNETCONF, NLM_F_MULTI,\n\t\t\t\t\t       NETCONFA_ALL) < 0)\n\t\t\tgoto done;\n\t\telse\n\t\t\th++;\n\t}\ndone:\n\tcb->args[0] = h;\n\tcb->args[1] = idx;\n\n\treturn skb->len;\n}\n\n#ifdef CONFIG_SYSCTL\nstatic void dev_forward_change(struct inet6_dev *idev)\n{\n\tstruct net_device *dev;\n\tstruct inet6_ifaddr *ifa;\n\n\tif (!idev)\n\t\treturn;\n\tdev = idev->dev;\n\tif (idev->cnf.forwarding)\n\t\tdev_disable_lro(dev);\n\tif (dev->flags & IFF_MULTICAST) {\n\t\tif (idev->cnf.forwarding) {\n\t\t\tipv6_dev_mc_inc(dev, &in6addr_linklocal_allrouters);\n\t\t\tipv6_dev_mc_inc(dev, &in6addr_interfacelocal_allrouters);\n\t\t\tipv6_dev_mc_inc(dev, &in6addr_sitelocal_allrouters);\n\t\t} else {\n\t\t\tipv6_dev_mc_dec(dev, &in6addr_linklocal_allrouters);\n\t\t\tipv6_dev_mc_dec(dev, &in6addr_interfacelocal_allrouters);\n\t\t\tipv6_dev_mc_dec(dev, &in6addr_sitelocal_allrouters);\n\t\t}\n\t}\n\n\tlist_for_each_entry(ifa, &idev->addr_list, if_list) {\n\t\tif (ifa->flags&IFA_F_TENTATIVE)\n\t\t\tcontinue;\n\t\tif (idev->cnf.forwarding)\n\t\t\taddrconf_join_anycast(ifa);\n\t\telse\n\t\t\taddrconf_leave_anycast(ifa);\n\t}\n\tinet6_netconf_notify_devconf(dev_net(dev), RTM_NEWNETCONF,\n\t\t\t\t     NETCONFA_FORWARDING,\n\t\t\t\t     dev->ifindex, &idev->cnf);\n}\n\n\nstatic void addrconf_forward_change(struct net *net, __s32 newf)\n{\n\tstruct net_device *dev;\n\tstruct inet6_dev *idev;\n\n\tfor_each_netdev(net, dev) {\n\t\tidev = __in6_dev_get(dev);\n\t\tif (idev) {\n\t\t\tint changed = (!idev->cnf.forwarding) ^ (!newf);\n\t\t\tidev->cnf.forwarding = newf;\n\t\t\tif (changed)\n\t\t\t\tdev_forward_change(idev);\n\t\t}\n\t}\n}\n\nstatic int addrconf_fixup_forwarding(struct ctl_table *table, int *p, int newf)\n{\n\tstruct net *net;\n\tint old;\n\n\tif (!rtnl_trylock())\n\t\treturn restart_syscall();\n\n\tnet = (struct net *)table->extra2;\n\told = *p;\n\t*p = newf;\n\n\tif (p == &net->ipv6.devconf_dflt->forwarding) {\n\t\tif ((!newf) ^ (!old))\n\t\t\tinet6_netconf_notify_devconf(net, RTM_NEWNETCONF,\n\t\t\t\t\t\t     NETCONFA_FORWARDING,\n\t\t\t\t\t\t     NETCONFA_IFINDEX_DEFAULT,\n\t\t\t\t\t\t     net->ipv6.devconf_dflt);\n\t\trtnl_unlock();\n\t\treturn 0;\n\t}\n\n\tif (p == &net->ipv6.devconf_all->forwarding) {\n\t\tint old_dflt = net->ipv6.devconf_dflt->forwarding;\n\n\t\tnet->ipv6.devconf_dflt->forwarding = newf;\n\t\tif ((!newf) ^ (!old_dflt))\n\t\t\tinet6_netconf_notify_devconf(net, RTM_NEWNETCONF,\n\t\t\t\t\t\t     NETCONFA_FORWARDING,\n\t\t\t\t\t\t     NETCONFA_IFINDEX_DEFAULT,\n\t\t\t\t\t\t     net->ipv6.devconf_dflt);\n\n\t\taddrconf_forward_change(net, newf);\n\t\tif ((!newf) ^ (!old))\n\t\t\tinet6_netconf_notify_devconf(net, RTM_NEWNETCONF,\n\t\t\t\t\t\t     NETCONFA_FORWARDING,\n\t\t\t\t\t\t     NETCONFA_IFINDEX_ALL,\n\t\t\t\t\t\t     net->ipv6.devconf_all);\n\t} else if ((!newf) ^ (!old))\n\t\tdev_forward_change((struct inet6_dev *)table->extra1);\n\trtnl_unlock();\n\n\tif (newf)\n\t\trt6_purge_dflt_routers(net);\n\treturn 1;\n}\n\nstatic void addrconf_linkdown_change(struct net *net, __s32 newf)\n{\n\tstruct net_device *dev;\n\tstruct inet6_dev *idev;\n\n\tfor_each_netdev(net, dev) {\n\t\tidev = __in6_dev_get(dev);\n\t\tif (idev) {\n\t\t\tint changed = (!idev->cnf.ignore_routes_with_linkdown) ^ (!newf);\n\n\t\t\tidev->cnf.ignore_routes_with_linkdown = newf;\n\t\t\tif (changed)\n\t\t\t\tinet6_netconf_notify_devconf(dev_net(dev),\n\t\t\t\t\t\t\t     RTM_NEWNETCONF,\n\t\t\t\t\t\t\t     NETCONFA_IGNORE_ROUTES_WITH_LINKDOWN,\n\t\t\t\t\t\t\t     dev->ifindex,\n\t\t\t\t\t\t\t     &idev->cnf);\n\t\t}\n\t}\n}\n\nstatic int addrconf_fixup_linkdown(struct ctl_table *table, int *p, int newf)\n{\n\tstruct net *net;\n\tint old;\n\n\tif (!rtnl_trylock())\n\t\treturn restart_syscall();\n\n\tnet = (struct net *)table->extra2;\n\told = *p;\n\t*p = newf;\n\n\tif (p == &net->ipv6.devconf_dflt->ignore_routes_with_linkdown) {\n\t\tif ((!newf) ^ (!old))\n\t\t\tinet6_netconf_notify_devconf(net,\n\t\t\t\t\t\t     RTM_NEWNETCONF,\n\t\t\t\t\t\t     NETCONFA_IGNORE_ROUTES_WITH_LINKDOWN,\n\t\t\t\t\t\t     NETCONFA_IFINDEX_DEFAULT,\n\t\t\t\t\t\t     net->ipv6.devconf_dflt);\n\t\trtnl_unlock();\n\t\treturn 0;\n\t}\n\n\tif (p == &net->ipv6.devconf_all->ignore_routes_with_linkdown) {\n\t\tnet->ipv6.devconf_dflt->ignore_routes_with_linkdown = newf;\n\t\taddrconf_linkdown_change(net, newf);\n\t\tif ((!newf) ^ (!old))\n\t\t\tinet6_netconf_notify_devconf(net,\n\t\t\t\t\t\t     RTM_NEWNETCONF,\n\t\t\t\t\t\t     NETCONFA_IGNORE_ROUTES_WITH_LINKDOWN,\n\t\t\t\t\t\t     NETCONFA_IFINDEX_ALL,\n\t\t\t\t\t\t     net->ipv6.devconf_all);\n\t}\n\trtnl_unlock();\n\n\treturn 1;\n}\n\n#endif\n\n/* Nobody refers to this ifaddr, destroy it */\nvoid inet6_ifa_finish_destroy(struct inet6_ifaddr *ifp)\n{\n\tWARN_ON(!hlist_unhashed(&ifp->addr_lst));\n\n#ifdef NET_REFCNT_DEBUG\n\tpr_debug(\"%s\\n\", __func__);\n#endif\n\n\tin6_dev_put(ifp->idev);\n\n\tif (cancel_delayed_work(&ifp->dad_work))\n\t\tpr_notice(\"delayed DAD work was pending while freeing ifa=%p\\n\",\n\t\t\t  ifp);\n\n\tif (ifp->state != INET6_IFADDR_STATE_DEAD) {\n\t\tpr_warn(\"Freeing alive inet6 address %p\\n\", ifp);\n\t\treturn;\n\t}\n\n\tkfree_rcu(ifp, rcu);\n}\n\nstatic void\nipv6_link_dev_addr(struct inet6_dev *idev, struct inet6_ifaddr *ifp)\n{\n\tstruct list_head *p;\n\tint ifp_scope = ipv6_addr_src_scope(&ifp->addr);\n\n\t/*\n\t * Each device address list is sorted in order of scope -\n\t * global before linklocal.\n\t */\n\tlist_for_each(p, &idev->addr_list) {\n\t\tstruct inet6_ifaddr *ifa\n\t\t\t= list_entry(p, struct inet6_ifaddr, if_list);\n\t\tif (ifp_scope >= ipv6_addr_src_scope(&ifa->addr))\n\t\t\tbreak;\n\t}\n\n\tlist_add_tail_rcu(&ifp->if_list, p);\n}\n\nstatic u32 inet6_addr_hash(const struct net *net, const struct in6_addr *addr)\n{\n\tu32 val = ipv6_addr_hash(addr) ^ net_hash_mix(net);\n\n\treturn hash_32(val, IN6_ADDR_HSIZE_SHIFT);\n}\n\nstatic bool ipv6_chk_same_addr(struct net *net, const struct in6_addr *addr,\n\t\t\t       struct net_device *dev, unsigned int hash)\n{\n\tstruct inet6_ifaddr *ifp;\n\n\thlist_for_each_entry(ifp, &inet6_addr_lst[hash], addr_lst) {\n\t\tif (!net_eq(dev_net(ifp->idev->dev), net))\n\t\t\tcontinue;\n\t\tif (ipv6_addr_equal(&ifp->addr, addr)) {\n\t\t\tif (!dev || ifp->idev->dev == dev)\n\t\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}\n\nstatic int ipv6_add_addr_hash(struct net_device *dev, struct inet6_ifaddr *ifa)\n{\n\tunsigned int hash = inet6_addr_hash(dev_net(dev), &ifa->addr);\n\tint err = 0;\n\n\tspin_lock(&addrconf_hash_lock);\n\n\t/* Ignore adding duplicate addresses on an interface */\n\tif (ipv6_chk_same_addr(dev_net(dev), &ifa->addr, dev, hash)) {\n\t\tnetdev_dbg(dev, \"ipv6_add_addr: already assigned\\n\");\n\t\terr = -EEXIST;\n\t} else {\n\t\thlist_add_head_rcu(&ifa->addr_lst, &inet6_addr_lst[hash]);\n\t}\n\n\tspin_unlock(&addrconf_hash_lock);\n\n\treturn err;\n}\n\n/* On success it returns ifp with increased reference count */\n\nstatic struct inet6_ifaddr *\nipv6_add_addr(struct inet6_dev *idev, struct ifa6_config *cfg,\n\t      bool can_block, struct netlink_ext_ack *extack)\n{\n\tgfp_t gfp_flags = can_block ? GFP_KERNEL : GFP_ATOMIC;\n\tint addr_type = ipv6_addr_type(cfg->pfx);\n\tstruct net *net = dev_net(idev->dev);\n\tstruct inet6_ifaddr *ifa = NULL;\n\tstruct fib6_info *f6i = NULL;\n\tint err = 0;\n\n\tif (addr_type == IPV6_ADDR_ANY ||\n\t    (addr_type & IPV6_ADDR_MULTICAST &&\n\t     !(cfg->ifa_flags & IFA_F_MCAUTOJOIN)) ||\n\t    (!(idev->dev->flags & IFF_LOOPBACK) &&\n\t     !netif_is_l3_master(idev->dev) &&\n\t     addr_type & IPV6_ADDR_LOOPBACK))\n\t\treturn ERR_PTR(-EADDRNOTAVAIL);\n\n\tif (idev->dead) {\n\t\terr = -ENODEV;\t\t\t/*XXX*/\n\t\tgoto out;\n\t}\n\n\tif (idev->cnf.disable_ipv6) {\n\t\terr = -EACCES;\n\t\tgoto out;\n\t}\n\n\t/* validator notifier needs to be blocking;\n\t * do not call in atomic context\n\t */\n\tif (can_block) {\n\t\tstruct in6_validator_info i6vi = {\n\t\t\t.i6vi_addr = *cfg->pfx,\n\t\t\t.i6vi_dev = idev,\n\t\t\t.extack = extack,\n\t\t};\n\n\t\terr = inet6addr_validator_notifier_call_chain(NETDEV_UP, &i6vi);\n\t\terr = notifier_to_errno(err);\n\t\tif (err < 0)\n\t\t\tgoto out;\n\t}\n\n\tifa = kzalloc(sizeof(*ifa), gfp_flags);\n\tif (!ifa) {\n\t\terr = -ENOBUFS;\n\t\tgoto out;\n\t}\n\n\tf6i = addrconf_f6i_alloc(net, idev, cfg->pfx, false, gfp_flags);\n\tif (IS_ERR(f6i)) {\n\t\terr = PTR_ERR(f6i);\n\t\tf6i = NULL;\n\t\tgoto out;\n\t}\n\n\tif (net->ipv6.devconf_all->disable_policy ||\n\t    idev->cnf.disable_policy)\n\t\tf6i->dst_nopolicy = true;\n\n\tneigh_parms_data_state_setall(idev->nd_parms);\n\n\tifa->addr = *cfg->pfx;\n\tif (cfg->peer_pfx)\n\t\tifa->peer_addr = *cfg->peer_pfx;\n\n\tspin_lock_init(&ifa->lock);\n\tINIT_DELAYED_WORK(&ifa->dad_work, addrconf_dad_work);\n\tINIT_HLIST_NODE(&ifa->addr_lst);\n\tifa->scope = cfg->scope;\n\tifa->prefix_len = cfg->plen;\n\tifa->rt_priority = cfg->rt_priority;\n\tifa->flags = cfg->ifa_flags;\n\t/* No need to add the TENTATIVE flag for addresses with NODAD */\n\tif (!(cfg->ifa_flags & IFA_F_NODAD))\n\t\tifa->flags |= IFA_F_TENTATIVE;\n\tifa->valid_lft = cfg->valid_lft;\n\tifa->prefered_lft = cfg->preferred_lft;\n\tifa->cstamp = ifa->tstamp = jiffies;\n\tifa->tokenized = false;\n\n\tifa->rt = f6i;\n\n\tifa->idev = idev;\n\tin6_dev_hold(idev);\n\n\t/* For caller */\n\trefcount_set(&ifa->refcnt, 1);\n\n\trcu_read_lock_bh();\n\n\terr = ipv6_add_addr_hash(idev->dev, ifa);\n\tif (err < 0) {\n\t\trcu_read_unlock_bh();\n\t\tgoto out;\n\t}\n\n\twrite_lock(&idev->lock);\n\n\t/* Add to inet6_dev unicast addr list. */\n\tipv6_link_dev_addr(idev, ifa);\n\n\tif (ifa->flags&IFA_F_TEMPORARY) {\n\t\tlist_add(&ifa->tmp_list, &idev->tempaddr_list);\n\t\tin6_ifa_hold(ifa);\n\t}\n\n\tin6_ifa_hold(ifa);\n\twrite_unlock(&idev->lock);\n\n\trcu_read_unlock_bh();\n\n\tinet6addr_notifier_call_chain(NETDEV_UP, ifa);\nout:\n\tif (unlikely(err < 0)) {\n\t\tfib6_info_release(f6i);\n\n\t\tif (ifa) {\n\t\t\tif (ifa->idev)\n\t\t\t\tin6_dev_put(ifa->idev);\n\t\t\tkfree(ifa);\n\t\t}\n\t\tifa = ERR_PTR(err);\n\t}\n\n\treturn ifa;\n}\n\nenum cleanup_prefix_rt_t {\n\tCLEANUP_PREFIX_RT_NOP,    /* no cleanup action for prefix route */\n\tCLEANUP_PREFIX_RT_DEL,    /* delete the prefix route */\n\tCLEANUP_PREFIX_RT_EXPIRE, /* update the lifetime of the prefix route */\n};\n\n/*\n * Check, whether the prefix for ifp would still need a prefix route\n * after deleting ifp. The function returns one of the CLEANUP_PREFIX_RT_*\n * constants.\n *\n * 1) we don't purge prefix if address was not permanent.\n *    prefix is managed by its own lifetime.\n * 2) we also don't purge, if the address was IFA_F_NOPREFIXROUTE.\n * 3) if there are no addresses, delete prefix.\n * 4) if there are still other permanent address(es),\n *    corresponding prefix is still permanent.\n * 5) if there are still other addresses with IFA_F_NOPREFIXROUTE,\n *    don't purge the prefix, assume user space is managing it.\n * 6) otherwise, update prefix lifetime to the\n *    longest valid lifetime among the corresponding\n *    addresses on the device.\n *    Note: subsequent RA will update lifetime.\n **/\nstatic enum cleanup_prefix_rt_t\ncheck_cleanup_prefix_route(struct inet6_ifaddr *ifp, unsigned long *expires)\n{\n\tstruct inet6_ifaddr *ifa;\n\tstruct inet6_dev *idev = ifp->idev;\n\tunsigned long lifetime;\n\tenum cleanup_prefix_rt_t action = CLEANUP_PREFIX_RT_DEL;\n\n\t*expires = jiffies;\n\n\tlist_for_each_entry(ifa, &idev->addr_list, if_list) {\n\t\tif (ifa == ifp)\n\t\t\tcontinue;\n\t\tif (ifa->prefix_len != ifp->prefix_len ||\n\t\t    !ipv6_prefix_equal(&ifa->addr, &ifp->addr,\n\t\t\t\t       ifp->prefix_len))\n\t\t\tcontinue;\n\t\tif (ifa->flags & (IFA_F_PERMANENT | IFA_F_NOPREFIXROUTE))\n\t\t\treturn CLEANUP_PREFIX_RT_NOP;\n\n\t\taction = CLEANUP_PREFIX_RT_EXPIRE;\n\n\t\tspin_lock(&ifa->lock);\n\n\t\tlifetime = addrconf_timeout_fixup(ifa->valid_lft, HZ);\n\t\t/*\n\t\t * Note: Because this address is\n\t\t * not permanent, lifetime <\n\t\t * LONG_MAX / HZ here.\n\t\t */\n\t\tif (time_before(*expires, ifa->tstamp + lifetime * HZ))\n\t\t\t*expires = ifa->tstamp + lifetime * HZ;\n\t\tspin_unlock(&ifa->lock);\n\t}\n\n\treturn action;\n}\n\nstatic void\ncleanup_prefix_route(struct inet6_ifaddr *ifp, unsigned long expires,\n\t\t     bool del_rt, bool del_peer)\n{\n\tstruct fib6_info *f6i;\n\n\tf6i = addrconf_get_prefix_route(del_peer ? &ifp->peer_addr : &ifp->addr,\n\t\t\t\t\tifp->prefix_len,\n\t\t\t\t\tifp->idev->dev, 0, RTF_DEFAULT, true);\n\tif (f6i) {\n\t\tif (del_rt)\n\t\t\tip6_del_rt(dev_net(ifp->idev->dev), f6i, false);\n\t\telse {\n\t\t\tif (!(f6i->fib6_flags & RTF_EXPIRES))\n\t\t\t\tfib6_set_expires(f6i, expires);\n\t\t\tfib6_info_release(f6i);\n\t\t}\n\t}\n}\n\n\n/* This function wants to get referenced ifp and releases it before return */\n\nstatic void ipv6_del_addr(struct inet6_ifaddr *ifp)\n{\n\tint state;\n\tenum cleanup_prefix_rt_t action = CLEANUP_PREFIX_RT_NOP;\n\tunsigned long expires;\n\n\tASSERT_RTNL();\n\n\tspin_lock_bh(&ifp->lock);\n\tstate = ifp->state;\n\tifp->state = INET6_IFADDR_STATE_DEAD;\n\tspin_unlock_bh(&ifp->lock);\n\n\tif (state == INET6_IFADDR_STATE_DEAD)\n\t\tgoto out;\n\n\tspin_lock_bh(&addrconf_hash_lock);\n\thlist_del_init_rcu(&ifp->addr_lst);\n\tspin_unlock_bh(&addrconf_hash_lock);\n\n\twrite_lock_bh(&ifp->idev->lock);\n\n\tif (ifp->flags&IFA_F_TEMPORARY) {\n\t\tlist_del(&ifp->tmp_list);\n\t\tif (ifp->ifpub) {\n\t\t\tin6_ifa_put(ifp->ifpub);\n\t\t\tifp->ifpub = NULL;\n\t\t}\n\t\t__in6_ifa_put(ifp);\n\t}\n\n\tif (ifp->flags & IFA_F_PERMANENT && !(ifp->flags & IFA_F_NOPREFIXROUTE))\n\t\taction = check_cleanup_prefix_route(ifp, &expires);\n\n\tlist_del_rcu(&ifp->if_list);\n\t__in6_ifa_put(ifp);\n\n\twrite_unlock_bh(&ifp->idev->lock);\n\n\taddrconf_del_dad_work(ifp);\n\n\tipv6_ifa_notify(RTM_DELADDR, ifp);\n\n\tinet6addr_notifier_call_chain(NETDEV_DOWN, ifp);\n\n\tif (action != CLEANUP_PREFIX_RT_NOP) {\n\t\tcleanup_prefix_route(ifp, expires,\n\t\t\taction == CLEANUP_PREFIX_RT_DEL, false);\n\t}\n\n\t/* clean up prefsrc entries */\n\trt6_remove_prefsrc(ifp);\nout:\n\tin6_ifa_put(ifp);\n}\n\nstatic int ipv6_create_tempaddr(struct inet6_ifaddr *ifp, bool block)\n{\n\tstruct inet6_dev *idev = ifp->idev;\n\tunsigned long tmp_tstamp, age;\n\tunsigned long regen_advance;\n\tunsigned long now = jiffies;\n\ts32 cnf_temp_preferred_lft;\n\tstruct inet6_ifaddr *ift;\n\tstruct ifa6_config cfg;\n\tlong max_desync_factor;\n\tstruct in6_addr addr;\n\tint ret = 0;\n\n\twrite_lock_bh(&idev->lock);\n\nretry:\n\tin6_dev_hold(idev);\n\tif (idev->cnf.use_tempaddr <= 0) {\n\t\twrite_unlock_bh(&idev->lock);\n\t\tpr_info(\"%s: use_tempaddr is disabled\\n\", __func__);\n\t\tin6_dev_put(idev);\n\t\tret = -1;\n\t\tgoto out;\n\t}\n\tspin_lock_bh(&ifp->lock);\n\tif (ifp->regen_count++ >= idev->cnf.regen_max_retry) {\n\t\tidev->cnf.use_tempaddr = -1;\t/*XXX*/\n\t\tspin_unlock_bh(&ifp->lock);\n\t\twrite_unlock_bh(&idev->lock);\n\t\tpr_warn(\"%s: regeneration time exceeded - disabled temporary address support\\n\",\n\t\t\t__func__);\n\t\tin6_dev_put(idev);\n\t\tret = -1;\n\t\tgoto out;\n\t}\n\tin6_ifa_hold(ifp);\n\tmemcpy(addr.s6_addr, ifp->addr.s6_addr, 8);\n\tipv6_gen_rnd_iid(&addr);\n\n\tage = (now - ifp->tstamp) / HZ;\n\n\tregen_advance = idev->cnf.regen_max_retry *\n\t\t\tidev->cnf.dad_transmits *\n\t\t\tmax(NEIGH_VAR(idev->nd_parms, RETRANS_TIME), HZ/100) / HZ;\n\n\t/* recalculate max_desync_factor each time and update\n\t * idev->desync_factor if it's larger\n\t */\n\tcnf_temp_preferred_lft = READ_ONCE(idev->cnf.temp_prefered_lft);\n\tmax_desync_factor = min_t(__u32,\n\t\t\t\t  idev->cnf.max_desync_factor,\n\t\t\t\t  cnf_temp_preferred_lft - regen_advance);\n\n\tif (unlikely(idev->desync_factor > max_desync_factor)) {\n\t\tif (max_desync_factor > 0) {\n\t\t\tget_random_bytes(&idev->desync_factor,\n\t\t\t\t\t sizeof(idev->desync_factor));\n\t\t\tidev->desync_factor %= max_desync_factor;\n\t\t} else {\n\t\t\tidev->desync_factor = 0;\n\t\t}\n\t}\n\n\tmemset(&cfg, 0, sizeof(cfg));\n\tcfg.valid_lft = min_t(__u32, ifp->valid_lft,\n\t\t\t      idev->cnf.temp_valid_lft + age);\n\tcfg.preferred_lft = cnf_temp_preferred_lft + age - idev->desync_factor;\n\tcfg.preferred_lft = min_t(__u32, ifp->prefered_lft, cfg.preferred_lft);\n\n\tcfg.plen = ifp->prefix_len;\n\ttmp_tstamp = ifp->tstamp;\n\tspin_unlock_bh(&ifp->lock);\n\n\twrite_unlock_bh(&idev->lock);\n\n\t/* A temporary address is created only if this calculated Preferred\n\t * Lifetime is greater than REGEN_ADVANCE time units.  In particular,\n\t * an implementation must not create a temporary address with a zero\n\t * Preferred Lifetime.\n\t * Use age calculation as in addrconf_verify to avoid unnecessary\n\t * temporary addresses being generated.\n\t */\n\tage = (now - tmp_tstamp + ADDRCONF_TIMER_FUZZ_MINUS) / HZ;\n\tif (cfg.preferred_lft <= regen_advance + age) {\n\t\tin6_ifa_put(ifp);\n\t\tin6_dev_put(idev);\n\t\tret = -1;\n\t\tgoto out;\n\t}\n\n\tcfg.ifa_flags = IFA_F_TEMPORARY;\n\t/* set in addrconf_prefix_rcv() */\n\tif (ifp->flags & IFA_F_OPTIMISTIC)\n\t\tcfg.ifa_flags |= IFA_F_OPTIMISTIC;\n\n\tcfg.pfx = &addr;\n\tcfg.scope = ipv6_addr_scope(cfg.pfx);\n\n\tift = ipv6_add_addr(idev, &cfg, block, NULL);\n\tif (IS_ERR(ift)) {\n\t\tin6_ifa_put(ifp);\n\t\tin6_dev_put(idev);\n\t\tpr_info(\"%s: retry temporary address regeneration\\n\", __func__);\n\t\twrite_lock_bh(&idev->lock);\n\t\tgoto retry;\n\t}\n\n\tspin_lock_bh(&ift->lock);\n\tift->ifpub = ifp;\n\tift->cstamp = now;\n\tift->tstamp = tmp_tstamp;\n\tspin_unlock_bh(&ift->lock);\n\n\taddrconf_dad_start(ift);\n\tin6_ifa_put(ift);\n\tin6_dev_put(idev);\nout:\n\treturn ret;\n}\n\n/*\n *\tChoose an appropriate source address (RFC3484)\n */\nenum {\n\tIPV6_SADDR_RULE_INIT = 0,\n\tIPV6_SADDR_RULE_LOCAL,\n\tIPV6_SADDR_RULE_SCOPE,\n\tIPV6_SADDR_RULE_PREFERRED,\n#ifdef CONFIG_IPV6_MIP6\n\tIPV6_SADDR_RULE_HOA,\n#endif\n\tIPV6_SADDR_RULE_OIF,\n\tIPV6_SADDR_RULE_LABEL,\n\tIPV6_SADDR_RULE_PRIVACY,\n\tIPV6_SADDR_RULE_ORCHID,\n\tIPV6_SADDR_RULE_PREFIX,\n#ifdef CONFIG_IPV6_OPTIMISTIC_DAD\n\tIPV6_SADDR_RULE_NOT_OPTIMISTIC,\n#endif\n\tIPV6_SADDR_RULE_MAX\n};\n\nstruct ipv6_saddr_score {\n\tint\t\t\trule;\n\tint\t\t\taddr_type;\n\tstruct inet6_ifaddr\t*ifa;\n\tDECLARE_BITMAP(scorebits, IPV6_SADDR_RULE_MAX);\n\tint\t\t\tscopedist;\n\tint\t\t\tmatchlen;\n};\n\nstruct ipv6_saddr_dst {\n\tconst struct in6_addr *addr;\n\tint ifindex;\n\tint scope;\n\tint label;\n\tunsigned int prefs;\n};\n\nstatic inline int ipv6_saddr_preferred(int type)\n{\n\tif (type & (IPV6_ADDR_MAPPED|IPV6_ADDR_COMPATv4|IPV6_ADDR_LOOPBACK))\n\t\treturn 1;\n\treturn 0;\n}\n\nstatic bool ipv6_use_optimistic_addr(struct net *net,\n\t\t\t\t     struct inet6_dev *idev)\n{\n#ifdef CONFIG_IPV6_OPTIMISTIC_DAD\n\tif (!idev)\n\t\treturn false;\n\tif (!net->ipv6.devconf_all->optimistic_dad && !idev->cnf.optimistic_dad)\n\t\treturn false;\n\tif (!net->ipv6.devconf_all->use_optimistic && !idev->cnf.use_optimistic)\n\t\treturn false;\n\n\treturn true;\n#else\n\treturn false;\n#endif\n}\n\nstatic bool ipv6_allow_optimistic_dad(struct net *net,\n\t\t\t\t      struct inet6_dev *idev)\n{\n#ifdef CONFIG_IPV6_OPTIMISTIC_DAD\n\tif (!idev)\n\t\treturn false;\n\tif (!net->ipv6.devconf_all->optimistic_dad && !idev->cnf.optimistic_dad)\n\t\treturn false;\n\n\treturn true;\n#else\n\treturn false;\n#endif\n}\n\nstatic int ipv6_get_saddr_eval(struct net *net,\n\t\t\t       struct ipv6_saddr_score *score,\n\t\t\t       struct ipv6_saddr_dst *dst,\n\t\t\t       int i)\n{\n\tint ret;\n\n\tif (i <= score->rule) {\n\t\tswitch (i) {\n\t\tcase IPV6_SADDR_RULE_SCOPE:\n\t\t\tret = score->scopedist;\n\t\t\tbreak;\n\t\tcase IPV6_SADDR_RULE_PREFIX:\n\t\t\tret = score->matchlen;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tret = !!test_bit(i, score->scorebits);\n\t\t}\n\t\tgoto out;\n\t}\n\n\tswitch (i) {\n\tcase IPV6_SADDR_RULE_INIT:\n\t\t/* Rule 0: remember if hiscore is not ready yet */\n\t\tret = !!score->ifa;\n\t\tbreak;\n\tcase IPV6_SADDR_RULE_LOCAL:\n\t\t/* Rule 1: Prefer same address */\n\t\tret = ipv6_addr_equal(&score->ifa->addr, dst->addr);\n\t\tbreak;\n\tcase IPV6_SADDR_RULE_SCOPE:\n\t\t/* Rule 2: Prefer appropriate scope\n\t\t *\n\t\t *      ret\n\t\t *       ^\n\t\t *    -1 |  d 15\n\t\t *    ---+--+-+---> scope\n\t\t *       |\n\t\t *       |             d is scope of the destination.\n\t\t *  B-d  |  \\\n\t\t *       |   \\      <- smaller scope is better if\n\t\t *  B-15 |    \\        if scope is enough for destination.\n\t\t *       |             ret = B - scope (-1 <= scope >= d <= 15).\n\t\t * d-C-1 | /\n\t\t *       |/         <- greater is better\n\t\t *   -C  /             if scope is not enough for destination.\n\t\t *      /|             ret = scope - C (-1 <= d < scope <= 15).\n\t\t *\n\t\t * d - C - 1 < B -15 (for all -1 <= d <= 15).\n\t\t * C > d + 14 - B >= 15 + 14 - B = 29 - B.\n\t\t * Assume B = 0 and we get C > 29.\n\t\t */\n\t\tret = __ipv6_addr_src_scope(score->addr_type);\n\t\tif (ret >= dst->scope)\n\t\t\tret = -ret;\n\t\telse\n\t\t\tret -= 128;\t/* 30 is enough */\n\t\tscore->scopedist = ret;\n\t\tbreak;\n\tcase IPV6_SADDR_RULE_PREFERRED:\n\t    {\n\t\t/* Rule 3: Avoid deprecated and optimistic addresses */\n\t\tu8 avoid = IFA_F_DEPRECATED;\n\n\t\tif (!ipv6_use_optimistic_addr(net, score->ifa->idev))\n\t\t\tavoid |= IFA_F_OPTIMISTIC;\n\t\tret = ipv6_saddr_preferred(score->addr_type) ||\n\t\t      !(score->ifa->flags & avoid);\n\t\tbreak;\n\t    }\n#ifdef CONFIG_IPV6_MIP6\n\tcase IPV6_SADDR_RULE_HOA:\n\t    {\n\t\t/* Rule 4: Prefer home address */\n\t\tint prefhome = !(dst->prefs & IPV6_PREFER_SRC_COA);\n\t\tret = !(score->ifa->flags & IFA_F_HOMEADDRESS) ^ prefhome;\n\t\tbreak;\n\t    }\n#endif\n\tcase IPV6_SADDR_RULE_OIF:\n\t\t/* Rule 5: Prefer outgoing interface */\n\t\tret = (!dst->ifindex ||\n\t\t       dst->ifindex == score->ifa->idev->dev->ifindex);\n\t\tbreak;\n\tcase IPV6_SADDR_RULE_LABEL:\n\t\t/* Rule 6: Prefer matching label */\n\t\tret = ipv6_addr_label(net,\n\t\t\t\t      &score->ifa->addr, score->addr_type,\n\t\t\t\t      score->ifa->idev->dev->ifindex) == dst->label;\n\t\tbreak;\n\tcase IPV6_SADDR_RULE_PRIVACY:\n\t    {\n\t\t/* Rule 7: Prefer public address\n\t\t * Note: prefer temporary address if use_tempaddr >= 2\n\t\t */\n\t\tint preftmp = dst->prefs & (IPV6_PREFER_SRC_PUBLIC|IPV6_PREFER_SRC_TMP) ?\n\t\t\t\t!!(dst->prefs & IPV6_PREFER_SRC_TMP) :\n\t\t\t\tscore->ifa->idev->cnf.use_tempaddr >= 2;\n\t\tret = (!(score->ifa->flags & IFA_F_TEMPORARY)) ^ preftmp;\n\t\tbreak;\n\t    }\n\tcase IPV6_SADDR_RULE_ORCHID:\n\t\t/* Rule 8-: Prefer ORCHID vs ORCHID or\n\t\t *\t    non-ORCHID vs non-ORCHID\n\t\t */\n\t\tret = !(ipv6_addr_orchid(&score->ifa->addr) ^\n\t\t\tipv6_addr_orchid(dst->addr));\n\t\tbreak;\n\tcase IPV6_SADDR_RULE_PREFIX:\n\t\t/* Rule 8: Use longest matching prefix */\n\t\tret = ipv6_addr_diff(&score->ifa->addr, dst->addr);\n\t\tif (ret > score->ifa->prefix_len)\n\t\t\tret = score->ifa->prefix_len;\n\t\tscore->matchlen = ret;\n\t\tbreak;\n#ifdef CONFIG_IPV6_OPTIMISTIC_DAD\n\tcase IPV6_SADDR_RULE_NOT_OPTIMISTIC:\n\t\t/* Optimistic addresses still have lower precedence than other\n\t\t * preferred addresses.\n\t\t */\n\t\tret = !(score->ifa->flags & IFA_F_OPTIMISTIC);\n\t\tbreak;\n#endif\n\tdefault:\n\t\tret = 0;\n\t}\n\n\tif (ret)\n\t\t__set_bit(i, score->scorebits);\n\tscore->rule = i;\nout:\n\treturn ret;\n}\n\nstatic int __ipv6_dev_get_saddr(struct net *net,\n\t\t\t\tstruct ipv6_saddr_dst *dst,\n\t\t\t\tstruct inet6_dev *idev,\n\t\t\t\tstruct ipv6_saddr_score *scores,\n\t\t\t\tint hiscore_idx)\n{\n\tstruct ipv6_saddr_score *score = &scores[1 - hiscore_idx], *hiscore = &scores[hiscore_idx];\n\n\tlist_for_each_entry_rcu(score->ifa, &idev->addr_list, if_list) {\n\t\tint i;\n\n\t\t/*\n\t\t * - Tentative Address (RFC2462 section 5.4)\n\t\t *  - A tentative address is not considered\n\t\t *    \"assigned to an interface\" in the traditional\n\t\t *    sense, unless it is also flagged as optimistic.\n\t\t * - Candidate Source Address (section 4)\n\t\t *  - In any case, anycast addresses, multicast\n\t\t *    addresses, and the unspecified address MUST\n\t\t *    NOT be included in a candidate set.\n\t\t */\n\t\tif ((score->ifa->flags & IFA_F_TENTATIVE) &&\n\t\t    (!(score->ifa->flags & IFA_F_OPTIMISTIC)))\n\t\t\tcontinue;\n\n\t\tscore->addr_type = __ipv6_addr_type(&score->ifa->addr);\n\n\t\tif (unlikely(score->addr_type == IPV6_ADDR_ANY ||\n\t\t\t     score->addr_type & IPV6_ADDR_MULTICAST)) {\n\t\t\tnet_dbg_ratelimited(\"ADDRCONF: unspecified / multicast address assigned as unicast address on %s\",\n\t\t\t\t\t    idev->dev->name);\n\t\t\tcontinue;\n\t\t}\n\n\t\tscore->rule = -1;\n\t\tbitmap_zero(score->scorebits, IPV6_SADDR_RULE_MAX);\n\n\t\tfor (i = 0; i < IPV6_SADDR_RULE_MAX; i++) {\n\t\t\tint minihiscore, miniscore;\n\n\t\t\tminihiscore = ipv6_get_saddr_eval(net, hiscore, dst, i);\n\t\t\tminiscore = ipv6_get_saddr_eval(net, score, dst, i);\n\n\t\t\tif (minihiscore > miniscore) {\n\t\t\t\tif (i == IPV6_SADDR_RULE_SCOPE &&\n\t\t\t\t    score->scopedist > 0) {\n\t\t\t\t\t/*\n\t\t\t\t\t * special case:\n\t\t\t\t\t * each remaining entry\n\t\t\t\t\t * has too small (not enough)\n\t\t\t\t\t * scope, because ifa entries\n\t\t\t\t\t * are sorted by their scope\n\t\t\t\t\t * values.\n\t\t\t\t\t */\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t} else if (minihiscore < miniscore) {\n\t\t\t\tswap(hiscore, score);\n\t\t\t\thiscore_idx = 1 - hiscore_idx;\n\n\t\t\t\t/* restore our iterator */\n\t\t\t\tscore->ifa = hiscore->ifa;\n\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\nout:\n\treturn hiscore_idx;\n}\n\nstatic int ipv6_get_saddr_master(struct net *net,\n\t\t\t\t const struct net_device *dst_dev,\n\t\t\t\t const struct net_device *master,\n\t\t\t\t struct ipv6_saddr_dst *dst,\n\t\t\t\t struct ipv6_saddr_score *scores,\n\t\t\t\t int hiscore_idx)\n{\n\tstruct inet6_dev *idev;\n\n\tidev = __in6_dev_get(dst_dev);\n\tif (idev)\n\t\thiscore_idx = __ipv6_dev_get_saddr(net, dst, idev,\n\t\t\t\t\t\t   scores, hiscore_idx);\n\n\tidev = __in6_dev_get(master);\n\tif (idev)\n\t\thiscore_idx = __ipv6_dev_get_saddr(net, dst, idev,\n\t\t\t\t\t\t   scores, hiscore_idx);\n\n\treturn hiscore_idx;\n}\n\nint ipv6_dev_get_saddr(struct net *net, const struct net_device *dst_dev,\n\t\t       const struct in6_addr *daddr, unsigned int prefs,\n\t\t       struct in6_addr *saddr)\n{\n\tstruct ipv6_saddr_score scores[2], *hiscore;\n\tstruct ipv6_saddr_dst dst;\n\tstruct inet6_dev *idev;\n\tstruct net_device *dev;\n\tint dst_type;\n\tbool use_oif_addr = false;\n\tint hiscore_idx = 0;\n\tint ret = 0;\n\n\tdst_type = __ipv6_addr_type(daddr);\n\tdst.addr = daddr;\n\tdst.ifindex = dst_dev ? dst_dev->ifindex : 0;\n\tdst.scope = __ipv6_addr_src_scope(dst_type);\n\tdst.label = ipv6_addr_label(net, daddr, dst_type, dst.ifindex);\n\tdst.prefs = prefs;\n\n\tscores[hiscore_idx].rule = -1;\n\tscores[hiscore_idx].ifa = NULL;\n\n\trcu_read_lock();\n\n\t/* Candidate Source Address (section 4)\n\t *  - multicast and link-local destination address,\n\t *    the set of candidate source address MUST only\n\t *    include addresses assigned to interfaces\n\t *    belonging to the same link as the outgoing\n\t *    interface.\n\t * (- For site-local destination addresses, the\n\t *    set of candidate source addresses MUST only\n\t *    include addresses assigned to interfaces\n\t *    belonging to the same site as the outgoing\n\t *    interface.)\n\t *  - \"It is RECOMMENDED that the candidate source addresses\n\t *    be the set of unicast addresses assigned to the\n\t *    interface that will be used to send to the destination\n\t *    (the 'outgoing' interface).\" (RFC 6724)\n\t */\n\tif (dst_dev) {\n\t\tidev = __in6_dev_get(dst_dev);\n\t\tif ((dst_type & IPV6_ADDR_MULTICAST) ||\n\t\t    dst.scope <= IPV6_ADDR_SCOPE_LINKLOCAL ||\n\t\t    (idev && idev->cnf.use_oif_addrs_only)) {\n\t\t\tuse_oif_addr = true;\n\t\t}\n\t}\n\n\tif (use_oif_addr) {\n\t\tif (idev)\n\t\t\thiscore_idx = __ipv6_dev_get_saddr(net, &dst, idev, scores, hiscore_idx);\n\t} else {\n\t\tconst struct net_device *master;\n\t\tint master_idx = 0;\n\n\t\t/* if dst_dev exists and is enslaved to an L3 device, then\n\t\t * prefer addresses from dst_dev and then the master over\n\t\t * any other enslaved devices in the L3 domain.\n\t\t */\n\t\tmaster = l3mdev_master_dev_rcu(dst_dev);\n\t\tif (master) {\n\t\t\tmaster_idx = master->ifindex;\n\n\t\t\thiscore_idx = ipv6_get_saddr_master(net, dst_dev,\n\t\t\t\t\t\t\t    master, &dst,\n\t\t\t\t\t\t\t    scores, hiscore_idx);\n\n\t\t\tif (scores[hiscore_idx].ifa)\n\t\t\t\tgoto out;\n\t\t}\n\n\t\tfor_each_netdev_rcu(net, dev) {\n\t\t\t/* only consider addresses on devices in the\n\t\t\t * same L3 domain\n\t\t\t */\n\t\t\tif (l3mdev_master_ifindex_rcu(dev) != master_idx)\n\t\t\t\tcontinue;\n\t\t\tidev = __in6_dev_get(dev);\n\t\t\tif (!idev)\n\t\t\t\tcontinue;\n\t\t\thiscore_idx = __ipv6_dev_get_saddr(net, &dst, idev, scores, hiscore_idx);\n\t\t}\n\t}\n\nout:\n\thiscore = &scores[hiscore_idx];\n\tif (!hiscore->ifa)\n\t\tret = -EADDRNOTAVAIL;\n\telse\n\t\t*saddr = hiscore->ifa->addr;\n\n\trcu_read_unlock();\n\treturn ret;\n}\nEXPORT_SYMBOL(ipv6_dev_get_saddr);\n\nint __ipv6_get_lladdr(struct inet6_dev *idev, struct in6_addr *addr,\n\t\t      u32 banned_flags)\n{\n\tstruct inet6_ifaddr *ifp;\n\tint err = -EADDRNOTAVAIL;\n\n\tlist_for_each_entry_reverse(ifp, &idev->addr_list, if_list) {\n\t\tif (ifp->scope > IFA_LINK)\n\t\t\tbreak;\n\t\tif (ifp->scope == IFA_LINK &&\n\t\t    !(ifp->flags & banned_flags)) {\n\t\t\t*addr = ifp->addr;\n\t\t\terr = 0;\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn err;\n}\n\nint ipv6_get_lladdr(struct net_device *dev, struct in6_addr *addr,\n\t\t    u32 banned_flags)\n{\n\tstruct inet6_dev *idev;\n\tint err = -EADDRNOTAVAIL;\n\n\trcu_read_lock();\n\tidev = __in6_dev_get(dev);\n\tif (idev) {\n\t\tread_lock_bh(&idev->lock);\n\t\terr = __ipv6_get_lladdr(idev, addr, banned_flags);\n\t\tread_unlock_bh(&idev->lock);\n\t}\n\trcu_read_unlock();\n\treturn err;\n}\n\nstatic int ipv6_count_addresses(const struct inet6_dev *idev)\n{\n\tconst struct inet6_ifaddr *ifp;\n\tint cnt = 0;\n\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(ifp, &idev->addr_list, if_list)\n\t\tcnt++;\n\trcu_read_unlock();\n\treturn cnt;\n}\n\nint ipv6_chk_addr(struct net *net, const struct in6_addr *addr,\n\t\t  const struct net_device *dev, int strict)\n{\n\treturn ipv6_chk_addr_and_flags(net, addr, dev, !dev,\n\t\t\t\t       strict, IFA_F_TENTATIVE);\n}\nEXPORT_SYMBOL(ipv6_chk_addr);\n\n/* device argument is used to find the L3 domain of interest. If\n * skip_dev_check is set, then the ifp device is not checked against\n * the passed in dev argument. So the 2 cases for addresses checks are:\n *   1. does the address exist in the L3 domain that dev is part of\n *      (skip_dev_check = true), or\n *\n *   2. does the address exist on the specific device\n *      (skip_dev_check = false)\n */\nstatic struct net_device *\n__ipv6_chk_addr_and_flags(struct net *net, const struct in6_addr *addr,\n\t\t\t  const struct net_device *dev, bool skip_dev_check,\n\t\t\t  int strict, u32 banned_flags)\n{\n\tunsigned int hash = inet6_addr_hash(net, addr);\n\tstruct net_device *l3mdev, *ndev;\n\tstruct inet6_ifaddr *ifp;\n\tu32 ifp_flags;\n\n\trcu_read_lock();\n\n\tl3mdev = l3mdev_master_dev_rcu(dev);\n\tif (skip_dev_check)\n\t\tdev = NULL;\n\n\thlist_for_each_entry_rcu(ifp, &inet6_addr_lst[hash], addr_lst) {\n\t\tndev = ifp->idev->dev;\n\t\tif (!net_eq(dev_net(ndev), net))\n\t\t\tcontinue;\n\n\t\tif (l3mdev_master_dev_rcu(ndev) != l3mdev)\n\t\t\tcontinue;\n\n\t\t/* Decouple optimistic from tentative for evaluation here.\n\t\t * Ban optimistic addresses explicitly, when required.\n\t\t */\n\t\tifp_flags = (ifp->flags&IFA_F_OPTIMISTIC)\n\t\t\t    ? (ifp->flags&~IFA_F_TENTATIVE)\n\t\t\t    : ifp->flags;\n\t\tif (ipv6_addr_equal(&ifp->addr, addr) &&\n\t\t    !(ifp_flags&banned_flags) &&\n\t\t    (!dev || ndev == dev ||\n\t\t     !(ifp->scope&(IFA_LINK|IFA_HOST) || strict))) {\n\t\t\trcu_read_unlock();\n\t\t\treturn ndev;\n\t\t}\n\t}\n\n\trcu_read_unlock();\n\treturn NULL;\n}\n\nint ipv6_chk_addr_and_flags(struct net *net, const struct in6_addr *addr,\n\t\t\t    const struct net_device *dev, bool skip_dev_check,\n\t\t\t    int strict, u32 banned_flags)\n{\n\treturn __ipv6_chk_addr_and_flags(net, addr, dev, skip_dev_check,\n\t\t\t\t\t strict, banned_flags) ? 1 : 0;\n}\nEXPORT_SYMBOL(ipv6_chk_addr_and_flags);\n\n\n/* Compares an address/prefix_len with addresses on device @dev.\n * If one is found it returns true.\n */\nbool ipv6_chk_custom_prefix(const struct in6_addr *addr,\n\tconst unsigned int prefix_len, struct net_device *dev)\n{\n\tconst struct inet6_ifaddr *ifa;\n\tconst struct inet6_dev *idev;\n\tbool ret = false;\n\n\trcu_read_lock();\n\tidev = __in6_dev_get(dev);\n\tif (idev) {\n\t\tlist_for_each_entry_rcu(ifa, &idev->addr_list, if_list) {\n\t\t\tret = ipv6_prefix_equal(addr, &ifa->addr, prefix_len);\n\t\t\tif (ret)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\treturn ret;\n}\nEXPORT_SYMBOL(ipv6_chk_custom_prefix);\n\nint ipv6_chk_prefix(const struct in6_addr *addr, struct net_device *dev)\n{\n\tconst struct inet6_ifaddr *ifa;\n\tconst struct inet6_dev *idev;\n\tint\tonlink;\n\n\tonlink = 0;\n\trcu_read_lock();\n\tidev = __in6_dev_get(dev);\n\tif (idev) {\n\t\tlist_for_each_entry_rcu(ifa, &idev->addr_list, if_list) {\n\t\t\tonlink = ipv6_prefix_equal(addr, &ifa->addr,\n\t\t\t\t\t\t   ifa->prefix_len);\n\t\t\tif (onlink)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\trcu_read_unlock();\n\treturn onlink;\n}\nEXPORT_SYMBOL(ipv6_chk_prefix);\n\n/**\n * ipv6_dev_find - find the first device with a given source address.\n * @net: the net namespace\n * @addr: the source address\n * @dev: used to find the L3 domain of interest\n *\n * The caller should be protected by RCU, or RTNL.\n */\nstruct net_device *ipv6_dev_find(struct net *net, const struct in6_addr *addr,\n\t\t\t\t struct net_device *dev)\n{\n\treturn __ipv6_chk_addr_and_flags(net, addr, dev, !dev, 1,\n\t\t\t\t\t IFA_F_TENTATIVE);\n}\nEXPORT_SYMBOL(ipv6_dev_find);\n\nstruct inet6_ifaddr *ipv6_get_ifaddr(struct net *net, const struct in6_addr *addr,\n\t\t\t\t     struct net_device *dev, int strict)\n{\n\tunsigned int hash = inet6_addr_hash(net, addr);\n\tstruct inet6_ifaddr *ifp, *result = NULL;\n\n\trcu_read_lock();\n\thlist_for_each_entry_rcu(ifp, &inet6_addr_lst[hash], addr_lst) {\n\t\tif (!net_eq(dev_net(ifp->idev->dev), net))\n\t\t\tcontinue;\n\t\tif (ipv6_addr_equal(&ifp->addr, addr)) {\n\t\t\tif (!dev || ifp->idev->dev == dev ||\n\t\t\t    !(ifp->scope&(IFA_LINK|IFA_HOST) || strict)) {\n\t\t\t\tresult = ifp;\n\t\t\t\tin6_ifa_hold(ifp);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\treturn result;\n}\n\n/* Gets referenced address, destroys ifaddr */\n\nstatic void addrconf_dad_stop(struct inet6_ifaddr *ifp, int dad_failed)\n{\n\tif (dad_failed)\n\t\tifp->flags |= IFA_F_DADFAILED;\n\n\tif (ifp->flags&IFA_F_TEMPORARY) {\n\t\tstruct inet6_ifaddr *ifpub;\n\t\tspin_lock_bh(&ifp->lock);\n\t\tifpub = ifp->ifpub;\n\t\tif (ifpub) {\n\t\t\tin6_ifa_hold(ifpub);\n\t\t\tspin_unlock_bh(&ifp->lock);\n\t\t\tipv6_create_tempaddr(ifpub, true);\n\t\t\tin6_ifa_put(ifpub);\n\t\t} else {\n\t\t\tspin_unlock_bh(&ifp->lock);\n\t\t}\n\t\tipv6_del_addr(ifp);\n\t} else if (ifp->flags&IFA_F_PERMANENT || !dad_failed) {\n\t\tspin_lock_bh(&ifp->lock);\n\t\taddrconf_del_dad_work(ifp);\n\t\tifp->flags |= IFA_F_TENTATIVE;\n\t\tif (dad_failed)\n\t\t\tifp->flags &= ~IFA_F_OPTIMISTIC;\n\t\tspin_unlock_bh(&ifp->lock);\n\t\tif (dad_failed)\n\t\t\tipv6_ifa_notify(0, ifp);\n\t\tin6_ifa_put(ifp);\n\t} else {\n\t\tipv6_del_addr(ifp);\n\t}\n}\n\nstatic int addrconf_dad_end(struct inet6_ifaddr *ifp)\n{\n\tint err = -ENOENT;\n\n\tspin_lock_bh(&ifp->lock);\n\tif (ifp->state == INET6_IFADDR_STATE_DAD) {\n\t\tifp->state = INET6_IFADDR_STATE_POSTDAD;\n\t\terr = 0;\n\t}\n\tspin_unlock_bh(&ifp->lock);\n\n\treturn err;\n}\n\nvoid addrconf_dad_failure(struct sk_buff *skb, struct inet6_ifaddr *ifp)\n{\n\tstruct inet6_dev *idev = ifp->idev;\n\tstruct net *net = dev_net(ifp->idev->dev);\n\n\tif (addrconf_dad_end(ifp)) {\n\t\tin6_ifa_put(ifp);\n\t\treturn;\n\t}\n\n\tnet_info_ratelimited(\"%s: IPv6 duplicate address %pI6c used by %pM detected!\\n\",\n\t\t\t     ifp->idev->dev->name, &ifp->addr, eth_hdr(skb)->h_source);\n\n\tspin_lock_bh(&ifp->lock);\n\n\tif (ifp->flags & IFA_F_STABLE_PRIVACY) {\n\t\tstruct in6_addr new_addr;\n\t\tstruct inet6_ifaddr *ifp2;\n\t\tint retries = ifp->stable_privacy_retry + 1;\n\t\tstruct ifa6_config cfg = {\n\t\t\t.pfx = &new_addr,\n\t\t\t.plen = ifp->prefix_len,\n\t\t\t.ifa_flags = ifp->flags,\n\t\t\t.valid_lft = ifp->valid_lft,\n\t\t\t.preferred_lft = ifp->prefered_lft,\n\t\t\t.scope = ifp->scope,\n\t\t};\n\n\t\tif (retries > net->ipv6.sysctl.idgen_retries) {\n\t\t\tnet_info_ratelimited(\"%s: privacy stable address generation failed because of DAD conflicts!\\n\",\n\t\t\t\t\t     ifp->idev->dev->name);\n\t\t\tgoto errdad;\n\t\t}\n\n\t\tnew_addr = ifp->addr;\n\t\tif (ipv6_generate_stable_address(&new_addr, retries,\n\t\t\t\t\t\t idev))\n\t\t\tgoto errdad;\n\n\t\tspin_unlock_bh(&ifp->lock);\n\n\t\tif (idev->cnf.max_addresses &&\n\t\t    ipv6_count_addresses(idev) >=\n\t\t    idev->cnf.max_addresses)\n\t\t\tgoto lock_errdad;\n\n\t\tnet_info_ratelimited(\"%s: generating new stable privacy address because of DAD conflict\\n\",\n\t\t\t\t     ifp->idev->dev->name);\n\n\t\tifp2 = ipv6_add_addr(idev, &cfg, false, NULL);\n\t\tif (IS_ERR(ifp2))\n\t\t\tgoto lock_errdad;\n\n\t\tspin_lock_bh(&ifp2->lock);\n\t\tifp2->stable_privacy_retry = retries;\n\t\tifp2->state = INET6_IFADDR_STATE_PREDAD;\n\t\tspin_unlock_bh(&ifp2->lock);\n\n\t\taddrconf_mod_dad_work(ifp2, net->ipv6.sysctl.idgen_delay);\n\t\tin6_ifa_put(ifp2);\nlock_errdad:\n\t\tspin_lock_bh(&ifp->lock);\n\t}\n\nerrdad:\n\t/* transition from _POSTDAD to _ERRDAD */\n\tifp->state = INET6_IFADDR_STATE_ERRDAD;\n\tspin_unlock_bh(&ifp->lock);\n\n\taddrconf_mod_dad_work(ifp, 0);\n\tin6_ifa_put(ifp);\n}\n\n/* Join to solicited addr multicast group.\n * caller must hold RTNL */\nvoid addrconf_join_solict(struct net_device *dev, const struct in6_addr *addr)\n{\n\tstruct in6_addr maddr;\n\n\tif (dev->flags&(IFF_LOOPBACK|IFF_NOARP))\n\t\treturn;\n\n\taddrconf_addr_solict_mult(addr, &maddr);\n\tipv6_dev_mc_inc(dev, &maddr);\n}\n\n/* caller must hold RTNL */\nvoid addrconf_leave_solict(struct inet6_dev *idev, const struct in6_addr *addr)\n{\n\tstruct in6_addr maddr;\n\n\tif (idev->dev->flags&(IFF_LOOPBACK|IFF_NOARP))\n\t\treturn;\n\n\taddrconf_addr_solict_mult(addr, &maddr);\n\t__ipv6_dev_mc_dec(idev, &maddr);\n}\n\n/* caller must hold RTNL */\nstatic void addrconf_join_anycast(struct inet6_ifaddr *ifp)\n{\n\tstruct in6_addr addr;\n\n\tif (ifp->prefix_len >= 127) /* RFC 6164 */\n\t\treturn;\n\tipv6_addr_prefix(&addr, &ifp->addr, ifp->prefix_len);\n\tif (ipv6_addr_any(&addr))\n\t\treturn;\n\t__ipv6_dev_ac_inc(ifp->idev, &addr);\n}\n\n/* caller must hold RTNL */\nstatic void addrconf_leave_anycast(struct inet6_ifaddr *ifp)\n{\n\tstruct in6_addr addr;\n\n\tif (ifp->prefix_len >= 127) /* RFC 6164 */\n\t\treturn;\n\tipv6_addr_prefix(&addr, &ifp->addr, ifp->prefix_len);\n\tif (ipv6_addr_any(&addr))\n\t\treturn;\n\t__ipv6_dev_ac_dec(ifp->idev, &addr);\n}\n\nstatic int addrconf_ifid_6lowpan(u8 *eui, struct net_device *dev)\n{\n\tswitch (dev->addr_len) {\n\tcase ETH_ALEN:\n\t\tmemcpy(eui, dev->dev_addr, 3);\n\t\teui[3] = 0xFF;\n\t\teui[4] = 0xFE;\n\t\tmemcpy(eui + 5, dev->dev_addr + 3, 3);\n\t\tbreak;\n\tcase EUI64_ADDR_LEN:\n\t\tmemcpy(eui, dev->dev_addr, EUI64_ADDR_LEN);\n\t\teui[0] ^= 2;\n\t\tbreak;\n\tdefault:\n\t\treturn -1;\n\t}\n\n\treturn 0;\n}\n\nstatic int addrconf_ifid_ieee1394(u8 *eui, struct net_device *dev)\n{\n\tunion fwnet_hwaddr *ha;\n\n\tif (dev->addr_len != FWNET_ALEN)\n\t\treturn -1;\n\n\tha = (union fwnet_hwaddr *)dev->dev_addr;\n\n\tmemcpy(eui, &ha->uc.uniq_id, sizeof(ha->uc.uniq_id));\n\teui[0] ^= 2;\n\treturn 0;\n}\n\nstatic int addrconf_ifid_arcnet(u8 *eui, struct net_device *dev)\n{\n\t/* XXX: inherit EUI-64 from other interface -- yoshfuji */\n\tif (dev->addr_len != ARCNET_ALEN)\n\t\treturn -1;\n\tmemset(eui, 0, 7);\n\teui[7] = *(u8 *)dev->dev_addr;\n\treturn 0;\n}\n\nstatic int addrconf_ifid_infiniband(u8 *eui, struct net_device *dev)\n{\n\tif (dev->addr_len != INFINIBAND_ALEN)\n\t\treturn -1;\n\tmemcpy(eui, dev->dev_addr + 12, 8);\n\teui[0] |= 2;\n\treturn 0;\n}\n\nstatic int __ipv6_isatap_ifid(u8 *eui, __be32 addr)\n{\n\tif (addr == 0)\n\t\treturn -1;\n\teui[0] = (ipv4_is_zeronet(addr) || ipv4_is_private_10(addr) ||\n\t\t  ipv4_is_loopback(addr) || ipv4_is_linklocal_169(addr) ||\n\t\t  ipv4_is_private_172(addr) || ipv4_is_test_192(addr) ||\n\t\t  ipv4_is_anycast_6to4(addr) || ipv4_is_private_192(addr) ||\n\t\t  ipv4_is_test_198(addr) || ipv4_is_multicast(addr) ||\n\t\t  ipv4_is_lbcast(addr)) ? 0x00 : 0x02;\n\teui[1] = 0;\n\teui[2] = 0x5E;\n\teui[3] = 0xFE;\n\tmemcpy(eui + 4, &addr, 4);\n\treturn 0;\n}\n\nstatic int addrconf_ifid_sit(u8 *eui, struct net_device *dev)\n{\n\tif (dev->priv_flags & IFF_ISATAP)\n\t\treturn __ipv6_isatap_ifid(eui, *(__be32 *)dev->dev_addr);\n\treturn -1;\n}\n\nstatic int addrconf_ifid_gre(u8 *eui, struct net_device *dev)\n{\n\treturn __ipv6_isatap_ifid(eui, *(__be32 *)dev->dev_addr);\n}\n\nstatic int addrconf_ifid_ip6tnl(u8 *eui, struct net_device *dev)\n{\n\tmemcpy(eui, dev->perm_addr, 3);\n\tmemcpy(eui + 5, dev->perm_addr + 3, 3);\n\teui[3] = 0xFF;\n\teui[4] = 0xFE;\n\teui[0] ^= 2;\n\treturn 0;\n}\n\nstatic int ipv6_generate_eui64(u8 *eui, struct net_device *dev)\n{\n\tswitch (dev->type) {\n\tcase ARPHRD_ETHER:\n\tcase ARPHRD_FDDI:\n\t\treturn addrconf_ifid_eui48(eui, dev);\n\tcase ARPHRD_ARCNET:\n\t\treturn addrconf_ifid_arcnet(eui, dev);\n\tcase ARPHRD_INFINIBAND:\n\t\treturn addrconf_ifid_infiniband(eui, dev);\n\tcase ARPHRD_SIT:\n\t\treturn addrconf_ifid_sit(eui, dev);\n\tcase ARPHRD_IPGRE:\n\tcase ARPHRD_TUNNEL:\n\t\treturn addrconf_ifid_gre(eui, dev);\n\tcase ARPHRD_6LOWPAN:\n\t\treturn addrconf_ifid_6lowpan(eui, dev);\n\tcase ARPHRD_IEEE1394:\n\t\treturn addrconf_ifid_ieee1394(eui, dev);\n\tcase ARPHRD_TUNNEL6:\n\tcase ARPHRD_IP6GRE:\n\tcase ARPHRD_RAWIP:\n\t\treturn addrconf_ifid_ip6tnl(eui, dev);\n\t}\n\treturn -1;\n}\n\nstatic int ipv6_inherit_eui64(u8 *eui, struct inet6_dev *idev)\n{\n\tint err = -1;\n\tstruct inet6_ifaddr *ifp;\n\n\tread_lock_bh(&idev->lock);\n\tlist_for_each_entry_reverse(ifp, &idev->addr_list, if_list) {\n\t\tif (ifp->scope > IFA_LINK)\n\t\t\tbreak;\n\t\tif (ifp->scope == IFA_LINK && !(ifp->flags&IFA_F_TENTATIVE)) {\n\t\t\tmemcpy(eui, ifp->addr.s6_addr+8, 8);\n\t\t\terr = 0;\n\t\t\tbreak;\n\t\t}\n\t}\n\tread_unlock_bh(&idev->lock);\n\treturn err;\n}\n\n/* Generation of a randomized Interface Identifier\n * draft-ietf-6man-rfc4941bis, Section 3.3.1\n */\n\nstatic void ipv6_gen_rnd_iid(struct in6_addr *addr)\n{\nregen:\n\tget_random_bytes(&addr->s6_addr[8], 8);\n\n\t/* <draft-ietf-6man-rfc4941bis-08.txt>, Section 3.3.1:\n\t * check if generated address is not inappropriate:\n\t *\n\t * - Reserved IPv6 Interface Identifers\n\t * - XXX: already assigned to an address on the device\n\t */\n\n\t/* Subnet-router anycast: 0000:0000:0000:0000 */\n\tif (!(addr->s6_addr32[2] | addr->s6_addr32[3]))\n\t\tgoto regen;\n\n\t/* IANA Ethernet block: 0200:5EFF:FE00:0000-0200:5EFF:FE00:5212\n\t * Proxy Mobile IPv6:   0200:5EFF:FE00:5213\n\t * IANA Ethernet block: 0200:5EFF:FE00:5214-0200:5EFF:FEFF:FFFF\n\t */\n\tif (ntohl(addr->s6_addr32[2]) == 0x02005eff &&\n\t    (ntohl(addr->s6_addr32[3]) & 0Xff000000) == 0xfe000000)\n\t\tgoto regen;\n\n\t/* Reserved subnet anycast addresses */\n\tif (ntohl(addr->s6_addr32[2]) == 0xfdffffff &&\n\t    ntohl(addr->s6_addr32[3]) >= 0Xffffff80)\n\t\tgoto regen;\n}\n\n/*\n *\tAdd prefix route.\n */\n\nstatic void\naddrconf_prefix_route(struct in6_addr *pfx, int plen, u32 metric,\n\t\t      struct net_device *dev, unsigned long expires,\n\t\t      u32 flags, gfp_t gfp_flags)\n{\n\tstruct fib6_config cfg = {\n\t\t.fc_table = l3mdev_fib_table(dev) ? : RT6_TABLE_PREFIX,\n\t\t.fc_metric = metric ? : IP6_RT_PRIO_ADDRCONF,\n\t\t.fc_ifindex = dev->ifindex,\n\t\t.fc_expires = expires,\n\t\t.fc_dst_len = plen,\n\t\t.fc_flags = RTF_UP | flags,\n\t\t.fc_nlinfo.nl_net = dev_net(dev),\n\t\t.fc_protocol = RTPROT_KERNEL,\n\t\t.fc_type = RTN_UNICAST,\n\t};\n\n\tcfg.fc_dst = *pfx;\n\n\t/* Prevent useless cloning on PtP SIT.\n\t   This thing is done here expecting that the whole\n\t   class of non-broadcast devices need not cloning.\n\t */\n#if IS_ENABLED(CONFIG_IPV6_SIT)\n\tif (dev->type == ARPHRD_SIT && (dev->flags & IFF_POINTOPOINT))\n\t\tcfg.fc_flags |= RTF_NONEXTHOP;\n#endif\n\n\tip6_route_add(&cfg, gfp_flags, NULL);\n}\n\n\nstatic struct fib6_info *addrconf_get_prefix_route(const struct in6_addr *pfx,\n\t\t\t\t\t\t  int plen,\n\t\t\t\t\t\t  const struct net_device *dev,\n\t\t\t\t\t\t  u32 flags, u32 noflags,\n\t\t\t\t\t\t  bool no_gw)\n{\n\tstruct fib6_node *fn;\n\tstruct fib6_info *rt = NULL;\n\tstruct fib6_table *table;\n\tu32 tb_id = l3mdev_fib_table(dev) ? : RT6_TABLE_PREFIX;\n\n\ttable = fib6_get_table(dev_net(dev), tb_id);\n\tif (!table)\n\t\treturn NULL;\n\n\trcu_read_lock();\n\tfn = fib6_locate(&table->tb6_root, pfx, plen, NULL, 0, true);\n\tif (!fn)\n\t\tgoto out;\n\n\tfor_each_fib6_node_rt_rcu(fn) {\n\t\t/* prefix routes only use builtin fib6_nh */\n\t\tif (rt->nh)\n\t\t\tcontinue;\n\n\t\tif (rt->fib6_nh->fib_nh_dev->ifindex != dev->ifindex)\n\t\t\tcontinue;\n\t\tif (no_gw && rt->fib6_nh->fib_nh_gw_family)\n\t\t\tcontinue;\n\t\tif ((rt->fib6_flags & flags) != flags)\n\t\t\tcontinue;\n\t\tif ((rt->fib6_flags & noflags) != 0)\n\t\t\tcontinue;\n\t\tif (!fib6_info_hold_safe(rt))\n\t\t\tcontinue;\n\t\tbreak;\n\t}\nout:\n\trcu_read_unlock();\n\treturn rt;\n}\n\n\n/* Create \"default\" multicast route to the interface */\n\nstatic void addrconf_add_mroute(struct net_device *dev)\n{\n\tstruct fib6_config cfg = {\n\t\t.fc_table = l3mdev_fib_table(dev) ? : RT6_TABLE_LOCAL,\n\t\t.fc_metric = IP6_RT_PRIO_ADDRCONF,\n\t\t.fc_ifindex = dev->ifindex,\n\t\t.fc_dst_len = 8,\n\t\t.fc_flags = RTF_UP,\n\t\t.fc_type = RTN_MULTICAST,\n\t\t.fc_nlinfo.nl_net = dev_net(dev),\n\t\t.fc_protocol = RTPROT_KERNEL,\n\t};\n\n\tipv6_addr_set(&cfg.fc_dst, htonl(0xFF000000), 0, 0, 0);\n\n\tip6_route_add(&cfg, GFP_KERNEL, NULL);\n}\n\nstatic struct inet6_dev *addrconf_add_dev(struct net_device *dev)\n{\n\tstruct inet6_dev *idev;\n\n\tASSERT_RTNL();\n\n\tidev = ipv6_find_idev(dev);\n\tif (IS_ERR(idev))\n\t\treturn idev;\n\n\tif (idev->cnf.disable_ipv6)\n\t\treturn ERR_PTR(-EACCES);\n\n\t/* Add default multicast route */\n\tif (!(dev->flags & IFF_LOOPBACK) && !netif_is_l3_master(dev))\n\t\taddrconf_add_mroute(dev);\n\n\treturn idev;\n}\n\nstatic void manage_tempaddrs(struct inet6_dev *idev,\n\t\t\t     struct inet6_ifaddr *ifp,\n\t\t\t     __u32 valid_lft, __u32 prefered_lft,\n\t\t\t     bool create, unsigned long now)\n{\n\tu32 flags;\n\tstruct inet6_ifaddr *ift;\n\n\tread_lock_bh(&idev->lock);\n\t/* update all temporary addresses in the list */\n\tlist_for_each_entry(ift, &idev->tempaddr_list, tmp_list) {\n\t\tint age, max_valid, max_prefered;\n\n\t\tif (ifp != ift->ifpub)\n\t\t\tcontinue;\n\n\t\t/* RFC 4941 section 3.3:\n\t\t * If a received option will extend the lifetime of a public\n\t\t * address, the lifetimes of temporary addresses should\n\t\t * be extended, subject to the overall constraint that no\n\t\t * temporary addresses should ever remain \"valid\" or \"preferred\"\n\t\t * for a time longer than (TEMP_VALID_LIFETIME) or\n\t\t * (TEMP_PREFERRED_LIFETIME - DESYNC_FACTOR), respectively.\n\t\t */\n\t\tage = (now - ift->cstamp) / HZ;\n\t\tmax_valid = idev->cnf.temp_valid_lft - age;\n\t\tif (max_valid < 0)\n\t\t\tmax_valid = 0;\n\n\t\tmax_prefered = idev->cnf.temp_prefered_lft -\n\t\t\t       idev->desync_factor - age;\n\t\tif (max_prefered < 0)\n\t\t\tmax_prefered = 0;\n\n\t\tif (valid_lft > max_valid)\n\t\t\tvalid_lft = max_valid;\n\n\t\tif (prefered_lft > max_prefered)\n\t\t\tprefered_lft = max_prefered;\n\n\t\tspin_lock(&ift->lock);\n\t\tflags = ift->flags;\n\t\tift->valid_lft = valid_lft;\n\t\tift->prefered_lft = prefered_lft;\n\t\tift->tstamp = now;\n\t\tif (prefered_lft > 0)\n\t\t\tift->flags &= ~IFA_F_DEPRECATED;\n\n\t\tspin_unlock(&ift->lock);\n\t\tif (!(flags&IFA_F_TENTATIVE))\n\t\t\tipv6_ifa_notify(0, ift);\n\t}\n\n\tif ((create || list_empty(&idev->tempaddr_list)) &&\n\t    idev->cnf.use_tempaddr > 0) {\n\t\t/* When a new public address is created as described\n\t\t * in [ADDRCONF], also create a new temporary address.\n\t\t * Also create a temporary address if it's enabled but\n\t\t * no temporary address currently exists.\n\t\t */\n\t\tread_unlock_bh(&idev->lock);\n\t\tipv6_create_tempaddr(ifp, false);\n\t} else {\n\t\tread_unlock_bh(&idev->lock);\n\t}\n}\n\nstatic bool is_addr_mode_generate_stable(struct inet6_dev *idev)\n{\n\treturn idev->cnf.addr_gen_mode == IN6_ADDR_GEN_MODE_STABLE_PRIVACY ||\n\t       idev->cnf.addr_gen_mode == IN6_ADDR_GEN_MODE_RANDOM;\n}\n\nint addrconf_prefix_rcv_add_addr(struct net *net, struct net_device *dev,\n\t\t\t\t const struct prefix_info *pinfo,\n\t\t\t\t struct inet6_dev *in6_dev,\n\t\t\t\t const struct in6_addr *addr, int addr_type,\n\t\t\t\t u32 addr_flags, bool sllao, bool tokenized,\n\t\t\t\t __u32 valid_lft, u32 prefered_lft)\n{\n\tstruct inet6_ifaddr *ifp = ipv6_get_ifaddr(net, addr, dev, 1);\n\tint create = 0;\n\n\tif (!ifp && valid_lft) {\n\t\tint max_addresses = in6_dev->cnf.max_addresses;\n\t\tstruct ifa6_config cfg = {\n\t\t\t.pfx = addr,\n\t\t\t.plen = pinfo->prefix_len,\n\t\t\t.ifa_flags = addr_flags,\n\t\t\t.valid_lft = valid_lft,\n\t\t\t.preferred_lft = prefered_lft,\n\t\t\t.scope = addr_type & IPV6_ADDR_SCOPE_MASK,\n\t\t};\n\n#ifdef CONFIG_IPV6_OPTIMISTIC_DAD\n\t\tif ((net->ipv6.devconf_all->optimistic_dad ||\n\t\t     in6_dev->cnf.optimistic_dad) &&\n\t\t    !net->ipv6.devconf_all->forwarding && sllao)\n\t\t\tcfg.ifa_flags |= IFA_F_OPTIMISTIC;\n#endif\n\n\t\t/* Do not allow to create too much of autoconfigured\n\t\t * addresses; this would be too easy way to crash kernel.\n\t\t */\n\t\tif (!max_addresses ||\n\t\t    ipv6_count_addresses(in6_dev) < max_addresses)\n\t\t\tifp = ipv6_add_addr(in6_dev, &cfg, false, NULL);\n\n\t\tif (IS_ERR_OR_NULL(ifp))\n\t\t\treturn -1;\n\n\t\tcreate = 1;\n\t\tspin_lock_bh(&ifp->lock);\n\t\tifp->flags |= IFA_F_MANAGETEMPADDR;\n\t\tifp->cstamp = jiffies;\n\t\tifp->tokenized = tokenized;\n\t\tspin_unlock_bh(&ifp->lock);\n\t\taddrconf_dad_start(ifp);\n\t}\n\n\tif (ifp) {\n\t\tu32 flags;\n\t\tunsigned long now;\n\t\tu32 stored_lft;\n\n\t\t/* Update lifetime (RFC4862 5.5.3 e)\n\t\t * We deviate from RFC4862 by honoring all Valid Lifetimes to\n\t\t * improve the reaction of SLAAC to renumbering events\n\t\t * (draft-gont-6man-slaac-renum-06, Section 4.2)\n\t\t */\n\t\tspin_lock_bh(&ifp->lock);\n\t\tnow = jiffies;\n\t\tif (ifp->valid_lft > (now - ifp->tstamp) / HZ)\n\t\t\tstored_lft = ifp->valid_lft - (now - ifp->tstamp) / HZ;\n\t\telse\n\t\t\tstored_lft = 0;\n\n\t\tif (!create && stored_lft) {\n\t\t\tifp->valid_lft = valid_lft;\n\t\t\tifp->prefered_lft = prefered_lft;\n\t\t\tifp->tstamp = now;\n\t\t\tflags = ifp->flags;\n\t\t\tifp->flags &= ~IFA_F_DEPRECATED;\n\t\t\tspin_unlock_bh(&ifp->lock);\n\n\t\t\tif (!(flags&IFA_F_TENTATIVE))\n\t\t\t\tipv6_ifa_notify(0, ifp);\n\t\t} else\n\t\t\tspin_unlock_bh(&ifp->lock);\n\n\t\tmanage_tempaddrs(in6_dev, ifp, valid_lft, prefered_lft,\n\t\t\t\t create, now);\n\n\t\tin6_ifa_put(ifp);\n\t\taddrconf_verify();\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(addrconf_prefix_rcv_add_addr);\n\nvoid addrconf_prefix_rcv(struct net_device *dev, u8 *opt, int len, bool sllao)\n{\n\tstruct prefix_info *pinfo;\n\t__u32 valid_lft;\n\t__u32 prefered_lft;\n\tint addr_type, err;\n\tu32 addr_flags = 0;\n\tstruct inet6_dev *in6_dev;\n\tstruct net *net = dev_net(dev);\n\n\tpinfo = (struct prefix_info *) opt;\n\n\tif (len < sizeof(struct prefix_info)) {\n\t\tnetdev_dbg(dev, \"addrconf: prefix option too short\\n\");\n\t\treturn;\n\t}\n\n\t/*\n\t *\tValidation checks ([ADDRCONF], page 19)\n\t */\n\n\taddr_type = ipv6_addr_type(&pinfo->prefix);\n\n\tif (addr_type & (IPV6_ADDR_MULTICAST|IPV6_ADDR_LINKLOCAL))\n\t\treturn;\n\n\tvalid_lft = ntohl(pinfo->valid);\n\tprefered_lft = ntohl(pinfo->prefered);\n\n\tif (prefered_lft > valid_lft) {\n\t\tnet_warn_ratelimited(\"addrconf: prefix option has invalid lifetime\\n\");\n\t\treturn;\n\t}\n\n\tin6_dev = in6_dev_get(dev);\n\n\tif (!in6_dev) {\n\t\tnet_dbg_ratelimited(\"addrconf: device %s not configured\\n\",\n\t\t\t\t    dev->name);\n\t\treturn;\n\t}\n\n\t/*\n\t *\tTwo things going on here:\n\t *\t1) Add routes for on-link prefixes\n\t *\t2) Configure prefixes with the auto flag set\n\t */\n\n\tif (pinfo->onlink) {\n\t\tstruct fib6_info *rt;\n\t\tunsigned long rt_expires;\n\n\t\t/* Avoid arithmetic overflow. Really, we could\n\t\t * save rt_expires in seconds, likely valid_lft,\n\t\t * but it would require division in fib gc, that it\n\t\t * not good.\n\t\t */\n\t\tif (HZ > USER_HZ)\n\t\t\trt_expires = addrconf_timeout_fixup(valid_lft, HZ);\n\t\telse\n\t\t\trt_expires = addrconf_timeout_fixup(valid_lft, USER_HZ);\n\n\t\tif (addrconf_finite_timeout(rt_expires))\n\t\t\trt_expires *= HZ;\n\n\t\trt = addrconf_get_prefix_route(&pinfo->prefix,\n\t\t\t\t\t       pinfo->prefix_len,\n\t\t\t\t\t       dev,\n\t\t\t\t\t       RTF_ADDRCONF | RTF_PREFIX_RT,\n\t\t\t\t\t       RTF_DEFAULT, true);\n\n\t\tif (rt) {\n\t\t\t/* Autoconf prefix route */\n\t\t\tif (valid_lft == 0) {\n\t\t\t\tip6_del_rt(net, rt, false);\n\t\t\t\trt = NULL;\n\t\t\t} else if (addrconf_finite_timeout(rt_expires)) {\n\t\t\t\t/* not infinity */\n\t\t\t\tfib6_set_expires(rt, jiffies + rt_expires);\n\t\t\t} else {\n\t\t\t\tfib6_clean_expires(rt);\n\t\t\t}\n\t\t} else if (valid_lft) {\n\t\t\tclock_t expires = 0;\n\t\t\tint flags = RTF_ADDRCONF | RTF_PREFIX_RT;\n\t\t\tif (addrconf_finite_timeout(rt_expires)) {\n\t\t\t\t/* not infinity */\n\t\t\t\tflags |= RTF_EXPIRES;\n\t\t\t\texpires = jiffies_to_clock_t(rt_expires);\n\t\t\t}\n\t\t\taddrconf_prefix_route(&pinfo->prefix, pinfo->prefix_len,\n\t\t\t\t\t      0, dev, expires, flags,\n\t\t\t\t\t      GFP_ATOMIC);\n\t\t}\n\t\tfib6_info_release(rt);\n\t}\n\n\t/* Try to figure out our local address for this prefix */\n\n\tif (pinfo->autoconf && in6_dev->cnf.autoconf) {\n\t\tstruct in6_addr addr;\n\t\tbool tokenized = false, dev_addr_generated = false;\n\n\t\tif (pinfo->prefix_len == 64) {\n\t\t\tmemcpy(&addr, &pinfo->prefix, 8);\n\n\t\t\tif (!ipv6_addr_any(&in6_dev->token)) {\n\t\t\t\tread_lock_bh(&in6_dev->lock);\n\t\t\t\tmemcpy(addr.s6_addr + 8,\n\t\t\t\t       in6_dev->token.s6_addr + 8, 8);\n\t\t\t\tread_unlock_bh(&in6_dev->lock);\n\t\t\t\ttokenized = true;\n\t\t\t} else if (is_addr_mode_generate_stable(in6_dev) &&\n\t\t\t\t   !ipv6_generate_stable_address(&addr, 0,\n\t\t\t\t\t\t\t\t in6_dev)) {\n\t\t\t\taddr_flags |= IFA_F_STABLE_PRIVACY;\n\t\t\t\tgoto ok;\n\t\t\t} else if (ipv6_generate_eui64(addr.s6_addr + 8, dev) &&\n\t\t\t\t   ipv6_inherit_eui64(addr.s6_addr + 8, in6_dev)) {\n\t\t\t\tgoto put;\n\t\t\t} else {\n\t\t\t\tdev_addr_generated = true;\n\t\t\t}\n\t\t\tgoto ok;\n\t\t}\n\t\tnet_dbg_ratelimited(\"IPv6 addrconf: prefix with wrong length %d\\n\",\n\t\t\t\t    pinfo->prefix_len);\n\t\tgoto put;\n\nok:\n\t\terr = addrconf_prefix_rcv_add_addr(net, dev, pinfo, in6_dev,\n\t\t\t\t\t\t   &addr, addr_type,\n\t\t\t\t\t\t   addr_flags, sllao,\n\t\t\t\t\t\t   tokenized, valid_lft,\n\t\t\t\t\t\t   prefered_lft);\n\t\tif (err)\n\t\t\tgoto put;\n\n\t\t/* Ignore error case here because previous prefix add addr was\n\t\t * successful which will be notified.\n\t\t */\n\t\tndisc_ops_prefix_rcv_add_addr(net, dev, pinfo, in6_dev, &addr,\n\t\t\t\t\t      addr_type, addr_flags, sllao,\n\t\t\t\t\t      tokenized, valid_lft,\n\t\t\t\t\t      prefered_lft,\n\t\t\t\t\t      dev_addr_generated);\n\t}\n\tinet6_prefix_notify(RTM_NEWPREFIX, in6_dev, pinfo);\nput:\n\tin6_dev_put(in6_dev);\n}\n\nstatic int addrconf_set_sit_dstaddr(struct net *net, struct net_device *dev,\n\t\tstruct in6_ifreq *ireq)\n{\n\tstruct ip_tunnel_parm p = { };\n\tint err;\n\n\tif (!(ipv6_addr_type(&ireq->ifr6_addr) & IPV6_ADDR_COMPATv4))\n\t\treturn -EADDRNOTAVAIL;\n\n\tp.iph.daddr = ireq->ifr6_addr.s6_addr32[3];\n\tp.iph.version = 4;\n\tp.iph.ihl = 5;\n\tp.iph.protocol = IPPROTO_IPV6;\n\tp.iph.ttl = 64;\n\n\tif (!dev->netdev_ops->ndo_tunnel_ctl)\n\t\treturn -EOPNOTSUPP;\n\terr = dev->netdev_ops->ndo_tunnel_ctl(dev, &p, SIOCADDTUNNEL);\n\tif (err)\n\t\treturn err;\n\n\tdev = __dev_get_by_name(net, p.name);\n\tif (!dev)\n\t\treturn -ENOBUFS;\n\treturn dev_open(dev, NULL);\n}\n\n/*\n *\tSet destination address.\n *\tSpecial case for SIT interfaces where we create a new \"virtual\"\n *\tdevice.\n */\nint addrconf_set_dstaddr(struct net *net, void __user *arg)\n{\n\tstruct net_device *dev;\n\tstruct in6_ifreq ireq;\n\tint err = -ENODEV;\n\n\tif (!IS_ENABLED(CONFIG_IPV6_SIT))\n\t\treturn -ENODEV;\n\tif (copy_from_user(&ireq, arg, sizeof(struct in6_ifreq)))\n\t\treturn -EFAULT;\n\n\trtnl_lock();\n\tdev = __dev_get_by_index(net, ireq.ifr6_ifindex);\n\tif (dev && dev->type == ARPHRD_SIT)\n\t\terr = addrconf_set_sit_dstaddr(net, dev, &ireq);\n\trtnl_unlock();\n\treturn err;\n}\n\nstatic int ipv6_mc_config(struct sock *sk, bool join,\n\t\t\t  const struct in6_addr *addr, int ifindex)\n{\n\tint ret;\n\n\tASSERT_RTNL();\n\n\tlock_sock(sk);\n\tif (join)\n\t\tret = ipv6_sock_mc_join(sk, ifindex, addr);\n\telse\n\t\tret = ipv6_sock_mc_drop(sk, ifindex, addr);\n\trelease_sock(sk);\n\n\treturn ret;\n}\n\n/*\n *\tManual configuration of address on an interface\n */\nstatic int inet6_addr_add(struct net *net, int ifindex,\n\t\t\t  struct ifa6_config *cfg,\n\t\t\t  struct netlink_ext_ack *extack)\n{\n\tstruct inet6_ifaddr *ifp;\n\tstruct inet6_dev *idev;\n\tstruct net_device *dev;\n\tunsigned long timeout;\n\tclock_t expires;\n\tu32 flags;\n\n\tASSERT_RTNL();\n\n\tif (cfg->plen > 128)\n\t\treturn -EINVAL;\n\n\t/* check the lifetime */\n\tif (!cfg->valid_lft || cfg->preferred_lft > cfg->valid_lft)\n\t\treturn -EINVAL;\n\n\tif (cfg->ifa_flags & IFA_F_MANAGETEMPADDR && cfg->plen != 64)\n\t\treturn -EINVAL;\n\n\tdev = __dev_get_by_index(net, ifindex);\n\tif (!dev)\n\t\treturn -ENODEV;\n\n\tidev = addrconf_add_dev(dev);\n\tif (IS_ERR(idev))\n\t\treturn PTR_ERR(idev);\n\n\tif (cfg->ifa_flags & IFA_F_MCAUTOJOIN) {\n\t\tint ret = ipv6_mc_config(net->ipv6.mc_autojoin_sk,\n\t\t\t\t\t true, cfg->pfx, ifindex);\n\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\n\tcfg->scope = ipv6_addr_scope(cfg->pfx);\n\n\ttimeout = addrconf_timeout_fixup(cfg->valid_lft, HZ);\n\tif (addrconf_finite_timeout(timeout)) {\n\t\texpires = jiffies_to_clock_t(timeout * HZ);\n\t\tcfg->valid_lft = timeout;\n\t\tflags = RTF_EXPIRES;\n\t} else {\n\t\texpires = 0;\n\t\tflags = 0;\n\t\tcfg->ifa_flags |= IFA_F_PERMANENT;\n\t}\n\n\ttimeout = addrconf_timeout_fixup(cfg->preferred_lft, HZ);\n\tif (addrconf_finite_timeout(timeout)) {\n\t\tif (timeout == 0)\n\t\t\tcfg->ifa_flags |= IFA_F_DEPRECATED;\n\t\tcfg->preferred_lft = timeout;\n\t}\n\n\tifp = ipv6_add_addr(idev, cfg, true, extack);\n\tif (!IS_ERR(ifp)) {\n\t\tif (!(cfg->ifa_flags & IFA_F_NOPREFIXROUTE)) {\n\t\t\taddrconf_prefix_route(&ifp->addr, ifp->prefix_len,\n\t\t\t\t\t      ifp->rt_priority, dev, expires,\n\t\t\t\t\t      flags, GFP_KERNEL);\n\t\t}\n\n\t\t/* Send a netlink notification if DAD is enabled and\n\t\t * optimistic flag is not set\n\t\t */\n\t\tif (!(ifp->flags & (IFA_F_OPTIMISTIC | IFA_F_NODAD)))\n\t\t\tipv6_ifa_notify(0, ifp);\n\t\t/*\n\t\t * Note that section 3.1 of RFC 4429 indicates\n\t\t * that the Optimistic flag should not be set for\n\t\t * manually configured addresses\n\t\t */\n\t\taddrconf_dad_start(ifp);\n\t\tif (cfg->ifa_flags & IFA_F_MANAGETEMPADDR)\n\t\t\tmanage_tempaddrs(idev, ifp, cfg->valid_lft,\n\t\t\t\t\t cfg->preferred_lft, true, jiffies);\n\t\tin6_ifa_put(ifp);\n\t\taddrconf_verify_rtnl();\n\t\treturn 0;\n\t} else if (cfg->ifa_flags & IFA_F_MCAUTOJOIN) {\n\t\tipv6_mc_config(net->ipv6.mc_autojoin_sk, false,\n\t\t\t       cfg->pfx, ifindex);\n\t}\n\n\treturn PTR_ERR(ifp);\n}\n\nstatic int inet6_addr_del(struct net *net, int ifindex, u32 ifa_flags,\n\t\t\t  const struct in6_addr *pfx, unsigned int plen)\n{\n\tstruct inet6_ifaddr *ifp;\n\tstruct inet6_dev *idev;\n\tstruct net_device *dev;\n\n\tif (plen > 128)\n\t\treturn -EINVAL;\n\n\tdev = __dev_get_by_index(net, ifindex);\n\tif (!dev)\n\t\treturn -ENODEV;\n\n\tidev = __in6_dev_get(dev);\n\tif (!idev)\n\t\treturn -ENXIO;\n\n\tread_lock_bh(&idev->lock);\n\tlist_for_each_entry(ifp, &idev->addr_list, if_list) {\n\t\tif (ifp->prefix_len == plen &&\n\t\t    ipv6_addr_equal(pfx, &ifp->addr)) {\n\t\t\tin6_ifa_hold(ifp);\n\t\t\tread_unlock_bh(&idev->lock);\n\n\t\t\tif (!(ifp->flags & IFA_F_TEMPORARY) &&\n\t\t\t    (ifa_flags & IFA_F_MANAGETEMPADDR))\n\t\t\t\tmanage_tempaddrs(idev, ifp, 0, 0, false,\n\t\t\t\t\t\t jiffies);\n\t\t\tipv6_del_addr(ifp);\n\t\t\taddrconf_verify_rtnl();\n\t\t\tif (ipv6_addr_is_multicast(pfx)) {\n\t\t\t\tipv6_mc_config(net->ipv6.mc_autojoin_sk,\n\t\t\t\t\t       false, pfx, dev->ifindex);\n\t\t\t}\n\t\t\treturn 0;\n\t\t}\n\t}\n\tread_unlock_bh(&idev->lock);\n\treturn -EADDRNOTAVAIL;\n}\n\n\nint addrconf_add_ifaddr(struct net *net, void __user *arg)\n{\n\tstruct ifa6_config cfg = {\n\t\t.ifa_flags = IFA_F_PERMANENT,\n\t\t.preferred_lft = INFINITY_LIFE_TIME,\n\t\t.valid_lft = INFINITY_LIFE_TIME,\n\t};\n\tstruct in6_ifreq ireq;\n\tint err;\n\n\tif (!ns_capable(net->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (copy_from_user(&ireq, arg, sizeof(struct in6_ifreq)))\n\t\treturn -EFAULT;\n\n\tcfg.pfx = &ireq.ifr6_addr;\n\tcfg.plen = ireq.ifr6_prefixlen;\n\n\trtnl_lock();\n\terr = inet6_addr_add(net, ireq.ifr6_ifindex, &cfg, NULL);\n\trtnl_unlock();\n\treturn err;\n}\n\nint addrconf_del_ifaddr(struct net *net, void __user *arg)\n{\n\tstruct in6_ifreq ireq;\n\tint err;\n\n\tif (!ns_capable(net->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (copy_from_user(&ireq, arg, sizeof(struct in6_ifreq)))\n\t\treturn -EFAULT;\n\n\trtnl_lock();\n\terr = inet6_addr_del(net, ireq.ifr6_ifindex, 0, &ireq.ifr6_addr,\n\t\t\t     ireq.ifr6_prefixlen);\n\trtnl_unlock();\n\treturn err;\n}\n\nstatic void add_addr(struct inet6_dev *idev, const struct in6_addr *addr,\n\t\t     int plen, int scope)\n{\n\tstruct inet6_ifaddr *ifp;\n\tstruct ifa6_config cfg = {\n\t\t.pfx = addr,\n\t\t.plen = plen,\n\t\t.ifa_flags = IFA_F_PERMANENT,\n\t\t.valid_lft = INFINITY_LIFE_TIME,\n\t\t.preferred_lft = INFINITY_LIFE_TIME,\n\t\t.scope = scope\n\t};\n\n\tifp = ipv6_add_addr(idev, &cfg, true, NULL);\n\tif (!IS_ERR(ifp)) {\n\t\tspin_lock_bh(&ifp->lock);\n\t\tifp->flags &= ~IFA_F_TENTATIVE;\n\t\tspin_unlock_bh(&ifp->lock);\n\t\trt_genid_bump_ipv6(dev_net(idev->dev));\n\t\tipv6_ifa_notify(RTM_NEWADDR, ifp);\n\t\tin6_ifa_put(ifp);\n\t}\n}\n\n#if IS_ENABLED(CONFIG_IPV6_SIT)\nstatic void sit_add_v4_addrs(struct inet6_dev *idev)\n{\n\tstruct in6_addr addr;\n\tstruct net_device *dev;\n\tstruct net *net = dev_net(idev->dev);\n\tint scope, plen;\n\tu32 pflags = 0;\n\n\tASSERT_RTNL();\n\n\tmemset(&addr, 0, sizeof(struct in6_addr));\n\tmemcpy(&addr.s6_addr32[3], idev->dev->dev_addr, 4);\n\n\tif (idev->dev->flags&IFF_POINTOPOINT) {\n\t\taddr.s6_addr32[0] = htonl(0xfe800000);\n\t\tscope = IFA_LINK;\n\t\tplen = 64;\n\t} else {\n\t\tscope = IPV6_ADDR_COMPATv4;\n\t\tplen = 96;\n\t\tpflags |= RTF_NONEXTHOP;\n\t}\n\n\tif (addr.s6_addr32[3]) {\n\t\tadd_addr(idev, &addr, plen, scope);\n\t\taddrconf_prefix_route(&addr, plen, 0, idev->dev, 0, pflags,\n\t\t\t\t      GFP_KERNEL);\n\t\treturn;\n\t}\n\n\tfor_each_netdev(net, dev) {\n\t\tstruct in_device *in_dev = __in_dev_get_rtnl(dev);\n\t\tif (in_dev && (dev->flags & IFF_UP)) {\n\t\t\tstruct in_ifaddr *ifa;\n\t\t\tint flag = scope;\n\n\t\t\tin_dev_for_each_ifa_rtnl(ifa, in_dev) {\n\t\t\t\taddr.s6_addr32[3] = ifa->ifa_local;\n\n\t\t\t\tif (ifa->ifa_scope == RT_SCOPE_LINK)\n\t\t\t\t\tcontinue;\n\t\t\t\tif (ifa->ifa_scope >= RT_SCOPE_HOST) {\n\t\t\t\t\tif (idev->dev->flags&IFF_POINTOPOINT)\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\tflag |= IFA_HOST;\n\t\t\t\t}\n\n\t\t\t\tadd_addr(idev, &addr, plen, flag);\n\t\t\t\taddrconf_prefix_route(&addr, plen, 0, idev->dev,\n\t\t\t\t\t\t      0, pflags, GFP_KERNEL);\n\t\t\t}\n\t\t}\n\t}\n}\n#endif\n\nstatic void init_loopback(struct net_device *dev)\n{\n\tstruct inet6_dev  *idev;\n\n\t/* ::1 */\n\n\tASSERT_RTNL();\n\n\tidev = ipv6_find_idev(dev);\n\tif (IS_ERR(idev)) {\n\t\tpr_debug(\"%s: add_dev failed\\n\", __func__);\n\t\treturn;\n\t}\n\n\tadd_addr(idev, &in6addr_loopback, 128, IFA_HOST);\n}\n\nvoid addrconf_add_linklocal(struct inet6_dev *idev,\n\t\t\t    const struct in6_addr *addr, u32 flags)\n{\n\tstruct ifa6_config cfg = {\n\t\t.pfx = addr,\n\t\t.plen = 64,\n\t\t.ifa_flags = flags | IFA_F_PERMANENT,\n\t\t.valid_lft = INFINITY_LIFE_TIME,\n\t\t.preferred_lft = INFINITY_LIFE_TIME,\n\t\t.scope = IFA_LINK\n\t};\n\tstruct inet6_ifaddr *ifp;\n\n#ifdef CONFIG_IPV6_OPTIMISTIC_DAD\n\tif ((dev_net(idev->dev)->ipv6.devconf_all->optimistic_dad ||\n\t     idev->cnf.optimistic_dad) &&\n\t    !dev_net(idev->dev)->ipv6.devconf_all->forwarding)\n\t\tcfg.ifa_flags |= IFA_F_OPTIMISTIC;\n#endif\n\n\tifp = ipv6_add_addr(idev, &cfg, true, NULL);\n\tif (!IS_ERR(ifp)) {\n\t\taddrconf_prefix_route(&ifp->addr, ifp->prefix_len, 0, idev->dev,\n\t\t\t\t      0, 0, GFP_ATOMIC);\n\t\taddrconf_dad_start(ifp);\n\t\tin6_ifa_put(ifp);\n\t}\n}\nEXPORT_SYMBOL_GPL(addrconf_add_linklocal);\n\nstatic bool ipv6_reserved_interfaceid(struct in6_addr address)\n{\n\tif ((address.s6_addr32[2] | address.s6_addr32[3]) == 0)\n\t\treturn true;\n\n\tif (address.s6_addr32[2] == htonl(0x02005eff) &&\n\t    ((address.s6_addr32[3] & htonl(0xfe000000)) == htonl(0xfe000000)))\n\t\treturn true;\n\n\tif (address.s6_addr32[2] == htonl(0xfdffffff) &&\n\t    ((address.s6_addr32[3] & htonl(0xffffff80)) == htonl(0xffffff80)))\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic int ipv6_generate_stable_address(struct in6_addr *address,\n\t\t\t\t\tu8 dad_count,\n\t\t\t\t\tconst struct inet6_dev *idev)\n{\n\tstatic DEFINE_SPINLOCK(lock);\n\tstatic __u32 digest[SHA1_DIGEST_WORDS];\n\tstatic __u32 workspace[SHA1_WORKSPACE_WORDS];\n\n\tstatic union {\n\t\tchar __data[SHA1_BLOCK_SIZE];\n\t\tstruct {\n\t\t\tstruct in6_addr secret;\n\t\t\t__be32 prefix[2];\n\t\t\tunsigned char hwaddr[MAX_ADDR_LEN];\n\t\t\tu8 dad_count;\n\t\t} __packed;\n\t} data;\n\n\tstruct in6_addr secret;\n\tstruct in6_addr temp;\n\tstruct net *net = dev_net(idev->dev);\n\n\tBUILD_BUG_ON(sizeof(data.__data) != sizeof(data));\n\n\tif (idev->cnf.stable_secret.initialized)\n\t\tsecret = idev->cnf.stable_secret.secret;\n\telse if (net->ipv6.devconf_dflt->stable_secret.initialized)\n\t\tsecret = net->ipv6.devconf_dflt->stable_secret.secret;\n\telse\n\t\treturn -1;\n\nretry:\n\tspin_lock_bh(&lock);\n\n\tsha1_init(digest);\n\tmemset(&data, 0, sizeof(data));\n\tmemset(workspace, 0, sizeof(workspace));\n\tmemcpy(data.hwaddr, idev->dev->perm_addr, idev->dev->addr_len);\n\tdata.prefix[0] = address->s6_addr32[0];\n\tdata.prefix[1] = address->s6_addr32[1];\n\tdata.secret = secret;\n\tdata.dad_count = dad_count;\n\n\tsha1_transform(digest, data.__data, workspace);\n\n\ttemp = *address;\n\ttemp.s6_addr32[2] = (__force __be32)digest[0];\n\ttemp.s6_addr32[3] = (__force __be32)digest[1];\n\n\tspin_unlock_bh(&lock);\n\n\tif (ipv6_reserved_interfaceid(temp)) {\n\t\tdad_count++;\n\t\tif (dad_count > dev_net(idev->dev)->ipv6.sysctl.idgen_retries)\n\t\t\treturn -1;\n\t\tgoto retry;\n\t}\n\n\t*address = temp;\n\treturn 0;\n}\n\nstatic void ipv6_gen_mode_random_init(struct inet6_dev *idev)\n{\n\tstruct ipv6_stable_secret *s = &idev->cnf.stable_secret;\n\n\tif (s->initialized)\n\t\treturn;\n\ts = &idev->cnf.stable_secret;\n\tget_random_bytes(&s->secret, sizeof(s->secret));\n\ts->initialized = true;\n}\n\nstatic void addrconf_addr_gen(struct inet6_dev *idev, bool prefix_route)\n{\n\tstruct in6_addr addr;\n\n\t/* no link local addresses on L3 master devices */\n\tif (netif_is_l3_master(idev->dev))\n\t\treturn;\n\n\t/* no link local addresses on devices flagged as slaves */\n\tif (idev->dev->flags & IFF_SLAVE)\n\t\treturn;\n\n\tipv6_addr_set(&addr, htonl(0xFE800000), 0, 0, 0);\n\n\tswitch (idev->cnf.addr_gen_mode) {\n\tcase IN6_ADDR_GEN_MODE_RANDOM:\n\t\tipv6_gen_mode_random_init(idev);\n\t\tfallthrough;\n\tcase IN6_ADDR_GEN_MODE_STABLE_PRIVACY:\n\t\tif (!ipv6_generate_stable_address(&addr, 0, idev))\n\t\t\taddrconf_add_linklocal(idev, &addr,\n\t\t\t\t\t       IFA_F_STABLE_PRIVACY);\n\t\telse if (prefix_route)\n\t\t\taddrconf_prefix_route(&addr, 64, 0, idev->dev,\n\t\t\t\t\t      0, 0, GFP_KERNEL);\n\t\tbreak;\n\tcase IN6_ADDR_GEN_MODE_EUI64:\n\t\t/* addrconf_add_linklocal also adds a prefix_route and we\n\t\t * only need to care about prefix routes if ipv6_generate_eui64\n\t\t * couldn't generate one.\n\t\t */\n\t\tif (ipv6_generate_eui64(addr.s6_addr + 8, idev->dev) == 0)\n\t\t\taddrconf_add_linklocal(idev, &addr, 0);\n\t\telse if (prefix_route)\n\t\t\taddrconf_prefix_route(&addr, 64, 0, idev->dev,\n\t\t\t\t\t      0, 0, GFP_KERNEL);\n\t\tbreak;\n\tcase IN6_ADDR_GEN_MODE_NONE:\n\tdefault:\n\t\t/* will not add any link local address */\n\t\tbreak;\n\t}\n}\n\nstatic void addrconf_dev_config(struct net_device *dev)\n{\n\tstruct inet6_dev *idev;\n\n\tASSERT_RTNL();\n\n\tif ((dev->type != ARPHRD_ETHER) &&\n\t    (dev->type != ARPHRD_FDDI) &&\n\t    (dev->type != ARPHRD_ARCNET) &&\n\t    (dev->type != ARPHRD_INFINIBAND) &&\n\t    (dev->type != ARPHRD_IEEE1394) &&\n\t    (dev->type != ARPHRD_TUNNEL6) &&\n\t    (dev->type != ARPHRD_6LOWPAN) &&\n\t    (dev->type != ARPHRD_IP6GRE) &&\n\t    (dev->type != ARPHRD_IPGRE) &&\n\t    (dev->type != ARPHRD_TUNNEL) &&\n\t    (dev->type != ARPHRD_NONE) &&\n\t    (dev->type != ARPHRD_RAWIP)) {\n\t\t/* Alas, we support only Ethernet autoconfiguration. */\n\t\tidev = __in6_dev_get(dev);\n\t\tif (!IS_ERR_OR_NULL(idev) && dev->flags & IFF_UP &&\n\t\t    dev->flags & IFF_MULTICAST)\n\t\t\tipv6_mc_up(idev);\n\t\treturn;\n\t}\n\n\tidev = addrconf_add_dev(dev);\n\tif (IS_ERR(idev))\n\t\treturn;\n\n\t/* this device type has no EUI support */\n\tif (dev->type == ARPHRD_NONE &&\n\t    idev->cnf.addr_gen_mode == IN6_ADDR_GEN_MODE_EUI64)\n\t\tidev->cnf.addr_gen_mode = IN6_ADDR_GEN_MODE_RANDOM;\n\n\taddrconf_addr_gen(idev, false);\n}\n\n#if IS_ENABLED(CONFIG_IPV6_SIT)\nstatic void addrconf_sit_config(struct net_device *dev)\n{\n\tstruct inet6_dev *idev;\n\n\tASSERT_RTNL();\n\n\t/*\n\t * Configure the tunnel with one of our IPv4\n\t * addresses... we should configure all of\n\t * our v4 addrs in the tunnel\n\t */\n\n\tidev = ipv6_find_idev(dev);\n\tif (IS_ERR(idev)) {\n\t\tpr_debug(\"%s: add_dev failed\\n\", __func__);\n\t\treturn;\n\t}\n\n\tif (dev->priv_flags & IFF_ISATAP) {\n\t\taddrconf_addr_gen(idev, false);\n\t\treturn;\n\t}\n\n\tsit_add_v4_addrs(idev);\n\n\tif (dev->flags&IFF_POINTOPOINT)\n\t\taddrconf_add_mroute(dev);\n}\n#endif\n\n#if IS_ENABLED(CONFIG_NET_IPGRE)\nstatic void addrconf_gre_config(struct net_device *dev)\n{\n\tstruct inet6_dev *idev;\n\n\tASSERT_RTNL();\n\n\tidev = ipv6_find_idev(dev);\n\tif (IS_ERR(idev)) {\n\t\tpr_debug(\"%s: add_dev failed\\n\", __func__);\n\t\treturn;\n\t}\n\n\taddrconf_addr_gen(idev, true);\n\tif (dev->flags & IFF_POINTOPOINT)\n\t\taddrconf_add_mroute(dev);\n}\n#endif\n\nstatic int fixup_permanent_addr(struct net *net,\n\t\t\t\tstruct inet6_dev *idev,\n\t\t\t\tstruct inet6_ifaddr *ifp)\n{\n\t/* !fib6_node means the host route was removed from the\n\t * FIB, for example, if 'lo' device is taken down. In that\n\t * case regenerate the host route.\n\t */\n\tif (!ifp->rt || !ifp->rt->fib6_node) {\n\t\tstruct fib6_info *f6i, *prev;\n\n\t\tf6i = addrconf_f6i_alloc(net, idev, &ifp->addr, false,\n\t\t\t\t\t GFP_ATOMIC);\n\t\tif (IS_ERR(f6i))\n\t\t\treturn PTR_ERR(f6i);\n\n\t\t/* ifp->rt can be accessed outside of rtnl */\n\t\tspin_lock(&ifp->lock);\n\t\tprev = ifp->rt;\n\t\tifp->rt = f6i;\n\t\tspin_unlock(&ifp->lock);\n\n\t\tfib6_info_release(prev);\n\t}\n\n\tif (!(ifp->flags & IFA_F_NOPREFIXROUTE)) {\n\t\taddrconf_prefix_route(&ifp->addr, ifp->prefix_len,\n\t\t\t\t      ifp->rt_priority, idev->dev, 0, 0,\n\t\t\t\t      GFP_ATOMIC);\n\t}\n\n\tif (ifp->state == INET6_IFADDR_STATE_PREDAD)\n\t\taddrconf_dad_start(ifp);\n\n\treturn 0;\n}\n\nstatic void addrconf_permanent_addr(struct net *net, struct net_device *dev)\n{\n\tstruct inet6_ifaddr *ifp, *tmp;\n\tstruct inet6_dev *idev;\n\n\tidev = __in6_dev_get(dev);\n\tif (!idev)\n\t\treturn;\n\n\twrite_lock_bh(&idev->lock);\n\n\tlist_for_each_entry_safe(ifp, tmp, &idev->addr_list, if_list) {\n\t\tif ((ifp->flags & IFA_F_PERMANENT) &&\n\t\t    fixup_permanent_addr(net, idev, ifp) < 0) {\n\t\t\twrite_unlock_bh(&idev->lock);\n\t\t\tin6_ifa_hold(ifp);\n\t\t\tipv6_del_addr(ifp);\n\t\t\twrite_lock_bh(&idev->lock);\n\n\t\t\tnet_info_ratelimited(\"%s: Failed to add prefix route for address %pI6c; dropping\\n\",\n\t\t\t\t\t     idev->dev->name, &ifp->addr);\n\t\t}\n\t}\n\n\twrite_unlock_bh(&idev->lock);\n}\n\nstatic int addrconf_notify(struct notifier_block *this, unsigned long event,\n\t\t\t   void *ptr)\n{\n\tstruct net_device *dev = netdev_notifier_info_to_dev(ptr);\n\tstruct netdev_notifier_change_info *change_info;\n\tstruct netdev_notifier_changeupper_info *info;\n\tstruct inet6_dev *idev = __in6_dev_get(dev);\n\tstruct net *net = dev_net(dev);\n\tint run_pending = 0;\n\tint err;\n\n\tswitch (event) {\n\tcase NETDEV_REGISTER:\n\t\tif (!idev && dev->mtu >= IPV6_MIN_MTU) {\n\t\t\tidev = ipv6_add_dev(dev);\n\t\t\tif (IS_ERR(idev))\n\t\t\t\treturn notifier_from_errno(PTR_ERR(idev));\n\t\t}\n\t\tbreak;\n\n\tcase NETDEV_CHANGEMTU:\n\t\t/* if MTU under IPV6_MIN_MTU stop IPv6 on this interface. */\n\t\tif (dev->mtu < IPV6_MIN_MTU) {\n\t\t\taddrconf_ifdown(dev, dev != net->loopback_dev);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (idev) {\n\t\t\trt6_mtu_change(dev, dev->mtu);\n\t\t\tidev->cnf.mtu6 = dev->mtu;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* allocate new idev */\n\t\tidev = ipv6_add_dev(dev);\n\t\tif (IS_ERR(idev))\n\t\t\tbreak;\n\n\t\t/* device is still not ready */\n\t\tif (!(idev->if_flags & IF_READY))\n\t\t\tbreak;\n\n\t\trun_pending = 1;\n\t\tfallthrough;\n\tcase NETDEV_UP:\n\tcase NETDEV_CHANGE:\n\t\tif (dev->flags & IFF_SLAVE)\n\t\t\tbreak;\n\n\t\tif (idev && idev->cnf.disable_ipv6)\n\t\t\tbreak;\n\n\t\tif (event == NETDEV_UP) {\n\t\t\t/* restore routes for permanent addresses */\n\t\t\taddrconf_permanent_addr(net, dev);\n\n\t\t\tif (!addrconf_link_ready(dev)) {\n\t\t\t\t/* device is not ready yet. */\n\t\t\t\tpr_debug(\"ADDRCONF(NETDEV_UP): %s: link is not ready\\n\",\n\t\t\t\t\t dev->name);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (!idev && dev->mtu >= IPV6_MIN_MTU)\n\t\t\t\tidev = ipv6_add_dev(dev);\n\n\t\t\tif (!IS_ERR_OR_NULL(idev)) {\n\t\t\t\tidev->if_flags |= IF_READY;\n\t\t\t\trun_pending = 1;\n\t\t\t}\n\t\t} else if (event == NETDEV_CHANGE) {\n\t\t\tif (!addrconf_link_ready(dev)) {\n\t\t\t\t/* device is still not ready. */\n\t\t\t\trt6_sync_down_dev(dev, event);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (!IS_ERR_OR_NULL(idev)) {\n\t\t\t\tif (idev->if_flags & IF_READY) {\n\t\t\t\t\t/* device is already configured -\n\t\t\t\t\t * but resend MLD reports, we might\n\t\t\t\t\t * have roamed and need to update\n\t\t\t\t\t * multicast snooping switches\n\t\t\t\t\t */\n\t\t\t\t\tipv6_mc_up(idev);\n\t\t\t\t\tchange_info = ptr;\n\t\t\t\t\tif (change_info->flags_changed & IFF_NOARP)\n\t\t\t\t\t\taddrconf_dad_run(idev, true);\n\t\t\t\t\trt6_sync_up(dev, RTNH_F_LINKDOWN);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tidev->if_flags |= IF_READY;\n\t\t\t}\n\n\t\t\tpr_info(\"ADDRCONF(NETDEV_CHANGE): %s: link becomes ready\\n\",\n\t\t\t\tdev->name);\n\n\t\t\trun_pending = 1;\n\t\t}\n\n\t\tswitch (dev->type) {\n#if IS_ENABLED(CONFIG_IPV6_SIT)\n\t\tcase ARPHRD_SIT:\n\t\t\taddrconf_sit_config(dev);\n\t\t\tbreak;\n#endif\n#if IS_ENABLED(CONFIG_NET_IPGRE)\n\t\tcase ARPHRD_IPGRE:\n\t\t\taddrconf_gre_config(dev);\n\t\t\tbreak;\n#endif\n\t\tcase ARPHRD_LOOPBACK:\n\t\t\tinit_loopback(dev);\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\taddrconf_dev_config(dev);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!IS_ERR_OR_NULL(idev)) {\n\t\t\tif (run_pending)\n\t\t\t\taddrconf_dad_run(idev, false);\n\n\t\t\t/* Device has an address by now */\n\t\t\trt6_sync_up(dev, RTNH_F_DEAD);\n\n\t\t\t/*\n\t\t\t * If the MTU changed during the interface down,\n\t\t\t * when the interface up, the changed MTU must be\n\t\t\t * reflected in the idev as well as routers.\n\t\t\t */\n\t\t\tif (idev->cnf.mtu6 != dev->mtu &&\n\t\t\t    dev->mtu >= IPV6_MIN_MTU) {\n\t\t\t\trt6_mtu_change(dev, dev->mtu);\n\t\t\t\tidev->cnf.mtu6 = dev->mtu;\n\t\t\t}\n\t\t\tidev->tstamp = jiffies;\n\t\t\tinet6_ifinfo_notify(RTM_NEWLINK, idev);\n\n\t\t\t/*\n\t\t\t * If the changed mtu during down is lower than\n\t\t\t * IPV6_MIN_MTU stop IPv6 on this interface.\n\t\t\t */\n\t\t\tif (dev->mtu < IPV6_MIN_MTU)\n\t\t\t\taddrconf_ifdown(dev, dev != net->loopback_dev);\n\t\t}\n\t\tbreak;\n\n\tcase NETDEV_DOWN:\n\tcase NETDEV_UNREGISTER:\n\t\t/*\n\t\t *\tRemove all addresses from this interface.\n\t\t */\n\t\taddrconf_ifdown(dev, event != NETDEV_DOWN);\n\t\tbreak;\n\n\tcase NETDEV_CHANGENAME:\n\t\tif (idev) {\n\t\t\tsnmp6_unregister_dev(idev);\n\t\t\taddrconf_sysctl_unregister(idev);\n\t\t\terr = addrconf_sysctl_register(idev);\n\t\t\tif (err)\n\t\t\t\treturn notifier_from_errno(err);\n\t\t\terr = snmp6_register_dev(idev);\n\t\t\tif (err) {\n\t\t\t\taddrconf_sysctl_unregister(idev);\n\t\t\t\treturn notifier_from_errno(err);\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\tcase NETDEV_PRE_TYPE_CHANGE:\n\tcase NETDEV_POST_TYPE_CHANGE:\n\t\tif (idev)\n\t\t\taddrconf_type_change(dev, event);\n\t\tbreak;\n\n\tcase NETDEV_CHANGEUPPER:\n\t\tinfo = ptr;\n\n\t\t/* flush all routes if dev is linked to or unlinked from\n\t\t * an L3 master device (e.g., VRF)\n\t\t */\n\t\tif (info->upper_dev && netif_is_l3_master(info->upper_dev))\n\t\t\taddrconf_ifdown(dev, false);\n\t}\n\n\treturn NOTIFY_OK;\n}\n\n/*\n *\taddrconf module should be notified of a device going up\n */\nstatic struct notifier_block ipv6_dev_notf = {\n\t.notifier_call = addrconf_notify,\n\t.priority = ADDRCONF_NOTIFY_PRIORITY,\n};\n\nstatic void addrconf_type_change(struct net_device *dev, unsigned long event)\n{\n\tstruct inet6_dev *idev;\n\tASSERT_RTNL();\n\n\tidev = __in6_dev_get(dev);\n\n\tif (event == NETDEV_POST_TYPE_CHANGE)\n\t\tipv6_mc_remap(idev);\n\telse if (event == NETDEV_PRE_TYPE_CHANGE)\n\t\tipv6_mc_unmap(idev);\n}\n\nstatic bool addr_is_local(const struct in6_addr *addr)\n{\n\treturn ipv6_addr_type(addr) &\n\t\t(IPV6_ADDR_LINKLOCAL | IPV6_ADDR_LOOPBACK);\n}\n\nstatic int addrconf_ifdown(struct net_device *dev, bool unregister)\n{\n\tunsigned long event = unregister ? NETDEV_UNREGISTER : NETDEV_DOWN;\n\tstruct net *net = dev_net(dev);\n\tstruct inet6_dev *idev;\n\tstruct inet6_ifaddr *ifa, *tmp;\n\tbool keep_addr = false;\n\tint state, i;\n\n\tASSERT_RTNL();\n\n\trt6_disable_ip(dev, event);\n\n\tidev = __in6_dev_get(dev);\n\tif (!idev)\n\t\treturn -ENODEV;\n\n\t/*\n\t * Step 1: remove reference to ipv6 device from parent device.\n\t *\t   Do not dev_put!\n\t */\n\tif (unregister) {\n\t\tidev->dead = 1;\n\n\t\t/* protected by rtnl_lock */\n\t\tRCU_INIT_POINTER(dev->ip6_ptr, NULL);\n\n\t\t/* Step 1.5: remove snmp6 entry */\n\t\tsnmp6_unregister_dev(idev);\n\n\t}\n\n\t/* combine the user config with event to determine if permanent\n\t * addresses are to be removed from address hash table\n\t */\n\tif (!unregister && !idev->cnf.disable_ipv6) {\n\t\t/* aggregate the system setting and interface setting */\n\t\tint _keep_addr = net->ipv6.devconf_all->keep_addr_on_down;\n\n\t\tif (!_keep_addr)\n\t\t\t_keep_addr = idev->cnf.keep_addr_on_down;\n\n\t\tkeep_addr = (_keep_addr > 0);\n\t}\n\n\t/* Step 2: clear hash table */\n\tfor (i = 0; i < IN6_ADDR_HSIZE; i++) {\n\t\tstruct hlist_head *h = &inet6_addr_lst[i];\n\n\t\tspin_lock_bh(&addrconf_hash_lock);\nrestart:\n\t\thlist_for_each_entry_rcu(ifa, h, addr_lst) {\n\t\t\tif (ifa->idev == idev) {\n\t\t\t\taddrconf_del_dad_work(ifa);\n\t\t\t\t/* combined flag + permanent flag decide if\n\t\t\t\t * address is retained on a down event\n\t\t\t\t */\n\t\t\t\tif (!keep_addr ||\n\t\t\t\t    !(ifa->flags & IFA_F_PERMANENT) ||\n\t\t\t\t    addr_is_local(&ifa->addr)) {\n\t\t\t\t\thlist_del_init_rcu(&ifa->addr_lst);\n\t\t\t\t\tgoto restart;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tspin_unlock_bh(&addrconf_hash_lock);\n\t}\n\n\twrite_lock_bh(&idev->lock);\n\n\taddrconf_del_rs_timer(idev);\n\n\t/* Step 2: clear flags for stateless addrconf */\n\tif (!unregister)\n\t\tidev->if_flags &= ~(IF_RS_SENT|IF_RA_RCVD|IF_READY);\n\n\t/* Step 3: clear tempaddr list */\n\twhile (!list_empty(&idev->tempaddr_list)) {\n\t\tifa = list_first_entry(&idev->tempaddr_list,\n\t\t\t\t       struct inet6_ifaddr, tmp_list);\n\t\tlist_del(&ifa->tmp_list);\n\t\twrite_unlock_bh(&idev->lock);\n\t\tspin_lock_bh(&ifa->lock);\n\n\t\tif (ifa->ifpub) {\n\t\t\tin6_ifa_put(ifa->ifpub);\n\t\t\tifa->ifpub = NULL;\n\t\t}\n\t\tspin_unlock_bh(&ifa->lock);\n\t\tin6_ifa_put(ifa);\n\t\twrite_lock_bh(&idev->lock);\n\t}\n\n\tlist_for_each_entry_safe(ifa, tmp, &idev->addr_list, if_list) {\n\t\tstruct fib6_info *rt = NULL;\n\t\tbool keep;\n\n\t\taddrconf_del_dad_work(ifa);\n\n\t\tkeep = keep_addr && (ifa->flags & IFA_F_PERMANENT) &&\n\t\t\t!addr_is_local(&ifa->addr);\n\n\t\twrite_unlock_bh(&idev->lock);\n\t\tspin_lock_bh(&ifa->lock);\n\n\t\tif (keep) {\n\t\t\t/* set state to skip the notifier below */\n\t\t\tstate = INET6_IFADDR_STATE_DEAD;\n\t\t\tifa->state = INET6_IFADDR_STATE_PREDAD;\n\t\t\tif (!(ifa->flags & IFA_F_NODAD))\n\t\t\t\tifa->flags |= IFA_F_TENTATIVE;\n\n\t\t\trt = ifa->rt;\n\t\t\tifa->rt = NULL;\n\t\t} else {\n\t\t\tstate = ifa->state;\n\t\t\tifa->state = INET6_IFADDR_STATE_DEAD;\n\t\t}\n\n\t\tspin_unlock_bh(&ifa->lock);\n\n\t\tif (rt)\n\t\t\tip6_del_rt(net, rt, false);\n\n\t\tif (state != INET6_IFADDR_STATE_DEAD) {\n\t\t\t__ipv6_ifa_notify(RTM_DELADDR, ifa);\n\t\t\tinet6addr_notifier_call_chain(NETDEV_DOWN, ifa);\n\t\t} else {\n\t\t\tif (idev->cnf.forwarding)\n\t\t\t\taddrconf_leave_anycast(ifa);\n\t\t\taddrconf_leave_solict(ifa->idev, &ifa->addr);\n\t\t}\n\n\t\twrite_lock_bh(&idev->lock);\n\t\tif (!keep) {\n\t\t\tlist_del_rcu(&ifa->if_list);\n\t\t\tin6_ifa_put(ifa);\n\t\t}\n\t}\n\n\twrite_unlock_bh(&idev->lock);\n\n\t/* Step 5: Discard anycast and multicast list */\n\tif (unregister) {\n\t\tipv6_ac_destroy_dev(idev);\n\t\tipv6_mc_destroy_dev(idev);\n\t} else {\n\t\tipv6_mc_down(idev);\n\t}\n\n\tidev->tstamp = jiffies;\n\n\t/* Last: Shot the device (if unregistered) */\n\tif (unregister) {\n\t\taddrconf_sysctl_unregister(idev);\n\t\tneigh_parms_release(&nd_tbl, idev->nd_parms);\n\t\tneigh_ifdown(&nd_tbl, dev);\n\t\tin6_dev_put(idev);\n\t}\n\treturn 0;\n}\n\nstatic void addrconf_rs_timer(struct timer_list *t)\n{\n\tstruct inet6_dev *idev = from_timer(idev, t, rs_timer);\n\tstruct net_device *dev = idev->dev;\n\tstruct in6_addr lladdr;\n\n\twrite_lock(&idev->lock);\n\tif (idev->dead || !(idev->if_flags & IF_READY))\n\t\tgoto out;\n\n\tif (!ipv6_accept_ra(idev))\n\t\tgoto out;\n\n\t/* Announcement received after solicitation was sent */\n\tif (idev->if_flags & IF_RA_RCVD)\n\t\tgoto out;\n\n\tif (idev->rs_probes++ < idev->cnf.rtr_solicits || idev->cnf.rtr_solicits < 0) {\n\t\twrite_unlock(&idev->lock);\n\t\tif (!ipv6_get_lladdr(dev, &lladdr, IFA_F_TENTATIVE))\n\t\t\tndisc_send_rs(dev, &lladdr,\n\t\t\t\t      &in6addr_linklocal_allrouters);\n\t\telse\n\t\t\tgoto put;\n\n\t\twrite_lock(&idev->lock);\n\t\tidev->rs_interval = rfc3315_s14_backoff_update(\n\t\t\tidev->rs_interval, idev->cnf.rtr_solicit_max_interval);\n\t\t/* The wait after the last probe can be shorter */\n\t\taddrconf_mod_rs_timer(idev, (idev->rs_probes ==\n\t\t\t\t\t     idev->cnf.rtr_solicits) ?\n\t\t\t\t      idev->cnf.rtr_solicit_delay :\n\t\t\t\t      idev->rs_interval);\n\t} else {\n\t\t/*\n\t\t * Note: we do not support deprecated \"all on-link\"\n\t\t * assumption any longer.\n\t\t */\n\t\tpr_debug(\"%s: no IPv6 routers present\\n\", idev->dev->name);\n\t}\n\nout:\n\twrite_unlock(&idev->lock);\nput:\n\tin6_dev_put(idev);\n}\n\n/*\n *\tDuplicate Address Detection\n */\nstatic void addrconf_dad_kick(struct inet6_ifaddr *ifp)\n{\n\tunsigned long rand_num;\n\tstruct inet6_dev *idev = ifp->idev;\n\tu64 nonce;\n\n\tif (ifp->flags & IFA_F_OPTIMISTIC)\n\t\trand_num = 0;\n\telse\n\t\trand_num = prandom_u32() % (idev->cnf.rtr_solicit_delay ? : 1);\n\n\tnonce = 0;\n\tif (idev->cnf.enhanced_dad ||\n\t    dev_net(idev->dev)->ipv6.devconf_all->enhanced_dad) {\n\t\tdo\n\t\t\tget_random_bytes(&nonce, 6);\n\t\twhile (nonce == 0);\n\t}\n\tifp->dad_nonce = nonce;\n\tifp->dad_probes = idev->cnf.dad_transmits;\n\taddrconf_mod_dad_work(ifp, rand_num);\n}\n\nstatic void addrconf_dad_begin(struct inet6_ifaddr *ifp)\n{\n\tstruct inet6_dev *idev = ifp->idev;\n\tstruct net_device *dev = idev->dev;\n\tbool bump_id, notify = false;\n\tstruct net *net;\n\n\taddrconf_join_solict(dev, &ifp->addr);\n\n\tprandom_seed((__force u32) ifp->addr.s6_addr32[3]);\n\n\tread_lock_bh(&idev->lock);\n\tspin_lock(&ifp->lock);\n\tif (ifp->state == INET6_IFADDR_STATE_DEAD)\n\t\tgoto out;\n\n\tnet = dev_net(dev);\n\tif (dev->flags&(IFF_NOARP|IFF_LOOPBACK) ||\n\t    (net->ipv6.devconf_all->accept_dad < 1 &&\n\t     idev->cnf.accept_dad < 1) ||\n\t    !(ifp->flags&IFA_F_TENTATIVE) ||\n\t    ifp->flags & IFA_F_NODAD) {\n\t\tbool send_na = false;\n\n\t\tif (ifp->flags & IFA_F_TENTATIVE &&\n\t\t    !(ifp->flags & IFA_F_OPTIMISTIC))\n\t\t\tsend_na = true;\n\t\tbump_id = ifp->flags & IFA_F_TENTATIVE;\n\t\tifp->flags &= ~(IFA_F_TENTATIVE|IFA_F_OPTIMISTIC|IFA_F_DADFAILED);\n\t\tspin_unlock(&ifp->lock);\n\t\tread_unlock_bh(&idev->lock);\n\n\t\taddrconf_dad_completed(ifp, bump_id, send_na);\n\t\treturn;\n\t}\n\n\tif (!(idev->if_flags & IF_READY)) {\n\t\tspin_unlock(&ifp->lock);\n\t\tread_unlock_bh(&idev->lock);\n\t\t/*\n\t\t * If the device is not ready:\n\t\t * - keep it tentative if it is a permanent address.\n\t\t * - otherwise, kill it.\n\t\t */\n\t\tin6_ifa_hold(ifp);\n\t\taddrconf_dad_stop(ifp, 0);\n\t\treturn;\n\t}\n\n\t/*\n\t * Optimistic nodes can start receiving\n\t * Frames right away\n\t */\n\tif (ifp->flags & IFA_F_OPTIMISTIC) {\n\t\tip6_ins_rt(net, ifp->rt);\n\t\tif (ipv6_use_optimistic_addr(net, idev)) {\n\t\t\t/* Because optimistic nodes can use this address,\n\t\t\t * notify listeners. If DAD fails, RTM_DELADDR is sent.\n\t\t\t */\n\t\t\tnotify = true;\n\t\t}\n\t}\n\n\taddrconf_dad_kick(ifp);\nout:\n\tspin_unlock(&ifp->lock);\n\tread_unlock_bh(&idev->lock);\n\tif (notify)\n\t\tipv6_ifa_notify(RTM_NEWADDR, ifp);\n}\n\nstatic void addrconf_dad_start(struct inet6_ifaddr *ifp)\n{\n\tbool begin_dad = false;\n\n\tspin_lock_bh(&ifp->lock);\n\tif (ifp->state != INET6_IFADDR_STATE_DEAD) {\n\t\tifp->state = INET6_IFADDR_STATE_PREDAD;\n\t\tbegin_dad = true;\n\t}\n\tspin_unlock_bh(&ifp->lock);\n\n\tif (begin_dad)\n\t\taddrconf_mod_dad_work(ifp, 0);\n}\n\nstatic void addrconf_dad_work(struct work_struct *w)\n{\n\tstruct inet6_ifaddr *ifp = container_of(to_delayed_work(w),\n\t\t\t\t\t\tstruct inet6_ifaddr,\n\t\t\t\t\t\tdad_work);\n\tstruct inet6_dev *idev = ifp->idev;\n\tbool bump_id, disable_ipv6 = false;\n\tstruct in6_addr mcaddr;\n\n\tenum {\n\t\tDAD_PROCESS,\n\t\tDAD_BEGIN,\n\t\tDAD_ABORT,\n\t} action = DAD_PROCESS;\n\n\trtnl_lock();\n\n\tspin_lock_bh(&ifp->lock);\n\tif (ifp->state == INET6_IFADDR_STATE_PREDAD) {\n\t\taction = DAD_BEGIN;\n\t\tifp->state = INET6_IFADDR_STATE_DAD;\n\t} else if (ifp->state == INET6_IFADDR_STATE_ERRDAD) {\n\t\taction = DAD_ABORT;\n\t\tifp->state = INET6_IFADDR_STATE_POSTDAD;\n\n\t\tif ((dev_net(idev->dev)->ipv6.devconf_all->accept_dad > 1 ||\n\t\t     idev->cnf.accept_dad > 1) &&\n\t\t    !idev->cnf.disable_ipv6 &&\n\t\t    !(ifp->flags & IFA_F_STABLE_PRIVACY)) {\n\t\t\tstruct in6_addr addr;\n\n\t\t\taddr.s6_addr32[0] = htonl(0xfe800000);\n\t\t\taddr.s6_addr32[1] = 0;\n\n\t\t\tif (!ipv6_generate_eui64(addr.s6_addr + 8, idev->dev) &&\n\t\t\t    ipv6_addr_equal(&ifp->addr, &addr)) {\n\t\t\t\t/* DAD failed for link-local based on MAC */\n\t\t\t\tidev->cnf.disable_ipv6 = 1;\n\n\t\t\t\tpr_info(\"%s: IPv6 being disabled!\\n\",\n\t\t\t\t\tifp->idev->dev->name);\n\t\t\t\tdisable_ipv6 = true;\n\t\t\t}\n\t\t}\n\t}\n\tspin_unlock_bh(&ifp->lock);\n\n\tif (action == DAD_BEGIN) {\n\t\taddrconf_dad_begin(ifp);\n\t\tgoto out;\n\t} else if (action == DAD_ABORT) {\n\t\tin6_ifa_hold(ifp);\n\t\taddrconf_dad_stop(ifp, 1);\n\t\tif (disable_ipv6)\n\t\t\taddrconf_ifdown(idev->dev, false);\n\t\tgoto out;\n\t}\n\n\tif (!ifp->dad_probes && addrconf_dad_end(ifp))\n\t\tgoto out;\n\n\twrite_lock_bh(&idev->lock);\n\tif (idev->dead || !(idev->if_flags & IF_READY)) {\n\t\twrite_unlock_bh(&idev->lock);\n\t\tgoto out;\n\t}\n\n\tspin_lock(&ifp->lock);\n\tif (ifp->state == INET6_IFADDR_STATE_DEAD) {\n\t\tspin_unlock(&ifp->lock);\n\t\twrite_unlock_bh(&idev->lock);\n\t\tgoto out;\n\t}\n\n\tif (ifp->dad_probes == 0) {\n\t\tbool send_na = false;\n\n\t\t/*\n\t\t * DAD was successful\n\t\t */\n\n\t\tif (ifp->flags & IFA_F_TENTATIVE &&\n\t\t    !(ifp->flags & IFA_F_OPTIMISTIC))\n\t\t\tsend_na = true;\n\t\tbump_id = ifp->flags & IFA_F_TENTATIVE;\n\t\tifp->flags &= ~(IFA_F_TENTATIVE|IFA_F_OPTIMISTIC|IFA_F_DADFAILED);\n\t\tspin_unlock(&ifp->lock);\n\t\twrite_unlock_bh(&idev->lock);\n\n\t\taddrconf_dad_completed(ifp, bump_id, send_na);\n\n\t\tgoto out;\n\t}\n\n\tifp->dad_probes--;\n\taddrconf_mod_dad_work(ifp,\n\t\t\t      max(NEIGH_VAR(ifp->idev->nd_parms, RETRANS_TIME),\n\t\t\t\t  HZ/100));\n\tspin_unlock(&ifp->lock);\n\twrite_unlock_bh(&idev->lock);\n\n\t/* send a neighbour solicitation for our addr */\n\taddrconf_addr_solict_mult(&ifp->addr, &mcaddr);\n\tndisc_send_ns(ifp->idev->dev, &ifp->addr, &mcaddr, &in6addr_any,\n\t\t      ifp->dad_nonce);\nout:\n\tin6_ifa_put(ifp);\n\trtnl_unlock();\n}\n\n/* ifp->idev must be at least read locked */\nstatic bool ipv6_lonely_lladdr(struct inet6_ifaddr *ifp)\n{\n\tstruct inet6_ifaddr *ifpiter;\n\tstruct inet6_dev *idev = ifp->idev;\n\n\tlist_for_each_entry_reverse(ifpiter, &idev->addr_list, if_list) {\n\t\tif (ifpiter->scope > IFA_LINK)\n\t\t\tbreak;\n\t\tif (ifp != ifpiter && ifpiter->scope == IFA_LINK &&\n\t\t    (ifpiter->flags & (IFA_F_PERMANENT|IFA_F_TENTATIVE|\n\t\t\t\t       IFA_F_OPTIMISTIC|IFA_F_DADFAILED)) ==\n\t\t    IFA_F_PERMANENT)\n\t\t\treturn false;\n\t}\n\treturn true;\n}\n\nstatic void addrconf_dad_completed(struct inet6_ifaddr *ifp, bool bump_id,\n\t\t\t\t   bool send_na)\n{\n\tstruct net_device *dev = ifp->idev->dev;\n\tstruct in6_addr lladdr;\n\tbool send_rs, send_mld;\n\n\taddrconf_del_dad_work(ifp);\n\n\t/*\n\t *\tConfigure the address for reception. Now it is valid.\n\t */\n\n\tipv6_ifa_notify(RTM_NEWADDR, ifp);\n\n\t/* If added prefix is link local and we are prepared to process\n\t   router advertisements, start sending router solicitations.\n\t */\n\n\tread_lock_bh(&ifp->idev->lock);\n\tsend_mld = ifp->scope == IFA_LINK && ipv6_lonely_lladdr(ifp);\n\tsend_rs = send_mld &&\n\t\t  ipv6_accept_ra(ifp->idev) &&\n\t\t  ifp->idev->cnf.rtr_solicits != 0 &&\n\t\t  (dev->flags&IFF_LOOPBACK) == 0;\n\tread_unlock_bh(&ifp->idev->lock);\n\n\t/* While dad is in progress mld report's source address is in6_addrany.\n\t * Resend with proper ll now.\n\t */\n\tif (send_mld)\n\t\tipv6_mc_dad_complete(ifp->idev);\n\n\t/* send unsolicited NA if enabled */\n\tif (send_na &&\n\t    (ifp->idev->cnf.ndisc_notify ||\n\t     dev_net(dev)->ipv6.devconf_all->ndisc_notify)) {\n\t\tndisc_send_na(dev, &in6addr_linklocal_allnodes, &ifp->addr,\n\t\t\t      /*router=*/ !!ifp->idev->cnf.forwarding,\n\t\t\t      /*solicited=*/ false, /*override=*/ true,\n\t\t\t      /*inc_opt=*/ true);\n\t}\n\n\tif (send_rs) {\n\t\t/*\n\t\t *\tIf a host as already performed a random delay\n\t\t *\t[...] as part of DAD [...] there is no need\n\t\t *\tto delay again before sending the first RS\n\t\t */\n\t\tif (ipv6_get_lladdr(dev, &lladdr, IFA_F_TENTATIVE))\n\t\t\treturn;\n\t\tndisc_send_rs(dev, &lladdr, &in6addr_linklocal_allrouters);\n\n\t\twrite_lock_bh(&ifp->idev->lock);\n\t\tspin_lock(&ifp->lock);\n\t\tifp->idev->rs_interval = rfc3315_s14_backoff_init(\n\t\t\tifp->idev->cnf.rtr_solicit_interval);\n\t\tifp->idev->rs_probes = 1;\n\t\tifp->idev->if_flags |= IF_RS_SENT;\n\t\taddrconf_mod_rs_timer(ifp->idev, ifp->idev->rs_interval);\n\t\tspin_unlock(&ifp->lock);\n\t\twrite_unlock_bh(&ifp->idev->lock);\n\t}\n\n\tif (bump_id)\n\t\trt_genid_bump_ipv6(dev_net(dev));\n\n\t/* Make sure that a new temporary address will be created\n\t * before this temporary address becomes deprecated.\n\t */\n\tif (ifp->flags & IFA_F_TEMPORARY)\n\t\taddrconf_verify_rtnl();\n}\n\nstatic void addrconf_dad_run(struct inet6_dev *idev, bool restart)\n{\n\tstruct inet6_ifaddr *ifp;\n\n\tread_lock_bh(&idev->lock);\n\tlist_for_each_entry(ifp, &idev->addr_list, if_list) {\n\t\tspin_lock(&ifp->lock);\n\t\tif ((ifp->flags & IFA_F_TENTATIVE &&\n\t\t     ifp->state == INET6_IFADDR_STATE_DAD) || restart) {\n\t\t\tif (restart)\n\t\t\t\tifp->state = INET6_IFADDR_STATE_PREDAD;\n\t\t\taddrconf_dad_kick(ifp);\n\t\t}\n\t\tspin_unlock(&ifp->lock);\n\t}\n\tread_unlock_bh(&idev->lock);\n}\n\n#ifdef CONFIG_PROC_FS\nstruct if6_iter_state {\n\tstruct seq_net_private p;\n\tint bucket;\n\tint offset;\n};\n\nstatic struct inet6_ifaddr *if6_get_first(struct seq_file *seq, loff_t pos)\n{\n\tstruct if6_iter_state *state = seq->private;\n\tstruct net *net = seq_file_net(seq);\n\tstruct inet6_ifaddr *ifa = NULL;\n\tint p = 0;\n\n\t/* initial bucket if pos is 0 */\n\tif (pos == 0) {\n\t\tstate->bucket = 0;\n\t\tstate->offset = 0;\n\t}\n\n\tfor (; state->bucket < IN6_ADDR_HSIZE; ++state->bucket) {\n\t\thlist_for_each_entry_rcu(ifa, &inet6_addr_lst[state->bucket],\n\t\t\t\t\t addr_lst) {\n\t\t\tif (!net_eq(dev_net(ifa->idev->dev), net))\n\t\t\t\tcontinue;\n\t\t\t/* sync with offset */\n\t\t\tif (p < state->offset) {\n\t\t\t\tp++;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\treturn ifa;\n\t\t}\n\n\t\t/* prepare for next bucket */\n\t\tstate->offset = 0;\n\t\tp = 0;\n\t}\n\treturn NULL;\n}\n\nstatic struct inet6_ifaddr *if6_get_next(struct seq_file *seq,\n\t\t\t\t\t struct inet6_ifaddr *ifa)\n{\n\tstruct if6_iter_state *state = seq->private;\n\tstruct net *net = seq_file_net(seq);\n\n\thlist_for_each_entry_continue_rcu(ifa, addr_lst) {\n\t\tif (!net_eq(dev_net(ifa->idev->dev), net))\n\t\t\tcontinue;\n\t\tstate->offset++;\n\t\treturn ifa;\n\t}\n\n\tstate->offset = 0;\n\twhile (++state->bucket < IN6_ADDR_HSIZE) {\n\t\thlist_for_each_entry_rcu(ifa,\n\t\t\t\t     &inet6_addr_lst[state->bucket], addr_lst) {\n\t\t\tif (!net_eq(dev_net(ifa->idev->dev), net))\n\t\t\t\tcontinue;\n\t\t\treturn ifa;\n\t\t}\n\t}\n\n\treturn NULL;\n}\n\nstatic void *if6_seq_start(struct seq_file *seq, loff_t *pos)\n\t__acquires(rcu)\n{\n\trcu_read_lock();\n\treturn if6_get_first(seq, *pos);\n}\n\nstatic void *if6_seq_next(struct seq_file *seq, void *v, loff_t *pos)\n{\n\tstruct inet6_ifaddr *ifa;\n\n\tifa = if6_get_next(seq, v);\n\t++*pos;\n\treturn ifa;\n}\n\nstatic void if6_seq_stop(struct seq_file *seq, void *v)\n\t__releases(rcu)\n{\n\trcu_read_unlock();\n}\n\nstatic int if6_seq_show(struct seq_file *seq, void *v)\n{\n\tstruct inet6_ifaddr *ifp = (struct inet6_ifaddr *)v;\n\tseq_printf(seq, \"%pi6 %02x %02x %02x %02x %8s\\n\",\n\t\t   &ifp->addr,\n\t\t   ifp->idev->dev->ifindex,\n\t\t   ifp->prefix_len,\n\t\t   ifp->scope,\n\t\t   (u8) ifp->flags,\n\t\t   ifp->idev->dev->name);\n\treturn 0;\n}\n\nstatic const struct seq_operations if6_seq_ops = {\n\t.start\t= if6_seq_start,\n\t.next\t= if6_seq_next,\n\t.show\t= if6_seq_show,\n\t.stop\t= if6_seq_stop,\n};\n\nstatic int __net_init if6_proc_net_init(struct net *net)\n{\n\tif (!proc_create_net(\"if_inet6\", 0444, net->proc_net, &if6_seq_ops,\n\t\t\tsizeof(struct if6_iter_state)))\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\nstatic void __net_exit if6_proc_net_exit(struct net *net)\n{\n\tremove_proc_entry(\"if_inet6\", net->proc_net);\n}\n\nstatic struct pernet_operations if6_proc_net_ops = {\n\t.init = if6_proc_net_init,\n\t.exit = if6_proc_net_exit,\n};\n\nint __init if6_proc_init(void)\n{\n\treturn register_pernet_subsys(&if6_proc_net_ops);\n}\n\nvoid if6_proc_exit(void)\n{\n\tunregister_pernet_subsys(&if6_proc_net_ops);\n}\n#endif\t/* CONFIG_PROC_FS */\n\n#if IS_ENABLED(CONFIG_IPV6_MIP6)\n/* Check if address is a home address configured on any interface. */\nint ipv6_chk_home_addr(struct net *net, const struct in6_addr *addr)\n{\n\tunsigned int hash = inet6_addr_hash(net, addr);\n\tstruct inet6_ifaddr *ifp = NULL;\n\tint ret = 0;\n\n\trcu_read_lock();\n\thlist_for_each_entry_rcu(ifp, &inet6_addr_lst[hash], addr_lst) {\n\t\tif (!net_eq(dev_net(ifp->idev->dev), net))\n\t\t\tcontinue;\n\t\tif (ipv6_addr_equal(&ifp->addr, addr) &&\n\t\t    (ifp->flags & IFA_F_HOMEADDRESS)) {\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\t}\n\trcu_read_unlock();\n\treturn ret;\n}\n#endif\n\n/* RFC6554 has some algorithm to avoid loops in segment routing by\n * checking if the segments contains any of a local interface address.\n *\n * Quote:\n *\n * To detect loops in the SRH, a router MUST determine if the SRH\n * includes multiple addresses assigned to any interface on that router.\n * If such addresses appear more than once and are separated by at least\n * one address not assigned to that router.\n */\nint ipv6_chk_rpl_srh_loop(struct net *net, const struct in6_addr *segs,\n\t\t\t  unsigned char nsegs)\n{\n\tconst struct in6_addr *addr;\n\tint i, ret = 0, found = 0;\n\tstruct inet6_ifaddr *ifp;\n\tbool separated = false;\n\tunsigned int hash;\n\tbool hash_found;\n\n\trcu_read_lock();\n\tfor (i = 0; i < nsegs; i++) {\n\t\taddr = &segs[i];\n\t\thash = inet6_addr_hash(net, addr);\n\n\t\thash_found = false;\n\t\thlist_for_each_entry_rcu(ifp, &inet6_addr_lst[hash], addr_lst) {\n\t\t\tif (!net_eq(dev_net(ifp->idev->dev), net))\n\t\t\t\tcontinue;\n\n\t\t\tif (ipv6_addr_equal(&ifp->addr, addr)) {\n\t\t\t\thash_found = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (hash_found) {\n\t\t\tif (found > 1 && separated) {\n\t\t\t\tret = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tseparated = false;\n\t\t\tfound++;\n\t\t} else {\n\t\t\tseparated = true;\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\treturn ret;\n}\n\n/*\n *\tPeriodic address status verification\n */\n\nstatic void addrconf_verify_rtnl(void)\n{\n\tunsigned long now, next, next_sec, next_sched;\n\tstruct inet6_ifaddr *ifp;\n\tint i;\n\n\tASSERT_RTNL();\n\n\trcu_read_lock_bh();\n\tnow = jiffies;\n\tnext = round_jiffies_up(now + ADDR_CHECK_FREQUENCY);\n\n\tcancel_delayed_work(&addr_chk_work);\n\n\tfor (i = 0; i < IN6_ADDR_HSIZE; i++) {\nrestart:\n\t\thlist_for_each_entry_rcu_bh(ifp, &inet6_addr_lst[i], addr_lst) {\n\t\t\tunsigned long age;\n\n\t\t\t/* When setting preferred_lft to a value not zero or\n\t\t\t * infinity, while valid_lft is infinity\n\t\t\t * IFA_F_PERMANENT has a non-infinity life time.\n\t\t\t */\n\t\t\tif ((ifp->flags & IFA_F_PERMANENT) &&\n\t\t\t    (ifp->prefered_lft == INFINITY_LIFE_TIME))\n\t\t\t\tcontinue;\n\n\t\t\tspin_lock(&ifp->lock);\n\t\t\t/* We try to batch several events at once. */\n\t\t\tage = (now - ifp->tstamp + ADDRCONF_TIMER_FUZZ_MINUS) / HZ;\n\n\t\t\tif (ifp->valid_lft != INFINITY_LIFE_TIME &&\n\t\t\t    age >= ifp->valid_lft) {\n\t\t\t\tspin_unlock(&ifp->lock);\n\t\t\t\tin6_ifa_hold(ifp);\n\t\t\t\tipv6_del_addr(ifp);\n\t\t\t\tgoto restart;\n\t\t\t} else if (ifp->prefered_lft == INFINITY_LIFE_TIME) {\n\t\t\t\tspin_unlock(&ifp->lock);\n\t\t\t\tcontinue;\n\t\t\t} else if (age >= ifp->prefered_lft) {\n\t\t\t\t/* jiffies - ifp->tstamp > age >= ifp->prefered_lft */\n\t\t\t\tint deprecate = 0;\n\n\t\t\t\tif (!(ifp->flags&IFA_F_DEPRECATED)) {\n\t\t\t\t\tdeprecate = 1;\n\t\t\t\t\tifp->flags |= IFA_F_DEPRECATED;\n\t\t\t\t}\n\n\t\t\t\tif ((ifp->valid_lft != INFINITY_LIFE_TIME) &&\n\t\t\t\t    (time_before(ifp->tstamp + ifp->valid_lft * HZ, next)))\n\t\t\t\t\tnext = ifp->tstamp + ifp->valid_lft * HZ;\n\n\t\t\t\tspin_unlock(&ifp->lock);\n\n\t\t\t\tif (deprecate) {\n\t\t\t\t\tin6_ifa_hold(ifp);\n\n\t\t\t\t\tipv6_ifa_notify(0, ifp);\n\t\t\t\t\tin6_ifa_put(ifp);\n\t\t\t\t\tgoto restart;\n\t\t\t\t}\n\t\t\t} else if ((ifp->flags&IFA_F_TEMPORARY) &&\n\t\t\t\t   !(ifp->flags&IFA_F_TENTATIVE)) {\n\t\t\t\tunsigned long regen_advance = ifp->idev->cnf.regen_max_retry *\n\t\t\t\t\tifp->idev->cnf.dad_transmits *\n\t\t\t\t\tmax(NEIGH_VAR(ifp->idev->nd_parms, RETRANS_TIME), HZ/100) / HZ;\n\n\t\t\t\tif (age >= ifp->prefered_lft - regen_advance) {\n\t\t\t\t\tstruct inet6_ifaddr *ifpub = ifp->ifpub;\n\t\t\t\t\tif (time_before(ifp->tstamp + ifp->prefered_lft * HZ, next))\n\t\t\t\t\t\tnext = ifp->tstamp + ifp->prefered_lft * HZ;\n\t\t\t\t\tif (!ifp->regen_count && ifpub) {\n\t\t\t\t\t\tifp->regen_count++;\n\t\t\t\t\t\tin6_ifa_hold(ifp);\n\t\t\t\t\t\tin6_ifa_hold(ifpub);\n\t\t\t\t\t\tspin_unlock(&ifp->lock);\n\n\t\t\t\t\t\tspin_lock(&ifpub->lock);\n\t\t\t\t\t\tifpub->regen_count = 0;\n\t\t\t\t\t\tspin_unlock(&ifpub->lock);\n\t\t\t\t\t\trcu_read_unlock_bh();\n\t\t\t\t\t\tipv6_create_tempaddr(ifpub, true);\n\t\t\t\t\t\tin6_ifa_put(ifpub);\n\t\t\t\t\t\tin6_ifa_put(ifp);\n\t\t\t\t\t\trcu_read_lock_bh();\n\t\t\t\t\t\tgoto restart;\n\t\t\t\t\t}\n\t\t\t\t} else if (time_before(ifp->tstamp + ifp->prefered_lft * HZ - regen_advance * HZ, next))\n\t\t\t\t\tnext = ifp->tstamp + ifp->prefered_lft * HZ - regen_advance * HZ;\n\t\t\t\tspin_unlock(&ifp->lock);\n\t\t\t} else {\n\t\t\t\t/* ifp->prefered_lft <= ifp->valid_lft */\n\t\t\t\tif (time_before(ifp->tstamp + ifp->prefered_lft * HZ, next))\n\t\t\t\t\tnext = ifp->tstamp + ifp->prefered_lft * HZ;\n\t\t\t\tspin_unlock(&ifp->lock);\n\t\t\t}\n\t\t}\n\t}\n\n\tnext_sec = round_jiffies_up(next);\n\tnext_sched = next;\n\n\t/* If rounded timeout is accurate enough, accept it. */\n\tif (time_before(next_sec, next + ADDRCONF_TIMER_FUZZ))\n\t\tnext_sched = next_sec;\n\n\t/* And minimum interval is ADDRCONF_TIMER_FUZZ_MAX. */\n\tif (time_before(next_sched, jiffies + ADDRCONF_TIMER_FUZZ_MAX))\n\t\tnext_sched = jiffies + ADDRCONF_TIMER_FUZZ_MAX;\n\n\tpr_debug(\"now = %lu, schedule = %lu, rounded schedule = %lu => %lu\\n\",\n\t\t now, next, next_sec, next_sched);\n\tmod_delayed_work(addrconf_wq, &addr_chk_work, next_sched - now);\n\trcu_read_unlock_bh();\n}\n\nstatic void addrconf_verify_work(struct work_struct *w)\n{\n\trtnl_lock();\n\taddrconf_verify_rtnl();\n\trtnl_unlock();\n}\n\nstatic void addrconf_verify(void)\n{\n\tmod_delayed_work(addrconf_wq, &addr_chk_work, 0);\n}\n\nstatic struct in6_addr *extract_addr(struct nlattr *addr, struct nlattr *local,\n\t\t\t\t     struct in6_addr **peer_pfx)\n{\n\tstruct in6_addr *pfx = NULL;\n\n\t*peer_pfx = NULL;\n\n\tif (addr)\n\t\tpfx = nla_data(addr);\n\n\tif (local) {\n\t\tif (pfx && nla_memcmp(local, pfx, sizeof(*pfx)))\n\t\t\t*peer_pfx = pfx;\n\t\tpfx = nla_data(local);\n\t}\n\n\treturn pfx;\n}\n\nstatic const struct nla_policy ifa_ipv6_policy[IFA_MAX+1] = {\n\t[IFA_ADDRESS]\t\t= { .len = sizeof(struct in6_addr) },\n\t[IFA_LOCAL]\t\t= { .len = sizeof(struct in6_addr) },\n\t[IFA_CACHEINFO]\t\t= { .len = sizeof(struct ifa_cacheinfo) },\n\t[IFA_FLAGS]\t\t= { .len = sizeof(u32) },\n\t[IFA_RT_PRIORITY]\t= { .len = sizeof(u32) },\n\t[IFA_TARGET_NETNSID]\t= { .type = NLA_S32 },\n};\n\nstatic int\ninet6_rtm_deladdr(struct sk_buff *skb, struct nlmsghdr *nlh,\n\t\t  struct netlink_ext_ack *extack)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct ifaddrmsg *ifm;\n\tstruct nlattr *tb[IFA_MAX+1];\n\tstruct in6_addr *pfx, *peer_pfx;\n\tu32 ifa_flags;\n\tint err;\n\n\terr = nlmsg_parse_deprecated(nlh, sizeof(*ifm), tb, IFA_MAX,\n\t\t\t\t     ifa_ipv6_policy, extack);\n\tif (err < 0)\n\t\treturn err;\n\n\tifm = nlmsg_data(nlh);\n\tpfx = extract_addr(tb[IFA_ADDRESS], tb[IFA_LOCAL], &peer_pfx);\n\tif (!pfx)\n\t\treturn -EINVAL;\n\n\tifa_flags = tb[IFA_FLAGS] ? nla_get_u32(tb[IFA_FLAGS]) : ifm->ifa_flags;\n\n\t/* We ignore other flags so far. */\n\tifa_flags &= IFA_F_MANAGETEMPADDR;\n\n\treturn inet6_addr_del(net, ifm->ifa_index, ifa_flags, pfx,\n\t\t\t      ifm->ifa_prefixlen);\n}\n\nstatic int modify_prefix_route(struct inet6_ifaddr *ifp,\n\t\t\t       unsigned long expires, u32 flags,\n\t\t\t       bool modify_peer)\n{\n\tstruct fib6_info *f6i;\n\tu32 prio;\n\n\tf6i = addrconf_get_prefix_route(modify_peer ? &ifp->peer_addr : &ifp->addr,\n\t\t\t\t\tifp->prefix_len,\n\t\t\t\t\tifp->idev->dev, 0, RTF_DEFAULT, true);\n\tif (!f6i)\n\t\treturn -ENOENT;\n\n\tprio = ifp->rt_priority ? : IP6_RT_PRIO_ADDRCONF;\n\tif (f6i->fib6_metric != prio) {\n\t\t/* delete old one */\n\t\tip6_del_rt(dev_net(ifp->idev->dev), f6i, false);\n\n\t\t/* add new one */\n\t\taddrconf_prefix_route(modify_peer ? &ifp->peer_addr : &ifp->addr,\n\t\t\t\t      ifp->prefix_len,\n\t\t\t\t      ifp->rt_priority, ifp->idev->dev,\n\t\t\t\t      expires, flags, GFP_KERNEL);\n\t} else {\n\t\tif (!expires)\n\t\t\tfib6_clean_expires(f6i);\n\t\telse\n\t\t\tfib6_set_expires(f6i, expires);\n\n\t\tfib6_info_release(f6i);\n\t}\n\n\treturn 0;\n}\n\nstatic int inet6_addr_modify(struct inet6_ifaddr *ifp, struct ifa6_config *cfg)\n{\n\tu32 flags;\n\tclock_t expires;\n\tunsigned long timeout;\n\tbool was_managetempaddr;\n\tbool had_prefixroute;\n\tbool new_peer = false;\n\n\tASSERT_RTNL();\n\n\tif (!cfg->valid_lft || cfg->preferred_lft > cfg->valid_lft)\n\t\treturn -EINVAL;\n\n\tif (cfg->ifa_flags & IFA_F_MANAGETEMPADDR &&\n\t    (ifp->flags & IFA_F_TEMPORARY || ifp->prefix_len != 64))\n\t\treturn -EINVAL;\n\n\tif (!(ifp->flags & IFA_F_TENTATIVE) || ifp->flags & IFA_F_DADFAILED)\n\t\tcfg->ifa_flags &= ~IFA_F_OPTIMISTIC;\n\n\ttimeout = addrconf_timeout_fixup(cfg->valid_lft, HZ);\n\tif (addrconf_finite_timeout(timeout)) {\n\t\texpires = jiffies_to_clock_t(timeout * HZ);\n\t\tcfg->valid_lft = timeout;\n\t\tflags = RTF_EXPIRES;\n\t} else {\n\t\texpires = 0;\n\t\tflags = 0;\n\t\tcfg->ifa_flags |= IFA_F_PERMANENT;\n\t}\n\n\ttimeout = addrconf_timeout_fixup(cfg->preferred_lft, HZ);\n\tif (addrconf_finite_timeout(timeout)) {\n\t\tif (timeout == 0)\n\t\t\tcfg->ifa_flags |= IFA_F_DEPRECATED;\n\t\tcfg->preferred_lft = timeout;\n\t}\n\n\tif (cfg->peer_pfx &&\n\t    memcmp(&ifp->peer_addr, cfg->peer_pfx, sizeof(struct in6_addr))) {\n\t\tif (!ipv6_addr_any(&ifp->peer_addr))\n\t\t\tcleanup_prefix_route(ifp, expires, true, true);\n\t\tnew_peer = true;\n\t}\n\n\tspin_lock_bh(&ifp->lock);\n\twas_managetempaddr = ifp->flags & IFA_F_MANAGETEMPADDR;\n\thad_prefixroute = ifp->flags & IFA_F_PERMANENT &&\n\t\t\t  !(ifp->flags & IFA_F_NOPREFIXROUTE);\n\tifp->flags &= ~(IFA_F_DEPRECATED | IFA_F_PERMANENT | IFA_F_NODAD |\n\t\t\tIFA_F_HOMEADDRESS | IFA_F_MANAGETEMPADDR |\n\t\t\tIFA_F_NOPREFIXROUTE);\n\tifp->flags |= cfg->ifa_flags;\n\tifp->tstamp = jiffies;\n\tifp->valid_lft = cfg->valid_lft;\n\tifp->prefered_lft = cfg->preferred_lft;\n\n\tif (cfg->rt_priority && cfg->rt_priority != ifp->rt_priority)\n\t\tifp->rt_priority = cfg->rt_priority;\n\n\tif (new_peer)\n\t\tifp->peer_addr = *cfg->peer_pfx;\n\n\tspin_unlock_bh(&ifp->lock);\n\tif (!(ifp->flags&IFA_F_TENTATIVE))\n\t\tipv6_ifa_notify(0, ifp);\n\n\tif (!(cfg->ifa_flags & IFA_F_NOPREFIXROUTE)) {\n\t\tint rc = -ENOENT;\n\n\t\tif (had_prefixroute)\n\t\t\trc = modify_prefix_route(ifp, expires, flags, false);\n\n\t\t/* prefix route could have been deleted; if so restore it */\n\t\tif (rc == -ENOENT) {\n\t\t\taddrconf_prefix_route(&ifp->addr, ifp->prefix_len,\n\t\t\t\t\t      ifp->rt_priority, ifp->idev->dev,\n\t\t\t\t\t      expires, flags, GFP_KERNEL);\n\t\t}\n\n\t\tif (had_prefixroute && !ipv6_addr_any(&ifp->peer_addr))\n\t\t\trc = modify_prefix_route(ifp, expires, flags, true);\n\n\t\tif (rc == -ENOENT && !ipv6_addr_any(&ifp->peer_addr)) {\n\t\t\taddrconf_prefix_route(&ifp->peer_addr, ifp->prefix_len,\n\t\t\t\t\t      ifp->rt_priority, ifp->idev->dev,\n\t\t\t\t\t      expires, flags, GFP_KERNEL);\n\t\t}\n\t} else if (had_prefixroute) {\n\t\tenum cleanup_prefix_rt_t action;\n\t\tunsigned long rt_expires;\n\n\t\twrite_lock_bh(&ifp->idev->lock);\n\t\taction = check_cleanup_prefix_route(ifp, &rt_expires);\n\t\twrite_unlock_bh(&ifp->idev->lock);\n\n\t\tif (action != CLEANUP_PREFIX_RT_NOP) {\n\t\t\tcleanup_prefix_route(ifp, rt_expires,\n\t\t\t\taction == CLEANUP_PREFIX_RT_DEL, false);\n\t\t}\n\t}\n\n\tif (was_managetempaddr || ifp->flags & IFA_F_MANAGETEMPADDR) {\n\t\tif (was_managetempaddr &&\n\t\t    !(ifp->flags & IFA_F_MANAGETEMPADDR)) {\n\t\t\tcfg->valid_lft = 0;\n\t\t\tcfg->preferred_lft = 0;\n\t\t}\n\t\tmanage_tempaddrs(ifp->idev, ifp, cfg->valid_lft,\n\t\t\t\t cfg->preferred_lft, !was_managetempaddr,\n\t\t\t\t jiffies);\n\t}\n\n\taddrconf_verify_rtnl();\n\n\treturn 0;\n}\n\nstatic int\ninet6_rtm_newaddr(struct sk_buff *skb, struct nlmsghdr *nlh,\n\t\t  struct netlink_ext_ack *extack)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct ifaddrmsg *ifm;\n\tstruct nlattr *tb[IFA_MAX+1];\n\tstruct in6_addr *peer_pfx;\n\tstruct inet6_ifaddr *ifa;\n\tstruct net_device *dev;\n\tstruct inet6_dev *idev;\n\tstruct ifa6_config cfg;\n\tint err;\n\n\terr = nlmsg_parse_deprecated(nlh, sizeof(*ifm), tb, IFA_MAX,\n\t\t\t\t     ifa_ipv6_policy, extack);\n\tif (err < 0)\n\t\treturn err;\n\n\tmemset(&cfg, 0, sizeof(cfg));\n\n\tifm = nlmsg_data(nlh);\n\tcfg.pfx = extract_addr(tb[IFA_ADDRESS], tb[IFA_LOCAL], &peer_pfx);\n\tif (!cfg.pfx)\n\t\treturn -EINVAL;\n\n\tcfg.peer_pfx = peer_pfx;\n\tcfg.plen = ifm->ifa_prefixlen;\n\tif (tb[IFA_RT_PRIORITY])\n\t\tcfg.rt_priority = nla_get_u32(tb[IFA_RT_PRIORITY]);\n\n\tcfg.valid_lft = INFINITY_LIFE_TIME;\n\tcfg.preferred_lft = INFINITY_LIFE_TIME;\n\n\tif (tb[IFA_CACHEINFO]) {\n\t\tstruct ifa_cacheinfo *ci;\n\n\t\tci = nla_data(tb[IFA_CACHEINFO]);\n\t\tcfg.valid_lft = ci->ifa_valid;\n\t\tcfg.preferred_lft = ci->ifa_prefered;\n\t}\n\n\tdev =  __dev_get_by_index(net, ifm->ifa_index);\n\tif (!dev)\n\t\treturn -ENODEV;\n\n\tif (tb[IFA_FLAGS])\n\t\tcfg.ifa_flags = nla_get_u32(tb[IFA_FLAGS]);\n\telse\n\t\tcfg.ifa_flags = ifm->ifa_flags;\n\n\t/* We ignore other flags so far. */\n\tcfg.ifa_flags &= IFA_F_NODAD | IFA_F_HOMEADDRESS |\n\t\t\t IFA_F_MANAGETEMPADDR | IFA_F_NOPREFIXROUTE |\n\t\t\t IFA_F_MCAUTOJOIN | IFA_F_OPTIMISTIC;\n\n\tidev = ipv6_find_idev(dev);\n\tif (IS_ERR(idev))\n\t\treturn PTR_ERR(idev);\n\n\tif (!ipv6_allow_optimistic_dad(net, idev))\n\t\tcfg.ifa_flags &= ~IFA_F_OPTIMISTIC;\n\n\tif (cfg.ifa_flags & IFA_F_NODAD &&\n\t    cfg.ifa_flags & IFA_F_OPTIMISTIC) {\n\t\tNL_SET_ERR_MSG(extack, \"IFA_F_NODAD and IFA_F_OPTIMISTIC are mutually exclusive\");\n\t\treturn -EINVAL;\n\t}\n\n\tifa = ipv6_get_ifaddr(net, cfg.pfx, dev, 1);\n\tif (!ifa) {\n\t\t/*\n\t\t * It would be best to check for !NLM_F_CREATE here but\n\t\t * userspace already relies on not having to provide this.\n\t\t */\n\t\treturn inet6_addr_add(net, ifm->ifa_index, &cfg, extack);\n\t}\n\n\tif (nlh->nlmsg_flags & NLM_F_EXCL ||\n\t    !(nlh->nlmsg_flags & NLM_F_REPLACE))\n\t\terr = -EEXIST;\n\telse\n\t\terr = inet6_addr_modify(ifa, &cfg);\n\n\tin6_ifa_put(ifa);\n\n\treturn err;\n}\n\nstatic void put_ifaddrmsg(struct nlmsghdr *nlh, u8 prefixlen, u32 flags,\n\t\t\t  u8 scope, int ifindex)\n{\n\tstruct ifaddrmsg *ifm;\n\n\tifm = nlmsg_data(nlh);\n\tifm->ifa_family = AF_INET6;\n\tifm->ifa_prefixlen = prefixlen;\n\tifm->ifa_flags = flags;\n\tifm->ifa_scope = scope;\n\tifm->ifa_index = ifindex;\n}\n\nstatic int put_cacheinfo(struct sk_buff *skb, unsigned long cstamp,\n\t\t\t unsigned long tstamp, u32 preferred, u32 valid)\n{\n\tstruct ifa_cacheinfo ci;\n\n\tci.cstamp = cstamp_delta(cstamp);\n\tci.tstamp = cstamp_delta(tstamp);\n\tci.ifa_prefered = preferred;\n\tci.ifa_valid = valid;\n\n\treturn nla_put(skb, IFA_CACHEINFO, sizeof(ci), &ci);\n}\n\nstatic inline int rt_scope(int ifa_scope)\n{\n\tif (ifa_scope & IFA_HOST)\n\t\treturn RT_SCOPE_HOST;\n\telse if (ifa_scope & IFA_LINK)\n\t\treturn RT_SCOPE_LINK;\n\telse if (ifa_scope & IFA_SITE)\n\t\treturn RT_SCOPE_SITE;\n\telse\n\t\treturn RT_SCOPE_UNIVERSE;\n}\n\nstatic inline int inet6_ifaddr_msgsize(void)\n{\n\treturn NLMSG_ALIGN(sizeof(struct ifaddrmsg))\n\t       + nla_total_size(16) /* IFA_LOCAL */\n\t       + nla_total_size(16) /* IFA_ADDRESS */\n\t       + nla_total_size(sizeof(struct ifa_cacheinfo))\n\t       + nla_total_size(4)  /* IFA_FLAGS */\n\t       + nla_total_size(4)  /* IFA_RT_PRIORITY */;\n}\n\nenum addr_type_t {\n\tUNICAST_ADDR,\n\tMULTICAST_ADDR,\n\tANYCAST_ADDR,\n};\n\nstruct inet6_fill_args {\n\tu32 portid;\n\tu32 seq;\n\tint event;\n\tunsigned int flags;\n\tint netnsid;\n\tint ifindex;\n\tenum addr_type_t type;\n};\n\nstatic int inet6_fill_ifaddr(struct sk_buff *skb, struct inet6_ifaddr *ifa,\n\t\t\t     struct inet6_fill_args *args)\n{\n\tstruct nlmsghdr  *nlh;\n\tu32 preferred, valid;\n\n\tnlh = nlmsg_put(skb, args->portid, args->seq, args->event,\n\t\t\tsizeof(struct ifaddrmsg), args->flags);\n\tif (!nlh)\n\t\treturn -EMSGSIZE;\n\n\tput_ifaddrmsg(nlh, ifa->prefix_len, ifa->flags, rt_scope(ifa->scope),\n\t\t      ifa->idev->dev->ifindex);\n\n\tif (args->netnsid >= 0 &&\n\t    nla_put_s32(skb, IFA_TARGET_NETNSID, args->netnsid))\n\t\tgoto error;\n\n\tif (!((ifa->flags&IFA_F_PERMANENT) &&\n\t      (ifa->prefered_lft == INFINITY_LIFE_TIME))) {\n\t\tpreferred = ifa->prefered_lft;\n\t\tvalid = ifa->valid_lft;\n\t\tif (preferred != INFINITY_LIFE_TIME) {\n\t\t\tlong tval = (jiffies - ifa->tstamp)/HZ;\n\t\t\tif (preferred > tval)\n\t\t\t\tpreferred -= tval;\n\t\t\telse\n\t\t\t\tpreferred = 0;\n\t\t\tif (valid != INFINITY_LIFE_TIME) {\n\t\t\t\tif (valid > tval)\n\t\t\t\t\tvalid -= tval;\n\t\t\t\telse\n\t\t\t\t\tvalid = 0;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tpreferred = INFINITY_LIFE_TIME;\n\t\tvalid = INFINITY_LIFE_TIME;\n\t}\n\n\tif (!ipv6_addr_any(&ifa->peer_addr)) {\n\t\tif (nla_put_in6_addr(skb, IFA_LOCAL, &ifa->addr) < 0 ||\n\t\t    nla_put_in6_addr(skb, IFA_ADDRESS, &ifa->peer_addr) < 0)\n\t\t\tgoto error;\n\t} else\n\t\tif (nla_put_in6_addr(skb, IFA_ADDRESS, &ifa->addr) < 0)\n\t\t\tgoto error;\n\n\tif (ifa->rt_priority &&\n\t    nla_put_u32(skb, IFA_RT_PRIORITY, ifa->rt_priority))\n\t\tgoto error;\n\n\tif (put_cacheinfo(skb, ifa->cstamp, ifa->tstamp, preferred, valid) < 0)\n\t\tgoto error;\n\n\tif (nla_put_u32(skb, IFA_FLAGS, ifa->flags) < 0)\n\t\tgoto error;\n\n\tnlmsg_end(skb, nlh);\n\treturn 0;\n\nerror:\n\tnlmsg_cancel(skb, nlh);\n\treturn -EMSGSIZE;\n}\n\nstatic int inet6_fill_ifmcaddr(struct sk_buff *skb, struct ifmcaddr6 *ifmca,\n\t\t\t       struct inet6_fill_args *args)\n{\n\tstruct nlmsghdr  *nlh;\n\tu8 scope = RT_SCOPE_UNIVERSE;\n\tint ifindex = ifmca->idev->dev->ifindex;\n\n\tif (ipv6_addr_scope(&ifmca->mca_addr) & IFA_SITE)\n\t\tscope = RT_SCOPE_SITE;\n\n\tnlh = nlmsg_put(skb, args->portid, args->seq, args->event,\n\t\t\tsizeof(struct ifaddrmsg), args->flags);\n\tif (!nlh)\n\t\treturn -EMSGSIZE;\n\n\tif (args->netnsid >= 0 &&\n\t    nla_put_s32(skb, IFA_TARGET_NETNSID, args->netnsid)) {\n\t\tnlmsg_cancel(skb, nlh);\n\t\treturn -EMSGSIZE;\n\t}\n\n\tput_ifaddrmsg(nlh, 128, IFA_F_PERMANENT, scope, ifindex);\n\tif (nla_put_in6_addr(skb, IFA_MULTICAST, &ifmca->mca_addr) < 0 ||\n\t    put_cacheinfo(skb, ifmca->mca_cstamp, ifmca->mca_tstamp,\n\t\t\t  INFINITY_LIFE_TIME, INFINITY_LIFE_TIME) < 0) {\n\t\tnlmsg_cancel(skb, nlh);\n\t\treturn -EMSGSIZE;\n\t}\n\n\tnlmsg_end(skb, nlh);\n\treturn 0;\n}\n\nstatic int inet6_fill_ifacaddr(struct sk_buff *skb, struct ifacaddr6 *ifaca,\n\t\t\t       struct inet6_fill_args *args)\n{\n\tstruct net_device *dev = fib6_info_nh_dev(ifaca->aca_rt);\n\tint ifindex = dev ? dev->ifindex : 1;\n\tstruct nlmsghdr  *nlh;\n\tu8 scope = RT_SCOPE_UNIVERSE;\n\n\tif (ipv6_addr_scope(&ifaca->aca_addr) & IFA_SITE)\n\t\tscope = RT_SCOPE_SITE;\n\n\tnlh = nlmsg_put(skb, args->portid, args->seq, args->event,\n\t\t\tsizeof(struct ifaddrmsg), args->flags);\n\tif (!nlh)\n\t\treturn -EMSGSIZE;\n\n\tif (args->netnsid >= 0 &&\n\t    nla_put_s32(skb, IFA_TARGET_NETNSID, args->netnsid)) {\n\t\tnlmsg_cancel(skb, nlh);\n\t\treturn -EMSGSIZE;\n\t}\n\n\tput_ifaddrmsg(nlh, 128, IFA_F_PERMANENT, scope, ifindex);\n\tif (nla_put_in6_addr(skb, IFA_ANYCAST, &ifaca->aca_addr) < 0 ||\n\t    put_cacheinfo(skb, ifaca->aca_cstamp, ifaca->aca_tstamp,\n\t\t\t  INFINITY_LIFE_TIME, INFINITY_LIFE_TIME) < 0) {\n\t\tnlmsg_cancel(skb, nlh);\n\t\treturn -EMSGSIZE;\n\t}\n\n\tnlmsg_end(skb, nlh);\n\treturn 0;\n}\n\n/* called with rcu_read_lock() */\nstatic int in6_dump_addrs(struct inet6_dev *idev, struct sk_buff *skb,\n\t\t\t  struct netlink_callback *cb, int s_ip_idx,\n\t\t\t  struct inet6_fill_args *fillargs)\n{\n\tstruct ifmcaddr6 *ifmca;\n\tstruct ifacaddr6 *ifaca;\n\tint ip_idx = 0;\n\tint err = 1;\n\n\tread_lock_bh(&idev->lock);\n\tswitch (fillargs->type) {\n\tcase UNICAST_ADDR: {\n\t\tstruct inet6_ifaddr *ifa;\n\t\tfillargs->event = RTM_NEWADDR;\n\n\t\t/* unicast address incl. temp addr */\n\t\tlist_for_each_entry(ifa, &idev->addr_list, if_list) {\n\t\t\tif (ip_idx < s_ip_idx)\n\t\t\t\tgoto next;\n\t\t\terr = inet6_fill_ifaddr(skb, ifa, fillargs);\n\t\t\tif (err < 0)\n\t\t\t\tbreak;\n\t\t\tnl_dump_check_consistent(cb, nlmsg_hdr(skb));\nnext:\n\t\t\tip_idx++;\n\t\t}\n\t\tbreak;\n\t}\n\tcase MULTICAST_ADDR:\n\t\tfillargs->event = RTM_GETMULTICAST;\n\n\t\t/* multicast address */\n\t\tfor (ifmca = idev->mc_list; ifmca;\n\t\t     ifmca = ifmca->next, ip_idx++) {\n\t\t\tif (ip_idx < s_ip_idx)\n\t\t\t\tcontinue;\n\t\t\terr = inet6_fill_ifmcaddr(skb, ifmca, fillargs);\n\t\t\tif (err < 0)\n\t\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase ANYCAST_ADDR:\n\t\tfillargs->event = RTM_GETANYCAST;\n\t\t/* anycast address */\n\t\tfor (ifaca = idev->ac_list; ifaca;\n\t\t     ifaca = ifaca->aca_next, ip_idx++) {\n\t\t\tif (ip_idx < s_ip_idx)\n\t\t\t\tcontinue;\n\t\t\terr = inet6_fill_ifacaddr(skb, ifaca, fillargs);\n\t\t\tif (err < 0)\n\t\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\tread_unlock_bh(&idev->lock);\n\tcb->args[2] = ip_idx;\n\treturn err;\n}\n\nstatic int inet6_valid_dump_ifaddr_req(const struct nlmsghdr *nlh,\n\t\t\t\t       struct inet6_fill_args *fillargs,\n\t\t\t\t       struct net **tgt_net, struct sock *sk,\n\t\t\t\t       struct netlink_callback *cb)\n{\n\tstruct netlink_ext_ack *extack = cb->extack;\n\tstruct nlattr *tb[IFA_MAX+1];\n\tstruct ifaddrmsg *ifm;\n\tint err, i;\n\n\tif (nlh->nlmsg_len < nlmsg_msg_size(sizeof(*ifm))) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Invalid header for address dump request\");\n\t\treturn -EINVAL;\n\t}\n\n\tifm = nlmsg_data(nlh);\n\tif (ifm->ifa_prefixlen || ifm->ifa_flags || ifm->ifa_scope) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Invalid values in header for address dump request\");\n\t\treturn -EINVAL;\n\t}\n\n\tfillargs->ifindex = ifm->ifa_index;\n\tif (fillargs->ifindex) {\n\t\tcb->answer_flags |= NLM_F_DUMP_FILTERED;\n\t\tfillargs->flags |= NLM_F_DUMP_FILTERED;\n\t}\n\n\terr = nlmsg_parse_deprecated_strict(nlh, sizeof(*ifm), tb, IFA_MAX,\n\t\t\t\t\t    ifa_ipv6_policy, extack);\n\tif (err < 0)\n\t\treturn err;\n\n\tfor (i = 0; i <= IFA_MAX; ++i) {\n\t\tif (!tb[i])\n\t\t\tcontinue;\n\n\t\tif (i == IFA_TARGET_NETNSID) {\n\t\t\tstruct net *net;\n\n\t\t\tfillargs->netnsid = nla_get_s32(tb[i]);\n\t\t\tnet = rtnl_get_net_ns_capable(sk, fillargs->netnsid);\n\t\t\tif (IS_ERR(net)) {\n\t\t\t\tfillargs->netnsid = -1;\n\t\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Invalid target network namespace id\");\n\t\t\t\treturn PTR_ERR(net);\n\t\t\t}\n\t\t\t*tgt_net = net;\n\t\t} else {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Unsupported attribute in dump request\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int inet6_dump_addr(struct sk_buff *skb, struct netlink_callback *cb,\n\t\t\t   enum addr_type_t type)\n{\n\tconst struct nlmsghdr *nlh = cb->nlh;\n\tstruct inet6_fill_args fillargs = {\n\t\t.portid = NETLINK_CB(cb->skb).portid,\n\t\t.seq = cb->nlh->nlmsg_seq,\n\t\t.flags = NLM_F_MULTI,\n\t\t.netnsid = -1,\n\t\t.type = type,\n\t};\n\tstruct net *net = sock_net(skb->sk);\n\tstruct net *tgt_net = net;\n\tint idx, s_idx, s_ip_idx;\n\tint h, s_h;\n\tstruct net_device *dev;\n\tstruct inet6_dev *idev;\n\tstruct hlist_head *head;\n\tint err = 0;\n\n\ts_h = cb->args[0];\n\ts_idx = idx = cb->args[1];\n\ts_ip_idx = cb->args[2];\n\n\tif (cb->strict_check) {\n\t\terr = inet6_valid_dump_ifaddr_req(nlh, &fillargs, &tgt_net,\n\t\t\t\t\t\t  skb->sk, cb);\n\t\tif (err < 0)\n\t\t\tgoto put_tgt_net;\n\n\t\terr = 0;\n\t\tif (fillargs.ifindex) {\n\t\t\tdev = __dev_get_by_index(tgt_net, fillargs.ifindex);\n\t\t\tif (!dev) {\n\t\t\t\terr = -ENODEV;\n\t\t\t\tgoto put_tgt_net;\n\t\t\t}\n\t\t\tidev = __in6_dev_get(dev);\n\t\t\tif (idev) {\n\t\t\t\terr = in6_dump_addrs(idev, skb, cb, s_ip_idx,\n\t\t\t\t\t\t     &fillargs);\n\t\t\t\tif (err > 0)\n\t\t\t\t\terr = 0;\n\t\t\t}\n\t\t\tgoto put_tgt_net;\n\t\t}\n\t}\n\n\trcu_read_lock();\n\tcb->seq = atomic_read(&tgt_net->ipv6.dev_addr_genid) ^ tgt_net->dev_base_seq;\n\tfor (h = s_h; h < NETDEV_HASHENTRIES; h++, s_idx = 0) {\n\t\tidx = 0;\n\t\thead = &tgt_net->dev_index_head[h];\n\t\thlist_for_each_entry_rcu(dev, head, index_hlist) {\n\t\t\tif (idx < s_idx)\n\t\t\t\tgoto cont;\n\t\t\tif (h > s_h || idx > s_idx)\n\t\t\t\ts_ip_idx = 0;\n\t\t\tidev = __in6_dev_get(dev);\n\t\t\tif (!idev)\n\t\t\t\tgoto cont;\n\n\t\t\tif (in6_dump_addrs(idev, skb, cb, s_ip_idx,\n\t\t\t\t\t   &fillargs) < 0)\n\t\t\t\tgoto done;\ncont:\n\t\t\tidx++;\n\t\t}\n\t}\ndone:\n\trcu_read_unlock();\n\tcb->args[0] = h;\n\tcb->args[1] = idx;\nput_tgt_net:\n\tif (fillargs.netnsid >= 0)\n\t\tput_net(tgt_net);\n\n\treturn skb->len ? : err;\n}\n\nstatic int inet6_dump_ifaddr(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tenum addr_type_t type = UNICAST_ADDR;\n\n\treturn inet6_dump_addr(skb, cb, type);\n}\n\nstatic int inet6_dump_ifmcaddr(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tenum addr_type_t type = MULTICAST_ADDR;\n\n\treturn inet6_dump_addr(skb, cb, type);\n}\n\n\nstatic int inet6_dump_ifacaddr(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tenum addr_type_t type = ANYCAST_ADDR;\n\n\treturn inet6_dump_addr(skb, cb, type);\n}\n\nstatic int inet6_rtm_valid_getaddr_req(struct sk_buff *skb,\n\t\t\t\t       const struct nlmsghdr *nlh,\n\t\t\t\t       struct nlattr **tb,\n\t\t\t\t       struct netlink_ext_ack *extack)\n{\n\tstruct ifaddrmsg *ifm;\n\tint i, err;\n\n\tif (nlh->nlmsg_len < nlmsg_msg_size(sizeof(*ifm))) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Invalid header for get address request\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!netlink_strict_get_check(skb))\n\t\treturn nlmsg_parse_deprecated(nlh, sizeof(*ifm), tb, IFA_MAX,\n\t\t\t\t\t      ifa_ipv6_policy, extack);\n\n\tifm = nlmsg_data(nlh);\n\tif (ifm->ifa_prefixlen || ifm->ifa_flags || ifm->ifa_scope) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Invalid values in header for get address request\");\n\t\treturn -EINVAL;\n\t}\n\n\terr = nlmsg_parse_deprecated_strict(nlh, sizeof(*ifm), tb, IFA_MAX,\n\t\t\t\t\t    ifa_ipv6_policy, extack);\n\tif (err)\n\t\treturn err;\n\n\tfor (i = 0; i <= IFA_MAX; i++) {\n\t\tif (!tb[i])\n\t\t\tcontinue;\n\n\t\tswitch (i) {\n\t\tcase IFA_TARGET_NETNSID:\n\t\tcase IFA_ADDRESS:\n\t\tcase IFA_LOCAL:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Unsupported attribute in get address request\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int inet6_rtm_getaddr(struct sk_buff *in_skb, struct nlmsghdr *nlh,\n\t\t\t     struct netlink_ext_ack *extack)\n{\n\tstruct net *net = sock_net(in_skb->sk);\n\tstruct inet6_fill_args fillargs = {\n\t\t.portid = NETLINK_CB(in_skb).portid,\n\t\t.seq = nlh->nlmsg_seq,\n\t\t.event = RTM_NEWADDR,\n\t\t.flags = 0,\n\t\t.netnsid = -1,\n\t};\n\tstruct net *tgt_net = net;\n\tstruct ifaddrmsg *ifm;\n\tstruct nlattr *tb[IFA_MAX+1];\n\tstruct in6_addr *addr = NULL, *peer;\n\tstruct net_device *dev = NULL;\n\tstruct inet6_ifaddr *ifa;\n\tstruct sk_buff *skb;\n\tint err;\n\n\terr = inet6_rtm_valid_getaddr_req(in_skb, nlh, tb, extack);\n\tif (err < 0)\n\t\treturn err;\n\n\tif (tb[IFA_TARGET_NETNSID]) {\n\t\tfillargs.netnsid = nla_get_s32(tb[IFA_TARGET_NETNSID]);\n\n\t\ttgt_net = rtnl_get_net_ns_capable(NETLINK_CB(in_skb).sk,\n\t\t\t\t\t\t  fillargs.netnsid);\n\t\tif (IS_ERR(tgt_net))\n\t\t\treturn PTR_ERR(tgt_net);\n\t}\n\n\taddr = extract_addr(tb[IFA_ADDRESS], tb[IFA_LOCAL], &peer);\n\tif (!addr)\n\t\treturn -EINVAL;\n\n\tifm = nlmsg_data(nlh);\n\tif (ifm->ifa_index)\n\t\tdev = dev_get_by_index(tgt_net, ifm->ifa_index);\n\n\tifa = ipv6_get_ifaddr(tgt_net, addr, dev, 1);\n\tif (!ifa) {\n\t\terr = -EADDRNOTAVAIL;\n\t\tgoto errout;\n\t}\n\n\tskb = nlmsg_new(inet6_ifaddr_msgsize(), GFP_KERNEL);\n\tif (!skb) {\n\t\terr = -ENOBUFS;\n\t\tgoto errout_ifa;\n\t}\n\n\terr = inet6_fill_ifaddr(skb, ifa, &fillargs);\n\tif (err < 0) {\n\t\t/* -EMSGSIZE implies BUG in inet6_ifaddr_msgsize() */\n\t\tWARN_ON(err == -EMSGSIZE);\n\t\tkfree_skb(skb);\n\t\tgoto errout_ifa;\n\t}\n\terr = rtnl_unicast(skb, tgt_net, NETLINK_CB(in_skb).portid);\nerrout_ifa:\n\tin6_ifa_put(ifa);\nerrout:\n\tif (dev)\n\t\tdev_put(dev);\n\tif (fillargs.netnsid >= 0)\n\t\tput_net(tgt_net);\n\n\treturn err;\n}\n\nstatic void inet6_ifa_notify(int event, struct inet6_ifaddr *ifa)\n{\n\tstruct sk_buff *skb;\n\tstruct net *net = dev_net(ifa->idev->dev);\n\tstruct inet6_fill_args fillargs = {\n\t\t.portid = 0,\n\t\t.seq = 0,\n\t\t.event = event,\n\t\t.flags = 0,\n\t\t.netnsid = -1,\n\t};\n\tint err = -ENOBUFS;\n\n\tskb = nlmsg_new(inet6_ifaddr_msgsize(), GFP_ATOMIC);\n\tif (!skb)\n\t\tgoto errout;\n\n\terr = inet6_fill_ifaddr(skb, ifa, &fillargs);\n\tif (err < 0) {\n\t\t/* -EMSGSIZE implies BUG in inet6_ifaddr_msgsize() */\n\t\tWARN_ON(err == -EMSGSIZE);\n\t\tkfree_skb(skb);\n\t\tgoto errout;\n\t}\n\trtnl_notify(skb, net, 0, RTNLGRP_IPV6_IFADDR, NULL, GFP_ATOMIC);\n\treturn;\nerrout:\n\tif (err < 0)\n\t\trtnl_set_sk_err(net, RTNLGRP_IPV6_IFADDR, err);\n}\n\nstatic inline void ipv6_store_devconf(struct ipv6_devconf *cnf,\n\t\t\t\t__s32 *array, int bytes)\n{\n\tBUG_ON(bytes < (DEVCONF_MAX * 4));\n\n\tmemset(array, 0, bytes);\n\tarray[DEVCONF_FORWARDING] = cnf->forwarding;\n\tarray[DEVCONF_HOPLIMIT] = cnf->hop_limit;\n\tarray[DEVCONF_MTU6] = cnf->mtu6;\n\tarray[DEVCONF_ACCEPT_RA] = cnf->accept_ra;\n\tarray[DEVCONF_ACCEPT_REDIRECTS] = cnf->accept_redirects;\n\tarray[DEVCONF_AUTOCONF] = cnf->autoconf;\n\tarray[DEVCONF_DAD_TRANSMITS] = cnf->dad_transmits;\n\tarray[DEVCONF_RTR_SOLICITS] = cnf->rtr_solicits;\n\tarray[DEVCONF_RTR_SOLICIT_INTERVAL] =\n\t\tjiffies_to_msecs(cnf->rtr_solicit_interval);\n\tarray[DEVCONF_RTR_SOLICIT_MAX_INTERVAL] =\n\t\tjiffies_to_msecs(cnf->rtr_solicit_max_interval);\n\tarray[DEVCONF_RTR_SOLICIT_DELAY] =\n\t\tjiffies_to_msecs(cnf->rtr_solicit_delay);\n\tarray[DEVCONF_FORCE_MLD_VERSION] = cnf->force_mld_version;\n\tarray[DEVCONF_MLDV1_UNSOLICITED_REPORT_INTERVAL] =\n\t\tjiffies_to_msecs(cnf->mldv1_unsolicited_report_interval);\n\tarray[DEVCONF_MLDV2_UNSOLICITED_REPORT_INTERVAL] =\n\t\tjiffies_to_msecs(cnf->mldv2_unsolicited_report_interval);\n\tarray[DEVCONF_USE_TEMPADDR] = cnf->use_tempaddr;\n\tarray[DEVCONF_TEMP_VALID_LFT] = cnf->temp_valid_lft;\n\tarray[DEVCONF_TEMP_PREFERED_LFT] = cnf->temp_prefered_lft;\n\tarray[DEVCONF_REGEN_MAX_RETRY] = cnf->regen_max_retry;\n\tarray[DEVCONF_MAX_DESYNC_FACTOR] = cnf->max_desync_factor;\n\tarray[DEVCONF_MAX_ADDRESSES] = cnf->max_addresses;\n\tarray[DEVCONF_ACCEPT_RA_DEFRTR] = cnf->accept_ra_defrtr;\n\tarray[DEVCONF_RA_DEFRTR_METRIC] = cnf->ra_defrtr_metric;\n\tarray[DEVCONF_ACCEPT_RA_MIN_HOP_LIMIT] = cnf->accept_ra_min_hop_limit;\n\tarray[DEVCONF_ACCEPT_RA_PINFO] = cnf->accept_ra_pinfo;\n#ifdef CONFIG_IPV6_ROUTER_PREF\n\tarray[DEVCONF_ACCEPT_RA_RTR_PREF] = cnf->accept_ra_rtr_pref;\n\tarray[DEVCONF_RTR_PROBE_INTERVAL] =\n\t\tjiffies_to_msecs(cnf->rtr_probe_interval);\n#ifdef CONFIG_IPV6_ROUTE_INFO\n\tarray[DEVCONF_ACCEPT_RA_RT_INFO_MIN_PLEN] = cnf->accept_ra_rt_info_min_plen;\n\tarray[DEVCONF_ACCEPT_RA_RT_INFO_MAX_PLEN] = cnf->accept_ra_rt_info_max_plen;\n#endif\n#endif\n\tarray[DEVCONF_PROXY_NDP] = cnf->proxy_ndp;\n\tarray[DEVCONF_ACCEPT_SOURCE_ROUTE] = cnf->accept_source_route;\n#ifdef CONFIG_IPV6_OPTIMISTIC_DAD\n\tarray[DEVCONF_OPTIMISTIC_DAD] = cnf->optimistic_dad;\n\tarray[DEVCONF_USE_OPTIMISTIC] = cnf->use_optimistic;\n#endif\n#ifdef CONFIG_IPV6_MROUTE\n\tarray[DEVCONF_MC_FORWARDING] = cnf->mc_forwarding;\n#endif\n\tarray[DEVCONF_DISABLE_IPV6] = cnf->disable_ipv6;\n\tarray[DEVCONF_ACCEPT_DAD] = cnf->accept_dad;\n\tarray[DEVCONF_FORCE_TLLAO] = cnf->force_tllao;\n\tarray[DEVCONF_NDISC_NOTIFY] = cnf->ndisc_notify;\n\tarray[DEVCONF_SUPPRESS_FRAG_NDISC] = cnf->suppress_frag_ndisc;\n\tarray[DEVCONF_ACCEPT_RA_FROM_LOCAL] = cnf->accept_ra_from_local;\n\tarray[DEVCONF_ACCEPT_RA_MTU] = cnf->accept_ra_mtu;\n\tarray[DEVCONF_IGNORE_ROUTES_WITH_LINKDOWN] = cnf->ignore_routes_with_linkdown;\n\t/* we omit DEVCONF_STABLE_SECRET for now */\n\tarray[DEVCONF_USE_OIF_ADDRS_ONLY] = cnf->use_oif_addrs_only;\n\tarray[DEVCONF_DROP_UNICAST_IN_L2_MULTICAST] = cnf->drop_unicast_in_l2_multicast;\n\tarray[DEVCONF_DROP_UNSOLICITED_NA] = cnf->drop_unsolicited_na;\n\tarray[DEVCONF_KEEP_ADDR_ON_DOWN] = cnf->keep_addr_on_down;\n\tarray[DEVCONF_SEG6_ENABLED] = cnf->seg6_enabled;\n#ifdef CONFIG_IPV6_SEG6_HMAC\n\tarray[DEVCONF_SEG6_REQUIRE_HMAC] = cnf->seg6_require_hmac;\n#endif\n\tarray[DEVCONF_ENHANCED_DAD] = cnf->enhanced_dad;\n\tarray[DEVCONF_ADDR_GEN_MODE] = cnf->addr_gen_mode;\n\tarray[DEVCONF_DISABLE_POLICY] = cnf->disable_policy;\n\tarray[DEVCONF_NDISC_TCLASS] = cnf->ndisc_tclass;\n\tarray[DEVCONF_RPL_SEG_ENABLED] = cnf->rpl_seg_enabled;\n}\n\nstatic inline size_t inet6_ifla6_size(void)\n{\n\treturn nla_total_size(4) /* IFLA_INET6_FLAGS */\n\t     + nla_total_size(sizeof(struct ifla_cacheinfo))\n\t     + nla_total_size(DEVCONF_MAX * 4) /* IFLA_INET6_CONF */\n\t     + nla_total_size(IPSTATS_MIB_MAX * 8) /* IFLA_INET6_STATS */\n\t     + nla_total_size(ICMP6_MIB_MAX * 8) /* IFLA_INET6_ICMP6STATS */\n\t     + nla_total_size(sizeof(struct in6_addr)) /* IFLA_INET6_TOKEN */\n\t     + nla_total_size(1) /* IFLA_INET6_ADDR_GEN_MODE */\n\t     + 0;\n}\n\nstatic inline size_t inet6_if_nlmsg_size(void)\n{\n\treturn NLMSG_ALIGN(sizeof(struct ifinfomsg))\n\t       + nla_total_size(IFNAMSIZ) /* IFLA_IFNAME */\n\t       + nla_total_size(MAX_ADDR_LEN) /* IFLA_ADDRESS */\n\t       + nla_total_size(4) /* IFLA_MTU */\n\t       + nla_total_size(4) /* IFLA_LINK */\n\t       + nla_total_size(1) /* IFLA_OPERSTATE */\n\t       + nla_total_size(inet6_ifla6_size()); /* IFLA_PROTINFO */\n}\n\nstatic inline void __snmp6_fill_statsdev(u64 *stats, atomic_long_t *mib,\n\t\t\t\t\tint bytes)\n{\n\tint i;\n\tint pad = bytes - sizeof(u64) * ICMP6_MIB_MAX;\n\tBUG_ON(pad < 0);\n\n\t/* Use put_unaligned() because stats may not be aligned for u64. */\n\tput_unaligned(ICMP6_MIB_MAX, &stats[0]);\n\tfor (i = 1; i < ICMP6_MIB_MAX; i++)\n\t\tput_unaligned(atomic_long_read(&mib[i]), &stats[i]);\n\n\tmemset(&stats[ICMP6_MIB_MAX], 0, pad);\n}\n\nstatic inline void __snmp6_fill_stats64(u64 *stats, void __percpu *mib,\n\t\t\t\t\tint bytes, size_t syncpoff)\n{\n\tint i, c;\n\tu64 buff[IPSTATS_MIB_MAX];\n\tint pad = bytes - sizeof(u64) * IPSTATS_MIB_MAX;\n\n\tBUG_ON(pad < 0);\n\n\tmemset(buff, 0, sizeof(buff));\n\tbuff[0] = IPSTATS_MIB_MAX;\n\n\tfor_each_possible_cpu(c) {\n\t\tfor (i = 1; i < IPSTATS_MIB_MAX; i++)\n\t\t\tbuff[i] += snmp_get_cpu_field64(mib, c, i, syncpoff);\n\t}\n\n\tmemcpy(stats, buff, IPSTATS_MIB_MAX * sizeof(u64));\n\tmemset(&stats[IPSTATS_MIB_MAX], 0, pad);\n}\n\nstatic void snmp6_fill_stats(u64 *stats, struct inet6_dev *idev, int attrtype,\n\t\t\t     int bytes)\n{\n\tswitch (attrtype) {\n\tcase IFLA_INET6_STATS:\n\t\t__snmp6_fill_stats64(stats, idev->stats.ipv6, bytes,\n\t\t\t\t     offsetof(struct ipstats_mib, syncp));\n\t\tbreak;\n\tcase IFLA_INET6_ICMP6STATS:\n\t\t__snmp6_fill_statsdev(stats, idev->stats.icmpv6dev->mibs, bytes);\n\t\tbreak;\n\t}\n}\n\nstatic int inet6_fill_ifla6_attrs(struct sk_buff *skb, struct inet6_dev *idev,\n\t\t\t\t  u32 ext_filter_mask)\n{\n\tstruct nlattr *nla;\n\tstruct ifla_cacheinfo ci;\n\n\tif (nla_put_u32(skb, IFLA_INET6_FLAGS, idev->if_flags))\n\t\tgoto nla_put_failure;\n\tci.max_reasm_len = IPV6_MAXPLEN;\n\tci.tstamp = cstamp_delta(idev->tstamp);\n\tci.reachable_time = jiffies_to_msecs(idev->nd_parms->reachable_time);\n\tci.retrans_time = jiffies_to_msecs(NEIGH_VAR(idev->nd_parms, RETRANS_TIME));\n\tif (nla_put(skb, IFLA_INET6_CACHEINFO, sizeof(ci), &ci))\n\t\tgoto nla_put_failure;\n\tnla = nla_reserve(skb, IFLA_INET6_CONF, DEVCONF_MAX * sizeof(s32));\n\tif (!nla)\n\t\tgoto nla_put_failure;\n\tipv6_store_devconf(&idev->cnf, nla_data(nla), nla_len(nla));\n\n\t/* XXX - MC not implemented */\n\n\tif (ext_filter_mask & RTEXT_FILTER_SKIP_STATS)\n\t\treturn 0;\n\n\tnla = nla_reserve(skb, IFLA_INET6_STATS, IPSTATS_MIB_MAX * sizeof(u64));\n\tif (!nla)\n\t\tgoto nla_put_failure;\n\tsnmp6_fill_stats(nla_data(nla), idev, IFLA_INET6_STATS, nla_len(nla));\n\n\tnla = nla_reserve(skb, IFLA_INET6_ICMP6STATS, ICMP6_MIB_MAX * sizeof(u64));\n\tif (!nla)\n\t\tgoto nla_put_failure;\n\tsnmp6_fill_stats(nla_data(nla), idev, IFLA_INET6_ICMP6STATS, nla_len(nla));\n\n\tnla = nla_reserve(skb, IFLA_INET6_TOKEN, sizeof(struct in6_addr));\n\tif (!nla)\n\t\tgoto nla_put_failure;\n\tread_lock_bh(&idev->lock);\n\tmemcpy(nla_data(nla), idev->token.s6_addr, nla_len(nla));\n\tread_unlock_bh(&idev->lock);\n\n\tif (nla_put_u8(skb, IFLA_INET6_ADDR_GEN_MODE, idev->cnf.addr_gen_mode))\n\t\tgoto nla_put_failure;\n\n\treturn 0;\n\nnla_put_failure:\n\treturn -EMSGSIZE;\n}\n\nstatic size_t inet6_get_link_af_size(const struct net_device *dev,\n\t\t\t\t     u32 ext_filter_mask)\n{\n\tif (!__in6_dev_get(dev))\n\t\treturn 0;\n\n\treturn inet6_ifla6_size();\n}\n\nstatic int inet6_fill_link_af(struct sk_buff *skb, const struct net_device *dev,\n\t\t\t      u32 ext_filter_mask)\n{\n\tstruct inet6_dev *idev = __in6_dev_get(dev);\n\n\tif (!idev)\n\t\treturn -ENODATA;\n\n\tif (inet6_fill_ifla6_attrs(skb, idev, ext_filter_mask) < 0)\n\t\treturn -EMSGSIZE;\n\n\treturn 0;\n}\n\nstatic int inet6_set_iftoken(struct inet6_dev *idev, struct in6_addr *token)\n{\n\tstruct inet6_ifaddr *ifp;\n\tstruct net_device *dev = idev->dev;\n\tbool clear_token, update_rs = false;\n\tstruct in6_addr ll_addr;\n\n\tASSERT_RTNL();\n\n\tif (!token)\n\t\treturn -EINVAL;\n\tif (dev->flags & (IFF_LOOPBACK | IFF_NOARP))\n\t\treturn -EINVAL;\n\tif (!ipv6_accept_ra(idev))\n\t\treturn -EINVAL;\n\tif (idev->cnf.rtr_solicits == 0)\n\t\treturn -EINVAL;\n\n\twrite_lock_bh(&idev->lock);\n\n\tBUILD_BUG_ON(sizeof(token->s6_addr) != 16);\n\tmemcpy(idev->token.s6_addr + 8, token->s6_addr + 8, 8);\n\n\twrite_unlock_bh(&idev->lock);\n\n\tclear_token = ipv6_addr_any(token);\n\tif (clear_token)\n\t\tgoto update_lft;\n\n\tif (!idev->dead && (idev->if_flags & IF_READY) &&\n\t    !ipv6_get_lladdr(dev, &ll_addr, IFA_F_TENTATIVE |\n\t\t\t     IFA_F_OPTIMISTIC)) {\n\t\t/* If we're not ready, then normal ifup will take care\n\t\t * of this. Otherwise, we need to request our rs here.\n\t\t */\n\t\tndisc_send_rs(dev, &ll_addr, &in6addr_linklocal_allrouters);\n\t\tupdate_rs = true;\n\t}\n\nupdate_lft:\n\twrite_lock_bh(&idev->lock);\n\n\tif (update_rs) {\n\t\tidev->if_flags |= IF_RS_SENT;\n\t\tidev->rs_interval = rfc3315_s14_backoff_init(\n\t\t\tidev->cnf.rtr_solicit_interval);\n\t\tidev->rs_probes = 1;\n\t\taddrconf_mod_rs_timer(idev, idev->rs_interval);\n\t}\n\n\t/* Well, that's kinda nasty ... */\n\tlist_for_each_entry(ifp, &idev->addr_list, if_list) {\n\t\tspin_lock(&ifp->lock);\n\t\tif (ifp->tokenized) {\n\t\t\tifp->valid_lft = 0;\n\t\t\tifp->prefered_lft = 0;\n\t\t}\n\t\tspin_unlock(&ifp->lock);\n\t}\n\n\twrite_unlock_bh(&idev->lock);\n\tinet6_ifinfo_notify(RTM_NEWLINK, idev);\n\taddrconf_verify_rtnl();\n\treturn 0;\n}\n\nstatic const struct nla_policy inet6_af_policy[IFLA_INET6_MAX + 1] = {\n\t[IFLA_INET6_ADDR_GEN_MODE]\t= { .type = NLA_U8 },\n\t[IFLA_INET6_TOKEN]\t\t= { .len = sizeof(struct in6_addr) },\n};\n\nstatic int check_addr_gen_mode(int mode)\n{\n\tif (mode != IN6_ADDR_GEN_MODE_EUI64 &&\n\t    mode != IN6_ADDR_GEN_MODE_NONE &&\n\t    mode != IN6_ADDR_GEN_MODE_STABLE_PRIVACY &&\n\t    mode != IN6_ADDR_GEN_MODE_RANDOM)\n\t\treturn -EINVAL;\n\treturn 1;\n}\n\nstatic int check_stable_privacy(struct inet6_dev *idev, struct net *net,\n\t\t\t\tint mode)\n{\n\tif (mode == IN6_ADDR_GEN_MODE_STABLE_PRIVACY &&\n\t    !idev->cnf.stable_secret.initialized &&\n\t    !net->ipv6.devconf_dflt->stable_secret.initialized)\n\t\treturn -EINVAL;\n\treturn 1;\n}\n\nstatic int inet6_validate_link_af(const struct net_device *dev,\n\t\t\t\t  const struct nlattr *nla)\n{\n\tstruct nlattr *tb[IFLA_INET6_MAX + 1];\n\tstruct inet6_dev *idev = NULL;\n\tint err;\n\n\tif (dev) {\n\t\tidev = __in6_dev_get(dev);\n\t\tif (!idev)\n\t\t\treturn -EAFNOSUPPORT;\n\t}\n\n\terr = nla_parse_nested_deprecated(tb, IFLA_INET6_MAX, nla,\n\t\t\t\t\t  inet6_af_policy, NULL);\n\tif (err)\n\t\treturn err;\n\n\tif (!tb[IFLA_INET6_TOKEN] && !tb[IFLA_INET6_ADDR_GEN_MODE])\n\t\treturn -EINVAL;\n\n\tif (tb[IFLA_INET6_ADDR_GEN_MODE]) {\n\t\tu8 mode = nla_get_u8(tb[IFLA_INET6_ADDR_GEN_MODE]);\n\n\t\tif (check_addr_gen_mode(mode) < 0)\n\t\t\treturn -EINVAL;\n\t\tif (dev && check_stable_privacy(idev, dev_net(dev), mode) < 0)\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int inet6_set_link_af(struct net_device *dev, const struct nlattr *nla)\n{\n\tstruct inet6_dev *idev = __in6_dev_get(dev);\n\tstruct nlattr *tb[IFLA_INET6_MAX + 1];\n\tint err;\n\n\tif (!idev)\n\t\treturn -EAFNOSUPPORT;\n\n\tif (nla_parse_nested_deprecated(tb, IFLA_INET6_MAX, nla, NULL, NULL) < 0)\n\t\tBUG();\n\n\tif (tb[IFLA_INET6_TOKEN]) {\n\t\terr = inet6_set_iftoken(idev, nla_data(tb[IFLA_INET6_TOKEN]));\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tif (tb[IFLA_INET6_ADDR_GEN_MODE]) {\n\t\tu8 mode = nla_get_u8(tb[IFLA_INET6_ADDR_GEN_MODE]);\n\n\t\tidev->cnf.addr_gen_mode = mode;\n\t}\n\n\treturn 0;\n}\n\nstatic int inet6_fill_ifinfo(struct sk_buff *skb, struct inet6_dev *idev,\n\t\t\t     u32 portid, u32 seq, int event, unsigned int flags)\n{\n\tstruct net_device *dev = idev->dev;\n\tstruct ifinfomsg *hdr;\n\tstruct nlmsghdr *nlh;\n\tvoid *protoinfo;\n\n\tnlh = nlmsg_put(skb, portid, seq, event, sizeof(*hdr), flags);\n\tif (!nlh)\n\t\treturn -EMSGSIZE;\n\n\thdr = nlmsg_data(nlh);\n\thdr->ifi_family = AF_INET6;\n\thdr->__ifi_pad = 0;\n\thdr->ifi_type = dev->type;\n\thdr->ifi_index = dev->ifindex;\n\thdr->ifi_flags = dev_get_flags(dev);\n\thdr->ifi_change = 0;\n\n\tif (nla_put_string(skb, IFLA_IFNAME, dev->name) ||\n\t    (dev->addr_len &&\n\t     nla_put(skb, IFLA_ADDRESS, dev->addr_len, dev->dev_addr)) ||\n\t    nla_put_u32(skb, IFLA_MTU, dev->mtu) ||\n\t    (dev->ifindex != dev_get_iflink(dev) &&\n\t     nla_put_u32(skb, IFLA_LINK, dev_get_iflink(dev))) ||\n\t    nla_put_u8(skb, IFLA_OPERSTATE,\n\t\t       netif_running(dev) ? dev->operstate : IF_OPER_DOWN))\n\t\tgoto nla_put_failure;\n\tprotoinfo = nla_nest_start_noflag(skb, IFLA_PROTINFO);\n\tif (!protoinfo)\n\t\tgoto nla_put_failure;\n\n\tif (inet6_fill_ifla6_attrs(skb, idev, 0) < 0)\n\t\tgoto nla_put_failure;\n\n\tnla_nest_end(skb, protoinfo);\n\tnlmsg_end(skb, nlh);\n\treturn 0;\n\nnla_put_failure:\n\tnlmsg_cancel(skb, nlh);\n\treturn -EMSGSIZE;\n}\n\nstatic int inet6_valid_dump_ifinfo(const struct nlmsghdr *nlh,\n\t\t\t\t   struct netlink_ext_ack *extack)\n{\n\tstruct ifinfomsg *ifm;\n\n\tif (nlh->nlmsg_len < nlmsg_msg_size(sizeof(*ifm))) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Invalid header for link dump request\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (nlmsg_attrlen(nlh, sizeof(*ifm))) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Invalid data after header\");\n\t\treturn -EINVAL;\n\t}\n\n\tifm = nlmsg_data(nlh);\n\tif (ifm->__ifi_pad || ifm->ifi_type || ifm->ifi_flags ||\n\t    ifm->ifi_change || ifm->ifi_index) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Invalid values in header for dump request\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int inet6_dump_ifinfo(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tint h, s_h;\n\tint idx = 0, s_idx;\n\tstruct net_device *dev;\n\tstruct inet6_dev *idev;\n\tstruct hlist_head *head;\n\n\t/* only requests using strict checking can pass data to\n\t * influence the dump\n\t */\n\tif (cb->strict_check) {\n\t\tint err = inet6_valid_dump_ifinfo(cb->nlh, cb->extack);\n\n\t\tif (err < 0)\n\t\t\treturn err;\n\t}\n\n\ts_h = cb->args[0];\n\ts_idx = cb->args[1];\n\n\trcu_read_lock();\n\tfor (h = s_h; h < NETDEV_HASHENTRIES; h++, s_idx = 0) {\n\t\tidx = 0;\n\t\thead = &net->dev_index_head[h];\n\t\thlist_for_each_entry_rcu(dev, head, index_hlist) {\n\t\t\tif (idx < s_idx)\n\t\t\t\tgoto cont;\n\t\t\tidev = __in6_dev_get(dev);\n\t\t\tif (!idev)\n\t\t\t\tgoto cont;\n\t\t\tif (inet6_fill_ifinfo(skb, idev,\n\t\t\t\t\t      NETLINK_CB(cb->skb).portid,\n\t\t\t\t\t      cb->nlh->nlmsg_seq,\n\t\t\t\t\t      RTM_NEWLINK, NLM_F_MULTI) < 0)\n\t\t\t\tgoto out;\ncont:\n\t\t\tidx++;\n\t\t}\n\t}\nout:\n\trcu_read_unlock();\n\tcb->args[1] = idx;\n\tcb->args[0] = h;\n\n\treturn skb->len;\n}\n\nvoid inet6_ifinfo_notify(int event, struct inet6_dev *idev)\n{\n\tstruct sk_buff *skb;\n\tstruct net *net = dev_net(idev->dev);\n\tint err = -ENOBUFS;\n\n\tskb = nlmsg_new(inet6_if_nlmsg_size(), GFP_ATOMIC);\n\tif (!skb)\n\t\tgoto errout;\n\n\terr = inet6_fill_ifinfo(skb, idev, 0, 0, event, 0);\n\tif (err < 0) {\n\t\t/* -EMSGSIZE implies BUG in inet6_if_nlmsg_size() */\n\t\tWARN_ON(err == -EMSGSIZE);\n\t\tkfree_skb(skb);\n\t\tgoto errout;\n\t}\n\trtnl_notify(skb, net, 0, RTNLGRP_IPV6_IFINFO, NULL, GFP_ATOMIC);\n\treturn;\nerrout:\n\tif (err < 0)\n\t\trtnl_set_sk_err(net, RTNLGRP_IPV6_IFINFO, err);\n}\n\nstatic inline size_t inet6_prefix_nlmsg_size(void)\n{\n\treturn NLMSG_ALIGN(sizeof(struct prefixmsg))\n\t       + nla_total_size(sizeof(struct in6_addr))\n\t       + nla_total_size(sizeof(struct prefix_cacheinfo));\n}\n\nstatic int inet6_fill_prefix(struct sk_buff *skb, struct inet6_dev *idev,\n\t\t\t     struct prefix_info *pinfo, u32 portid, u32 seq,\n\t\t\t     int event, unsigned int flags)\n{\n\tstruct prefixmsg *pmsg;\n\tstruct nlmsghdr *nlh;\n\tstruct prefix_cacheinfo\tci;\n\n\tnlh = nlmsg_put(skb, portid, seq, event, sizeof(*pmsg), flags);\n\tif (!nlh)\n\t\treturn -EMSGSIZE;\n\n\tpmsg = nlmsg_data(nlh);\n\tpmsg->prefix_family = AF_INET6;\n\tpmsg->prefix_pad1 = 0;\n\tpmsg->prefix_pad2 = 0;\n\tpmsg->prefix_ifindex = idev->dev->ifindex;\n\tpmsg->prefix_len = pinfo->prefix_len;\n\tpmsg->prefix_type = pinfo->type;\n\tpmsg->prefix_pad3 = 0;\n\tpmsg->prefix_flags = 0;\n\tif (pinfo->onlink)\n\t\tpmsg->prefix_flags |= IF_PREFIX_ONLINK;\n\tif (pinfo->autoconf)\n\t\tpmsg->prefix_flags |= IF_PREFIX_AUTOCONF;\n\n\tif (nla_put(skb, PREFIX_ADDRESS, sizeof(pinfo->prefix), &pinfo->prefix))\n\t\tgoto nla_put_failure;\n\tci.preferred_time = ntohl(pinfo->prefered);\n\tci.valid_time = ntohl(pinfo->valid);\n\tif (nla_put(skb, PREFIX_CACHEINFO, sizeof(ci), &ci))\n\t\tgoto nla_put_failure;\n\tnlmsg_end(skb, nlh);\n\treturn 0;\n\nnla_put_failure:\n\tnlmsg_cancel(skb, nlh);\n\treturn -EMSGSIZE;\n}\n\nstatic void inet6_prefix_notify(int event, struct inet6_dev *idev,\n\t\t\t struct prefix_info *pinfo)\n{\n\tstruct sk_buff *skb;\n\tstruct net *net = dev_net(idev->dev);\n\tint err = -ENOBUFS;\n\n\tskb = nlmsg_new(inet6_prefix_nlmsg_size(), GFP_ATOMIC);\n\tif (!skb)\n\t\tgoto errout;\n\n\terr = inet6_fill_prefix(skb, idev, pinfo, 0, 0, event, 0);\n\tif (err < 0) {\n\t\t/* -EMSGSIZE implies BUG in inet6_prefix_nlmsg_size() */\n\t\tWARN_ON(err == -EMSGSIZE);\n\t\tkfree_skb(skb);\n\t\tgoto errout;\n\t}\n\trtnl_notify(skb, net, 0, RTNLGRP_IPV6_PREFIX, NULL, GFP_ATOMIC);\n\treturn;\nerrout:\n\tif (err < 0)\n\t\trtnl_set_sk_err(net, RTNLGRP_IPV6_PREFIX, err);\n}\n\nstatic void __ipv6_ifa_notify(int event, struct inet6_ifaddr *ifp)\n{\n\tstruct net *net = dev_net(ifp->idev->dev);\n\n\tif (event)\n\t\tASSERT_RTNL();\n\n\tinet6_ifa_notify(event ? : RTM_NEWADDR, ifp);\n\n\tswitch (event) {\n\tcase RTM_NEWADDR:\n\t\t/*\n\t\t * If the address was optimistic we inserted the route at the\n\t\t * start of our DAD process, so we don't need to do it again.\n\t\t * If the device was taken down in the middle of the DAD\n\t\t * cycle there is a race where we could get here without a\n\t\t * host route, so nothing to insert. That will be fixed when\n\t\t * the device is brought up.\n\t\t */\n\t\tif (ifp->rt && !rcu_access_pointer(ifp->rt->fib6_node)) {\n\t\t\tip6_ins_rt(net, ifp->rt);\n\t\t} else if (!ifp->rt && (ifp->idev->dev->flags & IFF_UP)) {\n\t\t\tpr_warn(\"BUG: Address %pI6c on device %s is missing its host route.\\n\",\n\t\t\t\t&ifp->addr, ifp->idev->dev->name);\n\t\t}\n\n\t\tif (ifp->idev->cnf.forwarding)\n\t\t\taddrconf_join_anycast(ifp);\n\t\tif (!ipv6_addr_any(&ifp->peer_addr))\n\t\t\taddrconf_prefix_route(&ifp->peer_addr, 128,\n\t\t\t\t\t      ifp->rt_priority, ifp->idev->dev,\n\t\t\t\t\t      0, 0, GFP_ATOMIC);\n\t\tbreak;\n\tcase RTM_DELADDR:\n\t\tif (ifp->idev->cnf.forwarding)\n\t\t\taddrconf_leave_anycast(ifp);\n\t\taddrconf_leave_solict(ifp->idev, &ifp->addr);\n\t\tif (!ipv6_addr_any(&ifp->peer_addr)) {\n\t\t\tstruct fib6_info *rt;\n\n\t\t\trt = addrconf_get_prefix_route(&ifp->peer_addr, 128,\n\t\t\t\t\t\t       ifp->idev->dev, 0, 0,\n\t\t\t\t\t\t       false);\n\t\t\tif (rt)\n\t\t\t\tip6_del_rt(net, rt, false);\n\t\t}\n\t\tif (ifp->rt) {\n\t\t\tip6_del_rt(net, ifp->rt, false);\n\t\t\tifp->rt = NULL;\n\t\t}\n\t\trt_genid_bump_ipv6(net);\n\t\tbreak;\n\t}\n\tatomic_inc(&net->ipv6.dev_addr_genid);\n}\n\nstatic void ipv6_ifa_notify(int event, struct inet6_ifaddr *ifp)\n{\n\trcu_read_lock_bh();\n\tif (likely(ifp->idev->dead == 0))\n\t\t__ipv6_ifa_notify(event, ifp);\n\trcu_read_unlock_bh();\n}\n\n#ifdef CONFIG_SYSCTL\n\nstatic int addrconf_sysctl_forward(struct ctl_table *ctl, int write,\n\t\tvoid *buffer, size_t *lenp, loff_t *ppos)\n{\n\tint *valp = ctl->data;\n\tint val = *valp;\n\tloff_t pos = *ppos;\n\tstruct ctl_table lctl;\n\tint ret;\n\n\t/*\n\t * ctl->data points to idev->cnf.forwarding, we should\n\t * not modify it until we get the rtnl lock.\n\t */\n\tlctl = *ctl;\n\tlctl.data = &val;\n\n\tret = proc_dointvec(&lctl, write, buffer, lenp, ppos);\n\n\tif (write)\n\t\tret = addrconf_fixup_forwarding(ctl, valp, val);\n\tif (ret)\n\t\t*ppos = pos;\n\treturn ret;\n}\n\nstatic int addrconf_sysctl_mtu(struct ctl_table *ctl, int write,\n\t\tvoid *buffer, size_t *lenp, loff_t *ppos)\n{\n\tstruct inet6_dev *idev = ctl->extra1;\n\tint min_mtu = IPV6_MIN_MTU;\n\tstruct ctl_table lctl;\n\n\tlctl = *ctl;\n\tlctl.extra1 = &min_mtu;\n\tlctl.extra2 = idev ? &idev->dev->mtu : NULL;\n\n\treturn proc_dointvec_minmax(&lctl, write, buffer, lenp, ppos);\n}\n\nstatic void dev_disable_change(struct inet6_dev *idev)\n{\n\tstruct netdev_notifier_info info;\n\n\tif (!idev || !idev->dev)\n\t\treturn;\n\n\tnetdev_notifier_info_init(&info, idev->dev);\n\tif (idev->cnf.disable_ipv6)\n\t\taddrconf_notify(NULL, NETDEV_DOWN, &info);\n\telse\n\t\taddrconf_notify(NULL, NETDEV_UP, &info);\n}\n\nstatic void addrconf_disable_change(struct net *net, __s32 newf)\n{\n\tstruct net_device *dev;\n\tstruct inet6_dev *idev;\n\n\tfor_each_netdev(net, dev) {\n\t\tidev = __in6_dev_get(dev);\n\t\tif (idev) {\n\t\t\tint changed = (!idev->cnf.disable_ipv6) ^ (!newf);\n\t\t\tidev->cnf.disable_ipv6 = newf;\n\t\t\tif (changed)\n\t\t\t\tdev_disable_change(idev);\n\t\t}\n\t}\n}\n\nstatic int addrconf_disable_ipv6(struct ctl_table *table, int *p, int newf)\n{\n\tstruct net *net;\n\tint old;\n\n\tif (!rtnl_trylock())\n\t\treturn restart_syscall();\n\n\tnet = (struct net *)table->extra2;\n\told = *p;\n\t*p = newf;\n\n\tif (p == &net->ipv6.devconf_dflt->disable_ipv6) {\n\t\trtnl_unlock();\n\t\treturn 0;\n\t}\n\n\tif (p == &net->ipv6.devconf_all->disable_ipv6) {\n\t\tnet->ipv6.devconf_dflt->disable_ipv6 = newf;\n\t\taddrconf_disable_change(net, newf);\n\t} else if ((!newf) ^ (!old))\n\t\tdev_disable_change((struct inet6_dev *)table->extra1);\n\n\trtnl_unlock();\n\treturn 0;\n}\n\nstatic int addrconf_sysctl_disable(struct ctl_table *ctl, int write,\n\t\tvoid *buffer, size_t *lenp, loff_t *ppos)\n{\n\tint *valp = ctl->data;\n\tint val = *valp;\n\tloff_t pos = *ppos;\n\tstruct ctl_table lctl;\n\tint ret;\n\n\t/*\n\t * ctl->data points to idev->cnf.disable_ipv6, we should\n\t * not modify it until we get the rtnl lock.\n\t */\n\tlctl = *ctl;\n\tlctl.data = &val;\n\n\tret = proc_dointvec(&lctl, write, buffer, lenp, ppos);\n\n\tif (write)\n\t\tret = addrconf_disable_ipv6(ctl, valp, val);\n\tif (ret)\n\t\t*ppos = pos;\n\treturn ret;\n}\n\nstatic int addrconf_sysctl_proxy_ndp(struct ctl_table *ctl, int write,\n\t\tvoid *buffer, size_t *lenp, loff_t *ppos)\n{\n\tint *valp = ctl->data;\n\tint ret;\n\tint old, new;\n\n\told = *valp;\n\tret = proc_dointvec(ctl, write, buffer, lenp, ppos);\n\tnew = *valp;\n\n\tif (write && old != new) {\n\t\tstruct net *net = ctl->extra2;\n\n\t\tif (!rtnl_trylock())\n\t\t\treturn restart_syscall();\n\n\t\tif (valp == &net->ipv6.devconf_dflt->proxy_ndp)\n\t\t\tinet6_netconf_notify_devconf(net, RTM_NEWNETCONF,\n\t\t\t\t\t\t     NETCONFA_PROXY_NEIGH,\n\t\t\t\t\t\t     NETCONFA_IFINDEX_DEFAULT,\n\t\t\t\t\t\t     net->ipv6.devconf_dflt);\n\t\telse if (valp == &net->ipv6.devconf_all->proxy_ndp)\n\t\t\tinet6_netconf_notify_devconf(net, RTM_NEWNETCONF,\n\t\t\t\t\t\t     NETCONFA_PROXY_NEIGH,\n\t\t\t\t\t\t     NETCONFA_IFINDEX_ALL,\n\t\t\t\t\t\t     net->ipv6.devconf_all);\n\t\telse {\n\t\t\tstruct inet6_dev *idev = ctl->extra1;\n\n\t\t\tinet6_netconf_notify_devconf(net, RTM_NEWNETCONF,\n\t\t\t\t\t\t     NETCONFA_PROXY_NEIGH,\n\t\t\t\t\t\t     idev->dev->ifindex,\n\t\t\t\t\t\t     &idev->cnf);\n\t\t}\n\t\trtnl_unlock();\n\t}\n\n\treturn ret;\n}\n\nstatic int addrconf_sysctl_addr_gen_mode(struct ctl_table *ctl, int write,\n\t\t\t\t\t void *buffer, size_t *lenp,\n\t\t\t\t\t loff_t *ppos)\n{\n\tint ret = 0;\n\tu32 new_val;\n\tstruct inet6_dev *idev = (struct inet6_dev *)ctl->extra1;\n\tstruct net *net = (struct net *)ctl->extra2;\n\tstruct ctl_table tmp = {\n\t\t.data = &new_val,\n\t\t.maxlen = sizeof(new_val),\n\t\t.mode = ctl->mode,\n\t};\n\n\tif (!rtnl_trylock())\n\t\treturn restart_syscall();\n\n\tnew_val = *((u32 *)ctl->data);\n\n\tret = proc_douintvec(&tmp, write, buffer, lenp, ppos);\n\tif (ret != 0)\n\t\tgoto out;\n\n\tif (write) {\n\t\tif (check_addr_gen_mode(new_val) < 0) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (idev) {\n\t\t\tif (check_stable_privacy(idev, net, new_val) < 0) {\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tif (idev->cnf.addr_gen_mode != new_val) {\n\t\t\t\tidev->cnf.addr_gen_mode = new_val;\n\t\t\t\taddrconf_dev_config(idev->dev);\n\t\t\t}\n\t\t} else if (&net->ipv6.devconf_all->addr_gen_mode == ctl->data) {\n\t\t\tstruct net_device *dev;\n\n\t\t\tnet->ipv6.devconf_dflt->addr_gen_mode = new_val;\n\t\t\tfor_each_netdev(net, dev) {\n\t\t\t\tidev = __in6_dev_get(dev);\n\t\t\t\tif (idev &&\n\t\t\t\t    idev->cnf.addr_gen_mode != new_val) {\n\t\t\t\t\tidev->cnf.addr_gen_mode = new_val;\n\t\t\t\t\taddrconf_dev_config(idev->dev);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t*((u32 *)ctl->data) = new_val;\n\t}\n\nout:\n\trtnl_unlock();\n\n\treturn ret;\n}\n\nstatic int addrconf_sysctl_stable_secret(struct ctl_table *ctl, int write,\n\t\t\t\t\t void *buffer, size_t *lenp,\n\t\t\t\t\t loff_t *ppos)\n{\n\tint err;\n\tstruct in6_addr addr;\n\tchar str[IPV6_MAX_STRLEN];\n\tstruct ctl_table lctl = *ctl;\n\tstruct net *net = ctl->extra2;\n\tstruct ipv6_stable_secret *secret = ctl->data;\n\n\tif (&net->ipv6.devconf_all->stable_secret == ctl->data)\n\t\treturn -EIO;\n\n\tlctl.maxlen = IPV6_MAX_STRLEN;\n\tlctl.data = str;\n\n\tif (!rtnl_trylock())\n\t\treturn restart_syscall();\n\n\tif (!write && !secret->initialized) {\n\t\terr = -EIO;\n\t\tgoto out;\n\t}\n\n\terr = snprintf(str, sizeof(str), \"%pI6\", &secret->secret);\n\tif (err >= sizeof(str)) {\n\t\terr = -EIO;\n\t\tgoto out;\n\t}\n\n\terr = proc_dostring(&lctl, write, buffer, lenp, ppos);\n\tif (err || !write)\n\t\tgoto out;\n\n\tif (in6_pton(str, -1, addr.in6_u.u6_addr8, -1, NULL) != 1) {\n\t\terr = -EIO;\n\t\tgoto out;\n\t}\n\n\tsecret->initialized = true;\n\tsecret->secret = addr;\n\n\tif (&net->ipv6.devconf_dflt->stable_secret == ctl->data) {\n\t\tstruct net_device *dev;\n\n\t\tfor_each_netdev(net, dev) {\n\t\t\tstruct inet6_dev *idev = __in6_dev_get(dev);\n\n\t\t\tif (idev) {\n\t\t\t\tidev->cnf.addr_gen_mode =\n\t\t\t\t\tIN6_ADDR_GEN_MODE_STABLE_PRIVACY;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tstruct inet6_dev *idev = ctl->extra1;\n\n\t\tidev->cnf.addr_gen_mode = IN6_ADDR_GEN_MODE_STABLE_PRIVACY;\n\t}\n\nout:\n\trtnl_unlock();\n\n\treturn err;\n}\n\nstatic\nint addrconf_sysctl_ignore_routes_with_linkdown(struct ctl_table *ctl,\n\t\t\t\t\t\tint write, void *buffer,\n\t\t\t\t\t\tsize_t *lenp,\n\t\t\t\t\t\tloff_t *ppos)\n{\n\tint *valp = ctl->data;\n\tint val = *valp;\n\tloff_t pos = *ppos;\n\tstruct ctl_table lctl;\n\tint ret;\n\n\t/* ctl->data points to idev->cnf.ignore_routes_when_linkdown\n\t * we should not modify it until we get the rtnl lock.\n\t */\n\tlctl = *ctl;\n\tlctl.data = &val;\n\n\tret = proc_dointvec(&lctl, write, buffer, lenp, ppos);\n\n\tif (write)\n\t\tret = addrconf_fixup_linkdown(ctl, valp, val);\n\tif (ret)\n\t\t*ppos = pos;\n\treturn ret;\n}\n\nstatic\nvoid addrconf_set_nopolicy(struct rt6_info *rt, int action)\n{\n\tif (rt) {\n\t\tif (action)\n\t\t\trt->dst.flags |= DST_NOPOLICY;\n\t\telse\n\t\t\trt->dst.flags &= ~DST_NOPOLICY;\n\t}\n}\n\nstatic\nvoid addrconf_disable_policy_idev(struct inet6_dev *idev, int val)\n{\n\tstruct inet6_ifaddr *ifa;\n\n\tread_lock_bh(&idev->lock);\n\tlist_for_each_entry(ifa, &idev->addr_list, if_list) {\n\t\tspin_lock(&ifa->lock);\n\t\tif (ifa->rt) {\n\t\t\t/* host routes only use builtin fib6_nh */\n\t\t\tstruct fib6_nh *nh = ifa->rt->fib6_nh;\n\t\t\tint cpu;\n\n\t\t\trcu_read_lock();\n\t\t\tifa->rt->dst_nopolicy = val ? true : false;\n\t\t\tif (nh->rt6i_pcpu) {\n\t\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\t\tstruct rt6_info **rtp;\n\n\t\t\t\t\trtp = per_cpu_ptr(nh->rt6i_pcpu, cpu);\n\t\t\t\t\taddrconf_set_nopolicy(*rtp, val);\n\t\t\t\t}\n\t\t\t}\n\t\t\trcu_read_unlock();\n\t\t}\n\t\tspin_unlock(&ifa->lock);\n\t}\n\tread_unlock_bh(&idev->lock);\n}\n\nstatic\nint addrconf_disable_policy(struct ctl_table *ctl, int *valp, int val)\n{\n\tstruct inet6_dev *idev;\n\tstruct net *net;\n\n\tif (!rtnl_trylock())\n\t\treturn restart_syscall();\n\n\t*valp = val;\n\n\tnet = (struct net *)ctl->extra2;\n\tif (valp == &net->ipv6.devconf_dflt->disable_policy) {\n\t\trtnl_unlock();\n\t\treturn 0;\n\t}\n\n\tif (valp == &net->ipv6.devconf_all->disable_policy)  {\n\t\tstruct net_device *dev;\n\n\t\tfor_each_netdev(net, dev) {\n\t\t\tidev = __in6_dev_get(dev);\n\t\t\tif (idev)\n\t\t\t\taddrconf_disable_policy_idev(idev, val);\n\t\t}\n\t} else {\n\t\tidev = (struct inet6_dev *)ctl->extra1;\n\t\taddrconf_disable_policy_idev(idev, val);\n\t}\n\n\trtnl_unlock();\n\treturn 0;\n}\n\nstatic int addrconf_sysctl_disable_policy(struct ctl_table *ctl, int write,\n\t\t\t\t   void *buffer, size_t *lenp, loff_t *ppos)\n{\n\tint *valp = ctl->data;\n\tint val = *valp;\n\tloff_t pos = *ppos;\n\tstruct ctl_table lctl;\n\tint ret;\n\n\tlctl = *ctl;\n\tlctl.data = &val;\n\tret = proc_dointvec(&lctl, write, buffer, lenp, ppos);\n\n\tif (write && (*valp != val))\n\t\tret = addrconf_disable_policy(ctl, valp, val);\n\n\tif (ret)\n\t\t*ppos = pos;\n\n\treturn ret;\n}\n\nstatic int minus_one = -1;\nstatic const int two_five_five = 255;\n\nstatic const struct ctl_table addrconf_sysctl[] = {\n\t{\n\t\t.procname\t= \"forwarding\",\n\t\t.data\t\t= &ipv6_devconf.forwarding,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= addrconf_sysctl_forward,\n\t},\n\t{\n\t\t.procname\t= \"hop_limit\",\n\t\t.data\t\t= &ipv6_devconf.hop_limit,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec_minmax,\n\t\t.extra1\t\t= (void *)SYSCTL_ONE,\n\t\t.extra2\t\t= (void *)&two_five_five,\n\t},\n\t{\n\t\t.procname\t= \"mtu\",\n\t\t.data\t\t= &ipv6_devconf.mtu6,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= addrconf_sysctl_mtu,\n\t},\n\t{\n\t\t.procname\t= \"accept_ra\",\n\t\t.data\t\t= &ipv6_devconf.accept_ra,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{\n\t\t.procname\t= \"accept_redirects\",\n\t\t.data\t\t= &ipv6_devconf.accept_redirects,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{\n\t\t.procname\t= \"autoconf\",\n\t\t.data\t\t= &ipv6_devconf.autoconf,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{\n\t\t.procname\t= \"dad_transmits\",\n\t\t.data\t\t= &ipv6_devconf.dad_transmits,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{\n\t\t.procname\t= \"router_solicitations\",\n\t\t.data\t\t= &ipv6_devconf.rtr_solicits,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec_minmax,\n\t\t.extra1\t\t= &minus_one,\n\t},\n\t{\n\t\t.procname\t= \"router_solicitation_interval\",\n\t\t.data\t\t= &ipv6_devconf.rtr_solicit_interval,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec_jiffies,\n\t},\n\t{\n\t\t.procname\t= \"router_solicitation_max_interval\",\n\t\t.data\t\t= &ipv6_devconf.rtr_solicit_max_interval,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec_jiffies,\n\t},\n\t{\n\t\t.procname\t= \"router_solicitation_delay\",\n\t\t.data\t\t= &ipv6_devconf.rtr_solicit_delay,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec_jiffies,\n\t},\n\t{\n\t\t.procname\t= \"force_mld_version\",\n\t\t.data\t\t= &ipv6_devconf.force_mld_version,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{\n\t\t.procname\t= \"mldv1_unsolicited_report_interval\",\n\t\t.data\t\t=\n\t\t\t&ipv6_devconf.mldv1_unsolicited_report_interval,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec_ms_jiffies,\n\t},\n\t{\n\t\t.procname\t= \"mldv2_unsolicited_report_interval\",\n\t\t.data\t\t=\n\t\t\t&ipv6_devconf.mldv2_unsolicited_report_interval,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec_ms_jiffies,\n\t},\n\t{\n\t\t.procname\t= \"use_tempaddr\",\n\t\t.data\t\t= &ipv6_devconf.use_tempaddr,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{\n\t\t.procname\t= \"temp_valid_lft\",\n\t\t.data\t\t= &ipv6_devconf.temp_valid_lft,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{\n\t\t.procname\t= \"temp_prefered_lft\",\n\t\t.data\t\t= &ipv6_devconf.temp_prefered_lft,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{\n\t\t.procname\t= \"regen_max_retry\",\n\t\t.data\t\t= &ipv6_devconf.regen_max_retry,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{\n\t\t.procname\t= \"max_desync_factor\",\n\t\t.data\t\t= &ipv6_devconf.max_desync_factor,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{\n\t\t.procname\t= \"max_addresses\",\n\t\t.data\t\t= &ipv6_devconf.max_addresses,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{\n\t\t.procname\t= \"accept_ra_defrtr\",\n\t\t.data\t\t= &ipv6_devconf.accept_ra_defrtr,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{\n\t\t.procname\t= \"ra_defrtr_metric\",\n\t\t.data\t\t= &ipv6_devconf.ra_defrtr_metric,\n\t\t.maxlen\t\t= sizeof(u32),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_douintvec_minmax,\n\t\t.extra1\t\t= (void *)SYSCTL_ONE,\n\t},\n\t{\n\t\t.procname\t= \"accept_ra_min_hop_limit\",\n\t\t.data\t\t= &ipv6_devconf.accept_ra_min_hop_limit,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{\n\t\t.procname\t= \"accept_ra_pinfo\",\n\t\t.data\t\t= &ipv6_devconf.accept_ra_pinfo,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n#ifdef CONFIG_IPV6_ROUTER_PREF\n\t{\n\t\t.procname\t= \"accept_ra_rtr_pref\",\n\t\t.data\t\t= &ipv6_devconf.accept_ra_rtr_pref,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{\n\t\t.procname\t= \"router_probe_interval\",\n\t\t.data\t\t= &ipv6_devconf.rtr_probe_interval,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec_jiffies,\n\t},\n#ifdef CONFIG_IPV6_ROUTE_INFO\n\t{\n\t\t.procname\t= \"accept_ra_rt_info_min_plen\",\n\t\t.data\t\t= &ipv6_devconf.accept_ra_rt_info_min_plen,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{\n\t\t.procname\t= \"accept_ra_rt_info_max_plen\",\n\t\t.data\t\t= &ipv6_devconf.accept_ra_rt_info_max_plen,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n#endif\n#endif\n\t{\n\t\t.procname\t= \"proxy_ndp\",\n\t\t.data\t\t= &ipv6_devconf.proxy_ndp,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= addrconf_sysctl_proxy_ndp,\n\t},\n\t{\n\t\t.procname\t= \"accept_source_route\",\n\t\t.data\t\t= &ipv6_devconf.accept_source_route,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n#ifdef CONFIG_IPV6_OPTIMISTIC_DAD\n\t{\n\t\t.procname\t= \"optimistic_dad\",\n\t\t.data\t\t= &ipv6_devconf.optimistic_dad,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler   = proc_dointvec,\n\t},\n\t{\n\t\t.procname\t= \"use_optimistic\",\n\t\t.data\t\t= &ipv6_devconf.use_optimistic,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n#endif\n#ifdef CONFIG_IPV6_MROUTE\n\t{\n\t\t.procname\t= \"mc_forwarding\",\n\t\t.data\t\t= &ipv6_devconf.mc_forwarding,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0444,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n#endif\n\t{\n\t\t.procname\t= \"disable_ipv6\",\n\t\t.data\t\t= &ipv6_devconf.disable_ipv6,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= addrconf_sysctl_disable,\n\t},\n\t{\n\t\t.procname\t= \"accept_dad\",\n\t\t.data\t\t= &ipv6_devconf.accept_dad,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{\n\t\t.procname\t= \"force_tllao\",\n\t\t.data\t\t= &ipv6_devconf.force_tllao,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec\n\t},\n\t{\n\t\t.procname\t= \"ndisc_notify\",\n\t\t.data\t\t= &ipv6_devconf.ndisc_notify,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec\n\t},\n\t{\n\t\t.procname\t= \"suppress_frag_ndisc\",\n\t\t.data\t\t= &ipv6_devconf.suppress_frag_ndisc,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec\n\t},\n\t{\n\t\t.procname\t= \"accept_ra_from_local\",\n\t\t.data\t\t= &ipv6_devconf.accept_ra_from_local,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{\n\t\t.procname\t= \"accept_ra_mtu\",\n\t\t.data\t\t= &ipv6_devconf.accept_ra_mtu,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{\n\t\t.procname\t= \"stable_secret\",\n\t\t.data\t\t= &ipv6_devconf.stable_secret,\n\t\t.maxlen\t\t= IPV6_MAX_STRLEN,\n\t\t.mode\t\t= 0600,\n\t\t.proc_handler\t= addrconf_sysctl_stable_secret,\n\t},\n\t{\n\t\t.procname\t= \"use_oif_addrs_only\",\n\t\t.data\t\t= &ipv6_devconf.use_oif_addrs_only,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{\n\t\t.procname\t= \"ignore_routes_with_linkdown\",\n\t\t.data\t\t= &ipv6_devconf.ignore_routes_with_linkdown,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= addrconf_sysctl_ignore_routes_with_linkdown,\n\t},\n\t{\n\t\t.procname\t= \"drop_unicast_in_l2_multicast\",\n\t\t.data\t\t= &ipv6_devconf.drop_unicast_in_l2_multicast,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{\n\t\t.procname\t= \"drop_unsolicited_na\",\n\t\t.data\t\t= &ipv6_devconf.drop_unsolicited_na,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{\n\t\t.procname\t= \"keep_addr_on_down\",\n\t\t.data\t\t= &ipv6_devconf.keep_addr_on_down,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\n\t},\n\t{\n\t\t.procname\t= \"seg6_enabled\",\n\t\t.data\t\t= &ipv6_devconf.seg6_enabled,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n#ifdef CONFIG_IPV6_SEG6_HMAC\n\t{\n\t\t.procname\t= \"seg6_require_hmac\",\n\t\t.data\t\t= &ipv6_devconf.seg6_require_hmac,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n#endif\n\t{\n\t\t.procname       = \"enhanced_dad\",\n\t\t.data           = &ipv6_devconf.enhanced_dad,\n\t\t.maxlen         = sizeof(int),\n\t\t.mode           = 0644,\n\t\t.proc_handler   = proc_dointvec,\n\t},\n\t{\n\t\t.procname\t\t= \"addr_gen_mode\",\n\t\t.data\t\t\t= &ipv6_devconf.addr_gen_mode,\n\t\t.maxlen\t\t\t= sizeof(int),\n\t\t.mode\t\t\t= 0644,\n\t\t.proc_handler\t= addrconf_sysctl_addr_gen_mode,\n\t},\n\t{\n\t\t.procname       = \"disable_policy\",\n\t\t.data           = &ipv6_devconf.disable_policy,\n\t\t.maxlen         = sizeof(int),\n\t\t.mode           = 0644,\n\t\t.proc_handler   = addrconf_sysctl_disable_policy,\n\t},\n\t{\n\t\t.procname\t= \"ndisc_tclass\",\n\t\t.data\t\t= &ipv6_devconf.ndisc_tclass,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec_minmax,\n\t\t.extra1\t\t= (void *)SYSCTL_ZERO,\n\t\t.extra2\t\t= (void *)&two_five_five,\n\t},\n\t{\n\t\t.procname\t= \"rpl_seg_enabled\",\n\t\t.data\t\t= &ipv6_devconf.rpl_seg_enabled,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{\n\t\t/* sentinel */\n\t}\n};\n\nstatic int __addrconf_sysctl_register(struct net *net, char *dev_name,\n\t\tstruct inet6_dev *idev, struct ipv6_devconf *p)\n{\n\tint i, ifindex;\n\tstruct ctl_table *table;\n\tchar path[sizeof(\"net/ipv6/conf/\") + IFNAMSIZ];\n\n\ttable = kmemdup(addrconf_sysctl, sizeof(addrconf_sysctl), GFP_KERNEL);\n\tif (!table)\n\t\tgoto out;\n\n\tfor (i = 0; table[i].data; i++) {\n\t\ttable[i].data += (char *)p - (char *)&ipv6_devconf;\n\t\t/* If one of these is already set, then it is not safe to\n\t\t * overwrite either of them: this makes proc_dointvec_minmax\n\t\t * usable.\n\t\t */\n\t\tif (!table[i].extra1 && !table[i].extra2) {\n\t\t\ttable[i].extra1 = idev; /* embedded; no ref */\n\t\t\ttable[i].extra2 = net;\n\t\t}\n\t}\n\n\tsnprintf(path, sizeof(path), \"net/ipv6/conf/%s\", dev_name);\n\n\tp->sysctl_header = register_net_sysctl(net, path, table);\n\tif (!p->sysctl_header)\n\t\tgoto free;\n\n\tif (!strcmp(dev_name, \"all\"))\n\t\tifindex = NETCONFA_IFINDEX_ALL;\n\telse if (!strcmp(dev_name, \"default\"))\n\t\tifindex = NETCONFA_IFINDEX_DEFAULT;\n\telse\n\t\tifindex = idev->dev->ifindex;\n\tinet6_netconf_notify_devconf(net, RTM_NEWNETCONF, NETCONFA_ALL,\n\t\t\t\t     ifindex, p);\n\treturn 0;\n\nfree:\n\tkfree(table);\nout:\n\treturn -ENOBUFS;\n}\n\nstatic void __addrconf_sysctl_unregister(struct net *net,\n\t\t\t\t\t struct ipv6_devconf *p, int ifindex)\n{\n\tstruct ctl_table *table;\n\n\tif (!p->sysctl_header)\n\t\treturn;\n\n\ttable = p->sysctl_header->ctl_table_arg;\n\tunregister_net_sysctl_table(p->sysctl_header);\n\tp->sysctl_header = NULL;\n\tkfree(table);\n\n\tinet6_netconf_notify_devconf(net, RTM_DELNETCONF, 0, ifindex, NULL);\n}\n\nstatic int addrconf_sysctl_register(struct inet6_dev *idev)\n{\n\tint err;\n\n\tif (!sysctl_dev_name_is_allowed(idev->dev->name))\n\t\treturn -EINVAL;\n\n\terr = neigh_sysctl_register(idev->dev, idev->nd_parms,\n\t\t\t\t    &ndisc_ifinfo_sysctl_change);\n\tif (err)\n\t\treturn err;\n\terr = __addrconf_sysctl_register(dev_net(idev->dev), idev->dev->name,\n\t\t\t\t\t idev, &idev->cnf);\n\tif (err)\n\t\tneigh_sysctl_unregister(idev->nd_parms);\n\n\treturn err;\n}\n\nstatic void addrconf_sysctl_unregister(struct inet6_dev *idev)\n{\n\t__addrconf_sysctl_unregister(dev_net(idev->dev), &idev->cnf,\n\t\t\t\t     idev->dev->ifindex);\n\tneigh_sysctl_unregister(idev->nd_parms);\n}\n\n\n#endif\n\nstatic int __net_init addrconf_init_net(struct net *net)\n{\n\tint err = -ENOMEM;\n\tstruct ipv6_devconf *all, *dflt;\n\n\tall = kmemdup(&ipv6_devconf, sizeof(ipv6_devconf), GFP_KERNEL);\n\tif (!all)\n\t\tgoto err_alloc_all;\n\n\tdflt = kmemdup(&ipv6_devconf_dflt, sizeof(ipv6_devconf_dflt), GFP_KERNEL);\n\tif (!dflt)\n\t\tgoto err_alloc_dflt;\n\n\tif (IS_ENABLED(CONFIG_SYSCTL) &&\n\t    !net_eq(net, &init_net)) {\n\t\tswitch (sysctl_devconf_inherit_init_net) {\n\t\tcase 1:  /* copy from init_net */\n\t\t\tmemcpy(all, init_net.ipv6.devconf_all,\n\t\t\t       sizeof(ipv6_devconf));\n\t\t\tmemcpy(dflt, init_net.ipv6.devconf_dflt,\n\t\t\t       sizeof(ipv6_devconf_dflt));\n\t\t\tbreak;\n\t\tcase 3: /* copy from the current netns */\n\t\t\tmemcpy(all, current->nsproxy->net_ns->ipv6.devconf_all,\n\t\t\t       sizeof(ipv6_devconf));\n\t\t\tmemcpy(dflt,\n\t\t\t       current->nsproxy->net_ns->ipv6.devconf_dflt,\n\t\t\t       sizeof(ipv6_devconf_dflt));\n\t\t\tbreak;\n\t\tcase 0:\n\t\tcase 2:\n\t\t\t/* use compiled values */\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/* these will be inherited by all namespaces */\n\tdflt->autoconf = ipv6_defaults.autoconf;\n\tdflt->disable_ipv6 = ipv6_defaults.disable_ipv6;\n\n\tdflt->stable_secret.initialized = false;\n\tall->stable_secret.initialized = false;\n\n\tnet->ipv6.devconf_all = all;\n\tnet->ipv6.devconf_dflt = dflt;\n\n#ifdef CONFIG_SYSCTL\n\terr = __addrconf_sysctl_register(net, \"all\", NULL, all);\n\tif (err < 0)\n\t\tgoto err_reg_all;\n\n\terr = __addrconf_sysctl_register(net, \"default\", NULL, dflt);\n\tif (err < 0)\n\t\tgoto err_reg_dflt;\n#endif\n\treturn 0;\n\n#ifdef CONFIG_SYSCTL\nerr_reg_dflt:\n\t__addrconf_sysctl_unregister(net, all, NETCONFA_IFINDEX_ALL);\nerr_reg_all:\n\tkfree(dflt);\n#endif\nerr_alloc_dflt:\n\tkfree(all);\nerr_alloc_all:\n\treturn err;\n}\n\nstatic void __net_exit addrconf_exit_net(struct net *net)\n{\n#ifdef CONFIG_SYSCTL\n\t__addrconf_sysctl_unregister(net, net->ipv6.devconf_dflt,\n\t\t\t\t     NETCONFA_IFINDEX_DEFAULT);\n\t__addrconf_sysctl_unregister(net, net->ipv6.devconf_all,\n\t\t\t\t     NETCONFA_IFINDEX_ALL);\n#endif\n\tkfree(net->ipv6.devconf_dflt);\n\tkfree(net->ipv6.devconf_all);\n}\n\nstatic struct pernet_operations addrconf_ops = {\n\t.init = addrconf_init_net,\n\t.exit = addrconf_exit_net,\n};\n\nstatic struct rtnl_af_ops inet6_ops __read_mostly = {\n\t.family\t\t  = AF_INET6,\n\t.fill_link_af\t  = inet6_fill_link_af,\n\t.get_link_af_size = inet6_get_link_af_size,\n\t.validate_link_af = inet6_validate_link_af,\n\t.set_link_af\t  = inet6_set_link_af,\n};\n\n/*\n *\tInit / cleanup code\n */\n\nint __init addrconf_init(void)\n{\n\tstruct inet6_dev *idev;\n\tint i, err;\n\n\terr = ipv6_addr_label_init();\n\tif (err < 0) {\n\t\tpr_crit(\"%s: cannot initialize default policy table: %d\\n\",\n\t\t\t__func__, err);\n\t\tgoto out;\n\t}\n\n\terr = register_pernet_subsys(&addrconf_ops);\n\tif (err < 0)\n\t\tgoto out_addrlabel;\n\n\taddrconf_wq = create_workqueue(\"ipv6_addrconf\");\n\tif (!addrconf_wq) {\n\t\terr = -ENOMEM;\n\t\tgoto out_nowq;\n\t}\n\n\t/* The addrconf netdev notifier requires that loopback_dev\n\t * has it's ipv6 private information allocated and setup\n\t * before it can bring up and give link-local addresses\n\t * to other devices which are up.\n\t *\n\t * Unfortunately, loopback_dev is not necessarily the first\n\t * entry in the global dev_base list of net devices.  In fact,\n\t * it is likely to be the very last entry on that list.\n\t * So this causes the notifier registry below to try and\n\t * give link-local addresses to all devices besides loopback_dev\n\t * first, then loopback_dev, which cases all the non-loopback_dev\n\t * devices to fail to get a link-local address.\n\t *\n\t * So, as a temporary fix, allocate the ipv6 structure for\n\t * loopback_dev first by hand.\n\t * Longer term, all of the dependencies ipv6 has upon the loopback\n\t * device and it being up should be removed.\n\t */\n\trtnl_lock();\n\tidev = ipv6_add_dev(init_net.loopback_dev);\n\trtnl_unlock();\n\tif (IS_ERR(idev)) {\n\t\terr = PTR_ERR(idev);\n\t\tgoto errlo;\n\t}\n\n\tip6_route_init_special_entries();\n\n\tfor (i = 0; i < IN6_ADDR_HSIZE; i++)\n\t\tINIT_HLIST_HEAD(&inet6_addr_lst[i]);\n\n\tregister_netdevice_notifier(&ipv6_dev_notf);\n\n\taddrconf_verify();\n\n\trtnl_af_register(&inet6_ops);\n\n\terr = rtnl_register_module(THIS_MODULE, PF_INET6, RTM_GETLINK,\n\t\t\t\t   NULL, inet6_dump_ifinfo, 0);\n\tif (err < 0)\n\t\tgoto errout;\n\n\terr = rtnl_register_module(THIS_MODULE, PF_INET6, RTM_NEWADDR,\n\t\t\t\t   inet6_rtm_newaddr, NULL, 0);\n\tif (err < 0)\n\t\tgoto errout;\n\terr = rtnl_register_module(THIS_MODULE, PF_INET6, RTM_DELADDR,\n\t\t\t\t   inet6_rtm_deladdr, NULL, 0);\n\tif (err < 0)\n\t\tgoto errout;\n\terr = rtnl_register_module(THIS_MODULE, PF_INET6, RTM_GETADDR,\n\t\t\t\t   inet6_rtm_getaddr, inet6_dump_ifaddr,\n\t\t\t\t   RTNL_FLAG_DOIT_UNLOCKED);\n\tif (err < 0)\n\t\tgoto errout;\n\terr = rtnl_register_module(THIS_MODULE, PF_INET6, RTM_GETMULTICAST,\n\t\t\t\t   NULL, inet6_dump_ifmcaddr, 0);\n\tif (err < 0)\n\t\tgoto errout;\n\terr = rtnl_register_module(THIS_MODULE, PF_INET6, RTM_GETANYCAST,\n\t\t\t\t   NULL, inet6_dump_ifacaddr, 0);\n\tif (err < 0)\n\t\tgoto errout;\n\terr = rtnl_register_module(THIS_MODULE, PF_INET6, RTM_GETNETCONF,\n\t\t\t\t   inet6_netconf_get_devconf,\n\t\t\t\t   inet6_netconf_dump_devconf,\n\t\t\t\t   RTNL_FLAG_DOIT_UNLOCKED);\n\tif (err < 0)\n\t\tgoto errout;\n\terr = ipv6_addr_label_rtnl_register();\n\tif (err < 0)\n\t\tgoto errout;\n\n\treturn 0;\nerrout:\n\trtnl_unregister_all(PF_INET6);\n\trtnl_af_unregister(&inet6_ops);\n\tunregister_netdevice_notifier(&ipv6_dev_notf);\nerrlo:\n\tdestroy_workqueue(addrconf_wq);\nout_nowq:\n\tunregister_pernet_subsys(&addrconf_ops);\nout_addrlabel:\n\tipv6_addr_label_cleanup();\nout:\n\treturn err;\n}\n\nvoid addrconf_cleanup(void)\n{\n\tstruct net_device *dev;\n\tint i;\n\n\tunregister_netdevice_notifier(&ipv6_dev_notf);\n\tunregister_pernet_subsys(&addrconf_ops);\n\tipv6_addr_label_cleanup();\n\n\trtnl_af_unregister(&inet6_ops);\n\n\trtnl_lock();\n\n\t/* clean dev list */\n\tfor_each_netdev(&init_net, dev) {\n\t\tif (__in6_dev_get(dev) == NULL)\n\t\t\tcontinue;\n\t\taddrconf_ifdown(dev, true);\n\t}\n\taddrconf_ifdown(init_net.loopback_dev, true);\n\n\t/*\n\t *\tCheck hash table.\n\t */\n\tspin_lock_bh(&addrconf_hash_lock);\n\tfor (i = 0; i < IN6_ADDR_HSIZE; i++)\n\t\tWARN_ON(!hlist_empty(&inet6_addr_lst[i]));\n\tspin_unlock_bh(&addrconf_hash_lock);\n\tcancel_delayed_work(&addr_chk_work);\n\trtnl_unlock();\n\n\tdestroy_workqueue(addrconf_wq);\n}\n"}, "1": {"id": 1, "path": "/src/include/linux/rtnetlink.h", "content": "/* SPDX-License-Identifier: GPL-2.0 */\n#ifndef __LINUX_RTNETLINK_H\n#define __LINUX_RTNETLINK_H\n\n\n#include <linux/mutex.h>\n#include <linux/netdevice.h>\n#include <linux/wait.h>\n#include <linux/refcount.h>\n#include <uapi/linux/rtnetlink.h>\n\nextern int rtnetlink_send(struct sk_buff *skb, struct net *net, u32 pid, u32 group, int echo);\nextern int rtnl_unicast(struct sk_buff *skb, struct net *net, u32 pid);\nextern void rtnl_notify(struct sk_buff *skb, struct net *net, u32 pid,\n\t\t\tu32 group, struct nlmsghdr *nlh, gfp_t flags);\nextern void rtnl_set_sk_err(struct net *net, u32 group, int error);\nextern int rtnetlink_put_metrics(struct sk_buff *skb, u32 *metrics);\nextern int rtnl_put_cacheinfo(struct sk_buff *skb, struct dst_entry *dst,\n\t\t\t      u32 id, long expires, u32 error);\n\nvoid rtmsg_ifinfo(int type, struct net_device *dev, unsigned change, gfp_t flags);\nvoid rtmsg_ifinfo_newnet(int type, struct net_device *dev, unsigned int change,\n\t\t\t gfp_t flags, int *new_nsid, int new_ifindex);\nstruct sk_buff *rtmsg_ifinfo_build_skb(int type, struct net_device *dev,\n\t\t\t\t       unsigned change, u32 event,\n\t\t\t\t       gfp_t flags, int *new_nsid,\n\t\t\t\t       int new_ifindex);\nvoid rtmsg_ifinfo_send(struct sk_buff *skb, struct net_device *dev,\n\t\t       gfp_t flags);\n\n\n/* RTNL is used as a global lock for all changes to network configuration  */\nextern void rtnl_lock(void);\nextern void rtnl_unlock(void);\nextern int rtnl_trylock(void);\nextern int rtnl_is_locked(void);\nextern int rtnl_lock_killable(void);\nextern bool refcount_dec_and_rtnl_lock(refcount_t *r);\n\nextern wait_queue_head_t netdev_unregistering_wq;\nextern struct rw_semaphore pernet_ops_rwsem;\nextern struct rw_semaphore net_rwsem;\n\n#ifdef CONFIG_PROVE_LOCKING\nextern bool lockdep_rtnl_is_held(void);\n#else\nstatic inline bool lockdep_rtnl_is_held(void)\n{\n\treturn true;\n}\n#endif /* #ifdef CONFIG_PROVE_LOCKING */\n\n/**\n * rcu_dereference_rtnl - rcu_dereference with debug checking\n * @p: The pointer to read, prior to dereferencing\n *\n * Do an rcu_dereference(p), but check caller either holds rcu_read_lock()\n * or RTNL. Note : Please prefer rtnl_dereference() or rcu_dereference()\n */\n#define rcu_dereference_rtnl(p)\t\t\t\t\t\\\n\trcu_dereference_check(p, lockdep_rtnl_is_held())\n\n/**\n * rcu_dereference_bh_rtnl - rcu_dereference_bh with debug checking\n * @p: The pointer to read, prior to dereference\n *\n * Do an rcu_dereference_bh(p), but check caller either holds rcu_read_lock_bh()\n * or RTNL. Note : Please prefer rtnl_dereference() or rcu_dereference_bh()\n */\n#define rcu_dereference_bh_rtnl(p)\t\t\t\t\\\n\trcu_dereference_bh_check(p, lockdep_rtnl_is_held())\n\n/**\n * rtnl_dereference - fetch RCU pointer when updates are prevented by RTNL\n * @p: The pointer to read, prior to dereferencing\n *\n * Return the value of the specified RCU-protected pointer, but omit\n * the READ_ONCE(), because caller holds RTNL.\n */\n#define rtnl_dereference(p)\t\t\t\t\t\\\n\trcu_dereference_protected(p, lockdep_rtnl_is_held())\n\nstatic inline struct netdev_queue *dev_ingress_queue(struct net_device *dev)\n{\n\treturn rtnl_dereference(dev->ingress_queue);\n}\n\nstatic inline struct netdev_queue *dev_ingress_queue_rcu(struct net_device *dev)\n{\n\treturn rcu_dereference(dev->ingress_queue);\n}\n\nstruct netdev_queue *dev_ingress_queue_create(struct net_device *dev);\n\n#ifdef CONFIG_NET_INGRESS\nvoid net_inc_ingress_queue(void);\nvoid net_dec_ingress_queue(void);\n#endif\n\n#ifdef CONFIG_NET_EGRESS\nvoid net_inc_egress_queue(void);\nvoid net_dec_egress_queue(void);\n#endif\n\nvoid rtnetlink_init(void);\nvoid __rtnl_unlock(void);\nvoid rtnl_kfree_skbs(struct sk_buff *head, struct sk_buff *tail);\n\n#define ASSERT_RTNL() \\\n\tWARN_ONCE(!rtnl_is_locked(), \\\n\t\t  \"RTNL: assertion failed at %s (%d)\\n\", __FILE__,  __LINE__)\n\nextern int ndo_dflt_fdb_dump(struct sk_buff *skb,\n\t\t\t     struct netlink_callback *cb,\n\t\t\t     struct net_device *dev,\n\t\t\t     struct net_device *filter_dev,\n\t\t\t     int *idx);\nextern int ndo_dflt_fdb_add(struct ndmsg *ndm,\n\t\t\t    struct nlattr *tb[],\n\t\t\t    struct net_device *dev,\n\t\t\t    const unsigned char *addr,\n\t\t\t    u16 vid,\n\t\t\t    u16 flags);\nextern int ndo_dflt_fdb_del(struct ndmsg *ndm,\n\t\t\t    struct nlattr *tb[],\n\t\t\t    struct net_device *dev,\n\t\t\t    const unsigned char *addr,\n\t\t\t    u16 vid);\n\nextern int ndo_dflt_bridge_getlink(struct sk_buff *skb, u32 pid, u32 seq,\n\t\t\t\t   struct net_device *dev, u16 mode,\n\t\t\t\t   u32 flags, u32 mask, int nlflags,\n\t\t\t\t   u32 filter_mask,\n\t\t\t\t   int (*vlan_fill)(struct sk_buff *skb,\n\t\t\t\t\t\t    struct net_device *dev,\n\t\t\t\t\t\t    u32 filter_mask));\n#endif\t/* __LINUX_RTNETLINK_H */\n"}, "2": {"id": 2, "path": "/src/include/asm-generic/bug.h", "content": "/* SPDX-License-Identifier: GPL-2.0 */\n#ifndef _ASM_GENERIC_BUG_H\n#define _ASM_GENERIC_BUG_H\n\n#include <linux/compiler.h>\n#include <linux/instrumentation.h>\n\n#define CUT_HERE\t\t\"------------[ cut here ]------------\\n\"\n\n#ifdef CONFIG_GENERIC_BUG\n#define BUGFLAG_WARNING\t\t(1 << 0)\n#define BUGFLAG_ONCE\t\t(1 << 1)\n#define BUGFLAG_DONE\t\t(1 << 2)\n#define BUGFLAG_NO_CUT_HERE\t(1 << 3)\t/* CUT_HERE already sent */\n#define BUGFLAG_TAINT(taint)\t((taint) << 8)\n#define BUG_GET_TAINT(bug)\t((bug)->flags >> 8)\n#endif\n\n#ifndef __ASSEMBLY__\n#include <linux/kernel.h>\n\n#ifdef CONFIG_BUG\n\n#ifdef CONFIG_GENERIC_BUG\nstruct bug_entry {\n#ifndef CONFIG_GENERIC_BUG_RELATIVE_POINTERS\n\tunsigned long\tbug_addr;\n#else\n\tsigned int\tbug_addr_disp;\n#endif\n#ifdef CONFIG_DEBUG_BUGVERBOSE\n#ifndef CONFIG_GENERIC_BUG_RELATIVE_POINTERS\n\tconst char\t*file;\n#else\n\tsigned int\tfile_disp;\n#endif\n\tunsigned short\tline;\n#endif\n\tunsigned short\tflags;\n};\n#endif\t/* CONFIG_GENERIC_BUG */\n\n/*\n * Don't use BUG() or BUG_ON() unless there's really no way out; one\n * example might be detecting data structure corruption in the middle\n * of an operation that can't be backed out of.  If the (sub)system\n * can somehow continue operating, perhaps with reduced functionality,\n * it's probably not BUG-worthy.\n *\n * If you're tempted to BUG(), think again:  is completely giving up\n * really the *only* solution?  There are usually better options, where\n * users don't need to reboot ASAP and can mostly shut down cleanly.\n */\n#ifndef HAVE_ARCH_BUG\n#define BUG() do { \\\n\tprintk(\"BUG: failure at %s:%d/%s()!\\n\", __FILE__, __LINE__, __func__); \\\n\tbarrier_before_unreachable(); \\\n\tpanic(\"BUG!\"); \\\n} while (0)\n#endif\n\n#ifndef HAVE_ARCH_BUG_ON\n#define BUG_ON(condition) do { if (unlikely(condition)) BUG(); } while (0)\n#endif\n\n/*\n * WARN(), WARN_ON(), WARN_ON_ONCE, and so on can be used to report\n * significant kernel issues that need prompt attention if they should ever\n * appear at runtime.\n *\n * Do not use these macros when checking for invalid external inputs\n * (e.g. invalid system call arguments, or invalid data coming from\n * network/devices), and on transient conditions like ENOMEM or EAGAIN.\n * These macros should be used for recoverable kernel issues only.\n * For invalid external inputs, transient conditions, etc use\n * pr_err[_once/_ratelimited]() followed by dump_stack(), if necessary.\n * Do not include \"BUG\"/\"WARNING\" in format strings manually to make these\n * conditions distinguishable from kernel issues.\n *\n * Use the versions with printk format strings to provide better diagnostics.\n */\n#ifndef __WARN_FLAGS\nextern __printf(4, 5)\nvoid warn_slowpath_fmt(const char *file, const int line, unsigned taint,\n\t\t       const char *fmt, ...);\n#define __WARN()\t\t__WARN_printf(TAINT_WARN, NULL)\n#define __WARN_printf(taint, arg...) do {\t\t\t\t\\\n\t\tinstrumentation_begin();\t\t\t\t\\\n\t\twarn_slowpath_fmt(__FILE__, __LINE__, taint, arg);\t\\\n\t\tinstrumentation_end();\t\t\t\t\t\\\n\t} while (0)\n#else\nextern __printf(1, 2) void __warn_printk(const char *fmt, ...);\n#define __WARN()\t\t__WARN_FLAGS(BUGFLAG_TAINT(TAINT_WARN))\n#define __WARN_printf(taint, arg...) do {\t\t\t\t\\\n\t\tinstrumentation_begin();\t\t\t\t\\\n\t\t__warn_printk(arg);\t\t\t\t\t\\\n\t\t__WARN_FLAGS(BUGFLAG_NO_CUT_HERE | BUGFLAG_TAINT(taint));\\\n\t\tinstrumentation_end();\t\t\t\t\t\\\n\t} while (0)\n#define WARN_ON_ONCE(condition) ({\t\t\t\t\\\n\tint __ret_warn_on = !!(condition);\t\t\t\\\n\tif (unlikely(__ret_warn_on))\t\t\t\t\\\n\t\t__WARN_FLAGS(BUGFLAG_ONCE |\t\t\t\\\n\t\t\t     BUGFLAG_TAINT(TAINT_WARN));\t\\\n\tunlikely(__ret_warn_on);\t\t\t\t\\\n})\n#endif\n\n/* used internally by panic.c */\nstruct warn_args;\nstruct pt_regs;\n\nvoid __warn(const char *file, int line, void *caller, unsigned taint,\n\t    struct pt_regs *regs, struct warn_args *args);\n\n#ifndef WARN_ON\n#define WARN_ON(condition) ({\t\t\t\t\t\t\\\n\tint __ret_warn_on = !!(condition);\t\t\t\t\\\n\tif (unlikely(__ret_warn_on))\t\t\t\t\t\\\n\t\t__WARN();\t\t\t\t\t\t\\\n\tunlikely(__ret_warn_on);\t\t\t\t\t\\\n})\n#endif\n\n#ifndef WARN\n#define WARN(condition, format...) ({\t\t\t\t\t\\\n\tint __ret_warn_on = !!(condition);\t\t\t\t\\\n\tif (unlikely(__ret_warn_on))\t\t\t\t\t\\\n\t\t__WARN_printf(TAINT_WARN, format);\t\t\t\\\n\tunlikely(__ret_warn_on);\t\t\t\t\t\\\n})\n#endif\n\n#define WARN_TAINT(condition, taint, format...) ({\t\t\t\\\n\tint __ret_warn_on = !!(condition);\t\t\t\t\\\n\tif (unlikely(__ret_warn_on))\t\t\t\t\t\\\n\t\t__WARN_printf(taint, format);\t\t\t\t\\\n\tunlikely(__ret_warn_on);\t\t\t\t\t\\\n})\n\n#ifndef WARN_ON_ONCE\n#define WARN_ON_ONCE(condition)\t({\t\t\t\t\\\n\tstatic bool __section(\".data.once\") __warned;\t\t\\\n\tint __ret_warn_once = !!(condition);\t\t\t\\\n\t\t\t\t\t\t\t\t\\\n\tif (unlikely(__ret_warn_once && !__warned)) {\t\t\\\n\t\t__warned = true;\t\t\t\t\\\n\t\tWARN_ON(1);\t\t\t\t\t\\\n\t}\t\t\t\t\t\t\t\\\n\tunlikely(__ret_warn_once);\t\t\t\t\\\n})\n#endif\n\n#define WARN_ONCE(condition, format...)\t({\t\t\t\\\n\tstatic bool __section(\".data.once\") __warned;\t\t\\\n\tint __ret_warn_once = !!(condition);\t\t\t\\\n\t\t\t\t\t\t\t\t\\\n\tif (unlikely(__ret_warn_once && !__warned)) {\t\t\\\n\t\t__warned = true;\t\t\t\t\\\n\t\tWARN(1, format);\t\t\t\t\\\n\t}\t\t\t\t\t\t\t\\\n\tunlikely(__ret_warn_once);\t\t\t\t\\\n})\n\n#define WARN_TAINT_ONCE(condition, taint, format...)\t({\t\\\n\tstatic bool __section(\".data.once\") __warned;\t\t\\\n\tint __ret_warn_once = !!(condition);\t\t\t\\\n\t\t\t\t\t\t\t\t\\\n\tif (unlikely(__ret_warn_once && !__warned)) {\t\t\\\n\t\t__warned = true;\t\t\t\t\\\n\t\tWARN_TAINT(1, taint, format);\t\t\t\\\n\t}\t\t\t\t\t\t\t\\\n\tunlikely(__ret_warn_once);\t\t\t\t\\\n})\n\n#else /* !CONFIG_BUG */\n#ifndef HAVE_ARCH_BUG\n#define BUG() do {} while (1)\n#endif\n\n#ifndef HAVE_ARCH_BUG_ON\n#define BUG_ON(condition) do { if (unlikely(condition)) BUG(); } while (0)\n#endif\n\n#ifndef HAVE_ARCH_WARN_ON\n#define WARN_ON(condition) ({\t\t\t\t\t\t\\\n\tint __ret_warn_on = !!(condition);\t\t\t\t\\\n\tunlikely(__ret_warn_on);\t\t\t\t\t\\\n})\n#endif\n\n#ifndef WARN\n#define WARN(condition, format...) ({\t\t\t\t\t\\\n\tint __ret_warn_on = !!(condition);\t\t\t\t\\\n\tno_printk(format);\t\t\t\t\t\t\\\n\tunlikely(__ret_warn_on);\t\t\t\t\t\\\n})\n#endif\n\n#define WARN_ON_ONCE(condition) WARN_ON(condition)\n#define WARN_ONCE(condition, format...) WARN(condition, format)\n#define WARN_TAINT(condition, taint, format...) WARN(condition, format)\n#define WARN_TAINT_ONCE(condition, taint, format...) WARN(condition, format)\n\n#endif\n\n/*\n * WARN_ON_SMP() is for cases that the warning is either\n * meaningless for !SMP or may even cause failures.\n * It can also be used with values that are only defined\n * on SMP:\n *\n * struct foo {\n *  [...]\n * #ifdef CONFIG_SMP\n *\tint bar;\n * #endif\n * };\n *\n * void func(struct foo *zoot)\n * {\n *\tWARN_ON_SMP(!zoot->bar);\n *\n * For CONFIG_SMP, WARN_ON_SMP() should act the same as WARN_ON(),\n * and should be a nop and return false for uniprocessor.\n *\n * if (WARN_ON_SMP(x)) returns true only when CONFIG_SMP is set\n * and x is true.\n */\n#ifdef CONFIG_SMP\n# define WARN_ON_SMP(x)\t\t\tWARN_ON(x)\n#else\n/*\n * Use of ({0;}) because WARN_ON_SMP(x) may be used either as\n * a stand alone line statement or as a condition in an if ()\n * statement.\n * A simple \"0\" would cause gcc to give a \"statement has no effect\"\n * warning.\n */\n# define WARN_ON_SMP(x)\t\t\t({0;})\n#endif\n\n#endif /* __ASSEMBLY__ */\n\n#endif\n"}, "3": {"id": 3, "path": "/src/include/linux/compiler.h", "content": "/* SPDX-License-Identifier: GPL-2.0 */\n#ifndef __LINUX_COMPILER_H\n#define __LINUX_COMPILER_H\n\n#include <linux/compiler_types.h>\n\n#ifndef __ASSEMBLY__\n\n#ifdef __KERNEL__\n\n/*\n * Note: DISABLE_BRANCH_PROFILING can be used by special lowlevel code\n * to disable branch tracing on a per file basis.\n */\n#if defined(CONFIG_TRACE_BRANCH_PROFILING) \\\n    && !defined(DISABLE_BRANCH_PROFILING) && !defined(__CHECKER__)\nvoid ftrace_likely_update(struct ftrace_likely_data *f, int val,\n\t\t\t  int expect, int is_constant);\n\n#define likely_notrace(x)\t__builtin_expect(!!(x), 1)\n#define unlikely_notrace(x)\t__builtin_expect(!!(x), 0)\n\n#define __branch_check__(x, expect, is_constant) ({\t\t\t\\\n\t\t\tlong ______r;\t\t\t\t\t\\\n\t\t\tstatic struct ftrace_likely_data\t\t\\\n\t\t\t\t__aligned(4)\t\t\t\t\\\n\t\t\t\t__section(\"_ftrace_annotated_branch\")\t\\\n\t\t\t\t______f = {\t\t\t\t\\\n\t\t\t\t.data.func = __func__,\t\t\t\\\n\t\t\t\t.data.file = __FILE__,\t\t\t\\\n\t\t\t\t.data.line = __LINE__,\t\t\t\\\n\t\t\t};\t\t\t\t\t\t\\\n\t\t\t______r = __builtin_expect(!!(x), expect);\t\\\n\t\t\tftrace_likely_update(&______f, ______r,\t\t\\\n\t\t\t\t\t     expect, is_constant);\t\\\n\t\t\t______r;\t\t\t\t\t\\\n\t\t})\n\n/*\n * Using __builtin_constant_p(x) to ignore cases where the return\n * value is always the same.  This idea is taken from a similar patch\n * written by Daniel Walker.\n */\n# ifndef likely\n#  define likely(x)\t(__branch_check__(x, 1, __builtin_constant_p(x)))\n# endif\n# ifndef unlikely\n#  define unlikely(x)\t(__branch_check__(x, 0, __builtin_constant_p(x)))\n# endif\n\n#ifdef CONFIG_PROFILE_ALL_BRANCHES\n/*\n * \"Define 'is'\", Bill Clinton\n * \"Define 'if'\", Steven Rostedt\n */\n#define if(cond, ...) if ( __trace_if_var( !!(cond , ## __VA_ARGS__) ) )\n\n#define __trace_if_var(cond) (__builtin_constant_p(cond) ? (cond) : __trace_if_value(cond))\n\n#define __trace_if_value(cond) ({\t\t\t\\\n\tstatic struct ftrace_branch_data\t\t\\\n\t\t__aligned(4)\t\t\t\t\\\n\t\t__section(\"_ftrace_branch\")\t\t\\\n\t\t__if_trace = {\t\t\t\t\\\n\t\t\t.func = __func__,\t\t\\\n\t\t\t.file = __FILE__,\t\t\\\n\t\t\t.line = __LINE__,\t\t\\\n\t\t};\t\t\t\t\t\\\n\t(cond) ?\t\t\t\t\t\\\n\t\t(__if_trace.miss_hit[1]++,1) :\t\t\\\n\t\t(__if_trace.miss_hit[0]++,0);\t\t\\\n})\n\n#endif /* CONFIG_PROFILE_ALL_BRANCHES */\n\n#else\n# define likely(x)\t__builtin_expect(!!(x), 1)\n# define unlikely(x)\t__builtin_expect(!!(x), 0)\n# define likely_notrace(x)\tlikely(x)\n# define unlikely_notrace(x)\tunlikely(x)\n#endif\n\n/* Optimization barrier */\n#ifndef barrier\n/* The \"volatile\" is due to gcc bugs */\n# define barrier() __asm__ __volatile__(\"\": : :\"memory\")\n#endif\n\n#ifndef barrier_data\n/*\n * This version is i.e. to prevent dead stores elimination on @ptr\n * where gcc and llvm may behave differently when otherwise using\n * normal barrier(): while gcc behavior gets along with a normal\n * barrier(), llvm needs an explicit input variable to be assumed\n * clobbered. The issue is as follows: while the inline asm might\n * access any memory it wants, the compiler could have fit all of\n * @ptr into memory registers instead, and since @ptr never escaped\n * from that, it proved that the inline asm wasn't touching any of\n * it. This version works well with both compilers, i.e. we're telling\n * the compiler that the inline asm absolutely may see the contents\n * of @ptr. See also: https://llvm.org/bugs/show_bug.cgi?id=15495\n */\n# define barrier_data(ptr) __asm__ __volatile__(\"\": :\"r\"(ptr) :\"memory\")\n#endif\n\n/* workaround for GCC PR82365 if needed */\n#ifndef barrier_before_unreachable\n# define barrier_before_unreachable() do { } while (0)\n#endif\n\n/* Unreachable code */\n#ifdef CONFIG_STACK_VALIDATION\n/*\n * These macros help objtool understand GCC code flow for unreachable code.\n * The __COUNTER__ based labels are a hack to make each instance of the macros\n * unique, to convince GCC not to merge duplicate inline asm statements.\n */\n#define annotate_reachable() ({\t\t\t\t\t\t\\\n\tasm volatile(\"%c0:\\n\\t\"\t\t\t\t\t\t\\\n\t\t     \".pushsection .discard.reachable\\n\\t\"\t\t\\\n\t\t     \".long %c0b - .\\n\\t\"\t\t\t\t\\\n\t\t     \".popsection\\n\\t\" : : \"i\" (__COUNTER__));\t\t\\\n})\n#define annotate_unreachable() ({\t\t\t\t\t\\\n\tasm volatile(\"%c0:\\n\\t\"\t\t\t\t\t\t\\\n\t\t     \".pushsection .discard.unreachable\\n\\t\"\t\t\\\n\t\t     \".long %c0b - .\\n\\t\"\t\t\t\t\\\n\t\t     \".popsection\\n\\t\" : : \"i\" (__COUNTER__));\t\t\\\n})\n#define ASM_UNREACHABLE\t\t\t\t\t\t\t\\\n\t\"999:\\n\\t\"\t\t\t\t\t\t\t\\\n\t\".pushsection .discard.unreachable\\n\\t\"\t\t\t\t\\\n\t\".long 999b - .\\n\\t\"\t\t\t\t\t\t\\\n\t\".popsection\\n\\t\"\n\n/* Annotate a C jump table to allow objtool to follow the code flow */\n#define __annotate_jump_table __section(\".rodata..c_jump_table\")\n\n#else\n#define annotate_reachable()\n#define annotate_unreachable()\n#define __annotate_jump_table\n#endif\n\n#ifndef ASM_UNREACHABLE\n# define ASM_UNREACHABLE\n#endif\n#ifndef unreachable\n# define unreachable() do {\t\t\\\n\tannotate_unreachable();\t\t\\\n\t__builtin_unreachable();\t\\\n} while (0)\n#endif\n\n/*\n * KENTRY - kernel entry point\n * This can be used to annotate symbols (functions or data) that are used\n * without their linker symbol being referenced explicitly. For example,\n * interrupt vector handlers, or functions in the kernel image that are found\n * programatically.\n *\n * Not required for symbols exported with EXPORT_SYMBOL, or initcalls. Those\n * are handled in their own way (with KEEP() in linker scripts).\n *\n * KENTRY can be avoided if the symbols in question are marked as KEEP() in the\n * linker script. For example an architecture could KEEP() its entire\n * boot/exception vector code rather than annotate each function and data.\n */\n#ifndef KENTRY\n# define KENTRY(sym)\t\t\t\t\t\t\\\n\textern typeof(sym) sym;\t\t\t\t\t\\\n\tstatic const unsigned long __kentry_##sym\t\t\\\n\t__used\t\t\t\t\t\t\t\\\n\t__attribute__((__section__(\"___kentry+\" #sym)))\t\t\\\n\t= (unsigned long)&sym;\n#endif\n\n#ifndef RELOC_HIDE\n# define RELOC_HIDE(ptr, off)\t\t\t\t\t\\\n  ({ unsigned long __ptr;\t\t\t\t\t\\\n     __ptr = (unsigned long) (ptr);\t\t\t\t\\\n    (typeof(ptr)) (__ptr + (off)); })\n#endif\n\n#ifndef OPTIMIZER_HIDE_VAR\n/* Make the optimizer believe the variable can be manipulated arbitrarily. */\n#define OPTIMIZER_HIDE_VAR(var)\t\t\t\t\t\t\\\n\t__asm__ (\"\" : \"=r\" (var) : \"0\" (var))\n#endif\n\n/* Not-quite-unique ID. */\n#ifndef __UNIQUE_ID\n# define __UNIQUE_ID(prefix) __PASTE(__PASTE(__UNIQUE_ID_, prefix), __LINE__)\n#endif\n\n/**\n * data_race - mark an expression as containing intentional data races\n *\n * This data_race() macro is useful for situations in which data races\n * should be forgiven.  One example is diagnostic code that accesses\n * shared variables but is not a part of the core synchronization design.\n *\n * This macro *does not* affect normal code generation, but is a hint\n * to tooling that data races here are to be ignored.\n */\n#define data_race(expr)\t\t\t\t\t\t\t\\\n({\t\t\t\t\t\t\t\t\t\\\n\t__unqual_scalar_typeof(({ expr; })) __v = ({\t\t\t\\\n\t\t__kcsan_disable_current();\t\t\t\t\\\n\t\texpr;\t\t\t\t\t\t\t\\\n\t});\t\t\t\t\t\t\t\t\\\n\t__kcsan_enable_current();\t\t\t\t\t\\\n\t__v;\t\t\t\t\t\t\t\t\\\n})\n\n#endif /* __KERNEL__ */\n\n/*\n * Force the compiler to emit 'sym' as a symbol, so that we can reference\n * it from inline assembler. Necessary in case 'sym' could be inlined\n * otherwise, or eliminated entirely due to lack of references that are\n * visible to the compiler.\n */\n#define __ADDRESSABLE(sym) \\\n\tstatic void * __section(\".discard.addressable\") __used \\\n\t\t__UNIQUE_ID(__PASTE(__addressable_,sym)) = (void *)&sym;\n\n/**\n * offset_to_ptr - convert a relative memory offset to an absolute pointer\n * @off:\tthe address of the 32-bit offset value\n */\nstatic inline void *offset_to_ptr(const int *off)\n{\n\treturn (void *)((unsigned long)off + *off);\n}\n\n#endif /* __ASSEMBLY__ */\n\n/* &a[0] degrades to a pointer: a different type from an array */\n#define __must_be_array(a)\tBUILD_BUG_ON_ZERO(__same_type((a), &(a)[0]))\n\n/*\n * This is needed in functions which generate the stack canary, see\n * arch/x86/kernel/smpboot.c::start_secondary() for an example.\n */\n#define prevent_tail_call_optimization()\tmb()\n\n#include <asm/rwonce.h>\n\n#endif /* __LINUX_COMPILER_H */\n"}, "4": {"id": 4, "path": "/src/include/linux/slab.h", "content": "/* SPDX-License-Identifier: GPL-2.0 */\n/*\n * Written by Mark Hemment, 1996 (markhe@nextd.demon.co.uk).\n *\n * (C) SGI 2006, Christoph Lameter\n * \tCleaned up and restructured to ease the addition of alternative\n * \timplementations of SLAB allocators.\n * (C) Linux Foundation 2008-2013\n *      Unified interface for all slab allocators\n */\n\n#ifndef _LINUX_SLAB_H\n#define\t_LINUX_SLAB_H\n\n#include <linux/gfp.h>\n#include <linux/overflow.h>\n#include <linux/types.h>\n#include <linux/workqueue.h>\n#include <linux/percpu-refcount.h>\n\n\n/*\n * Flags to pass to kmem_cache_create().\n * The ones marked DEBUG are only valid if CONFIG_DEBUG_SLAB is set.\n */\n/* DEBUG: Perform (expensive) checks on alloc/free */\n#define SLAB_CONSISTENCY_CHECKS\t((slab_flags_t __force)0x00000100U)\n/* DEBUG: Red zone objs in a cache */\n#define SLAB_RED_ZONE\t\t((slab_flags_t __force)0x00000400U)\n/* DEBUG: Poison objects */\n#define SLAB_POISON\t\t((slab_flags_t __force)0x00000800U)\n/* Align objs on cache lines */\n#define SLAB_HWCACHE_ALIGN\t((slab_flags_t __force)0x00002000U)\n/* Use GFP_DMA memory */\n#define SLAB_CACHE_DMA\t\t((slab_flags_t __force)0x00004000U)\n/* Use GFP_DMA32 memory */\n#define SLAB_CACHE_DMA32\t((slab_flags_t __force)0x00008000U)\n/* DEBUG: Store the last owner for bug hunting */\n#define SLAB_STORE_USER\t\t((slab_flags_t __force)0x00010000U)\n/* Panic if kmem_cache_create() fails */\n#define SLAB_PANIC\t\t((slab_flags_t __force)0x00040000U)\n/*\n * SLAB_TYPESAFE_BY_RCU - **WARNING** READ THIS!\n *\n * This delays freeing the SLAB page by a grace period, it does _NOT_\n * delay object freeing. This means that if you do kmem_cache_free()\n * that memory location is free to be reused at any time. Thus it may\n * be possible to see another object there in the same RCU grace period.\n *\n * This feature only ensures the memory location backing the object\n * stays valid, the trick to using this is relying on an independent\n * object validation pass. Something like:\n *\n *  rcu_read_lock()\n * again:\n *  obj = lockless_lookup(key);\n *  if (obj) {\n *    if (!try_get_ref(obj)) // might fail for free objects\n *      goto again;\n *\n *    if (obj->key != key) { // not the object we expected\n *      put_ref(obj);\n *      goto again;\n *    }\n *  }\n *  rcu_read_unlock();\n *\n * This is useful if we need to approach a kernel structure obliquely,\n * from its address obtained without the usual locking. We can lock\n * the structure to stabilize it and check it's still at the given address,\n * only if we can be sure that the memory has not been meanwhile reused\n * for some other kind of object (which our subsystem's lock might corrupt).\n *\n * rcu_read_lock before reading the address, then rcu_read_unlock after\n * taking the spinlock within the structure expected at that address.\n *\n * Note that SLAB_TYPESAFE_BY_RCU was originally named SLAB_DESTROY_BY_RCU.\n */\n/* Defer freeing slabs to RCU */\n#define SLAB_TYPESAFE_BY_RCU\t((slab_flags_t __force)0x00080000U)\n/* Spread some memory over cpuset */\n#define SLAB_MEM_SPREAD\t\t((slab_flags_t __force)0x00100000U)\n/* Trace allocations and frees */\n#define SLAB_TRACE\t\t((slab_flags_t __force)0x00200000U)\n\n/* Flag to prevent checks on free */\n#ifdef CONFIG_DEBUG_OBJECTS\n# define SLAB_DEBUG_OBJECTS\t((slab_flags_t __force)0x00400000U)\n#else\n# define SLAB_DEBUG_OBJECTS\t0\n#endif\n\n/* Avoid kmemleak tracing */\n#define SLAB_NOLEAKTRACE\t((slab_flags_t __force)0x00800000U)\n\n/* Fault injection mark */\n#ifdef CONFIG_FAILSLAB\n# define SLAB_FAILSLAB\t\t((slab_flags_t __force)0x02000000U)\n#else\n# define SLAB_FAILSLAB\t\t0\n#endif\n/* Account to memcg */\n#ifdef CONFIG_MEMCG_KMEM\n# define SLAB_ACCOUNT\t\t((slab_flags_t __force)0x04000000U)\n#else\n# define SLAB_ACCOUNT\t\t0\n#endif\n\n#ifdef CONFIG_KASAN\n#define SLAB_KASAN\t\t((slab_flags_t __force)0x08000000U)\n#else\n#define SLAB_KASAN\t\t0\n#endif\n\n/* The following flags affect the page allocator grouping pages by mobility */\n/* Objects are reclaimable */\n#define SLAB_RECLAIM_ACCOUNT\t((slab_flags_t __force)0x00020000U)\n#define SLAB_TEMPORARY\t\tSLAB_RECLAIM_ACCOUNT\t/* Objects are short-lived */\n\n/* Slab deactivation flag */\n#define SLAB_DEACTIVATED\t((slab_flags_t __force)0x10000000U)\n\n/*\n * ZERO_SIZE_PTR will be returned for zero sized kmalloc requests.\n *\n * Dereferencing ZERO_SIZE_PTR will lead to a distinct access fault.\n *\n * ZERO_SIZE_PTR can be passed to kfree though in the same way that NULL can.\n * Both make kfree a no-op.\n */\n#define ZERO_SIZE_PTR ((void *)16)\n\n#define ZERO_OR_NULL_PTR(x) ((unsigned long)(x) <= \\\n\t\t\t\t(unsigned long)ZERO_SIZE_PTR)\n\n#include <linux/kasan.h>\n\nstruct mem_cgroup;\n/*\n * struct kmem_cache related prototypes\n */\nvoid __init kmem_cache_init(void);\nbool slab_is_available(void);\n\nextern bool usercopy_fallback;\n\nstruct kmem_cache *kmem_cache_create(const char *name, unsigned int size,\n\t\t\tunsigned int align, slab_flags_t flags,\n\t\t\tvoid (*ctor)(void *));\nstruct kmem_cache *kmem_cache_create_usercopy(const char *name,\n\t\t\tunsigned int size, unsigned int align,\n\t\t\tslab_flags_t flags,\n\t\t\tunsigned int useroffset, unsigned int usersize,\n\t\t\tvoid (*ctor)(void *));\nvoid kmem_cache_destroy(struct kmem_cache *);\nint kmem_cache_shrink(struct kmem_cache *);\n\n/*\n * Please use this macro to create slab caches. Simply specify the\n * name of the structure and maybe some flags that are listed above.\n *\n * The alignment of the struct determines object alignment. If you\n * f.e. add ____cacheline_aligned_in_smp to the struct declaration\n * then the objects will be properly aligned in SMP configurations.\n */\n#define KMEM_CACHE(__struct, __flags)\t\t\t\t\t\\\n\t\tkmem_cache_create(#__struct, sizeof(struct __struct),\t\\\n\t\t\t__alignof__(struct __struct), (__flags), NULL)\n\n/*\n * To whitelist a single field for copying to/from usercopy, use this\n * macro instead for KMEM_CACHE() above.\n */\n#define KMEM_CACHE_USERCOPY(__struct, __flags, __field)\t\t\t\\\n\t\tkmem_cache_create_usercopy(#__struct,\t\t\t\\\n\t\t\tsizeof(struct __struct),\t\t\t\\\n\t\t\t__alignof__(struct __struct), (__flags),\t\\\n\t\t\toffsetof(struct __struct, __field),\t\t\\\n\t\t\tsizeof_field(struct __struct, __field), NULL)\n\n/*\n * Common kmalloc functions provided by all allocators\n */\nvoid * __must_check krealloc(const void *, size_t, gfp_t);\nvoid kfree(const void *);\nvoid kfree_sensitive(const void *);\nsize_t __ksize(const void *);\nsize_t ksize(const void *);\n#ifdef CONFIG_PRINTK\nbool kmem_valid_obj(void *object);\nvoid kmem_dump_obj(void *object);\n#endif\n\n#ifdef CONFIG_HAVE_HARDENED_USERCOPY_ALLOCATOR\nvoid __check_heap_object(const void *ptr, unsigned long n, struct page *page,\n\t\t\tbool to_user);\n#else\nstatic inline void __check_heap_object(const void *ptr, unsigned long n,\n\t\t\t\t       struct page *page, bool to_user) { }\n#endif\n\n/*\n * Some archs want to perform DMA into kmalloc caches and need a guaranteed\n * alignment larger than the alignment of a 64-bit integer.\n * Setting ARCH_KMALLOC_MINALIGN in arch headers allows that.\n */\n#if defined(ARCH_DMA_MINALIGN) && ARCH_DMA_MINALIGN > 8\n#define ARCH_KMALLOC_MINALIGN ARCH_DMA_MINALIGN\n#define KMALLOC_MIN_SIZE ARCH_DMA_MINALIGN\n#define KMALLOC_SHIFT_LOW ilog2(ARCH_DMA_MINALIGN)\n#else\n#define ARCH_KMALLOC_MINALIGN __alignof__(unsigned long long)\n#endif\n\n/*\n * Setting ARCH_SLAB_MINALIGN in arch headers allows a different alignment.\n * Intended for arches that get misalignment faults even for 64 bit integer\n * aligned buffers.\n */\n#ifndef ARCH_SLAB_MINALIGN\n#define ARCH_SLAB_MINALIGN __alignof__(unsigned long long)\n#endif\n\n/*\n * kmalloc and friends return ARCH_KMALLOC_MINALIGN aligned\n * pointers. kmem_cache_alloc and friends return ARCH_SLAB_MINALIGN\n * aligned pointers.\n */\n#define __assume_kmalloc_alignment __assume_aligned(ARCH_KMALLOC_MINALIGN)\n#define __assume_slab_alignment __assume_aligned(ARCH_SLAB_MINALIGN)\n#define __assume_page_alignment __assume_aligned(PAGE_SIZE)\n\n/*\n * Kmalloc array related definitions\n */\n\n#ifdef CONFIG_SLAB\n/*\n * The largest kmalloc size supported by the SLAB allocators is\n * 32 megabyte (2^25) or the maximum allocatable page order if that is\n * less than 32 MB.\n *\n * WARNING: Its not easy to increase this value since the allocators have\n * to do various tricks to work around compiler limitations in order to\n * ensure proper constant folding.\n */\n#define KMALLOC_SHIFT_HIGH\t((MAX_ORDER + PAGE_SHIFT - 1) <= 25 ? \\\n\t\t\t\t(MAX_ORDER + PAGE_SHIFT - 1) : 25)\n#define KMALLOC_SHIFT_MAX\tKMALLOC_SHIFT_HIGH\n#ifndef KMALLOC_SHIFT_LOW\n#define KMALLOC_SHIFT_LOW\t5\n#endif\n#endif\n\n#ifdef CONFIG_SLUB\n/*\n * SLUB directly allocates requests fitting in to an order-1 page\n * (PAGE_SIZE*2).  Larger requests are passed to the page allocator.\n */\n#define KMALLOC_SHIFT_HIGH\t(PAGE_SHIFT + 1)\n#define KMALLOC_SHIFT_MAX\t(MAX_ORDER + PAGE_SHIFT - 1)\n#ifndef KMALLOC_SHIFT_LOW\n#define KMALLOC_SHIFT_LOW\t3\n#endif\n#endif\n\n#ifdef CONFIG_SLOB\n/*\n * SLOB passes all requests larger than one page to the page allocator.\n * No kmalloc array is necessary since objects of different sizes can\n * be allocated from the same page.\n */\n#define KMALLOC_SHIFT_HIGH\tPAGE_SHIFT\n#define KMALLOC_SHIFT_MAX\t(MAX_ORDER + PAGE_SHIFT - 1)\n#ifndef KMALLOC_SHIFT_LOW\n#define KMALLOC_SHIFT_LOW\t3\n#endif\n#endif\n\n/* Maximum allocatable size */\n#define KMALLOC_MAX_SIZE\t(1UL << KMALLOC_SHIFT_MAX)\n/* Maximum size for which we actually use a slab cache */\n#define KMALLOC_MAX_CACHE_SIZE\t(1UL << KMALLOC_SHIFT_HIGH)\n/* Maximum order allocatable via the slab allocator */\n#define KMALLOC_MAX_ORDER\t(KMALLOC_SHIFT_MAX - PAGE_SHIFT)\n\n/*\n * Kmalloc subsystem.\n */\n#ifndef KMALLOC_MIN_SIZE\n#define KMALLOC_MIN_SIZE (1 << KMALLOC_SHIFT_LOW)\n#endif\n\n/*\n * This restriction comes from byte sized index implementation.\n * Page size is normally 2^12 bytes and, in this case, if we want to use\n * byte sized index which can represent 2^8 entries, the size of the object\n * should be equal or greater to 2^12 / 2^8 = 2^4 = 16.\n * If minimum size of kmalloc is less than 16, we use it as minimum object\n * size and give up to use byte sized index.\n */\n#define SLAB_OBJ_MIN_SIZE      (KMALLOC_MIN_SIZE < 16 ? \\\n                               (KMALLOC_MIN_SIZE) : 16)\n\n/*\n * Whenever changing this, take care of that kmalloc_type() and\n * create_kmalloc_caches() still work as intended.\n */\nenum kmalloc_cache_type {\n\tKMALLOC_NORMAL = 0,\n\tKMALLOC_RECLAIM,\n#ifdef CONFIG_ZONE_DMA\n\tKMALLOC_DMA,\n#endif\n\tNR_KMALLOC_TYPES\n};\n\n#ifndef CONFIG_SLOB\nextern struct kmem_cache *\nkmalloc_caches[NR_KMALLOC_TYPES][KMALLOC_SHIFT_HIGH + 1];\n\nstatic __always_inline enum kmalloc_cache_type kmalloc_type(gfp_t flags)\n{\n#ifdef CONFIG_ZONE_DMA\n\t/*\n\t * The most common case is KMALLOC_NORMAL, so test for it\n\t * with a single branch for both flags.\n\t */\n\tif (likely((flags & (__GFP_DMA | __GFP_RECLAIMABLE)) == 0))\n\t\treturn KMALLOC_NORMAL;\n\n\t/*\n\t * At least one of the flags has to be set. If both are, __GFP_DMA\n\t * is more important.\n\t */\n\treturn flags & __GFP_DMA ? KMALLOC_DMA : KMALLOC_RECLAIM;\n#else\n\treturn flags & __GFP_RECLAIMABLE ? KMALLOC_RECLAIM : KMALLOC_NORMAL;\n#endif\n}\n\n/*\n * Figure out which kmalloc slab an allocation of a certain size\n * belongs to.\n * 0 = zero alloc\n * 1 =  65 .. 96 bytes\n * 2 = 129 .. 192 bytes\n * n = 2^(n-1)+1 .. 2^n\n */\nstatic __always_inline unsigned int kmalloc_index(size_t size)\n{\n\tif (!size)\n\t\treturn 0;\n\n\tif (size <= KMALLOC_MIN_SIZE)\n\t\treturn KMALLOC_SHIFT_LOW;\n\n\tif (KMALLOC_MIN_SIZE <= 32 && size > 64 && size <= 96)\n\t\treturn 1;\n\tif (KMALLOC_MIN_SIZE <= 64 && size > 128 && size <= 192)\n\t\treturn 2;\n\tif (size <=          8) return 3;\n\tif (size <=         16) return 4;\n\tif (size <=         32) return 5;\n\tif (size <=         64) return 6;\n\tif (size <=        128) return 7;\n\tif (size <=        256) return 8;\n\tif (size <=        512) return 9;\n\tif (size <=       1024) return 10;\n\tif (size <=   2 * 1024) return 11;\n\tif (size <=   4 * 1024) return 12;\n\tif (size <=   8 * 1024) return 13;\n\tif (size <=  16 * 1024) return 14;\n\tif (size <=  32 * 1024) return 15;\n\tif (size <=  64 * 1024) return 16;\n\tif (size <= 128 * 1024) return 17;\n\tif (size <= 256 * 1024) return 18;\n\tif (size <= 512 * 1024) return 19;\n\tif (size <= 1024 * 1024) return 20;\n\tif (size <=  2 * 1024 * 1024) return 21;\n\tif (size <=  4 * 1024 * 1024) return 22;\n\tif (size <=  8 * 1024 * 1024) return 23;\n\tif (size <=  16 * 1024 * 1024) return 24;\n\tif (size <=  32 * 1024 * 1024) return 25;\n\tif (size <=  64 * 1024 * 1024) return 26;\n\tBUG();\n\n\t/* Will never be reached. Needed because the compiler may complain */\n\treturn -1;\n}\n#endif /* !CONFIG_SLOB */\n\nvoid *__kmalloc(size_t size, gfp_t flags) __assume_kmalloc_alignment __malloc;\nvoid *kmem_cache_alloc(struct kmem_cache *, gfp_t flags) __assume_slab_alignment __malloc;\nvoid kmem_cache_free(struct kmem_cache *, void *);\n\n/*\n * Bulk allocation and freeing operations. These are accelerated in an\n * allocator specific way to avoid taking locks repeatedly or building\n * metadata structures unnecessarily.\n *\n * Note that interrupts must be enabled when calling these functions.\n */\nvoid kmem_cache_free_bulk(struct kmem_cache *, size_t, void **);\nint kmem_cache_alloc_bulk(struct kmem_cache *, gfp_t, size_t, void **);\n\n/*\n * Caller must not use kfree_bulk() on memory not originally allocated\n * by kmalloc(), because the SLOB allocator cannot handle this.\n */\nstatic __always_inline void kfree_bulk(size_t size, void **p)\n{\n\tkmem_cache_free_bulk(NULL, size, p);\n}\n\n#ifdef CONFIG_NUMA\nvoid *__kmalloc_node(size_t size, gfp_t flags, int node) __assume_kmalloc_alignment __malloc;\nvoid *kmem_cache_alloc_node(struct kmem_cache *, gfp_t flags, int node) __assume_slab_alignment __malloc;\n#else\nstatic __always_inline void *__kmalloc_node(size_t size, gfp_t flags, int node)\n{\n\treturn __kmalloc(size, flags);\n}\n\nstatic __always_inline void *kmem_cache_alloc_node(struct kmem_cache *s, gfp_t flags, int node)\n{\n\treturn kmem_cache_alloc(s, flags);\n}\n#endif\n\n#ifdef CONFIG_TRACING\nextern void *kmem_cache_alloc_trace(struct kmem_cache *, gfp_t, size_t) __assume_slab_alignment __malloc;\n\n#ifdef CONFIG_NUMA\nextern void *kmem_cache_alloc_node_trace(struct kmem_cache *s,\n\t\t\t\t\t   gfp_t gfpflags,\n\t\t\t\t\t   int node, size_t size) __assume_slab_alignment __malloc;\n#else\nstatic __always_inline void *\nkmem_cache_alloc_node_trace(struct kmem_cache *s,\n\t\t\t      gfp_t gfpflags,\n\t\t\t      int node, size_t size)\n{\n\treturn kmem_cache_alloc_trace(s, gfpflags, size);\n}\n#endif /* CONFIG_NUMA */\n\n#else /* CONFIG_TRACING */\nstatic __always_inline void *kmem_cache_alloc_trace(struct kmem_cache *s,\n\t\tgfp_t flags, size_t size)\n{\n\tvoid *ret = kmem_cache_alloc(s, flags);\n\n\tret = kasan_kmalloc(s, ret, size, flags);\n\treturn ret;\n}\n\nstatic __always_inline void *\nkmem_cache_alloc_node_trace(struct kmem_cache *s,\n\t\t\t      gfp_t gfpflags,\n\t\t\t      int node, size_t size)\n{\n\tvoid *ret = kmem_cache_alloc_node(s, gfpflags, node);\n\n\tret = kasan_kmalloc(s, ret, size, gfpflags);\n\treturn ret;\n}\n#endif /* CONFIG_TRACING */\n\nextern void *kmalloc_order(size_t size, gfp_t flags, unsigned int order) __assume_page_alignment __malloc;\n\n#ifdef CONFIG_TRACING\nextern void *kmalloc_order_trace(size_t size, gfp_t flags, unsigned int order) __assume_page_alignment __malloc;\n#else\nstatic __always_inline void *\nkmalloc_order_trace(size_t size, gfp_t flags, unsigned int order)\n{\n\treturn kmalloc_order(size, flags, order);\n}\n#endif\n\nstatic __always_inline void *kmalloc_large(size_t size, gfp_t flags)\n{\n\tunsigned int order = get_order(size);\n\treturn kmalloc_order_trace(size, flags, order);\n}\n\n/**\n * kmalloc - allocate memory\n * @size: how many bytes of memory are required.\n * @flags: the type of memory to allocate.\n *\n * kmalloc is the normal method of allocating memory\n * for objects smaller than page size in the kernel.\n *\n * The allocated object address is aligned to at least ARCH_KMALLOC_MINALIGN\n * bytes. For @size of power of two bytes, the alignment is also guaranteed\n * to be at least to the size.\n *\n * The @flags argument may be one of the GFP flags defined at\n * include/linux/gfp.h and described at\n * :ref:`Documentation/core-api/mm-api.rst <mm-api-gfp-flags>`\n *\n * The recommended usage of the @flags is described at\n * :ref:`Documentation/core-api/memory-allocation.rst <memory_allocation>`\n *\n * Below is a brief outline of the most useful GFP flags\n *\n * %GFP_KERNEL\n *\tAllocate normal kernel ram. May sleep.\n *\n * %GFP_NOWAIT\n *\tAllocation will not sleep.\n *\n * %GFP_ATOMIC\n *\tAllocation will not sleep.  May use emergency pools.\n *\n * %GFP_HIGHUSER\n *\tAllocate memory from high memory on behalf of user.\n *\n * Also it is possible to set different flags by OR'ing\n * in one or more of the following additional @flags:\n *\n * %__GFP_HIGH\n *\tThis allocation has high priority and may use emergency pools.\n *\n * %__GFP_NOFAIL\n *\tIndicate that this allocation is in no way allowed to fail\n *\t(think twice before using).\n *\n * %__GFP_NORETRY\n *\tIf memory is not immediately available,\n *\tthen give up at once.\n *\n * %__GFP_NOWARN\n *\tIf allocation fails, don't issue any warnings.\n *\n * %__GFP_RETRY_MAYFAIL\n *\tTry really hard to succeed the allocation but fail\n *\teventually.\n */\nstatic __always_inline void *kmalloc(size_t size, gfp_t flags)\n{\n\tif (__builtin_constant_p(size)) {\n#ifndef CONFIG_SLOB\n\t\tunsigned int index;\n#endif\n\t\tif (size > KMALLOC_MAX_CACHE_SIZE)\n\t\t\treturn kmalloc_large(size, flags);\n#ifndef CONFIG_SLOB\n\t\tindex = kmalloc_index(size);\n\n\t\tif (!index)\n\t\t\treturn ZERO_SIZE_PTR;\n\n\t\treturn kmem_cache_alloc_trace(\n\t\t\t\tkmalloc_caches[kmalloc_type(flags)][index],\n\t\t\t\tflags, size);\n#endif\n\t}\n\treturn __kmalloc(size, flags);\n}\n\nstatic __always_inline void *kmalloc_node(size_t size, gfp_t flags, int node)\n{\n#ifndef CONFIG_SLOB\n\tif (__builtin_constant_p(size) &&\n\t\tsize <= KMALLOC_MAX_CACHE_SIZE) {\n\t\tunsigned int i = kmalloc_index(size);\n\n\t\tif (!i)\n\t\t\treturn ZERO_SIZE_PTR;\n\n\t\treturn kmem_cache_alloc_node_trace(\n\t\t\t\tkmalloc_caches[kmalloc_type(flags)][i],\n\t\t\t\t\t\tflags, node, size);\n\t}\n#endif\n\treturn __kmalloc_node(size, flags, node);\n}\n\n/**\n * kmalloc_array - allocate memory for an array.\n * @n: number of elements.\n * @size: element size.\n * @flags: the type of memory to allocate (see kmalloc).\n */\nstatic inline void *kmalloc_array(size_t n, size_t size, gfp_t flags)\n{\n\tsize_t bytes;\n\n\tif (unlikely(check_mul_overflow(n, size, &bytes)))\n\t\treturn NULL;\n\tif (__builtin_constant_p(n) && __builtin_constant_p(size))\n\t\treturn kmalloc(bytes, flags);\n\treturn __kmalloc(bytes, flags);\n}\n\n/**\n * krealloc_array - reallocate memory for an array.\n * @p: pointer to the memory chunk to reallocate\n * @new_n: new number of elements to alloc\n * @new_size: new size of a single member of the array\n * @flags: the type of memory to allocate (see kmalloc)\n */\nstatic __must_check inline void *\nkrealloc_array(void *p, size_t new_n, size_t new_size, gfp_t flags)\n{\n\tsize_t bytes;\n\n\tif (unlikely(check_mul_overflow(new_n, new_size, &bytes)))\n\t\treturn NULL;\n\n\treturn krealloc(p, bytes, flags);\n}\n\n/**\n * kcalloc - allocate memory for an array. The memory is set to zero.\n * @n: number of elements.\n * @size: element size.\n * @flags: the type of memory to allocate (see kmalloc).\n */\nstatic inline void *kcalloc(size_t n, size_t size, gfp_t flags)\n{\n\treturn kmalloc_array(n, size, flags | __GFP_ZERO);\n}\n\n/*\n * kmalloc_track_caller is a special version of kmalloc that records the\n * calling function of the routine calling it for slab leak tracking instead\n * of just the calling function (confusing, eh?).\n * It's useful when the call to kmalloc comes from a widely-used standard\n * allocator where we care about the real place the memory allocation\n * request comes from.\n */\nextern void *__kmalloc_track_caller(size_t, gfp_t, unsigned long);\n#define kmalloc_track_caller(size, flags) \\\n\t__kmalloc_track_caller(size, flags, _RET_IP_)\n\nstatic inline void *kmalloc_array_node(size_t n, size_t size, gfp_t flags,\n\t\t\t\t       int node)\n{\n\tsize_t bytes;\n\n\tif (unlikely(check_mul_overflow(n, size, &bytes)))\n\t\treturn NULL;\n\tif (__builtin_constant_p(n) && __builtin_constant_p(size))\n\t\treturn kmalloc_node(bytes, flags, node);\n\treturn __kmalloc_node(bytes, flags, node);\n}\n\nstatic inline void *kcalloc_node(size_t n, size_t size, gfp_t flags, int node)\n{\n\treturn kmalloc_array_node(n, size, flags | __GFP_ZERO, node);\n}\n\n\n#ifdef CONFIG_NUMA\nextern void *__kmalloc_node_track_caller(size_t, gfp_t, int, unsigned long);\n#define kmalloc_node_track_caller(size, flags, node) \\\n\t__kmalloc_node_track_caller(size, flags, node, \\\n\t\t\t_RET_IP_)\n\n#else /* CONFIG_NUMA */\n\n#define kmalloc_node_track_caller(size, flags, node) \\\n\tkmalloc_track_caller(size, flags)\n\n#endif /* CONFIG_NUMA */\n\n/*\n * Shortcuts\n */\nstatic inline void *kmem_cache_zalloc(struct kmem_cache *k, gfp_t flags)\n{\n\treturn kmem_cache_alloc(k, flags | __GFP_ZERO);\n}\n\n/**\n * kzalloc - allocate memory. The memory is set to zero.\n * @size: how many bytes of memory are required.\n * @flags: the type of memory to allocate (see kmalloc).\n */\nstatic inline void *kzalloc(size_t size, gfp_t flags)\n{\n\treturn kmalloc(size, flags | __GFP_ZERO);\n}\n\n/**\n * kzalloc_node - allocate zeroed memory from a particular memory node.\n * @size: how many bytes of memory are required.\n * @flags: the type of memory to allocate (see kmalloc).\n * @node: memory node from which to allocate\n */\nstatic inline void *kzalloc_node(size_t size, gfp_t flags, int node)\n{\n\treturn kmalloc_node(size, flags | __GFP_ZERO, node);\n}\n\nunsigned int kmem_cache_size(struct kmem_cache *s);\nvoid __init kmem_cache_init_late(void);\n\n#if defined(CONFIG_SMP) && defined(CONFIG_SLAB)\nint slab_prepare_cpu(unsigned int cpu);\nint slab_dead_cpu(unsigned int cpu);\n#else\n#define slab_prepare_cpu\tNULL\n#define slab_dead_cpu\t\tNULL\n#endif\n\n#endif\t/* _LINUX_SLAB_H */\n"}, "5": {"id": 5, "path": "/src/include/linux/err.h", "content": "/* SPDX-License-Identifier: GPL-2.0 */\n#ifndef _LINUX_ERR_H\n#define _LINUX_ERR_H\n\n#include <linux/compiler.h>\n#include <linux/types.h>\n\n#include <asm/errno.h>\n\n/*\n * Kernel pointers have redundant information, so we can use a\n * scheme where we can return either an error code or a normal\n * pointer with the same return value.\n *\n * This should be a per-architecture thing, to allow different\n * error and pointer decisions.\n */\n#define MAX_ERRNO\t4095\n\n#ifndef __ASSEMBLY__\n\n#define IS_ERR_VALUE(x) unlikely((unsigned long)(void *)(x) >= (unsigned long)-MAX_ERRNO)\n\nstatic inline void * __must_check ERR_PTR(long error)\n{\n\treturn (void *) error;\n}\n\nstatic inline long __must_check PTR_ERR(__force const void *ptr)\n{\n\treturn (long) ptr;\n}\n\nstatic inline bool __must_check IS_ERR(__force const void *ptr)\n{\n\treturn IS_ERR_VALUE((unsigned long)ptr);\n}\n\nstatic inline bool __must_check IS_ERR_OR_NULL(__force const void *ptr)\n{\n\treturn unlikely(!ptr) || IS_ERR_VALUE((unsigned long)ptr);\n}\n\n/**\n * ERR_CAST - Explicitly cast an error-valued pointer to another pointer type\n * @ptr: The pointer to cast.\n *\n * Explicitly cast an error-valued pointer to another pointer type in such a\n * way as to make it clear that's what's going on.\n */\nstatic inline void * __must_check ERR_CAST(__force const void *ptr)\n{\n\t/* cast away the const */\n\treturn (void *) ptr;\n}\n\nstatic inline int __must_check PTR_ERR_OR_ZERO(__force const void *ptr)\n{\n\tif (IS_ERR(ptr))\n\t\treturn PTR_ERR(ptr);\n\telse\n\t\treturn 0;\n}\n\n#endif\n\n#endif /* _LINUX_ERR_H */\n"}, "6": {"id": 6, "path": "/src/include/linux/netdevice.h", "content": "/* SPDX-License-Identifier: GPL-2.0-or-later */\n/*\n * INET\t\tAn implementation of the TCP/IP protocol suite for the LINUX\n *\t\toperating system.  INET is implemented using the  BSD Socket\n *\t\tinterface as the means of communication with the user level.\n *\n *\t\tDefinitions for the Interfaces handler.\n *\n * Version:\t@(#)dev.h\t1.0.10\t08/12/93\n *\n * Authors:\tRoss Biro\n *\t\tFred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>\n *\t\tCorey Minyard <wf-rch!minyard@relay.EU.net>\n *\t\tDonald J. Becker, <becker@cesdis.gsfc.nasa.gov>\n *\t\tAlan Cox, <alan@lxorguk.ukuu.org.uk>\n *\t\tBjorn Ekwall. <bj0rn@blox.se>\n *              Pekka Riikonen <priikone@poseidon.pspt.fi>\n *\n *\t\tMoved to /usr/include/linux for NET3\n */\n#ifndef _LINUX_NETDEVICE_H\n#define _LINUX_NETDEVICE_H\n\n#include <linux/timer.h>\n#include <linux/bug.h>\n#include <linux/delay.h>\n#include <linux/atomic.h>\n#include <linux/prefetch.h>\n#include <asm/cache.h>\n#include <asm/byteorder.h>\n\n#include <linux/percpu.h>\n#include <linux/rculist.h>\n#include <linux/workqueue.h>\n#include <linux/dynamic_queue_limits.h>\n\n#include <net/net_namespace.h>\n#ifdef CONFIG_DCB\n#include <net/dcbnl.h>\n#endif\n#include <net/netprio_cgroup.h>\n#include <net/xdp.h>\n\n#include <linux/netdev_features.h>\n#include <linux/neighbour.h>\n#include <uapi/linux/netdevice.h>\n#include <uapi/linux/if_bonding.h>\n#include <uapi/linux/pkt_cls.h>\n#include <linux/hashtable.h>\n\nstruct netpoll_info;\nstruct device;\nstruct ethtool_ops;\nstruct phy_device;\nstruct dsa_port;\nstruct ip_tunnel_parm;\nstruct macsec_context;\nstruct macsec_ops;\n\nstruct sfp_bus;\n/* 802.11 specific */\nstruct wireless_dev;\n/* 802.15.4 specific */\nstruct wpan_dev;\nstruct mpls_dev;\n/* UDP Tunnel offloads */\nstruct udp_tunnel_info;\nstruct udp_tunnel_nic_info;\nstruct udp_tunnel_nic;\nstruct bpf_prog;\nstruct xdp_buff;\n\nvoid synchronize_net(void);\nvoid netdev_set_default_ethtool_ops(struct net_device *dev,\n\t\t\t\t    const struct ethtool_ops *ops);\n\n/* Backlog congestion levels */\n#define NET_RX_SUCCESS\t\t0\t/* keep 'em coming, baby */\n#define NET_RX_DROP\t\t1\t/* packet dropped */\n\n#define MAX_NEST_DEV 8\n\n/*\n * Transmit return codes: transmit return codes originate from three different\n * namespaces:\n *\n * - qdisc return codes\n * - driver transmit return codes\n * - errno values\n *\n * Drivers are allowed to return any one of those in their hard_start_xmit()\n * function. Real network devices commonly used with qdiscs should only return\n * the driver transmit return codes though - when qdiscs are used, the actual\n * transmission happens asynchronously, so the value is not propagated to\n * higher layers. Virtual network devices transmit synchronously; in this case\n * the driver transmit return codes are consumed by dev_queue_xmit(), and all\n * others are propagated to higher layers.\n */\n\n/* qdisc ->enqueue() return codes. */\n#define NET_XMIT_SUCCESS\t0x00\n#define NET_XMIT_DROP\t\t0x01\t/* skb dropped\t\t\t*/\n#define NET_XMIT_CN\t\t0x02\t/* congestion notification\t*/\n#define NET_XMIT_MASK\t\t0x0f\t/* qdisc flags in net/sch_generic.h */\n\n/* NET_XMIT_CN is special. It does not guarantee that this packet is lost. It\n * indicates that the device will soon be dropping packets, or already drops\n * some packets of the same priority; prompting us to send less aggressively. */\n#define net_xmit_eval(e)\t((e) == NET_XMIT_CN ? 0 : (e))\n#define net_xmit_errno(e)\t((e) != NET_XMIT_CN ? -ENOBUFS : 0)\n\n/* Driver transmit return codes */\n#define NETDEV_TX_MASK\t\t0xf0\n\nenum netdev_tx {\n\t__NETDEV_TX_MIN\t = INT_MIN,\t/* make sure enum is signed */\n\tNETDEV_TX_OK\t = 0x00,\t/* driver took care of packet */\n\tNETDEV_TX_BUSY\t = 0x10,\t/* driver tx path was busy*/\n};\ntypedef enum netdev_tx netdev_tx_t;\n\n/*\n * Current order: NETDEV_TX_MASK > NET_XMIT_MASK >= 0 is significant;\n * hard_start_xmit() return < NET_XMIT_MASK means skb was consumed.\n */\nstatic inline bool dev_xmit_complete(int rc)\n{\n\t/*\n\t * Positive cases with an skb consumed by a driver:\n\t * - successful transmission (rc == NETDEV_TX_OK)\n\t * - error while transmitting (rc < 0)\n\t * - error while queueing to a different device (rc & NET_XMIT_MASK)\n\t */\n\tif (likely(rc < NET_XMIT_MASK))\n\t\treturn true;\n\n\treturn false;\n}\n\n/*\n *\tCompute the worst-case header length according to the protocols\n *\tused.\n */\n\n#if defined(CONFIG_HYPERV_NET)\n# define LL_MAX_HEADER 128\n#elif defined(CONFIG_WLAN) || IS_ENABLED(CONFIG_AX25)\n# if defined(CONFIG_MAC80211_MESH)\n#  define LL_MAX_HEADER 128\n# else\n#  define LL_MAX_HEADER 96\n# endif\n#else\n# define LL_MAX_HEADER 32\n#endif\n\n#if !IS_ENABLED(CONFIG_NET_IPIP) && !IS_ENABLED(CONFIG_NET_IPGRE) && \\\n    !IS_ENABLED(CONFIG_IPV6_SIT) && !IS_ENABLED(CONFIG_IPV6_TUNNEL)\n#define MAX_HEADER LL_MAX_HEADER\n#else\n#define MAX_HEADER (LL_MAX_HEADER + 48)\n#endif\n\n/*\n *\tOld network device statistics. Fields are native words\n *\t(unsigned long) so they can be read and written atomically.\n */\n\nstruct net_device_stats {\n\tunsigned long\trx_packets;\n\tunsigned long\ttx_packets;\n\tunsigned long\trx_bytes;\n\tunsigned long\ttx_bytes;\n\tunsigned long\trx_errors;\n\tunsigned long\ttx_errors;\n\tunsigned long\trx_dropped;\n\tunsigned long\ttx_dropped;\n\tunsigned long\tmulticast;\n\tunsigned long\tcollisions;\n\tunsigned long\trx_length_errors;\n\tunsigned long\trx_over_errors;\n\tunsigned long\trx_crc_errors;\n\tunsigned long\trx_frame_errors;\n\tunsigned long\trx_fifo_errors;\n\tunsigned long\trx_missed_errors;\n\tunsigned long\ttx_aborted_errors;\n\tunsigned long\ttx_carrier_errors;\n\tunsigned long\ttx_fifo_errors;\n\tunsigned long\ttx_heartbeat_errors;\n\tunsigned long\ttx_window_errors;\n\tunsigned long\trx_compressed;\n\tunsigned long\ttx_compressed;\n};\n\n\n#include <linux/cache.h>\n#include <linux/skbuff.h>\n\n#ifdef CONFIG_RPS\n#include <linux/static_key.h>\nextern struct static_key_false rps_needed;\nextern struct static_key_false rfs_needed;\n#endif\n\nstruct neighbour;\nstruct neigh_parms;\nstruct sk_buff;\n\nstruct netdev_hw_addr {\n\tstruct list_head\tlist;\n\tunsigned char\t\taddr[MAX_ADDR_LEN];\n\tunsigned char\t\ttype;\n#define NETDEV_HW_ADDR_T_LAN\t\t1\n#define NETDEV_HW_ADDR_T_SAN\t\t2\n#define NETDEV_HW_ADDR_T_UNICAST\t3\n#define NETDEV_HW_ADDR_T_MULTICAST\t4\n\tbool\t\t\tglobal_use;\n\tint\t\t\tsync_cnt;\n\tint\t\t\trefcount;\n\tint\t\t\tsynced;\n\tstruct rcu_head\t\trcu_head;\n};\n\nstruct netdev_hw_addr_list {\n\tstruct list_head\tlist;\n\tint\t\t\tcount;\n};\n\n#define netdev_hw_addr_list_count(l) ((l)->count)\n#define netdev_hw_addr_list_empty(l) (netdev_hw_addr_list_count(l) == 0)\n#define netdev_hw_addr_list_for_each(ha, l) \\\n\tlist_for_each_entry(ha, &(l)->list, list)\n\n#define netdev_uc_count(dev) netdev_hw_addr_list_count(&(dev)->uc)\n#define netdev_uc_empty(dev) netdev_hw_addr_list_empty(&(dev)->uc)\n#define netdev_for_each_uc_addr(ha, dev) \\\n\tnetdev_hw_addr_list_for_each(ha, &(dev)->uc)\n\n#define netdev_mc_count(dev) netdev_hw_addr_list_count(&(dev)->mc)\n#define netdev_mc_empty(dev) netdev_hw_addr_list_empty(&(dev)->mc)\n#define netdev_for_each_mc_addr(ha, dev) \\\n\tnetdev_hw_addr_list_for_each(ha, &(dev)->mc)\n\nstruct hh_cache {\n\tunsigned int\thh_len;\n\tseqlock_t\thh_lock;\n\n\t/* cached hardware header; allow for machine alignment needs.        */\n#define HH_DATA_MOD\t16\n#define HH_DATA_OFF(__len) \\\n\t(HH_DATA_MOD - (((__len - 1) & (HH_DATA_MOD - 1)) + 1))\n#define HH_DATA_ALIGN(__len) \\\n\t(((__len)+(HH_DATA_MOD-1))&~(HH_DATA_MOD - 1))\n\tunsigned long\thh_data[HH_DATA_ALIGN(LL_MAX_HEADER) / sizeof(long)];\n};\n\n/* Reserve HH_DATA_MOD byte-aligned hard_header_len, but at least that much.\n * Alternative is:\n *   dev->hard_header_len ? (dev->hard_header_len +\n *                           (HH_DATA_MOD - 1)) & ~(HH_DATA_MOD - 1) : 0\n *\n * We could use other alignment values, but we must maintain the\n * relationship HH alignment <= LL alignment.\n */\n#define LL_RESERVED_SPACE(dev) \\\n\t((((dev)->hard_header_len+(dev)->needed_headroom)&~(HH_DATA_MOD - 1)) + HH_DATA_MOD)\n#define LL_RESERVED_SPACE_EXTRA(dev,extra) \\\n\t((((dev)->hard_header_len+(dev)->needed_headroom+(extra))&~(HH_DATA_MOD - 1)) + HH_DATA_MOD)\n\nstruct header_ops {\n\tint\t(*create) (struct sk_buff *skb, struct net_device *dev,\n\t\t\t   unsigned short type, const void *daddr,\n\t\t\t   const void *saddr, unsigned int len);\n\tint\t(*parse)(const struct sk_buff *skb, unsigned char *haddr);\n\tint\t(*cache)(const struct neighbour *neigh, struct hh_cache *hh, __be16 type);\n\tvoid\t(*cache_update)(struct hh_cache *hh,\n\t\t\t\tconst struct net_device *dev,\n\t\t\t\tconst unsigned char *haddr);\n\tbool\t(*validate)(const char *ll_header, unsigned int len);\n\t__be16\t(*parse_protocol)(const struct sk_buff *skb);\n};\n\n/* These flag bits are private to the generic network queueing\n * layer; they may not be explicitly referenced by any other\n * code.\n */\n\nenum netdev_state_t {\n\t__LINK_STATE_START,\n\t__LINK_STATE_PRESENT,\n\t__LINK_STATE_NOCARRIER,\n\t__LINK_STATE_LINKWATCH_PENDING,\n\t__LINK_STATE_DORMANT,\n\t__LINK_STATE_TESTING,\n};\n\n\n/*\n * This structure holds boot-time configured netdevice settings. They\n * are then used in the device probing.\n */\nstruct netdev_boot_setup {\n\tchar name[IFNAMSIZ];\n\tstruct ifmap map;\n};\n#define NETDEV_BOOT_SETUP_MAX 8\n\nint __init netdev_boot_setup(char *str);\n\nstruct gro_list {\n\tstruct list_head\tlist;\n\tint\t\t\tcount;\n};\n\n/*\n * size of gro hash buckets, must less than bit number of\n * napi_struct::gro_bitmask\n */\n#define GRO_HASH_BUCKETS\t8\n\n/*\n * Structure for NAPI scheduling similar to tasklet but with weighting\n */\nstruct napi_struct {\n\t/* The poll_list must only be managed by the entity which\n\t * changes the state of the NAPI_STATE_SCHED bit.  This means\n\t * whoever atomically sets that bit can add this napi_struct\n\t * to the per-CPU poll_list, and whoever clears that bit\n\t * can remove from the list right before clearing the bit.\n\t */\n\tstruct list_head\tpoll_list;\n\n\tunsigned long\t\tstate;\n\tint\t\t\tweight;\n\tint\t\t\tdefer_hard_irqs_count;\n\tunsigned long\t\tgro_bitmask;\n\tint\t\t\t(*poll)(struct napi_struct *, int);\n#ifdef CONFIG_NETPOLL\n\tint\t\t\tpoll_owner;\n#endif\n\tstruct net_device\t*dev;\n\tstruct gro_list\t\tgro_hash[GRO_HASH_BUCKETS];\n\tstruct sk_buff\t\t*skb;\n\tstruct list_head\trx_list; /* Pending GRO_NORMAL skbs */\n\tint\t\t\trx_count; /* length of rx_list */\n\tstruct hrtimer\t\ttimer;\n\tstruct list_head\tdev_list;\n\tstruct hlist_node\tnapi_hash_node;\n\tunsigned int\t\tnapi_id;\n\tstruct task_struct\t*thread;\n};\n\nenum {\n\tNAPI_STATE_SCHED,\t\t/* Poll is scheduled */\n\tNAPI_STATE_MISSED,\t\t/* reschedule a napi */\n\tNAPI_STATE_DISABLE,\t\t/* Disable pending */\n\tNAPI_STATE_NPSVC,\t\t/* Netpoll - don't dequeue from poll_list */\n\tNAPI_STATE_LISTED,\t\t/* NAPI added to system lists */\n\tNAPI_STATE_NO_BUSY_POLL,\t/* Do not add in napi_hash, no busy polling */\n\tNAPI_STATE_IN_BUSY_POLL,\t/* sk_busy_loop() owns this NAPI */\n\tNAPI_STATE_PREFER_BUSY_POLL,\t/* prefer busy-polling over softirq processing*/\n\tNAPI_STATE_THREADED,\t\t/* The poll is performed inside its own thread*/\n};\n\nenum {\n\tNAPIF_STATE_SCHED\t\t= BIT(NAPI_STATE_SCHED),\n\tNAPIF_STATE_MISSED\t\t= BIT(NAPI_STATE_MISSED),\n\tNAPIF_STATE_DISABLE\t\t= BIT(NAPI_STATE_DISABLE),\n\tNAPIF_STATE_NPSVC\t\t= BIT(NAPI_STATE_NPSVC),\n\tNAPIF_STATE_LISTED\t\t= BIT(NAPI_STATE_LISTED),\n\tNAPIF_STATE_NO_BUSY_POLL\t= BIT(NAPI_STATE_NO_BUSY_POLL),\n\tNAPIF_STATE_IN_BUSY_POLL\t= BIT(NAPI_STATE_IN_BUSY_POLL),\n\tNAPIF_STATE_PREFER_BUSY_POLL\t= BIT(NAPI_STATE_PREFER_BUSY_POLL),\n\tNAPIF_STATE_THREADED\t\t= BIT(NAPI_STATE_THREADED),\n};\n\nenum gro_result {\n\tGRO_MERGED,\n\tGRO_MERGED_FREE,\n\tGRO_HELD,\n\tGRO_NORMAL,\n\tGRO_CONSUMED,\n};\ntypedef enum gro_result gro_result_t;\n\n/*\n * enum rx_handler_result - Possible return values for rx_handlers.\n * @RX_HANDLER_CONSUMED: skb was consumed by rx_handler, do not process it\n * further.\n * @RX_HANDLER_ANOTHER: Do another round in receive path. This is indicated in\n * case skb->dev was changed by rx_handler.\n * @RX_HANDLER_EXACT: Force exact delivery, no wildcard.\n * @RX_HANDLER_PASS: Do nothing, pass the skb as if no rx_handler was called.\n *\n * rx_handlers are functions called from inside __netif_receive_skb(), to do\n * special processing of the skb, prior to delivery to protocol handlers.\n *\n * Currently, a net_device can only have a single rx_handler registered. Trying\n * to register a second rx_handler will return -EBUSY.\n *\n * To register a rx_handler on a net_device, use netdev_rx_handler_register().\n * To unregister a rx_handler on a net_device, use\n * netdev_rx_handler_unregister().\n *\n * Upon return, rx_handler is expected to tell __netif_receive_skb() what to\n * do with the skb.\n *\n * If the rx_handler consumed the skb in some way, it should return\n * RX_HANDLER_CONSUMED. This is appropriate when the rx_handler arranged for\n * the skb to be delivered in some other way.\n *\n * If the rx_handler changed skb->dev, to divert the skb to another\n * net_device, it should return RX_HANDLER_ANOTHER. The rx_handler for the\n * new device will be called if it exists.\n *\n * If the rx_handler decides the skb should be ignored, it should return\n * RX_HANDLER_EXACT. The skb will only be delivered to protocol handlers that\n * are registered on exact device (ptype->dev == skb->dev).\n *\n * If the rx_handler didn't change skb->dev, but wants the skb to be normally\n * delivered, it should return RX_HANDLER_PASS.\n *\n * A device without a registered rx_handler will behave as if rx_handler\n * returned RX_HANDLER_PASS.\n */\n\nenum rx_handler_result {\n\tRX_HANDLER_CONSUMED,\n\tRX_HANDLER_ANOTHER,\n\tRX_HANDLER_EXACT,\n\tRX_HANDLER_PASS,\n};\ntypedef enum rx_handler_result rx_handler_result_t;\ntypedef rx_handler_result_t rx_handler_func_t(struct sk_buff **pskb);\n\nvoid __napi_schedule(struct napi_struct *n);\nvoid __napi_schedule_irqoff(struct napi_struct *n);\n\nstatic inline bool napi_disable_pending(struct napi_struct *n)\n{\n\treturn test_bit(NAPI_STATE_DISABLE, &n->state);\n}\n\nstatic inline bool napi_prefer_busy_poll(struct napi_struct *n)\n{\n\treturn test_bit(NAPI_STATE_PREFER_BUSY_POLL, &n->state);\n}\n\nbool napi_schedule_prep(struct napi_struct *n);\n\n/**\n *\tnapi_schedule - schedule NAPI poll\n *\t@n: NAPI context\n *\n * Schedule NAPI poll routine to be called if it is not already\n * running.\n */\nstatic inline void napi_schedule(struct napi_struct *n)\n{\n\tif (napi_schedule_prep(n))\n\t\t__napi_schedule(n);\n}\n\n/**\n *\tnapi_schedule_irqoff - schedule NAPI poll\n *\t@n: NAPI context\n *\n * Variant of napi_schedule(), assuming hard irqs are masked.\n */\nstatic inline void napi_schedule_irqoff(struct napi_struct *n)\n{\n\tif (napi_schedule_prep(n))\n\t\t__napi_schedule_irqoff(n);\n}\n\n/* Try to reschedule poll. Called by dev->poll() after napi_complete().  */\nstatic inline bool napi_reschedule(struct napi_struct *napi)\n{\n\tif (napi_schedule_prep(napi)) {\n\t\t__napi_schedule(napi);\n\t\treturn true;\n\t}\n\treturn false;\n}\n\nbool napi_complete_done(struct napi_struct *n, int work_done);\n/**\n *\tnapi_complete - NAPI processing complete\n *\t@n: NAPI context\n *\n * Mark NAPI processing as complete.\n * Consider using napi_complete_done() instead.\n * Return false if device should avoid rearming interrupts.\n */\nstatic inline bool napi_complete(struct napi_struct *n)\n{\n\treturn napi_complete_done(n, 0);\n}\n\nint dev_set_threaded(struct net_device *dev, bool threaded);\n\n/**\n *\tnapi_disable - prevent NAPI from scheduling\n *\t@n: NAPI context\n *\n * Stop NAPI from being scheduled on this context.\n * Waits till any outstanding processing completes.\n */\nvoid napi_disable(struct napi_struct *n);\n\nvoid napi_enable(struct napi_struct *n);\n\n/**\n *\tnapi_synchronize - wait until NAPI is not running\n *\t@n: NAPI context\n *\n * Wait until NAPI is done being scheduled on this context.\n * Waits till any outstanding processing completes but\n * does not disable future activations.\n */\nstatic inline void napi_synchronize(const struct napi_struct *n)\n{\n\tif (IS_ENABLED(CONFIG_SMP))\n\t\twhile (test_bit(NAPI_STATE_SCHED, &n->state))\n\t\t\tmsleep(1);\n\telse\n\t\tbarrier();\n}\n\n/**\n *\tnapi_if_scheduled_mark_missed - if napi is running, set the\n *\tNAPIF_STATE_MISSED\n *\t@n: NAPI context\n *\n * If napi is running, set the NAPIF_STATE_MISSED, and return true if\n * NAPI is scheduled.\n **/\nstatic inline bool napi_if_scheduled_mark_missed(struct napi_struct *n)\n{\n\tunsigned long val, new;\n\n\tdo {\n\t\tval = READ_ONCE(n->state);\n\t\tif (val & NAPIF_STATE_DISABLE)\n\t\t\treturn true;\n\n\t\tif (!(val & NAPIF_STATE_SCHED))\n\t\t\treturn false;\n\n\t\tnew = val | NAPIF_STATE_MISSED;\n\t} while (cmpxchg(&n->state, val, new) != val);\n\n\treturn true;\n}\n\nenum netdev_queue_state_t {\n\t__QUEUE_STATE_DRV_XOFF,\n\t__QUEUE_STATE_STACK_XOFF,\n\t__QUEUE_STATE_FROZEN,\n};\n\n#define QUEUE_STATE_DRV_XOFF\t(1 << __QUEUE_STATE_DRV_XOFF)\n#define QUEUE_STATE_STACK_XOFF\t(1 << __QUEUE_STATE_STACK_XOFF)\n#define QUEUE_STATE_FROZEN\t(1 << __QUEUE_STATE_FROZEN)\n\n#define QUEUE_STATE_ANY_XOFF\t(QUEUE_STATE_DRV_XOFF | QUEUE_STATE_STACK_XOFF)\n#define QUEUE_STATE_ANY_XOFF_OR_FROZEN (QUEUE_STATE_ANY_XOFF | \\\n\t\t\t\t\tQUEUE_STATE_FROZEN)\n#define QUEUE_STATE_DRV_XOFF_OR_FROZEN (QUEUE_STATE_DRV_XOFF | \\\n\t\t\t\t\tQUEUE_STATE_FROZEN)\n\n/*\n * __QUEUE_STATE_DRV_XOFF is used by drivers to stop the transmit queue.  The\n * netif_tx_* functions below are used to manipulate this flag.  The\n * __QUEUE_STATE_STACK_XOFF flag is used by the stack to stop the transmit\n * queue independently.  The netif_xmit_*stopped functions below are called\n * to check if the queue has been stopped by the driver or stack (either\n * of the XOFF bits are set in the state).  Drivers should not need to call\n * netif_xmit*stopped functions, they should only be using netif_tx_*.\n */\n\nstruct netdev_queue {\n/*\n * read-mostly part\n */\n\tstruct net_device\t*dev;\n\tstruct Qdisc __rcu\t*qdisc;\n\tstruct Qdisc\t\t*qdisc_sleeping;\n#ifdef CONFIG_SYSFS\n\tstruct kobject\t\tkobj;\n#endif\n#if defined(CONFIG_XPS) && defined(CONFIG_NUMA)\n\tint\t\t\tnuma_node;\n#endif\n\tunsigned long\t\ttx_maxrate;\n\t/*\n\t * Number of TX timeouts for this queue\n\t * (/sys/class/net/DEV/Q/trans_timeout)\n\t */\n\tunsigned long\t\ttrans_timeout;\n\n\t/* Subordinate device that the queue has been assigned to */\n\tstruct net_device\t*sb_dev;\n#ifdef CONFIG_XDP_SOCKETS\n\tstruct xsk_buff_pool    *pool;\n#endif\n/*\n * write-mostly part\n */\n\tspinlock_t\t\t_xmit_lock ____cacheline_aligned_in_smp;\n\tint\t\t\txmit_lock_owner;\n\t/*\n\t * Time (in jiffies) of last Tx\n\t */\n\tunsigned long\t\ttrans_start;\n\n\tunsigned long\t\tstate;\n\n#ifdef CONFIG_BQL\n\tstruct dql\t\tdql;\n#endif\n} ____cacheline_aligned_in_smp;\n\nextern int sysctl_fb_tunnels_only_for_init_net;\nextern int sysctl_devconf_inherit_init_net;\n\n/*\n * sysctl_fb_tunnels_only_for_init_net == 0 : For all netns\n *                                     == 1 : For initns only\n *                                     == 2 : For none.\n */\nstatic inline bool net_has_fallback_tunnels(const struct net *net)\n{\n\treturn !IS_ENABLED(CONFIG_SYSCTL) ||\n\t       !sysctl_fb_tunnels_only_for_init_net ||\n\t       (net == &init_net && sysctl_fb_tunnels_only_for_init_net == 1);\n}\n\nstatic inline int netdev_queue_numa_node_read(const struct netdev_queue *q)\n{\n#if defined(CONFIG_XPS) && defined(CONFIG_NUMA)\n\treturn q->numa_node;\n#else\n\treturn NUMA_NO_NODE;\n#endif\n}\n\nstatic inline void netdev_queue_numa_node_write(struct netdev_queue *q, int node)\n{\n#if defined(CONFIG_XPS) && defined(CONFIG_NUMA)\n\tq->numa_node = node;\n#endif\n}\n\n#ifdef CONFIG_RPS\n/*\n * This structure holds an RPS map which can be of variable length.  The\n * map is an array of CPUs.\n */\nstruct rps_map {\n\tunsigned int len;\n\tstruct rcu_head rcu;\n\tu16 cpus[];\n};\n#define RPS_MAP_SIZE(_num) (sizeof(struct rps_map) + ((_num) * sizeof(u16)))\n\n/*\n * The rps_dev_flow structure contains the mapping of a flow to a CPU, the\n * tail pointer for that CPU's input queue at the time of last enqueue, and\n * a hardware filter index.\n */\nstruct rps_dev_flow {\n\tu16 cpu;\n\tu16 filter;\n\tunsigned int last_qtail;\n};\n#define RPS_NO_FILTER 0xffff\n\n/*\n * The rps_dev_flow_table structure contains a table of flow mappings.\n */\nstruct rps_dev_flow_table {\n\tunsigned int mask;\n\tstruct rcu_head rcu;\n\tstruct rps_dev_flow flows[];\n};\n#define RPS_DEV_FLOW_TABLE_SIZE(_num) (sizeof(struct rps_dev_flow_table) + \\\n    ((_num) * sizeof(struct rps_dev_flow)))\n\n/*\n * The rps_sock_flow_table contains mappings of flows to the last CPU\n * on which they were processed by the application (set in recvmsg).\n * Each entry is a 32bit value. Upper part is the high-order bits\n * of flow hash, lower part is CPU number.\n * rps_cpu_mask is used to partition the space, depending on number of\n * possible CPUs : rps_cpu_mask = roundup_pow_of_two(nr_cpu_ids) - 1\n * For example, if 64 CPUs are possible, rps_cpu_mask = 0x3f,\n * meaning we use 32-6=26 bits for the hash.\n */\nstruct rps_sock_flow_table {\n\tu32\tmask;\n\n\tu32\tents[] ____cacheline_aligned_in_smp;\n};\n#define\tRPS_SOCK_FLOW_TABLE_SIZE(_num) (offsetof(struct rps_sock_flow_table, ents[_num]))\n\n#define RPS_NO_CPU 0xffff\n\nextern u32 rps_cpu_mask;\nextern struct rps_sock_flow_table __rcu *rps_sock_flow_table;\n\nstatic inline void rps_record_sock_flow(struct rps_sock_flow_table *table,\n\t\t\t\t\tu32 hash)\n{\n\tif (table && hash) {\n\t\tunsigned int index = hash & table->mask;\n\t\tu32 val = hash & ~rps_cpu_mask;\n\n\t\t/* We only give a hint, preemption can change CPU under us */\n\t\tval |= raw_smp_processor_id();\n\n\t\tif (table->ents[index] != val)\n\t\t\ttable->ents[index] = val;\n\t}\n}\n\n#ifdef CONFIG_RFS_ACCEL\nbool rps_may_expire_flow(struct net_device *dev, u16 rxq_index, u32 flow_id,\n\t\t\t u16 filter_id);\n#endif\n#endif /* CONFIG_RPS */\n\n/* This structure contains an instance of an RX queue. */\nstruct netdev_rx_queue {\n#ifdef CONFIG_RPS\n\tstruct rps_map __rcu\t\t*rps_map;\n\tstruct rps_dev_flow_table __rcu\t*rps_flow_table;\n#endif\n\tstruct kobject\t\t\tkobj;\n\tstruct net_device\t\t*dev;\n\tstruct xdp_rxq_info\t\txdp_rxq;\n#ifdef CONFIG_XDP_SOCKETS\n\tstruct xsk_buff_pool            *pool;\n#endif\n} ____cacheline_aligned_in_smp;\n\n/*\n * RX queue sysfs structures and functions.\n */\nstruct rx_queue_attribute {\n\tstruct attribute attr;\n\tssize_t (*show)(struct netdev_rx_queue *queue, char *buf);\n\tssize_t (*store)(struct netdev_rx_queue *queue,\n\t\t\t const char *buf, size_t len);\n};\n\n#ifdef CONFIG_XPS\n/*\n * This structure holds an XPS map which can be of variable length.  The\n * map is an array of queues.\n */\nstruct xps_map {\n\tunsigned int len;\n\tunsigned int alloc_len;\n\tstruct rcu_head rcu;\n\tu16 queues[];\n};\n#define XPS_MAP_SIZE(_num) (sizeof(struct xps_map) + ((_num) * sizeof(u16)))\n#define XPS_MIN_MAP_ALLOC ((L1_CACHE_ALIGN(offsetof(struct xps_map, queues[1])) \\\n       - sizeof(struct xps_map)) / sizeof(u16))\n\n/*\n * This structure holds all XPS maps for device.  Maps are indexed by CPU.\n */\nstruct xps_dev_maps {\n\tstruct rcu_head rcu;\n\tstruct xps_map __rcu *attr_map[]; /* Either CPUs map or RXQs map */\n};\n\n#define XPS_CPU_DEV_MAPS_SIZE(_tcs) (sizeof(struct xps_dev_maps) +\t\\\n\t(nr_cpu_ids * (_tcs) * sizeof(struct xps_map *)))\n\n#define XPS_RXQ_DEV_MAPS_SIZE(_tcs, _rxqs) (sizeof(struct xps_dev_maps) +\\\n\t(_rxqs * (_tcs) * sizeof(struct xps_map *)))\n\n#endif /* CONFIG_XPS */\n\n#define TC_MAX_QUEUE\t16\n#define TC_BITMASK\t15\n/* HW offloaded queuing disciplines txq count and offset maps */\nstruct netdev_tc_txq {\n\tu16 count;\n\tu16 offset;\n};\n\n#if defined(CONFIG_FCOE) || defined(CONFIG_FCOE_MODULE)\n/*\n * This structure is to hold information about the device\n * configured to run FCoE protocol stack.\n */\nstruct netdev_fcoe_hbainfo {\n\tchar\tmanufacturer[64];\n\tchar\tserial_number[64];\n\tchar\thardware_version[64];\n\tchar\tdriver_version[64];\n\tchar\toptionrom_version[64];\n\tchar\tfirmware_version[64];\n\tchar\tmodel[256];\n\tchar\tmodel_description[256];\n};\n#endif\n\n#define MAX_PHYS_ITEM_ID_LEN 32\n\n/* This structure holds a unique identifier to identify some\n * physical item (port for example) used by a netdevice.\n */\nstruct netdev_phys_item_id {\n\tunsigned char id[MAX_PHYS_ITEM_ID_LEN];\n\tunsigned char id_len;\n};\n\nstatic inline bool netdev_phys_item_id_same(struct netdev_phys_item_id *a,\n\t\t\t\t\t    struct netdev_phys_item_id *b)\n{\n\treturn a->id_len == b->id_len &&\n\t       memcmp(a->id, b->id, a->id_len) == 0;\n}\n\ntypedef u16 (*select_queue_fallback_t)(struct net_device *dev,\n\t\t\t\t       struct sk_buff *skb,\n\t\t\t\t       struct net_device *sb_dev);\n\nenum tc_setup_type {\n\tTC_SETUP_QDISC_MQPRIO,\n\tTC_SETUP_CLSU32,\n\tTC_SETUP_CLSFLOWER,\n\tTC_SETUP_CLSMATCHALL,\n\tTC_SETUP_CLSBPF,\n\tTC_SETUP_BLOCK,\n\tTC_SETUP_QDISC_CBS,\n\tTC_SETUP_QDISC_RED,\n\tTC_SETUP_QDISC_PRIO,\n\tTC_SETUP_QDISC_MQ,\n\tTC_SETUP_QDISC_ETF,\n\tTC_SETUP_ROOT_QDISC,\n\tTC_SETUP_QDISC_GRED,\n\tTC_SETUP_QDISC_TAPRIO,\n\tTC_SETUP_FT,\n\tTC_SETUP_QDISC_ETS,\n\tTC_SETUP_QDISC_TBF,\n\tTC_SETUP_QDISC_FIFO,\n\tTC_SETUP_QDISC_HTB,\n};\n\n/* These structures hold the attributes of bpf state that are being passed\n * to the netdevice through the bpf op.\n */\nenum bpf_netdev_command {\n\t/* Set or clear a bpf program used in the earliest stages of packet\n\t * rx. The prog will have been loaded as BPF_PROG_TYPE_XDP. The callee\n\t * is responsible for calling bpf_prog_put on any old progs that are\n\t * stored. In case of error, the callee need not release the new prog\n\t * reference, but on success it takes ownership and must bpf_prog_put\n\t * when it is no longer used.\n\t */\n\tXDP_SETUP_PROG,\n\tXDP_SETUP_PROG_HW,\n\t/* BPF program for offload callbacks, invoked at program load time. */\n\tBPF_OFFLOAD_MAP_ALLOC,\n\tBPF_OFFLOAD_MAP_FREE,\n\tXDP_SETUP_XSK_POOL,\n};\n\nstruct bpf_prog_offload_ops;\nstruct netlink_ext_ack;\nstruct xdp_umem;\nstruct xdp_dev_bulk_queue;\nstruct bpf_xdp_link;\n\nenum bpf_xdp_mode {\n\tXDP_MODE_SKB = 0,\n\tXDP_MODE_DRV = 1,\n\tXDP_MODE_HW = 2,\n\t__MAX_XDP_MODE\n};\n\nstruct bpf_xdp_entity {\n\tstruct bpf_prog *prog;\n\tstruct bpf_xdp_link *link;\n};\n\nstruct netdev_bpf {\n\tenum bpf_netdev_command command;\n\tunion {\n\t\t/* XDP_SETUP_PROG */\n\t\tstruct {\n\t\t\tu32 flags;\n\t\t\tstruct bpf_prog *prog;\n\t\t\tstruct netlink_ext_ack *extack;\n\t\t};\n\t\t/* BPF_OFFLOAD_MAP_ALLOC, BPF_OFFLOAD_MAP_FREE */\n\t\tstruct {\n\t\t\tstruct bpf_offloaded_map *offmap;\n\t\t};\n\t\t/* XDP_SETUP_XSK_POOL */\n\t\tstruct {\n\t\t\tstruct xsk_buff_pool *pool;\n\t\t\tu16 queue_id;\n\t\t} xsk;\n\t};\n};\n\n/* Flags for ndo_xsk_wakeup. */\n#define XDP_WAKEUP_RX (1 << 0)\n#define XDP_WAKEUP_TX (1 << 1)\n\n#ifdef CONFIG_XFRM_OFFLOAD\nstruct xfrmdev_ops {\n\tint\t(*xdo_dev_state_add) (struct xfrm_state *x);\n\tvoid\t(*xdo_dev_state_delete) (struct xfrm_state *x);\n\tvoid\t(*xdo_dev_state_free) (struct xfrm_state *x);\n\tbool\t(*xdo_dev_offload_ok) (struct sk_buff *skb,\n\t\t\t\t       struct xfrm_state *x);\n\tvoid\t(*xdo_dev_state_advance_esn) (struct xfrm_state *x);\n};\n#endif\n\nstruct dev_ifalias {\n\tstruct rcu_head rcuhead;\n\tchar ifalias[];\n};\n\nstruct devlink;\nstruct tlsdev_ops;\n\nstruct netdev_name_node {\n\tstruct hlist_node hlist;\n\tstruct list_head list;\n\tstruct net_device *dev;\n\tconst char *name;\n};\n\nint netdev_name_node_alt_create(struct net_device *dev, const char *name);\nint netdev_name_node_alt_destroy(struct net_device *dev, const char *name);\n\nstruct netdev_net_notifier {\n\tstruct list_head list;\n\tstruct notifier_block *nb;\n};\n\n/*\n * This structure defines the management hooks for network devices.\n * The following hooks can be defined; unless noted otherwise, they are\n * optional and can be filled with a null pointer.\n *\n * int (*ndo_init)(struct net_device *dev);\n *     This function is called once when a network device is registered.\n *     The network device can use this for any late stage initialization\n *     or semantic validation. It can fail with an error code which will\n *     be propagated back to register_netdev.\n *\n * void (*ndo_uninit)(struct net_device *dev);\n *     This function is called when device is unregistered or when registration\n *     fails. It is not called if init fails.\n *\n * int (*ndo_open)(struct net_device *dev);\n *     This function is called when a network device transitions to the up\n *     state.\n *\n * int (*ndo_stop)(struct net_device *dev);\n *     This function is called when a network device transitions to the down\n *     state.\n *\n * netdev_tx_t (*ndo_start_xmit)(struct sk_buff *skb,\n *                               struct net_device *dev);\n *\tCalled when a packet needs to be transmitted.\n *\tReturns NETDEV_TX_OK.  Can return NETDEV_TX_BUSY, but you should stop\n *\tthe queue before that can happen; it's for obsolete devices and weird\n *\tcorner cases, but the stack really does a non-trivial amount\n *\tof useless work if you return NETDEV_TX_BUSY.\n *\tRequired; cannot be NULL.\n *\n * netdev_features_t (*ndo_features_check)(struct sk_buff *skb,\n *\t\t\t\t\t   struct net_device *dev\n *\t\t\t\t\t   netdev_features_t features);\n *\tCalled by core transmit path to determine if device is capable of\n *\tperforming offload operations on a given packet. This is to give\n *\tthe device an opportunity to implement any restrictions that cannot\n *\tbe otherwise expressed by feature flags. The check is called with\n *\tthe set of features that the stack has calculated and it returns\n *\tthose the driver believes to be appropriate.\n *\n * u16 (*ndo_select_queue)(struct net_device *dev, struct sk_buff *skb,\n *                         struct net_device *sb_dev);\n *\tCalled to decide which queue to use when device supports multiple\n *\ttransmit queues.\n *\n * void (*ndo_change_rx_flags)(struct net_device *dev, int flags);\n *\tThis function is called to allow device receiver to make\n *\tchanges to configuration when multicast or promiscuous is enabled.\n *\n * void (*ndo_set_rx_mode)(struct net_device *dev);\n *\tThis function is called device changes address list filtering.\n *\tIf driver handles unicast address filtering, it should set\n *\tIFF_UNICAST_FLT in its priv_flags.\n *\n * int (*ndo_set_mac_address)(struct net_device *dev, void *addr);\n *\tThis function  is called when the Media Access Control address\n *\tneeds to be changed. If this interface is not defined, the\n *\tMAC address can not be changed.\n *\n * int (*ndo_validate_addr)(struct net_device *dev);\n *\tTest if Media Access Control address is valid for the device.\n *\n * int (*ndo_do_ioctl)(struct net_device *dev, struct ifreq *ifr, int cmd);\n *\tCalled when a user requests an ioctl which can't be handled by\n *\tthe generic interface code. If not defined ioctls return\n *\tnot supported error code.\n *\n * int (*ndo_set_config)(struct net_device *dev, struct ifmap *map);\n *\tUsed to set network devices bus interface parameters. This interface\n *\tis retained for legacy reasons; new devices should use the bus\n *\tinterface (PCI) for low level management.\n *\n * int (*ndo_change_mtu)(struct net_device *dev, int new_mtu);\n *\tCalled when a user wants to change the Maximum Transfer Unit\n *\tof a device.\n *\n * void (*ndo_tx_timeout)(struct net_device *dev, unsigned int txqueue);\n *\tCallback used when the transmitter has not made any progress\n *\tfor dev->watchdog ticks.\n *\n * void (*ndo_get_stats64)(struct net_device *dev,\n *                         struct rtnl_link_stats64 *storage);\n * struct net_device_stats* (*ndo_get_stats)(struct net_device *dev);\n *\tCalled when a user wants to get the network device usage\n *\tstatistics. Drivers must do one of the following:\n *\t1. Define @ndo_get_stats64 to fill in a zero-initialised\n *\t   rtnl_link_stats64 structure passed by the caller.\n *\t2. Define @ndo_get_stats to update a net_device_stats structure\n *\t   (which should normally be dev->stats) and return a pointer to\n *\t   it. The structure may be changed asynchronously only if each\n *\t   field is written atomically.\n *\t3. Update dev->stats asynchronously and atomically, and define\n *\t   neither operation.\n *\n * bool (*ndo_has_offload_stats)(const struct net_device *dev, int attr_id)\n *\tReturn true if this device supports offload stats of this attr_id.\n *\n * int (*ndo_get_offload_stats)(int attr_id, const struct net_device *dev,\n *\tvoid *attr_data)\n *\tGet statistics for offload operations by attr_id. Write it into the\n *\tattr_data pointer.\n *\n * int (*ndo_vlan_rx_add_vid)(struct net_device *dev, __be16 proto, u16 vid);\n *\tIf device supports VLAN filtering this function is called when a\n *\tVLAN id is registered.\n *\n * int (*ndo_vlan_rx_kill_vid)(struct net_device *dev, __be16 proto, u16 vid);\n *\tIf device supports VLAN filtering this function is called when a\n *\tVLAN id is unregistered.\n *\n * void (*ndo_poll_controller)(struct net_device *dev);\n *\n *\tSR-IOV management functions.\n * int (*ndo_set_vf_mac)(struct net_device *dev, int vf, u8* mac);\n * int (*ndo_set_vf_vlan)(struct net_device *dev, int vf, u16 vlan,\n *\t\t\t  u8 qos, __be16 proto);\n * int (*ndo_set_vf_rate)(struct net_device *dev, int vf, int min_tx_rate,\n *\t\t\t  int max_tx_rate);\n * int (*ndo_set_vf_spoofchk)(struct net_device *dev, int vf, bool setting);\n * int (*ndo_set_vf_trust)(struct net_device *dev, int vf, bool setting);\n * int (*ndo_get_vf_config)(struct net_device *dev,\n *\t\t\t    int vf, struct ifla_vf_info *ivf);\n * int (*ndo_set_vf_link_state)(struct net_device *dev, int vf, int link_state);\n * int (*ndo_set_vf_port)(struct net_device *dev, int vf,\n *\t\t\t  struct nlattr *port[]);\n *\n *      Enable or disable the VF ability to query its RSS Redirection Table and\n *      Hash Key. This is needed since on some devices VF share this information\n *      with PF and querying it may introduce a theoretical security risk.\n * int (*ndo_set_vf_rss_query_en)(struct net_device *dev, int vf, bool setting);\n * int (*ndo_get_vf_port)(struct net_device *dev, int vf, struct sk_buff *skb);\n * int (*ndo_setup_tc)(struct net_device *dev, enum tc_setup_type type,\n *\t\t       void *type_data);\n *\tCalled to setup any 'tc' scheduler, classifier or action on @dev.\n *\tThis is always called from the stack with the rtnl lock held and netif\n *\ttx queues stopped. This allows the netdevice to perform queue\n *\tmanagement safely.\n *\n *\tFiber Channel over Ethernet (FCoE) offload functions.\n * int (*ndo_fcoe_enable)(struct net_device *dev);\n *\tCalled when the FCoE protocol stack wants to start using LLD for FCoE\n *\tso the underlying device can perform whatever needed configuration or\n *\tinitialization to support acceleration of FCoE traffic.\n *\n * int (*ndo_fcoe_disable)(struct net_device *dev);\n *\tCalled when the FCoE protocol stack wants to stop using LLD for FCoE\n *\tso the underlying device can perform whatever needed clean-ups to\n *\tstop supporting acceleration of FCoE traffic.\n *\n * int (*ndo_fcoe_ddp_setup)(struct net_device *dev, u16 xid,\n *\t\t\t     struct scatterlist *sgl, unsigned int sgc);\n *\tCalled when the FCoE Initiator wants to initialize an I/O that\n *\tis a possible candidate for Direct Data Placement (DDP). The LLD can\n *\tperform necessary setup and returns 1 to indicate the device is set up\n *\tsuccessfully to perform DDP on this I/O, otherwise this returns 0.\n *\n * int (*ndo_fcoe_ddp_done)(struct net_device *dev,  u16 xid);\n *\tCalled when the FCoE Initiator/Target is done with the DDPed I/O as\n *\tindicated by the FC exchange id 'xid', so the underlying device can\n *\tclean up and reuse resources for later DDP requests.\n *\n * int (*ndo_fcoe_ddp_target)(struct net_device *dev, u16 xid,\n *\t\t\t      struct scatterlist *sgl, unsigned int sgc);\n *\tCalled when the FCoE Target wants to initialize an I/O that\n *\tis a possible candidate for Direct Data Placement (DDP). The LLD can\n *\tperform necessary setup and returns 1 to indicate the device is set up\n *\tsuccessfully to perform DDP on this I/O, otherwise this returns 0.\n *\n * int (*ndo_fcoe_get_hbainfo)(struct net_device *dev,\n *\t\t\t       struct netdev_fcoe_hbainfo *hbainfo);\n *\tCalled when the FCoE Protocol stack wants information on the underlying\n *\tdevice. This information is utilized by the FCoE protocol stack to\n *\tregister attributes with Fiber Channel management service as per the\n *\tFC-GS Fabric Device Management Information(FDMI) specification.\n *\n * int (*ndo_fcoe_get_wwn)(struct net_device *dev, u64 *wwn, int type);\n *\tCalled when the underlying device wants to override default World Wide\n *\tName (WWN) generation mechanism in FCoE protocol stack to pass its own\n *\tWorld Wide Port Name (WWPN) or World Wide Node Name (WWNN) to the FCoE\n *\tprotocol stack to use.\n *\n *\tRFS acceleration.\n * int (*ndo_rx_flow_steer)(struct net_device *dev, const struct sk_buff *skb,\n *\t\t\t    u16 rxq_index, u32 flow_id);\n *\tSet hardware filter for RFS.  rxq_index is the target queue index;\n *\tflow_id is a flow ID to be passed to rps_may_expire_flow() later.\n *\tReturn the filter ID on success, or a negative error code.\n *\n *\tSlave management functions (for bridge, bonding, etc).\n * int (*ndo_add_slave)(struct net_device *dev, struct net_device *slave_dev);\n *\tCalled to make another netdev an underling.\n *\n * int (*ndo_del_slave)(struct net_device *dev, struct net_device *slave_dev);\n *\tCalled to release previously enslaved netdev.\n *\n * struct net_device *(*ndo_get_xmit_slave)(struct net_device *dev,\n *\t\t\t\t\t    struct sk_buff *skb,\n *\t\t\t\t\t    bool all_slaves);\n *\tGet the xmit slave of master device. If all_slaves is true, function\n *\tassume all the slaves can transmit.\n *\n *      Feature/offload setting functions.\n * netdev_features_t (*ndo_fix_features)(struct net_device *dev,\n *\t\tnetdev_features_t features);\n *\tAdjusts the requested feature flags according to device-specific\n *\tconstraints, and returns the resulting flags. Must not modify\n *\tthe device state.\n *\n * int (*ndo_set_features)(struct net_device *dev, netdev_features_t features);\n *\tCalled to update device configuration to new features. Passed\n *\tfeature set might be less than what was returned by ndo_fix_features()).\n *\tMust return >0 or -errno if it changed dev->features itself.\n *\n * int (*ndo_fdb_add)(struct ndmsg *ndm, struct nlattr *tb[],\n *\t\t      struct net_device *dev,\n *\t\t      const unsigned char *addr, u16 vid, u16 flags,\n *\t\t      struct netlink_ext_ack *extack);\n *\tAdds an FDB entry to dev for addr.\n * int (*ndo_fdb_del)(struct ndmsg *ndm, struct nlattr *tb[],\n *\t\t      struct net_device *dev,\n *\t\t      const unsigned char *addr, u16 vid)\n *\tDeletes the FDB entry from dev coresponding to addr.\n * int (*ndo_fdb_dump)(struct sk_buff *skb, struct netlink_callback *cb,\n *\t\t       struct net_device *dev, struct net_device *filter_dev,\n *\t\t       int *idx)\n *\tUsed to add FDB entries to dump requests. Implementers should add\n *\tentries to skb and update idx with the number of entries.\n *\n * int (*ndo_bridge_setlink)(struct net_device *dev, struct nlmsghdr *nlh,\n *\t\t\t     u16 flags, struct netlink_ext_ack *extack)\n * int (*ndo_bridge_getlink)(struct sk_buff *skb, u32 pid, u32 seq,\n *\t\t\t     struct net_device *dev, u32 filter_mask,\n *\t\t\t     int nlflags)\n * int (*ndo_bridge_dellink)(struct net_device *dev, struct nlmsghdr *nlh,\n *\t\t\t     u16 flags);\n *\n * int (*ndo_change_carrier)(struct net_device *dev, bool new_carrier);\n *\tCalled to change device carrier. Soft-devices (like dummy, team, etc)\n *\twhich do not represent real hardware may define this to allow their\n *\tuserspace components to manage their virtual carrier state. Devices\n *\tthat determine carrier state from physical hardware properties (eg\n *\tnetwork cables) or protocol-dependent mechanisms (eg\n *\tUSB_CDC_NOTIFY_NETWORK_CONNECTION) should NOT implement this function.\n *\n * int (*ndo_get_phys_port_id)(struct net_device *dev,\n *\t\t\t       struct netdev_phys_item_id *ppid);\n *\tCalled to get ID of physical port of this device. If driver does\n *\tnot implement this, it is assumed that the hw is not able to have\n *\tmultiple net devices on single physical port.\n *\n * int (*ndo_get_port_parent_id)(struct net_device *dev,\n *\t\t\t\t struct netdev_phys_item_id *ppid)\n *\tCalled to get the parent ID of the physical port of this device.\n *\n * void* (*ndo_dfwd_add_station)(struct net_device *pdev,\n *\t\t\t\t struct net_device *dev)\n *\tCalled by upper layer devices to accelerate switching or other\n *\tstation functionality into hardware. 'pdev is the lowerdev\n *\tto use for the offload and 'dev' is the net device that will\n *\tback the offload. Returns a pointer to the private structure\n *\tthe upper layer will maintain.\n * void (*ndo_dfwd_del_station)(struct net_device *pdev, void *priv)\n *\tCalled by upper layer device to delete the station created\n *\tby 'ndo_dfwd_add_station'. 'pdev' is the net device backing\n *\tthe station and priv is the structure returned by the add\n *\toperation.\n * int (*ndo_set_tx_maxrate)(struct net_device *dev,\n *\t\t\t     int queue_index, u32 maxrate);\n *\tCalled when a user wants to set a max-rate limitation of specific\n *\tTX queue.\n * int (*ndo_get_iflink)(const struct net_device *dev);\n *\tCalled to get the iflink value of this device.\n * void (*ndo_change_proto_down)(struct net_device *dev,\n *\t\t\t\t bool proto_down);\n *\tThis function is used to pass protocol port error state information\n *\tto the switch driver. The switch driver can react to the proto_down\n *      by doing a phys down on the associated switch port.\n * int (*ndo_fill_metadata_dst)(struct net_device *dev, struct sk_buff *skb);\n *\tThis function is used to get egress tunnel information for given skb.\n *\tThis is useful for retrieving outer tunnel header parameters while\n *\tsampling packet.\n * void (*ndo_set_rx_headroom)(struct net_device *dev, int needed_headroom);\n *\tThis function is used to specify the headroom that the skb must\n *\tconsider when allocation skb during packet reception. Setting\n *\tappropriate rx headroom value allows avoiding skb head copy on\n *\tforward. Setting a negative value resets the rx headroom to the\n *\tdefault value.\n * int (*ndo_bpf)(struct net_device *dev, struct netdev_bpf *bpf);\n *\tThis function is used to set or query state related to XDP on the\n *\tnetdevice and manage BPF offload. See definition of\n *\tenum bpf_netdev_command for details.\n * int (*ndo_xdp_xmit)(struct net_device *dev, int n, struct xdp_frame **xdp,\n *\t\t\tu32 flags);\n *\tThis function is used to submit @n XDP packets for transmit on a\n *\tnetdevice. Returns number of frames successfully transmitted, frames\n *\tthat got dropped are freed/returned via xdp_return_frame().\n *\tReturns negative number, means general error invoking ndo, meaning\n *\tno frames were xmit'ed and core-caller will free all frames.\n * int (*ndo_xsk_wakeup)(struct net_device *dev, u32 queue_id, u32 flags);\n *      This function is used to wake up the softirq, ksoftirqd or kthread\n *\tresponsible for sending and/or receiving packets on a specific\n *\tqueue id bound to an AF_XDP socket. The flags field specifies if\n *\tonly RX, only Tx, or both should be woken up using the flags\n *\tXDP_WAKEUP_RX and XDP_WAKEUP_TX.\n * struct devlink_port *(*ndo_get_devlink_port)(struct net_device *dev);\n *\tGet devlink port instance associated with a given netdev.\n *\tCalled with a reference on the netdevice and devlink locks only,\n *\trtnl_lock is not held.\n * int (*ndo_tunnel_ctl)(struct net_device *dev, struct ip_tunnel_parm *p,\n *\t\t\t int cmd);\n *\tAdd, change, delete or get information on an IPv4 tunnel.\n * struct net_device *(*ndo_get_peer_dev)(struct net_device *dev);\n *\tIf a device is paired with a peer device, return the peer instance.\n *\tThe caller must be under RCU read context.\n */\nstruct net_device_ops {\n\tint\t\t\t(*ndo_init)(struct net_device *dev);\n\tvoid\t\t\t(*ndo_uninit)(struct net_device *dev);\n\tint\t\t\t(*ndo_open)(struct net_device *dev);\n\tint\t\t\t(*ndo_stop)(struct net_device *dev);\n\tnetdev_tx_t\t\t(*ndo_start_xmit)(struct sk_buff *skb,\n\t\t\t\t\t\t  struct net_device *dev);\n\tnetdev_features_t\t(*ndo_features_check)(struct sk_buff *skb,\n\t\t\t\t\t\t      struct net_device *dev,\n\t\t\t\t\t\t      netdev_features_t features);\n\tu16\t\t\t(*ndo_select_queue)(struct net_device *dev,\n\t\t\t\t\t\t    struct sk_buff *skb,\n\t\t\t\t\t\t    struct net_device *sb_dev);\n\tvoid\t\t\t(*ndo_change_rx_flags)(struct net_device *dev,\n\t\t\t\t\t\t       int flags);\n\tvoid\t\t\t(*ndo_set_rx_mode)(struct net_device *dev);\n\tint\t\t\t(*ndo_set_mac_address)(struct net_device *dev,\n\t\t\t\t\t\t       void *addr);\n\tint\t\t\t(*ndo_validate_addr)(struct net_device *dev);\n\tint\t\t\t(*ndo_do_ioctl)(struct net_device *dev,\n\t\t\t\t\t        struct ifreq *ifr, int cmd);\n\tint\t\t\t(*ndo_set_config)(struct net_device *dev,\n\t\t\t\t\t          struct ifmap *map);\n\tint\t\t\t(*ndo_change_mtu)(struct net_device *dev,\n\t\t\t\t\t\t  int new_mtu);\n\tint\t\t\t(*ndo_neigh_setup)(struct net_device *dev,\n\t\t\t\t\t\t   struct neigh_parms *);\n\tvoid\t\t\t(*ndo_tx_timeout) (struct net_device *dev,\n\t\t\t\t\t\t   unsigned int txqueue);\n\n\tvoid\t\t\t(*ndo_get_stats64)(struct net_device *dev,\n\t\t\t\t\t\t   struct rtnl_link_stats64 *storage);\n\tbool\t\t\t(*ndo_has_offload_stats)(const struct net_device *dev, int attr_id);\n\tint\t\t\t(*ndo_get_offload_stats)(int attr_id,\n\t\t\t\t\t\t\t const struct net_device *dev,\n\t\t\t\t\t\t\t void *attr_data);\n\tstruct net_device_stats* (*ndo_get_stats)(struct net_device *dev);\n\n\tint\t\t\t(*ndo_vlan_rx_add_vid)(struct net_device *dev,\n\t\t\t\t\t\t       __be16 proto, u16 vid);\n\tint\t\t\t(*ndo_vlan_rx_kill_vid)(struct net_device *dev,\n\t\t\t\t\t\t        __be16 proto, u16 vid);\n#ifdef CONFIG_NET_POLL_CONTROLLER\n\tvoid                    (*ndo_poll_controller)(struct net_device *dev);\n\tint\t\t\t(*ndo_netpoll_setup)(struct net_device *dev,\n\t\t\t\t\t\t     struct netpoll_info *info);\n\tvoid\t\t\t(*ndo_netpoll_cleanup)(struct net_device *dev);\n#endif\n\tint\t\t\t(*ndo_set_vf_mac)(struct net_device *dev,\n\t\t\t\t\t\t  int queue, u8 *mac);\n\tint\t\t\t(*ndo_set_vf_vlan)(struct net_device *dev,\n\t\t\t\t\t\t   int queue, u16 vlan,\n\t\t\t\t\t\t   u8 qos, __be16 proto);\n\tint\t\t\t(*ndo_set_vf_rate)(struct net_device *dev,\n\t\t\t\t\t\t   int vf, int min_tx_rate,\n\t\t\t\t\t\t   int max_tx_rate);\n\tint\t\t\t(*ndo_set_vf_spoofchk)(struct net_device *dev,\n\t\t\t\t\t\t       int vf, bool setting);\n\tint\t\t\t(*ndo_set_vf_trust)(struct net_device *dev,\n\t\t\t\t\t\t    int vf, bool setting);\n\tint\t\t\t(*ndo_get_vf_config)(struct net_device *dev,\n\t\t\t\t\t\t     int vf,\n\t\t\t\t\t\t     struct ifla_vf_info *ivf);\n\tint\t\t\t(*ndo_set_vf_link_state)(struct net_device *dev,\n\t\t\t\t\t\t\t int vf, int link_state);\n\tint\t\t\t(*ndo_get_vf_stats)(struct net_device *dev,\n\t\t\t\t\t\t    int vf,\n\t\t\t\t\t\t    struct ifla_vf_stats\n\t\t\t\t\t\t    *vf_stats);\n\tint\t\t\t(*ndo_set_vf_port)(struct net_device *dev,\n\t\t\t\t\t\t   int vf,\n\t\t\t\t\t\t   struct nlattr *port[]);\n\tint\t\t\t(*ndo_get_vf_port)(struct net_device *dev,\n\t\t\t\t\t\t   int vf, struct sk_buff *skb);\n\tint\t\t\t(*ndo_get_vf_guid)(struct net_device *dev,\n\t\t\t\t\t\t   int vf,\n\t\t\t\t\t\t   struct ifla_vf_guid *node_guid,\n\t\t\t\t\t\t   struct ifla_vf_guid *port_guid);\n\tint\t\t\t(*ndo_set_vf_guid)(struct net_device *dev,\n\t\t\t\t\t\t   int vf, u64 guid,\n\t\t\t\t\t\t   int guid_type);\n\tint\t\t\t(*ndo_set_vf_rss_query_en)(\n\t\t\t\t\t\t   struct net_device *dev,\n\t\t\t\t\t\t   int vf, bool setting);\n\tint\t\t\t(*ndo_setup_tc)(struct net_device *dev,\n\t\t\t\t\t\tenum tc_setup_type type,\n\t\t\t\t\t\tvoid *type_data);\n#if IS_ENABLED(CONFIG_FCOE)\n\tint\t\t\t(*ndo_fcoe_enable)(struct net_device *dev);\n\tint\t\t\t(*ndo_fcoe_disable)(struct net_device *dev);\n\tint\t\t\t(*ndo_fcoe_ddp_setup)(struct net_device *dev,\n\t\t\t\t\t\t      u16 xid,\n\t\t\t\t\t\t      struct scatterlist *sgl,\n\t\t\t\t\t\t      unsigned int sgc);\n\tint\t\t\t(*ndo_fcoe_ddp_done)(struct net_device *dev,\n\t\t\t\t\t\t     u16 xid);\n\tint\t\t\t(*ndo_fcoe_ddp_target)(struct net_device *dev,\n\t\t\t\t\t\t       u16 xid,\n\t\t\t\t\t\t       struct scatterlist *sgl,\n\t\t\t\t\t\t       unsigned int sgc);\n\tint\t\t\t(*ndo_fcoe_get_hbainfo)(struct net_device *dev,\n\t\t\t\t\t\t\tstruct netdev_fcoe_hbainfo *hbainfo);\n#endif\n\n#if IS_ENABLED(CONFIG_LIBFCOE)\n#define NETDEV_FCOE_WWNN 0\n#define NETDEV_FCOE_WWPN 1\n\tint\t\t\t(*ndo_fcoe_get_wwn)(struct net_device *dev,\n\t\t\t\t\t\t    u64 *wwn, int type);\n#endif\n\n#ifdef CONFIG_RFS_ACCEL\n\tint\t\t\t(*ndo_rx_flow_steer)(struct net_device *dev,\n\t\t\t\t\t\t     const struct sk_buff *skb,\n\t\t\t\t\t\t     u16 rxq_index,\n\t\t\t\t\t\t     u32 flow_id);\n#endif\n\tint\t\t\t(*ndo_add_slave)(struct net_device *dev,\n\t\t\t\t\t\t struct net_device *slave_dev,\n\t\t\t\t\t\t struct netlink_ext_ack *extack);\n\tint\t\t\t(*ndo_del_slave)(struct net_device *dev,\n\t\t\t\t\t\t struct net_device *slave_dev);\n\tstruct net_device*\t(*ndo_get_xmit_slave)(struct net_device *dev,\n\t\t\t\t\t\t      struct sk_buff *skb,\n\t\t\t\t\t\t      bool all_slaves);\n\tstruct net_device*\t(*ndo_sk_get_lower_dev)(struct net_device *dev,\n\t\t\t\t\t\t\tstruct sock *sk);\n\tnetdev_features_t\t(*ndo_fix_features)(struct net_device *dev,\n\t\t\t\t\t\t    netdev_features_t features);\n\tint\t\t\t(*ndo_set_features)(struct net_device *dev,\n\t\t\t\t\t\t    netdev_features_t features);\n\tint\t\t\t(*ndo_neigh_construct)(struct net_device *dev,\n\t\t\t\t\t\t       struct neighbour *n);\n\tvoid\t\t\t(*ndo_neigh_destroy)(struct net_device *dev,\n\t\t\t\t\t\t     struct neighbour *n);\n\n\tint\t\t\t(*ndo_fdb_add)(struct ndmsg *ndm,\n\t\t\t\t\t       struct nlattr *tb[],\n\t\t\t\t\t       struct net_device *dev,\n\t\t\t\t\t       const unsigned char *addr,\n\t\t\t\t\t       u16 vid,\n\t\t\t\t\t       u16 flags,\n\t\t\t\t\t       struct netlink_ext_ack *extack);\n\tint\t\t\t(*ndo_fdb_del)(struct ndmsg *ndm,\n\t\t\t\t\t       struct nlattr *tb[],\n\t\t\t\t\t       struct net_device *dev,\n\t\t\t\t\t       const unsigned char *addr,\n\t\t\t\t\t       u16 vid);\n\tint\t\t\t(*ndo_fdb_dump)(struct sk_buff *skb,\n\t\t\t\t\t\tstruct netlink_callback *cb,\n\t\t\t\t\t\tstruct net_device *dev,\n\t\t\t\t\t\tstruct net_device *filter_dev,\n\t\t\t\t\t\tint *idx);\n\tint\t\t\t(*ndo_fdb_get)(struct sk_buff *skb,\n\t\t\t\t\t       struct nlattr *tb[],\n\t\t\t\t\t       struct net_device *dev,\n\t\t\t\t\t       const unsigned char *addr,\n\t\t\t\t\t       u16 vid, u32 portid, u32 seq,\n\t\t\t\t\t       struct netlink_ext_ack *extack);\n\tint\t\t\t(*ndo_bridge_setlink)(struct net_device *dev,\n\t\t\t\t\t\t      struct nlmsghdr *nlh,\n\t\t\t\t\t\t      u16 flags,\n\t\t\t\t\t\t      struct netlink_ext_ack *extack);\n\tint\t\t\t(*ndo_bridge_getlink)(struct sk_buff *skb,\n\t\t\t\t\t\t      u32 pid, u32 seq,\n\t\t\t\t\t\t      struct net_device *dev,\n\t\t\t\t\t\t      u32 filter_mask,\n\t\t\t\t\t\t      int nlflags);\n\tint\t\t\t(*ndo_bridge_dellink)(struct net_device *dev,\n\t\t\t\t\t\t      struct nlmsghdr *nlh,\n\t\t\t\t\t\t      u16 flags);\n\tint\t\t\t(*ndo_change_carrier)(struct net_device *dev,\n\t\t\t\t\t\t      bool new_carrier);\n\tint\t\t\t(*ndo_get_phys_port_id)(struct net_device *dev,\n\t\t\t\t\t\t\tstruct netdev_phys_item_id *ppid);\n\tint\t\t\t(*ndo_get_port_parent_id)(struct net_device *dev,\n\t\t\t\t\t\t\t  struct netdev_phys_item_id *ppid);\n\tint\t\t\t(*ndo_get_phys_port_name)(struct net_device *dev,\n\t\t\t\t\t\t\t  char *name, size_t len);\n\tvoid*\t\t\t(*ndo_dfwd_add_station)(struct net_device *pdev,\n\t\t\t\t\t\t\tstruct net_device *dev);\n\tvoid\t\t\t(*ndo_dfwd_del_station)(struct net_device *pdev,\n\t\t\t\t\t\t\tvoid *priv);\n\n\tint\t\t\t(*ndo_set_tx_maxrate)(struct net_device *dev,\n\t\t\t\t\t\t      int queue_index,\n\t\t\t\t\t\t      u32 maxrate);\n\tint\t\t\t(*ndo_get_iflink)(const struct net_device *dev);\n\tint\t\t\t(*ndo_change_proto_down)(struct net_device *dev,\n\t\t\t\t\t\t\t bool proto_down);\n\tint\t\t\t(*ndo_fill_metadata_dst)(struct net_device *dev,\n\t\t\t\t\t\t       struct sk_buff *skb);\n\tvoid\t\t\t(*ndo_set_rx_headroom)(struct net_device *dev,\n\t\t\t\t\t\t       int needed_headroom);\n\tint\t\t\t(*ndo_bpf)(struct net_device *dev,\n\t\t\t\t\t   struct netdev_bpf *bpf);\n\tint\t\t\t(*ndo_xdp_xmit)(struct net_device *dev, int n,\n\t\t\t\t\t\tstruct xdp_frame **xdp,\n\t\t\t\t\t\tu32 flags);\n\tint\t\t\t(*ndo_xsk_wakeup)(struct net_device *dev,\n\t\t\t\t\t\t  u32 queue_id, u32 flags);\n\tstruct devlink_port *\t(*ndo_get_devlink_port)(struct net_device *dev);\n\tint\t\t\t(*ndo_tunnel_ctl)(struct net_device *dev,\n\t\t\t\t\t\t  struct ip_tunnel_parm *p, int cmd);\n\tstruct net_device *\t(*ndo_get_peer_dev)(struct net_device *dev);\n};\n\n/**\n * enum netdev_priv_flags - &struct net_device priv_flags\n *\n * These are the &struct net_device, they are only set internally\n * by drivers and used in the kernel. These flags are invisible to\n * userspace; this means that the order of these flags can change\n * during any kernel release.\n *\n * You should have a pretty good reason to be extending these flags.\n *\n * @IFF_802_1Q_VLAN: 802.1Q VLAN device\n * @IFF_EBRIDGE: Ethernet bridging device\n * @IFF_BONDING: bonding master or slave\n * @IFF_ISATAP: ISATAP interface (RFC4214)\n * @IFF_WAN_HDLC: WAN HDLC device\n * @IFF_XMIT_DST_RELEASE: dev_hard_start_xmit() is allowed to\n *\trelease skb->dst\n * @IFF_DONT_BRIDGE: disallow bridging this ether dev\n * @IFF_DISABLE_NETPOLL: disable netpoll at run-time\n * @IFF_MACVLAN_PORT: device used as macvlan port\n * @IFF_BRIDGE_PORT: device used as bridge port\n * @IFF_OVS_DATAPATH: device used as Open vSwitch datapath port\n * @IFF_TX_SKB_SHARING: The interface supports sharing skbs on transmit\n * @IFF_UNICAST_FLT: Supports unicast filtering\n * @IFF_TEAM_PORT: device used as team port\n * @IFF_SUPP_NOFCS: device supports sending custom FCS\n * @IFF_LIVE_ADDR_CHANGE: device supports hardware address\n *\tchange when it's running\n * @IFF_MACVLAN: Macvlan device\n * @IFF_XMIT_DST_RELEASE_PERM: IFF_XMIT_DST_RELEASE not taking into account\n *\tunderlying stacked devices\n * @IFF_L3MDEV_MASTER: device is an L3 master device\n * @IFF_NO_QUEUE: device can run without qdisc attached\n * @IFF_OPENVSWITCH: device is a Open vSwitch master\n * @IFF_L3MDEV_SLAVE: device is enslaved to an L3 master device\n * @IFF_TEAM: device is a team device\n * @IFF_RXFH_CONFIGURED: device has had Rx Flow indirection table configured\n * @IFF_PHONY_HEADROOM: the headroom value is controlled by an external\n *\tentity (i.e. the master device for bridged veth)\n * @IFF_MACSEC: device is a MACsec device\n * @IFF_NO_RX_HANDLER: device doesn't support the rx_handler hook\n * @IFF_FAILOVER: device is a failover master device\n * @IFF_FAILOVER_SLAVE: device is lower dev of a failover master device\n * @IFF_L3MDEV_RX_HANDLER: only invoke the rx handler of L3 master device\n * @IFF_LIVE_RENAME_OK: rename is allowed while device is up and running\n * @IFF_TX_SKB_NO_LINEAR: device/driver is capable of xmitting frames with\n *\tskb_headlen(skb) == 0 (data starts from frag0)\n */\nenum netdev_priv_flags {\n\tIFF_802_1Q_VLAN\t\t\t= 1<<0,\n\tIFF_EBRIDGE\t\t\t= 1<<1,\n\tIFF_BONDING\t\t\t= 1<<2,\n\tIFF_ISATAP\t\t\t= 1<<3,\n\tIFF_WAN_HDLC\t\t\t= 1<<4,\n\tIFF_XMIT_DST_RELEASE\t\t= 1<<5,\n\tIFF_DONT_BRIDGE\t\t\t= 1<<6,\n\tIFF_DISABLE_NETPOLL\t\t= 1<<7,\n\tIFF_MACVLAN_PORT\t\t= 1<<8,\n\tIFF_BRIDGE_PORT\t\t\t= 1<<9,\n\tIFF_OVS_DATAPATH\t\t= 1<<10,\n\tIFF_TX_SKB_SHARING\t\t= 1<<11,\n\tIFF_UNICAST_FLT\t\t\t= 1<<12,\n\tIFF_TEAM_PORT\t\t\t= 1<<13,\n\tIFF_SUPP_NOFCS\t\t\t= 1<<14,\n\tIFF_LIVE_ADDR_CHANGE\t\t= 1<<15,\n\tIFF_MACVLAN\t\t\t= 1<<16,\n\tIFF_XMIT_DST_RELEASE_PERM\t= 1<<17,\n\tIFF_L3MDEV_MASTER\t\t= 1<<18,\n\tIFF_NO_QUEUE\t\t\t= 1<<19,\n\tIFF_OPENVSWITCH\t\t\t= 1<<20,\n\tIFF_L3MDEV_SLAVE\t\t= 1<<21,\n\tIFF_TEAM\t\t\t= 1<<22,\n\tIFF_RXFH_CONFIGURED\t\t= 1<<23,\n\tIFF_PHONY_HEADROOM\t\t= 1<<24,\n\tIFF_MACSEC\t\t\t= 1<<25,\n\tIFF_NO_RX_HANDLER\t\t= 1<<26,\n\tIFF_FAILOVER\t\t\t= 1<<27,\n\tIFF_FAILOVER_SLAVE\t\t= 1<<28,\n\tIFF_L3MDEV_RX_HANDLER\t\t= 1<<29,\n\tIFF_LIVE_RENAME_OK\t\t= 1<<30,\n\tIFF_TX_SKB_NO_LINEAR\t\t= 1<<31,\n};\n\n#define IFF_802_1Q_VLAN\t\t\tIFF_802_1Q_VLAN\n#define IFF_EBRIDGE\t\t\tIFF_EBRIDGE\n#define IFF_BONDING\t\t\tIFF_BONDING\n#define IFF_ISATAP\t\t\tIFF_ISATAP\n#define IFF_WAN_HDLC\t\t\tIFF_WAN_HDLC\n#define IFF_XMIT_DST_RELEASE\t\tIFF_XMIT_DST_RELEASE\n#define IFF_DONT_BRIDGE\t\t\tIFF_DONT_BRIDGE\n#define IFF_DISABLE_NETPOLL\t\tIFF_DISABLE_NETPOLL\n#define IFF_MACVLAN_PORT\t\tIFF_MACVLAN_PORT\n#define IFF_BRIDGE_PORT\t\t\tIFF_BRIDGE_PORT\n#define IFF_OVS_DATAPATH\t\tIFF_OVS_DATAPATH\n#define IFF_TX_SKB_SHARING\t\tIFF_TX_SKB_SHARING\n#define IFF_UNICAST_FLT\t\t\tIFF_UNICAST_FLT\n#define IFF_TEAM_PORT\t\t\tIFF_TEAM_PORT\n#define IFF_SUPP_NOFCS\t\t\tIFF_SUPP_NOFCS\n#define IFF_LIVE_ADDR_CHANGE\t\tIFF_LIVE_ADDR_CHANGE\n#define IFF_MACVLAN\t\t\tIFF_MACVLAN\n#define IFF_XMIT_DST_RELEASE_PERM\tIFF_XMIT_DST_RELEASE_PERM\n#define IFF_L3MDEV_MASTER\t\tIFF_L3MDEV_MASTER\n#define IFF_NO_QUEUE\t\t\tIFF_NO_QUEUE\n#define IFF_OPENVSWITCH\t\t\tIFF_OPENVSWITCH\n#define IFF_L3MDEV_SLAVE\t\tIFF_L3MDEV_SLAVE\n#define IFF_TEAM\t\t\tIFF_TEAM\n#define IFF_RXFH_CONFIGURED\t\tIFF_RXFH_CONFIGURED\n#define IFF_PHONY_HEADROOM\t\tIFF_PHONY_HEADROOM\n#define IFF_MACSEC\t\t\tIFF_MACSEC\n#define IFF_NO_RX_HANDLER\t\tIFF_NO_RX_HANDLER\n#define IFF_FAILOVER\t\t\tIFF_FAILOVER\n#define IFF_FAILOVER_SLAVE\t\tIFF_FAILOVER_SLAVE\n#define IFF_L3MDEV_RX_HANDLER\t\tIFF_L3MDEV_RX_HANDLER\n#define IFF_LIVE_RENAME_OK\t\tIFF_LIVE_RENAME_OK\n#define IFF_TX_SKB_NO_LINEAR\t\tIFF_TX_SKB_NO_LINEAR\n\n/* Specifies the type of the struct net_device::ml_priv pointer */\nenum netdev_ml_priv_type {\n\tML_PRIV_NONE,\n\tML_PRIV_CAN,\n};\n\n/**\n *\tstruct net_device - The DEVICE structure.\n *\n *\tActually, this whole structure is a big mistake.  It mixes I/O\n *\tdata with strictly \"high-level\" data, and it has to know about\n *\talmost every data structure used in the INET module.\n *\n *\t@name:\tThis is the first field of the \"visible\" part of this structure\n *\t\t(i.e. as seen by users in the \"Space.c\" file).  It is the name\n *\t\tof the interface.\n *\n *\t@name_node:\tName hashlist node\n *\t@ifalias:\tSNMP alias\n *\t@mem_end:\tShared memory end\n *\t@mem_start:\tShared memory start\n *\t@base_addr:\tDevice I/O address\n *\t@irq:\t\tDevice IRQ number\n *\n *\t@state:\t\tGeneric network queuing layer state, see netdev_state_t\n *\t@dev_list:\tThe global list of network devices\n *\t@napi_list:\tList entry used for polling NAPI devices\n *\t@unreg_list:\tList entry  when we are unregistering the\n *\t\t\tdevice; see the function unregister_netdev\n *\t@close_list:\tList entry used when we are closing the device\n *\t@ptype_all:     Device-specific packet handlers for all protocols\n *\t@ptype_specific: Device-specific, protocol-specific packet handlers\n *\n *\t@adj_list:\tDirectly linked devices, like slaves for bonding\n *\t@features:\tCurrently active device features\n *\t@hw_features:\tUser-changeable features\n *\n *\t@wanted_features:\tUser-requested features\n *\t@vlan_features:\t\tMask of features inheritable by VLAN devices\n *\n *\t@hw_enc_features:\tMask of features inherited by encapsulating devices\n *\t\t\t\tThis field indicates what encapsulation\n *\t\t\t\toffloads the hardware is capable of doing,\n *\t\t\t\tand drivers will need to set them appropriately.\n *\n *\t@mpls_features:\tMask of features inheritable by MPLS\n *\t@gso_partial_features: value(s) from NETIF_F_GSO\\*\n *\n *\t@ifindex:\tinterface index\n *\t@group:\t\tThe group the device belongs to\n *\n *\t@stats:\t\tStatistics struct, which was left as a legacy, use\n *\t\t\trtnl_link_stats64 instead\n *\n *\t@rx_dropped:\tDropped packets by core network,\n *\t\t\tdo not use this in drivers\n *\t@tx_dropped:\tDropped packets by core network,\n *\t\t\tdo not use this in drivers\n *\t@rx_nohandler:\tnohandler dropped packets by core network on\n *\t\t\tinactive devices, do not use this in drivers\n *\t@carrier_up_count:\tNumber of times the carrier has been up\n *\t@carrier_down_count:\tNumber of times the carrier has been down\n *\n *\t@wireless_handlers:\tList of functions to handle Wireless Extensions,\n *\t\t\t\tinstead of ioctl,\n *\t\t\t\tsee <net/iw_handler.h> for details.\n *\t@wireless_data:\tInstance data managed by the core of wireless extensions\n *\n *\t@netdev_ops:\tIncludes several pointers to callbacks,\n *\t\t\tif one wants to override the ndo_*() functions\n *\t@ethtool_ops:\tManagement operations\n *\t@l3mdev_ops:\tLayer 3 master device operations\n *\t@ndisc_ops:\tIncludes callbacks for different IPv6 neighbour\n *\t\t\tdiscovery handling. Necessary for e.g. 6LoWPAN.\n *\t@xfrmdev_ops:\tTransformation offload operations\n *\t@tlsdev_ops:\tTransport Layer Security offload operations\n *\t@header_ops:\tIncludes callbacks for creating,parsing,caching,etc\n *\t\t\tof Layer 2 headers.\n *\n *\t@flags:\t\tInterface flags (a la BSD)\n *\t@priv_flags:\tLike 'flags' but invisible to userspace,\n *\t\t\tsee if.h for the definitions\n *\t@gflags:\tGlobal flags ( kept as legacy )\n *\t@padded:\tHow much padding added by alloc_netdev()\n *\t@operstate:\tRFC2863 operstate\n *\t@link_mode:\tMapping policy to operstate\n *\t@if_port:\tSelectable AUI, TP, ...\n *\t@dma:\t\tDMA channel\n *\t@mtu:\t\tInterface MTU value\n *\t@min_mtu:\tInterface Minimum MTU value\n *\t@max_mtu:\tInterface Maximum MTU value\n *\t@type:\t\tInterface hardware type\n *\t@hard_header_len: Maximum hardware header length.\n *\t@min_header_len:  Minimum hardware header length\n *\n *\t@needed_headroom: Extra headroom the hardware may need, but not in all\n *\t\t\t  cases can this be guaranteed\n *\t@needed_tailroom: Extra tailroom the hardware may need, but not in all\n *\t\t\t  cases can this be guaranteed. Some cases also use\n *\t\t\t  LL_MAX_HEADER instead to allocate the skb\n *\n *\tinterface address info:\n *\n * \t@perm_addr:\t\tPermanent hw address\n * \t@addr_assign_type:\tHw address assignment type\n * \t@addr_len:\t\tHardware address length\n *\t@upper_level:\t\tMaximum depth level of upper devices.\n *\t@lower_level:\t\tMaximum depth level of lower devices.\n *\t@neigh_priv_len:\tUsed in neigh_alloc()\n * \t@dev_id:\t\tUsed to differentiate devices that share\n * \t\t\t\tthe same link layer address\n * \t@dev_port:\t\tUsed to differentiate devices that share\n * \t\t\t\tthe same function\n *\t@addr_list_lock:\tXXX: need comments on this one\n *\t@name_assign_type:\tnetwork interface name assignment type\n *\t@uc_promisc:\t\tCounter that indicates promiscuous mode\n *\t\t\t\thas been enabled due to the need to listen to\n *\t\t\t\tadditional unicast addresses in a device that\n *\t\t\t\tdoes not implement ndo_set_rx_mode()\n *\t@uc:\t\t\tunicast mac addresses\n *\t@mc:\t\t\tmulticast mac addresses\n *\t@dev_addrs:\t\tlist of device hw addresses\n *\t@queues_kset:\t\tGroup of all Kobjects in the Tx and RX queues\n *\t@promiscuity:\t\tNumber of times the NIC is told to work in\n *\t\t\t\tpromiscuous mode; if it becomes 0 the NIC will\n *\t\t\t\texit promiscuous mode\n *\t@allmulti:\t\tCounter, enables or disables allmulticast mode\n *\n *\t@vlan_info:\tVLAN info\n *\t@dsa_ptr:\tdsa specific data\n *\t@tipc_ptr:\tTIPC specific data\n *\t@atalk_ptr:\tAppleTalk link\n *\t@ip_ptr:\tIPv4 specific data\n *\t@dn_ptr:\tDECnet specific data\n *\t@ip6_ptr:\tIPv6 specific data\n *\t@ax25_ptr:\tAX.25 specific data\n *\t@ieee80211_ptr:\tIEEE 802.11 specific data, assign before registering\n *\t@ieee802154_ptr: IEEE 802.15.4 low-rate Wireless Personal Area Network\n *\t\t\t device struct\n *\t@mpls_ptr:\tmpls_dev struct pointer\n *\n *\t@dev_addr:\tHw address (before bcast,\n *\t\t\tbecause most packets are unicast)\n *\n *\t@_rx:\t\t\tArray of RX queues\n *\t@num_rx_queues:\t\tNumber of RX queues\n *\t\t\t\tallocated at register_netdev() time\n *\t@real_num_rx_queues: \tNumber of RX queues currently active in device\n *\t@xdp_prog:\t\tXDP sockets filter program pointer\n *\t@gro_flush_timeout:\ttimeout for GRO layer in NAPI\n *\t@napi_defer_hard_irqs:\tIf not zero, provides a counter that would\n *\t\t\t\tallow to avoid NIC hard IRQ, on busy queues.\n *\n *\t@rx_handler:\t\thandler for received packets\n *\t@rx_handler_data: \tXXX: need comments on this one\n *\t@miniq_ingress:\t\tingress/clsact qdisc specific data for\n *\t\t\t\tingress processing\n *\t@ingress_queue:\t\tXXX: need comments on this one\n *\t@nf_hooks_ingress:\tnetfilter hooks executed for ingress packets\n *\t@broadcast:\t\thw bcast address\n *\n *\t@rx_cpu_rmap:\tCPU reverse-mapping for RX completion interrupts,\n *\t\t\tindexed by RX queue number. Assigned by driver.\n *\t\t\tThis must only be set if the ndo_rx_flow_steer\n *\t\t\toperation is defined\n *\t@index_hlist:\t\tDevice index hash chain\n *\n *\t@_tx:\t\t\tArray of TX queues\n *\t@num_tx_queues:\t\tNumber of TX queues allocated at alloc_netdev_mq() time\n *\t@real_num_tx_queues: \tNumber of TX queues currently active in device\n *\t@qdisc:\t\t\tRoot qdisc from userspace point of view\n *\t@tx_queue_len:\t\tMax frames per queue allowed\n *\t@tx_global_lock: \tXXX: need comments on this one\n *\t@xdp_bulkq:\t\tXDP device bulk queue\n *\t@xps_cpus_map:\t\tall CPUs map for XPS device\n *\t@xps_rxqs_map:\t\tall RXQs map for XPS device\n *\n *\t@xps_maps:\tXXX: need comments on this one\n *\t@miniq_egress:\t\tclsact qdisc specific data for\n *\t\t\t\tegress processing\n *\t@qdisc_hash:\t\tqdisc hash table\n *\t@watchdog_timeo:\tRepresents the timeout that is used by\n *\t\t\t\tthe watchdog (see dev_watchdog())\n *\t@watchdog_timer:\tList of timers\n *\n *\t@proto_down_reason:\treason a netdev interface is held down\n *\t@pcpu_refcnt:\t\tNumber of references to this device\n *\t@todo_list:\t\tDelayed register/unregister\n *\t@link_watch_list:\tXXX: need comments on this one\n *\n *\t@reg_state:\t\tRegister/unregister state machine\n *\t@dismantle:\t\tDevice is going to be freed\n *\t@rtnl_link_state:\tThis enum represents the phases of creating\n *\t\t\t\ta new link\n *\n *\t@needs_free_netdev:\tShould unregister perform free_netdev?\n *\t@priv_destructor:\tCalled from unregister\n *\t@npinfo:\t\tXXX: need comments on this one\n * \t@nd_net:\t\tNetwork namespace this network device is inside\n *\n * \t@ml_priv:\tMid-layer private\n *\t@ml_priv_type:  Mid-layer private type\n * \t@lstats:\tLoopback statistics\n * \t@tstats:\tTunnel statistics\n * \t@dstats:\tDummy statistics\n * \t@vstats:\tVirtual ethernet statistics\n *\n *\t@garp_port:\tGARP\n *\t@mrp_port:\tMRP\n *\n *\t@dev:\t\tClass/net/name entry\n *\t@sysfs_groups:\tSpace for optional device, statistics and wireless\n *\t\t\tsysfs groups\n *\n *\t@sysfs_rx_queue_group:\tSpace for optional per-rx queue attributes\n *\t@rtnl_link_ops:\tRtnl_link_ops\n *\n *\t@gso_max_size:\tMaximum size of generic segmentation offload\n *\t@gso_max_segs:\tMaximum number of segments that can be passed to the\n *\t\t\tNIC for GSO\n *\n *\t@dcbnl_ops:\tData Center Bridging netlink ops\n *\t@num_tc:\tNumber of traffic classes in the net device\n *\t@tc_to_txq:\tXXX: need comments on this one\n *\t@prio_tc_map:\tXXX: need comments on this one\n *\n *\t@fcoe_ddp_xid:\tMax exchange id for FCoE LRO by ddp\n *\n *\t@priomap:\tXXX: need comments on this one\n *\t@phydev:\tPhysical device may attach itself\n *\t\t\tfor hardware timestamping\n *\t@sfp_bus:\tattached &struct sfp_bus structure.\n *\n *\t@qdisc_tx_busylock: lockdep class annotating Qdisc->busylock spinlock\n *\t@qdisc_running_key: lockdep class annotating Qdisc->running seqcount\n *\n *\t@proto_down:\tprotocol port state information can be sent to the\n *\t\t\tswitch driver and used to set the phys state of the\n *\t\t\tswitch port.\n *\n *\t@wol_enabled:\tWake-on-LAN is enabled\n *\n *\t@threaded:\tnapi threaded mode is enabled\n *\n *\t@net_notifier_list:\tList of per-net netdev notifier block\n *\t\t\t\tthat follow this device when it is moved\n *\t\t\t\tto another network namespace.\n *\n *\t@macsec_ops:    MACsec offloading ops\n *\n *\t@udp_tunnel_nic_info:\tstatic structure describing the UDP tunnel\n *\t\t\t\toffload capabilities of the device\n *\t@udp_tunnel_nic:\tUDP tunnel offload state\n *\t@xdp_state:\t\tstores info on attached XDP BPF programs\n *\n *\t@nested_level:\tUsed as as a parameter of spin_lock_nested() of\n *\t\t\tdev->addr_list_lock.\n *\t@unlink_list:\tAs netif_addr_lock() can be called recursively,\n *\t\t\tkeep a list of interfaces to be deleted.\n *\n *\tFIXME: cleanup struct net_device such that network protocol info\n *\tmoves out.\n */\n\nstruct net_device {\n\tchar\t\t\tname[IFNAMSIZ];\n\tstruct netdev_name_node\t*name_node;\n\tstruct dev_ifalias\t__rcu *ifalias;\n\t/*\n\t *\tI/O specific fields\n\t *\tFIXME: Merge these and struct ifmap into one\n\t */\n\tunsigned long\t\tmem_end;\n\tunsigned long\t\tmem_start;\n\tunsigned long\t\tbase_addr;\n\n\t/*\n\t *\tSome hardware also needs these fields (state,dev_list,\n\t *\tnapi_list,unreg_list,close_list) but they are not\n\t *\tpart of the usual set specified in Space.c.\n\t */\n\n\tunsigned long\t\tstate;\n\n\tstruct list_head\tdev_list;\n\tstruct list_head\tnapi_list;\n\tstruct list_head\tunreg_list;\n\tstruct list_head\tclose_list;\n\tstruct list_head\tptype_all;\n\tstruct list_head\tptype_specific;\n\n\tstruct {\n\t\tstruct list_head upper;\n\t\tstruct list_head lower;\n\t} adj_list;\n\n\t/* Read-mostly cache-line for fast-path access */\n\tunsigned int\t\tflags;\n\tunsigned int\t\tpriv_flags;\n\tconst struct net_device_ops *netdev_ops;\n\tint\t\t\tifindex;\n\tunsigned short\t\tgflags;\n\tunsigned short\t\thard_header_len;\n\n\t/* Note : dev->mtu is often read without holding a lock.\n\t * Writers usually hold RTNL.\n\t * It is recommended to use READ_ONCE() to annotate the reads,\n\t * and to use WRITE_ONCE() to annotate the writes.\n\t */\n\tunsigned int\t\tmtu;\n\tunsigned short\t\tneeded_headroom;\n\tunsigned short\t\tneeded_tailroom;\n\n\tnetdev_features_t\tfeatures;\n\tnetdev_features_t\thw_features;\n\tnetdev_features_t\twanted_features;\n\tnetdev_features_t\tvlan_features;\n\tnetdev_features_t\thw_enc_features;\n\tnetdev_features_t\tmpls_features;\n\tnetdev_features_t\tgso_partial_features;\n\n\tunsigned int\t\tmin_mtu;\n\tunsigned int\t\tmax_mtu;\n\tunsigned short\t\ttype;\n\tunsigned char\t\tmin_header_len;\n\tunsigned char\t\tname_assign_type;\n\n\tint\t\t\tgroup;\n\n\tstruct net_device_stats\tstats; /* not used by modern drivers */\n\n\tatomic_long_t\t\trx_dropped;\n\tatomic_long_t\t\ttx_dropped;\n\tatomic_long_t\t\trx_nohandler;\n\n\t/* Stats to monitor link on/off, flapping */\n\tatomic_t\t\tcarrier_up_count;\n\tatomic_t\t\tcarrier_down_count;\n\n#ifdef CONFIG_WIRELESS_EXT\n\tconst struct iw_handler_def *wireless_handlers;\n\tstruct iw_public_data\t*wireless_data;\n#endif\n\tconst struct ethtool_ops *ethtool_ops;\n#ifdef CONFIG_NET_L3_MASTER_DEV\n\tconst struct l3mdev_ops\t*l3mdev_ops;\n#endif\n#if IS_ENABLED(CONFIG_IPV6)\n\tconst struct ndisc_ops *ndisc_ops;\n#endif\n\n#ifdef CONFIG_XFRM_OFFLOAD\n\tconst struct xfrmdev_ops *xfrmdev_ops;\n#endif\n\n#if IS_ENABLED(CONFIG_TLS_DEVICE)\n\tconst struct tlsdev_ops *tlsdev_ops;\n#endif\n\n\tconst struct header_ops *header_ops;\n\n\tunsigned char\t\toperstate;\n\tunsigned char\t\tlink_mode;\n\n\tunsigned char\t\tif_port;\n\tunsigned char\t\tdma;\n\n\t/* Interface address info. */\n\tunsigned char\t\tperm_addr[MAX_ADDR_LEN];\n\tunsigned char\t\taddr_assign_type;\n\tunsigned char\t\taddr_len;\n\tunsigned char\t\tupper_level;\n\tunsigned char\t\tlower_level;\n\n\tunsigned short\t\tneigh_priv_len;\n\tunsigned short          dev_id;\n\tunsigned short          dev_port;\n\tunsigned short\t\tpadded;\n\n\tspinlock_t\t\taddr_list_lock;\n\tint\t\t\tirq;\n\n\tstruct netdev_hw_addr_list\tuc;\n\tstruct netdev_hw_addr_list\tmc;\n\tstruct netdev_hw_addr_list\tdev_addrs;\n\n#ifdef CONFIG_SYSFS\n\tstruct kset\t\t*queues_kset;\n#endif\n#ifdef CONFIG_LOCKDEP\n\tstruct list_head\tunlink_list;\n#endif\n\tunsigned int\t\tpromiscuity;\n\tunsigned int\t\tallmulti;\n\tbool\t\t\tuc_promisc;\n#ifdef CONFIG_LOCKDEP\n\tunsigned char\t\tnested_level;\n#endif\n\n\n\t/* Protocol-specific pointers */\n\n#if IS_ENABLED(CONFIG_VLAN_8021Q)\n\tstruct vlan_info __rcu\t*vlan_info;\n#endif\n#if IS_ENABLED(CONFIG_NET_DSA)\n\tstruct dsa_port\t\t*dsa_ptr;\n#endif\n#if IS_ENABLED(CONFIG_TIPC)\n\tstruct tipc_bearer __rcu *tipc_ptr;\n#endif\n#if IS_ENABLED(CONFIG_IRDA) || IS_ENABLED(CONFIG_ATALK)\n\tvoid \t\t\t*atalk_ptr;\n#endif\n\tstruct in_device __rcu\t*ip_ptr;\n#if IS_ENABLED(CONFIG_DECNET)\n\tstruct dn_dev __rcu     *dn_ptr;\n#endif\n\tstruct inet6_dev __rcu\t*ip6_ptr;\n#if IS_ENABLED(CONFIG_AX25)\n\tvoid\t\t\t*ax25_ptr;\n#endif\n\tstruct wireless_dev\t*ieee80211_ptr;\n\tstruct wpan_dev\t\t*ieee802154_ptr;\n#if IS_ENABLED(CONFIG_MPLS_ROUTING)\n\tstruct mpls_dev __rcu\t*mpls_ptr;\n#endif\n\n/*\n * Cache lines mostly used on receive path (including eth_type_trans())\n */\n\t/* Interface address info used in eth_type_trans() */\n\tunsigned char\t\t*dev_addr;\n\n\tstruct netdev_rx_queue\t*_rx;\n\tunsigned int\t\tnum_rx_queues;\n\tunsigned int\t\treal_num_rx_queues;\n\n\tstruct bpf_prog __rcu\t*xdp_prog;\n\tunsigned long\t\tgro_flush_timeout;\n\tint\t\t\tnapi_defer_hard_irqs;\n\trx_handler_func_t __rcu\t*rx_handler;\n\tvoid __rcu\t\t*rx_handler_data;\n\n#ifdef CONFIG_NET_CLS_ACT\n\tstruct mini_Qdisc __rcu\t*miniq_ingress;\n#endif\n\tstruct netdev_queue __rcu *ingress_queue;\n#ifdef CONFIG_NETFILTER_INGRESS\n\tstruct nf_hook_entries __rcu *nf_hooks_ingress;\n#endif\n\n\tunsigned char\t\tbroadcast[MAX_ADDR_LEN];\n#ifdef CONFIG_RFS_ACCEL\n\tstruct cpu_rmap\t\t*rx_cpu_rmap;\n#endif\n\tstruct hlist_node\tindex_hlist;\n\n/*\n * Cache lines mostly used on transmit path\n */\n\tstruct netdev_queue\t*_tx ____cacheline_aligned_in_smp;\n\tunsigned int\t\tnum_tx_queues;\n\tunsigned int\t\treal_num_tx_queues;\n\tstruct Qdisc\t\t*qdisc;\n\tunsigned int\t\ttx_queue_len;\n\tspinlock_t\t\ttx_global_lock;\n\n\tstruct xdp_dev_bulk_queue __percpu *xdp_bulkq;\n\n#ifdef CONFIG_XPS\n\tstruct xps_dev_maps __rcu *xps_cpus_map;\n\tstruct xps_dev_maps __rcu *xps_rxqs_map;\n#endif\n#ifdef CONFIG_NET_CLS_ACT\n\tstruct mini_Qdisc __rcu\t*miniq_egress;\n#endif\n\n#ifdef CONFIG_NET_SCHED\n\tDECLARE_HASHTABLE\t(qdisc_hash, 4);\n#endif\n\t/* These may be needed for future network-power-down code. */\n\tstruct timer_list\twatchdog_timer;\n\tint\t\t\twatchdog_timeo;\n\n\tu32                     proto_down_reason;\n\n\tstruct list_head\ttodo_list;\n\tint __percpu\t\t*pcpu_refcnt;\n\n\tstruct list_head\tlink_watch_list;\n\n\tenum { NETREG_UNINITIALIZED=0,\n\t       NETREG_REGISTERED,\t/* completed register_netdevice */\n\t       NETREG_UNREGISTERING,\t/* called unregister_netdevice */\n\t       NETREG_UNREGISTERED,\t/* completed unregister todo */\n\t       NETREG_RELEASED,\t\t/* called free_netdev */\n\t       NETREG_DUMMY,\t\t/* dummy device for NAPI poll */\n\t} reg_state:8;\n\n\tbool dismantle;\n\n\tenum {\n\t\tRTNL_LINK_INITIALIZED,\n\t\tRTNL_LINK_INITIALIZING,\n\t} rtnl_link_state:16;\n\n\tbool needs_free_netdev;\n\tvoid (*priv_destructor)(struct net_device *dev);\n\n#ifdef CONFIG_NETPOLL\n\tstruct netpoll_info __rcu\t*npinfo;\n#endif\n\n\tpossible_net_t\t\t\tnd_net;\n\n\t/* mid-layer private */\n\tvoid\t\t\t\t*ml_priv;\n\tenum netdev_ml_priv_type\tml_priv_type;\n\n\tunion {\n\t\tstruct pcpu_lstats __percpu\t\t*lstats;\n\t\tstruct pcpu_sw_netstats __percpu\t*tstats;\n\t\tstruct pcpu_dstats __percpu\t\t*dstats;\n\t};\n\n#if IS_ENABLED(CONFIG_GARP)\n\tstruct garp_port __rcu\t*garp_port;\n#endif\n#if IS_ENABLED(CONFIG_MRP)\n\tstruct mrp_port __rcu\t*mrp_port;\n#endif\n\n\tstruct device\t\tdev;\n\tconst struct attribute_group *sysfs_groups[4];\n\tconst struct attribute_group *sysfs_rx_queue_group;\n\n\tconst struct rtnl_link_ops *rtnl_link_ops;\n\n\t/* for setting kernel sock attribute on TCP connection setup */\n#define GSO_MAX_SIZE\t\t65536\n\tunsigned int\t\tgso_max_size;\n#define GSO_MAX_SEGS\t\t65535\n\tu16\t\t\tgso_max_segs;\n\n#ifdef CONFIG_DCB\n\tconst struct dcbnl_rtnl_ops *dcbnl_ops;\n#endif\n\ts16\t\t\tnum_tc;\n\tstruct netdev_tc_txq\ttc_to_txq[TC_MAX_QUEUE];\n\tu8\t\t\tprio_tc_map[TC_BITMASK + 1];\n\n#if IS_ENABLED(CONFIG_FCOE)\n\tunsigned int\t\tfcoe_ddp_xid;\n#endif\n#if IS_ENABLED(CONFIG_CGROUP_NET_PRIO)\n\tstruct netprio_map __rcu *priomap;\n#endif\n\tstruct phy_device\t*phydev;\n\tstruct sfp_bus\t\t*sfp_bus;\n\tstruct lock_class_key\t*qdisc_tx_busylock;\n\tstruct lock_class_key\t*qdisc_running_key;\n\tbool\t\t\tproto_down;\n\tunsigned\t\twol_enabled:1;\n\tunsigned\t\tthreaded:1;\n\n\tstruct list_head\tnet_notifier_list;\n\n#if IS_ENABLED(CONFIG_MACSEC)\n\t/* MACsec management functions */\n\tconst struct macsec_ops *macsec_ops;\n#endif\n\tconst struct udp_tunnel_nic_info\t*udp_tunnel_nic_info;\n\tstruct udp_tunnel_nic\t*udp_tunnel_nic;\n\n\t/* protected by rtnl_lock */\n\tstruct bpf_xdp_entity\txdp_state[__MAX_XDP_MODE];\n};\n#define to_net_dev(d) container_of(d, struct net_device, dev)\n\nstatic inline bool netif_elide_gro(const struct net_device *dev)\n{\n\tif (!(dev->features & NETIF_F_GRO) || dev->xdp_prog)\n\t\treturn true;\n\treturn false;\n}\n\n#define\tNETDEV_ALIGN\t\t32\n\nstatic inline\nint netdev_get_prio_tc_map(const struct net_device *dev, u32 prio)\n{\n\treturn dev->prio_tc_map[prio & TC_BITMASK];\n}\n\nstatic inline\nint netdev_set_prio_tc_map(struct net_device *dev, u8 prio, u8 tc)\n{\n\tif (tc >= dev->num_tc)\n\t\treturn -EINVAL;\n\n\tdev->prio_tc_map[prio & TC_BITMASK] = tc & TC_BITMASK;\n\treturn 0;\n}\n\nint netdev_txq_to_tc(struct net_device *dev, unsigned int txq);\nvoid netdev_reset_tc(struct net_device *dev);\nint netdev_set_tc_queue(struct net_device *dev, u8 tc, u16 count, u16 offset);\nint netdev_set_num_tc(struct net_device *dev, u8 num_tc);\n\nstatic inline\nint netdev_get_num_tc(struct net_device *dev)\n{\n\treturn dev->num_tc;\n}\n\nstatic inline void net_prefetch(void *p)\n{\n\tprefetch(p);\n#if L1_CACHE_BYTES < 128\n\tprefetch((u8 *)p + L1_CACHE_BYTES);\n#endif\n}\n\nstatic inline void net_prefetchw(void *p)\n{\n\tprefetchw(p);\n#if L1_CACHE_BYTES < 128\n\tprefetchw((u8 *)p + L1_CACHE_BYTES);\n#endif\n}\n\nvoid netdev_unbind_sb_channel(struct net_device *dev,\n\t\t\t      struct net_device *sb_dev);\nint netdev_bind_sb_channel_queue(struct net_device *dev,\n\t\t\t\t struct net_device *sb_dev,\n\t\t\t\t u8 tc, u16 count, u16 offset);\nint netdev_set_sb_channel(struct net_device *dev, u16 channel);\nstatic inline int netdev_get_sb_channel(struct net_device *dev)\n{\n\treturn max_t(int, -dev->num_tc, 0);\n}\n\nstatic inline\nstruct netdev_queue *netdev_get_tx_queue(const struct net_device *dev,\n\t\t\t\t\t unsigned int index)\n{\n\treturn &dev->_tx[index];\n}\n\nstatic inline struct netdev_queue *skb_get_tx_queue(const struct net_device *dev,\n\t\t\t\t\t\t    const struct sk_buff *skb)\n{\n\treturn netdev_get_tx_queue(dev, skb_get_queue_mapping(skb));\n}\n\nstatic inline void netdev_for_each_tx_queue(struct net_device *dev,\n\t\t\t\t\t    void (*f)(struct net_device *,\n\t\t\t\t\t\t      struct netdev_queue *,\n\t\t\t\t\t\t      void *),\n\t\t\t\t\t    void *arg)\n{\n\tunsigned int i;\n\n\tfor (i = 0; i < dev->num_tx_queues; i++)\n\t\tf(dev, &dev->_tx[i], arg);\n}\n\n#define netdev_lockdep_set_classes(dev)\t\t\t\t\\\n{\t\t\t\t\t\t\t\t\\\n\tstatic struct lock_class_key qdisc_tx_busylock_key;\t\\\n\tstatic struct lock_class_key qdisc_running_key;\t\t\\\n\tstatic struct lock_class_key qdisc_xmit_lock_key;\t\\\n\tstatic struct lock_class_key dev_addr_list_lock_key;\t\\\n\tunsigned int i;\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\\\n\t(dev)->qdisc_tx_busylock = &qdisc_tx_busylock_key;\t\\\n\t(dev)->qdisc_running_key = &qdisc_running_key;\t\t\\\n\tlockdep_set_class(&(dev)->addr_list_lock,\t\t\\\n\t\t\t  &dev_addr_list_lock_key);\t\t\\\n\tfor (i = 0; i < (dev)->num_tx_queues; i++)\t\t\\\n\t\tlockdep_set_class(&(dev)->_tx[i]._xmit_lock,\t\\\n\t\t\t\t  &qdisc_xmit_lock_key);\t\\\n}\n\nu16 netdev_pick_tx(struct net_device *dev, struct sk_buff *skb,\n\t\t     struct net_device *sb_dev);\nstruct netdev_queue *netdev_core_pick_tx(struct net_device *dev,\n\t\t\t\t\t struct sk_buff *skb,\n\t\t\t\t\t struct net_device *sb_dev);\n\n/* returns the headroom that the master device needs to take in account\n * when forwarding to this dev\n */\nstatic inline unsigned netdev_get_fwd_headroom(struct net_device *dev)\n{\n\treturn dev->priv_flags & IFF_PHONY_HEADROOM ? 0 : dev->needed_headroom;\n}\n\nstatic inline void netdev_set_rx_headroom(struct net_device *dev, int new_hr)\n{\n\tif (dev->netdev_ops->ndo_set_rx_headroom)\n\t\tdev->netdev_ops->ndo_set_rx_headroom(dev, new_hr);\n}\n\n/* set the device rx headroom to the dev's default */\nstatic inline void netdev_reset_rx_headroom(struct net_device *dev)\n{\n\tnetdev_set_rx_headroom(dev, -1);\n}\n\nstatic inline void *netdev_get_ml_priv(struct net_device *dev,\n\t\t\t\t       enum netdev_ml_priv_type type)\n{\n\tif (dev->ml_priv_type != type)\n\t\treturn NULL;\n\n\treturn dev->ml_priv;\n}\n\nstatic inline void netdev_set_ml_priv(struct net_device *dev,\n\t\t\t\t      void *ml_priv,\n\t\t\t\t      enum netdev_ml_priv_type type)\n{\n\tWARN(dev->ml_priv_type && dev->ml_priv_type != type,\n\t     \"Overwriting already set ml_priv_type (%u) with different ml_priv_type (%u)!\\n\",\n\t     dev->ml_priv_type, type);\n\tWARN(!dev->ml_priv_type && dev->ml_priv,\n\t     \"Overwriting already set ml_priv and ml_priv_type is ML_PRIV_NONE!\\n\");\n\n\tdev->ml_priv = ml_priv;\n\tdev->ml_priv_type = type;\n}\n\n/*\n * Net namespace inlines\n */\nstatic inline\nstruct net *dev_net(const struct net_device *dev)\n{\n\treturn read_pnet(&dev->nd_net);\n}\n\nstatic inline\nvoid dev_net_set(struct net_device *dev, struct net *net)\n{\n\twrite_pnet(&dev->nd_net, net);\n}\n\n/**\n *\tnetdev_priv - access network device private data\n *\t@dev: network device\n *\n * Get network device private data\n */\nstatic inline void *netdev_priv(const struct net_device *dev)\n{\n\treturn (char *)dev + ALIGN(sizeof(struct net_device), NETDEV_ALIGN);\n}\n\n/* Set the sysfs physical device reference for the network logical device\n * if set prior to registration will cause a symlink during initialization.\n */\n#define SET_NETDEV_DEV(net, pdev)\t((net)->dev.parent = (pdev))\n\n/* Set the sysfs device type for the network logical device to allow\n * fine-grained identification of different network device types. For\n * example Ethernet, Wireless LAN, Bluetooth, WiMAX etc.\n */\n#define SET_NETDEV_DEVTYPE(net, devtype)\t((net)->dev.type = (devtype))\n\n/* Default NAPI poll() weight\n * Device drivers are strongly advised to not use bigger value\n */\n#define NAPI_POLL_WEIGHT 64\n\n/**\n *\tnetif_napi_add - initialize a NAPI context\n *\t@dev:  network device\n *\t@napi: NAPI context\n *\t@poll: polling function\n *\t@weight: default weight\n *\n * netif_napi_add() must be used to initialize a NAPI context prior to calling\n * *any* of the other NAPI-related functions.\n */\nvoid netif_napi_add(struct net_device *dev, struct napi_struct *napi,\n\t\t    int (*poll)(struct napi_struct *, int), int weight);\n\n/**\n *\tnetif_tx_napi_add - initialize a NAPI context\n *\t@dev:  network device\n *\t@napi: NAPI context\n *\t@poll: polling function\n *\t@weight: default weight\n *\n * This variant of netif_napi_add() should be used from drivers using NAPI\n * to exclusively poll a TX queue.\n * This will avoid we add it into napi_hash[], thus polluting this hash table.\n */\nstatic inline void netif_tx_napi_add(struct net_device *dev,\n\t\t\t\t     struct napi_struct *napi,\n\t\t\t\t     int (*poll)(struct napi_struct *, int),\n\t\t\t\t     int weight)\n{\n\tset_bit(NAPI_STATE_NO_BUSY_POLL, &napi->state);\n\tnetif_napi_add(dev, napi, poll, weight);\n}\n\n/**\n *  __netif_napi_del - remove a NAPI context\n *  @napi: NAPI context\n *\n * Warning: caller must observe RCU grace period before freeing memory\n * containing @napi. Drivers might want to call this helper to combine\n * all the needed RCU grace periods into a single one.\n */\nvoid __netif_napi_del(struct napi_struct *napi);\n\n/**\n *  netif_napi_del - remove a NAPI context\n *  @napi: NAPI context\n *\n *  netif_napi_del() removes a NAPI context from the network device NAPI list\n */\nstatic inline void netif_napi_del(struct napi_struct *napi)\n{\n\t__netif_napi_del(napi);\n\tsynchronize_net();\n}\n\nstruct napi_gro_cb {\n\t/* Virtual address of skb_shinfo(skb)->frags[0].page + offset. */\n\tvoid\t*frag0;\n\n\t/* Length of frag0. */\n\tunsigned int frag0_len;\n\n\t/* This indicates where we are processing relative to skb->data. */\n\tint\tdata_offset;\n\n\t/* This is non-zero if the packet cannot be merged with the new skb. */\n\tu16\tflush;\n\n\t/* Save the IP ID here and check when we get to the transport layer */\n\tu16\tflush_id;\n\n\t/* Number of segments aggregated. */\n\tu16\tcount;\n\n\t/* Start offset for remote checksum offload */\n\tu16\tgro_remcsum_start;\n\n\t/* jiffies when first packet was created/queued */\n\tunsigned long age;\n\n\t/* Used in ipv6_gro_receive() and foo-over-udp */\n\tu16\tproto;\n\n\t/* This is non-zero if the packet may be of the same flow. */\n\tu8\tsame_flow:1;\n\n\t/* Used in tunnel GRO receive */\n\tu8\tencap_mark:1;\n\n\t/* GRO checksum is valid */\n\tu8\tcsum_valid:1;\n\n\t/* Number of checksums via CHECKSUM_UNNECESSARY */\n\tu8\tcsum_cnt:3;\n\n\t/* Free the skb? */\n\tu8\tfree:2;\n#define NAPI_GRO_FREE\t\t  1\n#define NAPI_GRO_FREE_STOLEN_HEAD 2\n\n\t/* Used in foo-over-udp, set in udp[46]_gro_receive */\n\tu8\tis_ipv6:1;\n\n\t/* Used in GRE, set in fou/gue_gro_receive */\n\tu8\tis_fou:1;\n\n\t/* Used to determine if flush_id can be ignored */\n\tu8\tis_atomic:1;\n\n\t/* Number of gro_receive callbacks this packet already went through */\n\tu8 recursion_counter:4;\n\n\t/* GRO is done by frag_list pointer chaining. */\n\tu8\tis_flist:1;\n\n\t/* used to support CHECKSUM_COMPLETE for tunneling protocols */\n\t__wsum\tcsum;\n\n\t/* used in skb_gro_receive() slow path */\n\tstruct sk_buff *last;\n};\n\n#define NAPI_GRO_CB(skb) ((struct napi_gro_cb *)(skb)->cb)\n\n#define GRO_RECURSION_LIMIT 15\nstatic inline int gro_recursion_inc_test(struct sk_buff *skb)\n{\n\treturn ++NAPI_GRO_CB(skb)->recursion_counter == GRO_RECURSION_LIMIT;\n}\n\ntypedef struct sk_buff *(*gro_receive_t)(struct list_head *, struct sk_buff *);\nstatic inline struct sk_buff *call_gro_receive(gro_receive_t cb,\n\t\t\t\t\t       struct list_head *head,\n\t\t\t\t\t       struct sk_buff *skb)\n{\n\tif (unlikely(gro_recursion_inc_test(skb))) {\n\t\tNAPI_GRO_CB(skb)->flush |= 1;\n\t\treturn NULL;\n\t}\n\n\treturn cb(head, skb);\n}\n\ntypedef struct sk_buff *(*gro_receive_sk_t)(struct sock *, struct list_head *,\n\t\t\t\t\t    struct sk_buff *);\nstatic inline struct sk_buff *call_gro_receive_sk(gro_receive_sk_t cb,\n\t\t\t\t\t\t  struct sock *sk,\n\t\t\t\t\t\t  struct list_head *head,\n\t\t\t\t\t\t  struct sk_buff *skb)\n{\n\tif (unlikely(gro_recursion_inc_test(skb))) {\n\t\tNAPI_GRO_CB(skb)->flush |= 1;\n\t\treturn NULL;\n\t}\n\n\treturn cb(sk, head, skb);\n}\n\nstruct packet_type {\n\t__be16\t\t\ttype;\t/* This is really htons(ether_type). */\n\tbool\t\t\tignore_outgoing;\n\tstruct net_device\t*dev;\t/* NULL is wildcarded here\t     */\n\tint\t\t\t(*func) (struct sk_buff *,\n\t\t\t\t\t struct net_device *,\n\t\t\t\t\t struct packet_type *,\n\t\t\t\t\t struct net_device *);\n\tvoid\t\t\t(*list_func) (struct list_head *,\n\t\t\t\t\t      struct packet_type *,\n\t\t\t\t\t      struct net_device *);\n\tbool\t\t\t(*id_match)(struct packet_type *ptype,\n\t\t\t\t\t    struct sock *sk);\n\tvoid\t\t\t*af_packet_priv;\n\tstruct list_head\tlist;\n};\n\nstruct offload_callbacks {\n\tstruct sk_buff\t\t*(*gso_segment)(struct sk_buff *skb,\n\t\t\t\t\t\tnetdev_features_t features);\n\tstruct sk_buff\t\t*(*gro_receive)(struct list_head *head,\n\t\t\t\t\t\tstruct sk_buff *skb);\n\tint\t\t\t(*gro_complete)(struct sk_buff *skb, int nhoff);\n};\n\nstruct packet_offload {\n\t__be16\t\t\t type;\t/* This is really htons(ether_type). */\n\tu16\t\t\t priority;\n\tstruct offload_callbacks callbacks;\n\tstruct list_head\t list;\n};\n\n/* often modified stats are per-CPU, other are shared (netdev->stats) */\nstruct pcpu_sw_netstats {\n\tu64     rx_packets;\n\tu64     rx_bytes;\n\tu64     tx_packets;\n\tu64     tx_bytes;\n\tstruct u64_stats_sync   syncp;\n} __aligned(4 * sizeof(u64));\n\nstruct pcpu_lstats {\n\tu64_stats_t packets;\n\tu64_stats_t bytes;\n\tstruct u64_stats_sync syncp;\n} __aligned(2 * sizeof(u64));\n\nvoid dev_lstats_read(struct net_device *dev, u64 *packets, u64 *bytes);\n\nstatic inline void dev_sw_netstats_rx_add(struct net_device *dev, unsigned int len)\n{\n\tstruct pcpu_sw_netstats *tstats = this_cpu_ptr(dev->tstats);\n\n\tu64_stats_update_begin(&tstats->syncp);\n\ttstats->rx_bytes += len;\n\ttstats->rx_packets++;\n\tu64_stats_update_end(&tstats->syncp);\n}\n\nstatic inline void dev_sw_netstats_tx_add(struct net_device *dev,\n\t\t\t\t\t  unsigned int packets,\n\t\t\t\t\t  unsigned int len)\n{\n\tstruct pcpu_sw_netstats *tstats = this_cpu_ptr(dev->tstats);\n\n\tu64_stats_update_begin(&tstats->syncp);\n\ttstats->tx_bytes += len;\n\ttstats->tx_packets += packets;\n\tu64_stats_update_end(&tstats->syncp);\n}\n\nstatic inline void dev_lstats_add(struct net_device *dev, unsigned int len)\n{\n\tstruct pcpu_lstats *lstats = this_cpu_ptr(dev->lstats);\n\n\tu64_stats_update_begin(&lstats->syncp);\n\tu64_stats_add(&lstats->bytes, len);\n\tu64_stats_inc(&lstats->packets);\n\tu64_stats_update_end(&lstats->syncp);\n}\n\n#define __netdev_alloc_pcpu_stats(type, gfp)\t\t\t\t\\\n({\t\t\t\t\t\t\t\t\t\\\n\ttypeof(type) __percpu *pcpu_stats = alloc_percpu_gfp(type, gfp);\\\n\tif (pcpu_stats)\t{\t\t\t\t\t\t\\\n\t\tint __cpu;\t\t\t\t\t\t\\\n\t\tfor_each_possible_cpu(__cpu) {\t\t\t\t\\\n\t\t\ttypeof(type) *stat;\t\t\t\t\\\n\t\t\tstat = per_cpu_ptr(pcpu_stats, __cpu);\t\t\\\n\t\t\tu64_stats_init(&stat->syncp);\t\t\t\\\n\t\t}\t\t\t\t\t\t\t\\\n\t}\t\t\t\t\t\t\t\t\\\n\tpcpu_stats;\t\t\t\t\t\t\t\\\n})\n\n#define netdev_alloc_pcpu_stats(type)\t\t\t\t\t\\\n\t__netdev_alloc_pcpu_stats(type, GFP_KERNEL)\n\n#define devm_netdev_alloc_pcpu_stats(dev, type)\t\t\t\t\\\n({\t\t\t\t\t\t\t\t\t\\\n\ttypeof(type) __percpu *pcpu_stats = devm_alloc_percpu(dev, type);\\\n\tif (pcpu_stats) {\t\t\t\t\t\t\\\n\t\tint __cpu;\t\t\t\t\t\t\\\n\t\tfor_each_possible_cpu(__cpu) {\t\t\t\t\\\n\t\t\ttypeof(type) *stat;\t\t\t\t\\\n\t\t\tstat = per_cpu_ptr(pcpu_stats, __cpu);\t\t\\\n\t\t\tu64_stats_init(&stat->syncp);\t\t\t\\\n\t\t}\t\t\t\t\t\t\t\\\n\t}\t\t\t\t\t\t\t\t\\\n\tpcpu_stats;\t\t\t\t\t\t\t\\\n})\n\nenum netdev_lag_tx_type {\n\tNETDEV_LAG_TX_TYPE_UNKNOWN,\n\tNETDEV_LAG_TX_TYPE_RANDOM,\n\tNETDEV_LAG_TX_TYPE_BROADCAST,\n\tNETDEV_LAG_TX_TYPE_ROUNDROBIN,\n\tNETDEV_LAG_TX_TYPE_ACTIVEBACKUP,\n\tNETDEV_LAG_TX_TYPE_HASH,\n};\n\nenum netdev_lag_hash {\n\tNETDEV_LAG_HASH_NONE,\n\tNETDEV_LAG_HASH_L2,\n\tNETDEV_LAG_HASH_L34,\n\tNETDEV_LAG_HASH_L23,\n\tNETDEV_LAG_HASH_E23,\n\tNETDEV_LAG_HASH_E34,\n\tNETDEV_LAG_HASH_VLAN_SRCMAC,\n\tNETDEV_LAG_HASH_UNKNOWN,\n};\n\nstruct netdev_lag_upper_info {\n\tenum netdev_lag_tx_type tx_type;\n\tenum netdev_lag_hash hash_type;\n};\n\nstruct netdev_lag_lower_state_info {\n\tu8 link_up : 1,\n\t   tx_enabled : 1;\n};\n\n#include <linux/notifier.h>\n\n/* netdevice notifier chain. Please remember to update netdev_cmd_to_name()\n * and the rtnetlink notification exclusion list in rtnetlink_event() when\n * adding new types.\n */\nenum netdev_cmd {\n\tNETDEV_UP\t= 1,\t/* For now you can't veto a device up/down */\n\tNETDEV_DOWN,\n\tNETDEV_REBOOT,\t\t/* Tell a protocol stack a network interface\n\t\t\t\t   detected a hardware crash and restarted\n\t\t\t\t   - we can use this eg to kick tcp sessions\n\t\t\t\t   once done */\n\tNETDEV_CHANGE,\t\t/* Notify device state change */\n\tNETDEV_REGISTER,\n\tNETDEV_UNREGISTER,\n\tNETDEV_CHANGEMTU,\t/* notify after mtu change happened */\n\tNETDEV_CHANGEADDR,\t/* notify after the address change */\n\tNETDEV_PRE_CHANGEADDR,\t/* notify before the address change */\n\tNETDEV_GOING_DOWN,\n\tNETDEV_CHANGENAME,\n\tNETDEV_FEAT_CHANGE,\n\tNETDEV_BONDING_FAILOVER,\n\tNETDEV_PRE_UP,\n\tNETDEV_PRE_TYPE_CHANGE,\n\tNETDEV_POST_TYPE_CHANGE,\n\tNETDEV_POST_INIT,\n\tNETDEV_RELEASE,\n\tNETDEV_NOTIFY_PEERS,\n\tNETDEV_JOIN,\n\tNETDEV_CHANGEUPPER,\n\tNETDEV_RESEND_IGMP,\n\tNETDEV_PRECHANGEMTU,\t/* notify before mtu change happened */\n\tNETDEV_CHANGEINFODATA,\n\tNETDEV_BONDING_INFO,\n\tNETDEV_PRECHANGEUPPER,\n\tNETDEV_CHANGELOWERSTATE,\n\tNETDEV_UDP_TUNNEL_PUSH_INFO,\n\tNETDEV_UDP_TUNNEL_DROP_INFO,\n\tNETDEV_CHANGE_TX_QUEUE_LEN,\n\tNETDEV_CVLAN_FILTER_PUSH_INFO,\n\tNETDEV_CVLAN_FILTER_DROP_INFO,\n\tNETDEV_SVLAN_FILTER_PUSH_INFO,\n\tNETDEV_SVLAN_FILTER_DROP_INFO,\n};\nconst char *netdev_cmd_to_name(enum netdev_cmd cmd);\n\nint register_netdevice_notifier(struct notifier_block *nb);\nint unregister_netdevice_notifier(struct notifier_block *nb);\nint register_netdevice_notifier_net(struct net *net, struct notifier_block *nb);\nint unregister_netdevice_notifier_net(struct net *net,\n\t\t\t\t      struct notifier_block *nb);\nint register_netdevice_notifier_dev_net(struct net_device *dev,\n\t\t\t\t\tstruct notifier_block *nb,\n\t\t\t\t\tstruct netdev_net_notifier *nn);\nint unregister_netdevice_notifier_dev_net(struct net_device *dev,\n\t\t\t\t\t  struct notifier_block *nb,\n\t\t\t\t\t  struct netdev_net_notifier *nn);\n\nstruct netdev_notifier_info {\n\tstruct net_device\t*dev;\n\tstruct netlink_ext_ack\t*extack;\n};\n\nstruct netdev_notifier_info_ext {\n\tstruct netdev_notifier_info info; /* must be first */\n\tunion {\n\t\tu32 mtu;\n\t} ext;\n};\n\nstruct netdev_notifier_change_info {\n\tstruct netdev_notifier_info info; /* must be first */\n\tunsigned int flags_changed;\n};\n\nstruct netdev_notifier_changeupper_info {\n\tstruct netdev_notifier_info info; /* must be first */\n\tstruct net_device *upper_dev; /* new upper dev */\n\tbool master; /* is upper dev master */\n\tbool linking; /* is the notification for link or unlink */\n\tvoid *upper_info; /* upper dev info */\n};\n\nstruct netdev_notifier_changelowerstate_info {\n\tstruct netdev_notifier_info info; /* must be first */\n\tvoid *lower_state_info; /* is lower dev state */\n};\n\nstruct netdev_notifier_pre_changeaddr_info {\n\tstruct netdev_notifier_info info; /* must be first */\n\tconst unsigned char *dev_addr;\n};\n\nstatic inline void netdev_notifier_info_init(struct netdev_notifier_info *info,\n\t\t\t\t\t     struct net_device *dev)\n{\n\tinfo->dev = dev;\n\tinfo->extack = NULL;\n}\n\nstatic inline struct net_device *\nnetdev_notifier_info_to_dev(const struct netdev_notifier_info *info)\n{\n\treturn info->dev;\n}\n\nstatic inline struct netlink_ext_ack *\nnetdev_notifier_info_to_extack(const struct netdev_notifier_info *info)\n{\n\treturn info->extack;\n}\n\nint call_netdevice_notifiers(unsigned long val, struct net_device *dev);\n\n\nextern rwlock_t\t\t\t\tdev_base_lock;\t\t/* Device list lock */\n\n#define for_each_netdev(net, d)\t\t\\\n\t\tlist_for_each_entry(d, &(net)->dev_base_head, dev_list)\n#define for_each_netdev_reverse(net, d)\t\\\n\t\tlist_for_each_entry_reverse(d, &(net)->dev_base_head, dev_list)\n#define for_each_netdev_rcu(net, d)\t\t\\\n\t\tlist_for_each_entry_rcu(d, &(net)->dev_base_head, dev_list)\n#define for_each_netdev_safe(net, d, n)\t\\\n\t\tlist_for_each_entry_safe(d, n, &(net)->dev_base_head, dev_list)\n#define for_each_netdev_continue(net, d)\t\t\\\n\t\tlist_for_each_entry_continue(d, &(net)->dev_base_head, dev_list)\n#define for_each_netdev_continue_reverse(net, d)\t\t\\\n\t\tlist_for_each_entry_continue_reverse(d, &(net)->dev_base_head, \\\n\t\t\t\t\t\t     dev_list)\n#define for_each_netdev_continue_rcu(net, d)\t\t\\\n\tlist_for_each_entry_continue_rcu(d, &(net)->dev_base_head, dev_list)\n#define for_each_netdev_in_bond_rcu(bond, slave)\t\\\n\t\tfor_each_netdev_rcu(&init_net, slave)\t\\\n\t\t\tif (netdev_master_upper_dev_get_rcu(slave) == (bond))\n#define net_device_entry(lh)\tlist_entry(lh, struct net_device, dev_list)\n\nstatic inline struct net_device *next_net_device(struct net_device *dev)\n{\n\tstruct list_head *lh;\n\tstruct net *net;\n\n\tnet = dev_net(dev);\n\tlh = dev->dev_list.next;\n\treturn lh == &net->dev_base_head ? NULL : net_device_entry(lh);\n}\n\nstatic inline struct net_device *next_net_device_rcu(struct net_device *dev)\n{\n\tstruct list_head *lh;\n\tstruct net *net;\n\n\tnet = dev_net(dev);\n\tlh = rcu_dereference(list_next_rcu(&dev->dev_list));\n\treturn lh == &net->dev_base_head ? NULL : net_device_entry(lh);\n}\n\nstatic inline struct net_device *first_net_device(struct net *net)\n{\n\treturn list_empty(&net->dev_base_head) ? NULL :\n\t\tnet_device_entry(net->dev_base_head.next);\n}\n\nstatic inline struct net_device *first_net_device_rcu(struct net *net)\n{\n\tstruct list_head *lh = rcu_dereference(list_next_rcu(&net->dev_base_head));\n\n\treturn lh == &net->dev_base_head ? NULL : net_device_entry(lh);\n}\n\nint netdev_boot_setup_check(struct net_device *dev);\nunsigned long netdev_boot_base(const char *prefix, int unit);\nstruct net_device *dev_getbyhwaddr_rcu(struct net *net, unsigned short type,\n\t\t\t\t       const char *hwaddr);\nstruct net_device *dev_getfirstbyhwtype(struct net *net, unsigned short type);\nvoid dev_add_pack(struct packet_type *pt);\nvoid dev_remove_pack(struct packet_type *pt);\nvoid __dev_remove_pack(struct packet_type *pt);\nvoid dev_add_offload(struct packet_offload *po);\nvoid dev_remove_offload(struct packet_offload *po);\n\nint dev_get_iflink(const struct net_device *dev);\nint dev_fill_metadata_dst(struct net_device *dev, struct sk_buff *skb);\nstruct net_device *__dev_get_by_flags(struct net *net, unsigned short flags,\n\t\t\t\t      unsigned short mask);\nstruct net_device *dev_get_by_name(struct net *net, const char *name);\nstruct net_device *dev_get_by_name_rcu(struct net *net, const char *name);\nstruct net_device *__dev_get_by_name(struct net *net, const char *name);\nint dev_alloc_name(struct net_device *dev, const char *name);\nint dev_open(struct net_device *dev, struct netlink_ext_ack *extack);\nvoid dev_close(struct net_device *dev);\nvoid dev_close_many(struct list_head *head, bool unlink);\nvoid dev_disable_lro(struct net_device *dev);\nint dev_loopback_xmit(struct net *net, struct sock *sk, struct sk_buff *newskb);\nu16 dev_pick_tx_zero(struct net_device *dev, struct sk_buff *skb,\n\t\t     struct net_device *sb_dev);\nu16 dev_pick_tx_cpu_id(struct net_device *dev, struct sk_buff *skb,\n\t\t       struct net_device *sb_dev);\n\nint dev_queue_xmit(struct sk_buff *skb);\nint dev_queue_xmit_accel(struct sk_buff *skb, struct net_device *sb_dev);\nint __dev_direct_xmit(struct sk_buff *skb, u16 queue_id);\n\nstatic inline int dev_direct_xmit(struct sk_buff *skb, u16 queue_id)\n{\n\tint ret;\n\n\tret = __dev_direct_xmit(skb, queue_id);\n\tif (!dev_xmit_complete(ret))\n\t\tkfree_skb(skb);\n\treturn ret;\n}\n\nint register_netdevice(struct net_device *dev);\nvoid unregister_netdevice_queue(struct net_device *dev, struct list_head *head);\nvoid unregister_netdevice_many(struct list_head *head);\nstatic inline void unregister_netdevice(struct net_device *dev)\n{\n\tunregister_netdevice_queue(dev, NULL);\n}\n\nint netdev_refcnt_read(const struct net_device *dev);\nvoid free_netdev(struct net_device *dev);\nvoid netdev_freemem(struct net_device *dev);\nint init_dummy_netdev(struct net_device *dev);\n\nstruct net_device *netdev_get_xmit_slave(struct net_device *dev,\n\t\t\t\t\t struct sk_buff *skb,\n\t\t\t\t\t bool all_slaves);\nstruct net_device *netdev_sk_get_lowest_dev(struct net_device *dev,\n\t\t\t\t\t    struct sock *sk);\nstruct net_device *dev_get_by_index(struct net *net, int ifindex);\nstruct net_device *__dev_get_by_index(struct net *net, int ifindex);\nstruct net_device *dev_get_by_index_rcu(struct net *net, int ifindex);\nstruct net_device *dev_get_by_napi_id(unsigned int napi_id);\nint netdev_get_name(struct net *net, char *name, int ifindex);\nint dev_restart(struct net_device *dev);\nint skb_gro_receive(struct sk_buff *p, struct sk_buff *skb);\nint skb_gro_receive_list(struct sk_buff *p, struct sk_buff *skb);\n\nstatic inline unsigned int skb_gro_offset(const struct sk_buff *skb)\n{\n\treturn NAPI_GRO_CB(skb)->data_offset;\n}\n\nstatic inline unsigned int skb_gro_len(const struct sk_buff *skb)\n{\n\treturn skb->len - NAPI_GRO_CB(skb)->data_offset;\n}\n\nstatic inline void skb_gro_pull(struct sk_buff *skb, unsigned int len)\n{\n\tNAPI_GRO_CB(skb)->data_offset += len;\n}\n\nstatic inline void *skb_gro_header_fast(struct sk_buff *skb,\n\t\t\t\t\tunsigned int offset)\n{\n\treturn NAPI_GRO_CB(skb)->frag0 + offset;\n}\n\nstatic inline int skb_gro_header_hard(struct sk_buff *skb, unsigned int hlen)\n{\n\treturn NAPI_GRO_CB(skb)->frag0_len < hlen;\n}\n\nstatic inline void skb_gro_frag0_invalidate(struct sk_buff *skb)\n{\n\tNAPI_GRO_CB(skb)->frag0 = NULL;\n\tNAPI_GRO_CB(skb)->frag0_len = 0;\n}\n\nstatic inline void *skb_gro_header_slow(struct sk_buff *skb, unsigned int hlen,\n\t\t\t\t\tunsigned int offset)\n{\n\tif (!pskb_may_pull(skb, hlen))\n\t\treturn NULL;\n\n\tskb_gro_frag0_invalidate(skb);\n\treturn skb->data + offset;\n}\n\nstatic inline void *skb_gro_network_header(struct sk_buff *skb)\n{\n\treturn (NAPI_GRO_CB(skb)->frag0 ?: skb->data) +\n\t       skb_network_offset(skb);\n}\n\nstatic inline void skb_gro_postpull_rcsum(struct sk_buff *skb,\n\t\t\t\t\tconst void *start, unsigned int len)\n{\n\tif (NAPI_GRO_CB(skb)->csum_valid)\n\t\tNAPI_GRO_CB(skb)->csum = csum_sub(NAPI_GRO_CB(skb)->csum,\n\t\t\t\t\t\t  csum_partial(start, len, 0));\n}\n\n/* GRO checksum functions. These are logical equivalents of the normal\n * checksum functions (in skbuff.h) except that they operate on the GRO\n * offsets and fields in sk_buff.\n */\n\n__sum16 __skb_gro_checksum_complete(struct sk_buff *skb);\n\nstatic inline bool skb_at_gro_remcsum_start(struct sk_buff *skb)\n{\n\treturn (NAPI_GRO_CB(skb)->gro_remcsum_start == skb_gro_offset(skb));\n}\n\nstatic inline bool __skb_gro_checksum_validate_needed(struct sk_buff *skb,\n\t\t\t\t\t\t      bool zero_okay,\n\t\t\t\t\t\t      __sum16 check)\n{\n\treturn ((skb->ip_summed != CHECKSUM_PARTIAL ||\n\t\tskb_checksum_start_offset(skb) <\n\t\t skb_gro_offset(skb)) &&\n\t\t!skb_at_gro_remcsum_start(skb) &&\n\t\tNAPI_GRO_CB(skb)->csum_cnt == 0 &&\n\t\t(!zero_okay || check));\n}\n\nstatic inline __sum16 __skb_gro_checksum_validate_complete(struct sk_buff *skb,\n\t\t\t\t\t\t\t   __wsum psum)\n{\n\tif (NAPI_GRO_CB(skb)->csum_valid &&\n\t    !csum_fold(csum_add(psum, NAPI_GRO_CB(skb)->csum)))\n\t\treturn 0;\n\n\tNAPI_GRO_CB(skb)->csum = psum;\n\n\treturn __skb_gro_checksum_complete(skb);\n}\n\nstatic inline void skb_gro_incr_csum_unnecessary(struct sk_buff *skb)\n{\n\tif (NAPI_GRO_CB(skb)->csum_cnt > 0) {\n\t\t/* Consume a checksum from CHECKSUM_UNNECESSARY */\n\t\tNAPI_GRO_CB(skb)->csum_cnt--;\n\t} else {\n\t\t/* Update skb for CHECKSUM_UNNECESSARY and csum_level when we\n\t\t * verified a new top level checksum or an encapsulated one\n\t\t * during GRO. This saves work if we fallback to normal path.\n\t\t */\n\t\t__skb_incr_checksum_unnecessary(skb);\n\t}\n}\n\n#define __skb_gro_checksum_validate(skb, proto, zero_okay, check,\t\\\n\t\t\t\t    compute_pseudo)\t\t\t\\\n({\t\t\t\t\t\t\t\t\t\\\n\t__sum16 __ret = 0;\t\t\t\t\t\t\\\n\tif (__skb_gro_checksum_validate_needed(skb, zero_okay, check))\t\\\n\t\t__ret = __skb_gro_checksum_validate_complete(skb,\t\\\n\t\t\t\tcompute_pseudo(skb, proto));\t\t\\\n\tif (!__ret)\t\t\t\t\t\t\t\\\n\t\tskb_gro_incr_csum_unnecessary(skb);\t\t\t\\\n\t__ret;\t\t\t\t\t\t\t\t\\\n})\n\n#define skb_gro_checksum_validate(skb, proto, compute_pseudo)\t\t\\\n\t__skb_gro_checksum_validate(skb, proto, false, 0, compute_pseudo)\n\n#define skb_gro_checksum_validate_zero_check(skb, proto, check,\t\t\\\n\t\t\t\t\t     compute_pseudo)\t\t\\\n\t__skb_gro_checksum_validate(skb, proto, true, check, compute_pseudo)\n\n#define skb_gro_checksum_simple_validate(skb)\t\t\t\t\\\n\t__skb_gro_checksum_validate(skb, 0, false, 0, null_compute_pseudo)\n\nstatic inline bool __skb_gro_checksum_convert_check(struct sk_buff *skb)\n{\n\treturn (NAPI_GRO_CB(skb)->csum_cnt == 0 &&\n\t\t!NAPI_GRO_CB(skb)->csum_valid);\n}\n\nstatic inline void __skb_gro_checksum_convert(struct sk_buff *skb,\n\t\t\t\t\t      __wsum pseudo)\n{\n\tNAPI_GRO_CB(skb)->csum = ~pseudo;\n\tNAPI_GRO_CB(skb)->csum_valid = 1;\n}\n\n#define skb_gro_checksum_try_convert(skb, proto, compute_pseudo)\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tif (__skb_gro_checksum_convert_check(skb))\t\t\t\\\n\t\t__skb_gro_checksum_convert(skb, \t\t\t\\\n\t\t\t\t\t   compute_pseudo(skb, proto));\t\\\n} while (0)\n\nstruct gro_remcsum {\n\tint offset;\n\t__wsum delta;\n};\n\nstatic inline void skb_gro_remcsum_init(struct gro_remcsum *grc)\n{\n\tgrc->offset = 0;\n\tgrc->delta = 0;\n}\n\nstatic inline void *skb_gro_remcsum_process(struct sk_buff *skb, void *ptr,\n\t\t\t\t\t    unsigned int off, size_t hdrlen,\n\t\t\t\t\t    int start, int offset,\n\t\t\t\t\t    struct gro_remcsum *grc,\n\t\t\t\t\t    bool nopartial)\n{\n\t__wsum delta;\n\tsize_t plen = hdrlen + max_t(size_t, offset + sizeof(u16), start);\n\n\tBUG_ON(!NAPI_GRO_CB(skb)->csum_valid);\n\n\tif (!nopartial) {\n\t\tNAPI_GRO_CB(skb)->gro_remcsum_start = off + hdrlen + start;\n\t\treturn ptr;\n\t}\n\n\tptr = skb_gro_header_fast(skb, off);\n\tif (skb_gro_header_hard(skb, off + plen)) {\n\t\tptr = skb_gro_header_slow(skb, off + plen, off);\n\t\tif (!ptr)\n\t\t\treturn NULL;\n\t}\n\n\tdelta = remcsum_adjust(ptr + hdrlen, NAPI_GRO_CB(skb)->csum,\n\t\t\t       start, offset);\n\n\t/* Adjust skb->csum since we changed the packet */\n\tNAPI_GRO_CB(skb)->csum = csum_add(NAPI_GRO_CB(skb)->csum, delta);\n\n\tgrc->offset = off + hdrlen + offset;\n\tgrc->delta = delta;\n\n\treturn ptr;\n}\n\nstatic inline void skb_gro_remcsum_cleanup(struct sk_buff *skb,\n\t\t\t\t\t   struct gro_remcsum *grc)\n{\n\tvoid *ptr;\n\tsize_t plen = grc->offset + sizeof(u16);\n\n\tif (!grc->delta)\n\t\treturn;\n\n\tptr = skb_gro_header_fast(skb, grc->offset);\n\tif (skb_gro_header_hard(skb, grc->offset + sizeof(u16))) {\n\t\tptr = skb_gro_header_slow(skb, plen, grc->offset);\n\t\tif (!ptr)\n\t\t\treturn;\n\t}\n\n\tremcsum_unadjust((__sum16 *)ptr, grc->delta);\n}\n\n#ifdef CONFIG_XFRM_OFFLOAD\nstatic inline void skb_gro_flush_final(struct sk_buff *skb, struct sk_buff *pp, int flush)\n{\n\tif (PTR_ERR(pp) != -EINPROGRESS)\n\t\tNAPI_GRO_CB(skb)->flush |= flush;\n}\nstatic inline void skb_gro_flush_final_remcsum(struct sk_buff *skb,\n\t\t\t\t\t       struct sk_buff *pp,\n\t\t\t\t\t       int flush,\n\t\t\t\t\t       struct gro_remcsum *grc)\n{\n\tif (PTR_ERR(pp) != -EINPROGRESS) {\n\t\tNAPI_GRO_CB(skb)->flush |= flush;\n\t\tskb_gro_remcsum_cleanup(skb, grc);\n\t\tskb->remcsum_offload = 0;\n\t}\n}\n#else\nstatic inline void skb_gro_flush_final(struct sk_buff *skb, struct sk_buff *pp, int flush)\n{\n\tNAPI_GRO_CB(skb)->flush |= flush;\n}\nstatic inline void skb_gro_flush_final_remcsum(struct sk_buff *skb,\n\t\t\t\t\t       struct sk_buff *pp,\n\t\t\t\t\t       int flush,\n\t\t\t\t\t       struct gro_remcsum *grc)\n{\n\tNAPI_GRO_CB(skb)->flush |= flush;\n\tskb_gro_remcsum_cleanup(skb, grc);\n\tskb->remcsum_offload = 0;\n}\n#endif\n\nstatic inline int dev_hard_header(struct sk_buff *skb, struct net_device *dev,\n\t\t\t\t  unsigned short type,\n\t\t\t\t  const void *daddr, const void *saddr,\n\t\t\t\t  unsigned int len)\n{\n\tif (!dev->header_ops || !dev->header_ops->create)\n\t\treturn 0;\n\n\treturn dev->header_ops->create(skb, dev, type, daddr, saddr, len);\n}\n\nstatic inline int dev_parse_header(const struct sk_buff *skb,\n\t\t\t\t   unsigned char *haddr)\n{\n\tconst struct net_device *dev = skb->dev;\n\n\tif (!dev->header_ops || !dev->header_ops->parse)\n\t\treturn 0;\n\treturn dev->header_ops->parse(skb, haddr);\n}\n\nstatic inline __be16 dev_parse_header_protocol(const struct sk_buff *skb)\n{\n\tconst struct net_device *dev = skb->dev;\n\n\tif (!dev->header_ops || !dev->header_ops->parse_protocol)\n\t\treturn 0;\n\treturn dev->header_ops->parse_protocol(skb);\n}\n\n/* ll_header must have at least hard_header_len allocated */\nstatic inline bool dev_validate_header(const struct net_device *dev,\n\t\t\t\t       char *ll_header, int len)\n{\n\tif (likely(len >= dev->hard_header_len))\n\t\treturn true;\n\tif (len < dev->min_header_len)\n\t\treturn false;\n\n\tif (capable(CAP_SYS_RAWIO)) {\n\t\tmemset(ll_header + len, 0, dev->hard_header_len - len);\n\t\treturn true;\n\t}\n\n\tif (dev->header_ops && dev->header_ops->validate)\n\t\treturn dev->header_ops->validate(ll_header, len);\n\n\treturn false;\n}\n\nstatic inline bool dev_has_header(const struct net_device *dev)\n{\n\treturn dev->header_ops && dev->header_ops->create;\n}\n\ntypedef int gifconf_func_t(struct net_device * dev, char __user * bufptr,\n\t\t\t   int len, int size);\nint register_gifconf(unsigned int family, gifconf_func_t *gifconf);\nstatic inline int unregister_gifconf(unsigned int family)\n{\n\treturn register_gifconf(family, NULL);\n}\n\n#ifdef CONFIG_NET_FLOW_LIMIT\n#define FLOW_LIMIT_HISTORY\t(1 << 7)  /* must be ^2 and !overflow buckets */\nstruct sd_flow_limit {\n\tu64\t\t\tcount;\n\tunsigned int\t\tnum_buckets;\n\tunsigned int\t\thistory_head;\n\tu16\t\t\thistory[FLOW_LIMIT_HISTORY];\n\tu8\t\t\tbuckets[];\n};\n\nextern int netdev_flow_limit_table_len;\n#endif /* CONFIG_NET_FLOW_LIMIT */\n\n/*\n * Incoming packets are placed on per-CPU queues\n */\nstruct softnet_data {\n\tstruct list_head\tpoll_list;\n\tstruct sk_buff_head\tprocess_queue;\n\n\t/* stats */\n\tunsigned int\t\tprocessed;\n\tunsigned int\t\ttime_squeeze;\n\tunsigned int\t\treceived_rps;\n#ifdef CONFIG_RPS\n\tstruct softnet_data\t*rps_ipi_list;\n#endif\n#ifdef CONFIG_NET_FLOW_LIMIT\n\tstruct sd_flow_limit __rcu *flow_limit;\n#endif\n\tstruct Qdisc\t\t*output_queue;\n\tstruct Qdisc\t\t**output_queue_tailp;\n\tstruct sk_buff\t\t*completion_queue;\n#ifdef CONFIG_XFRM_OFFLOAD\n\tstruct sk_buff_head\txfrm_backlog;\n#endif\n\t/* written and read only by owning cpu: */\n\tstruct {\n\t\tu16 recursion;\n\t\tu8  more;\n\t} xmit;\n#ifdef CONFIG_RPS\n\t/* input_queue_head should be written by cpu owning this struct,\n\t * and only read by other cpus. Worth using a cache line.\n\t */\n\tunsigned int\t\tinput_queue_head ____cacheline_aligned_in_smp;\n\n\t/* Elements below can be accessed between CPUs for RPS/RFS */\n\tcall_single_data_t\tcsd ____cacheline_aligned_in_smp;\n\tstruct softnet_data\t*rps_ipi_next;\n\tunsigned int\t\tcpu;\n\tunsigned int\t\tinput_queue_tail;\n#endif\n\tunsigned int\t\tdropped;\n\tstruct sk_buff_head\tinput_pkt_queue;\n\tstruct napi_struct\tbacklog;\n\n};\n\nstatic inline void input_queue_head_incr(struct softnet_data *sd)\n{\n#ifdef CONFIG_RPS\n\tsd->input_queue_head++;\n#endif\n}\n\nstatic inline void input_queue_tail_incr_save(struct softnet_data *sd,\n\t\t\t\t\t      unsigned int *qtail)\n{\n#ifdef CONFIG_RPS\n\t*qtail = ++sd->input_queue_tail;\n#endif\n}\n\nDECLARE_PER_CPU_ALIGNED(struct softnet_data, softnet_data);\n\nstatic inline int dev_recursion_level(void)\n{\n\treturn this_cpu_read(softnet_data.xmit.recursion);\n}\n\n#define XMIT_RECURSION_LIMIT\t8\nstatic inline bool dev_xmit_recursion(void)\n{\n\treturn unlikely(__this_cpu_read(softnet_data.xmit.recursion) >\n\t\t\tXMIT_RECURSION_LIMIT);\n}\n\nstatic inline void dev_xmit_recursion_inc(void)\n{\n\t__this_cpu_inc(softnet_data.xmit.recursion);\n}\n\nstatic inline void dev_xmit_recursion_dec(void)\n{\n\t__this_cpu_dec(softnet_data.xmit.recursion);\n}\n\nvoid __netif_schedule(struct Qdisc *q);\nvoid netif_schedule_queue(struct netdev_queue *txq);\n\nstatic inline void netif_tx_schedule_all(struct net_device *dev)\n{\n\tunsigned int i;\n\n\tfor (i = 0; i < dev->num_tx_queues; i++)\n\t\tnetif_schedule_queue(netdev_get_tx_queue(dev, i));\n}\n\nstatic __always_inline void netif_tx_start_queue(struct netdev_queue *dev_queue)\n{\n\tclear_bit(__QUEUE_STATE_DRV_XOFF, &dev_queue->state);\n}\n\n/**\n *\tnetif_start_queue - allow transmit\n *\t@dev: network device\n *\n *\tAllow upper layers to call the device hard_start_xmit routine.\n */\nstatic inline void netif_start_queue(struct net_device *dev)\n{\n\tnetif_tx_start_queue(netdev_get_tx_queue(dev, 0));\n}\n\nstatic inline void netif_tx_start_all_queues(struct net_device *dev)\n{\n\tunsigned int i;\n\n\tfor (i = 0; i < dev->num_tx_queues; i++) {\n\t\tstruct netdev_queue *txq = netdev_get_tx_queue(dev, i);\n\t\tnetif_tx_start_queue(txq);\n\t}\n}\n\nvoid netif_tx_wake_queue(struct netdev_queue *dev_queue);\n\n/**\n *\tnetif_wake_queue - restart transmit\n *\t@dev: network device\n *\n *\tAllow upper layers to call the device hard_start_xmit routine.\n *\tUsed for flow control when transmit resources are available.\n */\nstatic inline void netif_wake_queue(struct net_device *dev)\n{\n\tnetif_tx_wake_queue(netdev_get_tx_queue(dev, 0));\n}\n\nstatic inline void netif_tx_wake_all_queues(struct net_device *dev)\n{\n\tunsigned int i;\n\n\tfor (i = 0; i < dev->num_tx_queues; i++) {\n\t\tstruct netdev_queue *txq = netdev_get_tx_queue(dev, i);\n\t\tnetif_tx_wake_queue(txq);\n\t}\n}\n\nstatic __always_inline void netif_tx_stop_queue(struct netdev_queue *dev_queue)\n{\n\tset_bit(__QUEUE_STATE_DRV_XOFF, &dev_queue->state);\n}\n\n/**\n *\tnetif_stop_queue - stop transmitted packets\n *\t@dev: network device\n *\n *\tStop upper layers calling the device hard_start_xmit routine.\n *\tUsed for flow control when transmit resources are unavailable.\n */\nstatic inline void netif_stop_queue(struct net_device *dev)\n{\n\tnetif_tx_stop_queue(netdev_get_tx_queue(dev, 0));\n}\n\nvoid netif_tx_stop_all_queues(struct net_device *dev);\n\nstatic inline bool netif_tx_queue_stopped(const struct netdev_queue *dev_queue)\n{\n\treturn test_bit(__QUEUE_STATE_DRV_XOFF, &dev_queue->state);\n}\n\n/**\n *\tnetif_queue_stopped - test if transmit queue is flowblocked\n *\t@dev: network device\n *\n *\tTest if transmit queue on device is currently unable to send.\n */\nstatic inline bool netif_queue_stopped(const struct net_device *dev)\n{\n\treturn netif_tx_queue_stopped(netdev_get_tx_queue(dev, 0));\n}\n\nstatic inline bool netif_xmit_stopped(const struct netdev_queue *dev_queue)\n{\n\treturn dev_queue->state & QUEUE_STATE_ANY_XOFF;\n}\n\nstatic inline bool\nnetif_xmit_frozen_or_stopped(const struct netdev_queue *dev_queue)\n{\n\treturn dev_queue->state & QUEUE_STATE_ANY_XOFF_OR_FROZEN;\n}\n\nstatic inline bool\nnetif_xmit_frozen_or_drv_stopped(const struct netdev_queue *dev_queue)\n{\n\treturn dev_queue->state & QUEUE_STATE_DRV_XOFF_OR_FROZEN;\n}\n\n/**\n *\tnetdev_txq_bql_enqueue_prefetchw - prefetch bql data for write\n *\t@dev_queue: pointer to transmit queue\n *\n * BQL enabled drivers might use this helper in their ndo_start_xmit(),\n * to give appropriate hint to the CPU.\n */\nstatic inline void netdev_txq_bql_enqueue_prefetchw(struct netdev_queue *dev_queue)\n{\n#ifdef CONFIG_BQL\n\tprefetchw(&dev_queue->dql.num_queued);\n#endif\n}\n\n/**\n *\tnetdev_txq_bql_complete_prefetchw - prefetch bql data for write\n *\t@dev_queue: pointer to transmit queue\n *\n * BQL enabled drivers might use this helper in their TX completion path,\n * to give appropriate hint to the CPU.\n */\nstatic inline void netdev_txq_bql_complete_prefetchw(struct netdev_queue *dev_queue)\n{\n#ifdef CONFIG_BQL\n\tprefetchw(&dev_queue->dql.limit);\n#endif\n}\n\nstatic inline void netdev_tx_sent_queue(struct netdev_queue *dev_queue,\n\t\t\t\t\tunsigned int bytes)\n{\n#ifdef CONFIG_BQL\n\tdql_queued(&dev_queue->dql, bytes);\n\n\tif (likely(dql_avail(&dev_queue->dql) >= 0))\n\t\treturn;\n\n\tset_bit(__QUEUE_STATE_STACK_XOFF, &dev_queue->state);\n\n\t/*\n\t * The XOFF flag must be set before checking the dql_avail below,\n\t * because in netdev_tx_completed_queue we update the dql_completed\n\t * before checking the XOFF flag.\n\t */\n\tsmp_mb();\n\n\t/* check again in case another CPU has just made room avail */\n\tif (unlikely(dql_avail(&dev_queue->dql) >= 0))\n\t\tclear_bit(__QUEUE_STATE_STACK_XOFF, &dev_queue->state);\n#endif\n}\n\n/* Variant of netdev_tx_sent_queue() for drivers that are aware\n * that they should not test BQL status themselves.\n * We do want to change __QUEUE_STATE_STACK_XOFF only for the last\n * skb of a batch.\n * Returns true if the doorbell must be used to kick the NIC.\n */\nstatic inline bool __netdev_tx_sent_queue(struct netdev_queue *dev_queue,\n\t\t\t\t\t  unsigned int bytes,\n\t\t\t\t\t  bool xmit_more)\n{\n\tif (xmit_more) {\n#ifdef CONFIG_BQL\n\t\tdql_queued(&dev_queue->dql, bytes);\n#endif\n\t\treturn netif_tx_queue_stopped(dev_queue);\n\t}\n\tnetdev_tx_sent_queue(dev_queue, bytes);\n\treturn true;\n}\n\n/**\n * \tnetdev_sent_queue - report the number of bytes queued to hardware\n * \t@dev: network device\n * \t@bytes: number of bytes queued to the hardware device queue\n *\n * \tReport the number of bytes queued for sending/completion to the network\n * \tdevice hardware queue. @bytes should be a good approximation and should\n * \texactly match netdev_completed_queue() @bytes\n */\nstatic inline void netdev_sent_queue(struct net_device *dev, unsigned int bytes)\n{\n\tnetdev_tx_sent_queue(netdev_get_tx_queue(dev, 0), bytes);\n}\n\nstatic inline bool __netdev_sent_queue(struct net_device *dev,\n\t\t\t\t       unsigned int bytes,\n\t\t\t\t       bool xmit_more)\n{\n\treturn __netdev_tx_sent_queue(netdev_get_tx_queue(dev, 0), bytes,\n\t\t\t\t      xmit_more);\n}\n\nstatic inline void netdev_tx_completed_queue(struct netdev_queue *dev_queue,\n\t\t\t\t\t     unsigned int pkts, unsigned int bytes)\n{\n#ifdef CONFIG_BQL\n\tif (unlikely(!bytes))\n\t\treturn;\n\n\tdql_completed(&dev_queue->dql, bytes);\n\n\t/*\n\t * Without the memory barrier there is a small possiblity that\n\t * netdev_tx_sent_queue will miss the update and cause the queue to\n\t * be stopped forever\n\t */\n\tsmp_mb();\n\n\tif (unlikely(dql_avail(&dev_queue->dql) < 0))\n\t\treturn;\n\n\tif (test_and_clear_bit(__QUEUE_STATE_STACK_XOFF, &dev_queue->state))\n\t\tnetif_schedule_queue(dev_queue);\n#endif\n}\n\n/**\n * \tnetdev_completed_queue - report bytes and packets completed by device\n * \t@dev: network device\n * \t@pkts: actual number of packets sent over the medium\n * \t@bytes: actual number of bytes sent over the medium\n *\n * \tReport the number of bytes and packets transmitted by the network device\n * \thardware queue over the physical medium, @bytes must exactly match the\n * \t@bytes amount passed to netdev_sent_queue()\n */\nstatic inline void netdev_completed_queue(struct net_device *dev,\n\t\t\t\t\t  unsigned int pkts, unsigned int bytes)\n{\n\tnetdev_tx_completed_queue(netdev_get_tx_queue(dev, 0), pkts, bytes);\n}\n\nstatic inline void netdev_tx_reset_queue(struct netdev_queue *q)\n{\n#ifdef CONFIG_BQL\n\tclear_bit(__QUEUE_STATE_STACK_XOFF, &q->state);\n\tdql_reset(&q->dql);\n#endif\n}\n\n/**\n * \tnetdev_reset_queue - reset the packets and bytes count of a network device\n * \t@dev_queue: network device\n *\n * \tReset the bytes and packet count of a network device and clear the\n * \tsoftware flow control OFF bit for this network device\n */\nstatic inline void netdev_reset_queue(struct net_device *dev_queue)\n{\n\tnetdev_tx_reset_queue(netdev_get_tx_queue(dev_queue, 0));\n}\n\n/**\n * \tnetdev_cap_txqueue - check if selected tx queue exceeds device queues\n * \t@dev: network device\n * \t@queue_index: given tx queue index\n *\n * \tReturns 0 if given tx queue index >= number of device tx queues,\n * \totherwise returns the originally passed tx queue index.\n */\nstatic inline u16 netdev_cap_txqueue(struct net_device *dev, u16 queue_index)\n{\n\tif (unlikely(queue_index >= dev->real_num_tx_queues)) {\n\t\tnet_warn_ratelimited(\"%s selects TX queue %d, but real number of TX queues is %d\\n\",\n\t\t\t\t     dev->name, queue_index,\n\t\t\t\t     dev->real_num_tx_queues);\n\t\treturn 0;\n\t}\n\n\treturn queue_index;\n}\n\n/**\n *\tnetif_running - test if up\n *\t@dev: network device\n *\n *\tTest if the device has been brought up.\n */\nstatic inline bool netif_running(const struct net_device *dev)\n{\n\treturn test_bit(__LINK_STATE_START, &dev->state);\n}\n\n/*\n * Routines to manage the subqueues on a device.  We only need start,\n * stop, and a check if it's stopped.  All other device management is\n * done at the overall netdevice level.\n * Also test the device if we're multiqueue.\n */\n\n/**\n *\tnetif_start_subqueue - allow sending packets on subqueue\n *\t@dev: network device\n *\t@queue_index: sub queue index\n *\n * Start individual transmit queue of a device with multiple transmit queues.\n */\nstatic inline void netif_start_subqueue(struct net_device *dev, u16 queue_index)\n{\n\tstruct netdev_queue *txq = netdev_get_tx_queue(dev, queue_index);\n\n\tnetif_tx_start_queue(txq);\n}\n\n/**\n *\tnetif_stop_subqueue - stop sending packets on subqueue\n *\t@dev: network device\n *\t@queue_index: sub queue index\n *\n * Stop individual transmit queue of a device with multiple transmit queues.\n */\nstatic inline void netif_stop_subqueue(struct net_device *dev, u16 queue_index)\n{\n\tstruct netdev_queue *txq = netdev_get_tx_queue(dev, queue_index);\n\tnetif_tx_stop_queue(txq);\n}\n\n/**\n *\t__netif_subqueue_stopped - test status of subqueue\n *\t@dev: network device\n *\t@queue_index: sub queue index\n *\n * Check individual transmit queue of a device with multiple transmit queues.\n */\nstatic inline bool __netif_subqueue_stopped(const struct net_device *dev,\n\t\t\t\t\t    u16 queue_index)\n{\n\tstruct netdev_queue *txq = netdev_get_tx_queue(dev, queue_index);\n\n\treturn netif_tx_queue_stopped(txq);\n}\n\n/**\n *\tnetif_subqueue_stopped - test status of subqueue\n *\t@dev: network device\n *\t@skb: sub queue buffer pointer\n *\n * Check individual transmit queue of a device with multiple transmit queues.\n */\nstatic inline bool netif_subqueue_stopped(const struct net_device *dev,\n\t\t\t\t\t  struct sk_buff *skb)\n{\n\treturn __netif_subqueue_stopped(dev, skb_get_queue_mapping(skb));\n}\n\n/**\n *\tnetif_wake_subqueue - allow sending packets on subqueue\n *\t@dev: network device\n *\t@queue_index: sub queue index\n *\n * Resume individual transmit queue of a device with multiple transmit queues.\n */\nstatic inline void netif_wake_subqueue(struct net_device *dev, u16 queue_index)\n{\n\tstruct netdev_queue *txq = netdev_get_tx_queue(dev, queue_index);\n\n\tnetif_tx_wake_queue(txq);\n}\n\n#ifdef CONFIG_XPS\nint netif_set_xps_queue(struct net_device *dev, const struct cpumask *mask,\n\t\t\tu16 index);\nint __netif_set_xps_queue(struct net_device *dev, const unsigned long *mask,\n\t\t\t  u16 index, bool is_rxqs_map);\n\n/**\n *\tnetif_attr_test_mask - Test a CPU or Rx queue set in a mask\n *\t@j: CPU/Rx queue index\n *\t@mask: bitmask of all cpus/rx queues\n *\t@nr_bits: number of bits in the bitmask\n *\n * Test if a CPU or Rx queue index is set in a mask of all CPU/Rx queues.\n */\nstatic inline bool netif_attr_test_mask(unsigned long j,\n\t\t\t\t\tconst unsigned long *mask,\n\t\t\t\t\tunsigned int nr_bits)\n{\n\tcpu_max_bits_warn(j, nr_bits);\n\treturn test_bit(j, mask);\n}\n\n/**\n *\tnetif_attr_test_online - Test for online CPU/Rx queue\n *\t@j: CPU/Rx queue index\n *\t@online_mask: bitmask for CPUs/Rx queues that are online\n *\t@nr_bits: number of bits in the bitmask\n *\n * Returns true if a CPU/Rx queue is online.\n */\nstatic inline bool netif_attr_test_online(unsigned long j,\n\t\t\t\t\t  const unsigned long *online_mask,\n\t\t\t\t\t  unsigned int nr_bits)\n{\n\tcpu_max_bits_warn(j, nr_bits);\n\n\tif (online_mask)\n\t\treturn test_bit(j, online_mask);\n\n\treturn (j < nr_bits);\n}\n\n/**\n *\tnetif_attrmask_next - get the next CPU/Rx queue in a cpu/Rx queues mask\n *\t@n: CPU/Rx queue index\n *\t@srcp: the cpumask/Rx queue mask pointer\n *\t@nr_bits: number of bits in the bitmask\n *\n * Returns >= nr_bits if no further CPUs/Rx queues set.\n */\nstatic inline unsigned int netif_attrmask_next(int n, const unsigned long *srcp,\n\t\t\t\t\t       unsigned int nr_bits)\n{\n\t/* -1 is a legal arg here. */\n\tif (n != -1)\n\t\tcpu_max_bits_warn(n, nr_bits);\n\n\tif (srcp)\n\t\treturn find_next_bit(srcp, nr_bits, n + 1);\n\n\treturn n + 1;\n}\n\n/**\n *\tnetif_attrmask_next_and - get the next CPU/Rx queue in \\*src1p & \\*src2p\n *\t@n: CPU/Rx queue index\n *\t@src1p: the first CPUs/Rx queues mask pointer\n *\t@src2p: the second CPUs/Rx queues mask pointer\n *\t@nr_bits: number of bits in the bitmask\n *\n * Returns >= nr_bits if no further CPUs/Rx queues set in both.\n */\nstatic inline int netif_attrmask_next_and(int n, const unsigned long *src1p,\n\t\t\t\t\t  const unsigned long *src2p,\n\t\t\t\t\t  unsigned int nr_bits)\n{\n\t/* -1 is a legal arg here. */\n\tif (n != -1)\n\t\tcpu_max_bits_warn(n, nr_bits);\n\n\tif (src1p && src2p)\n\t\treturn find_next_and_bit(src1p, src2p, nr_bits, n + 1);\n\telse if (src1p)\n\t\treturn find_next_bit(src1p, nr_bits, n + 1);\n\telse if (src2p)\n\t\treturn find_next_bit(src2p, nr_bits, n + 1);\n\n\treturn n + 1;\n}\n#else\nstatic inline int netif_set_xps_queue(struct net_device *dev,\n\t\t\t\t      const struct cpumask *mask,\n\t\t\t\t      u16 index)\n{\n\treturn 0;\n}\n\nstatic inline int __netif_set_xps_queue(struct net_device *dev,\n\t\t\t\t\tconst unsigned long *mask,\n\t\t\t\t\tu16 index, bool is_rxqs_map)\n{\n\treturn 0;\n}\n#endif\n\n/**\n *\tnetif_is_multiqueue - test if device has multiple transmit queues\n *\t@dev: network device\n *\n * Check if device has multiple transmit queues\n */\nstatic inline bool netif_is_multiqueue(const struct net_device *dev)\n{\n\treturn dev->num_tx_queues > 1;\n}\n\nint netif_set_real_num_tx_queues(struct net_device *dev, unsigned int txq);\n\n#ifdef CONFIG_SYSFS\nint netif_set_real_num_rx_queues(struct net_device *dev, unsigned int rxq);\n#else\nstatic inline int netif_set_real_num_rx_queues(struct net_device *dev,\n\t\t\t\t\t\tunsigned int rxqs)\n{\n\tdev->real_num_rx_queues = rxqs;\n\treturn 0;\n}\n#endif\n\nstatic inline struct netdev_rx_queue *\n__netif_get_rx_queue(struct net_device *dev, unsigned int rxq)\n{\n\treturn dev->_rx + rxq;\n}\n\n#ifdef CONFIG_SYSFS\nstatic inline unsigned int get_netdev_rx_queue_index(\n\t\tstruct netdev_rx_queue *queue)\n{\n\tstruct net_device *dev = queue->dev;\n\tint index = queue - dev->_rx;\n\n\tBUG_ON(index >= dev->num_rx_queues);\n\treturn index;\n}\n#endif\n\n#define DEFAULT_MAX_NUM_RSS_QUEUES\t(8)\nint netif_get_num_default_rss_queues(void);\n\nenum skb_free_reason {\n\tSKB_REASON_CONSUMED,\n\tSKB_REASON_DROPPED,\n};\n\nvoid __dev_kfree_skb_irq(struct sk_buff *skb, enum skb_free_reason reason);\nvoid __dev_kfree_skb_any(struct sk_buff *skb, enum skb_free_reason reason);\n\n/*\n * It is not allowed to call kfree_skb() or consume_skb() from hardware\n * interrupt context or with hardware interrupts being disabled.\n * (in_irq() || irqs_disabled())\n *\n * We provide four helpers that can be used in following contexts :\n *\n * dev_kfree_skb_irq(skb) when caller drops a packet from irq context,\n *  replacing kfree_skb(skb)\n *\n * dev_consume_skb_irq(skb) when caller consumes a packet from irq context.\n *  Typically used in place of consume_skb(skb) in TX completion path\n *\n * dev_kfree_skb_any(skb) when caller doesn't know its current irq context,\n *  replacing kfree_skb(skb)\n *\n * dev_consume_skb_any(skb) when caller doesn't know its current irq context,\n *  and consumed a packet. Used in place of consume_skb(skb)\n */\nstatic inline void dev_kfree_skb_irq(struct sk_buff *skb)\n{\n\t__dev_kfree_skb_irq(skb, SKB_REASON_DROPPED);\n}\n\nstatic inline void dev_consume_skb_irq(struct sk_buff *skb)\n{\n\t__dev_kfree_skb_irq(skb, SKB_REASON_CONSUMED);\n}\n\nstatic inline void dev_kfree_skb_any(struct sk_buff *skb)\n{\n\t__dev_kfree_skb_any(skb, SKB_REASON_DROPPED);\n}\n\nstatic inline void dev_consume_skb_any(struct sk_buff *skb)\n{\n\t__dev_kfree_skb_any(skb, SKB_REASON_CONSUMED);\n}\n\nvoid generic_xdp_tx(struct sk_buff *skb, struct bpf_prog *xdp_prog);\nint do_xdp_generic(struct bpf_prog *xdp_prog, struct sk_buff *skb);\nint netif_rx(struct sk_buff *skb);\nint netif_rx_ni(struct sk_buff *skb);\nint netif_rx_any_context(struct sk_buff *skb);\nint netif_receive_skb(struct sk_buff *skb);\nint netif_receive_skb_core(struct sk_buff *skb);\nvoid netif_receive_skb_list(struct list_head *head);\ngro_result_t napi_gro_receive(struct napi_struct *napi, struct sk_buff *skb);\nvoid napi_gro_flush(struct napi_struct *napi, bool flush_old);\nstruct sk_buff *napi_get_frags(struct napi_struct *napi);\ngro_result_t napi_gro_frags(struct napi_struct *napi);\nstruct packet_offload *gro_find_receive_by_type(__be16 type);\nstruct packet_offload *gro_find_complete_by_type(__be16 type);\n\nstatic inline void napi_free_frags(struct napi_struct *napi)\n{\n\tkfree_skb(napi->skb);\n\tnapi->skb = NULL;\n}\n\nbool netdev_is_rx_handler_busy(struct net_device *dev);\nint netdev_rx_handler_register(struct net_device *dev,\n\t\t\t       rx_handler_func_t *rx_handler,\n\t\t\t       void *rx_handler_data);\nvoid netdev_rx_handler_unregister(struct net_device *dev);\n\nbool dev_valid_name(const char *name);\nint dev_ioctl(struct net *net, unsigned int cmd, struct ifreq *ifr,\n\t\tbool *need_copyout);\nint dev_ifconf(struct net *net, struct ifconf *, int);\nint dev_ethtool(struct net *net, struct ifreq *);\nunsigned int dev_get_flags(const struct net_device *);\nint __dev_change_flags(struct net_device *dev, unsigned int flags,\n\t\t       struct netlink_ext_ack *extack);\nint dev_change_flags(struct net_device *dev, unsigned int flags,\n\t\t     struct netlink_ext_ack *extack);\nvoid __dev_notify_flags(struct net_device *, unsigned int old_flags,\n\t\t\tunsigned int gchanges);\nint dev_change_name(struct net_device *, const char *);\nint dev_set_alias(struct net_device *, const char *, size_t);\nint dev_get_alias(const struct net_device *, char *, size_t);\nint dev_change_net_namespace(struct net_device *, struct net *, const char *);\nint __dev_set_mtu(struct net_device *, int);\nint dev_validate_mtu(struct net_device *dev, int mtu,\n\t\t     struct netlink_ext_ack *extack);\nint dev_set_mtu_ext(struct net_device *dev, int mtu,\n\t\t    struct netlink_ext_ack *extack);\nint dev_set_mtu(struct net_device *, int);\nint dev_change_tx_queue_len(struct net_device *, unsigned long);\nvoid dev_set_group(struct net_device *, int);\nint dev_pre_changeaddr_notify(struct net_device *dev, const char *addr,\n\t\t\t      struct netlink_ext_ack *extack);\nint dev_set_mac_address(struct net_device *dev, struct sockaddr *sa,\n\t\t\tstruct netlink_ext_ack *extack);\nint dev_set_mac_address_user(struct net_device *dev, struct sockaddr *sa,\n\t\t\t     struct netlink_ext_ack *extack);\nint dev_get_mac_address(struct sockaddr *sa, struct net *net, char *dev_name);\nint dev_change_carrier(struct net_device *, bool new_carrier);\nint dev_get_phys_port_id(struct net_device *dev,\n\t\t\t struct netdev_phys_item_id *ppid);\nint dev_get_phys_port_name(struct net_device *dev,\n\t\t\t   char *name, size_t len);\nint dev_get_port_parent_id(struct net_device *dev,\n\t\t\t   struct netdev_phys_item_id *ppid, bool recurse);\nbool netdev_port_same_parent_id(struct net_device *a, struct net_device *b);\nint dev_change_proto_down(struct net_device *dev, bool proto_down);\nint dev_change_proto_down_generic(struct net_device *dev, bool proto_down);\nvoid dev_change_proto_down_reason(struct net_device *dev, unsigned long mask,\n\t\t\t\t  u32 value);\nstruct sk_buff *validate_xmit_skb_list(struct sk_buff *skb, struct net_device *dev, bool *again);\nstruct sk_buff *dev_hard_start_xmit(struct sk_buff *skb, struct net_device *dev,\n\t\t\t\t    struct netdev_queue *txq, int *ret);\n\ntypedef int (*bpf_op_t)(struct net_device *dev, struct netdev_bpf *bpf);\nint dev_change_xdp_fd(struct net_device *dev, struct netlink_ext_ack *extack,\n\t\t      int fd, int expected_fd, u32 flags);\nint bpf_xdp_link_attach(const union bpf_attr *attr, struct bpf_prog *prog);\nu32 dev_xdp_prog_id(struct net_device *dev, enum bpf_xdp_mode mode);\n\nint __dev_forward_skb(struct net_device *dev, struct sk_buff *skb);\nint dev_forward_skb(struct net_device *dev, struct sk_buff *skb);\nint dev_forward_skb_nomtu(struct net_device *dev, struct sk_buff *skb);\nbool is_skb_forwardable(const struct net_device *dev,\n\t\t\tconst struct sk_buff *skb);\n\nstatic __always_inline bool __is_skb_forwardable(const struct net_device *dev,\n\t\t\t\t\t\t const struct sk_buff *skb,\n\t\t\t\t\t\t const bool check_mtu)\n{\n\tconst u32 vlan_hdr_len = 4; /* VLAN_HLEN */\n\tunsigned int len;\n\n\tif (!(dev->flags & IFF_UP))\n\t\treturn false;\n\n\tif (!check_mtu)\n\t\treturn true;\n\n\tlen = dev->mtu + dev->hard_header_len + vlan_hdr_len;\n\tif (skb->len <= len)\n\t\treturn true;\n\n\t/* if TSO is enabled, we don't care about the length as the packet\n\t * could be forwarded without being segmented before\n\t */\n\tif (skb_is_gso(skb))\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic __always_inline int ____dev_forward_skb(struct net_device *dev,\n\t\t\t\t\t       struct sk_buff *skb,\n\t\t\t\t\t       const bool check_mtu)\n{\n\tif (skb_orphan_frags(skb, GFP_ATOMIC) ||\n\t    unlikely(!__is_skb_forwardable(dev, skb, check_mtu))) {\n\t\tatomic_long_inc(&dev->rx_dropped);\n\t\tkfree_skb(skb);\n\t\treturn NET_RX_DROP;\n\t}\n\n\tskb_scrub_packet(skb, true);\n\tskb->priority = 0;\n\treturn 0;\n}\n\nbool dev_nit_active(struct net_device *dev);\nvoid dev_queue_xmit_nit(struct sk_buff *skb, struct net_device *dev);\n\nextern int\t\tnetdev_budget;\nextern unsigned int\tnetdev_budget_usecs;\n\n/* Called by rtnetlink.c:rtnl_unlock() */\nvoid netdev_run_todo(void);\n\n/**\n *\tdev_put - release reference to device\n *\t@dev: network device\n *\n * Release reference to device to allow it to be freed.\n */\nstatic inline void dev_put(struct net_device *dev)\n{\n\tthis_cpu_dec(*dev->pcpu_refcnt);\n}\n\n/**\n *\tdev_hold - get reference to device\n *\t@dev: network device\n *\n * Hold reference to device to keep it from being freed.\n */\nstatic inline void dev_hold(struct net_device *dev)\n{\n\tthis_cpu_inc(*dev->pcpu_refcnt);\n}\n\n/* Carrier loss detection, dial on demand. The functions netif_carrier_on\n * and _off may be called from IRQ context, but it is caller\n * who is responsible for serialization of these calls.\n *\n * The name carrier is inappropriate, these functions should really be\n * called netif_lowerlayer_*() because they represent the state of any\n * kind of lower layer not just hardware media.\n */\n\nvoid linkwatch_init_dev(struct net_device *dev);\nvoid linkwatch_fire_event(struct net_device *dev);\nvoid linkwatch_forget_dev(struct net_device *dev);\n\n/**\n *\tnetif_carrier_ok - test if carrier present\n *\t@dev: network device\n *\n * Check if carrier is present on device\n */\nstatic inline bool netif_carrier_ok(const struct net_device *dev)\n{\n\treturn !test_bit(__LINK_STATE_NOCARRIER, &dev->state);\n}\n\nunsigned long dev_trans_start(struct net_device *dev);\n\nvoid __netdev_watchdog_up(struct net_device *dev);\n\nvoid netif_carrier_on(struct net_device *dev);\n\nvoid netif_carrier_off(struct net_device *dev);\n\n/**\n *\tnetif_dormant_on - mark device as dormant.\n *\t@dev: network device\n *\n * Mark device as dormant (as per RFC2863).\n *\n * The dormant state indicates that the relevant interface is not\n * actually in a condition to pass packets (i.e., it is not 'up') but is\n * in a \"pending\" state, waiting for some external event.  For \"on-\n * demand\" interfaces, this new state identifies the situation where the\n * interface is waiting for events to place it in the up state.\n */\nstatic inline void netif_dormant_on(struct net_device *dev)\n{\n\tif (!test_and_set_bit(__LINK_STATE_DORMANT, &dev->state))\n\t\tlinkwatch_fire_event(dev);\n}\n\n/**\n *\tnetif_dormant_off - set device as not dormant.\n *\t@dev: network device\n *\n * Device is not in dormant state.\n */\nstatic inline void netif_dormant_off(struct net_device *dev)\n{\n\tif (test_and_clear_bit(__LINK_STATE_DORMANT, &dev->state))\n\t\tlinkwatch_fire_event(dev);\n}\n\n/**\n *\tnetif_dormant - test if device is dormant\n *\t@dev: network device\n *\n * Check if device is dormant.\n */\nstatic inline bool netif_dormant(const struct net_device *dev)\n{\n\treturn test_bit(__LINK_STATE_DORMANT, &dev->state);\n}\n\n\n/**\n *\tnetif_testing_on - mark device as under test.\n *\t@dev: network device\n *\n * Mark device as under test (as per RFC2863).\n *\n * The testing state indicates that some test(s) must be performed on\n * the interface. After completion, of the test, the interface state\n * will change to up, dormant, or down, as appropriate.\n */\nstatic inline void netif_testing_on(struct net_device *dev)\n{\n\tif (!test_and_set_bit(__LINK_STATE_TESTING, &dev->state))\n\t\tlinkwatch_fire_event(dev);\n}\n\n/**\n *\tnetif_testing_off - set device as not under test.\n *\t@dev: network device\n *\n * Device is not in testing state.\n */\nstatic inline void netif_testing_off(struct net_device *dev)\n{\n\tif (test_and_clear_bit(__LINK_STATE_TESTING, &dev->state))\n\t\tlinkwatch_fire_event(dev);\n}\n\n/**\n *\tnetif_testing - test if device is under test\n *\t@dev: network device\n *\n * Check if device is under test\n */\nstatic inline bool netif_testing(const struct net_device *dev)\n{\n\treturn test_bit(__LINK_STATE_TESTING, &dev->state);\n}\n\n\n/**\n *\tnetif_oper_up - test if device is operational\n *\t@dev: network device\n *\n * Check if carrier is operational\n */\nstatic inline bool netif_oper_up(const struct net_device *dev)\n{\n\treturn (dev->operstate == IF_OPER_UP ||\n\t\tdev->operstate == IF_OPER_UNKNOWN /* backward compat */);\n}\n\n/**\n *\tnetif_device_present - is device available or removed\n *\t@dev: network device\n *\n * Check if device has not been removed from system.\n */\nstatic inline bool netif_device_present(const struct net_device *dev)\n{\n\treturn test_bit(__LINK_STATE_PRESENT, &dev->state);\n}\n\nvoid netif_device_detach(struct net_device *dev);\n\nvoid netif_device_attach(struct net_device *dev);\n\n/*\n * Network interface message level settings\n */\n\nenum {\n\tNETIF_MSG_DRV_BIT,\n\tNETIF_MSG_PROBE_BIT,\n\tNETIF_MSG_LINK_BIT,\n\tNETIF_MSG_TIMER_BIT,\n\tNETIF_MSG_IFDOWN_BIT,\n\tNETIF_MSG_IFUP_BIT,\n\tNETIF_MSG_RX_ERR_BIT,\n\tNETIF_MSG_TX_ERR_BIT,\n\tNETIF_MSG_TX_QUEUED_BIT,\n\tNETIF_MSG_INTR_BIT,\n\tNETIF_MSG_TX_DONE_BIT,\n\tNETIF_MSG_RX_STATUS_BIT,\n\tNETIF_MSG_PKTDATA_BIT,\n\tNETIF_MSG_HW_BIT,\n\tNETIF_MSG_WOL_BIT,\n\n\t/* When you add a new bit above, update netif_msg_class_names array\n\t * in net/ethtool/common.c\n\t */\n\tNETIF_MSG_CLASS_COUNT,\n};\n/* Both ethtool_ops interface and internal driver implementation use u32 */\nstatic_assert(NETIF_MSG_CLASS_COUNT <= 32);\n\n#define __NETIF_MSG_BIT(bit)\t((u32)1 << (bit))\n#define __NETIF_MSG(name)\t__NETIF_MSG_BIT(NETIF_MSG_ ## name ## _BIT)\n\n#define NETIF_MSG_DRV\t\t__NETIF_MSG(DRV)\n#define NETIF_MSG_PROBE\t\t__NETIF_MSG(PROBE)\n#define NETIF_MSG_LINK\t\t__NETIF_MSG(LINK)\n#define NETIF_MSG_TIMER\t\t__NETIF_MSG(TIMER)\n#define NETIF_MSG_IFDOWN\t__NETIF_MSG(IFDOWN)\n#define NETIF_MSG_IFUP\t\t__NETIF_MSG(IFUP)\n#define NETIF_MSG_RX_ERR\t__NETIF_MSG(RX_ERR)\n#define NETIF_MSG_TX_ERR\t__NETIF_MSG(TX_ERR)\n#define NETIF_MSG_TX_QUEUED\t__NETIF_MSG(TX_QUEUED)\n#define NETIF_MSG_INTR\t\t__NETIF_MSG(INTR)\n#define NETIF_MSG_TX_DONE\t__NETIF_MSG(TX_DONE)\n#define NETIF_MSG_RX_STATUS\t__NETIF_MSG(RX_STATUS)\n#define NETIF_MSG_PKTDATA\t__NETIF_MSG(PKTDATA)\n#define NETIF_MSG_HW\t\t__NETIF_MSG(HW)\n#define NETIF_MSG_WOL\t\t__NETIF_MSG(WOL)\n\n#define netif_msg_drv(p)\t((p)->msg_enable & NETIF_MSG_DRV)\n#define netif_msg_probe(p)\t((p)->msg_enable & NETIF_MSG_PROBE)\n#define netif_msg_link(p)\t((p)->msg_enable & NETIF_MSG_LINK)\n#define netif_msg_timer(p)\t((p)->msg_enable & NETIF_MSG_TIMER)\n#define netif_msg_ifdown(p)\t((p)->msg_enable & NETIF_MSG_IFDOWN)\n#define netif_msg_ifup(p)\t((p)->msg_enable & NETIF_MSG_IFUP)\n#define netif_msg_rx_err(p)\t((p)->msg_enable & NETIF_MSG_RX_ERR)\n#define netif_msg_tx_err(p)\t((p)->msg_enable & NETIF_MSG_TX_ERR)\n#define netif_msg_tx_queued(p)\t((p)->msg_enable & NETIF_MSG_TX_QUEUED)\n#define netif_msg_intr(p)\t((p)->msg_enable & NETIF_MSG_INTR)\n#define netif_msg_tx_done(p)\t((p)->msg_enable & NETIF_MSG_TX_DONE)\n#define netif_msg_rx_status(p)\t((p)->msg_enable & NETIF_MSG_RX_STATUS)\n#define netif_msg_pktdata(p)\t((p)->msg_enable & NETIF_MSG_PKTDATA)\n#define netif_msg_hw(p)\t\t((p)->msg_enable & NETIF_MSG_HW)\n#define netif_msg_wol(p)\t((p)->msg_enable & NETIF_MSG_WOL)\n\nstatic inline u32 netif_msg_init(int debug_value, int default_msg_enable_bits)\n{\n\t/* use default */\n\tif (debug_value < 0 || debug_value >= (sizeof(u32) * 8))\n\t\treturn default_msg_enable_bits;\n\tif (debug_value == 0)\t/* no output */\n\t\treturn 0;\n\t/* set low N bits */\n\treturn (1U << debug_value) - 1;\n}\n\nstatic inline void __netif_tx_lock(struct netdev_queue *txq, int cpu)\n{\n\tspin_lock(&txq->_xmit_lock);\n\ttxq->xmit_lock_owner = cpu;\n}\n\nstatic inline bool __netif_tx_acquire(struct netdev_queue *txq)\n{\n\t__acquire(&txq->_xmit_lock);\n\treturn true;\n}\n\nstatic inline void __netif_tx_release(struct netdev_queue *txq)\n{\n\t__release(&txq->_xmit_lock);\n}\n\nstatic inline void __netif_tx_lock_bh(struct netdev_queue *txq)\n{\n\tspin_lock_bh(&txq->_xmit_lock);\n\ttxq->xmit_lock_owner = smp_processor_id();\n}\n\nstatic inline bool __netif_tx_trylock(struct netdev_queue *txq)\n{\n\tbool ok = spin_trylock(&txq->_xmit_lock);\n\tif (likely(ok))\n\t\ttxq->xmit_lock_owner = smp_processor_id();\n\treturn ok;\n}\n\nstatic inline void __netif_tx_unlock(struct netdev_queue *txq)\n{\n\ttxq->xmit_lock_owner = -1;\n\tspin_unlock(&txq->_xmit_lock);\n}\n\nstatic inline void __netif_tx_unlock_bh(struct netdev_queue *txq)\n{\n\ttxq->xmit_lock_owner = -1;\n\tspin_unlock_bh(&txq->_xmit_lock);\n}\n\nstatic inline void txq_trans_update(struct netdev_queue *txq)\n{\n\tif (txq->xmit_lock_owner != -1)\n\t\ttxq->trans_start = jiffies;\n}\n\n/* legacy drivers only, netdev_start_xmit() sets txq->trans_start */\nstatic inline void netif_trans_update(struct net_device *dev)\n{\n\tstruct netdev_queue *txq = netdev_get_tx_queue(dev, 0);\n\n\tif (txq->trans_start != jiffies)\n\t\ttxq->trans_start = jiffies;\n}\n\n/**\n *\tnetif_tx_lock - grab network device transmit lock\n *\t@dev: network device\n *\n * Get network device transmit lock\n */\nstatic inline void netif_tx_lock(struct net_device *dev)\n{\n\tunsigned int i;\n\tint cpu;\n\n\tspin_lock(&dev->tx_global_lock);\n\tcpu = smp_processor_id();\n\tfor (i = 0; i < dev->num_tx_queues; i++) {\n\t\tstruct netdev_queue *txq = netdev_get_tx_queue(dev, i);\n\n\t\t/* We are the only thread of execution doing a\n\t\t * freeze, but we have to grab the _xmit_lock in\n\t\t * order to synchronize with threads which are in\n\t\t * the ->hard_start_xmit() handler and already\n\t\t * checked the frozen bit.\n\t\t */\n\t\t__netif_tx_lock(txq, cpu);\n\t\tset_bit(__QUEUE_STATE_FROZEN, &txq->state);\n\t\t__netif_tx_unlock(txq);\n\t}\n}\n\nstatic inline void netif_tx_lock_bh(struct net_device *dev)\n{\n\tlocal_bh_disable();\n\tnetif_tx_lock(dev);\n}\n\nstatic inline void netif_tx_unlock(struct net_device *dev)\n{\n\tunsigned int i;\n\n\tfor (i = 0; i < dev->num_tx_queues; i++) {\n\t\tstruct netdev_queue *txq = netdev_get_tx_queue(dev, i);\n\n\t\t/* No need to grab the _xmit_lock here.  If the\n\t\t * queue is not stopped for another reason, we\n\t\t * force a schedule.\n\t\t */\n\t\tclear_bit(__QUEUE_STATE_FROZEN, &txq->state);\n\t\tnetif_schedule_queue(txq);\n\t}\n\tspin_unlock(&dev->tx_global_lock);\n}\n\nstatic inline void netif_tx_unlock_bh(struct net_device *dev)\n{\n\tnetif_tx_unlock(dev);\n\tlocal_bh_enable();\n}\n\n#define HARD_TX_LOCK(dev, txq, cpu) {\t\t\t\\\n\tif ((dev->features & NETIF_F_LLTX) == 0) {\t\\\n\t\t__netif_tx_lock(txq, cpu);\t\t\\\n\t} else {\t\t\t\t\t\\\n\t\t__netif_tx_acquire(txq);\t\t\\\n\t}\t\t\t\t\t\t\\\n}\n\n#define HARD_TX_TRYLOCK(dev, txq)\t\t\t\\\n\t(((dev->features & NETIF_F_LLTX) == 0) ?\t\\\n\t\t__netif_tx_trylock(txq) :\t\t\\\n\t\t__netif_tx_acquire(txq))\n\n#define HARD_TX_UNLOCK(dev, txq) {\t\t\t\\\n\tif ((dev->features & NETIF_F_LLTX) == 0) {\t\\\n\t\t__netif_tx_unlock(txq);\t\t\t\\\n\t} else {\t\t\t\t\t\\\n\t\t__netif_tx_release(txq);\t\t\\\n\t}\t\t\t\t\t\t\\\n}\n\nstatic inline void netif_tx_disable(struct net_device *dev)\n{\n\tunsigned int i;\n\tint cpu;\n\n\tlocal_bh_disable();\n\tcpu = smp_processor_id();\n\tspin_lock(&dev->tx_global_lock);\n\tfor (i = 0; i < dev->num_tx_queues; i++) {\n\t\tstruct netdev_queue *txq = netdev_get_tx_queue(dev, i);\n\n\t\t__netif_tx_lock(txq, cpu);\n\t\tnetif_tx_stop_queue(txq);\n\t\t__netif_tx_unlock(txq);\n\t}\n\tspin_unlock(&dev->tx_global_lock);\n\tlocal_bh_enable();\n}\n\nstatic inline void netif_addr_lock(struct net_device *dev)\n{\n\tunsigned char nest_level = 0;\n\n#ifdef CONFIG_LOCKDEP\n\tnest_level = dev->nested_level;\n#endif\n\tspin_lock_nested(&dev->addr_list_lock, nest_level);\n}\n\nstatic inline void netif_addr_lock_bh(struct net_device *dev)\n{\n\tunsigned char nest_level = 0;\n\n#ifdef CONFIG_LOCKDEP\n\tnest_level = dev->nested_level;\n#endif\n\tlocal_bh_disable();\n\tspin_lock_nested(&dev->addr_list_lock, nest_level);\n}\n\nstatic inline void netif_addr_unlock(struct net_device *dev)\n{\n\tspin_unlock(&dev->addr_list_lock);\n}\n\nstatic inline void netif_addr_unlock_bh(struct net_device *dev)\n{\n\tspin_unlock_bh(&dev->addr_list_lock);\n}\n\n/*\n * dev_addrs walker. Should be used only for read access. Call with\n * rcu_read_lock held.\n */\n#define for_each_dev_addr(dev, ha) \\\n\t\tlist_for_each_entry_rcu(ha, &dev->dev_addrs.list, list)\n\n/* These functions live elsewhere (drivers/net/net_init.c, but related) */\n\nvoid ether_setup(struct net_device *dev);\n\n/* Support for loadable net-drivers */\nstruct net_device *alloc_netdev_mqs(int sizeof_priv, const char *name,\n\t\t\t\t    unsigned char name_assign_type,\n\t\t\t\t    void (*setup)(struct net_device *),\n\t\t\t\t    unsigned int txqs, unsigned int rxqs);\n#define alloc_netdev(sizeof_priv, name, name_assign_type, setup) \\\n\talloc_netdev_mqs(sizeof_priv, name, name_assign_type, setup, 1, 1)\n\n#define alloc_netdev_mq(sizeof_priv, name, name_assign_type, setup, count) \\\n\talloc_netdev_mqs(sizeof_priv, name, name_assign_type, setup, count, \\\n\t\t\t count)\n\nint register_netdev(struct net_device *dev);\nvoid unregister_netdev(struct net_device *dev);\n\nint devm_register_netdev(struct device *dev, struct net_device *ndev);\n\n/* General hardware address lists handling functions */\nint __hw_addr_sync(struct netdev_hw_addr_list *to_list,\n\t\t   struct netdev_hw_addr_list *from_list, int addr_len);\nvoid __hw_addr_unsync(struct netdev_hw_addr_list *to_list,\n\t\t      struct netdev_hw_addr_list *from_list, int addr_len);\nint __hw_addr_sync_dev(struct netdev_hw_addr_list *list,\n\t\t       struct net_device *dev,\n\t\t       int (*sync)(struct net_device *, const unsigned char *),\n\t\t       int (*unsync)(struct net_device *,\n\t\t\t\t     const unsigned char *));\nint __hw_addr_ref_sync_dev(struct netdev_hw_addr_list *list,\n\t\t\t   struct net_device *dev,\n\t\t\t   int (*sync)(struct net_device *,\n\t\t\t\t       const unsigned char *, int),\n\t\t\t   int (*unsync)(struct net_device *,\n\t\t\t\t\t const unsigned char *, int));\nvoid __hw_addr_ref_unsync_dev(struct netdev_hw_addr_list *list,\n\t\t\t      struct net_device *dev,\n\t\t\t      int (*unsync)(struct net_device *,\n\t\t\t\t\t    const unsigned char *, int));\nvoid __hw_addr_unsync_dev(struct netdev_hw_addr_list *list,\n\t\t\t  struct net_device *dev,\n\t\t\t  int (*unsync)(struct net_device *,\n\t\t\t\t\tconst unsigned char *));\nvoid __hw_addr_init(struct netdev_hw_addr_list *list);\n\n/* Functions used for device addresses handling */\nint dev_addr_add(struct net_device *dev, const unsigned char *addr,\n\t\t unsigned char addr_type);\nint dev_addr_del(struct net_device *dev, const unsigned char *addr,\n\t\t unsigned char addr_type);\nvoid dev_addr_flush(struct net_device *dev);\nint dev_addr_init(struct net_device *dev);\n\n/* Functions used for unicast addresses handling */\nint dev_uc_add(struct net_device *dev, const unsigned char *addr);\nint dev_uc_add_excl(struct net_device *dev, const unsigned char *addr);\nint dev_uc_del(struct net_device *dev, const unsigned char *addr);\nint dev_uc_sync(struct net_device *to, struct net_device *from);\nint dev_uc_sync_multiple(struct net_device *to, struct net_device *from);\nvoid dev_uc_unsync(struct net_device *to, struct net_device *from);\nvoid dev_uc_flush(struct net_device *dev);\nvoid dev_uc_init(struct net_device *dev);\n\n/**\n *  __dev_uc_sync - Synchonize device's unicast list\n *  @dev:  device to sync\n *  @sync: function to call if address should be added\n *  @unsync: function to call if address should be removed\n *\n *  Add newly added addresses to the interface, and release\n *  addresses that have been deleted.\n */\nstatic inline int __dev_uc_sync(struct net_device *dev,\n\t\t\t\tint (*sync)(struct net_device *,\n\t\t\t\t\t    const unsigned char *),\n\t\t\t\tint (*unsync)(struct net_device *,\n\t\t\t\t\t      const unsigned char *))\n{\n\treturn __hw_addr_sync_dev(&dev->uc, dev, sync, unsync);\n}\n\n/**\n *  __dev_uc_unsync - Remove synchronized addresses from device\n *  @dev:  device to sync\n *  @unsync: function to call if address should be removed\n *\n *  Remove all addresses that were added to the device by dev_uc_sync().\n */\nstatic inline void __dev_uc_unsync(struct net_device *dev,\n\t\t\t\t   int (*unsync)(struct net_device *,\n\t\t\t\t\t\t const unsigned char *))\n{\n\t__hw_addr_unsync_dev(&dev->uc, dev, unsync);\n}\n\n/* Functions used for multicast addresses handling */\nint dev_mc_add(struct net_device *dev, const unsigned char *addr);\nint dev_mc_add_global(struct net_device *dev, const unsigned char *addr);\nint dev_mc_add_excl(struct net_device *dev, const unsigned char *addr);\nint dev_mc_del(struct net_device *dev, const unsigned char *addr);\nint dev_mc_del_global(struct net_device *dev, const unsigned char *addr);\nint dev_mc_sync(struct net_device *to, struct net_device *from);\nint dev_mc_sync_multiple(struct net_device *to, struct net_device *from);\nvoid dev_mc_unsync(struct net_device *to, struct net_device *from);\nvoid dev_mc_flush(struct net_device *dev);\nvoid dev_mc_init(struct net_device *dev);\n\n/**\n *  __dev_mc_sync - Synchonize device's multicast list\n *  @dev:  device to sync\n *  @sync: function to call if address should be added\n *  @unsync: function to call if address should be removed\n *\n *  Add newly added addresses to the interface, and release\n *  addresses that have been deleted.\n */\nstatic inline int __dev_mc_sync(struct net_device *dev,\n\t\t\t\tint (*sync)(struct net_device *,\n\t\t\t\t\t    const unsigned char *),\n\t\t\t\tint (*unsync)(struct net_device *,\n\t\t\t\t\t      const unsigned char *))\n{\n\treturn __hw_addr_sync_dev(&dev->mc, dev, sync, unsync);\n}\n\n/**\n *  __dev_mc_unsync - Remove synchronized addresses from device\n *  @dev:  device to sync\n *  @unsync: function to call if address should be removed\n *\n *  Remove all addresses that were added to the device by dev_mc_sync().\n */\nstatic inline void __dev_mc_unsync(struct net_device *dev,\n\t\t\t\t   int (*unsync)(struct net_device *,\n\t\t\t\t\t\t const unsigned char *))\n{\n\t__hw_addr_unsync_dev(&dev->mc, dev, unsync);\n}\n\n/* Functions used for secondary unicast and multicast support */\nvoid dev_set_rx_mode(struct net_device *dev);\nvoid __dev_set_rx_mode(struct net_device *dev);\nint dev_set_promiscuity(struct net_device *dev, int inc);\nint dev_set_allmulti(struct net_device *dev, int inc);\nvoid netdev_state_change(struct net_device *dev);\nvoid __netdev_notify_peers(struct net_device *dev);\nvoid netdev_notify_peers(struct net_device *dev);\nvoid netdev_features_change(struct net_device *dev);\n/* Load a device via the kmod */\nvoid dev_load(struct net *net, const char *name);\nstruct rtnl_link_stats64 *dev_get_stats(struct net_device *dev,\n\t\t\t\t\tstruct rtnl_link_stats64 *storage);\nvoid netdev_stats_to_stats64(struct rtnl_link_stats64 *stats64,\n\t\t\t     const struct net_device_stats *netdev_stats);\nvoid dev_fetch_sw_netstats(struct rtnl_link_stats64 *s,\n\t\t\t   const struct pcpu_sw_netstats __percpu *netstats);\nvoid dev_get_tstats64(struct net_device *dev, struct rtnl_link_stats64 *s);\n\nextern int\t\tnetdev_max_backlog;\nextern int\t\tnetdev_tstamp_prequeue;\nextern int\t\tweight_p;\nextern int\t\tdev_weight_rx_bias;\nextern int\t\tdev_weight_tx_bias;\nextern int\t\tdev_rx_weight;\nextern int\t\tdev_tx_weight;\nextern int\t\tgro_normal_batch;\n\nenum {\n\tNESTED_SYNC_IMM_BIT,\n\tNESTED_SYNC_TODO_BIT,\n};\n\n#define __NESTED_SYNC_BIT(bit)\t((u32)1 << (bit))\n#define __NESTED_SYNC(name)\t__NESTED_SYNC_BIT(NESTED_SYNC_ ## name ## _BIT)\n\n#define NESTED_SYNC_IMM\t\t__NESTED_SYNC(IMM)\n#define NESTED_SYNC_TODO\t__NESTED_SYNC(TODO)\n\nstruct netdev_nested_priv {\n\tunsigned char flags;\n\tvoid *data;\n};\n\nbool netdev_has_upper_dev(struct net_device *dev, struct net_device *upper_dev);\nstruct net_device *netdev_upper_get_next_dev_rcu(struct net_device *dev,\n\t\t\t\t\t\t     struct list_head **iter);\nstruct net_device *netdev_all_upper_get_next_dev_rcu(struct net_device *dev,\n\t\t\t\t\t\t     struct list_head **iter);\n\n#ifdef CONFIG_LOCKDEP\nstatic LIST_HEAD(net_unlink_list);\n\nstatic inline void net_unlink_todo(struct net_device *dev)\n{\n\tif (list_empty(&dev->unlink_list))\n\t\tlist_add_tail(&dev->unlink_list, &net_unlink_list);\n}\n#endif\n\n/* iterate through upper list, must be called under RCU read lock */\n#define netdev_for_each_upper_dev_rcu(dev, updev, iter) \\\n\tfor (iter = &(dev)->adj_list.upper, \\\n\t     updev = netdev_upper_get_next_dev_rcu(dev, &(iter)); \\\n\t     updev; \\\n\t     updev = netdev_upper_get_next_dev_rcu(dev, &(iter)))\n\nint netdev_walk_all_upper_dev_rcu(struct net_device *dev,\n\t\t\t\t  int (*fn)(struct net_device *upper_dev,\n\t\t\t\t\t    struct netdev_nested_priv *priv),\n\t\t\t\t  struct netdev_nested_priv *priv);\n\nbool netdev_has_upper_dev_all_rcu(struct net_device *dev,\n\t\t\t\t  struct net_device *upper_dev);\n\nbool netdev_has_any_upper_dev(struct net_device *dev);\n\nvoid *netdev_lower_get_next_private(struct net_device *dev,\n\t\t\t\t    struct list_head **iter);\nvoid *netdev_lower_get_next_private_rcu(struct net_device *dev,\n\t\t\t\t\tstruct list_head **iter);\n\n#define netdev_for_each_lower_private(dev, priv, iter) \\\n\tfor (iter = (dev)->adj_list.lower.next, \\\n\t     priv = netdev_lower_get_next_private(dev, &(iter)); \\\n\t     priv; \\\n\t     priv = netdev_lower_get_next_private(dev, &(iter)))\n\n#define netdev_for_each_lower_private_rcu(dev, priv, iter) \\\n\tfor (iter = &(dev)->adj_list.lower, \\\n\t     priv = netdev_lower_get_next_private_rcu(dev, &(iter)); \\\n\t     priv; \\\n\t     priv = netdev_lower_get_next_private_rcu(dev, &(iter)))\n\nvoid *netdev_lower_get_next(struct net_device *dev,\n\t\t\t\tstruct list_head **iter);\n\n#define netdev_for_each_lower_dev(dev, ldev, iter) \\\n\tfor (iter = (dev)->adj_list.lower.next, \\\n\t     ldev = netdev_lower_get_next(dev, &(iter)); \\\n\t     ldev; \\\n\t     ldev = netdev_lower_get_next(dev, &(iter)))\n\nstruct net_device *netdev_next_lower_dev_rcu(struct net_device *dev,\n\t\t\t\t\t     struct list_head **iter);\nint netdev_walk_all_lower_dev(struct net_device *dev,\n\t\t\t      int (*fn)(struct net_device *lower_dev,\n\t\t\t\t\tstruct netdev_nested_priv *priv),\n\t\t\t      struct netdev_nested_priv *priv);\nint netdev_walk_all_lower_dev_rcu(struct net_device *dev,\n\t\t\t\t  int (*fn)(struct net_device *lower_dev,\n\t\t\t\t\t    struct netdev_nested_priv *priv),\n\t\t\t\t  struct netdev_nested_priv *priv);\n\nvoid *netdev_adjacent_get_private(struct list_head *adj_list);\nvoid *netdev_lower_get_first_private_rcu(struct net_device *dev);\nstruct net_device *netdev_master_upper_dev_get(struct net_device *dev);\nstruct net_device *netdev_master_upper_dev_get_rcu(struct net_device *dev);\nint netdev_upper_dev_link(struct net_device *dev, struct net_device *upper_dev,\n\t\t\t  struct netlink_ext_ack *extack);\nint netdev_master_upper_dev_link(struct net_device *dev,\n\t\t\t\t struct net_device *upper_dev,\n\t\t\t\t void *upper_priv, void *upper_info,\n\t\t\t\t struct netlink_ext_ack *extack);\nvoid netdev_upper_dev_unlink(struct net_device *dev,\n\t\t\t     struct net_device *upper_dev);\nint netdev_adjacent_change_prepare(struct net_device *old_dev,\n\t\t\t\t   struct net_device *new_dev,\n\t\t\t\t   struct net_device *dev,\n\t\t\t\t   struct netlink_ext_ack *extack);\nvoid netdev_adjacent_change_commit(struct net_device *old_dev,\n\t\t\t\t   struct net_device *new_dev,\n\t\t\t\t   struct net_device *dev);\nvoid netdev_adjacent_change_abort(struct net_device *old_dev,\n\t\t\t\t  struct net_device *new_dev,\n\t\t\t\t  struct net_device *dev);\nvoid netdev_adjacent_rename_links(struct net_device *dev, char *oldname);\nvoid *netdev_lower_dev_get_private(struct net_device *dev,\n\t\t\t\t   struct net_device *lower_dev);\nvoid netdev_lower_state_changed(struct net_device *lower_dev,\n\t\t\t\tvoid *lower_state_info);\n\n/* RSS keys are 40 or 52 bytes long */\n#define NETDEV_RSS_KEY_LEN 52\nextern u8 netdev_rss_key[NETDEV_RSS_KEY_LEN] __read_mostly;\nvoid netdev_rss_key_fill(void *buffer, size_t len);\n\nint skb_checksum_help(struct sk_buff *skb);\nint skb_crc32c_csum_help(struct sk_buff *skb);\nint skb_csum_hwoffload_help(struct sk_buff *skb,\n\t\t\t    const netdev_features_t features);\n\nstruct sk_buff *__skb_gso_segment(struct sk_buff *skb,\n\t\t\t\t  netdev_features_t features, bool tx_path);\nstruct sk_buff *skb_mac_gso_segment(struct sk_buff *skb,\n\t\t\t\t    netdev_features_t features);\n\nstruct netdev_bonding_info {\n\tifslave\tslave;\n\tifbond\tmaster;\n};\n\nstruct netdev_notifier_bonding_info {\n\tstruct netdev_notifier_info info; /* must be first */\n\tstruct netdev_bonding_info  bonding_info;\n};\n\nvoid netdev_bonding_info_change(struct net_device *dev,\n\t\t\t\tstruct netdev_bonding_info *bonding_info);\n\n#if IS_ENABLED(CONFIG_ETHTOOL_NETLINK)\nvoid ethtool_notify(struct net_device *dev, unsigned int cmd, const void *data);\n#else\nstatic inline void ethtool_notify(struct net_device *dev, unsigned int cmd,\n\t\t\t\t  const void *data)\n{\n}\n#endif\n\nstatic inline\nstruct sk_buff *skb_gso_segment(struct sk_buff *skb, netdev_features_t features)\n{\n\treturn __skb_gso_segment(skb, features, true);\n}\n__be16 skb_network_protocol(struct sk_buff *skb, int *depth);\n\nstatic inline bool can_checksum_protocol(netdev_features_t features,\n\t\t\t\t\t __be16 protocol)\n{\n\tif (protocol == htons(ETH_P_FCOE))\n\t\treturn !!(features & NETIF_F_FCOE_CRC);\n\n\t/* Assume this is an IP checksum (not SCTP CRC) */\n\n\tif (features & NETIF_F_HW_CSUM) {\n\t\t/* Can checksum everything */\n\t\treturn true;\n\t}\n\n\tswitch (protocol) {\n\tcase htons(ETH_P_IP):\n\t\treturn !!(features & NETIF_F_IP_CSUM);\n\tcase htons(ETH_P_IPV6):\n\t\treturn !!(features & NETIF_F_IPV6_CSUM);\n\tdefault:\n\t\treturn false;\n\t}\n}\n\n#ifdef CONFIG_BUG\nvoid netdev_rx_csum_fault(struct net_device *dev, struct sk_buff *skb);\n#else\nstatic inline void netdev_rx_csum_fault(struct net_device *dev,\n\t\t\t\t\tstruct sk_buff *skb)\n{\n}\n#endif\n/* rx skb timestamps */\nvoid net_enable_timestamp(void);\nvoid net_disable_timestamp(void);\n\n#ifdef CONFIG_PROC_FS\nint __init dev_proc_init(void);\n#else\n#define dev_proc_init() 0\n#endif\n\nstatic inline netdev_tx_t __netdev_start_xmit(const struct net_device_ops *ops,\n\t\t\t\t\t      struct sk_buff *skb, struct net_device *dev,\n\t\t\t\t\t      bool more)\n{\n\t__this_cpu_write(softnet_data.xmit.more, more);\n\treturn ops->ndo_start_xmit(skb, dev);\n}\n\nstatic inline bool netdev_xmit_more(void)\n{\n\treturn __this_cpu_read(softnet_data.xmit.more);\n}\n\nstatic inline netdev_tx_t netdev_start_xmit(struct sk_buff *skb, struct net_device *dev,\n\t\t\t\t\t    struct netdev_queue *txq, bool more)\n{\n\tconst struct net_device_ops *ops = dev->netdev_ops;\n\tnetdev_tx_t rc;\n\n\trc = __netdev_start_xmit(ops, skb, dev, more);\n\tif (rc == NETDEV_TX_OK)\n\t\ttxq_trans_update(txq);\n\n\treturn rc;\n}\n\nint netdev_class_create_file_ns(const struct class_attribute *class_attr,\n\t\t\t\tconst void *ns);\nvoid netdev_class_remove_file_ns(const struct class_attribute *class_attr,\n\t\t\t\t const void *ns);\n\nextern const struct kobj_ns_type_operations net_ns_type_operations;\n\nconst char *netdev_drivername(const struct net_device *dev);\n\nvoid linkwatch_run_queue(void);\n\nstatic inline netdev_features_t netdev_intersect_features(netdev_features_t f1,\n\t\t\t\t\t\t\t  netdev_features_t f2)\n{\n\tif ((f1 ^ f2) & NETIF_F_HW_CSUM) {\n\t\tif (f1 & NETIF_F_HW_CSUM)\n\t\t\tf1 |= (NETIF_F_IP_CSUM|NETIF_F_IPV6_CSUM);\n\t\telse\n\t\t\tf2 |= (NETIF_F_IP_CSUM|NETIF_F_IPV6_CSUM);\n\t}\n\n\treturn f1 & f2;\n}\n\nstatic inline netdev_features_t netdev_get_wanted_features(\n\tstruct net_device *dev)\n{\n\treturn (dev->features & ~dev->hw_features) | dev->wanted_features;\n}\nnetdev_features_t netdev_increment_features(netdev_features_t all,\n\tnetdev_features_t one, netdev_features_t mask);\n\n/* Allow TSO being used on stacked device :\n * Performing the GSO segmentation before last device\n * is a performance improvement.\n */\nstatic inline netdev_features_t netdev_add_tso_features(netdev_features_t features,\n\t\t\t\t\t\t\tnetdev_features_t mask)\n{\n\treturn netdev_increment_features(features, NETIF_F_ALL_TSO, mask);\n}\n\nint __netdev_update_features(struct net_device *dev);\nvoid netdev_update_features(struct net_device *dev);\nvoid netdev_change_features(struct net_device *dev);\n\nvoid netif_stacked_transfer_operstate(const struct net_device *rootdev,\n\t\t\t\t\tstruct net_device *dev);\n\nnetdev_features_t passthru_features_check(struct sk_buff *skb,\n\t\t\t\t\t  struct net_device *dev,\n\t\t\t\t\t  netdev_features_t features);\nnetdev_features_t netif_skb_features(struct sk_buff *skb);\n\nstatic inline bool net_gso_ok(netdev_features_t features, int gso_type)\n{\n\tnetdev_features_t feature = (netdev_features_t)gso_type << NETIF_F_GSO_SHIFT;\n\n\t/* check flags correspondence */\n\tBUILD_BUG_ON(SKB_GSO_TCPV4   != (NETIF_F_TSO >> NETIF_F_GSO_SHIFT));\n\tBUILD_BUG_ON(SKB_GSO_DODGY   != (NETIF_F_GSO_ROBUST >> NETIF_F_GSO_SHIFT));\n\tBUILD_BUG_ON(SKB_GSO_TCP_ECN != (NETIF_F_TSO_ECN >> NETIF_F_GSO_SHIFT));\n\tBUILD_BUG_ON(SKB_GSO_TCP_FIXEDID != (NETIF_F_TSO_MANGLEID >> NETIF_F_GSO_SHIFT));\n\tBUILD_BUG_ON(SKB_GSO_TCPV6   != (NETIF_F_TSO6 >> NETIF_F_GSO_SHIFT));\n\tBUILD_BUG_ON(SKB_GSO_FCOE    != (NETIF_F_FSO >> NETIF_F_GSO_SHIFT));\n\tBUILD_BUG_ON(SKB_GSO_GRE     != (NETIF_F_GSO_GRE >> NETIF_F_GSO_SHIFT));\n\tBUILD_BUG_ON(SKB_GSO_GRE_CSUM != (NETIF_F_GSO_GRE_CSUM >> NETIF_F_GSO_SHIFT));\n\tBUILD_BUG_ON(SKB_GSO_IPXIP4  != (NETIF_F_GSO_IPXIP4 >> NETIF_F_GSO_SHIFT));\n\tBUILD_BUG_ON(SKB_GSO_IPXIP6  != (NETIF_F_GSO_IPXIP6 >> NETIF_F_GSO_SHIFT));\n\tBUILD_BUG_ON(SKB_GSO_UDP_TUNNEL != (NETIF_F_GSO_UDP_TUNNEL >> NETIF_F_GSO_SHIFT));\n\tBUILD_BUG_ON(SKB_GSO_UDP_TUNNEL_CSUM != (NETIF_F_GSO_UDP_TUNNEL_CSUM >> NETIF_F_GSO_SHIFT));\n\tBUILD_BUG_ON(SKB_GSO_PARTIAL != (NETIF_F_GSO_PARTIAL >> NETIF_F_GSO_SHIFT));\n\tBUILD_BUG_ON(SKB_GSO_TUNNEL_REMCSUM != (NETIF_F_GSO_TUNNEL_REMCSUM >> NETIF_F_GSO_SHIFT));\n\tBUILD_BUG_ON(SKB_GSO_SCTP    != (NETIF_F_GSO_SCTP >> NETIF_F_GSO_SHIFT));\n\tBUILD_BUG_ON(SKB_GSO_ESP != (NETIF_F_GSO_ESP >> NETIF_F_GSO_SHIFT));\n\tBUILD_BUG_ON(SKB_GSO_UDP != (NETIF_F_GSO_UDP >> NETIF_F_GSO_SHIFT));\n\tBUILD_BUG_ON(SKB_GSO_UDP_L4 != (NETIF_F_GSO_UDP_L4 >> NETIF_F_GSO_SHIFT));\n\tBUILD_BUG_ON(SKB_GSO_FRAGLIST != (NETIF_F_GSO_FRAGLIST >> NETIF_F_GSO_SHIFT));\n\n\treturn (features & feature) == feature;\n}\n\nstatic inline bool skb_gso_ok(struct sk_buff *skb, netdev_features_t features)\n{\n\treturn net_gso_ok(features, skb_shinfo(skb)->gso_type) &&\n\t       (!skb_has_frag_list(skb) || (features & NETIF_F_FRAGLIST));\n}\n\nstatic inline bool netif_needs_gso(struct sk_buff *skb,\n\t\t\t\t   netdev_features_t features)\n{\n\treturn skb_is_gso(skb) && (!skb_gso_ok(skb, features) ||\n\t\tunlikely((skb->ip_summed != CHECKSUM_PARTIAL) &&\n\t\t\t (skb->ip_summed != CHECKSUM_UNNECESSARY)));\n}\n\nstatic inline void netif_set_gso_max_size(struct net_device *dev,\n\t\t\t\t\t  unsigned int size)\n{\n\tdev->gso_max_size = size;\n}\n\nstatic inline void skb_gso_error_unwind(struct sk_buff *skb, __be16 protocol,\n\t\t\t\t\tint pulled_hlen, u16 mac_offset,\n\t\t\t\t\tint mac_len)\n{\n\tskb->protocol = protocol;\n\tskb->encapsulation = 1;\n\tskb_push(skb, pulled_hlen);\n\tskb_reset_transport_header(skb);\n\tskb->mac_header = mac_offset;\n\tskb->network_header = skb->mac_header + mac_len;\n\tskb->mac_len = mac_len;\n}\n\nstatic inline bool netif_is_macsec(const struct net_device *dev)\n{\n\treturn dev->priv_flags & IFF_MACSEC;\n}\n\nstatic inline bool netif_is_macvlan(const struct net_device *dev)\n{\n\treturn dev->priv_flags & IFF_MACVLAN;\n}\n\nstatic inline bool netif_is_macvlan_port(const struct net_device *dev)\n{\n\treturn dev->priv_flags & IFF_MACVLAN_PORT;\n}\n\nstatic inline bool netif_is_bond_master(const struct net_device *dev)\n{\n\treturn dev->flags & IFF_MASTER && dev->priv_flags & IFF_BONDING;\n}\n\nstatic inline bool netif_is_bond_slave(const struct net_device *dev)\n{\n\treturn dev->flags & IFF_SLAVE && dev->priv_flags & IFF_BONDING;\n}\n\nstatic inline bool netif_supports_nofcs(struct net_device *dev)\n{\n\treturn dev->priv_flags & IFF_SUPP_NOFCS;\n}\n\nstatic inline bool netif_has_l3_rx_handler(const struct net_device *dev)\n{\n\treturn dev->priv_flags & IFF_L3MDEV_RX_HANDLER;\n}\n\nstatic inline bool netif_is_l3_master(const struct net_device *dev)\n{\n\treturn dev->priv_flags & IFF_L3MDEV_MASTER;\n}\n\nstatic inline bool netif_is_l3_slave(const struct net_device *dev)\n{\n\treturn dev->priv_flags & IFF_L3MDEV_SLAVE;\n}\n\nstatic inline bool netif_is_bridge_master(const struct net_device *dev)\n{\n\treturn dev->priv_flags & IFF_EBRIDGE;\n}\n\nstatic inline bool netif_is_bridge_port(const struct net_device *dev)\n{\n\treturn dev->priv_flags & IFF_BRIDGE_PORT;\n}\n\nstatic inline bool netif_is_ovs_master(const struct net_device *dev)\n{\n\treturn dev->priv_flags & IFF_OPENVSWITCH;\n}\n\nstatic inline bool netif_is_ovs_port(const struct net_device *dev)\n{\n\treturn dev->priv_flags & IFF_OVS_DATAPATH;\n}\n\nstatic inline bool netif_is_any_bridge_port(const struct net_device *dev)\n{\n\treturn netif_is_bridge_port(dev) || netif_is_ovs_port(dev);\n}\n\nstatic inline bool netif_is_team_master(const struct net_device *dev)\n{\n\treturn dev->priv_flags & IFF_TEAM;\n}\n\nstatic inline bool netif_is_team_port(const struct net_device *dev)\n{\n\treturn dev->priv_flags & IFF_TEAM_PORT;\n}\n\nstatic inline bool netif_is_lag_master(const struct net_device *dev)\n{\n\treturn netif_is_bond_master(dev) || netif_is_team_master(dev);\n}\n\nstatic inline bool netif_is_lag_port(const struct net_device *dev)\n{\n\treturn netif_is_bond_slave(dev) || netif_is_team_port(dev);\n}\n\nstatic inline bool netif_is_rxfh_configured(const struct net_device *dev)\n{\n\treturn dev->priv_flags & IFF_RXFH_CONFIGURED;\n}\n\nstatic inline bool netif_is_failover(const struct net_device *dev)\n{\n\treturn dev->priv_flags & IFF_FAILOVER;\n}\n\nstatic inline bool netif_is_failover_slave(const struct net_device *dev)\n{\n\treturn dev->priv_flags & IFF_FAILOVER_SLAVE;\n}\n\n/* This device needs to keep skb dst for qdisc enqueue or ndo_start_xmit() */\nstatic inline void netif_keep_dst(struct net_device *dev)\n{\n\tdev->priv_flags &= ~(IFF_XMIT_DST_RELEASE | IFF_XMIT_DST_RELEASE_PERM);\n}\n\n/* return true if dev can't cope with mtu frames that need vlan tag insertion */\nstatic inline bool netif_reduces_vlan_mtu(struct net_device *dev)\n{\n\t/* TODO: reserve and use an additional IFF bit, if we get more users */\n\treturn dev->priv_flags & IFF_MACSEC;\n}\n\nextern struct pernet_operations __net_initdata loopback_net_ops;\n\n/* Logging, debugging and troubleshooting/diagnostic helpers. */\n\n/* netdev_printk helpers, similar to dev_printk */\n\nstatic inline const char *netdev_name(const struct net_device *dev)\n{\n\tif (!dev->name[0] || strchr(dev->name, '%'))\n\t\treturn \"(unnamed net_device)\";\n\treturn dev->name;\n}\n\nstatic inline bool netdev_unregistering(const struct net_device *dev)\n{\n\treturn dev->reg_state == NETREG_UNREGISTERING;\n}\n\nstatic inline const char *netdev_reg_state(const struct net_device *dev)\n{\n\tswitch (dev->reg_state) {\n\tcase NETREG_UNINITIALIZED: return \" (uninitialized)\";\n\tcase NETREG_REGISTERED: return \"\";\n\tcase NETREG_UNREGISTERING: return \" (unregistering)\";\n\tcase NETREG_UNREGISTERED: return \" (unregistered)\";\n\tcase NETREG_RELEASED: return \" (released)\";\n\tcase NETREG_DUMMY: return \" (dummy)\";\n\t}\n\n\tWARN_ONCE(1, \"%s: unknown reg_state %d\\n\", dev->name, dev->reg_state);\n\treturn \" (unknown)\";\n}\n\n__printf(3, 4) __cold\nvoid netdev_printk(const char *level, const struct net_device *dev,\n\t\t   const char *format, ...);\n__printf(2, 3) __cold\nvoid netdev_emerg(const struct net_device *dev, const char *format, ...);\n__printf(2, 3) __cold\nvoid netdev_alert(const struct net_device *dev, const char *format, ...);\n__printf(2, 3) __cold\nvoid netdev_crit(const struct net_device *dev, const char *format, ...);\n__printf(2, 3) __cold\nvoid netdev_err(const struct net_device *dev, const char *format, ...);\n__printf(2, 3) __cold\nvoid netdev_warn(const struct net_device *dev, const char *format, ...);\n__printf(2, 3) __cold\nvoid netdev_notice(const struct net_device *dev, const char *format, ...);\n__printf(2, 3) __cold\nvoid netdev_info(const struct net_device *dev, const char *format, ...);\n\n#define netdev_level_once(level, dev, fmt, ...)\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\\\n\tstatic bool __print_once __read_mostly;\t\t\t\\\n\t\t\t\t\t\t\t\t\\\n\tif (!__print_once) {\t\t\t\t\t\\\n\t\t__print_once = true;\t\t\t\t\\\n\t\tnetdev_printk(level, dev, fmt, ##__VA_ARGS__);\t\\\n\t}\t\t\t\t\t\t\t\\\n} while (0)\n\n#define netdev_emerg_once(dev, fmt, ...) \\\n\tnetdev_level_once(KERN_EMERG, dev, fmt, ##__VA_ARGS__)\n#define netdev_alert_once(dev, fmt, ...) \\\n\tnetdev_level_once(KERN_ALERT, dev, fmt, ##__VA_ARGS__)\n#define netdev_crit_once(dev, fmt, ...) \\\n\tnetdev_level_once(KERN_CRIT, dev, fmt, ##__VA_ARGS__)\n#define netdev_err_once(dev, fmt, ...) \\\n\tnetdev_level_once(KERN_ERR, dev, fmt, ##__VA_ARGS__)\n#define netdev_warn_once(dev, fmt, ...) \\\n\tnetdev_level_once(KERN_WARNING, dev, fmt, ##__VA_ARGS__)\n#define netdev_notice_once(dev, fmt, ...) \\\n\tnetdev_level_once(KERN_NOTICE, dev, fmt, ##__VA_ARGS__)\n#define netdev_info_once(dev, fmt, ...) \\\n\tnetdev_level_once(KERN_INFO, dev, fmt, ##__VA_ARGS__)\n\n#define MODULE_ALIAS_NETDEV(device) \\\n\tMODULE_ALIAS(\"netdev-\" device)\n\n#if defined(CONFIG_DYNAMIC_DEBUG) || \\\n\t(defined(CONFIG_DYNAMIC_DEBUG_CORE) && defined(DYNAMIC_DEBUG_MODULE))\n#define netdev_dbg(__dev, format, args...)\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\\\n\tdynamic_netdev_dbg(__dev, format, ##args);\t\t\\\n} while (0)\n#elif defined(DEBUG)\n#define netdev_dbg(__dev, format, args...)\t\t\t\\\n\tnetdev_printk(KERN_DEBUG, __dev, format, ##args)\n#else\n#define netdev_dbg(__dev, format, args...)\t\t\t\\\n({\t\t\t\t\t\t\t\t\\\n\tif (0)\t\t\t\t\t\t\t\\\n\t\tnetdev_printk(KERN_DEBUG, __dev, format, ##args); \\\n})\n#endif\n\n#if defined(VERBOSE_DEBUG)\n#define netdev_vdbg\tnetdev_dbg\n#else\n\n#define netdev_vdbg(dev, format, args...)\t\t\t\\\n({\t\t\t\t\t\t\t\t\\\n\tif (0)\t\t\t\t\t\t\t\\\n\t\tnetdev_printk(KERN_DEBUG, dev, format, ##args);\t\\\n\t0;\t\t\t\t\t\t\t\\\n})\n#endif\n\n/*\n * netdev_WARN() acts like dev_printk(), but with the key difference\n * of using a WARN/WARN_ON to get the message out, including the\n * file/line information and a backtrace.\n */\n#define netdev_WARN(dev, format, args...)\t\t\t\\\n\tWARN(1, \"netdevice: %s%s: \" format, netdev_name(dev),\t\\\n\t     netdev_reg_state(dev), ##args)\n\n#define netdev_WARN_ONCE(dev, format, args...)\t\t\t\t\\\n\tWARN_ONCE(1, \"netdevice: %s%s: \" format, netdev_name(dev),\t\\\n\t\t  netdev_reg_state(dev), ##args)\n\n/* netif printk helpers, similar to netdev_printk */\n\n#define netif_printk(priv, type, level, dev, fmt, args...)\t\\\ndo {\t\t\t\t\t  \t\t\t\\\n\tif (netif_msg_##type(priv))\t\t\t\t\\\n\t\tnetdev_printk(level, (dev), fmt, ##args);\t\\\n} while (0)\n\n#define netif_level(level, priv, type, dev, fmt, args...)\t\\\ndo {\t\t\t\t\t\t\t\t\\\n\tif (netif_msg_##type(priv))\t\t\t\t\\\n\t\tnetdev_##level(dev, fmt, ##args);\t\t\\\n} while (0)\n\n#define netif_emerg(priv, type, dev, fmt, args...)\t\t\\\n\tnetif_level(emerg, priv, type, dev, fmt, ##args)\n#define netif_alert(priv, type, dev, fmt, args...)\t\t\\\n\tnetif_level(alert, priv, type, dev, fmt, ##args)\n#define netif_crit(priv, type, dev, fmt, args...)\t\t\\\n\tnetif_level(crit, priv, type, dev, fmt, ##args)\n#define netif_err(priv, type, dev, fmt, args...)\t\t\\\n\tnetif_level(err, priv, type, dev, fmt, ##args)\n#define netif_warn(priv, type, dev, fmt, args...)\t\t\\\n\tnetif_level(warn, priv, type, dev, fmt, ##args)\n#define netif_notice(priv, type, dev, fmt, args...)\t\t\\\n\tnetif_level(notice, priv, type, dev, fmt, ##args)\n#define netif_info(priv, type, dev, fmt, args...)\t\t\\\n\tnetif_level(info, priv, type, dev, fmt, ##args)\n\n#if defined(CONFIG_DYNAMIC_DEBUG) || \\\n\t(defined(CONFIG_DYNAMIC_DEBUG_CORE) && defined(DYNAMIC_DEBUG_MODULE))\n#define netif_dbg(priv, type, netdev, format, args...)\t\t\\\ndo {\t\t\t\t\t\t\t\t\\\n\tif (netif_msg_##type(priv))\t\t\t\t\\\n\t\tdynamic_netdev_dbg(netdev, format, ##args);\t\\\n} while (0)\n#elif defined(DEBUG)\n#define netif_dbg(priv, type, dev, format, args...)\t\t\\\n\tnetif_printk(priv, type, KERN_DEBUG, dev, format, ##args)\n#else\n#define netif_dbg(priv, type, dev, format, args...)\t\t\t\\\n({\t\t\t\t\t\t\t\t\t\\\n\tif (0)\t\t\t\t\t\t\t\t\\\n\t\tnetif_printk(priv, type, KERN_DEBUG, dev, format, ##args); \\\n\t0;\t\t\t\t\t\t\t\t\\\n})\n#endif\n\n/* if @cond then downgrade to debug, else print at @level */\n#define netif_cond_dbg(priv, type, netdev, cond, level, fmt, args...)     \\\n\tdo {                                                              \\\n\t\tif (cond)                                                 \\\n\t\t\tnetif_dbg(priv, type, netdev, fmt, ##args);       \\\n\t\telse                                                      \\\n\t\t\tnetif_ ## level(priv, type, netdev, fmt, ##args); \\\n\t} while (0)\n\n#if defined(VERBOSE_DEBUG)\n#define netif_vdbg\tnetif_dbg\n#else\n#define netif_vdbg(priv, type, dev, format, args...)\t\t\\\n({\t\t\t\t\t\t\t\t\\\n\tif (0)\t\t\t\t\t\t\t\\\n\t\tnetif_printk(priv, type, KERN_DEBUG, dev, format, ##args); \\\n\t0;\t\t\t\t\t\t\t\\\n})\n#endif\n\n/*\n *\tThe list of packet types we will receive (as opposed to discard)\n *\tand the routines to invoke.\n *\n *\tWhy 16. Because with 16 the only overlap we get on a hash of the\n *\tlow nibble of the protocol value is RARP/SNAP/X.25.\n *\n *\t\t0800\tIP\n *\t\t0001\t802.3\n *\t\t0002\tAX.25\n *\t\t0004\t802.2\n *\t\t8035\tRARP\n *\t\t0005\tSNAP\n *\t\t0805\tX.25\n *\t\t0806\tARP\n *\t\t8137\tIPX\n *\t\t0009\tLocaltalk\n *\t\t86DD\tIPv6\n */\n#define PTYPE_HASH_SIZE\t(16)\n#define PTYPE_HASH_MASK\t(PTYPE_HASH_SIZE - 1)\n\nextern struct net_device *blackhole_netdev;\n\n#endif\t/* _LINUX_NETDEVICE_H */\n"}, "7": {"id": 7, "path": "/src/include/linux/list.h", "content": "/* SPDX-License-Identifier: GPL-2.0 */\n#ifndef _LINUX_LIST_H\n#define _LINUX_LIST_H\n\n#include <linux/types.h>\n#include <linux/stddef.h>\n#include <linux/poison.h>\n#include <linux/const.h>\n#include <linux/kernel.h>\n\n/*\n * Circular doubly linked list implementation.\n *\n * Some of the internal functions (\"__xxx\") are useful when\n * manipulating whole lists rather than single entries, as\n * sometimes we already know the next/prev entries and we can\n * generate better code by using them directly rather than\n * using the generic single-entry routines.\n */\n\n#define LIST_HEAD_INIT(name) { &(name), &(name) }\n\n#define LIST_HEAD(name) \\\n\tstruct list_head name = LIST_HEAD_INIT(name)\n\n/**\n * INIT_LIST_HEAD - Initialize a list_head structure\n * @list: list_head structure to be initialized.\n *\n * Initializes the list_head to point to itself.  If it is a list header,\n * the result is an empty list.\n */\nstatic inline void INIT_LIST_HEAD(struct list_head *list)\n{\n\tWRITE_ONCE(list->next, list);\n\tlist->prev = list;\n}\n\n#ifdef CONFIG_DEBUG_LIST\nextern bool __list_add_valid(struct list_head *new,\n\t\t\t      struct list_head *prev,\n\t\t\t      struct list_head *next);\nextern bool __list_del_entry_valid(struct list_head *entry);\n#else\nstatic inline bool __list_add_valid(struct list_head *new,\n\t\t\t\tstruct list_head *prev,\n\t\t\t\tstruct list_head *next)\n{\n\treturn true;\n}\nstatic inline bool __list_del_entry_valid(struct list_head *entry)\n{\n\treturn true;\n}\n#endif\n\n/*\n * Insert a new entry between two known consecutive entries.\n *\n * This is only for internal list manipulation where we know\n * the prev/next entries already!\n */\nstatic inline void __list_add(struct list_head *new,\n\t\t\t      struct list_head *prev,\n\t\t\t      struct list_head *next)\n{\n\tif (!__list_add_valid(new, prev, next))\n\t\treturn;\n\n\tnext->prev = new;\n\tnew->next = next;\n\tnew->prev = prev;\n\tWRITE_ONCE(prev->next, new);\n}\n\n/**\n * list_add - add a new entry\n * @new: new entry to be added\n * @head: list head to add it after\n *\n * Insert a new entry after the specified head.\n * This is good for implementing stacks.\n */\nstatic inline void list_add(struct list_head *new, struct list_head *head)\n{\n\t__list_add(new, head, head->next);\n}\n\n\n/**\n * list_add_tail - add a new entry\n * @new: new entry to be added\n * @head: list head to add it before\n *\n * Insert a new entry before the specified head.\n * This is useful for implementing queues.\n */\nstatic inline void list_add_tail(struct list_head *new, struct list_head *head)\n{\n\t__list_add(new, head->prev, head);\n}\n\n/*\n * Delete a list entry by making the prev/next entries\n * point to each other.\n *\n * This is only for internal list manipulation where we know\n * the prev/next entries already!\n */\nstatic inline void __list_del(struct list_head * prev, struct list_head * next)\n{\n\tnext->prev = prev;\n\tWRITE_ONCE(prev->next, next);\n}\n\n/*\n * Delete a list entry and clear the 'prev' pointer.\n *\n * This is a special-purpose list clearing method used in the networking code\n * for lists allocated as per-cpu, where we don't want to incur the extra\n * WRITE_ONCE() overhead of a regular list_del_init(). The code that uses this\n * needs to check the node 'prev' pointer instead of calling list_empty().\n */\nstatic inline void __list_del_clearprev(struct list_head *entry)\n{\n\t__list_del(entry->prev, entry->next);\n\tentry->prev = NULL;\n}\n\nstatic inline void __list_del_entry(struct list_head *entry)\n{\n\tif (!__list_del_entry_valid(entry))\n\t\treturn;\n\n\t__list_del(entry->prev, entry->next);\n}\n\n/**\n * list_del - deletes entry from list.\n * @entry: the element to delete from the list.\n * Note: list_empty() on entry does not return true after this, the entry is\n * in an undefined state.\n */\nstatic inline void list_del(struct list_head *entry)\n{\n\t__list_del_entry(entry);\n\tentry->next = LIST_POISON1;\n\tentry->prev = LIST_POISON2;\n}\n\n/**\n * list_replace - replace old entry by new one\n * @old : the element to be replaced\n * @new : the new element to insert\n *\n * If @old was empty, it will be overwritten.\n */\nstatic inline void list_replace(struct list_head *old,\n\t\t\t\tstruct list_head *new)\n{\n\tnew->next = old->next;\n\tnew->next->prev = new;\n\tnew->prev = old->prev;\n\tnew->prev->next = new;\n}\n\n/**\n * list_replace_init - replace old entry by new one and initialize the old one\n * @old : the element to be replaced\n * @new : the new element to insert\n *\n * If @old was empty, it will be overwritten.\n */\nstatic inline void list_replace_init(struct list_head *old,\n\t\t\t\t     struct list_head *new)\n{\n\tlist_replace(old, new);\n\tINIT_LIST_HEAD(old);\n}\n\n/**\n * list_swap - replace entry1 with entry2 and re-add entry1 at entry2's position\n * @entry1: the location to place entry2\n * @entry2: the location to place entry1\n */\nstatic inline void list_swap(struct list_head *entry1,\n\t\t\t     struct list_head *entry2)\n{\n\tstruct list_head *pos = entry2->prev;\n\n\tlist_del(entry2);\n\tlist_replace(entry1, entry2);\n\tif (pos == entry1)\n\t\tpos = entry2;\n\tlist_add(entry1, pos);\n}\n\n/**\n * list_del_init - deletes entry from list and reinitialize it.\n * @entry: the element to delete from the list.\n */\nstatic inline void list_del_init(struct list_head *entry)\n{\n\t__list_del_entry(entry);\n\tINIT_LIST_HEAD(entry);\n}\n\n/**\n * list_move - delete from one list and add as another's head\n * @list: the entry to move\n * @head: the head that will precede our entry\n */\nstatic inline void list_move(struct list_head *list, struct list_head *head)\n{\n\t__list_del_entry(list);\n\tlist_add(list, head);\n}\n\n/**\n * list_move_tail - delete from one list and add as another's tail\n * @list: the entry to move\n * @head: the head that will follow our entry\n */\nstatic inline void list_move_tail(struct list_head *list,\n\t\t\t\t  struct list_head *head)\n{\n\t__list_del_entry(list);\n\tlist_add_tail(list, head);\n}\n\n/**\n * list_bulk_move_tail - move a subsection of a list to its tail\n * @head: the head that will follow our entry\n * @first: first entry to move\n * @last: last entry to move, can be the same as first\n *\n * Move all entries between @first and including @last before @head.\n * All three entries must belong to the same linked list.\n */\nstatic inline void list_bulk_move_tail(struct list_head *head,\n\t\t\t\t       struct list_head *first,\n\t\t\t\t       struct list_head *last)\n{\n\tfirst->prev->next = last->next;\n\tlast->next->prev = first->prev;\n\n\thead->prev->next = first;\n\tfirst->prev = head->prev;\n\n\tlast->next = head;\n\thead->prev = last;\n}\n\n/**\n * list_is_first -- tests whether @list is the first entry in list @head\n * @list: the entry to test\n * @head: the head of the list\n */\nstatic inline int list_is_first(const struct list_head *list,\n\t\t\t\t\tconst struct list_head *head)\n{\n\treturn list->prev == head;\n}\n\n/**\n * list_is_last - tests whether @list is the last entry in list @head\n * @list: the entry to test\n * @head: the head of the list\n */\nstatic inline int list_is_last(const struct list_head *list,\n\t\t\t\tconst struct list_head *head)\n{\n\treturn list->next == head;\n}\n\n/**\n * list_empty - tests whether a list is empty\n * @head: the list to test.\n */\nstatic inline int list_empty(const struct list_head *head)\n{\n\treturn READ_ONCE(head->next) == head;\n}\n\n/**\n * list_del_init_careful - deletes entry from list and reinitialize it.\n * @entry: the element to delete from the list.\n *\n * This is the same as list_del_init(), except designed to be used\n * together with list_empty_careful() in a way to guarantee ordering\n * of other memory operations.\n *\n * Any memory operations done before a list_del_init_careful() are\n * guaranteed to be visible after a list_empty_careful() test.\n */\nstatic inline void list_del_init_careful(struct list_head *entry)\n{\n\t__list_del_entry(entry);\n\tentry->prev = entry;\n\tsmp_store_release(&entry->next, entry);\n}\n\n/**\n * list_empty_careful - tests whether a list is empty and not being modified\n * @head: the list to test\n *\n * Description:\n * tests whether a list is empty _and_ checks that no other CPU might be\n * in the process of modifying either member (next or prev)\n *\n * NOTE: using list_empty_careful() without synchronization\n * can only be safe if the only activity that can happen\n * to the list entry is list_del_init(). Eg. it cannot be used\n * if another CPU could re-list_add() it.\n */\nstatic inline int list_empty_careful(const struct list_head *head)\n{\n\tstruct list_head *next = smp_load_acquire(&head->next);\n\treturn (next == head) && (next == head->prev);\n}\n\n/**\n * list_rotate_left - rotate the list to the left\n * @head: the head of the list\n */\nstatic inline void list_rotate_left(struct list_head *head)\n{\n\tstruct list_head *first;\n\n\tif (!list_empty(head)) {\n\t\tfirst = head->next;\n\t\tlist_move_tail(first, head);\n\t}\n}\n\n/**\n * list_rotate_to_front() - Rotate list to specific item.\n * @list: The desired new front of the list.\n * @head: The head of the list.\n *\n * Rotates list so that @list becomes the new front of the list.\n */\nstatic inline void list_rotate_to_front(struct list_head *list,\n\t\t\t\t\tstruct list_head *head)\n{\n\t/*\n\t * Deletes the list head from the list denoted by @head and\n\t * places it as the tail of @list, this effectively rotates the\n\t * list so that @list is at the front.\n\t */\n\tlist_move_tail(head, list);\n}\n\n/**\n * list_is_singular - tests whether a list has just one entry.\n * @head: the list to test.\n */\nstatic inline int list_is_singular(const struct list_head *head)\n{\n\treturn !list_empty(head) && (head->next == head->prev);\n}\n\nstatic inline void __list_cut_position(struct list_head *list,\n\t\tstruct list_head *head, struct list_head *entry)\n{\n\tstruct list_head *new_first = entry->next;\n\tlist->next = head->next;\n\tlist->next->prev = list;\n\tlist->prev = entry;\n\tentry->next = list;\n\thead->next = new_first;\n\tnew_first->prev = head;\n}\n\n/**\n * list_cut_position - cut a list into two\n * @list: a new list to add all removed entries\n * @head: a list with entries\n * @entry: an entry within head, could be the head itself\n *\tand if so we won't cut the list\n *\n * This helper moves the initial part of @head, up to and\n * including @entry, from @head to @list. You should\n * pass on @entry an element you know is on @head. @list\n * should be an empty list or a list you do not care about\n * losing its data.\n *\n */\nstatic inline void list_cut_position(struct list_head *list,\n\t\tstruct list_head *head, struct list_head *entry)\n{\n\tif (list_empty(head))\n\t\treturn;\n\tif (list_is_singular(head) &&\n\t\t(head->next != entry && head != entry))\n\t\treturn;\n\tif (entry == head)\n\t\tINIT_LIST_HEAD(list);\n\telse\n\t\t__list_cut_position(list, head, entry);\n}\n\n/**\n * list_cut_before - cut a list into two, before given entry\n * @list: a new list to add all removed entries\n * @head: a list with entries\n * @entry: an entry within head, could be the head itself\n *\n * This helper moves the initial part of @head, up to but\n * excluding @entry, from @head to @list.  You should pass\n * in @entry an element you know is on @head.  @list should\n * be an empty list or a list you do not care about losing\n * its data.\n * If @entry == @head, all entries on @head are moved to\n * @list.\n */\nstatic inline void list_cut_before(struct list_head *list,\n\t\t\t\t   struct list_head *head,\n\t\t\t\t   struct list_head *entry)\n{\n\tif (head->next == entry) {\n\t\tINIT_LIST_HEAD(list);\n\t\treturn;\n\t}\n\tlist->next = head->next;\n\tlist->next->prev = list;\n\tlist->prev = entry->prev;\n\tlist->prev->next = list;\n\thead->next = entry;\n\tentry->prev = head;\n}\n\nstatic inline void __list_splice(const struct list_head *list,\n\t\t\t\t struct list_head *prev,\n\t\t\t\t struct list_head *next)\n{\n\tstruct list_head *first = list->next;\n\tstruct list_head *last = list->prev;\n\n\tfirst->prev = prev;\n\tprev->next = first;\n\n\tlast->next = next;\n\tnext->prev = last;\n}\n\n/**\n * list_splice - join two lists, this is designed for stacks\n * @list: the new list to add.\n * @head: the place to add it in the first list.\n */\nstatic inline void list_splice(const struct list_head *list,\n\t\t\t\tstruct list_head *head)\n{\n\tif (!list_empty(list))\n\t\t__list_splice(list, head, head->next);\n}\n\n/**\n * list_splice_tail - join two lists, each list being a queue\n * @list: the new list to add.\n * @head: the place to add it in the first list.\n */\nstatic inline void list_splice_tail(struct list_head *list,\n\t\t\t\tstruct list_head *head)\n{\n\tif (!list_empty(list))\n\t\t__list_splice(list, head->prev, head);\n}\n\n/**\n * list_splice_init - join two lists and reinitialise the emptied list.\n * @list: the new list to add.\n * @head: the place to add it in the first list.\n *\n * The list at @list is reinitialised\n */\nstatic inline void list_splice_init(struct list_head *list,\n\t\t\t\t    struct list_head *head)\n{\n\tif (!list_empty(list)) {\n\t\t__list_splice(list, head, head->next);\n\t\tINIT_LIST_HEAD(list);\n\t}\n}\n\n/**\n * list_splice_tail_init - join two lists and reinitialise the emptied list\n * @list: the new list to add.\n * @head: the place to add it in the first list.\n *\n * Each of the lists is a queue.\n * The list at @list is reinitialised\n */\nstatic inline void list_splice_tail_init(struct list_head *list,\n\t\t\t\t\t struct list_head *head)\n{\n\tif (!list_empty(list)) {\n\t\t__list_splice(list, head->prev, head);\n\t\tINIT_LIST_HEAD(list);\n\t}\n}\n\n/**\n * list_entry - get the struct for this entry\n * @ptr:\tthe &struct list_head pointer.\n * @type:\tthe type of the struct this is embedded in.\n * @member:\tthe name of the list_head within the struct.\n */\n#define list_entry(ptr, type, member) \\\n\tcontainer_of(ptr, type, member)\n\n/**\n * list_first_entry - get the first element from a list\n * @ptr:\tthe list head to take the element from.\n * @type:\tthe type of the struct this is embedded in.\n * @member:\tthe name of the list_head within the struct.\n *\n * Note, that list is expected to be not empty.\n */\n#define list_first_entry(ptr, type, member) \\\n\tlist_entry((ptr)->next, type, member)\n\n/**\n * list_last_entry - get the last element from a list\n * @ptr:\tthe list head to take the element from.\n * @type:\tthe type of the struct this is embedded in.\n * @member:\tthe name of the list_head within the struct.\n *\n * Note, that list is expected to be not empty.\n */\n#define list_last_entry(ptr, type, member) \\\n\tlist_entry((ptr)->prev, type, member)\n\n/**\n * list_first_entry_or_null - get the first element from a list\n * @ptr:\tthe list head to take the element from.\n * @type:\tthe type of the struct this is embedded in.\n * @member:\tthe name of the list_head within the struct.\n *\n * Note that if the list is empty, it returns NULL.\n */\n#define list_first_entry_or_null(ptr, type, member) ({ \\\n\tstruct list_head *head__ = (ptr); \\\n\tstruct list_head *pos__ = READ_ONCE(head__->next); \\\n\tpos__ != head__ ? list_entry(pos__, type, member) : NULL; \\\n})\n\n/**\n * list_next_entry - get the next element in list\n * @pos:\tthe type * to cursor\n * @member:\tthe name of the list_head within the struct.\n */\n#define list_next_entry(pos, member) \\\n\tlist_entry((pos)->member.next, typeof(*(pos)), member)\n\n/**\n * list_prev_entry - get the prev element in list\n * @pos:\tthe type * to cursor\n * @member:\tthe name of the list_head within the struct.\n */\n#define list_prev_entry(pos, member) \\\n\tlist_entry((pos)->member.prev, typeof(*(pos)), member)\n\n/**\n * list_for_each\t-\titerate over a list\n * @pos:\tthe &struct list_head to use as a loop cursor.\n * @head:\tthe head for your list.\n */\n#define list_for_each(pos, head) \\\n\tfor (pos = (head)->next; pos != (head); pos = pos->next)\n\n/**\n * list_for_each_continue - continue iteration over a list\n * @pos:\tthe &struct list_head to use as a loop cursor.\n * @head:\tthe head for your list.\n *\n * Continue to iterate over a list, continuing after the current position.\n */\n#define list_for_each_continue(pos, head) \\\n\tfor (pos = pos->next; pos != (head); pos = pos->next)\n\n/**\n * list_for_each_prev\t-\titerate over a list backwards\n * @pos:\tthe &struct list_head to use as a loop cursor.\n * @head:\tthe head for your list.\n */\n#define list_for_each_prev(pos, head) \\\n\tfor (pos = (head)->prev; pos != (head); pos = pos->prev)\n\n/**\n * list_for_each_safe - iterate over a list safe against removal of list entry\n * @pos:\tthe &struct list_head to use as a loop cursor.\n * @n:\t\tanother &struct list_head to use as temporary storage\n * @head:\tthe head for your list.\n */\n#define list_for_each_safe(pos, n, head) \\\n\tfor (pos = (head)->next, n = pos->next; pos != (head); \\\n\t\tpos = n, n = pos->next)\n\n/**\n * list_for_each_prev_safe - iterate over a list backwards safe against removal of list entry\n * @pos:\tthe &struct list_head to use as a loop cursor.\n * @n:\t\tanother &struct list_head to use as temporary storage\n * @head:\tthe head for your list.\n */\n#define list_for_each_prev_safe(pos, n, head) \\\n\tfor (pos = (head)->prev, n = pos->prev; \\\n\t     pos != (head); \\\n\t     pos = n, n = pos->prev)\n\n/**\n * list_entry_is_head - test if the entry points to the head of the list\n * @pos:\tthe type * to cursor\n * @head:\tthe head for your list.\n * @member:\tthe name of the list_head within the struct.\n */\n#define list_entry_is_head(pos, head, member)\t\t\t\t\\\n\t(&pos->member == (head))\n\n/**\n * list_for_each_entry\t-\titerate over list of given type\n * @pos:\tthe type * to use as a loop cursor.\n * @head:\tthe head for your list.\n * @member:\tthe name of the list_head within the struct.\n */\n#define list_for_each_entry(pos, head, member)\t\t\t\t\\\n\tfor (pos = list_first_entry(head, typeof(*pos), member);\t\\\n\t     !list_entry_is_head(pos, head, member);\t\t\t\\\n\t     pos = list_next_entry(pos, member))\n\n/**\n * list_for_each_entry_reverse - iterate backwards over list of given type.\n * @pos:\tthe type * to use as a loop cursor.\n * @head:\tthe head for your list.\n * @member:\tthe name of the list_head within the struct.\n */\n#define list_for_each_entry_reverse(pos, head, member)\t\t\t\\\n\tfor (pos = list_last_entry(head, typeof(*pos), member);\t\t\\\n\t     !list_entry_is_head(pos, head, member); \t\t\t\\\n\t     pos = list_prev_entry(pos, member))\n\n/**\n * list_prepare_entry - prepare a pos entry for use in list_for_each_entry_continue()\n * @pos:\tthe type * to use as a start point\n * @head:\tthe head of the list\n * @member:\tthe name of the list_head within the struct.\n *\n * Prepares a pos entry for use as a start point in list_for_each_entry_continue().\n */\n#define list_prepare_entry(pos, head, member) \\\n\t((pos) ? : list_entry(head, typeof(*pos), member))\n\n/**\n * list_for_each_entry_continue - continue iteration over list of given type\n * @pos:\tthe type * to use as a loop cursor.\n * @head:\tthe head for your list.\n * @member:\tthe name of the list_head within the struct.\n *\n * Continue to iterate over list of given type, continuing after\n * the current position.\n */\n#define list_for_each_entry_continue(pos, head, member) \t\t\\\n\tfor (pos = list_next_entry(pos, member);\t\t\t\\\n\t     !list_entry_is_head(pos, head, member);\t\t\t\\\n\t     pos = list_next_entry(pos, member))\n\n/**\n * list_for_each_entry_continue_reverse - iterate backwards from the given point\n * @pos:\tthe type * to use as a loop cursor.\n * @head:\tthe head for your list.\n * @member:\tthe name of the list_head within the struct.\n *\n * Start to iterate over list of given type backwards, continuing after\n * the current position.\n */\n#define list_for_each_entry_continue_reverse(pos, head, member)\t\t\\\n\tfor (pos = list_prev_entry(pos, member);\t\t\t\\\n\t     !list_entry_is_head(pos, head, member);\t\t\t\\\n\t     pos = list_prev_entry(pos, member))\n\n/**\n * list_for_each_entry_from - iterate over list of given type from the current point\n * @pos:\tthe type * to use as a loop cursor.\n * @head:\tthe head for your list.\n * @member:\tthe name of the list_head within the struct.\n *\n * Iterate over list of given type, continuing from current position.\n */\n#define list_for_each_entry_from(pos, head, member) \t\t\t\\\n\tfor (; !list_entry_is_head(pos, head, member);\t\t\t\\\n\t     pos = list_next_entry(pos, member))\n\n/**\n * list_for_each_entry_from_reverse - iterate backwards over list of given type\n *                                    from the current point\n * @pos:\tthe type * to use as a loop cursor.\n * @head:\tthe head for your list.\n * @member:\tthe name of the list_head within the struct.\n *\n * Iterate backwards over list of given type, continuing from current position.\n */\n#define list_for_each_entry_from_reverse(pos, head, member)\t\t\\\n\tfor (; !list_entry_is_head(pos, head, member);\t\t\t\\\n\t     pos = list_prev_entry(pos, member))\n\n/**\n * list_for_each_entry_safe - iterate over list of given type safe against removal of list entry\n * @pos:\tthe type * to use as a loop cursor.\n * @n:\t\tanother type * to use as temporary storage\n * @head:\tthe head for your list.\n * @member:\tthe name of the list_head within the struct.\n */\n#define list_for_each_entry_safe(pos, n, head, member)\t\t\t\\\n\tfor (pos = list_first_entry(head, typeof(*pos), member),\t\\\n\t\tn = list_next_entry(pos, member);\t\t\t\\\n\t     !list_entry_is_head(pos, head, member); \t\t\t\\\n\t     pos = n, n = list_next_entry(n, member))\n\n/**\n * list_for_each_entry_safe_continue - continue list iteration safe against removal\n * @pos:\tthe type * to use as a loop cursor.\n * @n:\t\tanother type * to use as temporary storage\n * @head:\tthe head for your list.\n * @member:\tthe name of the list_head within the struct.\n *\n * Iterate over list of given type, continuing after current point,\n * safe against removal of list entry.\n */\n#define list_for_each_entry_safe_continue(pos, n, head, member) \t\t\\\n\tfor (pos = list_next_entry(pos, member), \t\t\t\t\\\n\t\tn = list_next_entry(pos, member);\t\t\t\t\\\n\t     !list_entry_is_head(pos, head, member);\t\t\t\t\\\n\t     pos = n, n = list_next_entry(n, member))\n\n/**\n * list_for_each_entry_safe_from - iterate over list from current point safe against removal\n * @pos:\tthe type * to use as a loop cursor.\n * @n:\t\tanother type * to use as temporary storage\n * @head:\tthe head for your list.\n * @member:\tthe name of the list_head within the struct.\n *\n * Iterate over list of given type from current point, safe against\n * removal of list entry.\n */\n#define list_for_each_entry_safe_from(pos, n, head, member) \t\t\t\\\n\tfor (n = list_next_entry(pos, member);\t\t\t\t\t\\\n\t     !list_entry_is_head(pos, head, member);\t\t\t\t\\\n\t     pos = n, n = list_next_entry(n, member))\n\n/**\n * list_for_each_entry_safe_reverse - iterate backwards over list safe against removal\n * @pos:\tthe type * to use as a loop cursor.\n * @n:\t\tanother type * to use as temporary storage\n * @head:\tthe head for your list.\n * @member:\tthe name of the list_head within the struct.\n *\n * Iterate backwards over list of given type, safe against removal\n * of list entry.\n */\n#define list_for_each_entry_safe_reverse(pos, n, head, member)\t\t\\\n\tfor (pos = list_last_entry(head, typeof(*pos), member),\t\t\\\n\t\tn = list_prev_entry(pos, member);\t\t\t\\\n\t     !list_entry_is_head(pos, head, member); \t\t\t\\\n\t     pos = n, n = list_prev_entry(n, member))\n\n/**\n * list_safe_reset_next - reset a stale list_for_each_entry_safe loop\n * @pos:\tthe loop cursor used in the list_for_each_entry_safe loop\n * @n:\t\ttemporary storage used in list_for_each_entry_safe\n * @member:\tthe name of the list_head within the struct.\n *\n * list_safe_reset_next is not safe to use in general if the list may be\n * modified concurrently (eg. the lock is dropped in the loop body). An\n * exception to this is if the cursor element (pos) is pinned in the list,\n * and list_safe_reset_next is called after re-taking the lock and before\n * completing the current iteration of the loop body.\n */\n#define list_safe_reset_next(pos, n, member)\t\t\t\t\\\n\tn = list_next_entry(pos, member)\n\n/*\n * Double linked lists with a single pointer list head.\n * Mostly useful for hash tables where the two pointer list head is\n * too wasteful.\n * You lose the ability to access the tail in O(1).\n */\n\n#define HLIST_HEAD_INIT { .first = NULL }\n#define HLIST_HEAD(name) struct hlist_head name = {  .first = NULL }\n#define INIT_HLIST_HEAD(ptr) ((ptr)->first = NULL)\nstatic inline void INIT_HLIST_NODE(struct hlist_node *h)\n{\n\th->next = NULL;\n\th->pprev = NULL;\n}\n\n/**\n * hlist_unhashed - Has node been removed from list and reinitialized?\n * @h: Node to be checked\n *\n * Not that not all removal functions will leave a node in unhashed\n * state.  For example, hlist_nulls_del_init_rcu() does leave the\n * node in unhashed state, but hlist_nulls_del() does not.\n */\nstatic inline int hlist_unhashed(const struct hlist_node *h)\n{\n\treturn !h->pprev;\n}\n\n/**\n * hlist_unhashed_lockless - Version of hlist_unhashed for lockless use\n * @h: Node to be checked\n *\n * This variant of hlist_unhashed() must be used in lockless contexts\n * to avoid potential load-tearing.  The READ_ONCE() is paired with the\n * various WRITE_ONCE() in hlist helpers that are defined below.\n */\nstatic inline int hlist_unhashed_lockless(const struct hlist_node *h)\n{\n\treturn !READ_ONCE(h->pprev);\n}\n\n/**\n * hlist_empty - Is the specified hlist_head structure an empty hlist?\n * @h: Structure to check.\n */\nstatic inline int hlist_empty(const struct hlist_head *h)\n{\n\treturn !READ_ONCE(h->first);\n}\n\nstatic inline void __hlist_del(struct hlist_node *n)\n{\n\tstruct hlist_node *next = n->next;\n\tstruct hlist_node **pprev = n->pprev;\n\n\tWRITE_ONCE(*pprev, next);\n\tif (next)\n\t\tWRITE_ONCE(next->pprev, pprev);\n}\n\n/**\n * hlist_del - Delete the specified hlist_node from its list\n * @n: Node to delete.\n *\n * Note that this function leaves the node in hashed state.  Use\n * hlist_del_init() or similar instead to unhash @n.\n */\nstatic inline void hlist_del(struct hlist_node *n)\n{\n\t__hlist_del(n);\n\tn->next = LIST_POISON1;\n\tn->pprev = LIST_POISON2;\n}\n\n/**\n * hlist_del_init - Delete the specified hlist_node from its list and initialize\n * @n: Node to delete.\n *\n * Note that this function leaves the node in unhashed state.\n */\nstatic inline void hlist_del_init(struct hlist_node *n)\n{\n\tif (!hlist_unhashed(n)) {\n\t\t__hlist_del(n);\n\t\tINIT_HLIST_NODE(n);\n\t}\n}\n\n/**\n * hlist_add_head - add a new entry at the beginning of the hlist\n * @n: new entry to be added\n * @h: hlist head to add it after\n *\n * Insert a new entry after the specified head.\n * This is good for implementing stacks.\n */\nstatic inline void hlist_add_head(struct hlist_node *n, struct hlist_head *h)\n{\n\tstruct hlist_node *first = h->first;\n\tWRITE_ONCE(n->next, first);\n\tif (first)\n\t\tWRITE_ONCE(first->pprev, &n->next);\n\tWRITE_ONCE(h->first, n);\n\tWRITE_ONCE(n->pprev, &h->first);\n}\n\n/**\n * hlist_add_before - add a new entry before the one specified\n * @n: new entry to be added\n * @next: hlist node to add it before, which must be non-NULL\n */\nstatic inline void hlist_add_before(struct hlist_node *n,\n\t\t\t\t    struct hlist_node *next)\n{\n\tWRITE_ONCE(n->pprev, next->pprev);\n\tWRITE_ONCE(n->next, next);\n\tWRITE_ONCE(next->pprev, &n->next);\n\tWRITE_ONCE(*(n->pprev), n);\n}\n\n/**\n * hlist_add_behind - add a new entry after the one specified\n * @n: new entry to be added\n * @prev: hlist node to add it after, which must be non-NULL\n */\nstatic inline void hlist_add_behind(struct hlist_node *n,\n\t\t\t\t    struct hlist_node *prev)\n{\n\tWRITE_ONCE(n->next, prev->next);\n\tWRITE_ONCE(prev->next, n);\n\tWRITE_ONCE(n->pprev, &prev->next);\n\n\tif (n->next)\n\t\tWRITE_ONCE(n->next->pprev, &n->next);\n}\n\n/**\n * hlist_add_fake - create a fake hlist consisting of a single headless node\n * @n: Node to make a fake list out of\n *\n * This makes @n appear to be its own predecessor on a headless hlist.\n * The point of this is to allow things like hlist_del() to work correctly\n * in cases where there is no list.\n */\nstatic inline void hlist_add_fake(struct hlist_node *n)\n{\n\tn->pprev = &n->next;\n}\n\n/**\n * hlist_fake: Is this node a fake hlist?\n * @h: Node to check for being a self-referential fake hlist.\n */\nstatic inline bool hlist_fake(struct hlist_node *h)\n{\n\treturn h->pprev == &h->next;\n}\n\n/**\n * hlist_is_singular_node - is node the only element of the specified hlist?\n * @n: Node to check for singularity.\n * @h: Header for potentially singular list.\n *\n * Check whether the node is the only node of the head without\n * accessing head, thus avoiding unnecessary cache misses.\n */\nstatic inline bool\nhlist_is_singular_node(struct hlist_node *n, struct hlist_head *h)\n{\n\treturn !n->next && n->pprev == &h->first;\n}\n\n/**\n * hlist_move_list - Move an hlist\n * @old: hlist_head for old list.\n * @new: hlist_head for new list.\n *\n * Move a list from one list head to another. Fixup the pprev\n * reference of the first entry if it exists.\n */\nstatic inline void hlist_move_list(struct hlist_head *old,\n\t\t\t\t   struct hlist_head *new)\n{\n\tnew->first = old->first;\n\tif (new->first)\n\t\tnew->first->pprev = &new->first;\n\told->first = NULL;\n}\n\n#define hlist_entry(ptr, type, member) container_of(ptr,type,member)\n\n#define hlist_for_each(pos, head) \\\n\tfor (pos = (head)->first; pos ; pos = pos->next)\n\n#define hlist_for_each_safe(pos, n, head) \\\n\tfor (pos = (head)->first; pos && ({ n = pos->next; 1; }); \\\n\t     pos = n)\n\n#define hlist_entry_safe(ptr, type, member) \\\n\t({ typeof(ptr) ____ptr = (ptr); \\\n\t   ____ptr ? hlist_entry(____ptr, type, member) : NULL; \\\n\t})\n\n/**\n * hlist_for_each_entry\t- iterate over list of given type\n * @pos:\tthe type * to use as a loop cursor.\n * @head:\tthe head for your list.\n * @member:\tthe name of the hlist_node within the struct.\n */\n#define hlist_for_each_entry(pos, head, member)\t\t\t\t\\\n\tfor (pos = hlist_entry_safe((head)->first, typeof(*(pos)), member);\\\n\t     pos;\t\t\t\t\t\t\t\\\n\t     pos = hlist_entry_safe((pos)->member.next, typeof(*(pos)), member))\n\n/**\n * hlist_for_each_entry_continue - iterate over a hlist continuing after current point\n * @pos:\tthe type * to use as a loop cursor.\n * @member:\tthe name of the hlist_node within the struct.\n */\n#define hlist_for_each_entry_continue(pos, member)\t\t\t\\\n\tfor (pos = hlist_entry_safe((pos)->member.next, typeof(*(pos)), member);\\\n\t     pos;\t\t\t\t\t\t\t\\\n\t     pos = hlist_entry_safe((pos)->member.next, typeof(*(pos)), member))\n\n/**\n * hlist_for_each_entry_from - iterate over a hlist continuing from current point\n * @pos:\tthe type * to use as a loop cursor.\n * @member:\tthe name of the hlist_node within the struct.\n */\n#define hlist_for_each_entry_from(pos, member)\t\t\t\t\\\n\tfor (; pos;\t\t\t\t\t\t\t\\\n\t     pos = hlist_entry_safe((pos)->member.next, typeof(*(pos)), member))\n\n/**\n * hlist_for_each_entry_safe - iterate over list of given type safe against removal of list entry\n * @pos:\tthe type * to use as a loop cursor.\n * @n:\t\ta &struct hlist_node to use as temporary storage\n * @head:\tthe head for your list.\n * @member:\tthe name of the hlist_node within the struct.\n */\n#define hlist_for_each_entry_safe(pos, n, head, member) \t\t\\\n\tfor (pos = hlist_entry_safe((head)->first, typeof(*pos), member);\\\n\t     pos && ({ n = pos->member.next; 1; });\t\t\t\\\n\t     pos = hlist_entry_safe(n, typeof(*pos), member))\n\n#endif\n"}, "8": {"id": 8, "path": "/src/include/linux/kernel.h", "content": "/* SPDX-License-Identifier: GPL-2.0 */\n#ifndef _LINUX_KERNEL_H\n#define _LINUX_KERNEL_H\n\n#include <stdarg.h>\n#include <linux/limits.h>\n#include <linux/linkage.h>\n#include <linux/stddef.h>\n#include <linux/types.h>\n#include <linux/compiler.h>\n#include <linux/bitops.h>\n#include <linux/log2.h>\n#include <linux/math.h>\n#include <linux/minmax.h>\n#include <linux/typecheck.h>\n#include <linux/printk.h>\n#include <linux/build_bug.h>\n#include <linux/static_call_types.h>\n#include <asm/byteorder.h>\n\n#include <uapi/linux/kernel.h>\n\n#define STACK_MAGIC\t0xdeadbeef\n\n/**\n * REPEAT_BYTE - repeat the value @x multiple times as an unsigned long value\n * @x: value to repeat\n *\n * NOTE: @x is not checked for > 0xff; larger values produce odd results.\n */\n#define REPEAT_BYTE(x)\t((~0ul / 0xff) * (x))\n\n/* @a is a power of 2 value */\n#define ALIGN(x, a)\t\t__ALIGN_KERNEL((x), (a))\n#define ALIGN_DOWN(x, a)\t__ALIGN_KERNEL((x) - ((a) - 1), (a))\n#define __ALIGN_MASK(x, mask)\t__ALIGN_KERNEL_MASK((x), (mask))\n#define PTR_ALIGN(p, a)\t\t((typeof(p))ALIGN((unsigned long)(p), (a)))\n#define PTR_ALIGN_DOWN(p, a)\t((typeof(p))ALIGN_DOWN((unsigned long)(p), (a)))\n#define IS_ALIGNED(x, a)\t\t(((x) & ((typeof(x))(a) - 1)) == 0)\n\n/* generic data direction definitions */\n#define READ\t\t\t0\n#define WRITE\t\t\t1\n\n/**\n * ARRAY_SIZE - get the number of elements in array @arr\n * @arr: array to be sized\n */\n#define ARRAY_SIZE(arr) (sizeof(arr) / sizeof((arr)[0]) + __must_be_array(arr))\n\n#define u64_to_user_ptr(x) (\t\t\\\n{\t\t\t\t\t\\\n\ttypecheck(u64, (x));\t\t\\\n\t(void __user *)(uintptr_t)(x);\t\\\n}\t\t\t\t\t\\\n)\n\n#define typeof_member(T, m)\ttypeof(((T*)0)->m)\n\n#define _RET_IP_\t\t(unsigned long)__builtin_return_address(0)\n#define _THIS_IP_  ({ __label__ __here; __here: (unsigned long)&&__here; })\n\n/**\n * upper_32_bits - return bits 32-63 of a number\n * @n: the number we're accessing\n *\n * A basic shift-right of a 64- or 32-bit quantity.  Use this to suppress\n * the \"right shift count >= width of type\" warning when that quantity is\n * 32-bits.\n */\n#define upper_32_bits(n) ((u32)(((n) >> 16) >> 16))\n\n/**\n * lower_32_bits - return bits 0-31 of a number\n * @n: the number we're accessing\n */\n#define lower_32_bits(n) ((u32)((n) & 0xffffffff))\n\nstruct completion;\nstruct pt_regs;\nstruct user;\n\n#ifdef CONFIG_PREEMPT_VOLUNTARY\n\nextern int __cond_resched(void);\n# define might_resched() __cond_resched()\n\n#elif defined(CONFIG_PREEMPT_DYNAMIC)\n\nextern int __cond_resched(void);\n\nDECLARE_STATIC_CALL(might_resched, __cond_resched);\n\nstatic __always_inline void might_resched(void)\n{\n\tstatic_call_mod(might_resched)();\n}\n\n#else\n\n# define might_resched() do { } while (0)\n\n#endif /* CONFIG_PREEMPT_* */\n\n#ifdef CONFIG_DEBUG_ATOMIC_SLEEP\nextern void ___might_sleep(const char *file, int line, int preempt_offset);\nextern void __might_sleep(const char *file, int line, int preempt_offset);\nextern void __cant_sleep(const char *file, int line, int preempt_offset);\nextern void __cant_migrate(const char *file, int line);\n\n/**\n * might_sleep - annotation for functions that can sleep\n *\n * this macro will print a stack trace if it is executed in an atomic\n * context (spinlock, irq-handler, ...). Additional sections where blocking is\n * not allowed can be annotated with non_block_start() and non_block_end()\n * pairs.\n *\n * This is a useful debugging help to be able to catch problems early and not\n * be bitten later when the calling function happens to sleep when it is not\n * supposed to.\n */\n# define might_sleep() \\\n\tdo { __might_sleep(__FILE__, __LINE__, 0); might_resched(); } while (0)\n/**\n * cant_sleep - annotation for functions that cannot sleep\n *\n * this macro will print a stack trace if it is executed with preemption enabled\n */\n# define cant_sleep() \\\n\tdo { __cant_sleep(__FILE__, __LINE__, 0); } while (0)\n# define sched_annotate_sleep()\t(current->task_state_change = 0)\n\n/**\n * cant_migrate - annotation for functions that cannot migrate\n *\n * Will print a stack trace if executed in code which is migratable\n */\n# define cant_migrate()\t\t\t\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tif (IS_ENABLED(CONFIG_SMP))\t\t\t\t\\\n\t\t\t__cant_migrate(__FILE__, __LINE__);\t\t\\\n\t} while (0)\n\n/**\n * non_block_start - annotate the start of section where sleeping is prohibited\n *\n * This is on behalf of the oom reaper, specifically when it is calling the mmu\n * notifiers. The problem is that if the notifier were to block on, for example,\n * mutex_lock() and if the process which holds that mutex were to perform a\n * sleeping memory allocation, the oom reaper is now blocked on completion of\n * that memory allocation. Other blocking calls like wait_event() pose similar\n * issues.\n */\n# define non_block_start() (current->non_block_count++)\n/**\n * non_block_end - annotate the end of section where sleeping is prohibited\n *\n * Closes a section opened by non_block_start().\n */\n# define non_block_end() WARN_ON(current->non_block_count-- == 0)\n#else\n  static inline void ___might_sleep(const char *file, int line,\n\t\t\t\t   int preempt_offset) { }\n  static inline void __might_sleep(const char *file, int line,\n\t\t\t\t   int preempt_offset) { }\n# define might_sleep() do { might_resched(); } while (0)\n# define cant_sleep() do { } while (0)\n# define cant_migrate()\t\tdo { } while (0)\n# define sched_annotate_sleep() do { } while (0)\n# define non_block_start() do { } while (0)\n# define non_block_end() do { } while (0)\n#endif\n\n#define might_sleep_if(cond) do { if (cond) might_sleep(); } while (0)\n\n#if defined(CONFIG_MMU) && \\\n\t(defined(CONFIG_PROVE_LOCKING) || defined(CONFIG_DEBUG_ATOMIC_SLEEP))\n#define might_fault() __might_fault(__FILE__, __LINE__)\nvoid __might_fault(const char *file, int line);\n#else\nstatic inline void might_fault(void) { }\n#endif\n\nextern struct atomic_notifier_head panic_notifier_list;\nextern long (*panic_blink)(int state);\n__printf(1, 2)\nvoid panic(const char *fmt, ...) __noreturn __cold;\nvoid nmi_panic(struct pt_regs *regs, const char *msg);\nextern void oops_enter(void);\nextern void oops_exit(void);\nextern bool oops_may_print(void);\nvoid do_exit(long error_code) __noreturn;\nvoid complete_and_exit(struct completion *, long) __noreturn;\n\n/* Internal, do not use. */\nint __must_check _kstrtoul(const char *s, unsigned int base, unsigned long *res);\nint __must_check _kstrtol(const char *s, unsigned int base, long *res);\n\nint __must_check kstrtoull(const char *s, unsigned int base, unsigned long long *res);\nint __must_check kstrtoll(const char *s, unsigned int base, long long *res);\n\n/**\n * kstrtoul - convert a string to an unsigned long\n * @s: The start of the string. The string must be null-terminated, and may also\n *  include a single newline before its terminating null. The first character\n *  may also be a plus sign, but not a minus sign.\n * @base: The number base to use. The maximum supported base is 16. If base is\n *  given as 0, then the base of the string is automatically detected with the\n *  conventional semantics - If it begins with 0x the number will be parsed as a\n *  hexadecimal (case insensitive), if it otherwise begins with 0, it will be\n *  parsed as an octal number. Otherwise it will be parsed as a decimal.\n * @res: Where to write the result of the conversion on success.\n *\n * Returns 0 on success, -ERANGE on overflow and -EINVAL on parsing error.\n * Preferred over simple_strtoul(). Return code must be checked.\n*/\nstatic inline int __must_check kstrtoul(const char *s, unsigned int base, unsigned long *res)\n{\n\t/*\n\t * We want to shortcut function call, but\n\t * __builtin_types_compatible_p(unsigned long, unsigned long long) = 0.\n\t */\n\tif (sizeof(unsigned long) == sizeof(unsigned long long) &&\n\t    __alignof__(unsigned long) == __alignof__(unsigned long long))\n\t\treturn kstrtoull(s, base, (unsigned long long *)res);\n\telse\n\t\treturn _kstrtoul(s, base, res);\n}\n\n/**\n * kstrtol - convert a string to a long\n * @s: The start of the string. The string must be null-terminated, and may also\n *  include a single newline before its terminating null. The first character\n *  may also be a plus sign or a minus sign.\n * @base: The number base to use. The maximum supported base is 16. If base is\n *  given as 0, then the base of the string is automatically detected with the\n *  conventional semantics - If it begins with 0x the number will be parsed as a\n *  hexadecimal (case insensitive), if it otherwise begins with 0, it will be\n *  parsed as an octal number. Otherwise it will be parsed as a decimal.\n * @res: Where to write the result of the conversion on success.\n *\n * Returns 0 on success, -ERANGE on overflow and -EINVAL on parsing error.\n * Preferred over simple_strtol(). Return code must be checked.\n */\nstatic inline int __must_check kstrtol(const char *s, unsigned int base, long *res)\n{\n\t/*\n\t * We want to shortcut function call, but\n\t * __builtin_types_compatible_p(long, long long) = 0.\n\t */\n\tif (sizeof(long) == sizeof(long long) &&\n\t    __alignof__(long) == __alignof__(long long))\n\t\treturn kstrtoll(s, base, (long long *)res);\n\telse\n\t\treturn _kstrtol(s, base, res);\n}\n\nint __must_check kstrtouint(const char *s, unsigned int base, unsigned int *res);\nint __must_check kstrtoint(const char *s, unsigned int base, int *res);\n\nstatic inline int __must_check kstrtou64(const char *s, unsigned int base, u64 *res)\n{\n\treturn kstrtoull(s, base, res);\n}\n\nstatic inline int __must_check kstrtos64(const char *s, unsigned int base, s64 *res)\n{\n\treturn kstrtoll(s, base, res);\n}\n\nstatic inline int __must_check kstrtou32(const char *s, unsigned int base, u32 *res)\n{\n\treturn kstrtouint(s, base, res);\n}\n\nstatic inline int __must_check kstrtos32(const char *s, unsigned int base, s32 *res)\n{\n\treturn kstrtoint(s, base, res);\n}\n\nint __must_check kstrtou16(const char *s, unsigned int base, u16 *res);\nint __must_check kstrtos16(const char *s, unsigned int base, s16 *res);\nint __must_check kstrtou8(const char *s, unsigned int base, u8 *res);\nint __must_check kstrtos8(const char *s, unsigned int base, s8 *res);\nint __must_check kstrtobool(const char *s, bool *res);\n\nint __must_check kstrtoull_from_user(const char __user *s, size_t count, unsigned int base, unsigned long long *res);\nint __must_check kstrtoll_from_user(const char __user *s, size_t count, unsigned int base, long long *res);\nint __must_check kstrtoul_from_user(const char __user *s, size_t count, unsigned int base, unsigned long *res);\nint __must_check kstrtol_from_user(const char __user *s, size_t count, unsigned int base, long *res);\nint __must_check kstrtouint_from_user(const char __user *s, size_t count, unsigned int base, unsigned int *res);\nint __must_check kstrtoint_from_user(const char __user *s, size_t count, unsigned int base, int *res);\nint __must_check kstrtou16_from_user(const char __user *s, size_t count, unsigned int base, u16 *res);\nint __must_check kstrtos16_from_user(const char __user *s, size_t count, unsigned int base, s16 *res);\nint __must_check kstrtou8_from_user(const char __user *s, size_t count, unsigned int base, u8 *res);\nint __must_check kstrtos8_from_user(const char __user *s, size_t count, unsigned int base, s8 *res);\nint __must_check kstrtobool_from_user(const char __user *s, size_t count, bool *res);\n\nstatic inline int __must_check kstrtou64_from_user(const char __user *s, size_t count, unsigned int base, u64 *res)\n{\n\treturn kstrtoull_from_user(s, count, base, res);\n}\n\nstatic inline int __must_check kstrtos64_from_user(const char __user *s, size_t count, unsigned int base, s64 *res)\n{\n\treturn kstrtoll_from_user(s, count, base, res);\n}\n\nstatic inline int __must_check kstrtou32_from_user(const char __user *s, size_t count, unsigned int base, u32 *res)\n{\n\treturn kstrtouint_from_user(s, count, base, res);\n}\n\nstatic inline int __must_check kstrtos32_from_user(const char __user *s, size_t count, unsigned int base, s32 *res)\n{\n\treturn kstrtoint_from_user(s, count, base, res);\n}\n\n/*\n * Use kstrto<foo> instead.\n *\n * NOTE: simple_strto<foo> does not check for the range overflow and,\n *\t depending on the input, may give interesting results.\n *\n * Use these functions if and only if you cannot use kstrto<foo>, because\n * the conversion ends on the first non-digit character, which may be far\n * beyond the supported range. It might be useful to parse the strings like\n * 10x50 or 12:21 without altering original string or temporary buffer in use.\n * Keep in mind above caveat.\n */\n\nextern unsigned long simple_strtoul(const char *,char **,unsigned int);\nextern long simple_strtol(const char *,char **,unsigned int);\nextern unsigned long long simple_strtoull(const char *,char **,unsigned int);\nextern long long simple_strtoll(const char *,char **,unsigned int);\n\nextern int num_to_str(char *buf, int size,\n\t\t      unsigned long long num, unsigned int width);\n\n/* lib/printf utilities */\n\nextern __printf(2, 3) int sprintf(char *buf, const char * fmt, ...);\nextern __printf(2, 0) int vsprintf(char *buf, const char *, va_list);\nextern __printf(3, 4)\nint snprintf(char *buf, size_t size, const char *fmt, ...);\nextern __printf(3, 0)\nint vsnprintf(char *buf, size_t size, const char *fmt, va_list args);\nextern __printf(3, 4)\nint scnprintf(char *buf, size_t size, const char *fmt, ...);\nextern __printf(3, 0)\nint vscnprintf(char *buf, size_t size, const char *fmt, va_list args);\nextern __printf(2, 3) __malloc\nchar *kasprintf(gfp_t gfp, const char *fmt, ...);\nextern __printf(2, 0) __malloc\nchar *kvasprintf(gfp_t gfp, const char *fmt, va_list args);\nextern __printf(2, 0)\nconst char *kvasprintf_const(gfp_t gfp, const char *fmt, va_list args);\n\nextern __scanf(2, 3)\nint sscanf(const char *, const char *, ...);\nextern __scanf(2, 0)\nint vsscanf(const char *, const char *, va_list);\n\nextern int get_option(char **str, int *pint);\nextern char *get_options(const char *str, int nints, int *ints);\nextern unsigned long long memparse(const char *ptr, char **retptr);\nextern bool parse_option_str(const char *str, const char *option);\nextern char *next_arg(char *args, char **param, char **val);\n\nextern int core_kernel_text(unsigned long addr);\nextern int init_kernel_text(unsigned long addr);\nextern int core_kernel_data(unsigned long addr);\nextern int __kernel_text_address(unsigned long addr);\nextern int kernel_text_address(unsigned long addr);\nextern int func_ptr_is_kernel_text(void *ptr);\n\n#ifdef CONFIG_SMP\nextern unsigned int sysctl_oops_all_cpu_backtrace;\n#else\n#define sysctl_oops_all_cpu_backtrace 0\n#endif /* CONFIG_SMP */\n\nextern void bust_spinlocks(int yes);\nextern int panic_timeout;\nextern unsigned long panic_print;\nextern int panic_on_oops;\nextern int panic_on_unrecovered_nmi;\nextern int panic_on_io_nmi;\nextern int panic_on_warn;\nextern unsigned long panic_on_taint;\nextern bool panic_on_taint_nousertaint;\nextern int sysctl_panic_on_rcu_stall;\nextern int sysctl_max_rcu_stall_to_panic;\nextern int sysctl_panic_on_stackoverflow;\n\nextern bool crash_kexec_post_notifiers;\n\n/*\n * panic_cpu is used for synchronizing panic() and crash_kexec() execution. It\n * holds a CPU number which is executing panic() currently. A value of\n * PANIC_CPU_INVALID means no CPU has entered panic() or crash_kexec().\n */\nextern atomic_t panic_cpu;\n#define PANIC_CPU_INVALID\t-1\n\n/*\n * Only to be used by arch init code. If the user over-wrote the default\n * CONFIG_PANIC_TIMEOUT, honor it.\n */\nstatic inline void set_arch_panic_timeout(int timeout, int arch_default_timeout)\n{\n\tif (panic_timeout == arch_default_timeout)\n\t\tpanic_timeout = timeout;\n}\nextern const char *print_tainted(void);\nenum lockdep_ok {\n\tLOCKDEP_STILL_OK,\n\tLOCKDEP_NOW_UNRELIABLE\n};\nextern void add_taint(unsigned flag, enum lockdep_ok);\nextern int test_taint(unsigned flag);\nextern unsigned long get_taint(void);\nextern int root_mountflags;\n\nextern bool early_boot_irqs_disabled;\n\n/*\n * Values used for system_state. Ordering of the states must not be changed\n * as code checks for <, <=, >, >= STATE.\n */\nextern enum system_states {\n\tSYSTEM_BOOTING,\n\tSYSTEM_SCHEDULING,\n\tSYSTEM_RUNNING,\n\tSYSTEM_HALT,\n\tSYSTEM_POWER_OFF,\n\tSYSTEM_RESTART,\n\tSYSTEM_SUSPEND,\n} system_state;\n\n/* This cannot be an enum because some may be used in assembly source. */\n#define TAINT_PROPRIETARY_MODULE\t0\n#define TAINT_FORCED_MODULE\t\t1\n#define TAINT_CPU_OUT_OF_SPEC\t\t2\n#define TAINT_FORCED_RMMOD\t\t3\n#define TAINT_MACHINE_CHECK\t\t4\n#define TAINT_BAD_PAGE\t\t\t5\n#define TAINT_USER\t\t\t6\n#define TAINT_DIE\t\t\t7\n#define TAINT_OVERRIDDEN_ACPI_TABLE\t8\n#define TAINT_WARN\t\t\t9\n#define TAINT_CRAP\t\t\t10\n#define TAINT_FIRMWARE_WORKAROUND\t11\n#define TAINT_OOT_MODULE\t\t12\n#define TAINT_UNSIGNED_MODULE\t\t13\n#define TAINT_SOFTLOCKUP\t\t14\n#define TAINT_LIVEPATCH\t\t\t15\n#define TAINT_AUX\t\t\t16\n#define TAINT_RANDSTRUCT\t\t17\n#define TAINT_FLAGS_COUNT\t\t18\n#define TAINT_FLAGS_MAX\t\t\t((1UL << TAINT_FLAGS_COUNT) - 1)\n\nstruct taint_flag {\n\tchar c_true;\t/* character printed when tainted */\n\tchar c_false;\t/* character printed when not tainted */\n\tbool module;\t/* also show as a per-module taint flag */\n};\n\nextern const struct taint_flag taint_flags[TAINT_FLAGS_COUNT];\n\nextern const char hex_asc[];\n#define hex_asc_lo(x)\thex_asc[((x) & 0x0f)]\n#define hex_asc_hi(x)\thex_asc[((x) & 0xf0) >> 4]\n\nstatic inline char *hex_byte_pack(char *buf, u8 byte)\n{\n\t*buf++ = hex_asc_hi(byte);\n\t*buf++ = hex_asc_lo(byte);\n\treturn buf;\n}\n\nextern const char hex_asc_upper[];\n#define hex_asc_upper_lo(x)\thex_asc_upper[((x) & 0x0f)]\n#define hex_asc_upper_hi(x)\thex_asc_upper[((x) & 0xf0) >> 4]\n\nstatic inline char *hex_byte_pack_upper(char *buf, u8 byte)\n{\n\t*buf++ = hex_asc_upper_hi(byte);\n\t*buf++ = hex_asc_upper_lo(byte);\n\treturn buf;\n}\n\nextern int hex_to_bin(char ch);\nextern int __must_check hex2bin(u8 *dst, const char *src, size_t count);\nextern char *bin2hex(char *dst, const void *src, size_t count);\n\nbool mac_pton(const char *s, u8 *mac);\n\n/*\n * General tracing related utility functions - trace_printk(),\n * tracing_on/tracing_off and tracing_start()/tracing_stop\n *\n * Use tracing_on/tracing_off when you want to quickly turn on or off\n * tracing. It simply enables or disables the recording of the trace events.\n * This also corresponds to the user space /sys/kernel/debug/tracing/tracing_on\n * file, which gives a means for the kernel and userspace to interact.\n * Place a tracing_off() in the kernel where you want tracing to end.\n * From user space, examine the trace, and then echo 1 > tracing_on\n * to continue tracing.\n *\n * tracing_stop/tracing_start has slightly more overhead. It is used\n * by things like suspend to ram where disabling the recording of the\n * trace is not enough, but tracing must actually stop because things\n * like calling smp_processor_id() may crash the system.\n *\n * Most likely, you want to use tracing_on/tracing_off.\n */\n\nenum ftrace_dump_mode {\n\tDUMP_NONE,\n\tDUMP_ALL,\n\tDUMP_ORIG,\n};\n\n#ifdef CONFIG_TRACING\nvoid tracing_on(void);\nvoid tracing_off(void);\nint tracing_is_on(void);\nvoid tracing_snapshot(void);\nvoid tracing_snapshot_alloc(void);\n\nextern void tracing_start(void);\nextern void tracing_stop(void);\n\nstatic inline __printf(1, 2)\nvoid ____trace_printk_check_format(const char *fmt, ...)\n{\n}\n#define __trace_printk_check_format(fmt, args...)\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tif (0)\t\t\t\t\t\t\t\t\\\n\t\t____trace_printk_check_format(fmt, ##args);\t\t\\\n} while (0)\n\n/**\n * trace_printk - printf formatting in the ftrace buffer\n * @fmt: the printf format for printing\n *\n * Note: __trace_printk is an internal function for trace_printk() and\n *       the @ip is passed in via the trace_printk() macro.\n *\n * This function allows a kernel developer to debug fast path sections\n * that printk is not appropriate for. By scattering in various\n * printk like tracing in the code, a developer can quickly see\n * where problems are occurring.\n *\n * This is intended as a debugging tool for the developer only.\n * Please refrain from leaving trace_printks scattered around in\n * your code. (Extra memory is used for special buffers that are\n * allocated when trace_printk() is used.)\n *\n * A little optimization trick is done here. If there's only one\n * argument, there's no need to scan the string for printf formats.\n * The trace_puts() will suffice. But how can we take advantage of\n * using trace_puts() when trace_printk() has only one argument?\n * By stringifying the args and checking the size we can tell\n * whether or not there are args. __stringify((__VA_ARGS__)) will\n * turn into \"()\\0\" with a size of 3 when there are no args, anything\n * else will be bigger. All we need to do is define a string to this,\n * and then take its size and compare to 3. If it's bigger, use\n * do_trace_printk() otherwise, optimize it to trace_puts(). Then just\n * let gcc optimize the rest.\n */\n\n#define trace_printk(fmt, ...)\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\\\n\tchar _______STR[] = __stringify((__VA_ARGS__));\t\\\n\tif (sizeof(_______STR) > 3)\t\t\t\\\n\t\tdo_trace_printk(fmt, ##__VA_ARGS__);\t\\\n\telse\t\t\t\t\t\t\\\n\t\ttrace_puts(fmt);\t\t\t\\\n} while (0)\n\n#define do_trace_printk(fmt, args...)\t\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tstatic const char *trace_printk_fmt __used\t\t\t\\\n\t\t__section(\"__trace_printk_fmt\") =\t\t\t\\\n\t\t__builtin_constant_p(fmt) ? fmt : NULL;\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\t__trace_printk_check_format(fmt, ##args);\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tif (__builtin_constant_p(fmt))\t\t\t\t\t\\\n\t\t__trace_bprintk(_THIS_IP_, trace_printk_fmt, ##args);\t\\\n\telse\t\t\t\t\t\t\t\t\\\n\t\t__trace_printk(_THIS_IP_, fmt, ##args);\t\t\t\\\n} while (0)\n\nextern __printf(2, 3)\nint __trace_bprintk(unsigned long ip, const char *fmt, ...);\n\nextern __printf(2, 3)\nint __trace_printk(unsigned long ip, const char *fmt, ...);\n\n/**\n * trace_puts - write a string into the ftrace buffer\n * @str: the string to record\n *\n * Note: __trace_bputs is an internal function for trace_puts and\n *       the @ip is passed in via the trace_puts macro.\n *\n * This is similar to trace_printk() but is made for those really fast\n * paths that a developer wants the least amount of \"Heisenbug\" effects,\n * where the processing of the print format is still too much.\n *\n * This function allows a kernel developer to debug fast path sections\n * that printk is not appropriate for. By scattering in various\n * printk like tracing in the code, a developer can quickly see\n * where problems are occurring.\n *\n * This is intended as a debugging tool for the developer only.\n * Please refrain from leaving trace_puts scattered around in\n * your code. (Extra memory is used for special buffers that are\n * allocated when trace_puts() is used.)\n *\n * Returns: 0 if nothing was written, positive # if string was.\n *  (1 when __trace_bputs is used, strlen(str) when __trace_puts is used)\n */\n\n#define trace_puts(str) ({\t\t\t\t\t\t\\\n\tstatic const char *trace_printk_fmt __used\t\t\t\\\n\t\t__section(\"__trace_printk_fmt\") =\t\t\t\\\n\t\t__builtin_constant_p(str) ? str : NULL;\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tif (__builtin_constant_p(str))\t\t\t\t\t\\\n\t\t__trace_bputs(_THIS_IP_, trace_printk_fmt);\t\t\\\n\telse\t\t\t\t\t\t\t\t\\\n\t\t__trace_puts(_THIS_IP_, str, strlen(str));\t\t\\\n})\nextern int __trace_bputs(unsigned long ip, const char *str);\nextern int __trace_puts(unsigned long ip, const char *str, int size);\n\nextern void trace_dump_stack(int skip);\n\n/*\n * The double __builtin_constant_p is because gcc will give us an error\n * if we try to allocate the static variable to fmt if it is not a\n * constant. Even with the outer if statement.\n */\n#define ftrace_vprintk(fmt, vargs)\t\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tif (__builtin_constant_p(fmt)) {\t\t\t\t\\\n\t\tstatic const char *trace_printk_fmt __used\t\t\\\n\t\t  __section(\"__trace_printk_fmt\") =\t\t\t\\\n\t\t\t__builtin_constant_p(fmt) ? fmt : NULL;\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\t\t__ftrace_vbprintk(_THIS_IP_, trace_printk_fmt, vargs);\t\\\n\t} else\t\t\t\t\t\t\t\t\\\n\t\t__ftrace_vprintk(_THIS_IP_, fmt, vargs);\t\t\\\n} while (0)\n\nextern __printf(2, 0) int\n__ftrace_vbprintk(unsigned long ip, const char *fmt, va_list ap);\n\nextern __printf(2, 0) int\n__ftrace_vprintk(unsigned long ip, const char *fmt, va_list ap);\n\nextern void ftrace_dump(enum ftrace_dump_mode oops_dump_mode);\n#else\nstatic inline void tracing_start(void) { }\nstatic inline void tracing_stop(void) { }\nstatic inline void trace_dump_stack(int skip) { }\n\nstatic inline void tracing_on(void) { }\nstatic inline void tracing_off(void) { }\nstatic inline int tracing_is_on(void) { return 0; }\nstatic inline void tracing_snapshot(void) { }\nstatic inline void tracing_snapshot_alloc(void) { }\n\nstatic inline __printf(1, 2)\nint trace_printk(const char *fmt, ...)\n{\n\treturn 0;\n}\nstatic __printf(1, 0) inline int\nftrace_vprintk(const char *fmt, va_list ap)\n{\n\treturn 0;\n}\nstatic inline void ftrace_dump(enum ftrace_dump_mode oops_dump_mode) { }\n#endif /* CONFIG_TRACING */\n\n/* This counts to 12. Any more, it will return 13th argument. */\n#define __COUNT_ARGS(_0, _1, _2, _3, _4, _5, _6, _7, _8, _9, _10, _11, _12, _n, X...) _n\n#define COUNT_ARGS(X...) __COUNT_ARGS(, ##X, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0)\n\n#define __CONCAT(a, b) a ## b\n#define CONCATENATE(a, b) __CONCAT(a, b)\n\n/**\n * container_of - cast a member of a structure out to the containing structure\n * @ptr:\tthe pointer to the member.\n * @type:\tthe type of the container struct this is embedded in.\n * @member:\tthe name of the member within the struct.\n *\n */\n#define container_of(ptr, type, member) ({\t\t\t\t\\\n\tvoid *__mptr = (void *)(ptr);\t\t\t\t\t\\\n\tBUILD_BUG_ON_MSG(!__same_type(*(ptr), ((type *)0)->member) &&\t\\\n\t\t\t !__same_type(*(ptr), void),\t\t\t\\\n\t\t\t \"pointer type mismatch in container_of()\");\t\\\n\t((type *)(__mptr - offsetof(type, member))); })\n\n/**\n * container_of_safe - cast a member of a structure out to the containing structure\n * @ptr:\tthe pointer to the member.\n * @type:\tthe type of the container struct this is embedded in.\n * @member:\tthe name of the member within the struct.\n *\n * If IS_ERR_OR_NULL(ptr), ptr is returned unchanged.\n */\n#define container_of_safe(ptr, type, member) ({\t\t\t\t\\\n\tvoid *__mptr = (void *)(ptr);\t\t\t\t\t\\\n\tBUILD_BUG_ON_MSG(!__same_type(*(ptr), ((type *)0)->member) &&\t\\\n\t\t\t !__same_type(*(ptr), void),\t\t\t\\\n\t\t\t \"pointer type mismatch in container_of()\");\t\\\n\tIS_ERR_OR_NULL(__mptr) ? ERR_CAST(__mptr) :\t\t\t\\\n\t\t((type *)(__mptr - offsetof(type, member))); })\n\n/* Rebuild everything on CONFIG_FTRACE_MCOUNT_RECORD */\n#ifdef CONFIG_FTRACE_MCOUNT_RECORD\n# define REBUILD_DUE_TO_FTRACE_MCOUNT_RECORD\n#endif\n\n/* Permissions on a sysfs file: you didn't miss the 0 prefix did you? */\n#define VERIFY_OCTAL_PERMISSIONS(perms)\t\t\t\t\t\t\\\n\t(BUILD_BUG_ON_ZERO((perms) < 0) +\t\t\t\t\t\\\n\t BUILD_BUG_ON_ZERO((perms) > 0777) +\t\t\t\t\t\\\n\t /* USER_READABLE >= GROUP_READABLE >= OTHER_READABLE */\t\t\\\n\t BUILD_BUG_ON_ZERO((((perms) >> 6) & 4) < (((perms) >> 3) & 4)) +\t\\\n\t BUILD_BUG_ON_ZERO((((perms) >> 3) & 4) < ((perms) & 4)) +\t\t\\\n\t /* USER_WRITABLE >= GROUP_WRITABLE */\t\t\t\t\t\\\n\t BUILD_BUG_ON_ZERO((((perms) >> 6) & 2) < (((perms) >> 3) & 2)) +\t\\\n\t /* OTHER_WRITABLE?  Generally considered a bad idea. */\t\t\\\n\t BUILD_BUG_ON_ZERO((perms) & 2) +\t\t\t\t\t\\\n\t (perms))\n#endif\n"}}, "reports": [{"events": [{"location": {"col": 6, "file": 0, "line": 6280}, "message": "Assuming the condition is false"}, {"location": {"col": 2, "file": 0, "line": 6280}, "message": "Taking false branch"}, {"location": {"col": 6, "file": 0, "line": 6286}, "message": "Assuming 'ret' is equal to 0"}, {"location": {"col": 2, "file": 0, "line": 6286}, "message": "Taking false branch"}, {"location": {"col": 6, "file": 0, "line": 6289}, "message": "Assuming 'write' is not equal to 0"}, {"location": {"col": 2, "file": 0, "line": 6289}, "message": "Taking true branch"}, {"location": {"col": 3, "file": 0, "line": 6290}, "message": "Taking false branch"}, {"location": {"col": 7, "file": 0, "line": 6295}, "message": "Assuming 'idev' is non-null"}, {"location": {"col": 3, "file": 0, "line": 6295}, "message": "Taking true branch"}, {"location": {"col": 4, "file": 0, "line": 6296}, "message": "Taking false branch"}, {"location": {"col": 8, "file": 0, "line": 6301}, "message": "Assuming 'new_val' is not equal to field 'addr_gen_mode'"}, {"location": {"col": 4, "file": 0, "line": 6301}, "message": "Taking true branch"}, {"location": {"col": 5, "file": 0, "line": 6303}, "message": "Calling 'addrconf_dev_config'"}, {"location": {"col": 2, "file": 0, "line": 3329}, "message": "Assuming the condition is false"}, {"location": {"col": 12, "file": 1, "line": 110}, "message": "expanded from macro 'ASSERT_RTNL'"}, {"location": {"col": 27, "file": 2, "line": 157}, "message": "expanded from macro 'WARN_ONCE'"}, {"location": {"col": 2, "file": 0, "line": 3329}, "message": "'__ret_warn_once' is 0"}, {"location": {"col": 2, "file": 1, "line": 110}, "message": "expanded from macro 'ASSERT_RTNL'"}, {"location": {"col": 15, "file": 2, "line": 159}, "message": "expanded from macro 'WARN_ONCE'"}, {"location": {"col": 42, "file": 3, "line": 78}, "message": "expanded from macro 'unlikely'"}, {"location": {"col": 2, "file": 0, "line": 3329}, "message": "Left side of '&&' is false"}, {"location": {"col": 2, "file": 1, "line": 110}, "message": "expanded from macro 'ASSERT_RTNL'"}, {"location": {"col": 31, "file": 2, "line": 159}, "message": "expanded from macro 'WARN_ONCE'"}, {"location": {"col": 2, "file": 0, "line": 3329}, "message": "Taking false branch"}, {"location": {"col": 2, "file": 1, "line": 110}, "message": "expanded from macro 'ASSERT_RTNL'"}, {"location": {"col": 2, "file": 2, "line": 159}, "message": "expanded from macro 'WARN_ONCE'"}, {"location": {"col": 7, "file": 0, "line": 3331}, "message": "Assuming field 'type' is equal to ARPHRD_ETHER"}, {"location": {"col": 34, "file": 0, "line": 3331}, "message": "Left side of '&&' is false"}, {"location": {"col": 9, "file": 0, "line": 3351}, "message": "Calling 'addrconf_add_dev'"}, {"location": {"col": 2, "file": 0, "line": 2486}, "message": "Assuming the condition is false"}, {"location": {"col": 12, "file": 1, "line": 110}, "message": "expanded from macro 'ASSERT_RTNL'"}, {"location": {"col": 27, "file": 2, "line": 157}, "message": "expanded from macro 'WARN_ONCE'"}, {"location": {"col": 2, "file": 0, "line": 2486}, "message": "'__ret_warn_once' is 0"}, {"location": {"col": 2, "file": 1, "line": 110}, "message": "expanded from macro 'ASSERT_RTNL'"}, {"location": {"col": 15, "file": 2, "line": 159}, "message": "expanded from macro 'WARN_ONCE'"}, {"location": {"col": 42, "file": 3, "line": 78}, "message": "expanded from macro 'unlikely'"}, {"location": {"col": 2, "file": 0, "line": 2486}, "message": "Left side of '&&' is false"}, {"location": {"col": 2, "file": 1, "line": 110}, "message": "expanded from macro 'ASSERT_RTNL'"}, {"location": {"col": 31, "file": 2, "line": 159}, "message": "expanded from macro 'WARN_ONCE'"}, {"location": {"col": 2, "file": 0, "line": 2486}, "message": "Taking false branch"}, {"location": {"col": 2, "file": 1, "line": 110}, "message": "expanded from macro 'ASSERT_RTNL'"}, {"location": {"col": 2, "file": 2, "line": 159}, "message": "expanded from macro 'WARN_ONCE'"}, {"location": {"col": 2, "file": 0, "line": 2489}, "message": "Taking false branch"}, {"location": {"col": 6, "file": 0, "line": 2492}, "message": "Assuming field 'disable_ipv6' is 0"}, {"location": {"col": 2, "file": 0, "line": 2492}, "message": "Taking false branch"}, {"location": {"col": 6, "file": 0, "line": 2496}, "message": "Assuming the condition is false"}, {"location": {"col": 35, "file": 0, "line": 2496}, "message": "Left side of '&&' is false"}, {"location": {"col": 9, "file": 0, "line": 3351}, "message": "Returning from 'addrconf_add_dev'"}, {"location": {"col": 2, "file": 0, "line": 3352}, "message": "Taking false branch"}, {"location": {"col": 6, "file": 0, "line": 3356}, "message": "Assuming field 'type' is not equal to ARPHRD_NONE"}, {"location": {"col": 31, "file": 0, "line": 3356}, "message": "Left side of '&&' is false"}, {"location": {"col": 2, "file": 0, "line": 3360}, "message": "Calling 'addrconf_addr_gen'"}, {"location": {"col": 6, "file": 0, "line": 3286}, "message": "Assuming the condition is false"}, {"location": {"col": 2, "file": 0, "line": 3286}, "message": "Taking false branch"}, {"location": {"col": 6, "file": 0, "line": 3290}, "message": "Assuming the condition is false"}, {"location": {"col": 2, "file": 0, "line": 3290}, "message": "Taking false branch"}, {"location": {"col": 2, "file": 0, "line": 3295}, "message": "Control jumps to 'case IN6_ADDR_GEN_MODE_EUI64:'  at line 3307"}, {"location": {"col": 3, "file": 0, "line": 3312}, "message": "Taking true branch"}, {"location": {"col": 4, "file": 0, "line": 3313}, "message": "Calling 'addrconf_add_linklocal'"}, {"location": {"col": 8, "file": 0, "line": 3182}, "message": "Calling 'ipv6_add_addr'"}, {"location": {"col": 20, "file": 0, "line": 1042}, "message": "'can_block' is true"}, {"location": {"col": 20, "file": 0, "line": 1042}, "message": "'?' condition is true"}, {"location": {"col": 6, "file": 0, "line": 1049}, "message": "Assuming 'addr_type' is not equal to IPV6_ADDR_ANY"}, {"location": {"col": 6, "file": 0, "line": 1049}, "message": "Left side of '||' is false"}, {"location": {"col": 7, "file": 0, "line": 1050}, "message": "Assuming the condition is false"}, {"location": {"col": 39, "file": 0, "line": 1050}, "message": "Left side of '&&' is false"}, {"location": {"col": 7, "file": 0, "line": 1052}, "message": "Assuming the condition is false"}, {"location": {"col": 42, "file": 0, "line": 1052}, "message": "Left side of '&&' is false"}, {"location": {"col": 6, "file": 0, "line": 1057}, "message": "Assuming field 'dead' is 0"}, {"location": {"col": 2, "file": 0, "line": 1057}, "message": "Taking false branch"}, {"location": {"col": 16, "file": 0, "line": 1062}, "message": "Field 'disable_ipv6' is 0"}, {"location": {"col": 2, "file": 0, "line": 1062}, "message": "Taking false branch"}, {"location": {"col": 6, "file": 0, "line": 1070}, "message": "'can_block' is true"}, {"location": {"col": 2, "file": 0, "line": 1070}, "message": "Taking true branch"}, {"location": {"col": 7, "file": 0, "line": 1079}, "message": "Assuming 'err' is >= 0"}, {"location": {"col": 3, "file": 0, "line": 1079}, "message": "Taking false branch"}, {"location": {"col": 8, "file": 0, "line": 1083}, "message": "Calling 'kzalloc'"}, {"location": {"col": 9, "file": 4, "line": 686}, "message": "Uninitialized value stored to field 'idev'"}, {"location": {"col": 2, "file": 4, "line": 686}, "message": "Returning pointer, which participates in a condition later"}, {"location": {"col": 8, "file": 0, "line": 1083}, "message": "Returning from 'kzalloc'"}, {"location": {"col": 6, "file": 0, "line": 1084}, "message": "Assuming 'ifa' is non-null"}, {"location": {"col": 2, "file": 0, "line": 1084}, "message": "Taking false branch"}, {"location": {"col": 2, "file": 0, "line": 1090}, "message": "Taking true branch"}, {"location": {"col": 3, "file": 0, "line": 1093}, "message": "Control jumps to line 1154"}, {"location": {"col": 15, "file": 0, "line": 1154}, "message": "Assuming 'err' is < 0"}, {"location": {"col": 42, "file": 3, "line": 78}, "message": "expanded from macro 'unlikely'"}, {"location": {"col": 2, "file": 0, "line": 1154}, "message": "Taking true branch"}, {"location": {"col": 7, "file": 0, "line": 1157}, "message": "'ifa' is non-null"}, {"location": {"col": 3, "file": 0, "line": 1157}, "message": "Taking true branch"}, {"location": {"col": 8, "file": 0, "line": 1158}, "message": "Branch condition evaluates to a garbage value"}, {"location": {"col": 8, "file": 0, "line": 1158}, "message": "Branch condition evaluates to a garbage value"}], "macros": [], "notes": [], "path": "/src/net/ipv6/addrconf.c", "reportHash": "6c2ae9ad7fffb6266255d8d30ce9e325", "checkerName": "clang-analyzer-core.uninitialized.Branch", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 6, "file": 0, "line": 6280}, "message": "Assuming the condition is false"}, {"location": {"col": 2, "file": 0, "line": 6280}, "message": "Taking false branch"}, {"location": {"col": 6, "file": 0, "line": 6286}, "message": "Assuming 'ret' is equal to 0"}, {"location": {"col": 2, "file": 0, "line": 6286}, "message": "Taking false branch"}, {"location": {"col": 6, "file": 0, "line": 6289}, "message": "Assuming 'write' is not equal to 0"}, {"location": {"col": 2, "file": 0, "line": 6289}, "message": "Taking true branch"}, {"location": {"col": 3, "file": 0, "line": 6290}, "message": "Taking false branch"}, {"location": {"col": 7, "file": 0, "line": 6295}, "message": "Assuming 'idev' is non-null"}, {"location": {"col": 3, "file": 0, "line": 6295}, "message": "Taking true branch"}, {"location": {"col": 4, "file": 0, "line": 6296}, "message": "Taking false branch"}, {"location": {"col": 8, "file": 0, "line": 6301}, "message": "Assuming 'new_val' is not equal to field 'addr_gen_mode'"}, {"location": {"col": 4, "file": 0, "line": 6301}, "message": "Taking true branch"}, {"location": {"col": 5, "file": 0, "line": 6303}, "message": "Calling 'addrconf_dev_config'"}, {"location": {"col": 2, "file": 0, "line": 3329}, "message": "Assuming the condition is false"}, {"location": {"col": 12, "file": 1, "line": 110}, "message": "expanded from macro 'ASSERT_RTNL'"}, {"location": {"col": 27, "file": 2, "line": 157}, "message": "expanded from macro 'WARN_ONCE'"}, {"location": {"col": 2, "file": 0, "line": 3329}, "message": "'__ret_warn_once' is 0"}, {"location": {"col": 2, "file": 1, "line": 110}, "message": "expanded from macro 'ASSERT_RTNL'"}, {"location": {"col": 15, "file": 2, "line": 159}, "message": "expanded from macro 'WARN_ONCE'"}, {"location": {"col": 42, "file": 3, "line": 78}, "message": "expanded from macro 'unlikely'"}, {"location": {"col": 2, "file": 0, "line": 3329}, "message": "Left side of '&&' is false"}, {"location": {"col": 2, "file": 1, "line": 110}, "message": "expanded from macro 'ASSERT_RTNL'"}, {"location": {"col": 31, "file": 2, "line": 159}, "message": "expanded from macro 'WARN_ONCE'"}, {"location": {"col": 2, "file": 0, "line": 3329}, "message": "Taking false branch"}, {"location": {"col": 2, "file": 1, "line": 110}, "message": "expanded from macro 'ASSERT_RTNL'"}, {"location": {"col": 2, "file": 2, "line": 159}, "message": "expanded from macro 'WARN_ONCE'"}, {"location": {"col": 7, "file": 0, "line": 3331}, "message": "Assuming field 'type' is equal to ARPHRD_ETHER"}, {"location": {"col": 34, "file": 0, "line": 3331}, "message": "Left side of '&&' is false"}, {"location": {"col": 2, "file": 0, "line": 3352}, "message": "Taking false branch"}, {"location": {"col": 6, "file": 0, "line": 3356}, "message": "Assuming field 'type' is not equal to ARPHRD_NONE"}, {"location": {"col": 31, "file": 0, "line": 3356}, "message": "Left side of '&&' is false"}, {"location": {"col": 2, "file": 0, "line": 3360}, "message": "Calling 'addrconf_addr_gen'"}, {"location": {"col": 6, "file": 0, "line": 3286}, "message": "Assuming the condition is false"}, {"location": {"col": 2, "file": 0, "line": 3286}, "message": "Taking false branch"}, {"location": {"col": 6, "file": 0, "line": 3290}, "message": "Assuming the condition is false"}, {"location": {"col": 2, "file": 0, "line": 3290}, "message": "Taking false branch"}, {"location": {"col": 2, "file": 0, "line": 3295}, "message": "Control jumps to 'case IN6_ADDR_GEN_MODE_EUI64:'  at line 3307"}, {"location": {"col": 3, "file": 0, "line": 3312}, "message": "Taking true branch"}, {"location": {"col": 4, "file": 0, "line": 3313}, "message": "Calling 'addrconf_add_linklocal'"}, {"location": {"col": 8, "file": 0, "line": 3182}, "message": "Calling 'ipv6_add_addr'"}, {"location": {"col": 20, "file": 0, "line": 1042}, "message": "'can_block' is true"}, {"location": {"col": 20, "file": 0, "line": 1042}, "message": "'?' condition is true"}, {"location": {"col": 6, "file": 0, "line": 1049}, "message": "Assuming 'addr_type' is not equal to IPV6_ADDR_ANY"}, {"location": {"col": 6, "file": 0, "line": 1049}, "message": "Left side of '||' is false"}, {"location": {"col": 7, "file": 0, "line": 1050}, "message": "Assuming the condition is false"}, {"location": {"col": 39, "file": 0, "line": 1050}, "message": "Left side of '&&' is false"}, {"location": {"col": 7, "file": 0, "line": 1052}, "message": "Assuming the condition is false"}, {"location": {"col": 42, "file": 0, "line": 1052}, "message": "Left side of '&&' is false"}, {"location": {"col": 6, "file": 0, "line": 1057}, "message": "Assuming field 'dead' is 0"}, {"location": {"col": 2, "file": 0, "line": 1057}, "message": "Taking false branch"}, {"location": {"col": 16, "file": 0, "line": 1062}, "message": "Field 'disable_ipv6' is 0"}, {"location": {"col": 2, "file": 0, "line": 1062}, "message": "Taking false branch"}, {"location": {"col": 6, "file": 0, "line": 1070}, "message": "'can_block' is true"}, {"location": {"col": 2, "file": 0, "line": 1070}, "message": "Taking true branch"}, {"location": {"col": 7, "file": 0, "line": 1079}, "message": "Assuming 'err' is >= 0"}, {"location": {"col": 3, "file": 0, "line": 1079}, "message": "Taking false branch"}, {"location": {"col": 8, "file": 0, "line": 1083}, "message": "Calling 'kzalloc'"}, {"location": {"col": 9, "file": 4, "line": 686}, "message": "Uninitialized value stored to field 'prefix_len'"}, {"location": {"col": 8, "file": 0, "line": 1083}, "message": "Returning from 'kzalloc'"}, {"location": {"col": 6, "file": 0, "line": 1084}, "message": "Assuming 'ifa' is non-null"}, {"location": {"col": 2, "file": 0, "line": 1084}, "message": "Taking false branch"}, {"location": {"col": 2, "file": 0, "line": 1090}, "message": "Taking true branch"}, {"location": {"col": 3, "file": 0, "line": 1093}, "message": "Control jumps to line 1154"}, {"location": {"col": 15, "file": 0, "line": 1154}, "message": "Assuming 'err' is >= 0"}, {"location": {"col": 42, "file": 3, "line": 78}, "message": "expanded from macro 'unlikely'"}, {"location": {"col": 2, "file": 0, "line": 1154}, "message": "Taking false branch"}, {"location": {"col": 8, "file": 0, "line": 3182}, "message": "Returning from 'ipv6_add_addr'"}, {"location": {"col": 7, "file": 0, "line": 3183}, "message": "Calling 'IS_ERR'"}, {"location": {"col": 9, "file": 5, "line": 36}, "message": "Assuming the condition is false"}, {"location": {"col": 34, "file": 5, "line": 22}, "message": "expanded from macro 'IS_ERR_VALUE'"}, {"location": {"col": 42, "file": 3, "line": 78}, "message": "expanded from macro 'unlikely'"}, {"location": {"col": 2, "file": 5, "line": 36}, "message": "Returning zero, which participates in a condition later"}, {"location": {"col": 7, "file": 0, "line": 3183}, "message": "Returning from 'IS_ERR'"}, {"location": {"col": 2, "file": 0, "line": 3183}, "message": "Taking true branch"}, {"location": {"col": 3, "file": 0, "line": 3184}, "message": "2nd function call argument is an uninitialized value"}, {"location": {"col": 3, "file": 0, "line": 3184}, "message": "2nd function call argument is an uninitialized value"}], "macros": [], "notes": [], "path": "/src/net/ipv6/addrconf.c", "reportHash": "635a17c304e250c09b6a3f2a29375176", "checkerName": "clang-analyzer-core.CallAndMessage", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 6, "file": 0, "line": 6280}, "message": "Assuming the condition is false"}, {"location": {"col": 2, "file": 0, "line": 6280}, "message": "Taking false branch"}, {"location": {"col": 6, "file": 0, "line": 6286}, "message": "Assuming 'ret' is equal to 0"}, {"location": {"col": 2, "file": 0, "line": 6286}, "message": "Taking false branch"}, {"location": {"col": 6, "file": 0, "line": 6289}, "message": "Assuming 'write' is not equal to 0"}, {"location": {"col": 2, "file": 0, "line": 6289}, "message": "Taking true branch"}, {"location": {"col": 3, "file": 0, "line": 6290}, "message": "Taking false branch"}, {"location": {"col": 7, "file": 0, "line": 6295}, "message": "Assuming 'idev' is non-null"}, {"location": {"col": 3, "file": 0, "line": 6295}, "message": "Taking true branch"}, {"location": {"col": 4, "file": 0, "line": 6296}, "message": "Taking false branch"}, {"location": {"col": 8, "file": 0, "line": 6301}, "message": "Assuming 'new_val' is not equal to field 'addr_gen_mode'"}, {"location": {"col": 4, "file": 0, "line": 6301}, "message": "Taking true branch"}, {"location": {"col": 5, "file": 0, "line": 6303}, "message": "Calling 'addrconf_dev_config'"}, {"location": {"col": 2, "file": 0, "line": 3329}, "message": "Assuming the condition is false"}, {"location": {"col": 12, "file": 1, "line": 110}, "message": "expanded from macro 'ASSERT_RTNL'"}, {"location": {"col": 27, "file": 2, "line": 157}, "message": "expanded from macro 'WARN_ONCE'"}, {"location": {"col": 2, "file": 0, "line": 3329}, "message": "'__ret_warn_once' is 0"}, {"location": {"col": 2, "file": 1, "line": 110}, "message": "expanded from macro 'ASSERT_RTNL'"}, {"location": {"col": 15, "file": 2, "line": 159}, "message": "expanded from macro 'WARN_ONCE'"}, {"location": {"col": 42, "file": 3, "line": 78}, "message": "expanded from macro 'unlikely'"}, {"location": {"col": 2, "file": 0, "line": 3329}, "message": "Left side of '&&' is false"}, {"location": {"col": 2, "file": 1, "line": 110}, "message": "expanded from macro 'ASSERT_RTNL'"}, {"location": {"col": 31, "file": 2, "line": 159}, "message": "expanded from macro 'WARN_ONCE'"}, {"location": {"col": 2, "file": 0, "line": 3329}, "message": "Taking false branch"}, {"location": {"col": 2, "file": 1, "line": 110}, "message": "expanded from macro 'ASSERT_RTNL'"}, {"location": {"col": 2, "file": 2, "line": 159}, "message": "expanded from macro 'WARN_ONCE'"}, {"location": {"col": 7, "file": 0, "line": 3331}, "message": "Assuming field 'type' is equal to ARPHRD_ETHER"}, {"location": {"col": 34, "file": 0, "line": 3331}, "message": "Left side of '&&' is false"}, {"location": {"col": 2, "file": 0, "line": 3352}, "message": "Taking false branch"}, {"location": {"col": 6, "file": 0, "line": 3356}, "message": "Assuming field 'type' is not equal to ARPHRD_NONE"}, {"location": {"col": 31, "file": 0, "line": 3356}, "message": "Left side of '&&' is false"}, {"location": {"col": 2, "file": 0, "line": 3360}, "message": "Calling 'addrconf_addr_gen'"}, {"location": {"col": 6, "file": 0, "line": 3286}, "message": "Assuming the condition is false"}, {"location": {"col": 2, "file": 0, "line": 3286}, "message": "Taking false branch"}, {"location": {"col": 6, "file": 0, "line": 3290}, "message": "Assuming the condition is false"}, {"location": {"col": 2, "file": 0, "line": 3290}, "message": "Taking false branch"}, {"location": {"col": 2, "file": 0, "line": 3295}, "message": "Control jumps to 'case IN6_ADDR_GEN_MODE_EUI64:'  at line 3307"}, {"location": {"col": 3, "file": 0, "line": 3312}, "message": "Taking true branch"}, {"location": {"col": 4, "file": 0, "line": 3313}, "message": "Calling 'addrconf_add_linklocal'"}, {"location": {"col": 8, "file": 0, "line": 3182}, "message": "Calling 'ipv6_add_addr'"}, {"location": {"col": 20, "file": 0, "line": 1042}, "message": "'can_block' is true"}, {"location": {"col": 20, "file": 0, "line": 1042}, "message": "'?' condition is true"}, {"location": {"col": 6, "file": 0, "line": 1049}, "message": "Assuming 'addr_type' is not equal to IPV6_ADDR_ANY"}, {"location": {"col": 6, "file": 0, "line": 1049}, "message": "Left side of '||' is false"}, {"location": {"col": 7, "file": 0, "line": 1050}, "message": "Assuming the condition is false"}, {"location": {"col": 39, "file": 0, "line": 1050}, "message": "Left side of '&&' is false"}, {"location": {"col": 7, "file": 0, "line": 1052}, "message": "Assuming the condition is false"}, {"location": {"col": 42, "file": 0, "line": 1052}, "message": "Left side of '&&' is false"}, {"location": {"col": 6, "file": 0, "line": 1057}, "message": "Assuming field 'dead' is 0"}, {"location": {"col": 2, "file": 0, "line": 1057}, "message": "Taking false branch"}, {"location": {"col": 16, "file": 0, "line": 1062}, "message": "Field 'disable_ipv6' is 0"}, {"location": {"col": 2, "file": 0, "line": 1062}, "message": "Taking false branch"}, {"location": {"col": 6, "file": 0, "line": 1070}, "message": "'can_block' is true"}, {"location": {"col": 2, "file": 0, "line": 1070}, "message": "Taking true branch"}, {"location": {"col": 7, "file": 0, "line": 1079}, "message": "Assuming 'err' is >= 0"}, {"location": {"col": 3, "file": 0, "line": 1079}, "message": "Taking false branch"}, {"location": {"col": 8, "file": 0, "line": 1083}, "message": "Calling 'kzalloc'"}, {"location": {"col": 9, "file": 4, "line": 686}, "message": "Memory is allocated"}, {"location": {"col": 8, "file": 0, "line": 1083}, "message": "Returned allocated memory"}, {"location": {"col": 6, "file": 0, "line": 1084}, "message": "Assuming 'ifa' is non-null"}, {"location": {"col": 2, "file": 0, "line": 1084}, "message": "Taking false branch"}, {"location": {"col": 2, "file": 0, "line": 1090}, "message": "Taking true branch"}, {"location": {"col": 3, "file": 0, "line": 1093}, "message": "Control jumps to line 1154"}, {"location": {"col": 15, "file": 0, "line": 1154}, "message": "Assuming 'err' is >= 0"}, {"location": {"col": 42, "file": 3, "line": 78}, "message": "expanded from macro 'unlikely'"}, {"location": {"col": 2, "file": 0, "line": 1154}, "message": "Taking false branch"}, {"location": {"col": 8, "file": 0, "line": 3182}, "message": "Returned allocated memory"}, {"location": {"col": 2, "file": 0, "line": 3183}, "message": "Taking false branch"}, {"location": {"col": 1, "file": 0, "line": 3189}, "message": "Potential leak of memory pointed to by 'ifp'"}, {"location": {"col": 1, "file": 0, "line": 3189}, "message": "Potential leak of memory pointed to by 'ifp'"}], "macros": [], "notes": [], "path": "/src/net/ipv6/addrconf.c", "reportHash": "5b1d0ced953050656c0837098bbd43a2", "checkerName": "clang-analyzer-unix.Malloc", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 6, "file": 0, "line": 6218}, "message": "Assuming 'write' is not equal to 0"}, {"location": {"col": 2, "file": 0, "line": 6218}, "message": "Taking true branch"}, {"location": {"col": 9, "file": 0, "line": 6219}, "message": "Calling 'addrconf_disable_ipv6'"}, {"location": {"col": 6, "file": 0, "line": 6178}, "message": "Assuming the condition is false"}, {"location": {"col": 2, "file": 0, "line": 6178}, "message": "Taking false branch"}, {"location": {"col": 6, "file": 0, "line": 6185}, "message": "Assuming the condition is false"}, {"location": {"col": 2, "file": 0, "line": 6185}, "message": "Taking false branch"}, {"location": {"col": 6, "file": 0, "line": 6190}, "message": "Assuming the condition is true"}, {"location": {"col": 2, "file": 0, "line": 6190}, "message": "Taking true branch"}, {"location": {"col": 3, "file": 0, "line": 6192}, "message": "Calling 'addrconf_disable_change'"}, {"location": {"col": 2, "file": 0, "line": 6162}, "message": "Left side of '&&' is false"}, {"location": {"col": 3, "file": 6, "line": 2787}, "message": "expanded from macro 'for_each_netdev'"}, {"location": {"col": 13, "file": 7, "line": 628}, "message": "expanded from macro 'list_for_each_entry'"}, {"location": {"col": 2, "file": 7, "line": 522}, "message": "expanded from macro 'list_first_entry'"}, {"location": {"col": 2, "file": 7, "line": 511}, "message": "expanded from macro 'list_entry'"}, {"location": {"col": 61, "file": 8, "line": 709}, "message": "expanded from macro 'container_of'"}, {"location": {"col": 2, "file": 0, "line": 6162}, "message": "Taking false branch"}, {"location": {"col": 3, "file": 6, "line": 2787}, "message": "expanded from macro 'for_each_netdev'"}, {"location": {"col": 13, "file": 7, "line": 628}, "message": "expanded from macro 'list_for_each_entry'"}, {"location": {"col": 2, "file": 7, "line": 522}, "message": "expanded from macro 'list_first_entry'"}, {"location": {"col": 20, "file": 0, "line": 3544}, "message": "Access to field 'if_flags' results in a dereference of a null pointer (loaded from variable 'idev')"}], "macros": [], "notes": [], "path": "/src/net/ipv6/addrconf.c", "reportHash": "ab2d4c33078cb3ee035910e713181a9d", "checkerName": "clang-analyzer-core.NullDereference", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 6, "file": 0, "line": 6218}, "message": "Assuming 'write' is not equal to 0"}, {"location": {"col": 2, "file": 0, "line": 6218}, "message": "Taking true branch"}, {"location": {"col": 9, "file": 0, "line": 6219}, "message": "Calling 'addrconf_disable_ipv6'"}, {"location": {"col": 6, "file": 0, "line": 6178}, "message": "Assuming the condition is false"}, {"location": {"col": 2, "file": 0, "line": 6178}, "message": "Taking false branch"}, {"location": {"col": 6, "file": 0, "line": 6185}, "message": "Assuming the condition is false"}, {"location": {"col": 2, "file": 0, "line": 6185}, "message": "Taking false branch"}, {"location": {"col": 6, "file": 0, "line": 6190}, "message": "Assuming the condition is true"}, {"location": {"col": 2, "file": 0, "line": 6190}, "message": "Taking true branch"}, {"location": {"col": 3, "file": 0, "line": 6192}, "message": "Calling 'addrconf_disable_change'"}, {"location": {"col": 2, "file": 0, "line": 6162}, "message": "Left side of '&&' is false"}, {"location": {"col": 3, "file": 6, "line": 2787}, "message": "expanded from macro 'for_each_netdev'"}, {"location": {"col": 13, "file": 7, "line": 628}, "message": "expanded from macro 'list_for_each_entry'"}, {"location": {"col": 2, "file": 7, "line": 522}, "message": "expanded from macro 'list_first_entry'"}, {"location": {"col": 2, "file": 7, "line": 511}, "message": "expanded from macro 'list_entry'"}, {"location": {"col": 61, "file": 8, "line": 709}, "message": "expanded from macro 'container_of'"}, {"location": {"col": 2, "file": 0, "line": 6162}, "message": "Taking false branch"}, {"location": {"col": 3, "file": 6, "line": 2787}, "message": "expanded from macro 'for_each_netdev'"}, {"location": {"col": 13, "file": 7, "line": 628}, "message": "expanded from macro 'list_for_each_entry'"}, {"location": {"col": 2, "file": 7, "line": 522}, "message": "expanded from macro 'list_first_entry'"}, {"location": {"col": 8, "file": 0, "line": 3609}, "message": "Dereference of null pointer"}], "macros": [], "notes": [], "path": "/src/net/ipv6/addrconf.c", "reportHash": "e3c48ccf04fe39a75efef1986d8d1964", "checkerName": "clang-analyzer-core.NullDereference", "reviewStatus": null, "severity": "UNSPECIFIED"}]};
      window.onload = function() {
        if (!browserCompatible) {
          setNonCompatibleBrowserMessage();
        } else {
          BugViewer.init(data.files, data.reports);
          BugViewer.create();
          BugViewer.initByUrl();
        }
      };
    </script>
  </head>
  <body>
  <div class="container">
    <div id="content">
      <div id="side-bar">
        <div class="header">
          <a href="index.html" class="button">&#8249; Return to List</a>
        </div>
        <div id="report-nav">
          <div class="header">Reports</div>
        </div>
      </div>
      <div id="editor-wrapper">
        <div class="header">
          <div id="file">
            <span class="label">File:</span>
            <span id="file-path"></span>
          </div>
          <div id="checker">
            <span class="label">Checker name:</span>
            <span id="checker-name"></span>
          </div>
          <div id="review-status-wrapper">
            <span class="label">Review status:</span>
            <span id="review-status"></span>
          </div>
        </div>
        <div id="editor"></div>
      </div>
    </div>
  </div>
  </body>
</html>
