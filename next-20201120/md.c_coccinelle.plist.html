<!DOCTYPE html>
<html>
  <head>
    <title>Plist HTML Viewer</title>

    <meta charset="UTF-8">

    <style type="text/css">
      .CodeMirror{font-family:monospace;height:300px;color:#000;direction:ltr}.CodeMirror-lines{padding:4px 0}.CodeMirror pre{padding:0 4px}.CodeMirror-gutter-filler,.CodeMirror-scrollbar-filler{background-color:#fff}.CodeMirror-gutters{border-right:1px solid #ddd;background-color:#f7f7f7;white-space:nowrap}.CodeMirror-linenumber{padding:0 3px 0 5px;min-width:20px;text-align:right;color:#999;white-space:nowrap}.CodeMirror-guttermarker{color:#000}.CodeMirror-guttermarker-subtle{color:#999}.CodeMirror-cursor{border-left:1px solid #000;border-right:none;width:0}.CodeMirror div.CodeMirror-secondarycursor{border-left:1px solid silver}.cm-fat-cursor .CodeMirror-cursor{width:auto;border:0!important;background:#7e7}.cm-fat-cursor div.CodeMirror-cursors{z-index:1}.cm-animate-fat-cursor{width:auto;border:0;-webkit-animation:blink 1.06s steps(1) infinite;-moz-animation:blink 1.06s steps(1) infinite;animation:blink 1.06s steps(1) infinite;background-color:#7e7}@-moz-keyframes blink{50%{background-color:transparent}}@-webkit-keyframes blink{50%{background-color:transparent}}@keyframes blink{50%{background-color:transparent}}.cm-tab{display:inline-block;text-decoration:inherit}.CodeMirror-rulers{position:absolute;left:0;right:0;top:-50px;bottom:-20px;overflow:hidden}.CodeMirror-ruler{border-left:1px solid #ccc;top:0;bottom:0;position:absolute}.cm-s-default .cm-header{color:#00f}.cm-s-default .cm-quote{color:#090}.cm-negative{color:#d44}.cm-positive{color:#292}.cm-header,.cm-strong{font-weight:700}.cm-em{font-style:italic}.cm-link{text-decoration:underline}.cm-strikethrough{text-decoration:line-through}.cm-s-default .cm-keyword{color:#708}.cm-s-default .cm-atom{color:#219}.cm-s-default .cm-number{color:#164}.cm-s-default .cm-def{color:#00f}.cm-s-default .cm-variable-2{color:#05a}.cm-s-default .cm-type,.cm-s-default .cm-variable-3{color:#085}.cm-s-default .cm-comment{color:#a50}.cm-s-default .cm-string{color:#a11}.cm-s-default .cm-string-2{color:#f50}.cm-s-default .cm-meta{color:#555}.cm-s-default .cm-qualifier{color:#555}.cm-s-default .cm-builtin{color:#30a}.cm-s-default .cm-bracket{color:#997}.cm-s-default .cm-tag{color:#170}.cm-s-default .cm-attribute{color:#00c}.cm-s-default .cm-hr{color:#999}.cm-s-default .cm-link{color:#00c}.cm-s-default .cm-error{color:red}.cm-invalidchar{color:red}.CodeMirror-composing{border-bottom:2px solid}div.CodeMirror span.CodeMirror-matchingbracket{color:#0f0}div.CodeMirror span.CodeMirror-nonmatchingbracket{color:#f22}.CodeMirror-matchingtag{background:rgba(255,150,0,.3)}.CodeMirror-activeline-background{background:#e8f2ff}.CodeMirror{position:relative;overflow:hidden;background:#fff}.CodeMirror-scroll{overflow:scroll!important;margin-bottom:-30px;margin-right:-30px;padding-bottom:30px;height:100%;outline:0;position:relative}.CodeMirror-sizer{position:relative;border-right:30px solid transparent}.CodeMirror-gutter-filler,.CodeMirror-hscrollbar,.CodeMirror-scrollbar-filler,.CodeMirror-vscrollbar{position:absolute;z-index:6;display:none}.CodeMirror-vscrollbar{right:0;top:0;overflow-x:hidden;overflow-y:scroll}.CodeMirror-hscrollbar{bottom:0;left:0;overflow-y:hidden;overflow-x:scroll}.CodeMirror-scrollbar-filler{right:0;bottom:0}.CodeMirror-gutter-filler{left:0;bottom:0}.CodeMirror-gutters{position:absolute;left:0;top:0;min-height:100%;z-index:3}.CodeMirror-gutter{white-space:normal;height:100%;display:inline-block;vertical-align:top;margin-bottom:-30px}.CodeMirror-gutter-wrapper{position:absolute;z-index:4;background:0 0!important;border:none!important}.CodeMirror-gutter-background{position:absolute;top:0;bottom:0;z-index:4}.CodeMirror-gutter-elt{position:absolute;cursor:default;z-index:4}.CodeMirror-gutter-wrapper ::selection{background-color:transparent}.CodeMirror-gutter-wrapper ::-moz-selection{background-color:transparent}.CodeMirror-lines{cursor:text;min-height:1px}.CodeMirror pre{-moz-border-radius:0;-webkit-border-radius:0;border-radius:0;border-width:0;background:0 0;font-family:inherit;font-size:inherit;margin:0;white-space:pre;word-wrap:normal;line-height:inherit;color:inherit;z-index:2;position:relative;overflow:visible;-webkit-tap-highlight-color:transparent;-webkit-font-variant-ligatures:contextual;font-variant-ligatures:contextual}.CodeMirror-wrap pre{word-wrap:break-word;white-space:pre-wrap;word-break:normal}.CodeMirror-linebackground{position:absolute;left:0;right:0;top:0;bottom:0;z-index:0}.CodeMirror-linewidget{position:relative;z-index:2;overflow:auto}.CodeMirror-rtl pre{direction:rtl}.CodeMirror-code{outline:0}.CodeMirror-gutter,.CodeMirror-gutters,.CodeMirror-linenumber,.CodeMirror-scroll,.CodeMirror-sizer{-moz-box-sizing:content-box;box-sizing:content-box}.CodeMirror-measure{position:absolute;width:100%;height:0;overflow:hidden;visibility:hidden}.CodeMirror-cursor{position:absolute;pointer-events:none}.CodeMirror-measure pre{position:static}div.CodeMirror-cursors{visibility:hidden;position:relative;z-index:3}div.CodeMirror-dragcursors{visibility:visible}.CodeMirror-focused div.CodeMirror-cursors{visibility:visible}.CodeMirror-selected{background:#d9d9d9}.CodeMirror-focused .CodeMirror-selected{background:#d7d4f0}.CodeMirror-crosshair{cursor:crosshair}.CodeMirror-line::selection,.CodeMirror-line>span::selection,.CodeMirror-line>span>span::selection{background:#d7d4f0}.CodeMirror-line::-moz-selection,.CodeMirror-line>span::-moz-selection,.CodeMirror-line>span>span::-moz-selection{background:#d7d4f0}.cm-searching{background-color:#ffa;background-color:rgba(255,255,0,.4)}.cm-force-border{padding-right:.1px}@media print{.CodeMirror div.CodeMirror-cursors{visibility:hidden}}.cm-tab-wrap-hack:after{content:''}span.CodeMirror-selectedtext{background:0 0}
/*# sourceMappingURL=codemirror.min.css.map */

      .severity-low {
  background-color: #669603;
}

.severity-low:after {
  content : 'L';
}

.severity-unspecified {
  background-color: #666666;
}

.severity-unspecified:after {
  content : 'U';
}

.severity-style {
  background-color: #9932cc;
}

.severity-style:after {
  content : 'S';
}

.severity-medium {
  background-color: #a9d323;
  color: black;
}

.severity-medium:after {
  content : 'M';
}

.severity-high {
  background-color: #ffa800;
}

.severity-high:after {
  content : 'H';
}

.severity-critical {
  background-color: #e92625;
}

.severity-critical:after {
  content : 'C';
}

i[class*="severity-"] {
  line-height: normal;
  text-transform: capitalize;
  font-size: 0.8em;
  font-weight: bold;
  color: white;
  display: inline-block;
  width: 16px;
  height: 16px;
  text-align: center;
  font-family: sans-serif;
}

      html, body {
  width: 100%;
  height: 100%;
  padding: 0px;
  margin: 0px;
}

div.container {
  padding: 10px;
}

#content {
  height: 100%;
  display: block;
  overflow: hidden;
}

#content > div {
  margin: 10px;
  overflow: hidden;
  border: 1px solid #ddd;
  border-radius: 3px;
  overflow: hidden;
  height: 97%;
}

.button {
  background-color: #f1f1f1;
  text-decoration: none;
  display: inline-block;
  padding: 8px 16px;
  color: black;
  cursor: pointer;
}

.button:hover {
  background-color: #ddd;
  color: black;
}

.review-status {
  color: white;
  text-align: center;
}

.review-status-confirmed {
  background-color: #e92625;
}

.review-status-false-positive {
  background-color: grey;
}

.review-status-intentional {
  background-color: #669603;
}

      div.container {
  width: 100%;
  height: 100%;
  padding: 0px;
}

#editor-wrapper {
  margin: 10px;
}

#side-bar {
  float: left;
  width: 260px;
  margin: 0px;
}

#report-nav ul {
  list-style-type: none;
  padding: 0;
  margin: 0;
  overflow-y: auto;
  height: 100%;
}

#report-nav ul > li {
  padding: .4em;
  background-color: #fff;
  border-bottom: 1px solid rgba(0,0,0,.125);
  text-align: left;
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

#report-nav ul > li.active {
  background-color: #427ea9;
  color: white;
}

#report-nav ul > li:hover {
  background-color: #427ea9;
  color: white;
  cursor: pointer;
}

#report-nav ul a {
  text-decoration: none;
}

#report-nav i[class*="severity-"] {
  margin-right: 5px;
}

.header {
  border-bottom: 1px solid lightgrey;
  font-family: monospace;
  padding: 10px;
  background-color: #fafbfc;
  border-bottom: 1px solid #e1e4e8;
  border-top-left-radius: 2px;
  border-top-right-radius: 2px;
}

#report-nav .header {
  font-weight: bold;
}

#editor-wrapper .header > div {
  padding-top: 2px;
}

#file-path,
#checker-name {
  color: #195ea2;
}

#review-status {
  padding: 0px 5px;
}

#file-path {
  font-family: monospace;
}

.check-msg {
  display: inline-block;
  padding: 3px 6px;
  margin: 1px;
  -webkit-border-radius: 5px;
  -moz-border-radius: 5px;
  border-radius: 5px;
}

.check-msg.info {
  color: #00546f;
  background-color: #bfdfe9;
  border: 1px solid #87a8b3;
}

.check-msg.error {
  background-color: #f2dede;
  color: #a94442;
  border: 1px solid #ebcccc;
}

.check-msg.macro {
  background-color: #d7dac2;
  color: #4f5c6d;
  border: 1px solid #d7dac2;
}

.check-msg.note {
  background-color: #d7d7d7;
  color: #4f5c6d;
  border: 1px solid #bfbfbf;
}

.check-msg.current {
  border: 2px dashed #3692ff;
}

.check-msg .tag {
  padding: 1px 5px;
  text-align: center;
  border-radius: 2px;
  margin-right: 5px;
  text-decoration: inherit;
}

.check-msg .tag.macro {
  background-color: #83876a;
  color: white;
  text-transform: capitalize;
}

.check-msg .tag.note {
  background-color: #9299a1;
  color: white;
  text-transform: capitalize;
}

.checker-enum {
  color: white;
  padding: 1px 5px;
  text-align: center;
  border-radius: 25px;
  margin-right: 5px;
  text-decoration: inherit;
}

.checker-enum.info {
  background-color: #427ea9;
}

.checker-enum.error {
  background-color: #a94442;
}

.arrow {
  border: solid black;
  border-width: 0 3px 3px 0;
  display: inline-block;
  padding: 3px;
  cursor: pointer;
  margin: 0px 5px;
}

.arrow:hover {
  border: solid #437ea8;
  border-width: 0 3px 3px 0;
}

.left-arrow {
  transform: rotate(135deg);
  -webkit-transform: rotate(135deg);
}

.right-arrow {
  transform: rotate(-45deg);
  -webkit-transform: rotate(-45deg);
}

    </style>

    <script type="text/javascript">
      function setNonCompatibleBrowserMessage() {
  document.body.innerHTML =
    '<h2 style="margin-left: 20px;">Your browser is not compatible with CodeChecker Viewer!</h2> \
     <p style="margin-left: 20px;">The version required for the following browsers are:</p> \
     <ul style="margin-left: 20px;"> \
     <li>Internet Explorer: version 9 or newer</li> \
     <li>Firefox: version 22.0 or newer</li> \
     </ul>';
}

// http://stackoverflow.com/questions/5916900/how-can-you-detect-the-version-of-a-browser
var browserVersion = (function(){
  var ua = navigator.userAgent, tem,
    M = ua.match(/(opera|chrome|safari|firefox|msie|trident(?=\/))\/?\s*(\d+)/i) || [];

  if (/trident/i.test(M[1])) {
    tem = /\brv[ :]+(\d+)/g.exec(ua) || [];
    return 'IE ' + (tem[1] || '');
  }

  if (M[1] === 'Chrome') {
    tem = ua.match(/\b(OPR|Edge)\/(\d+)/);
    if (tem != null) return tem.slice(1).join(' ').replace('OPR', 'Opera');
  }

  M = M[2] ? [M[1], M[2]] : [navigator.appName, navigator.appVersion, '-?'];
  if ((tem = ua.match(/version\/(\d+)/i)) != null) M.splice(1, 1, tem[1]);
    return M.join(' ');
})();

var pos = browserVersion.indexOf(' ');
var browser = browserVersion.substr(0, pos);
var version = parseInt(browserVersion.substr(pos + 1));

var browserCompatible
  = browser === 'Firefox'
  ? version >= 22
  : browser === 'IE'
  ? version >= 9
  : true;


      /* MIT License

Copyright (C) 2017 by Marijn Haverbeke <marijnh@gmail.com> and others

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
 */
      !function(e,t){"object"==typeof exports&&"undefined"!=typeof module?module.exports=t():"function"==typeof define&&define.amd?define(t):e.CodeMirror=t()}(this,function(){"use strict";function e(e){return new RegExp("(^|\\s)"+e+"(?:$|\\s)\\s*")}function t(e){for(var t=e.childNodes.length;t>0;--t)e.removeChild(e.firstChild);return e}function r(e,r){return t(e).appendChild(r)}function n(e,t,r,n){var i=document.createElement(e);if(r&&(i.className=r),n&&(i.style.cssText=n),"string"==typeof t)i.appendChild(document.createTextNode(t));else if(t)for(var o=0;o<t.length;++o)i.appendChild(t[o]);return i}function i(e,t,r,i){var o=n(e,t,r,i);return o.setAttribute("role","presentation"),o}function o(e,t){if(3==t.nodeType&&(t=t.parentNode),e.contains)return e.contains(t);do{if(11==t.nodeType&&(t=t.host),t==e)return!0}while(t=t.parentNode)}function l(){var e;try{e=document.activeElement}catch(t){e=document.body||null}for(;e&&e.shadowRoot&&e.shadowRoot.activeElement;)e=e.shadowRoot.activeElement;return e}function s(t,r){var n=t.className;e(r).test(n)||(t.className+=(n?" ":"")+r)}function a(t,r){for(var n=t.split(" "),i=0;i<n.length;i++)n[i]&&!e(n[i]).test(r)&&(r+=" "+n[i]);return r}function u(e){var t=Array.prototype.slice.call(arguments,1);return function(){return e.apply(null,t)}}function c(e,t,r){t||(t={});for(var n in e)!e.hasOwnProperty(n)||!1===r&&t.hasOwnProperty(n)||(t[n]=e[n]);return t}function f(e,t,r,n,i){null==t&&-1==(t=e.search(/[^\s\u00a0]/))&&(t=e.length);for(var o=n||0,l=i||0;;){var s=e.indexOf("\t",o);if(s<0||s>=t)return l+(t-o);l+=s-o,l+=r-l%r,o=s+1}}function h(e,t){for(var r=0;r<e.length;++r)if(e[r]==t)return r;return-1}function d(e,t,r){for(var n=0,i=0;;){var o=e.indexOf("\t",n);-1==o&&(o=e.length);var l=o-n;if(o==e.length||i+l>=t)return n+Math.min(l,t-i);if(i+=o-n,i+=r-i%r,n=o+1,i>=t)return n}}function p(e){for(;Kl.length<=e;)Kl.push(g(Kl)+" ");return Kl[e]}function g(e){return e[e.length-1]}function v(e,t){for(var r=[],n=0;n<e.length;n++)r[n]=t(e[n],n);return r}function m(e,t,r){for(var n=0,i=r(t);n<e.length&&r(e[n])<=i;)n++;e.splice(n,0,t)}function y(){}function b(e,t){var r;return Object.create?r=Object.create(e):(y.prototype=e,r=new y),t&&c(t,r),r}function w(e){return/\w/.test(e)||e>""&&(e.toUpperCase()!=e.toLowerCase()||jl.test(e))}function x(e,t){return t?!!(t.source.indexOf("\\w")>-1&&w(e))||t.test(e):w(e)}function C(e){for(var t in e)if(e.hasOwnProperty(t)&&e[t])return!1;return!0}function S(e){return e.charCodeAt(0)>=768&&Xl.test(e)}function L(e,t,r){for(;(r<0?t>0:t<e.length)&&S(e.charAt(t));)t+=r;return t}function k(e,t,r){for(var n=t>r?-1:1;;){if(t==r)return t;var i=(t+r)/2,o=n<0?Math.ceil(i):Math.floor(i);if(o==t)return e(o)?t:r;e(o)?r=o:t=o+n}}function T(e,t,r){var o=this;this.input=r,o.scrollbarFiller=n("div",null,"CodeMirror-scrollbar-filler"),o.scrollbarFiller.setAttribute("cm-not-content","true"),o.gutterFiller=n("div",null,"CodeMirror-gutter-filler"),o.gutterFiller.setAttribute("cm-not-content","true"),o.lineDiv=i("div",null,"CodeMirror-code"),o.selectionDiv=n("div",null,null,"position: relative; z-index: 1"),o.cursorDiv=n("div",null,"CodeMirror-cursors"),o.measure=n("div",null,"CodeMirror-measure"),o.lineMeasure=n("div",null,"CodeMirror-measure"),o.lineSpace=i("div",[o.measure,o.lineMeasure,o.selectionDiv,o.cursorDiv,o.lineDiv],null,"position: relative; outline: none");var l=i("div",[o.lineSpace],"CodeMirror-lines");o.mover=n("div",[l],null,"position: relative"),o.sizer=n("div",[o.mover],"CodeMirror-sizer"),o.sizerWidth=null,o.heightForcer=n("div",null,null,"position: absolute; height: "+Rl+"px; width: 1px;"),o.gutters=n("div",null,"CodeMirror-gutters"),o.lineGutter=null,o.scroller=n("div",[o.sizer,o.heightForcer,o.gutters],"CodeMirror-scroll"),o.scroller.setAttribute("tabIndex","-1"),o.wrapper=n("div",[o.scrollbarFiller,o.gutterFiller,o.scroller],"CodeMirror"),gl&&vl<8&&(o.gutters.style.zIndex=-1,o.scroller.style.paddingRight=0),ml||fl&&Tl||(o.scroller.draggable=!0),e&&(e.appendChild?e.appendChild(o.wrapper):e(o.wrapper)),o.viewFrom=o.viewTo=t.first,o.reportedViewFrom=o.reportedViewTo=t.first,o.view=[],o.renderedView=null,o.externalMeasured=null,o.viewOffset=0,o.lastWrapHeight=o.lastWrapWidth=0,o.updateLineNumbers=null,o.nativeBarWidth=o.barHeight=o.barWidth=0,o.scrollbarsClipped=!1,o.lineNumWidth=o.lineNumInnerWidth=o.lineNumChars=null,o.alignWidgets=!1,o.cachedCharWidth=o.cachedTextHeight=o.cachedPaddingH=null,o.maxLine=null,o.maxLineLength=0,o.maxLineChanged=!1,o.wheelDX=o.wheelDY=o.wheelStartX=o.wheelStartY=null,o.shift=!1,o.selForContextMenu=null,o.activeTouch=null,r.init(o)}function M(e,t){if((t-=e.first)<0||t>=e.size)throw new Error("There is no line "+(t+e.first)+" in the document.");for(var r=e;!r.lines;)for(var n=0;;++n){var i=r.children[n],o=i.chunkSize();if(t<o){r=i;break}t-=o}return r.lines[t]}function N(e,t,r){var n=[],i=t.line;return e.iter(t.line,r.line+1,function(e){var o=e.text;i==r.line&&(o=o.slice(0,r.ch)),i==t.line&&(o=o.slice(t.ch)),n.push(o),++i}),n}function O(e,t,r){var n=[];return e.iter(t,r,function(e){n.push(e.text)}),n}function A(e,t){var r=t-e.height;if(r)for(var n=e;n;n=n.parent)n.height+=r}function W(e){if(null==e.parent)return null;for(var t=e.parent,r=h(t.lines,e),n=t.parent;n;t=n,n=n.parent)for(var i=0;n.children[i]!=t;++i)r+=n.children[i].chunkSize();return r+t.first}function D(e,t){var r=e.first;e:do{for(var n=0;n<e.children.length;++n){var i=e.children[n],o=i.height;if(t<o){e=i;continue e}t-=o,r+=i.chunkSize()}return r}while(!e.lines);for(var l=0;l<e.lines.length;++l){var s=e.lines[l].height;if(t<s)break;t-=s}return r+l}function H(e,t){return t>=e.first&&t<e.first+e.size}function F(e,t){return String(e.lineNumberFormatter(t+e.firstLineNumber))}function E(e,t,r){if(void 0===r&&(r=null),!(this instanceof E))return new E(e,t,r);this.line=e,this.ch=t,this.sticky=r}function P(e,t){return e.line-t.line||e.ch-t.ch}function I(e,t){return e.sticky==t.sticky&&0==P(e,t)}function z(e){return E(e.line,e.ch)}function R(e,t){return P(e,t)<0?t:e}function B(e,t){return P(e,t)<0?e:t}function G(e,t){return Math.max(e.first,Math.min(t,e.first+e.size-1))}function U(e,t){if(t.line<e.first)return E(e.first,0);var r=e.first+e.size-1;return t.line>r?E(r,M(e,r).text.length):V(t,M(e,t.line).text.length)}function V(e,t){var r=e.ch;return null==r||r>t?E(e.line,t):r<0?E(e.line,0):e}function K(e,t){for(var r=[],n=0;n<t.length;n++)r[n]=U(e,t[n]);return r}function j(){Yl=!0}function X(){_l=!0}function Y(e,t,r){this.marker=e,this.from=t,this.to=r}function _(e,t){if(e)for(var r=0;r<e.length;++r){var n=e[r];if(n.marker==t)return n}}function $(e,t){for(var r,n=0;n<e.length;++n)e[n]!=t&&(r||(r=[])).push(e[n]);return r}function q(e,t){e.markedSpans=e.markedSpans?e.markedSpans.concat([t]):[t],t.marker.attachLine(e)}function Z(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t)||o.from==t&&"bookmark"==l.type&&(!r||!o.marker.insertLeft)){var s=null==o.to||(l.inclusiveRight?o.to>=t:o.to>t);(n||(n=[])).push(new Y(l,o.from,s?null:o.to))}}return n}function Q(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.to||(l.inclusiveRight?o.to>=t:o.to>t)||o.from==t&&"bookmark"==l.type&&(!r||o.marker.insertLeft)){var s=null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t);(n||(n=[])).push(new Y(l,s?null:o.from-t,null==o.to?null:o.to-t))}}return n}function J(e,t){if(t.full)return null;var r=H(e,t.from.line)&&M(e,t.from.line).markedSpans,n=H(e,t.to.line)&&M(e,t.to.line).markedSpans;if(!r&&!n)return null;var i=t.from.ch,o=t.to.ch,l=0==P(t.from,t.to),s=Z(r,i,l),a=Q(n,o,l),u=1==t.text.length,c=g(t.text).length+(u?i:0);if(s)for(var f=0;f<s.length;++f){var h=s[f];if(null==h.to){var d=_(a,h.marker);d?u&&(h.to=null==d.to?null:d.to+c):h.to=i}}if(a)for(var p=0;p<a.length;++p){var v=a[p];null!=v.to&&(v.to+=c),null==v.from?_(s,v.marker)||(v.from=c,u&&(s||(s=[])).push(v)):(v.from+=c,u&&(s||(s=[])).push(v))}s&&(s=ee(s)),a&&a!=s&&(a=ee(a));var m=[s];if(!u){var y,b=t.text.length-2;if(b>0&&s)for(var w=0;w<s.length;++w)null==s[w].to&&(y||(y=[])).push(new Y(s[w].marker,null,null));for(var x=0;x<b;++x)m.push(y);m.push(a)}return m}function ee(e){for(var t=0;t<e.length;++t){var r=e[t];null!=r.from&&r.from==r.to&&!1!==r.marker.clearWhenEmpty&&e.splice(t--,1)}return e.length?e:null}function te(e,t,r){var n=null;if(e.iter(t.line,r.line+1,function(e){if(e.markedSpans)for(var t=0;t<e.markedSpans.length;++t){var r=e.markedSpans[t].marker;!r.readOnly||n&&-1!=h(n,r)||(n||(n=[])).push(r)}}),!n)return null;for(var i=[{from:t,to:r}],o=0;o<n.length;++o)for(var l=n[o],s=l.find(0),a=0;a<i.length;++a){var u=i[a];if(!(P(u.to,s.from)<0||P(u.from,s.to)>0)){var c=[a,1],f=P(u.from,s.from),d=P(u.to,s.to);(f<0||!l.inclusiveLeft&&!f)&&c.push({from:u.from,to:s.from}),(d>0||!l.inclusiveRight&&!d)&&c.push({from:s.to,to:u.to}),i.splice.apply(i,c),a+=c.length-3}}return i}function re(e){var t=e.markedSpans;if(t){for(var r=0;r<t.length;++r)t[r].marker.detachLine(e);e.markedSpans=null}}function ne(e,t){if(t){for(var r=0;r<t.length;++r)t[r].marker.attachLine(e);e.markedSpans=t}}function ie(e){return e.inclusiveLeft?-1:0}function oe(e){return e.inclusiveRight?1:0}function le(e,t){var r=e.lines.length-t.lines.length;if(0!=r)return r;var n=e.find(),i=t.find(),o=P(n.from,i.from)||ie(e)-ie(t);if(o)return-o;var l=P(n.to,i.to)||oe(e)-oe(t);return l||t.id-e.id}function se(e,t){var r,n=_l&&e.markedSpans;if(n)for(var i=void 0,o=0;o<n.length;++o)(i=n[o]).marker.collapsed&&null==(t?i.from:i.to)&&(!r||le(r,i.marker)<0)&&(r=i.marker);return r}function ae(e){return se(e,!0)}function ue(e){return se(e,!1)}function ce(e,t,r,n,i){var o=M(e,t),l=_l&&o.markedSpans;if(l)for(var s=0;s<l.length;++s){var a=l[s];if(a.marker.collapsed){var u=a.marker.find(0),c=P(u.from,r)||ie(a.marker)-ie(i),f=P(u.to,n)||oe(a.marker)-oe(i);if(!(c>=0&&f<=0||c<=0&&f>=0)&&(c<=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.to,r)>=0:P(u.to,r)>0)||c>=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.from,n)<=0:P(u.from,n)<0)))return!0}}}function fe(e){for(var t;t=ae(e);)e=t.find(-1,!0).line;return e}function he(e){for(var t;t=ue(e);)e=t.find(1,!0).line;return e}function de(e){for(var t,r;t=ue(e);)e=t.find(1,!0).line,(r||(r=[])).push(e);return r}function pe(e,t){var r=M(e,t),n=fe(r);return r==n?t:W(n)}function ge(e,t){if(t>e.lastLine())return t;var r,n=M(e,t);if(!ve(e,n))return t;for(;r=ue(n);)n=r.find(1,!0).line;return W(n)+1}function ve(e,t){var r=_l&&t.markedSpans;if(r)for(var n=void 0,i=0;i<r.length;++i)if((n=r[i]).marker.collapsed){if(null==n.from)return!0;if(!n.marker.widgetNode&&0==n.from&&n.marker.inclusiveLeft&&me(e,t,n))return!0}}function me(e,t,r){if(null==r.to){var n=r.marker.find(1,!0);return me(e,n.line,_(n.line.markedSpans,r.marker))}if(r.marker.inclusiveRight&&r.to==t.text.length)return!0;for(var i=void 0,o=0;o<t.markedSpans.length;++o)if((i=t.markedSpans[o]).marker.collapsed&&!i.marker.widgetNode&&i.from==r.to&&(null==i.to||i.to!=r.from)&&(i.marker.inclusiveLeft||r.marker.inclusiveRight)&&me(e,t,i))return!0}function ye(e){for(var t=0,r=(e=fe(e)).parent,n=0;n<r.lines.length;++n){var i=r.lines[n];if(i==e)break;t+=i.height}for(var o=r.parent;o;r=o,o=r.parent)for(var l=0;l<o.children.length;++l){var s=o.children[l];if(s==r)break;t+=s.height}return t}function be(e){if(0==e.height)return 0;for(var t,r=e.text.length,n=e;t=ae(n);){var i=t.find(0,!0);n=i.from.line,r+=i.from.ch-i.to.ch}for(n=e;t=ue(n);){var o=t.find(0,!0);r-=n.text.length-o.from.ch,r+=(n=o.to.line).text.length-o.to.ch}return r}function we(e){var t=e.display,r=e.doc;t.maxLine=M(r,r.first),t.maxLineLength=be(t.maxLine),t.maxLineChanged=!0,r.iter(function(e){var r=be(e);r>t.maxLineLength&&(t.maxLineLength=r,t.maxLine=e)})}function xe(e,t,r,n){if(!e)return n(t,r,"ltr",0);for(var i=!1,o=0;o<e.length;++o){var l=e[o];(l.from<r&&l.to>t||t==r&&l.to==t)&&(n(Math.max(l.from,t),Math.min(l.to,r),1==l.level?"rtl":"ltr",o),i=!0)}i||n(t,r,"ltr")}function Ce(e,t,r){var n;$l=null;for(var i=0;i<e.length;++i){var o=e[i];if(o.from<t&&o.to>t)return i;o.to==t&&(o.from!=o.to&&"before"==r?n=i:$l=i),o.from==t&&(o.from!=o.to&&"before"!=r?n=i:$l=i)}return null!=n?n:$l}function Se(e,t){var r=e.order;return null==r&&(r=e.order=ql(e.text,t)),r}function Le(e,t){return e._handlers&&e._handlers[t]||Zl}function ke(e,t,r){if(e.removeEventListener)e.removeEventListener(t,r,!1);else if(e.detachEvent)e.detachEvent("on"+t,r);else{var n=e._handlers,i=n&&n[t];if(i){var o=h(i,r);o>-1&&(n[t]=i.slice(0,o).concat(i.slice(o+1)))}}}function Te(e,t){var r=Le(e,t);if(r.length)for(var n=Array.prototype.slice.call(arguments,2),i=0;i<r.length;++i)r[i].apply(null,n)}function Me(e,t,r){return"string"==typeof t&&(t={type:t,preventDefault:function(){this.defaultPrevented=!0}}),Te(e,r||t.type,e,t),He(t)||t.codemirrorIgnore}function Ne(e){var t=e._handlers&&e._handlers.cursorActivity;if(t)for(var r=e.curOp.cursorActivityHandlers||(e.curOp.cursorActivityHandlers=[]),n=0;n<t.length;++n)-1==h(r,t[n])&&r.push(t[n])}function Oe(e,t){return Le(e,t).length>0}function Ae(e){e.prototype.on=function(e,t){Ql(this,e,t)},e.prototype.off=function(e,t){ke(this,e,t)}}function We(e){e.preventDefault?e.preventDefault():e.returnValue=!1}function De(e){e.stopPropagation?e.stopPropagation():e.cancelBubble=!0}function He(e){return null!=e.defaultPrevented?e.defaultPrevented:0==e.returnValue}function Fe(e){We(e),De(e)}function Ee(e){return e.target||e.srcElement}function Pe(e){var t=e.which;return null==t&&(1&e.button?t=1:2&e.button?t=3:4&e.button&&(t=2)),Ml&&e.ctrlKey&&1==t&&(t=3),t}function Ie(e){if(null==Il){var t=n("span","​");r(e,n("span",[t,document.createTextNode("x")])),0!=e.firstChild.offsetHeight&&(Il=t.offsetWidth<=1&&t.offsetHeight>2&&!(gl&&vl<8))}var i=Il?n("span","​"):n("span"," ",null,"display: inline-block; width: 1px; margin-right: -1px");return i.setAttribute("cm-text",""),i}function ze(e){if(null!=zl)return zl;var n=r(e,document.createTextNode("AخA")),i=Wl(n,0,1).getBoundingClientRect(),o=Wl(n,1,2).getBoundingClientRect();return t(e),!(!i||i.left==i.right)&&(zl=o.right-i.right<3)}function Re(e){if(null!=ns)return ns;var t=r(e,n("span","x")),i=t.getBoundingClientRect(),o=Wl(t,0,1).getBoundingClientRect();return ns=Math.abs(i.left-o.left)>1}function Be(e,t){arguments.length>2&&(t.dependencies=Array.prototype.slice.call(arguments,2)),is[e]=t}function Ge(e){if("string"==typeof e&&os.hasOwnProperty(e))e=os[e];else if(e&&"string"==typeof e.name&&os.hasOwnProperty(e.name)){var t=os[e.name];"string"==typeof t&&(t={name:t}),(e=b(t,e)).name=t.name}else{if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+xml$/.test(e))return Ge("application/xml");if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+json$/.test(e))return Ge("application/json")}return"string"==typeof e?{name:e}:e||{name:"null"}}function Ue(e,t){t=Ge(t);var r=is[t.name];if(!r)return Ue(e,"text/plain");var n=r(e,t);if(ls.hasOwnProperty(t.name)){var i=ls[t.name];for(var o in i)i.hasOwnProperty(o)&&(n.hasOwnProperty(o)&&(n["_"+o]=n[o]),n[o]=i[o])}if(n.name=t.name,t.helperType&&(n.helperType=t.helperType),t.modeProps)for(var l in t.modeProps)n[l]=t.modeProps[l];return n}function Ve(e,t){c(t,ls.hasOwnProperty(e)?ls[e]:ls[e]={})}function Ke(e,t){if(!0===t)return t;if(e.copyState)return e.copyState(t);var r={};for(var n in t){var i=t[n];i instanceof Array&&(i=i.concat([])),r[n]=i}return r}function je(e,t){for(var r;e.innerMode&&(r=e.innerMode(t))&&r.mode!=e;)t=r.state,e=r.mode;return r||{mode:e,state:t}}function Xe(e,t,r){return!e.startState||e.startState(t,r)}function Ye(e,t,r,n){var i=[e.state.modeGen],o={};tt(e,t.text,e.doc.mode,r,function(e,t){return i.push(e,t)},o,n);for(var l=r.state,s=0;s<e.state.overlays.length;++s)!function(n){var l=e.state.overlays[n],s=1,a=0;r.state=!0,tt(e,t.text,l.mode,r,function(e,t){for(var r=s;a<e;){var n=i[s];n>e&&i.splice(s,1,e,i[s+1],n),s+=2,a=Math.min(e,n)}if(t)if(l.opaque)i.splice(r,s-r,e,"overlay "+t),s=r+2;else for(;r<s;r+=2){var o=i[r+1];i[r+1]=(o?o+" ":"")+"overlay "+t}},o)}(s);return r.state=l,{styles:i,classes:o.bgClass||o.textClass?o:null}}function _e(e,t,r){if(!t.styles||t.styles[0]!=e.state.modeGen){var n=$e(e,W(t)),i=t.text.length>e.options.maxHighlightLength&&Ke(e.doc.mode,n.state),o=Ye(e,t,n);i&&(n.state=i),t.stateAfter=n.save(!i),t.styles=o.styles,o.classes?t.styleClasses=o.classes:t.styleClasses&&(t.styleClasses=null),r===e.doc.highlightFrontier&&(e.doc.modeFrontier=Math.max(e.doc.modeFrontier,++e.doc.highlightFrontier))}return t.styles}function $e(e,t,r){var n=e.doc,i=e.display;if(!n.mode.startState)return new us(n,!0,t);var o=rt(e,t,r),l=o>n.first&&M(n,o-1).stateAfter,s=l?us.fromSaved(n,l,o):new us(n,Xe(n.mode),o);return n.iter(o,t,function(r){qe(e,r.text,s);var n=s.line;r.stateAfter=n==t-1||n%5==0||n>=i.viewFrom&&n<i.viewTo?s.save():null,s.nextLine()}),r&&(n.modeFrontier=s.line),s}function qe(e,t,r,n){var i=e.doc.mode,o=new ss(t,e.options.tabSize,r);for(o.start=o.pos=n||0,""==t&&Ze(i,r.state);!o.eol();)Qe(i,o,r.state),o.start=o.pos}function Ze(e,t){if(e.blankLine)return e.blankLine(t);if(e.innerMode){var r=je(e,t);return r.mode.blankLine?r.mode.blankLine(r.state):void 0}}function Qe(e,t,r,n){for(var i=0;i<10;i++){n&&(n[0]=je(e,r).mode);var o=e.token(t,r);if(t.pos>t.start)return o}throw new Error("Mode "+e.name+" failed to advance stream.")}function Je(e,t,r,n){var i,o,l=e.doc,s=l.mode,a=M(l,(t=U(l,t)).line),u=$e(e,t.line,r),c=new ss(a.text,e.options.tabSize,u);for(n&&(o=[]);(n||c.pos<t.ch)&&!c.eol();)c.start=c.pos,i=Qe(s,c,u.state),n&&o.push(new cs(c,i,Ke(l.mode,u.state)));return n?o:new cs(c,i,u.state)}function et(e,t){if(e)for(;;){var r=e.match(/(?:^|\s+)line-(background-)?(\S+)/);if(!r)break;e=e.slice(0,r.index)+e.slice(r.index+r[0].length);var n=r[1]?"bgClass":"textClass";null==t[n]?t[n]=r[2]:new RegExp("(?:^|s)"+r[2]+"(?:$|s)").test(t[n])||(t[n]+=" "+r[2])}return e}function tt(e,t,r,n,i,o,l){var s=r.flattenSpans;null==s&&(s=e.options.flattenSpans);var a,u=0,c=null,f=new ss(t,e.options.tabSize,n),h=e.options.addModeClass&&[null];for(""==t&&et(Ze(r,n.state),o);!f.eol();){if(f.pos>e.options.maxHighlightLength?(s=!1,l&&qe(e,t,n,f.pos),f.pos=t.length,a=null):a=et(Qe(r,f,n.state,h),o),h){var d=h[0].name;d&&(a="m-"+(a?d+" "+a:d))}if(!s||c!=a){for(;u<f.start;)i(u=Math.min(f.start,u+5e3),c);c=a}f.start=f.pos}for(;u<f.pos;){var p=Math.min(f.pos,u+5e3);i(p,c),u=p}}function rt(e,t,r){for(var n,i,o=e.doc,l=r?-1:t-(e.doc.mode.innerMode?1e3:100),s=t;s>l;--s){if(s<=o.first)return o.first;var a=M(o,s-1),u=a.stateAfter;if(u&&(!r||s+(u instanceof as?u.lookAhead:0)<=o.modeFrontier))return s;var c=f(a.text,null,e.options.tabSize);(null==i||n>c)&&(i=s-1,n=c)}return i}function nt(e,t){if(e.modeFrontier=Math.min(e.modeFrontier,t),!(e.highlightFrontier<t-10)){for(var r=e.first,n=t-1;n>r;n--){var i=M(e,n).stateAfter;if(i&&(!(i instanceof as)||n+i.lookAhead<t)){r=n+1;break}}e.highlightFrontier=Math.min(e.highlightFrontier,r)}}function it(e,t,r,n){e.text=t,e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null),null!=e.order&&(e.order=null),re(e),ne(e,r);var i=n?n(e):1;i!=e.height&&A(e,i)}function ot(e){e.parent=null,re(e)}function lt(e,t){if(!e||/^\s*$/.test(e))return null;var r=t.addModeClass?ps:ds;return r[e]||(r[e]=e.replace(/\S+/g,"cm-$&"))}function st(e,t){var r=i("span",null,null,ml?"padding-right: .1px":null),n={pre:i("pre",[r],"CodeMirror-line"),content:r,col:0,pos:0,cm:e,trailingSpace:!1,splitSpaces:(gl||ml)&&e.getOption("lineWrapping")};t.measure={};for(var o=0;o<=(t.rest?t.rest.length:0);o++){var l=o?t.rest[o-1]:t.line,s=void 0;n.pos=0,n.addToken=ut,ze(e.display.measure)&&(s=Se(l,e.doc.direction))&&(n.addToken=ft(n.addToken,s)),n.map=[],dt(l,n,_e(e,l,t!=e.display.externalMeasured&&W(l))),l.styleClasses&&(l.styleClasses.bgClass&&(n.bgClass=a(l.styleClasses.bgClass,n.bgClass||"")),l.styleClasses.textClass&&(n.textClass=a(l.styleClasses.textClass,n.textClass||""))),0==n.map.length&&n.map.push(0,0,n.content.appendChild(Ie(e.display.measure))),0==o?(t.measure.map=n.map,t.measure.cache={}):((t.measure.maps||(t.measure.maps=[])).push(n.map),(t.measure.caches||(t.measure.caches=[])).push({}))}if(ml){var u=n.content.lastChild;(/\bcm-tab\b/.test(u.className)||u.querySelector&&u.querySelector(".cm-tab"))&&(n.content.className="cm-tab-wrap-hack")}return Te(e,"renderLine",e,t.line,n.pre),n.pre.className&&(n.textClass=a(n.pre.className,n.textClass||"")),n}function at(e){var t=n("span","•","cm-invalidchar");return t.title="\\u"+e.charCodeAt(0).toString(16),t.setAttribute("aria-label",t.title),t}function ut(e,t,r,i,o,l,s){if(t){var a,u=e.splitSpaces?ct(t,e.trailingSpace):t,c=e.cm.state.specialChars,f=!1;if(c.test(t)){a=document.createDocumentFragment();for(var h=0;;){c.lastIndex=h;var d=c.exec(t),g=d?d.index-h:t.length-h;if(g){var v=document.createTextNode(u.slice(h,h+g));gl&&vl<9?a.appendChild(n("span",[v])):a.appendChild(v),e.map.push(e.pos,e.pos+g,v),e.col+=g,e.pos+=g}if(!d)break;h+=g+1;var m=void 0;if("\t"==d[0]){var y=e.cm.options.tabSize,b=y-e.col%y;(m=a.appendChild(n("span",p(b),"cm-tab"))).setAttribute("role","presentation"),m.setAttribute("cm-text","\t"),e.col+=b}else"\r"==d[0]||"\n"==d[0]?((m=a.appendChild(n("span","\r"==d[0]?"␍":"␤","cm-invalidchar"))).setAttribute("cm-text",d[0]),e.col+=1):((m=e.cm.options.specialCharPlaceholder(d[0])).setAttribute("cm-text",d[0]),gl&&vl<9?a.appendChild(n("span",[m])):a.appendChild(m),e.col+=1);e.map.push(e.pos,e.pos+1,m),e.pos++}}else e.col+=t.length,a=document.createTextNode(u),e.map.push(e.pos,e.pos+t.length,a),gl&&vl<9&&(f=!0),e.pos+=t.length;if(e.trailingSpace=32==u.charCodeAt(t.length-1),r||i||o||f||s){var w=r||"";i&&(w+=i),o&&(w+=o);var x=n("span",[a],w,s);return l&&(x.title=l),e.content.appendChild(x)}e.content.appendChild(a)}}function ct(e,t){if(e.length>1&&!/  /.test(e))return e;for(var r=t,n="",i=0;i<e.length;i++){var o=e.charAt(i);" "!=o||!r||i!=e.length-1&&32!=e.charCodeAt(i+1)||(o=" "),n+=o,r=" "==o}return n}function ft(e,t){return function(r,n,i,o,l,s,a){i=i?i+" cm-force-border":"cm-force-border";for(var u=r.pos,c=u+n.length;;){for(var f=void 0,h=0;h<t.length&&!((f=t[h]).to>u&&f.from<=u);h++);if(f.to>=c)return e(r,n,i,o,l,s,a);e(r,n.slice(0,f.to-u),i,o,null,s,a),o=null,n=n.slice(f.to-u),u=f.to}}}function ht(e,t,r,n){var i=!n&&r.widgetNode;i&&e.map.push(e.pos,e.pos+t,i),!n&&e.cm.display.input.needsContentAttribute&&(i||(i=e.content.appendChild(document.createElement("span"))),i.setAttribute("cm-marker",r.id)),i&&(e.cm.display.input.setUneditable(i),e.content.appendChild(i)),e.pos+=t,e.trailingSpace=!1}function dt(e,t,r){var n=e.markedSpans,i=e.text,o=0;if(n)for(var l,s,a,u,c,f,h,d=i.length,p=0,g=1,v="",m=0;;){if(m==p){a=u=c=f=s="",h=null,m=1/0;for(var y=[],b=void 0,w=0;w<n.length;++w){var x=n[w],C=x.marker;"bookmark"==C.type&&x.from==p&&C.widgetNode?y.push(C):x.from<=p&&(null==x.to||x.to>p||C.collapsed&&x.to==p&&x.from==p)?(null!=x.to&&x.to!=p&&m>x.to&&(m=x.to,u=""),C.className&&(a+=" "+C.className),C.css&&(s=(s?s+";":"")+C.css),C.startStyle&&x.from==p&&(c+=" "+C.startStyle),C.endStyle&&x.to==m&&(b||(b=[])).push(C.endStyle,x.to),C.title&&!f&&(f=C.title),C.collapsed&&(!h||le(h.marker,C)<0)&&(h=x)):x.from>p&&m>x.from&&(m=x.from)}if(b)for(var S=0;S<b.length;S+=2)b[S+1]==m&&(u+=" "+b[S]);if(!h||h.from==p)for(var L=0;L<y.length;++L)ht(t,0,y[L]);if(h&&(h.from||0)==p){if(ht(t,(null==h.to?d+1:h.to)-p,h.marker,null==h.from),null==h.to)return;h.to==p&&(h=!1)}}if(p>=d)break;for(var k=Math.min(d,m);;){if(v){var T=p+v.length;if(!h){var M=T>k?v.slice(0,k-p):v;t.addToken(t,M,l?l+a:a,c,p+M.length==m?u:"",f,s)}if(T>=k){v=v.slice(k-p),p=k;break}p=T,c=""}v=i.slice(o,o=r[g++]),l=lt(r[g++],t.cm.options)}}else for(var N=1;N<r.length;N+=2)t.addToken(t,i.slice(o,o=r[N]),lt(r[N+1],t.cm.options))}function pt(e,t,r){this.line=t,this.rest=de(t),this.size=this.rest?W(g(this.rest))-r+1:1,this.node=this.text=null,this.hidden=ve(e,t)}function gt(e,t,r){for(var n,i=[],o=t;o<r;o=n){var l=new pt(e.doc,M(e.doc,o),o);n=o+l.size,i.push(l)}return i}function vt(e){gs?gs.ops.push(e):e.ownsGroup=gs={ops:[e],delayedCallbacks:[]}}function mt(e){var t=e.delayedCallbacks,r=0;do{for(;r<t.length;r++)t[r].call(null);for(var n=0;n<e.ops.length;n++){var i=e.ops[n];if(i.cursorActivityHandlers)for(;i.cursorActivityCalled<i.cursorActivityHandlers.length;)i.cursorActivityHandlers[i.cursorActivityCalled++].call(null,i.cm)}}while(r<t.length)}function yt(e,t){var r=e.ownsGroup;if(r)try{mt(r)}finally{gs=null,t(r)}}function bt(e,t){var r=Le(e,t);if(r.length){var n,i=Array.prototype.slice.call(arguments,2);gs?n=gs.delayedCallbacks:vs?n=vs:(n=vs=[],setTimeout(wt,0));for(var o=0;o<r.length;++o)!function(e){n.push(function(){return r[e].apply(null,i)})}(o)}}function wt(){var e=vs;vs=null;for(var t=0;t<e.length;++t)e[t]()}function xt(e,t,r,n){for(var i=0;i<t.changes.length;i++){var o=t.changes[i];"text"==o?kt(e,t):"gutter"==o?Mt(e,t,r,n):"class"==o?Tt(e,t):"widget"==o&&Nt(e,t,n)}t.changes=null}function Ct(e){return e.node==e.text&&(e.node=n("div",null,null,"position: relative"),e.text.parentNode&&e.text.parentNode.replaceChild(e.node,e.text),e.node.appendChild(e.text),gl&&vl<8&&(e.node.style.zIndex=2)),e.node}function St(e,t){var r=t.bgClass?t.bgClass+" "+(t.line.bgClass||""):t.line.bgClass;if(r&&(r+=" CodeMirror-linebackground"),t.background)r?t.background.className=r:(t.background.parentNode.removeChild(t.background),t.background=null);else if(r){var i=Ct(t);t.background=i.insertBefore(n("div",null,r),i.firstChild),e.display.input.setUneditable(t.background)}}function Lt(e,t){var r=e.display.externalMeasured;return r&&r.line==t.line?(e.display.externalMeasured=null,t.measure=r.measure,r.built):st(e,t)}function kt(e,t){var r=t.text.className,n=Lt(e,t);t.text==t.node&&(t.node=n.pre),t.text.parentNode.replaceChild(n.pre,t.text),t.text=n.pre,n.bgClass!=t.bgClass||n.textClass!=t.textClass?(t.bgClass=n.bgClass,t.textClass=n.textClass,Tt(e,t)):r&&(t.text.className=r)}function Tt(e,t){St(e,t),t.line.wrapClass?Ct(t).className=t.line.wrapClass:t.node!=t.text&&(t.node.className="");var r=t.textClass?t.textClass+" "+(t.line.textClass||""):t.line.textClass;t.text.className=r||""}function Mt(e,t,r,i){if(t.gutter&&(t.node.removeChild(t.gutter),t.gutter=null),t.gutterBackground&&(t.node.removeChild(t.gutterBackground),t.gutterBackground=null),t.line.gutterClass){var o=Ct(t);t.gutterBackground=n("div",null,"CodeMirror-gutter-background "+t.line.gutterClass,"left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px; width: "+i.gutterTotalWidth+"px"),e.display.input.setUneditable(t.gutterBackground),o.insertBefore(t.gutterBackground,t.text)}var l=t.line.gutterMarkers;if(e.options.lineNumbers||l){var s=Ct(t),a=t.gutter=n("div",null,"CodeMirror-gutter-wrapper","left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px");if(e.display.input.setUneditable(a),s.insertBefore(a,t.text),t.line.gutterClass&&(a.className+=" "+t.line.gutterClass),!e.options.lineNumbers||l&&l["CodeMirror-linenumbers"]||(t.lineNumber=a.appendChild(n("div",F(e.options,r),"CodeMirror-linenumber CodeMirror-gutter-elt","left: "+i.gutterLeft["CodeMirror-linenumbers"]+"px; width: "+e.display.lineNumInnerWidth+"px"))),l)for(var u=0;u<e.options.gutters.length;++u){var c=e.options.gutters[u],f=l.hasOwnProperty(c)&&l[c];f&&a.appendChild(n("div",[f],"CodeMirror-gutter-elt","left: "+i.gutterLeft[c]+"px; width: "+i.gutterWidth[c]+"px"))}}}function Nt(e,t,r){t.alignable&&(t.alignable=null);for(var n=t.node.firstChild,i=void 0;n;n=i)i=n.nextSibling,"CodeMirror-linewidget"==n.className&&t.node.removeChild(n);At(e,t,r)}function Ot(e,t,r,n){var i=Lt(e,t);return t.text=t.node=i.pre,i.bgClass&&(t.bgClass=i.bgClass),i.textClass&&(t.textClass=i.textClass),Tt(e,t),Mt(e,t,r,n),At(e,t,n),t.node}function At(e,t,r){if(Wt(e,t.line,t,r,!0),t.rest)for(var n=0;n<t.rest.length;n++)Wt(e,t.rest[n],t,r,!1)}function Wt(e,t,r,i,o){if(t.widgets)for(var l=Ct(r),s=0,a=t.widgets;s<a.length;++s){var u=a[s],c=n("div",[u.node],"CodeMirror-linewidget");u.handleMouseEvents||c.setAttribute("cm-ignore-events","true"),Dt(u,c,r,i),e.display.input.setUneditable(c),o&&u.above?l.insertBefore(c,r.gutter||r.text):l.appendChild(c),bt(u,"redraw")}}function Dt(e,t,r,n){if(e.noHScroll){(r.alignable||(r.alignable=[])).push(t);var i=n.wrapperWidth;t.style.left=n.fixedPos+"px",e.coverGutter||(i-=n.gutterTotalWidth,t.style.paddingLeft=n.gutterTotalWidth+"px"),t.style.width=i+"px"}e.coverGutter&&(t.style.zIndex=5,t.style.position="relative",e.noHScroll||(t.style.marginLeft=-n.gutterTotalWidth+"px"))}function Ht(e){if(null!=e.height)return e.height;var t=e.doc.cm;if(!t)return 0;if(!o(document.body,e.node)){var i="position: relative;";e.coverGutter&&(i+="margin-left: -"+t.display.gutters.offsetWidth+"px;"),e.noHScroll&&(i+="width: "+t.display.wrapper.clientWidth+"px;"),r(t.display.measure,n("div",[e.node],null,i))}return e.height=e.node.parentNode.offsetHeight}function Ft(e,t){for(var r=Ee(t);r!=e.wrapper;r=r.parentNode)if(!r||1==r.nodeType&&"true"==r.getAttribute("cm-ignore-events")||r.parentNode==e.sizer&&r!=e.mover)return!0}function Et(e){return e.lineSpace.offsetTop}function Pt(e){return e.mover.offsetHeight-e.lineSpace.offsetHeight}function It(e){if(e.cachedPaddingH)return e.cachedPaddingH;var t=r(e.measure,n("pre","x")),i=window.getComputedStyle?window.getComputedStyle(t):t.currentStyle,o={left:parseInt(i.paddingLeft),right:parseInt(i.paddingRight)};return isNaN(o.left)||isNaN(o.right)||(e.cachedPaddingH=o),o}function zt(e){return Rl-e.display.nativeBarWidth}function Rt(e){return e.display.scroller.clientWidth-zt(e)-e.display.barWidth}function Bt(e){return e.display.scroller.clientHeight-zt(e)-e.display.barHeight}function Gt(e,t,r){var n=e.options.lineWrapping,i=n&&Rt(e);if(!t.measure.heights||n&&t.measure.width!=i){var o=t.measure.heights=[];if(n){t.measure.width=i;for(var l=t.text.firstChild.getClientRects(),s=0;s<l.length-1;s++){var a=l[s],u=l[s+1];Math.abs(a.bottom-u.bottom)>2&&o.push((a.bottom+u.top)/2-r.top)}}o.push(r.bottom-r.top)}}function Ut(e,t,r){if(e.line==t)return{map:e.measure.map,cache:e.measure.cache};for(var n=0;n<e.rest.length;n++)if(e.rest[n]==t)return{map:e.measure.maps[n],cache:e.measure.caches[n]};for(var i=0;i<e.rest.length;i++)if(W(e.rest[i])>r)return{map:e.measure.maps[i],cache:e.measure.caches[i],before:!0}}function Vt(e,t){var n=W(t=fe(t)),i=e.display.externalMeasured=new pt(e.doc,t,n);i.lineN=n;var o=i.built=st(e,i);return i.text=o.pre,r(e.display.lineMeasure,o.pre),i}function Kt(e,t,r,n){return Yt(e,Xt(e,t),r,n)}function jt(e,t){if(t>=e.display.viewFrom&&t<e.display.viewTo)return e.display.view[Lr(e,t)];var r=e.display.externalMeasured;return r&&t>=r.lineN&&t<r.lineN+r.size?r:void 0}function Xt(e,t){var r=W(t),n=jt(e,r);n&&!n.text?n=null:n&&n.changes&&(xt(e,n,r,br(e)),e.curOp.forceUpdate=!0),n||(n=Vt(e,t));var i=Ut(n,t,r);return{line:t,view:n,rect:null,map:i.map,cache:i.cache,before:i.before,hasHeights:!1}}function Yt(e,t,r,n,i){t.before&&(r=-1);var o,l=r+(n||"");return t.cache.hasOwnProperty(l)?o=t.cache[l]:(t.rect||(t.rect=t.view.text.getBoundingClientRect()),t.hasHeights||(Gt(e,t.view,t.rect),t.hasHeights=!0),(o=qt(e,t,r,n)).bogus||(t.cache[l]=o)),{left:o.left,right:o.right,top:i?o.rtop:o.top,bottom:i?o.rbottom:o.bottom}}function _t(e,t,r){for(var n,i,o,l,s,a,u=0;u<e.length;u+=3)if(s=e[u],a=e[u+1],t<s?(i=0,o=1,l="left"):t<a?o=(i=t-s)+1:(u==e.length-3||t==a&&e[u+3]>t)&&(i=(o=a-s)-1,t>=a&&(l="right")),null!=i){if(n=e[u+2],s==a&&r==(n.insertLeft?"left":"right")&&(l=r),"left"==r&&0==i)for(;u&&e[u-2]==e[u-3]&&e[u-1].insertLeft;)n=e[2+(u-=3)],l="left";if("right"==r&&i==a-s)for(;u<e.length-3&&e[u+3]==e[u+4]&&!e[u+5].insertLeft;)n=e[(u+=3)+2],l="right";break}return{node:n,start:i,end:o,collapse:l,coverStart:s,coverEnd:a}}function $t(e,t){var r=ms;if("left"==t)for(var n=0;n<e.length&&(r=e[n]).left==r.right;n++);else for(var i=e.length-1;i>=0&&(r=e[i]).left==r.right;i--);return r}function qt(e,t,r,n){var i,o=_t(t.map,r,n),l=o.node,s=o.start,a=o.end,u=o.collapse;if(3==l.nodeType){for(var c=0;c<4;c++){for(;s&&S(t.line.text.charAt(o.coverStart+s));)--s;for(;o.coverStart+a<o.coverEnd&&S(t.line.text.charAt(o.coverStart+a));)++a;if((i=gl&&vl<9&&0==s&&a==o.coverEnd-o.coverStart?l.parentNode.getBoundingClientRect():$t(Wl(l,s,a).getClientRects(),n)).left||i.right||0==s)break;a=s,s-=1,u="right"}gl&&vl<11&&(i=Zt(e.display.measure,i))}else{s>0&&(u=n="right");var f;i=e.options.lineWrapping&&(f=l.getClientRects()).length>1?f["right"==n?f.length-1:0]:l.getBoundingClientRect()}if(gl&&vl<9&&!s&&(!i||!i.left&&!i.right)){var h=l.parentNode.getClientRects()[0];i=h?{left:h.left,right:h.left+yr(e.display),top:h.top,bottom:h.bottom}:ms}for(var d=i.top-t.rect.top,p=i.bottom-t.rect.top,g=(d+p)/2,v=t.view.measure.heights,m=0;m<v.length-1&&!(g<v[m]);m++);var y=m?v[m-1]:0,b=v[m],w={left:("right"==u?i.right:i.left)-t.rect.left,right:("left"==u?i.left:i.right)-t.rect.left,top:y,bottom:b};return i.left||i.right||(w.bogus=!0),e.options.singleCursorHeightPerLine||(w.rtop=d,w.rbottom=p),w}function Zt(e,t){if(!window.screen||null==screen.logicalXDPI||screen.logicalXDPI==screen.deviceXDPI||!Re(e))return t;var r=screen.logicalXDPI/screen.deviceXDPI,n=screen.logicalYDPI/screen.deviceYDPI;return{left:t.left*r,right:t.right*r,top:t.top*n,bottom:t.bottom*n}}function Qt(e){if(e.measure&&(e.measure.cache={},e.measure.heights=null,e.rest))for(var t=0;t<e.rest.length;t++)e.measure.caches[t]={}}function Jt(e){e.display.externalMeasure=null,t(e.display.lineMeasure);for(var r=0;r<e.display.view.length;r++)Qt(e.display.view[r])}function er(e){Jt(e),e.display.cachedCharWidth=e.display.cachedTextHeight=e.display.cachedPaddingH=null,e.options.lineWrapping||(e.display.maxLineChanged=!0),e.display.lineNumChars=null}function tr(){return bl&&kl?-(document.body.getBoundingClientRect().left-parseInt(getComputedStyle(document.body).marginLeft)):window.pageXOffset||(document.documentElement||document.body).scrollLeft}function rr(){return bl&&kl?-(document.body.getBoundingClientRect().top-parseInt(getComputedStyle(document.body).marginTop)):window.pageYOffset||(document.documentElement||document.body).scrollTop}function nr(e){var t=0;if(e.widgets)for(var r=0;r<e.widgets.length;++r)e.widgets[r].above&&(t+=Ht(e.widgets[r]));return t}function ir(e,t,r,n,i){if(!i){var o=nr(t);r.top+=o,r.bottom+=o}if("line"==n)return r;n||(n="local");var l=ye(t);if("local"==n?l+=Et(e.display):l-=e.display.viewOffset,"page"==n||"window"==n){var s=e.display.lineSpace.getBoundingClientRect();l+=s.top+("window"==n?0:rr());var a=s.left+("window"==n?0:tr());r.left+=a,r.right+=a}return r.top+=l,r.bottom+=l,r}function or(e,t,r){if("div"==r)return t;var n=t.left,i=t.top;if("page"==r)n-=tr(),i-=rr();else if("local"==r||!r){var o=e.display.sizer.getBoundingClientRect();n+=o.left,i+=o.top}var l=e.display.lineSpace.getBoundingClientRect();return{left:n-l.left,top:i-l.top}}function lr(e,t,r,n,i){return n||(n=M(e.doc,t.line)),ir(e,n,Kt(e,n,t.ch,i),r)}function sr(e,t,r,n,i,o){function l(t,l){var s=Yt(e,i,t,l?"right":"left",o);return l?s.left=s.right:s.right=s.left,ir(e,n,s,r)}function s(e,t,r){var n=1==a[t].level;return l(r?e-1:e,n!=r)}n=n||M(e.doc,t.line),i||(i=Xt(e,n));var a=Se(n,e.doc.direction),u=t.ch,c=t.sticky;if(u>=n.text.length?(u=n.text.length,c="before"):u<=0&&(u=0,c="after"),!a)return l("before"==c?u-1:u,"before"==c);var f=Ce(a,u,c),h=$l,d=s(u,f,"before"==c);return null!=h&&(d.other=s(u,h,"before"!=c)),d}function ar(e,t){var r=0;t=U(e.doc,t),e.options.lineWrapping||(r=yr(e.display)*t.ch);var n=M(e.doc,t.line),i=ye(n)+Et(e.display);return{left:r,right:r,top:i,bottom:i+n.height}}function ur(e,t,r,n,i){var o=E(e,t,r);return o.xRel=i,n&&(o.outside=!0),o}function cr(e,t,r){var n=e.doc;if((r+=e.display.viewOffset)<0)return ur(n.first,0,null,!0,-1);var i=D(n,r),o=n.first+n.size-1;if(i>o)return ur(n.first+n.size-1,M(n,o).text.length,null,!0,1);t<0&&(t=0);for(var l=M(n,i);;){var s=pr(e,l,i,t,r),a=ue(l),u=a&&a.find(0,!0);if(!a||!(s.ch>u.from.ch||s.ch==u.from.ch&&s.xRel>0))return s;i=W(l=u.to.line)}}function fr(e,t,r,n){n-=nr(t);var i=t.text.length,o=k(function(t){return Yt(e,r,t-1).bottom<=n},i,0);return i=k(function(t){return Yt(e,r,t).top>n},o,i),{begin:o,end:i}}function hr(e,t,r,n){return r||(r=Xt(e,t)),fr(e,t,r,ir(e,t,Yt(e,r,n),"line").top)}function dr(e,t,r,n){return!(e.bottom<=r)&&(e.top>r||(n?e.left:e.right)>t)}function pr(e,t,r,n,i){i-=ye(t);var o=Xt(e,t),l=nr(t),s=0,a=t.text.length,u=!0,c=Se(t,e.doc.direction);if(c){var f=(e.options.lineWrapping?vr:gr)(e,t,r,o,c,n,i);s=(u=1!=f.level)?f.from:f.to-1,a=u?f.to:f.from-1}var h,d,p=null,g=null,v=k(function(t){var r=Yt(e,o,t);return r.top+=l,r.bottom+=l,!!dr(r,n,i,!1)&&(r.top<=i&&r.left<=n&&(p=t,g=r),!0)},s,a),m=!1;if(g){var y=n-g.left<g.right-n,b=y==u;v=p+(b?0:1),d=b?"after":"before",h=y?g.left:g.right}else{u||v!=a&&v!=s||v++,d=0==v?"after":v==t.text.length?"before":Yt(e,o,v-(u?1:0)).bottom+l<=i==u?"after":"before";var w=sr(e,E(r,v,d),"line",t,o);h=w.left,m=i<w.top||i>=w.bottom}return v=L(t.text,v,1),ur(r,v,d,m,n-h)}function gr(e,t,r,n,i,o,l){var s=k(function(s){var a=i[s],u=1!=a.level;return dr(sr(e,E(r,u?a.to:a.from,u?"before":"after"),"line",t,n),o,l,!0)},0,i.length-1),a=i[s];if(s>0){var u=1!=a.level,c=sr(e,E(r,u?a.from:a.to,u?"after":"before"),"line",t,n);dr(c,o,l,!0)&&c.top>l&&(a=i[s-1])}return a}function vr(e,t,r,n,i,o,l){for(var s=fr(e,t,n,l),a=s.begin,u=s.end,c=null,f=null,h=0;h<i.length;h++){var d=i[h];if(!(d.from>=u||d.to<=a)){var p=Yt(e,n,1!=d.level?Math.min(u,d.to)-1:Math.max(a,d.from)).right,g=p<o?o-p+1e9:p-o;(!c||f>g)&&(c=d,f=g)}}return c||(c=i[i.length-1]),c.from<a&&(c={from:a,to:c.to,level:c.level}),c.to>u&&(c={from:c.from,to:u,level:c.level}),c}function mr(e){if(null!=e.cachedTextHeight)return e.cachedTextHeight;if(null==hs){hs=n("pre");for(var i=0;i<49;++i)hs.appendChild(document.createTextNode("x")),hs.appendChild(n("br"));hs.appendChild(document.createTextNode("x"))}r(e.measure,hs);var o=hs.offsetHeight/50;return o>3&&(e.cachedTextHeight=o),t(e.measure),o||1}function yr(e){if(null!=e.cachedCharWidth)return e.cachedCharWidth;var t=n("span","xxxxxxxxxx"),i=n("pre",[t]);r(e.measure,i);var o=t.getBoundingClientRect(),l=(o.right-o.left)/10;return l>2&&(e.cachedCharWidth=l),l||10}function br(e){for(var t=e.display,r={},n={},i=t.gutters.clientLeft,o=t.gutters.firstChild,l=0;o;o=o.nextSibling,++l)r[e.options.gutters[l]]=o.offsetLeft+o.clientLeft+i,n[e.options.gutters[l]]=o.clientWidth;return{fixedPos:wr(t),gutterTotalWidth:t.gutters.offsetWidth,gutterLeft:r,gutterWidth:n,wrapperWidth:t.wrapper.clientWidth}}function wr(e){return e.scroller.getBoundingClientRect().left-e.sizer.getBoundingClientRect().left}function xr(e){var t=mr(e.display),r=e.options.lineWrapping,n=r&&Math.max(5,e.display.scroller.clientWidth/yr(e.display)-3);return function(i){if(ve(e.doc,i))return 0;var o=0;if(i.widgets)for(var l=0;l<i.widgets.length;l++)i.widgets[l].height&&(o+=i.widgets[l].height);return r?o+(Math.ceil(i.text.length/n)||1)*t:o+t}}function Cr(e){var t=e.doc,r=xr(e);t.iter(function(e){var t=r(e);t!=e.height&&A(e,t)})}function Sr(e,t,r,n){var i=e.display;if(!r&&"true"==Ee(t).getAttribute("cm-not-content"))return null;var o,l,s=i.lineSpace.getBoundingClientRect();try{o=t.clientX-s.left,l=t.clientY-s.top}catch(t){return null}var a,u=cr(e,o,l);if(n&&1==u.xRel&&(a=M(e.doc,u.line).text).length==u.ch){var c=f(a,a.length,e.options.tabSize)-a.length;u=E(u.line,Math.max(0,Math.round((o-It(e.display).left)/yr(e.display))-c))}return u}function Lr(e,t){if(t>=e.display.viewTo)return null;if((t-=e.display.viewFrom)<0)return null;for(var r=e.display.view,n=0;n<r.length;n++)if((t-=r[n].size)<0)return n}function kr(e){e.display.input.showSelection(e.display.input.prepareSelection())}function Tr(e,t){void 0===t&&(t=!0);for(var r=e.doc,n={},i=n.cursors=document.createDocumentFragment(),o=n.selection=document.createDocumentFragment(),l=0;l<r.sel.ranges.length;l++)if(t||l!=r.sel.primIndex){var s=r.sel.ranges[l];if(!(s.from().line>=e.display.viewTo||s.to().line<e.display.viewFrom)){var a=s.empty();(a||e.options.showCursorWhenSelecting)&&Mr(e,s.head,i),a||Or(e,s,o)}}return n}function Mr(e,t,r){var i=sr(e,t,"div",null,null,!e.options.singleCursorHeightPerLine),o=r.appendChild(n("div"," ","CodeMirror-cursor"));if(o.style.left=i.left+"px",o.style.top=i.top+"px",o.style.height=Math.max(0,i.bottom-i.top)*e.options.cursorHeight+"px",i.other){var l=r.appendChild(n("div"," ","CodeMirror-cursor CodeMirror-secondarycursor"));l.style.display="",l.style.left=i.other.left+"px",l.style.top=i.other.top+"px",l.style.height=.85*(i.other.bottom-i.other.top)+"px"}}function Nr(e,t){return e.top-t.top||e.left-t.left}function Or(e,t,r){function i(e,t,r,i){t<0&&(t=0),t=Math.round(t),i=Math.round(i),a.appendChild(n("div",null,"CodeMirror-selected","position: absolute; left: "+e+"px;\n                             top: "+t+"px; width: "+(null==r?f-e:r)+"px;\n                             height: "+(i-t)+"px"))}function o(t,r,n){function o(r,n){return lr(e,E(t,r),"div",u,n)}var l,a,u=M(s,t),h=u.text.length,d=Se(u,s.direction);return xe(d,r||0,null==n?h:n,function(t,s,p,g){var v=o(t,"ltr"==p?"left":"right"),m=o(s-1,"ltr"==p?"right":"left");if("ltr"==p){var y=null==r&&0==t?c:v.left,b=null==n&&s==h?f:m.right;m.top-v.top<=3?i(y,m.top,b-y,m.bottom):(i(y,v.top,null,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top),i(c,m.top,m.right,m.bottom))}else if(t<s){var w=null==r&&0==t?f:v.right,x=null==n&&s==h?c:m.left;if(m.top-v.top<=3)i(x,m.top,w-x,m.bottom);else{var C=c;if(g){var S=hr(e,u,null,t).end;C=o(S-(/\s/.test(u.text.charAt(S-1))?2:1),"left").left}i(C,v.top,w-C,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top);var L=null;d.length,L=o(hr(e,u,null,s).begin,"right").right-x,i(x,m.top,L,m.bottom)}}(!l||Nr(v,l)<0)&&(l=v),Nr(m,l)<0&&(l=m),(!a||Nr(v,a)<0)&&(a=v),Nr(m,a)<0&&(a=m)}),{start:l,end:a}}var l=e.display,s=e.doc,a=document.createDocumentFragment(),u=It(e.display),c=u.left,f=Math.max(l.sizerWidth,Rt(e)-l.sizer.offsetLeft)-u.right,h=t.from(),d=t.to();if(h.line==d.line)o(h.line,h.ch,d.ch);else{var p=M(s,h.line),g=M(s,d.line),v=fe(p)==fe(g),m=o(h.line,h.ch,v?p.text.length+1:null).end,y=o(d.line,v?0:null,d.ch).start;v&&(m.top<y.top-2?(i(m.right,m.top,null,m.bottom),i(c,y.top,y.left,y.bottom)):i(m.right,m.top,y.left-m.right,m.bottom)),m.bottom<y.top&&i(c,m.bottom,null,y.top)}r.appendChild(a)}function Ar(e){if(e.state.focused){var t=e.display;clearInterval(t.blinker);var r=!0;t.cursorDiv.style.visibility="",e.options.cursorBlinkRate>0?t.blinker=setInterval(function(){return t.cursorDiv.style.visibility=(r=!r)?"":"hidden"},e.options.cursorBlinkRate):e.options.cursorBlinkRate<0&&(t.cursorDiv.style.visibility="hidden")}}function Wr(e){e.state.focused||(e.display.input.focus(),Hr(e))}function Dr(e){e.state.delayingBlurEvent=!0,setTimeout(function(){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1,Fr(e))},100)}function Hr(e,t){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1),"nocursor"!=e.options.readOnly&&(e.state.focused||(Te(e,"focus",e,t),e.state.focused=!0,s(e.display.wrapper,"CodeMirror-focused"),e.curOp||e.display.selForContextMenu==e.doc.sel||(e.display.input.reset(),ml&&setTimeout(function(){return e.display.input.reset(!0)},20)),e.display.input.receivedFocus()),Ar(e))}function Fr(e,t){e.state.delayingBlurEvent||(e.state.focused&&(Te(e,"blur",e,t),e.state.focused=!1,Fl(e.display.wrapper,"CodeMirror-focused")),clearInterval(e.display.blinker),setTimeout(function(){e.state.focused||(e.display.shift=!1)},150))}function Er(e){for(var t=e.display,r=t.lineDiv.offsetTop,n=0;n<t.view.length;n++){var i=t.view[n],o=void 0;if(!i.hidden){if(gl&&vl<8){var l=i.node.offsetTop+i.node.offsetHeight;o=l-r,r=l}else{var s=i.node.getBoundingClientRect();o=s.bottom-s.top}var a=i.line.height-o;if(o<2&&(o=mr(t)),(a>.005||a<-.005)&&(A(i.line,o),Pr(i.line),i.rest))for(var u=0;u<i.rest.length;u++)Pr(i.rest[u])}}}function Pr(e){if(e.widgets)for(var t=0;t<e.widgets.length;++t)e.widgets[t].height=e.widgets[t].node.parentNode.offsetHeight}function Ir(e,t,r){var n=r&&null!=r.top?Math.max(0,r.top):e.scroller.scrollTop;n=Math.floor(n-Et(e));var i=r&&null!=r.bottom?r.bottom:n+e.wrapper.clientHeight,o=D(t,n),l=D(t,i);if(r&&r.ensure){var s=r.ensure.from.line,a=r.ensure.to.line;s<o?(o=s,l=D(t,ye(M(t,s))+e.wrapper.clientHeight)):Math.min(a,t.lastLine())>=l&&(o=D(t,ye(M(t,a))-e.wrapper.clientHeight),l=a)}return{from:o,to:Math.max(l,o+1)}}function zr(e){var t=e.display,r=t.view;if(t.alignWidgets||t.gutters.firstChild&&e.options.fixedGutter){for(var n=wr(t)-t.scroller.scrollLeft+e.doc.scrollLeft,i=t.gutters.offsetWidth,o=n+"px",l=0;l<r.length;l++)if(!r[l].hidden){e.options.fixedGutter&&(r[l].gutter&&(r[l].gutter.style.left=o),r[l].gutterBackground&&(r[l].gutterBackground.style.left=o));var s=r[l].alignable;if(s)for(var a=0;a<s.length;a++)s[a].style.left=o}e.options.fixedGutter&&(t.gutters.style.left=n+i+"px")}}function Rr(e){if(!e.options.lineNumbers)return!1;var t=e.doc,r=F(e.options,t.first+t.size-1),i=e.display;if(r.length!=i.lineNumChars){var o=i.measure.appendChild(n("div",[n("div",r)],"CodeMirror-linenumber CodeMirror-gutter-elt")),l=o.firstChild.offsetWidth,s=o.offsetWidth-l;return i.lineGutter.style.width="",i.lineNumInnerWidth=Math.max(l,i.lineGutter.offsetWidth-s)+1,i.lineNumWidth=i.lineNumInnerWidth+s,i.lineNumChars=i.lineNumInnerWidth?r.length:-1,i.lineGutter.style.width=i.lineNumWidth+"px",Wn(e),!0}return!1}function Br(e,t){if(!Me(e,"scrollCursorIntoView")){var r=e.display,i=r.sizer.getBoundingClientRect(),o=null;if(t.top+i.top<0?o=!0:t.bottom+i.top>(window.innerHeight||document.documentElement.clientHeight)&&(o=!1),null!=o&&!Sl){var l=n("div","​",null,"position: absolute;\n                         top: "+(t.top-r.viewOffset-Et(e.display))+"px;\n                         height: "+(t.bottom-t.top+zt(e)+r.barHeight)+"px;\n                         left: "+t.left+"px; width: "+Math.max(2,t.right-t.left)+"px;");e.display.lineSpace.appendChild(l),l.scrollIntoView(o),e.display.lineSpace.removeChild(l)}}}function Gr(e,t,r,n){null==n&&(n=0);var i;e.options.lineWrapping||t!=r||(r="before"==(t=t.ch?E(t.line,"before"==t.sticky?t.ch-1:t.ch,"after"):t).sticky?E(t.line,t.ch+1,"before"):t);for(var o=0;o<5;o++){var l=!1,s=sr(e,t),a=r&&r!=t?sr(e,r):s,u=Vr(e,i={left:Math.min(s.left,a.left),top:Math.min(s.top,a.top)-n,right:Math.max(s.left,a.left),bottom:Math.max(s.bottom,a.bottom)+n}),c=e.doc.scrollTop,f=e.doc.scrollLeft;if(null!=u.scrollTop&&(qr(e,u.scrollTop),Math.abs(e.doc.scrollTop-c)>1&&(l=!0)),null!=u.scrollLeft&&(Qr(e,u.scrollLeft),Math.abs(e.doc.scrollLeft-f)>1&&(l=!0)),!l)break}return i}function Ur(e,t){var r=Vr(e,t);null!=r.scrollTop&&qr(e,r.scrollTop),null!=r.scrollLeft&&Qr(e,r.scrollLeft)}function Vr(e,t){var r=e.display,n=mr(e.display);t.top<0&&(t.top=0);var i=e.curOp&&null!=e.curOp.scrollTop?e.curOp.scrollTop:r.scroller.scrollTop,o=Bt(e),l={};t.bottom-t.top>o&&(t.bottom=t.top+o);var s=e.doc.height+Pt(r),a=t.top<n,u=t.bottom>s-n;if(t.top<i)l.scrollTop=a?0:t.top;else if(t.bottom>i+o){var c=Math.min(t.top,(u?s:t.bottom)-o);c!=i&&(l.scrollTop=c)}var f=e.curOp&&null!=e.curOp.scrollLeft?e.curOp.scrollLeft:r.scroller.scrollLeft,h=Rt(e)-(e.options.fixedGutter?r.gutters.offsetWidth:0),d=t.right-t.left>h;return d&&(t.right=t.left+h),t.left<10?l.scrollLeft=0:t.left<f?l.scrollLeft=Math.max(0,t.left-(d?0:10)):t.right>h+f-3&&(l.scrollLeft=t.right+(d?0:10)-h),l}function Kr(e,t){null!=t&&(_r(e),e.curOp.scrollTop=(null==e.curOp.scrollTop?e.doc.scrollTop:e.curOp.scrollTop)+t)}function jr(e){_r(e);var t=e.getCursor();e.curOp.scrollToPos={from:t,to:t,margin:e.options.cursorScrollMargin}}function Xr(e,t,r){null==t&&null==r||_r(e),null!=t&&(e.curOp.scrollLeft=t),null!=r&&(e.curOp.scrollTop=r)}function Yr(e,t){_r(e),e.curOp.scrollToPos=t}function _r(e){var t=e.curOp.scrollToPos;t&&(e.curOp.scrollToPos=null,$r(e,ar(e,t.from),ar(e,t.to),t.margin))}function $r(e,t,r,n){var i=Vr(e,{left:Math.min(t.left,r.left),top:Math.min(t.top,r.top)-n,right:Math.max(t.right,r.right),bottom:Math.max(t.bottom,r.bottom)+n});Xr(e,i.scrollLeft,i.scrollTop)}function qr(e,t){Math.abs(e.doc.scrollTop-t)<2||(fl||On(e,{top:t}),Zr(e,t,!0),fl&&On(e),Cn(e,100))}function Zr(e,t,r){t=Math.min(e.display.scroller.scrollHeight-e.display.scroller.clientHeight,t),(e.display.scroller.scrollTop!=t||r)&&(e.doc.scrollTop=t,e.display.scrollbars.setScrollTop(t),e.display.scroller.scrollTop!=t&&(e.display.scroller.scrollTop=t))}function Qr(e,t,r,n){t=Math.min(t,e.display.scroller.scrollWidth-e.display.scroller.clientWidth),(r?t==e.doc.scrollLeft:Math.abs(e.doc.scrollLeft-t)<2)&&!n||(e.doc.scrollLeft=t,zr(e),e.display.scroller.scrollLeft!=t&&(e.display.scroller.scrollLeft=t),e.display.scrollbars.setScrollLeft(t))}function Jr(e){var t=e.display,r=t.gutters.offsetWidth,n=Math.round(e.doc.height+Pt(e.display));return{clientHeight:t.scroller.clientHeight,viewHeight:t.wrapper.clientHeight,scrollWidth:t.scroller.scrollWidth,clientWidth:t.scroller.clientWidth,viewWidth:t.wrapper.clientWidth,barLeft:e.options.fixedGutter?r:0,docHeight:n,scrollHeight:n+zt(e)+t.barHeight,nativeBarWidth:t.nativeBarWidth,gutterWidth:r}}function en(e,t){t||(t=Jr(e));var r=e.display.barWidth,n=e.display.barHeight;tn(e,t);for(var i=0;i<4&&r!=e.display.barWidth||n!=e.display.barHeight;i++)r!=e.display.barWidth&&e.options.lineWrapping&&Er(e),tn(e,Jr(e)),r=e.display.barWidth,n=e.display.barHeight}function tn(e,t){var r=e.display,n=r.scrollbars.update(t);r.sizer.style.paddingRight=(r.barWidth=n.right)+"px",r.sizer.style.paddingBottom=(r.barHeight=n.bottom)+"px",r.heightForcer.style.borderBottom=n.bottom+"px solid transparent",n.right&&n.bottom?(r.scrollbarFiller.style.display="block",r.scrollbarFiller.style.height=n.bottom+"px",r.scrollbarFiller.style.width=n.right+"px"):r.scrollbarFiller.style.display="",n.bottom&&e.options.coverGutterNextToScrollbar&&e.options.fixedGutter?(r.gutterFiller.style.display="block",r.gutterFiller.style.height=n.bottom+"px",r.gutterFiller.style.width=t.gutterWidth+"px"):r.gutterFiller.style.display=""}function rn(e){e.display.scrollbars&&(e.display.scrollbars.clear(),e.display.scrollbars.addClass&&Fl(e.display.wrapper,e.display.scrollbars.addClass)),e.display.scrollbars=new ws[e.options.scrollbarStyle](function(t){e.display.wrapper.insertBefore(t,e.display.scrollbarFiller),Ql(t,"mousedown",function(){e.state.focused&&setTimeout(function(){return e.display.input.focus()},0)}),t.setAttribute("cm-not-content","true")},function(t,r){"horizontal"==r?Qr(e,t):qr(e,t)},e),e.display.scrollbars.addClass&&s(e.display.wrapper,e.display.scrollbars.addClass)}function nn(e){e.curOp={cm:e,viewChanged:!1,startHeight:e.doc.height,forceUpdate:!1,updateInput:null,typing:!1,changeObjs:null,cursorActivityHandlers:null,cursorActivityCalled:0,selectionChanged:!1,updateMaxLine:!1,scrollLeft:null,scrollTop:null,scrollToPos:null,focus:!1,id:++xs},vt(e.curOp)}function on(e){yt(e.curOp,function(e){for(var t=0;t<e.ops.length;t++)e.ops[t].cm.curOp=null;ln(e)})}function ln(e){for(var t=e.ops,r=0;r<t.length;r++)sn(t[r]);for(var n=0;n<t.length;n++)an(t[n]);for(var i=0;i<t.length;i++)un(t[i]);for(var o=0;o<t.length;o++)cn(t[o]);for(var l=0;l<t.length;l++)fn(t[l])}function sn(e){var t=e.cm,r=t.display;Ln(t),e.updateMaxLine&&we(t),e.mustUpdate=e.viewChanged||e.forceUpdate||null!=e.scrollTop||e.scrollToPos&&(e.scrollToPos.from.line<r.viewFrom||e.scrollToPos.to.line>=r.viewTo)||r.maxLineChanged&&t.options.lineWrapping,e.update=e.mustUpdate&&new Cs(t,e.mustUpdate&&{top:e.scrollTop,ensure:e.scrollToPos},e.forceUpdate)}function an(e){e.updatedDisplay=e.mustUpdate&&Mn(e.cm,e.update)}function un(e){var t=e.cm,r=t.display;e.updatedDisplay&&Er(t),e.barMeasure=Jr(t),r.maxLineChanged&&!t.options.lineWrapping&&(e.adjustWidthTo=Kt(t,r.maxLine,r.maxLine.text.length).left+3,t.display.sizerWidth=e.adjustWidthTo,e.barMeasure.scrollWidth=Math.max(r.scroller.clientWidth,r.sizer.offsetLeft+e.adjustWidthTo+zt(t)+t.display.barWidth),e.maxScrollLeft=Math.max(0,r.sizer.offsetLeft+e.adjustWidthTo-Rt(t))),(e.updatedDisplay||e.selectionChanged)&&(e.preparedSelection=r.input.prepareSelection())}function cn(e){var t=e.cm;null!=e.adjustWidthTo&&(t.display.sizer.style.minWidth=e.adjustWidthTo+"px",e.maxScrollLeft<t.doc.scrollLeft&&Qr(t,Math.min(t.display.scroller.scrollLeft,e.maxScrollLeft),!0),t.display.maxLineChanged=!1);var r=e.focus&&e.focus==l();e.preparedSelection&&t.display.input.showSelection(e.preparedSelection,r),(e.updatedDisplay||e.startHeight!=t.doc.height)&&en(t,e.barMeasure),e.updatedDisplay&&Dn(t,e.barMeasure),e.selectionChanged&&Ar(t),t.state.focused&&e.updateInput&&t.display.input.reset(e.typing),r&&Wr(e.cm)}function fn(e){var t=e.cm,r=t.display,n=t.doc;e.updatedDisplay&&Nn(t,e.update),null==r.wheelStartX||null==e.scrollTop&&null==e.scrollLeft&&!e.scrollToPos||(r.wheelStartX=r.wheelStartY=null),null!=e.scrollTop&&Zr(t,e.scrollTop,e.forceScroll),null!=e.scrollLeft&&Qr(t,e.scrollLeft,!0,!0),e.scrollToPos&&Br(t,Gr(t,U(n,e.scrollToPos.from),U(n,e.scrollToPos.to),e.scrollToPos.margin));var i=e.maybeHiddenMarkers,o=e.maybeUnhiddenMarkers;if(i)for(var l=0;l<i.length;++l)i[l].lines.length||Te(i[l],"hide");if(o)for(var s=0;s<o.length;++s)o[s].lines.length&&Te(o[s],"unhide");r.wrapper.offsetHeight&&(n.scrollTop=t.display.scroller.scrollTop),e.changeObjs&&Te(t,"changes",t,e.changeObjs),e.update&&e.update.finish()}function hn(e,t){if(e.curOp)return t();nn(e);try{return t()}finally{on(e)}}function dn(e,t){return function(){if(e.curOp)return t.apply(e,arguments);nn(e);try{return t.apply(e,arguments)}finally{on(e)}}}function pn(e){return function(){if(this.curOp)return e.apply(this,arguments);nn(this);try{return e.apply(this,arguments)}finally{on(this)}}}function gn(e){return function(){var t=this.cm;if(!t||t.curOp)return e.apply(this,arguments);nn(t);try{return e.apply(this,arguments)}finally{on(t)}}}function vn(e,t,r,n){null==t&&(t=e.doc.first),null==r&&(r=e.doc.first+e.doc.size),n||(n=0);var i=e.display;if(n&&r<i.viewTo&&(null==i.updateLineNumbers||i.updateLineNumbers>t)&&(i.updateLineNumbers=t),e.curOp.viewChanged=!0,t>=i.viewTo)_l&&pe(e.doc,t)<i.viewTo&&yn(e);else if(r<=i.viewFrom)_l&&ge(e.doc,r+n)>i.viewFrom?yn(e):(i.viewFrom+=n,i.viewTo+=n);else if(t<=i.viewFrom&&r>=i.viewTo)yn(e);else if(t<=i.viewFrom){var o=bn(e,r,r+n,1);o?(i.view=i.view.slice(o.index),i.viewFrom=o.lineN,i.viewTo+=n):yn(e)}else if(r>=i.viewTo){var l=bn(e,t,t,-1);l?(i.view=i.view.slice(0,l.index),i.viewTo=l.lineN):yn(e)}else{var s=bn(e,t,t,-1),a=bn(e,r,r+n,1);s&&a?(i.view=i.view.slice(0,s.index).concat(gt(e,s.lineN,a.lineN)).concat(i.view.slice(a.index)),i.viewTo+=n):yn(e)}var u=i.externalMeasured;u&&(r<u.lineN?u.lineN+=n:t<u.lineN+u.size&&(i.externalMeasured=null))}function mn(e,t,r){e.curOp.viewChanged=!0;var n=e.display,i=e.display.externalMeasured;if(i&&t>=i.lineN&&t<i.lineN+i.size&&(n.externalMeasured=null),!(t<n.viewFrom||t>=n.viewTo)){var o=n.view[Lr(e,t)];if(null!=o.node){var l=o.changes||(o.changes=[]);-1==h(l,r)&&l.push(r)}}}function yn(e){e.display.viewFrom=e.display.viewTo=e.doc.first,e.display.view=[],e.display.viewOffset=0}function bn(e,t,r,n){var i,o=Lr(e,t),l=e.display.view;if(!_l||r==e.doc.first+e.doc.size)return{index:o,lineN:r};for(var s=e.display.viewFrom,a=0;a<o;a++)s+=l[a].size;if(s!=t){if(n>0){if(o==l.length-1)return null;i=s+l[o].size-t,o++}else i=s-t;t+=i,r+=i}for(;pe(e.doc,r)!=r;){if(o==(n<0?0:l.length-1))return null;r+=n*l[o-(n<0?1:0)].size,o+=n}return{index:o,lineN:r}}function wn(e,t,r){var n=e.display;0==n.view.length||t>=n.viewTo||r<=n.viewFrom?(n.view=gt(e,t,r),n.viewFrom=t):(n.viewFrom>t?n.view=gt(e,t,n.viewFrom).concat(n.view):n.viewFrom<t&&(n.view=n.view.slice(Lr(e,t))),n.viewFrom=t,n.viewTo<r?n.view=n.view.concat(gt(e,n.viewTo,r)):n.viewTo>r&&(n.view=n.view.slice(0,Lr(e,r)))),n.viewTo=r}function xn(e){for(var t=e.display.view,r=0,n=0;n<t.length;n++){var i=t[n];i.hidden||i.node&&!i.changes||++r}return r}function Cn(e,t){e.doc.highlightFrontier<e.display.viewTo&&e.state.highlight.set(t,u(Sn,e))}function Sn(e){var t=e.doc;if(!(t.highlightFrontier>=e.display.viewTo)){var r=+new Date+e.options.workTime,n=$e(e,t.highlightFrontier),i=[];t.iter(n.line,Math.min(t.first+t.size,e.display.viewTo+500),function(o){if(n.line>=e.display.viewFrom){var l=o.styles,s=o.text.length>e.options.maxHighlightLength?Ke(t.mode,n.state):null,a=Ye(e,o,n,!0);s&&(n.state=s),o.styles=a.styles;var u=o.styleClasses,c=a.classes;c?o.styleClasses=c:u&&(o.styleClasses=null);for(var f=!l||l.length!=o.styles.length||u!=c&&(!u||!c||u.bgClass!=c.bgClass||u.textClass!=c.textClass),h=0;!f&&h<l.length;++h)f=l[h]!=o.styles[h];f&&i.push(n.line),o.stateAfter=n.save(),n.nextLine()}else o.text.length<=e.options.maxHighlightLength&&qe(e,o.text,n),o.stateAfter=n.line%5==0?n.save():null,n.nextLine();if(+new Date>r)return Cn(e,e.options.workDelay),!0}),t.highlightFrontier=n.line,t.modeFrontier=Math.max(t.modeFrontier,n.line),i.length&&hn(e,function(){for(var t=0;t<i.length;t++)mn(e,i[t],"text")})}}function Ln(e){var t=e.display;!t.scrollbarsClipped&&t.scroller.offsetWidth&&(t.nativeBarWidth=t.scroller.offsetWidth-t.scroller.clientWidth,t.heightForcer.style.height=zt(e)+"px",t.sizer.style.marginBottom=-t.nativeBarWidth+"px",t.sizer.style.borderRightWidth=zt(e)+"px",t.scrollbarsClipped=!0)}function kn(e){if(e.hasFocus())return null;var t=l();if(!t||!o(e.display.lineDiv,t))return null;var r={activeElt:t};if(window.getSelection){var n=window.getSelection();n.anchorNode&&n.extend&&o(e.display.lineDiv,n.anchorNode)&&(r.anchorNode=n.anchorNode,r.anchorOffset=n.anchorOffset,r.focusNode=n.focusNode,r.focusOffset=n.focusOffset)}return r}function Tn(e){if(e&&e.activeElt&&e.activeElt!=l()&&(e.activeElt.focus(),e.anchorNode&&o(document.body,e.anchorNode)&&o(document.body,e.focusNode))){var t=window.getSelection(),r=document.createRange();r.setEnd(e.anchorNode,e.anchorOffset),r.collapse(!1),t.removeAllRanges(),t.addRange(r),t.extend(e.focusNode,e.focusOffset)}}function Mn(e,r){var n=e.display,i=e.doc;if(r.editorIsHidden)return yn(e),!1;if(!r.force&&r.visible.from>=n.viewFrom&&r.visible.to<=n.viewTo&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo)&&n.renderedView==n.view&&0==xn(e))return!1;Rr(e)&&(yn(e),r.dims=br(e));var o=i.first+i.size,l=Math.max(r.visible.from-e.options.viewportMargin,i.first),s=Math.min(o,r.visible.to+e.options.viewportMargin);n.viewFrom<l&&l-n.viewFrom<20&&(l=Math.max(i.first,n.viewFrom)),n.viewTo>s&&n.viewTo-s<20&&(s=Math.min(o,n.viewTo)),_l&&(l=pe(e.doc,l),s=ge(e.doc,s));var a=l!=n.viewFrom||s!=n.viewTo||n.lastWrapHeight!=r.wrapperHeight||n.lastWrapWidth!=r.wrapperWidth;wn(e,l,s),n.viewOffset=ye(M(e.doc,n.viewFrom)),e.display.mover.style.top=n.viewOffset+"px";var u=xn(e);if(!a&&0==u&&!r.force&&n.renderedView==n.view&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo))return!1;var c=kn(e);return u>4&&(n.lineDiv.style.display="none"),An(e,n.updateLineNumbers,r.dims),u>4&&(n.lineDiv.style.display=""),n.renderedView=n.view,Tn(c),t(n.cursorDiv),t(n.selectionDiv),n.gutters.style.height=n.sizer.style.minHeight=0,a&&(n.lastWrapHeight=r.wrapperHeight,n.lastWrapWidth=r.wrapperWidth,Cn(e,400)),n.updateLineNumbers=null,!0}function Nn(e,t){for(var r=t.viewport,n=!0;(n&&e.options.lineWrapping&&t.oldDisplayWidth!=Rt(e)||(r&&null!=r.top&&(r={top:Math.min(e.doc.height+Pt(e.display)-Bt(e),r.top)}),t.visible=Ir(e.display,e.doc,r),!(t.visible.from>=e.display.viewFrom&&t.visible.to<=e.display.viewTo)))&&Mn(e,t);n=!1){Er(e);var i=Jr(e);kr(e),en(e,i),Dn(e,i),t.force=!1}t.signal(e,"update",e),e.display.viewFrom==e.display.reportedViewFrom&&e.display.viewTo==e.display.reportedViewTo||(t.signal(e,"viewportChange",e,e.display.viewFrom,e.display.viewTo),e.display.reportedViewFrom=e.display.viewFrom,e.display.reportedViewTo=e.display.viewTo)}function On(e,t){var r=new Cs(e,t);if(Mn(e,r)){Er(e),Nn(e,r);var n=Jr(e);kr(e),en(e,n),Dn(e,n),r.finish()}}function An(e,r,n){function i(t){var r=t.nextSibling;return ml&&Ml&&e.display.currentWheelTarget==t?t.style.display="none":t.parentNode.removeChild(t),r}for(var o=e.display,l=e.options.lineNumbers,s=o.lineDiv,a=s.firstChild,u=o.view,c=o.viewFrom,f=0;f<u.length;f++){var d=u[f];if(d.hidden);else if(d.node&&d.node.parentNode==s){for(;a!=d.node;)a=i(a);var p=l&&null!=r&&r<=c&&d.lineNumber;d.changes&&(h(d.changes,"gutter")>-1&&(p=!1),xt(e,d,c,n)),p&&(t(d.lineNumber),d.lineNumber.appendChild(document.createTextNode(F(e.options,c)))),a=d.node.nextSibling}else{var g=Ot(e,d,c,n);s.insertBefore(g,a)}c+=d.size}for(;a;)a=i(a)}function Wn(e){var t=e.display.gutters.offsetWidth;e.display.sizer.style.marginLeft=t+"px"}function Dn(e,t){e.display.sizer.style.minHeight=t.docHeight+"px",e.display.heightForcer.style.top=t.docHeight+"px",e.display.gutters.style.height=t.docHeight+e.display.barHeight+zt(e)+"px"}function Hn(e){var r=e.display.gutters,i=e.options.gutters;t(r);for(var o=0;o<i.length;++o){var l=i[o],s=r.appendChild(n("div",null,"CodeMirror-gutter "+l));"CodeMirror-linenumbers"==l&&(e.display.lineGutter=s,s.style.width=(e.display.lineNumWidth||1)+"px")}r.style.display=o?"":"none",Wn(e)}function Fn(e){var t=h(e.gutters,"CodeMirror-linenumbers");-1==t&&e.lineNumbers?e.gutters=e.gutters.concat(["CodeMirror-linenumbers"]):t>-1&&!e.lineNumbers&&(e.gutters=e.gutters.slice(0),e.gutters.splice(t,1))}function En(e){var t=e.wheelDeltaX,r=e.wheelDeltaY;return null==t&&e.detail&&e.axis==e.HORIZONTAL_AXIS&&(t=e.detail),null==r&&e.detail&&e.axis==e.VERTICAL_AXIS?r=e.detail:null==r&&(r=e.wheelDelta),{x:t,y:r}}function Pn(e){var t=En(e);return t.x*=Ls,t.y*=Ls,t}function In(e,t){var r=En(t),n=r.x,i=r.y,o=e.display,l=o.scroller,s=l.scrollWidth>l.clientWidth,a=l.scrollHeight>l.clientHeight;if(n&&s||i&&a){if(i&&Ml&&ml)e:for(var u=t.target,c=o.view;u!=l;u=u.parentNode)for(var f=0;f<c.length;f++)if(c[f].node==u){e.display.currentWheelTarget=u;break e}if(n&&!fl&&!wl&&null!=Ls)return i&&a&&qr(e,Math.max(0,l.scrollTop+i*Ls)),Qr(e,Math.max(0,l.scrollLeft+n*Ls)),(!i||i&&a)&&We(t),void(o.wheelStartX=null);if(i&&null!=Ls){var h=i*Ls,d=e.doc.scrollTop,p=d+o.wrapper.clientHeight;h<0?d=Math.max(0,d+h-50):p=Math.min(e.doc.height,p+h+50),On(e,{top:d,bottom:p})}Ss<20&&(null==o.wheelStartX?(o.wheelStartX=l.scrollLeft,o.wheelStartY=l.scrollTop,o.wheelDX=n,o.wheelDY=i,setTimeout(function(){if(null!=o.wheelStartX){var e=l.scrollLeft-o.wheelStartX,t=l.scrollTop-o.wheelStartY,r=t&&o.wheelDY&&t/o.wheelDY||e&&o.wheelDX&&e/o.wheelDX;o.wheelStartX=o.wheelStartY=null,r&&(Ls=(Ls*Ss+r)/(Ss+1),++Ss)}},200)):(o.wheelDX+=n,o.wheelDY+=i))}}function zn(e,t){var r=e[t];e.sort(function(e,t){return P(e.from(),t.from())}),t=h(e,r);for(var n=1;n<e.length;n++){var i=e[n],o=e[n-1];if(P(o.to(),i.from())>=0){var l=B(o.from(),i.from()),s=R(o.to(),i.to()),a=o.empty()?i.from()==i.head:o.from()==o.head;n<=t&&--t,e.splice(--n,2,new Ts(a?s:l,a?l:s))}}return new ks(e,t)}function Rn(e,t){return new ks([new Ts(e,t||e)],0)}function Bn(e){return e.text?E(e.from.line+e.text.length-1,g(e.text).length+(1==e.text.length?e.from.ch:0)):e.to}function Gn(e,t){if(P(e,t.from)<0)return e;if(P(e,t.to)<=0)return Bn(t);var r=e.line+t.text.length-(t.to.line-t.from.line)-1,n=e.ch;return e.line==t.to.line&&(n+=Bn(t).ch-t.to.ch),E(r,n)}function Un(e,t){for(var r=[],n=0;n<e.sel.ranges.length;n++){var i=e.sel.ranges[n];r.push(new Ts(Gn(i.anchor,t),Gn(i.head,t)))}return zn(r,e.sel.primIndex)}function Vn(e,t,r){return e.line==t.line?E(r.line,e.ch-t.ch+r.ch):E(r.line+(e.line-t.line),e.ch)}function Kn(e,t,r){for(var n=[],i=E(e.first,0),o=i,l=0;l<t.length;l++){var s=t[l],a=Vn(s.from,i,o),u=Vn(Bn(s),i,o);if(i=s.to,o=u,"around"==r){var c=e.sel.ranges[l],f=P(c.head,c.anchor)<0;n[l]=new Ts(f?u:a,f?a:u)}else n[l]=new Ts(a,a)}return new ks(n,e.sel.primIndex)}function jn(e){e.doc.mode=Ue(e.options,e.doc.modeOption),Xn(e)}function Xn(e){e.doc.iter(function(e){e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null)}),e.doc.modeFrontier=e.doc.highlightFrontier=e.doc.first,Cn(e,100),e.state.modeGen++,e.curOp&&vn(e)}function Yn(e,t){return 0==t.from.ch&&0==t.to.ch&&""==g(t.text)&&(!e.cm||e.cm.options.wholeLineUpdateBefore)}function _n(e,t,r,n){function i(e){return r?r[e]:null}function o(e,r,i){it(e,r,i,n),bt(e,"change",e,t)}function l(e,t){for(var r=[],o=e;o<t;++o)r.push(new fs(u[o],i(o),n));return r}var s=t.from,a=t.to,u=t.text,c=M(e,s.line),f=M(e,a.line),h=g(u),d=i(u.length-1),p=a.line-s.line;if(t.full)e.insert(0,l(0,u.length)),e.remove(u.length,e.size-u.length);else if(Yn(e,t)){var v=l(0,u.length-1);o(f,f.text,d),p&&e.remove(s.line,p),v.length&&e.insert(s.line,v)}else if(c==f)if(1==u.length)o(c,c.text.slice(0,s.ch)+h+c.text.slice(a.ch),d);else{var m=l(1,u.length-1);m.push(new fs(h+c.text.slice(a.ch),d,n)),o(c,c.text.slice(0,s.ch)+u[0],i(0)),e.insert(s.line+1,m)}else if(1==u.length)o(c,c.text.slice(0,s.ch)+u[0]+f.text.slice(a.ch),i(0)),e.remove(s.line+1,p);else{o(c,c.text.slice(0,s.ch)+u[0],i(0)),o(f,h+f.text.slice(a.ch),d);var y=l(1,u.length-1);p>1&&e.remove(s.line+1,p-1),e.insert(s.line+1,y)}bt(e,"change",e,t)}function $n(e,t,r){function n(e,i,o){if(e.linked)for(var l=0;l<e.linked.length;++l){var s=e.linked[l];if(s.doc!=i){var a=o&&s.sharedHist;r&&!a||(t(s.doc,a),n(s.doc,e,a))}}}n(e,null,!0)}function qn(e,t){if(t.cm)throw new Error("This document is already in use.");e.doc=t,t.cm=e,Cr(e),jn(e),Zn(e),e.options.lineWrapping||we(e),e.options.mode=t.modeOption,vn(e)}function Zn(e){("rtl"==e.doc.direction?s:Fl)(e.display.lineDiv,"CodeMirror-rtl")}function Qn(e){hn(e,function(){Zn(e),vn(e)})}function Jn(e){this.done=[],this.undone=[],this.undoDepth=1/0,this.lastModTime=this.lastSelTime=0,this.lastOp=this.lastSelOp=null,this.lastOrigin=this.lastSelOrigin=null,this.generation=this.maxGeneration=e||1}function ei(e,t){var r={from:z(t.from),to:Bn(t),text:N(e,t.from,t.to)};return si(e,r,t.from.line,t.to.line+1),$n(e,function(e){return si(e,r,t.from.line,t.to.line+1)},!0),r}function ti(e){for(;e.length&&g(e).ranges;)e.pop()}function ri(e,t){return t?(ti(e.done),g(e.done)):e.done.length&&!g(e.done).ranges?g(e.done):e.done.length>1&&!e.done[e.done.length-2].ranges?(e.done.pop(),g(e.done)):void 0}function ni(e,t,r,n){var i=e.history;i.undone.length=0;var o,l,s=+new Date;if((i.lastOp==n||i.lastOrigin==t.origin&&t.origin&&("+"==t.origin.charAt(0)&&e.cm&&i.lastModTime>s-e.cm.options.historyEventDelay||"*"==t.origin.charAt(0)))&&(o=ri(i,i.lastOp==n)))l=g(o.changes),0==P(t.from,t.to)&&0==P(t.from,l.to)?l.to=Bn(t):o.changes.push(ei(e,t));else{var a=g(i.done);for(a&&a.ranges||li(e.sel,i.done),o={changes:[ei(e,t)],generation:i.generation},i.done.push(o);i.done.length>i.undoDepth;)i.done.shift(),i.done[0].ranges||i.done.shift()}i.done.push(r),i.generation=++i.maxGeneration,i.lastModTime=i.lastSelTime=s,i.lastOp=i.lastSelOp=n,i.lastOrigin=i.lastSelOrigin=t.origin,l||Te(e,"historyAdded")}function ii(e,t,r,n){var i=t.charAt(0);return"*"==i||"+"==i&&r.ranges.length==n.ranges.length&&r.somethingSelected()==n.somethingSelected()&&new Date-e.history.lastSelTime<=(e.cm?e.cm.options.historyEventDelay:500)}function oi(e,t,r,n){var i=e.history,o=n&&n.origin;r==i.lastSelOp||o&&i.lastSelOrigin==o&&(i.lastModTime==i.lastSelTime&&i.lastOrigin==o||ii(e,o,g(i.done),t))?i.done[i.done.length-1]=t:li(t,i.done),i.lastSelTime=+new Date,i.lastSelOrigin=o,i.lastSelOp=r,n&&!1!==n.clearRedo&&ti(i.undone)}function li(e,t){var r=g(t);r&&r.ranges&&r.equals(e)||t.push(e)}function si(e,t,r,n){var i=t["spans_"+e.id],o=0;e.iter(Math.max(e.first,r),Math.min(e.first+e.size,n),function(r){r.markedSpans&&((i||(i=t["spans_"+e.id]={}))[o]=r.markedSpans),++o})}function ai(e){if(!e)return null;for(var t,r=0;r<e.length;++r)e[r].marker.explicitlyCleared?t||(t=e.slice(0,r)):t&&t.push(e[r]);return t?t.length?t:null:e}function ui(e,t){var r=t["spans_"+e.id];if(!r)return null;for(var n=[],i=0;i<t.text.length;++i)n.push(ai(r[i]));return n}function ci(e,t){var r=ui(e,t),n=J(e,t);if(!r)return n;if(!n)return r;for(var i=0;i<r.length;++i){var o=r[i],l=n[i];if(o&&l)e:for(var s=0;s<l.length;++s){for(var a=l[s],u=0;u<o.length;++u)if(o[u].marker==a.marker)continue e;o.push(a)}else l&&(r[i]=l)}return r}function fi(e,t,r){for(var n=[],i=0;i<e.length;++i){var o=e[i];if(o.ranges)n.push(r?ks.prototype.deepCopy.call(o):o);else{var l=o.changes,s=[];n.push({changes:s});for(var a=0;a<l.length;++a){var u=l[a],c=void 0;if(s.push({from:u.from,to:u.to,text:u.text}),t)for(var f in u)(c=f.match(/^spans_(\d+)$/))&&h(t,Number(c[1]))>-1&&(g(s)[f]=u[f],delete u[f])}}}return n}function hi(e,t,r,n){if(n){var i=e.anchor;if(r){var o=P(t,i)<0;o!=P(r,i)<0?(i=t,t=r):o!=P(t,r)<0&&(t=r)}return new Ts(i,t)}return new Ts(r||t,t)}function di(e,t,r,n,i){null==i&&(i=e.cm&&(e.cm.display.shift||e.extend)),bi(e,new ks([hi(e.sel.primary(),t,r,i)],0),n)}function pi(e,t,r){for(var n=[],i=e.cm&&(e.cm.display.shift||e.extend),o=0;o<e.sel.ranges.length;o++)n[o]=hi(e.sel.ranges[o],t[o],null,i);bi(e,zn(n,e.sel.primIndex),r)}function gi(e,t,r,n){var i=e.sel.ranges.slice(0);i[t]=r,bi(e,zn(i,e.sel.primIndex),n)}function vi(e,t,r,n){bi(e,Rn(t,r),n)}function mi(e,t,r){var n={ranges:t.ranges,update:function(t){var r=this;this.ranges=[];for(var n=0;n<t.length;n++)r.ranges[n]=new Ts(U(e,t[n].anchor),U(e,t[n].head))},origin:r&&r.origin};return Te(e,"beforeSelectionChange",e,n),e.cm&&Te(e.cm,"beforeSelectionChange",e.cm,n),n.ranges!=t.ranges?zn(n.ranges,n.ranges.length-1):t}function yi(e,t,r){var n=e.history.done,i=g(n);i&&i.ranges?(n[n.length-1]=t,wi(e,t,r)):bi(e,t,r)}function bi(e,t,r){wi(e,t,r),oi(e,e.sel,e.cm?e.cm.curOp.id:NaN,r)}function wi(e,t,r){(Oe(e,"beforeSelectionChange")||e.cm&&Oe(e.cm,"beforeSelectionChange"))&&(t=mi(e,t,r)),xi(e,Si(e,t,r&&r.bias||(P(t.primary().head,e.sel.primary().head)<0?-1:1),!0)),r&&!1===r.scroll||!e.cm||jr(e.cm)}function xi(e,t){t.equals(e.sel)||(e.sel=t,e.cm&&(e.cm.curOp.updateInput=e.cm.curOp.selectionChanged=!0,Ne(e.cm)),bt(e,"cursorActivity",e))}function Ci(e){xi(e,Si(e,e.sel,null,!1))}function Si(e,t,r,n){for(var i,o=0;o<t.ranges.length;o++){var l=t.ranges[o],s=t.ranges.length==e.sel.ranges.length&&e.sel.ranges[o],a=ki(e,l.anchor,s&&s.anchor,r,n),u=ki(e,l.head,s&&s.head,r,n);(i||a!=l.anchor||u!=l.head)&&(i||(i=t.ranges.slice(0,o)),i[o]=new Ts(a,u))}return i?zn(i,t.primIndex):t}function Li(e,t,r,n,i){var o=M(e,t.line);if(o.markedSpans)for(var l=0;l<o.markedSpans.length;++l){var s=o.markedSpans[l],a=s.marker;if((null==s.from||(a.inclusiveLeft?s.from<=t.ch:s.from<t.ch))&&(null==s.to||(a.inclusiveRight?s.to>=t.ch:s.to>t.ch))){if(i&&(Te(a,"beforeCursorEnter"),a.explicitlyCleared)){if(o.markedSpans){--l;continue}break}if(!a.atomic)continue;if(r){var u=a.find(n<0?1:-1),c=void 0;if((n<0?a.inclusiveRight:a.inclusiveLeft)&&(u=Ti(e,u,-n,u&&u.line==t.line?o:null)),u&&u.line==t.line&&(c=P(u,r))&&(n<0?c<0:c>0))return Li(e,u,t,n,i)}var f=a.find(n<0?-1:1);return(n<0?a.inclusiveLeft:a.inclusiveRight)&&(f=Ti(e,f,n,f.line==t.line?o:null)),f?Li(e,f,t,n,i):null}}return t}function ki(e,t,r,n,i){var o=n||1,l=Li(e,t,r,o,i)||!i&&Li(e,t,r,o,!0)||Li(e,t,r,-o,i)||!i&&Li(e,t,r,-o,!0);return l||(e.cantEdit=!0,E(e.first,0))}function Ti(e,t,r,n){return r<0&&0==t.ch?t.line>e.first?U(e,E(t.line-1)):null:r>0&&t.ch==(n||M(e,t.line)).text.length?t.line<e.first+e.size-1?E(t.line+1,0):null:new E(t.line,t.ch+r)}function Mi(e){e.setSelection(E(e.firstLine(),0),E(e.lastLine()),Gl)}function Ni(e,t,r){var n={canceled:!1,from:t.from,to:t.to,text:t.text,origin:t.origin,cancel:function(){return n.canceled=!0}};return r&&(n.update=function(t,r,i,o){t&&(n.from=U(e,t)),r&&(n.to=U(e,r)),i&&(n.text=i),void 0!==o&&(n.origin=o)}),Te(e,"beforeChange",e,n),e.cm&&Te(e.cm,"beforeChange",e.cm,n),n.canceled?null:{from:n.from,to:n.to,text:n.text,origin:n.origin}}function Oi(e,t,r){if(e.cm){if(!e.cm.curOp)return dn(e.cm,Oi)(e,t,r);if(e.cm.state.suppressEdits)return}if(!(Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"))||(t=Ni(e,t,!0))){var n=Yl&&!r&&te(e,t.from,t.to);if(n)for(var i=n.length-1;i>=0;--i)Ai(e,{from:n[i].from,to:n[i].to,text:i?[""]:t.text,origin:t.origin});else Ai(e,t)}}function Ai(e,t){if(1!=t.text.length||""!=t.text[0]||0!=P(t.from,t.to)){var r=Un(e,t);ni(e,t,r,e.cm?e.cm.curOp.id:NaN),Hi(e,t,r,J(e,t));var n=[];$n(e,function(e,r){r||-1!=h(n,e.history)||(zi(e.history,t),n.push(e.history)),Hi(e,t,null,J(e,t))})}}function Wi(e,t,r){if(!e.cm||!e.cm.state.suppressEdits||r){for(var n,i=e.history,o=e.sel,l="undo"==t?i.done:i.undone,s="undo"==t?i.undone:i.done,a=0;a<l.length&&(n=l[a],r?!n.ranges||n.equals(e.sel):n.ranges);a++);if(a!=l.length){for(i.lastOrigin=i.lastSelOrigin=null;(n=l.pop()).ranges;){if(li(n,s),r&&!n.equals(e.sel))return void bi(e,n,{clearRedo:!1});o=n}var u=[];li(o,s),s.push({changes:u,generation:i.generation}),i.generation=n.generation||++i.maxGeneration;for(var c=Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"),f=n.changes.length-1;f>=0;--f){var d=function(r){var i=n.changes[r];if(i.origin=t,c&&!Ni(e,i,!1))return l.length=0,{};u.push(ei(e,i));var o=r?Un(e,i):g(l);Hi(e,i,o,ci(e,i)),!r&&e.cm&&e.cm.scrollIntoView({from:i.from,to:Bn(i)});var s=[];$n(e,function(e,t){t||-1!=h(s,e.history)||(zi(e.history,i),s.push(e.history)),Hi(e,i,null,ci(e,i))})}(f);if(d)return d.v}}}}function Di(e,t){if(0!=t&&(e.first+=t,e.sel=new ks(v(e.sel.ranges,function(e){return new Ts(E(e.anchor.line+t,e.anchor.ch),E(e.head.line+t,e.head.ch))}),e.sel.primIndex),e.cm)){vn(e.cm,e.first,e.first-t,t);for(var r=e.cm.display,n=r.viewFrom;n<r.viewTo;n++)mn(e.cm,n,"gutter")}}function Hi(e,t,r,n){if(e.cm&&!e.cm.curOp)return dn(e.cm,Hi)(e,t,r,n);if(t.to.line<e.first)Di(e,t.text.length-1-(t.to.line-t.from.line));else if(!(t.from.line>e.lastLine())){if(t.from.line<e.first){var i=t.text.length-1-(e.first-t.from.line);Di(e,i),t={from:E(e.first,0),to:E(t.to.line+i,t.to.ch),text:[g(t.text)],origin:t.origin}}var o=e.lastLine();t.to.line>o&&(t={from:t.from,to:E(o,M(e,o).text.length),text:[t.text[0]],origin:t.origin}),t.removed=N(e,t.from,t.to),r||(r=Un(e,t)),e.cm?Fi(e.cm,t,n):_n(e,t,n),wi(e,r,Gl)}}function Fi(e,t,r){var n=e.doc,i=e.display,o=t.from,l=t.to,s=!1,a=o.line;e.options.lineWrapping||(a=W(fe(M(n,o.line))),n.iter(a,l.line+1,function(e){if(e==i.maxLine)return s=!0,!0})),n.sel.contains(t.from,t.to)>-1&&Ne(e),_n(n,t,r,xr(e)),e.options.lineWrapping||(n.iter(a,o.line+t.text.length,function(e){var t=be(e);t>i.maxLineLength&&(i.maxLine=e,i.maxLineLength=t,i.maxLineChanged=!0,s=!1)}),s&&(e.curOp.updateMaxLine=!0)),nt(n,o.line),Cn(e,400);var u=t.text.length-(l.line-o.line)-1;t.full?vn(e):o.line!=l.line||1!=t.text.length||Yn(e.doc,t)?vn(e,o.line,l.line+1,u):mn(e,o.line,"text");var c=Oe(e,"changes"),f=Oe(e,"change");if(f||c){var h={from:o,to:l,text:t.text,removed:t.removed,origin:t.origin};f&&bt(e,"change",e,h),c&&(e.curOp.changeObjs||(e.curOp.changeObjs=[])).push(h)}e.display.selForContextMenu=null}function Ei(e,t,r,n,i){if(n||(n=r),P(n,r)<0){var o;r=(o=[n,r])[0],n=o[1]}"string"==typeof t&&(t=e.splitLines(t)),Oi(e,{from:r,to:n,text:t,origin:i})}function Pi(e,t,r,n){r<e.line?e.line+=n:t<e.line&&(e.line=t,e.ch=0)}function Ii(e,t,r,n){for(var i=0;i<e.length;++i){var o=e[i],l=!0;if(o.ranges){o.copied||((o=e[i]=o.deepCopy()).copied=!0);for(var s=0;s<o.ranges.length;s++)Pi(o.ranges[s].anchor,t,r,n),Pi(o.ranges[s].head,t,r,n)}else{for(var a=0;a<o.changes.length;++a){var u=o.changes[a];if(r<u.from.line)u.from=E(u.from.line+n,u.from.ch),u.to=E(u.to.line+n,u.to.ch);else if(t<=u.to.line){l=!1;break}}l||(e.splice(0,i+1),i=0)}}}function zi(e,t){var r=t.from.line,n=t.to.line,i=t.text.length-(n-r)-1;Ii(e.done,r,n,i),Ii(e.undone,r,n,i)}function Ri(e,t,r,n){var i=t,o=t;return"number"==typeof t?o=M(e,G(e,t)):i=W(t),null==i?null:(n(o,i)&&e.cm&&mn(e.cm,i,r),o)}function Bi(e){var t=this;this.lines=e,this.parent=null;for(var r=0,n=0;n<e.length;++n)e[n].parent=t,r+=e[n].height;this.height=r}function Gi(e){var t=this;this.children=e;for(var r=0,n=0,i=0;i<e.length;++i){var o=e[i];r+=o.chunkSize(),n+=o.height,o.parent=t}this.size=r,this.height=n,this.parent=null}function Ui(e,t,r){ye(t)<(e.curOp&&e.curOp.scrollTop||e.doc.scrollTop)&&Kr(e,r)}function Vi(e,t,r,n){var i=new Ms(e,r,n),o=e.cm;return o&&i.noHScroll&&(o.display.alignWidgets=!0),Ri(e,t,"widget",function(t){var r=t.widgets||(t.widgets=[]);if(null==i.insertAt?r.push(i):r.splice(Math.min(r.length-1,Math.max(0,i.insertAt)),0,i),i.line=t,o&&!ve(e,t)){var n=ye(t)<e.scrollTop;A(t,t.height+Ht(i)),n&&Kr(o,i.height),o.curOp.forceUpdate=!0}return!0}),bt(o,"lineWidgetAdded",o,i,"number"==typeof t?t:W(t)),i}function Ki(e,t,r,n,o){if(n&&n.shared)return ji(e,t,r,n,o);if(e.cm&&!e.cm.curOp)return dn(e.cm,Ki)(e,t,r,n,o);var l=new Os(e,o),s=P(t,r);if(n&&c(n,l,!1),s>0||0==s&&!1!==l.clearWhenEmpty)return l;if(l.replacedWith&&(l.collapsed=!0,l.widgetNode=i("span",[l.replacedWith],"CodeMirror-widget"),n.handleMouseEvents||l.widgetNode.setAttribute("cm-ignore-events","true"),n.insertLeft&&(l.widgetNode.insertLeft=!0)),l.collapsed){if(ce(e,t.line,t,r,l)||t.line!=r.line&&ce(e,r.line,t,r,l))throw new Error("Inserting collapsed marker partially overlapping an existing one");X()}l.addToHistory&&ni(e,{from:t,to:r,origin:"markText"},e.sel,NaN);var a,u=t.line,f=e.cm;if(e.iter(u,r.line+1,function(e){f&&l.collapsed&&!f.options.lineWrapping&&fe(e)==f.display.maxLine&&(a=!0),l.collapsed&&u!=t.line&&A(e,0),q(e,new Y(l,u==t.line?t.ch:null,u==r.line?r.ch:null)),++u}),l.collapsed&&e.iter(t.line,r.line+1,function(t){ve(e,t)&&A(t,0)}),l.clearOnEnter&&Ql(l,"beforeCursorEnter",function(){return l.clear()}),l.readOnly&&(j(),(e.history.done.length||e.history.undone.length)&&e.clearHistory()),l.collapsed&&(l.id=++Ns,l.atomic=!0),f){if(a&&(f.curOp.updateMaxLine=!0),l.collapsed)vn(f,t.line,r.line+1);else if(l.className||l.title||l.startStyle||l.endStyle||l.css)for(var h=t.line;h<=r.line;h++)mn(f,h,"text");l.atomic&&Ci(f.doc),bt(f,"markerAdded",f,l)}return l}function ji(e,t,r,n,i){(n=c(n)).shared=!1;var o=[Ki(e,t,r,n,i)],l=o[0],s=n.widgetNode;return $n(e,function(e){s&&(n.widgetNode=s.cloneNode(!0)),o.push(Ki(e,U(e,t),U(e,r),n,i));for(var a=0;a<e.linked.length;++a)if(e.linked[a].isParent)return;l=g(o)}),new As(o,l)}function Xi(e){return e.findMarks(E(e.first,0),e.clipPos(E(e.lastLine())),function(e){return e.parent})}function Yi(e,t){for(var r=0;r<t.length;r++){var n=t[r],i=n.find(),o=e.clipPos(i.from),l=e.clipPos(i.to);if(P(o,l)){var s=Ki(e,o,l,n.primary,n.primary.type);n.markers.push(s),s.parent=n}}}function _i(e){for(var t=0;t<e.length;t++)!function(t){var r=e[t],n=[r.primary.doc];$n(r.primary.doc,function(e){return n.push(e)});for(var i=0;i<r.markers.length;i++){var o=r.markers[i];-1==h(n,o.doc)&&(o.parent=null,r.markers.splice(i--,1))}}(t)}function $i(e){var t=this;if(Qi(t),!Me(t,e)&&!Ft(t.display,e)){We(e),gl&&(Hs=+new Date);var r=Sr(t,e,!0),n=e.dataTransfer.files;if(r&&!t.isReadOnly())if(n&&n.length&&window.FileReader&&window.File)for(var i=n.length,o=Array(i),l=0,s=0;s<i;++s)!function(e,n){if(!t.options.allowDropFileTypes||-1!=h(t.options.allowDropFileTypes,e.type)){var s=new FileReader;s.onload=dn(t,function(){var e=s.result;if(/[\x00-\x08\x0e-\x1f]{2}/.test(e)&&(e=""),o[n]=e,++l==i){var a={from:r=U(t.doc,r),to:r,text:t.doc.splitLines(o.join(t.doc.lineSeparator())),origin:"paste"};Oi(t.doc,a),yi(t.doc,Rn(r,Bn(a)))}}),s.readAsText(e)}}(n[s],s);else{if(t.state.draggingText&&t.doc.sel.contains(r)>-1)return t.state.draggingText(e),void setTimeout(function(){return t.display.input.focus()},20);try{var a=e.dataTransfer.getData("Text");if(a){var u;if(t.state.draggingText&&!t.state.draggingText.copy&&(u=t.listSelections()),wi(t.doc,Rn(r,r)),u)for(var c=0;c<u.length;++c)Ei(t.doc,"",u[c].anchor,u[c].head,"drag");t.replaceSelection(a,"around","paste"),t.display.input.focus()}}catch(e){}}}}function qi(e,t){if(gl&&(!e.state.draggingText||+new Date-Hs<100))Fe(t);else if(!Me(e,t)&&!Ft(e.display,t)&&(t.dataTransfer.setData("Text",e.getSelection()),t.dataTransfer.effectAllowed="copyMove",t.dataTransfer.setDragImage&&!xl)){var r=n("img",null,null,"position: fixed; left: 0; top: 0;");r.src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==",wl&&(r.width=r.height=1,e.display.wrapper.appendChild(r),r._top=r.offsetTop),t.dataTransfer.setDragImage(r,0,0),wl&&r.parentNode.removeChild(r)}}function Zi(e,t){var i=Sr(e,t);if(i){var o=document.createDocumentFragment();Mr(e,i,o),e.display.dragCursor||(e.display.dragCursor=n("div",null,"CodeMirror-cursors CodeMirror-dragcursors"),e.display.lineSpace.insertBefore(e.display.dragCursor,e.display.cursorDiv)),r(e.display.dragCursor,o)}}function Qi(e){e.display.dragCursor&&(e.display.lineSpace.removeChild(e.display.dragCursor),e.display.dragCursor=null)}function Ji(e){if(document.getElementsByClassName)for(var t=document.getElementsByClassName("CodeMirror"),r=0;r<t.length;r++){var n=t[r].CodeMirror;n&&e(n)}}function eo(){Fs||(to(),Fs=!0)}function to(){var e;Ql(window,"resize",function(){null==e&&(e=setTimeout(function(){e=null,Ji(ro)},100))}),Ql(window,"blur",function(){return Ji(Fr)})}function ro(e){var t=e.display;t.lastWrapHeight==t.wrapper.clientHeight&&t.lastWrapWidth==t.wrapper.clientWidth||(t.cachedCharWidth=t.cachedTextHeight=t.cachedPaddingH=null,t.scrollbarsClipped=!1,e.setSize())}function no(e){var t=e.split(/-(?!$)/);e=t[t.length-1];for(var r,n,i,o,l=0;l<t.length-1;l++){var s=t[l];if(/^(cmd|meta|m)$/i.test(s))o=!0;else if(/^a(lt)?$/i.test(s))r=!0;else if(/^(c|ctrl|control)$/i.test(s))n=!0;else{if(!/^s(hift)?$/i.test(s))throw new Error("Unrecognized modifier name: "+s);i=!0}}return r&&(e="Alt-"+e),n&&(e="Ctrl-"+e),o&&(e="Cmd-"+e),i&&(e="Shift-"+e),e}function io(e){var t={};for(var r in e)if(e.hasOwnProperty(r)){var n=e[r];if(/^(name|fallthrough|(de|at)tach)$/.test(r))continue;if("..."==n){delete e[r];continue}for(var i=v(r.split(" "),no),o=0;o<i.length;o++){var l=void 0,s=void 0;o==i.length-1?(s=i.join(" "),l=n):(s=i.slice(0,o+1).join(" "),l="...");var a=t[s];if(a){if(a!=l)throw new Error("Inconsistent bindings for "+s)}else t[s]=l}delete e[r]}for(var u in t)e[u]=t[u];return e}function oo(e,t,r,n){var i=(t=uo(t)).call?t.call(e,n):t[e];if(!1===i)return"nothing";if("..."===i)return"multi";if(null!=i&&r(i))return"handled";if(t.fallthrough){if("[object Array]"!=Object.prototype.toString.call(t.fallthrough))return oo(e,t.fallthrough,r,n);for(var o=0;o<t.fallthrough.length;o++){var l=oo(e,t.fallthrough[o],r,n);if(l)return l}}}function lo(e){var t="string"==typeof e?e:Es[e.keyCode];return"Ctrl"==t||"Alt"==t||"Shift"==t||"Mod"==t}function so(e,t,r){var n=e;return t.altKey&&"Alt"!=n&&(e="Alt-"+e),(Dl?t.metaKey:t.ctrlKey)&&"Ctrl"!=n&&(e="Ctrl-"+e),(Dl?t.ctrlKey:t.metaKey)&&"Cmd"!=n&&(e="Cmd-"+e),!r&&t.shiftKey&&"Shift"!=n&&(e="Shift-"+e),e}function ao(e,t){if(wl&&34==e.keyCode&&e.char)return!1;var r=Es[e.keyCode];return null!=r&&!e.altGraphKey&&so(r,e,t)}function uo(e){return"string"==typeof e?Rs[e]:e}function co(e,t){for(var r=e.doc.sel.ranges,n=[],i=0;i<r.length;i++){for(var o=t(r[i]);n.length&&P(o.from,g(n).to)<=0;){var l=n.pop();if(P(l.from,o.from)<0){o.from=l.from;break}}n.push(o)}hn(e,function(){for(var t=n.length-1;t>=0;t--)Ei(e.doc,"",n[t].from,n[t].to,"+delete");jr(e)})}function fo(e,t,r){var n=L(e.text,t+r,r);return n<0||n>e.text.length?null:n}function ho(e,t,r){var n=fo(e,t.ch,r);return null==n?null:new E(t.line,n,r<0?"after":"before")}function po(e,t,r,n,i){if(e){var o=Se(r,t.doc.direction);if(o){var l,s=i<0?g(o):o[0],a=i<0==(1==s.level)?"after":"before";if(s.level>0){var u=Xt(t,r);l=i<0?r.text.length-1:0;var c=Yt(t,u,l).top;l=k(function(e){return Yt(t,u,e).top==c},i<0==(1==s.level)?s.from:s.to-1,l),"before"==a&&(l=fo(r,l,1))}else l=i<0?s.to:s.from;return new E(n,l,a)}}return new E(n,i<0?r.text.length:0,i<0?"before":"after")}function go(e,t,r,n){var i=Se(t,e.doc.direction);if(!i)return ho(t,r,n);r.ch>=t.text.length?(r.ch=t.text.length,r.sticky="before"):r.ch<=0&&(r.ch=0,r.sticky="after");var o=Ce(i,r.ch,r.sticky),l=i[o];if("ltr"==e.doc.direction&&l.level%2==0&&(n>0?l.to>r.ch:l.from<r.ch))return ho(t,r,n);var s,a=function(e,r){return fo(t,e instanceof E?e.ch:e,r)},u=function(r){return e.options.lineWrapping?(s=s||Xt(e,t),hr(e,t,s,r)):{begin:0,end:t.text.length}},c=u("before"==r.sticky?a(r,-1):r.ch);if("rtl"==e.doc.direction||1==l.level){var f=1==l.level==n<0,h=a(r,f?1:-1);if(null!=h&&(f?h<=l.to&&h<=c.end:h>=l.from&&h>=c.begin)){var d=f?"before":"after";return new E(r.line,h,d)}}var p=function(e,t,n){for(var o=function(e,t){return t?new E(r.line,a(e,1),"before"):new E(r.line,e,"after")};e>=0&&e<i.length;e+=t){var l=i[e],s=t>0==(1!=l.level),u=s?n.begin:a(n.end,-1);if(l.from<=u&&u<l.to)return o(u,s);if(u=s?l.from:a(l.to,-1),n.begin<=u&&u<n.end)return o(u,s)}},g=p(o+n,n,c);if(g)return g;var v=n>0?c.end:a(c.begin,-1);return null==v||n>0&&v==t.text.length||!(g=p(n>0?0:i.length-1,n,u(v)))?null:g}function vo(e,t){var r=M(e.doc,t),n=fe(r);return n!=r&&(t=W(n)),po(!0,e,n,t,1)}function mo(e,t){var r=M(e.doc,t),n=he(r);return n!=r&&(t=W(n)),po(!0,e,r,t,-1)}function yo(e,t){var r=vo(e,t.line),n=M(e.doc,r.line),i=Se(n,e.doc.direction);if(!i||0==i[0].level){var o=Math.max(0,n.text.search(/\S/)),l=t.line==r.line&&t.ch<=o&&t.ch;return E(r.line,l?0:o,r.sticky)}return r}function bo(e,t,r){if("string"==typeof t&&!(t=Bs[t]))return!1;e.display.input.ensurePolled();var n=e.display.shift,i=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),r&&(e.display.shift=!1),i=t(e)!=Bl}finally{e.display.shift=n,e.state.suppressEdits=!1}return i}function wo(e,t,r){for(var n=0;n<e.state.keyMaps.length;n++){var i=oo(t,e.state.keyMaps[n],r,e);if(i)return i}return e.options.extraKeys&&oo(t,e.options.extraKeys,r,e)||oo(t,e.options.keyMap,r,e)}function xo(e,t,r,n){var i=e.state.keySeq;if(i){if(lo(t))return"handled";Gs.set(50,function(){e.state.keySeq==i&&(e.state.keySeq=null,e.display.input.reset())}),t=i+" "+t}var o=wo(e,t,n);return"multi"==o&&(e.state.keySeq=t),"handled"==o&&bt(e,"keyHandled",e,t,r),"handled"!=o&&"multi"!=o||(We(r),Ar(e)),i&&!o&&/\'$/.test(t)?(We(r),!0):!!o}function Co(e,t){var r=ao(t,!0);return!!r&&(t.shiftKey&&!e.state.keySeq?xo(e,"Shift-"+r,t,function(t){return bo(e,t,!0)})||xo(e,r,t,function(t){if("string"==typeof t?/^go[A-Z]/.test(t):t.motion)return bo(e,t)}):xo(e,r,t,function(t){return bo(e,t)}))}function So(e,t,r){return xo(e,"'"+r+"'",t,function(t){return bo(e,t,!0)})}function Lo(e){var t=this;if(t.curOp.focus=l(),!Me(t,e)){gl&&vl<11&&27==e.keyCode&&(e.returnValue=!1);var r=e.keyCode;t.display.shift=16==r||e.shiftKey;var n=Co(t,e);wl&&(Us=n?r:null,!n&&88==r&&!rs&&(Ml?e.metaKey:e.ctrlKey)&&t.replaceSelection("",null,"cut")),18!=r||/\bCodeMirror-crosshair\b/.test(t.display.lineDiv.className)||ko(t)}}function ko(e){function t(e){18!=e.keyCode&&e.altKey||(Fl(r,"CodeMirror-crosshair"),ke(document,"keyup",t),ke(document,"mouseover",t))}var r=e.display.lineDiv;s(r,"CodeMirror-crosshair"),Ql(document,"keyup",t),Ql(document,"mouseover",t)}function To(e){16==e.keyCode&&(this.doc.sel.shift=!1),Me(this,e)}function Mo(e){var t=this;if(!(Ft(t.display,e)||Me(t,e)||e.ctrlKey&&!e.altKey||Ml&&e.metaKey)){var r=e.keyCode,n=e.charCode;if(wl&&r==Us)return Us=null,void We(e);if(!wl||e.which&&!(e.which<10)||!Co(t,e)){var i=String.fromCharCode(null==n?r:n);"\b"!=i&&(So(t,e,i)||t.display.input.onKeyPress(e))}}}function No(e,t){var r=+new Date;return js&&js.compare(r,e,t)?(Ks=js=null,"triple"):Ks&&Ks.compare(r,e,t)?(js=new Vs(r,e,t),Ks=null,"double"):(Ks=new Vs(r,e,t),js=null,"single")}function Oo(e){var t=this,r=t.display;if(!(Me(t,e)||r.activeTouch&&r.input.supportsTouch()))if(r.input.ensurePolled(),r.shift=e.shiftKey,Ft(r,e))ml||(r.scroller.draggable=!1,setTimeout(function(){return r.scroller.draggable=!0},100));else if(!zo(t,e)){var n=Sr(t,e),i=Pe(e),o=n?No(n,i):"single";window.focus(),1==i&&t.state.selectingText&&t.state.selectingText(e),n&&Ao(t,i,n,o,e)||(1==i?n?Do(t,n,o,e):Ee(e)==r.scroller&&We(e):2==i?(n&&di(t.doc,n),setTimeout(function(){return r.input.focus()},20)):3==i&&(Hl?Ro(t,e):Dr(t)))}}function Ao(e,t,r,n,i){var o="Click";return"double"==n?o="Double"+o:"triple"==n&&(o="Triple"+o),o=(1==t?"Left":2==t?"Middle":"Right")+o,xo(e,so(o,i),i,function(t){if("string"==typeof t&&(t=Bs[t]),!t)return!1;var n=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),n=t(e,r)!=Bl}finally{e.state.suppressEdits=!1}return n})}function Wo(e,t,r){var n=e.getOption("configureMouse"),i=n?n(e,t,r):{};if(null==i.unit){var o=Nl?r.shiftKey&&r.metaKey:r.altKey;i.unit=o?"rectangle":"single"==t?"char":"double"==t?"word":"line"}return(null==i.extend||e.doc.extend)&&(i.extend=e.doc.extend||r.shiftKey),null==i.addNew&&(i.addNew=Ml?r.metaKey:r.ctrlKey),null==i.moveOnDrag&&(i.moveOnDrag=!(Ml?r.altKey:r.ctrlKey)),i}function Do(e,t,r,n){gl?setTimeout(u(Wr,e),0):e.curOp.focus=l();var i,o=Wo(e,r,n),s=e.doc.sel;e.options.dragDrop&&Jl&&!e.isReadOnly()&&"single"==r&&(i=s.contains(t))>-1&&(P((i=s.ranges[i]).from(),t)<0||t.xRel>0)&&(P(i.to(),t)>0||t.xRel<0)?Ho(e,n,t,o):Eo(e,n,t,o)}function Ho(e,t,r,n){var i=e.display,o=!1,l=dn(e,function(t){ml&&(i.scroller.draggable=!1),e.state.draggingText=!1,ke(document,"mouseup",l),ke(document,"mousemove",s),ke(i.scroller,"dragstart",a),ke(i.scroller,"drop",l),o||(We(t),n.addNew||di(e.doc,r,null,null,n.extend),ml||gl&&9==vl?setTimeout(function(){document.body.focus(),i.input.focus()},20):i.input.focus())}),s=function(e){o=o||Math.abs(t.clientX-e.clientX)+Math.abs(t.clientY-e.clientY)>=10},a=function(){return o=!0};ml&&(i.scroller.draggable=!0),e.state.draggingText=l,l.copy=!n.moveOnDrag,i.scroller.dragDrop&&i.scroller.dragDrop(),Ql(document,"mouseup",l),Ql(document,"mousemove",s),Ql(i.scroller,"dragstart",a),Ql(i.scroller,"drop",l),Dr(e),setTimeout(function(){return i.input.focus()},20)}function Fo(e,t,r){if("char"==r)return new Ts(t,t);if("word"==r)return e.findWordAt(t);if("line"==r)return new Ts(E(t.line,0),U(e.doc,E(t.line+1,0)));var n=r(e,t);return new Ts(n.from,n.to)}function Eo(e,t,r,n){function i(t){if(0!=P(m,t))if(m=t,"rectangle"==n.unit){for(var i=[],o=e.options.tabSize,l=f(M(u,r.line).text,r.ch,o),s=f(M(u,t.line).text,t.ch,o),a=Math.min(l,s),g=Math.max(l,s),v=Math.min(r.line,t.line),y=Math.min(e.lastLine(),Math.max(r.line,t.line));v<=y;v++){var b=M(u,v).text,w=d(b,a,o);a==g?i.push(new Ts(E(v,w),E(v,w))):b.length>w&&i.push(new Ts(E(v,w),E(v,d(b,g,o))))}i.length||i.push(new Ts(r,r)),bi(u,zn(p.ranges.slice(0,h).concat(i),h),{origin:"*mouse",scroll:!1}),e.scrollIntoView(t)}else{var x,C=c,S=Fo(e,t,n.unit),L=C.anchor;P(S.anchor,L)>0?(x=S.head,L=B(C.from(),S.anchor)):(x=S.anchor,L=R(C.to(),S.head));var k=p.ranges.slice(0);k[h]=Po(e,new Ts(U(u,L),x)),bi(u,zn(k,h),Ul)}}function o(t){var r=++b,s=Sr(e,t,!0,"rectangle"==n.unit);if(s)if(0!=P(s,m)){e.curOp.focus=l(),i(s);var c=Ir(a,u);(s.line>=c.to||s.line<c.from)&&setTimeout(dn(e,function(){b==r&&o(t)}),150)}else{var f=t.clientY<y.top?-20:t.clientY>y.bottom?20:0;f&&setTimeout(dn(e,function(){b==r&&(a.scroller.scrollTop+=f,o(t))}),50)}}function s(t){e.state.selectingText=!1,b=1/0,We(t),a.input.focus(),ke(document,"mousemove",w),ke(document,"mouseup",x),u.history.lastSelOrigin=null}var a=e.display,u=e.doc;We(t);var c,h,p=u.sel,g=p.ranges;if(n.addNew&&!n.extend?(h=u.sel.contains(r),c=h>-1?g[h]:new Ts(r,r)):(c=u.sel.primary(),h=u.sel.primIndex),"rectangle"==n.unit)n.addNew||(c=new Ts(r,r)),r=Sr(e,t,!0,!0),h=-1;else{var v=Fo(e,r,n.unit);c=n.extend?hi(c,v.anchor,v.head,n.extend):v}n.addNew?-1==h?(h=g.length,bi(u,zn(g.concat([c]),h),{scroll:!1,origin:"*mouse"})):g.length>1&&g[h].empty()&&"char"==n.unit&&!n.extend?(bi(u,zn(g.slice(0,h).concat(g.slice(h+1)),0),{scroll:!1,origin:"*mouse"}),p=u.sel):gi(u,h,c,Ul):(h=0,bi(u,new ks([c],0),Ul),p=u.sel);var m=r,y=a.wrapper.getBoundingClientRect(),b=0,w=dn(e,function(e){Pe(e)?o(e):s(e)}),x=dn(e,s);e.state.selectingText=x,Ql(document,"mousemove",w),Ql(document,"mouseup",x)}function Po(e,t){var r=t.anchor,n=t.head,i=M(e.doc,r.line);if(0==P(r,n)&&r.sticky==n.sticky)return t;var o=Se(i);if(!o)return t;var l=Ce(o,r.ch,r.sticky),s=o[l];if(s.from!=r.ch&&s.to!=r.ch)return t;var a=l+(s.from==r.ch==(1!=s.level)?0:1);if(0==a||a==o.length)return t;var u;if(n.line!=r.line)u=(n.line-r.line)*("ltr"==e.doc.direction?1:-1)>0;else{var c=Ce(o,n.ch,n.sticky),f=c-l||(n.ch-r.ch)*(1==s.level?-1:1);u=c==a-1||c==a?f<0:f>0}var h=o[a+(u?-1:0)],d=u==(1==h.level),p=d?h.from:h.to,g=d?"after":"before";return r.ch==p&&r.sticky==g?t:new Ts(new E(r.line,p,g),n)}function Io(e,t,r,n){var i,o;if(t.touches)i=t.touches[0].clientX,o=t.touches[0].clientY;else try{i=t.clientX,o=t.clientY}catch(t){return!1}if(i>=Math.floor(e.display.gutters.getBoundingClientRect().right))return!1;n&&We(t);var l=e.display,s=l.lineDiv.getBoundingClientRect();if(o>s.bottom||!Oe(e,r))return He(t);o-=s.top-l.viewOffset;for(var a=0;a<e.options.gutters.length;++a){var u=l.gutters.childNodes[a];if(u&&u.getBoundingClientRect().right>=i)return Te(e,r,e,D(e.doc,o),e.options.gutters[a],t),He(t)}}function zo(e,t){return Io(e,t,"gutterClick",!0)}function Ro(e,t){Ft(e.display,t)||Bo(e,t)||Me(e,t,"contextmenu")||e.display.input.onContextMenu(t)}function Bo(e,t){return!!Oe(e,"gutterContextMenu")&&Io(e,t,"gutterContextMenu",!1)}function Go(e){e.display.wrapper.className=e.display.wrapper.className.replace(/\s*cm-s-\S+/g,"")+e.options.theme.replace(/(^|\s)\s*/g," cm-s-"),er(e)}function Uo(e){Hn(e),vn(e),zr(e)}function Vo(e,t,r){if(!t!=!(r&&r!=Xs)){var n=e.display.dragFunctions,i=t?Ql:ke;i(e.display.scroller,"dragstart",n.start),i(e.display.scroller,"dragenter",n.enter),i(e.display.scroller,"dragover",n.over),i(e.display.scroller,"dragleave",n.leave),i(e.display.scroller,"drop",n.drop)}}function Ko(e){e.options.lineWrapping?(s(e.display.wrapper,"CodeMirror-wrap"),e.display.sizer.style.minWidth="",e.display.sizerWidth=null):(Fl(e.display.wrapper,"CodeMirror-wrap"),we(e)),Cr(e),vn(e),er(e),setTimeout(function(){return en(e)},100)}function jo(e,t){var r=this;if(!(this instanceof jo))return new jo(e,t);this.options=t=t?c(t):{},c(Ys,t,!1),Fn(t);var n=t.value;"string"==typeof n&&(n=new Ds(n,t.mode,null,t.lineSeparator,t.direction)),this.doc=n;var i=new jo.inputStyles[t.inputStyle](this),o=this.display=new T(e,n,i);o.wrapper.CodeMirror=this,Hn(this),Go(this),t.lineWrapping&&(this.display.wrapper.className+=" CodeMirror-wrap"),rn(this),this.state={keyMaps:[],overlays:[],modeGen:0,overwrite:!1,delayingBlurEvent:!1,focused:!1,suppressEdits:!1,pasteIncoming:!1,cutIncoming:!1,selectingText:!1,draggingText:!1,highlight:new Pl,keySeq:null,specialChars:null},t.autofocus&&!Tl&&o.input.focus(),gl&&vl<11&&setTimeout(function(){return r.display.input.reset(!0)},20),Xo(this),eo(),nn(this),this.curOp.forceUpdate=!0,qn(this,n),t.autofocus&&!Tl||this.hasFocus()?setTimeout(u(Hr,this),20):Fr(this);for(var l in _s)_s.hasOwnProperty(l)&&_s[l](r,t[l],Xs);Rr(this),t.finishInit&&t.finishInit(this);for(var s=0;s<$s.length;++s)$s[s](r);on(this),ml&&t.lineWrapping&&"optimizelegibility"==getComputedStyle(o.lineDiv).textRendering&&(o.lineDiv.style.textRendering="auto")}function Xo(e){function t(){i.activeTouch&&(o=setTimeout(function(){return i.activeTouch=null},1e3),(l=i.activeTouch).end=+new Date)}function r(e){if(1!=e.touches.length)return!1;var t=e.touches[0];return t.radiusX<=1&&t.radiusY<=1}function n(e,t){if(null==t.left)return!0;var r=t.left-e.left,n=t.top-e.top;return r*r+n*n>400}var i=e.display;Ql(i.scroller,"mousedown",dn(e,Oo)),gl&&vl<11?Ql(i.scroller,"dblclick",dn(e,function(t){if(!Me(e,t)){var r=Sr(e,t);if(r&&!zo(e,t)&&!Ft(e.display,t)){We(t);var n=e.findWordAt(r);di(e.doc,n.anchor,n.head)}}})):Ql(i.scroller,"dblclick",function(t){return Me(e,t)||We(t)}),Hl||Ql(i.scroller,"contextmenu",function(t){return Ro(e,t)});var o,l={end:0};Ql(i.scroller,"touchstart",function(t){if(!Me(e,t)&&!r(t)&&!zo(e,t)){i.input.ensurePolled(),clearTimeout(o);var n=+new Date;i.activeTouch={start:n,moved:!1,prev:n-l.end<=300?l:null},1==t.touches.length&&(i.activeTouch.left=t.touches[0].pageX,i.activeTouch.top=t.touches[0].pageY)}}),Ql(i.scroller,"touchmove",function(){i.activeTouch&&(i.activeTouch.moved=!0)}),Ql(i.scroller,"touchend",function(r){var o=i.activeTouch;if(o&&!Ft(i,r)&&null!=o.left&&!o.moved&&new Date-o.start<300){var l,s=e.coordsChar(i.activeTouch,"page");l=!o.prev||n(o,o.prev)?new Ts(s,s):!o.prev.prev||n(o,o.prev.prev)?e.findWordAt(s):new Ts(E(s.line,0),U(e.doc,E(s.line+1,0))),e.setSelection(l.anchor,l.head),e.focus(),We(r)}t()}),Ql(i.scroller,"touchcancel",t),Ql(i.scroller,"scroll",function(){i.scroller.clientHeight&&(qr(e,i.scroller.scrollTop),Qr(e,i.scroller.scrollLeft,!0),Te(e,"scroll",e))}),Ql(i.scroller,"mousewheel",function(t){return In(e,t)}),Ql(i.scroller,"DOMMouseScroll",function(t){return In(e,t)}),Ql(i.wrapper,"scroll",function(){return i.wrapper.scrollTop=i.wrapper.scrollLeft=0}),i.dragFunctions={enter:function(t){Me(e,t)||Fe(t)},over:function(t){Me(e,t)||(Zi(e,t),Fe(t))},start:function(t){return qi(e,t)},drop:dn(e,$i),leave:function(t){Me(e,t)||Qi(e)}};var s=i.input.getField();Ql(s,"keyup",function(t){return To.call(e,t)}),Ql(s,"keydown",dn(e,Lo)),Ql(s,"keypress",dn(e,Mo)),Ql(s,"focus",function(t){return Hr(e,t)}),Ql(s,"blur",function(t){return Fr(e,t)})}function Yo(e,t,r,n){var i,o=e.doc;null==r&&(r="add"),"smart"==r&&(o.mode.indent?i=$e(e,t).state:r="prev");var l=e.options.tabSize,s=M(o,t),a=f(s.text,null,l);s.stateAfter&&(s.stateAfter=null);var u,c=s.text.match(/^\s*/)[0];if(n||/\S/.test(s.text)){if("smart"==r&&((u=o.mode.indent(i,s.text.slice(c.length),s.text))==Bl||u>150)){if(!n)return;r="prev"}}else u=0,r="not";"prev"==r?u=t>o.first?f(M(o,t-1).text,null,l):0:"add"==r?u=a+e.options.indentUnit:"subtract"==r?u=a-e.options.indentUnit:"number"==typeof r&&(u=a+r),u=Math.max(0,u);var h="",d=0;if(e.options.indentWithTabs)for(var g=Math.floor(u/l);g;--g)d+=l,h+="\t";if(d<u&&(h+=p(u-d)),h!=c)return Ei(o,h,E(t,0),E(t,c.length),"+input"),s.stateAfter=null,!0;for(var v=0;v<o.sel.ranges.length;v++){var m=o.sel.ranges[v];if(m.head.line==t&&m.head.ch<c.length){var y=E(t,c.length);gi(o,v,new Ts(y,y));break}}}function _o(e){qs=e}function $o(e,t,r,n,i){var o=e.doc;e.display.shift=!1,n||(n=o.sel);var l=e.state.pasteIncoming||"paste"==i,s=es(t),a=null;if(l&&n.ranges.length>1)if(qs&&qs.text.join("\n")==t){if(n.ranges.length%qs.text.length==0){a=[];for(var u=0;u<qs.text.length;u++)a.push(o.splitLines(qs.text[u]))}}else s.length==n.ranges.length&&e.options.pasteLinesPerSelection&&(a=v(s,function(e){return[e]}));for(var c,f=n.ranges.length-1;f>=0;f--){var h=n.ranges[f],d=h.from(),p=h.to();h.empty()&&(r&&r>0?d=E(d.line,d.ch-r):e.state.overwrite&&!l?p=E(p.line,Math.min(M(o,p.line).text.length,p.ch+g(s).length)):qs&&qs.lineWise&&qs.text.join("\n")==t&&(d=p=E(d.line,0))),c=e.curOp.updateInput;var m={from:d,to:p,text:a?a[f%a.length]:s,origin:i||(l?"paste":e.state.cutIncoming?"cut":"+input")};Oi(e.doc,m),bt(e,"inputRead",e,m)}t&&!l&&Zo(e,t),jr(e),e.curOp.updateInput=c,e.curOp.typing=!0,e.state.pasteIncoming=e.state.cutIncoming=!1}function qo(e,t){var r=e.clipboardData&&e.clipboardData.getData("Text");if(r)return e.preventDefault(),t.isReadOnly()||t.options.disableInput||hn(t,function(){return $o(t,r,0,null,"paste")}),!0}function Zo(e,t){if(e.options.electricChars&&e.options.smartIndent)for(var r=e.doc.sel,n=r.ranges.length-1;n>=0;n--){var i=r.ranges[n];if(!(i.head.ch>100||n&&r.ranges[n-1].head.line==i.head.line)){var o=e.getModeAt(i.head),l=!1;if(o.electricChars){for(var s=0;s<o.electricChars.length;s++)if(t.indexOf(o.electricChars.charAt(s))>-1){l=Yo(e,i.head.line,"smart");break}}else o.electricInput&&o.electricInput.test(M(e.doc,i.head.line).text.slice(0,i.head.ch))&&(l=Yo(e,i.head.line,"smart"));l&&bt(e,"electricInput",e,i.head.line)}}}function Qo(e){for(var t=[],r=[],n=0;n<e.doc.sel.ranges.length;n++){var i=e.doc.sel.ranges[n].head.line,o={anchor:E(i,0),head:E(i+1,0)};r.push(o),t.push(e.getRange(o.anchor,o.head))}return{text:t,ranges:r}}function Jo(e,t){e.setAttribute("autocorrect","off"),e.setAttribute("autocapitalize","off"),e.setAttribute("spellcheck",!!t)}function el(){var e=n("textarea",null,null,"position: absolute; bottom: -1em; padding: 0; width: 1px; height: 1em; outline: none"),t=n("div",[e],null,"overflow: hidden; position: relative; width: 3px; height: 0px;");return ml?e.style.width="1000px":e.setAttribute("wrap","off"),Ll&&(e.style.border="1px solid black"),Jo(e),t}function tl(e,t,r,n,i){function o(){var n=t.line+r;return!(n<e.first||n>=e.first+e.size)&&(t=new E(n,t.ch,t.sticky),u=M(e,n))}function l(n){var l;if(null==(l=i?go(e.cm,u,t,r):ho(u,t,r))){if(n||!o())return!1;t=po(i,e.cm,u,t.line,r)}else t=l;return!0}var s=t,a=r,u=M(e,t.line);if("char"==n)l();else if("column"==n)l(!0);else if("word"==n||"group"==n)for(var c=null,f="group"==n,h=e.cm&&e.cm.getHelper(t,"wordChars"),d=!0;!(r<0)||l(!d);d=!1){var p=u.text.charAt(t.ch)||"\n",g=x(p,h)?"w":f&&"\n"==p?"n":!f||/\s/.test(p)?null:"p";if(!f||d||g||(g="s"),c&&c!=g){r<0&&(r=1,l(),t.sticky="after");break}if(g&&(c=g),r>0&&!l(!d))break}var v=ki(e,t,s,a,!0);return I(s,v)&&(v.hitSide=!0),v}function rl(e,t,r,n){var i,o=e.doc,l=t.left;if("page"==n){var s=Math.min(e.display.wrapper.clientHeight,window.innerHeight||document.documentElement.clientHeight),a=Math.max(s-.5*mr(e.display),3);i=(r>0?t.bottom:t.top)+r*a}else"line"==n&&(i=r>0?t.bottom+3:t.top-3);for(var u;(u=cr(e,l,i)).outside;){if(r<0?i<=0:i>=o.height){u.hitSide=!0;break}i+=5*r}return u}function nl(e,t){var r=jt(e,t.line);if(!r||r.hidden)return null;var n=M(e.doc,t.line),i=Ut(r,n,t.line),o=Se(n,e.doc.direction),l="left";o&&(l=Ce(o,t.ch)%2?"right":"left");var s=_t(i.map,t.ch,l);return s.offset="right"==s.collapse?s.end:s.start,s}function il(e){for(var t=e;t;t=t.parentNode)if(/CodeMirror-gutter-wrapper/.test(t.className))return!0;return!1}function ol(e,t){return t&&(e.bad=!0),e}function ll(e,t,r,n,i){function o(e){return function(t){return t.id==e}}function l(){c&&(u+=f,c=!1)}function s(e){e&&(l(),u+=e)}function a(t){if(1==t.nodeType){var r=t.getAttribute("cm-text");if(null!=r)return void s(r||t.textContent.replace(/\u200b/g,""));var u,h=t.getAttribute("cm-marker");if(h){var d=e.findMarks(E(n,0),E(i+1,0),o(+h));return void(d.length&&(u=d[0].find(0))&&s(N(e.doc,u.from,u.to).join(f)))}if("false"==t.getAttribute("contenteditable"))return;var p=/^(pre|div|p)$/i.test(t.nodeName);p&&l();for(var g=0;g<t.childNodes.length;g++)a(t.childNodes[g]);p&&(c=!0)}else 3==t.nodeType&&s(t.nodeValue)}for(var u="",c=!1,f=e.doc.lineSeparator();a(t),t!=r;)t=t.nextSibling;return u}function sl(e,t,r){var n;if(t==e.display.lineDiv){if(!(n=e.display.lineDiv.childNodes[r]))return ol(e.clipPos(E(e.display.viewTo-1)),!0);t=null,r=0}else for(n=t;;n=n.parentNode){if(!n||n==e.display.lineDiv)return null;if(n.parentNode&&n.parentNode==e.display.lineDiv)break}for(var i=0;i<e.display.view.length;i++){var o=e.display.view[i];if(o.node==n)return al(o,t,r)}}function al(e,t,r){function n(t,r,n){for(var i=-1;i<(f?f.length:0);i++)for(var o=i<0?c.map:f[i],l=0;l<o.length;l+=3){var s=o[l+2];if(s==t||s==r){var a=W(i<0?e.line:e.rest[i]),u=o[l]+n;return(n<0||s!=t)&&(u=o[l+(n?1:0)]),E(a,u)}}}var i=e.text.firstChild,l=!1;if(!t||!o(i,t))return ol(E(W(e.line),0),!0);if(t==i&&(l=!0,t=i.childNodes[r],r=0,!t)){var s=e.rest?g(e.rest):e.line;return ol(E(W(s),s.text.length),l)}var a=3==t.nodeType?t:null,u=t;for(a||1!=t.childNodes.length||3!=t.firstChild.nodeType||(a=t.firstChild,r&&(r=a.nodeValue.length));u.parentNode!=i;)u=u.parentNode;var c=e.measure,f=c.maps,h=n(a,u,r);if(h)return ol(h,l);for(var d=u.nextSibling,p=a?a.nodeValue.length-r:0;d;d=d.nextSibling){if(h=n(d,d.firstChild,0))return ol(E(h.line,h.ch-p),l);p+=d.textContent.length}for(var v=u.previousSibling,m=r;v;v=v.previousSibling){if(h=n(v,v.firstChild,-1))return ol(E(h.line,h.ch+m),l);m+=v.textContent.length}}var ul=navigator.userAgent,cl=navigator.platform,fl=/gecko\/\d/i.test(ul),hl=/MSIE \d/.test(ul),dl=/Trident\/(?:[7-9]|\d{2,})\..*rv:(\d+)/.exec(ul),pl=/Edge\/(\d+)/.exec(ul),gl=hl||dl||pl,vl=gl&&(hl?document.documentMode||6:+(pl||dl)[1]),ml=!pl&&/WebKit\//.test(ul),yl=ml&&/Qt\/\d+\.\d+/.test(ul),bl=!pl&&/Chrome\//.test(ul),wl=/Opera\//.test(ul),xl=/Apple Computer/.test(navigator.vendor),Cl=/Mac OS X 1\d\D([8-9]|\d\d)\D/.test(ul),Sl=/PhantomJS/.test(ul),Ll=!pl&&/AppleWebKit/.test(ul)&&/Mobile\/\w+/.test(ul),kl=/Android/.test(ul),Tl=Ll||kl||/webOS|BlackBerry|Opera Mini|Opera Mobi|IEMobile/i.test(ul),Ml=Ll||/Mac/.test(cl),Nl=/\bCrOS\b/.test(ul),Ol=/win/i.test(cl),Al=wl&&ul.match(/Version\/(\d*\.\d*)/);Al&&(Al=Number(Al[1])),Al&&Al>=15&&(wl=!1,ml=!0);var Wl,Dl=Ml&&(yl||wl&&(null==Al||Al<12.11)),Hl=fl||gl&&vl>=9,Fl=function(t,r){var n=t.className,i=e(r).exec(n);if(i){var o=n.slice(i.index+i[0].length);t.className=n.slice(0,i.index)+(o?i[1]+o:"")}};Wl=document.createRange?function(e,t,r,n){var i=document.createRange();return i.setEnd(n||e,r),i.setStart(e,t),i}:function(e,t,r){var n=document.body.createTextRange();try{n.moveToElementText(e.parentNode)}catch(e){return n}return n.collapse(!0),n.moveEnd("character",r),n.moveStart("character",t),n};var El=function(e){e.select()};Ll?El=function(e){e.selectionStart=0,e.selectionEnd=e.value.length}:gl&&(El=function(e){try{e.select()}catch(e){}});var Pl=function(){this.id=null};Pl.prototype.set=function(e,t){clearTimeout(this.id),this.id=setTimeout(t,e)};var Il,zl,Rl=30,Bl={toString:function(){return"CodeMirror.Pass"}},Gl={scroll:!1},Ul={origin:"*mouse"},Vl={origin:"+move"},Kl=[""],jl=/[\u00df\u0587\u0590-\u05f4\u0600-\u06ff\u3040-\u309f\u30a0-\u30ff\u3400-\u4db5\u4e00-\u9fcc\uac00-\ud7af]/,Xl=/[\u0300-\u036f\u0483-\u0489\u0591-\u05bd\u05bf\u05c1\u05c2\u05c4\u05c5\u05c7\u0610-\u061a\u064b-\u065e\u0670\u06d6-\u06dc\u06de-\u06e4\u06e7\u06e8\u06ea-\u06ed\u0711\u0730-\u074a\u07a6-\u07b0\u07eb-\u07f3\u0816-\u0819\u081b-\u0823\u0825-\u0827\u0829-\u082d\u0900-\u0902\u093c\u0941-\u0948\u094d\u0951-\u0955\u0962\u0963\u0981\u09bc\u09be\u09c1-\u09c4\u09cd\u09d7\u09e2\u09e3\u0a01\u0a02\u0a3c\u0a41\u0a42\u0a47\u0a48\u0a4b-\u0a4d\u0a51\u0a70\u0a71\u0a75\u0a81\u0a82\u0abc\u0ac1-\u0ac5\u0ac7\u0ac8\u0acd\u0ae2\u0ae3\u0b01\u0b3c\u0b3e\u0b3f\u0b41-\u0b44\u0b4d\u0b56\u0b57\u0b62\u0b63\u0b82\u0bbe\u0bc0\u0bcd\u0bd7\u0c3e-\u0c40\u0c46-\u0c48\u0c4a-\u0c4d\u0c55\u0c56\u0c62\u0c63\u0cbc\u0cbf\u0cc2\u0cc6\u0ccc\u0ccd\u0cd5\u0cd6\u0ce2\u0ce3\u0d3e\u0d41-\u0d44\u0d4d\u0d57\u0d62\u0d63\u0dca\u0dcf\u0dd2-\u0dd4\u0dd6\u0ddf\u0e31\u0e34-\u0e3a\u0e47-\u0e4e\u0eb1\u0eb4-\u0eb9\u0ebb\u0ebc\u0ec8-\u0ecd\u0f18\u0f19\u0f35\u0f37\u0f39\u0f71-\u0f7e\u0f80-\u0f84\u0f86\u0f87\u0f90-\u0f97\u0f99-\u0fbc\u0fc6\u102d-\u1030\u1032-\u1037\u1039\u103a\u103d\u103e\u1058\u1059\u105e-\u1060\u1071-\u1074\u1082\u1085\u1086\u108d\u109d\u135f\u1712-\u1714\u1732-\u1734\u1752\u1753\u1772\u1773\u17b7-\u17bd\u17c6\u17c9-\u17d3\u17dd\u180b-\u180d\u18a9\u1920-\u1922\u1927\u1928\u1932\u1939-\u193b\u1a17\u1a18\u1a56\u1a58-\u1a5e\u1a60\u1a62\u1a65-\u1a6c\u1a73-\u1a7c\u1a7f\u1b00-\u1b03\u1b34\u1b36-\u1b3a\u1b3c\u1b42\u1b6b-\u1b73\u1b80\u1b81\u1ba2-\u1ba5\u1ba8\u1ba9\u1c2c-\u1c33\u1c36\u1c37\u1cd0-\u1cd2\u1cd4-\u1ce0\u1ce2-\u1ce8\u1ced\u1dc0-\u1de6\u1dfd-\u1dff\u200c\u200d\u20d0-\u20f0\u2cef-\u2cf1\u2de0-\u2dff\u302a-\u302f\u3099\u309a\ua66f-\ua672\ua67c\ua67d\ua6f0\ua6f1\ua802\ua806\ua80b\ua825\ua826\ua8c4\ua8e0-\ua8f1\ua926-\ua92d\ua947-\ua951\ua980-\ua982\ua9b3\ua9b6-\ua9b9\ua9bc\uaa29-\uaa2e\uaa31\uaa32\uaa35\uaa36\uaa43\uaa4c\uaab0\uaab2-\uaab4\uaab7\uaab8\uaabe\uaabf\uaac1\uabe5\uabe8\uabed\udc00-\udfff\ufb1e\ufe00-\ufe0f\ufe20-\ufe26\uff9e\uff9f]/,Yl=!1,_l=!1,$l=null,ql=function(){function e(e){return e<=247?r.charAt(e):1424<=e&&e<=1524?"R":1536<=e&&e<=1785?n.charAt(e-1536):1774<=e&&e<=2220?"r":8192<=e&&e<=8203?"w":8204==e?"b":"L"}function t(e,t,r){this.level=e,this.from=t,this.to=r}var r="bbbbbbbbbtstwsbbbbbbbbbbbbbbssstwNN%%%NNNNNN,N,N1111111111NNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNbbbbbbsbbbbbbbbbbbbbbbbbbbbbbbbbb,N%%%%NNNNLNNNNN%%11NLNNN1LNNNNNLLLLLLLLLLLLLLLLLLLLLLLNLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLN",n="nnnnnnNNr%%r,rNNmmmmmmmmmmmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmmmmmmmmmmmmmmmnnnnnnnnnn%nnrrrmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmnNmmmmmmrrmmNmmmmrr1111111111",i=/[\u0590-\u05f4\u0600-\u06ff\u0700-\u08ac]/,o=/[stwN]/,l=/[LRr]/,s=/[Lb1n]/,a=/[1n]/;return function(r,n){var u="ltr"==n?"L":"R";if(0==r.length||"ltr"==n&&!i.test(r))return!1;for(var c=r.length,f=[],h=0;h<c;++h)f.push(e(r.charCodeAt(h)));for(var d=0,p=u;d<c;++d){var v=f[d];"m"==v?f[d]=p:p=v}for(var m=0,y=u;m<c;++m){var b=f[m];"1"==b&&"r"==y?f[m]="n":l.test(b)&&(y=b,"r"==b&&(f[m]="R"))}for(var w=1,x=f[0];w<c-1;++w){var C=f[w];"+"==C&&"1"==x&&"1"==f[w+1]?f[w]="1":","!=C||x!=f[w+1]||"1"!=x&&"n"!=x||(f[w]=x),x=C}for(var S=0;S<c;++S){var L=f[S];if(","==L)f[S]="N";else if("%"==L){var k=void 0;for(k=S+1;k<c&&"%"==f[k];++k);for(var T=S&&"!"==f[S-1]||k<c&&"1"==f[k]?"1":"N",M=S;M<k;++M)f[M]=T;S=k-1}}for(var N=0,O=u;N<c;++N){var A=f[N];"L"==O&&"1"==A?f[N]="L":l.test(A)&&(O=A)}for(var W=0;W<c;++W)if(o.test(f[W])){var D=void 0;for(D=W+1;D<c&&o.test(f[D]);++D);for(var H="L"==(W?f[W-1]:u),F=H==("L"==(D<c?f[D]:u))?H?"L":"R":u,E=W;E<D;++E)f[E]=F;W=D-1}for(var P,I=[],z=0;z<c;)if(s.test(f[z])){var R=z;for(++z;z<c&&s.test(f[z]);++z);I.push(new t(0,R,z))}else{var B=z,G=I.length;for(++z;z<c&&"L"!=f[z];++z);for(var U=B;U<z;)if(a.test(f[U])){B<U&&I.splice(G,0,new t(1,B,U));var V=U;for(++U;U<z&&a.test(f[U]);++U);I.splice(G,0,new t(2,V,U)),B=U}else++U;B<z&&I.splice(G,0,new t(1,B,z))}return 1==I[0].level&&(P=r.match(/^\s+/))&&(I[0].from=P[0].length,I.unshift(new t(0,0,P[0].length))),1==g(I).level&&(P=r.match(/\s+$/))&&(g(I).to-=P[0].length,I.push(new t(0,c-P[0].length,c))),"rtl"==n?I.reverse():I}}(),Zl=[],Ql=function(e,t,r){if(e.addEventListener)e.addEventListener(t,r,!1);else if(e.attachEvent)e.attachEvent("on"+t,r);else{var n=e._handlers||(e._handlers={});n[t]=(n[t]||Zl).concat(r)}},Jl=function(){if(gl&&vl<9)return!1;var e=n("div");return"draggable"in e||"dragDrop"in e}(),es=3!="\n\nb".split(/\n/).length?function(e){for(var t=0,r=[],n=e.length;t<=n;){var i=e.indexOf("\n",t);-1==i&&(i=e.length);var o=e.slice(t,"\r"==e.charAt(i-1)?i-1:i),l=o.indexOf("\r");-1!=l?(r.push(o.slice(0,l)),t+=l+1):(r.push(o),t=i+1)}return r}:function(e){return e.split(/\r\n?|\n/)},ts=window.getSelection?function(e){try{return e.selectionStart!=e.selectionEnd}catch(e){return!1}}:function(e){var t;try{t=e.ownerDocument.selection.createRange()}catch(e){}return!(!t||t.parentElement()!=e)&&0!=t.compareEndPoints("StartToEnd",t)},rs=function(){var e=n("div");return"oncopy"in e||(e.setAttribute("oncopy","return;"),"function"==typeof e.oncopy)}(),ns=null,is={},os={},ls={},ss=function(e,t,r){this.pos=this.start=0,this.string=e,this.tabSize=t||8,this.lastColumnPos=this.lastColumnValue=0,this.lineStart=0,this.lineOracle=r};ss.prototype.eol=function(){return this.pos>=this.string.length},ss.prototype.sol=function(){return this.pos==this.lineStart},ss.prototype.peek=function(){return this.string.charAt(this.pos)||void 0},ss.prototype.next=function(){if(this.pos<this.string.length)return this.string.charAt(this.pos++)},ss.prototype.eat=function(e){var t=this.string.charAt(this.pos);if("string"==typeof e?t==e:t&&(e.test?e.test(t):e(t)))return++this.pos,t},ss.prototype.eatWhile=function(e){for(var t=this.pos;this.eat(e););return this.pos>t},ss.prototype.eatSpace=function(){for(var e=this,t=this.pos;/[\s\u00a0]/.test(this.string.charAt(this.pos));)++e.pos;return this.pos>t},ss.prototype.skipToEnd=function(){this.pos=this.string.length},ss.prototype.skipTo=function(e){var t=this.string.indexOf(e,this.pos);if(t>-1)return this.pos=t,!0},ss.prototype.backUp=function(e){this.pos-=e},ss.prototype.column=function(){return this.lastColumnPos<this.start&&(this.lastColumnValue=f(this.string,this.start,this.tabSize,this.lastColumnPos,this.lastColumnValue),this.lastColumnPos=this.start),this.lastColumnValue-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.indentation=function(){return f(this.string,null,this.tabSize)-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.match=function(e,t,r){if("string"!=typeof e){var n=this.string.slice(this.pos).match(e);return n&&n.index>0?null:(n&&!1!==t&&(this.pos+=n[0].length),n)}var i=function(e){return r?e.toLowerCase():e};if(i(this.string.substr(this.pos,e.length))==i(e))return!1!==t&&(this.pos+=e.length),!0},ss.prototype.current=function(){return this.string.slice(this.start,this.pos)},ss.prototype.hideFirstChars=function(e,t){this.lineStart+=e;try{return t()}finally{this.lineStart-=e}},ss.prototype.lookAhead=function(e){var t=this.lineOracle;return t&&t.lookAhead(e)};var as=function(e,t){this.state=e,this.lookAhead=t},us=function(e,t,r,n){this.state=t,this.doc=e,this.line=r,this.maxLookAhead=n||0};us.prototype.lookAhead=function(e){var t=this.doc.getLine(this.line+e);return null!=t&&e>this.maxLookAhead&&(this.maxLookAhead=e),t},us.prototype.nextLine=function(){this.line++,this.maxLookAhead>0&&this.maxLookAhead--},us.fromSaved=function(e,t,r){return t instanceof as?new us(e,Ke(e.mode,t.state),r,t.lookAhead):new us(e,Ke(e.mode,t),r)},us.prototype.save=function(e){var t=!1!==e?Ke(this.doc.mode,this.state):this.state;return this.maxLookAhead>0?new as(t,this.maxLookAhead):t};var cs=function(e,t,r){this.start=e.start,this.end=e.pos,this.string=e.current(),this.type=t||null,this.state=r},fs=function(e,t,r){this.text=e,ne(this,t),this.height=r?r(this):1};fs.prototype.lineNo=function(){return W(this)},Ae(fs);var hs,ds={},ps={},gs=null,vs=null,ms={left:0,right:0,top:0,bottom:0},ys=function(e,t,r){this.cm=r;var i=this.vert=n("div",[n("div",null,null,"min-width: 1px")],"CodeMirror-vscrollbar"),o=this.horiz=n("div",[n("div",null,null,"height: 100%; min-height: 1px")],"CodeMirror-hscrollbar");e(i),e(o),Ql(i,"scroll",function(){i.clientHeight&&t(i.scrollTop,"vertical")}),Ql(o,"scroll",function(){o.clientWidth&&t(o.scrollLeft,"horizontal")}),this.checkedZeroWidth=!1,gl&&vl<8&&(this.horiz.style.minHeight=this.vert.style.minWidth="18px")};ys.prototype.update=function(e){var t=e.scrollWidth>e.clientWidth+1,r=e.scrollHeight>e.clientHeight+1,n=e.nativeBarWidth;if(r){this.vert.style.display="block",this.vert.style.bottom=t?n+"px":"0";var i=e.viewHeight-(t?n:0);this.vert.firstChild.style.height=Math.max(0,e.scrollHeight-e.clientHeight+i)+"px"}else this.vert.style.display="",this.vert.firstChild.style.height="0";if(t){this.horiz.style.display="block",this.horiz.style.right=r?n+"px":"0",this.horiz.style.left=e.barLeft+"px";var o=e.viewWidth-e.barLeft-(r?n:0);this.horiz.firstChild.style.width=Math.max(0,e.scrollWidth-e.clientWidth+o)+"px"}else this.horiz.style.display="",this.horiz.firstChild.style.width="0";return!this.checkedZeroWidth&&e.clientHeight>0&&(0==n&&this.zeroWidthHack(),this.checkedZeroWidth=!0),{right:r?n:0,bottom:t?n:0}},ys.prototype.setScrollLeft=function(e){this.horiz.scrollLeft!=e&&(this.horiz.scrollLeft=e),this.disableHoriz&&this.enableZeroWidthBar(this.horiz,this.disableHoriz,"horiz")},ys.prototype.setScrollTop=function(e){this.vert.scrollTop!=e&&(this.vert.scrollTop=e),this.disableVert&&this.enableZeroWidthBar(this.vert,this.disableVert,"vert")},ys.prototype.zeroWidthHack=function(){var e=Ml&&!Cl?"12px":"18px";this.horiz.style.height=this.vert.style.width=e,this.horiz.style.pointerEvents=this.vert.style.pointerEvents="none",this.disableHoriz=new Pl,this.disableVert=new Pl},ys.prototype.enableZeroWidthBar=function(e,t,r){function n(){var i=e.getBoundingClientRect();("vert"==r?document.elementFromPoint(i.right-1,(i.top+i.bottom)/2):document.elementFromPoint((i.right+i.left)/2,i.bottom-1))!=e?e.style.pointerEvents="none":t.set(1e3,n)}e.style.pointerEvents="auto",t.set(1e3,n)},ys.prototype.clear=function(){var e=this.horiz.parentNode;e.removeChild(this.horiz),e.removeChild(this.vert)};var bs=function(){};bs.prototype.update=function(){return{bottom:0,right:0}},bs.prototype.setScrollLeft=function(){},bs.prototype.setScrollTop=function(){},bs.prototype.clear=function(){};var ws={native:ys,null:bs},xs=0,Cs=function(e,t,r){var n=e.display;this.viewport=t,this.visible=Ir(n,e.doc,t),this.editorIsHidden=!n.wrapper.offsetWidth,this.wrapperHeight=n.wrapper.clientHeight,this.wrapperWidth=n.wrapper.clientWidth,this.oldDisplayWidth=Rt(e),this.force=r,this.dims=br(e),this.events=[]};Cs.prototype.signal=function(e,t){Oe(e,t)&&this.events.push(arguments)},Cs.prototype.finish=function(){for(var e=this,t=0;t<this.events.length;t++)Te.apply(null,e.events[t])};var Ss=0,Ls=null;gl?Ls=-.53:fl?Ls=15:bl?Ls=-.7:xl&&(Ls=-1/3);var ks=function(e,t){this.ranges=e,this.primIndex=t};ks.prototype.primary=function(){return this.ranges[this.primIndex]},ks.prototype.equals=function(e){var t=this;if(e==this)return!0;if(e.primIndex!=this.primIndex||e.ranges.length!=this.ranges.length)return!1;for(var r=0;r<this.ranges.length;r++){var n=t.ranges[r],i=e.ranges[r];if(!I(n.anchor,i.anchor)||!I(n.head,i.head))return!1}return!0},ks.prototype.deepCopy=function(){for(var e=this,t=[],r=0;r<this.ranges.length;r++)t[r]=new Ts(z(e.ranges[r].anchor),z(e.ranges[r].head));return new ks(t,this.primIndex)},ks.prototype.somethingSelected=function(){for(var e=this,t=0;t<this.ranges.length;t++)if(!e.ranges[t].empty())return!0;return!1},ks.prototype.contains=function(e,t){var r=this;t||(t=e);for(var n=0;n<this.ranges.length;n++){var i=r.ranges[n];if(P(t,i.from())>=0&&P(e,i.to())<=0)return n}return-1};var Ts=function(e,t){this.anchor=e,this.head=t};Ts.prototype.from=function(){return B(this.anchor,this.head)},Ts.prototype.to=function(){return R(this.anchor,this.head)},Ts.prototype.empty=function(){return this.head.line==this.anchor.line&&this.head.ch==this.anchor.ch},Bi.prototype={chunkSize:function(){return this.lines.length},removeInner:function(e,t){for(var r=this,n=e,i=e+t;n<i;++n){var o=r.lines[n];r.height-=o.height,ot(o),bt(o,"delete")}this.lines.splice(e,t)},collapse:function(e){e.push.apply(e,this.lines)},insertInner:function(e,t,r){var n=this;this.height+=r,this.lines=this.lines.slice(0,e).concat(t).concat(this.lines.slice(e));for(var i=0;i<t.length;++i)t[i].parent=n},iterN:function(e,t,r){for(var n=this,i=e+t;e<i;++e)if(r(n.lines[e]))return!0}},Gi.prototype={chunkSize:function(){return this.size},removeInner:function(e,t){var r=this;this.size-=t;for(var n=0;n<this.children.length;++n){var i=r.children[n],o=i.chunkSize();if(e<o){var l=Math.min(t,o-e),s=i.height;if(i.removeInner(e,l),r.height-=s-i.height,o==l&&(r.children.splice(n--,1),i.parent=null),0==(t-=l))break;e=0}else e-=o}if(this.size-t<25&&(this.children.length>1||!(this.children[0]instanceof Bi))){var a=[];this.collapse(a),this.children=[new Bi(a)],this.children[0].parent=this}},collapse:function(e){for(var t=this,r=0;r<this.children.length;++r)t.children[r].collapse(e)},insertInner:function(e,t,r){var n=this;this.size+=t.length,this.height+=r;for(var i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<=l){if(o.insertInner(e,t,r),o.lines&&o.lines.length>50){for(var s=o.lines.length%25+25,a=s;a<o.lines.length;){var u=new Bi(o.lines.slice(a,a+=25));o.height-=u.height,n.children.splice(++i,0,u),u.parent=n}o.lines=o.lines.slice(0,s),n.maybeSpill()}break}e-=l}},maybeSpill:function(){if(!(this.children.length<=10)){var e=this;do{var t=new Gi(e.children.splice(e.children.length-5,5));if(e.parent){e.size-=t.size,e.height-=t.height;var r=h(e.parent.children,e);e.parent.children.splice(r+1,0,t)}else{var n=new Gi(e.children);n.parent=e,e.children=[n,t],e=n}t.parent=e.parent}while(e.children.length>10);e.parent.maybeSpill()}},iterN:function(e,t,r){for(var n=this,i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<l){var s=Math.min(t,l-e);if(o.iterN(e,s,r))return!0;if(0==(t-=s))break;e=0}else e-=l}}};var Ms=function(e,t,r){var n=this;if(r)for(var i in r)r.hasOwnProperty(i)&&(n[i]=r[i]);this.doc=e,this.node=t};Ms.prototype.clear=function(){var e=this,t=this.doc.cm,r=this.line.widgets,n=this.line,i=W(n);if(null!=i&&r){for(var o=0;o<r.length;++o)r[o]==e&&r.splice(o--,1);r.length||(n.widgets=null);var l=Ht(this);A(n,Math.max(0,n.height-l)),t&&(hn(t,function(){Ui(t,n,-l),mn(t,i,"widget")}),bt(t,"lineWidgetCleared",t,this,i))}},Ms.prototype.changed=function(){var e=this,t=this.height,r=this.doc.cm,n=this.line;this.height=null;var i=Ht(this)-t;i&&(A(n,n.height+i),r&&hn(r,function(){r.curOp.forceUpdate=!0,Ui(r,n,i),bt(r,"lineWidgetChanged",r,e,W(n))}))},Ae(Ms);var Ns=0,Os=function(e,t){this.lines=[],this.type=t,this.doc=e,this.id=++Ns};Os.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){var t=this.doc.cm,r=t&&!t.curOp;if(r&&nn(t),Oe(this,"clear")){var n=this.find();n&&bt(this,"clear",n.from,n.to)}for(var i=null,o=null,l=0;l<this.lines.length;++l){var s=e.lines[l],a=_(s.markedSpans,e);t&&!e.collapsed?mn(t,W(s),"text"):t&&(null!=a.to&&(o=W(s)),null!=a.from&&(i=W(s))),s.markedSpans=$(s.markedSpans,a),null==a.from&&e.collapsed&&!ve(e.doc,s)&&t&&A(s,mr(t.display))}if(t&&this.collapsed&&!t.options.lineWrapping)for(var u=0;u<this.lines.length;++u){var c=fe(e.lines[u]),f=be(c);f>t.display.maxLineLength&&(t.display.maxLine=c,t.display.maxLineLength=f,t.display.maxLineChanged=!0)}null!=i&&t&&this.collapsed&&vn(t,i,o+1),this.lines.length=0,this.explicitlyCleared=!0,this.atomic&&this.doc.cantEdit&&(this.doc.cantEdit=!1,t&&Ci(t.doc)),t&&bt(t,"markerCleared",t,this,i,o),r&&on(t),this.parent&&this.parent.clear()}},Os.prototype.find=function(e,t){var r=this;null==e&&"bookmark"==this.type&&(e=1);for(var n,i,o=0;o<this.lines.length;++o){var l=r.lines[o],s=_(l.markedSpans,r);if(null!=s.from&&(n=E(t?l:W(l),s.from),-1==e))return n;if(null!=s.to&&(i=E(t?l:W(l),s.to),1==e))return i}return n&&{from:n,to:i}},Os.prototype.changed=function(){var e=this,t=this.find(-1,!0),r=this,n=this.doc.cm;t&&n&&hn(n,function(){var i=t.line,o=W(t.line),l=jt(n,o);if(l&&(Qt(l),n.curOp.selectionChanged=n.curOp.forceUpdate=!0),n.curOp.updateMaxLine=!0,!ve(r.doc,i)&&null!=r.height){var s=r.height;r.height=null;var a=Ht(r)-s;a&&A(i,i.height+a)}bt(n,"markerChanged",n,e)})},Os.prototype.attachLine=function(e){if(!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;t.maybeHiddenMarkers&&-1!=h(t.maybeHiddenMarkers,this)||(t.maybeUnhiddenMarkers||(t.maybeUnhiddenMarkers=[])).push(this)}this.lines.push(e)},Os.prototype.detachLine=function(e){if(this.lines.splice(h(this.lines,e),1),!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;(t.maybeHiddenMarkers||(t.maybeHiddenMarkers=[])).push(this)}},Ae(Os);var As=function(e,t){var r=this;this.markers=e,this.primary=t;for(var n=0;n<e.length;++n)e[n].parent=r};As.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){this.explicitlyCleared=!0;for(var t=0;t<this.markers.length;++t)e.markers[t].clear();bt(this,"clear")}},As.prototype.find=function(e,t){return this.primary.find(e,t)},Ae(As);var Ws=0,Ds=function(e,t,r,n,i){if(!(this instanceof Ds))return new Ds(e,t,r,n,i);null==r&&(r=0),Gi.call(this,[new Bi([new fs("",null)])]),this.first=r,this.scrollTop=this.scrollLeft=0,this.cantEdit=!1,this.cleanGeneration=1,this.modeFrontier=this.highlightFrontier=r;var o=E(r,0);this.sel=Rn(o),this.history=new Jn(null),this.id=++Ws,this.modeOption=t,this.lineSep=n,this.direction="rtl"==i?"rtl":"ltr",this.extend=!1,"string"==typeof e&&(e=this.splitLines(e)),_n(this,{from:o,to:o,text:e}),bi(this,Rn(o),Gl)};Ds.prototype=b(Gi.prototype,{constructor:Ds,iter:function(e,t,r){r?this.iterN(e-this.first,t-e,r):this.iterN(this.first,this.first+this.size,e)},insert:function(e,t){for(var r=0,n=0;n<t.length;++n)r+=t[n].height;this.insertInner(e-this.first,t,r)},remove:function(e,t){this.removeInner(e-this.first,t)},getValue:function(e){var t=O(this,this.first,this.first+this.size);return!1===e?t:t.join(e||this.lineSeparator())},setValue:gn(function(e){var t=E(this.first,0),r=this.first+this.size-1;Oi(this,{from:t,to:E(r,M(this,r).text.length),text:this.splitLines(e),origin:"setValue",full:!0},!0),this.cm&&Xr(this.cm,0,0),bi(this,Rn(t),Gl)}),replaceRange:function(e,t,r,n){Ei(this,e,t=U(this,t),r=r?U(this,r):t,n)},getRange:function(e,t,r){var n=N(this,U(this,e),U(this,t));return!1===r?n:n.join(r||this.lineSeparator())},getLine:function(e){var t=this.getLineHandle(e);return t&&t.text},getLineHandle:function(e){if(H(this,e))return M(this,e)},getLineNumber:function(e){return W(e)},getLineHandleVisualStart:function(e){return"number"==typeof e&&(e=M(this,e)),fe(e)},lineCount:function(){return this.size},firstLine:function(){return this.first},lastLine:function(){return this.first+this.size-1},clipPos:function(e){return U(this,e)},getCursor:function(e){var t=this.sel.primary();return null==e||"head"==e?t.head:"anchor"==e?t.anchor:"end"==e||"to"==e||!1===e?t.to():t.from()},listSelections:function(){return this.sel.ranges},somethingSelected:function(){return this.sel.somethingSelected()},setCursor:gn(function(e,t,r){vi(this,U(this,"number"==typeof e?E(e,t||0):e),null,r)}),setSelection:gn(function(e,t,r){vi(this,U(this,e),U(this,t||e),r)}),extendSelection:gn(function(e,t,r){di(this,U(this,e),t&&U(this,t),r)}),extendSelections:gn(function(e,t){pi(this,K(this,e),t)}),extendSelectionsBy:gn(function(e,t){pi(this,K(this,v(this.sel.ranges,e)),t)}),setSelections:gn(function(e,t,r){var n=this;if(e.length){for(var i=[],o=0;o<e.length;o++)i[o]=new Ts(U(n,e[o].anchor),U(n,e[o].head));null==t&&(t=Math.min(e.length-1,this.sel.primIndex)),bi(this,zn(i,t),r)}}),addSelection:gn(function(e,t,r){var n=this.sel.ranges.slice(0);n.push(new Ts(U(this,e),U(this,t||e))),bi(this,zn(n,n.length-1),r)}),getSelection:function(e){for(var t,r=this,n=this.sel.ranges,i=0;i<n.length;i++){var o=N(r,n[i].from(),n[i].to());t=t?t.concat(o):o}return!1===e?t:t.join(e||this.lineSeparator())},getSelections:function(e){for(var t=this,r=[],n=this.sel.ranges,i=0;i<n.length;i++){var o=N(t,n[i].from(),n[i].to());!1!==e&&(o=o.join(e||t.lineSeparator())),r[i]=o}return r},replaceSelection:function(e,t,r){for(var n=[],i=0;i<this.sel.ranges.length;i++)n[i]=e;this.replaceSelections(n,t,r||"+input")},replaceSelections:gn(function(e,t,r){for(var n=this,i=[],o=this.sel,l=0;l<o.ranges.length;l++){var s=o.ranges[l];i[l]={from:s.from(),to:s.to(),text:n.splitLines(e[l]),origin:r}}for(var a=t&&"end"!=t&&Kn(this,i,t),u=i.length-1;u>=0;u--)Oi(n,i[u]);a?yi(this,a):this.cm&&jr(this.cm)}),undo:gn(function(){Wi(this,"undo")}),redo:gn(function(){Wi(this,"redo")}),undoSelection:gn(function(){Wi(this,"undo",!0)}),redoSelection:gn(function(){Wi(this,"redo",!0)}),setExtending:function(e){this.extend=e},getExtending:function(){return this.extend},historySize:function(){for(var e=this.history,t=0,r=0,n=0;n<e.done.length;n++)e.done[n].ranges||++t;for(var i=0;i<e.undone.length;i++)e.undone[i].ranges||++r;return{undo:t,redo:r}},clearHistory:function(){this.history=new Jn(this.history.maxGeneration)},markClean:function(){this.cleanGeneration=this.changeGeneration(!0)},changeGeneration:function(e){return e&&(this.history.lastOp=this.history.lastSelOp=this.history.lastOrigin=null),this.history.generation},isClean:function(e){return this.history.generation==(e||this.cleanGeneration)},getHistory:function(){return{done:fi(this.history.done),undone:fi(this.history.undone)}},setHistory:function(e){var t=this.history=new Jn(this.history.maxGeneration);t.done=fi(e.done.slice(0),null,!0),t.undone=fi(e.undone.slice(0),null,!0)},setGutterMarker:gn(function(e,t,r){return Ri(this,e,"gutter",function(e){var n=e.gutterMarkers||(e.gutterMarkers={});return n[t]=r,!r&&C(n)&&(e.gutterMarkers=null),!0})}),clearGutter:gn(function(e){var t=this;this.iter(function(r){r.gutterMarkers&&r.gutterMarkers[e]&&Ri(t,r,"gutter",function(){return r.gutterMarkers[e]=null,C(r.gutterMarkers)&&(r.gutterMarkers=null),!0})})}),lineInfo:function(e){var t;if("number"==typeof e){if(!H(this,e))return null;if(t=e,!(e=M(this,e)))return null}else if(null==(t=W(e)))return null;return{line:t,handle:e,text:e.text,gutterMarkers:e.gutterMarkers,textClass:e.textClass,bgClass:e.bgClass,wrapClass:e.wrapClass,widgets:e.widgets}},addLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass";if(t[i]){if(e(n).test(t[i]))return!1;t[i]+=" "+n}else t[i]=n;return!0})}),removeLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass",o=t[i];if(!o)return!1;if(null==n)t[i]=null;else{var l=o.match(e(n));if(!l)return!1;var s=l.index+l[0].length;t[i]=o.slice(0,l.index)+(l.index&&s!=o.length?" ":"")+o.slice(s)||null}return!0})}),addLineWidget:gn(function(e,t,r){return Vi(this,e,t,r)}),removeLineWidget:function(e){e.clear()},markText:function(e,t,r){return Ki(this,U(this,e),U(this,t),r,r&&r.type||"range")},setBookmark:function(e,t){var r={replacedWith:t&&(null==t.nodeType?t.widget:t),insertLeft:t&&t.insertLeft,clearWhenEmpty:!1,shared:t&&t.shared,handleMouseEvents:t&&t.handleMouseEvents};return e=U(this,e),Ki(this,e,e,r,"bookmark")},findMarksAt:function(e){var t=[],r=M(this,(e=U(this,e)).line).markedSpans;if(r)for(var n=0;n<r.length;++n){var i=r[n];(null==i.from||i.from<=e.ch)&&(null==i.to||i.to>=e.ch)&&t.push(i.marker.parent||i.marker)}return t},findMarks:function(e,t,r){e=U(this,e),t=U(this,t);var n=[],i=e.line;return this.iter(e.line,t.line+1,function(o){var l=o.markedSpans;if(l)for(var s=0;s<l.length;s++){var a=l[s];null!=a.to&&i==e.line&&e.ch>=a.to||null==a.from&&i!=e.line||null!=a.from&&i==t.line&&a.from>=t.ch||r&&!r(a.marker)||n.push(a.marker.parent||a.marker)}++i}),n},getAllMarks:function(){var e=[];return this.iter(function(t){var r=t.markedSpans;if(r)for(var n=0;n<r.length;++n)null!=r[n].from&&e.push(r[n].marker)}),e},posFromIndex:function(e){var t,r=this.first,n=this.lineSeparator().length;return this.iter(function(i){var o=i.text.length+n;if(o>e)return t=e,!0;e-=o,++r}),U(this,E(r,t))},indexFromPos:function(e){var t=(e=U(this,e)).ch;if(e.line<this.first||e.ch<0)return 0;var r=this.lineSeparator().length;return this.iter(this.first,e.line,function(e){t+=e.text.length+r}),t},copy:function(e){var t=new Ds(O(this,this.first,this.first+this.size),this.modeOption,this.first,this.lineSep,this.direction);return t.scrollTop=this.scrollTop,t.scrollLeft=this.scrollLeft,t.sel=this.sel,t.extend=!1,e&&(t.history.undoDepth=this.history.undoDepth,t.setHistory(this.getHistory())),t},linkedDoc:function(e){e||(e={});var t=this.first,r=this.first+this.size;null!=e.from&&e.from>t&&(t=e.from),null!=e.to&&e.to<r&&(r=e.to);var n=new Ds(O(this,t,r),e.mode||this.modeOption,t,this.lineSep,this.direction);return e.sharedHist&&(n.history=this.history),(this.linked||(this.linked=[])).push({doc:n,sharedHist:e.sharedHist}),n.linked=[{doc:this,isParent:!0,sharedHist:e.sharedHist}],Yi(n,Xi(this)),n},unlinkDoc:function(e){var t=this;if(e instanceof jo&&(e=e.doc),this.linked)for(var r=0;r<this.linked.length;++r)if(t.linked[r].doc==e){t.linked.splice(r,1),e.unlinkDoc(t),_i(Xi(t));break}if(e.history==this.history){var n=[e.id];$n(e,function(e){return n.push(e.id)},!0),e.history=new Jn(null),e.history.done=fi(this.history.done,n),e.history.undone=fi(this.history.undone,n)}},iterLinkedDocs:function(e){$n(this,e)},getMode:function(){return this.mode},getEditor:function(){return this.cm},splitLines:function(e){return this.lineSep?e.split(this.lineSep):es(e)},lineSeparator:function(){return this.lineSep||"\n"},setDirection:gn(function(e){"rtl"!=e&&(e="ltr"),e!=this.direction&&(this.direction=e,this.iter(function(e){return e.order=null}),this.cm&&Qn(this.cm))})}),Ds.prototype.eachLine=Ds.prototype.iter;for(var Hs=0,Fs=!1,Es={3:"Enter",8:"Backspace",9:"Tab",13:"Enter",16:"Shift",17:"Ctrl",18:"Alt",19:"Pause",20:"CapsLock",27:"Esc",32:"Space",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"Left",38:"Up",39:"Right",40:"Down",44:"PrintScrn",45:"Insert",46:"Delete",59:";",61:"=",91:"Mod",92:"Mod",93:"Mod",106:"*",107:"=",109:"-",110:".",111:"/",127:"Delete",173:"-",186:";",187:"=",188:",",189:"-",190:".",191:"/",192:"`",219:"[",220:"\\",221:"]",222:"'",63232:"Up",63233:"Down",63234:"Left",63235:"Right",63272:"Delete",63273:"Home",63275:"End",63276:"PageUp",63277:"PageDown",63302:"Insert"},Ps=0;Ps<10;Ps++)Es[Ps+48]=Es[Ps+96]=String(Ps);for(var Is=65;Is<=90;Is++)Es[Is]=String.fromCharCode(Is);for(var zs=1;zs<=12;zs++)Es[zs+111]=Es[zs+63235]="F"+zs;var Rs={};Rs.basic={Left:"goCharLeft",Right:"goCharRight",Up:"goLineUp",Down:"goLineDown",End:"goLineEnd",Home:"goLineStartSmart",PageUp:"goPageUp",PageDown:"goPageDown",Delete:"delCharAfter",Backspace:"delCharBefore","Shift-Backspace":"delCharBefore",Tab:"defaultTab","Shift-Tab":"indentAuto",Enter:"newlineAndIndent",Insert:"toggleOverwrite",Esc:"singleSelection"},Rs.pcDefault={"Ctrl-A":"selectAll","Ctrl-D":"deleteLine","Ctrl-Z":"undo","Shift-Ctrl-Z":"redo","Ctrl-Y":"redo","Ctrl-Home":"goDocStart","Ctrl-End":"goDocEnd","Ctrl-Up":"goLineUp","Ctrl-Down":"goLineDown","Ctrl-Left":"goGroupLeft","Ctrl-Right":"goGroupRight","Alt-Left":"goLineStart","Alt-Right":"goLineEnd","Ctrl-Backspace":"delGroupBefore","Ctrl-Delete":"delGroupAfter","Ctrl-S":"save","Ctrl-F":"find","Ctrl-G":"findNext","Shift-Ctrl-G":"findPrev","Shift-Ctrl-F":"replace","Shift-Ctrl-R":"replaceAll","Ctrl-[":"indentLess","Ctrl-]":"indentMore","Ctrl-U":"undoSelection","Shift-Ctrl-U":"redoSelection","Alt-U":"redoSelection",fallthrough:"basic"},Rs.emacsy={"Ctrl-F":"goCharRight","Ctrl-B":"goCharLeft","Ctrl-P":"goLineUp","Ctrl-N":"goLineDown","Alt-F":"goWordRight","Alt-B":"goWordLeft","Ctrl-A":"goLineStart","Ctrl-E":"goLineEnd","Ctrl-V":"goPageDown","Shift-Ctrl-V":"goPageUp","Ctrl-D":"delCharAfter","Ctrl-H":"delCharBefore","Alt-D":"delWordAfter","Alt-Backspace":"delWordBefore","Ctrl-K":"killLine","Ctrl-T":"transposeChars","Ctrl-O":"openLine"},Rs.macDefault={"Cmd-A":"selectAll","Cmd-D":"deleteLine","Cmd-Z":"undo","Shift-Cmd-Z":"redo","Cmd-Y":"redo","Cmd-Home":"goDocStart","Cmd-Up":"goDocStart","Cmd-End":"goDocEnd","Cmd-Down":"goDocEnd","Alt-Left":"goGroupLeft","Alt-Right":"goGroupRight","Cmd-Left":"goLineLeft","Cmd-Right":"goLineRight","Alt-Backspace":"delGroupBefore","Ctrl-Alt-Backspace":"delGroupAfter","Alt-Delete":"delGroupAfter","Cmd-S":"save","Cmd-F":"find","Cmd-G":"findNext","Shift-Cmd-G":"findPrev","Cmd-Alt-F":"replace","Shift-Cmd-Alt-F":"replaceAll","Cmd-[":"indentLess","Cmd-]":"indentMore","Cmd-Backspace":"delWrappedLineLeft","Cmd-Delete":"delWrappedLineRight","Cmd-U":"undoSelection","Shift-Cmd-U":"redoSelection","Ctrl-Up":"goDocStart","Ctrl-Down":"goDocEnd",fallthrough:["basic","emacsy"]},Rs.default=Ml?Rs.macDefault:Rs.pcDefault;var Bs={selectAll:Mi,singleSelection:function(e){return e.setSelection(e.getCursor("anchor"),e.getCursor("head"),Gl)},killLine:function(e){return co(e,function(t){if(t.empty()){var r=M(e.doc,t.head.line).text.length;return t.head.ch==r&&t.head.line<e.lastLine()?{from:t.head,to:E(t.head.line+1,0)}:{from:t.head,to:E(t.head.line,r)}}return{from:t.from(),to:t.to()}})},deleteLine:function(e){return co(e,function(t){return{from:E(t.from().line,0),to:U(e.doc,E(t.to().line+1,0))}})},delLineLeft:function(e){return co(e,function(e){return{from:E(e.from().line,0),to:e.from()}})},delWrappedLineLeft:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5;return{from:e.coordsChar({left:0,top:r},"div"),to:t.from()}})},delWrappedLineRight:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5,n=e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div");return{from:t.from(),to:n}})},undo:function(e){return e.undo()},redo:function(e){return e.redo()},undoSelection:function(e){return e.undoSelection()},redoSelection:function(e){return e.redoSelection()},goDocStart:function(e){return e.extendSelection(E(e.firstLine(),0))},goDocEnd:function(e){return e.extendSelection(E(e.lastLine()))},goLineStart:function(e){return e.extendSelectionsBy(function(t){return vo(e,t.head.line)},{origin:"+move",bias:1})},goLineStartSmart:function(e){return e.extendSelectionsBy(function(t){return yo(e,t.head)},{origin:"+move",bias:1})},goLineEnd:function(e){return e.extendSelectionsBy(function(t){return mo(e,t.head.line)},{origin:"+move",bias:-1})},goLineRight:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div")},Vl)},goLineLeft:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:0,top:r},"div")},Vl)},goLineLeftSmart:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5,n=e.coordsChar({left:0,top:r},"div");return n.ch<e.getLine(n.line).search(/\S/)?yo(e,t.head):n},Vl)},goLineUp:function(e){return e.moveV(-1,"line")},goLineDown:function(e){return e.moveV(1,"line")},goPageUp:function(e){return e.moveV(-1,"page")},goPageDown:function(e){return e.moveV(1,"page")},goCharLeft:function(e){return e.moveH(-1,"char")},goCharRight:function(e){return e.moveH(1,"char")},goColumnLeft:function(e){return e.moveH(-1,"column")},goColumnRight:function(e){return e.moveH(1,"column")},goWordLeft:function(e){return e.moveH(-1,"word")},goGroupRight:function(e){return e.moveH(1,"group")},goGroupLeft:function(e){return e.moveH(-1,"group")},goWordRight:function(e){return e.moveH(1,"word")},delCharBefore:function(e){return e.deleteH(-1,"char")},delCharAfter:function(e){return e.deleteH(1,"char")},delWordBefore:function(e){return e.deleteH(-1,"word")},delWordAfter:function(e){return e.deleteH(1,"word")},delGroupBefore:function(e){return e.deleteH(-1,"group")},delGroupAfter:function(e){return e.deleteH(1,"group")},indentAuto:function(e){return e.indentSelection("smart")},indentMore:function(e){return e.indentSelection("add")},indentLess:function(e){return e.indentSelection("subtract")},insertTab:function(e){return e.replaceSelection("\t")},insertSoftTab:function(e){for(var t=[],r=e.listSelections(),n=e.options.tabSize,i=0;i<r.length;i++){var o=r[i].from(),l=f(e.getLine(o.line),o.ch,n);t.push(p(n-l%n))}e.replaceSelections(t)},defaultTab:function(e){e.somethingSelected()?e.indentSelection("add"):e.execCommand("insertTab")},transposeChars:function(e){return hn(e,function(){for(var t=e.listSelections(),r=[],n=0;n<t.length;n++)if(t[n].empty()){var i=t[n].head,o=M(e.doc,i.line).text;if(o)if(i.ch==o.length&&(i=new E(i.line,i.ch-1)),i.ch>0)i=new E(i.line,i.ch+1),e.replaceRange(o.charAt(i.ch-1)+o.charAt(i.ch-2),E(i.line,i.ch-2),i,"+transpose");else if(i.line>e.doc.first){var l=M(e.doc,i.line-1).text;l&&(i=new E(i.line,1),e.replaceRange(o.charAt(0)+e.doc.lineSeparator()+l.charAt(l.length-1),E(i.line-1,l.length-1),i,"+transpose"))}r.push(new Ts(i,i))}e.setSelections(r)})},newlineAndIndent:function(e){return hn(e,function(){for(var t=e.listSelections(),r=t.length-1;r>=0;r--)e.replaceRange(e.doc.lineSeparator(),t[r].anchor,t[r].head,"+input");t=e.listSelections();for(var n=0;n<t.length;n++)e.indentLine(t[n].from().line,null,!0);jr(e)})},openLine:function(e){return e.replaceSelection("\n","start")},toggleOverwrite:function(e){return e.toggleOverwrite()}},Gs=new Pl,Us=null,Vs=function(e,t,r){this.time=e,this.pos=t,this.button=r};Vs.prototype.compare=function(e,t,r){return this.time+400>e&&0==P(t,this.pos)&&r==this.button};var Ks,js,Xs={toString:function(){return"CodeMirror.Init"}},Ys={},_s={};jo.defaults=Ys,jo.optionHandlers=_s;var $s=[];jo.defineInitHook=function(e){return $s.push(e)};var qs=null,Zs=function(e){this.cm=e,this.lastAnchorNode=this.lastAnchorOffset=this.lastFocusNode=this.lastFocusOffset=null,this.polling=new Pl,this.composing=null,this.gracePeriod=!1,this.readDOMTimeout=null};Zs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()}),"cut"==e.type&&i.replaceSelection("",null,"cut");else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type&&i.operation(function(){i.setSelections(t.ranges,0,Gl),i.replaceSelection("",null,"cut")})}if(e.clipboardData){e.clipboardData.clearData();var r=qs.text.join("\n");if(e.clipboardData.setData("Text",r),e.clipboardData.getData("Text")==r)return void e.preventDefault()}var l=el(),s=l.firstChild;i.display.lineSpace.insertBefore(l,i.display.lineSpace.firstChild),s.value=qs.text.join("\n");var a=document.activeElement;El(s),setTimeout(function(){i.display.lineSpace.removeChild(l),a.focus(),a==o&&n.showPrimarySelection()},50)}}var r=this,n=this,i=n.cm,o=n.div=e.lineDiv;Jo(o,i.options.spellcheck),Ql(o,"paste",function(e){Me(i,e)||qo(e,i)||vl<=11&&setTimeout(dn(i,function(){return r.updateFromDOM()}),20)}),Ql(o,"compositionstart",function(e){r.composing={data:e.data,done:!1}}),Ql(o,"compositionupdate",function(e){r.composing||(r.composing={data:e.data,done:!1})}),Ql(o,"compositionend",function(e){r.composing&&(e.data!=r.composing.data&&r.readFromDOMSoon(),r.composing.done=!0)}),Ql(o,"touchstart",function(){return n.forceCompositionEnd()}),Ql(o,"input",function(){r.composing||r.readFromDOMSoon()}),Ql(o,"copy",t),Ql(o,"cut",t)},Zs.prototype.prepareSelection=function(){var e=Tr(this.cm,!1);return e.focus=this.cm.state.focused,e},Zs.prototype.showSelection=function(e,t){e&&this.cm.display.view.length&&((e.focus||t)&&this.showPrimarySelection(),this.showMultipleSelections(e))},Zs.prototype.showPrimarySelection=function(){var e=window.getSelection(),t=this.cm,r=t.doc.sel.primary(),n=r.from(),i=r.to();if(t.display.viewTo==t.display.viewFrom||n.line>=t.display.viewTo||i.line<t.display.viewFrom)e.removeAllRanges();else{var o=sl(t,e.anchorNode,e.anchorOffset),l=sl(t,e.focusNode,e.focusOffset);if(!o||o.bad||!l||l.bad||0!=P(B(o,l),n)||0!=P(R(o,l),i)){var s=t.display.view,a=n.line>=t.display.viewFrom&&nl(t,n)||{node:s[0].measure.map[2],offset:0},u=i.line<t.display.viewTo&&nl(t,i);if(!u){var c=s[s.length-1].measure,f=c.maps?c.maps[c.maps.length-1]:c.map;u={node:f[f.length-1],offset:f[f.length-2]-f[f.length-3]}}if(a&&u){var h,d=e.rangeCount&&e.getRangeAt(0);try{h=Wl(a.node,a.offset,u.offset,u.node)}catch(e){}h&&(!fl&&t.state.focused?(e.collapse(a.node,a.offset),h.collapsed||(e.removeAllRanges(),e.addRange(h))):(e.removeAllRanges(),e.addRange(h)),d&&null==e.anchorNode?e.addRange(d):fl&&this.startGracePeriod()),this.rememberSelection()}else e.removeAllRanges()}}},Zs.prototype.startGracePeriod=function(){var e=this;clearTimeout(this.gracePeriod),this.gracePeriod=setTimeout(function(){e.gracePeriod=!1,e.selectionChanged()&&e.cm.operation(function(){return e.cm.curOp.selectionChanged=!0})},20)},Zs.prototype.showMultipleSelections=function(e){r(this.cm.display.cursorDiv,e.cursors),r(this.cm.display.selectionDiv,e.selection)},Zs.prototype.rememberSelection=function(){var e=window.getSelection();this.lastAnchorNode=e.anchorNode,this.lastAnchorOffset=e.anchorOffset,this.lastFocusNode=e.focusNode,this.lastFocusOffset=e.focusOffset},Zs.prototype.selectionInEditor=function(){var e=window.getSelection();if(!e.rangeCount)return!1;var t=e.getRangeAt(0).commonAncestorContainer;return o(this.div,t)},Zs.prototype.focus=function(){"nocursor"!=this.cm.options.readOnly&&(this.selectionInEditor()||this.showSelection(this.prepareSelection(),!0),this.div.focus())},Zs.prototype.blur=function(){this.div.blur()},Zs.prototype.getField=function(){return this.div},Zs.prototype.supportsTouch=function(){return!0},Zs.prototype.receivedFocus=function(){function e(){t.cm.state.focused&&(t.pollSelection(),t.polling.set(t.cm.options.pollInterval,e))}var t=this;this.selectionInEditor()?this.pollSelection():hn(this.cm,function(){return t.cm.curOp.selectionChanged=!0}),this.polling.set(this.cm.options.pollInterval,e)},Zs.prototype.selectionChanged=function(){var e=window.getSelection();return e.anchorNode!=this.lastAnchorNode||e.anchorOffset!=this.lastAnchorOffset||e.focusNode!=this.lastFocusNode||e.focusOffset!=this.lastFocusOffset},Zs.prototype.pollSelection=function(){if(null==this.readDOMTimeout&&!this.gracePeriod&&this.selectionChanged()){var e=window.getSelection(),t=this.cm;if(kl&&bl&&this.cm.options.gutters.length&&il(e.anchorNode))return this.cm.triggerOnKeyDown({type:"keydown",keyCode:8,preventDefault:Math.abs}),this.blur(),void this.focus();if(!this.composing){this.rememberSelection();var r=sl(t,e.anchorNode,e.anchorOffset),n=sl(t,e.focusNode,e.focusOffset);r&&n&&hn(t,function(){bi(t.doc,Rn(r,n),Gl),(r.bad||n.bad)&&(t.curOp.selectionChanged=!0)})}}},Zs.prototype.pollContent=function(){null!=this.readDOMTimeout&&(clearTimeout(this.readDOMTimeout),this.readDOMTimeout=null);var e=this.cm,t=e.display,r=e.doc.sel.primary(),n=r.from(),i=r.to();if(0==n.ch&&n.line>e.firstLine()&&(n=E(n.line-1,M(e.doc,n.line-1).length)),i.ch==M(e.doc,i.line).text.length&&i.line<e.lastLine()&&(i=E(i.line+1,0)),n.line<t.viewFrom||i.line>t.viewTo-1)return!1;var o,l,s;n.line==t.viewFrom||0==(o=Lr(e,n.line))?(l=W(t.view[0].line),s=t.view[0].node):(l=W(t.view[o].line),s=t.view[o-1].node.nextSibling);var a,u,c=Lr(e,i.line);if(c==t.view.length-1?(a=t.viewTo-1,u=t.lineDiv.lastChild):(a=W(t.view[c+1].line)-1,u=t.view[c+1].node.previousSibling),!s)return!1;for(var f=e.doc.splitLines(ll(e,s,u,l,a)),h=N(e.doc,E(l,0),E(a,M(e.doc,a).text.length));f.length>1&&h.length>1;)if(g(f)==g(h))f.pop(),h.pop(),a--;else{if(f[0]!=h[0])break;f.shift(),h.shift(),l++}for(var d=0,p=0,v=f[0],m=h[0],y=Math.min(v.length,m.length);d<y&&v.charCodeAt(d)==m.charCodeAt(d);)++d;for(var b=g(f),w=g(h),x=Math.min(b.length-(1==f.length?d:0),w.length-(1==h.length?d:0));p<x&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)++p;if(1==f.length&&1==h.length&&l==n.line)for(;d&&d>n.ch&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)d--,p++;f[f.length-1]=b.slice(0,b.length-p).replace(/^\u200b+/,""),f[0]=f[0].slice(d).replace(/\u200b+$/,"");var C=E(l,d),S=E(a,h.length?g(h).length-p:0);return f.length>1||f[0]||P(C,S)?(Ei(e.doc,f,C,S,"+input"),!0):void 0},Zs.prototype.ensurePolled=function(){this.forceCompositionEnd()},Zs.prototype.reset=function(){this.forceCompositionEnd()},Zs.prototype.forceCompositionEnd=function(){this.composing&&(clearTimeout(this.readDOMTimeout),this.composing=null,this.updateFromDOM(),this.div.blur(),this.div.focus())},Zs.prototype.readFromDOMSoon=function(){var e=this;null==this.readDOMTimeout&&(this.readDOMTimeout=setTimeout(function(){if(e.readDOMTimeout=null,e.composing){if(!e.composing.done)return;e.composing=null}e.updateFromDOM()},80))},Zs.prototype.updateFromDOM=function(){var e=this;!this.cm.isReadOnly()&&this.pollContent()||hn(this.cm,function(){return vn(e.cm)})},Zs.prototype.setUneditable=function(e){e.contentEditable="false"},Zs.prototype.onKeyPress=function(e){0!=e.charCode&&(e.preventDefault(),this.cm.isReadOnly()||dn(this.cm,$o)(this.cm,String.fromCharCode(null==e.charCode?e.keyCode:e.charCode),0))},Zs.prototype.readOnlyChanged=function(e){this.div.contentEditable=String("nocursor"!=e)},Zs.prototype.onContextMenu=function(){},Zs.prototype.resetPosition=function(){},Zs.prototype.needsContentAttribute=!0;var Qs=function(e){this.cm=e,this.prevInput="",this.pollingFast=!1,this.polling=new Pl,this.hasSelection=!1,this.composing=null};Qs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()});else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type?i.setSelections(t.ranges,null,Gl):(n.prevInput="",l.value=t.text.join("\n"),El(l))}"cut"==e.type&&(i.state.cutIncoming=!0)}}var r=this,n=this,i=this.cm,o=this.wrapper=el(),l=this.textarea=o.firstChild;e.wrapper.insertBefore(o,e.wrapper.firstChild),Ll&&(l.style.width="0px"),Ql(l,"input",function(){gl&&vl>=9&&r.hasSelection&&(r.hasSelection=null),n.poll()}),Ql(l,"paste",function(e){Me(i,e)||qo(e,i)||(i.state.pasteIncoming=!0,n.fastPoll())}),Ql(l,"cut",t),Ql(l,"copy",t),Ql(e.scroller,"paste",function(t){Ft(e,t)||Me(i,t)||(i.state.pasteIncoming=!0,n.focus())}),Ql(e.lineSpace,"selectstart",function(t){Ft(e,t)||We(t)}),Ql(l,"compositionstart",function(){var e=i.getCursor("from");n.composing&&n.composing.range.clear(),n.composing={start:e,range:i.markText(e,i.getCursor("to"),{className:"CodeMirror-composing"})}}),Ql(l,"compositionend",function(){n.composing&&(n.poll(),n.composing.range.clear(),n.composing=null)})},Qs.prototype.prepareSelection=function(){var e=this.cm,t=e.display,r=e.doc,n=Tr(e);if(e.options.moveInputWithCursor){var i=sr(e,r.sel.primary().head,"div"),o=t.wrapper.getBoundingClientRect(),l=t.lineDiv.getBoundingClientRect();n.teTop=Math.max(0,Math.min(t.wrapper.clientHeight-10,i.top+l.top-o.top)),n.teLeft=Math.max(0,Math.min(t.wrapper.clientWidth-10,i.left+l.left-o.left))}return n},Qs.prototype.showSelection=function(e){var t=this.cm.display;r(t.cursorDiv,e.cursors),r(t.selectionDiv,e.selection),null!=e.teTop&&(this.wrapper.style.top=e.teTop+"px",this.wrapper.style.left=e.teLeft+"px")},Qs.prototype.reset=function(e){if(!this.contextMenuPending&&!this.composing){var t=this.cm;if(t.somethingSelected()){this.prevInput="";var r=t.getSelection();this.textarea.value=r,t.state.focused&&El(this.textarea),gl&&vl>=9&&(this.hasSelection=r)}else e||(this.prevInput=this.textarea.value="",gl&&vl>=9&&(this.hasSelection=null))}},Qs.prototype.getField=function(){return this.textarea},Qs.prototype.supportsTouch=function(){return!1},Qs.prototype.focus=function(){if("nocursor"!=this.cm.options.readOnly&&(!Tl||l()!=this.textarea))try{this.textarea.focus()}catch(e){}},Qs.prototype.blur=function(){this.textarea.blur()},Qs.prototype.resetPosition=function(){this.wrapper.style.top=this.wrapper.style.left=0},Qs.prototype.receivedFocus=function(){this.slowPoll()},Qs.prototype.slowPoll=function(){var e=this;this.pollingFast||this.polling.set(this.cm.options.pollInterval,function(){e.poll(),e.cm.state.focused&&e.slowPoll()})},Qs.prototype.fastPoll=function(){function e(){r.poll()||t?(r.pollingFast=!1,r.slowPoll()):(t=!0,r.polling.set(60,e))}var t=!1,r=this;r.pollingFast=!0,r.polling.set(20,e)},Qs.prototype.poll=function(){var e=this,t=this.cm,r=this.textarea,n=this.prevInput;if(this.contextMenuPending||!t.state.focused||ts(r)&&!n&&!this.composing||t.isReadOnly()||t.options.disableInput||t.state.keySeq)return!1;var i=r.value;if(i==n&&!t.somethingSelected())return!1;if(gl&&vl>=9&&this.hasSelection===i||Ml&&/[\uf700-\uf7ff]/.test(i))return t.display.input.reset(),!1;if(t.doc.sel==t.display.selForContextMenu){var o=i.charCodeAt(0);if(8203!=o||n||(n="​"),8666==o)return this.reset(),this.cm.execCommand("undo")}for(var l=0,s=Math.min(n.length,i.length);l<s&&n.charCodeAt(l)==i.charCodeAt(l);)++l;return hn(t,function(){$o(t,i.slice(l),n.length-l,null,e.composing?"*compose":null),i.length>1e3||i.indexOf("\n")>-1?r.value=e.prevInput="":e.prevInput=i,e.composing&&(e.composing.range.clear(),e.composing.range=t.markText(e.composing.start,t.getCursor("to"),{className:"CodeMirror-composing"}))}),!0},Qs.prototype.ensurePolled=function(){this.pollingFast&&this.poll()&&(this.pollingFast=!1)},Qs.prototype.onKeyPress=function(){gl&&vl>=9&&(this.hasSelection=null),this.fastPoll()},Qs.prototype.onContextMenu=function(e){function t(){if(null!=l.selectionStart){var e=i.somethingSelected(),t="​"+(e?l.value:"");l.value="⇚",l.value=t,n.prevInput=e?"":"​",l.selectionStart=1,l.selectionEnd=t.length,o.selForContextMenu=i.doc.sel}}function r(){if(n.contextMenuPending=!1,n.wrapper.style.cssText=c,l.style.cssText=u,gl&&vl<9&&o.scrollbars.setScrollTop(o.scroller.scrollTop=a),null!=l.selectionStart){(!gl||gl&&vl<9)&&t();var e=0,r=function(){o.selForContextMenu==i.doc.sel&&0==l.selectionStart&&l.selectionEnd>0&&"​"==n.prevInput?dn(i,Mi)(i):e++<10?o.detectingSelectAll=setTimeout(r,500):(o.selForContextMenu=null,o.input.reset())};o.detectingSelectAll=setTimeout(r,200)}}var n=this,i=n.cm,o=i.display,l=n.textarea,s=Sr(i,e),a=o.scroller.scrollTop;if(s&&!wl){i.options.resetSelectionOnContextMenu&&-1==i.doc.sel.contains(s)&&dn(i,bi)(i.doc,Rn(s),Gl);var u=l.style.cssText,c=n.wrapper.style.cssText;n.wrapper.style.cssText="position: absolute";var f=n.wrapper.getBoundingClientRect();l.style.cssText="position: absolute; width: 30px; height: 30px;\n      top: "+(e.clientY-f.top-5)+"px; left: "+(e.clientX-f.left-5)+"px;\n      z-index: 1000; background: "+(gl?"rgba(255, 255, 255, .05)":"transparent")+";\n      outline: none; border-width: 0; outline: none; overflow: hidden; opacity: .05; filter: alpha(opacity=5);";var h;if(ml&&(h=window.scrollY),o.input.focus(),ml&&window.scrollTo(null,h),o.input.reset(),i.somethingSelected()||(l.value=n.prevInput=" "),n.contextMenuPending=!0,o.selForContextMenu=i.doc.sel,clearTimeout(o.detectingSelectAll),gl&&vl>=9&&t(),Hl){Fe(e);var d=function(){ke(window,"mouseup",d),setTimeout(r,20)};Ql(window,"mouseup",d)}else setTimeout(r,50)}},Qs.prototype.readOnlyChanged=function(e){e||this.reset(),this.textarea.disabled="nocursor"==e},Qs.prototype.setUneditable=function(){},Qs.prototype.needsContentAttribute=!1,function(e){function t(t,n,i,o){e.defaults[t]=n,i&&(r[t]=o?function(e,t,r){r!=Xs&&i(e,t,r)}:i)}var r=e.optionHandlers;e.defineOption=t,e.Init=Xs,t("value","",function(e,t){return e.setValue(t)},!0),t("mode",null,function(e,t){e.doc.modeOption=t,jn(e)},!0),t("indentUnit",2,jn,!0),t("indentWithTabs",!1),t("smartIndent",!0),t("tabSize",4,function(e){Xn(e),er(e),vn(e)},!0),t("lineSeparator",null,function(e,t){if(e.doc.lineSep=t,t){var r=[],n=e.doc.first;e.doc.iter(function(e){for(var i=0;;){var o=e.text.indexOf(t,i);if(-1==o)break;i=o+t.length,r.push(E(n,o))}n++});for(var i=r.length-1;i>=0;i--)Ei(e.doc,t,r[i],E(r[i].line,r[i].ch+t.length))}}),t("specialChars",/[\u0000-\u001f\u007f-\u009f\u00ad\u061c\u200b-\u200f\u2028\u2029\ufeff]/g,function(e,t,r){e.state.specialChars=new RegExp(t.source+(t.test("\t")?"":"|\t"),"g"),r!=Xs&&e.refresh()}),t("specialCharPlaceholder",at,function(e){return e.refresh()},!0),t("electricChars",!0),t("inputStyle",Tl?"contenteditable":"textarea",function(){throw new Error("inputStyle can not (yet) be changed in a running editor")},!0),t("spellcheck",!1,function(e,t){return e.getInputField().spellcheck=t},!0),t("rtlMoveVisually",!Ol),t("wholeLineUpdateBefore",!0),t("theme","default",function(e){Go(e),Uo(e)},!0),t("keyMap","default",function(e,t,r){var n=uo(t),i=r!=Xs&&uo(r);i&&i.detach&&i.detach(e,n),n.attach&&n.attach(e,i||null)}),t("extraKeys",null),t("configureMouse",null),t("lineWrapping",!1,Ko,!0),t("gutters",[],function(e){Fn(e.options),Uo(e)},!0),t("fixedGutter",!0,function(e,t){e.display.gutters.style.left=t?wr(e.display)+"px":"0",e.refresh()},!0),t("coverGutterNextToScrollbar",!1,function(e){return en(e)},!0),t("scrollbarStyle","native",function(e){rn(e),en(e),e.display.scrollbars.setScrollTop(e.doc.scrollTop),e.display.scrollbars.setScrollLeft(e.doc.scrollLeft)},!0),t("lineNumbers",!1,function(e){Fn(e.options),Uo(e)},!0),t("firstLineNumber",1,Uo,!0),t("lineNumberFormatter",function(e){return e},Uo,!0),t("showCursorWhenSelecting",!1,kr,!0),t("resetSelectionOnContextMenu",!0),t("lineWiseCopyCut",!0),t("pasteLinesPerSelection",!0),t("readOnly",!1,function(e,t){"nocursor"==t&&(Fr(e),e.display.input.blur()),e.display.input.readOnlyChanged(t)}),t("disableInput",!1,function(e,t){t||e.display.input.reset()},!0),t("dragDrop",!0,Vo),t("allowDropFileTypes",null),t("cursorBlinkRate",530),t("cursorScrollMargin",0),t("cursorHeight",1,kr,!0),t("singleCursorHeightPerLine",!0,kr,!0),t("workTime",100),t("workDelay",100),t("flattenSpans",!0,Xn,!0),t("addModeClass",!1,Xn,!0),t("pollInterval",100),t("undoDepth",200,function(e,t){return e.doc.history.undoDepth=t}),t("historyEventDelay",1250),t("viewportMargin",10,function(e){return e.refresh()},!0),t("maxHighlightLength",1e4,Xn,!0),t("moveInputWithCursor",!0,function(e,t){t||e.display.input.resetPosition()}),t("tabindex",null,function(e,t){return e.display.input.getField().tabIndex=t||""}),t("autofocus",null),t("direction","ltr",function(e,t){return e.doc.setDirection(t)},!0)}(jo),function(e){var t=e.optionHandlers,r=e.helpers={};e.prototype={constructor:e,focus:function(){window.focus(),this.display.input.focus()},setOption:function(e,r){var n=this.options,i=n[e];n[e]==r&&"mode"!=e||(n[e]=r,t.hasOwnProperty(e)&&dn(this,t[e])(this,r,i),Te(this,"optionChange",this,e))},getOption:function(e){return this.options[e]},getDoc:function(){return this.doc},addKeyMap:function(e,t){this.state.keyMaps[t?"push":"unshift"](uo(e))},removeKeyMap:function(e){for(var t=this.state.keyMaps,r=0;r<t.length;++r)if(t[r]==e||t[r].name==e)return t.splice(r,1),!0},addOverlay:pn(function(t,r){var n=t.token?t:e.getMode(this.options,t);if(n.startState)throw new Error("Overlays may not be stateful.");m(this.state.overlays,{mode:n,modeSpec:t,opaque:r&&r.opaque,priority:r&&r.priority||0},function(e){return e.priority}),this.state.modeGen++,vn(this)}),removeOverlay:pn(function(e){for(var t=this,r=this.state.overlays,n=0;n<r.length;++n){var i=r[n].modeSpec;if(i==e||"string"==typeof e&&i.name==e)return r.splice(n,1),t.state.modeGen++,void vn(t)}}),indentLine:pn(function(e,t,r){"string"!=typeof t&&"number"!=typeof t&&(t=null==t?this.options.smartIndent?"smart":"prev":t?"add":"subtract"),H(this.doc,e)&&Yo(this,e,t,r)}),indentSelection:pn(function(e){for(var t=this,r=this.doc.sel.ranges,n=-1,i=0;i<r.length;i++){var o=r[i];if(o.empty())o.head.line>n&&(Yo(t,o.head.line,e,!0),n=o.head.line,i==t.doc.sel.primIndex&&jr(t));else{var l=o.from(),s=o.to(),a=Math.max(n,l.line);n=Math.min(t.lastLine(),s.line-(s.ch?0:1))+1;for(var u=a;u<n;++u)Yo(t,u,e);var c=t.doc.sel.ranges;0==l.ch&&r.length==c.length&&c[i].from().ch>0&&gi(t.doc,i,new Ts(l,c[i].to()),Gl)}}}),getTokenAt:function(e,t){return Je(this,e,t)},getLineTokens:function(e,t){return Je(this,E(e),t,!0)},getTokenTypeAt:function(e){e=U(this.doc,e);var t,r=_e(this,M(this.doc,e.line)),n=0,i=(r.length-1)/2,o=e.ch;if(0==o)t=r[2];else for(;;){var l=n+i>>1;if((l?r[2*l-1]:0)>=o)i=l;else{if(!(r[2*l+1]<o)){t=r[2*l+2];break}n=l+1}}var s=t?t.indexOf("overlay "):-1;return s<0?t:0==s?null:t.slice(0,s-1)},getModeAt:function(t){var r=this.doc.mode;return r.innerMode?e.innerMode(r,this.getTokenAt(t).state).mode:r},getHelper:function(e,t){return this.getHelpers(e,t)[0]},getHelpers:function(e,t){var n=this,i=[];if(!r.hasOwnProperty(t))return i;var o=r[t],l=this.getModeAt(e);if("string"==typeof l[t])o[l[t]]&&i.push(o[l[t]]);else if(l[t])for(var s=0;s<l[t].length;s++){var a=o[l[t][s]];a&&i.push(a)}else l.helperType&&o[l.helperType]?i.push(o[l.helperType]):o[l.name]&&i.push(o[l.name]);for(var u=0;u<o._global.length;u++){var c=o._global[u];c.pred(l,n)&&-1==h(i,c.val)&&i.push(c.val)}return i},getStateAfter:function(e,t){var r=this.doc;return e=G(r,null==e?r.first+r.size-1:e),$e(this,e+1,t).state},cursorCoords:function(e,t){var r,n=this.doc.sel.primary();return r=null==e?n.head:"object"==typeof e?U(this.doc,e):e?n.from():n.to(),sr(this,r,t||"page")},charCoords:function(e,t){return lr(this,U(this.doc,e),t||"page")},coordsChar:function(e,t){return e=or(this,e,t||"page"),cr(this,e.left,e.top)},lineAtHeight:function(e,t){return e=or(this,{top:e,left:0},t||"page").top,D(this.doc,e+this.display.viewOffset)},heightAtLine:function(e,t,r){var n,i=!1;if("number"==typeof e){var o=this.doc.first+this.doc.size-1;e<this.doc.first?e=this.doc.first:e>o&&(e=o,i=!0),n=M(this.doc,e)}else n=e;return ir(this,n,{top:0,left:0},t||"page",r||i).top+(i?this.doc.height-ye(n):0)},defaultTextHeight:function(){return mr(this.display)},defaultCharWidth:function(){return yr(this.display)},getViewport:function(){return{from:this.display.viewFrom,to:this.display.viewTo}},addWidget:function(e,t,r,n,i){var o=this.display,l=(e=sr(this,U(this.doc,e))).bottom,s=e.left;if(t.style.position="absolute",t.setAttribute("cm-ignore-events","true"),this.display.input.setUneditable(t),o.sizer.appendChild(t),"over"==n)l=e.top;else if("above"==n||"near"==n){var a=Math.max(o.wrapper.clientHeight,this.doc.height),u=Math.max(o.sizer.clientWidth,o.lineSpace.clientWidth);("above"==n||e.bottom+t.offsetHeight>a)&&e.top>t.offsetHeight?l=e.top-t.offsetHeight:e.bottom+t.offsetHeight<=a&&(l=e.bottom),s+t.offsetWidth>u&&(s=u-t.offsetWidth)}t.style.top=l+"px",t.style.left=t.style.right="","right"==i?(s=o.sizer.clientWidth-t.offsetWidth,t.style.right="0px"):("left"==i?s=0:"middle"==i&&(s=(o.sizer.clientWidth-t.offsetWidth)/2),t.style.left=s+"px"),r&&Ur(this,{left:s,top:l,right:s+t.offsetWidth,bottom:l+t.offsetHeight})},triggerOnKeyDown:pn(Lo),triggerOnKeyPress:pn(Mo),triggerOnKeyUp:To,triggerOnMouseDown:pn(Oo),execCommand:function(e){if(Bs.hasOwnProperty(e))return Bs[e].call(null,this)},triggerElectric:pn(function(e){Zo(this,e)}),findPosH:function(e,t,r,n){var i=this,o=1;t<0&&(o=-1,t=-t);for(var l=U(this.doc,e),s=0;s<t&&!(l=tl(i.doc,l,o,r,n)).hitSide;++s);return l},moveH:pn(function(e,t){var r=this;this.extendSelectionsBy(function(n){return r.display.shift||r.doc.extend||n.empty()?tl(r.doc,n.head,e,t,r.options.rtlMoveVisually):e<0?n.from():n.to()},Vl)}),deleteH:pn(function(e,t){var r=this.doc.sel,n=this.doc;r.somethingSelected()?n.replaceSelection("",null,"+delete"):co(this,function(r){var i=tl(n,r.head,e,t,!1);return e<0?{from:i,to:r.head}:{from:r.head,to:i}})}),findPosV:function(e,t,r,n){var i=this,o=1,l=n;t<0&&(o=-1,t=-t);for(var s=U(this.doc,e),a=0;a<t;++a){var u=sr(i,s,"div");if(null==l?l=u.left:u.left=l,(s=rl(i,u,o,r)).hitSide)break}return s},moveV:pn(function(e,t){var r=this,n=this.doc,i=[],o=!this.display.shift&&!n.extend&&n.sel.somethingSelected();if(n.extendSelectionsBy(function(l){if(o)return e<0?l.from():l.to();var s=sr(r,l.head,"div");null!=l.goalColumn&&(s.left=l.goalColumn),i.push(s.left);var a=rl(r,s,e,t);return"page"==t&&l==n.sel.primary()&&Kr(r,lr(r,a,"div").top-s.top),a},Vl),i.length)for(var l=0;l<n.sel.ranges.length;l++)n.sel.ranges[l].goalColumn=i[l]}),findWordAt:function(e){var t=M(this.doc,e.line).text,r=e.ch,n=e.ch;if(t){var i=this.getHelper(e,"wordChars");"before"!=e.sticky&&n!=t.length||!r?++n:--r;for(var o=t.charAt(r),l=x(o,i)?function(e){return x(e,i)}:/\s/.test(o)?function(e){return/\s/.test(e)}:function(e){return!/\s/.test(e)&&!x(e)};r>0&&l(t.charAt(r-1));)--r;for(;n<t.length&&l(t.charAt(n));)++n}return new Ts(E(e.line,r),E(e.line,n))},toggleOverwrite:function(e){null!=e&&e==this.state.overwrite||((this.state.overwrite=!this.state.overwrite)?s(this.display.cursorDiv,"CodeMirror-overwrite"):Fl(this.display.cursorDiv,"CodeMirror-overwrite"),Te(this,"overwriteToggle",this,this.state.overwrite))},hasFocus:function(){return this.display.input.getField()==l()},isReadOnly:function(){return!(!this.options.readOnly&&!this.doc.cantEdit)},scrollTo:pn(function(e,t){Xr(this,e,t)}),getScrollInfo:function(){var e=this.display.scroller;return{left:e.scrollLeft,top:e.scrollTop,height:e.scrollHeight-zt(this)-this.display.barHeight,width:e.scrollWidth-zt(this)-this.display.barWidth,clientHeight:Bt(this),clientWidth:Rt(this)}},scrollIntoView:pn(function(e,t){null==e?(e={from:this.doc.sel.primary().head,to:null},null==t&&(t=this.options.cursorScrollMargin)):"number"==typeof e?e={from:E(e,0),to:null}:null==e.from&&(e={from:e,to:null}),e.to||(e.to=e.from),e.margin=t||0,null!=e.from.line?Yr(this,e):$r(this,e.from,e.to,e.margin)}),setSize:pn(function(e,t){var r=this,n=function(e){return"number"==typeof e||/^\d+$/.test(String(e))?e+"px":e};null!=e&&(this.display.wrapper.style.width=n(e)),null!=t&&(this.display.wrapper.style.height=n(t)),this.options.lineWrapping&&Jt(this);var i=this.display.viewFrom;this.doc.iter(i,this.display.viewTo,function(e){if(e.widgets)for(var t=0;t<e.widgets.length;t++)if(e.widgets[t].noHScroll){mn(r,i,"widget");break}++i}),this.curOp.forceUpdate=!0,Te(this,"refresh",this)}),operation:function(e){return hn(this,e)},startOperation:function(){return nn(this)},endOperation:function(){return on(this)},refresh:pn(function(){var e=this.display.cachedTextHeight;vn(this),this.curOp.forceUpdate=!0,er(this),Xr(this,this.doc.scrollLeft,this.doc.scrollTop),Wn(this),(null==e||Math.abs(e-mr(this.display))>.5)&&Cr(this),Te(this,"refresh",this)}),swapDoc:pn(function(e){var t=this.doc;return t.cm=null,qn(this,e),er(this),this.display.input.reset(),Xr(this,e.scrollLeft,e.scrollTop),this.curOp.forceScroll=!0,bt(this,"swapDoc",this,t),t}),getInputField:function(){return this.display.input.getField()},getWrapperElement:function(){return this.display.wrapper},getScrollerElement:function(){return this.display.scroller},getGutterElement:function(){return this.display.gutters}},Ae(e),e.registerHelper=function(t,n,i){r.hasOwnProperty(t)||(r[t]=e[t]={_global:[]}),r[t][n]=i},e.registerGlobalHelper=function(t,n,i,o){e.registerHelper(t,n,o),r[t]._global.push({pred:i,val:o})}}(jo);var Js="iter insert remove copy getEditor constructor".split(" ");for(var ea in Ds.prototype)Ds.prototype.hasOwnProperty(ea)&&h(Js,ea)<0&&(jo.prototype[ea]=function(e){return function(){return e.apply(this.doc,arguments)}}(Ds.prototype[ea]));return Ae(Ds),jo.inputStyles={textarea:Qs,contenteditable:Zs},jo.defineMode=function(e){jo.defaults.mode||"null"==e||(jo.defaults.mode=e),Be.apply(this,arguments)},jo.defineMIME=function(e,t){os[e]=t},jo.defineMode("null",function(){return{token:function(e){return e.skipToEnd()}}}),jo.defineMIME("text/plain","null"),jo.defineExtension=function(e,t){jo.prototype[e]=t},jo.defineDocExtension=function(e,t){Ds.prototype[e]=t},jo.fromTextArea=function(e,t){function r(){e.value=a.getValue()}if(t=t?c(t):{},t.value=e.value,!t.tabindex&&e.tabIndex&&(t.tabindex=e.tabIndex),!t.placeholder&&e.placeholder&&(t.placeholder=e.placeholder),null==t.autofocus){var n=l();t.autofocus=n==e||null!=e.getAttribute("autofocus")&&n==document.body}var i;if(e.form&&(Ql(e.form,"submit",r),!t.leaveSubmitMethodAlone)){var o=e.form;i=o.submit;try{var s=o.submit=function(){r(),o.submit=i,o.submit(),o.submit=s}}catch(e){}}t.finishInit=function(t){t.save=r,t.getTextArea=function(){return e},t.toTextArea=function(){t.toTextArea=isNaN,r(),e.parentNode.removeChild(t.getWrapperElement()),e.style.display="",e.form&&(ke(e.form,"submit",r),"function"==typeof e.form.submit&&(e.form.submit=i))}},e.style.display="none";var a=jo(function(t){return e.parentNode.insertBefore(t,e.nextSibling)},t);return a},function(e){e.off=ke,e.on=Ql,e.wheelEventPixels=Pn,e.Doc=Ds,e.splitLines=es,e.countColumn=f,e.findColumn=d,e.isWordChar=w,e.Pass=Bl,e.signal=Te,e.Line=fs,e.changeEnd=Bn,e.scrollbarModel=ws,e.Pos=E,e.cmpPos=P,e.modes=is,e.mimeModes=os,e.resolveMode=Ge,e.getMode=Ue,e.modeExtensions=ls,e.extendMode=Ve,e.copyState=Ke,e.startState=Xe,e.innerMode=je,e.commands=Bs,e.keyMap=Rs,e.keyName=ao,e.isModifierKey=lo,e.lookupKey=oo,e.normalizeKeyMap=io,e.StringStream=ss,e.SharedTextMarker=As,e.TextMarker=Os,e.LineWidget=Ms,e.e_preventDefault=We,e.e_stopPropagation=De,e.e_stop=Fe,e.addClass=s,e.contains=o,e.rmClass=Fl,e.keyNames=Es}(jo),jo.version="5.30.0",jo});
      !function(e){"object"==typeof exports&&"object"==typeof module?e(require("../../lib/codemirror")):"function"==typeof define&&define.amd?define(["../../lib/codemirror"],e):e(CodeMirror)}(function(e){"use strict";function t(e,t,n,r,o,a){this.indented=e,this.column=t,this.type=n,this.info=r,this.align=o,this.prev=a}function n(e,n,r,o){var a=e.indented;return e.context&&"statement"==e.context.type&&"statement"!=r&&(a=e.context.indented),e.context=new t(a,n,r,o,null,e.context)}function r(e){var t=e.context.type;return")"!=t&&"]"!=t&&"}"!=t||(e.indented=e.context.indented),e.context=e.context.prev}function o(e,t,n){return"variable"==t.prevToken||"type"==t.prevToken||(!!/\S(?:[^- ]>|[*\]])\s*$|\*$/.test(e.string.slice(0,n))||(!(!t.typeAtEndOfLine||e.column()!=e.indentation())||void 0))}function a(e){for(;;){if(!e||"top"==e.type)return!0;if("}"==e.type&&"namespace"!=e.prev.info)return!1;e=e.prev}}function i(e){for(var t={},n=e.split(" "),r=0;r<n.length;++r)t[n[r]]=!0;return t}function l(e,t){return"function"==typeof e?e(t):e.propertyIsEnumerable(t)}function s(e,t){if(!t.startOfLine)return!1;for(var n,r=null;n=e.peek();){if("\\"==n&&e.match(/^.$/)){r=s;break}if("/"==n&&e.match(/^\/[\/\*]/,!1))break;e.next()}return t.tokenize=r,"meta"}function c(e,t){return"type"==t.prevToken&&"type"}function u(e){return e.eatWhile(/[\w\.']/),"number"}function d(e,t){if(e.backUp(1),e.match(/(R|u8R|uR|UR|LR)/)){var n=e.match(/"([^\s\\()]{0,16})\(/);return!!n&&(t.cpp11RawStringDelim=n[1],t.tokenize=m,m(e,t))}return e.match(/(u8|u|U|L)/)?!!e.match(/["']/,!1)&&"string":(e.next(),!1)}function f(e){var t=/(\w+)::~?(\w+)$/.exec(e);return t&&t[1]==t[2]}function p(e,t){for(var n;null!=(n=e.next());)if('"'==n&&!e.eat('"')){t.tokenize=null;break}return"string"}function m(e,t){var n=t.cpp11RawStringDelim.replace(/[^\w\s]/g,"\\$&");return e.match(new RegExp(".*?\\)"+n+'"'))?t.tokenize=null:e.skipToEnd(),"string"}function h(t,n){function r(e){if(e)for(var t in e)e.hasOwnProperty(t)&&o.push(t)}"string"==typeof t&&(t=[t]);var o=[];r(n.keywords),r(n.types),r(n.builtin),r(n.atoms),o.length&&(n.helperType=t[0],e.registerHelper("hintWords",t[0],o));for(var a=0;a<t.length;++a)e.defineMIME(t[a],n)}function g(e,t){for(var n=!1;!e.eol();){if(!n&&e.match('"""')){t.tokenize=null;break}n="\\"==e.next()&&!n}return"string"}function y(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!e&&!o&&t.match('"')){a=!0;break}if(e&&t.match('"""')){a=!0;break}r=t.next(),!o&&"$"==r&&t.match("{")&&t.skipTo("}"),o=!o&&"\\"==r&&!e}return!a&&e||(n.tokenize=null),"string"}}function x(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!o&&t.match('"')&&("single"==e||t.match('""'))){a=!0;break}if(!o&&t.match("``")){w=x(e),a=!0;break}r=t.next(),o="single"==e&&!o&&"\\"==r}return a&&(n.tokenize=null),"string"}}e.defineMode("clike",function(i,s){function c(e,t){var n=e.next();if(S[n]){var r=S[n](e,t);if(!1!==r)return r}if('"'==n||"'"==n)return t.tokenize=u(n),t.tokenize(e,t);if(D.test(n))return p=n,null;if(L.test(n)){if(e.backUp(1),e.match(I))return"number";e.next()}if("/"==n){if(e.eat("*"))return t.tokenize=d,d(e,t);if(e.eat("/"))return e.skipToEnd(),"comment"}if(F.test(n)){for(;!e.match(/^\/[\/*]/,!1)&&e.eat(F););return"operator"}if(e.eatWhile(z),P)for(;e.match(P);)e.eatWhile(z);var o=e.current();return l(x,o)?(l(w,o)&&(p="newstatement"),l(v,o)&&(m=!0),"keyword"):l(b,o)?"type":l(k,o)?(l(w,o)&&(p="newstatement"),"builtin"):l(_,o)?"atom":"variable"}function u(e){return function(t,n){for(var r,o=!1,a=!1;null!=(r=t.next());){if(r==e&&!o){a=!0;break}o=!o&&"\\"==r}return(a||!o&&!C)&&(n.tokenize=null),"string"}}function d(e,t){for(var n,r=!1;n=e.next();){if("/"==n&&r){t.tokenize=null;break}r="*"==n}return"comment"}function f(e,t){s.typeFirstDefinitions&&e.eol()&&a(t.context)&&(t.typeAtEndOfLine=o(e,t,e.pos))}var p,m,h=i.indentUnit,g=s.statementIndentUnit||h,y=s.dontAlignCalls,x=s.keywords||{},b=s.types||{},k=s.builtin||{},w=s.blockKeywords||{},v=s.defKeywords||{},_=s.atoms||{},S=s.hooks||{},C=s.multiLineStrings,T=!1!==s.indentStatements,M=!1!==s.indentSwitch,P=s.namespaceSeparator,D=s.isPunctuationChar||/[\[\]{}\(\),;\:\.]/,L=s.numberStart||/[\d\.]/,I=s.number||/^(?:0x[a-f\d]+|0b[01]+|(?:\d+\.?\d*|\.\d+)(?:e[-+]?\d+)?)(u|ll?|l|f)?/i,F=s.isOperatorChar||/[+\-*&%=<>!?|\/]/,z=s.isIdentifierChar||/[\w\$_\xa1-\uffff]/;return{startState:function(e){return{tokenize:null,context:new t((e||0)-h,0,"top",null,!1),indented:0,startOfLine:!0,prevToken:null}},token:function(e,t){var i=t.context;if(e.sol()&&(null==i.align&&(i.align=!1),t.indented=e.indentation(),t.startOfLine=!0),e.eatSpace())return f(e,t),null;p=m=null;var l=(t.tokenize||c)(e,t);if("comment"==l||"meta"==l)return l;if(null==i.align&&(i.align=!0),";"==p||":"==p||","==p&&e.match(/^\s*(?:\/\/.*)?$/,!1))for(;"statement"==t.context.type;)r(t);else if("{"==p)n(t,e.column(),"}");else if("["==p)n(t,e.column(),"]");else if("("==p)n(t,e.column(),")");else if("}"==p){for(;"statement"==i.type;)i=r(t);for("}"==i.type&&(i=r(t));"statement"==i.type;)i=r(t)}else p==i.type?r(t):T&&(("}"==i.type||"top"==i.type)&&";"!=p||"statement"==i.type&&"newstatement"==p)&&n(t,e.column(),"statement",e.current());if("variable"==l&&("def"==t.prevToken||s.typeFirstDefinitions&&o(e,t,e.start)&&a(t.context)&&e.match(/^\s*\(/,!1))&&(l="def"),S.token){var u=S.token(e,t,l);void 0!==u&&(l=u)}return"def"==l&&!1===s.styleDefs&&(l="variable"),t.startOfLine=!1,t.prevToken=m?"def":l||p,f(e,t),l},indent:function(t,n){if(t.tokenize!=c&&null!=t.tokenize||t.typeAtEndOfLine)return e.Pass;var r=t.context,o=n&&n.charAt(0);if("statement"==r.type&&"}"==o&&(r=r.prev),s.dontIndentStatements)for(;"statement"==r.type&&s.dontIndentStatements.test(r.info);)r=r.prev;if(S.indent){var a=S.indent(t,r,n);if("number"==typeof a)return a}var i=o==r.type,l=r.prev&&"switch"==r.prev.info;if(s.allmanIndentation&&/[{(]/.test(o)){for(;"top"!=r.type&&"}"!=r.type;)r=r.prev;return r.indented}return"statement"==r.type?r.indented+("{"==o?0:g):!r.align||y&&")"==r.type?")"!=r.type||i?r.indented+(i?0:h)+(i||!l||/^(?:case|default)\b/.test(n)?0:h):r.indented+g:r.column+(i?0:1)},electricInput:M?/^\s*(?:case .*?:|default:|\{\}?|\})$/:/^\s*[{}]$/,blockCommentStart:"/*",blockCommentEnd:"*/",lineComment:"//",fold:"brace"}});var b="auto if break case register continue return default do sizeof static else struct switch extern typedef union for goto while enum const volatile",k="int long char short double float unsigned signed void size_t ptrdiff_t";h(["text/x-csrc","text/x-c","text/x-chdr"],{name:"clike",keywords:i(b),types:i(k+" bool _Complex _Bool float_t double_t intptr_t intmax_t int8_t int16_t int32_t int64_t uintptr_t uintmax_t uint8_t uint16_t uint32_t uint64_t"),blockKeywords:i("case do else for if switch while struct"),defKeywords:i("struct"),typeFirstDefinitions:!0,atoms:i("null true false"),hooks:{"#":s,"*":c},modeProps:{fold:["brace","include"]}}),h(["text/x-c++src","text/x-c++hdr"],{name:"clike",keywords:i(b+" asm dynamic_cast namespace reinterpret_cast try explicit new static_cast typeid catch operator template typename class friend private this using const_cast inline public throw virtual delete mutable protected alignas alignof constexpr decltype nullptr noexcept thread_local final static_assert override"),types:i(k+" bool wchar_t"),blockKeywords:i("catch class do else finally for if struct switch try while"),defKeywords:i("class namespace struct enum union"),typeFirstDefinitions:!0,atoms:i("true false null"),dontIndentStatements:/^template$/,isIdentifierChar:/[\w\$_~\xa1-\uffff]/,hooks:{"#":s,"*":c,u:d,U:d,L:d,R:d,0:u,1:u,2:u,3:u,4:u,5:u,6:u,7:u,8:u,9:u,token:function(e,t,n){if("variable"==n&&"("==e.peek()&&(";"==t.prevToken||null==t.prevToken||"}"==t.prevToken)&&f(e.current()))return"def"}},namespaceSeparator:"::",modeProps:{fold:["brace","include"]}}),h("text/x-java",{name:"clike",keywords:i("abstract assert break case catch class const continue default do else enum extends final finally float for goto if implements import instanceof interface native new package private protected public return static strictfp super switch synchronized this throw throws transient try volatile while @interface"),types:i("byte short int long float double boolean char void Boolean Byte Character Double Float Integer Long Number Object Short String StringBuffer StringBuilder Void"),blockKeywords:i("catch class do else finally for if switch try while"),defKeywords:i("class interface package enum @interface"),typeFirstDefinitions:!0,atoms:i("true false null"),number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,hooks:{"@":function(e){return!e.match("interface",!1)&&(e.eatWhile(/[\w\$_]/),"meta")}},modeProps:{fold:["brace","import"]}}),h("text/x-csharp",{name:"clike",keywords:i("abstract as async await base break case catch checked class const continue default delegate do else enum event explicit extern finally fixed for foreach goto if implicit in interface internal is lock namespace new operator out override params private protected public readonly ref return sealed sizeof stackalloc static struct switch this throw try typeof unchecked unsafe using virtual void volatile while add alias ascending descending dynamic from get global group into join let orderby partial remove select set value var yield"),types:i("Action Boolean Byte Char DateTime DateTimeOffset Decimal Double Func Guid Int16 Int32 Int64 Object SByte Single String Task TimeSpan UInt16 UInt32 UInt64 bool byte char decimal double short int long object sbyte float string ushort uint ulong"),blockKeywords:i("catch class do else finally for foreach if struct switch try while"),defKeywords:i("class interface namespace struct var"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"@":function(e,t){return e.eat('"')?(t.tokenize=p,p(e,t)):(e.eatWhile(/[\w\$_]/),"meta")}}}),h("text/x-scala",{name:"clike",keywords:i("abstract case catch class def do else extends final finally for forSome if implicit import lazy match new null object override package private protected return sealed super this throw trait try type val var while with yield _ assert assume require print println printf readLine readBoolean readByte readShort readChar readInt readLong readFloat readDouble"),types:i("AnyVal App Application Array BufferedIterator BigDecimal BigInt Char Console Either Enumeration Equiv Error Exception Fractional Function IndexedSeq Int Integral Iterable Iterator List Map Numeric Nil NotNull Option Ordered Ordering PartialFunction PartialOrdering Product Proxy Range Responder Seq Serializable Set Specializable Stream StringBuilder StringContext Symbol Throwable Traversable TraversableOnce Tuple Unit Vector Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),multiLineStrings:!0,blockKeywords:i("catch class enum do else finally for forSome if match switch try while"),defKeywords:i("class enum def object package trait type val var"),atoms:i("true false null"),indentStatements:!1,indentSwitch:!1,isOperatorChar:/[+\-*&%=<>!?|\/#:@]/,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return!!e.match('""')&&(t.tokenize=g,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},"=":function(e,n){var r=n.context;return!("}"!=r.type||!r.align||!e.eat(">"))&&(n.context=new t(r.indented,r.column,r.type,r.info,null,r.prev),"operator")}},modeProps:{closeBrackets:{triples:'"'}}}),h("text/x-kotlin",{name:"clike",keywords:i("package as typealias class interface this super val var fun for is in This throw return break continue object if else while do try when !in !is as? file import where by get set abstract enum open inner override private public internal protected catch finally out final vararg reified dynamic companion constructor init sealed field property receiver param sparam lateinit data inline noinline tailrec external annotation crossinline const operator infix suspend"),types:i("Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),intendSwitch:!1,indentStatements:!1,multiLineStrings:!0,number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,blockKeywords:i("catch class do else finally for if where try while enum"),defKeywords:i("class val var object package interface fun"),atoms:i("true false null this"),hooks:{'"':function(e,t){return t.tokenize=y(e.match('""')),t.tokenize(e,t)}},modeProps:{closeBrackets:{triples:'"'}}}),h(["x-shader/x-vertex","x-shader/x-fragment"],{name:"clike",keywords:i("sampler1D sampler2D sampler3D samplerCube sampler1DShadow sampler2DShadow const attribute uniform varying break continue discard return for while do if else struct in out inout"),types:i("float int bool void vec2 vec3 vec4 ivec2 ivec3 ivec4 bvec2 bvec3 bvec4 mat2 mat3 mat4"),blockKeywords:i("for while do if else struct"),builtin:i("radians degrees sin cos tan asin acos atan pow exp log exp2 sqrt inversesqrt abs sign floor ceil fract mod min max clamp mix step smoothstep length distance dot cross normalize ftransform faceforward reflect refract matrixCompMult lessThan lessThanEqual greaterThan greaterThanEqual equal notEqual any all not texture1D texture1DProj texture1DLod texture1DProjLod texture2D texture2DProj texture2DLod texture2DProjLod texture3D texture3DProj texture3DLod texture3DProjLod textureCube textureCubeLod shadow1D shadow2D shadow1DProj shadow2DProj shadow1DLod shadow2DLod shadow1DProjLod shadow2DProjLod dFdx dFdy fwidth noise1 noise2 noise3 noise4"),atoms:i("true false gl_FragColor gl_SecondaryColor gl_Normal gl_Vertex gl_MultiTexCoord0 gl_MultiTexCoord1 gl_MultiTexCoord2 gl_MultiTexCoord3 gl_MultiTexCoord4 gl_MultiTexCoord5 gl_MultiTexCoord6 gl_MultiTexCoord7 gl_FogCoord gl_PointCoord gl_Position gl_PointSize gl_ClipVertex gl_FrontColor gl_BackColor gl_FrontSecondaryColor gl_BackSecondaryColor gl_TexCoord gl_FogFragCoord gl_FragCoord gl_FrontFacing gl_FragData gl_FragDepth gl_ModelViewMatrix gl_ProjectionMatrix gl_ModelViewProjectionMatrix gl_TextureMatrix gl_NormalMatrix gl_ModelViewMatrixInverse gl_ProjectionMatrixInverse gl_ModelViewProjectionMatrixInverse gl_TexureMatrixTranspose gl_ModelViewMatrixInverseTranspose gl_ProjectionMatrixInverseTranspose gl_ModelViewProjectionMatrixInverseTranspose gl_TextureMatrixInverseTranspose gl_NormalScale gl_DepthRange gl_ClipPlane gl_Point gl_FrontMaterial gl_BackMaterial gl_LightSource gl_LightModel gl_FrontLightModelProduct gl_BackLightModelProduct gl_TextureColor gl_EyePlaneS gl_EyePlaneT gl_EyePlaneR gl_EyePlaneQ gl_FogParameters gl_MaxLights gl_MaxClipPlanes gl_MaxTextureUnits gl_MaxTextureCoords gl_MaxVertexAttribs gl_MaxVertexUniformComponents gl_MaxVaryingFloats gl_MaxVertexTextureImageUnits gl_MaxTextureImageUnits gl_MaxFragmentUniformComponents gl_MaxCombineTextureImageUnits gl_MaxDrawBuffers"),indentSwitch:!1,hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-nesc",{name:"clike",keywords:i(b+"as atomic async call command component components configuration event generic implementation includes interface module new norace nx_struct nx_union post provides signal task uses abstract extends"),types:i(k),blockKeywords:i("case do else for if switch while struct"),atoms:i("null true false"),hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-objectivec",{name:"clike",keywords:i(b+"inline restrict _Bool _Complex _Imaginary BOOL Class bycopy byref id IMP in inout nil oneway out Protocol SEL self super atomic nonatomic retain copy readwrite readonly"),types:i(k),atoms:i("YES NO NULL NILL ON OFF true false"),hooks:{"@":function(e){return e.eatWhile(/[\w\$]/),"keyword"},"#":s,indent:function(e,t,n){if("statement"==t.type&&/^@\w/.test(n))return t.indented}},modeProps:{fold:"brace"}}),h("text/x-squirrel",{name:"clike",keywords:i("base break clone continue const default delete enum extends function in class foreach local resume return this throw typeof yield constructor instanceof static"),types:i(k),blockKeywords:i("case catch class else for foreach if switch try while"),defKeywords:i("function local class"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"#":s},modeProps:{fold:["brace","include"]}});var w=null;h("text/x-ceylon",{name:"clike",keywords:i("abstracts alias assembly assert assign break case catch class continue dynamic else exists extends finally for function given if import in interface is let module new nonempty object of out outer package return satisfies super switch then this throw try value void while"),types:function(e){var t=e.charAt(0);return t===t.toUpperCase()&&t!==t.toLowerCase()},blockKeywords:i("case catch class dynamic else finally for function if interface module new object switch try while"),defKeywords:i("class dynamic function interface module object package value"),builtin:i("abstract actual aliased annotation by default deprecated doc final formal late license native optional sealed see serializable shared suppressWarnings tagged throws variable"),isPunctuationChar:/[\[\]{}\(\),;\:\.`]/,isOperatorChar:/[+\-*&%=<>!?|^~:\/]/,numberStart:/[\d#$]/,number:/^(?:#[\da-fA-F_]+|\$[01_]+|[\d_]+[kMGTPmunpf]?|[\d_]+\.[\d_]+(?:[eE][-+]?\d+|[kMGTPmunpf]|)|)/i,multiLineStrings:!0,typeFirstDefinitions:!0,atoms:i("true false null larger smaller equal empty finished"),indentSwitch:!1,styleDefs:!1,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return t.tokenize=x(e.match('""')?"triple":"single"),t.tokenize(e,t)},"`":function(e,t){return!(!w||!e.match("`"))&&(t.tokenize=w,w=null,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},token:function(e,t,n){if(("variable"==n||"type"==n)&&"."==t.prevToken)return"variable-2"}},modeProps:{fold:["brace","import"],closeBrackets:{triples:'"'}}})});
      // -------------------------------------------------------------------------
//  Part of the CodeChecker project, under the Apache License v2.0 with
//  LLVM Exceptions. See LICENSE for license information.
//  SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
// -------------------------------------------------------------------------

var BugViewer = {
  _files : [],
  _reports : [],
  _lineWidgets : [],
  _navigationMenuItems : [],
  _sourceFileData : null,
  _currentReport : null,
  _lastBugEvent  : null,

  init : function (files, reports) {
    this._files = files;
    this._reports = reports;

    this.initEscapeChars();
  },

  initEscapeChars : function () {
    this.escapeChars = {
      ' ' : 'nbsp',
      '<' : 'lt',
      '>' : 'gt',
      '"' : 'quot',
      '&' : 'amp'
    };

    var regexString = '[';
    for (var key in this.escapeChars) {
      regexString += key;
    }
    regexString += ']';

    this.escapeRegExp = new RegExp( regexString, 'g');
  },

  escapeHTML : function (str) {
    var that = this;

    return str.replace(this.escapeRegExp, function (m) {
      return '&' + that.escapeChars[m] + ';';
    });
  },

  initByUrl : function () {
    if (!this._reports) return;

    var state = {};
    window.location.hash.substr(1).split('&').forEach(function (s) {
      var parts = s.split('=');
      state[parts[0]] = parts[1];
    });

    for (var key in this._reports) {
      var report = this._reports[key];
      if (report.reportHash === state['reportHash']) {
        this.navigate(report);
        return;
      }
    }

    this.navigate(this._reports[0]);
  },

  create : function () {
    this._content = document.getElementById('editor-wrapper');
    this._filepath = document.getElementById('file-path');
    this._checkerName = document.getElementById('checker-name');
    this._reviewStatusWrapper =
      document.getElementById('review-status-wrapper');
    this._reviewStatus = document.getElementById('review-status');
    this._editor = document.getElementById('editor');

    this._codeMirror = CodeMirror(this._editor, {
      mode: 'text/x-c++src',
      matchBrackets : true,
      lineNumbers : true,
      readOnly : true,
      foldGutter : true,
      extraKeys : {},
      viewportMargin : 100
    });

    this._createNavigationMenu();
  },

  navigate : function (report, item) {
    if (!item) {
      var items = this._navigationMenuItems.filter(function (navItem) {
        return navItem.report.reportHash === report.reportHash;
      });

      if (!items.length) return;

      item = items[0].widget;
    }

    this._selectedReport.classList.remove('active');
    this._selectedReport = item;
    this._selectedReport.classList.add('active');
    this.setReport(report);
  },

  _createNavigationMenu : function () {
    var that = this;

    var nav = document.getElementById('report-nav');
    var list = document.createElement('ul');
    this._reports.forEach(function (report) {
      var events = report['events'];
      var lastBugEvent = events[events.length - 1];
      var item = document.createElement('li');

      var severity = document.createElement('i');
      severity.className = 'severity-' + report.severity.toLowerCase();

      item.appendChild(severity);
      item.appendChild(document.createTextNode(lastBugEvent.message));

      item.addEventListener('click', function () {
        that.navigate(report, item);
      })
      list.appendChild(item);
      that._navigationMenuItems.push({ report : report, widget : item });
    });

    if (!this._selectedReport && list.childNodes.length) {
      this._selectedReport = list.childNodes[0];
      this._selectedReport.classList.add('active');
    }

    nav.appendChild(list);
  },

  setReport : function (report) {
    this._currentReport = report;
    var events = report['events'];
    var lastBugEvent = events[events.length - 1];
    this.setCurrentBugEvent(lastBugEvent, events.length - 1);
    this.setCheckerName(report.checkerName);
    this.setReviewStatus(report.reviewStatus);

    window.location.hash = '#reportHash=' + report.reportHash;
  },

  setCurrentBugEvent : function (event, idx) {
    this._currentBugEvent = event;
    this.setSourceFileData(this._files[event.location.file]);
    this.drawBugPath();

    this.jumpTo(event.location.line, 0);
    this.highlightBugEvent(event, idx);
  },

  highlightBugEvent : function (event, idx) {
    this._lineWidgets.forEach(function (widget) {
      var lineIdx = widget.node.getAttribute('idx');
      if (parseInt(lineIdx) === idx) {
        widget.node.classList.add('current');
      }
    });
  },

  setCheckerName : function (checkerName) {
    this._checkerName.innerHTML = checkerName;
  },

  setReviewStatus : function (status) {
    if (status) {
      var className =
        'review-status-' + status.toLowerCase().split(' ').join('-');
      this._reviewStatus.className = "review-status " + className;

      this._reviewStatus.innerHTML = status;
      this._reviewStatusWrapper.style.display = 'block';
    } else {
      this._reviewStatusWrapper.style.display = 'none';
    }
  },

  setSourceFileData : function (file) {
    if (this._sourceFileData && file.id === this._sourceFileData.id) {
      return;
    }

    this._sourceFileData = file;
    this._filepath.innerHTML = file.path;
    this._codeMirror.doc.setValue(file.content);
    this._refresh();
  },

  _refresh : function () {
    var that = this;
    setTimeout(function () {
      var fullHeight = parseInt(that._content.clientHeight);
      var headerHeight = that._filepath.clientHeight;

      that._codeMirror.setSize('auto', fullHeight - headerHeight);
      that._codeMirror.refresh();
    }, 200);
  },

  clearBubbles : function () {
    this._lineWidgets.forEach(function (widget) { widget.clear(); });
    this._lineWidgets = [];
  },

  getMessage : function (event, kind) {
    if (kind === 'macro') {
      var name = 'macro expansion' + (event.name ? ': ' + event.name : '');

      return '<span class="tag macro">' + name + '</span>'
        + this.escapeHTML(event.expansion).replace(/(?:\r\n|\r|\n)/g, '<br>');
    } else if (kind === 'note') {
      return '<span class="tag note">note</span>'
        +  this.escapeHTML(event.message).replace(/(?:\r\n|\r|\n)/g, '<br>');
    }
  },

  addExtraPathEvents : function (events, kind) {
    var that = this;

    if (!events) {
      return;
    }

    events.forEach(function (event) {
      if (event.location.file !== that._currentBugEvent.location.file) {
        return;
      }

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + kind);

      var msg = document.createElement('span');
      msg.innerHTML = that.getMessage(event, kind);
      element.appendChild(msg);

      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  drawBugPath : function () {
    var that = this;

    this.clearBubbles();

    this.addExtraPathEvents(this._currentReport.macros, 'macro');
    this.addExtraPathEvents(this._currentReport.notes, 'note');

    // Processing bug path events.
    var currentEvents = this._currentReport.events;
    currentEvents.forEach(function (event, step) {
      if (event.location.file !== that._currentBugEvent.location.file)
        return;

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';
      var type = step === currentEvents.length - 1 ? 'error' : 'info';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + type);
      element.setAttribute('idx', step);

      var enumeration = document.createElement('span');
      enumeration.setAttribute('class', 'checker-enum ' + type);
      enumeration.innerHTML = step + 1;

      if (currentEvents.length > 1)
        element.appendChild(enumeration);

      var prevBugEvent = step - 1;
      if (step > 0) {
        var prevBug = document.createElement('span');
        prevBug.setAttribute('class', 'arrow left-arrow');
        prevBug.addEventListener('click', function () {
          var event = currentEvents[prevBugEvent];
          that.setCurrentBugEvent(event, prevBugEvent);
        });
        element.appendChild(prevBug);
      }

      var msg = document.createElement('span');
      msg.innerHTML = that.escapeHTML(event.message)
        .replace(/(?:\r\n|\r|\n)/g, '<br>');

      element.appendChild(msg);

      var nextBugEvent = step + 1;
      if (nextBugEvent < currentEvents.length) {
        var nextBug = document.createElement('span');
        nextBug.setAttribute('class', 'arrow right-arrow');
        nextBug.addEventListener('click', function () {
          var event = currentEvents[nextBugEvent];
          that.setCurrentBugEvent(event, nextBugEvent);
        });
        element.appendChild(nextBug);
      }


      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  jumpTo : function (line, column) {
    var that = this;

    setTimeout(function () {
      var selPosPixel
        = that._codeMirror.charCoords({ line : line, ch : column }, 'local');
      var editorSize = {
        width  : that._editor.clientWidth,
        height : that._editor.clientHeight
      };

      that._codeMirror.scrollIntoView({
        top    : selPosPixel.top - 100,
        bottom : selPosPixel.top + editorSize.height - 150,
        left   : selPosPixel.left < editorSize.width - 100
               ? 0
               : selPosPixel.left - 50,
        right  : selPosPixel.left < editorSize.width - 100
               ? 10
               : selPosPixel.left + editorSize.width - 100
      });
    }, 0);
  }
}


      var data = {"files": {"0": {"id": 0, "path": "/src/drivers/md/md.c", "content": "// SPDX-License-Identifier: GPL-2.0-or-later\n/*\n   md.c : Multiple Devices driver for Linux\n     Copyright (C) 1998, 1999, 2000 Ingo Molnar\n\n     completely rewritten, based on the MD driver code from Marc Zyngier\n\n   Changes:\n\n   - RAID-1/RAID-5 extensions by Miguel de Icaza, Gadi Oxman, Ingo Molnar\n   - RAID-6 extensions by H. Peter Anvin <hpa@zytor.com>\n   - boot support for linear and striped mode by Harald Hoyer <HarryH@Royal.Net>\n   - kerneld support by Boris Tobotras <boris@xtalk.msk.su>\n   - kmod support by: Cyrus Durgin\n   - RAID0 bugfixes: Mark Anthony Lisher <markal@iname.com>\n   - Devfs support by Richard Gooch <rgooch@atnf.csiro.au>\n\n   - lots of fixes and improvements to the RAID1/RAID5 and generic\n     RAID code (such as request based resynchronization):\n\n     Neil Brown <neilb@cse.unsw.edu.au>.\n\n   - persistent bitmap code\n     Copyright (C) 2003-2004, Paul Clements, SteelEye Technology, Inc.\n\n\n   Errors, Warnings, etc.\n   Please use:\n     pr_crit() for error conditions that risk data loss\n     pr_err() for error conditions that are unexpected, like an IO error\n         or internal inconsistency\n     pr_warn() for error conditions that could have been predicated, like\n         adding a device to an array when it has incompatible metadata\n     pr_info() for every interesting, very rare events, like an array starting\n         or stopping, or resync starting or stopping\n     pr_debug() for everything else.\n\n*/\n\n#include <linux/sched/mm.h>\n#include <linux/sched/signal.h>\n#include <linux/kthread.h>\n#include <linux/blkdev.h>\n#include <linux/badblocks.h>\n#include <linux/sysctl.h>\n#include <linux/seq_file.h>\n#include <linux/fs.h>\n#include <linux/poll.h>\n#include <linux/ctype.h>\n#include <linux/string.h>\n#include <linux/hdreg.h>\n#include <linux/proc_fs.h>\n#include <linux/random.h>\n#include <linux/module.h>\n#include <linux/reboot.h>\n#include <linux/file.h>\n#include <linux/compat.h>\n#include <linux/delay.h>\n#include <linux/raid/md_p.h>\n#include <linux/raid/md_u.h>\n#include <linux/raid/detect.h>\n#include <linux/slab.h>\n#include <linux/percpu-refcount.h>\n#include <linux/part_stat.h>\n\n#include <trace/events/block.h>\n#include \"md.h\"\n#include \"md-bitmap.h\"\n#include \"md-cluster.h\"\n\n/* pers_list is a list of registered personalities protected\n * by pers_lock.\n * pers_lock does extra service to protect accesses to\n * mddev->thread when the mutex cannot be held.\n */\nstatic LIST_HEAD(pers_list);\nstatic DEFINE_SPINLOCK(pers_lock);\n\nstatic struct kobj_type md_ktype;\n\nstruct md_cluster_operations *md_cluster_ops;\nEXPORT_SYMBOL(md_cluster_ops);\nstatic struct module *md_cluster_mod;\n\nstatic DECLARE_WAIT_QUEUE_HEAD(resync_wait);\nstatic struct workqueue_struct *md_wq;\nstatic struct workqueue_struct *md_misc_wq;\nstatic struct workqueue_struct *md_rdev_misc_wq;\n\nstatic int remove_and_add_spares(struct mddev *mddev,\n\t\t\t\t struct md_rdev *this);\nstatic void mddev_detach(struct mddev *mddev);\n\n/*\n * Default number of read corrections we'll attempt on an rdev\n * before ejecting it from the array. We divide the read error\n * count by 2 for every hour elapsed between read errors.\n */\n#define MD_DEFAULT_MAX_CORRECTED_READ_ERRORS 20\n/* Default safemode delay: 200 msec */\n#define DEFAULT_SAFEMODE_DELAY ((200 * HZ)/1000 +1)\n/*\n * Current RAID-1,4,5 parallel reconstruction 'guaranteed speed limit'\n * is 1000 KB/sec, so the extra system load does not show up that much.\n * Increase it if you want to have more _guaranteed_ speed. Note that\n * the RAID driver will use the maximum available bandwidth if the IO\n * subsystem is idle. There is also an 'absolute maximum' reconstruction\n * speed limit - in case reconstruction slows down your system despite\n * idle IO detection.\n *\n * you can change it via /proc/sys/dev/raid/speed_limit_min and _max.\n * or /sys/block/mdX/md/sync_speed_{min,max}\n */\n\nstatic int sysctl_speed_limit_min = 1000;\nstatic int sysctl_speed_limit_max = 200000;\nstatic inline int speed_min(struct mddev *mddev)\n{\n\treturn mddev->sync_speed_min ?\n\t\tmddev->sync_speed_min : sysctl_speed_limit_min;\n}\n\nstatic inline int speed_max(struct mddev *mddev)\n{\n\treturn mddev->sync_speed_max ?\n\t\tmddev->sync_speed_max : sysctl_speed_limit_max;\n}\n\nstatic void rdev_uninit_serial(struct md_rdev *rdev)\n{\n\tif (!test_and_clear_bit(CollisionCheck, &rdev->flags))\n\t\treturn;\n\n\tkvfree(rdev->serial);\n\trdev->serial = NULL;\n}\n\nstatic void rdevs_uninit_serial(struct mddev *mddev)\n{\n\tstruct md_rdev *rdev;\n\n\trdev_for_each(rdev, mddev)\n\t\trdev_uninit_serial(rdev);\n}\n\nstatic int rdev_init_serial(struct md_rdev *rdev)\n{\n\t/* serial_nums equals with BARRIER_BUCKETS_NR */\n\tint i, serial_nums = 1 << ((PAGE_SHIFT - ilog2(sizeof(atomic_t))));\n\tstruct serial_in_rdev *serial = NULL;\n\n\tif (test_bit(CollisionCheck, &rdev->flags))\n\t\treturn 0;\n\n\tserial = kvmalloc(sizeof(struct serial_in_rdev) * serial_nums,\n\t\t\t  GFP_KERNEL);\n\tif (!serial)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < serial_nums; i++) {\n\t\tstruct serial_in_rdev *serial_tmp = &serial[i];\n\n\t\tspin_lock_init(&serial_tmp->serial_lock);\n\t\tserial_tmp->serial_rb = RB_ROOT_CACHED;\n\t\tinit_waitqueue_head(&serial_tmp->serial_io_wait);\n\t}\n\n\trdev->serial = serial;\n\tset_bit(CollisionCheck, &rdev->flags);\n\n\treturn 0;\n}\n\nstatic int rdevs_init_serial(struct mddev *mddev)\n{\n\tstruct md_rdev *rdev;\n\tint ret = 0;\n\n\trdev_for_each(rdev, mddev) {\n\t\tret = rdev_init_serial(rdev);\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\n\t/* Free all resources if pool is not existed */\n\tif (ret && !mddev->serial_info_pool)\n\t\trdevs_uninit_serial(mddev);\n\n\treturn ret;\n}\n\n/*\n * rdev needs to enable serial stuffs if it meets the conditions:\n * 1. it is multi-queue device flaged with writemostly.\n * 2. the write-behind mode is enabled.\n */\nstatic int rdev_need_serial(struct md_rdev *rdev)\n{\n\treturn (rdev && rdev->mddev->bitmap_info.max_write_behind > 0 &&\n\t\trdev->bdev->bd_disk->queue->nr_hw_queues != 1 &&\n\t\ttest_bit(WriteMostly, &rdev->flags));\n}\n\n/*\n * Init resource for rdev(s), then create serial_info_pool if:\n * 1. rdev is the first device which return true from rdev_enable_serial.\n * 2. rdev is NULL, means we want to enable serialization for all rdevs.\n */\nvoid mddev_create_serial_pool(struct mddev *mddev, struct md_rdev *rdev,\n\t\t\t      bool is_suspend)\n{\n\tint ret = 0;\n\n\tif (rdev && !rdev_need_serial(rdev) &&\n\t    !test_bit(CollisionCheck, &rdev->flags))\n\t\treturn;\n\n\tif (!is_suspend)\n\t\tmddev_suspend(mddev);\n\n\tif (!rdev)\n\t\tret = rdevs_init_serial(mddev);\n\telse\n\t\tret = rdev_init_serial(rdev);\n\tif (ret)\n\t\tgoto abort;\n\n\tif (mddev->serial_info_pool == NULL) {\n\t\t/*\n\t\t * already in memalloc noio context by\n\t\t * mddev_suspend()\n\t\t */\n\t\tmddev->serial_info_pool =\n\t\t\tmempool_create_kmalloc_pool(NR_SERIAL_INFOS,\n\t\t\t\t\t\tsizeof(struct serial_info));\n\t\tif (!mddev->serial_info_pool) {\n\t\t\trdevs_uninit_serial(mddev);\n\t\t\tpr_err(\"can't alloc memory pool for serialization\\n\");\n\t\t}\n\t}\n\nabort:\n\tif (!is_suspend)\n\t\tmddev_resume(mddev);\n}\n\n/*\n * Free resource from rdev(s), and destroy serial_info_pool under conditions:\n * 1. rdev is the last device flaged with CollisionCheck.\n * 2. when bitmap is destroyed while policy is not enabled.\n * 3. for disable policy, the pool is destroyed only when no rdev needs it.\n */\nvoid mddev_destroy_serial_pool(struct mddev *mddev, struct md_rdev *rdev,\n\t\t\t       bool is_suspend)\n{\n\tif (rdev && !test_bit(CollisionCheck, &rdev->flags))\n\t\treturn;\n\n\tif (mddev->serial_info_pool) {\n\t\tstruct md_rdev *temp;\n\t\tint num = 0; /* used to track if other rdevs need the pool */\n\n\t\tif (!is_suspend)\n\t\t\tmddev_suspend(mddev);\n\t\trdev_for_each(temp, mddev) {\n\t\t\tif (!rdev) {\n\t\t\t\tif (!mddev->serialize_policy ||\n\t\t\t\t    !rdev_need_serial(temp))\n\t\t\t\t\trdev_uninit_serial(temp);\n\t\t\t\telse\n\t\t\t\t\tnum++;\n\t\t\t} else if (temp != rdev &&\n\t\t\t\t   test_bit(CollisionCheck, &temp->flags))\n\t\t\t\tnum++;\n\t\t}\n\n\t\tif (rdev)\n\t\t\trdev_uninit_serial(rdev);\n\n\t\tif (num)\n\t\t\tpr_info(\"The mempool could be used by other devices\\n\");\n\t\telse {\n\t\t\tmempool_destroy(mddev->serial_info_pool);\n\t\t\tmddev->serial_info_pool = NULL;\n\t\t}\n\t\tif (!is_suspend)\n\t\t\tmddev_resume(mddev);\n\t}\n}\n\nstatic struct ctl_table_header *raid_table_header;\n\nstatic struct ctl_table raid_table[] = {\n\t{\n\t\t.procname\t= \"speed_limit_min\",\n\t\t.data\t\t= &sysctl_speed_limit_min,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= S_IRUGO|S_IWUSR,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{\n\t\t.procname\t= \"speed_limit_max\",\n\t\t.data\t\t= &sysctl_speed_limit_max,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= S_IRUGO|S_IWUSR,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{ }\n};\n\nstatic struct ctl_table raid_dir_table[] = {\n\t{\n\t\t.procname\t= \"raid\",\n\t\t.maxlen\t\t= 0,\n\t\t.mode\t\t= S_IRUGO|S_IXUGO,\n\t\t.child\t\t= raid_table,\n\t},\n\t{ }\n};\n\nstatic struct ctl_table raid_root_table[] = {\n\t{\n\t\t.procname\t= \"dev\",\n\t\t.maxlen\t\t= 0,\n\t\t.mode\t\t= 0555,\n\t\t.child\t\t= raid_dir_table,\n\t},\n\t{  }\n};\n\nstatic int start_readonly;\n\n/*\n * The original mechanism for creating an md device is to create\n * a device node in /dev and to open it.  This causes races with device-close.\n * The preferred method is to write to the \"new_array\" module parameter.\n * This can avoid races.\n * Setting create_on_open to false disables the original mechanism\n * so all the races disappear.\n */\nstatic bool create_on_open = true;\n\nstruct bio *bio_alloc_mddev(gfp_t gfp_mask, int nr_iovecs,\n\t\t\t    struct mddev *mddev)\n{\n\tif (!mddev || !bioset_initialized(&mddev->bio_set))\n\t\treturn bio_alloc(gfp_mask, nr_iovecs);\n\n\treturn bio_alloc_bioset(gfp_mask, nr_iovecs, &mddev->bio_set);\n}\nEXPORT_SYMBOL_GPL(bio_alloc_mddev);\n\nstatic struct bio *md_bio_alloc_sync(struct mddev *mddev)\n{\n\tif (!mddev || !bioset_initialized(&mddev->sync_set))\n\t\treturn bio_alloc(GFP_NOIO, 1);\n\n\treturn bio_alloc_bioset(GFP_NOIO, 1, &mddev->sync_set);\n}\n\n/*\n * We have a system wide 'event count' that is incremented\n * on any 'interesting' event, and readers of /proc/mdstat\n * can use 'poll' or 'select' to find out when the event\n * count increases.\n *\n * Events are:\n *  start array, stop array, error, add device, remove device,\n *  start build, activate spare\n */\nstatic DECLARE_WAIT_QUEUE_HEAD(md_event_waiters);\nstatic atomic_t md_event_count;\nvoid md_new_event(struct mddev *mddev)\n{\n\tatomic_inc(&md_event_count);\n\twake_up(&md_event_waiters);\n}\nEXPORT_SYMBOL_GPL(md_new_event);\n\n/*\n * Enables to iterate over all existing md arrays\n * all_mddevs_lock protects this list.\n */\nstatic LIST_HEAD(all_mddevs);\nstatic DEFINE_SPINLOCK(all_mddevs_lock);\n\n/*\n * iterates through all used mddevs in the system.\n * We take care to grab the all_mddevs_lock whenever navigating\n * the list, and to always hold a refcount when unlocked.\n * Any code which breaks out of this loop while own\n * a reference to the current mddev and must mddev_put it.\n */\n#define for_each_mddev(_mddev,_tmp)\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tfor (({ spin_lock(&all_mddevs_lock);\t\t\t\t\\\n\t\t_tmp = all_mddevs.next;\t\t\t\t\t\\\n\t\t_mddev = NULL;});\t\t\t\t\t\\\n\t     ({ if (_tmp != &all_mddevs)\t\t\t\t\\\n\t\t\tmddev_get(list_entry(_tmp, struct mddev, all_mddevs));\\\n\t\tspin_unlock(&all_mddevs_lock);\t\t\t\t\\\n\t\tif (_mddev) mddev_put(_mddev);\t\t\t\t\\\n\t\t_mddev = list_entry(_tmp, struct mddev, all_mddevs);\t\\\n\t\t_tmp != &all_mddevs;});\t\t\t\t\t\\\n\t     ({ spin_lock(&all_mddevs_lock);\t\t\t\t\\\n\t\t_tmp = _tmp->next;})\t\t\t\t\t\\\n\t\t)\n\n/* Rather than calling directly into the personality make_request function,\n * IO requests come here first so that we can check if the device is\n * being suspended pending a reconfiguration.\n * We hold a refcount over the call to ->make_request.  By the time that\n * call has finished, the bio has been linked into some internal structure\n * and so is visible to ->quiesce(), so we don't need the refcount any more.\n */\nstatic bool is_suspended(struct mddev *mddev, struct bio *bio)\n{\n\tif (mddev->suspended)\n\t\treturn true;\n\tif (bio_data_dir(bio) != WRITE)\n\t\treturn false;\n\tif (mddev->suspend_lo >= mddev->suspend_hi)\n\t\treturn false;\n\tif (bio->bi_iter.bi_sector >= mddev->suspend_hi)\n\t\treturn false;\n\tif (bio_end_sector(bio) < mddev->suspend_lo)\n\t\treturn false;\n\treturn true;\n}\n\nvoid md_handle_request(struct mddev *mddev, struct bio *bio)\n{\ncheck_suspended:\n\trcu_read_lock();\n\tif (is_suspended(mddev, bio)) {\n\t\tDEFINE_WAIT(__wait);\n\t\tfor (;;) {\n\t\t\tprepare_to_wait(&mddev->sb_wait, &__wait,\n\t\t\t\t\tTASK_UNINTERRUPTIBLE);\n\t\t\tif (!is_suspended(mddev, bio))\n\t\t\t\tbreak;\n\t\t\trcu_read_unlock();\n\t\t\tschedule();\n\t\t\trcu_read_lock();\n\t\t}\n\t\tfinish_wait(&mddev->sb_wait, &__wait);\n\t}\n\tatomic_inc(&mddev->active_io);\n\trcu_read_unlock();\n\n\tif (!mddev->pers->make_request(mddev, bio)) {\n\t\tatomic_dec(&mddev->active_io);\n\t\twake_up(&mddev->sb_wait);\n\t\tgoto check_suspended;\n\t}\n\n\tif (atomic_dec_and_test(&mddev->active_io) && mddev->suspended)\n\t\twake_up(&mddev->sb_wait);\n}\nEXPORT_SYMBOL(md_handle_request);\n\nstruct md_io {\n\tstruct mddev *mddev;\n\tbio_end_io_t *orig_bi_end_io;\n\tvoid *orig_bi_private;\n\tunsigned long start_time;\n\tstruct hd_struct *part;\n};\n\nstatic void md_end_io(struct bio *bio)\n{\n\tstruct md_io *md_io = bio->bi_private;\n\tstruct mddev *mddev = md_io->mddev;\n\n\tpart_end_io_acct(md_io->part, bio, md_io->start_time);\n\n\tbio->bi_end_io = md_io->orig_bi_end_io;\n\tbio->bi_private = md_io->orig_bi_private;\n\n\tmempool_free(md_io, &mddev->md_io_pool);\n\n\tif (bio->bi_end_io)\n\t\tbio->bi_end_io(bio);\n}\n\nstatic blk_qc_t md_submit_bio(struct bio *bio)\n{\n\tconst int rw = bio_data_dir(bio);\n\tstruct mddev *mddev = bio->bi_disk->private_data;\n\n\tif (mddev == NULL || mddev->pers == NULL) {\n\t\tbio_io_error(bio);\n\t\treturn BLK_QC_T_NONE;\n\t}\n\n\tif (unlikely(test_bit(MD_BROKEN, &mddev->flags)) && (rw == WRITE)) {\n\t\tbio_io_error(bio);\n\t\treturn BLK_QC_T_NONE;\n\t}\n\n\tblk_queue_split(&bio);\n\n\tif (mddev->ro == 1 && unlikely(rw == WRITE)) {\n\t\tif (bio_sectors(bio) != 0)\n\t\t\tbio->bi_status = BLK_STS_IOERR;\n\t\tbio_endio(bio);\n\t\treturn BLK_QC_T_NONE;\n\t}\n\n\tif (bio->bi_end_io != md_end_io) {\n\t\tstruct md_io *md_io;\n\n\t\tmd_io = mempool_alloc(&mddev->md_io_pool, GFP_NOIO);\n\t\tmd_io->mddev = mddev;\n\t\tmd_io->orig_bi_end_io = bio->bi_end_io;\n\t\tmd_io->orig_bi_private = bio->bi_private;\n\n\t\tbio->bi_end_io = md_end_io;\n\t\tbio->bi_private = md_io;\n\n\t\tmd_io->start_time = part_start_io_acct(mddev->gendisk,\n\t\t\t\t\t\t       &md_io->part, bio);\n\t}\n\n\t/* bio could be mergeable after passing to underlayer */\n\tbio->bi_opf &= ~REQ_NOMERGE;\n\n\tmd_handle_request(mddev, bio);\n\n\treturn BLK_QC_T_NONE;\n}\n\n/* mddev_suspend makes sure no new requests are submitted\n * to the device, and that any requests that have been submitted\n * are completely handled.\n * Once mddev_detach() is called and completes, the module will be\n * completely unused.\n */\nvoid mddev_suspend(struct mddev *mddev)\n{\n\tWARN_ON_ONCE(mddev->thread && current == mddev->thread->tsk);\n\tlockdep_assert_held(&mddev->reconfig_mutex);\n\tif (mddev->suspended++)\n\t\treturn;\n\tsynchronize_rcu();\n\twake_up(&mddev->sb_wait);\n\tset_bit(MD_ALLOW_SB_UPDATE, &mddev->flags);\n\tsmp_mb__after_atomic();\n\twait_event(mddev->sb_wait, atomic_read(&mddev->active_io) == 0);\n\tmddev->pers->quiesce(mddev, 1);\n\tclear_bit_unlock(MD_ALLOW_SB_UPDATE, &mddev->flags);\n\twait_event(mddev->sb_wait, !test_bit(MD_UPDATING_SB, &mddev->flags));\n\n\tdel_timer_sync(&mddev->safemode_timer);\n\t/* restrict memory reclaim I/O during raid array is suspend */\n\tmddev->noio_flag = memalloc_noio_save();\n}\nEXPORT_SYMBOL_GPL(mddev_suspend);\n\nvoid mddev_resume(struct mddev *mddev)\n{\n\t/* entred the memalloc scope from mddev_suspend() */\n\tmemalloc_noio_restore(mddev->noio_flag);\n\tlockdep_assert_held(&mddev->reconfig_mutex);\n\tif (--mddev->suspended)\n\t\treturn;\n\twake_up(&mddev->sb_wait);\n\tmddev->pers->quiesce(mddev, 0);\n\n\tset_bit(MD_RECOVERY_NEEDED, &mddev->recovery);\n\tmd_wakeup_thread(mddev->thread);\n\tmd_wakeup_thread(mddev->sync_thread); /* possibly kick off a reshape */\n}\nEXPORT_SYMBOL_GPL(mddev_resume);\n\n/*\n * Generic flush handling for md\n */\n\nstatic void md_end_flush(struct bio *bio)\n{\n\tstruct md_rdev *rdev = bio->bi_private;\n\tstruct mddev *mddev = rdev->mddev;\n\n\trdev_dec_pending(rdev, mddev);\n\n\tif (atomic_dec_and_test(&mddev->flush_pending)) {\n\t\t/* The pre-request flush has finished */\n\t\tqueue_work(md_wq, &mddev->flush_work);\n\t}\n\tbio_put(bio);\n}\n\nstatic void md_submit_flush_data(struct work_struct *ws);\n\nstatic void submit_flushes(struct work_struct *ws)\n{\n\tstruct mddev *mddev = container_of(ws, struct mddev, flush_work);\n\tstruct md_rdev *rdev;\n\n\tmddev->start_flush = ktime_get_boottime();\n\tINIT_WORK(&mddev->flush_work, md_submit_flush_data);\n\tatomic_set(&mddev->flush_pending, 1);\n\trcu_read_lock();\n\trdev_for_each_rcu(rdev, mddev)\n\t\tif (rdev->raid_disk >= 0 &&\n\t\t    !test_bit(Faulty, &rdev->flags)) {\n\t\t\t/* Take two references, one is dropped\n\t\t\t * when request finishes, one after\n\t\t\t * we reclaim rcu_read_lock\n\t\t\t */\n\t\t\tstruct bio *bi;\n\t\t\tatomic_inc(&rdev->nr_pending);\n\t\t\tatomic_inc(&rdev->nr_pending);\n\t\t\trcu_read_unlock();\n\t\t\tbi = bio_alloc_mddev(GFP_NOIO, 0, mddev);\n\t\t\tbi->bi_end_io = md_end_flush;\n\t\t\tbi->bi_private = rdev;\n\t\t\tbio_set_dev(bi, rdev->bdev);\n\t\t\tbi->bi_opf = REQ_OP_WRITE | REQ_PREFLUSH;\n\t\t\tatomic_inc(&mddev->flush_pending);\n\t\t\tsubmit_bio(bi);\n\t\t\trcu_read_lock();\n\t\t\trdev_dec_pending(rdev, mddev);\n\t\t}\n\trcu_read_unlock();\n\tif (atomic_dec_and_test(&mddev->flush_pending))\n\t\tqueue_work(md_wq, &mddev->flush_work);\n}\n\nstatic void md_submit_flush_data(struct work_struct *ws)\n{\n\tstruct mddev *mddev = container_of(ws, struct mddev, flush_work);\n\tstruct bio *bio = mddev->flush_bio;\n\n\t/*\n\t * must reset flush_bio before calling into md_handle_request to avoid a\n\t * deadlock, because other bios passed md_handle_request suspend check\n\t * could wait for this and below md_handle_request could wait for those\n\t * bios because of suspend check\n\t */\n\tmddev->last_flush = mddev->start_flush;\n\tmddev->flush_bio = NULL;\n\twake_up(&mddev->sb_wait);\n\n\tif (bio->bi_iter.bi_size == 0) {\n\t\t/* an empty barrier - all done */\n\t\tbio_endio(bio);\n\t} else {\n\t\tbio->bi_opf &= ~REQ_PREFLUSH;\n\t\tmd_handle_request(mddev, bio);\n\t}\n}\n\n/*\n * Manages consolidation of flushes and submitting any flushes needed for\n * a bio with REQ_PREFLUSH.  Returns true if the bio is finished or is\n * being finished in another context.  Returns false if the flushing is\n * complete but still needs the I/O portion of the bio to be processed.\n */\nbool md_flush_request(struct mddev *mddev, struct bio *bio)\n{\n\tktime_t start = ktime_get_boottime();\n\tspin_lock_irq(&mddev->lock);\n\twait_event_lock_irq(mddev->sb_wait,\n\t\t\t    !mddev->flush_bio ||\n\t\t\t    ktime_after(mddev->last_flush, start),\n\t\t\t    mddev->lock);\n\tif (!ktime_after(mddev->last_flush, start)) {\n\t\tWARN_ON(mddev->flush_bio);\n\t\tmddev->flush_bio = bio;\n\t\tbio = NULL;\n\t}\n\tspin_unlock_irq(&mddev->lock);\n\n\tif (!bio) {\n\t\tINIT_WORK(&mddev->flush_work, submit_flushes);\n\t\tqueue_work(md_wq, &mddev->flush_work);\n\t} else {\n\t\t/* flush was performed for some other bio while we waited. */\n\t\tif (bio->bi_iter.bi_size == 0)\n\t\t\t/* an empty barrier - all done */\n\t\t\tbio_endio(bio);\n\t\telse {\n\t\t\tbio->bi_opf &= ~REQ_PREFLUSH;\n\t\t\treturn false;\n\t\t}\n\t}\n\treturn true;\n}\nEXPORT_SYMBOL(md_flush_request);\n\nstatic inline struct mddev *mddev_get(struct mddev *mddev)\n{\n\tatomic_inc(&mddev->active);\n\treturn mddev;\n}\n\nstatic void mddev_delayed_delete(struct work_struct *ws);\n\nstatic void mddev_put(struct mddev *mddev)\n{\n\tif (!atomic_dec_and_lock(&mddev->active, &all_mddevs_lock))\n\t\treturn;\n\tif (!mddev->raid_disks && list_empty(&mddev->disks) &&\n\t    mddev->ctime == 0 && !mddev->hold_active) {\n\t\t/* Array is not configured at all, and not held active,\n\t\t * so destroy it */\n\t\tlist_del_init(&mddev->all_mddevs);\n\n\t\t/*\n\t\t * Call queue_work inside the spinlock so that\n\t\t * flush_workqueue() after mddev_find will succeed in waiting\n\t\t * for the work to be done.\n\t\t */\n\t\tINIT_WORK(&mddev->del_work, mddev_delayed_delete);\n\t\tqueue_work(md_misc_wq, &mddev->del_work);\n\t}\n\tspin_unlock(&all_mddevs_lock);\n}\n\nstatic void md_safemode_timeout(struct timer_list *t);\n\nvoid mddev_init(struct mddev *mddev)\n{\n\tkobject_init(&mddev->kobj, &md_ktype);\n\tmutex_init(&mddev->open_mutex);\n\tmutex_init(&mddev->reconfig_mutex);\n\tmutex_init(&mddev->bitmap_info.mutex);\n\tINIT_LIST_HEAD(&mddev->disks);\n\tINIT_LIST_HEAD(&mddev->all_mddevs);\n\ttimer_setup(&mddev->safemode_timer, md_safemode_timeout, 0);\n\tatomic_set(&mddev->active, 1);\n\tatomic_set(&mddev->openers, 0);\n\tatomic_set(&mddev->active_io, 0);\n\tspin_lock_init(&mddev->lock);\n\tatomic_set(&mddev->flush_pending, 0);\n\tinit_waitqueue_head(&mddev->sb_wait);\n\tinit_waitqueue_head(&mddev->recovery_wait);\n\tmddev->reshape_position = MaxSector;\n\tmddev->reshape_backwards = 0;\n\tmddev->last_sync_action = \"none\";\n\tmddev->resync_min = 0;\n\tmddev->resync_max = MaxSector;\n\tmddev->level = LEVEL_NONE;\n}\nEXPORT_SYMBOL_GPL(mddev_init);\n\nstatic struct mddev *mddev_find(dev_t unit)\n{\n\tstruct mddev *mddev, *new = NULL;\n\n\tif (unit && MAJOR(unit) != MD_MAJOR)\n\t\tunit &= ~((1<<MdpMinorShift)-1);\n\n retry:\n\tspin_lock(&all_mddevs_lock);\n\n\tif (unit) {\n\t\tlist_for_each_entry(mddev, &all_mddevs, all_mddevs)\n\t\t\tif (mddev->unit == unit) {\n\t\t\t\tmddev_get(mddev);\n\t\t\t\tspin_unlock(&all_mddevs_lock);\n\t\t\t\tkfree(new);\n\t\t\t\treturn mddev;\n\t\t\t}\n\n\t\tif (new) {\n\t\t\tlist_add(&new->all_mddevs, &all_mddevs);\n\t\t\tspin_unlock(&all_mddevs_lock);\n\t\t\tnew->hold_active = UNTIL_IOCTL;\n\t\t\treturn new;\n\t\t}\n\t} else if (new) {\n\t\t/* find an unused unit number */\n\t\tstatic int next_minor = 512;\n\t\tint start = next_minor;\n\t\tint is_free = 0;\n\t\tint dev = 0;\n\t\twhile (!is_free) {\n\t\t\tdev = MKDEV(MD_MAJOR, next_minor);\n\t\t\tnext_minor++;\n\t\t\tif (next_minor > MINORMASK)\n\t\t\t\tnext_minor = 0;\n\t\t\tif (next_minor == start) {\n\t\t\t\t/* Oh dear, all in use. */\n\t\t\t\tspin_unlock(&all_mddevs_lock);\n\t\t\t\tkfree(new);\n\t\t\t\treturn NULL;\n\t\t\t}\n\n\t\t\tis_free = 1;\n\t\t\tlist_for_each_entry(mddev, &all_mddevs, all_mddevs)\n\t\t\t\tif (mddev->unit == dev) {\n\t\t\t\t\tis_free = 0;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t}\n\t\tnew->unit = dev;\n\t\tnew->md_minor = MINOR(dev);\n\t\tnew->hold_active = UNTIL_STOP;\n\t\tlist_add(&new->all_mddevs, &all_mddevs);\n\t\tspin_unlock(&all_mddevs_lock);\n\t\treturn new;\n\t}\n\tspin_unlock(&all_mddevs_lock);\n\n\tnew = kzalloc(sizeof(*new), GFP_KERNEL);\n\tif (!new)\n\t\treturn NULL;\n\n\tnew->unit = unit;\n\tif (MAJOR(unit) == MD_MAJOR)\n\t\tnew->md_minor = MINOR(unit);\n\telse\n\t\tnew->md_minor = MINOR(unit) >> MdpMinorShift;\n\n\tmddev_init(new);\n\n\tgoto retry;\n}\n\nstatic struct attribute_group md_redundancy_group;\n\nvoid mddev_unlock(struct mddev *mddev)\n{\n\tif (mddev->to_remove) {\n\t\t/* These cannot be removed under reconfig_mutex as\n\t\t * an access to the files will try to take reconfig_mutex\n\t\t * while holding the file unremovable, which leads to\n\t\t * a deadlock.\n\t\t * So hold set sysfs_active while the remove in happeing,\n\t\t * and anything else which might set ->to_remove or my\n\t\t * otherwise change the sysfs namespace will fail with\n\t\t * -EBUSY if sysfs_active is still set.\n\t\t * We set sysfs_active under reconfig_mutex and elsewhere\n\t\t * test it under the same mutex to ensure its correct value\n\t\t * is seen.\n\t\t */\n\t\tstruct attribute_group *to_remove = mddev->to_remove;\n\t\tmddev->to_remove = NULL;\n\t\tmddev->sysfs_active = 1;\n\t\tmutex_unlock(&mddev->reconfig_mutex);\n\n\t\tif (mddev->kobj.sd) {\n\t\t\tif (to_remove != &md_redundancy_group)\n\t\t\t\tsysfs_remove_group(&mddev->kobj, to_remove);\n\t\t\tif (mddev->pers == NULL ||\n\t\t\t    mddev->pers->sync_request == NULL) {\n\t\t\t\tsysfs_remove_group(&mddev->kobj, &md_redundancy_group);\n\t\t\t\tif (mddev->sysfs_action)\n\t\t\t\t\tsysfs_put(mddev->sysfs_action);\n\t\t\t\tif (mddev->sysfs_completed)\n\t\t\t\t\tsysfs_put(mddev->sysfs_completed);\n\t\t\t\tif (mddev->sysfs_degraded)\n\t\t\t\t\tsysfs_put(mddev->sysfs_degraded);\n\t\t\t\tmddev->sysfs_action = NULL;\n\t\t\t\tmddev->sysfs_completed = NULL;\n\t\t\t\tmddev->sysfs_degraded = NULL;\n\t\t\t}\n\t\t}\n\t\tmddev->sysfs_active = 0;\n\t} else\n\t\tmutex_unlock(&mddev->reconfig_mutex);\n\n\t/* As we've dropped the mutex we need a spinlock to\n\t * make sure the thread doesn't disappear\n\t */\n\tspin_lock(&pers_lock);\n\tmd_wakeup_thread(mddev->thread);\n\twake_up(&mddev->sb_wait);\n\tspin_unlock(&pers_lock);\n}\nEXPORT_SYMBOL_GPL(mddev_unlock);\n\nstruct md_rdev *md_find_rdev_nr_rcu(struct mddev *mddev, int nr)\n{\n\tstruct md_rdev *rdev;\n\n\trdev_for_each_rcu(rdev, mddev)\n\t\tif (rdev->desc_nr == nr)\n\t\t\treturn rdev;\n\n\treturn NULL;\n}\nEXPORT_SYMBOL_GPL(md_find_rdev_nr_rcu);\n\nstatic struct md_rdev *find_rdev(struct mddev *mddev, dev_t dev)\n{\n\tstruct md_rdev *rdev;\n\n\trdev_for_each(rdev, mddev)\n\t\tif (rdev->bdev->bd_dev == dev)\n\t\t\treturn rdev;\n\n\treturn NULL;\n}\n\nstruct md_rdev *md_find_rdev_rcu(struct mddev *mddev, dev_t dev)\n{\n\tstruct md_rdev *rdev;\n\n\trdev_for_each_rcu(rdev, mddev)\n\t\tif (rdev->bdev->bd_dev == dev)\n\t\t\treturn rdev;\n\n\treturn NULL;\n}\nEXPORT_SYMBOL_GPL(md_find_rdev_rcu);\n\nstatic struct md_personality *find_pers(int level, char *clevel)\n{\n\tstruct md_personality *pers;\n\tlist_for_each_entry(pers, &pers_list, list) {\n\t\tif (level != LEVEL_NONE && pers->level == level)\n\t\t\treturn pers;\n\t\tif (strcmp(pers->name, clevel)==0)\n\t\t\treturn pers;\n\t}\n\treturn NULL;\n}\n\n/* return the offset of the super block in 512byte sectors */\nstatic inline sector_t calc_dev_sboffset(struct md_rdev *rdev)\n{\n\tsector_t num_sectors = i_size_read(rdev->bdev->bd_inode) / 512;\n\treturn MD_NEW_SIZE_SECTORS(num_sectors);\n}\n\nstatic int alloc_disk_sb(struct md_rdev *rdev)\n{\n\trdev->sb_page = alloc_page(GFP_KERNEL);\n\tif (!rdev->sb_page)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\nvoid md_rdev_clear(struct md_rdev *rdev)\n{\n\tif (rdev->sb_page) {\n\t\tput_page(rdev->sb_page);\n\t\trdev->sb_loaded = 0;\n\t\trdev->sb_page = NULL;\n\t\trdev->sb_start = 0;\n\t\trdev->sectors = 0;\n\t}\n\tif (rdev->bb_page) {\n\t\tput_page(rdev->bb_page);\n\t\trdev->bb_page = NULL;\n\t}\n\tbadblocks_exit(&rdev->badblocks);\n}\nEXPORT_SYMBOL_GPL(md_rdev_clear);\n\nstatic void super_written(struct bio *bio)\n{\n\tstruct md_rdev *rdev = bio->bi_private;\n\tstruct mddev *mddev = rdev->mddev;\n\n\tif (bio->bi_status) {\n\t\tpr_err(\"md: %s gets error=%d\\n\", __func__,\n\t\t       blk_status_to_errno(bio->bi_status));\n\t\tmd_error(mddev, rdev);\n\t\tif (!test_bit(Faulty, &rdev->flags)\n\t\t    && (bio->bi_opf & MD_FAILFAST)) {\n\t\t\tset_bit(MD_SB_NEED_REWRITE, &mddev->sb_flags);\n\t\t\tset_bit(LastDev, &rdev->flags);\n\t\t}\n\t} else\n\t\tclear_bit(LastDev, &rdev->flags);\n\n\tif (atomic_dec_and_test(&mddev->pending_writes))\n\t\twake_up(&mddev->sb_wait);\n\trdev_dec_pending(rdev, mddev);\n\tbio_put(bio);\n}\n\nvoid md_super_write(struct mddev *mddev, struct md_rdev *rdev,\n\t\t   sector_t sector, int size, struct page *page)\n{\n\t/* write first size bytes of page to sector of rdev\n\t * Increment mddev->pending_writes before returning\n\t * and decrement it on completion, waking up sb_wait\n\t * if zero is reached.\n\t * If an error occurred, call md_error\n\t */\n\tstruct bio *bio;\n\tint ff = 0;\n\n\tif (!page)\n\t\treturn;\n\n\tif (test_bit(Faulty, &rdev->flags))\n\t\treturn;\n\n\tbio = md_bio_alloc_sync(mddev);\n\n\tatomic_inc(&rdev->nr_pending);\n\n\tbio_set_dev(bio, rdev->meta_bdev ? rdev->meta_bdev : rdev->bdev);\n\tbio->bi_iter.bi_sector = sector;\n\tbio_add_page(bio, page, size, 0);\n\tbio->bi_private = rdev;\n\tbio->bi_end_io = super_written;\n\n\tif (test_bit(MD_FAILFAST_SUPPORTED, &mddev->flags) &&\n\t    test_bit(FailFast, &rdev->flags) &&\n\t    !test_bit(LastDev, &rdev->flags))\n\t\tff = MD_FAILFAST;\n\tbio->bi_opf = REQ_OP_WRITE | REQ_SYNC | REQ_PREFLUSH | REQ_FUA | ff;\n\n\tatomic_inc(&mddev->pending_writes);\n\tsubmit_bio(bio);\n}\n\nint md_super_wait(struct mddev *mddev)\n{\n\t/* wait for all superblock writes that were scheduled to complete */\n\twait_event(mddev->sb_wait, atomic_read(&mddev->pending_writes)==0);\n\tif (test_and_clear_bit(MD_SB_NEED_REWRITE, &mddev->sb_flags))\n\t\treturn -EAGAIN;\n\treturn 0;\n}\n\nint sync_page_io(struct md_rdev *rdev, sector_t sector, int size,\n\t\t struct page *page, int op, int op_flags, bool metadata_op)\n{\n\tstruct bio *bio = md_bio_alloc_sync(rdev->mddev);\n\tint ret;\n\n\tif (metadata_op && rdev->meta_bdev)\n\t\tbio_set_dev(bio, rdev->meta_bdev);\n\telse\n\t\tbio_set_dev(bio, rdev->bdev);\n\tbio_set_op_attrs(bio, op, op_flags);\n\tif (metadata_op)\n\t\tbio->bi_iter.bi_sector = sector + rdev->sb_start;\n\telse if (rdev->mddev->reshape_position != MaxSector &&\n\t\t (rdev->mddev->reshape_backwards ==\n\t\t  (sector >= rdev->mddev->reshape_position)))\n\t\tbio->bi_iter.bi_sector = sector + rdev->new_data_offset;\n\telse\n\t\tbio->bi_iter.bi_sector = sector + rdev->data_offset;\n\tbio_add_page(bio, page, size, 0);\n\n\tsubmit_bio_wait(bio);\n\n\tret = !bio->bi_status;\n\tbio_put(bio);\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(sync_page_io);\n\nstatic int read_disk_sb(struct md_rdev *rdev, int size)\n{\n\tchar b[BDEVNAME_SIZE];\n\n\tif (rdev->sb_loaded)\n\t\treturn 0;\n\n\tif (!sync_page_io(rdev, 0, size, rdev->sb_page, REQ_OP_READ, 0, true))\n\t\tgoto fail;\n\trdev->sb_loaded = 1;\n\treturn 0;\n\nfail:\n\tpr_err(\"md: disabled device %s, could not read superblock.\\n\",\n\t       bdevname(rdev->bdev,b));\n\treturn -EINVAL;\n}\n\nstatic int md_uuid_equal(mdp_super_t *sb1, mdp_super_t *sb2)\n{\n\treturn\tsb1->set_uuid0 == sb2->set_uuid0 &&\n\t\tsb1->set_uuid1 == sb2->set_uuid1 &&\n\t\tsb1->set_uuid2 == sb2->set_uuid2 &&\n\t\tsb1->set_uuid3 == sb2->set_uuid3;\n}\n\nstatic int md_sb_equal(mdp_super_t *sb1, mdp_super_t *sb2)\n{\n\tint ret;\n\tmdp_super_t *tmp1, *tmp2;\n\n\ttmp1 = kmalloc(sizeof(*tmp1),GFP_KERNEL);\n\ttmp2 = kmalloc(sizeof(*tmp2),GFP_KERNEL);\n\n\tif (!tmp1 || !tmp2) {\n\t\tret = 0;\n\t\tgoto abort;\n\t}\n\n\t*tmp1 = *sb1;\n\t*tmp2 = *sb2;\n\n\t/*\n\t * nr_disks is not constant\n\t */\n\ttmp1->nr_disks = 0;\n\ttmp2->nr_disks = 0;\n\n\tret = (memcmp(tmp1, tmp2, MD_SB_GENERIC_CONSTANT_WORDS * 4) == 0);\nabort:\n\tkfree(tmp1);\n\tkfree(tmp2);\n\treturn ret;\n}\n\nstatic u32 md_csum_fold(u32 csum)\n{\n\tcsum = (csum & 0xffff) + (csum >> 16);\n\treturn (csum & 0xffff) + (csum >> 16);\n}\n\nstatic unsigned int calc_sb_csum(mdp_super_t *sb)\n{\n\tu64 newcsum = 0;\n\tu32 *sb32 = (u32*)sb;\n\tint i;\n\tunsigned int disk_csum, csum;\n\n\tdisk_csum = sb->sb_csum;\n\tsb->sb_csum = 0;\n\n\tfor (i = 0; i < MD_SB_BYTES/4 ; i++)\n\t\tnewcsum += sb32[i];\n\tcsum = (newcsum & 0xffffffff) + (newcsum>>32);\n\n#ifdef CONFIG_ALPHA\n\t/* This used to use csum_partial, which was wrong for several\n\t * reasons including that different results are returned on\n\t * different architectures.  It isn't critical that we get exactly\n\t * the same return value as before (we always csum_fold before\n\t * testing, and that removes any differences).  However as we\n\t * know that csum_partial always returned a 16bit value on\n\t * alphas, do a fold to maximise conformity to previous behaviour.\n\t */\n\tsb->sb_csum = md_csum_fold(disk_csum);\n#else\n\tsb->sb_csum = disk_csum;\n#endif\n\treturn csum;\n}\n\n/*\n * Handle superblock details.\n * We want to be able to handle multiple superblock formats\n * so we have a common interface to them all, and an array of\n * different handlers.\n * We rely on user-space to write the initial superblock, and support\n * reading and updating of superblocks.\n * Interface methods are:\n *   int load_super(struct md_rdev *dev, struct md_rdev *refdev, int minor_version)\n *      loads and validates a superblock on dev.\n *      if refdev != NULL, compare superblocks on both devices\n *    Return:\n *      0 - dev has a superblock that is compatible with refdev\n *      1 - dev has a superblock that is compatible and newer than refdev\n *          so dev should be used as the refdev in future\n *     -EINVAL superblock incompatible or invalid\n *     -othererror e.g. -EIO\n *\n *   int validate_super(struct mddev *mddev, struct md_rdev *dev)\n *      Verify that dev is acceptable into mddev.\n *       The first time, mddev->raid_disks will be 0, and data from\n *       dev should be merged in.  Subsequent calls check that dev\n *       is new enough.  Return 0 or -EINVAL\n *\n *   void sync_super(struct mddev *mddev, struct md_rdev *dev)\n *     Update the superblock for rdev with data in mddev\n *     This does not write to disc.\n *\n */\n\nstruct super_type  {\n\tchar\t\t    *name;\n\tstruct module\t    *owner;\n\tint\t\t    (*load_super)(struct md_rdev *rdev,\n\t\t\t\t\t  struct md_rdev *refdev,\n\t\t\t\t\t  int minor_version);\n\tint\t\t    (*validate_super)(struct mddev *mddev,\n\t\t\t\t\t      struct md_rdev *rdev);\n\tvoid\t\t    (*sync_super)(struct mddev *mddev,\n\t\t\t\t\t  struct md_rdev *rdev);\n\tunsigned long long  (*rdev_size_change)(struct md_rdev *rdev,\n\t\t\t\t\t\tsector_t num_sectors);\n\tint\t\t    (*allow_new_offset)(struct md_rdev *rdev,\n\t\t\t\t\t\tunsigned long long new_offset);\n};\n\n/*\n * Check that the given mddev has no bitmap.\n *\n * This function is called from the run method of all personalities that do not\n * support bitmaps. It prints an error message and returns non-zero if mddev\n * has a bitmap. Otherwise, it returns 0.\n *\n */\nint md_check_no_bitmap(struct mddev *mddev)\n{\n\tif (!mddev->bitmap_info.file && !mddev->bitmap_info.offset)\n\t\treturn 0;\n\tpr_warn(\"%s: bitmaps are not supported for %s\\n\",\n\t\tmdname(mddev), mddev->pers->name);\n\treturn 1;\n}\nEXPORT_SYMBOL(md_check_no_bitmap);\n\n/*\n * load_super for 0.90.0\n */\nstatic int super_90_load(struct md_rdev *rdev, struct md_rdev *refdev, int minor_version)\n{\n\tchar b[BDEVNAME_SIZE], b2[BDEVNAME_SIZE];\n\tmdp_super_t *sb;\n\tint ret;\n\tbool spare_disk = true;\n\n\t/*\n\t * Calculate the position of the superblock (512byte sectors),\n\t * it's at the end of the disk.\n\t *\n\t * It also happens to be a multiple of 4Kb.\n\t */\n\trdev->sb_start = calc_dev_sboffset(rdev);\n\n\tret = read_disk_sb(rdev, MD_SB_BYTES);\n\tif (ret)\n\t\treturn ret;\n\n\tret = -EINVAL;\n\n\tbdevname(rdev->bdev, b);\n\tsb = page_address(rdev->sb_page);\n\n\tif (sb->md_magic != MD_SB_MAGIC) {\n\t\tpr_warn(\"md: invalid raid superblock magic on %s\\n\", b);\n\t\tgoto abort;\n\t}\n\n\tif (sb->major_version != 0 ||\n\t    sb->minor_version < 90 ||\n\t    sb->minor_version > 91) {\n\t\tpr_warn(\"Bad version number %d.%d on %s\\n\",\n\t\t\tsb->major_version, sb->minor_version, b);\n\t\tgoto abort;\n\t}\n\n\tif (sb->raid_disks <= 0)\n\t\tgoto abort;\n\n\tif (md_csum_fold(calc_sb_csum(sb)) != md_csum_fold(sb->sb_csum)) {\n\t\tpr_warn(\"md: invalid superblock checksum on %s\\n\", b);\n\t\tgoto abort;\n\t}\n\n\trdev->preferred_minor = sb->md_minor;\n\trdev->data_offset = 0;\n\trdev->new_data_offset = 0;\n\trdev->sb_size = MD_SB_BYTES;\n\trdev->badblocks.shift = -1;\n\n\tif (sb->level == LEVEL_MULTIPATH)\n\t\trdev->desc_nr = -1;\n\telse\n\t\trdev->desc_nr = sb->this_disk.number;\n\n\t/* not spare disk, or LEVEL_MULTIPATH */\n\tif (sb->level == LEVEL_MULTIPATH ||\n\t\t(rdev->desc_nr >= 0 &&\n\t\t rdev->desc_nr < MD_SB_DISKS &&\n\t\t sb->disks[rdev->desc_nr].state &\n\t\t ((1<<MD_DISK_SYNC) | (1 << MD_DISK_ACTIVE))))\n\t\tspare_disk = false;\n\n\tif (!refdev) {\n\t\tif (!spare_disk)\n\t\t\tret = 1;\n\t\telse\n\t\t\tret = 0;\n\t} else {\n\t\t__u64 ev1, ev2;\n\t\tmdp_super_t *refsb = page_address(refdev->sb_page);\n\t\tif (!md_uuid_equal(refsb, sb)) {\n\t\t\tpr_warn(\"md: %s has different UUID to %s\\n\",\n\t\t\t\tb, bdevname(refdev->bdev,b2));\n\t\t\tgoto abort;\n\t\t}\n\t\tif (!md_sb_equal(refsb, sb)) {\n\t\t\tpr_warn(\"md: %s has same UUID but different superblock to %s\\n\",\n\t\t\t\tb, bdevname(refdev->bdev, b2));\n\t\t\tgoto abort;\n\t\t}\n\t\tev1 = md_event(sb);\n\t\tev2 = md_event(refsb);\n\n\t\tif (!spare_disk && ev1 > ev2)\n\t\t\tret = 1;\n\t\telse\n\t\t\tret = 0;\n\t}\n\trdev->sectors = rdev->sb_start;\n\t/* Limit to 4TB as metadata cannot record more than that.\n\t * (not needed for Linear and RAID0 as metadata doesn't\n\t * record this size)\n\t */\n\tif ((u64)rdev->sectors >= (2ULL << 32) && sb->level >= 1)\n\t\trdev->sectors = (sector_t)(2ULL << 32) - 2;\n\n\tif (rdev->sectors < ((sector_t)sb->size) * 2 && sb->level >= 1)\n\t\t/* \"this cannot possibly happen\" ... */\n\t\tret = -EINVAL;\n\n abort:\n\treturn ret;\n}\n\n/*\n * validate_super for 0.90.0\n */\nstatic int super_90_validate(struct mddev *mddev, struct md_rdev *rdev)\n{\n\tmdp_disk_t *desc;\n\tmdp_super_t *sb = page_address(rdev->sb_page);\n\t__u64 ev1 = md_event(sb);\n\n\trdev->raid_disk = -1;\n\tclear_bit(Faulty, &rdev->flags);\n\tclear_bit(In_sync, &rdev->flags);\n\tclear_bit(Bitmap_sync, &rdev->flags);\n\tclear_bit(WriteMostly, &rdev->flags);\n\n\tif (mddev->raid_disks == 0) {\n\t\tmddev->major_version = 0;\n\t\tmddev->minor_version = sb->minor_version;\n\t\tmddev->patch_version = sb->patch_version;\n\t\tmddev->external = 0;\n\t\tmddev->chunk_sectors = sb->chunk_size >> 9;\n\t\tmddev->ctime = sb->ctime;\n\t\tmddev->utime = sb->utime;\n\t\tmddev->level = sb->level;\n\t\tmddev->clevel[0] = 0;\n\t\tmddev->layout = sb->layout;\n\t\tmddev->raid_disks = sb->raid_disks;\n\t\tmddev->dev_sectors = ((sector_t)sb->size) * 2;\n\t\tmddev->events = ev1;\n\t\tmddev->bitmap_info.offset = 0;\n\t\tmddev->bitmap_info.space = 0;\n\t\t/* bitmap can use 60 K after the 4K superblocks */\n\t\tmddev->bitmap_info.default_offset = MD_SB_BYTES >> 9;\n\t\tmddev->bitmap_info.default_space = 64*2 - (MD_SB_BYTES >> 9);\n\t\tmddev->reshape_backwards = 0;\n\n\t\tif (mddev->minor_version >= 91) {\n\t\t\tmddev->reshape_position = sb->reshape_position;\n\t\t\tmddev->delta_disks = sb->delta_disks;\n\t\t\tmddev->new_level = sb->new_level;\n\t\t\tmddev->new_layout = sb->new_layout;\n\t\t\tmddev->new_chunk_sectors = sb->new_chunk >> 9;\n\t\t\tif (mddev->delta_disks < 0)\n\t\t\t\tmddev->reshape_backwards = 1;\n\t\t} else {\n\t\t\tmddev->reshape_position = MaxSector;\n\t\t\tmddev->delta_disks = 0;\n\t\t\tmddev->new_level = mddev->level;\n\t\t\tmddev->new_layout = mddev->layout;\n\t\t\tmddev->new_chunk_sectors = mddev->chunk_sectors;\n\t\t}\n\t\tif (mddev->level == 0)\n\t\t\tmddev->layout = -1;\n\n\t\tif (sb->state & (1<<MD_SB_CLEAN))\n\t\t\tmddev->recovery_cp = MaxSector;\n\t\telse {\n\t\t\tif (sb->events_hi == sb->cp_events_hi &&\n\t\t\t\tsb->events_lo == sb->cp_events_lo) {\n\t\t\t\tmddev->recovery_cp = sb->recovery_cp;\n\t\t\t} else\n\t\t\t\tmddev->recovery_cp = 0;\n\t\t}\n\n\t\tmemcpy(mddev->uuid+0, &sb->set_uuid0, 4);\n\t\tmemcpy(mddev->uuid+4, &sb->set_uuid1, 4);\n\t\tmemcpy(mddev->uuid+8, &sb->set_uuid2, 4);\n\t\tmemcpy(mddev->uuid+12,&sb->set_uuid3, 4);\n\n\t\tmddev->max_disks = MD_SB_DISKS;\n\n\t\tif (sb->state & (1<<MD_SB_BITMAP_PRESENT) &&\n\t\t    mddev->bitmap_info.file == NULL) {\n\t\t\tmddev->bitmap_info.offset =\n\t\t\t\tmddev->bitmap_info.default_offset;\n\t\t\tmddev->bitmap_info.space =\n\t\t\t\tmddev->bitmap_info.default_space;\n\t\t}\n\n\t} else if (mddev->pers == NULL) {\n\t\t/* Insist on good event counter while assembling, except\n\t\t * for spares (which don't need an event count) */\n\t\t++ev1;\n\t\tif (sb->disks[rdev->desc_nr].state & (\n\t\t\t    (1<<MD_DISK_SYNC) | (1 << MD_DISK_ACTIVE)))\n\t\t\tif (ev1 < mddev->events)\n\t\t\t\treturn -EINVAL;\n\t} else if (mddev->bitmap) {\n\t\t/* if adding to array with a bitmap, then we can accept an\n\t\t * older device ... but not too old.\n\t\t */\n\t\tif (ev1 < mddev->bitmap->events_cleared)\n\t\t\treturn 0;\n\t\tif (ev1 < mddev->events)\n\t\t\tset_bit(Bitmap_sync, &rdev->flags);\n\t} else {\n\t\tif (ev1 < mddev->events)\n\t\t\t/* just a hot-add of a new device, leave raid_disk at -1 */\n\t\t\treturn 0;\n\t}\n\n\tif (mddev->level != LEVEL_MULTIPATH) {\n\t\tdesc = sb->disks + rdev->desc_nr;\n\n\t\tif (desc->state & (1<<MD_DISK_FAULTY))\n\t\t\tset_bit(Faulty, &rdev->flags);\n\t\telse if (desc->state & (1<<MD_DISK_SYNC) /* &&\n\t\t\t    desc->raid_disk < mddev->raid_disks */) {\n\t\t\tset_bit(In_sync, &rdev->flags);\n\t\t\trdev->raid_disk = desc->raid_disk;\n\t\t\trdev->saved_raid_disk = desc->raid_disk;\n\t\t} else if (desc->state & (1<<MD_DISK_ACTIVE)) {\n\t\t\t/* active but not in sync implies recovery up to\n\t\t\t * reshape position.  We don't know exactly where\n\t\t\t * that is, so set to zero for now */\n\t\t\tif (mddev->minor_version >= 91) {\n\t\t\t\trdev->recovery_offset = 0;\n\t\t\t\trdev->raid_disk = desc->raid_disk;\n\t\t\t}\n\t\t}\n\t\tif (desc->state & (1<<MD_DISK_WRITEMOSTLY))\n\t\t\tset_bit(WriteMostly, &rdev->flags);\n\t\tif (desc->state & (1<<MD_DISK_FAILFAST))\n\t\t\tset_bit(FailFast, &rdev->flags);\n\t} else /* MULTIPATH are always insync */\n\t\tset_bit(In_sync, &rdev->flags);\n\treturn 0;\n}\n\n/*\n * sync_super for 0.90.0\n */\nstatic void super_90_sync(struct mddev *mddev, struct md_rdev *rdev)\n{\n\tmdp_super_t *sb;\n\tstruct md_rdev *rdev2;\n\tint next_spare = mddev->raid_disks;\n\n\t/* make rdev->sb match mddev data..\n\t *\n\t * 1/ zero out disks\n\t * 2/ Add info for each disk, keeping track of highest desc_nr (next_spare);\n\t * 3/ any empty disks < next_spare become removed\n\t *\n\t * disks[0] gets initialised to REMOVED because\n\t * we cannot be sure from other fields if it has\n\t * been initialised or not.\n\t */\n\tint i;\n\tint active=0, working=0,failed=0,spare=0,nr_disks=0;\n\n\trdev->sb_size = MD_SB_BYTES;\n\n\tsb = page_address(rdev->sb_page);\n\n\tmemset(sb, 0, sizeof(*sb));\n\n\tsb->md_magic = MD_SB_MAGIC;\n\tsb->major_version = mddev->major_version;\n\tsb->patch_version = mddev->patch_version;\n\tsb->gvalid_words  = 0; /* ignored */\n\tmemcpy(&sb->set_uuid0, mddev->uuid+0, 4);\n\tmemcpy(&sb->set_uuid1, mddev->uuid+4, 4);\n\tmemcpy(&sb->set_uuid2, mddev->uuid+8, 4);\n\tmemcpy(&sb->set_uuid3, mddev->uuid+12,4);\n\n\tsb->ctime = clamp_t(time64_t, mddev->ctime, 0, U32_MAX);\n\tsb->level = mddev->level;\n\tsb->size = mddev->dev_sectors / 2;\n\tsb->raid_disks = mddev->raid_disks;\n\tsb->md_minor = mddev->md_minor;\n\tsb->not_persistent = 0;\n\tsb->utime = clamp_t(time64_t, mddev->utime, 0, U32_MAX);\n\tsb->state = 0;\n\tsb->events_hi = (mddev->events>>32);\n\tsb->events_lo = (u32)mddev->events;\n\n\tif (mddev->reshape_position == MaxSector)\n\t\tsb->minor_version = 90;\n\telse {\n\t\tsb->minor_version = 91;\n\t\tsb->reshape_position = mddev->reshape_position;\n\t\tsb->new_level = mddev->new_level;\n\t\tsb->delta_disks = mddev->delta_disks;\n\t\tsb->new_layout = mddev->new_layout;\n\t\tsb->new_chunk = mddev->new_chunk_sectors << 9;\n\t}\n\tmddev->minor_version = sb->minor_version;\n\tif (mddev->in_sync)\n\t{\n\t\tsb->recovery_cp = mddev->recovery_cp;\n\t\tsb->cp_events_hi = (mddev->events>>32);\n\t\tsb->cp_events_lo = (u32)mddev->events;\n\t\tif (mddev->recovery_cp == MaxSector)\n\t\t\tsb->state = (1<< MD_SB_CLEAN);\n\t} else\n\t\tsb->recovery_cp = 0;\n\n\tsb->layout = mddev->layout;\n\tsb->chunk_size = mddev->chunk_sectors << 9;\n\n\tif (mddev->bitmap && mddev->bitmap_info.file == NULL)\n\t\tsb->state |= (1<<MD_SB_BITMAP_PRESENT);\n\n\tsb->disks[0].state = (1<<MD_DISK_REMOVED);\n\trdev_for_each(rdev2, mddev) {\n\t\tmdp_disk_t *d;\n\t\tint desc_nr;\n\t\tint is_active = test_bit(In_sync, &rdev2->flags);\n\n\t\tif (rdev2->raid_disk >= 0 &&\n\t\t    sb->minor_version >= 91)\n\t\t\t/* we have nowhere to store the recovery_offset,\n\t\t\t * but if it is not below the reshape_position,\n\t\t\t * we can piggy-back on that.\n\t\t\t */\n\t\t\tis_active = 1;\n\t\tif (rdev2->raid_disk < 0 ||\n\t\t    test_bit(Faulty, &rdev2->flags))\n\t\t\tis_active = 0;\n\t\tif (is_active)\n\t\t\tdesc_nr = rdev2->raid_disk;\n\t\telse\n\t\t\tdesc_nr = next_spare++;\n\t\trdev2->desc_nr = desc_nr;\n\t\td = &sb->disks[rdev2->desc_nr];\n\t\tnr_disks++;\n\t\td->number = rdev2->desc_nr;\n\t\td->major = MAJOR(rdev2->bdev->bd_dev);\n\t\td->minor = MINOR(rdev2->bdev->bd_dev);\n\t\tif (is_active)\n\t\t\td->raid_disk = rdev2->raid_disk;\n\t\telse\n\t\t\td->raid_disk = rdev2->desc_nr; /* compatibility */\n\t\tif (test_bit(Faulty, &rdev2->flags))\n\t\t\td->state = (1<<MD_DISK_FAULTY);\n\t\telse if (is_active) {\n\t\t\td->state = (1<<MD_DISK_ACTIVE);\n\t\t\tif (test_bit(In_sync, &rdev2->flags))\n\t\t\t\td->state |= (1<<MD_DISK_SYNC);\n\t\t\tactive++;\n\t\t\tworking++;\n\t\t} else {\n\t\t\td->state = 0;\n\t\t\tspare++;\n\t\t\tworking++;\n\t\t}\n\t\tif (test_bit(WriteMostly, &rdev2->flags))\n\t\t\td->state |= (1<<MD_DISK_WRITEMOSTLY);\n\t\tif (test_bit(FailFast, &rdev2->flags))\n\t\t\td->state |= (1<<MD_DISK_FAILFAST);\n\t}\n\t/* now set the \"removed\" and \"faulty\" bits on any missing devices */\n\tfor (i=0 ; i < mddev->raid_disks ; i++) {\n\t\tmdp_disk_t *d = &sb->disks[i];\n\t\tif (d->state == 0 && d->number == 0) {\n\t\t\td->number = i;\n\t\t\td->raid_disk = i;\n\t\t\td->state = (1<<MD_DISK_REMOVED);\n\t\t\td->state |= (1<<MD_DISK_FAULTY);\n\t\t\tfailed++;\n\t\t}\n\t}\n\tsb->nr_disks = nr_disks;\n\tsb->active_disks = active;\n\tsb->working_disks = working;\n\tsb->failed_disks = failed;\n\tsb->spare_disks = spare;\n\n\tsb->this_disk = sb->disks[rdev->desc_nr];\n\tsb->sb_csum = calc_sb_csum(sb);\n}\n\n/*\n * rdev_size_change for 0.90.0\n */\nstatic unsigned long long\nsuper_90_rdev_size_change(struct md_rdev *rdev, sector_t num_sectors)\n{\n\tif (num_sectors && num_sectors < rdev->mddev->dev_sectors)\n\t\treturn 0; /* component must fit device */\n\tif (rdev->mddev->bitmap_info.offset)\n\t\treturn 0; /* can't move bitmap */\n\trdev->sb_start = calc_dev_sboffset(rdev);\n\tif (!num_sectors || num_sectors > rdev->sb_start)\n\t\tnum_sectors = rdev->sb_start;\n\t/* Limit to 4TB as metadata cannot record more than that.\n\t * 4TB == 2^32 KB, or 2*2^32 sectors.\n\t */\n\tif ((u64)num_sectors >= (2ULL << 32) && rdev->mddev->level >= 1)\n\t\tnum_sectors = (sector_t)(2ULL << 32) - 2;\n\tdo {\n\t\tmd_super_write(rdev->mddev, rdev, rdev->sb_start, rdev->sb_size,\n\t\t       rdev->sb_page);\n\t} while (md_super_wait(rdev->mddev) < 0);\n\treturn num_sectors;\n}\n\nstatic int\nsuper_90_allow_new_offset(struct md_rdev *rdev, unsigned long long new_offset)\n{\n\t/* non-zero offset changes not possible with v0.90 */\n\treturn new_offset == 0;\n}\n\n/*\n * version 1 superblock\n */\n\nstatic __le32 calc_sb_1_csum(struct mdp_superblock_1 *sb)\n{\n\t__le32 disk_csum;\n\tu32 csum;\n\tunsigned long long newcsum;\n\tint size = 256 + le32_to_cpu(sb->max_dev)*2;\n\t__le32 *isuper = (__le32*)sb;\n\n\tdisk_csum = sb->sb_csum;\n\tsb->sb_csum = 0;\n\tnewcsum = 0;\n\tfor (; size >= 4; size -= 4)\n\t\tnewcsum += le32_to_cpu(*isuper++);\n\n\tif (size == 2)\n\t\tnewcsum += le16_to_cpu(*(__le16*) isuper);\n\n\tcsum = (newcsum & 0xffffffff) + (newcsum >> 32);\n\tsb->sb_csum = disk_csum;\n\treturn cpu_to_le32(csum);\n}\n\nstatic int super_1_load(struct md_rdev *rdev, struct md_rdev *refdev, int minor_version)\n{\n\tstruct mdp_superblock_1 *sb;\n\tint ret;\n\tsector_t sb_start;\n\tsector_t sectors;\n\tchar b[BDEVNAME_SIZE], b2[BDEVNAME_SIZE];\n\tint bmask;\n\tbool spare_disk = true;\n\n\t/*\n\t * Calculate the position of the superblock in 512byte sectors.\n\t * It is always aligned to a 4K boundary and\n\t * depeding on minor_version, it can be:\n\t * 0: At least 8K, but less than 12K, from end of device\n\t * 1: At start of device\n\t * 2: 4K from start of device.\n\t */\n\tswitch(minor_version) {\n\tcase 0:\n\t\tsb_start = i_size_read(rdev->bdev->bd_inode) >> 9;\n\t\tsb_start -= 8*2;\n\t\tsb_start &= ~(sector_t)(4*2-1);\n\t\tbreak;\n\tcase 1:\n\t\tsb_start = 0;\n\t\tbreak;\n\tcase 2:\n\t\tsb_start = 8;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\trdev->sb_start = sb_start;\n\n\t/* superblock is rarely larger than 1K, but it can be larger,\n\t * and it is safe to read 4k, so we do that\n\t */\n\tret = read_disk_sb(rdev, 4096);\n\tif (ret) return ret;\n\n\tsb = page_address(rdev->sb_page);\n\n\tif (sb->magic != cpu_to_le32(MD_SB_MAGIC) ||\n\t    sb->major_version != cpu_to_le32(1) ||\n\t    le32_to_cpu(sb->max_dev) > (4096-256)/2 ||\n\t    le64_to_cpu(sb->super_offset) != rdev->sb_start ||\n\t    (le32_to_cpu(sb->feature_map) & ~MD_FEATURE_ALL) != 0)\n\t\treturn -EINVAL;\n\n\tif (calc_sb_1_csum(sb) != sb->sb_csum) {\n\t\tpr_warn(\"md: invalid superblock checksum on %s\\n\",\n\t\t\tbdevname(rdev->bdev,b));\n\t\treturn -EINVAL;\n\t}\n\tif (le64_to_cpu(sb->data_size) < 10) {\n\t\tpr_warn(\"md: data_size too small on %s\\n\",\n\t\t\tbdevname(rdev->bdev,b));\n\t\treturn -EINVAL;\n\t}\n\tif (sb->pad0 ||\n\t    sb->pad3[0] ||\n\t    memcmp(sb->pad3, sb->pad3+1, sizeof(sb->pad3) - sizeof(sb->pad3[1])))\n\t\t/* Some padding is non-zero, might be a new feature */\n\t\treturn -EINVAL;\n\n\trdev->preferred_minor = 0xffff;\n\trdev->data_offset = le64_to_cpu(sb->data_offset);\n\trdev->new_data_offset = rdev->data_offset;\n\tif ((le32_to_cpu(sb->feature_map) & MD_FEATURE_RESHAPE_ACTIVE) &&\n\t    (le32_to_cpu(sb->feature_map) & MD_FEATURE_NEW_OFFSET))\n\t\trdev->new_data_offset += (s32)le32_to_cpu(sb->new_offset);\n\tatomic_set(&rdev->corrected_errors, le32_to_cpu(sb->cnt_corrected_read));\n\n\trdev->sb_size = le32_to_cpu(sb->max_dev) * 2 + 256;\n\tbmask = queue_logical_block_size(rdev->bdev->bd_disk->queue)-1;\n\tif (rdev->sb_size & bmask)\n\t\trdev->sb_size = (rdev->sb_size | bmask) + 1;\n\n\tif (minor_version\n\t    && rdev->data_offset < sb_start + (rdev->sb_size/512))\n\t\treturn -EINVAL;\n\tif (minor_version\n\t    && rdev->new_data_offset < sb_start + (rdev->sb_size/512))\n\t\treturn -EINVAL;\n\n\tif (sb->level == cpu_to_le32(LEVEL_MULTIPATH))\n\t\trdev->desc_nr = -1;\n\telse\n\t\trdev->desc_nr = le32_to_cpu(sb->dev_number);\n\n\tif (!rdev->bb_page) {\n\t\trdev->bb_page = alloc_page(GFP_KERNEL);\n\t\tif (!rdev->bb_page)\n\t\t\treturn -ENOMEM;\n\t}\n\tif ((le32_to_cpu(sb->feature_map) & MD_FEATURE_BAD_BLOCKS) &&\n\t    rdev->badblocks.count == 0) {\n\t\t/* need to load the bad block list.\n\t\t * Currently we limit it to one page.\n\t\t */\n\t\ts32 offset;\n\t\tsector_t bb_sector;\n\t\t__le64 *bbp;\n\t\tint i;\n\t\tint sectors = le16_to_cpu(sb->bblog_size);\n\t\tif (sectors > (PAGE_SIZE / 512))\n\t\t\treturn -EINVAL;\n\t\toffset = le32_to_cpu(sb->bblog_offset);\n\t\tif (offset == 0)\n\t\t\treturn -EINVAL;\n\t\tbb_sector = (long long)offset;\n\t\tif (!sync_page_io(rdev, bb_sector, sectors << 9,\n\t\t\t\t  rdev->bb_page, REQ_OP_READ, 0, true))\n\t\t\treturn -EIO;\n\t\tbbp = (__le64 *)page_address(rdev->bb_page);\n\t\trdev->badblocks.shift = sb->bblog_shift;\n\t\tfor (i = 0 ; i < (sectors << (9-3)) ; i++, bbp++) {\n\t\t\tu64 bb = le64_to_cpu(*bbp);\n\t\t\tint count = bb & (0x3ff);\n\t\t\tu64 sector = bb >> 10;\n\t\t\tsector <<= sb->bblog_shift;\n\t\t\tcount <<= sb->bblog_shift;\n\t\t\tif (bb + 1 == 0)\n\t\t\t\tbreak;\n\t\t\tif (badblocks_set(&rdev->badblocks, sector, count, 1))\n\t\t\t\treturn -EINVAL;\n\t\t}\n\t} else if (sb->bblog_offset != 0)\n\t\trdev->badblocks.shift = 0;\n\n\tif ((le32_to_cpu(sb->feature_map) &\n\t    (MD_FEATURE_PPL | MD_FEATURE_MULTIPLE_PPLS))) {\n\t\trdev->ppl.offset = (__s16)le16_to_cpu(sb->ppl.offset);\n\t\trdev->ppl.size = le16_to_cpu(sb->ppl.size);\n\t\trdev->ppl.sector = rdev->sb_start + rdev->ppl.offset;\n\t}\n\n\tif ((le32_to_cpu(sb->feature_map) & MD_FEATURE_RAID0_LAYOUT) &&\n\t    sb->level != 0)\n\t\treturn -EINVAL;\n\n\t/* not spare disk, or LEVEL_MULTIPATH */\n\tif (sb->level == cpu_to_le32(LEVEL_MULTIPATH) ||\n\t\t(rdev->desc_nr >= 0 &&\n\t\trdev->desc_nr < le32_to_cpu(sb->max_dev) &&\n\t\t(le16_to_cpu(sb->dev_roles[rdev->desc_nr]) < MD_DISK_ROLE_MAX ||\n\t\t le16_to_cpu(sb->dev_roles[rdev->desc_nr]) == MD_DISK_ROLE_JOURNAL)))\n\t\tspare_disk = false;\n\n\tif (!refdev) {\n\t\tif (!spare_disk)\n\t\t\tret = 1;\n\t\telse\n\t\t\tret = 0;\n\t} else {\n\t\t__u64 ev1, ev2;\n\t\tstruct mdp_superblock_1 *refsb = page_address(refdev->sb_page);\n\n\t\tif (memcmp(sb->set_uuid, refsb->set_uuid, 16) != 0 ||\n\t\t    sb->level != refsb->level ||\n\t\t    sb->layout != refsb->layout ||\n\t\t    sb->chunksize != refsb->chunksize) {\n\t\t\tpr_warn(\"md: %s has strangely different superblock to %s\\n\",\n\t\t\t\tbdevname(rdev->bdev,b),\n\t\t\t\tbdevname(refdev->bdev,b2));\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tev1 = le64_to_cpu(sb->events);\n\t\tev2 = le64_to_cpu(refsb->events);\n\n\t\tif (!spare_disk && ev1 > ev2)\n\t\t\tret = 1;\n\t\telse\n\t\t\tret = 0;\n\t}\n\tif (minor_version) {\n\t\tsectors = (i_size_read(rdev->bdev->bd_inode) >> 9);\n\t\tsectors -= rdev->data_offset;\n\t} else\n\t\tsectors = rdev->sb_start;\n\tif (sectors < le64_to_cpu(sb->data_size))\n\t\treturn -EINVAL;\n\trdev->sectors = le64_to_cpu(sb->data_size);\n\treturn ret;\n}\n\nstatic int super_1_validate(struct mddev *mddev, struct md_rdev *rdev)\n{\n\tstruct mdp_superblock_1 *sb = page_address(rdev->sb_page);\n\t__u64 ev1 = le64_to_cpu(sb->events);\n\n\trdev->raid_disk = -1;\n\tclear_bit(Faulty, &rdev->flags);\n\tclear_bit(In_sync, &rdev->flags);\n\tclear_bit(Bitmap_sync, &rdev->flags);\n\tclear_bit(WriteMostly, &rdev->flags);\n\n\tif (mddev->raid_disks == 0) {\n\t\tmddev->major_version = 1;\n\t\tmddev->patch_version = 0;\n\t\tmddev->external = 0;\n\t\tmddev->chunk_sectors = le32_to_cpu(sb->chunksize);\n\t\tmddev->ctime = le64_to_cpu(sb->ctime);\n\t\tmddev->utime = le64_to_cpu(sb->utime);\n\t\tmddev->level = le32_to_cpu(sb->level);\n\t\tmddev->clevel[0] = 0;\n\t\tmddev->layout = le32_to_cpu(sb->layout);\n\t\tmddev->raid_disks = le32_to_cpu(sb->raid_disks);\n\t\tmddev->dev_sectors = le64_to_cpu(sb->size);\n\t\tmddev->events = ev1;\n\t\tmddev->bitmap_info.offset = 0;\n\t\tmddev->bitmap_info.space = 0;\n\t\t/* Default location for bitmap is 1K after superblock\n\t\t * using 3K - total of 4K\n\t\t */\n\t\tmddev->bitmap_info.default_offset = 1024 >> 9;\n\t\tmddev->bitmap_info.default_space = (4096-1024) >> 9;\n\t\tmddev->reshape_backwards = 0;\n\n\t\tmddev->recovery_cp = le64_to_cpu(sb->resync_offset);\n\t\tmemcpy(mddev->uuid, sb->set_uuid, 16);\n\n\t\tmddev->max_disks =  (4096-256)/2;\n\n\t\tif ((le32_to_cpu(sb->feature_map) & MD_FEATURE_BITMAP_OFFSET) &&\n\t\t    mddev->bitmap_info.file == NULL) {\n\t\t\tmddev->bitmap_info.offset =\n\t\t\t\t(__s32)le32_to_cpu(sb->bitmap_offset);\n\t\t\t/* Metadata doesn't record how much space is available.\n\t\t\t * For 1.0, we assume we can use up to the superblock\n\t\t\t * if before, else to 4K beyond superblock.\n\t\t\t * For others, assume no change is possible.\n\t\t\t */\n\t\t\tif (mddev->minor_version > 0)\n\t\t\t\tmddev->bitmap_info.space = 0;\n\t\t\telse if (mddev->bitmap_info.offset > 0)\n\t\t\t\tmddev->bitmap_info.space =\n\t\t\t\t\t8 - mddev->bitmap_info.offset;\n\t\t\telse\n\t\t\t\tmddev->bitmap_info.space =\n\t\t\t\t\t-mddev->bitmap_info.offset;\n\t\t}\n\n\t\tif ((le32_to_cpu(sb->feature_map) & MD_FEATURE_RESHAPE_ACTIVE)) {\n\t\t\tmddev->reshape_position = le64_to_cpu(sb->reshape_position);\n\t\t\tmddev->delta_disks = le32_to_cpu(sb->delta_disks);\n\t\t\tmddev->new_level = le32_to_cpu(sb->new_level);\n\t\t\tmddev->new_layout = le32_to_cpu(sb->new_layout);\n\t\t\tmddev->new_chunk_sectors = le32_to_cpu(sb->new_chunk);\n\t\t\tif (mddev->delta_disks < 0 ||\n\t\t\t    (mddev->delta_disks == 0 &&\n\t\t\t     (le32_to_cpu(sb->feature_map)\n\t\t\t      & MD_FEATURE_RESHAPE_BACKWARDS)))\n\t\t\t\tmddev->reshape_backwards = 1;\n\t\t} else {\n\t\t\tmddev->reshape_position = MaxSector;\n\t\t\tmddev->delta_disks = 0;\n\t\t\tmddev->new_level = mddev->level;\n\t\t\tmddev->new_layout = mddev->layout;\n\t\t\tmddev->new_chunk_sectors = mddev->chunk_sectors;\n\t\t}\n\n\t\tif (mddev->level == 0 &&\n\t\t    !(le32_to_cpu(sb->feature_map) & MD_FEATURE_RAID0_LAYOUT))\n\t\t\tmddev->layout = -1;\n\n\t\tif (le32_to_cpu(sb->feature_map) & MD_FEATURE_JOURNAL)\n\t\t\tset_bit(MD_HAS_JOURNAL, &mddev->flags);\n\n\t\tif (le32_to_cpu(sb->feature_map) &\n\t\t    (MD_FEATURE_PPL | MD_FEATURE_MULTIPLE_PPLS)) {\n\t\t\tif (le32_to_cpu(sb->feature_map) &\n\t\t\t    (MD_FEATURE_BITMAP_OFFSET | MD_FEATURE_JOURNAL))\n\t\t\t\treturn -EINVAL;\n\t\t\tif ((le32_to_cpu(sb->feature_map) & MD_FEATURE_PPL) &&\n\t\t\t    (le32_to_cpu(sb->feature_map) &\n\t\t\t\t\t    MD_FEATURE_MULTIPLE_PPLS))\n\t\t\t\treturn -EINVAL;\n\t\t\tset_bit(MD_HAS_PPL, &mddev->flags);\n\t\t}\n\t} else if (mddev->pers == NULL) {\n\t\t/* Insist of good event counter while assembling, except for\n\t\t * spares (which don't need an event count) */\n\t\t++ev1;\n\t\tif (rdev->desc_nr >= 0 &&\n\t\t    rdev->desc_nr < le32_to_cpu(sb->max_dev) &&\n\t\t    (le16_to_cpu(sb->dev_roles[rdev->desc_nr]) < MD_DISK_ROLE_MAX ||\n\t\t     le16_to_cpu(sb->dev_roles[rdev->desc_nr]) == MD_DISK_ROLE_JOURNAL))\n\t\t\tif (ev1 < mddev->events)\n\t\t\t\treturn -EINVAL;\n\t} else if (mddev->bitmap) {\n\t\t/* If adding to array with a bitmap, then we can accept an\n\t\t * older device, but not too old.\n\t\t */\n\t\tif (ev1 < mddev->bitmap->events_cleared)\n\t\t\treturn 0;\n\t\tif (ev1 < mddev->events)\n\t\t\tset_bit(Bitmap_sync, &rdev->flags);\n\t} else {\n\t\tif (ev1 < mddev->events)\n\t\t\t/* just a hot-add of a new device, leave raid_disk at -1 */\n\t\t\treturn 0;\n\t}\n\tif (mddev->level != LEVEL_MULTIPATH) {\n\t\tint role;\n\t\tif (rdev->desc_nr < 0 ||\n\t\t    rdev->desc_nr >= le32_to_cpu(sb->max_dev)) {\n\t\t\trole = MD_DISK_ROLE_SPARE;\n\t\t\trdev->desc_nr = -1;\n\t\t} else\n\t\t\trole = le16_to_cpu(sb->dev_roles[rdev->desc_nr]);\n\t\tswitch(role) {\n\t\tcase MD_DISK_ROLE_SPARE: /* spare */\n\t\t\tbreak;\n\t\tcase MD_DISK_ROLE_FAULTY: /* faulty */\n\t\t\tset_bit(Faulty, &rdev->flags);\n\t\t\tbreak;\n\t\tcase MD_DISK_ROLE_JOURNAL: /* journal device */\n\t\t\tif (!(le32_to_cpu(sb->feature_map) & MD_FEATURE_JOURNAL)) {\n\t\t\t\t/* journal device without journal feature */\n\t\t\t\tpr_warn(\"md: journal device provided without journal feature, ignoring the device\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tset_bit(Journal, &rdev->flags);\n\t\t\trdev->journal_tail = le64_to_cpu(sb->journal_tail);\n\t\t\trdev->raid_disk = 0;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\trdev->saved_raid_disk = role;\n\t\t\tif ((le32_to_cpu(sb->feature_map) &\n\t\t\t     MD_FEATURE_RECOVERY_OFFSET)) {\n\t\t\t\trdev->recovery_offset = le64_to_cpu(sb->recovery_offset);\n\t\t\t\tif (!(le32_to_cpu(sb->feature_map) &\n\t\t\t\t      MD_FEATURE_RECOVERY_BITMAP))\n\t\t\t\t\trdev->saved_raid_disk = -1;\n\t\t\t} else {\n\t\t\t\t/*\n\t\t\t\t * If the array is FROZEN, then the device can't\n\t\t\t\t * be in_sync with rest of array.\n\t\t\t\t */\n\t\t\t\tif (!test_bit(MD_RECOVERY_FROZEN,\n\t\t\t\t\t      &mddev->recovery))\n\t\t\t\t\tset_bit(In_sync, &rdev->flags);\n\t\t\t}\n\t\t\trdev->raid_disk = role;\n\t\t\tbreak;\n\t\t}\n\t\tif (sb->devflags & WriteMostly1)\n\t\t\tset_bit(WriteMostly, &rdev->flags);\n\t\tif (sb->devflags & FailFast1)\n\t\t\tset_bit(FailFast, &rdev->flags);\n\t\tif (le32_to_cpu(sb->feature_map) & MD_FEATURE_REPLACEMENT)\n\t\t\tset_bit(Replacement, &rdev->flags);\n\t} else /* MULTIPATH are always insync */\n\t\tset_bit(In_sync, &rdev->flags);\n\n\treturn 0;\n}\n\nstatic void super_1_sync(struct mddev *mddev, struct md_rdev *rdev)\n{\n\tstruct mdp_superblock_1 *sb;\n\tstruct md_rdev *rdev2;\n\tint max_dev, i;\n\t/* make rdev->sb match mddev and rdev data. */\n\n\tsb = page_address(rdev->sb_page);\n\n\tsb->feature_map = 0;\n\tsb->pad0 = 0;\n\tsb->recovery_offset = cpu_to_le64(0);\n\tmemset(sb->pad3, 0, sizeof(sb->pad3));\n\n\tsb->utime = cpu_to_le64((__u64)mddev->utime);\n\tsb->events = cpu_to_le64(mddev->events);\n\tif (mddev->in_sync)\n\t\tsb->resync_offset = cpu_to_le64(mddev->recovery_cp);\n\telse if (test_bit(MD_JOURNAL_CLEAN, &mddev->flags))\n\t\tsb->resync_offset = cpu_to_le64(MaxSector);\n\telse\n\t\tsb->resync_offset = cpu_to_le64(0);\n\n\tsb->cnt_corrected_read = cpu_to_le32(atomic_read(&rdev->corrected_errors));\n\n\tsb->raid_disks = cpu_to_le32(mddev->raid_disks);\n\tsb->size = cpu_to_le64(mddev->dev_sectors);\n\tsb->chunksize = cpu_to_le32(mddev->chunk_sectors);\n\tsb->level = cpu_to_le32(mddev->level);\n\tsb->layout = cpu_to_le32(mddev->layout);\n\tif (test_bit(FailFast, &rdev->flags))\n\t\tsb->devflags |= FailFast1;\n\telse\n\t\tsb->devflags &= ~FailFast1;\n\n\tif (test_bit(WriteMostly, &rdev->flags))\n\t\tsb->devflags |= WriteMostly1;\n\telse\n\t\tsb->devflags &= ~WriteMostly1;\n\tsb->data_offset = cpu_to_le64(rdev->data_offset);\n\tsb->data_size = cpu_to_le64(rdev->sectors);\n\n\tif (mddev->bitmap && mddev->bitmap_info.file == NULL) {\n\t\tsb->bitmap_offset = cpu_to_le32((__u32)mddev->bitmap_info.offset);\n\t\tsb->feature_map = cpu_to_le32(MD_FEATURE_BITMAP_OFFSET);\n\t}\n\n\tif (rdev->raid_disk >= 0 && !test_bit(Journal, &rdev->flags) &&\n\t    !test_bit(In_sync, &rdev->flags)) {\n\t\tsb->feature_map |=\n\t\t\tcpu_to_le32(MD_FEATURE_RECOVERY_OFFSET);\n\t\tsb->recovery_offset =\n\t\t\tcpu_to_le64(rdev->recovery_offset);\n\t\tif (rdev->saved_raid_disk >= 0 && mddev->bitmap)\n\t\t\tsb->feature_map |=\n\t\t\t\tcpu_to_le32(MD_FEATURE_RECOVERY_BITMAP);\n\t}\n\t/* Note: recovery_offset and journal_tail share space  */\n\tif (test_bit(Journal, &rdev->flags))\n\t\tsb->journal_tail = cpu_to_le64(rdev->journal_tail);\n\tif (test_bit(Replacement, &rdev->flags))\n\t\tsb->feature_map |=\n\t\t\tcpu_to_le32(MD_FEATURE_REPLACEMENT);\n\n\tif (mddev->reshape_position != MaxSector) {\n\t\tsb->feature_map |= cpu_to_le32(MD_FEATURE_RESHAPE_ACTIVE);\n\t\tsb->reshape_position = cpu_to_le64(mddev->reshape_position);\n\t\tsb->new_layout = cpu_to_le32(mddev->new_layout);\n\t\tsb->delta_disks = cpu_to_le32(mddev->delta_disks);\n\t\tsb->new_level = cpu_to_le32(mddev->new_level);\n\t\tsb->new_chunk = cpu_to_le32(mddev->new_chunk_sectors);\n\t\tif (mddev->delta_disks == 0 &&\n\t\t    mddev->reshape_backwards)\n\t\t\tsb->feature_map\n\t\t\t\t|= cpu_to_le32(MD_FEATURE_RESHAPE_BACKWARDS);\n\t\tif (rdev->new_data_offset != rdev->data_offset) {\n\t\t\tsb->feature_map\n\t\t\t\t|= cpu_to_le32(MD_FEATURE_NEW_OFFSET);\n\t\t\tsb->new_offset = cpu_to_le32((__u32)(rdev->new_data_offset\n\t\t\t\t\t\t\t     - rdev->data_offset));\n\t\t}\n\t}\n\n\tif (mddev_is_clustered(mddev))\n\t\tsb->feature_map |= cpu_to_le32(MD_FEATURE_CLUSTERED);\n\n\tif (rdev->badblocks.count == 0)\n\t\t/* Nothing to do for bad blocks*/ ;\n\telse if (sb->bblog_offset == 0)\n\t\t/* Cannot record bad blocks on this device */\n\t\tmd_error(mddev, rdev);\n\telse {\n\t\tstruct badblocks *bb = &rdev->badblocks;\n\t\t__le64 *bbp = (__le64 *)page_address(rdev->bb_page);\n\t\tu64 *p = bb->page;\n\t\tsb->feature_map |= cpu_to_le32(MD_FEATURE_BAD_BLOCKS);\n\t\tif (bb->changed) {\n\t\t\tunsigned seq;\n\nretry:\n\t\t\tseq = read_seqbegin(&bb->lock);\n\n\t\t\tmemset(bbp, 0xff, PAGE_SIZE);\n\n\t\t\tfor (i = 0 ; i < bb->count ; i++) {\n\t\t\t\tu64 internal_bb = p[i];\n\t\t\t\tu64 store_bb = ((BB_OFFSET(internal_bb) << 10)\n\t\t\t\t\t\t| BB_LEN(internal_bb));\n\t\t\t\tbbp[i] = cpu_to_le64(store_bb);\n\t\t\t}\n\t\t\tbb->changed = 0;\n\t\t\tif (read_seqretry(&bb->lock, seq))\n\t\t\t\tgoto retry;\n\n\t\t\tbb->sector = (rdev->sb_start +\n\t\t\t\t      (int)le32_to_cpu(sb->bblog_offset));\n\t\t\tbb->size = le16_to_cpu(sb->bblog_size);\n\t\t}\n\t}\n\n\tmax_dev = 0;\n\trdev_for_each(rdev2, mddev)\n\t\tif (rdev2->desc_nr+1 > max_dev)\n\t\t\tmax_dev = rdev2->desc_nr+1;\n\n\tif (max_dev > le32_to_cpu(sb->max_dev)) {\n\t\tint bmask;\n\t\tsb->max_dev = cpu_to_le32(max_dev);\n\t\trdev->sb_size = max_dev * 2 + 256;\n\t\tbmask = queue_logical_block_size(rdev->bdev->bd_disk->queue)-1;\n\t\tif (rdev->sb_size & bmask)\n\t\t\trdev->sb_size = (rdev->sb_size | bmask) + 1;\n\t} else\n\t\tmax_dev = le32_to_cpu(sb->max_dev);\n\n\tfor (i=0; i<max_dev;i++)\n\t\tsb->dev_roles[i] = cpu_to_le16(MD_DISK_ROLE_SPARE);\n\n\tif (test_bit(MD_HAS_JOURNAL, &mddev->flags))\n\t\tsb->feature_map |= cpu_to_le32(MD_FEATURE_JOURNAL);\n\n\tif (test_bit(MD_HAS_PPL, &mddev->flags)) {\n\t\tif (test_bit(MD_HAS_MULTIPLE_PPLS, &mddev->flags))\n\t\t\tsb->feature_map |=\n\t\t\t    cpu_to_le32(MD_FEATURE_MULTIPLE_PPLS);\n\t\telse\n\t\t\tsb->feature_map |= cpu_to_le32(MD_FEATURE_PPL);\n\t\tsb->ppl.offset = cpu_to_le16(rdev->ppl.offset);\n\t\tsb->ppl.size = cpu_to_le16(rdev->ppl.size);\n\t}\n\n\trdev_for_each(rdev2, mddev) {\n\t\ti = rdev2->desc_nr;\n\t\tif (test_bit(Faulty, &rdev2->flags))\n\t\t\tsb->dev_roles[i] = cpu_to_le16(MD_DISK_ROLE_FAULTY);\n\t\telse if (test_bit(In_sync, &rdev2->flags))\n\t\t\tsb->dev_roles[i] = cpu_to_le16(rdev2->raid_disk);\n\t\telse if (test_bit(Journal, &rdev2->flags))\n\t\t\tsb->dev_roles[i] = cpu_to_le16(MD_DISK_ROLE_JOURNAL);\n\t\telse if (rdev2->raid_disk >= 0)\n\t\t\tsb->dev_roles[i] = cpu_to_le16(rdev2->raid_disk);\n\t\telse\n\t\t\tsb->dev_roles[i] = cpu_to_le16(MD_DISK_ROLE_SPARE);\n\t}\n\n\tsb->sb_csum = calc_sb_1_csum(sb);\n}\n\nstatic sector_t super_1_choose_bm_space(sector_t dev_size)\n{\n\tsector_t bm_space;\n\n\t/* if the device is bigger than 8Gig, save 64k for bitmap\n\t * usage, if bigger than 200Gig, save 128k\n\t */\n\tif (dev_size < 64*2)\n\t\tbm_space = 0;\n\telse if (dev_size - 64*2 >= 200*1024*1024*2)\n\t\tbm_space = 128*2;\n\telse if (dev_size - 4*2 > 8*1024*1024*2)\n\t\tbm_space = 64*2;\n\telse\n\t\tbm_space = 4*2;\n\treturn bm_space;\n}\n\nstatic unsigned long long\nsuper_1_rdev_size_change(struct md_rdev *rdev, sector_t num_sectors)\n{\n\tstruct mdp_superblock_1 *sb;\n\tsector_t max_sectors;\n\tif (num_sectors && num_sectors < rdev->mddev->dev_sectors)\n\t\treturn 0; /* component must fit device */\n\tif (rdev->data_offset != rdev->new_data_offset)\n\t\treturn 0; /* too confusing */\n\tif (rdev->sb_start < rdev->data_offset) {\n\t\t/* minor versions 1 and 2; superblock before data */\n\t\tmax_sectors = i_size_read(rdev->bdev->bd_inode) >> 9;\n\t\tmax_sectors -= rdev->data_offset;\n\t\tif (!num_sectors || num_sectors > max_sectors)\n\t\t\tnum_sectors = max_sectors;\n\t} else if (rdev->mddev->bitmap_info.offset) {\n\t\t/* minor version 0 with bitmap we can't move */\n\t\treturn 0;\n\t} else {\n\t\t/* minor version 0; superblock after data */\n\t\tsector_t sb_start, bm_space;\n\t\tsector_t dev_size = i_size_read(rdev->bdev->bd_inode) >> 9;\n\n\t\t/* 8K is for superblock */\n\t\tsb_start = dev_size - 8*2;\n\t\tsb_start &= ~(sector_t)(4*2 - 1);\n\n\t\tbm_space = super_1_choose_bm_space(dev_size);\n\n\t\t/* Space that can be used to store date needs to decrease\n\t\t * superblock bitmap space and bad block space(4K)\n\t\t */\n\t\tmax_sectors = sb_start - bm_space - 4*2;\n\n\t\tif (!num_sectors || num_sectors > max_sectors)\n\t\t\tnum_sectors = max_sectors;\n\t}\n\tsb = page_address(rdev->sb_page);\n\tsb->data_size = cpu_to_le64(num_sectors);\n\tsb->super_offset = cpu_to_le64(rdev->sb_start);\n\tsb->sb_csum = calc_sb_1_csum(sb);\n\tdo {\n\t\tmd_super_write(rdev->mddev, rdev, rdev->sb_start, rdev->sb_size,\n\t\t\t       rdev->sb_page);\n\t} while (md_super_wait(rdev->mddev) < 0);\n\treturn num_sectors;\n\n}\n\nstatic int\nsuper_1_allow_new_offset(struct md_rdev *rdev,\n\t\t\t unsigned long long new_offset)\n{\n\t/* All necessary checks on new >= old have been done */\n\tstruct bitmap *bitmap;\n\tif (new_offset >= rdev->data_offset)\n\t\treturn 1;\n\n\t/* with 1.0 metadata, there is no metadata to tread on\n\t * so we can always move back */\n\tif (rdev->mddev->minor_version == 0)\n\t\treturn 1;\n\n\t/* otherwise we must be sure not to step on\n\t * any metadata, so stay:\n\t * 36K beyond start of superblock\n\t * beyond end of badblocks\n\t * beyond write-intent bitmap\n\t */\n\tif (rdev->sb_start + (32+4)*2 > new_offset)\n\t\treturn 0;\n\tbitmap = rdev->mddev->bitmap;\n\tif (bitmap && !rdev->mddev->bitmap_info.file &&\n\t    rdev->sb_start + rdev->mddev->bitmap_info.offset +\n\t    bitmap->storage.file_pages * (PAGE_SIZE>>9) > new_offset)\n\t\treturn 0;\n\tif (rdev->badblocks.sector + rdev->badblocks.size > new_offset)\n\t\treturn 0;\n\n\treturn 1;\n}\n\nstatic struct super_type super_types[] = {\n\t[0] = {\n\t\t.name\t= \"0.90.0\",\n\t\t.owner\t= THIS_MODULE,\n\t\t.load_super\t    = super_90_load,\n\t\t.validate_super\t    = super_90_validate,\n\t\t.sync_super\t    = super_90_sync,\n\t\t.rdev_size_change   = super_90_rdev_size_change,\n\t\t.allow_new_offset   = super_90_allow_new_offset,\n\t},\n\t[1] = {\n\t\t.name\t= \"md-1\",\n\t\t.owner\t= THIS_MODULE,\n\t\t.load_super\t    = super_1_load,\n\t\t.validate_super\t    = super_1_validate,\n\t\t.sync_super\t    = super_1_sync,\n\t\t.rdev_size_change   = super_1_rdev_size_change,\n\t\t.allow_new_offset   = super_1_allow_new_offset,\n\t},\n};\n\nstatic void sync_super(struct mddev *mddev, struct md_rdev *rdev)\n{\n\tif (mddev->sync_super) {\n\t\tmddev->sync_super(mddev, rdev);\n\t\treturn;\n\t}\n\n\tBUG_ON(mddev->major_version >= ARRAY_SIZE(super_types));\n\n\tsuper_types[mddev->major_version].sync_super(mddev, rdev);\n}\n\nstatic int match_mddev_units(struct mddev *mddev1, struct mddev *mddev2)\n{\n\tstruct md_rdev *rdev, *rdev2;\n\n\trcu_read_lock();\n\trdev_for_each_rcu(rdev, mddev1) {\n\t\tif (test_bit(Faulty, &rdev->flags) ||\n\t\t    test_bit(Journal, &rdev->flags) ||\n\t\t    rdev->raid_disk == -1)\n\t\t\tcontinue;\n\t\trdev_for_each_rcu(rdev2, mddev2) {\n\t\t\tif (test_bit(Faulty, &rdev2->flags) ||\n\t\t\t    test_bit(Journal, &rdev2->flags) ||\n\t\t\t    rdev2->raid_disk == -1)\n\t\t\t\tcontinue;\n\t\t\tif (rdev->bdev->bd_disk == rdev2->bdev->bd_disk) {\n\t\t\t\trcu_read_unlock();\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}\n\t}\n\trcu_read_unlock();\n\treturn 0;\n}\n\nstatic LIST_HEAD(pending_raid_disks);\n\n/*\n * Try to register data integrity profile for an mddev\n *\n * This is called when an array is started and after a disk has been kicked\n * from the array. It only succeeds if all working and active component devices\n * are integrity capable with matching profiles.\n */\nint md_integrity_register(struct mddev *mddev)\n{\n\tstruct md_rdev *rdev, *reference = NULL;\n\n\tif (list_empty(&mddev->disks))\n\t\treturn 0; /* nothing to do */\n\tif (!mddev->gendisk || blk_get_integrity(mddev->gendisk))\n\t\treturn 0; /* shouldn't register, or already is */\n\trdev_for_each(rdev, mddev) {\n\t\t/* skip spares and non-functional disks */\n\t\tif (test_bit(Faulty, &rdev->flags))\n\t\t\tcontinue;\n\t\tif (rdev->raid_disk < 0)\n\t\t\tcontinue;\n\t\tif (!reference) {\n\t\t\t/* Use the first rdev as the reference */\n\t\t\treference = rdev;\n\t\t\tcontinue;\n\t\t}\n\t\t/* does this rdev's profile match the reference profile? */\n\t\tif (blk_integrity_compare(reference->bdev->bd_disk,\n\t\t\t\trdev->bdev->bd_disk) < 0)\n\t\t\treturn -EINVAL;\n\t}\n\tif (!reference || !bdev_get_integrity(reference->bdev))\n\t\treturn 0;\n\t/*\n\t * All component devices are integrity capable and have matching\n\t * profiles, register the common profile for the md device.\n\t */\n\tblk_integrity_register(mddev->gendisk,\n\t\t\t       bdev_get_integrity(reference->bdev));\n\n\tpr_debug(\"md: data integrity enabled on %s\\n\", mdname(mddev));\n\tif (bioset_integrity_create(&mddev->bio_set, BIO_POOL_SIZE)) {\n\t\tpr_err(\"md: failed to create integrity pool for %s\\n\",\n\t\t       mdname(mddev));\n\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\nEXPORT_SYMBOL(md_integrity_register);\n\n/*\n * Attempt to add an rdev, but only if it is consistent with the current\n * integrity profile\n */\nint md_integrity_add_rdev(struct md_rdev *rdev, struct mddev *mddev)\n{\n\tstruct blk_integrity *bi_mddev;\n\tchar name[BDEVNAME_SIZE];\n\n\tif (!mddev->gendisk)\n\t\treturn 0;\n\n\tbi_mddev = blk_get_integrity(mddev->gendisk);\n\n\tif (!bi_mddev) /* nothing to do */\n\t\treturn 0;\n\n\tif (blk_integrity_compare(mddev->gendisk, rdev->bdev->bd_disk) != 0) {\n\t\tpr_err(\"%s: incompatible integrity profile for %s\\n\",\n\t\t       mdname(mddev), bdevname(rdev->bdev, name));\n\t\treturn -ENXIO;\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL(md_integrity_add_rdev);\n\nstatic int bind_rdev_to_array(struct md_rdev *rdev, struct mddev *mddev)\n{\n\tchar b[BDEVNAME_SIZE];\n\tstruct kobject *ko;\n\tint err;\n\n\t/* prevent duplicates */\n\tif (find_rdev(mddev, rdev->bdev->bd_dev))\n\t\treturn -EEXIST;\n\n\tif ((bdev_read_only(rdev->bdev) || bdev_read_only(rdev->meta_bdev)) &&\n\t    mddev->pers)\n\t\treturn -EROFS;\n\n\t/* make sure rdev->sectors exceeds mddev->dev_sectors */\n\tif (!test_bit(Journal, &rdev->flags) &&\n\t    rdev->sectors &&\n\t    (mddev->dev_sectors == 0 || rdev->sectors < mddev->dev_sectors)) {\n\t\tif (mddev->pers) {\n\t\t\t/* Cannot change size, so fail\n\t\t\t * If mddev->level <= 0, then we don't care\n\t\t\t * about aligning sizes (e.g. linear)\n\t\t\t */\n\t\t\tif (mddev->level > 0)\n\t\t\t\treturn -ENOSPC;\n\t\t} else\n\t\t\tmddev->dev_sectors = rdev->sectors;\n\t}\n\n\t/* Verify rdev->desc_nr is unique.\n\t * If it is -1, assign a free number, else\n\t * check number is not in use\n\t */\n\trcu_read_lock();\n\tif (rdev->desc_nr < 0) {\n\t\tint choice = 0;\n\t\tif (mddev->pers)\n\t\t\tchoice = mddev->raid_disks;\n\t\twhile (md_find_rdev_nr_rcu(mddev, choice))\n\t\t\tchoice++;\n\t\trdev->desc_nr = choice;\n\t} else {\n\t\tif (md_find_rdev_nr_rcu(mddev, rdev->desc_nr)) {\n\t\t\trcu_read_unlock();\n\t\t\treturn -EBUSY;\n\t\t}\n\t}\n\trcu_read_unlock();\n\tif (!test_bit(Journal, &rdev->flags) &&\n\t    mddev->max_disks && rdev->desc_nr >= mddev->max_disks) {\n\t\tpr_warn(\"md: %s: array is limited to %d devices\\n\",\n\t\t\tmdname(mddev), mddev->max_disks);\n\t\treturn -EBUSY;\n\t}\n\tbdevname(rdev->bdev,b);\n\tstrreplace(b, '/', '!');\n\n\trdev->mddev = mddev;\n\tpr_debug(\"md: bind<%s>\\n\", b);\n\n\tif (mddev->raid_disks)\n\t\tmddev_create_serial_pool(mddev, rdev, false);\n\n\tif ((err = kobject_add(&rdev->kobj, &mddev->kobj, \"dev-%s\", b)))\n\t\tgoto fail;\n\n\tko = &part_to_dev(rdev->bdev->bd_part)->kobj;\n\t/* failure here is OK */\n\terr = sysfs_create_link(&rdev->kobj, ko, \"block\");\n\trdev->sysfs_state = sysfs_get_dirent_safe(rdev->kobj.sd, \"state\");\n\trdev->sysfs_unack_badblocks =\n\t\tsysfs_get_dirent_safe(rdev->kobj.sd, \"unacknowledged_bad_blocks\");\n\trdev->sysfs_badblocks =\n\t\tsysfs_get_dirent_safe(rdev->kobj.sd, \"bad_blocks\");\n\n\tlist_add_rcu(&rdev->same_set, &mddev->disks);\n\tbd_link_disk_holder(rdev->bdev, mddev->gendisk);\n\n\t/* May as well allow recovery to be retried once */\n\tmddev->recovery_disabled++;\n\n\treturn 0;\n\n fail:\n\tpr_warn(\"md: failed to register dev-%s for %s\\n\",\n\t\tb, mdname(mddev));\n\treturn err;\n}\n\nstatic void rdev_delayed_delete(struct work_struct *ws)\n{\n\tstruct md_rdev *rdev = container_of(ws, struct md_rdev, del_work);\n\tkobject_del(&rdev->kobj);\n\tkobject_put(&rdev->kobj);\n}\n\nstatic void unbind_rdev_from_array(struct md_rdev *rdev)\n{\n\tchar b[BDEVNAME_SIZE];\n\n\tbd_unlink_disk_holder(rdev->bdev, rdev->mddev->gendisk);\n\tlist_del_rcu(&rdev->same_set);\n\tpr_debug(\"md: unbind<%s>\\n\", bdevname(rdev->bdev,b));\n\tmddev_destroy_serial_pool(rdev->mddev, rdev, false);\n\trdev->mddev = NULL;\n\tsysfs_remove_link(&rdev->kobj, \"block\");\n\tsysfs_put(rdev->sysfs_state);\n\tsysfs_put(rdev->sysfs_unack_badblocks);\n\tsysfs_put(rdev->sysfs_badblocks);\n\trdev->sysfs_state = NULL;\n\trdev->sysfs_unack_badblocks = NULL;\n\trdev->sysfs_badblocks = NULL;\n\trdev->badblocks.count = 0;\n\t/* We need to delay this, otherwise we can deadlock when\n\t * writing to 'remove' to \"dev/state\".  We also need\n\t * to delay it due to rcu usage.\n\t */\n\tsynchronize_rcu();\n\tINIT_WORK(&rdev->del_work, rdev_delayed_delete);\n\tkobject_get(&rdev->kobj);\n\tqueue_work(md_rdev_misc_wq, &rdev->del_work);\n}\n\n/*\n * prevent the device from being mounted, repartitioned or\n * otherwise reused by a RAID array (or any other kernel\n * subsystem), by bd_claiming the device.\n */\nstatic int lock_rdev(struct md_rdev *rdev, dev_t dev, int shared)\n{\n\tint err = 0;\n\tstruct block_device *bdev;\n\n\tbdev = blkdev_get_by_dev(dev, FMODE_READ|FMODE_WRITE|FMODE_EXCL,\n\t\t\t\t shared ? (struct md_rdev *)lock_rdev : rdev);\n\tif (IS_ERR(bdev)) {\n\t\tpr_warn(\"md: could not open device unknown-block(%u,%u).\\n\",\n\t\t\tMAJOR(dev), MINOR(dev));\n\t\treturn PTR_ERR(bdev);\n\t}\n\trdev->bdev = bdev;\n\treturn err;\n}\n\nstatic void unlock_rdev(struct md_rdev *rdev)\n{\n\tstruct block_device *bdev = rdev->bdev;\n\trdev->bdev = NULL;\n\tblkdev_put(bdev, FMODE_READ|FMODE_WRITE|FMODE_EXCL);\n}\n\nvoid md_autodetect_dev(dev_t dev);\n\nstatic void export_rdev(struct md_rdev *rdev)\n{\n\tchar b[BDEVNAME_SIZE];\n\n\tpr_debug(\"md: export_rdev(%s)\\n\", bdevname(rdev->bdev,b));\n\tmd_rdev_clear(rdev);\n#ifndef MODULE\n\tif (test_bit(AutoDetected, &rdev->flags))\n\t\tmd_autodetect_dev(rdev->bdev->bd_dev);\n#endif\n\tunlock_rdev(rdev);\n\tkobject_put(&rdev->kobj);\n}\n\nvoid md_kick_rdev_from_array(struct md_rdev *rdev)\n{\n\tunbind_rdev_from_array(rdev);\n\texport_rdev(rdev);\n}\nEXPORT_SYMBOL_GPL(md_kick_rdev_from_array);\n\nstatic void export_array(struct mddev *mddev)\n{\n\tstruct md_rdev *rdev;\n\n\twhile (!list_empty(&mddev->disks)) {\n\t\trdev = list_first_entry(&mddev->disks, struct md_rdev,\n\t\t\t\t\tsame_set);\n\t\tmd_kick_rdev_from_array(rdev);\n\t}\n\tmddev->raid_disks = 0;\n\tmddev->major_version = 0;\n}\n\nstatic bool set_in_sync(struct mddev *mddev)\n{\n\tlockdep_assert_held(&mddev->lock);\n\tif (!mddev->in_sync) {\n\t\tmddev->sync_checkers++;\n\t\tspin_unlock(&mddev->lock);\n\t\tpercpu_ref_switch_to_atomic_sync(&mddev->writes_pending);\n\t\tspin_lock(&mddev->lock);\n\t\tif (!mddev->in_sync &&\n\t\t    percpu_ref_is_zero(&mddev->writes_pending)) {\n\t\t\tmddev->in_sync = 1;\n\t\t\t/*\n\t\t\t * Ensure ->in_sync is visible before we clear\n\t\t\t * ->sync_checkers.\n\t\t\t */\n\t\t\tsmp_mb();\n\t\t\tset_bit(MD_SB_CHANGE_CLEAN, &mddev->sb_flags);\n\t\t\tsysfs_notify_dirent_safe(mddev->sysfs_state);\n\t\t}\n\t\tif (--mddev->sync_checkers == 0)\n\t\t\tpercpu_ref_switch_to_percpu(&mddev->writes_pending);\n\t}\n\tif (mddev->safemode == 1)\n\t\tmddev->safemode = 0;\n\treturn mddev->in_sync;\n}\n\nstatic void sync_sbs(struct mddev *mddev, int nospares)\n{\n\t/* Update each superblock (in-memory image), but\n\t * if we are allowed to, skip spares which already\n\t * have the right event counter, or have one earlier\n\t * (which would mean they aren't being marked as dirty\n\t * with the rest of the array)\n\t */\n\tstruct md_rdev *rdev;\n\trdev_for_each(rdev, mddev) {\n\t\tif (rdev->sb_events == mddev->events ||\n\t\t    (nospares &&\n\t\t     rdev->raid_disk < 0 &&\n\t\t     rdev->sb_events+1 == mddev->events)) {\n\t\t\t/* Don't update this superblock */\n\t\t\trdev->sb_loaded = 2;\n\t\t} else {\n\t\t\tsync_super(mddev, rdev);\n\t\t\trdev->sb_loaded = 1;\n\t\t}\n\t}\n}\n\nstatic bool does_sb_need_changing(struct mddev *mddev)\n{\n\tstruct md_rdev *rdev;\n\tstruct mdp_superblock_1 *sb;\n\tint role;\n\n\t/* Find a good rdev */\n\trdev_for_each(rdev, mddev)\n\t\tif ((rdev->raid_disk >= 0) && !test_bit(Faulty, &rdev->flags))\n\t\t\tbreak;\n\n\t/* No good device found. */\n\tif (!rdev)\n\t\treturn false;\n\n\tsb = page_address(rdev->sb_page);\n\t/* Check if a device has become faulty or a spare become active */\n\trdev_for_each(rdev, mddev) {\n\t\trole = le16_to_cpu(sb->dev_roles[rdev->desc_nr]);\n\t\t/* Device activated? */\n\t\tif (role == 0xffff && rdev->raid_disk >=0 &&\n\t\t    !test_bit(Faulty, &rdev->flags))\n\t\t\treturn true;\n\t\t/* Device turned faulty? */\n\t\tif (test_bit(Faulty, &rdev->flags) && (role < 0xfffd))\n\t\t\treturn true;\n\t}\n\n\t/* Check if any mddev parameters have changed */\n\tif ((mddev->dev_sectors != le64_to_cpu(sb->size)) ||\n\t    (mddev->reshape_position != le64_to_cpu(sb->reshape_position)) ||\n\t    (mddev->layout != le32_to_cpu(sb->layout)) ||\n\t    (mddev->raid_disks != le32_to_cpu(sb->raid_disks)) ||\n\t    (mddev->chunk_sectors != le32_to_cpu(sb->chunksize)))\n\t\treturn true;\n\n\treturn false;\n}\n\nvoid md_update_sb(struct mddev *mddev, int force_change)\n{\n\tstruct md_rdev *rdev;\n\tint sync_req;\n\tint nospares = 0;\n\tint any_badblocks_changed = 0;\n\tint ret = -1;\n\n\tif (mddev->ro) {\n\t\tif (force_change)\n\t\t\tset_bit(MD_SB_CHANGE_DEVS, &mddev->sb_flags);\n\t\treturn;\n\t}\n\nrepeat:\n\tif (mddev_is_clustered(mddev)) {\n\t\tif (test_and_clear_bit(MD_SB_CHANGE_DEVS, &mddev->sb_flags))\n\t\t\tforce_change = 1;\n\t\tif (test_and_clear_bit(MD_SB_CHANGE_CLEAN, &mddev->sb_flags))\n\t\t\tnospares = 1;\n\t\tret = md_cluster_ops->metadata_update_start(mddev);\n\t\t/* Has someone else has updated the sb */\n\t\tif (!does_sb_need_changing(mddev)) {\n\t\t\tif (ret == 0)\n\t\t\t\tmd_cluster_ops->metadata_update_cancel(mddev);\n\t\t\tbit_clear_unless(&mddev->sb_flags, BIT(MD_SB_CHANGE_PENDING),\n\t\t\t\t\t\t\t BIT(MD_SB_CHANGE_DEVS) |\n\t\t\t\t\t\t\t BIT(MD_SB_CHANGE_CLEAN));\n\t\t\treturn;\n\t\t}\n\t}\n\n\t/*\n\t * First make sure individual recovery_offsets are correct\n\t * curr_resync_completed can only be used during recovery.\n\t * During reshape/resync it might use array-addresses rather\n\t * that device addresses.\n\t */\n\trdev_for_each(rdev, mddev) {\n\t\tif (rdev->raid_disk >= 0 &&\n\t\t    mddev->delta_disks >= 0 &&\n\t\t    test_bit(MD_RECOVERY_RUNNING, &mddev->recovery) &&\n\t\t    test_bit(MD_RECOVERY_RECOVER, &mddev->recovery) &&\n\t\t    !test_bit(MD_RECOVERY_RESHAPE, &mddev->recovery) &&\n\t\t    !test_bit(Journal, &rdev->flags) &&\n\t\t    !test_bit(In_sync, &rdev->flags) &&\n\t\t    mddev->curr_resync_completed > rdev->recovery_offset)\n\t\t\t\trdev->recovery_offset = mddev->curr_resync_completed;\n\n\t}\n\tif (!mddev->persistent) {\n\t\tclear_bit(MD_SB_CHANGE_CLEAN, &mddev->sb_flags);\n\t\tclear_bit(MD_SB_CHANGE_DEVS, &mddev->sb_flags);\n\t\tif (!mddev->external) {\n\t\t\tclear_bit(MD_SB_CHANGE_PENDING, &mddev->sb_flags);\n\t\t\trdev_for_each(rdev, mddev) {\n\t\t\t\tif (rdev->badblocks.changed) {\n\t\t\t\t\trdev->badblocks.changed = 0;\n\t\t\t\t\tack_all_badblocks(&rdev->badblocks);\n\t\t\t\t\tmd_error(mddev, rdev);\n\t\t\t\t}\n\t\t\t\tclear_bit(Blocked, &rdev->flags);\n\t\t\t\tclear_bit(BlockedBadBlocks, &rdev->flags);\n\t\t\t\twake_up(&rdev->blocked_wait);\n\t\t\t}\n\t\t}\n\t\twake_up(&mddev->sb_wait);\n\t\treturn;\n\t}\n\n\tspin_lock(&mddev->lock);\n\n\tmddev->utime = ktime_get_real_seconds();\n\n\tif (test_and_clear_bit(MD_SB_CHANGE_DEVS, &mddev->sb_flags))\n\t\tforce_change = 1;\n\tif (test_and_clear_bit(MD_SB_CHANGE_CLEAN, &mddev->sb_flags))\n\t\t/* just a clean<-> dirty transition, possibly leave spares alone,\n\t\t * though if events isn't the right even/odd, we will have to do\n\t\t * spares after all\n\t\t */\n\t\tnospares = 1;\n\tif (force_change)\n\t\tnospares = 0;\n\tif (mddev->degraded)\n\t\t/* If the array is degraded, then skipping spares is both\n\t\t * dangerous and fairly pointless.\n\t\t * Dangerous because a device that was removed from the array\n\t\t * might have a event_count that still looks up-to-date,\n\t\t * so it can be re-added without a resync.\n\t\t * Pointless because if there are any spares to skip,\n\t\t * then a recovery will happen and soon that array won't\n\t\t * be degraded any more and the spare can go back to sleep then.\n\t\t */\n\t\tnospares = 0;\n\n\tsync_req = mddev->in_sync;\n\n\t/* If this is just a dirty<->clean transition, and the array is clean\n\t * and 'events' is odd, we can roll back to the previous clean state */\n\tif (nospares\n\t    && (mddev->in_sync && mddev->recovery_cp == MaxSector)\n\t    && mddev->can_decrease_events\n\t    && mddev->events != 1) {\n\t\tmddev->events--;\n\t\tmddev->can_decrease_events = 0;\n\t} else {\n\t\t/* otherwise we have to go forward and ... */\n\t\tmddev->events ++;\n\t\tmddev->can_decrease_events = nospares;\n\t}\n\n\t/*\n\t * This 64-bit counter should never wrap.\n\t * Either we are in around ~1 trillion A.C., assuming\n\t * 1 reboot per second, or we have a bug...\n\t */\n\tWARN_ON(mddev->events == 0);\n\n\trdev_for_each(rdev, mddev) {\n\t\tif (rdev->badblocks.changed)\n\t\t\tany_badblocks_changed++;\n\t\tif (test_bit(Faulty, &rdev->flags))\n\t\t\tset_bit(FaultRecorded, &rdev->flags);\n\t}\n\n\tsync_sbs(mddev, nospares);\n\tspin_unlock(&mddev->lock);\n\n\tpr_debug(\"md: updating %s RAID superblock on device (in sync %d)\\n\",\n\t\t mdname(mddev), mddev->in_sync);\n\n\tif (mddev->queue)\n\t\tblk_add_trace_msg(mddev->queue, \"md md_update_sb\");\nrewrite:\n\tmd_bitmap_update_sb(mddev->bitmap);\n\trdev_for_each(rdev, mddev) {\n\t\tchar b[BDEVNAME_SIZE];\n\n\t\tif (rdev->sb_loaded != 1)\n\t\t\tcontinue; /* no noise on spare devices */\n\n\t\tif (!test_bit(Faulty, &rdev->flags)) {\n\t\t\tmd_super_write(mddev,rdev,\n\t\t\t\t       rdev->sb_start, rdev->sb_size,\n\t\t\t\t       rdev->sb_page);\n\t\t\tpr_debug(\"md: (write) %s's sb offset: %llu\\n\",\n\t\t\t\t bdevname(rdev->bdev, b),\n\t\t\t\t (unsigned long long)rdev->sb_start);\n\t\t\trdev->sb_events = mddev->events;\n\t\t\tif (rdev->badblocks.size) {\n\t\t\t\tmd_super_write(mddev, rdev,\n\t\t\t\t\t       rdev->badblocks.sector,\n\t\t\t\t\t       rdev->badblocks.size << 9,\n\t\t\t\t\t       rdev->bb_page);\n\t\t\t\trdev->badblocks.size = 0;\n\t\t\t}\n\n\t\t} else\n\t\t\tpr_debug(\"md: %s (skipping faulty)\\n\",\n\t\t\t\t bdevname(rdev->bdev, b));\n\n\t\tif (mddev->level == LEVEL_MULTIPATH)\n\t\t\t/* only need to write one superblock... */\n\t\t\tbreak;\n\t}\n\tif (md_super_wait(mddev) < 0)\n\t\tgoto rewrite;\n\t/* if there was a failure, MD_SB_CHANGE_DEVS was set, and we re-write super */\n\n\tif (mddev_is_clustered(mddev) && ret == 0)\n\t\tmd_cluster_ops->metadata_update_finish(mddev);\n\n\tif (mddev->in_sync != sync_req ||\n\t    !bit_clear_unless(&mddev->sb_flags, BIT(MD_SB_CHANGE_PENDING),\n\t\t\t       BIT(MD_SB_CHANGE_DEVS) | BIT(MD_SB_CHANGE_CLEAN)))\n\t\t/* have to write it out again */\n\t\tgoto repeat;\n\twake_up(&mddev->sb_wait);\n\tif (test_bit(MD_RECOVERY_RUNNING, &mddev->recovery))\n\t\tsysfs_notify_dirent_safe(mddev->sysfs_completed);\n\n\trdev_for_each(rdev, mddev) {\n\t\tif (test_and_clear_bit(FaultRecorded, &rdev->flags))\n\t\t\tclear_bit(Blocked, &rdev->flags);\n\n\t\tif (any_badblocks_changed)\n\t\t\tack_all_badblocks(&rdev->badblocks);\n\t\tclear_bit(BlockedBadBlocks, &rdev->flags);\n\t\twake_up(&rdev->blocked_wait);\n\t}\n}\nEXPORT_SYMBOL(md_update_sb);\n\nstatic int add_bound_rdev(struct md_rdev *rdev)\n{\n\tstruct mddev *mddev = rdev->mddev;\n\tint err = 0;\n\tbool add_journal = test_bit(Journal, &rdev->flags);\n\n\tif (!mddev->pers->hot_remove_disk || add_journal) {\n\t\t/* If there is hot_add_disk but no hot_remove_disk\n\t\t * then added disks for geometry changes,\n\t\t * and should be added immediately.\n\t\t */\n\t\tsuper_types[mddev->major_version].\n\t\t\tvalidate_super(mddev, rdev);\n\t\tif (add_journal)\n\t\t\tmddev_suspend(mddev);\n\t\terr = mddev->pers->hot_add_disk(mddev, rdev);\n\t\tif (add_journal)\n\t\t\tmddev_resume(mddev);\n\t\tif (err) {\n\t\t\tmd_kick_rdev_from_array(rdev);\n\t\t\treturn err;\n\t\t}\n\t}\n\tsysfs_notify_dirent_safe(rdev->sysfs_state);\n\n\tset_bit(MD_SB_CHANGE_DEVS, &mddev->sb_flags);\n\tif (mddev->degraded)\n\t\tset_bit(MD_RECOVERY_RECOVER, &mddev->recovery);\n\tset_bit(MD_RECOVERY_NEEDED, &mddev->recovery);\n\tmd_new_event(mddev);\n\tmd_wakeup_thread(mddev->thread);\n\treturn 0;\n}\n\n/* words written to sysfs files may, or may not, be \\n terminated.\n * We want to accept with case. For this we use cmd_match.\n */\nstatic int cmd_match(const char *cmd, const char *str)\n{\n\t/* See if cmd, written into a sysfs file, matches\n\t * str.  They must either be the same, or cmd can\n\t * have a trailing newline\n\t */\n\twhile (*cmd && *str && *cmd == *str) {\n\t\tcmd++;\n\t\tstr++;\n\t}\n\tif (*cmd == '\\n')\n\t\tcmd++;\n\tif (*str || *cmd)\n\t\treturn 0;\n\treturn 1;\n}\n\nstruct rdev_sysfs_entry {\n\tstruct attribute attr;\n\tssize_t (*show)(struct md_rdev *, char *);\n\tssize_t (*store)(struct md_rdev *, const char *, size_t);\n};\n\nstatic ssize_t\nstate_show(struct md_rdev *rdev, char *page)\n{\n\tchar *sep = \",\";\n\tsize_t len = 0;\n\tunsigned long flags = READ_ONCE(rdev->flags);\n\n\tif (test_bit(Faulty, &flags) ||\n\t    (!test_bit(ExternalBbl, &flags) &&\n\t    rdev->badblocks.unacked_exist))\n\t\tlen += sprintf(page+len, \"faulty%s\", sep);\n\tif (test_bit(In_sync, &flags))\n\t\tlen += sprintf(page+len, \"in_sync%s\", sep);\n\tif (test_bit(Journal, &flags))\n\t\tlen += sprintf(page+len, \"journal%s\", sep);\n\tif (test_bit(WriteMostly, &flags))\n\t\tlen += sprintf(page+len, \"write_mostly%s\", sep);\n\tif (test_bit(Blocked, &flags) ||\n\t    (rdev->badblocks.unacked_exist\n\t     && !test_bit(Faulty, &flags)))\n\t\tlen += sprintf(page+len, \"blocked%s\", sep);\n\tif (!test_bit(Faulty, &flags) &&\n\t    !test_bit(Journal, &flags) &&\n\t    !test_bit(In_sync, &flags))\n\t\tlen += sprintf(page+len, \"spare%s\", sep);\n\tif (test_bit(WriteErrorSeen, &flags))\n\t\tlen += sprintf(page+len, \"write_error%s\", sep);\n\tif (test_bit(WantReplacement, &flags))\n\t\tlen += sprintf(page+len, \"want_replacement%s\", sep);\n\tif (test_bit(Replacement, &flags))\n\t\tlen += sprintf(page+len, \"replacement%s\", sep);\n\tif (test_bit(ExternalBbl, &flags))\n\t\tlen += sprintf(page+len, \"external_bbl%s\", sep);\n\tif (test_bit(FailFast, &flags))\n\t\tlen += sprintf(page+len, \"failfast%s\", sep);\n\n\tif (len)\n\t\tlen -= strlen(sep);\n\n\treturn len+sprintf(page+len, \"\\n\");\n}\n\nstatic ssize_t\nstate_store(struct md_rdev *rdev, const char *buf, size_t len)\n{\n\t/* can write\n\t *  faulty  - simulates an error\n\t *  remove  - disconnects the device\n\t *  writemostly - sets write_mostly\n\t *  -writemostly - clears write_mostly\n\t *  blocked - sets the Blocked flags\n\t *  -blocked - clears the Blocked and possibly simulates an error\n\t *  insync - sets Insync providing device isn't active\n\t *  -insync - clear Insync for a device with a slot assigned,\n\t *            so that it gets rebuilt based on bitmap\n\t *  write_error - sets WriteErrorSeen\n\t *  -write_error - clears WriteErrorSeen\n\t *  {,-}failfast - set/clear FailFast\n\t */\n\tint err = -EINVAL;\n\tif (cmd_match(buf, \"faulty\") && rdev->mddev->pers) {\n\t\tmd_error(rdev->mddev, rdev);\n\t\tif (test_bit(Faulty, &rdev->flags))\n\t\t\terr = 0;\n\t\telse\n\t\t\terr = -EBUSY;\n\t} else if (cmd_match(buf, \"remove\")) {\n\t\tif (rdev->mddev->pers) {\n\t\t\tclear_bit(Blocked, &rdev->flags);\n\t\t\tremove_and_add_spares(rdev->mddev, rdev);\n\t\t}\n\t\tif (rdev->raid_disk >= 0)\n\t\t\terr = -EBUSY;\n\t\telse {\n\t\t\tstruct mddev *mddev = rdev->mddev;\n\t\t\terr = 0;\n\t\t\tif (mddev_is_clustered(mddev))\n\t\t\t\terr = md_cluster_ops->remove_disk(mddev, rdev);\n\n\t\t\tif (err == 0) {\n\t\t\t\tmd_kick_rdev_from_array(rdev);\n\t\t\t\tif (mddev->pers) {\n\t\t\t\t\tset_bit(MD_SB_CHANGE_DEVS, &mddev->sb_flags);\n\t\t\t\t\tmd_wakeup_thread(mddev->thread);\n\t\t\t\t}\n\t\t\t\tmd_new_event(mddev);\n\t\t\t}\n\t\t}\n\t} else if (cmd_match(buf, \"writemostly\")) {\n\t\tset_bit(WriteMostly, &rdev->flags);\n\t\tmddev_create_serial_pool(rdev->mddev, rdev, false);\n\t\terr = 0;\n\t} else if (cmd_match(buf, \"-writemostly\")) {\n\t\tmddev_destroy_serial_pool(rdev->mddev, rdev, false);\n\t\tclear_bit(WriteMostly, &rdev->flags);\n\t\terr = 0;\n\t} else if (cmd_match(buf, \"blocked\")) {\n\t\tset_bit(Blocked, &rdev->flags);\n\t\terr = 0;\n\t} else if (cmd_match(buf, \"-blocked\")) {\n\t\tif (!test_bit(Faulty, &rdev->flags) &&\n\t\t    !test_bit(ExternalBbl, &rdev->flags) &&\n\t\t    rdev->badblocks.unacked_exist) {\n\t\t\t/* metadata handler doesn't understand badblocks,\n\t\t\t * so we need to fail the device\n\t\t\t */\n\t\t\tmd_error(rdev->mddev, rdev);\n\t\t}\n\t\tclear_bit(Blocked, &rdev->flags);\n\t\tclear_bit(BlockedBadBlocks, &rdev->flags);\n\t\twake_up(&rdev->blocked_wait);\n\t\tset_bit(MD_RECOVERY_NEEDED, &rdev->mddev->recovery);\n\t\tmd_wakeup_thread(rdev->mddev->thread);\n\n\t\terr = 0;\n\t} else if (cmd_match(buf, \"insync\") && rdev->raid_disk == -1) {\n\t\tset_bit(In_sync, &rdev->flags);\n\t\terr = 0;\n\t} else if (cmd_match(buf, \"failfast\")) {\n\t\tset_bit(FailFast, &rdev->flags);\n\t\terr = 0;\n\t} else if (cmd_match(buf, \"-failfast\")) {\n\t\tclear_bit(FailFast, &rdev->flags);\n\t\terr = 0;\n\t} else if (cmd_match(buf, \"-insync\") && rdev->raid_disk >= 0 &&\n\t\t   !test_bit(Journal, &rdev->flags)) {\n\t\tif (rdev->mddev->pers == NULL) {\n\t\t\tclear_bit(In_sync, &rdev->flags);\n\t\t\trdev->saved_raid_disk = rdev->raid_disk;\n\t\t\trdev->raid_disk = -1;\n\t\t\terr = 0;\n\t\t}\n\t} else if (cmd_match(buf, \"write_error\")) {\n\t\tset_bit(WriteErrorSeen, &rdev->flags);\n\t\terr = 0;\n\t} else if (cmd_match(buf, \"-write_error\")) {\n\t\tclear_bit(WriteErrorSeen, &rdev->flags);\n\t\terr = 0;\n\t} else if (cmd_match(buf, \"want_replacement\")) {\n\t\t/* Any non-spare device that is not a replacement can\n\t\t * become want_replacement at any time, but we then need to\n\t\t * check if recovery is needed.\n\t\t */\n\t\tif (rdev->raid_disk >= 0 &&\n\t\t    !test_bit(Journal, &rdev->flags) &&\n\t\t    !test_bit(Replacement, &rdev->flags))\n\t\t\tset_bit(WantReplacement, &rdev->flags);\n\t\tset_bit(MD_RECOVERY_NEEDED, &rdev->mddev->recovery);\n\t\tmd_wakeup_thread(rdev->mddev->thread);\n\t\terr = 0;\n\t} else if (cmd_match(buf, \"-want_replacement\")) {\n\t\t/* Clearing 'want_replacement' is always allowed.\n\t\t * Once replacements starts it is too late though.\n\t\t */\n\t\terr = 0;\n\t\tclear_bit(WantReplacement, &rdev->flags);\n\t} else if (cmd_match(buf, \"replacement\")) {\n\t\t/* Can only set a device as a replacement when array has not\n\t\t * yet been started.  Once running, replacement is automatic\n\t\t * from spares, or by assigning 'slot'.\n\t\t */\n\t\tif (rdev->mddev->pers)\n\t\t\terr = -EBUSY;\n\t\telse {\n\t\t\tset_bit(Replacement, &rdev->flags);\n\t\t\terr = 0;\n\t\t}\n\t} else if (cmd_match(buf, \"-replacement\")) {\n\t\t/* Similarly, can only clear Replacement before start */\n\t\tif (rdev->mddev->pers)\n\t\t\terr = -EBUSY;\n\t\telse {\n\t\t\tclear_bit(Replacement, &rdev->flags);\n\t\t\terr = 0;\n\t\t}\n\t} else if (cmd_match(buf, \"re-add\")) {\n\t\tif (!rdev->mddev->pers)\n\t\t\terr = -EINVAL;\n\t\telse if (test_bit(Faulty, &rdev->flags) && (rdev->raid_disk == -1) &&\n\t\t\t\trdev->saved_raid_disk >= 0) {\n\t\t\t/* clear_bit is performed _after_ all the devices\n\t\t\t * have their local Faulty bit cleared. If any writes\n\t\t\t * happen in the meantime in the local node, they\n\t\t\t * will land in the local bitmap, which will be synced\n\t\t\t * by this node eventually\n\t\t\t */\n\t\t\tif (!mddev_is_clustered(rdev->mddev) ||\n\t\t\t    (err = md_cluster_ops->gather_bitmaps(rdev)) == 0) {\n\t\t\t\tclear_bit(Faulty, &rdev->flags);\n\t\t\t\terr = add_bound_rdev(rdev);\n\t\t\t}\n\t\t} else\n\t\t\terr = -EBUSY;\n\t} else if (cmd_match(buf, \"external_bbl\") && (rdev->mddev->external)) {\n\t\tset_bit(ExternalBbl, &rdev->flags);\n\t\trdev->badblocks.shift = 0;\n\t\terr = 0;\n\t} else if (cmd_match(buf, \"-external_bbl\") && (rdev->mddev->external)) {\n\t\tclear_bit(ExternalBbl, &rdev->flags);\n\t\terr = 0;\n\t}\n\tif (!err)\n\t\tsysfs_notify_dirent_safe(rdev->sysfs_state);\n\treturn err ? err : len;\n}\nstatic struct rdev_sysfs_entry rdev_state =\n__ATTR_PREALLOC(state, S_IRUGO|S_IWUSR, state_show, state_store);\n\nstatic ssize_t\nerrors_show(struct md_rdev *rdev, char *page)\n{\n\treturn sprintf(page, \"%d\\n\", atomic_read(&rdev->corrected_errors));\n}\n\nstatic ssize_t\nerrors_store(struct md_rdev *rdev, const char *buf, size_t len)\n{\n\tunsigned int n;\n\tint rv;\n\n\trv = kstrtouint(buf, 10, &n);\n\tif (rv < 0)\n\t\treturn rv;\n\tatomic_set(&rdev->corrected_errors, n);\n\treturn len;\n}\nstatic struct rdev_sysfs_entry rdev_errors =\n__ATTR(errors, S_IRUGO|S_IWUSR, errors_show, errors_store);\n\nstatic ssize_t\nslot_show(struct md_rdev *rdev, char *page)\n{\n\tif (test_bit(Journal, &rdev->flags))\n\t\treturn sprintf(page, \"journal\\n\");\n\telse if (rdev->raid_disk < 0)\n\t\treturn sprintf(page, \"none\\n\");\n\telse\n\t\treturn sprintf(page, \"%d\\n\", rdev->raid_disk);\n}\n\nstatic ssize_t\nslot_store(struct md_rdev *rdev, const char *buf, size_t len)\n{\n\tint slot;\n\tint err;\n\n\tif (test_bit(Journal, &rdev->flags))\n\t\treturn -EBUSY;\n\tif (strncmp(buf, \"none\", 4)==0)\n\t\tslot = -1;\n\telse {\n\t\terr = kstrtouint(buf, 10, (unsigned int *)&slot);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t}\n\tif (rdev->mddev->pers && slot == -1) {\n\t\t/* Setting 'slot' on an active array requires also\n\t\t * updating the 'rd%d' link, and communicating\n\t\t * with the personality with ->hot_*_disk.\n\t\t * For now we only support removing\n\t\t * failed/spare devices.  This normally happens automatically,\n\t\t * but not when the metadata is externally managed.\n\t\t */\n\t\tif (rdev->raid_disk == -1)\n\t\t\treturn -EEXIST;\n\t\t/* personality does all needed checks */\n\t\tif (rdev->mddev->pers->hot_remove_disk == NULL)\n\t\t\treturn -EINVAL;\n\t\tclear_bit(Blocked, &rdev->flags);\n\t\tremove_and_add_spares(rdev->mddev, rdev);\n\t\tif (rdev->raid_disk >= 0)\n\t\t\treturn -EBUSY;\n\t\tset_bit(MD_RECOVERY_NEEDED, &rdev->mddev->recovery);\n\t\tmd_wakeup_thread(rdev->mddev->thread);\n\t} else if (rdev->mddev->pers) {\n\t\t/* Activating a spare .. or possibly reactivating\n\t\t * if we ever get bitmaps working here.\n\t\t */\n\t\tint err;\n\n\t\tif (rdev->raid_disk != -1)\n\t\t\treturn -EBUSY;\n\n\t\tif (test_bit(MD_RECOVERY_RUNNING, &rdev->mddev->recovery))\n\t\t\treturn -EBUSY;\n\n\t\tif (rdev->mddev->pers->hot_add_disk == NULL)\n\t\t\treturn -EINVAL;\n\n\t\tif (slot >= rdev->mddev->raid_disks &&\n\t\t    slot >= rdev->mddev->raid_disks + rdev->mddev->delta_disks)\n\t\t\treturn -ENOSPC;\n\n\t\trdev->raid_disk = slot;\n\t\tif (test_bit(In_sync, &rdev->flags))\n\t\t\trdev->saved_raid_disk = slot;\n\t\telse\n\t\t\trdev->saved_raid_disk = -1;\n\t\tclear_bit(In_sync, &rdev->flags);\n\t\tclear_bit(Bitmap_sync, &rdev->flags);\n\t\terr = rdev->mddev->pers->hot_add_disk(rdev->mddev, rdev);\n\t\tif (err) {\n\t\t\trdev->raid_disk = -1;\n\t\t\treturn err;\n\t\t} else\n\t\t\tsysfs_notify_dirent_safe(rdev->sysfs_state);\n\t\t/* failure here is OK */;\n\t\tsysfs_link_rdev(rdev->mddev, rdev);\n\t\t/* don't wakeup anyone, leave that to userspace. */\n\t} else {\n\t\tif (slot >= rdev->mddev->raid_disks &&\n\t\t    slot >= rdev->mddev->raid_disks + rdev->mddev->delta_disks)\n\t\t\treturn -ENOSPC;\n\t\trdev->raid_disk = slot;\n\t\t/* assume it is working */\n\t\tclear_bit(Faulty, &rdev->flags);\n\t\tclear_bit(WriteMostly, &rdev->flags);\n\t\tset_bit(In_sync, &rdev->flags);\n\t\tsysfs_notify_dirent_safe(rdev->sysfs_state);\n\t}\n\treturn len;\n}\n\nstatic struct rdev_sysfs_entry rdev_slot =\n__ATTR(slot, S_IRUGO|S_IWUSR, slot_show, slot_store);\n\nstatic ssize_t\noffset_show(struct md_rdev *rdev, char *page)\n{\n\treturn sprintf(page, \"%llu\\n\", (unsigned long long)rdev->data_offset);\n}\n\nstatic ssize_t\noffset_store(struct md_rdev *rdev, const char *buf, size_t len)\n{\n\tunsigned long long offset;\n\tif (kstrtoull(buf, 10, &offset) < 0)\n\t\treturn -EINVAL;\n\tif (rdev->mddev->pers && rdev->raid_disk >= 0)\n\t\treturn -EBUSY;\n\tif (rdev->sectors && rdev->mddev->external)\n\t\t/* Must set offset before size, so overlap checks\n\t\t * can be sane */\n\t\treturn -EBUSY;\n\trdev->data_offset = offset;\n\trdev->new_data_offset = offset;\n\treturn len;\n}\n\nstatic struct rdev_sysfs_entry rdev_offset =\n__ATTR(offset, S_IRUGO|S_IWUSR, offset_show, offset_store);\n\nstatic ssize_t new_offset_show(struct md_rdev *rdev, char *page)\n{\n\treturn sprintf(page, \"%llu\\n\",\n\t\t       (unsigned long long)rdev->new_data_offset);\n}\n\nstatic ssize_t new_offset_store(struct md_rdev *rdev,\n\t\t\t\tconst char *buf, size_t len)\n{\n\tunsigned long long new_offset;\n\tstruct mddev *mddev = rdev->mddev;\n\n\tif (kstrtoull(buf, 10, &new_offset) < 0)\n\t\treturn -EINVAL;\n\n\tif (mddev->sync_thread ||\n\t    test_bit(MD_RECOVERY_RUNNING,&mddev->recovery))\n\t\treturn -EBUSY;\n\tif (new_offset == rdev->data_offset)\n\t\t/* reset is always permitted */\n\t\t;\n\telse if (new_offset > rdev->data_offset) {\n\t\t/* must not push array size beyond rdev_sectors */\n\t\tif (new_offset - rdev->data_offset\n\t\t    + mddev->dev_sectors > rdev->sectors)\n\t\t\t\treturn -E2BIG;\n\t}\n\t/* Metadata worries about other space details. */\n\n\t/* decreasing the offset is inconsistent with a backwards\n\t * reshape.\n\t */\n\tif (new_offset < rdev->data_offset &&\n\t    mddev->reshape_backwards)\n\t\treturn -EINVAL;\n\t/* Increasing offset is inconsistent with forwards\n\t * reshape.  reshape_direction should be set to\n\t * 'backwards' first.\n\t */\n\tif (new_offset > rdev->data_offset &&\n\t    !mddev->reshape_backwards)\n\t\treturn -EINVAL;\n\n\tif (mddev->pers && mddev->persistent &&\n\t    !super_types[mddev->major_version]\n\t    .allow_new_offset(rdev, new_offset))\n\t\treturn -E2BIG;\n\trdev->new_data_offset = new_offset;\n\tif (new_offset > rdev->data_offset)\n\t\tmddev->reshape_backwards = 1;\n\telse if (new_offset < rdev->data_offset)\n\t\tmddev->reshape_backwards = 0;\n\n\treturn len;\n}\nstatic struct rdev_sysfs_entry rdev_new_offset =\n__ATTR(new_offset, S_IRUGO|S_IWUSR, new_offset_show, new_offset_store);\n\nstatic ssize_t\nrdev_size_show(struct md_rdev *rdev, char *page)\n{\n\treturn sprintf(page, \"%llu\\n\", (unsigned long long)rdev->sectors / 2);\n}\n\nstatic int overlaps(sector_t s1, sector_t l1, sector_t s2, sector_t l2)\n{\n\t/* check if two start/length pairs overlap */\n\tif (s1+l1 <= s2)\n\t\treturn 0;\n\tif (s2+l2 <= s1)\n\t\treturn 0;\n\treturn 1;\n}\n\nstatic int strict_blocks_to_sectors(const char *buf, sector_t *sectors)\n{\n\tunsigned long long blocks;\n\tsector_t new;\n\n\tif (kstrtoull(buf, 10, &blocks) < 0)\n\t\treturn -EINVAL;\n\n\tif (blocks & 1ULL << (8 * sizeof(blocks) - 1))\n\t\treturn -EINVAL; /* sector conversion overflow */\n\n\tnew = blocks * 2;\n\tif (new != blocks * 2)\n\t\treturn -EINVAL; /* unsigned long long to sector_t overflow */\n\n\t*sectors = new;\n\treturn 0;\n}\n\nstatic ssize_t\nrdev_size_store(struct md_rdev *rdev, const char *buf, size_t len)\n{\n\tstruct mddev *my_mddev = rdev->mddev;\n\tsector_t oldsectors = rdev->sectors;\n\tsector_t sectors;\n\n\tif (test_bit(Journal, &rdev->flags))\n\t\treturn -EBUSY;\n\tif (strict_blocks_to_sectors(buf, &sectors) < 0)\n\t\treturn -EINVAL;\n\tif (rdev->data_offset != rdev->new_data_offset)\n\t\treturn -EINVAL; /* too confusing */\n\tif (my_mddev->pers && rdev->raid_disk >= 0) {\n\t\tif (my_mddev->persistent) {\n\t\t\tsectors = super_types[my_mddev->major_version].\n\t\t\t\trdev_size_change(rdev, sectors);\n\t\t\tif (!sectors)\n\t\t\t\treturn -EBUSY;\n\t\t} else if (!sectors)\n\t\t\tsectors = (i_size_read(rdev->bdev->bd_inode) >> 9) -\n\t\t\t\trdev->data_offset;\n\t\tif (!my_mddev->pers->resize)\n\t\t\t/* Cannot change size for RAID0 or Linear etc */\n\t\t\treturn -EINVAL;\n\t}\n\tif (sectors < my_mddev->dev_sectors)\n\t\treturn -EINVAL; /* component must fit device */\n\n\trdev->sectors = sectors;\n\tif (sectors > oldsectors && my_mddev->external) {\n\t\t/* Need to check that all other rdevs with the same\n\t\t * ->bdev do not overlap.  'rcu' is sufficient to walk\n\t\t * the rdev lists safely.\n\t\t * This check does not provide a hard guarantee, it\n\t\t * just helps avoid dangerous mistakes.\n\t\t */\n\t\tstruct mddev *mddev;\n\t\tint overlap = 0;\n\t\tstruct list_head *tmp;\n\n\t\trcu_read_lock();\n\t\tfor_each_mddev(mddev, tmp) {\n\t\t\tstruct md_rdev *rdev2;\n\n\t\t\trdev_for_each(rdev2, mddev)\n\t\t\t\tif (rdev->bdev == rdev2->bdev &&\n\t\t\t\t    rdev != rdev2 &&\n\t\t\t\t    overlaps(rdev->data_offset, rdev->sectors,\n\t\t\t\t\t     rdev2->data_offset,\n\t\t\t\t\t     rdev2->sectors)) {\n\t\t\t\t\toverlap = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\tif (overlap) {\n\t\t\t\tmddev_put(mddev);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\trcu_read_unlock();\n\t\tif (overlap) {\n\t\t\t/* Someone else could have slipped in a size\n\t\t\t * change here, but doing so is just silly.\n\t\t\t * We put oldsectors back because we *know* it is\n\t\t\t * safe, and trust userspace not to race with\n\t\t\t * itself\n\t\t\t */\n\t\t\trdev->sectors = oldsectors;\n\t\t\treturn -EBUSY;\n\t\t}\n\t}\n\treturn len;\n}\n\nstatic struct rdev_sysfs_entry rdev_size =\n__ATTR(size, S_IRUGO|S_IWUSR, rdev_size_show, rdev_size_store);\n\nstatic ssize_t recovery_start_show(struct md_rdev *rdev, char *page)\n{\n\tunsigned long long recovery_start = rdev->recovery_offset;\n\n\tif (test_bit(In_sync, &rdev->flags) ||\n\t    recovery_start == MaxSector)\n\t\treturn sprintf(page, \"none\\n\");\n\n\treturn sprintf(page, \"%llu\\n\", recovery_start);\n}\n\nstatic ssize_t recovery_start_store(struct md_rdev *rdev, const char *buf, size_t len)\n{\n\tunsigned long long recovery_start;\n\n\tif (cmd_match(buf, \"none\"))\n\t\trecovery_start = MaxSector;\n\telse if (kstrtoull(buf, 10, &recovery_start))\n\t\treturn -EINVAL;\n\n\tif (rdev->mddev->pers &&\n\t    rdev->raid_disk >= 0)\n\t\treturn -EBUSY;\n\n\trdev->recovery_offset = recovery_start;\n\tif (recovery_start == MaxSector)\n\t\tset_bit(In_sync, &rdev->flags);\n\telse\n\t\tclear_bit(In_sync, &rdev->flags);\n\treturn len;\n}\n\nstatic struct rdev_sysfs_entry rdev_recovery_start =\n__ATTR(recovery_start, S_IRUGO|S_IWUSR, recovery_start_show, recovery_start_store);\n\n/* sysfs access to bad-blocks list.\n * We present two files.\n * 'bad-blocks' lists sector numbers and lengths of ranges that\n *    are recorded as bad.  The list is truncated to fit within\n *    the one-page limit of sysfs.\n *    Writing \"sector length\" to this file adds an acknowledged\n *    bad block list.\n * 'unacknowledged-bad-blocks' lists bad blocks that have not yet\n *    been acknowledged.  Writing to this file adds bad blocks\n *    without acknowledging them.  This is largely for testing.\n */\nstatic ssize_t bb_show(struct md_rdev *rdev, char *page)\n{\n\treturn badblocks_show(&rdev->badblocks, page, 0);\n}\nstatic ssize_t bb_store(struct md_rdev *rdev, const char *page, size_t len)\n{\n\tint rv = badblocks_store(&rdev->badblocks, page, len, 0);\n\t/* Maybe that ack was all we needed */\n\tif (test_and_clear_bit(BlockedBadBlocks, &rdev->flags))\n\t\twake_up(&rdev->blocked_wait);\n\treturn rv;\n}\nstatic struct rdev_sysfs_entry rdev_bad_blocks =\n__ATTR(bad_blocks, S_IRUGO|S_IWUSR, bb_show, bb_store);\n\nstatic ssize_t ubb_show(struct md_rdev *rdev, char *page)\n{\n\treturn badblocks_show(&rdev->badblocks, page, 1);\n}\nstatic ssize_t ubb_store(struct md_rdev *rdev, const char *page, size_t len)\n{\n\treturn badblocks_store(&rdev->badblocks, page, len, 1);\n}\nstatic struct rdev_sysfs_entry rdev_unack_bad_blocks =\n__ATTR(unacknowledged_bad_blocks, S_IRUGO|S_IWUSR, ubb_show, ubb_store);\n\nstatic ssize_t\nppl_sector_show(struct md_rdev *rdev, char *page)\n{\n\treturn sprintf(page, \"%llu\\n\", (unsigned long long)rdev->ppl.sector);\n}\n\nstatic ssize_t\nppl_sector_store(struct md_rdev *rdev, const char *buf, size_t len)\n{\n\tunsigned long long sector;\n\n\tif (kstrtoull(buf, 10, &sector) < 0)\n\t\treturn -EINVAL;\n\tif (sector != (sector_t)sector)\n\t\treturn -EINVAL;\n\n\tif (rdev->mddev->pers && test_bit(MD_HAS_PPL, &rdev->mddev->flags) &&\n\t    rdev->raid_disk >= 0)\n\t\treturn -EBUSY;\n\n\tif (rdev->mddev->persistent) {\n\t\tif (rdev->mddev->major_version == 0)\n\t\t\treturn -EINVAL;\n\t\tif ((sector > rdev->sb_start &&\n\t\t     sector - rdev->sb_start > S16_MAX) ||\n\t\t    (sector < rdev->sb_start &&\n\t\t     rdev->sb_start - sector > -S16_MIN))\n\t\t\treturn -EINVAL;\n\t\trdev->ppl.offset = sector - rdev->sb_start;\n\t} else if (!rdev->mddev->external) {\n\t\treturn -EBUSY;\n\t}\n\trdev->ppl.sector = sector;\n\treturn len;\n}\n\nstatic struct rdev_sysfs_entry rdev_ppl_sector =\n__ATTR(ppl_sector, S_IRUGO|S_IWUSR, ppl_sector_show, ppl_sector_store);\n\nstatic ssize_t\nppl_size_show(struct md_rdev *rdev, char *page)\n{\n\treturn sprintf(page, \"%u\\n\", rdev->ppl.size);\n}\n\nstatic ssize_t\nppl_size_store(struct md_rdev *rdev, const char *buf, size_t len)\n{\n\tunsigned int size;\n\n\tif (kstrtouint(buf, 10, &size) < 0)\n\t\treturn -EINVAL;\n\n\tif (rdev->mddev->pers && test_bit(MD_HAS_PPL, &rdev->mddev->flags) &&\n\t    rdev->raid_disk >= 0)\n\t\treturn -EBUSY;\n\n\tif (rdev->mddev->persistent) {\n\t\tif (rdev->mddev->major_version == 0)\n\t\t\treturn -EINVAL;\n\t\tif (size > U16_MAX)\n\t\t\treturn -EINVAL;\n\t} else if (!rdev->mddev->external) {\n\t\treturn -EBUSY;\n\t}\n\trdev->ppl.size = size;\n\treturn len;\n}\n\nstatic struct rdev_sysfs_entry rdev_ppl_size =\n__ATTR(ppl_size, S_IRUGO|S_IWUSR, ppl_size_show, ppl_size_store);\n\nstatic struct attribute *rdev_default_attrs[] = {\n\t&rdev_state.attr,\n\t&rdev_errors.attr,\n\t&rdev_slot.attr,\n\t&rdev_offset.attr,\n\t&rdev_new_offset.attr,\n\t&rdev_size.attr,\n\t&rdev_recovery_start.attr,\n\t&rdev_bad_blocks.attr,\n\t&rdev_unack_bad_blocks.attr,\n\t&rdev_ppl_sector.attr,\n\t&rdev_ppl_size.attr,\n\tNULL,\n};\nstatic ssize_t\nrdev_attr_show(struct kobject *kobj, struct attribute *attr, char *page)\n{\n\tstruct rdev_sysfs_entry *entry = container_of(attr, struct rdev_sysfs_entry, attr);\n\tstruct md_rdev *rdev = container_of(kobj, struct md_rdev, kobj);\n\n\tif (!entry->show)\n\t\treturn -EIO;\n\tif (!rdev->mddev)\n\t\treturn -ENODEV;\n\treturn entry->show(rdev, page);\n}\n\nstatic ssize_t\nrdev_attr_store(struct kobject *kobj, struct attribute *attr,\n\t      const char *page, size_t length)\n{\n\tstruct rdev_sysfs_entry *entry = container_of(attr, struct rdev_sysfs_entry, attr);\n\tstruct md_rdev *rdev = container_of(kobj, struct md_rdev, kobj);\n\tssize_t rv;\n\tstruct mddev *mddev = rdev->mddev;\n\n\tif (!entry->store)\n\t\treturn -EIO;\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn -EACCES;\n\trv = mddev ? mddev_lock(mddev) : -ENODEV;\n\tif (!rv) {\n\t\tif (rdev->mddev == NULL)\n\t\t\trv = -ENODEV;\n\t\telse\n\t\t\trv = entry->store(rdev, page, length);\n\t\tmddev_unlock(mddev);\n\t}\n\treturn rv;\n}\n\nstatic void rdev_free(struct kobject *ko)\n{\n\tstruct md_rdev *rdev = container_of(ko, struct md_rdev, kobj);\n\tkfree(rdev);\n}\nstatic const struct sysfs_ops rdev_sysfs_ops = {\n\t.show\t\t= rdev_attr_show,\n\t.store\t\t= rdev_attr_store,\n};\nstatic struct kobj_type rdev_ktype = {\n\t.release\t= rdev_free,\n\t.sysfs_ops\t= &rdev_sysfs_ops,\n\t.default_attrs\t= rdev_default_attrs,\n};\n\nint md_rdev_init(struct md_rdev *rdev)\n{\n\trdev->desc_nr = -1;\n\trdev->saved_raid_disk = -1;\n\trdev->raid_disk = -1;\n\trdev->flags = 0;\n\trdev->data_offset = 0;\n\trdev->new_data_offset = 0;\n\trdev->sb_events = 0;\n\trdev->last_read_error = 0;\n\trdev->sb_loaded = 0;\n\trdev->bb_page = NULL;\n\tatomic_set(&rdev->nr_pending, 0);\n\tatomic_set(&rdev->read_errors, 0);\n\tatomic_set(&rdev->corrected_errors, 0);\n\n\tINIT_LIST_HEAD(&rdev->same_set);\n\tinit_waitqueue_head(&rdev->blocked_wait);\n\n\t/* Add space to store bad block list.\n\t * This reserves the space even on arrays where it cannot\n\t * be used - I wonder if that matters\n\t */\n\treturn badblocks_init(&rdev->badblocks, 0);\n}\nEXPORT_SYMBOL_GPL(md_rdev_init);\n/*\n * Import a device. If 'super_format' >= 0, then sanity check the superblock\n *\n * mark the device faulty if:\n *\n *   - the device is nonexistent (zero size)\n *   - the device has no valid superblock\n *\n * a faulty rdev _never_ has rdev->sb set.\n */\nstatic struct md_rdev *md_import_device(dev_t newdev, int super_format, int super_minor)\n{\n\tchar b[BDEVNAME_SIZE];\n\tint err;\n\tstruct md_rdev *rdev;\n\tsector_t size;\n\n\trdev = kzalloc(sizeof(*rdev), GFP_KERNEL);\n\tif (!rdev)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\terr = md_rdev_init(rdev);\n\tif (err)\n\t\tgoto abort_free;\n\terr = alloc_disk_sb(rdev);\n\tif (err)\n\t\tgoto abort_free;\n\n\terr = lock_rdev(rdev, newdev, super_format == -2);\n\tif (err)\n\t\tgoto abort_free;\n\n\tkobject_init(&rdev->kobj, &rdev_ktype);\n\n\tsize = i_size_read(rdev->bdev->bd_inode) >> BLOCK_SIZE_BITS;\n\tif (!size) {\n\t\tpr_warn(\"md: %s has zero or unknown size, marking faulty!\\n\",\n\t\t\tbdevname(rdev->bdev,b));\n\t\terr = -EINVAL;\n\t\tgoto abort_free;\n\t}\n\n\tif (super_format >= 0) {\n\t\terr = super_types[super_format].\n\t\t\tload_super(rdev, NULL, super_minor);\n\t\tif (err == -EINVAL) {\n\t\t\tpr_warn(\"md: %s does not have a valid v%d.%d superblock, not importing!\\n\",\n\t\t\t\tbdevname(rdev->bdev,b),\n\t\t\t\tsuper_format, super_minor);\n\t\t\tgoto abort_free;\n\t\t}\n\t\tif (err < 0) {\n\t\t\tpr_warn(\"md: could not read %s's sb, not importing!\\n\",\n\t\t\t\tbdevname(rdev->bdev,b));\n\t\t\tgoto abort_free;\n\t\t}\n\t}\n\n\treturn rdev;\n\nabort_free:\n\tif (rdev->bdev)\n\t\tunlock_rdev(rdev);\n\tmd_rdev_clear(rdev);\n\tkfree(rdev);\n\treturn ERR_PTR(err);\n}\n\n/*\n * Check a full RAID array for plausibility\n */\n\nstatic int analyze_sbs(struct mddev *mddev)\n{\n\tint i;\n\tstruct md_rdev *rdev, *freshest, *tmp;\n\tchar b[BDEVNAME_SIZE];\n\n\tfreshest = NULL;\n\trdev_for_each_safe(rdev, tmp, mddev)\n\t\tswitch (super_types[mddev->major_version].\n\t\t\tload_super(rdev, freshest, mddev->minor_version)) {\n\t\tcase 1:\n\t\t\tfreshest = rdev;\n\t\t\tbreak;\n\t\tcase 0:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tpr_warn(\"md: fatal superblock inconsistency in %s -- removing from array\\n\",\n\t\t\t\tbdevname(rdev->bdev,b));\n\t\t\tmd_kick_rdev_from_array(rdev);\n\t\t}\n\n\t/* Cannot find a valid fresh disk */\n\tif (!freshest) {\n\t\tpr_warn(\"md: cannot find a valid disk\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tsuper_types[mddev->major_version].\n\t\tvalidate_super(mddev, freshest);\n\n\ti = 0;\n\trdev_for_each_safe(rdev, tmp, mddev) {\n\t\tif (mddev->max_disks &&\n\t\t    (rdev->desc_nr >= mddev->max_disks ||\n\t\t     i > mddev->max_disks)) {\n\t\t\tpr_warn(\"md: %s: %s: only %d devices permitted\\n\",\n\t\t\t\tmdname(mddev), bdevname(rdev->bdev, b),\n\t\t\t\tmddev->max_disks);\n\t\t\tmd_kick_rdev_from_array(rdev);\n\t\t\tcontinue;\n\t\t}\n\t\tif (rdev != freshest) {\n\t\t\tif (super_types[mddev->major_version].\n\t\t\t    validate_super(mddev, rdev)) {\n\t\t\t\tpr_warn(\"md: kicking non-fresh %s from array!\\n\",\n\t\t\t\t\tbdevname(rdev->bdev,b));\n\t\t\t\tmd_kick_rdev_from_array(rdev);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\t\tif (mddev->level == LEVEL_MULTIPATH) {\n\t\t\trdev->desc_nr = i++;\n\t\t\trdev->raid_disk = rdev->desc_nr;\n\t\t\tset_bit(In_sync, &rdev->flags);\n\t\t} else if (rdev->raid_disk >=\n\t\t\t    (mddev->raid_disks - min(0, mddev->delta_disks)) &&\n\t\t\t   !test_bit(Journal, &rdev->flags)) {\n\t\t\trdev->raid_disk = -1;\n\t\t\tclear_bit(In_sync, &rdev->flags);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n/* Read a fixed-point number.\n * Numbers in sysfs attributes should be in \"standard\" units where\n * possible, so time should be in seconds.\n * However we internally use a a much smaller unit such as\n * milliseconds or jiffies.\n * This function takes a decimal number with a possible fractional\n * component, and produces an integer which is the result of\n * multiplying that number by 10^'scale'.\n * all without any floating-point arithmetic.\n */\nint strict_strtoul_scaled(const char *cp, unsigned long *res, int scale)\n{\n\tunsigned long result = 0;\n\tlong decimals = -1;\n\twhile (isdigit(*cp) || (*cp == '.' && decimals < 0)) {\n\t\tif (*cp == '.')\n\t\t\tdecimals = 0;\n\t\telse if (decimals < scale) {\n\t\t\tunsigned int value;\n\t\t\tvalue = *cp - '0';\n\t\t\tresult = result * 10 + value;\n\t\t\tif (decimals >= 0)\n\t\t\t\tdecimals++;\n\t\t}\n\t\tcp++;\n\t}\n\tif (*cp == '\\n')\n\t\tcp++;\n\tif (*cp)\n\t\treturn -EINVAL;\n\tif (decimals < 0)\n\t\tdecimals = 0;\n\t*res = result * int_pow(10, scale - decimals);\n\treturn 0;\n}\n\nstatic ssize_t\nsafe_delay_show(struct mddev *mddev, char *page)\n{\n\tint msec = (mddev->safemode_delay*1000)/HZ;\n\treturn sprintf(page, \"%d.%03d\\n\", msec/1000, msec%1000);\n}\nstatic ssize_t\nsafe_delay_store(struct mddev *mddev, const char *cbuf, size_t len)\n{\n\tunsigned long msec;\n\n\tif (mddev_is_clustered(mddev)) {\n\t\tpr_warn(\"md: Safemode is disabled for clustered mode\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (strict_strtoul_scaled(cbuf, &msec, 3) < 0)\n\t\treturn -EINVAL;\n\tif (msec == 0)\n\t\tmddev->safemode_delay = 0;\n\telse {\n\t\tunsigned long old_delay = mddev->safemode_delay;\n\t\tunsigned long new_delay = (msec*HZ)/1000;\n\n\t\tif (new_delay == 0)\n\t\t\tnew_delay = 1;\n\t\tmddev->safemode_delay = new_delay;\n\t\tif (new_delay < old_delay || old_delay == 0)\n\t\t\tmod_timer(&mddev->safemode_timer, jiffies+1);\n\t}\n\treturn len;\n}\nstatic struct md_sysfs_entry md_safe_delay =\n__ATTR(safe_mode_delay, S_IRUGO|S_IWUSR,safe_delay_show, safe_delay_store);\n\nstatic ssize_t\nlevel_show(struct mddev *mddev, char *page)\n{\n\tstruct md_personality *p;\n\tint ret;\n\tspin_lock(&mddev->lock);\n\tp = mddev->pers;\n\tif (p)\n\t\tret = sprintf(page, \"%s\\n\", p->name);\n\telse if (mddev->clevel[0])\n\t\tret = sprintf(page, \"%s\\n\", mddev->clevel);\n\telse if (mddev->level != LEVEL_NONE)\n\t\tret = sprintf(page, \"%d\\n\", mddev->level);\n\telse\n\t\tret = 0;\n\tspin_unlock(&mddev->lock);\n\treturn ret;\n}\n\nstatic ssize_t\nlevel_store(struct mddev *mddev, const char *buf, size_t len)\n{\n\tchar clevel[16];\n\tssize_t rv;\n\tsize_t slen = len;\n\tstruct md_personality *pers, *oldpers;\n\tlong level;\n\tvoid *priv, *oldpriv;\n\tstruct md_rdev *rdev;\n\n\tif (slen == 0 || slen >= sizeof(clevel))\n\t\treturn -EINVAL;\n\n\trv = mddev_lock(mddev);\n\tif (rv)\n\t\treturn rv;\n\n\tif (mddev->pers == NULL) {\n\t\tstrncpy(mddev->clevel, buf, slen);\n\t\tif (mddev->clevel[slen-1] == '\\n')\n\t\t\tslen--;\n\t\tmddev->clevel[slen] = 0;\n\t\tmddev->level = LEVEL_NONE;\n\t\trv = len;\n\t\tgoto out_unlock;\n\t}\n\trv = -EROFS;\n\tif (mddev->ro)\n\t\tgoto out_unlock;\n\n\t/* request to change the personality.  Need to ensure:\n\t *  - array is not engaged in resync/recovery/reshape\n\t *  - old personality can be suspended\n\t *  - new personality will access other array.\n\t */\n\n\trv = -EBUSY;\n\tif (mddev->sync_thread ||\n\t    test_bit(MD_RECOVERY_RUNNING, &mddev->recovery) ||\n\t    mddev->reshape_position != MaxSector ||\n\t    mddev->sysfs_active)\n\t\tgoto out_unlock;\n\n\trv = -EINVAL;\n\tif (!mddev->pers->quiesce) {\n\t\tpr_warn(\"md: %s: %s does not support online personality change\\n\",\n\t\t\tmdname(mddev), mddev->pers->name);\n\t\tgoto out_unlock;\n\t}\n\n\t/* Now find the new personality */\n\tstrncpy(clevel, buf, slen);\n\tif (clevel[slen-1] == '\\n')\n\t\tslen--;\n\tclevel[slen] = 0;\n\tif (kstrtol(clevel, 10, &level))\n\t\tlevel = LEVEL_NONE;\n\n\tif (request_module(\"md-%s\", clevel) != 0)\n\t\trequest_module(\"md-level-%s\", clevel);\n\tspin_lock(&pers_lock);\n\tpers = find_pers(level, clevel);\n\tif (!pers || !try_module_get(pers->owner)) {\n\t\tspin_unlock(&pers_lock);\n\t\tpr_warn(\"md: personality %s not loaded\\n\", clevel);\n\t\trv = -EINVAL;\n\t\tgoto out_unlock;\n\t}\n\tspin_unlock(&pers_lock);\n\n\tif (pers == mddev->pers) {\n\t\t/* Nothing to do! */\n\t\tmodule_put(pers->owner);\n\t\trv = len;\n\t\tgoto out_unlock;\n\t}\n\tif (!pers->takeover) {\n\t\tmodule_put(pers->owner);\n\t\tpr_warn(\"md: %s: %s does not support personality takeover\\n\",\n\t\t\tmdname(mddev), clevel);\n\t\trv = -EINVAL;\n\t\tgoto out_unlock;\n\t}\n\n\trdev_for_each(rdev, mddev)\n\t\trdev->new_raid_disk = rdev->raid_disk;\n\n\t/* ->takeover must set new_* and/or delta_disks\n\t * if it succeeds, and may set them when it fails.\n\t */\n\tpriv = pers->takeover(mddev);\n\tif (IS_ERR(priv)) {\n\t\tmddev->new_level = mddev->level;\n\t\tmddev->new_layout = mddev->layout;\n\t\tmddev->new_chunk_sectors = mddev->chunk_sectors;\n\t\tmddev->raid_disks -= mddev->delta_disks;\n\t\tmddev->delta_disks = 0;\n\t\tmddev->reshape_backwards = 0;\n\t\tmodule_put(pers->owner);\n\t\tpr_warn(\"md: %s: %s would not accept array\\n\",\n\t\t\tmdname(mddev), clevel);\n\t\trv = PTR_ERR(priv);\n\t\tgoto out_unlock;\n\t}\n\n\t/* Looks like we have a winner */\n\tmddev_suspend(mddev);\n\tmddev_detach(mddev);\n\n\tspin_lock(&mddev->lock);\n\toldpers = mddev->pers;\n\toldpriv = mddev->private;\n\tmddev->pers = pers;\n\tmddev->private = priv;\n\tstrlcpy(mddev->clevel, pers->name, sizeof(mddev->clevel));\n\tmddev->level = mddev->new_level;\n\tmddev->layout = mddev->new_layout;\n\tmddev->chunk_sectors = mddev->new_chunk_sectors;\n\tmddev->delta_disks = 0;\n\tmddev->reshape_backwards = 0;\n\tmddev->degraded = 0;\n\tspin_unlock(&mddev->lock);\n\n\tif (oldpers->sync_request == NULL &&\n\t    mddev->external) {\n\t\t/* We are converting from a no-redundancy array\n\t\t * to a redundancy array and metadata is managed\n\t\t * externally so we need to be sure that writes\n\t\t * won't block due to a need to transition\n\t\t *      clean->dirty\n\t\t * until external management is started.\n\t\t */\n\t\tmddev->in_sync = 0;\n\t\tmddev->safemode_delay = 0;\n\t\tmddev->safemode = 0;\n\t}\n\n\toldpers->free(mddev, oldpriv);\n\n\tif (oldpers->sync_request == NULL &&\n\t    pers->sync_request != NULL) {\n\t\t/* need to add the md_redundancy_group */\n\t\tif (sysfs_create_group(&mddev->kobj, &md_redundancy_group))\n\t\t\tpr_warn(\"md: cannot register extra attributes for %s\\n\",\n\t\t\t\tmdname(mddev));\n\t\tmddev->sysfs_action = sysfs_get_dirent(mddev->kobj.sd, \"sync_action\");\n\t\tmddev->sysfs_completed = sysfs_get_dirent_safe(mddev->kobj.sd, \"sync_completed\");\n\t\tmddev->sysfs_degraded = sysfs_get_dirent_safe(mddev->kobj.sd, \"degraded\");\n\t}\n\tif (oldpers->sync_request != NULL &&\n\t    pers->sync_request == NULL) {\n\t\t/* need to remove the md_redundancy_group */\n\t\tif (mddev->to_remove == NULL)\n\t\t\tmddev->to_remove = &md_redundancy_group;\n\t}\n\n\tmodule_put(oldpers->owner);\n\n\trdev_for_each(rdev, mddev) {\n\t\tif (rdev->raid_disk < 0)\n\t\t\tcontinue;\n\t\tif (rdev->new_raid_disk >= mddev->raid_disks)\n\t\t\trdev->new_raid_disk = -1;\n\t\tif (rdev->new_raid_disk == rdev->raid_disk)\n\t\t\tcontinue;\n\t\tsysfs_unlink_rdev(mddev, rdev);\n\t}\n\trdev_for_each(rdev, mddev) {\n\t\tif (rdev->raid_disk < 0)\n\t\t\tcontinue;\n\t\tif (rdev->new_raid_disk == rdev->raid_disk)\n\t\t\tcontinue;\n\t\trdev->raid_disk = rdev->new_raid_disk;\n\t\tif (rdev->raid_disk < 0)\n\t\t\tclear_bit(In_sync, &rdev->flags);\n\t\telse {\n\t\t\tif (sysfs_link_rdev(mddev, rdev))\n\t\t\t\tpr_warn(\"md: cannot register rd%d for %s after level change\\n\",\n\t\t\t\t\trdev->raid_disk, mdname(mddev));\n\t\t}\n\t}\n\n\tif (pers->sync_request == NULL) {\n\t\t/* this is now an array without redundancy, so\n\t\t * it must always be in_sync\n\t\t */\n\t\tmddev->in_sync = 1;\n\t\tdel_timer_sync(&mddev->safemode_timer);\n\t}\n\tblk_set_stacking_limits(&mddev->queue->limits);\n\tpers->run(mddev);\n\tset_bit(MD_SB_CHANGE_DEVS, &mddev->sb_flags);\n\tmddev_resume(mddev);\n\tif (!mddev->thread)\n\t\tmd_update_sb(mddev, 1);\n\tsysfs_notify_dirent_safe(mddev->sysfs_level);\n\tmd_new_event(mddev);\n\trv = len;\nout_unlock:\n\tmddev_unlock(mddev);\n\treturn rv;\n}\n\nstatic struct md_sysfs_entry md_level =\n__ATTR(level, S_IRUGO|S_IWUSR, level_show, level_store);\n\nstatic ssize_t\nlayout_show(struct mddev *mddev, char *page)\n{\n\t/* just a number, not meaningful for all levels */\n\tif (mddev->reshape_position != MaxSector &&\n\t    mddev->layout != mddev->new_layout)\n\t\treturn sprintf(page, \"%d (%d)\\n\",\n\t\t\t       mddev->new_layout, mddev->layout);\n\treturn sprintf(page, \"%d\\n\", mddev->layout);\n}\n\nstatic ssize_t\nlayout_store(struct mddev *mddev, const char *buf, size_t len)\n{\n\tunsigned int n;\n\tint err;\n\n\terr = kstrtouint(buf, 10, &n);\n\tif (err < 0)\n\t\treturn err;\n\terr = mddev_lock(mddev);\n\tif (err)\n\t\treturn err;\n\n\tif (mddev->pers) {\n\t\tif (mddev->pers->check_reshape == NULL)\n\t\t\terr = -EBUSY;\n\t\telse if (mddev->ro)\n\t\t\terr = -EROFS;\n\t\telse {\n\t\t\tmddev->new_layout = n;\n\t\t\terr = mddev->pers->check_reshape(mddev);\n\t\t\tif (err)\n\t\t\t\tmddev->new_layout = mddev->layout;\n\t\t}\n\t} else {\n\t\tmddev->new_layout = n;\n\t\tif (mddev->reshape_position == MaxSector)\n\t\t\tmddev->layout = n;\n\t}\n\tmddev_unlock(mddev);\n\treturn err ?: len;\n}\nstatic struct md_sysfs_entry md_layout =\n__ATTR(layout, S_IRUGO|S_IWUSR, layout_show, layout_store);\n\nstatic ssize_t\nraid_disks_show(struct mddev *mddev, char *page)\n{\n\tif (mddev->raid_disks == 0)\n\t\treturn 0;\n\tif (mddev->reshape_position != MaxSector &&\n\t    mddev->delta_disks != 0)\n\t\treturn sprintf(page, \"%d (%d)\\n\", mddev->raid_disks,\n\t\t\t       mddev->raid_disks - mddev->delta_disks);\n\treturn sprintf(page, \"%d\\n\", mddev->raid_disks);\n}\n\nstatic int update_raid_disks(struct mddev *mddev, int raid_disks);\n\nstatic ssize_t\nraid_disks_store(struct mddev *mddev, const char *buf, size_t len)\n{\n\tunsigned int n;\n\tint err;\n\n\terr = kstrtouint(buf, 10, &n);\n\tif (err < 0)\n\t\treturn err;\n\n\terr = mddev_lock(mddev);\n\tif (err)\n\t\treturn err;\n\tif (mddev->pers)\n\t\terr = update_raid_disks(mddev, n);\n\telse if (mddev->reshape_position != MaxSector) {\n\t\tstruct md_rdev *rdev;\n\t\tint olddisks = mddev->raid_disks - mddev->delta_disks;\n\n\t\terr = -EINVAL;\n\t\trdev_for_each(rdev, mddev) {\n\t\t\tif (olddisks < n &&\n\t\t\t    rdev->data_offset < rdev->new_data_offset)\n\t\t\t\tgoto out_unlock;\n\t\t\tif (olddisks > n &&\n\t\t\t    rdev->data_offset > rdev->new_data_offset)\n\t\t\t\tgoto out_unlock;\n\t\t}\n\t\terr = 0;\n\t\tmddev->delta_disks = n - olddisks;\n\t\tmddev->raid_disks = n;\n\t\tmddev->reshape_backwards = (mddev->delta_disks < 0);\n\t} else\n\t\tmddev->raid_disks = n;\nout_unlock:\n\tmddev_unlock(mddev);\n\treturn err ? err : len;\n}\nstatic struct md_sysfs_entry md_raid_disks =\n__ATTR(raid_disks, S_IRUGO|S_IWUSR, raid_disks_show, raid_disks_store);\n\nstatic ssize_t\nuuid_show(struct mddev *mddev, char *page)\n{\n\treturn sprintf(page, \"%pU\\n\", mddev->uuid);\n}\nstatic struct md_sysfs_entry md_uuid =\n__ATTR(uuid, S_IRUGO, uuid_show, NULL);\n\nstatic ssize_t\nchunk_size_show(struct mddev *mddev, char *page)\n{\n\tif (mddev->reshape_position != MaxSector &&\n\t    mddev->chunk_sectors != mddev->new_chunk_sectors)\n\t\treturn sprintf(page, \"%d (%d)\\n\",\n\t\t\t       mddev->new_chunk_sectors << 9,\n\t\t\t       mddev->chunk_sectors << 9);\n\treturn sprintf(page, \"%d\\n\", mddev->chunk_sectors << 9);\n}\n\nstatic ssize_t\nchunk_size_store(struct mddev *mddev, const char *buf, size_t len)\n{\n\tunsigned long n;\n\tint err;\n\n\terr = kstrtoul(buf, 10, &n);\n\tif (err < 0)\n\t\treturn err;\n\n\terr = mddev_lock(mddev);\n\tif (err)\n\t\treturn err;\n\tif (mddev->pers) {\n\t\tif (mddev->pers->check_reshape == NULL)\n\t\t\terr = -EBUSY;\n\t\telse if (mddev->ro)\n\t\t\terr = -EROFS;\n\t\telse {\n\t\t\tmddev->new_chunk_sectors = n >> 9;\n\t\t\terr = mddev->pers->check_reshape(mddev);\n\t\t\tif (err)\n\t\t\t\tmddev->new_chunk_sectors = mddev->chunk_sectors;\n\t\t}\n\t} else {\n\t\tmddev->new_chunk_sectors = n >> 9;\n\t\tif (mddev->reshape_position == MaxSector)\n\t\t\tmddev->chunk_sectors = n >> 9;\n\t}\n\tmddev_unlock(mddev);\n\treturn err ?: len;\n}\nstatic struct md_sysfs_entry md_chunk_size =\n__ATTR(chunk_size, S_IRUGO|S_IWUSR, chunk_size_show, chunk_size_store);\n\nstatic ssize_t\nresync_start_show(struct mddev *mddev, char *page)\n{\n\tif (mddev->recovery_cp == MaxSector)\n\t\treturn sprintf(page, \"none\\n\");\n\treturn sprintf(page, \"%llu\\n\", (unsigned long long)mddev->recovery_cp);\n}\n\nstatic ssize_t\nresync_start_store(struct mddev *mddev, const char *buf, size_t len)\n{\n\tunsigned long long n;\n\tint err;\n\n\tif (cmd_match(buf, \"none\"))\n\t\tn = MaxSector;\n\telse {\n\t\terr = kstrtoull(buf, 10, &n);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t\tif (n != (sector_t)n)\n\t\t\treturn -EINVAL;\n\t}\n\n\terr = mddev_lock(mddev);\n\tif (err)\n\t\treturn err;\n\tif (mddev->pers && !test_bit(MD_RECOVERY_FROZEN, &mddev->recovery))\n\t\terr = -EBUSY;\n\n\tif (!err) {\n\t\tmddev->recovery_cp = n;\n\t\tif (mddev->pers)\n\t\t\tset_bit(MD_SB_CHANGE_CLEAN, &mddev->sb_flags);\n\t}\n\tmddev_unlock(mddev);\n\treturn err ?: len;\n}\nstatic struct md_sysfs_entry md_resync_start =\n__ATTR_PREALLOC(resync_start, S_IRUGO|S_IWUSR,\n\t\tresync_start_show, resync_start_store);\n\n/*\n * The array state can be:\n *\n * clear\n *     No devices, no size, no level\n *     Equivalent to STOP_ARRAY ioctl\n * inactive\n *     May have some settings, but array is not active\n *        all IO results in error\n *     When written, doesn't tear down array, but just stops it\n * suspended (not supported yet)\n *     All IO requests will block. The array can be reconfigured.\n *     Writing this, if accepted, will block until array is quiescent\n * readonly\n *     no resync can happen.  no superblocks get written.\n *     write requests fail\n * read-auto\n *     like readonly, but behaves like 'clean' on a write request.\n *\n * clean - no pending writes, but otherwise active.\n *     When written to inactive array, starts without resync\n *     If a write request arrives then\n *       if metadata is known, mark 'dirty' and switch to 'active'.\n *       if not known, block and switch to write-pending\n *     If written to an active array that has pending writes, then fails.\n * active\n *     fully active: IO and resync can be happening.\n *     When written to inactive array, starts with resync\n *\n * write-pending\n *     clean, but writes are blocked waiting for 'active' to be written.\n *\n * active-idle\n *     like active, but no writes have been seen for a while (100msec).\n *\n * broken\n *     RAID0/LINEAR-only: same as clean, but array is missing a member.\n *     It's useful because RAID0/LINEAR mounted-arrays aren't stopped\n *     when a member is gone, so this state will at least alert the\n *     user that something is wrong.\n */\nenum array_state { clear, inactive, suspended, readonly, read_auto, clean, active,\n\t\t   write_pending, active_idle, broken, bad_word};\nstatic char *array_states[] = {\n\t\"clear\", \"inactive\", \"suspended\", \"readonly\", \"read-auto\", \"clean\", \"active\",\n\t\"write-pending\", \"active-idle\", \"broken\", NULL };\n\nstatic int match_word(const char *word, char **list)\n{\n\tint n;\n\tfor (n=0; list[n]; n++)\n\t\tif (cmd_match(word, list[n]))\n\t\t\tbreak;\n\treturn n;\n}\n\nstatic ssize_t\narray_state_show(struct mddev *mddev, char *page)\n{\n\tenum array_state st = inactive;\n\n\tif (mddev->pers && !test_bit(MD_NOT_READY, &mddev->flags)) {\n\t\tswitch(mddev->ro) {\n\t\tcase 1:\n\t\t\tst = readonly;\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tst = read_auto;\n\t\t\tbreak;\n\t\tcase 0:\n\t\t\tspin_lock(&mddev->lock);\n\t\t\tif (test_bit(MD_SB_CHANGE_PENDING, &mddev->sb_flags))\n\t\t\t\tst = write_pending;\n\t\t\telse if (mddev->in_sync)\n\t\t\t\tst = clean;\n\t\t\telse if (mddev->safemode)\n\t\t\t\tst = active_idle;\n\t\t\telse\n\t\t\t\tst = active;\n\t\t\tspin_unlock(&mddev->lock);\n\t\t}\n\n\t\tif (test_bit(MD_BROKEN, &mddev->flags) && st == clean)\n\t\t\tst = broken;\n\t} else {\n\t\tif (list_empty(&mddev->disks) &&\n\t\t    mddev->raid_disks == 0 &&\n\t\t    mddev->dev_sectors == 0)\n\t\t\tst = clear;\n\t\telse\n\t\t\tst = inactive;\n\t}\n\treturn sprintf(page, \"%s\\n\", array_states[st]);\n}\n\nstatic int do_md_stop(struct mddev *mddev, int ro, struct block_device *bdev);\nstatic int md_set_readonly(struct mddev *mddev, struct block_device *bdev);\nstatic int restart_array(struct mddev *mddev);\n\nstatic ssize_t\narray_state_store(struct mddev *mddev, const char *buf, size_t len)\n{\n\tint err = 0;\n\tenum array_state st = match_word(buf, array_states);\n\n\tif (mddev->pers && (st == active || st == clean) && mddev->ro != 1) {\n\t\t/* don't take reconfig_mutex when toggling between\n\t\t * clean and active\n\t\t */\n\t\tspin_lock(&mddev->lock);\n\t\tif (st == active) {\n\t\t\trestart_array(mddev);\n\t\t\tclear_bit(MD_SB_CHANGE_PENDING, &mddev->sb_flags);\n\t\t\tmd_wakeup_thread(mddev->thread);\n\t\t\twake_up(&mddev->sb_wait);\n\t\t} else /* st == clean */ {\n\t\t\trestart_array(mddev);\n\t\t\tif (!set_in_sync(mddev))\n\t\t\t\terr = -EBUSY;\n\t\t}\n\t\tif (!err)\n\t\t\tsysfs_notify_dirent_safe(mddev->sysfs_state);\n\t\tspin_unlock(&mddev->lock);\n\t\treturn err ?: len;\n\t}\n\terr = mddev_lock(mddev);\n\tif (err)\n\t\treturn err;\n\terr = -EINVAL;\n\tswitch(st) {\n\tcase bad_word:\n\t\tbreak;\n\tcase clear:\n\t\t/* stopping an active array */\n\t\terr = do_md_stop(mddev, 0, NULL);\n\t\tbreak;\n\tcase inactive:\n\t\t/* stopping an active array */\n\t\tif (mddev->pers)\n\t\t\terr = do_md_stop(mddev, 2, NULL);\n\t\telse\n\t\t\terr = 0; /* already inactive */\n\t\tbreak;\n\tcase suspended:\n\t\tbreak; /* not supported yet */\n\tcase readonly:\n\t\tif (mddev->pers)\n\t\t\terr = md_set_readonly(mddev, NULL);\n\t\telse {\n\t\t\tmddev->ro = 1;\n\t\t\tset_disk_ro(mddev->gendisk, 1);\n\t\t\terr = do_md_run(mddev);\n\t\t}\n\t\tbreak;\n\tcase read_auto:\n\t\tif (mddev->pers) {\n\t\t\tif (mddev->ro == 0)\n\t\t\t\terr = md_set_readonly(mddev, NULL);\n\t\t\telse if (mddev->ro == 1)\n\t\t\t\terr = restart_array(mddev);\n\t\t\tif (err == 0) {\n\t\t\t\tmddev->ro = 2;\n\t\t\t\tset_disk_ro(mddev->gendisk, 0);\n\t\t\t}\n\t\t} else {\n\t\t\tmddev->ro = 2;\n\t\t\terr = do_md_run(mddev);\n\t\t}\n\t\tbreak;\n\tcase clean:\n\t\tif (mddev->pers) {\n\t\t\terr = restart_array(mddev);\n\t\t\tif (err)\n\t\t\t\tbreak;\n\t\t\tspin_lock(&mddev->lock);\n\t\t\tif (!set_in_sync(mddev))\n\t\t\t\terr = -EBUSY;\n\t\t\tspin_unlock(&mddev->lock);\n\t\t} else\n\t\t\terr = -EINVAL;\n\t\tbreak;\n\tcase active:\n\t\tif (mddev->pers) {\n\t\t\terr = restart_array(mddev);\n\t\t\tif (err)\n\t\t\t\tbreak;\n\t\t\tclear_bit(MD_SB_CHANGE_PENDING, &mddev->sb_flags);\n\t\t\twake_up(&mddev->sb_wait);\n\t\t\terr = 0;\n\t\t} else {\n\t\t\tmddev->ro = 0;\n\t\t\tset_disk_ro(mddev->gendisk, 0);\n\t\t\terr = do_md_run(mddev);\n\t\t}\n\t\tbreak;\n\tcase write_pending:\n\tcase active_idle:\n\tcase broken:\n\t\t/* these cannot be set */\n\t\tbreak;\n\t}\n\n\tif (!err) {\n\t\tif (mddev->hold_active == UNTIL_IOCTL)\n\t\t\tmddev->hold_active = 0;\n\t\tsysfs_notify_dirent_safe(mddev->sysfs_state);\n\t}\n\tmddev_unlock(mddev);\n\treturn err ?: len;\n}\nstatic struct md_sysfs_entry md_array_state =\n__ATTR_PREALLOC(array_state, S_IRUGO|S_IWUSR, array_state_show, array_state_store);\n\nstatic ssize_t\nmax_corrected_read_errors_show(struct mddev *mddev, char *page) {\n\treturn sprintf(page, \"%d\\n\",\n\t\t       atomic_read(&mddev->max_corr_read_errors));\n}\n\nstatic ssize_t\nmax_corrected_read_errors_store(struct mddev *mddev, const char *buf, size_t len)\n{\n\tunsigned int n;\n\tint rv;\n\n\trv = kstrtouint(buf, 10, &n);\n\tif (rv < 0)\n\t\treturn rv;\n\tatomic_set(&mddev->max_corr_read_errors, n);\n\treturn len;\n}\n\nstatic struct md_sysfs_entry max_corr_read_errors =\n__ATTR(max_read_errors, S_IRUGO|S_IWUSR, max_corrected_read_errors_show,\n\tmax_corrected_read_errors_store);\n\nstatic ssize_t\nnull_show(struct mddev *mddev, char *page)\n{\n\treturn -EINVAL;\n}\n\n/* need to ensure rdev_delayed_delete() has completed */\nstatic void flush_rdev_wq(struct mddev *mddev)\n{\n\tstruct md_rdev *rdev;\n\n\trcu_read_lock();\n\trdev_for_each_rcu(rdev, mddev)\n\t\tif (work_pending(&rdev->del_work)) {\n\t\t\tflush_workqueue(md_rdev_misc_wq);\n\t\t\tbreak;\n\t\t}\n\trcu_read_unlock();\n}\n\nstatic ssize_t\nnew_dev_store(struct mddev *mddev, const char *buf, size_t len)\n{\n\t/* buf must be %d:%d\\n? giving major and minor numbers */\n\t/* The new device is added to the array.\n\t * If the array has a persistent superblock, we read the\n\t * superblock to initialise info and check validity.\n\t * Otherwise, only checking done is that in bind_rdev_to_array,\n\t * which mainly checks size.\n\t */\n\tchar *e;\n\tint major = simple_strtoul(buf, &e, 10);\n\tint minor;\n\tdev_t dev;\n\tstruct md_rdev *rdev;\n\tint err;\n\n\tif (!*buf || *e != ':' || !e[1] || e[1] == '\\n')\n\t\treturn -EINVAL;\n\tminor = simple_strtoul(e+1, &e, 10);\n\tif (*e && *e != '\\n')\n\t\treturn -EINVAL;\n\tdev = MKDEV(major, minor);\n\tif (major != MAJOR(dev) ||\n\t    minor != MINOR(dev))\n\t\treturn -EOVERFLOW;\n\n\tflush_rdev_wq(mddev);\n\terr = mddev_lock(mddev);\n\tif (err)\n\t\treturn err;\n\tif (mddev->persistent) {\n\t\trdev = md_import_device(dev, mddev->major_version,\n\t\t\t\t\tmddev->minor_version);\n\t\tif (!IS_ERR(rdev) && !list_empty(&mddev->disks)) {\n\t\t\tstruct md_rdev *rdev0\n\t\t\t\t= list_entry(mddev->disks.next,\n\t\t\t\t\t     struct md_rdev, same_set);\n\t\t\terr = super_types[mddev->major_version]\n\t\t\t\t.load_super(rdev, rdev0, mddev->minor_version);\n\t\t\tif (err < 0)\n\t\t\t\tgoto out;\n\t\t}\n\t} else if (mddev->external)\n\t\trdev = md_import_device(dev, -2, -1);\n\telse\n\t\trdev = md_import_device(dev, -1, -1);\n\n\tif (IS_ERR(rdev)) {\n\t\tmddev_unlock(mddev);\n\t\treturn PTR_ERR(rdev);\n\t}\n\terr = bind_rdev_to_array(rdev, mddev);\n out:\n\tif (err)\n\t\texport_rdev(rdev);\n\tmddev_unlock(mddev);\n\tif (!err)\n\t\tmd_new_event(mddev);\n\treturn err ? err : len;\n}\n\nstatic struct md_sysfs_entry md_new_device =\n__ATTR(new_dev, S_IWUSR, null_show, new_dev_store);\n\nstatic ssize_t\nbitmap_store(struct mddev *mddev, const char *buf, size_t len)\n{\n\tchar *end;\n\tunsigned long chunk, end_chunk;\n\tint err;\n\n\terr = mddev_lock(mddev);\n\tif (err)\n\t\treturn err;\n\tif (!mddev->bitmap)\n\t\tgoto out;\n\t/* buf should be <chunk> <chunk> ... or <chunk>-<chunk> ... (range) */\n\twhile (*buf) {\n\t\tchunk = end_chunk = simple_strtoul(buf, &end, 0);\n\t\tif (buf == end) break;\n\t\tif (*end == '-') { /* range */\n\t\t\tbuf = end + 1;\n\t\t\tend_chunk = simple_strtoul(buf, &end, 0);\n\t\t\tif (buf == end) break;\n\t\t}\n\t\tif (*end && !isspace(*end)) break;\n\t\tmd_bitmap_dirty_bits(mddev->bitmap, chunk, end_chunk);\n\t\tbuf = skip_spaces(end);\n\t}\n\tmd_bitmap_unplug(mddev->bitmap); /* flush the bits to disk */\nout:\n\tmddev_unlock(mddev);\n\treturn len;\n}\n\nstatic struct md_sysfs_entry md_bitmap =\n__ATTR(bitmap_set_bits, S_IWUSR, null_show, bitmap_store);\n\nstatic ssize_t\nsize_show(struct mddev *mddev, char *page)\n{\n\treturn sprintf(page, \"%llu\\n\",\n\t\t(unsigned long long)mddev->dev_sectors / 2);\n}\n\nstatic int update_size(struct mddev *mddev, sector_t num_sectors);\n\nstatic ssize_t\nsize_store(struct mddev *mddev, const char *buf, size_t len)\n{\n\t/* If array is inactive, we can reduce the component size, but\n\t * not increase it (except from 0).\n\t * If array is active, we can try an on-line resize\n\t */\n\tsector_t sectors;\n\tint err = strict_blocks_to_sectors(buf, &sectors);\n\n\tif (err < 0)\n\t\treturn err;\n\terr = mddev_lock(mddev);\n\tif (err)\n\t\treturn err;\n\tif (mddev->pers) {\n\t\terr = update_size(mddev, sectors);\n\t\tif (err == 0)\n\t\t\tmd_update_sb(mddev, 1);\n\t} else {\n\t\tif (mddev->dev_sectors == 0 ||\n\t\t    mddev->dev_sectors > sectors)\n\t\t\tmddev->dev_sectors = sectors;\n\t\telse\n\t\t\terr = -ENOSPC;\n\t}\n\tmddev_unlock(mddev);\n\treturn err ? err : len;\n}\n\nstatic struct md_sysfs_entry md_size =\n__ATTR(component_size, S_IRUGO|S_IWUSR, size_show, size_store);\n\n/* Metadata version.\n * This is one of\n *   'none' for arrays with no metadata (good luck...)\n *   'external' for arrays with externally managed metadata,\n * or N.M for internally known formats\n */\nstatic ssize_t\nmetadata_show(struct mddev *mddev, char *page)\n{\n\tif (mddev->persistent)\n\t\treturn sprintf(page, \"%d.%d\\n\",\n\t\t\t       mddev->major_version, mddev->minor_version);\n\telse if (mddev->external)\n\t\treturn sprintf(page, \"external:%s\\n\", mddev->metadata_type);\n\telse\n\t\treturn sprintf(page, \"none\\n\");\n}\n\nstatic ssize_t\nmetadata_store(struct mddev *mddev, const char *buf, size_t len)\n{\n\tint major, minor;\n\tchar *e;\n\tint err;\n\t/* Changing the details of 'external' metadata is\n\t * always permitted.  Otherwise there must be\n\t * no devices attached to the array.\n\t */\n\n\terr = mddev_lock(mddev);\n\tif (err)\n\t\treturn err;\n\terr = -EBUSY;\n\tif (mddev->external && strncmp(buf, \"external:\", 9) == 0)\n\t\t;\n\telse if (!list_empty(&mddev->disks))\n\t\tgoto out_unlock;\n\n\terr = 0;\n\tif (cmd_match(buf, \"none\")) {\n\t\tmddev->persistent = 0;\n\t\tmddev->external = 0;\n\t\tmddev->major_version = 0;\n\t\tmddev->minor_version = 90;\n\t\tgoto out_unlock;\n\t}\n\tif (strncmp(buf, \"external:\", 9) == 0) {\n\t\tsize_t namelen = len-9;\n\t\tif (namelen >= sizeof(mddev->metadata_type))\n\t\t\tnamelen = sizeof(mddev->metadata_type)-1;\n\t\tstrncpy(mddev->metadata_type, buf+9, namelen);\n\t\tmddev->metadata_type[namelen] = 0;\n\t\tif (namelen && mddev->metadata_type[namelen-1] == '\\n')\n\t\t\tmddev->metadata_type[--namelen] = 0;\n\t\tmddev->persistent = 0;\n\t\tmddev->external = 1;\n\t\tmddev->major_version = 0;\n\t\tmddev->minor_version = 90;\n\t\tgoto out_unlock;\n\t}\n\tmajor = simple_strtoul(buf, &e, 10);\n\terr = -EINVAL;\n\tif (e==buf || *e != '.')\n\t\tgoto out_unlock;\n\tbuf = e+1;\n\tminor = simple_strtoul(buf, &e, 10);\n\tif (e==buf || (*e && *e != '\\n') )\n\t\tgoto out_unlock;\n\terr = -ENOENT;\n\tif (major >= ARRAY_SIZE(super_types) || super_types[major].name == NULL)\n\t\tgoto out_unlock;\n\tmddev->major_version = major;\n\tmddev->minor_version = minor;\n\tmddev->persistent = 1;\n\tmddev->external = 0;\n\terr = 0;\nout_unlock:\n\tmddev_unlock(mddev);\n\treturn err ?: len;\n}\n\nstatic struct md_sysfs_entry md_metadata =\n__ATTR_PREALLOC(metadata_version, S_IRUGO|S_IWUSR, metadata_show, metadata_store);\n\nstatic ssize_t\naction_show(struct mddev *mddev, char *page)\n{\n\tchar *type = \"idle\";\n\tunsigned long recovery = mddev->recovery;\n\tif (test_bit(MD_RECOVERY_FROZEN, &recovery))\n\t\ttype = \"frozen\";\n\telse if (test_bit(MD_RECOVERY_RUNNING, &recovery) ||\n\t    (!mddev->ro && test_bit(MD_RECOVERY_NEEDED, &recovery))) {\n\t\tif (test_bit(MD_RECOVERY_RESHAPE, &recovery))\n\t\t\ttype = \"reshape\";\n\t\telse if (test_bit(MD_RECOVERY_SYNC, &recovery)) {\n\t\t\tif (!test_bit(MD_RECOVERY_REQUESTED, &recovery))\n\t\t\t\ttype = \"resync\";\n\t\t\telse if (test_bit(MD_RECOVERY_CHECK, &recovery))\n\t\t\t\ttype = \"check\";\n\t\t\telse\n\t\t\t\ttype = \"repair\";\n\t\t} else if (test_bit(MD_RECOVERY_RECOVER, &recovery))\n\t\t\ttype = \"recover\";\n\t\telse if (mddev->reshape_position != MaxSector)\n\t\t\ttype = \"reshape\";\n\t}\n\treturn sprintf(page, \"%s\\n\", type);\n}\n\nstatic ssize_t\naction_store(struct mddev *mddev, const char *page, size_t len)\n{\n\tif (!mddev->pers || !mddev->pers->sync_request)\n\t\treturn -EINVAL;\n\n\n\tif (cmd_match(page, \"idle\") || cmd_match(page, \"frozen\")) {\n\t\tif (cmd_match(page, \"frozen\"))\n\t\t\tset_bit(MD_RECOVERY_FROZEN, &mddev->recovery);\n\t\telse\n\t\t\tclear_bit(MD_RECOVERY_FROZEN, &mddev->recovery);\n\t\tif (test_bit(MD_RECOVERY_RUNNING, &mddev->recovery) &&\n\t\t    mddev_lock(mddev) == 0) {\n\t\t\tif (work_pending(&mddev->del_work))\n\t\t\t\tflush_workqueue(md_misc_wq);\n\t\t\tif (mddev->sync_thread) {\n\t\t\t\tset_bit(MD_RECOVERY_INTR, &mddev->recovery);\n\t\t\t\tmd_reap_sync_thread(mddev);\n\t\t\t}\n\t\t\tmddev_unlock(mddev);\n\t\t}\n\t} else if (test_bit(MD_RECOVERY_RUNNING, &mddev->recovery))\n\t\treturn -EBUSY;\n\telse if (cmd_match(page, \"resync\"))\n\t\tclear_bit(MD_RECOVERY_FROZEN, &mddev->recovery);\n\telse if (cmd_match(page, \"recover\")) {\n\t\tclear_bit(MD_RECOVERY_FROZEN, &mddev->recovery);\n\t\tset_bit(MD_RECOVERY_RECOVER, &mddev->recovery);\n\t} else if (cmd_match(page, \"reshape\")) {\n\t\tint err;\n\t\tif (mddev->pers->start_reshape == NULL)\n\t\t\treturn -EINVAL;\n\t\terr = mddev_lock(mddev);\n\t\tif (!err) {\n\t\t\tif (test_bit(MD_RECOVERY_RUNNING, &mddev->recovery))\n\t\t\t\terr =  -EBUSY;\n\t\t\telse {\n\t\t\t\tclear_bit(MD_RECOVERY_FROZEN, &mddev->recovery);\n\t\t\t\terr = mddev->pers->start_reshape(mddev);\n\t\t\t}\n\t\t\tmddev_unlock(mddev);\n\t\t}\n\t\tif (err)\n\t\t\treturn err;\n\t\tsysfs_notify_dirent_safe(mddev->sysfs_degraded);\n\t} else {\n\t\tif (cmd_match(page, \"check\"))\n\t\t\tset_bit(MD_RECOVERY_CHECK, &mddev->recovery);\n\t\telse if (!cmd_match(page, \"repair\"))\n\t\t\treturn -EINVAL;\n\t\tclear_bit(MD_RECOVERY_FROZEN, &mddev->recovery);\n\t\tset_bit(MD_RECOVERY_REQUESTED, &mddev->recovery);\n\t\tset_bit(MD_RECOVERY_SYNC, &mddev->recovery);\n\t}\n\tif (mddev->ro == 2) {\n\t\t/* A write to sync_action is enough to justify\n\t\t * canceling read-auto mode\n\t\t */\n\t\tmddev->ro = 0;\n\t\tmd_wakeup_thread(mddev->sync_thread);\n\t}\n\tset_bit(MD_RECOVERY_NEEDED, &mddev->recovery);\n\tmd_wakeup_thread(mddev->thread);\n\tsysfs_notify_dirent_safe(mddev->sysfs_action);\n\treturn len;\n}\n\nstatic struct md_sysfs_entry md_scan_mode =\n__ATTR_PREALLOC(sync_action, S_IRUGO|S_IWUSR, action_show, action_store);\n\nstatic ssize_t\nlast_sync_action_show(struct mddev *mddev, char *page)\n{\n\treturn sprintf(page, \"%s\\n\", mddev->last_sync_action);\n}\n\nstatic struct md_sysfs_entry md_last_scan_mode = __ATTR_RO(last_sync_action);\n\nstatic ssize_t\nmismatch_cnt_show(struct mddev *mddev, char *page)\n{\n\treturn sprintf(page, \"%llu\\n\",\n\t\t       (unsigned long long)\n\t\t       atomic64_read(&mddev->resync_mismatches));\n}\n\nstatic struct md_sysfs_entry md_mismatches = __ATTR_RO(mismatch_cnt);\n\nstatic ssize_t\nsync_min_show(struct mddev *mddev, char *page)\n{\n\treturn sprintf(page, \"%d (%s)\\n\", speed_min(mddev),\n\t\t       mddev->sync_speed_min ? \"local\": \"system\");\n}\n\nstatic ssize_t\nsync_min_store(struct mddev *mddev, const char *buf, size_t len)\n{\n\tunsigned int min;\n\tint rv;\n\n\tif (strncmp(buf, \"system\", 6)==0) {\n\t\tmin = 0;\n\t} else {\n\t\trv = kstrtouint(buf, 10, &min);\n\t\tif (rv < 0)\n\t\t\treturn rv;\n\t\tif (min == 0)\n\t\t\treturn -EINVAL;\n\t}\n\tmddev->sync_speed_min = min;\n\treturn len;\n}\n\nstatic struct md_sysfs_entry md_sync_min =\n__ATTR(sync_speed_min, S_IRUGO|S_IWUSR, sync_min_show, sync_min_store);\n\nstatic ssize_t\nsync_max_show(struct mddev *mddev, char *page)\n{\n\treturn sprintf(page, \"%d (%s)\\n\", speed_max(mddev),\n\t\t       mddev->sync_speed_max ? \"local\": \"system\");\n}\n\nstatic ssize_t\nsync_max_store(struct mddev *mddev, const char *buf, size_t len)\n{\n\tunsigned int max;\n\tint rv;\n\n\tif (strncmp(buf, \"system\", 6)==0) {\n\t\tmax = 0;\n\t} else {\n\t\trv = kstrtouint(buf, 10, &max);\n\t\tif (rv < 0)\n\t\t\treturn rv;\n\t\tif (max == 0)\n\t\t\treturn -EINVAL;\n\t}\n\tmddev->sync_speed_max = max;\n\treturn len;\n}\n\nstatic struct md_sysfs_entry md_sync_max =\n__ATTR(sync_speed_max, S_IRUGO|S_IWUSR, sync_max_show, sync_max_store);\n\nstatic ssize_t\ndegraded_show(struct mddev *mddev, char *page)\n{\n\treturn sprintf(page, \"%d\\n\", mddev->degraded);\n}\nstatic struct md_sysfs_entry md_degraded = __ATTR_RO(degraded);\n\nstatic ssize_t\nsync_force_parallel_show(struct mddev *mddev, char *page)\n{\n\treturn sprintf(page, \"%d\\n\", mddev->parallel_resync);\n}\n\nstatic ssize_t\nsync_force_parallel_store(struct mddev *mddev, const char *buf, size_t len)\n{\n\tlong n;\n\n\tif (kstrtol(buf, 10, &n))\n\t\treturn -EINVAL;\n\n\tif (n != 0 && n != 1)\n\t\treturn -EINVAL;\n\n\tmddev->parallel_resync = n;\n\n\tif (mddev->sync_thread)\n\t\twake_up(&resync_wait);\n\n\treturn len;\n}\n\n/* force parallel resync, even with shared block devices */\nstatic struct md_sysfs_entry md_sync_force_parallel =\n__ATTR(sync_force_parallel, S_IRUGO|S_IWUSR,\n       sync_force_parallel_show, sync_force_parallel_store);\n\nstatic ssize_t\nsync_speed_show(struct mddev *mddev, char *page)\n{\n\tunsigned long resync, dt, db;\n\tif (mddev->curr_resync == 0)\n\t\treturn sprintf(page, \"none\\n\");\n\tresync = mddev->curr_mark_cnt - atomic_read(&mddev->recovery_active);\n\tdt = (jiffies - mddev->resync_mark) / HZ;\n\tif (!dt) dt++;\n\tdb = resync - mddev->resync_mark_cnt;\n\treturn sprintf(page, \"%lu\\n\", db/dt/2); /* K/sec */\n}\n\nstatic struct md_sysfs_entry md_sync_speed = __ATTR_RO(sync_speed);\n\nstatic ssize_t\nsync_completed_show(struct mddev *mddev, char *page)\n{\n\tunsigned long long max_sectors, resync;\n\n\tif (!test_bit(MD_RECOVERY_RUNNING, &mddev->recovery))\n\t\treturn sprintf(page, \"none\\n\");\n\n\tif (mddev->curr_resync == 1 ||\n\t    mddev->curr_resync == 2)\n\t\treturn sprintf(page, \"delayed\\n\");\n\n\tif (test_bit(MD_RECOVERY_SYNC, &mddev->recovery) ||\n\t    test_bit(MD_RECOVERY_RESHAPE, &mddev->recovery))\n\t\tmax_sectors = mddev->resync_max_sectors;\n\telse\n\t\tmax_sectors = mddev->dev_sectors;\n\n\tresync = mddev->curr_resync_completed;\n\treturn sprintf(page, \"%llu / %llu\\n\", resync, max_sectors);\n}\n\nstatic struct md_sysfs_entry md_sync_completed =\n\t__ATTR_PREALLOC(sync_completed, S_IRUGO, sync_completed_show, NULL);\n\nstatic ssize_t\nmin_sync_show(struct mddev *mddev, char *page)\n{\n\treturn sprintf(page, \"%llu\\n\",\n\t\t       (unsigned long long)mddev->resync_min);\n}\nstatic ssize_t\nmin_sync_store(struct mddev *mddev, const char *buf, size_t len)\n{\n\tunsigned long long min;\n\tint err;\n\n\tif (kstrtoull(buf, 10, &min))\n\t\treturn -EINVAL;\n\n\tspin_lock(&mddev->lock);\n\terr = -EINVAL;\n\tif (min > mddev->resync_max)\n\t\tgoto out_unlock;\n\n\terr = -EBUSY;\n\tif (test_bit(MD_RECOVERY_RUNNING, &mddev->recovery))\n\t\tgoto out_unlock;\n\n\t/* Round down to multiple of 4K for safety */\n\tmddev->resync_min = round_down(min, 8);\n\terr = 0;\n\nout_unlock:\n\tspin_unlock(&mddev->lock);\n\treturn err ?: len;\n}\n\nstatic struct md_sysfs_entry md_min_sync =\n__ATTR(sync_min, S_IRUGO|S_IWUSR, min_sync_show, min_sync_store);\n\nstatic ssize_t\nmax_sync_show(struct mddev *mddev, char *page)\n{\n\tif (mddev->resync_max == MaxSector)\n\t\treturn sprintf(page, \"max\\n\");\n\telse\n\t\treturn sprintf(page, \"%llu\\n\",\n\t\t\t       (unsigned long long)mddev->resync_max);\n}\nstatic ssize_t\nmax_sync_store(struct mddev *mddev, const char *buf, size_t len)\n{\n\tint err;\n\tspin_lock(&mddev->lock);\n\tif (strncmp(buf, \"max\", 3) == 0)\n\t\tmddev->resync_max = MaxSector;\n\telse {\n\t\tunsigned long long max;\n\t\tint chunk;\n\n\t\terr = -EINVAL;\n\t\tif (kstrtoull(buf, 10, &max))\n\t\t\tgoto out_unlock;\n\t\tif (max < mddev->resync_min)\n\t\t\tgoto out_unlock;\n\n\t\terr = -EBUSY;\n\t\tif (max < mddev->resync_max &&\n\t\t    mddev->ro == 0 &&\n\t\t    test_bit(MD_RECOVERY_RUNNING, &mddev->recovery))\n\t\t\tgoto out_unlock;\n\n\t\t/* Must be a multiple of chunk_size */\n\t\tchunk = mddev->chunk_sectors;\n\t\tif (chunk) {\n\t\t\tsector_t temp = max;\n\n\t\t\terr = -EINVAL;\n\t\t\tif (sector_div(temp, chunk))\n\t\t\t\tgoto out_unlock;\n\t\t}\n\t\tmddev->resync_max = max;\n\t}\n\twake_up(&mddev->recovery_wait);\n\terr = 0;\nout_unlock:\n\tspin_unlock(&mddev->lock);\n\treturn err ?: len;\n}\n\nstatic struct md_sysfs_entry md_max_sync =\n__ATTR(sync_max, S_IRUGO|S_IWUSR, max_sync_show, max_sync_store);\n\nstatic ssize_t\nsuspend_lo_show(struct mddev *mddev, char *page)\n{\n\treturn sprintf(page, \"%llu\\n\", (unsigned long long)mddev->suspend_lo);\n}\n\nstatic ssize_t\nsuspend_lo_store(struct mddev *mddev, const char *buf, size_t len)\n{\n\tunsigned long long new;\n\tint err;\n\n\terr = kstrtoull(buf, 10, &new);\n\tif (err < 0)\n\t\treturn err;\n\tif (new != (sector_t)new)\n\t\treturn -EINVAL;\n\n\terr = mddev_lock(mddev);\n\tif (err)\n\t\treturn err;\n\terr = -EINVAL;\n\tif (mddev->pers == NULL ||\n\t    mddev->pers->quiesce == NULL)\n\t\tgoto unlock;\n\tmddev_suspend(mddev);\n\tmddev->suspend_lo = new;\n\tmddev_resume(mddev);\n\n\terr = 0;\nunlock:\n\tmddev_unlock(mddev);\n\treturn err ?: len;\n}\nstatic struct md_sysfs_entry md_suspend_lo =\n__ATTR(suspend_lo, S_IRUGO|S_IWUSR, suspend_lo_show, suspend_lo_store);\n\nstatic ssize_t\nsuspend_hi_show(struct mddev *mddev, char *page)\n{\n\treturn sprintf(page, \"%llu\\n\", (unsigned long long)mddev->suspend_hi);\n}\n\nstatic ssize_t\nsuspend_hi_store(struct mddev *mddev, const char *buf, size_t len)\n{\n\tunsigned long long new;\n\tint err;\n\n\terr = kstrtoull(buf, 10, &new);\n\tif (err < 0)\n\t\treturn err;\n\tif (new != (sector_t)new)\n\t\treturn -EINVAL;\n\n\terr = mddev_lock(mddev);\n\tif (err)\n\t\treturn err;\n\terr = -EINVAL;\n\tif (mddev->pers == NULL)\n\t\tgoto unlock;\n\n\tmddev_suspend(mddev);\n\tmddev->suspend_hi = new;\n\tmddev_resume(mddev);\n\n\terr = 0;\nunlock:\n\tmddev_unlock(mddev);\n\treturn err ?: len;\n}\nstatic struct md_sysfs_entry md_suspend_hi =\n__ATTR(suspend_hi, S_IRUGO|S_IWUSR, suspend_hi_show, suspend_hi_store);\n\nstatic ssize_t\nreshape_position_show(struct mddev *mddev, char *page)\n{\n\tif (mddev->reshape_position != MaxSector)\n\t\treturn sprintf(page, \"%llu\\n\",\n\t\t\t       (unsigned long long)mddev->reshape_position);\n\tstrcpy(page, \"none\\n\");\n\treturn 5;\n}\n\nstatic ssize_t\nreshape_position_store(struct mddev *mddev, const char *buf, size_t len)\n{\n\tstruct md_rdev *rdev;\n\tunsigned long long new;\n\tint err;\n\n\terr = kstrtoull(buf, 10, &new);\n\tif (err < 0)\n\t\treturn err;\n\tif (new != (sector_t)new)\n\t\treturn -EINVAL;\n\terr = mddev_lock(mddev);\n\tif (err)\n\t\treturn err;\n\terr = -EBUSY;\n\tif (mddev->pers)\n\t\tgoto unlock;\n\tmddev->reshape_position = new;\n\tmddev->delta_disks = 0;\n\tmddev->reshape_backwards = 0;\n\tmddev->new_level = mddev->level;\n\tmddev->new_layout = mddev->layout;\n\tmddev->new_chunk_sectors = mddev->chunk_sectors;\n\trdev_for_each(rdev, mddev)\n\t\trdev->new_data_offset = rdev->data_offset;\n\terr = 0;\nunlock:\n\tmddev_unlock(mddev);\n\treturn err ?: len;\n}\n\nstatic struct md_sysfs_entry md_reshape_position =\n__ATTR(reshape_position, S_IRUGO|S_IWUSR, reshape_position_show,\n       reshape_position_store);\n\nstatic ssize_t\nreshape_direction_show(struct mddev *mddev, char *page)\n{\n\treturn sprintf(page, \"%s\\n\",\n\t\t       mddev->reshape_backwards ? \"backwards\" : \"forwards\");\n}\n\nstatic ssize_t\nreshape_direction_store(struct mddev *mddev, const char *buf, size_t len)\n{\n\tint backwards = 0;\n\tint err;\n\n\tif (cmd_match(buf, \"forwards\"))\n\t\tbackwards = 0;\n\telse if (cmd_match(buf, \"backwards\"))\n\t\tbackwards = 1;\n\telse\n\t\treturn -EINVAL;\n\tif (mddev->reshape_backwards == backwards)\n\t\treturn len;\n\n\terr = mddev_lock(mddev);\n\tif (err)\n\t\treturn err;\n\t/* check if we are allowed to change */\n\tif (mddev->delta_disks)\n\t\terr = -EBUSY;\n\telse if (mddev->persistent &&\n\t    mddev->major_version == 0)\n\t\terr =  -EINVAL;\n\telse\n\t\tmddev->reshape_backwards = backwards;\n\tmddev_unlock(mddev);\n\treturn err ?: len;\n}\n\nstatic struct md_sysfs_entry md_reshape_direction =\n__ATTR(reshape_direction, S_IRUGO|S_IWUSR, reshape_direction_show,\n       reshape_direction_store);\n\nstatic ssize_t\narray_size_show(struct mddev *mddev, char *page)\n{\n\tif (mddev->external_size)\n\t\treturn sprintf(page, \"%llu\\n\",\n\t\t\t       (unsigned long long)mddev->array_sectors/2);\n\telse\n\t\treturn sprintf(page, \"default\\n\");\n}\n\nstatic ssize_t\narray_size_store(struct mddev *mddev, const char *buf, size_t len)\n{\n\tsector_t sectors;\n\tint err;\n\n\terr = mddev_lock(mddev);\n\tif (err)\n\t\treturn err;\n\n\t/* cluster raid doesn't support change array_sectors */\n\tif (mddev_is_clustered(mddev)) {\n\t\tmddev_unlock(mddev);\n\t\treturn -EINVAL;\n\t}\n\n\tif (strncmp(buf, \"default\", 7) == 0) {\n\t\tif (mddev->pers)\n\t\t\tsectors = mddev->pers->size(mddev, 0, 0);\n\t\telse\n\t\t\tsectors = mddev->array_sectors;\n\n\t\tmddev->external_size = 0;\n\t} else {\n\t\tif (strict_blocks_to_sectors(buf, &sectors) < 0)\n\t\t\terr = -EINVAL;\n\t\telse if (mddev->pers && mddev->pers->size(mddev, 0, 0) < sectors)\n\t\t\terr = -E2BIG;\n\t\telse\n\t\t\tmddev->external_size = 1;\n\t}\n\n\tif (!err) {\n\t\tmddev->array_sectors = sectors;\n\t\tif (mddev->pers)\n\t\t\tset_capacity_and_notify(mddev->gendisk,\n\t\t\t\t\t\tmddev->array_sectors);\n\t}\n\tmddev_unlock(mddev);\n\treturn err ?: len;\n}\n\nstatic struct md_sysfs_entry md_array_size =\n__ATTR(array_size, S_IRUGO|S_IWUSR, array_size_show,\n       array_size_store);\n\nstatic ssize_t\nconsistency_policy_show(struct mddev *mddev, char *page)\n{\n\tint ret;\n\n\tif (test_bit(MD_HAS_JOURNAL, &mddev->flags)) {\n\t\tret = sprintf(page, \"journal\\n\");\n\t} else if (test_bit(MD_HAS_PPL, &mddev->flags)) {\n\t\tret = sprintf(page, \"ppl\\n\");\n\t} else if (mddev->bitmap) {\n\t\tret = sprintf(page, \"bitmap\\n\");\n\t} else if (mddev->pers) {\n\t\tif (mddev->pers->sync_request)\n\t\t\tret = sprintf(page, \"resync\\n\");\n\t\telse\n\t\t\tret = sprintf(page, \"none\\n\");\n\t} else {\n\t\tret = sprintf(page, \"unknown\\n\");\n\t}\n\n\treturn ret;\n}\n\nstatic ssize_t\nconsistency_policy_store(struct mddev *mddev, const char *buf, size_t len)\n{\n\tint err = 0;\n\n\tif (mddev->pers) {\n\t\tif (mddev->pers->change_consistency_policy)\n\t\t\terr = mddev->pers->change_consistency_policy(mddev, buf);\n\t\telse\n\t\t\terr = -EBUSY;\n\t} else if (mddev->external && strncmp(buf, \"ppl\", 3) == 0) {\n\t\tset_bit(MD_HAS_PPL, &mddev->flags);\n\t} else {\n\t\terr = -EINVAL;\n\t}\n\n\treturn err ? err : len;\n}\n\nstatic struct md_sysfs_entry md_consistency_policy =\n__ATTR(consistency_policy, S_IRUGO | S_IWUSR, consistency_policy_show,\n       consistency_policy_store);\n\nstatic ssize_t fail_last_dev_show(struct mddev *mddev, char *page)\n{\n\treturn sprintf(page, \"%d\\n\", mddev->fail_last_dev);\n}\n\n/*\n * Setting fail_last_dev to true to allow last device to be forcibly removed\n * from RAID1/RAID10.\n */\nstatic ssize_t\nfail_last_dev_store(struct mddev *mddev, const char *buf, size_t len)\n{\n\tint ret;\n\tbool value;\n\n\tret = kstrtobool(buf, &value);\n\tif (ret)\n\t\treturn ret;\n\n\tif (value != mddev->fail_last_dev)\n\t\tmddev->fail_last_dev = value;\n\n\treturn len;\n}\nstatic struct md_sysfs_entry md_fail_last_dev =\n__ATTR(fail_last_dev, S_IRUGO | S_IWUSR, fail_last_dev_show,\n       fail_last_dev_store);\n\nstatic ssize_t serialize_policy_show(struct mddev *mddev, char *page)\n{\n\tif (mddev->pers == NULL || (mddev->pers->level != 1))\n\t\treturn sprintf(page, \"n/a\\n\");\n\telse\n\t\treturn sprintf(page, \"%d\\n\", mddev->serialize_policy);\n}\n\n/*\n * Setting serialize_policy to true to enforce write IO is not reordered\n * for raid1.\n */\nstatic ssize_t\nserialize_policy_store(struct mddev *mddev, const char *buf, size_t len)\n{\n\tint err;\n\tbool value;\n\n\terr = kstrtobool(buf, &value);\n\tif (err)\n\t\treturn err;\n\n\tif (value == mddev->serialize_policy)\n\t\treturn len;\n\n\terr = mddev_lock(mddev);\n\tif (err)\n\t\treturn err;\n\tif (mddev->pers == NULL || (mddev->pers->level != 1)) {\n\t\tpr_err(\"md: serialize_policy is only effective for raid1\\n\");\n\t\terr = -EINVAL;\n\t\tgoto unlock;\n\t}\n\n\tmddev_suspend(mddev);\n\tif (value)\n\t\tmddev_create_serial_pool(mddev, NULL, true);\n\telse\n\t\tmddev_destroy_serial_pool(mddev, NULL, true);\n\tmddev->serialize_policy = value;\n\tmddev_resume(mddev);\nunlock:\n\tmddev_unlock(mddev);\n\treturn err ?: len;\n}\n\nstatic struct md_sysfs_entry md_serialize_policy =\n__ATTR(serialize_policy, S_IRUGO | S_IWUSR, serialize_policy_show,\n       serialize_policy_store);\n\n\nstatic struct attribute *md_default_attrs[] = {\n\t&md_level.attr,\n\t&md_layout.attr,\n\t&md_raid_disks.attr,\n\t&md_uuid.attr,\n\t&md_chunk_size.attr,\n\t&md_size.attr,\n\t&md_resync_start.attr,\n\t&md_metadata.attr,\n\t&md_new_device.attr,\n\t&md_safe_delay.attr,\n\t&md_array_state.attr,\n\t&md_reshape_position.attr,\n\t&md_reshape_direction.attr,\n\t&md_array_size.attr,\n\t&max_corr_read_errors.attr,\n\t&md_consistency_policy.attr,\n\t&md_fail_last_dev.attr,\n\t&md_serialize_policy.attr,\n\tNULL,\n};\n\nstatic struct attribute *md_redundancy_attrs[] = {\n\t&md_scan_mode.attr,\n\t&md_last_scan_mode.attr,\n\t&md_mismatches.attr,\n\t&md_sync_min.attr,\n\t&md_sync_max.attr,\n\t&md_sync_speed.attr,\n\t&md_sync_force_parallel.attr,\n\t&md_sync_completed.attr,\n\t&md_min_sync.attr,\n\t&md_max_sync.attr,\n\t&md_suspend_lo.attr,\n\t&md_suspend_hi.attr,\n\t&md_bitmap.attr,\n\t&md_degraded.attr,\n\tNULL,\n};\nstatic struct attribute_group md_redundancy_group = {\n\t.name = NULL,\n\t.attrs = md_redundancy_attrs,\n};\n\nstatic ssize_t\nmd_attr_show(struct kobject *kobj, struct attribute *attr, char *page)\n{\n\tstruct md_sysfs_entry *entry = container_of(attr, struct md_sysfs_entry, attr);\n\tstruct mddev *mddev = container_of(kobj, struct mddev, kobj);\n\tssize_t rv;\n\n\tif (!entry->show)\n\t\treturn -EIO;\n\tspin_lock(&all_mddevs_lock);\n\tif (list_empty(&mddev->all_mddevs)) {\n\t\tspin_unlock(&all_mddevs_lock);\n\t\treturn -EBUSY;\n\t}\n\tmddev_get(mddev);\n\tspin_unlock(&all_mddevs_lock);\n\n\trv = entry->show(mddev, page);\n\tmddev_put(mddev);\n\treturn rv;\n}\n\nstatic ssize_t\nmd_attr_store(struct kobject *kobj, struct attribute *attr,\n\t      const char *page, size_t length)\n{\n\tstruct md_sysfs_entry *entry = container_of(attr, struct md_sysfs_entry, attr);\n\tstruct mddev *mddev = container_of(kobj, struct mddev, kobj);\n\tssize_t rv;\n\n\tif (!entry->store)\n\t\treturn -EIO;\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn -EACCES;\n\tspin_lock(&all_mddevs_lock);\n\tif (list_empty(&mddev->all_mddevs)) {\n\t\tspin_unlock(&all_mddevs_lock);\n\t\treturn -EBUSY;\n\t}\n\tmddev_get(mddev);\n\tspin_unlock(&all_mddevs_lock);\n\trv = entry->store(mddev, page, length);\n\tmddev_put(mddev);\n\treturn rv;\n}\n\nstatic void md_free(struct kobject *ko)\n{\n\tstruct mddev *mddev = container_of(ko, struct mddev, kobj);\n\n\tif (mddev->sysfs_state)\n\t\tsysfs_put(mddev->sysfs_state);\n\tif (mddev->sysfs_level)\n\t\tsysfs_put(mddev->sysfs_level);\n\n\tif (mddev->gendisk)\n\t\tdel_gendisk(mddev->gendisk);\n\tif (mddev->queue)\n\t\tblk_cleanup_queue(mddev->queue);\n\tif (mddev->gendisk)\n\t\tput_disk(mddev->gendisk);\n\tpercpu_ref_exit(&mddev->writes_pending);\n\n\tbioset_exit(&mddev->bio_set);\n\tbioset_exit(&mddev->sync_set);\n\tmempool_exit(&mddev->md_io_pool);\n\tkfree(mddev);\n}\n\nstatic const struct sysfs_ops md_sysfs_ops = {\n\t.show\t= md_attr_show,\n\t.store\t= md_attr_store,\n};\nstatic struct kobj_type md_ktype = {\n\t.release\t= md_free,\n\t.sysfs_ops\t= &md_sysfs_ops,\n\t.default_attrs\t= md_default_attrs,\n};\n\nint mdp_major = 0;\n\nstatic void mddev_delayed_delete(struct work_struct *ws)\n{\n\tstruct mddev *mddev = container_of(ws, struct mddev, del_work);\n\n\tsysfs_remove_group(&mddev->kobj, &md_bitmap_group);\n\tkobject_del(&mddev->kobj);\n\tkobject_put(&mddev->kobj);\n}\n\nstatic void no_op(struct percpu_ref *r) {}\n\nint mddev_init_writes_pending(struct mddev *mddev)\n{\n\tif (mddev->writes_pending.percpu_count_ptr)\n\t\treturn 0;\n\tif (percpu_ref_init(&mddev->writes_pending, no_op,\n\t\t\t    PERCPU_REF_ALLOW_REINIT, GFP_KERNEL) < 0)\n\t\treturn -ENOMEM;\n\t/* We want to start with the refcount at zero */\n\tpercpu_ref_put(&mddev->writes_pending);\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(mddev_init_writes_pending);\n\nstatic int md_alloc(dev_t dev, char *name)\n{\n\t/*\n\t * If dev is zero, name is the name of a device to allocate with\n\t * an arbitrary minor number.  It will be \"md_???\"\n\t * If dev is non-zero it must be a device number with a MAJOR of\n\t * MD_MAJOR or mdp_major.  In this case, if \"name\" is NULL, then\n\t * the device is being created by opening a node in /dev.\n\t * If \"name\" is not NULL, the device is being created by\n\t * writing to /sys/module/md_mod/parameters/new_array.\n\t */\n\tstatic DEFINE_MUTEX(disks_mutex);\n\tstruct mddev *mddev = mddev_find(dev);\n\tstruct gendisk *disk;\n\tint partitioned;\n\tint shift;\n\tint unit;\n\tint error;\n\n\tif (!mddev)\n\t\treturn -ENODEV;\n\n\tpartitioned = (MAJOR(mddev->unit) != MD_MAJOR);\n\tshift = partitioned ? MdpMinorShift : 0;\n\tunit = MINOR(mddev->unit) >> shift;\n\n\t/* wait for any previous instance of this device to be\n\t * completely removed (mddev_delayed_delete).\n\t */\n\tflush_workqueue(md_misc_wq);\n\n\tmutex_lock(&disks_mutex);\n\terror = -EEXIST;\n\tif (mddev->gendisk)\n\t\tgoto abort;\n\n\tif (name && !dev) {\n\t\t/* Need to ensure that 'name' is not a duplicate.\n\t\t */\n\t\tstruct mddev *mddev2;\n\t\tspin_lock(&all_mddevs_lock);\n\n\t\tlist_for_each_entry(mddev2, &all_mddevs, all_mddevs)\n\t\t\tif (mddev2->gendisk &&\n\t\t\t    strcmp(mddev2->gendisk->disk_name, name) == 0) {\n\t\t\t\tspin_unlock(&all_mddevs_lock);\n\t\t\t\tgoto abort;\n\t\t\t}\n\t\tspin_unlock(&all_mddevs_lock);\n\t}\n\tif (name && dev)\n\t\t/*\n\t\t * Creating /dev/mdNNN via \"newarray\", so adjust hold_active.\n\t\t */\n\t\tmddev->hold_active = UNTIL_STOP;\n\n\terror = mempool_init_kmalloc_pool(&mddev->md_io_pool, BIO_POOL_SIZE,\n\t\t\t\t\t  sizeof(struct md_io));\n\tif (error)\n\t\tgoto abort;\n\n\terror = -ENOMEM;\n\tmddev->queue = blk_alloc_queue(NUMA_NO_NODE);\n\tif (!mddev->queue)\n\t\tgoto abort;\n\n\tblk_set_stacking_limits(&mddev->queue->limits);\n\n\tdisk = alloc_disk(1 << shift);\n\tif (!disk) {\n\t\tblk_cleanup_queue(mddev->queue);\n\t\tmddev->queue = NULL;\n\t\tgoto abort;\n\t}\n\tdisk->major = MAJOR(mddev->unit);\n\tdisk->first_minor = unit << shift;\n\tif (name)\n\t\tstrcpy(disk->disk_name, name);\n\telse if (partitioned)\n\t\tsprintf(disk->disk_name, \"md_d%d\", unit);\n\telse\n\t\tsprintf(disk->disk_name, \"md%d\", unit);\n\tdisk->fops = &md_fops;\n\tdisk->private_data = mddev;\n\tdisk->queue = mddev->queue;\n\tblk_queue_write_cache(mddev->queue, true, true);\n\t/* Allow extended partitions.  This makes the\n\t * 'mdp' device redundant, but we can't really\n\t * remove it now.\n\t */\n\tdisk->flags |= GENHD_FL_EXT_DEVT;\n\tdisk->events |= DISK_EVENT_MEDIA_CHANGE;\n\tmddev->gendisk = disk;\n\t/* As soon as we call add_disk(), another thread could get\n\t * through to md_open, so make sure it doesn't get too far\n\t */\n\tmutex_lock(&mddev->open_mutex);\n\tadd_disk(disk);\n\n\terror = kobject_add(&mddev->kobj, &disk_to_dev(disk)->kobj, \"%s\", \"md\");\n\tif (error) {\n\t\t/* This isn't possible, but as kobject_init_and_add is marked\n\t\t * __must_check, we must do something with the result\n\t\t */\n\t\tpr_debug(\"md: cannot register %s/md - name in use\\n\",\n\t\t\t disk->disk_name);\n\t\terror = 0;\n\t}\n\tif (mddev->kobj.sd &&\n\t    sysfs_create_group(&mddev->kobj, &md_bitmap_group))\n\t\tpr_debug(\"pointless warning\\n\");\n\tmutex_unlock(&mddev->open_mutex);\n abort:\n\tmutex_unlock(&disks_mutex);\n\tif (!error && mddev->kobj.sd) {\n\t\tkobject_uevent(&mddev->kobj, KOBJ_ADD);\n\t\tmddev->sysfs_state = sysfs_get_dirent_safe(mddev->kobj.sd, \"array_state\");\n\t\tmddev->sysfs_level = sysfs_get_dirent_safe(mddev->kobj.sd, \"level\");\n\t}\n\tmddev_put(mddev);\n\treturn error;\n}\n\nstatic void md_probe(dev_t dev)\n{\n\tif (MAJOR(dev) == MD_MAJOR && MINOR(dev) >= 512)\n\t\treturn;\n\tif (create_on_open)\n\t\tmd_alloc(dev, NULL);\n}\n\nstatic int add_named_array(const char *val, const struct kernel_param *kp)\n{\n\t/*\n\t * val must be \"md_*\" or \"mdNNN\".\n\t * For \"md_*\" we allocate an array with a large free minor number, and\n\t * set the name to val.  val must not already be an active name.\n\t * For \"mdNNN\" we allocate an array with the minor number NNN\n\t * which must not already be in use.\n\t */\n\tint len = strlen(val);\n\tchar buf[DISK_NAME_LEN];\n\tunsigned long devnum;\n\n\twhile (len && val[len-1] == '\\n')\n\t\tlen--;\n\tif (len >= DISK_NAME_LEN)\n\t\treturn -E2BIG;\n\tstrlcpy(buf, val, len+1);\n\tif (strncmp(buf, \"md_\", 3) == 0)\n\t\treturn md_alloc(0, buf);\n\tif (strncmp(buf, \"md\", 2) == 0 &&\n\t    isdigit(buf[2]) &&\n\t    kstrtoul(buf+2, 10, &devnum) == 0 &&\n\t    devnum <= MINORMASK)\n\t\treturn md_alloc(MKDEV(MD_MAJOR, devnum), NULL);\n\n\treturn -EINVAL;\n}\n\nstatic void md_safemode_timeout(struct timer_list *t)\n{\n\tstruct mddev *mddev = from_timer(mddev, t, safemode_timer);\n\n\tmddev->safemode = 1;\n\tif (mddev->external)\n\t\tsysfs_notify_dirent_safe(mddev->sysfs_state);\n\n\tmd_wakeup_thread(mddev->thread);\n}\n\nstatic int start_dirty_degraded;\n\nint md_run(struct mddev *mddev)\n{\n\tint err;\n\tstruct md_rdev *rdev;\n\tstruct md_personality *pers;\n\n\tif (list_empty(&mddev->disks))\n\t\t/* cannot run an array with no devices.. */\n\t\treturn -EINVAL;\n\n\tif (mddev->pers)\n\t\treturn -EBUSY;\n\t/* Cannot run until previous stop completes properly */\n\tif (mddev->sysfs_active)\n\t\treturn -EBUSY;\n\n\t/*\n\t * Analyze all RAID superblock(s)\n\t */\n\tif (!mddev->raid_disks) {\n\t\tif (!mddev->persistent)\n\t\t\treturn -EINVAL;\n\t\terr = analyze_sbs(mddev);\n\t\tif (err)\n\t\t\treturn -EINVAL;\n\t}\n\n\tif (mddev->level != LEVEL_NONE)\n\t\trequest_module(\"md-level-%d\", mddev->level);\n\telse if (mddev->clevel[0])\n\t\trequest_module(\"md-%s\", mddev->clevel);\n\n\t/*\n\t * Drop all container device buffers, from now on\n\t * the only valid external interface is through the md\n\t * device.\n\t */\n\tmddev->has_superblocks = false;\n\trdev_for_each(rdev, mddev) {\n\t\tif (test_bit(Faulty, &rdev->flags))\n\t\t\tcontinue;\n\t\tsync_blockdev(rdev->bdev);\n\t\tinvalidate_bdev(rdev->bdev);\n\t\tif (mddev->ro != 1 &&\n\t\t    (bdev_read_only(rdev->bdev) ||\n\t\t     bdev_read_only(rdev->meta_bdev))) {\n\t\t\tmddev->ro = 1;\n\t\t\tif (mddev->gendisk)\n\t\t\t\tset_disk_ro(mddev->gendisk, 1);\n\t\t}\n\n\t\tif (rdev->sb_page)\n\t\t\tmddev->has_superblocks = true;\n\n\t\t/* perform some consistency tests on the device.\n\t\t * We don't want the data to overlap the metadata,\n\t\t * Internal Bitmap issues have been handled elsewhere.\n\t\t */\n\t\tif (rdev->meta_bdev) {\n\t\t\t/* Nothing to check */;\n\t\t} else if (rdev->data_offset < rdev->sb_start) {\n\t\t\tif (mddev->dev_sectors &&\n\t\t\t    rdev->data_offset + mddev->dev_sectors\n\t\t\t    > rdev->sb_start) {\n\t\t\t\tpr_warn(\"md: %s: data overlaps metadata\\n\",\n\t\t\t\t\tmdname(mddev));\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t} else {\n\t\t\tif (rdev->sb_start + rdev->sb_size/512\n\t\t\t    > rdev->data_offset) {\n\t\t\t\tpr_warn(\"md: %s: metadata overlaps data\\n\",\n\t\t\t\t\tmdname(mddev));\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\t\tsysfs_notify_dirent_safe(rdev->sysfs_state);\n\t}\n\n\tif (!bioset_initialized(&mddev->bio_set)) {\n\t\terr = bioset_init(&mddev->bio_set, BIO_POOL_SIZE, 0, BIOSET_NEED_BVECS);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\tif (!bioset_initialized(&mddev->sync_set)) {\n\t\terr = bioset_init(&mddev->sync_set, BIO_POOL_SIZE, 0, BIOSET_NEED_BVECS);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tspin_lock(&pers_lock);\n\tpers = find_pers(mddev->level, mddev->clevel);\n\tif (!pers || !try_module_get(pers->owner)) {\n\t\tspin_unlock(&pers_lock);\n\t\tif (mddev->level != LEVEL_NONE)\n\t\t\tpr_warn(\"md: personality for level %d is not loaded!\\n\",\n\t\t\t\tmddev->level);\n\t\telse\n\t\t\tpr_warn(\"md: personality for level %s is not loaded!\\n\",\n\t\t\t\tmddev->clevel);\n\t\terr = -EINVAL;\n\t\tgoto abort;\n\t}\n\tspin_unlock(&pers_lock);\n\tif (mddev->level != pers->level) {\n\t\tmddev->level = pers->level;\n\t\tmddev->new_level = pers->level;\n\t}\n\tstrlcpy(mddev->clevel, pers->name, sizeof(mddev->clevel));\n\n\tif (mddev->reshape_position != MaxSector &&\n\t    pers->start_reshape == NULL) {\n\t\t/* This personality cannot handle reshaping... */\n\t\tmodule_put(pers->owner);\n\t\terr = -EINVAL;\n\t\tgoto abort;\n\t}\n\n\tif (pers->sync_request) {\n\t\t/* Warn if this is a potentially silly\n\t\t * configuration.\n\t\t */\n\t\tchar b[BDEVNAME_SIZE], b2[BDEVNAME_SIZE];\n\t\tstruct md_rdev *rdev2;\n\t\tint warned = 0;\n\n\t\trdev_for_each(rdev, mddev)\n\t\t\trdev_for_each(rdev2, mddev) {\n\t\t\t\tif (rdev < rdev2 &&\n\t\t\t\t    rdev->bdev->bd_disk ==\n\t\t\t\t    rdev2->bdev->bd_disk) {\n\t\t\t\t\tpr_warn(\"%s: WARNING: %s appears to be on the same physical disk as %s.\\n\",\n\t\t\t\t\t\tmdname(mddev),\n\t\t\t\t\t\tbdevname(rdev->bdev,b),\n\t\t\t\t\t\tbdevname(rdev2->bdev,b2));\n\t\t\t\t\twarned = 1;\n\t\t\t\t}\n\t\t\t}\n\n\t\tif (warned)\n\t\t\tpr_warn(\"True protection against single-disk failure might be compromised.\\n\");\n\t}\n\n\tmddev->recovery = 0;\n\t/* may be over-ridden by personality */\n\tmddev->resync_max_sectors = mddev->dev_sectors;\n\n\tmddev->ok_start_degraded = start_dirty_degraded;\n\n\tif (start_readonly && mddev->ro == 0)\n\t\tmddev->ro = 2; /* read-only, but switch on first write */\n\n\terr = pers->run(mddev);\n\tif (err)\n\t\tpr_warn(\"md: pers->run() failed ...\\n\");\n\telse if (pers->size(mddev, 0, 0) < mddev->array_sectors) {\n\t\tWARN_ONCE(!mddev->external_size,\n\t\t\t  \"%s: default size too small, but 'external_size' not in effect?\\n\",\n\t\t\t  __func__);\n\t\tpr_warn(\"md: invalid array_size %llu > default size %llu\\n\",\n\t\t\t(unsigned long long)mddev->array_sectors / 2,\n\t\t\t(unsigned long long)pers->size(mddev, 0, 0) / 2);\n\t\terr = -EINVAL;\n\t}\n\tif (err == 0 && pers->sync_request &&\n\t    (mddev->bitmap_info.file || mddev->bitmap_info.offset)) {\n\t\tstruct bitmap *bitmap;\n\n\t\tbitmap = md_bitmap_create(mddev, -1);\n\t\tif (IS_ERR(bitmap)) {\n\t\t\terr = PTR_ERR(bitmap);\n\t\t\tpr_warn(\"%s: failed to create bitmap (%d)\\n\",\n\t\t\t\tmdname(mddev), err);\n\t\t} else\n\t\t\tmddev->bitmap = bitmap;\n\n\t}\n\tif (err)\n\t\tgoto bitmap_abort;\n\n\tif (mddev->bitmap_info.max_write_behind > 0) {\n\t\tbool create_pool = false;\n\n\t\trdev_for_each(rdev, mddev) {\n\t\t\tif (test_bit(WriteMostly, &rdev->flags) &&\n\t\t\t    rdev_init_serial(rdev))\n\t\t\t\tcreate_pool = true;\n\t\t}\n\t\tif (create_pool && mddev->serial_info_pool == NULL) {\n\t\t\tmddev->serial_info_pool =\n\t\t\t\tmempool_create_kmalloc_pool(NR_SERIAL_INFOS,\n\t\t\t\t\t\t    sizeof(struct serial_info));\n\t\t\tif (!mddev->serial_info_pool) {\n\t\t\t\terr = -ENOMEM;\n\t\t\t\tgoto bitmap_abort;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (mddev->queue) {\n\t\tbool nonrot = true;\n\n\t\trdev_for_each(rdev, mddev) {\n\t\t\tif (rdev->raid_disk >= 0 &&\n\t\t\t    !blk_queue_nonrot(bdev_get_queue(rdev->bdev))) {\n\t\t\t\tnonrot = false;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (mddev->degraded)\n\t\t\tnonrot = false;\n\t\tif (nonrot)\n\t\t\tblk_queue_flag_set(QUEUE_FLAG_NONROT, mddev->queue);\n\t\telse\n\t\t\tblk_queue_flag_clear(QUEUE_FLAG_NONROT, mddev->queue);\n\t}\n\tif (pers->sync_request) {\n\t\tif (mddev->kobj.sd &&\n\t\t    sysfs_create_group(&mddev->kobj, &md_redundancy_group))\n\t\t\tpr_warn(\"md: cannot register extra attributes for %s\\n\",\n\t\t\t\tmdname(mddev));\n\t\tmddev->sysfs_action = sysfs_get_dirent_safe(mddev->kobj.sd, \"sync_action\");\n\t\tmddev->sysfs_completed = sysfs_get_dirent_safe(mddev->kobj.sd, \"sync_completed\");\n\t\tmddev->sysfs_degraded = sysfs_get_dirent_safe(mddev->kobj.sd, \"degraded\");\n\t} else if (mddev->ro == 2) /* auto-readonly not meaningful */\n\t\tmddev->ro = 0;\n\n\tatomic_set(&mddev->max_corr_read_errors,\n\t\t   MD_DEFAULT_MAX_CORRECTED_READ_ERRORS);\n\tmddev->safemode = 0;\n\tif (mddev_is_clustered(mddev))\n\t\tmddev->safemode_delay = 0;\n\telse\n\t\tmddev->safemode_delay = DEFAULT_SAFEMODE_DELAY;\n\tmddev->in_sync = 1;\n\tsmp_wmb();\n\tspin_lock(&mddev->lock);\n\tmddev->pers = pers;\n\tspin_unlock(&mddev->lock);\n\trdev_for_each(rdev, mddev)\n\t\tif (rdev->raid_disk >= 0)\n\t\t\tsysfs_link_rdev(mddev, rdev); /* failure here is OK */\n\n\tif (mddev->degraded && !mddev->ro)\n\t\t/* This ensures that recovering status is reported immediately\n\t\t * via sysfs - until a lack of spares is confirmed.\n\t\t */\n\t\tset_bit(MD_RECOVERY_RECOVER, &mddev->recovery);\n\tset_bit(MD_RECOVERY_NEEDED, &mddev->recovery);\n\n\tif (mddev->sb_flags)\n\t\tmd_update_sb(mddev, 0);\n\n\tmd_new_event(mddev);\n\treturn 0;\n\nbitmap_abort:\n\tmddev_detach(mddev);\n\tif (mddev->private)\n\t\tpers->free(mddev, mddev->private);\n\tmddev->private = NULL;\n\tmodule_put(pers->owner);\n\tmd_bitmap_destroy(mddev);\nabort:\n\tbioset_exit(&mddev->bio_set);\n\tbioset_exit(&mddev->sync_set);\n\treturn err;\n}\nEXPORT_SYMBOL_GPL(md_run);\n\nint do_md_run(struct mddev *mddev)\n{\n\tint err;\n\n\tset_bit(MD_NOT_READY, &mddev->flags);\n\terr = md_run(mddev);\n\tif (err)\n\t\tgoto out;\n\terr = md_bitmap_load(mddev);\n\tif (err) {\n\t\tmd_bitmap_destroy(mddev);\n\t\tgoto out;\n\t}\n\n\tif (mddev_is_clustered(mddev))\n\t\tmd_allow_write(mddev);\n\n\t/* run start up tasks that require md_thread */\n\tmd_start(mddev);\n\n\tmd_wakeup_thread(mddev->thread);\n\tmd_wakeup_thread(mddev->sync_thread); /* possibly kick off a reshape */\n\n\tset_capacity_and_notify(mddev->gendisk, mddev->array_sectors);\n\tclear_bit(MD_NOT_READY, &mddev->flags);\n\tmddev->changed = 1;\n\tkobject_uevent(&disk_to_dev(mddev->gendisk)->kobj, KOBJ_CHANGE);\n\tsysfs_notify_dirent_safe(mddev->sysfs_state);\n\tsysfs_notify_dirent_safe(mddev->sysfs_action);\n\tsysfs_notify_dirent_safe(mddev->sysfs_degraded);\nout:\n\tclear_bit(MD_NOT_READY, &mddev->flags);\n\treturn err;\n}\n\nint md_start(struct mddev *mddev)\n{\n\tint ret = 0;\n\n\tif (mddev->pers->start) {\n\t\tset_bit(MD_RECOVERY_WAIT, &mddev->recovery);\n\t\tmd_wakeup_thread(mddev->thread);\n\t\tret = mddev->pers->start(mddev);\n\t\tclear_bit(MD_RECOVERY_WAIT, &mddev->recovery);\n\t\tmd_wakeup_thread(mddev->sync_thread);\n\t}\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(md_start);\n\nstatic int restart_array(struct mddev *mddev)\n{\n\tstruct gendisk *disk = mddev->gendisk;\n\tstruct md_rdev *rdev;\n\tbool has_journal = false;\n\tbool has_readonly = false;\n\n\t/* Complain if it has no devices */\n\tif (list_empty(&mddev->disks))\n\t\treturn -ENXIO;\n\tif (!mddev->pers)\n\t\treturn -EINVAL;\n\tif (!mddev->ro)\n\t\treturn -EBUSY;\n\n\trcu_read_lock();\n\trdev_for_each_rcu(rdev, mddev) {\n\t\tif (test_bit(Journal, &rdev->flags) &&\n\t\t    !test_bit(Faulty, &rdev->flags))\n\t\t\thas_journal = true;\n\t\tif (bdev_read_only(rdev->bdev))\n\t\t\thas_readonly = true;\n\t}\n\trcu_read_unlock();\n\tif (test_bit(MD_HAS_JOURNAL, &mddev->flags) && !has_journal)\n\t\t/* Don't restart rw with journal missing/faulty */\n\t\t\treturn -EINVAL;\n\tif (has_readonly)\n\t\treturn -EROFS;\n\n\tmddev->safemode = 0;\n\tmddev->ro = 0;\n\tset_disk_ro(disk, 0);\n\tpr_debug(\"md: %s switched to read-write mode.\\n\", mdname(mddev));\n\t/* Kick recovery or resync if necessary */\n\tset_bit(MD_RECOVERY_NEEDED, &mddev->recovery);\n\tmd_wakeup_thread(mddev->thread);\n\tmd_wakeup_thread(mddev->sync_thread);\n\tsysfs_notify_dirent_safe(mddev->sysfs_state);\n\treturn 0;\n}\n\nstatic void md_clean(struct mddev *mddev)\n{\n\tmddev->array_sectors = 0;\n\tmddev->external_size = 0;\n\tmddev->dev_sectors = 0;\n\tmddev->raid_disks = 0;\n\tmddev->recovery_cp = 0;\n\tmddev->resync_min = 0;\n\tmddev->resync_max = MaxSector;\n\tmddev->reshape_position = MaxSector;\n\tmddev->external = 0;\n\tmddev->persistent = 0;\n\tmddev->level = LEVEL_NONE;\n\tmddev->clevel[0] = 0;\n\tmddev->flags = 0;\n\tmddev->sb_flags = 0;\n\tmddev->ro = 0;\n\tmddev->metadata_type[0] = 0;\n\tmddev->chunk_sectors = 0;\n\tmddev->ctime = mddev->utime = 0;\n\tmddev->layout = 0;\n\tmddev->max_disks = 0;\n\tmddev->events = 0;\n\tmddev->can_decrease_events = 0;\n\tmddev->delta_disks = 0;\n\tmddev->reshape_backwards = 0;\n\tmddev->new_level = LEVEL_NONE;\n\tmddev->new_layout = 0;\n\tmddev->new_chunk_sectors = 0;\n\tmddev->curr_resync = 0;\n\tatomic64_set(&mddev->resync_mismatches, 0);\n\tmddev->suspend_lo = mddev->suspend_hi = 0;\n\tmddev->sync_speed_min = mddev->sync_speed_max = 0;\n\tmddev->recovery = 0;\n\tmddev->in_sync = 0;\n\tmddev->changed = 0;\n\tmddev->degraded = 0;\n\tmddev->safemode = 0;\n\tmddev->private = NULL;\n\tmddev->cluster_info = NULL;\n\tmddev->bitmap_info.offset = 0;\n\tmddev->bitmap_info.default_offset = 0;\n\tmddev->bitmap_info.default_space = 0;\n\tmddev->bitmap_info.chunksize = 0;\n\tmddev->bitmap_info.daemon_sleep = 0;\n\tmddev->bitmap_info.max_write_behind = 0;\n\tmddev->bitmap_info.nodes = 0;\n}\n\nstatic void __md_stop_writes(struct mddev *mddev)\n{\n\tset_bit(MD_RECOVERY_FROZEN, &mddev->recovery);\n\tif (work_pending(&mddev->del_work))\n\t\tflush_workqueue(md_misc_wq);\n\tif (mddev->sync_thread) {\n\t\tset_bit(MD_RECOVERY_INTR, &mddev->recovery);\n\t\tmd_reap_sync_thread(mddev);\n\t}\n\n\tdel_timer_sync(&mddev->safemode_timer);\n\n\tif (mddev->pers && mddev->pers->quiesce) {\n\t\tmddev->pers->quiesce(mddev, 1);\n\t\tmddev->pers->quiesce(mddev, 0);\n\t}\n\tmd_bitmap_flush(mddev);\n\n\tif (mddev->ro == 0 &&\n\t    ((!mddev->in_sync && !mddev_is_clustered(mddev)) ||\n\t     mddev->sb_flags)) {\n\t\t/* mark array as shutdown cleanly */\n\t\tif (!mddev_is_clustered(mddev))\n\t\t\tmddev->in_sync = 1;\n\t\tmd_update_sb(mddev, 1);\n\t}\n\t/* disable policy to guarantee rdevs free resources for serialization */\n\tmddev->serialize_policy = 0;\n\tmddev_destroy_serial_pool(mddev, NULL, true);\n}\n\nvoid md_stop_writes(struct mddev *mddev)\n{\n\tmddev_lock_nointr(mddev);\n\t__md_stop_writes(mddev);\n\tmddev_unlock(mddev);\n}\nEXPORT_SYMBOL_GPL(md_stop_writes);\n\nstatic void mddev_detach(struct mddev *mddev)\n{\n\tmd_bitmap_wait_behind_writes(mddev);\n\tif (mddev->pers && mddev->pers->quiesce && !mddev->suspended) {\n\t\tmddev->pers->quiesce(mddev, 1);\n\t\tmddev->pers->quiesce(mddev, 0);\n\t}\n\tmd_unregister_thread(&mddev->thread);\n\tif (mddev->queue)\n\t\tblk_sync_queue(mddev->queue); /* the unplug fn references 'conf'*/\n}\n\nstatic void __md_stop(struct mddev *mddev)\n{\n\tstruct md_personality *pers = mddev->pers;\n\tmd_bitmap_destroy(mddev);\n\tmddev_detach(mddev);\n\t/* Ensure ->event_work is done */\n\tif (mddev->event_work.func)\n\t\tflush_workqueue(md_misc_wq);\n\tspin_lock(&mddev->lock);\n\tmddev->pers = NULL;\n\tspin_unlock(&mddev->lock);\n\tpers->free(mddev, mddev->private);\n\tmddev->private = NULL;\n\tif (pers->sync_request && mddev->to_remove == NULL)\n\t\tmddev->to_remove = &md_redundancy_group;\n\tmodule_put(pers->owner);\n\tclear_bit(MD_RECOVERY_FROZEN, &mddev->recovery);\n}\n\nvoid md_stop(struct mddev *mddev)\n{\n\t/* stop the array and free an attached data structures.\n\t * This is called from dm-raid\n\t */\n\t__md_stop(mddev);\n\tbioset_exit(&mddev->bio_set);\n\tbioset_exit(&mddev->sync_set);\n}\n\nEXPORT_SYMBOL_GPL(md_stop);\n\nstatic int md_set_readonly(struct mddev *mddev, struct block_device *bdev)\n{\n\tint err = 0;\n\tint did_freeze = 0;\n\n\tif (!test_bit(MD_RECOVERY_FROZEN, &mddev->recovery)) {\n\t\tdid_freeze = 1;\n\t\tset_bit(MD_RECOVERY_FROZEN, &mddev->recovery);\n\t\tmd_wakeup_thread(mddev->thread);\n\t}\n\tif (test_bit(MD_RECOVERY_RUNNING, &mddev->recovery))\n\t\tset_bit(MD_RECOVERY_INTR, &mddev->recovery);\n\tif (mddev->sync_thread)\n\t\t/* Thread might be blocked waiting for metadata update\n\t\t * which will now never happen */\n\t\twake_up_process(mddev->sync_thread->tsk);\n\n\tif (mddev->external && test_bit(MD_SB_CHANGE_PENDING, &mddev->sb_flags))\n\t\treturn -EBUSY;\n\tmddev_unlock(mddev);\n\twait_event(resync_wait, !test_bit(MD_RECOVERY_RUNNING,\n\t\t\t\t\t  &mddev->recovery));\n\twait_event(mddev->sb_wait,\n\t\t   !test_bit(MD_SB_CHANGE_PENDING, &mddev->sb_flags));\n\tmddev_lock_nointr(mddev);\n\n\tmutex_lock(&mddev->open_mutex);\n\tif ((mddev->pers && atomic_read(&mddev->openers) > !!bdev) ||\n\t    mddev->sync_thread ||\n\t    test_bit(MD_RECOVERY_RUNNING, &mddev->recovery)) {\n\t\tpr_warn(\"md: %s still in use.\\n\",mdname(mddev));\n\t\tif (did_freeze) {\n\t\t\tclear_bit(MD_RECOVERY_FROZEN, &mddev->recovery);\n\t\t\tset_bit(MD_RECOVERY_NEEDED, &mddev->recovery);\n\t\t\tmd_wakeup_thread(mddev->thread);\n\t\t}\n\t\terr = -EBUSY;\n\t\tgoto out;\n\t}\n\tif (mddev->pers) {\n\t\t__md_stop_writes(mddev);\n\n\t\terr  = -ENXIO;\n\t\tif (mddev->ro==1)\n\t\t\tgoto out;\n\t\tmddev->ro = 1;\n\t\tset_disk_ro(mddev->gendisk, 1);\n\t\tclear_bit(MD_RECOVERY_FROZEN, &mddev->recovery);\n\t\tset_bit(MD_RECOVERY_NEEDED, &mddev->recovery);\n\t\tmd_wakeup_thread(mddev->thread);\n\t\tsysfs_notify_dirent_safe(mddev->sysfs_state);\n\t\terr = 0;\n\t}\nout:\n\tmutex_unlock(&mddev->open_mutex);\n\treturn err;\n}\n\n/* mode:\n *   0 - completely stop and dis-assemble array\n *   2 - stop but do not disassemble array\n */\nstatic int do_md_stop(struct mddev *mddev, int mode,\n\t\t      struct block_device *bdev)\n{\n\tstruct gendisk *disk = mddev->gendisk;\n\tstruct md_rdev *rdev;\n\tint did_freeze = 0;\n\n\tif (!test_bit(MD_RECOVERY_FROZEN, &mddev->recovery)) {\n\t\tdid_freeze = 1;\n\t\tset_bit(MD_RECOVERY_FROZEN, &mddev->recovery);\n\t\tmd_wakeup_thread(mddev->thread);\n\t}\n\tif (test_bit(MD_RECOVERY_RUNNING, &mddev->recovery))\n\t\tset_bit(MD_RECOVERY_INTR, &mddev->recovery);\n\tif (mddev->sync_thread)\n\t\t/* Thread might be blocked waiting for metadata update\n\t\t * which will now never happen */\n\t\twake_up_process(mddev->sync_thread->tsk);\n\n\tmddev_unlock(mddev);\n\twait_event(resync_wait, (mddev->sync_thread == NULL &&\n\t\t\t\t !test_bit(MD_RECOVERY_RUNNING,\n\t\t\t\t\t   &mddev->recovery)));\n\tmddev_lock_nointr(mddev);\n\n\tmutex_lock(&mddev->open_mutex);\n\tif ((mddev->pers && atomic_read(&mddev->openers) > !!bdev) ||\n\t    mddev->sysfs_active ||\n\t    mddev->sync_thread ||\n\t    test_bit(MD_RECOVERY_RUNNING, &mddev->recovery)) {\n\t\tpr_warn(\"md: %s still in use.\\n\",mdname(mddev));\n\t\tmutex_unlock(&mddev->open_mutex);\n\t\tif (did_freeze) {\n\t\t\tclear_bit(MD_RECOVERY_FROZEN, &mddev->recovery);\n\t\t\tset_bit(MD_RECOVERY_NEEDED, &mddev->recovery);\n\t\t\tmd_wakeup_thread(mddev->thread);\n\t\t}\n\t\treturn -EBUSY;\n\t}\n\tif (mddev->pers) {\n\t\tif (mddev->ro)\n\t\t\tset_disk_ro(disk, 0);\n\n\t\t__md_stop_writes(mddev);\n\t\t__md_stop(mddev);\n\n\t\t/* tell userspace to handle 'inactive' */\n\t\tsysfs_notify_dirent_safe(mddev->sysfs_state);\n\n\t\trdev_for_each(rdev, mddev)\n\t\t\tif (rdev->raid_disk >= 0)\n\t\t\t\tsysfs_unlink_rdev(mddev, rdev);\n\n\t\tset_capacity_and_notify(disk, 0);\n\t\tmutex_unlock(&mddev->open_mutex);\n\t\tmddev->changed = 1;\n\n\t\tif (mddev->ro)\n\t\t\tmddev->ro = 0;\n\t} else\n\t\tmutex_unlock(&mddev->open_mutex);\n\t/*\n\t * Free resources if final stop\n\t */\n\tif (mode == 0) {\n\t\tpr_info(\"md: %s stopped.\\n\", mdname(mddev));\n\n\t\tif (mddev->bitmap_info.file) {\n\t\t\tstruct file *f = mddev->bitmap_info.file;\n\t\t\tspin_lock(&mddev->lock);\n\t\t\tmddev->bitmap_info.file = NULL;\n\t\t\tspin_unlock(&mddev->lock);\n\t\t\tfput(f);\n\t\t}\n\t\tmddev->bitmap_info.offset = 0;\n\n\t\texport_array(mddev);\n\n\t\tmd_clean(mddev);\n\t\tif (mddev->hold_active == UNTIL_STOP)\n\t\t\tmddev->hold_active = 0;\n\t}\n\tmd_new_event(mddev);\n\tsysfs_notify_dirent_safe(mddev->sysfs_state);\n\treturn 0;\n}\n\n#ifndef MODULE\nstatic void autorun_array(struct mddev *mddev)\n{\n\tstruct md_rdev *rdev;\n\tint err;\n\n\tif (list_empty(&mddev->disks))\n\t\treturn;\n\n\tpr_info(\"md: running: \");\n\n\trdev_for_each(rdev, mddev) {\n\t\tchar b[BDEVNAME_SIZE];\n\t\tpr_cont(\"<%s>\", bdevname(rdev->bdev,b));\n\t}\n\tpr_cont(\"\\n\");\n\n\terr = do_md_run(mddev);\n\tif (err) {\n\t\tpr_warn(\"md: do_md_run() returned %d\\n\", err);\n\t\tdo_md_stop(mddev, 0, NULL);\n\t}\n}\n\n/*\n * lets try to run arrays based on all disks that have arrived\n * until now. (those are in pending_raid_disks)\n *\n * the method: pick the first pending disk, collect all disks with\n * the same UUID, remove all from the pending list and put them into\n * the 'same_array' list. Then order this list based on superblock\n * update time (freshest comes first), kick out 'old' disks and\n * compare superblocks. If everything's fine then run it.\n *\n * If \"unit\" is allocated, then bump its reference count\n */\nstatic void autorun_devices(int part)\n{\n\tstruct md_rdev *rdev0, *rdev, *tmp;\n\tstruct mddev *mddev;\n\tchar b[BDEVNAME_SIZE];\n\n\tpr_info(\"md: autorun ...\\n\");\n\twhile (!list_empty(&pending_raid_disks)) {\n\t\tint unit;\n\t\tdev_t dev;\n\t\tLIST_HEAD(candidates);\n\t\trdev0 = list_entry(pending_raid_disks.next,\n\t\t\t\t\t struct md_rdev, same_set);\n\n\t\tpr_debug(\"md: considering %s ...\\n\", bdevname(rdev0->bdev,b));\n\t\tINIT_LIST_HEAD(&candidates);\n\t\trdev_for_each_list(rdev, tmp, &pending_raid_disks)\n\t\t\tif (super_90_load(rdev, rdev0, 0) >= 0) {\n\t\t\t\tpr_debug(\"md:  adding %s ...\\n\",\n\t\t\t\t\t bdevname(rdev->bdev,b));\n\t\t\t\tlist_move(&rdev->same_set, &candidates);\n\t\t\t}\n\t\t/*\n\t\t * now we have a set of devices, with all of them having\n\t\t * mostly sane superblocks. It's time to allocate the\n\t\t * mddev.\n\t\t */\n\t\tif (part) {\n\t\t\tdev = MKDEV(mdp_major,\n\t\t\t\t    rdev0->preferred_minor << MdpMinorShift);\n\t\t\tunit = MINOR(dev) >> MdpMinorShift;\n\t\t} else {\n\t\t\tdev = MKDEV(MD_MAJOR, rdev0->preferred_minor);\n\t\t\tunit = MINOR(dev);\n\t\t}\n\t\tif (rdev0->preferred_minor != unit) {\n\t\t\tpr_warn(\"md: unit number in %s is bad: %d\\n\",\n\t\t\t\tbdevname(rdev0->bdev, b), rdev0->preferred_minor);\n\t\t\tbreak;\n\t\t}\n\n\t\tmd_probe(dev);\n\t\tmddev = mddev_find(dev);\n\t\tif (!mddev || !mddev->gendisk) {\n\t\t\tif (mddev)\n\t\t\t\tmddev_put(mddev);\n\t\t\tbreak;\n\t\t}\n\t\tif (mddev_lock(mddev))\n\t\t\tpr_warn(\"md: %s locked, cannot run\\n\", mdname(mddev));\n\t\telse if (mddev->raid_disks || mddev->major_version\n\t\t\t || !list_empty(&mddev->disks)) {\n\t\t\tpr_warn(\"md: %s already running, cannot run %s\\n\",\n\t\t\t\tmdname(mddev), bdevname(rdev0->bdev,b));\n\t\t\tmddev_unlock(mddev);\n\t\t} else {\n\t\t\tpr_debug(\"md: created %s\\n\", mdname(mddev));\n\t\t\tmddev->persistent = 1;\n\t\t\trdev_for_each_list(rdev, tmp, &candidates) {\n\t\t\t\tlist_del_init(&rdev->same_set);\n\t\t\t\tif (bind_rdev_to_array(rdev, mddev))\n\t\t\t\t\texport_rdev(rdev);\n\t\t\t}\n\t\t\tautorun_array(mddev);\n\t\t\tmddev_unlock(mddev);\n\t\t}\n\t\t/* on success, candidates will be empty, on error\n\t\t * it won't...\n\t\t */\n\t\trdev_for_each_list(rdev, tmp, &candidates) {\n\t\t\tlist_del_init(&rdev->same_set);\n\t\t\texport_rdev(rdev);\n\t\t}\n\t\tmddev_put(mddev);\n\t}\n\tpr_info(\"md: ... autorun DONE.\\n\");\n}\n#endif /* !MODULE */\n\nstatic int get_version(void __user *arg)\n{\n\tmdu_version_t ver;\n\n\tver.major = MD_MAJOR_VERSION;\n\tver.minor = MD_MINOR_VERSION;\n\tver.patchlevel = MD_PATCHLEVEL_VERSION;\n\n\tif (copy_to_user(arg, &ver, sizeof(ver)))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}\n\nstatic int get_array_info(struct mddev *mddev, void __user *arg)\n{\n\tmdu_array_info_t info;\n\tint nr,working,insync,failed,spare;\n\tstruct md_rdev *rdev;\n\n\tnr = working = insync = failed = spare = 0;\n\trcu_read_lock();\n\trdev_for_each_rcu(rdev, mddev) {\n\t\tnr++;\n\t\tif (test_bit(Faulty, &rdev->flags))\n\t\t\tfailed++;\n\t\telse {\n\t\t\tworking++;\n\t\t\tif (test_bit(In_sync, &rdev->flags))\n\t\t\t\tinsync++;\n\t\t\telse if (test_bit(Journal, &rdev->flags))\n\t\t\t\t/* TODO: add journal count to md_u.h */\n\t\t\t\t;\n\t\t\telse\n\t\t\t\tspare++;\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\tinfo.major_version = mddev->major_version;\n\tinfo.minor_version = mddev->minor_version;\n\tinfo.patch_version = MD_PATCHLEVEL_VERSION;\n\tinfo.ctime         = clamp_t(time64_t, mddev->ctime, 0, U32_MAX);\n\tinfo.level         = mddev->level;\n\tinfo.size          = mddev->dev_sectors / 2;\n\tif (info.size != mddev->dev_sectors / 2) /* overflow */\n\t\tinfo.size = -1;\n\tinfo.nr_disks      = nr;\n\tinfo.raid_disks    = mddev->raid_disks;\n\tinfo.md_minor      = mddev->md_minor;\n\tinfo.not_persistent= !mddev->persistent;\n\n\tinfo.utime         = clamp_t(time64_t, mddev->utime, 0, U32_MAX);\n\tinfo.state         = 0;\n\tif (mddev->in_sync)\n\t\tinfo.state = (1<<MD_SB_CLEAN);\n\tif (mddev->bitmap && mddev->bitmap_info.offset)\n\t\tinfo.state |= (1<<MD_SB_BITMAP_PRESENT);\n\tif (mddev_is_clustered(mddev))\n\t\tinfo.state |= (1<<MD_SB_CLUSTERED);\n\tinfo.active_disks  = insync;\n\tinfo.working_disks = working;\n\tinfo.failed_disks  = failed;\n\tinfo.spare_disks   = spare;\n\n\tinfo.layout        = mddev->layout;\n\tinfo.chunk_size    = mddev->chunk_sectors << 9;\n\n\tif (copy_to_user(arg, &info, sizeof(info)))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}\n\nstatic int get_bitmap_file(struct mddev *mddev, void __user * arg)\n{\n\tmdu_bitmap_file_t *file = NULL; /* too big for stack allocation */\n\tchar *ptr;\n\tint err;\n\n\tfile = kzalloc(sizeof(*file), GFP_NOIO);\n\tif (!file)\n\t\treturn -ENOMEM;\n\n\terr = 0;\n\tspin_lock(&mddev->lock);\n\t/* bitmap enabled */\n\tif (mddev->bitmap_info.file) {\n\t\tptr = file_path(mddev->bitmap_info.file, file->pathname,\n\t\t\t\tsizeof(file->pathname));\n\t\tif (IS_ERR(ptr))\n\t\t\terr = PTR_ERR(ptr);\n\t\telse\n\t\t\tmemmove(file->pathname, ptr,\n\t\t\t\tsizeof(file->pathname)-(ptr-file->pathname));\n\t}\n\tspin_unlock(&mddev->lock);\n\n\tif (err == 0 &&\n\t    copy_to_user(arg, file, sizeof(*file)))\n\t\terr = -EFAULT;\n\n\tkfree(file);\n\treturn err;\n}\n\nstatic int get_disk_info(struct mddev *mddev, void __user * arg)\n{\n\tmdu_disk_info_t info;\n\tstruct md_rdev *rdev;\n\n\tif (copy_from_user(&info, arg, sizeof(info)))\n\t\treturn -EFAULT;\n\n\trcu_read_lock();\n\trdev = md_find_rdev_nr_rcu(mddev, info.number);\n\tif (rdev) {\n\t\tinfo.major = MAJOR(rdev->bdev->bd_dev);\n\t\tinfo.minor = MINOR(rdev->bdev->bd_dev);\n\t\tinfo.raid_disk = rdev->raid_disk;\n\t\tinfo.state = 0;\n\t\tif (test_bit(Faulty, &rdev->flags))\n\t\t\tinfo.state |= (1<<MD_DISK_FAULTY);\n\t\telse if (test_bit(In_sync, &rdev->flags)) {\n\t\t\tinfo.state |= (1<<MD_DISK_ACTIVE);\n\t\t\tinfo.state |= (1<<MD_DISK_SYNC);\n\t\t}\n\t\tif (test_bit(Journal, &rdev->flags))\n\t\t\tinfo.state |= (1<<MD_DISK_JOURNAL);\n\t\tif (test_bit(WriteMostly, &rdev->flags))\n\t\t\tinfo.state |= (1<<MD_DISK_WRITEMOSTLY);\n\t\tif (test_bit(FailFast, &rdev->flags))\n\t\t\tinfo.state |= (1<<MD_DISK_FAILFAST);\n\t} else {\n\t\tinfo.major = info.minor = 0;\n\t\tinfo.raid_disk = -1;\n\t\tinfo.state = (1<<MD_DISK_REMOVED);\n\t}\n\trcu_read_unlock();\n\n\tif (copy_to_user(arg, &info, sizeof(info)))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}\n\nint md_add_new_disk(struct mddev *mddev, struct mdu_disk_info_s *info)\n{\n\tchar b[BDEVNAME_SIZE], b2[BDEVNAME_SIZE];\n\tstruct md_rdev *rdev;\n\tdev_t dev = MKDEV(info->major,info->minor);\n\n\tif (mddev_is_clustered(mddev) &&\n\t\t!(info->state & ((1 << MD_DISK_CLUSTER_ADD) | (1 << MD_DISK_CANDIDATE)))) {\n\t\tpr_warn(\"%s: Cannot add to clustered mddev.\\n\",\n\t\t\tmdname(mddev));\n\t\treturn -EINVAL;\n\t}\n\n\tif (info->major != MAJOR(dev) || info->minor != MINOR(dev))\n\t\treturn -EOVERFLOW;\n\n\tif (!mddev->raid_disks) {\n\t\tint err;\n\t\t/* expecting a device which has a superblock */\n\t\trdev = md_import_device(dev, mddev->major_version, mddev->minor_version);\n\t\tif (IS_ERR(rdev)) {\n\t\t\tpr_warn(\"md: md_import_device returned %ld\\n\",\n\t\t\t\tPTR_ERR(rdev));\n\t\t\treturn PTR_ERR(rdev);\n\t\t}\n\t\tif (!list_empty(&mddev->disks)) {\n\t\t\tstruct md_rdev *rdev0\n\t\t\t\t= list_entry(mddev->disks.next,\n\t\t\t\t\t     struct md_rdev, same_set);\n\t\t\terr = super_types[mddev->major_version]\n\t\t\t\t.load_super(rdev, rdev0, mddev->minor_version);\n\t\t\tif (err < 0) {\n\t\t\t\tpr_warn(\"md: %s has different UUID to %s\\n\",\n\t\t\t\t\tbdevname(rdev->bdev,b),\n\t\t\t\t\tbdevname(rdev0->bdev,b2));\n\t\t\t\texport_rdev(rdev);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\t\terr = bind_rdev_to_array(rdev, mddev);\n\t\tif (err)\n\t\t\texport_rdev(rdev);\n\t\treturn err;\n\t}\n\n\t/*\n\t * md_add_new_disk can be used once the array is assembled\n\t * to add \"hot spares\".  They must already have a superblock\n\t * written\n\t */\n\tif (mddev->pers) {\n\t\tint err;\n\t\tif (!mddev->pers->hot_add_disk) {\n\t\t\tpr_warn(\"%s: personality does not support diskops!\\n\",\n\t\t\t\tmdname(mddev));\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (mddev->persistent)\n\t\t\trdev = md_import_device(dev, mddev->major_version,\n\t\t\t\t\t\tmddev->minor_version);\n\t\telse\n\t\t\trdev = md_import_device(dev, -1, -1);\n\t\tif (IS_ERR(rdev)) {\n\t\t\tpr_warn(\"md: md_import_device returned %ld\\n\",\n\t\t\t\tPTR_ERR(rdev));\n\t\t\treturn PTR_ERR(rdev);\n\t\t}\n\t\t/* set saved_raid_disk if appropriate */\n\t\tif (!mddev->persistent) {\n\t\t\tif (info->state & (1<<MD_DISK_SYNC)  &&\n\t\t\t    info->raid_disk < mddev->raid_disks) {\n\t\t\t\trdev->raid_disk = info->raid_disk;\n\t\t\t\tset_bit(In_sync, &rdev->flags);\n\t\t\t\tclear_bit(Bitmap_sync, &rdev->flags);\n\t\t\t} else\n\t\t\t\trdev->raid_disk = -1;\n\t\t\trdev->saved_raid_disk = rdev->raid_disk;\n\t\t} else\n\t\t\tsuper_types[mddev->major_version].\n\t\t\t\tvalidate_super(mddev, rdev);\n\t\tif ((info->state & (1<<MD_DISK_SYNC)) &&\n\t\t     rdev->raid_disk != info->raid_disk) {\n\t\t\t/* This was a hot-add request, but events doesn't\n\t\t\t * match, so reject it.\n\t\t\t */\n\t\t\texport_rdev(rdev);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tclear_bit(In_sync, &rdev->flags); /* just to be sure */\n\t\tif (info->state & (1<<MD_DISK_WRITEMOSTLY))\n\t\t\tset_bit(WriteMostly, &rdev->flags);\n\t\telse\n\t\t\tclear_bit(WriteMostly, &rdev->flags);\n\t\tif (info->state & (1<<MD_DISK_FAILFAST))\n\t\t\tset_bit(FailFast, &rdev->flags);\n\t\telse\n\t\t\tclear_bit(FailFast, &rdev->flags);\n\n\t\tif (info->state & (1<<MD_DISK_JOURNAL)) {\n\t\t\tstruct md_rdev *rdev2;\n\t\t\tbool has_journal = false;\n\n\t\t\t/* make sure no existing journal disk */\n\t\t\trdev_for_each(rdev2, mddev) {\n\t\t\t\tif (test_bit(Journal, &rdev2->flags)) {\n\t\t\t\t\thas_journal = true;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (has_journal || mddev->bitmap) {\n\t\t\t\texport_rdev(rdev);\n\t\t\t\treturn -EBUSY;\n\t\t\t}\n\t\t\tset_bit(Journal, &rdev->flags);\n\t\t}\n\t\t/*\n\t\t * check whether the device shows up in other nodes\n\t\t */\n\t\tif (mddev_is_clustered(mddev)) {\n\t\t\tif (info->state & (1 << MD_DISK_CANDIDATE))\n\t\t\t\tset_bit(Candidate, &rdev->flags);\n\t\t\telse if (info->state & (1 << MD_DISK_CLUSTER_ADD)) {\n\t\t\t\t/* --add initiated by this node */\n\t\t\t\terr = md_cluster_ops->add_new_disk(mddev, rdev);\n\t\t\t\tif (err) {\n\t\t\t\t\texport_rdev(rdev);\n\t\t\t\t\treturn err;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\trdev->raid_disk = -1;\n\t\terr = bind_rdev_to_array(rdev, mddev);\n\n\t\tif (err)\n\t\t\texport_rdev(rdev);\n\n\t\tif (mddev_is_clustered(mddev)) {\n\t\t\tif (info->state & (1 << MD_DISK_CANDIDATE)) {\n\t\t\t\tif (!err) {\n\t\t\t\t\terr = md_cluster_ops->new_disk_ack(mddev,\n\t\t\t\t\t\terr == 0);\n\t\t\t\t\tif (err)\n\t\t\t\t\t\tmd_kick_rdev_from_array(rdev);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (err)\n\t\t\t\t\tmd_cluster_ops->add_new_disk_cancel(mddev);\n\t\t\t\telse\n\t\t\t\t\terr = add_bound_rdev(rdev);\n\t\t\t}\n\n\t\t} else if (!err)\n\t\t\terr = add_bound_rdev(rdev);\n\n\t\treturn err;\n\t}\n\n\t/* otherwise, md_add_new_disk is only allowed\n\t * for major_version==0 superblocks\n\t */\n\tif (mddev->major_version != 0) {\n\t\tpr_warn(\"%s: ADD_NEW_DISK not supported\\n\", mdname(mddev));\n\t\treturn -EINVAL;\n\t}\n\n\tif (!(info->state & (1<<MD_DISK_FAULTY))) {\n\t\tint err;\n\t\trdev = md_import_device(dev, -1, 0);\n\t\tif (IS_ERR(rdev)) {\n\t\t\tpr_warn(\"md: error, md_import_device() returned %ld\\n\",\n\t\t\t\tPTR_ERR(rdev));\n\t\t\treturn PTR_ERR(rdev);\n\t\t}\n\t\trdev->desc_nr = info->number;\n\t\tif (info->raid_disk < mddev->raid_disks)\n\t\t\trdev->raid_disk = info->raid_disk;\n\t\telse\n\t\t\trdev->raid_disk = -1;\n\n\t\tif (rdev->raid_disk < mddev->raid_disks)\n\t\t\tif (info->state & (1<<MD_DISK_SYNC))\n\t\t\t\tset_bit(In_sync, &rdev->flags);\n\n\t\tif (info->state & (1<<MD_DISK_WRITEMOSTLY))\n\t\t\tset_bit(WriteMostly, &rdev->flags);\n\t\tif (info->state & (1<<MD_DISK_FAILFAST))\n\t\t\tset_bit(FailFast, &rdev->flags);\n\n\t\tif (!mddev->persistent) {\n\t\t\tpr_debug(\"md: nonpersistent superblock ...\\n\");\n\t\t\trdev->sb_start = i_size_read(rdev->bdev->bd_inode) / 512;\n\t\t} else\n\t\t\trdev->sb_start = calc_dev_sboffset(rdev);\n\t\trdev->sectors = rdev->sb_start;\n\n\t\terr = bind_rdev_to_array(rdev, mddev);\n\t\tif (err) {\n\t\t\texport_rdev(rdev);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int hot_remove_disk(struct mddev *mddev, dev_t dev)\n{\n\tchar b[BDEVNAME_SIZE];\n\tstruct md_rdev *rdev;\n\n\tif (!mddev->pers)\n\t\treturn -ENODEV;\n\n\trdev = find_rdev(mddev, dev);\n\tif (!rdev)\n\t\treturn -ENXIO;\n\n\tif (rdev->raid_disk < 0)\n\t\tgoto kick_rdev;\n\n\tclear_bit(Blocked, &rdev->flags);\n\tremove_and_add_spares(mddev, rdev);\n\n\tif (rdev->raid_disk >= 0)\n\t\tgoto busy;\n\nkick_rdev:\n\tif (mddev_is_clustered(mddev))\n\t\tmd_cluster_ops->remove_disk(mddev, rdev);\n\n\tmd_kick_rdev_from_array(rdev);\n\tset_bit(MD_SB_CHANGE_DEVS, &mddev->sb_flags);\n\tif (mddev->thread)\n\t\tmd_wakeup_thread(mddev->thread);\n\telse\n\t\tmd_update_sb(mddev, 1);\n\tmd_new_event(mddev);\n\n\treturn 0;\nbusy:\n\tpr_debug(\"md: cannot remove active disk %s from %s ...\\n\",\n\t\t bdevname(rdev->bdev,b), mdname(mddev));\n\treturn -EBUSY;\n}\n\nstatic int hot_add_disk(struct mddev *mddev, dev_t dev)\n{\n\tchar b[BDEVNAME_SIZE];\n\tint err;\n\tstruct md_rdev *rdev;\n\n\tif (!mddev->pers)\n\t\treturn -ENODEV;\n\n\tif (mddev->major_version != 0) {\n\t\tpr_warn(\"%s: HOT_ADD may only be used with version-0 superblocks.\\n\",\n\t\t\tmdname(mddev));\n\t\treturn -EINVAL;\n\t}\n\tif (!mddev->pers->hot_add_disk) {\n\t\tpr_warn(\"%s: personality does not support diskops!\\n\",\n\t\t\tmdname(mddev));\n\t\treturn -EINVAL;\n\t}\n\n\trdev = md_import_device(dev, -1, 0);\n\tif (IS_ERR(rdev)) {\n\t\tpr_warn(\"md: error, md_import_device() returned %ld\\n\",\n\t\t\tPTR_ERR(rdev));\n\t\treturn -EINVAL;\n\t}\n\n\tif (mddev->persistent)\n\t\trdev->sb_start = calc_dev_sboffset(rdev);\n\telse\n\t\trdev->sb_start = i_size_read(rdev->bdev->bd_inode) / 512;\n\n\trdev->sectors = rdev->sb_start;\n\n\tif (test_bit(Faulty, &rdev->flags)) {\n\t\tpr_warn(\"md: can not hot-add faulty %s disk to %s!\\n\",\n\t\t\tbdevname(rdev->bdev,b), mdname(mddev));\n\t\terr = -EINVAL;\n\t\tgoto abort_export;\n\t}\n\n\tclear_bit(In_sync, &rdev->flags);\n\trdev->desc_nr = -1;\n\trdev->saved_raid_disk = -1;\n\terr = bind_rdev_to_array(rdev, mddev);\n\tif (err)\n\t\tgoto abort_export;\n\n\t/*\n\t * The rest should better be atomic, we can have disk failures\n\t * noticed in interrupt contexts ...\n\t */\n\n\trdev->raid_disk = -1;\n\n\tset_bit(MD_SB_CHANGE_DEVS, &mddev->sb_flags);\n\tif (!mddev->thread)\n\t\tmd_update_sb(mddev, 1);\n\t/*\n\t * Kick recovery, maybe this spare has to be added to the\n\t * array immediately.\n\t */\n\tset_bit(MD_RECOVERY_NEEDED, &mddev->recovery);\n\tmd_wakeup_thread(mddev->thread);\n\tmd_new_event(mddev);\n\treturn 0;\n\nabort_export:\n\texport_rdev(rdev);\n\treturn err;\n}\n\nstatic int set_bitmap_file(struct mddev *mddev, int fd)\n{\n\tint err = 0;\n\n\tif (mddev->pers) {\n\t\tif (!mddev->pers->quiesce || !mddev->thread)\n\t\t\treturn -EBUSY;\n\t\tif (mddev->recovery || mddev->sync_thread)\n\t\t\treturn -EBUSY;\n\t\t/* we should be able to change the bitmap.. */\n\t}\n\n\tif (fd >= 0) {\n\t\tstruct inode *inode;\n\t\tstruct file *f;\n\n\t\tif (mddev->bitmap || mddev->bitmap_info.file)\n\t\t\treturn -EEXIST; /* cannot add when bitmap is present */\n\t\tf = fget(fd);\n\n\t\tif (f == NULL) {\n\t\t\tpr_warn(\"%s: error: failed to get bitmap file\\n\",\n\t\t\t\tmdname(mddev));\n\t\t\treturn -EBADF;\n\t\t}\n\n\t\tinode = f->f_mapping->host;\n\t\tif (!S_ISREG(inode->i_mode)) {\n\t\t\tpr_warn(\"%s: error: bitmap file must be a regular file\\n\",\n\t\t\t\tmdname(mddev));\n\t\t\terr = -EBADF;\n\t\t} else if (!(f->f_mode & FMODE_WRITE)) {\n\t\t\tpr_warn(\"%s: error: bitmap file must open for write\\n\",\n\t\t\t\tmdname(mddev));\n\t\t\terr = -EBADF;\n\t\t} else if (atomic_read(&inode->i_writecount) != 1) {\n\t\t\tpr_warn(\"%s: error: bitmap file is already in use\\n\",\n\t\t\t\tmdname(mddev));\n\t\t\terr = -EBUSY;\n\t\t}\n\t\tif (err) {\n\t\t\tfput(f);\n\t\t\treturn err;\n\t\t}\n\t\tmddev->bitmap_info.file = f;\n\t\tmddev->bitmap_info.offset = 0; /* file overrides offset */\n\t} else if (mddev->bitmap == NULL)\n\t\treturn -ENOENT; /* cannot remove what isn't there */\n\terr = 0;\n\tif (mddev->pers) {\n\t\tif (fd >= 0) {\n\t\t\tstruct bitmap *bitmap;\n\n\t\t\tbitmap = md_bitmap_create(mddev, -1);\n\t\t\tmddev_suspend(mddev);\n\t\t\tif (!IS_ERR(bitmap)) {\n\t\t\t\tmddev->bitmap = bitmap;\n\t\t\t\terr = md_bitmap_load(mddev);\n\t\t\t} else\n\t\t\t\terr = PTR_ERR(bitmap);\n\t\t\tif (err) {\n\t\t\t\tmd_bitmap_destroy(mddev);\n\t\t\t\tfd = -1;\n\t\t\t}\n\t\t\tmddev_resume(mddev);\n\t\t} else if (fd < 0) {\n\t\t\tmddev_suspend(mddev);\n\t\t\tmd_bitmap_destroy(mddev);\n\t\t\tmddev_resume(mddev);\n\t\t}\n\t}\n\tif (fd < 0) {\n\t\tstruct file *f = mddev->bitmap_info.file;\n\t\tif (f) {\n\t\t\tspin_lock(&mddev->lock);\n\t\t\tmddev->bitmap_info.file = NULL;\n\t\t\tspin_unlock(&mddev->lock);\n\t\t\tfput(f);\n\t\t}\n\t}\n\n\treturn err;\n}\n\n/*\n * md_set_array_info is used two different ways\n * The original usage is when creating a new array.\n * In this usage, raid_disks is > 0 and it together with\n *  level, size, not_persistent,layout,chunksize determine the\n *  shape of the array.\n *  This will always create an array with a type-0.90.0 superblock.\n * The newer usage is when assembling an array.\n *  In this case raid_disks will be 0, and the major_version field is\n *  use to determine which style super-blocks are to be found on the devices.\n *  The minor and patch _version numbers are also kept incase the\n *  super_block handler wishes to interpret them.\n */\nint md_set_array_info(struct mddev *mddev, struct mdu_array_info_s *info)\n{\n\tif (info->raid_disks == 0) {\n\t\t/* just setting version number for superblock loading */\n\t\tif (info->major_version < 0 ||\n\t\t    info->major_version >= ARRAY_SIZE(super_types) ||\n\t\t    super_types[info->major_version].name == NULL) {\n\t\t\t/* maybe try to auto-load a module? */\n\t\t\tpr_warn(\"md: superblock version %d not known\\n\",\n\t\t\t\tinfo->major_version);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tmddev->major_version = info->major_version;\n\t\tmddev->minor_version = info->minor_version;\n\t\tmddev->patch_version = info->patch_version;\n\t\tmddev->persistent = !info->not_persistent;\n\t\t/* ensure mddev_put doesn't delete this now that there\n\t\t * is some minimal configuration.\n\t\t */\n\t\tmddev->ctime         = ktime_get_real_seconds();\n\t\treturn 0;\n\t}\n\tmddev->major_version = MD_MAJOR_VERSION;\n\tmddev->minor_version = MD_MINOR_VERSION;\n\tmddev->patch_version = MD_PATCHLEVEL_VERSION;\n\tmddev->ctime         = ktime_get_real_seconds();\n\n\tmddev->level         = info->level;\n\tmddev->clevel[0]     = 0;\n\tmddev->dev_sectors   = 2 * (sector_t)info->size;\n\tmddev->raid_disks    = info->raid_disks;\n\t/* don't set md_minor, it is determined by which /dev/md* was\n\t * openned\n\t */\n\tif (info->state & (1<<MD_SB_CLEAN))\n\t\tmddev->recovery_cp = MaxSector;\n\telse\n\t\tmddev->recovery_cp = 0;\n\tmddev->persistent    = ! info->not_persistent;\n\tmddev->external\t     = 0;\n\n\tmddev->layout        = info->layout;\n\tif (mddev->level == 0)\n\t\t/* Cannot trust RAID0 layout info here */\n\t\tmddev->layout = -1;\n\tmddev->chunk_sectors = info->chunk_size >> 9;\n\n\tif (mddev->persistent) {\n\t\tmddev->max_disks = MD_SB_DISKS;\n\t\tmddev->flags = 0;\n\t\tmddev->sb_flags = 0;\n\t}\n\tset_bit(MD_SB_CHANGE_DEVS, &mddev->sb_flags);\n\n\tmddev->bitmap_info.default_offset = MD_SB_BYTES >> 9;\n\tmddev->bitmap_info.default_space = 64*2 - (MD_SB_BYTES >> 9);\n\tmddev->bitmap_info.offset = 0;\n\n\tmddev->reshape_position = MaxSector;\n\n\t/*\n\t * Generate a 128 bit UUID\n\t */\n\tget_random_bytes(mddev->uuid, 16);\n\n\tmddev->new_level = mddev->level;\n\tmddev->new_chunk_sectors = mddev->chunk_sectors;\n\tmddev->new_layout = mddev->layout;\n\tmddev->delta_disks = 0;\n\tmddev->reshape_backwards = 0;\n\n\treturn 0;\n}\n\nvoid md_set_array_sectors(struct mddev *mddev, sector_t array_sectors)\n{\n\tlockdep_assert_held(&mddev->reconfig_mutex);\n\n\tif (mddev->external_size)\n\t\treturn;\n\n\tmddev->array_sectors = array_sectors;\n}\nEXPORT_SYMBOL(md_set_array_sectors);\n\nstatic int update_size(struct mddev *mddev, sector_t num_sectors)\n{\n\tstruct md_rdev *rdev;\n\tint rv;\n\tint fit = (num_sectors == 0);\n\tsector_t old_dev_sectors = mddev->dev_sectors;\n\n\tif (mddev->pers->resize == NULL)\n\t\treturn -EINVAL;\n\t/* The \"num_sectors\" is the number of sectors of each device that\n\t * is used.  This can only make sense for arrays with redundancy.\n\t * linear and raid0 always use whatever space is available. We can only\n\t * consider changing this number if no resync or reconstruction is\n\t * happening, and if the new size is acceptable. It must fit before the\n\t * sb_start or, if that is <data_offset, it must fit before the size\n\t * of each device.  If num_sectors is zero, we find the largest size\n\t * that fits.\n\t */\n\tif (test_bit(MD_RECOVERY_RUNNING, &mddev->recovery) ||\n\t    mddev->sync_thread)\n\t\treturn -EBUSY;\n\tif (mddev->ro)\n\t\treturn -EROFS;\n\n\trdev_for_each(rdev, mddev) {\n\t\tsector_t avail = rdev->sectors;\n\n\t\tif (fit && (num_sectors == 0 || num_sectors > avail))\n\t\t\tnum_sectors = avail;\n\t\tif (avail < num_sectors)\n\t\t\treturn -ENOSPC;\n\t}\n\trv = mddev->pers->resize(mddev, num_sectors);\n\tif (!rv) {\n\t\tif (mddev_is_clustered(mddev))\n\t\t\tmd_cluster_ops->update_size(mddev, old_dev_sectors);\n\t\telse if (mddev->queue) {\n\t\t\tset_capacity_and_notify(mddev->gendisk,\n\t\t\t\t\t\tmddev->array_sectors);\n\t\t}\n\t}\n\treturn rv;\n}\n\nstatic int update_raid_disks(struct mddev *mddev, int raid_disks)\n{\n\tint rv;\n\tstruct md_rdev *rdev;\n\t/* change the number of raid disks */\n\tif (mddev->pers->check_reshape == NULL)\n\t\treturn -EINVAL;\n\tif (mddev->ro)\n\t\treturn -EROFS;\n\tif (raid_disks <= 0 ||\n\t    (mddev->max_disks && raid_disks >= mddev->max_disks))\n\t\treturn -EINVAL;\n\tif (mddev->sync_thread ||\n\t    test_bit(MD_RECOVERY_RUNNING, &mddev->recovery) ||\n\t    mddev->reshape_position != MaxSector)\n\t\treturn -EBUSY;\n\n\trdev_for_each(rdev, mddev) {\n\t\tif (mddev->raid_disks < raid_disks &&\n\t\t    rdev->data_offset < rdev->new_data_offset)\n\t\t\treturn -EINVAL;\n\t\tif (mddev->raid_disks > raid_disks &&\n\t\t    rdev->data_offset > rdev->new_data_offset)\n\t\t\treturn -EINVAL;\n\t}\n\n\tmddev->delta_disks = raid_disks - mddev->raid_disks;\n\tif (mddev->delta_disks < 0)\n\t\tmddev->reshape_backwards = 1;\n\telse if (mddev->delta_disks > 0)\n\t\tmddev->reshape_backwards = 0;\n\n\trv = mddev->pers->check_reshape(mddev);\n\tif (rv < 0) {\n\t\tmddev->delta_disks = 0;\n\t\tmddev->reshape_backwards = 0;\n\t}\n\treturn rv;\n}\n\n/*\n * update_array_info is used to change the configuration of an\n * on-line array.\n * The version, ctime,level,size,raid_disks,not_persistent, layout,chunk_size\n * fields in the info are checked against the array.\n * Any differences that cannot be handled will cause an error.\n * Normally, only one change can be managed at a time.\n */\nstatic int update_array_info(struct mddev *mddev, mdu_array_info_t *info)\n{\n\tint rv = 0;\n\tint cnt = 0;\n\tint state = 0;\n\n\t/* calculate expected state,ignoring low bits */\n\tif (mddev->bitmap && mddev->bitmap_info.offset)\n\t\tstate |= (1 << MD_SB_BITMAP_PRESENT);\n\n\tif (mddev->major_version != info->major_version ||\n\t    mddev->minor_version != info->minor_version ||\n/*\t    mddev->patch_version != info->patch_version || */\n\t    mddev->ctime         != info->ctime         ||\n\t    mddev->level         != info->level         ||\n/*\t    mddev->layout        != info->layout        || */\n\t    mddev->persistent\t != !info->not_persistent ||\n\t    mddev->chunk_sectors != info->chunk_size >> 9 ||\n\t    /* ignore bottom 8 bits of state, and allow SB_BITMAP_PRESENT to change */\n\t    ((state^info->state) & 0xfffffe00)\n\t\t)\n\t\treturn -EINVAL;\n\t/* Check there is only one change */\n\tif (info->size >= 0 && mddev->dev_sectors / 2 != info->size)\n\t\tcnt++;\n\tif (mddev->raid_disks != info->raid_disks)\n\t\tcnt++;\n\tif (mddev->layout != info->layout)\n\t\tcnt++;\n\tif ((state ^ info->state) & (1<<MD_SB_BITMAP_PRESENT))\n\t\tcnt++;\n\tif (cnt == 0)\n\t\treturn 0;\n\tif (cnt > 1)\n\t\treturn -EINVAL;\n\n\tif (mddev->layout != info->layout) {\n\t\t/* Change layout\n\t\t * we don't need to do anything at the md level, the\n\t\t * personality will take care of it all.\n\t\t */\n\t\tif (mddev->pers->check_reshape == NULL)\n\t\t\treturn -EINVAL;\n\t\telse {\n\t\t\tmddev->new_layout = info->layout;\n\t\t\trv = mddev->pers->check_reshape(mddev);\n\t\t\tif (rv)\n\t\t\t\tmddev->new_layout = mddev->layout;\n\t\t\treturn rv;\n\t\t}\n\t}\n\tif (info->size >= 0 && mddev->dev_sectors / 2 != info->size)\n\t\trv = update_size(mddev, (sector_t)info->size * 2);\n\n\tif (mddev->raid_disks    != info->raid_disks)\n\t\trv = update_raid_disks(mddev, info->raid_disks);\n\n\tif ((state ^ info->state) & (1<<MD_SB_BITMAP_PRESENT)) {\n\t\tif (mddev->pers->quiesce == NULL || mddev->thread == NULL) {\n\t\t\trv = -EINVAL;\n\t\t\tgoto err;\n\t\t}\n\t\tif (mddev->recovery || mddev->sync_thread) {\n\t\t\trv = -EBUSY;\n\t\t\tgoto err;\n\t\t}\n\t\tif (info->state & (1<<MD_SB_BITMAP_PRESENT)) {\n\t\t\tstruct bitmap *bitmap;\n\t\t\t/* add the bitmap */\n\t\t\tif (mddev->bitmap) {\n\t\t\t\trv = -EEXIST;\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t\tif (mddev->bitmap_info.default_offset == 0) {\n\t\t\t\trv = -EINVAL;\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t\tmddev->bitmap_info.offset =\n\t\t\t\tmddev->bitmap_info.default_offset;\n\t\t\tmddev->bitmap_info.space =\n\t\t\t\tmddev->bitmap_info.default_space;\n\t\t\tbitmap = md_bitmap_create(mddev, -1);\n\t\t\tmddev_suspend(mddev);\n\t\t\tif (!IS_ERR(bitmap)) {\n\t\t\t\tmddev->bitmap = bitmap;\n\t\t\t\trv = md_bitmap_load(mddev);\n\t\t\t} else\n\t\t\t\trv = PTR_ERR(bitmap);\n\t\t\tif (rv)\n\t\t\t\tmd_bitmap_destroy(mddev);\n\t\t\tmddev_resume(mddev);\n\t\t} else {\n\t\t\t/* remove the bitmap */\n\t\t\tif (!mddev->bitmap) {\n\t\t\t\trv = -ENOENT;\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t\tif (mddev->bitmap->storage.file) {\n\t\t\t\trv = -EINVAL;\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t\tif (mddev->bitmap_info.nodes) {\n\t\t\t\t/* hold PW on all the bitmap lock */\n\t\t\t\tif (md_cluster_ops->lock_all_bitmaps(mddev) <= 0) {\n\t\t\t\t\tpr_warn(\"md: can't change bitmap to none since the array is in use by more than one node\\n\");\n\t\t\t\t\trv = -EPERM;\n\t\t\t\t\tmd_cluster_ops->unlock_all_bitmaps(mddev);\n\t\t\t\t\tgoto err;\n\t\t\t\t}\n\n\t\t\t\tmddev->bitmap_info.nodes = 0;\n\t\t\t\tmd_cluster_ops->leave(mddev);\n\t\t\t\tmodule_put(md_cluster_mod);\n\t\t\t\tmddev->safemode_delay = DEFAULT_SAFEMODE_DELAY;\n\t\t\t}\n\t\t\tmddev_suspend(mddev);\n\t\t\tmd_bitmap_destroy(mddev);\n\t\t\tmddev_resume(mddev);\n\t\t\tmddev->bitmap_info.offset = 0;\n\t\t}\n\t}\n\tmd_update_sb(mddev, 1);\n\treturn rv;\nerr:\n\treturn rv;\n}\n\nstatic int set_disk_faulty(struct mddev *mddev, dev_t dev)\n{\n\tstruct md_rdev *rdev;\n\tint err = 0;\n\n\tif (mddev->pers == NULL)\n\t\treturn -ENODEV;\n\n\trcu_read_lock();\n\trdev = md_find_rdev_rcu(mddev, dev);\n\tif (!rdev)\n\t\terr =  -ENODEV;\n\telse {\n\t\tmd_error(mddev, rdev);\n\t\tif (!test_bit(Faulty, &rdev->flags))\n\t\t\terr = -EBUSY;\n\t}\n\trcu_read_unlock();\n\treturn err;\n}\n\n/*\n * We have a problem here : there is no easy way to give a CHS\n * virtual geometry. We currently pretend that we have a 2 heads\n * 4 sectors (with a BIG number of cylinders...). This drives\n * dosfs just mad... ;-)\n */\nstatic int md_getgeo(struct block_device *bdev, struct hd_geometry *geo)\n{\n\tstruct mddev *mddev = bdev->bd_disk->private_data;\n\n\tgeo->heads = 2;\n\tgeo->sectors = 4;\n\tgeo->cylinders = mddev->array_sectors / 8;\n\treturn 0;\n}\n\nstatic inline bool md_ioctl_valid(unsigned int cmd)\n{\n\tswitch (cmd) {\n\tcase ADD_NEW_DISK:\n\tcase GET_ARRAY_INFO:\n\tcase GET_BITMAP_FILE:\n\tcase GET_DISK_INFO:\n\tcase HOT_ADD_DISK:\n\tcase HOT_REMOVE_DISK:\n\tcase RAID_VERSION:\n\tcase RESTART_ARRAY_RW:\n\tcase RUN_ARRAY:\n\tcase SET_ARRAY_INFO:\n\tcase SET_BITMAP_FILE:\n\tcase SET_DISK_FAULTY:\n\tcase STOP_ARRAY:\n\tcase STOP_ARRAY_RO:\n\tcase CLUSTERED_DISK_NACK:\n\t\treturn true;\n\tdefault:\n\t\treturn false;\n\t}\n}\n\nstatic int md_ioctl(struct block_device *bdev, fmode_t mode,\n\t\t\tunsigned int cmd, unsigned long arg)\n{\n\tint err = 0;\n\tvoid __user *argp = (void __user *)arg;\n\tstruct mddev *mddev = NULL;\n\tbool did_set_md_closing = false;\n\n\tif (!md_ioctl_valid(cmd))\n\t\treturn -ENOTTY;\n\n\tswitch (cmd) {\n\tcase RAID_VERSION:\n\tcase GET_ARRAY_INFO:\n\tcase GET_DISK_INFO:\n\t\tbreak;\n\tdefault:\n\t\tif (!capable(CAP_SYS_ADMIN))\n\t\t\treturn -EACCES;\n\t}\n\n\t/*\n\t * Commands dealing with the RAID driver but not any\n\t * particular array:\n\t */\n\tswitch (cmd) {\n\tcase RAID_VERSION:\n\t\terr = get_version(argp);\n\t\tgoto out;\n\tdefault:;\n\t}\n\n\t/*\n\t * Commands creating/starting a new array:\n\t */\n\n\tmddev = bdev->bd_disk->private_data;\n\n\tif (!mddev) {\n\t\tBUG();\n\t\tgoto out;\n\t}\n\n\t/* Some actions do not requires the mutex */\n\tswitch (cmd) {\n\tcase GET_ARRAY_INFO:\n\t\tif (!mddev->raid_disks && !mddev->external)\n\t\t\terr = -ENODEV;\n\t\telse\n\t\t\terr = get_array_info(mddev, argp);\n\t\tgoto out;\n\n\tcase GET_DISK_INFO:\n\t\tif (!mddev->raid_disks && !mddev->external)\n\t\t\terr = -ENODEV;\n\t\telse\n\t\t\terr = get_disk_info(mddev, argp);\n\t\tgoto out;\n\n\tcase SET_DISK_FAULTY:\n\t\terr = set_disk_faulty(mddev, new_decode_dev(arg));\n\t\tgoto out;\n\n\tcase GET_BITMAP_FILE:\n\t\terr = get_bitmap_file(mddev, argp);\n\t\tgoto out;\n\n\t}\n\n\tif (cmd == ADD_NEW_DISK || cmd == HOT_ADD_DISK)\n\t\tflush_rdev_wq(mddev);\n\n\tif (cmd == HOT_REMOVE_DISK)\n\t\t/* need to ensure recovery thread has run */\n\t\twait_event_interruptible_timeout(mddev->sb_wait,\n\t\t\t\t\t\t !test_bit(MD_RECOVERY_NEEDED,\n\t\t\t\t\t\t\t   &mddev->recovery),\n\t\t\t\t\t\t msecs_to_jiffies(5000));\n\tif (cmd == STOP_ARRAY || cmd == STOP_ARRAY_RO) {\n\t\t/* Need to flush page cache, and ensure no-one else opens\n\t\t * and writes\n\t\t */\n\t\tmutex_lock(&mddev->open_mutex);\n\t\tif (mddev->pers && atomic_read(&mddev->openers) > 1) {\n\t\t\tmutex_unlock(&mddev->open_mutex);\n\t\t\terr = -EBUSY;\n\t\t\tgoto out;\n\t\t}\n\t\tWARN_ON_ONCE(test_bit(MD_CLOSING, &mddev->flags));\n\t\tset_bit(MD_CLOSING, &mddev->flags);\n\t\tdid_set_md_closing = true;\n\t\tmutex_unlock(&mddev->open_mutex);\n\t\tsync_blockdev(bdev);\n\t}\n\terr = mddev_lock(mddev);\n\tif (err) {\n\t\tpr_debug(\"md: ioctl lock interrupted, reason %d, cmd %d\\n\",\n\t\t\t err, cmd);\n\t\tgoto out;\n\t}\n\n\tif (cmd == SET_ARRAY_INFO) {\n\t\tmdu_array_info_t info;\n\t\tif (!arg)\n\t\t\tmemset(&info, 0, sizeof(info));\n\t\telse if (copy_from_user(&info, argp, sizeof(info))) {\n\t\t\terr = -EFAULT;\n\t\t\tgoto unlock;\n\t\t}\n\t\tif (mddev->pers) {\n\t\t\terr = update_array_info(mddev, &info);\n\t\t\tif (err) {\n\t\t\t\tpr_warn(\"md: couldn't update array info. %d\\n\", err);\n\t\t\t\tgoto unlock;\n\t\t\t}\n\t\t\tgoto unlock;\n\t\t}\n\t\tif (!list_empty(&mddev->disks)) {\n\t\t\tpr_warn(\"md: array %s already has disks!\\n\", mdname(mddev));\n\t\t\terr = -EBUSY;\n\t\t\tgoto unlock;\n\t\t}\n\t\tif (mddev->raid_disks) {\n\t\t\tpr_warn(\"md: array %s already initialised!\\n\", mdname(mddev));\n\t\t\terr = -EBUSY;\n\t\t\tgoto unlock;\n\t\t}\n\t\terr = md_set_array_info(mddev, &info);\n\t\tif (err) {\n\t\t\tpr_warn(\"md: couldn't set array info. %d\\n\", err);\n\t\t\tgoto unlock;\n\t\t}\n\t\tgoto unlock;\n\t}\n\n\t/*\n\t * Commands querying/configuring an existing array:\n\t */\n\t/* if we are not initialised yet, only ADD_NEW_DISK, STOP_ARRAY,\n\t * RUN_ARRAY, and GET_ and SET_BITMAP_FILE are allowed */\n\tif ((!mddev->raid_disks && !mddev->external)\n\t    && cmd != ADD_NEW_DISK && cmd != STOP_ARRAY\n\t    && cmd != RUN_ARRAY && cmd != SET_BITMAP_FILE\n\t    && cmd != GET_BITMAP_FILE) {\n\t\terr = -ENODEV;\n\t\tgoto unlock;\n\t}\n\n\t/*\n\t * Commands even a read-only array can execute:\n\t */\n\tswitch (cmd) {\n\tcase RESTART_ARRAY_RW:\n\t\terr = restart_array(mddev);\n\t\tgoto unlock;\n\n\tcase STOP_ARRAY:\n\t\terr = do_md_stop(mddev, 0, bdev);\n\t\tgoto unlock;\n\n\tcase STOP_ARRAY_RO:\n\t\terr = md_set_readonly(mddev, bdev);\n\t\tgoto unlock;\n\n\tcase HOT_REMOVE_DISK:\n\t\terr = hot_remove_disk(mddev, new_decode_dev(arg));\n\t\tgoto unlock;\n\n\tcase ADD_NEW_DISK:\n\t\t/* We can support ADD_NEW_DISK on read-only arrays\n\t\t * only if we are re-adding a preexisting device.\n\t\t * So require mddev->pers and MD_DISK_SYNC.\n\t\t */\n\t\tif (mddev->pers) {\n\t\t\tmdu_disk_info_t info;\n\t\t\tif (copy_from_user(&info, argp, sizeof(info)))\n\t\t\t\terr = -EFAULT;\n\t\t\telse if (!(info.state & (1<<MD_DISK_SYNC)))\n\t\t\t\t/* Need to clear read-only for this */\n\t\t\t\tbreak;\n\t\t\telse\n\t\t\t\terr = md_add_new_disk(mddev, &info);\n\t\t\tgoto unlock;\n\t\t}\n\t\tbreak;\n\t}\n\n\t/*\n\t * The remaining ioctls are changing the state of the\n\t * superblock, so we do not allow them on read-only arrays.\n\t */\n\tif (mddev->ro && mddev->pers) {\n\t\tif (mddev->ro == 2) {\n\t\t\tmddev->ro = 0;\n\t\t\tsysfs_notify_dirent_safe(mddev->sysfs_state);\n\t\t\tset_bit(MD_RECOVERY_NEEDED, &mddev->recovery);\n\t\t\t/* mddev_unlock will wake thread */\n\t\t\t/* If a device failed while we were read-only, we\n\t\t\t * need to make sure the metadata is updated now.\n\t\t\t */\n\t\t\tif (test_bit(MD_SB_CHANGE_DEVS, &mddev->sb_flags)) {\n\t\t\t\tmddev_unlock(mddev);\n\t\t\t\twait_event(mddev->sb_wait,\n\t\t\t\t\t   !test_bit(MD_SB_CHANGE_DEVS, &mddev->sb_flags) &&\n\t\t\t\t\t   !test_bit(MD_SB_CHANGE_PENDING, &mddev->sb_flags));\n\t\t\t\tmddev_lock_nointr(mddev);\n\t\t\t}\n\t\t} else {\n\t\t\terr = -EROFS;\n\t\t\tgoto unlock;\n\t\t}\n\t}\n\n\tswitch (cmd) {\n\tcase ADD_NEW_DISK:\n\t{\n\t\tmdu_disk_info_t info;\n\t\tif (copy_from_user(&info, argp, sizeof(info)))\n\t\t\terr = -EFAULT;\n\t\telse\n\t\t\terr = md_add_new_disk(mddev, &info);\n\t\tgoto unlock;\n\t}\n\n\tcase CLUSTERED_DISK_NACK:\n\t\tif (mddev_is_clustered(mddev))\n\t\t\tmd_cluster_ops->new_disk_ack(mddev, false);\n\t\telse\n\t\t\terr = -EINVAL;\n\t\tgoto unlock;\n\n\tcase HOT_ADD_DISK:\n\t\terr = hot_add_disk(mddev, new_decode_dev(arg));\n\t\tgoto unlock;\n\n\tcase RUN_ARRAY:\n\t\terr = do_md_run(mddev);\n\t\tgoto unlock;\n\n\tcase SET_BITMAP_FILE:\n\t\terr = set_bitmap_file(mddev, (int)arg);\n\t\tgoto unlock;\n\n\tdefault:\n\t\terr = -EINVAL;\n\t\tgoto unlock;\n\t}\n\nunlock:\n\tif (mddev->hold_active == UNTIL_IOCTL &&\n\t    err != -EINVAL)\n\t\tmddev->hold_active = 0;\n\tmddev_unlock(mddev);\nout:\n\tif(did_set_md_closing)\n\t\tclear_bit(MD_CLOSING, &mddev->flags);\n\treturn err;\n}\n#ifdef CONFIG_COMPAT\nstatic int md_compat_ioctl(struct block_device *bdev, fmode_t mode,\n\t\t    unsigned int cmd, unsigned long arg)\n{\n\tswitch (cmd) {\n\tcase HOT_REMOVE_DISK:\n\tcase HOT_ADD_DISK:\n\tcase SET_DISK_FAULTY:\n\tcase SET_BITMAP_FILE:\n\t\t/* These take in integer arg, do not convert */\n\t\tbreak;\n\tdefault:\n\t\targ = (unsigned long)compat_ptr(arg);\n\t\tbreak;\n\t}\n\n\treturn md_ioctl(bdev, mode, cmd, arg);\n}\n#endif /* CONFIG_COMPAT */\n\nstatic int md_set_read_only(struct block_device *bdev, bool ro)\n{\n\tstruct mddev *mddev = bdev->bd_disk->private_data;\n\tint err;\n\n\terr = mddev_lock(mddev);\n\tif (err)\n\t\treturn err;\n\n\tif (!mddev->raid_disks && !mddev->external) {\n\t\terr = -ENODEV;\n\t\tgoto out_unlock;\n\t}\n\n\t/*\n\t * Transitioning to read-auto need only happen for arrays that call\n\t * md_write_start and which are not ready for writes yet.\n\t */\n\tif (!ro && mddev->ro == 1 && mddev->pers) {\n\t\terr = restart_array(mddev);\n\t\tif (err)\n\t\t\tgoto out_unlock;\n\t\tmddev->ro = 2;\n\t}\n\nout_unlock:\n\tmddev_unlock(mddev);\n\treturn err;\n}\n\nstatic int md_open(struct block_device *bdev, fmode_t mode)\n{\n\t/*\n\t * Succeed if we can lock the mddev, which confirms that\n\t * it isn't being stopped right now.\n\t */\n\tstruct mddev *mddev = mddev_find(bdev->bd_dev);\n\tint err;\n\n\tif (!mddev)\n\t\treturn -ENODEV;\n\n\tif (mddev->gendisk != bdev->bd_disk) {\n\t\t/* we are racing with mddev_put which is discarding this\n\t\t * bd_disk.\n\t\t */\n\t\tmddev_put(mddev);\n\t\t/* Wait until bdev->bd_disk is definitely gone */\n\t\tif (work_pending(&mddev->del_work))\n\t\t\tflush_workqueue(md_misc_wq);\n\t\t/* Then retry the open from the top */\n\t\treturn -ERESTARTSYS;\n\t}\n\tBUG_ON(mddev != bdev->bd_disk->private_data);\n\n\tif ((err = mutex_lock_interruptible(&mddev->open_mutex)))\n\t\tgoto out;\n\n\tif (test_bit(MD_CLOSING, &mddev->flags)) {\n\t\tmutex_unlock(&mddev->open_mutex);\n\t\terr = -ENODEV;\n\t\tgoto out;\n\t}\n\n\terr = 0;\n\tatomic_inc(&mddev->openers);\n\tmutex_unlock(&mddev->open_mutex);\n\n\tbdev_check_media_change(bdev);\n out:\n\tif (err)\n\t\tmddev_put(mddev);\n\treturn err;\n}\n\nstatic void md_release(struct gendisk *disk, fmode_t mode)\n{\n\tstruct mddev *mddev = disk->private_data;\n\n\tBUG_ON(!mddev);\n\tatomic_dec(&mddev->openers);\n\tmddev_put(mddev);\n}\n\nstatic unsigned int md_check_events(struct gendisk *disk, unsigned int clearing)\n{\n\tstruct mddev *mddev = disk->private_data;\n\tunsigned int ret = 0;\n\n\tif (mddev->changed)\n\t\tret = DISK_EVENT_MEDIA_CHANGE;\n\tmddev->changed = 0;\n\treturn ret;\n}\n\nconst struct block_device_operations md_fops =\n{\n\t.owner\t\t= THIS_MODULE,\n\t.submit_bio\t= md_submit_bio,\n\t.open\t\t= md_open,\n\t.release\t= md_release,\n\t.ioctl\t\t= md_ioctl,\n#ifdef CONFIG_COMPAT\n\t.compat_ioctl\t= md_compat_ioctl,\n#endif\n\t.getgeo\t\t= md_getgeo,\n\t.check_events\t= md_check_events,\n\t.set_read_only\t= md_set_read_only,\n};\n\nstatic int md_thread(void *arg)\n{\n\tstruct md_thread *thread = arg;\n\n\t/*\n\t * md_thread is a 'system-thread', it's priority should be very\n\t * high. We avoid resource deadlocks individually in each\n\t * raid personality. (RAID5 does preallocation) We also use RR and\n\t * the very same RT priority as kswapd, thus we will never get\n\t * into a priority inversion deadlock.\n\t *\n\t * we definitely have to have equal or higher priority than\n\t * bdflush, otherwise bdflush will deadlock if there are too\n\t * many dirty RAID5 blocks.\n\t */\n\n\tallow_signal(SIGKILL);\n\twhile (!kthread_should_stop()) {\n\n\t\t/* We need to wait INTERRUPTIBLE so that\n\t\t * we don't add to the load-average.\n\t\t * That means we need to be sure no signals are\n\t\t * pending\n\t\t */\n\t\tif (signal_pending(current))\n\t\t\tflush_signals(current);\n\n\t\twait_event_interruptible_timeout\n\t\t\t(thread->wqueue,\n\t\t\t test_bit(THREAD_WAKEUP, &thread->flags)\n\t\t\t || kthread_should_stop() || kthread_should_park(),\n\t\t\t thread->timeout);\n\n\t\tclear_bit(THREAD_WAKEUP, &thread->flags);\n\t\tif (kthread_should_park())\n\t\t\tkthread_parkme();\n\t\tif (!kthread_should_stop())\n\t\t\tthread->run(thread);\n\t}\n\n\treturn 0;\n}\n\nvoid md_wakeup_thread(struct md_thread *thread)\n{\n\tif (thread) {\n\t\tpr_debug(\"md: waking up MD thread %s.\\n\", thread->tsk->comm);\n\t\tset_bit(THREAD_WAKEUP, &thread->flags);\n\t\twake_up(&thread->wqueue);\n\t}\n}\nEXPORT_SYMBOL(md_wakeup_thread);\n\nstruct md_thread *md_register_thread(void (*run) (struct md_thread *),\n\t\tstruct mddev *mddev, const char *name)\n{\n\tstruct md_thread *thread;\n\n\tthread = kzalloc(sizeof(struct md_thread), GFP_KERNEL);\n\tif (!thread)\n\t\treturn NULL;\n\n\tinit_waitqueue_head(&thread->wqueue);\n\n\tthread->run = run;\n\tthread->mddev = mddev;\n\tthread->timeout = MAX_SCHEDULE_TIMEOUT;\n\tthread->tsk = kthread_run(md_thread, thread,\n\t\t\t\t  \"%s_%s\",\n\t\t\t\t  mdname(thread->mddev),\n\t\t\t\t  name);\n\tif (IS_ERR(thread->tsk)) {\n\t\tkfree(thread);\n\t\treturn NULL;\n\t}\n\treturn thread;\n}\nEXPORT_SYMBOL(md_register_thread);\n\nvoid md_unregister_thread(struct md_thread **threadp)\n{\n\tstruct md_thread *thread = *threadp;\n\tif (!thread)\n\t\treturn;\n\tpr_debug(\"interrupting MD-thread pid %d\\n\", task_pid_nr(thread->tsk));\n\t/* Locking ensures that mddev_unlock does not wake_up a\n\t * non-existent thread\n\t */\n\tspin_lock(&pers_lock);\n\t*threadp = NULL;\n\tspin_unlock(&pers_lock);\n\n\tkthread_stop(thread->tsk);\n\tkfree(thread);\n}\nEXPORT_SYMBOL(md_unregister_thread);\n\nvoid md_error(struct mddev *mddev, struct md_rdev *rdev)\n{\n\tif (!rdev || test_bit(Faulty, &rdev->flags))\n\t\treturn;\n\n\tif (!mddev->pers || !mddev->pers->error_handler)\n\t\treturn;\n\tmddev->pers->error_handler(mddev,rdev);\n\tif (mddev->degraded)\n\t\tset_bit(MD_RECOVERY_RECOVER, &mddev->recovery);\n\tsysfs_notify_dirent_safe(rdev->sysfs_state);\n\tset_bit(MD_RECOVERY_INTR, &mddev->recovery);\n\tset_bit(MD_RECOVERY_NEEDED, &mddev->recovery);\n\tmd_wakeup_thread(mddev->thread);\n\tif (mddev->event_work.func)\n\t\tqueue_work(md_misc_wq, &mddev->event_work);\n\tmd_new_event(mddev);\n}\nEXPORT_SYMBOL(md_error);\n\n/* seq_file implementation /proc/mdstat */\n\nstatic void status_unused(struct seq_file *seq)\n{\n\tint i = 0;\n\tstruct md_rdev *rdev;\n\n\tseq_printf(seq, \"unused devices: \");\n\n\tlist_for_each_entry(rdev, &pending_raid_disks, same_set) {\n\t\tchar b[BDEVNAME_SIZE];\n\t\ti++;\n\t\tseq_printf(seq, \"%s \",\n\t\t\t      bdevname(rdev->bdev,b));\n\t}\n\tif (!i)\n\t\tseq_printf(seq, \"<none>\");\n\n\tseq_printf(seq, \"\\n\");\n}\n\nstatic int status_resync(struct seq_file *seq, struct mddev *mddev)\n{\n\tsector_t max_sectors, resync, res;\n\tunsigned long dt, db = 0;\n\tsector_t rt, curr_mark_cnt, resync_mark_cnt;\n\tint scale, recovery_active;\n\tunsigned int per_milli;\n\n\tif (test_bit(MD_RECOVERY_SYNC, &mddev->recovery) ||\n\t    test_bit(MD_RECOVERY_RESHAPE, &mddev->recovery))\n\t\tmax_sectors = mddev->resync_max_sectors;\n\telse\n\t\tmax_sectors = mddev->dev_sectors;\n\n\tresync = mddev->curr_resync;\n\tif (resync <= 3) {\n\t\tif (test_bit(MD_RECOVERY_DONE, &mddev->recovery))\n\t\t\t/* Still cleaning up */\n\t\t\tresync = max_sectors;\n\t} else if (resync > max_sectors)\n\t\tresync = max_sectors;\n\telse\n\t\tresync -= atomic_read(&mddev->recovery_active);\n\n\tif (resync == 0) {\n\t\tif (test_bit(MD_RESYNCING_REMOTE, &mddev->recovery)) {\n\t\t\tstruct md_rdev *rdev;\n\n\t\t\trdev_for_each(rdev, mddev)\n\t\t\t\tif (rdev->raid_disk >= 0 &&\n\t\t\t\t    !test_bit(Faulty, &rdev->flags) &&\n\t\t\t\t    rdev->recovery_offset != MaxSector &&\n\t\t\t\t    rdev->recovery_offset) {\n\t\t\t\t\tseq_printf(seq, \"\\trecover=REMOTE\");\n\t\t\t\t\treturn 1;\n\t\t\t\t}\n\t\t\tif (mddev->reshape_position != MaxSector)\n\t\t\t\tseq_printf(seq, \"\\treshape=REMOTE\");\n\t\t\telse\n\t\t\t\tseq_printf(seq, \"\\tresync=REMOTE\");\n\t\t\treturn 1;\n\t\t}\n\t\tif (mddev->recovery_cp < MaxSector) {\n\t\t\tseq_printf(seq, \"\\tresync=PENDING\");\n\t\t\treturn 1;\n\t\t}\n\t\treturn 0;\n\t}\n\tif (resync < 3) {\n\t\tseq_printf(seq, \"\\tresync=DELAYED\");\n\t\treturn 1;\n\t}\n\n\tWARN_ON(max_sectors == 0);\n\t/* Pick 'scale' such that (resync>>scale)*1000 will fit\n\t * in a sector_t, and (max_sectors>>scale) will fit in a\n\t * u32, as those are the requirements for sector_div.\n\t * Thus 'scale' must be at least 10\n\t */\n\tscale = 10;\n\tif (sizeof(sector_t) > sizeof(unsigned long)) {\n\t\twhile ( max_sectors/2 > (1ULL<<(scale+32)))\n\t\t\tscale++;\n\t}\n\tres = (resync>>scale)*1000;\n\tsector_div(res, (u32)((max_sectors>>scale)+1));\n\n\tper_milli = res;\n\t{\n\t\tint i, x = per_milli/50, y = 20-x;\n\t\tseq_printf(seq, \"[\");\n\t\tfor (i = 0; i < x; i++)\n\t\t\tseq_printf(seq, \"=\");\n\t\tseq_printf(seq, \">\");\n\t\tfor (i = 0; i < y; i++)\n\t\t\tseq_printf(seq, \".\");\n\t\tseq_printf(seq, \"] \");\n\t}\n\tseq_printf(seq, \" %s =%3u.%u%% (%llu/%llu)\",\n\t\t   (test_bit(MD_RECOVERY_RESHAPE, &mddev->recovery)?\n\t\t    \"reshape\" :\n\t\t    (test_bit(MD_RECOVERY_CHECK, &mddev->recovery)?\n\t\t     \"check\" :\n\t\t     (test_bit(MD_RECOVERY_SYNC, &mddev->recovery) ?\n\t\t      \"resync\" : \"recovery\"))),\n\t\t   per_milli/10, per_milli % 10,\n\t\t   (unsigned long long) resync/2,\n\t\t   (unsigned long long) max_sectors/2);\n\n\t/*\n\t * dt: time from mark until now\n\t * db: blocks written from mark until now\n\t * rt: remaining time\n\t *\n\t * rt is a sector_t, which is always 64bit now. We are keeping\n\t * the original algorithm, but it is not really necessary.\n\t *\n\t * Original algorithm:\n\t *   So we divide before multiply in case it is 32bit and close\n\t *   to the limit.\n\t *   We scale the divisor (db) by 32 to avoid losing precision\n\t *   near the end of resync when the number of remaining sectors\n\t *   is close to 'db'.\n\t *   We then divide rt by 32 after multiplying by db to compensate.\n\t *   The '+1' avoids division by zero if db is very small.\n\t */\n\tdt = ((jiffies - mddev->resync_mark) / HZ);\n\tif (!dt) dt++;\n\n\tcurr_mark_cnt = mddev->curr_mark_cnt;\n\trecovery_active = atomic_read(&mddev->recovery_active);\n\tresync_mark_cnt = mddev->resync_mark_cnt;\n\n\tif (curr_mark_cnt >= (recovery_active + resync_mark_cnt))\n\t\tdb = curr_mark_cnt - (recovery_active + resync_mark_cnt);\n\n\trt = max_sectors - resync;    /* number of remaining sectors */\n\trt = div64_u64(rt, db/32+1);\n\trt *= dt;\n\trt >>= 5;\n\n\tseq_printf(seq, \" finish=%lu.%lumin\", (unsigned long)rt / 60,\n\t\t   ((unsigned long)rt % 60)/6);\n\n\tseq_printf(seq, \" speed=%ldK/sec\", db/2/dt);\n\treturn 1;\n}\n\nstatic void *md_seq_start(struct seq_file *seq, loff_t *pos)\n{\n\tstruct list_head *tmp;\n\tloff_t l = *pos;\n\tstruct mddev *mddev;\n\n\tif (l >= 0x10000)\n\t\treturn NULL;\n\tif (!l--)\n\t\t/* header */\n\t\treturn (void*)1;\n\n\tspin_lock(&all_mddevs_lock);\n\tlist_for_each(tmp,&all_mddevs)\n\t\tif (!l--) {\n\t\t\tmddev = list_entry(tmp, struct mddev, all_mddevs);\n\t\t\tmddev_get(mddev);\n\t\t\tspin_unlock(&all_mddevs_lock);\n\t\t\treturn mddev;\n\t\t}\n\tspin_unlock(&all_mddevs_lock);\n\tif (!l--)\n\t\treturn (void*)2;/* tail */\n\treturn NULL;\n}\n\nstatic void *md_seq_next(struct seq_file *seq, void *v, loff_t *pos)\n{\n\tstruct list_head *tmp;\n\tstruct mddev *next_mddev, *mddev = v;\n\n\t++*pos;\n\tif (v == (void*)2)\n\t\treturn NULL;\n\n\tspin_lock(&all_mddevs_lock);\n\tif (v == (void*)1)\n\t\ttmp = all_mddevs.next;\n\telse\n\t\ttmp = mddev->all_mddevs.next;\n\tif (tmp != &all_mddevs)\n\t\tnext_mddev = mddev_get(list_entry(tmp,struct mddev,all_mddevs));\n\telse {\n\t\tnext_mddev = (void*)2;\n\t\t*pos = 0x10000;\n\t}\n\tspin_unlock(&all_mddevs_lock);\n\n\tif (v != (void*)1)\n\t\tmddev_put(mddev);\n\treturn next_mddev;\n\n}\n\nstatic void md_seq_stop(struct seq_file *seq, void *v)\n{\n\tstruct mddev *mddev = v;\n\n\tif (mddev && v != (void*)1 && v != (void*)2)\n\t\tmddev_put(mddev);\n}\n\nstatic int md_seq_show(struct seq_file *seq, void *v)\n{\n\tstruct mddev *mddev = v;\n\tsector_t sectors;\n\tstruct md_rdev *rdev;\n\n\tif (v == (void*)1) {\n\t\tstruct md_personality *pers;\n\t\tseq_printf(seq, \"Personalities : \");\n\t\tspin_lock(&pers_lock);\n\t\tlist_for_each_entry(pers, &pers_list, list)\n\t\t\tseq_printf(seq, \"[%s] \", pers->name);\n\n\t\tspin_unlock(&pers_lock);\n\t\tseq_printf(seq, \"\\n\");\n\t\tseq->poll_event = atomic_read(&md_event_count);\n\t\treturn 0;\n\t}\n\tif (v == (void*)2) {\n\t\tstatus_unused(seq);\n\t\treturn 0;\n\t}\n\n\tspin_lock(&mddev->lock);\n\tif (mddev->pers || mddev->raid_disks || !list_empty(&mddev->disks)) {\n\t\tseq_printf(seq, \"%s : %sactive\", mdname(mddev),\n\t\t\t\t\t\tmddev->pers ? \"\" : \"in\");\n\t\tif (mddev->pers) {\n\t\t\tif (mddev->ro==1)\n\t\t\t\tseq_printf(seq, \" (read-only)\");\n\t\t\tif (mddev->ro==2)\n\t\t\t\tseq_printf(seq, \" (auto-read-only)\");\n\t\t\tseq_printf(seq, \" %s\", mddev->pers->name);\n\t\t}\n\n\t\tsectors = 0;\n\t\trcu_read_lock();\n\t\trdev_for_each_rcu(rdev, mddev) {\n\t\t\tchar b[BDEVNAME_SIZE];\n\t\t\tseq_printf(seq, \" %s[%d]\",\n\t\t\t\tbdevname(rdev->bdev,b), rdev->desc_nr);\n\t\t\tif (test_bit(WriteMostly, &rdev->flags))\n\t\t\t\tseq_printf(seq, \"(W)\");\n\t\t\tif (test_bit(Journal, &rdev->flags))\n\t\t\t\tseq_printf(seq, \"(J)\");\n\t\t\tif (test_bit(Faulty, &rdev->flags)) {\n\t\t\t\tseq_printf(seq, \"(F)\");\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (rdev->raid_disk < 0)\n\t\t\t\tseq_printf(seq, \"(S)\"); /* spare */\n\t\t\tif (test_bit(Replacement, &rdev->flags))\n\t\t\t\tseq_printf(seq, \"(R)\");\n\t\t\tsectors += rdev->sectors;\n\t\t}\n\t\trcu_read_unlock();\n\n\t\tif (!list_empty(&mddev->disks)) {\n\t\t\tif (mddev->pers)\n\t\t\t\tseq_printf(seq, \"\\n      %llu blocks\",\n\t\t\t\t\t   (unsigned long long)\n\t\t\t\t\t   mddev->array_sectors / 2);\n\t\t\telse\n\t\t\t\tseq_printf(seq, \"\\n      %llu blocks\",\n\t\t\t\t\t   (unsigned long long)sectors / 2);\n\t\t}\n\t\tif (mddev->persistent) {\n\t\t\tif (mddev->major_version != 0 ||\n\t\t\t    mddev->minor_version != 90) {\n\t\t\t\tseq_printf(seq,\" super %d.%d\",\n\t\t\t\t\t   mddev->major_version,\n\t\t\t\t\t   mddev->minor_version);\n\t\t\t}\n\t\t} else if (mddev->external)\n\t\t\tseq_printf(seq, \" super external:%s\",\n\t\t\t\t   mddev->metadata_type);\n\t\telse\n\t\t\tseq_printf(seq, \" super non-persistent\");\n\n\t\tif (mddev->pers) {\n\t\t\tmddev->pers->status(seq, mddev);\n\t\t\tseq_printf(seq, \"\\n      \");\n\t\t\tif (mddev->pers->sync_request) {\n\t\t\t\tif (status_resync(seq, mddev))\n\t\t\t\t\tseq_printf(seq, \"\\n      \");\n\t\t\t}\n\t\t} else\n\t\t\tseq_printf(seq, \"\\n       \");\n\n\t\tmd_bitmap_status(seq, mddev->bitmap);\n\n\t\tseq_printf(seq, \"\\n\");\n\t}\n\tspin_unlock(&mddev->lock);\n\n\treturn 0;\n}\n\nstatic const struct seq_operations md_seq_ops = {\n\t.start  = md_seq_start,\n\t.next   = md_seq_next,\n\t.stop   = md_seq_stop,\n\t.show   = md_seq_show,\n};\n\nstatic int md_seq_open(struct inode *inode, struct file *file)\n{\n\tstruct seq_file *seq;\n\tint error;\n\n\terror = seq_open(file, &md_seq_ops);\n\tif (error)\n\t\treturn error;\n\n\tseq = file->private_data;\n\tseq->poll_event = atomic_read(&md_event_count);\n\treturn error;\n}\n\nstatic int md_unloading;\nstatic __poll_t mdstat_poll(struct file *filp, poll_table *wait)\n{\n\tstruct seq_file *seq = filp->private_data;\n\t__poll_t mask;\n\n\tif (md_unloading)\n\t\treturn EPOLLIN|EPOLLRDNORM|EPOLLERR|EPOLLPRI;\n\tpoll_wait(filp, &md_event_waiters, wait);\n\n\t/* always allow read */\n\tmask = EPOLLIN | EPOLLRDNORM;\n\n\tif (seq->poll_event != atomic_read(&md_event_count))\n\t\tmask |= EPOLLERR | EPOLLPRI;\n\treturn mask;\n}\n\nstatic const struct proc_ops mdstat_proc_ops = {\n\t.proc_open\t= md_seq_open,\n\t.proc_read\t= seq_read,\n\t.proc_lseek\t= seq_lseek,\n\t.proc_release\t= seq_release,\n\t.proc_poll\t= mdstat_poll,\n};\n\nint register_md_personality(struct md_personality *p)\n{\n\tpr_debug(\"md: %s personality registered for level %d\\n\",\n\t\t p->name, p->level);\n\tspin_lock(&pers_lock);\n\tlist_add_tail(&p->list, &pers_list);\n\tspin_unlock(&pers_lock);\n\treturn 0;\n}\nEXPORT_SYMBOL(register_md_personality);\n\nint unregister_md_personality(struct md_personality *p)\n{\n\tpr_debug(\"md: %s personality unregistered\\n\", p->name);\n\tspin_lock(&pers_lock);\n\tlist_del_init(&p->list);\n\tspin_unlock(&pers_lock);\n\treturn 0;\n}\nEXPORT_SYMBOL(unregister_md_personality);\n\nint register_md_cluster_operations(struct md_cluster_operations *ops,\n\t\t\t\t   struct module *module)\n{\n\tint ret = 0;\n\tspin_lock(&pers_lock);\n\tif (md_cluster_ops != NULL)\n\t\tret = -EALREADY;\n\telse {\n\t\tmd_cluster_ops = ops;\n\t\tmd_cluster_mod = module;\n\t}\n\tspin_unlock(&pers_lock);\n\treturn ret;\n}\nEXPORT_SYMBOL(register_md_cluster_operations);\n\nint unregister_md_cluster_operations(void)\n{\n\tspin_lock(&pers_lock);\n\tmd_cluster_ops = NULL;\n\tspin_unlock(&pers_lock);\n\treturn 0;\n}\nEXPORT_SYMBOL(unregister_md_cluster_operations);\n\nint md_setup_cluster(struct mddev *mddev, int nodes)\n{\n\tint ret;\n\tif (!md_cluster_ops)\n\t\trequest_module(\"md-cluster\");\n\tspin_lock(&pers_lock);\n\t/* ensure module won't be unloaded */\n\tif (!md_cluster_ops || !try_module_get(md_cluster_mod)) {\n\t\tpr_warn(\"can't find md-cluster module or get it's reference.\\n\");\n\t\tspin_unlock(&pers_lock);\n\t\treturn -ENOENT;\n\t}\n\tspin_unlock(&pers_lock);\n\n\tret = md_cluster_ops->join(mddev, nodes);\n\tif (!ret)\n\t\tmddev->safemode_delay = 0;\n\treturn ret;\n}\n\nvoid md_cluster_stop(struct mddev *mddev)\n{\n\tif (!md_cluster_ops)\n\t\treturn;\n\tmd_cluster_ops->leave(mddev);\n\tmodule_put(md_cluster_mod);\n}\n\nstatic int is_mddev_idle(struct mddev *mddev, int init)\n{\n\tstruct md_rdev *rdev;\n\tint idle;\n\tint curr_events;\n\n\tidle = 1;\n\trcu_read_lock();\n\trdev_for_each_rcu(rdev, mddev) {\n\t\tstruct gendisk *disk = rdev->bdev->bd_disk;\n\t\tcurr_events = (int)part_stat_read_accum(&disk->part0, sectors) -\n\t\t\t      atomic_read(&disk->sync_io);\n\t\t/* sync IO will cause sync_io to increase before the disk_stats\n\t\t * as sync_io is counted when a request starts, and\n\t\t * disk_stats is counted when it completes.\n\t\t * So resync activity will cause curr_events to be smaller than\n\t\t * when there was no such activity.\n\t\t * non-sync IO will cause disk_stat to increase without\n\t\t * increasing sync_io so curr_events will (eventually)\n\t\t * be larger than it was before.  Once it becomes\n\t\t * substantially larger, the test below will cause\n\t\t * the array to appear non-idle, and resync will slow\n\t\t * down.\n\t\t * If there is a lot of outstanding resync activity when\n\t\t * we set last_event to curr_events, then all that activity\n\t\t * completing might cause the array to appear non-idle\n\t\t * and resync will be slowed down even though there might\n\t\t * not have been non-resync activity.  This will only\n\t\t * happen once though.  'last_events' will soon reflect\n\t\t * the state where there is little or no outstanding\n\t\t * resync requests, and further resync activity will\n\t\t * always make curr_events less than last_events.\n\t\t *\n\t\t */\n\t\tif (init || curr_events - rdev->last_events > 64) {\n\t\t\trdev->last_events = curr_events;\n\t\t\tidle = 0;\n\t\t}\n\t}\n\trcu_read_unlock();\n\treturn idle;\n}\n\nvoid md_done_sync(struct mddev *mddev, int blocks, int ok)\n{\n\t/* another \"blocks\" (512byte) blocks have been synced */\n\tatomic_sub(blocks, &mddev->recovery_active);\n\twake_up(&mddev->recovery_wait);\n\tif (!ok) {\n\t\tset_bit(MD_RECOVERY_INTR, &mddev->recovery);\n\t\tset_bit(MD_RECOVERY_ERROR, &mddev->recovery);\n\t\tmd_wakeup_thread(mddev->thread);\n\t\t// stop recovery, signal do_sync ....\n\t}\n}\nEXPORT_SYMBOL(md_done_sync);\n\n/* md_write_start(mddev, bi)\n * If we need to update some array metadata (e.g. 'active' flag\n * in superblock) before writing, schedule a superblock update\n * and wait for it to complete.\n * A return value of 'false' means that the write wasn't recorded\n * and cannot proceed as the array is being suspend.\n */\nbool md_write_start(struct mddev *mddev, struct bio *bi)\n{\n\tint did_change = 0;\n\n\tif (bio_data_dir(bi) != WRITE)\n\t\treturn true;\n\n\tBUG_ON(mddev->ro == 1);\n\tif (mddev->ro == 2) {\n\t\t/* need to switch to read/write */\n\t\tmddev->ro = 0;\n\t\tset_bit(MD_RECOVERY_NEEDED, &mddev->recovery);\n\t\tmd_wakeup_thread(mddev->thread);\n\t\tmd_wakeup_thread(mddev->sync_thread);\n\t\tdid_change = 1;\n\t}\n\trcu_read_lock();\n\tpercpu_ref_get(&mddev->writes_pending);\n\tsmp_mb(); /* Match smp_mb in set_in_sync() */\n\tif (mddev->safemode == 1)\n\t\tmddev->safemode = 0;\n\t/* sync_checkers is always 0 when writes_pending is in per-cpu mode */\n\tif (mddev->in_sync || mddev->sync_checkers) {\n\t\tspin_lock(&mddev->lock);\n\t\tif (mddev->in_sync) {\n\t\t\tmddev->in_sync = 0;\n\t\t\tset_bit(MD_SB_CHANGE_CLEAN, &mddev->sb_flags);\n\t\t\tset_bit(MD_SB_CHANGE_PENDING, &mddev->sb_flags);\n\t\t\tmd_wakeup_thread(mddev->thread);\n\t\t\tdid_change = 1;\n\t\t}\n\t\tspin_unlock(&mddev->lock);\n\t}\n\trcu_read_unlock();\n\tif (did_change)\n\t\tsysfs_notify_dirent_safe(mddev->sysfs_state);\n\tif (!mddev->has_superblocks)\n\t\treturn true;\n\twait_event(mddev->sb_wait,\n\t\t   !test_bit(MD_SB_CHANGE_PENDING, &mddev->sb_flags) ||\n\t\t   mddev->suspended);\n\tif (test_bit(MD_SB_CHANGE_PENDING, &mddev->sb_flags)) {\n\t\tpercpu_ref_put(&mddev->writes_pending);\n\t\treturn false;\n\t}\n\treturn true;\n}\nEXPORT_SYMBOL(md_write_start);\n\n/* md_write_inc can only be called when md_write_start() has\n * already been called at least once of the current request.\n * It increments the counter and is useful when a single request\n * is split into several parts.  Each part causes an increment and\n * so needs a matching md_write_end().\n * Unlike md_write_start(), it is safe to call md_write_inc() inside\n * a spinlocked region.\n */\nvoid md_write_inc(struct mddev *mddev, struct bio *bi)\n{\n\tif (bio_data_dir(bi) != WRITE)\n\t\treturn;\n\tWARN_ON_ONCE(mddev->in_sync || mddev->ro);\n\tpercpu_ref_get(&mddev->writes_pending);\n}\nEXPORT_SYMBOL(md_write_inc);\n\nvoid md_write_end(struct mddev *mddev)\n{\n\tpercpu_ref_put(&mddev->writes_pending);\n\n\tif (mddev->safemode == 2)\n\t\tmd_wakeup_thread(mddev->thread);\n\telse if (mddev->safemode_delay)\n\t\t/* The roundup() ensures this only performs locking once\n\t\t * every ->safemode_delay jiffies\n\t\t */\n\t\tmod_timer(&mddev->safemode_timer,\n\t\t\t  roundup(jiffies, mddev->safemode_delay) +\n\t\t\t  mddev->safemode_delay);\n}\n\nEXPORT_SYMBOL(md_write_end);\n\n/* This is used by raid0 and raid10 */\nvoid md_submit_discard_bio(struct mddev *mddev, struct md_rdev *rdev,\n\t\t\tstruct bio *bio, sector_t start, sector_t size)\n{\n\tstruct bio *discard_bio = NULL;\n\n\tif (__blkdev_issue_discard(rdev->bdev, start, size,\n\t\tGFP_NOIO, 0, &discard_bio) || !discard_bio)\n\t\treturn;\n\n\tbio_chain(discard_bio, bio);\n\tbio_clone_blkg_association(discard_bio, bio);\n\tif (mddev->gendisk)\n\t\ttrace_block_bio_remap(bdev_get_queue(rdev->bdev),\n\t\t\tdiscard_bio, disk_devt(mddev->gendisk),\n\t\t\tbio->bi_iter.bi_sector);\n\tsubmit_bio_noacct(discard_bio);\n}\nEXPORT_SYMBOL(md_submit_discard_bio);\n\n/* md_allow_write(mddev)\n * Calling this ensures that the array is marked 'active' so that writes\n * may proceed without blocking.  It is important to call this before\n * attempting a GFP_KERNEL allocation while holding the mddev lock.\n * Must be called with mddev_lock held.\n */\nvoid md_allow_write(struct mddev *mddev)\n{\n\tif (!mddev->pers)\n\t\treturn;\n\tif (mddev->ro)\n\t\treturn;\n\tif (!mddev->pers->sync_request)\n\t\treturn;\n\n\tspin_lock(&mddev->lock);\n\tif (mddev->in_sync) {\n\t\tmddev->in_sync = 0;\n\t\tset_bit(MD_SB_CHANGE_CLEAN, &mddev->sb_flags);\n\t\tset_bit(MD_SB_CHANGE_PENDING, &mddev->sb_flags);\n\t\tif (mddev->safemode_delay &&\n\t\t    mddev->safemode == 0)\n\t\t\tmddev->safemode = 1;\n\t\tspin_unlock(&mddev->lock);\n\t\tmd_update_sb(mddev, 0);\n\t\tsysfs_notify_dirent_safe(mddev->sysfs_state);\n\t\t/* wait for the dirty state to be recorded in the metadata */\n\t\twait_event(mddev->sb_wait,\n\t\t\t   !test_bit(MD_SB_CHANGE_PENDING, &mddev->sb_flags));\n\t} else\n\t\tspin_unlock(&mddev->lock);\n}\nEXPORT_SYMBOL_GPL(md_allow_write);\n\n#define SYNC_MARKS\t10\n#define\tSYNC_MARK_STEP\t(3*HZ)\n#define UPDATE_FREQUENCY (5*60*HZ)\nvoid md_do_sync(struct md_thread *thread)\n{\n\tstruct mddev *mddev = thread->mddev;\n\tstruct mddev *mddev2;\n\tunsigned int currspeed = 0, window;\n\tsector_t max_sectors,j, io_sectors, recovery_done;\n\tunsigned long mark[SYNC_MARKS];\n\tunsigned long update_time;\n\tsector_t mark_cnt[SYNC_MARKS];\n\tint last_mark,m;\n\tstruct list_head *tmp;\n\tsector_t last_check;\n\tint skipped = 0;\n\tstruct md_rdev *rdev;\n\tchar *desc, *action = NULL;\n\tstruct blk_plug plug;\n\tint ret;\n\n\t/* just incase thread restarts... */\n\tif (test_bit(MD_RECOVERY_DONE, &mddev->recovery) ||\n\t    test_bit(MD_RECOVERY_WAIT, &mddev->recovery))\n\t\treturn;\n\tif (mddev->ro) {/* never try to sync a read-only array */\n\t\tset_bit(MD_RECOVERY_INTR, &mddev->recovery);\n\t\treturn;\n\t}\n\n\tif (mddev_is_clustered(mddev)) {\n\t\tret = md_cluster_ops->resync_start(mddev);\n\t\tif (ret)\n\t\t\tgoto skip;\n\n\t\tset_bit(MD_CLUSTER_RESYNC_LOCKED, &mddev->flags);\n\t\tif (!(test_bit(MD_RECOVERY_SYNC, &mddev->recovery) ||\n\t\t\ttest_bit(MD_RECOVERY_RESHAPE, &mddev->recovery) ||\n\t\t\ttest_bit(MD_RECOVERY_RECOVER, &mddev->recovery))\n\t\t     && ((unsigned long long)mddev->curr_resync_completed\n\t\t\t < (unsigned long long)mddev->resync_max_sectors))\n\t\t\tgoto skip;\n\t}\n\n\tif (test_bit(MD_RECOVERY_SYNC, &mddev->recovery)) {\n\t\tif (test_bit(MD_RECOVERY_CHECK, &mddev->recovery)) {\n\t\t\tdesc = \"data-check\";\n\t\t\taction = \"check\";\n\t\t} else if (test_bit(MD_RECOVERY_REQUESTED, &mddev->recovery)) {\n\t\t\tdesc = \"requested-resync\";\n\t\t\taction = \"repair\";\n\t\t} else\n\t\t\tdesc = \"resync\";\n\t} else if (test_bit(MD_RECOVERY_RESHAPE, &mddev->recovery))\n\t\tdesc = \"reshape\";\n\telse\n\t\tdesc = \"recovery\";\n\n\tmddev->last_sync_action = action ?: desc;\n\n\t/* we overload curr_resync somewhat here.\n\t * 0 == not engaged in resync at all\n\t * 2 == checking that there is no conflict with another sync\n\t * 1 == like 2, but have yielded to allow conflicting resync to\n\t *\t\tcommence\n\t * other == active in resync - this many blocks\n\t *\n\t * Before starting a resync we must have set curr_resync to\n\t * 2, and then checked that every \"conflicting\" array has curr_resync\n\t * less than ours.  When we find one that is the same or higher\n\t * we wait on resync_wait.  To avoid deadlock, we reduce curr_resync\n\t * to 1 if we choose to yield (based arbitrarily on address of mddev structure).\n\t * This will mean we have to start checking from the beginning again.\n\t *\n\t */\n\n\tdo {\n\t\tint mddev2_minor = -1;\n\t\tmddev->curr_resync = 2;\n\n\ttry_again:\n\t\tif (test_bit(MD_RECOVERY_INTR, &mddev->recovery))\n\t\t\tgoto skip;\n\t\tfor_each_mddev(mddev2, tmp) {\n\t\t\tif (mddev2 == mddev)\n\t\t\t\tcontinue;\n\t\t\tif (!mddev->parallel_resync\n\t\t\t&&  mddev2->curr_resync\n\t\t\t&&  match_mddev_units(mddev, mddev2)) {\n\t\t\t\tDEFINE_WAIT(wq);\n\t\t\t\tif (mddev < mddev2 && mddev->curr_resync == 2) {\n\t\t\t\t\t/* arbitrarily yield */\n\t\t\t\t\tmddev->curr_resync = 1;\n\t\t\t\t\twake_up(&resync_wait);\n\t\t\t\t}\n\t\t\t\tif (mddev > mddev2 && mddev->curr_resync == 1)\n\t\t\t\t\t/* no need to wait here, we can wait the next\n\t\t\t\t\t * time 'round when curr_resync == 2\n\t\t\t\t\t */\n\t\t\t\t\tcontinue;\n\t\t\t\t/* We need to wait 'interruptible' so as not to\n\t\t\t\t * contribute to the load average, and not to\n\t\t\t\t * be caught by 'softlockup'\n\t\t\t\t */\n\t\t\t\tprepare_to_wait(&resync_wait, &wq, TASK_INTERRUPTIBLE);\n\t\t\t\tif (!test_bit(MD_RECOVERY_INTR, &mddev->recovery) &&\n\t\t\t\t    mddev2->curr_resync >= mddev->curr_resync) {\n\t\t\t\t\tif (mddev2_minor != mddev2->md_minor) {\n\t\t\t\t\t\tmddev2_minor = mddev2->md_minor;\n\t\t\t\t\t\tpr_info(\"md: delaying %s of %s until %s has finished (they share one or more physical units)\\n\",\n\t\t\t\t\t\t\tdesc, mdname(mddev),\n\t\t\t\t\t\t\tmdname(mddev2));\n\t\t\t\t\t}\n\t\t\t\t\tmddev_put(mddev2);\n\t\t\t\t\tif (signal_pending(current))\n\t\t\t\t\t\tflush_signals(current);\n\t\t\t\t\tschedule();\n\t\t\t\t\tfinish_wait(&resync_wait, &wq);\n\t\t\t\t\tgoto try_again;\n\t\t\t\t}\n\t\t\t\tfinish_wait(&resync_wait, &wq);\n\t\t\t}\n\t\t}\n\t} while (mddev->curr_resync < 2);\n\n\tj = 0;\n\tif (test_bit(MD_RECOVERY_SYNC, &mddev->recovery)) {\n\t\t/* resync follows the size requested by the personality,\n\t\t * which defaults to physical size, but can be virtual size\n\t\t */\n\t\tmax_sectors = mddev->resync_max_sectors;\n\t\tatomic64_set(&mddev->resync_mismatches, 0);\n\t\t/* we don't use the checkpoint if there's a bitmap */\n\t\tif (test_bit(MD_RECOVERY_REQUESTED, &mddev->recovery))\n\t\t\tj = mddev->resync_min;\n\t\telse if (!mddev->bitmap)\n\t\t\tj = mddev->recovery_cp;\n\n\t} else if (test_bit(MD_RECOVERY_RESHAPE, &mddev->recovery)) {\n\t\tmax_sectors = mddev->resync_max_sectors;\n\t\t/*\n\t\t * If the original node aborts reshaping then we continue the\n\t\t * reshaping, so set j again to avoid restart reshape from the\n\t\t * first beginning\n\t\t */\n\t\tif (mddev_is_clustered(mddev) &&\n\t\t    mddev->reshape_position != MaxSector)\n\t\t\tj = mddev->reshape_position;\n\t} else {\n\t\t/* recovery follows the physical size of devices */\n\t\tmax_sectors = mddev->dev_sectors;\n\t\tj = MaxSector;\n\t\trcu_read_lock();\n\t\trdev_for_each_rcu(rdev, mddev)\n\t\t\tif (rdev->raid_disk >= 0 &&\n\t\t\t    !test_bit(Journal, &rdev->flags) &&\n\t\t\t    !test_bit(Faulty, &rdev->flags) &&\n\t\t\t    !test_bit(In_sync, &rdev->flags) &&\n\t\t\t    rdev->recovery_offset < j)\n\t\t\t\tj = rdev->recovery_offset;\n\t\trcu_read_unlock();\n\n\t\t/* If there is a bitmap, we need to make sure all\n\t\t * writes that started before we added a spare\n\t\t * complete before we start doing a recovery.\n\t\t * Otherwise the write might complete and (via\n\t\t * bitmap_endwrite) set a bit in the bitmap after the\n\t\t * recovery has checked that bit and skipped that\n\t\t * region.\n\t\t */\n\t\tif (mddev->bitmap) {\n\t\t\tmddev->pers->quiesce(mddev, 1);\n\t\t\tmddev->pers->quiesce(mddev, 0);\n\t\t}\n\t}\n\n\tpr_info(\"md: %s of RAID array %s\\n\", desc, mdname(mddev));\n\tpr_debug(\"md: minimum _guaranteed_  speed: %d KB/sec/disk.\\n\", speed_min(mddev));\n\tpr_debug(\"md: using maximum available idle IO bandwidth (but not more than %d KB/sec) for %s.\\n\",\n\t\t speed_max(mddev), desc);\n\n\tis_mddev_idle(mddev, 1); /* this initializes IO event counters */\n\n\tio_sectors = 0;\n\tfor (m = 0; m < SYNC_MARKS; m++) {\n\t\tmark[m] = jiffies;\n\t\tmark_cnt[m] = io_sectors;\n\t}\n\tlast_mark = 0;\n\tmddev->resync_mark = mark[last_mark];\n\tmddev->resync_mark_cnt = mark_cnt[last_mark];\n\n\t/*\n\t * Tune reconstruction:\n\t */\n\twindow = 32 * (PAGE_SIZE / 512);\n\tpr_debug(\"md: using %dk window, over a total of %lluk.\\n\",\n\t\t window/2, (unsigned long long)max_sectors/2);\n\n\tatomic_set(&mddev->recovery_active, 0);\n\tlast_check = 0;\n\n\tif (j>2) {\n\t\tpr_debug(\"md: resuming %s of %s from checkpoint.\\n\",\n\t\t\t desc, mdname(mddev));\n\t\tmddev->curr_resync = j;\n\t} else\n\t\tmddev->curr_resync = 3; /* no longer delayed */\n\tmddev->curr_resync_completed = j;\n\tsysfs_notify_dirent_safe(mddev->sysfs_completed);\n\tmd_new_event(mddev);\n\tupdate_time = jiffies;\n\n\tblk_start_plug(&plug);\n\twhile (j < max_sectors) {\n\t\tsector_t sectors;\n\n\t\tskipped = 0;\n\n\t\tif (!test_bit(MD_RECOVERY_RESHAPE, &mddev->recovery) &&\n\t\t    ((mddev->curr_resync > mddev->curr_resync_completed &&\n\t\t      (mddev->curr_resync - mddev->curr_resync_completed)\n\t\t      > (max_sectors >> 4)) ||\n\t\t     time_after_eq(jiffies, update_time + UPDATE_FREQUENCY) ||\n\t\t     (j - mddev->curr_resync_completed)*2\n\t\t     >= mddev->resync_max - mddev->curr_resync_completed ||\n\t\t     mddev->curr_resync_completed > mddev->resync_max\n\t\t\t    )) {\n\t\t\t/* time to update curr_resync_completed */\n\t\t\twait_event(mddev->recovery_wait,\n\t\t\t\t   atomic_read(&mddev->recovery_active) == 0);\n\t\t\tmddev->curr_resync_completed = j;\n\t\t\tif (test_bit(MD_RECOVERY_SYNC, &mddev->recovery) &&\n\t\t\t    j > mddev->recovery_cp)\n\t\t\t\tmddev->recovery_cp = j;\n\t\t\tupdate_time = jiffies;\n\t\t\tset_bit(MD_SB_CHANGE_CLEAN, &mddev->sb_flags);\n\t\t\tsysfs_notify_dirent_safe(mddev->sysfs_completed);\n\t\t}\n\n\t\twhile (j >= mddev->resync_max &&\n\t\t       !test_bit(MD_RECOVERY_INTR, &mddev->recovery)) {\n\t\t\t/* As this condition is controlled by user-space,\n\t\t\t * we can block indefinitely, so use '_interruptible'\n\t\t\t * to avoid triggering warnings.\n\t\t\t */\n\t\t\tflush_signals(current); /* just in case */\n\t\t\twait_event_interruptible(mddev->recovery_wait,\n\t\t\t\t\t\t mddev->resync_max > j\n\t\t\t\t\t\t || test_bit(MD_RECOVERY_INTR,\n\t\t\t\t\t\t\t     &mddev->recovery));\n\t\t}\n\n\t\tif (test_bit(MD_RECOVERY_INTR, &mddev->recovery))\n\t\t\tbreak;\n\n\t\tsectors = mddev->pers->sync_request(mddev, j, &skipped);\n\t\tif (sectors == 0) {\n\t\t\tset_bit(MD_RECOVERY_INTR, &mddev->recovery);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!skipped) { /* actual IO requested */\n\t\t\tio_sectors += sectors;\n\t\t\tatomic_add(sectors, &mddev->recovery_active);\n\t\t}\n\n\t\tif (test_bit(MD_RECOVERY_INTR, &mddev->recovery))\n\t\t\tbreak;\n\n\t\tj += sectors;\n\t\tif (j > max_sectors)\n\t\t\t/* when skipping, extra large numbers can be returned. */\n\t\t\tj = max_sectors;\n\t\tif (j > 2)\n\t\t\tmddev->curr_resync = j;\n\t\tmddev->curr_mark_cnt = io_sectors;\n\t\tif (last_check == 0)\n\t\t\t/* this is the earliest that rebuild will be\n\t\t\t * visible in /proc/mdstat\n\t\t\t */\n\t\t\tmd_new_event(mddev);\n\n\t\tif (last_check + window > io_sectors || j == max_sectors)\n\t\t\tcontinue;\n\n\t\tlast_check = io_sectors;\n\trepeat:\n\t\tif (time_after_eq(jiffies, mark[last_mark] + SYNC_MARK_STEP )) {\n\t\t\t/* step marks */\n\t\t\tint next = (last_mark+1) % SYNC_MARKS;\n\n\t\t\tmddev->resync_mark = mark[next];\n\t\t\tmddev->resync_mark_cnt = mark_cnt[next];\n\t\t\tmark[next] = jiffies;\n\t\t\tmark_cnt[next] = io_sectors - atomic_read(&mddev->recovery_active);\n\t\t\tlast_mark = next;\n\t\t}\n\n\t\tif (test_bit(MD_RECOVERY_INTR, &mddev->recovery))\n\t\t\tbreak;\n\n\t\t/*\n\t\t * this loop exits only if either when we are slower than\n\t\t * the 'hard' speed limit, or the system was IO-idle for\n\t\t * a jiffy.\n\t\t * the system might be non-idle CPU-wise, but we only care\n\t\t * about not overloading the IO subsystem. (things like an\n\t\t * e2fsck being done on the RAID array should execute fast)\n\t\t */\n\t\tcond_resched();\n\n\t\trecovery_done = io_sectors - atomic_read(&mddev->recovery_active);\n\t\tcurrspeed = ((unsigned long)(recovery_done - mddev->resync_mark_cnt))/2\n\t\t\t/((jiffies-mddev->resync_mark)/HZ +1) +1;\n\n\t\tif (currspeed > speed_min(mddev)) {\n\t\t\tif (currspeed > speed_max(mddev)) {\n\t\t\t\tmsleep(500);\n\t\t\t\tgoto repeat;\n\t\t\t}\n\t\t\tif (!is_mddev_idle(mddev, 0)) {\n\t\t\t\t/*\n\t\t\t\t * Give other IO more of a chance.\n\t\t\t\t * The faster the devices, the less we wait.\n\t\t\t\t */\n\t\t\t\twait_event(mddev->recovery_wait,\n\t\t\t\t\t   !atomic_read(&mddev->recovery_active));\n\t\t\t}\n\t\t}\n\t}\n\tpr_info(\"md: %s: %s %s.\\n\",mdname(mddev), desc,\n\t\ttest_bit(MD_RECOVERY_INTR, &mddev->recovery)\n\t\t? \"interrupted\" : \"done\");\n\t/*\n\t * this also signals 'finished resyncing' to md_stop\n\t */\n\tblk_finish_plug(&plug);\n\twait_event(mddev->recovery_wait, !atomic_read(&mddev->recovery_active));\n\n\tif (!test_bit(MD_RECOVERY_RESHAPE, &mddev->recovery) &&\n\t    !test_bit(MD_RECOVERY_INTR, &mddev->recovery) &&\n\t    mddev->curr_resync > 3) {\n\t\tmddev->curr_resync_completed = mddev->curr_resync;\n\t\tsysfs_notify_dirent_safe(mddev->sysfs_completed);\n\t}\n\tmddev->pers->sync_request(mddev, max_sectors, &skipped);\n\n\tif (!test_bit(MD_RECOVERY_CHECK, &mddev->recovery) &&\n\t    mddev->curr_resync > 3) {\n\t\tif (test_bit(MD_RECOVERY_SYNC, &mddev->recovery)) {\n\t\t\tif (test_bit(MD_RECOVERY_INTR, &mddev->recovery)) {\n\t\t\t\tif (mddev->curr_resync >= mddev->recovery_cp) {\n\t\t\t\t\tpr_debug(\"md: checkpointing %s of %s.\\n\",\n\t\t\t\t\t\t desc, mdname(mddev));\n\t\t\t\t\tif (test_bit(MD_RECOVERY_ERROR,\n\t\t\t\t\t\t&mddev->recovery))\n\t\t\t\t\t\tmddev->recovery_cp =\n\t\t\t\t\t\t\tmddev->curr_resync_completed;\n\t\t\t\t\telse\n\t\t\t\t\t\tmddev->recovery_cp =\n\t\t\t\t\t\t\tmddev->curr_resync;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\tmddev->recovery_cp = MaxSector;\n\t\t} else {\n\t\t\tif (!test_bit(MD_RECOVERY_INTR, &mddev->recovery))\n\t\t\t\tmddev->curr_resync = MaxSector;\n\t\t\tif (!test_bit(MD_RECOVERY_RESHAPE, &mddev->recovery) &&\n\t\t\t    test_bit(MD_RECOVERY_RECOVER, &mddev->recovery)) {\n\t\t\t\trcu_read_lock();\n\t\t\t\trdev_for_each_rcu(rdev, mddev)\n\t\t\t\t\tif (rdev->raid_disk >= 0 &&\n\t\t\t\t\t    mddev->delta_disks >= 0 &&\n\t\t\t\t\t    !test_bit(Journal, &rdev->flags) &&\n\t\t\t\t\t    !test_bit(Faulty, &rdev->flags) &&\n\t\t\t\t\t    !test_bit(In_sync, &rdev->flags) &&\n\t\t\t\t\t    rdev->recovery_offset < mddev->curr_resync)\n\t\t\t\t\t\trdev->recovery_offset = mddev->curr_resync;\n\t\t\t\trcu_read_unlock();\n\t\t\t}\n\t\t}\n\t}\n skip:\n\t/* set CHANGE_PENDING here since maybe another update is needed,\n\t * so other nodes are informed. It should be harmless for normal\n\t * raid */\n\tset_mask_bits(&mddev->sb_flags, 0,\n\t\t      BIT(MD_SB_CHANGE_PENDING) | BIT(MD_SB_CHANGE_DEVS));\n\n\tif (test_bit(MD_RECOVERY_RESHAPE, &mddev->recovery) &&\n\t\t\t!test_bit(MD_RECOVERY_INTR, &mddev->recovery) &&\n\t\t\tmddev->delta_disks > 0 &&\n\t\t\tmddev->pers->finish_reshape &&\n\t\t\tmddev->pers->size &&\n\t\t\tmddev->queue) {\n\t\tmddev_lock_nointr(mddev);\n\t\tmd_set_array_sectors(mddev, mddev->pers->size(mddev, 0, 0));\n\t\tmddev_unlock(mddev);\n\t\tif (!mddev_is_clustered(mddev))\n\t\t\tset_capacity_and_notify(mddev->gendisk,\n\t\t\t\t\t\tmddev->array_sectors);\n\t}\n\n\tspin_lock(&mddev->lock);\n\tif (!test_bit(MD_RECOVERY_INTR, &mddev->recovery)) {\n\t\t/* We completed so min/max setting can be forgotten if used. */\n\t\tif (test_bit(MD_RECOVERY_REQUESTED, &mddev->recovery))\n\t\t\tmddev->resync_min = 0;\n\t\tmddev->resync_max = MaxSector;\n\t} else if (test_bit(MD_RECOVERY_REQUESTED, &mddev->recovery))\n\t\tmddev->resync_min = mddev->curr_resync_completed;\n\tset_bit(MD_RECOVERY_DONE, &mddev->recovery);\n\tmddev->curr_resync = 0;\n\tspin_unlock(&mddev->lock);\n\n\twake_up(&resync_wait);\n\tmd_wakeup_thread(mddev->thread);\n\treturn;\n}\nEXPORT_SYMBOL_GPL(md_do_sync);\n\nstatic int remove_and_add_spares(struct mddev *mddev,\n\t\t\t\t struct md_rdev *this)\n{\n\tstruct md_rdev *rdev;\n\tint spares = 0;\n\tint removed = 0;\n\tbool remove_some = false;\n\n\tif (this && test_bit(MD_RECOVERY_RUNNING, &mddev->recovery))\n\t\t/* Mustn't remove devices when resync thread is running */\n\t\treturn 0;\n\n\trdev_for_each(rdev, mddev) {\n\t\tif ((this == NULL || rdev == this) &&\n\t\t    rdev->raid_disk >= 0 &&\n\t\t    !test_bit(Blocked, &rdev->flags) &&\n\t\t    test_bit(Faulty, &rdev->flags) &&\n\t\t    atomic_read(&rdev->nr_pending)==0) {\n\t\t\t/* Faulty non-Blocked devices with nr_pending == 0\n\t\t\t * never get nr_pending incremented,\n\t\t\t * never get Faulty cleared, and never get Blocked set.\n\t\t\t * So we can synchronize_rcu now rather than once per device\n\t\t\t */\n\t\t\tremove_some = true;\n\t\t\tset_bit(RemoveSynchronized, &rdev->flags);\n\t\t}\n\t}\n\n\tif (remove_some)\n\t\tsynchronize_rcu();\n\trdev_for_each(rdev, mddev) {\n\t\tif ((this == NULL || rdev == this) &&\n\t\t    rdev->raid_disk >= 0 &&\n\t\t    !test_bit(Blocked, &rdev->flags) &&\n\t\t    ((test_bit(RemoveSynchronized, &rdev->flags) ||\n\t\t     (!test_bit(In_sync, &rdev->flags) &&\n\t\t      !test_bit(Journal, &rdev->flags))) &&\n\t\t    atomic_read(&rdev->nr_pending)==0)) {\n\t\t\tif (mddev->pers->hot_remove_disk(\n\t\t\t\t    mddev, rdev) == 0) {\n\t\t\t\tsysfs_unlink_rdev(mddev, rdev);\n\t\t\t\trdev->saved_raid_disk = rdev->raid_disk;\n\t\t\t\trdev->raid_disk = -1;\n\t\t\t\tremoved++;\n\t\t\t}\n\t\t}\n\t\tif (remove_some && test_bit(RemoveSynchronized, &rdev->flags))\n\t\t\tclear_bit(RemoveSynchronized, &rdev->flags);\n\t}\n\n\tif (removed && mddev->kobj.sd)\n\t\tsysfs_notify_dirent_safe(mddev->sysfs_degraded);\n\n\tif (this && removed)\n\t\tgoto no_add;\n\n\trdev_for_each(rdev, mddev) {\n\t\tif (this && this != rdev)\n\t\t\tcontinue;\n\t\tif (test_bit(Candidate, &rdev->flags))\n\t\t\tcontinue;\n\t\tif (rdev->raid_disk >= 0 &&\n\t\t    !test_bit(In_sync, &rdev->flags) &&\n\t\t    !test_bit(Journal, &rdev->flags) &&\n\t\t    !test_bit(Faulty, &rdev->flags))\n\t\t\tspares++;\n\t\tif (rdev->raid_disk >= 0)\n\t\t\tcontinue;\n\t\tif (test_bit(Faulty, &rdev->flags))\n\t\t\tcontinue;\n\t\tif (!test_bit(Journal, &rdev->flags)) {\n\t\t\tif (mddev->ro &&\n\t\t\t    ! (rdev->saved_raid_disk >= 0 &&\n\t\t\t       !test_bit(Bitmap_sync, &rdev->flags)))\n\t\t\t\tcontinue;\n\n\t\t\trdev->recovery_offset = 0;\n\t\t}\n\t\tif (mddev->pers->hot_add_disk(mddev, rdev) == 0) {\n\t\t\t/* failure here is OK */\n\t\t\tsysfs_link_rdev(mddev, rdev);\n\t\t\tif (!test_bit(Journal, &rdev->flags))\n\t\t\t\tspares++;\n\t\t\tmd_new_event(mddev);\n\t\t\tset_bit(MD_SB_CHANGE_DEVS, &mddev->sb_flags);\n\t\t}\n\t}\nno_add:\n\tif (removed)\n\t\tset_bit(MD_SB_CHANGE_DEVS, &mddev->sb_flags);\n\treturn spares;\n}\n\nstatic void md_start_sync(struct work_struct *ws)\n{\n\tstruct mddev *mddev = container_of(ws, struct mddev, del_work);\n\n\tmddev->sync_thread = md_register_thread(md_do_sync,\n\t\t\t\t\t\tmddev,\n\t\t\t\t\t\t\"resync\");\n\tif (!mddev->sync_thread) {\n\t\tpr_warn(\"%s: could not start resync thread...\\n\",\n\t\t\tmdname(mddev));\n\t\t/* leave the spares where they are, it shouldn't hurt */\n\t\tclear_bit(MD_RECOVERY_SYNC, &mddev->recovery);\n\t\tclear_bit(MD_RECOVERY_RESHAPE, &mddev->recovery);\n\t\tclear_bit(MD_RECOVERY_REQUESTED, &mddev->recovery);\n\t\tclear_bit(MD_RECOVERY_CHECK, &mddev->recovery);\n\t\tclear_bit(MD_RECOVERY_RUNNING, &mddev->recovery);\n\t\twake_up(&resync_wait);\n\t\tif (test_and_clear_bit(MD_RECOVERY_RECOVER,\n\t\t\t\t       &mddev->recovery))\n\t\t\tif (mddev->sysfs_action)\n\t\t\t\tsysfs_notify_dirent_safe(mddev->sysfs_action);\n\t} else\n\t\tmd_wakeup_thread(mddev->sync_thread);\n\tsysfs_notify_dirent_safe(mddev->sysfs_action);\n\tmd_new_event(mddev);\n}\n\n/*\n * This routine is regularly called by all per-raid-array threads to\n * deal with generic issues like resync and super-block update.\n * Raid personalities that don't have a thread (linear/raid0) do not\n * need this as they never do any recovery or update the superblock.\n *\n * It does not do any resync itself, but rather \"forks\" off other threads\n * to do that as needed.\n * When it is determined that resync is needed, we set MD_RECOVERY_RUNNING in\n * \"->recovery\" and create a thread at ->sync_thread.\n * When the thread finishes it sets MD_RECOVERY_DONE\n * and wakeups up this thread which will reap the thread and finish up.\n * This thread also removes any faulty devices (with nr_pending == 0).\n *\n * The overall approach is:\n *  1/ if the superblock needs updating, update it.\n *  2/ If a recovery thread is running, don't do anything else.\n *  3/ If recovery has finished, clean up, possibly marking spares active.\n *  4/ If there are any faulty devices, remove them.\n *  5/ If array is degraded, try to add spares devices\n *  6/ If array has spares or is not in-sync, start a resync thread.\n */\nvoid md_check_recovery(struct mddev *mddev)\n{\n\tif (test_bit(MD_ALLOW_SB_UPDATE, &mddev->flags) && mddev->sb_flags) {\n\t\t/* Write superblock - thread that called mddev_suspend()\n\t\t * holds reconfig_mutex for us.\n\t\t */\n\t\tset_bit(MD_UPDATING_SB, &mddev->flags);\n\t\tsmp_mb__after_atomic();\n\t\tif (test_bit(MD_ALLOW_SB_UPDATE, &mddev->flags))\n\t\t\tmd_update_sb(mddev, 0);\n\t\tclear_bit_unlock(MD_UPDATING_SB, &mddev->flags);\n\t\twake_up(&mddev->sb_wait);\n\t}\n\n\tif (mddev->suspended)\n\t\treturn;\n\n\tif (mddev->bitmap)\n\t\tmd_bitmap_daemon_work(mddev);\n\n\tif (signal_pending(current)) {\n\t\tif (mddev->pers->sync_request && !mddev->external) {\n\t\t\tpr_debug(\"md: %s in immediate safe mode\\n\",\n\t\t\t\t mdname(mddev));\n\t\t\tmddev->safemode = 2;\n\t\t}\n\t\tflush_signals(current);\n\t}\n\n\tif (mddev->ro && !test_bit(MD_RECOVERY_NEEDED, &mddev->recovery))\n\t\treturn;\n\tif ( ! (\n\t\t(mddev->sb_flags & ~ (1<<MD_SB_CHANGE_PENDING)) ||\n\t\ttest_bit(MD_RECOVERY_NEEDED, &mddev->recovery) ||\n\t\ttest_bit(MD_RECOVERY_DONE, &mddev->recovery) ||\n\t\t(mddev->external == 0 && mddev->safemode == 1) ||\n\t\t(mddev->safemode == 2\n\t\t && !mddev->in_sync && mddev->recovery_cp == MaxSector)\n\t\t))\n\t\treturn;\n\n\tif (mddev_trylock(mddev)) {\n\t\tint spares = 0;\n\t\tbool try_set_sync = mddev->safemode != 0;\n\n\t\tif (!mddev->external && mddev->safemode == 1)\n\t\t\tmddev->safemode = 0;\n\n\t\tif (mddev->ro) {\n\t\t\tstruct md_rdev *rdev;\n\t\t\tif (!mddev->external && mddev->in_sync)\n\t\t\t\t/* 'Blocked' flag not needed as failed devices\n\t\t\t\t * will be recorded if array switched to read/write.\n\t\t\t\t * Leaving it set will prevent the device\n\t\t\t\t * from being removed.\n\t\t\t\t */\n\t\t\t\trdev_for_each(rdev, mddev)\n\t\t\t\t\tclear_bit(Blocked, &rdev->flags);\n\t\t\t/* On a read-only array we can:\n\t\t\t * - remove failed devices\n\t\t\t * - add already-in_sync devices if the array itself\n\t\t\t *   is in-sync.\n\t\t\t * As we only add devices that are already in-sync,\n\t\t\t * we can activate the spares immediately.\n\t\t\t */\n\t\t\tremove_and_add_spares(mddev, NULL);\n\t\t\t/* There is no thread, but we need to call\n\t\t\t * ->spare_active and clear saved_raid_disk\n\t\t\t */\n\t\t\tset_bit(MD_RECOVERY_INTR, &mddev->recovery);\n\t\t\tmd_reap_sync_thread(mddev);\n\t\t\tclear_bit(MD_RECOVERY_RECOVER, &mddev->recovery);\n\t\t\tclear_bit(MD_RECOVERY_NEEDED, &mddev->recovery);\n\t\t\tclear_bit(MD_SB_CHANGE_PENDING, &mddev->sb_flags);\n\t\t\tgoto unlock;\n\t\t}\n\n\t\tif (mddev_is_clustered(mddev)) {\n\t\t\tstruct md_rdev *rdev;\n\t\t\t/* kick the device if another node issued a\n\t\t\t * remove disk.\n\t\t\t */\n\t\t\trdev_for_each(rdev, mddev) {\n\t\t\t\tif (test_and_clear_bit(ClusterRemove, &rdev->flags) &&\n\t\t\t\t\t\trdev->raid_disk < 0)\n\t\t\t\t\tmd_kick_rdev_from_array(rdev);\n\t\t\t}\n\t\t}\n\n\t\tif (try_set_sync && !mddev->external && !mddev->in_sync) {\n\t\t\tspin_lock(&mddev->lock);\n\t\t\tset_in_sync(mddev);\n\t\t\tspin_unlock(&mddev->lock);\n\t\t}\n\n\t\tif (mddev->sb_flags)\n\t\t\tmd_update_sb(mddev, 0);\n\n\t\tif (test_bit(MD_RECOVERY_RUNNING, &mddev->recovery) &&\n\t\t    !test_bit(MD_RECOVERY_DONE, &mddev->recovery)) {\n\t\t\t/* resync/recovery still happening */\n\t\t\tclear_bit(MD_RECOVERY_NEEDED, &mddev->recovery);\n\t\t\tgoto unlock;\n\t\t}\n\t\tif (mddev->sync_thread) {\n\t\t\tmd_reap_sync_thread(mddev);\n\t\t\tgoto unlock;\n\t\t}\n\t\t/* Set RUNNING before clearing NEEDED to avoid\n\t\t * any transients in the value of \"sync_action\".\n\t\t */\n\t\tmddev->curr_resync_completed = 0;\n\t\tspin_lock(&mddev->lock);\n\t\tset_bit(MD_RECOVERY_RUNNING, &mddev->recovery);\n\t\tspin_unlock(&mddev->lock);\n\t\t/* Clear some bits that don't mean anything, but\n\t\t * might be left set\n\t\t */\n\t\tclear_bit(MD_RECOVERY_INTR, &mddev->recovery);\n\t\tclear_bit(MD_RECOVERY_DONE, &mddev->recovery);\n\n\t\tif (!test_and_clear_bit(MD_RECOVERY_NEEDED, &mddev->recovery) ||\n\t\t    test_bit(MD_RECOVERY_FROZEN, &mddev->recovery))\n\t\t\tgoto not_running;\n\t\t/* no recovery is running.\n\t\t * remove any failed drives, then\n\t\t * add spares if possible.\n\t\t * Spares are also removed and re-added, to allow\n\t\t * the personality to fail the re-add.\n\t\t */\n\n\t\tif (mddev->reshape_position != MaxSector) {\n\t\t\tif (mddev->pers->check_reshape == NULL ||\n\t\t\t    mddev->pers->check_reshape(mddev) != 0)\n\t\t\t\t/* Cannot proceed */\n\t\t\t\tgoto not_running;\n\t\t\tset_bit(MD_RECOVERY_RESHAPE, &mddev->recovery);\n\t\t\tclear_bit(MD_RECOVERY_RECOVER, &mddev->recovery);\n\t\t} else if ((spares = remove_and_add_spares(mddev, NULL))) {\n\t\t\tclear_bit(MD_RECOVERY_SYNC, &mddev->recovery);\n\t\t\tclear_bit(MD_RECOVERY_CHECK, &mddev->recovery);\n\t\t\tclear_bit(MD_RECOVERY_REQUESTED, &mddev->recovery);\n\t\t\tset_bit(MD_RECOVERY_RECOVER, &mddev->recovery);\n\t\t} else if (mddev->recovery_cp < MaxSector) {\n\t\t\tset_bit(MD_RECOVERY_SYNC, &mddev->recovery);\n\t\t\tclear_bit(MD_RECOVERY_RECOVER, &mddev->recovery);\n\t\t} else if (!test_bit(MD_RECOVERY_SYNC, &mddev->recovery))\n\t\t\t/* nothing to be done ... */\n\t\t\tgoto not_running;\n\n\t\tif (mddev->pers->sync_request) {\n\t\t\tif (spares) {\n\t\t\t\t/* We are adding a device or devices to an array\n\t\t\t\t * which has the bitmap stored on all devices.\n\t\t\t\t * So make sure all bitmap pages get written\n\t\t\t\t */\n\t\t\t\tmd_bitmap_write_all(mddev->bitmap);\n\t\t\t}\n\t\t\tINIT_WORK(&mddev->del_work, md_start_sync);\n\t\t\tqueue_work(md_misc_wq, &mddev->del_work);\n\t\t\tgoto unlock;\n\t\t}\n\tnot_running:\n\t\tif (!mddev->sync_thread) {\n\t\t\tclear_bit(MD_RECOVERY_RUNNING, &mddev->recovery);\n\t\t\twake_up(&resync_wait);\n\t\t\tif (test_and_clear_bit(MD_RECOVERY_RECOVER,\n\t\t\t\t\t       &mddev->recovery))\n\t\t\t\tif (mddev->sysfs_action)\n\t\t\t\t\tsysfs_notify_dirent_safe(mddev->sysfs_action);\n\t\t}\n\tunlock:\n\t\twake_up(&mddev->sb_wait);\n\t\tmddev_unlock(mddev);\n\t}\n}\nEXPORT_SYMBOL(md_check_recovery);\n\nvoid md_reap_sync_thread(struct mddev *mddev)\n{\n\tstruct md_rdev *rdev;\n\tsector_t old_dev_sectors = mddev->dev_sectors;\n\tbool is_reshaped = false;\n\n\t/* resync has finished, collect result */\n\tmd_unregister_thread(&mddev->sync_thread);\n\tif (!test_bit(MD_RECOVERY_INTR, &mddev->recovery) &&\n\t    !test_bit(MD_RECOVERY_REQUESTED, &mddev->recovery) &&\n\t    mddev->degraded != mddev->raid_disks) {\n\t\t/* success...*/\n\t\t/* activate any spares */\n\t\tif (mddev->pers->spare_active(mddev)) {\n\t\t\tsysfs_notify_dirent_safe(mddev->sysfs_degraded);\n\t\t\tset_bit(MD_SB_CHANGE_DEVS, &mddev->sb_flags);\n\t\t}\n\t}\n\tif (test_bit(MD_RECOVERY_RESHAPE, &mddev->recovery) &&\n\t    mddev->pers->finish_reshape) {\n\t\tmddev->pers->finish_reshape(mddev);\n\t\tif (mddev_is_clustered(mddev))\n\t\t\tis_reshaped = true;\n\t}\n\n\t/* If array is no-longer degraded, then any saved_raid_disk\n\t * information must be scrapped.\n\t */\n\tif (!mddev->degraded)\n\t\trdev_for_each(rdev, mddev)\n\t\t\trdev->saved_raid_disk = -1;\n\n\tmd_update_sb(mddev, 1);\n\t/* MD_SB_CHANGE_PENDING should be cleared by md_update_sb, so we can\n\t * call resync_finish here if MD_CLUSTER_RESYNC_LOCKED is set by\n\t * clustered raid */\n\tif (test_and_clear_bit(MD_CLUSTER_RESYNC_LOCKED, &mddev->flags))\n\t\tmd_cluster_ops->resync_finish(mddev);\n\tclear_bit(MD_RECOVERY_RUNNING, &mddev->recovery);\n\tclear_bit(MD_RECOVERY_DONE, &mddev->recovery);\n\tclear_bit(MD_RECOVERY_SYNC, &mddev->recovery);\n\tclear_bit(MD_RECOVERY_RESHAPE, &mddev->recovery);\n\tclear_bit(MD_RECOVERY_REQUESTED, &mddev->recovery);\n\tclear_bit(MD_RECOVERY_CHECK, &mddev->recovery);\n\t/*\n\t * We call md_cluster_ops->update_size here because sync_size could\n\t * be changed by md_update_sb, and MD_RECOVERY_RESHAPE is cleared,\n\t * so it is time to update size across cluster.\n\t */\n\tif (mddev_is_clustered(mddev) && is_reshaped\n\t\t\t\t      && !test_bit(MD_CLOSING, &mddev->flags))\n\t\tmd_cluster_ops->update_size(mddev, old_dev_sectors);\n\twake_up(&resync_wait);\n\t/* flag recovery needed just to double check */\n\tset_bit(MD_RECOVERY_NEEDED, &mddev->recovery);\n\tsysfs_notify_dirent_safe(mddev->sysfs_action);\n\tmd_new_event(mddev);\n\tif (mddev->event_work.func)\n\t\tqueue_work(md_misc_wq, &mddev->event_work);\n}\nEXPORT_SYMBOL(md_reap_sync_thread);\n\nvoid md_wait_for_blocked_rdev(struct md_rdev *rdev, struct mddev *mddev)\n{\n\tsysfs_notify_dirent_safe(rdev->sysfs_state);\n\twait_event_timeout(rdev->blocked_wait,\n\t\t\t   !test_bit(Blocked, &rdev->flags) &&\n\t\t\t   !test_bit(BlockedBadBlocks, &rdev->flags),\n\t\t\t   msecs_to_jiffies(5000));\n\trdev_dec_pending(rdev, mddev);\n}\nEXPORT_SYMBOL(md_wait_for_blocked_rdev);\n\nvoid md_finish_reshape(struct mddev *mddev)\n{\n\t/* called be personality module when reshape completes. */\n\tstruct md_rdev *rdev;\n\n\trdev_for_each(rdev, mddev) {\n\t\tif (rdev->data_offset > rdev->new_data_offset)\n\t\t\trdev->sectors += rdev->data_offset - rdev->new_data_offset;\n\t\telse\n\t\t\trdev->sectors -= rdev->new_data_offset - rdev->data_offset;\n\t\trdev->data_offset = rdev->new_data_offset;\n\t}\n}\nEXPORT_SYMBOL(md_finish_reshape);\n\n/* Bad block management */\n\n/* Returns 1 on success, 0 on failure */\nint rdev_set_badblocks(struct md_rdev *rdev, sector_t s, int sectors,\n\t\t       int is_new)\n{\n\tstruct mddev *mddev = rdev->mddev;\n\tint rv;\n\tif (is_new)\n\t\ts += rdev->new_data_offset;\n\telse\n\t\ts += rdev->data_offset;\n\trv = badblocks_set(&rdev->badblocks, s, sectors, 0);\n\tif (rv == 0) {\n\t\t/* Make sure they get written out promptly */\n\t\tif (test_bit(ExternalBbl, &rdev->flags))\n\t\t\tsysfs_notify_dirent_safe(rdev->sysfs_unack_badblocks);\n\t\tsysfs_notify_dirent_safe(rdev->sysfs_state);\n\t\tset_mask_bits(&mddev->sb_flags, 0,\n\t\t\t      BIT(MD_SB_CHANGE_CLEAN) | BIT(MD_SB_CHANGE_PENDING));\n\t\tmd_wakeup_thread(rdev->mddev->thread);\n\t\treturn 1;\n\t} else\n\t\treturn 0;\n}\nEXPORT_SYMBOL_GPL(rdev_set_badblocks);\n\nint rdev_clear_badblocks(struct md_rdev *rdev, sector_t s, int sectors,\n\t\t\t int is_new)\n{\n\tint rv;\n\tif (is_new)\n\t\ts += rdev->new_data_offset;\n\telse\n\t\ts += rdev->data_offset;\n\trv = badblocks_clear(&rdev->badblocks, s, sectors);\n\tif ((rv == 0) && test_bit(ExternalBbl, &rdev->flags))\n\t\tsysfs_notify_dirent_safe(rdev->sysfs_badblocks);\n\treturn rv;\n}\nEXPORT_SYMBOL_GPL(rdev_clear_badblocks);\n\nstatic int md_notify_reboot(struct notifier_block *this,\n\t\t\t    unsigned long code, void *x)\n{\n\tstruct list_head *tmp;\n\tstruct mddev *mddev;\n\tint need_delay = 0;\n\n\tfor_each_mddev(mddev, tmp) {\n\t\tif (mddev_trylock(mddev)) {\n\t\t\tif (mddev->pers)\n\t\t\t\t__md_stop_writes(mddev);\n\t\t\tif (mddev->persistent)\n\t\t\t\tmddev->safemode = 2;\n\t\t\tmddev_unlock(mddev);\n\t\t}\n\t\tneed_delay = 1;\n\t}\n\t/*\n\t * certain more exotic SCSI devices are known to be\n\t * volatile wrt too early system reboots. While the\n\t * right place to handle this issue is the given\n\t * driver, we do want to have a safe RAID driver ...\n\t */\n\tif (need_delay)\n\t\tmdelay(1000*1);\n\n\treturn NOTIFY_DONE;\n}\n\nstatic struct notifier_block md_notifier = {\n\t.notifier_call\t= md_notify_reboot,\n\t.next\t\t= NULL,\n\t.priority\t= INT_MAX, /* before any real devices */\n};\n\nstatic void md_geninit(void)\n{\n\tpr_debug(\"md: sizeof(mdp_super_t) = %d\\n\", (int)sizeof(mdp_super_t));\n\n\tproc_create(\"mdstat\", S_IRUGO, NULL, &mdstat_proc_ops);\n}\n\nstatic int __init md_init(void)\n{\n\tint ret = -ENOMEM;\n\n\tmd_wq = alloc_workqueue(\"md\", WQ_MEM_RECLAIM, 0);\n\tif (!md_wq)\n\t\tgoto err_wq;\n\n\tmd_misc_wq = alloc_workqueue(\"md_misc\", 0, 0);\n\tif (!md_misc_wq)\n\t\tgoto err_misc_wq;\n\n\tmd_rdev_misc_wq = alloc_workqueue(\"md_rdev_misc\", 0, 0);\n\tif (!md_rdev_misc_wq)\n\t\tgoto err_rdev_misc_wq;\n\n\tret = __register_blkdev(MD_MAJOR, \"md\", md_probe);\n\tif (ret < 0)\n\t\tgoto err_md;\n\n\tret = __register_blkdev(0, \"mdp\", md_probe);\n\tif (ret < 0)\n\t\tgoto err_mdp;\n\tmdp_major = ret;\n\n\tregister_reboot_notifier(&md_notifier);\n\traid_table_header = register_sysctl_table(raid_root_table);\n\n\tmd_geninit();\n\treturn 0;\n\nerr_mdp:\n\tunregister_blkdev(MD_MAJOR, \"md\");\nerr_md:\n\tdestroy_workqueue(md_rdev_misc_wq);\nerr_rdev_misc_wq:\n\tdestroy_workqueue(md_misc_wq);\nerr_misc_wq:\n\tdestroy_workqueue(md_wq);\nerr_wq:\n\treturn ret;\n}\n\nstatic void check_sb_changes(struct mddev *mddev, struct md_rdev *rdev)\n{\n\tstruct mdp_superblock_1 *sb = page_address(rdev->sb_page);\n\tstruct md_rdev *rdev2;\n\tint role, ret;\n\tchar b[BDEVNAME_SIZE];\n\n\t/*\n\t * If size is changed in another node then we need to\n\t * do resize as well.\n\t */\n\tif (mddev->dev_sectors != le64_to_cpu(sb->size)) {\n\t\tret = mddev->pers->resize(mddev, le64_to_cpu(sb->size));\n\t\tif (ret)\n\t\t\tpr_info(\"md-cluster: resize failed\\n\");\n\t\telse\n\t\t\tmd_bitmap_update_sb(mddev->bitmap);\n\t}\n\n\t/* Check for change of roles in the active devices */\n\trdev_for_each(rdev2, mddev) {\n\t\tif (test_bit(Faulty, &rdev2->flags))\n\t\t\tcontinue;\n\n\t\t/* Check if the roles changed */\n\t\trole = le16_to_cpu(sb->dev_roles[rdev2->desc_nr]);\n\n\t\tif (test_bit(Candidate, &rdev2->flags)) {\n\t\t\tif (role == 0xfffe) {\n\t\t\t\tpr_info(\"md: Removing Candidate device %s because add failed\\n\", bdevname(rdev2->bdev,b));\n\t\t\t\tmd_kick_rdev_from_array(rdev2);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\telse\n\t\t\t\tclear_bit(Candidate, &rdev2->flags);\n\t\t}\n\n\t\tif (role != rdev2->raid_disk) {\n\t\t\t/*\n\t\t\t * got activated except reshape is happening.\n\t\t\t */\n\t\t\tif (rdev2->raid_disk == -1 && role != 0xffff &&\n\t\t\t    !(le32_to_cpu(sb->feature_map) &\n\t\t\t      MD_FEATURE_RESHAPE_ACTIVE)) {\n\t\t\t\trdev2->saved_raid_disk = role;\n\t\t\t\tret = remove_and_add_spares(mddev, rdev2);\n\t\t\t\tpr_info(\"Activated spare: %s\\n\",\n\t\t\t\t\tbdevname(rdev2->bdev,b));\n\t\t\t\t/* wakeup mddev->thread here, so array could\n\t\t\t\t * perform resync with the new activated disk */\n\t\t\t\tset_bit(MD_RECOVERY_NEEDED, &mddev->recovery);\n\t\t\t\tmd_wakeup_thread(mddev->thread);\n\t\t\t}\n\t\t\t/* device faulty\n\t\t\t * We just want to do the minimum to mark the disk\n\t\t\t * as faulty. The recovery is performed by the\n\t\t\t * one who initiated the error.\n\t\t\t */\n\t\t\tif ((role == 0xfffe) || (role == 0xfffd)) {\n\t\t\t\tmd_error(mddev, rdev2);\n\t\t\t\tclear_bit(Blocked, &rdev2->flags);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (mddev->raid_disks != le32_to_cpu(sb->raid_disks))\n\t\tupdate_raid_disks(mddev, le32_to_cpu(sb->raid_disks));\n\n\t/*\n\t * Since mddev->delta_disks has already updated in update_raid_disks,\n\t * so it is time to check reshape.\n\t */\n\tif (test_bit(MD_RESYNCING_REMOTE, &mddev->recovery) &&\n\t    (le32_to_cpu(sb->feature_map) & MD_FEATURE_RESHAPE_ACTIVE)) {\n\t\t/*\n\t\t * reshape is happening in the remote node, we need to\n\t\t * update reshape_position and call start_reshape.\n\t\t */\n\t\tmddev->reshape_position = le64_to_cpu(sb->reshape_position);\n\t\tif (mddev->pers->update_reshape_pos)\n\t\t\tmddev->pers->update_reshape_pos(mddev);\n\t\tif (mddev->pers->start_reshape)\n\t\t\tmddev->pers->start_reshape(mddev);\n\t} else if (test_bit(MD_RESYNCING_REMOTE, &mddev->recovery) &&\n\t\t   mddev->reshape_position != MaxSector &&\n\t\t   !(le32_to_cpu(sb->feature_map) & MD_FEATURE_RESHAPE_ACTIVE)) {\n\t\t/* reshape is just done in another node. */\n\t\tmddev->reshape_position = MaxSector;\n\t\tif (mddev->pers->update_reshape_pos)\n\t\t\tmddev->pers->update_reshape_pos(mddev);\n\t}\n\n\t/* Finally set the event to be up to date */\n\tmddev->events = le64_to_cpu(sb->events);\n}\n\nstatic int read_rdev(struct mddev *mddev, struct md_rdev *rdev)\n{\n\tint err;\n\tstruct page *swapout = rdev->sb_page;\n\tstruct mdp_superblock_1 *sb;\n\n\t/* Store the sb page of the rdev in the swapout temporary\n\t * variable in case we err in the future\n\t */\n\trdev->sb_page = NULL;\n\terr = alloc_disk_sb(rdev);\n\tif (err == 0) {\n\t\tClearPageUptodate(rdev->sb_page);\n\t\trdev->sb_loaded = 0;\n\t\terr = super_types[mddev->major_version].\n\t\t\tload_super(rdev, NULL, mddev->minor_version);\n\t}\n\tif (err < 0) {\n\t\tpr_warn(\"%s: %d Could not reload rdev(%d) err: %d. Restoring old values\\n\",\n\t\t\t\t__func__, __LINE__, rdev->desc_nr, err);\n\t\tif (rdev->sb_page)\n\t\t\tput_page(rdev->sb_page);\n\t\trdev->sb_page = swapout;\n\t\trdev->sb_loaded = 1;\n\t\treturn err;\n\t}\n\n\tsb = page_address(rdev->sb_page);\n\t/* Read the offset unconditionally, even if MD_FEATURE_RECOVERY_OFFSET\n\t * is not set\n\t */\n\n\tif ((le32_to_cpu(sb->feature_map) & MD_FEATURE_RECOVERY_OFFSET))\n\t\trdev->recovery_offset = le64_to_cpu(sb->recovery_offset);\n\n\t/* The other node finished recovery, call spare_active to set\n\t * device In_sync and mddev->degraded\n\t */\n\tif (rdev->recovery_offset == MaxSector &&\n\t    !test_bit(In_sync, &rdev->flags) &&\n\t    mddev->pers->spare_active(mddev))\n\t\tsysfs_notify_dirent_safe(mddev->sysfs_degraded);\n\n\tput_page(swapout);\n\treturn 0;\n}\n\nvoid md_reload_sb(struct mddev *mddev, int nr)\n{\n\tstruct md_rdev *rdev;\n\tint err;\n\n\t/* Find the rdev */\n\trdev_for_each_rcu(rdev, mddev) {\n\t\tif (rdev->desc_nr == nr)\n\t\t\tbreak;\n\t}\n\n\tif (!rdev || rdev->desc_nr != nr) {\n\t\tpr_warn(\"%s: %d Could not find rdev with nr %d\\n\", __func__, __LINE__, nr);\n\t\treturn;\n\t}\n\n\terr = read_rdev(mddev, rdev);\n\tif (err < 0)\n\t\treturn;\n\n\tcheck_sb_changes(mddev, rdev);\n\n\t/* Read all rdev's to update recovery_offset */\n\trdev_for_each_rcu(rdev, mddev) {\n\t\tif (!test_bit(Faulty, &rdev->flags))\n\t\t\tread_rdev(mddev, rdev);\n\t}\n}\nEXPORT_SYMBOL(md_reload_sb);\n\n#ifndef MODULE\n\n/*\n * Searches all registered partitions for autorun RAID arrays\n * at boot time.\n */\n\nstatic DEFINE_MUTEX(detected_devices_mutex);\nstatic LIST_HEAD(all_detected_devices);\nstruct detected_devices_node {\n\tstruct list_head list;\n\tdev_t dev;\n};\n\nvoid md_autodetect_dev(dev_t dev)\n{\n\tstruct detected_devices_node *node_detected_dev;\n\n\tnode_detected_dev = kzalloc(sizeof(*node_detected_dev), GFP_KERNEL);\n\tif (node_detected_dev) {\n\t\tnode_detected_dev->dev = dev;\n\t\tmutex_lock(&detected_devices_mutex);\n\t\tlist_add_tail(&node_detected_dev->list, &all_detected_devices);\n\t\tmutex_unlock(&detected_devices_mutex);\n\t}\n}\n\nvoid md_autostart_arrays(int part)\n{\n\tstruct md_rdev *rdev;\n\tstruct detected_devices_node *node_detected_dev;\n\tdev_t dev;\n\tint i_scanned, i_passed;\n\n\ti_scanned = 0;\n\ti_passed = 0;\n\n\tpr_info(\"md: Autodetecting RAID arrays.\\n\");\n\n\tmutex_lock(&detected_devices_mutex);\n\twhile (!list_empty(&all_detected_devices) && i_scanned < INT_MAX) {\n\t\ti_scanned++;\n\t\tnode_detected_dev = list_entry(all_detected_devices.next,\n\t\t\t\t\tstruct detected_devices_node, list);\n\t\tlist_del(&node_detected_dev->list);\n\t\tdev = node_detected_dev->dev;\n\t\tkfree(node_detected_dev);\n\t\tmutex_unlock(&detected_devices_mutex);\n\t\trdev = md_import_device(dev,0, 90);\n\t\tmutex_lock(&detected_devices_mutex);\n\t\tif (IS_ERR(rdev))\n\t\t\tcontinue;\n\n\t\tif (test_bit(Faulty, &rdev->flags))\n\t\t\tcontinue;\n\n\t\tset_bit(AutoDetected, &rdev->flags);\n\t\tlist_add(&rdev->same_set, &pending_raid_disks);\n\t\ti_passed++;\n\t}\n\tmutex_unlock(&detected_devices_mutex);\n\n\tpr_debug(\"md: Scanned %d and added %d devices.\\n\", i_scanned, i_passed);\n\n\tautorun_devices(part);\n}\n\n#endif /* !MODULE */\n\nstatic __exit void md_exit(void)\n{\n\tstruct mddev *mddev;\n\tstruct list_head *tmp;\n\tint delay = 1;\n\n\tunregister_blkdev(MD_MAJOR,\"md\");\n\tunregister_blkdev(mdp_major, \"mdp\");\n\tunregister_reboot_notifier(&md_notifier);\n\tunregister_sysctl_table(raid_table_header);\n\n\t/* We cannot unload the modules while some process is\n\t * waiting for us in select() or poll() - wake them up\n\t */\n\tmd_unloading = 1;\n\twhile (waitqueue_active(&md_event_waiters)) {\n\t\t/* not safe to leave yet */\n\t\twake_up(&md_event_waiters);\n\t\tmsleep(delay);\n\t\tdelay += delay;\n\t}\n\tremove_proc_entry(\"mdstat\", NULL);\n\n\tfor_each_mddev(mddev, tmp) {\n\t\texport_array(mddev);\n\t\tmddev->ctime = 0;\n\t\tmddev->hold_active = 0;\n\t\t/*\n\t\t * for_each_mddev() will call mddev_put() at the end of each\n\t\t * iteration.  As the mddev is now fully clear, this will\n\t\t * schedule the mddev for destruction by a workqueue, and the\n\t\t * destroy_workqueue() below will wait for that to complete.\n\t\t */\n\t}\n\tdestroy_workqueue(md_rdev_misc_wq);\n\tdestroy_workqueue(md_misc_wq);\n\tdestroy_workqueue(md_wq);\n}\n\nsubsys_initcall(md_init);\nmodule_exit(md_exit)\n\nstatic int get_ro(char *buffer, const struct kernel_param *kp)\n{\n\treturn sprintf(buffer, \"%d\\n\", start_readonly);\n}\nstatic int set_ro(const char *val, const struct kernel_param *kp)\n{\n\treturn kstrtouint(val, 10, (unsigned int *)&start_readonly);\n}\n\nmodule_param_call(start_ro, set_ro, get_ro, NULL, S_IRUSR|S_IWUSR);\nmodule_param(start_dirty_degraded, int, S_IRUGO|S_IWUSR);\nmodule_param_call(new_array, add_named_array, NULL, NULL, S_IWUSR);\nmodule_param(create_on_open, bool, S_IRUSR|S_IWUSR);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"MD RAID framework\");\nMODULE_ALIAS(\"md\");\nMODULE_ALIAS_BLOCKDEV_MAJOR(MD_MAJOR);\n"}}, "reports": [{"events": [{"location": {"col": 1, "file": 0, "line": 6255}, "message": "WARNING: Assignment of 0/1 to bool variable"}], "macros": [], "notes": [], "path": "/src/drivers/md/md.c", "reportHash": "b252fa079c79b8d84d4f1dbbdc9a1664", "checkerName": "coccinelle", "reviewStatus": null, "severity": "UNSPECIFIED"}]};
      window.onload = function() {
        if (!browserCompatible) {
          setNonCompatibleBrowserMessage();
        } else {
          BugViewer.init(data.files, data.reports);
          BugViewer.create();
          BugViewer.initByUrl();
        }
      };
    </script>
  </head>
  <body>
  <div class="container">
    <div id="content">
      <div id="side-bar">
        <div class="header">
          <a href="index.html" class="button">&#8249; Return to List</a>
        </div>
        <div id="report-nav">
          <div class="header">Reports</div>
        </div>
      </div>
      <div id="editor-wrapper">
        <div class="header">
          <div id="file">
            <span class="label">File:</span>
            <span id="file-path"></span>
          </div>
          <div id="checker">
            <span class="label">Checker name:</span>
            <span id="checker-name"></span>
          </div>
          <div id="review-status-wrapper">
            <span class="label">Review status:</span>
            <span id="review-status"></span>
          </div>
        </div>
        <div id="editor"></div>
      </div>
    </div>
  </div>
  </body>
</html>
