<!DOCTYPE html>
<html>
  <head>
    <title>Plist HTML Viewer</title>

    <meta charset="UTF-8">

    <style type="text/css">
      .CodeMirror{font-family:monospace;height:300px;color:#000;direction:ltr}.CodeMirror-lines{padding:4px 0}.CodeMirror pre{padding:0 4px}.CodeMirror-gutter-filler,.CodeMirror-scrollbar-filler{background-color:#fff}.CodeMirror-gutters{border-right:1px solid #ddd;background-color:#f7f7f7;white-space:nowrap}.CodeMirror-linenumber{padding:0 3px 0 5px;min-width:20px;text-align:right;color:#999;white-space:nowrap}.CodeMirror-guttermarker{color:#000}.CodeMirror-guttermarker-subtle{color:#999}.CodeMirror-cursor{border-left:1px solid #000;border-right:none;width:0}.CodeMirror div.CodeMirror-secondarycursor{border-left:1px solid silver}.cm-fat-cursor .CodeMirror-cursor{width:auto;border:0!important;background:#7e7}.cm-fat-cursor div.CodeMirror-cursors{z-index:1}.cm-animate-fat-cursor{width:auto;border:0;-webkit-animation:blink 1.06s steps(1) infinite;-moz-animation:blink 1.06s steps(1) infinite;animation:blink 1.06s steps(1) infinite;background-color:#7e7}@-moz-keyframes blink{50%{background-color:transparent}}@-webkit-keyframes blink{50%{background-color:transparent}}@keyframes blink{50%{background-color:transparent}}.cm-tab{display:inline-block;text-decoration:inherit}.CodeMirror-rulers{position:absolute;left:0;right:0;top:-50px;bottom:-20px;overflow:hidden}.CodeMirror-ruler{border-left:1px solid #ccc;top:0;bottom:0;position:absolute}.cm-s-default .cm-header{color:#00f}.cm-s-default .cm-quote{color:#090}.cm-negative{color:#d44}.cm-positive{color:#292}.cm-header,.cm-strong{font-weight:700}.cm-em{font-style:italic}.cm-link{text-decoration:underline}.cm-strikethrough{text-decoration:line-through}.cm-s-default .cm-keyword{color:#708}.cm-s-default .cm-atom{color:#219}.cm-s-default .cm-number{color:#164}.cm-s-default .cm-def{color:#00f}.cm-s-default .cm-variable-2{color:#05a}.cm-s-default .cm-type,.cm-s-default .cm-variable-3{color:#085}.cm-s-default .cm-comment{color:#a50}.cm-s-default .cm-string{color:#a11}.cm-s-default .cm-string-2{color:#f50}.cm-s-default .cm-meta{color:#555}.cm-s-default .cm-qualifier{color:#555}.cm-s-default .cm-builtin{color:#30a}.cm-s-default .cm-bracket{color:#997}.cm-s-default .cm-tag{color:#170}.cm-s-default .cm-attribute{color:#00c}.cm-s-default .cm-hr{color:#999}.cm-s-default .cm-link{color:#00c}.cm-s-default .cm-error{color:red}.cm-invalidchar{color:red}.CodeMirror-composing{border-bottom:2px solid}div.CodeMirror span.CodeMirror-matchingbracket{color:#0f0}div.CodeMirror span.CodeMirror-nonmatchingbracket{color:#f22}.CodeMirror-matchingtag{background:rgba(255,150,0,.3)}.CodeMirror-activeline-background{background:#e8f2ff}.CodeMirror{position:relative;overflow:hidden;background:#fff}.CodeMirror-scroll{overflow:scroll!important;margin-bottom:-30px;margin-right:-30px;padding-bottom:30px;height:100%;outline:0;position:relative}.CodeMirror-sizer{position:relative;border-right:30px solid transparent}.CodeMirror-gutter-filler,.CodeMirror-hscrollbar,.CodeMirror-scrollbar-filler,.CodeMirror-vscrollbar{position:absolute;z-index:6;display:none}.CodeMirror-vscrollbar{right:0;top:0;overflow-x:hidden;overflow-y:scroll}.CodeMirror-hscrollbar{bottom:0;left:0;overflow-y:hidden;overflow-x:scroll}.CodeMirror-scrollbar-filler{right:0;bottom:0}.CodeMirror-gutter-filler{left:0;bottom:0}.CodeMirror-gutters{position:absolute;left:0;top:0;min-height:100%;z-index:3}.CodeMirror-gutter{white-space:normal;height:100%;display:inline-block;vertical-align:top;margin-bottom:-30px}.CodeMirror-gutter-wrapper{position:absolute;z-index:4;background:0 0!important;border:none!important}.CodeMirror-gutter-background{position:absolute;top:0;bottom:0;z-index:4}.CodeMirror-gutter-elt{position:absolute;cursor:default;z-index:4}.CodeMirror-gutter-wrapper ::selection{background-color:transparent}.CodeMirror-gutter-wrapper ::-moz-selection{background-color:transparent}.CodeMirror-lines{cursor:text;min-height:1px}.CodeMirror pre{-moz-border-radius:0;-webkit-border-radius:0;border-radius:0;border-width:0;background:0 0;font-family:inherit;font-size:inherit;margin:0;white-space:pre;word-wrap:normal;line-height:inherit;color:inherit;z-index:2;position:relative;overflow:visible;-webkit-tap-highlight-color:transparent;-webkit-font-variant-ligatures:contextual;font-variant-ligatures:contextual}.CodeMirror-wrap pre{word-wrap:break-word;white-space:pre-wrap;word-break:normal}.CodeMirror-linebackground{position:absolute;left:0;right:0;top:0;bottom:0;z-index:0}.CodeMirror-linewidget{position:relative;z-index:2;overflow:auto}.CodeMirror-rtl pre{direction:rtl}.CodeMirror-code{outline:0}.CodeMirror-gutter,.CodeMirror-gutters,.CodeMirror-linenumber,.CodeMirror-scroll,.CodeMirror-sizer{-moz-box-sizing:content-box;box-sizing:content-box}.CodeMirror-measure{position:absolute;width:100%;height:0;overflow:hidden;visibility:hidden}.CodeMirror-cursor{position:absolute;pointer-events:none}.CodeMirror-measure pre{position:static}div.CodeMirror-cursors{visibility:hidden;position:relative;z-index:3}div.CodeMirror-dragcursors{visibility:visible}.CodeMirror-focused div.CodeMirror-cursors{visibility:visible}.CodeMirror-selected{background:#d9d9d9}.CodeMirror-focused .CodeMirror-selected{background:#d7d4f0}.CodeMirror-crosshair{cursor:crosshair}.CodeMirror-line::selection,.CodeMirror-line>span::selection,.CodeMirror-line>span>span::selection{background:#d7d4f0}.CodeMirror-line::-moz-selection,.CodeMirror-line>span::-moz-selection,.CodeMirror-line>span>span::-moz-selection{background:#d7d4f0}.cm-searching{background-color:#ffa;background-color:rgba(255,255,0,.4)}.cm-force-border{padding-right:.1px}@media print{.CodeMirror div.CodeMirror-cursors{visibility:hidden}}.cm-tab-wrap-hack:after{content:''}span.CodeMirror-selectedtext{background:0 0}
/*# sourceMappingURL=codemirror.min.css.map */

      .severity-low {
  background-color: #669603;
}

.severity-low:after {
  content : 'L';
}

.severity-unspecified {
  background-color: #666666;
}

.severity-unspecified:after {
  content : 'U';
}

.severity-style {
  background-color: #9932cc;
}

.severity-style:after {
  content : 'S';
}

.severity-medium {
  background-color: #a9d323;
  color: black;
}

.severity-medium:after {
  content : 'M';
}

.severity-high {
  background-color: #ffa800;
}

.severity-high:after {
  content : 'H';
}

.severity-critical {
  background-color: #e92625;
}

.severity-critical:after {
  content : 'C';
}

i[class*="severity-"] {
  line-height: normal;
  text-transform: capitalize;
  font-size: 0.8em;
  font-weight: bold;
  color: white;
  display: inline-block;
  width: 16px;
  height: 16px;
  text-align: center;
  font-family: sans-serif;
}

      html, body {
  width: 100%;
  height: 100%;
  padding: 0px;
  margin: 0px;
}

div.container {
  padding: 10px;
}

#content {
  height: 100%;
  display: block;
  overflow: hidden;
}

#content > div {
  margin: 10px;
  overflow: hidden;
  border: 1px solid #ddd;
  border-radius: 3px;
  overflow: hidden;
  height: 97%;
}

.button {
  background-color: #f1f1f1;
  text-decoration: none;
  display: inline-block;
  padding: 8px 16px;
  color: black;
  cursor: pointer;
}

.button:hover {
  background-color: #ddd;
  color: black;
}

.review-status {
  color: white;
  text-align: center;
}

.review-status-confirmed {
  background-color: #e92625;
}

.review-status-false-positive {
  background-color: grey;
}

.review-status-intentional {
  background-color: #669603;
}

      div.container {
  width: 100%;
  height: 100%;
  padding: 0px;
}

#editor-wrapper {
  margin: 10px;
}

#side-bar {
  float: left;
  width: 260px;
  margin: 0px;
}

#report-nav ul {
  list-style-type: none;
  padding: 0;
  margin: 0;
  overflow-y: auto;
  height: 100%;
}

#report-nav ul > li {
  padding: .4em;
  background-color: #fff;
  border-bottom: 1px solid rgba(0,0,0,.125);
  text-align: left;
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

#report-nav ul > li.active {
  background-color: #427ea9;
  color: white;
}

#report-nav ul > li:hover {
  background-color: #427ea9;
  color: white;
  cursor: pointer;
}

#report-nav ul a {
  text-decoration: none;
}

#report-nav i[class*="severity-"] {
  margin-right: 5px;
}

.header {
  border-bottom: 1px solid lightgrey;
  font-family: monospace;
  padding: 10px;
  background-color: #fafbfc;
  border-bottom: 1px solid #e1e4e8;
  border-top-left-radius: 2px;
  border-top-right-radius: 2px;
}

#report-nav .header {
  font-weight: bold;
}

#editor-wrapper .header > div {
  padding-top: 2px;
}

#file-path,
#checker-name {
  color: #195ea2;
}

#review-status {
  padding: 0px 5px;
}

#file-path {
  font-family: monospace;
}

.check-msg {
  display: inline-block;
  padding: 3px 6px;
  margin: 1px;
  -webkit-border-radius: 5px;
  -moz-border-radius: 5px;
  border-radius: 5px;
}

.check-msg.info {
  color: #00546f;
  background-color: #bfdfe9;
  border: 1px solid #87a8b3;
}

.check-msg.error {
  background-color: #f2dede;
  color: #a94442;
  border: 1px solid #ebcccc;
}

.check-msg.macro {
  background-color: #d7dac2;
  color: #4f5c6d;
  border: 1px solid #d7dac2;
}

.check-msg.note {
  background-color: #d7d7d7;
  color: #4f5c6d;
  border: 1px solid #bfbfbf;
}

.check-msg.current {
  border: 2px dashed #3692ff;
}

.check-msg .tag {
  padding: 1px 5px;
  text-align: center;
  border-radius: 2px;
  margin-right: 5px;
  text-decoration: inherit;
}

.check-msg .tag.macro {
  background-color: #83876a;
  color: white;
  text-transform: capitalize;
}

.check-msg .tag.note {
  background-color: #9299a1;
  color: white;
  text-transform: capitalize;
}

.checker-enum {
  color: white;
  padding: 1px 5px;
  text-align: center;
  border-radius: 25px;
  margin-right: 5px;
  text-decoration: inherit;
}

.checker-enum.info {
  background-color: #427ea9;
}

.checker-enum.error {
  background-color: #a94442;
}

.arrow {
  border: solid black;
  border-width: 0 3px 3px 0;
  display: inline-block;
  padding: 3px;
  cursor: pointer;
  margin: 0px 5px;
}

.arrow:hover {
  border: solid #437ea8;
  border-width: 0 3px 3px 0;
}

.left-arrow {
  transform: rotate(135deg);
  -webkit-transform: rotate(135deg);
}

.right-arrow {
  transform: rotate(-45deg);
  -webkit-transform: rotate(-45deg);
}

    </style>

    <script type="text/javascript">
      function setNonCompatibleBrowserMessage() {
  document.body.innerHTML =
    '<h2 style="margin-left: 20px;">Your browser is not compatible with CodeChecker Viewer!</h2> \
     <p style="margin-left: 20px;">The version required for the following browsers are:</p> \
     <ul style="margin-left: 20px;"> \
     <li>Internet Explorer: version 9 or newer</li> \
     <li>Firefox: version 22.0 or newer</li> \
     </ul>';
}

// http://stackoverflow.com/questions/5916900/how-can-you-detect-the-version-of-a-browser
var browserVersion = (function(){
  var ua = navigator.userAgent, tem,
    M = ua.match(/(opera|chrome|safari|firefox|msie|trident(?=\/))\/?\s*(\d+)/i) || [];

  if (/trident/i.test(M[1])) {
    tem = /\brv[ :]+(\d+)/g.exec(ua) || [];
    return 'IE ' + (tem[1] || '');
  }

  if (M[1] === 'Chrome') {
    tem = ua.match(/\b(OPR|Edge)\/(\d+)/);
    if (tem != null) return tem.slice(1).join(' ').replace('OPR', 'Opera');
  }

  M = M[2] ? [M[1], M[2]] : [navigator.appName, navigator.appVersion, '-?'];
  if ((tem = ua.match(/version\/(\d+)/i)) != null) M.splice(1, 1, tem[1]);
    return M.join(' ');
})();

var pos = browserVersion.indexOf(' ');
var browser = browserVersion.substr(0, pos);
var version = parseInt(browserVersion.substr(pos + 1));

var browserCompatible
  = browser === 'Firefox'
  ? version >= 22
  : browser === 'IE'
  ? version >= 9
  : true;


      /* MIT License

Copyright (C) 2017 by Marijn Haverbeke <marijnh@gmail.com> and others

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
 */
      !function(e,t){"object"==typeof exports&&"undefined"!=typeof module?module.exports=t():"function"==typeof define&&define.amd?define(t):e.CodeMirror=t()}(this,function(){"use strict";function e(e){return new RegExp("(^|\\s)"+e+"(?:$|\\s)\\s*")}function t(e){for(var t=e.childNodes.length;t>0;--t)e.removeChild(e.firstChild);return e}function r(e,r){return t(e).appendChild(r)}function n(e,t,r,n){var i=document.createElement(e);if(r&&(i.className=r),n&&(i.style.cssText=n),"string"==typeof t)i.appendChild(document.createTextNode(t));else if(t)for(var o=0;o<t.length;++o)i.appendChild(t[o]);return i}function i(e,t,r,i){var o=n(e,t,r,i);return o.setAttribute("role","presentation"),o}function o(e,t){if(3==t.nodeType&&(t=t.parentNode),e.contains)return e.contains(t);do{if(11==t.nodeType&&(t=t.host),t==e)return!0}while(t=t.parentNode)}function l(){var e;try{e=document.activeElement}catch(t){e=document.body||null}for(;e&&e.shadowRoot&&e.shadowRoot.activeElement;)e=e.shadowRoot.activeElement;return e}function s(t,r){var n=t.className;e(r).test(n)||(t.className+=(n?" ":"")+r)}function a(t,r){for(var n=t.split(" "),i=0;i<n.length;i++)n[i]&&!e(n[i]).test(r)&&(r+=" "+n[i]);return r}function u(e){var t=Array.prototype.slice.call(arguments,1);return function(){return e.apply(null,t)}}function c(e,t,r){t||(t={});for(var n in e)!e.hasOwnProperty(n)||!1===r&&t.hasOwnProperty(n)||(t[n]=e[n]);return t}function f(e,t,r,n,i){null==t&&-1==(t=e.search(/[^\s\u00a0]/))&&(t=e.length);for(var o=n||0,l=i||0;;){var s=e.indexOf("\t",o);if(s<0||s>=t)return l+(t-o);l+=s-o,l+=r-l%r,o=s+1}}function h(e,t){for(var r=0;r<e.length;++r)if(e[r]==t)return r;return-1}function d(e,t,r){for(var n=0,i=0;;){var o=e.indexOf("\t",n);-1==o&&(o=e.length);var l=o-n;if(o==e.length||i+l>=t)return n+Math.min(l,t-i);if(i+=o-n,i+=r-i%r,n=o+1,i>=t)return n}}function p(e){for(;Kl.length<=e;)Kl.push(g(Kl)+" ");return Kl[e]}function g(e){return e[e.length-1]}function v(e,t){for(var r=[],n=0;n<e.length;n++)r[n]=t(e[n],n);return r}function m(e,t,r){for(var n=0,i=r(t);n<e.length&&r(e[n])<=i;)n++;e.splice(n,0,t)}function y(){}function b(e,t){var r;return Object.create?r=Object.create(e):(y.prototype=e,r=new y),t&&c(t,r),r}function w(e){return/\w/.test(e)||e>""&&(e.toUpperCase()!=e.toLowerCase()||jl.test(e))}function x(e,t){return t?!!(t.source.indexOf("\\w")>-1&&w(e))||t.test(e):w(e)}function C(e){for(var t in e)if(e.hasOwnProperty(t)&&e[t])return!1;return!0}function S(e){return e.charCodeAt(0)>=768&&Xl.test(e)}function L(e,t,r){for(;(r<0?t>0:t<e.length)&&S(e.charAt(t));)t+=r;return t}function k(e,t,r){for(var n=t>r?-1:1;;){if(t==r)return t;var i=(t+r)/2,o=n<0?Math.ceil(i):Math.floor(i);if(o==t)return e(o)?t:r;e(o)?r=o:t=o+n}}function T(e,t,r){var o=this;this.input=r,o.scrollbarFiller=n("div",null,"CodeMirror-scrollbar-filler"),o.scrollbarFiller.setAttribute("cm-not-content","true"),o.gutterFiller=n("div",null,"CodeMirror-gutter-filler"),o.gutterFiller.setAttribute("cm-not-content","true"),o.lineDiv=i("div",null,"CodeMirror-code"),o.selectionDiv=n("div",null,null,"position: relative; z-index: 1"),o.cursorDiv=n("div",null,"CodeMirror-cursors"),o.measure=n("div",null,"CodeMirror-measure"),o.lineMeasure=n("div",null,"CodeMirror-measure"),o.lineSpace=i("div",[o.measure,o.lineMeasure,o.selectionDiv,o.cursorDiv,o.lineDiv],null,"position: relative; outline: none");var l=i("div",[o.lineSpace],"CodeMirror-lines");o.mover=n("div",[l],null,"position: relative"),o.sizer=n("div",[o.mover],"CodeMirror-sizer"),o.sizerWidth=null,o.heightForcer=n("div",null,null,"position: absolute; height: "+Rl+"px; width: 1px;"),o.gutters=n("div",null,"CodeMirror-gutters"),o.lineGutter=null,o.scroller=n("div",[o.sizer,o.heightForcer,o.gutters],"CodeMirror-scroll"),o.scroller.setAttribute("tabIndex","-1"),o.wrapper=n("div",[o.scrollbarFiller,o.gutterFiller,o.scroller],"CodeMirror"),gl&&vl<8&&(o.gutters.style.zIndex=-1,o.scroller.style.paddingRight=0),ml||fl&&Tl||(o.scroller.draggable=!0),e&&(e.appendChild?e.appendChild(o.wrapper):e(o.wrapper)),o.viewFrom=o.viewTo=t.first,o.reportedViewFrom=o.reportedViewTo=t.first,o.view=[],o.renderedView=null,o.externalMeasured=null,o.viewOffset=0,o.lastWrapHeight=o.lastWrapWidth=0,o.updateLineNumbers=null,o.nativeBarWidth=o.barHeight=o.barWidth=0,o.scrollbarsClipped=!1,o.lineNumWidth=o.lineNumInnerWidth=o.lineNumChars=null,o.alignWidgets=!1,o.cachedCharWidth=o.cachedTextHeight=o.cachedPaddingH=null,o.maxLine=null,o.maxLineLength=0,o.maxLineChanged=!1,o.wheelDX=o.wheelDY=o.wheelStartX=o.wheelStartY=null,o.shift=!1,o.selForContextMenu=null,o.activeTouch=null,r.init(o)}function M(e,t){if((t-=e.first)<0||t>=e.size)throw new Error("There is no line "+(t+e.first)+" in the document.");for(var r=e;!r.lines;)for(var n=0;;++n){var i=r.children[n],o=i.chunkSize();if(t<o){r=i;break}t-=o}return r.lines[t]}function N(e,t,r){var n=[],i=t.line;return e.iter(t.line,r.line+1,function(e){var o=e.text;i==r.line&&(o=o.slice(0,r.ch)),i==t.line&&(o=o.slice(t.ch)),n.push(o),++i}),n}function O(e,t,r){var n=[];return e.iter(t,r,function(e){n.push(e.text)}),n}function A(e,t){var r=t-e.height;if(r)for(var n=e;n;n=n.parent)n.height+=r}function W(e){if(null==e.parent)return null;for(var t=e.parent,r=h(t.lines,e),n=t.parent;n;t=n,n=n.parent)for(var i=0;n.children[i]!=t;++i)r+=n.children[i].chunkSize();return r+t.first}function D(e,t){var r=e.first;e:do{for(var n=0;n<e.children.length;++n){var i=e.children[n],o=i.height;if(t<o){e=i;continue e}t-=o,r+=i.chunkSize()}return r}while(!e.lines);for(var l=0;l<e.lines.length;++l){var s=e.lines[l].height;if(t<s)break;t-=s}return r+l}function H(e,t){return t>=e.first&&t<e.first+e.size}function F(e,t){return String(e.lineNumberFormatter(t+e.firstLineNumber))}function E(e,t,r){if(void 0===r&&(r=null),!(this instanceof E))return new E(e,t,r);this.line=e,this.ch=t,this.sticky=r}function P(e,t){return e.line-t.line||e.ch-t.ch}function I(e,t){return e.sticky==t.sticky&&0==P(e,t)}function z(e){return E(e.line,e.ch)}function R(e,t){return P(e,t)<0?t:e}function B(e,t){return P(e,t)<0?e:t}function G(e,t){return Math.max(e.first,Math.min(t,e.first+e.size-1))}function U(e,t){if(t.line<e.first)return E(e.first,0);var r=e.first+e.size-1;return t.line>r?E(r,M(e,r).text.length):V(t,M(e,t.line).text.length)}function V(e,t){var r=e.ch;return null==r||r>t?E(e.line,t):r<0?E(e.line,0):e}function K(e,t){for(var r=[],n=0;n<t.length;n++)r[n]=U(e,t[n]);return r}function j(){Yl=!0}function X(){_l=!0}function Y(e,t,r){this.marker=e,this.from=t,this.to=r}function _(e,t){if(e)for(var r=0;r<e.length;++r){var n=e[r];if(n.marker==t)return n}}function $(e,t){for(var r,n=0;n<e.length;++n)e[n]!=t&&(r||(r=[])).push(e[n]);return r}function q(e,t){e.markedSpans=e.markedSpans?e.markedSpans.concat([t]):[t],t.marker.attachLine(e)}function Z(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t)||o.from==t&&"bookmark"==l.type&&(!r||!o.marker.insertLeft)){var s=null==o.to||(l.inclusiveRight?o.to>=t:o.to>t);(n||(n=[])).push(new Y(l,o.from,s?null:o.to))}}return n}function Q(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.to||(l.inclusiveRight?o.to>=t:o.to>t)||o.from==t&&"bookmark"==l.type&&(!r||o.marker.insertLeft)){var s=null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t);(n||(n=[])).push(new Y(l,s?null:o.from-t,null==o.to?null:o.to-t))}}return n}function J(e,t){if(t.full)return null;var r=H(e,t.from.line)&&M(e,t.from.line).markedSpans,n=H(e,t.to.line)&&M(e,t.to.line).markedSpans;if(!r&&!n)return null;var i=t.from.ch,o=t.to.ch,l=0==P(t.from,t.to),s=Z(r,i,l),a=Q(n,o,l),u=1==t.text.length,c=g(t.text).length+(u?i:0);if(s)for(var f=0;f<s.length;++f){var h=s[f];if(null==h.to){var d=_(a,h.marker);d?u&&(h.to=null==d.to?null:d.to+c):h.to=i}}if(a)for(var p=0;p<a.length;++p){var v=a[p];null!=v.to&&(v.to+=c),null==v.from?_(s,v.marker)||(v.from=c,u&&(s||(s=[])).push(v)):(v.from+=c,u&&(s||(s=[])).push(v))}s&&(s=ee(s)),a&&a!=s&&(a=ee(a));var m=[s];if(!u){var y,b=t.text.length-2;if(b>0&&s)for(var w=0;w<s.length;++w)null==s[w].to&&(y||(y=[])).push(new Y(s[w].marker,null,null));for(var x=0;x<b;++x)m.push(y);m.push(a)}return m}function ee(e){for(var t=0;t<e.length;++t){var r=e[t];null!=r.from&&r.from==r.to&&!1!==r.marker.clearWhenEmpty&&e.splice(t--,1)}return e.length?e:null}function te(e,t,r){var n=null;if(e.iter(t.line,r.line+1,function(e){if(e.markedSpans)for(var t=0;t<e.markedSpans.length;++t){var r=e.markedSpans[t].marker;!r.readOnly||n&&-1!=h(n,r)||(n||(n=[])).push(r)}}),!n)return null;for(var i=[{from:t,to:r}],o=0;o<n.length;++o)for(var l=n[o],s=l.find(0),a=0;a<i.length;++a){var u=i[a];if(!(P(u.to,s.from)<0||P(u.from,s.to)>0)){var c=[a,1],f=P(u.from,s.from),d=P(u.to,s.to);(f<0||!l.inclusiveLeft&&!f)&&c.push({from:u.from,to:s.from}),(d>0||!l.inclusiveRight&&!d)&&c.push({from:s.to,to:u.to}),i.splice.apply(i,c),a+=c.length-3}}return i}function re(e){var t=e.markedSpans;if(t){for(var r=0;r<t.length;++r)t[r].marker.detachLine(e);e.markedSpans=null}}function ne(e,t){if(t){for(var r=0;r<t.length;++r)t[r].marker.attachLine(e);e.markedSpans=t}}function ie(e){return e.inclusiveLeft?-1:0}function oe(e){return e.inclusiveRight?1:0}function le(e,t){var r=e.lines.length-t.lines.length;if(0!=r)return r;var n=e.find(),i=t.find(),o=P(n.from,i.from)||ie(e)-ie(t);if(o)return-o;var l=P(n.to,i.to)||oe(e)-oe(t);return l||t.id-e.id}function se(e,t){var r,n=_l&&e.markedSpans;if(n)for(var i=void 0,o=0;o<n.length;++o)(i=n[o]).marker.collapsed&&null==(t?i.from:i.to)&&(!r||le(r,i.marker)<0)&&(r=i.marker);return r}function ae(e){return se(e,!0)}function ue(e){return se(e,!1)}function ce(e,t,r,n,i){var o=M(e,t),l=_l&&o.markedSpans;if(l)for(var s=0;s<l.length;++s){var a=l[s];if(a.marker.collapsed){var u=a.marker.find(0),c=P(u.from,r)||ie(a.marker)-ie(i),f=P(u.to,n)||oe(a.marker)-oe(i);if(!(c>=0&&f<=0||c<=0&&f>=0)&&(c<=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.to,r)>=0:P(u.to,r)>0)||c>=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.from,n)<=0:P(u.from,n)<0)))return!0}}}function fe(e){for(var t;t=ae(e);)e=t.find(-1,!0).line;return e}function he(e){for(var t;t=ue(e);)e=t.find(1,!0).line;return e}function de(e){for(var t,r;t=ue(e);)e=t.find(1,!0).line,(r||(r=[])).push(e);return r}function pe(e,t){var r=M(e,t),n=fe(r);return r==n?t:W(n)}function ge(e,t){if(t>e.lastLine())return t;var r,n=M(e,t);if(!ve(e,n))return t;for(;r=ue(n);)n=r.find(1,!0).line;return W(n)+1}function ve(e,t){var r=_l&&t.markedSpans;if(r)for(var n=void 0,i=0;i<r.length;++i)if((n=r[i]).marker.collapsed){if(null==n.from)return!0;if(!n.marker.widgetNode&&0==n.from&&n.marker.inclusiveLeft&&me(e,t,n))return!0}}function me(e,t,r){if(null==r.to){var n=r.marker.find(1,!0);return me(e,n.line,_(n.line.markedSpans,r.marker))}if(r.marker.inclusiveRight&&r.to==t.text.length)return!0;for(var i=void 0,o=0;o<t.markedSpans.length;++o)if((i=t.markedSpans[o]).marker.collapsed&&!i.marker.widgetNode&&i.from==r.to&&(null==i.to||i.to!=r.from)&&(i.marker.inclusiveLeft||r.marker.inclusiveRight)&&me(e,t,i))return!0}function ye(e){for(var t=0,r=(e=fe(e)).parent,n=0;n<r.lines.length;++n){var i=r.lines[n];if(i==e)break;t+=i.height}for(var o=r.parent;o;r=o,o=r.parent)for(var l=0;l<o.children.length;++l){var s=o.children[l];if(s==r)break;t+=s.height}return t}function be(e){if(0==e.height)return 0;for(var t,r=e.text.length,n=e;t=ae(n);){var i=t.find(0,!0);n=i.from.line,r+=i.from.ch-i.to.ch}for(n=e;t=ue(n);){var o=t.find(0,!0);r-=n.text.length-o.from.ch,r+=(n=o.to.line).text.length-o.to.ch}return r}function we(e){var t=e.display,r=e.doc;t.maxLine=M(r,r.first),t.maxLineLength=be(t.maxLine),t.maxLineChanged=!0,r.iter(function(e){var r=be(e);r>t.maxLineLength&&(t.maxLineLength=r,t.maxLine=e)})}function xe(e,t,r,n){if(!e)return n(t,r,"ltr",0);for(var i=!1,o=0;o<e.length;++o){var l=e[o];(l.from<r&&l.to>t||t==r&&l.to==t)&&(n(Math.max(l.from,t),Math.min(l.to,r),1==l.level?"rtl":"ltr",o),i=!0)}i||n(t,r,"ltr")}function Ce(e,t,r){var n;$l=null;for(var i=0;i<e.length;++i){var o=e[i];if(o.from<t&&o.to>t)return i;o.to==t&&(o.from!=o.to&&"before"==r?n=i:$l=i),o.from==t&&(o.from!=o.to&&"before"!=r?n=i:$l=i)}return null!=n?n:$l}function Se(e,t){var r=e.order;return null==r&&(r=e.order=ql(e.text,t)),r}function Le(e,t){return e._handlers&&e._handlers[t]||Zl}function ke(e,t,r){if(e.removeEventListener)e.removeEventListener(t,r,!1);else if(e.detachEvent)e.detachEvent("on"+t,r);else{var n=e._handlers,i=n&&n[t];if(i){var o=h(i,r);o>-1&&(n[t]=i.slice(0,o).concat(i.slice(o+1)))}}}function Te(e,t){var r=Le(e,t);if(r.length)for(var n=Array.prototype.slice.call(arguments,2),i=0;i<r.length;++i)r[i].apply(null,n)}function Me(e,t,r){return"string"==typeof t&&(t={type:t,preventDefault:function(){this.defaultPrevented=!0}}),Te(e,r||t.type,e,t),He(t)||t.codemirrorIgnore}function Ne(e){var t=e._handlers&&e._handlers.cursorActivity;if(t)for(var r=e.curOp.cursorActivityHandlers||(e.curOp.cursorActivityHandlers=[]),n=0;n<t.length;++n)-1==h(r,t[n])&&r.push(t[n])}function Oe(e,t){return Le(e,t).length>0}function Ae(e){e.prototype.on=function(e,t){Ql(this,e,t)},e.prototype.off=function(e,t){ke(this,e,t)}}function We(e){e.preventDefault?e.preventDefault():e.returnValue=!1}function De(e){e.stopPropagation?e.stopPropagation():e.cancelBubble=!0}function He(e){return null!=e.defaultPrevented?e.defaultPrevented:0==e.returnValue}function Fe(e){We(e),De(e)}function Ee(e){return e.target||e.srcElement}function Pe(e){var t=e.which;return null==t&&(1&e.button?t=1:2&e.button?t=3:4&e.button&&(t=2)),Ml&&e.ctrlKey&&1==t&&(t=3),t}function Ie(e){if(null==Il){var t=n("span","​");r(e,n("span",[t,document.createTextNode("x")])),0!=e.firstChild.offsetHeight&&(Il=t.offsetWidth<=1&&t.offsetHeight>2&&!(gl&&vl<8))}var i=Il?n("span","​"):n("span"," ",null,"display: inline-block; width: 1px; margin-right: -1px");return i.setAttribute("cm-text",""),i}function ze(e){if(null!=zl)return zl;var n=r(e,document.createTextNode("AخA")),i=Wl(n,0,1).getBoundingClientRect(),o=Wl(n,1,2).getBoundingClientRect();return t(e),!(!i||i.left==i.right)&&(zl=o.right-i.right<3)}function Re(e){if(null!=ns)return ns;var t=r(e,n("span","x")),i=t.getBoundingClientRect(),o=Wl(t,0,1).getBoundingClientRect();return ns=Math.abs(i.left-o.left)>1}function Be(e,t){arguments.length>2&&(t.dependencies=Array.prototype.slice.call(arguments,2)),is[e]=t}function Ge(e){if("string"==typeof e&&os.hasOwnProperty(e))e=os[e];else if(e&&"string"==typeof e.name&&os.hasOwnProperty(e.name)){var t=os[e.name];"string"==typeof t&&(t={name:t}),(e=b(t,e)).name=t.name}else{if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+xml$/.test(e))return Ge("application/xml");if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+json$/.test(e))return Ge("application/json")}return"string"==typeof e?{name:e}:e||{name:"null"}}function Ue(e,t){t=Ge(t);var r=is[t.name];if(!r)return Ue(e,"text/plain");var n=r(e,t);if(ls.hasOwnProperty(t.name)){var i=ls[t.name];for(var o in i)i.hasOwnProperty(o)&&(n.hasOwnProperty(o)&&(n["_"+o]=n[o]),n[o]=i[o])}if(n.name=t.name,t.helperType&&(n.helperType=t.helperType),t.modeProps)for(var l in t.modeProps)n[l]=t.modeProps[l];return n}function Ve(e,t){c(t,ls.hasOwnProperty(e)?ls[e]:ls[e]={})}function Ke(e,t){if(!0===t)return t;if(e.copyState)return e.copyState(t);var r={};for(var n in t){var i=t[n];i instanceof Array&&(i=i.concat([])),r[n]=i}return r}function je(e,t){for(var r;e.innerMode&&(r=e.innerMode(t))&&r.mode!=e;)t=r.state,e=r.mode;return r||{mode:e,state:t}}function Xe(e,t,r){return!e.startState||e.startState(t,r)}function Ye(e,t,r,n){var i=[e.state.modeGen],o={};tt(e,t.text,e.doc.mode,r,function(e,t){return i.push(e,t)},o,n);for(var l=r.state,s=0;s<e.state.overlays.length;++s)!function(n){var l=e.state.overlays[n],s=1,a=0;r.state=!0,tt(e,t.text,l.mode,r,function(e,t){for(var r=s;a<e;){var n=i[s];n>e&&i.splice(s,1,e,i[s+1],n),s+=2,a=Math.min(e,n)}if(t)if(l.opaque)i.splice(r,s-r,e,"overlay "+t),s=r+2;else for(;r<s;r+=2){var o=i[r+1];i[r+1]=(o?o+" ":"")+"overlay "+t}},o)}(s);return r.state=l,{styles:i,classes:o.bgClass||o.textClass?o:null}}function _e(e,t,r){if(!t.styles||t.styles[0]!=e.state.modeGen){var n=$e(e,W(t)),i=t.text.length>e.options.maxHighlightLength&&Ke(e.doc.mode,n.state),o=Ye(e,t,n);i&&(n.state=i),t.stateAfter=n.save(!i),t.styles=o.styles,o.classes?t.styleClasses=o.classes:t.styleClasses&&(t.styleClasses=null),r===e.doc.highlightFrontier&&(e.doc.modeFrontier=Math.max(e.doc.modeFrontier,++e.doc.highlightFrontier))}return t.styles}function $e(e,t,r){var n=e.doc,i=e.display;if(!n.mode.startState)return new us(n,!0,t);var o=rt(e,t,r),l=o>n.first&&M(n,o-1).stateAfter,s=l?us.fromSaved(n,l,o):new us(n,Xe(n.mode),o);return n.iter(o,t,function(r){qe(e,r.text,s);var n=s.line;r.stateAfter=n==t-1||n%5==0||n>=i.viewFrom&&n<i.viewTo?s.save():null,s.nextLine()}),r&&(n.modeFrontier=s.line),s}function qe(e,t,r,n){var i=e.doc.mode,o=new ss(t,e.options.tabSize,r);for(o.start=o.pos=n||0,""==t&&Ze(i,r.state);!o.eol();)Qe(i,o,r.state),o.start=o.pos}function Ze(e,t){if(e.blankLine)return e.blankLine(t);if(e.innerMode){var r=je(e,t);return r.mode.blankLine?r.mode.blankLine(r.state):void 0}}function Qe(e,t,r,n){for(var i=0;i<10;i++){n&&(n[0]=je(e,r).mode);var o=e.token(t,r);if(t.pos>t.start)return o}throw new Error("Mode "+e.name+" failed to advance stream.")}function Je(e,t,r,n){var i,o,l=e.doc,s=l.mode,a=M(l,(t=U(l,t)).line),u=$e(e,t.line,r),c=new ss(a.text,e.options.tabSize,u);for(n&&(o=[]);(n||c.pos<t.ch)&&!c.eol();)c.start=c.pos,i=Qe(s,c,u.state),n&&o.push(new cs(c,i,Ke(l.mode,u.state)));return n?o:new cs(c,i,u.state)}function et(e,t){if(e)for(;;){var r=e.match(/(?:^|\s+)line-(background-)?(\S+)/);if(!r)break;e=e.slice(0,r.index)+e.slice(r.index+r[0].length);var n=r[1]?"bgClass":"textClass";null==t[n]?t[n]=r[2]:new RegExp("(?:^|s)"+r[2]+"(?:$|s)").test(t[n])||(t[n]+=" "+r[2])}return e}function tt(e,t,r,n,i,o,l){var s=r.flattenSpans;null==s&&(s=e.options.flattenSpans);var a,u=0,c=null,f=new ss(t,e.options.tabSize,n),h=e.options.addModeClass&&[null];for(""==t&&et(Ze(r,n.state),o);!f.eol();){if(f.pos>e.options.maxHighlightLength?(s=!1,l&&qe(e,t,n,f.pos),f.pos=t.length,a=null):a=et(Qe(r,f,n.state,h),o),h){var d=h[0].name;d&&(a="m-"+(a?d+" "+a:d))}if(!s||c!=a){for(;u<f.start;)i(u=Math.min(f.start,u+5e3),c);c=a}f.start=f.pos}for(;u<f.pos;){var p=Math.min(f.pos,u+5e3);i(p,c),u=p}}function rt(e,t,r){for(var n,i,o=e.doc,l=r?-1:t-(e.doc.mode.innerMode?1e3:100),s=t;s>l;--s){if(s<=o.first)return o.first;var a=M(o,s-1),u=a.stateAfter;if(u&&(!r||s+(u instanceof as?u.lookAhead:0)<=o.modeFrontier))return s;var c=f(a.text,null,e.options.tabSize);(null==i||n>c)&&(i=s-1,n=c)}return i}function nt(e,t){if(e.modeFrontier=Math.min(e.modeFrontier,t),!(e.highlightFrontier<t-10)){for(var r=e.first,n=t-1;n>r;n--){var i=M(e,n).stateAfter;if(i&&(!(i instanceof as)||n+i.lookAhead<t)){r=n+1;break}}e.highlightFrontier=Math.min(e.highlightFrontier,r)}}function it(e,t,r,n){e.text=t,e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null),null!=e.order&&(e.order=null),re(e),ne(e,r);var i=n?n(e):1;i!=e.height&&A(e,i)}function ot(e){e.parent=null,re(e)}function lt(e,t){if(!e||/^\s*$/.test(e))return null;var r=t.addModeClass?ps:ds;return r[e]||(r[e]=e.replace(/\S+/g,"cm-$&"))}function st(e,t){var r=i("span",null,null,ml?"padding-right: .1px":null),n={pre:i("pre",[r],"CodeMirror-line"),content:r,col:0,pos:0,cm:e,trailingSpace:!1,splitSpaces:(gl||ml)&&e.getOption("lineWrapping")};t.measure={};for(var o=0;o<=(t.rest?t.rest.length:0);o++){var l=o?t.rest[o-1]:t.line,s=void 0;n.pos=0,n.addToken=ut,ze(e.display.measure)&&(s=Se(l,e.doc.direction))&&(n.addToken=ft(n.addToken,s)),n.map=[],dt(l,n,_e(e,l,t!=e.display.externalMeasured&&W(l))),l.styleClasses&&(l.styleClasses.bgClass&&(n.bgClass=a(l.styleClasses.bgClass,n.bgClass||"")),l.styleClasses.textClass&&(n.textClass=a(l.styleClasses.textClass,n.textClass||""))),0==n.map.length&&n.map.push(0,0,n.content.appendChild(Ie(e.display.measure))),0==o?(t.measure.map=n.map,t.measure.cache={}):((t.measure.maps||(t.measure.maps=[])).push(n.map),(t.measure.caches||(t.measure.caches=[])).push({}))}if(ml){var u=n.content.lastChild;(/\bcm-tab\b/.test(u.className)||u.querySelector&&u.querySelector(".cm-tab"))&&(n.content.className="cm-tab-wrap-hack")}return Te(e,"renderLine",e,t.line,n.pre),n.pre.className&&(n.textClass=a(n.pre.className,n.textClass||"")),n}function at(e){var t=n("span","•","cm-invalidchar");return t.title="\\u"+e.charCodeAt(0).toString(16),t.setAttribute("aria-label",t.title),t}function ut(e,t,r,i,o,l,s){if(t){var a,u=e.splitSpaces?ct(t,e.trailingSpace):t,c=e.cm.state.specialChars,f=!1;if(c.test(t)){a=document.createDocumentFragment();for(var h=0;;){c.lastIndex=h;var d=c.exec(t),g=d?d.index-h:t.length-h;if(g){var v=document.createTextNode(u.slice(h,h+g));gl&&vl<9?a.appendChild(n("span",[v])):a.appendChild(v),e.map.push(e.pos,e.pos+g,v),e.col+=g,e.pos+=g}if(!d)break;h+=g+1;var m=void 0;if("\t"==d[0]){var y=e.cm.options.tabSize,b=y-e.col%y;(m=a.appendChild(n("span",p(b),"cm-tab"))).setAttribute("role","presentation"),m.setAttribute("cm-text","\t"),e.col+=b}else"\r"==d[0]||"\n"==d[0]?((m=a.appendChild(n("span","\r"==d[0]?"␍":"␤","cm-invalidchar"))).setAttribute("cm-text",d[0]),e.col+=1):((m=e.cm.options.specialCharPlaceholder(d[0])).setAttribute("cm-text",d[0]),gl&&vl<9?a.appendChild(n("span",[m])):a.appendChild(m),e.col+=1);e.map.push(e.pos,e.pos+1,m),e.pos++}}else e.col+=t.length,a=document.createTextNode(u),e.map.push(e.pos,e.pos+t.length,a),gl&&vl<9&&(f=!0),e.pos+=t.length;if(e.trailingSpace=32==u.charCodeAt(t.length-1),r||i||o||f||s){var w=r||"";i&&(w+=i),o&&(w+=o);var x=n("span",[a],w,s);return l&&(x.title=l),e.content.appendChild(x)}e.content.appendChild(a)}}function ct(e,t){if(e.length>1&&!/  /.test(e))return e;for(var r=t,n="",i=0;i<e.length;i++){var o=e.charAt(i);" "!=o||!r||i!=e.length-1&&32!=e.charCodeAt(i+1)||(o=" "),n+=o,r=" "==o}return n}function ft(e,t){return function(r,n,i,o,l,s,a){i=i?i+" cm-force-border":"cm-force-border";for(var u=r.pos,c=u+n.length;;){for(var f=void 0,h=0;h<t.length&&!((f=t[h]).to>u&&f.from<=u);h++);if(f.to>=c)return e(r,n,i,o,l,s,a);e(r,n.slice(0,f.to-u),i,o,null,s,a),o=null,n=n.slice(f.to-u),u=f.to}}}function ht(e,t,r,n){var i=!n&&r.widgetNode;i&&e.map.push(e.pos,e.pos+t,i),!n&&e.cm.display.input.needsContentAttribute&&(i||(i=e.content.appendChild(document.createElement("span"))),i.setAttribute("cm-marker",r.id)),i&&(e.cm.display.input.setUneditable(i),e.content.appendChild(i)),e.pos+=t,e.trailingSpace=!1}function dt(e,t,r){var n=e.markedSpans,i=e.text,o=0;if(n)for(var l,s,a,u,c,f,h,d=i.length,p=0,g=1,v="",m=0;;){if(m==p){a=u=c=f=s="",h=null,m=1/0;for(var y=[],b=void 0,w=0;w<n.length;++w){var x=n[w],C=x.marker;"bookmark"==C.type&&x.from==p&&C.widgetNode?y.push(C):x.from<=p&&(null==x.to||x.to>p||C.collapsed&&x.to==p&&x.from==p)?(null!=x.to&&x.to!=p&&m>x.to&&(m=x.to,u=""),C.className&&(a+=" "+C.className),C.css&&(s=(s?s+";":"")+C.css),C.startStyle&&x.from==p&&(c+=" "+C.startStyle),C.endStyle&&x.to==m&&(b||(b=[])).push(C.endStyle,x.to),C.title&&!f&&(f=C.title),C.collapsed&&(!h||le(h.marker,C)<0)&&(h=x)):x.from>p&&m>x.from&&(m=x.from)}if(b)for(var S=0;S<b.length;S+=2)b[S+1]==m&&(u+=" "+b[S]);if(!h||h.from==p)for(var L=0;L<y.length;++L)ht(t,0,y[L]);if(h&&(h.from||0)==p){if(ht(t,(null==h.to?d+1:h.to)-p,h.marker,null==h.from),null==h.to)return;h.to==p&&(h=!1)}}if(p>=d)break;for(var k=Math.min(d,m);;){if(v){var T=p+v.length;if(!h){var M=T>k?v.slice(0,k-p):v;t.addToken(t,M,l?l+a:a,c,p+M.length==m?u:"",f,s)}if(T>=k){v=v.slice(k-p),p=k;break}p=T,c=""}v=i.slice(o,o=r[g++]),l=lt(r[g++],t.cm.options)}}else for(var N=1;N<r.length;N+=2)t.addToken(t,i.slice(o,o=r[N]),lt(r[N+1],t.cm.options))}function pt(e,t,r){this.line=t,this.rest=de(t),this.size=this.rest?W(g(this.rest))-r+1:1,this.node=this.text=null,this.hidden=ve(e,t)}function gt(e,t,r){for(var n,i=[],o=t;o<r;o=n){var l=new pt(e.doc,M(e.doc,o),o);n=o+l.size,i.push(l)}return i}function vt(e){gs?gs.ops.push(e):e.ownsGroup=gs={ops:[e],delayedCallbacks:[]}}function mt(e){var t=e.delayedCallbacks,r=0;do{for(;r<t.length;r++)t[r].call(null);for(var n=0;n<e.ops.length;n++){var i=e.ops[n];if(i.cursorActivityHandlers)for(;i.cursorActivityCalled<i.cursorActivityHandlers.length;)i.cursorActivityHandlers[i.cursorActivityCalled++].call(null,i.cm)}}while(r<t.length)}function yt(e,t){var r=e.ownsGroup;if(r)try{mt(r)}finally{gs=null,t(r)}}function bt(e,t){var r=Le(e,t);if(r.length){var n,i=Array.prototype.slice.call(arguments,2);gs?n=gs.delayedCallbacks:vs?n=vs:(n=vs=[],setTimeout(wt,0));for(var o=0;o<r.length;++o)!function(e){n.push(function(){return r[e].apply(null,i)})}(o)}}function wt(){var e=vs;vs=null;for(var t=0;t<e.length;++t)e[t]()}function xt(e,t,r,n){for(var i=0;i<t.changes.length;i++){var o=t.changes[i];"text"==o?kt(e,t):"gutter"==o?Mt(e,t,r,n):"class"==o?Tt(e,t):"widget"==o&&Nt(e,t,n)}t.changes=null}function Ct(e){return e.node==e.text&&(e.node=n("div",null,null,"position: relative"),e.text.parentNode&&e.text.parentNode.replaceChild(e.node,e.text),e.node.appendChild(e.text),gl&&vl<8&&(e.node.style.zIndex=2)),e.node}function St(e,t){var r=t.bgClass?t.bgClass+" "+(t.line.bgClass||""):t.line.bgClass;if(r&&(r+=" CodeMirror-linebackground"),t.background)r?t.background.className=r:(t.background.parentNode.removeChild(t.background),t.background=null);else if(r){var i=Ct(t);t.background=i.insertBefore(n("div",null,r),i.firstChild),e.display.input.setUneditable(t.background)}}function Lt(e,t){var r=e.display.externalMeasured;return r&&r.line==t.line?(e.display.externalMeasured=null,t.measure=r.measure,r.built):st(e,t)}function kt(e,t){var r=t.text.className,n=Lt(e,t);t.text==t.node&&(t.node=n.pre),t.text.parentNode.replaceChild(n.pre,t.text),t.text=n.pre,n.bgClass!=t.bgClass||n.textClass!=t.textClass?(t.bgClass=n.bgClass,t.textClass=n.textClass,Tt(e,t)):r&&(t.text.className=r)}function Tt(e,t){St(e,t),t.line.wrapClass?Ct(t).className=t.line.wrapClass:t.node!=t.text&&(t.node.className="");var r=t.textClass?t.textClass+" "+(t.line.textClass||""):t.line.textClass;t.text.className=r||""}function Mt(e,t,r,i){if(t.gutter&&(t.node.removeChild(t.gutter),t.gutter=null),t.gutterBackground&&(t.node.removeChild(t.gutterBackground),t.gutterBackground=null),t.line.gutterClass){var o=Ct(t);t.gutterBackground=n("div",null,"CodeMirror-gutter-background "+t.line.gutterClass,"left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px; width: "+i.gutterTotalWidth+"px"),e.display.input.setUneditable(t.gutterBackground),o.insertBefore(t.gutterBackground,t.text)}var l=t.line.gutterMarkers;if(e.options.lineNumbers||l){var s=Ct(t),a=t.gutter=n("div",null,"CodeMirror-gutter-wrapper","left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px");if(e.display.input.setUneditable(a),s.insertBefore(a,t.text),t.line.gutterClass&&(a.className+=" "+t.line.gutterClass),!e.options.lineNumbers||l&&l["CodeMirror-linenumbers"]||(t.lineNumber=a.appendChild(n("div",F(e.options,r),"CodeMirror-linenumber CodeMirror-gutter-elt","left: "+i.gutterLeft["CodeMirror-linenumbers"]+"px; width: "+e.display.lineNumInnerWidth+"px"))),l)for(var u=0;u<e.options.gutters.length;++u){var c=e.options.gutters[u],f=l.hasOwnProperty(c)&&l[c];f&&a.appendChild(n("div",[f],"CodeMirror-gutter-elt","left: "+i.gutterLeft[c]+"px; width: "+i.gutterWidth[c]+"px"))}}}function Nt(e,t,r){t.alignable&&(t.alignable=null);for(var n=t.node.firstChild,i=void 0;n;n=i)i=n.nextSibling,"CodeMirror-linewidget"==n.className&&t.node.removeChild(n);At(e,t,r)}function Ot(e,t,r,n){var i=Lt(e,t);return t.text=t.node=i.pre,i.bgClass&&(t.bgClass=i.bgClass),i.textClass&&(t.textClass=i.textClass),Tt(e,t),Mt(e,t,r,n),At(e,t,n),t.node}function At(e,t,r){if(Wt(e,t.line,t,r,!0),t.rest)for(var n=0;n<t.rest.length;n++)Wt(e,t.rest[n],t,r,!1)}function Wt(e,t,r,i,o){if(t.widgets)for(var l=Ct(r),s=0,a=t.widgets;s<a.length;++s){var u=a[s],c=n("div",[u.node],"CodeMirror-linewidget");u.handleMouseEvents||c.setAttribute("cm-ignore-events","true"),Dt(u,c,r,i),e.display.input.setUneditable(c),o&&u.above?l.insertBefore(c,r.gutter||r.text):l.appendChild(c),bt(u,"redraw")}}function Dt(e,t,r,n){if(e.noHScroll){(r.alignable||(r.alignable=[])).push(t);var i=n.wrapperWidth;t.style.left=n.fixedPos+"px",e.coverGutter||(i-=n.gutterTotalWidth,t.style.paddingLeft=n.gutterTotalWidth+"px"),t.style.width=i+"px"}e.coverGutter&&(t.style.zIndex=5,t.style.position="relative",e.noHScroll||(t.style.marginLeft=-n.gutterTotalWidth+"px"))}function Ht(e){if(null!=e.height)return e.height;var t=e.doc.cm;if(!t)return 0;if(!o(document.body,e.node)){var i="position: relative;";e.coverGutter&&(i+="margin-left: -"+t.display.gutters.offsetWidth+"px;"),e.noHScroll&&(i+="width: "+t.display.wrapper.clientWidth+"px;"),r(t.display.measure,n("div",[e.node],null,i))}return e.height=e.node.parentNode.offsetHeight}function Ft(e,t){for(var r=Ee(t);r!=e.wrapper;r=r.parentNode)if(!r||1==r.nodeType&&"true"==r.getAttribute("cm-ignore-events")||r.parentNode==e.sizer&&r!=e.mover)return!0}function Et(e){return e.lineSpace.offsetTop}function Pt(e){return e.mover.offsetHeight-e.lineSpace.offsetHeight}function It(e){if(e.cachedPaddingH)return e.cachedPaddingH;var t=r(e.measure,n("pre","x")),i=window.getComputedStyle?window.getComputedStyle(t):t.currentStyle,o={left:parseInt(i.paddingLeft),right:parseInt(i.paddingRight)};return isNaN(o.left)||isNaN(o.right)||(e.cachedPaddingH=o),o}function zt(e){return Rl-e.display.nativeBarWidth}function Rt(e){return e.display.scroller.clientWidth-zt(e)-e.display.barWidth}function Bt(e){return e.display.scroller.clientHeight-zt(e)-e.display.barHeight}function Gt(e,t,r){var n=e.options.lineWrapping,i=n&&Rt(e);if(!t.measure.heights||n&&t.measure.width!=i){var o=t.measure.heights=[];if(n){t.measure.width=i;for(var l=t.text.firstChild.getClientRects(),s=0;s<l.length-1;s++){var a=l[s],u=l[s+1];Math.abs(a.bottom-u.bottom)>2&&o.push((a.bottom+u.top)/2-r.top)}}o.push(r.bottom-r.top)}}function Ut(e,t,r){if(e.line==t)return{map:e.measure.map,cache:e.measure.cache};for(var n=0;n<e.rest.length;n++)if(e.rest[n]==t)return{map:e.measure.maps[n],cache:e.measure.caches[n]};for(var i=0;i<e.rest.length;i++)if(W(e.rest[i])>r)return{map:e.measure.maps[i],cache:e.measure.caches[i],before:!0}}function Vt(e,t){var n=W(t=fe(t)),i=e.display.externalMeasured=new pt(e.doc,t,n);i.lineN=n;var o=i.built=st(e,i);return i.text=o.pre,r(e.display.lineMeasure,o.pre),i}function Kt(e,t,r,n){return Yt(e,Xt(e,t),r,n)}function jt(e,t){if(t>=e.display.viewFrom&&t<e.display.viewTo)return e.display.view[Lr(e,t)];var r=e.display.externalMeasured;return r&&t>=r.lineN&&t<r.lineN+r.size?r:void 0}function Xt(e,t){var r=W(t),n=jt(e,r);n&&!n.text?n=null:n&&n.changes&&(xt(e,n,r,br(e)),e.curOp.forceUpdate=!0),n||(n=Vt(e,t));var i=Ut(n,t,r);return{line:t,view:n,rect:null,map:i.map,cache:i.cache,before:i.before,hasHeights:!1}}function Yt(e,t,r,n,i){t.before&&(r=-1);var o,l=r+(n||"");return t.cache.hasOwnProperty(l)?o=t.cache[l]:(t.rect||(t.rect=t.view.text.getBoundingClientRect()),t.hasHeights||(Gt(e,t.view,t.rect),t.hasHeights=!0),(o=qt(e,t,r,n)).bogus||(t.cache[l]=o)),{left:o.left,right:o.right,top:i?o.rtop:o.top,bottom:i?o.rbottom:o.bottom}}function _t(e,t,r){for(var n,i,o,l,s,a,u=0;u<e.length;u+=3)if(s=e[u],a=e[u+1],t<s?(i=0,o=1,l="left"):t<a?o=(i=t-s)+1:(u==e.length-3||t==a&&e[u+3]>t)&&(i=(o=a-s)-1,t>=a&&(l="right")),null!=i){if(n=e[u+2],s==a&&r==(n.insertLeft?"left":"right")&&(l=r),"left"==r&&0==i)for(;u&&e[u-2]==e[u-3]&&e[u-1].insertLeft;)n=e[2+(u-=3)],l="left";if("right"==r&&i==a-s)for(;u<e.length-3&&e[u+3]==e[u+4]&&!e[u+5].insertLeft;)n=e[(u+=3)+2],l="right";break}return{node:n,start:i,end:o,collapse:l,coverStart:s,coverEnd:a}}function $t(e,t){var r=ms;if("left"==t)for(var n=0;n<e.length&&(r=e[n]).left==r.right;n++);else for(var i=e.length-1;i>=0&&(r=e[i]).left==r.right;i--);return r}function qt(e,t,r,n){var i,o=_t(t.map,r,n),l=o.node,s=o.start,a=o.end,u=o.collapse;if(3==l.nodeType){for(var c=0;c<4;c++){for(;s&&S(t.line.text.charAt(o.coverStart+s));)--s;for(;o.coverStart+a<o.coverEnd&&S(t.line.text.charAt(o.coverStart+a));)++a;if((i=gl&&vl<9&&0==s&&a==o.coverEnd-o.coverStart?l.parentNode.getBoundingClientRect():$t(Wl(l,s,a).getClientRects(),n)).left||i.right||0==s)break;a=s,s-=1,u="right"}gl&&vl<11&&(i=Zt(e.display.measure,i))}else{s>0&&(u=n="right");var f;i=e.options.lineWrapping&&(f=l.getClientRects()).length>1?f["right"==n?f.length-1:0]:l.getBoundingClientRect()}if(gl&&vl<9&&!s&&(!i||!i.left&&!i.right)){var h=l.parentNode.getClientRects()[0];i=h?{left:h.left,right:h.left+yr(e.display),top:h.top,bottom:h.bottom}:ms}for(var d=i.top-t.rect.top,p=i.bottom-t.rect.top,g=(d+p)/2,v=t.view.measure.heights,m=0;m<v.length-1&&!(g<v[m]);m++);var y=m?v[m-1]:0,b=v[m],w={left:("right"==u?i.right:i.left)-t.rect.left,right:("left"==u?i.left:i.right)-t.rect.left,top:y,bottom:b};return i.left||i.right||(w.bogus=!0),e.options.singleCursorHeightPerLine||(w.rtop=d,w.rbottom=p),w}function Zt(e,t){if(!window.screen||null==screen.logicalXDPI||screen.logicalXDPI==screen.deviceXDPI||!Re(e))return t;var r=screen.logicalXDPI/screen.deviceXDPI,n=screen.logicalYDPI/screen.deviceYDPI;return{left:t.left*r,right:t.right*r,top:t.top*n,bottom:t.bottom*n}}function Qt(e){if(e.measure&&(e.measure.cache={},e.measure.heights=null,e.rest))for(var t=0;t<e.rest.length;t++)e.measure.caches[t]={}}function Jt(e){e.display.externalMeasure=null,t(e.display.lineMeasure);for(var r=0;r<e.display.view.length;r++)Qt(e.display.view[r])}function er(e){Jt(e),e.display.cachedCharWidth=e.display.cachedTextHeight=e.display.cachedPaddingH=null,e.options.lineWrapping||(e.display.maxLineChanged=!0),e.display.lineNumChars=null}function tr(){return bl&&kl?-(document.body.getBoundingClientRect().left-parseInt(getComputedStyle(document.body).marginLeft)):window.pageXOffset||(document.documentElement||document.body).scrollLeft}function rr(){return bl&&kl?-(document.body.getBoundingClientRect().top-parseInt(getComputedStyle(document.body).marginTop)):window.pageYOffset||(document.documentElement||document.body).scrollTop}function nr(e){var t=0;if(e.widgets)for(var r=0;r<e.widgets.length;++r)e.widgets[r].above&&(t+=Ht(e.widgets[r]));return t}function ir(e,t,r,n,i){if(!i){var o=nr(t);r.top+=o,r.bottom+=o}if("line"==n)return r;n||(n="local");var l=ye(t);if("local"==n?l+=Et(e.display):l-=e.display.viewOffset,"page"==n||"window"==n){var s=e.display.lineSpace.getBoundingClientRect();l+=s.top+("window"==n?0:rr());var a=s.left+("window"==n?0:tr());r.left+=a,r.right+=a}return r.top+=l,r.bottom+=l,r}function or(e,t,r){if("div"==r)return t;var n=t.left,i=t.top;if("page"==r)n-=tr(),i-=rr();else if("local"==r||!r){var o=e.display.sizer.getBoundingClientRect();n+=o.left,i+=o.top}var l=e.display.lineSpace.getBoundingClientRect();return{left:n-l.left,top:i-l.top}}function lr(e,t,r,n,i){return n||(n=M(e.doc,t.line)),ir(e,n,Kt(e,n,t.ch,i),r)}function sr(e,t,r,n,i,o){function l(t,l){var s=Yt(e,i,t,l?"right":"left",o);return l?s.left=s.right:s.right=s.left,ir(e,n,s,r)}function s(e,t,r){var n=1==a[t].level;return l(r?e-1:e,n!=r)}n=n||M(e.doc,t.line),i||(i=Xt(e,n));var a=Se(n,e.doc.direction),u=t.ch,c=t.sticky;if(u>=n.text.length?(u=n.text.length,c="before"):u<=0&&(u=0,c="after"),!a)return l("before"==c?u-1:u,"before"==c);var f=Ce(a,u,c),h=$l,d=s(u,f,"before"==c);return null!=h&&(d.other=s(u,h,"before"!=c)),d}function ar(e,t){var r=0;t=U(e.doc,t),e.options.lineWrapping||(r=yr(e.display)*t.ch);var n=M(e.doc,t.line),i=ye(n)+Et(e.display);return{left:r,right:r,top:i,bottom:i+n.height}}function ur(e,t,r,n,i){var o=E(e,t,r);return o.xRel=i,n&&(o.outside=!0),o}function cr(e,t,r){var n=e.doc;if((r+=e.display.viewOffset)<0)return ur(n.first,0,null,!0,-1);var i=D(n,r),o=n.first+n.size-1;if(i>o)return ur(n.first+n.size-1,M(n,o).text.length,null,!0,1);t<0&&(t=0);for(var l=M(n,i);;){var s=pr(e,l,i,t,r),a=ue(l),u=a&&a.find(0,!0);if(!a||!(s.ch>u.from.ch||s.ch==u.from.ch&&s.xRel>0))return s;i=W(l=u.to.line)}}function fr(e,t,r,n){n-=nr(t);var i=t.text.length,o=k(function(t){return Yt(e,r,t-1).bottom<=n},i,0);return i=k(function(t){return Yt(e,r,t).top>n},o,i),{begin:o,end:i}}function hr(e,t,r,n){return r||(r=Xt(e,t)),fr(e,t,r,ir(e,t,Yt(e,r,n),"line").top)}function dr(e,t,r,n){return!(e.bottom<=r)&&(e.top>r||(n?e.left:e.right)>t)}function pr(e,t,r,n,i){i-=ye(t);var o=Xt(e,t),l=nr(t),s=0,a=t.text.length,u=!0,c=Se(t,e.doc.direction);if(c){var f=(e.options.lineWrapping?vr:gr)(e,t,r,o,c,n,i);s=(u=1!=f.level)?f.from:f.to-1,a=u?f.to:f.from-1}var h,d,p=null,g=null,v=k(function(t){var r=Yt(e,o,t);return r.top+=l,r.bottom+=l,!!dr(r,n,i,!1)&&(r.top<=i&&r.left<=n&&(p=t,g=r),!0)},s,a),m=!1;if(g){var y=n-g.left<g.right-n,b=y==u;v=p+(b?0:1),d=b?"after":"before",h=y?g.left:g.right}else{u||v!=a&&v!=s||v++,d=0==v?"after":v==t.text.length?"before":Yt(e,o,v-(u?1:0)).bottom+l<=i==u?"after":"before";var w=sr(e,E(r,v,d),"line",t,o);h=w.left,m=i<w.top||i>=w.bottom}return v=L(t.text,v,1),ur(r,v,d,m,n-h)}function gr(e,t,r,n,i,o,l){var s=k(function(s){var a=i[s],u=1!=a.level;return dr(sr(e,E(r,u?a.to:a.from,u?"before":"after"),"line",t,n),o,l,!0)},0,i.length-1),a=i[s];if(s>0){var u=1!=a.level,c=sr(e,E(r,u?a.from:a.to,u?"after":"before"),"line",t,n);dr(c,o,l,!0)&&c.top>l&&(a=i[s-1])}return a}function vr(e,t,r,n,i,o,l){for(var s=fr(e,t,n,l),a=s.begin,u=s.end,c=null,f=null,h=0;h<i.length;h++){var d=i[h];if(!(d.from>=u||d.to<=a)){var p=Yt(e,n,1!=d.level?Math.min(u,d.to)-1:Math.max(a,d.from)).right,g=p<o?o-p+1e9:p-o;(!c||f>g)&&(c=d,f=g)}}return c||(c=i[i.length-1]),c.from<a&&(c={from:a,to:c.to,level:c.level}),c.to>u&&(c={from:c.from,to:u,level:c.level}),c}function mr(e){if(null!=e.cachedTextHeight)return e.cachedTextHeight;if(null==hs){hs=n("pre");for(var i=0;i<49;++i)hs.appendChild(document.createTextNode("x")),hs.appendChild(n("br"));hs.appendChild(document.createTextNode("x"))}r(e.measure,hs);var o=hs.offsetHeight/50;return o>3&&(e.cachedTextHeight=o),t(e.measure),o||1}function yr(e){if(null!=e.cachedCharWidth)return e.cachedCharWidth;var t=n("span","xxxxxxxxxx"),i=n("pre",[t]);r(e.measure,i);var o=t.getBoundingClientRect(),l=(o.right-o.left)/10;return l>2&&(e.cachedCharWidth=l),l||10}function br(e){for(var t=e.display,r={},n={},i=t.gutters.clientLeft,o=t.gutters.firstChild,l=0;o;o=o.nextSibling,++l)r[e.options.gutters[l]]=o.offsetLeft+o.clientLeft+i,n[e.options.gutters[l]]=o.clientWidth;return{fixedPos:wr(t),gutterTotalWidth:t.gutters.offsetWidth,gutterLeft:r,gutterWidth:n,wrapperWidth:t.wrapper.clientWidth}}function wr(e){return e.scroller.getBoundingClientRect().left-e.sizer.getBoundingClientRect().left}function xr(e){var t=mr(e.display),r=e.options.lineWrapping,n=r&&Math.max(5,e.display.scroller.clientWidth/yr(e.display)-3);return function(i){if(ve(e.doc,i))return 0;var o=0;if(i.widgets)for(var l=0;l<i.widgets.length;l++)i.widgets[l].height&&(o+=i.widgets[l].height);return r?o+(Math.ceil(i.text.length/n)||1)*t:o+t}}function Cr(e){var t=e.doc,r=xr(e);t.iter(function(e){var t=r(e);t!=e.height&&A(e,t)})}function Sr(e,t,r,n){var i=e.display;if(!r&&"true"==Ee(t).getAttribute("cm-not-content"))return null;var o,l,s=i.lineSpace.getBoundingClientRect();try{o=t.clientX-s.left,l=t.clientY-s.top}catch(t){return null}var a,u=cr(e,o,l);if(n&&1==u.xRel&&(a=M(e.doc,u.line).text).length==u.ch){var c=f(a,a.length,e.options.tabSize)-a.length;u=E(u.line,Math.max(0,Math.round((o-It(e.display).left)/yr(e.display))-c))}return u}function Lr(e,t){if(t>=e.display.viewTo)return null;if((t-=e.display.viewFrom)<0)return null;for(var r=e.display.view,n=0;n<r.length;n++)if((t-=r[n].size)<0)return n}function kr(e){e.display.input.showSelection(e.display.input.prepareSelection())}function Tr(e,t){void 0===t&&(t=!0);for(var r=e.doc,n={},i=n.cursors=document.createDocumentFragment(),o=n.selection=document.createDocumentFragment(),l=0;l<r.sel.ranges.length;l++)if(t||l!=r.sel.primIndex){var s=r.sel.ranges[l];if(!(s.from().line>=e.display.viewTo||s.to().line<e.display.viewFrom)){var a=s.empty();(a||e.options.showCursorWhenSelecting)&&Mr(e,s.head,i),a||Or(e,s,o)}}return n}function Mr(e,t,r){var i=sr(e,t,"div",null,null,!e.options.singleCursorHeightPerLine),o=r.appendChild(n("div"," ","CodeMirror-cursor"));if(o.style.left=i.left+"px",o.style.top=i.top+"px",o.style.height=Math.max(0,i.bottom-i.top)*e.options.cursorHeight+"px",i.other){var l=r.appendChild(n("div"," ","CodeMirror-cursor CodeMirror-secondarycursor"));l.style.display="",l.style.left=i.other.left+"px",l.style.top=i.other.top+"px",l.style.height=.85*(i.other.bottom-i.other.top)+"px"}}function Nr(e,t){return e.top-t.top||e.left-t.left}function Or(e,t,r){function i(e,t,r,i){t<0&&(t=0),t=Math.round(t),i=Math.round(i),a.appendChild(n("div",null,"CodeMirror-selected","position: absolute; left: "+e+"px;\n                             top: "+t+"px; width: "+(null==r?f-e:r)+"px;\n                             height: "+(i-t)+"px"))}function o(t,r,n){function o(r,n){return lr(e,E(t,r),"div",u,n)}var l,a,u=M(s,t),h=u.text.length,d=Se(u,s.direction);return xe(d,r||0,null==n?h:n,function(t,s,p,g){var v=o(t,"ltr"==p?"left":"right"),m=o(s-1,"ltr"==p?"right":"left");if("ltr"==p){var y=null==r&&0==t?c:v.left,b=null==n&&s==h?f:m.right;m.top-v.top<=3?i(y,m.top,b-y,m.bottom):(i(y,v.top,null,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top),i(c,m.top,m.right,m.bottom))}else if(t<s){var w=null==r&&0==t?f:v.right,x=null==n&&s==h?c:m.left;if(m.top-v.top<=3)i(x,m.top,w-x,m.bottom);else{var C=c;if(g){var S=hr(e,u,null,t).end;C=o(S-(/\s/.test(u.text.charAt(S-1))?2:1),"left").left}i(C,v.top,w-C,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top);var L=null;d.length,L=o(hr(e,u,null,s).begin,"right").right-x,i(x,m.top,L,m.bottom)}}(!l||Nr(v,l)<0)&&(l=v),Nr(m,l)<0&&(l=m),(!a||Nr(v,a)<0)&&(a=v),Nr(m,a)<0&&(a=m)}),{start:l,end:a}}var l=e.display,s=e.doc,a=document.createDocumentFragment(),u=It(e.display),c=u.left,f=Math.max(l.sizerWidth,Rt(e)-l.sizer.offsetLeft)-u.right,h=t.from(),d=t.to();if(h.line==d.line)o(h.line,h.ch,d.ch);else{var p=M(s,h.line),g=M(s,d.line),v=fe(p)==fe(g),m=o(h.line,h.ch,v?p.text.length+1:null).end,y=o(d.line,v?0:null,d.ch).start;v&&(m.top<y.top-2?(i(m.right,m.top,null,m.bottom),i(c,y.top,y.left,y.bottom)):i(m.right,m.top,y.left-m.right,m.bottom)),m.bottom<y.top&&i(c,m.bottom,null,y.top)}r.appendChild(a)}function Ar(e){if(e.state.focused){var t=e.display;clearInterval(t.blinker);var r=!0;t.cursorDiv.style.visibility="",e.options.cursorBlinkRate>0?t.blinker=setInterval(function(){return t.cursorDiv.style.visibility=(r=!r)?"":"hidden"},e.options.cursorBlinkRate):e.options.cursorBlinkRate<0&&(t.cursorDiv.style.visibility="hidden")}}function Wr(e){e.state.focused||(e.display.input.focus(),Hr(e))}function Dr(e){e.state.delayingBlurEvent=!0,setTimeout(function(){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1,Fr(e))},100)}function Hr(e,t){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1),"nocursor"!=e.options.readOnly&&(e.state.focused||(Te(e,"focus",e,t),e.state.focused=!0,s(e.display.wrapper,"CodeMirror-focused"),e.curOp||e.display.selForContextMenu==e.doc.sel||(e.display.input.reset(),ml&&setTimeout(function(){return e.display.input.reset(!0)},20)),e.display.input.receivedFocus()),Ar(e))}function Fr(e,t){e.state.delayingBlurEvent||(e.state.focused&&(Te(e,"blur",e,t),e.state.focused=!1,Fl(e.display.wrapper,"CodeMirror-focused")),clearInterval(e.display.blinker),setTimeout(function(){e.state.focused||(e.display.shift=!1)},150))}function Er(e){for(var t=e.display,r=t.lineDiv.offsetTop,n=0;n<t.view.length;n++){var i=t.view[n],o=void 0;if(!i.hidden){if(gl&&vl<8){var l=i.node.offsetTop+i.node.offsetHeight;o=l-r,r=l}else{var s=i.node.getBoundingClientRect();o=s.bottom-s.top}var a=i.line.height-o;if(o<2&&(o=mr(t)),(a>.005||a<-.005)&&(A(i.line,o),Pr(i.line),i.rest))for(var u=0;u<i.rest.length;u++)Pr(i.rest[u])}}}function Pr(e){if(e.widgets)for(var t=0;t<e.widgets.length;++t)e.widgets[t].height=e.widgets[t].node.parentNode.offsetHeight}function Ir(e,t,r){var n=r&&null!=r.top?Math.max(0,r.top):e.scroller.scrollTop;n=Math.floor(n-Et(e));var i=r&&null!=r.bottom?r.bottom:n+e.wrapper.clientHeight,o=D(t,n),l=D(t,i);if(r&&r.ensure){var s=r.ensure.from.line,a=r.ensure.to.line;s<o?(o=s,l=D(t,ye(M(t,s))+e.wrapper.clientHeight)):Math.min(a,t.lastLine())>=l&&(o=D(t,ye(M(t,a))-e.wrapper.clientHeight),l=a)}return{from:o,to:Math.max(l,o+1)}}function zr(e){var t=e.display,r=t.view;if(t.alignWidgets||t.gutters.firstChild&&e.options.fixedGutter){for(var n=wr(t)-t.scroller.scrollLeft+e.doc.scrollLeft,i=t.gutters.offsetWidth,o=n+"px",l=0;l<r.length;l++)if(!r[l].hidden){e.options.fixedGutter&&(r[l].gutter&&(r[l].gutter.style.left=o),r[l].gutterBackground&&(r[l].gutterBackground.style.left=o));var s=r[l].alignable;if(s)for(var a=0;a<s.length;a++)s[a].style.left=o}e.options.fixedGutter&&(t.gutters.style.left=n+i+"px")}}function Rr(e){if(!e.options.lineNumbers)return!1;var t=e.doc,r=F(e.options,t.first+t.size-1),i=e.display;if(r.length!=i.lineNumChars){var o=i.measure.appendChild(n("div",[n("div",r)],"CodeMirror-linenumber CodeMirror-gutter-elt")),l=o.firstChild.offsetWidth,s=o.offsetWidth-l;return i.lineGutter.style.width="",i.lineNumInnerWidth=Math.max(l,i.lineGutter.offsetWidth-s)+1,i.lineNumWidth=i.lineNumInnerWidth+s,i.lineNumChars=i.lineNumInnerWidth?r.length:-1,i.lineGutter.style.width=i.lineNumWidth+"px",Wn(e),!0}return!1}function Br(e,t){if(!Me(e,"scrollCursorIntoView")){var r=e.display,i=r.sizer.getBoundingClientRect(),o=null;if(t.top+i.top<0?o=!0:t.bottom+i.top>(window.innerHeight||document.documentElement.clientHeight)&&(o=!1),null!=o&&!Sl){var l=n("div","​",null,"position: absolute;\n                         top: "+(t.top-r.viewOffset-Et(e.display))+"px;\n                         height: "+(t.bottom-t.top+zt(e)+r.barHeight)+"px;\n                         left: "+t.left+"px; width: "+Math.max(2,t.right-t.left)+"px;");e.display.lineSpace.appendChild(l),l.scrollIntoView(o),e.display.lineSpace.removeChild(l)}}}function Gr(e,t,r,n){null==n&&(n=0);var i;e.options.lineWrapping||t!=r||(r="before"==(t=t.ch?E(t.line,"before"==t.sticky?t.ch-1:t.ch,"after"):t).sticky?E(t.line,t.ch+1,"before"):t);for(var o=0;o<5;o++){var l=!1,s=sr(e,t),a=r&&r!=t?sr(e,r):s,u=Vr(e,i={left:Math.min(s.left,a.left),top:Math.min(s.top,a.top)-n,right:Math.max(s.left,a.left),bottom:Math.max(s.bottom,a.bottom)+n}),c=e.doc.scrollTop,f=e.doc.scrollLeft;if(null!=u.scrollTop&&(qr(e,u.scrollTop),Math.abs(e.doc.scrollTop-c)>1&&(l=!0)),null!=u.scrollLeft&&(Qr(e,u.scrollLeft),Math.abs(e.doc.scrollLeft-f)>1&&(l=!0)),!l)break}return i}function Ur(e,t){var r=Vr(e,t);null!=r.scrollTop&&qr(e,r.scrollTop),null!=r.scrollLeft&&Qr(e,r.scrollLeft)}function Vr(e,t){var r=e.display,n=mr(e.display);t.top<0&&(t.top=0);var i=e.curOp&&null!=e.curOp.scrollTop?e.curOp.scrollTop:r.scroller.scrollTop,o=Bt(e),l={};t.bottom-t.top>o&&(t.bottom=t.top+o);var s=e.doc.height+Pt(r),a=t.top<n,u=t.bottom>s-n;if(t.top<i)l.scrollTop=a?0:t.top;else if(t.bottom>i+o){var c=Math.min(t.top,(u?s:t.bottom)-o);c!=i&&(l.scrollTop=c)}var f=e.curOp&&null!=e.curOp.scrollLeft?e.curOp.scrollLeft:r.scroller.scrollLeft,h=Rt(e)-(e.options.fixedGutter?r.gutters.offsetWidth:0),d=t.right-t.left>h;return d&&(t.right=t.left+h),t.left<10?l.scrollLeft=0:t.left<f?l.scrollLeft=Math.max(0,t.left-(d?0:10)):t.right>h+f-3&&(l.scrollLeft=t.right+(d?0:10)-h),l}function Kr(e,t){null!=t&&(_r(e),e.curOp.scrollTop=(null==e.curOp.scrollTop?e.doc.scrollTop:e.curOp.scrollTop)+t)}function jr(e){_r(e);var t=e.getCursor();e.curOp.scrollToPos={from:t,to:t,margin:e.options.cursorScrollMargin}}function Xr(e,t,r){null==t&&null==r||_r(e),null!=t&&(e.curOp.scrollLeft=t),null!=r&&(e.curOp.scrollTop=r)}function Yr(e,t){_r(e),e.curOp.scrollToPos=t}function _r(e){var t=e.curOp.scrollToPos;t&&(e.curOp.scrollToPos=null,$r(e,ar(e,t.from),ar(e,t.to),t.margin))}function $r(e,t,r,n){var i=Vr(e,{left:Math.min(t.left,r.left),top:Math.min(t.top,r.top)-n,right:Math.max(t.right,r.right),bottom:Math.max(t.bottom,r.bottom)+n});Xr(e,i.scrollLeft,i.scrollTop)}function qr(e,t){Math.abs(e.doc.scrollTop-t)<2||(fl||On(e,{top:t}),Zr(e,t,!0),fl&&On(e),Cn(e,100))}function Zr(e,t,r){t=Math.min(e.display.scroller.scrollHeight-e.display.scroller.clientHeight,t),(e.display.scroller.scrollTop!=t||r)&&(e.doc.scrollTop=t,e.display.scrollbars.setScrollTop(t),e.display.scroller.scrollTop!=t&&(e.display.scroller.scrollTop=t))}function Qr(e,t,r,n){t=Math.min(t,e.display.scroller.scrollWidth-e.display.scroller.clientWidth),(r?t==e.doc.scrollLeft:Math.abs(e.doc.scrollLeft-t)<2)&&!n||(e.doc.scrollLeft=t,zr(e),e.display.scroller.scrollLeft!=t&&(e.display.scroller.scrollLeft=t),e.display.scrollbars.setScrollLeft(t))}function Jr(e){var t=e.display,r=t.gutters.offsetWidth,n=Math.round(e.doc.height+Pt(e.display));return{clientHeight:t.scroller.clientHeight,viewHeight:t.wrapper.clientHeight,scrollWidth:t.scroller.scrollWidth,clientWidth:t.scroller.clientWidth,viewWidth:t.wrapper.clientWidth,barLeft:e.options.fixedGutter?r:0,docHeight:n,scrollHeight:n+zt(e)+t.barHeight,nativeBarWidth:t.nativeBarWidth,gutterWidth:r}}function en(e,t){t||(t=Jr(e));var r=e.display.barWidth,n=e.display.barHeight;tn(e,t);for(var i=0;i<4&&r!=e.display.barWidth||n!=e.display.barHeight;i++)r!=e.display.barWidth&&e.options.lineWrapping&&Er(e),tn(e,Jr(e)),r=e.display.barWidth,n=e.display.barHeight}function tn(e,t){var r=e.display,n=r.scrollbars.update(t);r.sizer.style.paddingRight=(r.barWidth=n.right)+"px",r.sizer.style.paddingBottom=(r.barHeight=n.bottom)+"px",r.heightForcer.style.borderBottom=n.bottom+"px solid transparent",n.right&&n.bottom?(r.scrollbarFiller.style.display="block",r.scrollbarFiller.style.height=n.bottom+"px",r.scrollbarFiller.style.width=n.right+"px"):r.scrollbarFiller.style.display="",n.bottom&&e.options.coverGutterNextToScrollbar&&e.options.fixedGutter?(r.gutterFiller.style.display="block",r.gutterFiller.style.height=n.bottom+"px",r.gutterFiller.style.width=t.gutterWidth+"px"):r.gutterFiller.style.display=""}function rn(e){e.display.scrollbars&&(e.display.scrollbars.clear(),e.display.scrollbars.addClass&&Fl(e.display.wrapper,e.display.scrollbars.addClass)),e.display.scrollbars=new ws[e.options.scrollbarStyle](function(t){e.display.wrapper.insertBefore(t,e.display.scrollbarFiller),Ql(t,"mousedown",function(){e.state.focused&&setTimeout(function(){return e.display.input.focus()},0)}),t.setAttribute("cm-not-content","true")},function(t,r){"horizontal"==r?Qr(e,t):qr(e,t)},e),e.display.scrollbars.addClass&&s(e.display.wrapper,e.display.scrollbars.addClass)}function nn(e){e.curOp={cm:e,viewChanged:!1,startHeight:e.doc.height,forceUpdate:!1,updateInput:null,typing:!1,changeObjs:null,cursorActivityHandlers:null,cursorActivityCalled:0,selectionChanged:!1,updateMaxLine:!1,scrollLeft:null,scrollTop:null,scrollToPos:null,focus:!1,id:++xs},vt(e.curOp)}function on(e){yt(e.curOp,function(e){for(var t=0;t<e.ops.length;t++)e.ops[t].cm.curOp=null;ln(e)})}function ln(e){for(var t=e.ops,r=0;r<t.length;r++)sn(t[r]);for(var n=0;n<t.length;n++)an(t[n]);for(var i=0;i<t.length;i++)un(t[i]);for(var o=0;o<t.length;o++)cn(t[o]);for(var l=0;l<t.length;l++)fn(t[l])}function sn(e){var t=e.cm,r=t.display;Ln(t),e.updateMaxLine&&we(t),e.mustUpdate=e.viewChanged||e.forceUpdate||null!=e.scrollTop||e.scrollToPos&&(e.scrollToPos.from.line<r.viewFrom||e.scrollToPos.to.line>=r.viewTo)||r.maxLineChanged&&t.options.lineWrapping,e.update=e.mustUpdate&&new Cs(t,e.mustUpdate&&{top:e.scrollTop,ensure:e.scrollToPos},e.forceUpdate)}function an(e){e.updatedDisplay=e.mustUpdate&&Mn(e.cm,e.update)}function un(e){var t=e.cm,r=t.display;e.updatedDisplay&&Er(t),e.barMeasure=Jr(t),r.maxLineChanged&&!t.options.lineWrapping&&(e.adjustWidthTo=Kt(t,r.maxLine,r.maxLine.text.length).left+3,t.display.sizerWidth=e.adjustWidthTo,e.barMeasure.scrollWidth=Math.max(r.scroller.clientWidth,r.sizer.offsetLeft+e.adjustWidthTo+zt(t)+t.display.barWidth),e.maxScrollLeft=Math.max(0,r.sizer.offsetLeft+e.adjustWidthTo-Rt(t))),(e.updatedDisplay||e.selectionChanged)&&(e.preparedSelection=r.input.prepareSelection())}function cn(e){var t=e.cm;null!=e.adjustWidthTo&&(t.display.sizer.style.minWidth=e.adjustWidthTo+"px",e.maxScrollLeft<t.doc.scrollLeft&&Qr(t,Math.min(t.display.scroller.scrollLeft,e.maxScrollLeft),!0),t.display.maxLineChanged=!1);var r=e.focus&&e.focus==l();e.preparedSelection&&t.display.input.showSelection(e.preparedSelection,r),(e.updatedDisplay||e.startHeight!=t.doc.height)&&en(t,e.barMeasure),e.updatedDisplay&&Dn(t,e.barMeasure),e.selectionChanged&&Ar(t),t.state.focused&&e.updateInput&&t.display.input.reset(e.typing),r&&Wr(e.cm)}function fn(e){var t=e.cm,r=t.display,n=t.doc;e.updatedDisplay&&Nn(t,e.update),null==r.wheelStartX||null==e.scrollTop&&null==e.scrollLeft&&!e.scrollToPos||(r.wheelStartX=r.wheelStartY=null),null!=e.scrollTop&&Zr(t,e.scrollTop,e.forceScroll),null!=e.scrollLeft&&Qr(t,e.scrollLeft,!0,!0),e.scrollToPos&&Br(t,Gr(t,U(n,e.scrollToPos.from),U(n,e.scrollToPos.to),e.scrollToPos.margin));var i=e.maybeHiddenMarkers,o=e.maybeUnhiddenMarkers;if(i)for(var l=0;l<i.length;++l)i[l].lines.length||Te(i[l],"hide");if(o)for(var s=0;s<o.length;++s)o[s].lines.length&&Te(o[s],"unhide");r.wrapper.offsetHeight&&(n.scrollTop=t.display.scroller.scrollTop),e.changeObjs&&Te(t,"changes",t,e.changeObjs),e.update&&e.update.finish()}function hn(e,t){if(e.curOp)return t();nn(e);try{return t()}finally{on(e)}}function dn(e,t){return function(){if(e.curOp)return t.apply(e,arguments);nn(e);try{return t.apply(e,arguments)}finally{on(e)}}}function pn(e){return function(){if(this.curOp)return e.apply(this,arguments);nn(this);try{return e.apply(this,arguments)}finally{on(this)}}}function gn(e){return function(){var t=this.cm;if(!t||t.curOp)return e.apply(this,arguments);nn(t);try{return e.apply(this,arguments)}finally{on(t)}}}function vn(e,t,r,n){null==t&&(t=e.doc.first),null==r&&(r=e.doc.first+e.doc.size),n||(n=0);var i=e.display;if(n&&r<i.viewTo&&(null==i.updateLineNumbers||i.updateLineNumbers>t)&&(i.updateLineNumbers=t),e.curOp.viewChanged=!0,t>=i.viewTo)_l&&pe(e.doc,t)<i.viewTo&&yn(e);else if(r<=i.viewFrom)_l&&ge(e.doc,r+n)>i.viewFrom?yn(e):(i.viewFrom+=n,i.viewTo+=n);else if(t<=i.viewFrom&&r>=i.viewTo)yn(e);else if(t<=i.viewFrom){var o=bn(e,r,r+n,1);o?(i.view=i.view.slice(o.index),i.viewFrom=o.lineN,i.viewTo+=n):yn(e)}else if(r>=i.viewTo){var l=bn(e,t,t,-1);l?(i.view=i.view.slice(0,l.index),i.viewTo=l.lineN):yn(e)}else{var s=bn(e,t,t,-1),a=bn(e,r,r+n,1);s&&a?(i.view=i.view.slice(0,s.index).concat(gt(e,s.lineN,a.lineN)).concat(i.view.slice(a.index)),i.viewTo+=n):yn(e)}var u=i.externalMeasured;u&&(r<u.lineN?u.lineN+=n:t<u.lineN+u.size&&(i.externalMeasured=null))}function mn(e,t,r){e.curOp.viewChanged=!0;var n=e.display,i=e.display.externalMeasured;if(i&&t>=i.lineN&&t<i.lineN+i.size&&(n.externalMeasured=null),!(t<n.viewFrom||t>=n.viewTo)){var o=n.view[Lr(e,t)];if(null!=o.node){var l=o.changes||(o.changes=[]);-1==h(l,r)&&l.push(r)}}}function yn(e){e.display.viewFrom=e.display.viewTo=e.doc.first,e.display.view=[],e.display.viewOffset=0}function bn(e,t,r,n){var i,o=Lr(e,t),l=e.display.view;if(!_l||r==e.doc.first+e.doc.size)return{index:o,lineN:r};for(var s=e.display.viewFrom,a=0;a<o;a++)s+=l[a].size;if(s!=t){if(n>0){if(o==l.length-1)return null;i=s+l[o].size-t,o++}else i=s-t;t+=i,r+=i}for(;pe(e.doc,r)!=r;){if(o==(n<0?0:l.length-1))return null;r+=n*l[o-(n<0?1:0)].size,o+=n}return{index:o,lineN:r}}function wn(e,t,r){var n=e.display;0==n.view.length||t>=n.viewTo||r<=n.viewFrom?(n.view=gt(e,t,r),n.viewFrom=t):(n.viewFrom>t?n.view=gt(e,t,n.viewFrom).concat(n.view):n.viewFrom<t&&(n.view=n.view.slice(Lr(e,t))),n.viewFrom=t,n.viewTo<r?n.view=n.view.concat(gt(e,n.viewTo,r)):n.viewTo>r&&(n.view=n.view.slice(0,Lr(e,r)))),n.viewTo=r}function xn(e){for(var t=e.display.view,r=0,n=0;n<t.length;n++){var i=t[n];i.hidden||i.node&&!i.changes||++r}return r}function Cn(e,t){e.doc.highlightFrontier<e.display.viewTo&&e.state.highlight.set(t,u(Sn,e))}function Sn(e){var t=e.doc;if(!(t.highlightFrontier>=e.display.viewTo)){var r=+new Date+e.options.workTime,n=$e(e,t.highlightFrontier),i=[];t.iter(n.line,Math.min(t.first+t.size,e.display.viewTo+500),function(o){if(n.line>=e.display.viewFrom){var l=o.styles,s=o.text.length>e.options.maxHighlightLength?Ke(t.mode,n.state):null,a=Ye(e,o,n,!0);s&&(n.state=s),o.styles=a.styles;var u=o.styleClasses,c=a.classes;c?o.styleClasses=c:u&&(o.styleClasses=null);for(var f=!l||l.length!=o.styles.length||u!=c&&(!u||!c||u.bgClass!=c.bgClass||u.textClass!=c.textClass),h=0;!f&&h<l.length;++h)f=l[h]!=o.styles[h];f&&i.push(n.line),o.stateAfter=n.save(),n.nextLine()}else o.text.length<=e.options.maxHighlightLength&&qe(e,o.text,n),o.stateAfter=n.line%5==0?n.save():null,n.nextLine();if(+new Date>r)return Cn(e,e.options.workDelay),!0}),t.highlightFrontier=n.line,t.modeFrontier=Math.max(t.modeFrontier,n.line),i.length&&hn(e,function(){for(var t=0;t<i.length;t++)mn(e,i[t],"text")})}}function Ln(e){var t=e.display;!t.scrollbarsClipped&&t.scroller.offsetWidth&&(t.nativeBarWidth=t.scroller.offsetWidth-t.scroller.clientWidth,t.heightForcer.style.height=zt(e)+"px",t.sizer.style.marginBottom=-t.nativeBarWidth+"px",t.sizer.style.borderRightWidth=zt(e)+"px",t.scrollbarsClipped=!0)}function kn(e){if(e.hasFocus())return null;var t=l();if(!t||!o(e.display.lineDiv,t))return null;var r={activeElt:t};if(window.getSelection){var n=window.getSelection();n.anchorNode&&n.extend&&o(e.display.lineDiv,n.anchorNode)&&(r.anchorNode=n.anchorNode,r.anchorOffset=n.anchorOffset,r.focusNode=n.focusNode,r.focusOffset=n.focusOffset)}return r}function Tn(e){if(e&&e.activeElt&&e.activeElt!=l()&&(e.activeElt.focus(),e.anchorNode&&o(document.body,e.anchorNode)&&o(document.body,e.focusNode))){var t=window.getSelection(),r=document.createRange();r.setEnd(e.anchorNode,e.anchorOffset),r.collapse(!1),t.removeAllRanges(),t.addRange(r),t.extend(e.focusNode,e.focusOffset)}}function Mn(e,r){var n=e.display,i=e.doc;if(r.editorIsHidden)return yn(e),!1;if(!r.force&&r.visible.from>=n.viewFrom&&r.visible.to<=n.viewTo&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo)&&n.renderedView==n.view&&0==xn(e))return!1;Rr(e)&&(yn(e),r.dims=br(e));var o=i.first+i.size,l=Math.max(r.visible.from-e.options.viewportMargin,i.first),s=Math.min(o,r.visible.to+e.options.viewportMargin);n.viewFrom<l&&l-n.viewFrom<20&&(l=Math.max(i.first,n.viewFrom)),n.viewTo>s&&n.viewTo-s<20&&(s=Math.min(o,n.viewTo)),_l&&(l=pe(e.doc,l),s=ge(e.doc,s));var a=l!=n.viewFrom||s!=n.viewTo||n.lastWrapHeight!=r.wrapperHeight||n.lastWrapWidth!=r.wrapperWidth;wn(e,l,s),n.viewOffset=ye(M(e.doc,n.viewFrom)),e.display.mover.style.top=n.viewOffset+"px";var u=xn(e);if(!a&&0==u&&!r.force&&n.renderedView==n.view&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo))return!1;var c=kn(e);return u>4&&(n.lineDiv.style.display="none"),An(e,n.updateLineNumbers,r.dims),u>4&&(n.lineDiv.style.display=""),n.renderedView=n.view,Tn(c),t(n.cursorDiv),t(n.selectionDiv),n.gutters.style.height=n.sizer.style.minHeight=0,a&&(n.lastWrapHeight=r.wrapperHeight,n.lastWrapWidth=r.wrapperWidth,Cn(e,400)),n.updateLineNumbers=null,!0}function Nn(e,t){for(var r=t.viewport,n=!0;(n&&e.options.lineWrapping&&t.oldDisplayWidth!=Rt(e)||(r&&null!=r.top&&(r={top:Math.min(e.doc.height+Pt(e.display)-Bt(e),r.top)}),t.visible=Ir(e.display,e.doc,r),!(t.visible.from>=e.display.viewFrom&&t.visible.to<=e.display.viewTo)))&&Mn(e,t);n=!1){Er(e);var i=Jr(e);kr(e),en(e,i),Dn(e,i),t.force=!1}t.signal(e,"update",e),e.display.viewFrom==e.display.reportedViewFrom&&e.display.viewTo==e.display.reportedViewTo||(t.signal(e,"viewportChange",e,e.display.viewFrom,e.display.viewTo),e.display.reportedViewFrom=e.display.viewFrom,e.display.reportedViewTo=e.display.viewTo)}function On(e,t){var r=new Cs(e,t);if(Mn(e,r)){Er(e),Nn(e,r);var n=Jr(e);kr(e),en(e,n),Dn(e,n),r.finish()}}function An(e,r,n){function i(t){var r=t.nextSibling;return ml&&Ml&&e.display.currentWheelTarget==t?t.style.display="none":t.parentNode.removeChild(t),r}for(var o=e.display,l=e.options.lineNumbers,s=o.lineDiv,a=s.firstChild,u=o.view,c=o.viewFrom,f=0;f<u.length;f++){var d=u[f];if(d.hidden);else if(d.node&&d.node.parentNode==s){for(;a!=d.node;)a=i(a);var p=l&&null!=r&&r<=c&&d.lineNumber;d.changes&&(h(d.changes,"gutter")>-1&&(p=!1),xt(e,d,c,n)),p&&(t(d.lineNumber),d.lineNumber.appendChild(document.createTextNode(F(e.options,c)))),a=d.node.nextSibling}else{var g=Ot(e,d,c,n);s.insertBefore(g,a)}c+=d.size}for(;a;)a=i(a)}function Wn(e){var t=e.display.gutters.offsetWidth;e.display.sizer.style.marginLeft=t+"px"}function Dn(e,t){e.display.sizer.style.minHeight=t.docHeight+"px",e.display.heightForcer.style.top=t.docHeight+"px",e.display.gutters.style.height=t.docHeight+e.display.barHeight+zt(e)+"px"}function Hn(e){var r=e.display.gutters,i=e.options.gutters;t(r);for(var o=0;o<i.length;++o){var l=i[o],s=r.appendChild(n("div",null,"CodeMirror-gutter "+l));"CodeMirror-linenumbers"==l&&(e.display.lineGutter=s,s.style.width=(e.display.lineNumWidth||1)+"px")}r.style.display=o?"":"none",Wn(e)}function Fn(e){var t=h(e.gutters,"CodeMirror-linenumbers");-1==t&&e.lineNumbers?e.gutters=e.gutters.concat(["CodeMirror-linenumbers"]):t>-1&&!e.lineNumbers&&(e.gutters=e.gutters.slice(0),e.gutters.splice(t,1))}function En(e){var t=e.wheelDeltaX,r=e.wheelDeltaY;return null==t&&e.detail&&e.axis==e.HORIZONTAL_AXIS&&(t=e.detail),null==r&&e.detail&&e.axis==e.VERTICAL_AXIS?r=e.detail:null==r&&(r=e.wheelDelta),{x:t,y:r}}function Pn(e){var t=En(e);return t.x*=Ls,t.y*=Ls,t}function In(e,t){var r=En(t),n=r.x,i=r.y,o=e.display,l=o.scroller,s=l.scrollWidth>l.clientWidth,a=l.scrollHeight>l.clientHeight;if(n&&s||i&&a){if(i&&Ml&&ml)e:for(var u=t.target,c=o.view;u!=l;u=u.parentNode)for(var f=0;f<c.length;f++)if(c[f].node==u){e.display.currentWheelTarget=u;break e}if(n&&!fl&&!wl&&null!=Ls)return i&&a&&qr(e,Math.max(0,l.scrollTop+i*Ls)),Qr(e,Math.max(0,l.scrollLeft+n*Ls)),(!i||i&&a)&&We(t),void(o.wheelStartX=null);if(i&&null!=Ls){var h=i*Ls,d=e.doc.scrollTop,p=d+o.wrapper.clientHeight;h<0?d=Math.max(0,d+h-50):p=Math.min(e.doc.height,p+h+50),On(e,{top:d,bottom:p})}Ss<20&&(null==o.wheelStartX?(o.wheelStartX=l.scrollLeft,o.wheelStartY=l.scrollTop,o.wheelDX=n,o.wheelDY=i,setTimeout(function(){if(null!=o.wheelStartX){var e=l.scrollLeft-o.wheelStartX,t=l.scrollTop-o.wheelStartY,r=t&&o.wheelDY&&t/o.wheelDY||e&&o.wheelDX&&e/o.wheelDX;o.wheelStartX=o.wheelStartY=null,r&&(Ls=(Ls*Ss+r)/(Ss+1),++Ss)}},200)):(o.wheelDX+=n,o.wheelDY+=i))}}function zn(e,t){var r=e[t];e.sort(function(e,t){return P(e.from(),t.from())}),t=h(e,r);for(var n=1;n<e.length;n++){var i=e[n],o=e[n-1];if(P(o.to(),i.from())>=0){var l=B(o.from(),i.from()),s=R(o.to(),i.to()),a=o.empty()?i.from()==i.head:o.from()==o.head;n<=t&&--t,e.splice(--n,2,new Ts(a?s:l,a?l:s))}}return new ks(e,t)}function Rn(e,t){return new ks([new Ts(e,t||e)],0)}function Bn(e){return e.text?E(e.from.line+e.text.length-1,g(e.text).length+(1==e.text.length?e.from.ch:0)):e.to}function Gn(e,t){if(P(e,t.from)<0)return e;if(P(e,t.to)<=0)return Bn(t);var r=e.line+t.text.length-(t.to.line-t.from.line)-1,n=e.ch;return e.line==t.to.line&&(n+=Bn(t).ch-t.to.ch),E(r,n)}function Un(e,t){for(var r=[],n=0;n<e.sel.ranges.length;n++){var i=e.sel.ranges[n];r.push(new Ts(Gn(i.anchor,t),Gn(i.head,t)))}return zn(r,e.sel.primIndex)}function Vn(e,t,r){return e.line==t.line?E(r.line,e.ch-t.ch+r.ch):E(r.line+(e.line-t.line),e.ch)}function Kn(e,t,r){for(var n=[],i=E(e.first,0),o=i,l=0;l<t.length;l++){var s=t[l],a=Vn(s.from,i,o),u=Vn(Bn(s),i,o);if(i=s.to,o=u,"around"==r){var c=e.sel.ranges[l],f=P(c.head,c.anchor)<0;n[l]=new Ts(f?u:a,f?a:u)}else n[l]=new Ts(a,a)}return new ks(n,e.sel.primIndex)}function jn(e){e.doc.mode=Ue(e.options,e.doc.modeOption),Xn(e)}function Xn(e){e.doc.iter(function(e){e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null)}),e.doc.modeFrontier=e.doc.highlightFrontier=e.doc.first,Cn(e,100),e.state.modeGen++,e.curOp&&vn(e)}function Yn(e,t){return 0==t.from.ch&&0==t.to.ch&&""==g(t.text)&&(!e.cm||e.cm.options.wholeLineUpdateBefore)}function _n(e,t,r,n){function i(e){return r?r[e]:null}function o(e,r,i){it(e,r,i,n),bt(e,"change",e,t)}function l(e,t){for(var r=[],o=e;o<t;++o)r.push(new fs(u[o],i(o),n));return r}var s=t.from,a=t.to,u=t.text,c=M(e,s.line),f=M(e,a.line),h=g(u),d=i(u.length-1),p=a.line-s.line;if(t.full)e.insert(0,l(0,u.length)),e.remove(u.length,e.size-u.length);else if(Yn(e,t)){var v=l(0,u.length-1);o(f,f.text,d),p&&e.remove(s.line,p),v.length&&e.insert(s.line,v)}else if(c==f)if(1==u.length)o(c,c.text.slice(0,s.ch)+h+c.text.slice(a.ch),d);else{var m=l(1,u.length-1);m.push(new fs(h+c.text.slice(a.ch),d,n)),o(c,c.text.slice(0,s.ch)+u[0],i(0)),e.insert(s.line+1,m)}else if(1==u.length)o(c,c.text.slice(0,s.ch)+u[0]+f.text.slice(a.ch),i(0)),e.remove(s.line+1,p);else{o(c,c.text.slice(0,s.ch)+u[0],i(0)),o(f,h+f.text.slice(a.ch),d);var y=l(1,u.length-1);p>1&&e.remove(s.line+1,p-1),e.insert(s.line+1,y)}bt(e,"change",e,t)}function $n(e,t,r){function n(e,i,o){if(e.linked)for(var l=0;l<e.linked.length;++l){var s=e.linked[l];if(s.doc!=i){var a=o&&s.sharedHist;r&&!a||(t(s.doc,a),n(s.doc,e,a))}}}n(e,null,!0)}function qn(e,t){if(t.cm)throw new Error("This document is already in use.");e.doc=t,t.cm=e,Cr(e),jn(e),Zn(e),e.options.lineWrapping||we(e),e.options.mode=t.modeOption,vn(e)}function Zn(e){("rtl"==e.doc.direction?s:Fl)(e.display.lineDiv,"CodeMirror-rtl")}function Qn(e){hn(e,function(){Zn(e),vn(e)})}function Jn(e){this.done=[],this.undone=[],this.undoDepth=1/0,this.lastModTime=this.lastSelTime=0,this.lastOp=this.lastSelOp=null,this.lastOrigin=this.lastSelOrigin=null,this.generation=this.maxGeneration=e||1}function ei(e,t){var r={from:z(t.from),to:Bn(t),text:N(e,t.from,t.to)};return si(e,r,t.from.line,t.to.line+1),$n(e,function(e){return si(e,r,t.from.line,t.to.line+1)},!0),r}function ti(e){for(;e.length&&g(e).ranges;)e.pop()}function ri(e,t){return t?(ti(e.done),g(e.done)):e.done.length&&!g(e.done).ranges?g(e.done):e.done.length>1&&!e.done[e.done.length-2].ranges?(e.done.pop(),g(e.done)):void 0}function ni(e,t,r,n){var i=e.history;i.undone.length=0;var o,l,s=+new Date;if((i.lastOp==n||i.lastOrigin==t.origin&&t.origin&&("+"==t.origin.charAt(0)&&e.cm&&i.lastModTime>s-e.cm.options.historyEventDelay||"*"==t.origin.charAt(0)))&&(o=ri(i,i.lastOp==n)))l=g(o.changes),0==P(t.from,t.to)&&0==P(t.from,l.to)?l.to=Bn(t):o.changes.push(ei(e,t));else{var a=g(i.done);for(a&&a.ranges||li(e.sel,i.done),o={changes:[ei(e,t)],generation:i.generation},i.done.push(o);i.done.length>i.undoDepth;)i.done.shift(),i.done[0].ranges||i.done.shift()}i.done.push(r),i.generation=++i.maxGeneration,i.lastModTime=i.lastSelTime=s,i.lastOp=i.lastSelOp=n,i.lastOrigin=i.lastSelOrigin=t.origin,l||Te(e,"historyAdded")}function ii(e,t,r,n){var i=t.charAt(0);return"*"==i||"+"==i&&r.ranges.length==n.ranges.length&&r.somethingSelected()==n.somethingSelected()&&new Date-e.history.lastSelTime<=(e.cm?e.cm.options.historyEventDelay:500)}function oi(e,t,r,n){var i=e.history,o=n&&n.origin;r==i.lastSelOp||o&&i.lastSelOrigin==o&&(i.lastModTime==i.lastSelTime&&i.lastOrigin==o||ii(e,o,g(i.done),t))?i.done[i.done.length-1]=t:li(t,i.done),i.lastSelTime=+new Date,i.lastSelOrigin=o,i.lastSelOp=r,n&&!1!==n.clearRedo&&ti(i.undone)}function li(e,t){var r=g(t);r&&r.ranges&&r.equals(e)||t.push(e)}function si(e,t,r,n){var i=t["spans_"+e.id],o=0;e.iter(Math.max(e.first,r),Math.min(e.first+e.size,n),function(r){r.markedSpans&&((i||(i=t["spans_"+e.id]={}))[o]=r.markedSpans),++o})}function ai(e){if(!e)return null;for(var t,r=0;r<e.length;++r)e[r].marker.explicitlyCleared?t||(t=e.slice(0,r)):t&&t.push(e[r]);return t?t.length?t:null:e}function ui(e,t){var r=t["spans_"+e.id];if(!r)return null;for(var n=[],i=0;i<t.text.length;++i)n.push(ai(r[i]));return n}function ci(e,t){var r=ui(e,t),n=J(e,t);if(!r)return n;if(!n)return r;for(var i=0;i<r.length;++i){var o=r[i],l=n[i];if(o&&l)e:for(var s=0;s<l.length;++s){for(var a=l[s],u=0;u<o.length;++u)if(o[u].marker==a.marker)continue e;o.push(a)}else l&&(r[i]=l)}return r}function fi(e,t,r){for(var n=[],i=0;i<e.length;++i){var o=e[i];if(o.ranges)n.push(r?ks.prototype.deepCopy.call(o):o);else{var l=o.changes,s=[];n.push({changes:s});for(var a=0;a<l.length;++a){var u=l[a],c=void 0;if(s.push({from:u.from,to:u.to,text:u.text}),t)for(var f in u)(c=f.match(/^spans_(\d+)$/))&&h(t,Number(c[1]))>-1&&(g(s)[f]=u[f],delete u[f])}}}return n}function hi(e,t,r,n){if(n){var i=e.anchor;if(r){var o=P(t,i)<0;o!=P(r,i)<0?(i=t,t=r):o!=P(t,r)<0&&(t=r)}return new Ts(i,t)}return new Ts(r||t,t)}function di(e,t,r,n,i){null==i&&(i=e.cm&&(e.cm.display.shift||e.extend)),bi(e,new ks([hi(e.sel.primary(),t,r,i)],0),n)}function pi(e,t,r){for(var n=[],i=e.cm&&(e.cm.display.shift||e.extend),o=0;o<e.sel.ranges.length;o++)n[o]=hi(e.sel.ranges[o],t[o],null,i);bi(e,zn(n,e.sel.primIndex),r)}function gi(e,t,r,n){var i=e.sel.ranges.slice(0);i[t]=r,bi(e,zn(i,e.sel.primIndex),n)}function vi(e,t,r,n){bi(e,Rn(t,r),n)}function mi(e,t,r){var n={ranges:t.ranges,update:function(t){var r=this;this.ranges=[];for(var n=0;n<t.length;n++)r.ranges[n]=new Ts(U(e,t[n].anchor),U(e,t[n].head))},origin:r&&r.origin};return Te(e,"beforeSelectionChange",e,n),e.cm&&Te(e.cm,"beforeSelectionChange",e.cm,n),n.ranges!=t.ranges?zn(n.ranges,n.ranges.length-1):t}function yi(e,t,r){var n=e.history.done,i=g(n);i&&i.ranges?(n[n.length-1]=t,wi(e,t,r)):bi(e,t,r)}function bi(e,t,r){wi(e,t,r),oi(e,e.sel,e.cm?e.cm.curOp.id:NaN,r)}function wi(e,t,r){(Oe(e,"beforeSelectionChange")||e.cm&&Oe(e.cm,"beforeSelectionChange"))&&(t=mi(e,t,r)),xi(e,Si(e,t,r&&r.bias||(P(t.primary().head,e.sel.primary().head)<0?-1:1),!0)),r&&!1===r.scroll||!e.cm||jr(e.cm)}function xi(e,t){t.equals(e.sel)||(e.sel=t,e.cm&&(e.cm.curOp.updateInput=e.cm.curOp.selectionChanged=!0,Ne(e.cm)),bt(e,"cursorActivity",e))}function Ci(e){xi(e,Si(e,e.sel,null,!1))}function Si(e,t,r,n){for(var i,o=0;o<t.ranges.length;o++){var l=t.ranges[o],s=t.ranges.length==e.sel.ranges.length&&e.sel.ranges[o],a=ki(e,l.anchor,s&&s.anchor,r,n),u=ki(e,l.head,s&&s.head,r,n);(i||a!=l.anchor||u!=l.head)&&(i||(i=t.ranges.slice(0,o)),i[o]=new Ts(a,u))}return i?zn(i,t.primIndex):t}function Li(e,t,r,n,i){var o=M(e,t.line);if(o.markedSpans)for(var l=0;l<o.markedSpans.length;++l){var s=o.markedSpans[l],a=s.marker;if((null==s.from||(a.inclusiveLeft?s.from<=t.ch:s.from<t.ch))&&(null==s.to||(a.inclusiveRight?s.to>=t.ch:s.to>t.ch))){if(i&&(Te(a,"beforeCursorEnter"),a.explicitlyCleared)){if(o.markedSpans){--l;continue}break}if(!a.atomic)continue;if(r){var u=a.find(n<0?1:-1),c=void 0;if((n<0?a.inclusiveRight:a.inclusiveLeft)&&(u=Ti(e,u,-n,u&&u.line==t.line?o:null)),u&&u.line==t.line&&(c=P(u,r))&&(n<0?c<0:c>0))return Li(e,u,t,n,i)}var f=a.find(n<0?-1:1);return(n<0?a.inclusiveLeft:a.inclusiveRight)&&(f=Ti(e,f,n,f.line==t.line?o:null)),f?Li(e,f,t,n,i):null}}return t}function ki(e,t,r,n,i){var o=n||1,l=Li(e,t,r,o,i)||!i&&Li(e,t,r,o,!0)||Li(e,t,r,-o,i)||!i&&Li(e,t,r,-o,!0);return l||(e.cantEdit=!0,E(e.first,0))}function Ti(e,t,r,n){return r<0&&0==t.ch?t.line>e.first?U(e,E(t.line-1)):null:r>0&&t.ch==(n||M(e,t.line)).text.length?t.line<e.first+e.size-1?E(t.line+1,0):null:new E(t.line,t.ch+r)}function Mi(e){e.setSelection(E(e.firstLine(),0),E(e.lastLine()),Gl)}function Ni(e,t,r){var n={canceled:!1,from:t.from,to:t.to,text:t.text,origin:t.origin,cancel:function(){return n.canceled=!0}};return r&&(n.update=function(t,r,i,o){t&&(n.from=U(e,t)),r&&(n.to=U(e,r)),i&&(n.text=i),void 0!==o&&(n.origin=o)}),Te(e,"beforeChange",e,n),e.cm&&Te(e.cm,"beforeChange",e.cm,n),n.canceled?null:{from:n.from,to:n.to,text:n.text,origin:n.origin}}function Oi(e,t,r){if(e.cm){if(!e.cm.curOp)return dn(e.cm,Oi)(e,t,r);if(e.cm.state.suppressEdits)return}if(!(Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"))||(t=Ni(e,t,!0))){var n=Yl&&!r&&te(e,t.from,t.to);if(n)for(var i=n.length-1;i>=0;--i)Ai(e,{from:n[i].from,to:n[i].to,text:i?[""]:t.text,origin:t.origin});else Ai(e,t)}}function Ai(e,t){if(1!=t.text.length||""!=t.text[0]||0!=P(t.from,t.to)){var r=Un(e,t);ni(e,t,r,e.cm?e.cm.curOp.id:NaN),Hi(e,t,r,J(e,t));var n=[];$n(e,function(e,r){r||-1!=h(n,e.history)||(zi(e.history,t),n.push(e.history)),Hi(e,t,null,J(e,t))})}}function Wi(e,t,r){if(!e.cm||!e.cm.state.suppressEdits||r){for(var n,i=e.history,o=e.sel,l="undo"==t?i.done:i.undone,s="undo"==t?i.undone:i.done,a=0;a<l.length&&(n=l[a],r?!n.ranges||n.equals(e.sel):n.ranges);a++);if(a!=l.length){for(i.lastOrigin=i.lastSelOrigin=null;(n=l.pop()).ranges;){if(li(n,s),r&&!n.equals(e.sel))return void bi(e,n,{clearRedo:!1});o=n}var u=[];li(o,s),s.push({changes:u,generation:i.generation}),i.generation=n.generation||++i.maxGeneration;for(var c=Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"),f=n.changes.length-1;f>=0;--f){var d=function(r){var i=n.changes[r];if(i.origin=t,c&&!Ni(e,i,!1))return l.length=0,{};u.push(ei(e,i));var o=r?Un(e,i):g(l);Hi(e,i,o,ci(e,i)),!r&&e.cm&&e.cm.scrollIntoView({from:i.from,to:Bn(i)});var s=[];$n(e,function(e,t){t||-1!=h(s,e.history)||(zi(e.history,i),s.push(e.history)),Hi(e,i,null,ci(e,i))})}(f);if(d)return d.v}}}}function Di(e,t){if(0!=t&&(e.first+=t,e.sel=new ks(v(e.sel.ranges,function(e){return new Ts(E(e.anchor.line+t,e.anchor.ch),E(e.head.line+t,e.head.ch))}),e.sel.primIndex),e.cm)){vn(e.cm,e.first,e.first-t,t);for(var r=e.cm.display,n=r.viewFrom;n<r.viewTo;n++)mn(e.cm,n,"gutter")}}function Hi(e,t,r,n){if(e.cm&&!e.cm.curOp)return dn(e.cm,Hi)(e,t,r,n);if(t.to.line<e.first)Di(e,t.text.length-1-(t.to.line-t.from.line));else if(!(t.from.line>e.lastLine())){if(t.from.line<e.first){var i=t.text.length-1-(e.first-t.from.line);Di(e,i),t={from:E(e.first,0),to:E(t.to.line+i,t.to.ch),text:[g(t.text)],origin:t.origin}}var o=e.lastLine();t.to.line>o&&(t={from:t.from,to:E(o,M(e,o).text.length),text:[t.text[0]],origin:t.origin}),t.removed=N(e,t.from,t.to),r||(r=Un(e,t)),e.cm?Fi(e.cm,t,n):_n(e,t,n),wi(e,r,Gl)}}function Fi(e,t,r){var n=e.doc,i=e.display,o=t.from,l=t.to,s=!1,a=o.line;e.options.lineWrapping||(a=W(fe(M(n,o.line))),n.iter(a,l.line+1,function(e){if(e==i.maxLine)return s=!0,!0})),n.sel.contains(t.from,t.to)>-1&&Ne(e),_n(n,t,r,xr(e)),e.options.lineWrapping||(n.iter(a,o.line+t.text.length,function(e){var t=be(e);t>i.maxLineLength&&(i.maxLine=e,i.maxLineLength=t,i.maxLineChanged=!0,s=!1)}),s&&(e.curOp.updateMaxLine=!0)),nt(n,o.line),Cn(e,400);var u=t.text.length-(l.line-o.line)-1;t.full?vn(e):o.line!=l.line||1!=t.text.length||Yn(e.doc,t)?vn(e,o.line,l.line+1,u):mn(e,o.line,"text");var c=Oe(e,"changes"),f=Oe(e,"change");if(f||c){var h={from:o,to:l,text:t.text,removed:t.removed,origin:t.origin};f&&bt(e,"change",e,h),c&&(e.curOp.changeObjs||(e.curOp.changeObjs=[])).push(h)}e.display.selForContextMenu=null}function Ei(e,t,r,n,i){if(n||(n=r),P(n,r)<0){var o;r=(o=[n,r])[0],n=o[1]}"string"==typeof t&&(t=e.splitLines(t)),Oi(e,{from:r,to:n,text:t,origin:i})}function Pi(e,t,r,n){r<e.line?e.line+=n:t<e.line&&(e.line=t,e.ch=0)}function Ii(e,t,r,n){for(var i=0;i<e.length;++i){var o=e[i],l=!0;if(o.ranges){o.copied||((o=e[i]=o.deepCopy()).copied=!0);for(var s=0;s<o.ranges.length;s++)Pi(o.ranges[s].anchor,t,r,n),Pi(o.ranges[s].head,t,r,n)}else{for(var a=0;a<o.changes.length;++a){var u=o.changes[a];if(r<u.from.line)u.from=E(u.from.line+n,u.from.ch),u.to=E(u.to.line+n,u.to.ch);else if(t<=u.to.line){l=!1;break}}l||(e.splice(0,i+1),i=0)}}}function zi(e,t){var r=t.from.line,n=t.to.line,i=t.text.length-(n-r)-1;Ii(e.done,r,n,i),Ii(e.undone,r,n,i)}function Ri(e,t,r,n){var i=t,o=t;return"number"==typeof t?o=M(e,G(e,t)):i=W(t),null==i?null:(n(o,i)&&e.cm&&mn(e.cm,i,r),o)}function Bi(e){var t=this;this.lines=e,this.parent=null;for(var r=0,n=0;n<e.length;++n)e[n].parent=t,r+=e[n].height;this.height=r}function Gi(e){var t=this;this.children=e;for(var r=0,n=0,i=0;i<e.length;++i){var o=e[i];r+=o.chunkSize(),n+=o.height,o.parent=t}this.size=r,this.height=n,this.parent=null}function Ui(e,t,r){ye(t)<(e.curOp&&e.curOp.scrollTop||e.doc.scrollTop)&&Kr(e,r)}function Vi(e,t,r,n){var i=new Ms(e,r,n),o=e.cm;return o&&i.noHScroll&&(o.display.alignWidgets=!0),Ri(e,t,"widget",function(t){var r=t.widgets||(t.widgets=[]);if(null==i.insertAt?r.push(i):r.splice(Math.min(r.length-1,Math.max(0,i.insertAt)),0,i),i.line=t,o&&!ve(e,t)){var n=ye(t)<e.scrollTop;A(t,t.height+Ht(i)),n&&Kr(o,i.height),o.curOp.forceUpdate=!0}return!0}),bt(o,"lineWidgetAdded",o,i,"number"==typeof t?t:W(t)),i}function Ki(e,t,r,n,o){if(n&&n.shared)return ji(e,t,r,n,o);if(e.cm&&!e.cm.curOp)return dn(e.cm,Ki)(e,t,r,n,o);var l=new Os(e,o),s=P(t,r);if(n&&c(n,l,!1),s>0||0==s&&!1!==l.clearWhenEmpty)return l;if(l.replacedWith&&(l.collapsed=!0,l.widgetNode=i("span",[l.replacedWith],"CodeMirror-widget"),n.handleMouseEvents||l.widgetNode.setAttribute("cm-ignore-events","true"),n.insertLeft&&(l.widgetNode.insertLeft=!0)),l.collapsed){if(ce(e,t.line,t,r,l)||t.line!=r.line&&ce(e,r.line,t,r,l))throw new Error("Inserting collapsed marker partially overlapping an existing one");X()}l.addToHistory&&ni(e,{from:t,to:r,origin:"markText"},e.sel,NaN);var a,u=t.line,f=e.cm;if(e.iter(u,r.line+1,function(e){f&&l.collapsed&&!f.options.lineWrapping&&fe(e)==f.display.maxLine&&(a=!0),l.collapsed&&u!=t.line&&A(e,0),q(e,new Y(l,u==t.line?t.ch:null,u==r.line?r.ch:null)),++u}),l.collapsed&&e.iter(t.line,r.line+1,function(t){ve(e,t)&&A(t,0)}),l.clearOnEnter&&Ql(l,"beforeCursorEnter",function(){return l.clear()}),l.readOnly&&(j(),(e.history.done.length||e.history.undone.length)&&e.clearHistory()),l.collapsed&&(l.id=++Ns,l.atomic=!0),f){if(a&&(f.curOp.updateMaxLine=!0),l.collapsed)vn(f,t.line,r.line+1);else if(l.className||l.title||l.startStyle||l.endStyle||l.css)for(var h=t.line;h<=r.line;h++)mn(f,h,"text");l.atomic&&Ci(f.doc),bt(f,"markerAdded",f,l)}return l}function ji(e,t,r,n,i){(n=c(n)).shared=!1;var o=[Ki(e,t,r,n,i)],l=o[0],s=n.widgetNode;return $n(e,function(e){s&&(n.widgetNode=s.cloneNode(!0)),o.push(Ki(e,U(e,t),U(e,r),n,i));for(var a=0;a<e.linked.length;++a)if(e.linked[a].isParent)return;l=g(o)}),new As(o,l)}function Xi(e){return e.findMarks(E(e.first,0),e.clipPos(E(e.lastLine())),function(e){return e.parent})}function Yi(e,t){for(var r=0;r<t.length;r++){var n=t[r],i=n.find(),o=e.clipPos(i.from),l=e.clipPos(i.to);if(P(o,l)){var s=Ki(e,o,l,n.primary,n.primary.type);n.markers.push(s),s.parent=n}}}function _i(e){for(var t=0;t<e.length;t++)!function(t){var r=e[t],n=[r.primary.doc];$n(r.primary.doc,function(e){return n.push(e)});for(var i=0;i<r.markers.length;i++){var o=r.markers[i];-1==h(n,o.doc)&&(o.parent=null,r.markers.splice(i--,1))}}(t)}function $i(e){var t=this;if(Qi(t),!Me(t,e)&&!Ft(t.display,e)){We(e),gl&&(Hs=+new Date);var r=Sr(t,e,!0),n=e.dataTransfer.files;if(r&&!t.isReadOnly())if(n&&n.length&&window.FileReader&&window.File)for(var i=n.length,o=Array(i),l=0,s=0;s<i;++s)!function(e,n){if(!t.options.allowDropFileTypes||-1!=h(t.options.allowDropFileTypes,e.type)){var s=new FileReader;s.onload=dn(t,function(){var e=s.result;if(/[\x00-\x08\x0e-\x1f]{2}/.test(e)&&(e=""),o[n]=e,++l==i){var a={from:r=U(t.doc,r),to:r,text:t.doc.splitLines(o.join(t.doc.lineSeparator())),origin:"paste"};Oi(t.doc,a),yi(t.doc,Rn(r,Bn(a)))}}),s.readAsText(e)}}(n[s],s);else{if(t.state.draggingText&&t.doc.sel.contains(r)>-1)return t.state.draggingText(e),void setTimeout(function(){return t.display.input.focus()},20);try{var a=e.dataTransfer.getData("Text");if(a){var u;if(t.state.draggingText&&!t.state.draggingText.copy&&(u=t.listSelections()),wi(t.doc,Rn(r,r)),u)for(var c=0;c<u.length;++c)Ei(t.doc,"",u[c].anchor,u[c].head,"drag");t.replaceSelection(a,"around","paste"),t.display.input.focus()}}catch(e){}}}}function qi(e,t){if(gl&&(!e.state.draggingText||+new Date-Hs<100))Fe(t);else if(!Me(e,t)&&!Ft(e.display,t)&&(t.dataTransfer.setData("Text",e.getSelection()),t.dataTransfer.effectAllowed="copyMove",t.dataTransfer.setDragImage&&!xl)){var r=n("img",null,null,"position: fixed; left: 0; top: 0;");r.src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==",wl&&(r.width=r.height=1,e.display.wrapper.appendChild(r),r._top=r.offsetTop),t.dataTransfer.setDragImage(r,0,0),wl&&r.parentNode.removeChild(r)}}function Zi(e,t){var i=Sr(e,t);if(i){var o=document.createDocumentFragment();Mr(e,i,o),e.display.dragCursor||(e.display.dragCursor=n("div",null,"CodeMirror-cursors CodeMirror-dragcursors"),e.display.lineSpace.insertBefore(e.display.dragCursor,e.display.cursorDiv)),r(e.display.dragCursor,o)}}function Qi(e){e.display.dragCursor&&(e.display.lineSpace.removeChild(e.display.dragCursor),e.display.dragCursor=null)}function Ji(e){if(document.getElementsByClassName)for(var t=document.getElementsByClassName("CodeMirror"),r=0;r<t.length;r++){var n=t[r].CodeMirror;n&&e(n)}}function eo(){Fs||(to(),Fs=!0)}function to(){var e;Ql(window,"resize",function(){null==e&&(e=setTimeout(function(){e=null,Ji(ro)},100))}),Ql(window,"blur",function(){return Ji(Fr)})}function ro(e){var t=e.display;t.lastWrapHeight==t.wrapper.clientHeight&&t.lastWrapWidth==t.wrapper.clientWidth||(t.cachedCharWidth=t.cachedTextHeight=t.cachedPaddingH=null,t.scrollbarsClipped=!1,e.setSize())}function no(e){var t=e.split(/-(?!$)/);e=t[t.length-1];for(var r,n,i,o,l=0;l<t.length-1;l++){var s=t[l];if(/^(cmd|meta|m)$/i.test(s))o=!0;else if(/^a(lt)?$/i.test(s))r=!0;else if(/^(c|ctrl|control)$/i.test(s))n=!0;else{if(!/^s(hift)?$/i.test(s))throw new Error("Unrecognized modifier name: "+s);i=!0}}return r&&(e="Alt-"+e),n&&(e="Ctrl-"+e),o&&(e="Cmd-"+e),i&&(e="Shift-"+e),e}function io(e){var t={};for(var r in e)if(e.hasOwnProperty(r)){var n=e[r];if(/^(name|fallthrough|(de|at)tach)$/.test(r))continue;if("..."==n){delete e[r];continue}for(var i=v(r.split(" "),no),o=0;o<i.length;o++){var l=void 0,s=void 0;o==i.length-1?(s=i.join(" "),l=n):(s=i.slice(0,o+1).join(" "),l="...");var a=t[s];if(a){if(a!=l)throw new Error("Inconsistent bindings for "+s)}else t[s]=l}delete e[r]}for(var u in t)e[u]=t[u];return e}function oo(e,t,r,n){var i=(t=uo(t)).call?t.call(e,n):t[e];if(!1===i)return"nothing";if("..."===i)return"multi";if(null!=i&&r(i))return"handled";if(t.fallthrough){if("[object Array]"!=Object.prototype.toString.call(t.fallthrough))return oo(e,t.fallthrough,r,n);for(var o=0;o<t.fallthrough.length;o++){var l=oo(e,t.fallthrough[o],r,n);if(l)return l}}}function lo(e){var t="string"==typeof e?e:Es[e.keyCode];return"Ctrl"==t||"Alt"==t||"Shift"==t||"Mod"==t}function so(e,t,r){var n=e;return t.altKey&&"Alt"!=n&&(e="Alt-"+e),(Dl?t.metaKey:t.ctrlKey)&&"Ctrl"!=n&&(e="Ctrl-"+e),(Dl?t.ctrlKey:t.metaKey)&&"Cmd"!=n&&(e="Cmd-"+e),!r&&t.shiftKey&&"Shift"!=n&&(e="Shift-"+e),e}function ao(e,t){if(wl&&34==e.keyCode&&e.char)return!1;var r=Es[e.keyCode];return null!=r&&!e.altGraphKey&&so(r,e,t)}function uo(e){return"string"==typeof e?Rs[e]:e}function co(e,t){for(var r=e.doc.sel.ranges,n=[],i=0;i<r.length;i++){for(var o=t(r[i]);n.length&&P(o.from,g(n).to)<=0;){var l=n.pop();if(P(l.from,o.from)<0){o.from=l.from;break}}n.push(o)}hn(e,function(){for(var t=n.length-1;t>=0;t--)Ei(e.doc,"",n[t].from,n[t].to,"+delete");jr(e)})}function fo(e,t,r){var n=L(e.text,t+r,r);return n<0||n>e.text.length?null:n}function ho(e,t,r){var n=fo(e,t.ch,r);return null==n?null:new E(t.line,n,r<0?"after":"before")}function po(e,t,r,n,i){if(e){var o=Se(r,t.doc.direction);if(o){var l,s=i<0?g(o):o[0],a=i<0==(1==s.level)?"after":"before";if(s.level>0){var u=Xt(t,r);l=i<0?r.text.length-1:0;var c=Yt(t,u,l).top;l=k(function(e){return Yt(t,u,e).top==c},i<0==(1==s.level)?s.from:s.to-1,l),"before"==a&&(l=fo(r,l,1))}else l=i<0?s.to:s.from;return new E(n,l,a)}}return new E(n,i<0?r.text.length:0,i<0?"before":"after")}function go(e,t,r,n){var i=Se(t,e.doc.direction);if(!i)return ho(t,r,n);r.ch>=t.text.length?(r.ch=t.text.length,r.sticky="before"):r.ch<=0&&(r.ch=0,r.sticky="after");var o=Ce(i,r.ch,r.sticky),l=i[o];if("ltr"==e.doc.direction&&l.level%2==0&&(n>0?l.to>r.ch:l.from<r.ch))return ho(t,r,n);var s,a=function(e,r){return fo(t,e instanceof E?e.ch:e,r)},u=function(r){return e.options.lineWrapping?(s=s||Xt(e,t),hr(e,t,s,r)):{begin:0,end:t.text.length}},c=u("before"==r.sticky?a(r,-1):r.ch);if("rtl"==e.doc.direction||1==l.level){var f=1==l.level==n<0,h=a(r,f?1:-1);if(null!=h&&(f?h<=l.to&&h<=c.end:h>=l.from&&h>=c.begin)){var d=f?"before":"after";return new E(r.line,h,d)}}var p=function(e,t,n){for(var o=function(e,t){return t?new E(r.line,a(e,1),"before"):new E(r.line,e,"after")};e>=0&&e<i.length;e+=t){var l=i[e],s=t>0==(1!=l.level),u=s?n.begin:a(n.end,-1);if(l.from<=u&&u<l.to)return o(u,s);if(u=s?l.from:a(l.to,-1),n.begin<=u&&u<n.end)return o(u,s)}},g=p(o+n,n,c);if(g)return g;var v=n>0?c.end:a(c.begin,-1);return null==v||n>0&&v==t.text.length||!(g=p(n>0?0:i.length-1,n,u(v)))?null:g}function vo(e,t){var r=M(e.doc,t),n=fe(r);return n!=r&&(t=W(n)),po(!0,e,n,t,1)}function mo(e,t){var r=M(e.doc,t),n=he(r);return n!=r&&(t=W(n)),po(!0,e,r,t,-1)}function yo(e,t){var r=vo(e,t.line),n=M(e.doc,r.line),i=Se(n,e.doc.direction);if(!i||0==i[0].level){var o=Math.max(0,n.text.search(/\S/)),l=t.line==r.line&&t.ch<=o&&t.ch;return E(r.line,l?0:o,r.sticky)}return r}function bo(e,t,r){if("string"==typeof t&&!(t=Bs[t]))return!1;e.display.input.ensurePolled();var n=e.display.shift,i=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),r&&(e.display.shift=!1),i=t(e)!=Bl}finally{e.display.shift=n,e.state.suppressEdits=!1}return i}function wo(e,t,r){for(var n=0;n<e.state.keyMaps.length;n++){var i=oo(t,e.state.keyMaps[n],r,e);if(i)return i}return e.options.extraKeys&&oo(t,e.options.extraKeys,r,e)||oo(t,e.options.keyMap,r,e)}function xo(e,t,r,n){var i=e.state.keySeq;if(i){if(lo(t))return"handled";Gs.set(50,function(){e.state.keySeq==i&&(e.state.keySeq=null,e.display.input.reset())}),t=i+" "+t}var o=wo(e,t,n);return"multi"==o&&(e.state.keySeq=t),"handled"==o&&bt(e,"keyHandled",e,t,r),"handled"!=o&&"multi"!=o||(We(r),Ar(e)),i&&!o&&/\'$/.test(t)?(We(r),!0):!!o}function Co(e,t){var r=ao(t,!0);return!!r&&(t.shiftKey&&!e.state.keySeq?xo(e,"Shift-"+r,t,function(t){return bo(e,t,!0)})||xo(e,r,t,function(t){if("string"==typeof t?/^go[A-Z]/.test(t):t.motion)return bo(e,t)}):xo(e,r,t,function(t){return bo(e,t)}))}function So(e,t,r){return xo(e,"'"+r+"'",t,function(t){return bo(e,t,!0)})}function Lo(e){var t=this;if(t.curOp.focus=l(),!Me(t,e)){gl&&vl<11&&27==e.keyCode&&(e.returnValue=!1);var r=e.keyCode;t.display.shift=16==r||e.shiftKey;var n=Co(t,e);wl&&(Us=n?r:null,!n&&88==r&&!rs&&(Ml?e.metaKey:e.ctrlKey)&&t.replaceSelection("",null,"cut")),18!=r||/\bCodeMirror-crosshair\b/.test(t.display.lineDiv.className)||ko(t)}}function ko(e){function t(e){18!=e.keyCode&&e.altKey||(Fl(r,"CodeMirror-crosshair"),ke(document,"keyup",t),ke(document,"mouseover",t))}var r=e.display.lineDiv;s(r,"CodeMirror-crosshair"),Ql(document,"keyup",t),Ql(document,"mouseover",t)}function To(e){16==e.keyCode&&(this.doc.sel.shift=!1),Me(this,e)}function Mo(e){var t=this;if(!(Ft(t.display,e)||Me(t,e)||e.ctrlKey&&!e.altKey||Ml&&e.metaKey)){var r=e.keyCode,n=e.charCode;if(wl&&r==Us)return Us=null,void We(e);if(!wl||e.which&&!(e.which<10)||!Co(t,e)){var i=String.fromCharCode(null==n?r:n);"\b"!=i&&(So(t,e,i)||t.display.input.onKeyPress(e))}}}function No(e,t){var r=+new Date;return js&&js.compare(r,e,t)?(Ks=js=null,"triple"):Ks&&Ks.compare(r,e,t)?(js=new Vs(r,e,t),Ks=null,"double"):(Ks=new Vs(r,e,t),js=null,"single")}function Oo(e){var t=this,r=t.display;if(!(Me(t,e)||r.activeTouch&&r.input.supportsTouch()))if(r.input.ensurePolled(),r.shift=e.shiftKey,Ft(r,e))ml||(r.scroller.draggable=!1,setTimeout(function(){return r.scroller.draggable=!0},100));else if(!zo(t,e)){var n=Sr(t,e),i=Pe(e),o=n?No(n,i):"single";window.focus(),1==i&&t.state.selectingText&&t.state.selectingText(e),n&&Ao(t,i,n,o,e)||(1==i?n?Do(t,n,o,e):Ee(e)==r.scroller&&We(e):2==i?(n&&di(t.doc,n),setTimeout(function(){return r.input.focus()},20)):3==i&&(Hl?Ro(t,e):Dr(t)))}}function Ao(e,t,r,n,i){var o="Click";return"double"==n?o="Double"+o:"triple"==n&&(o="Triple"+o),o=(1==t?"Left":2==t?"Middle":"Right")+o,xo(e,so(o,i),i,function(t){if("string"==typeof t&&(t=Bs[t]),!t)return!1;var n=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),n=t(e,r)!=Bl}finally{e.state.suppressEdits=!1}return n})}function Wo(e,t,r){var n=e.getOption("configureMouse"),i=n?n(e,t,r):{};if(null==i.unit){var o=Nl?r.shiftKey&&r.metaKey:r.altKey;i.unit=o?"rectangle":"single"==t?"char":"double"==t?"word":"line"}return(null==i.extend||e.doc.extend)&&(i.extend=e.doc.extend||r.shiftKey),null==i.addNew&&(i.addNew=Ml?r.metaKey:r.ctrlKey),null==i.moveOnDrag&&(i.moveOnDrag=!(Ml?r.altKey:r.ctrlKey)),i}function Do(e,t,r,n){gl?setTimeout(u(Wr,e),0):e.curOp.focus=l();var i,o=Wo(e,r,n),s=e.doc.sel;e.options.dragDrop&&Jl&&!e.isReadOnly()&&"single"==r&&(i=s.contains(t))>-1&&(P((i=s.ranges[i]).from(),t)<0||t.xRel>0)&&(P(i.to(),t)>0||t.xRel<0)?Ho(e,n,t,o):Eo(e,n,t,o)}function Ho(e,t,r,n){var i=e.display,o=!1,l=dn(e,function(t){ml&&(i.scroller.draggable=!1),e.state.draggingText=!1,ke(document,"mouseup",l),ke(document,"mousemove",s),ke(i.scroller,"dragstart",a),ke(i.scroller,"drop",l),o||(We(t),n.addNew||di(e.doc,r,null,null,n.extend),ml||gl&&9==vl?setTimeout(function(){document.body.focus(),i.input.focus()},20):i.input.focus())}),s=function(e){o=o||Math.abs(t.clientX-e.clientX)+Math.abs(t.clientY-e.clientY)>=10},a=function(){return o=!0};ml&&(i.scroller.draggable=!0),e.state.draggingText=l,l.copy=!n.moveOnDrag,i.scroller.dragDrop&&i.scroller.dragDrop(),Ql(document,"mouseup",l),Ql(document,"mousemove",s),Ql(i.scroller,"dragstart",a),Ql(i.scroller,"drop",l),Dr(e),setTimeout(function(){return i.input.focus()},20)}function Fo(e,t,r){if("char"==r)return new Ts(t,t);if("word"==r)return e.findWordAt(t);if("line"==r)return new Ts(E(t.line,0),U(e.doc,E(t.line+1,0)));var n=r(e,t);return new Ts(n.from,n.to)}function Eo(e,t,r,n){function i(t){if(0!=P(m,t))if(m=t,"rectangle"==n.unit){for(var i=[],o=e.options.tabSize,l=f(M(u,r.line).text,r.ch,o),s=f(M(u,t.line).text,t.ch,o),a=Math.min(l,s),g=Math.max(l,s),v=Math.min(r.line,t.line),y=Math.min(e.lastLine(),Math.max(r.line,t.line));v<=y;v++){var b=M(u,v).text,w=d(b,a,o);a==g?i.push(new Ts(E(v,w),E(v,w))):b.length>w&&i.push(new Ts(E(v,w),E(v,d(b,g,o))))}i.length||i.push(new Ts(r,r)),bi(u,zn(p.ranges.slice(0,h).concat(i),h),{origin:"*mouse",scroll:!1}),e.scrollIntoView(t)}else{var x,C=c,S=Fo(e,t,n.unit),L=C.anchor;P(S.anchor,L)>0?(x=S.head,L=B(C.from(),S.anchor)):(x=S.anchor,L=R(C.to(),S.head));var k=p.ranges.slice(0);k[h]=Po(e,new Ts(U(u,L),x)),bi(u,zn(k,h),Ul)}}function o(t){var r=++b,s=Sr(e,t,!0,"rectangle"==n.unit);if(s)if(0!=P(s,m)){e.curOp.focus=l(),i(s);var c=Ir(a,u);(s.line>=c.to||s.line<c.from)&&setTimeout(dn(e,function(){b==r&&o(t)}),150)}else{var f=t.clientY<y.top?-20:t.clientY>y.bottom?20:0;f&&setTimeout(dn(e,function(){b==r&&(a.scroller.scrollTop+=f,o(t))}),50)}}function s(t){e.state.selectingText=!1,b=1/0,We(t),a.input.focus(),ke(document,"mousemove",w),ke(document,"mouseup",x),u.history.lastSelOrigin=null}var a=e.display,u=e.doc;We(t);var c,h,p=u.sel,g=p.ranges;if(n.addNew&&!n.extend?(h=u.sel.contains(r),c=h>-1?g[h]:new Ts(r,r)):(c=u.sel.primary(),h=u.sel.primIndex),"rectangle"==n.unit)n.addNew||(c=new Ts(r,r)),r=Sr(e,t,!0,!0),h=-1;else{var v=Fo(e,r,n.unit);c=n.extend?hi(c,v.anchor,v.head,n.extend):v}n.addNew?-1==h?(h=g.length,bi(u,zn(g.concat([c]),h),{scroll:!1,origin:"*mouse"})):g.length>1&&g[h].empty()&&"char"==n.unit&&!n.extend?(bi(u,zn(g.slice(0,h).concat(g.slice(h+1)),0),{scroll:!1,origin:"*mouse"}),p=u.sel):gi(u,h,c,Ul):(h=0,bi(u,new ks([c],0),Ul),p=u.sel);var m=r,y=a.wrapper.getBoundingClientRect(),b=0,w=dn(e,function(e){Pe(e)?o(e):s(e)}),x=dn(e,s);e.state.selectingText=x,Ql(document,"mousemove",w),Ql(document,"mouseup",x)}function Po(e,t){var r=t.anchor,n=t.head,i=M(e.doc,r.line);if(0==P(r,n)&&r.sticky==n.sticky)return t;var o=Se(i);if(!o)return t;var l=Ce(o,r.ch,r.sticky),s=o[l];if(s.from!=r.ch&&s.to!=r.ch)return t;var a=l+(s.from==r.ch==(1!=s.level)?0:1);if(0==a||a==o.length)return t;var u;if(n.line!=r.line)u=(n.line-r.line)*("ltr"==e.doc.direction?1:-1)>0;else{var c=Ce(o,n.ch,n.sticky),f=c-l||(n.ch-r.ch)*(1==s.level?-1:1);u=c==a-1||c==a?f<0:f>0}var h=o[a+(u?-1:0)],d=u==(1==h.level),p=d?h.from:h.to,g=d?"after":"before";return r.ch==p&&r.sticky==g?t:new Ts(new E(r.line,p,g),n)}function Io(e,t,r,n){var i,o;if(t.touches)i=t.touches[0].clientX,o=t.touches[0].clientY;else try{i=t.clientX,o=t.clientY}catch(t){return!1}if(i>=Math.floor(e.display.gutters.getBoundingClientRect().right))return!1;n&&We(t);var l=e.display,s=l.lineDiv.getBoundingClientRect();if(o>s.bottom||!Oe(e,r))return He(t);o-=s.top-l.viewOffset;for(var a=0;a<e.options.gutters.length;++a){var u=l.gutters.childNodes[a];if(u&&u.getBoundingClientRect().right>=i)return Te(e,r,e,D(e.doc,o),e.options.gutters[a],t),He(t)}}function zo(e,t){return Io(e,t,"gutterClick",!0)}function Ro(e,t){Ft(e.display,t)||Bo(e,t)||Me(e,t,"contextmenu")||e.display.input.onContextMenu(t)}function Bo(e,t){return!!Oe(e,"gutterContextMenu")&&Io(e,t,"gutterContextMenu",!1)}function Go(e){e.display.wrapper.className=e.display.wrapper.className.replace(/\s*cm-s-\S+/g,"")+e.options.theme.replace(/(^|\s)\s*/g," cm-s-"),er(e)}function Uo(e){Hn(e),vn(e),zr(e)}function Vo(e,t,r){if(!t!=!(r&&r!=Xs)){var n=e.display.dragFunctions,i=t?Ql:ke;i(e.display.scroller,"dragstart",n.start),i(e.display.scroller,"dragenter",n.enter),i(e.display.scroller,"dragover",n.over),i(e.display.scroller,"dragleave",n.leave),i(e.display.scroller,"drop",n.drop)}}function Ko(e){e.options.lineWrapping?(s(e.display.wrapper,"CodeMirror-wrap"),e.display.sizer.style.minWidth="",e.display.sizerWidth=null):(Fl(e.display.wrapper,"CodeMirror-wrap"),we(e)),Cr(e),vn(e),er(e),setTimeout(function(){return en(e)},100)}function jo(e,t){var r=this;if(!(this instanceof jo))return new jo(e,t);this.options=t=t?c(t):{},c(Ys,t,!1),Fn(t);var n=t.value;"string"==typeof n&&(n=new Ds(n,t.mode,null,t.lineSeparator,t.direction)),this.doc=n;var i=new jo.inputStyles[t.inputStyle](this),o=this.display=new T(e,n,i);o.wrapper.CodeMirror=this,Hn(this),Go(this),t.lineWrapping&&(this.display.wrapper.className+=" CodeMirror-wrap"),rn(this),this.state={keyMaps:[],overlays:[],modeGen:0,overwrite:!1,delayingBlurEvent:!1,focused:!1,suppressEdits:!1,pasteIncoming:!1,cutIncoming:!1,selectingText:!1,draggingText:!1,highlight:new Pl,keySeq:null,specialChars:null},t.autofocus&&!Tl&&o.input.focus(),gl&&vl<11&&setTimeout(function(){return r.display.input.reset(!0)},20),Xo(this),eo(),nn(this),this.curOp.forceUpdate=!0,qn(this,n),t.autofocus&&!Tl||this.hasFocus()?setTimeout(u(Hr,this),20):Fr(this);for(var l in _s)_s.hasOwnProperty(l)&&_s[l](r,t[l],Xs);Rr(this),t.finishInit&&t.finishInit(this);for(var s=0;s<$s.length;++s)$s[s](r);on(this),ml&&t.lineWrapping&&"optimizelegibility"==getComputedStyle(o.lineDiv).textRendering&&(o.lineDiv.style.textRendering="auto")}function Xo(e){function t(){i.activeTouch&&(o=setTimeout(function(){return i.activeTouch=null},1e3),(l=i.activeTouch).end=+new Date)}function r(e){if(1!=e.touches.length)return!1;var t=e.touches[0];return t.radiusX<=1&&t.radiusY<=1}function n(e,t){if(null==t.left)return!0;var r=t.left-e.left,n=t.top-e.top;return r*r+n*n>400}var i=e.display;Ql(i.scroller,"mousedown",dn(e,Oo)),gl&&vl<11?Ql(i.scroller,"dblclick",dn(e,function(t){if(!Me(e,t)){var r=Sr(e,t);if(r&&!zo(e,t)&&!Ft(e.display,t)){We(t);var n=e.findWordAt(r);di(e.doc,n.anchor,n.head)}}})):Ql(i.scroller,"dblclick",function(t){return Me(e,t)||We(t)}),Hl||Ql(i.scroller,"contextmenu",function(t){return Ro(e,t)});var o,l={end:0};Ql(i.scroller,"touchstart",function(t){if(!Me(e,t)&&!r(t)&&!zo(e,t)){i.input.ensurePolled(),clearTimeout(o);var n=+new Date;i.activeTouch={start:n,moved:!1,prev:n-l.end<=300?l:null},1==t.touches.length&&(i.activeTouch.left=t.touches[0].pageX,i.activeTouch.top=t.touches[0].pageY)}}),Ql(i.scroller,"touchmove",function(){i.activeTouch&&(i.activeTouch.moved=!0)}),Ql(i.scroller,"touchend",function(r){var o=i.activeTouch;if(o&&!Ft(i,r)&&null!=o.left&&!o.moved&&new Date-o.start<300){var l,s=e.coordsChar(i.activeTouch,"page");l=!o.prev||n(o,o.prev)?new Ts(s,s):!o.prev.prev||n(o,o.prev.prev)?e.findWordAt(s):new Ts(E(s.line,0),U(e.doc,E(s.line+1,0))),e.setSelection(l.anchor,l.head),e.focus(),We(r)}t()}),Ql(i.scroller,"touchcancel",t),Ql(i.scroller,"scroll",function(){i.scroller.clientHeight&&(qr(e,i.scroller.scrollTop),Qr(e,i.scroller.scrollLeft,!0),Te(e,"scroll",e))}),Ql(i.scroller,"mousewheel",function(t){return In(e,t)}),Ql(i.scroller,"DOMMouseScroll",function(t){return In(e,t)}),Ql(i.wrapper,"scroll",function(){return i.wrapper.scrollTop=i.wrapper.scrollLeft=0}),i.dragFunctions={enter:function(t){Me(e,t)||Fe(t)},over:function(t){Me(e,t)||(Zi(e,t),Fe(t))},start:function(t){return qi(e,t)},drop:dn(e,$i),leave:function(t){Me(e,t)||Qi(e)}};var s=i.input.getField();Ql(s,"keyup",function(t){return To.call(e,t)}),Ql(s,"keydown",dn(e,Lo)),Ql(s,"keypress",dn(e,Mo)),Ql(s,"focus",function(t){return Hr(e,t)}),Ql(s,"blur",function(t){return Fr(e,t)})}function Yo(e,t,r,n){var i,o=e.doc;null==r&&(r="add"),"smart"==r&&(o.mode.indent?i=$e(e,t).state:r="prev");var l=e.options.tabSize,s=M(o,t),a=f(s.text,null,l);s.stateAfter&&(s.stateAfter=null);var u,c=s.text.match(/^\s*/)[0];if(n||/\S/.test(s.text)){if("smart"==r&&((u=o.mode.indent(i,s.text.slice(c.length),s.text))==Bl||u>150)){if(!n)return;r="prev"}}else u=0,r="not";"prev"==r?u=t>o.first?f(M(o,t-1).text,null,l):0:"add"==r?u=a+e.options.indentUnit:"subtract"==r?u=a-e.options.indentUnit:"number"==typeof r&&(u=a+r),u=Math.max(0,u);var h="",d=0;if(e.options.indentWithTabs)for(var g=Math.floor(u/l);g;--g)d+=l,h+="\t";if(d<u&&(h+=p(u-d)),h!=c)return Ei(o,h,E(t,0),E(t,c.length),"+input"),s.stateAfter=null,!0;for(var v=0;v<o.sel.ranges.length;v++){var m=o.sel.ranges[v];if(m.head.line==t&&m.head.ch<c.length){var y=E(t,c.length);gi(o,v,new Ts(y,y));break}}}function _o(e){qs=e}function $o(e,t,r,n,i){var o=e.doc;e.display.shift=!1,n||(n=o.sel);var l=e.state.pasteIncoming||"paste"==i,s=es(t),a=null;if(l&&n.ranges.length>1)if(qs&&qs.text.join("\n")==t){if(n.ranges.length%qs.text.length==0){a=[];for(var u=0;u<qs.text.length;u++)a.push(o.splitLines(qs.text[u]))}}else s.length==n.ranges.length&&e.options.pasteLinesPerSelection&&(a=v(s,function(e){return[e]}));for(var c,f=n.ranges.length-1;f>=0;f--){var h=n.ranges[f],d=h.from(),p=h.to();h.empty()&&(r&&r>0?d=E(d.line,d.ch-r):e.state.overwrite&&!l?p=E(p.line,Math.min(M(o,p.line).text.length,p.ch+g(s).length)):qs&&qs.lineWise&&qs.text.join("\n")==t&&(d=p=E(d.line,0))),c=e.curOp.updateInput;var m={from:d,to:p,text:a?a[f%a.length]:s,origin:i||(l?"paste":e.state.cutIncoming?"cut":"+input")};Oi(e.doc,m),bt(e,"inputRead",e,m)}t&&!l&&Zo(e,t),jr(e),e.curOp.updateInput=c,e.curOp.typing=!0,e.state.pasteIncoming=e.state.cutIncoming=!1}function qo(e,t){var r=e.clipboardData&&e.clipboardData.getData("Text");if(r)return e.preventDefault(),t.isReadOnly()||t.options.disableInput||hn(t,function(){return $o(t,r,0,null,"paste")}),!0}function Zo(e,t){if(e.options.electricChars&&e.options.smartIndent)for(var r=e.doc.sel,n=r.ranges.length-1;n>=0;n--){var i=r.ranges[n];if(!(i.head.ch>100||n&&r.ranges[n-1].head.line==i.head.line)){var o=e.getModeAt(i.head),l=!1;if(o.electricChars){for(var s=0;s<o.electricChars.length;s++)if(t.indexOf(o.electricChars.charAt(s))>-1){l=Yo(e,i.head.line,"smart");break}}else o.electricInput&&o.electricInput.test(M(e.doc,i.head.line).text.slice(0,i.head.ch))&&(l=Yo(e,i.head.line,"smart"));l&&bt(e,"electricInput",e,i.head.line)}}}function Qo(e){for(var t=[],r=[],n=0;n<e.doc.sel.ranges.length;n++){var i=e.doc.sel.ranges[n].head.line,o={anchor:E(i,0),head:E(i+1,0)};r.push(o),t.push(e.getRange(o.anchor,o.head))}return{text:t,ranges:r}}function Jo(e,t){e.setAttribute("autocorrect","off"),e.setAttribute("autocapitalize","off"),e.setAttribute("spellcheck",!!t)}function el(){var e=n("textarea",null,null,"position: absolute; bottom: -1em; padding: 0; width: 1px; height: 1em; outline: none"),t=n("div",[e],null,"overflow: hidden; position: relative; width: 3px; height: 0px;");return ml?e.style.width="1000px":e.setAttribute("wrap","off"),Ll&&(e.style.border="1px solid black"),Jo(e),t}function tl(e,t,r,n,i){function o(){var n=t.line+r;return!(n<e.first||n>=e.first+e.size)&&(t=new E(n,t.ch,t.sticky),u=M(e,n))}function l(n){var l;if(null==(l=i?go(e.cm,u,t,r):ho(u,t,r))){if(n||!o())return!1;t=po(i,e.cm,u,t.line,r)}else t=l;return!0}var s=t,a=r,u=M(e,t.line);if("char"==n)l();else if("column"==n)l(!0);else if("word"==n||"group"==n)for(var c=null,f="group"==n,h=e.cm&&e.cm.getHelper(t,"wordChars"),d=!0;!(r<0)||l(!d);d=!1){var p=u.text.charAt(t.ch)||"\n",g=x(p,h)?"w":f&&"\n"==p?"n":!f||/\s/.test(p)?null:"p";if(!f||d||g||(g="s"),c&&c!=g){r<0&&(r=1,l(),t.sticky="after");break}if(g&&(c=g),r>0&&!l(!d))break}var v=ki(e,t,s,a,!0);return I(s,v)&&(v.hitSide=!0),v}function rl(e,t,r,n){var i,o=e.doc,l=t.left;if("page"==n){var s=Math.min(e.display.wrapper.clientHeight,window.innerHeight||document.documentElement.clientHeight),a=Math.max(s-.5*mr(e.display),3);i=(r>0?t.bottom:t.top)+r*a}else"line"==n&&(i=r>0?t.bottom+3:t.top-3);for(var u;(u=cr(e,l,i)).outside;){if(r<0?i<=0:i>=o.height){u.hitSide=!0;break}i+=5*r}return u}function nl(e,t){var r=jt(e,t.line);if(!r||r.hidden)return null;var n=M(e.doc,t.line),i=Ut(r,n,t.line),o=Se(n,e.doc.direction),l="left";o&&(l=Ce(o,t.ch)%2?"right":"left");var s=_t(i.map,t.ch,l);return s.offset="right"==s.collapse?s.end:s.start,s}function il(e){for(var t=e;t;t=t.parentNode)if(/CodeMirror-gutter-wrapper/.test(t.className))return!0;return!1}function ol(e,t){return t&&(e.bad=!0),e}function ll(e,t,r,n,i){function o(e){return function(t){return t.id==e}}function l(){c&&(u+=f,c=!1)}function s(e){e&&(l(),u+=e)}function a(t){if(1==t.nodeType){var r=t.getAttribute("cm-text");if(null!=r)return void s(r||t.textContent.replace(/\u200b/g,""));var u,h=t.getAttribute("cm-marker");if(h){var d=e.findMarks(E(n,0),E(i+1,0),o(+h));return void(d.length&&(u=d[0].find(0))&&s(N(e.doc,u.from,u.to).join(f)))}if("false"==t.getAttribute("contenteditable"))return;var p=/^(pre|div|p)$/i.test(t.nodeName);p&&l();for(var g=0;g<t.childNodes.length;g++)a(t.childNodes[g]);p&&(c=!0)}else 3==t.nodeType&&s(t.nodeValue)}for(var u="",c=!1,f=e.doc.lineSeparator();a(t),t!=r;)t=t.nextSibling;return u}function sl(e,t,r){var n;if(t==e.display.lineDiv){if(!(n=e.display.lineDiv.childNodes[r]))return ol(e.clipPos(E(e.display.viewTo-1)),!0);t=null,r=0}else for(n=t;;n=n.parentNode){if(!n||n==e.display.lineDiv)return null;if(n.parentNode&&n.parentNode==e.display.lineDiv)break}for(var i=0;i<e.display.view.length;i++){var o=e.display.view[i];if(o.node==n)return al(o,t,r)}}function al(e,t,r){function n(t,r,n){for(var i=-1;i<(f?f.length:0);i++)for(var o=i<0?c.map:f[i],l=0;l<o.length;l+=3){var s=o[l+2];if(s==t||s==r){var a=W(i<0?e.line:e.rest[i]),u=o[l]+n;return(n<0||s!=t)&&(u=o[l+(n?1:0)]),E(a,u)}}}var i=e.text.firstChild,l=!1;if(!t||!o(i,t))return ol(E(W(e.line),0),!0);if(t==i&&(l=!0,t=i.childNodes[r],r=0,!t)){var s=e.rest?g(e.rest):e.line;return ol(E(W(s),s.text.length),l)}var a=3==t.nodeType?t:null,u=t;for(a||1!=t.childNodes.length||3!=t.firstChild.nodeType||(a=t.firstChild,r&&(r=a.nodeValue.length));u.parentNode!=i;)u=u.parentNode;var c=e.measure,f=c.maps,h=n(a,u,r);if(h)return ol(h,l);for(var d=u.nextSibling,p=a?a.nodeValue.length-r:0;d;d=d.nextSibling){if(h=n(d,d.firstChild,0))return ol(E(h.line,h.ch-p),l);p+=d.textContent.length}for(var v=u.previousSibling,m=r;v;v=v.previousSibling){if(h=n(v,v.firstChild,-1))return ol(E(h.line,h.ch+m),l);m+=v.textContent.length}}var ul=navigator.userAgent,cl=navigator.platform,fl=/gecko\/\d/i.test(ul),hl=/MSIE \d/.test(ul),dl=/Trident\/(?:[7-9]|\d{2,})\..*rv:(\d+)/.exec(ul),pl=/Edge\/(\d+)/.exec(ul),gl=hl||dl||pl,vl=gl&&(hl?document.documentMode||6:+(pl||dl)[1]),ml=!pl&&/WebKit\//.test(ul),yl=ml&&/Qt\/\d+\.\d+/.test(ul),bl=!pl&&/Chrome\//.test(ul),wl=/Opera\//.test(ul),xl=/Apple Computer/.test(navigator.vendor),Cl=/Mac OS X 1\d\D([8-9]|\d\d)\D/.test(ul),Sl=/PhantomJS/.test(ul),Ll=!pl&&/AppleWebKit/.test(ul)&&/Mobile\/\w+/.test(ul),kl=/Android/.test(ul),Tl=Ll||kl||/webOS|BlackBerry|Opera Mini|Opera Mobi|IEMobile/i.test(ul),Ml=Ll||/Mac/.test(cl),Nl=/\bCrOS\b/.test(ul),Ol=/win/i.test(cl),Al=wl&&ul.match(/Version\/(\d*\.\d*)/);Al&&(Al=Number(Al[1])),Al&&Al>=15&&(wl=!1,ml=!0);var Wl,Dl=Ml&&(yl||wl&&(null==Al||Al<12.11)),Hl=fl||gl&&vl>=9,Fl=function(t,r){var n=t.className,i=e(r).exec(n);if(i){var o=n.slice(i.index+i[0].length);t.className=n.slice(0,i.index)+(o?i[1]+o:"")}};Wl=document.createRange?function(e,t,r,n){var i=document.createRange();return i.setEnd(n||e,r),i.setStart(e,t),i}:function(e,t,r){var n=document.body.createTextRange();try{n.moveToElementText(e.parentNode)}catch(e){return n}return n.collapse(!0),n.moveEnd("character",r),n.moveStart("character",t),n};var El=function(e){e.select()};Ll?El=function(e){e.selectionStart=0,e.selectionEnd=e.value.length}:gl&&(El=function(e){try{e.select()}catch(e){}});var Pl=function(){this.id=null};Pl.prototype.set=function(e,t){clearTimeout(this.id),this.id=setTimeout(t,e)};var Il,zl,Rl=30,Bl={toString:function(){return"CodeMirror.Pass"}},Gl={scroll:!1},Ul={origin:"*mouse"},Vl={origin:"+move"},Kl=[""],jl=/[\u00df\u0587\u0590-\u05f4\u0600-\u06ff\u3040-\u309f\u30a0-\u30ff\u3400-\u4db5\u4e00-\u9fcc\uac00-\ud7af]/,Xl=/[\u0300-\u036f\u0483-\u0489\u0591-\u05bd\u05bf\u05c1\u05c2\u05c4\u05c5\u05c7\u0610-\u061a\u064b-\u065e\u0670\u06d6-\u06dc\u06de-\u06e4\u06e7\u06e8\u06ea-\u06ed\u0711\u0730-\u074a\u07a6-\u07b0\u07eb-\u07f3\u0816-\u0819\u081b-\u0823\u0825-\u0827\u0829-\u082d\u0900-\u0902\u093c\u0941-\u0948\u094d\u0951-\u0955\u0962\u0963\u0981\u09bc\u09be\u09c1-\u09c4\u09cd\u09d7\u09e2\u09e3\u0a01\u0a02\u0a3c\u0a41\u0a42\u0a47\u0a48\u0a4b-\u0a4d\u0a51\u0a70\u0a71\u0a75\u0a81\u0a82\u0abc\u0ac1-\u0ac5\u0ac7\u0ac8\u0acd\u0ae2\u0ae3\u0b01\u0b3c\u0b3e\u0b3f\u0b41-\u0b44\u0b4d\u0b56\u0b57\u0b62\u0b63\u0b82\u0bbe\u0bc0\u0bcd\u0bd7\u0c3e-\u0c40\u0c46-\u0c48\u0c4a-\u0c4d\u0c55\u0c56\u0c62\u0c63\u0cbc\u0cbf\u0cc2\u0cc6\u0ccc\u0ccd\u0cd5\u0cd6\u0ce2\u0ce3\u0d3e\u0d41-\u0d44\u0d4d\u0d57\u0d62\u0d63\u0dca\u0dcf\u0dd2-\u0dd4\u0dd6\u0ddf\u0e31\u0e34-\u0e3a\u0e47-\u0e4e\u0eb1\u0eb4-\u0eb9\u0ebb\u0ebc\u0ec8-\u0ecd\u0f18\u0f19\u0f35\u0f37\u0f39\u0f71-\u0f7e\u0f80-\u0f84\u0f86\u0f87\u0f90-\u0f97\u0f99-\u0fbc\u0fc6\u102d-\u1030\u1032-\u1037\u1039\u103a\u103d\u103e\u1058\u1059\u105e-\u1060\u1071-\u1074\u1082\u1085\u1086\u108d\u109d\u135f\u1712-\u1714\u1732-\u1734\u1752\u1753\u1772\u1773\u17b7-\u17bd\u17c6\u17c9-\u17d3\u17dd\u180b-\u180d\u18a9\u1920-\u1922\u1927\u1928\u1932\u1939-\u193b\u1a17\u1a18\u1a56\u1a58-\u1a5e\u1a60\u1a62\u1a65-\u1a6c\u1a73-\u1a7c\u1a7f\u1b00-\u1b03\u1b34\u1b36-\u1b3a\u1b3c\u1b42\u1b6b-\u1b73\u1b80\u1b81\u1ba2-\u1ba5\u1ba8\u1ba9\u1c2c-\u1c33\u1c36\u1c37\u1cd0-\u1cd2\u1cd4-\u1ce0\u1ce2-\u1ce8\u1ced\u1dc0-\u1de6\u1dfd-\u1dff\u200c\u200d\u20d0-\u20f0\u2cef-\u2cf1\u2de0-\u2dff\u302a-\u302f\u3099\u309a\ua66f-\ua672\ua67c\ua67d\ua6f0\ua6f1\ua802\ua806\ua80b\ua825\ua826\ua8c4\ua8e0-\ua8f1\ua926-\ua92d\ua947-\ua951\ua980-\ua982\ua9b3\ua9b6-\ua9b9\ua9bc\uaa29-\uaa2e\uaa31\uaa32\uaa35\uaa36\uaa43\uaa4c\uaab0\uaab2-\uaab4\uaab7\uaab8\uaabe\uaabf\uaac1\uabe5\uabe8\uabed\udc00-\udfff\ufb1e\ufe00-\ufe0f\ufe20-\ufe26\uff9e\uff9f]/,Yl=!1,_l=!1,$l=null,ql=function(){function e(e){return e<=247?r.charAt(e):1424<=e&&e<=1524?"R":1536<=e&&e<=1785?n.charAt(e-1536):1774<=e&&e<=2220?"r":8192<=e&&e<=8203?"w":8204==e?"b":"L"}function t(e,t,r){this.level=e,this.from=t,this.to=r}var r="bbbbbbbbbtstwsbbbbbbbbbbbbbbssstwNN%%%NNNNNN,N,N1111111111NNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNbbbbbbsbbbbbbbbbbbbbbbbbbbbbbbbbb,N%%%%NNNNLNNNNN%%11NLNNN1LNNNNNLLLLLLLLLLLLLLLLLLLLLLLNLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLN",n="nnnnnnNNr%%r,rNNmmmmmmmmmmmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmmmmmmmmmmmmmmmnnnnnnnnnn%nnrrrmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmnNmmmmmmrrmmNmmmmrr1111111111",i=/[\u0590-\u05f4\u0600-\u06ff\u0700-\u08ac]/,o=/[stwN]/,l=/[LRr]/,s=/[Lb1n]/,a=/[1n]/;return function(r,n){var u="ltr"==n?"L":"R";if(0==r.length||"ltr"==n&&!i.test(r))return!1;for(var c=r.length,f=[],h=0;h<c;++h)f.push(e(r.charCodeAt(h)));for(var d=0,p=u;d<c;++d){var v=f[d];"m"==v?f[d]=p:p=v}for(var m=0,y=u;m<c;++m){var b=f[m];"1"==b&&"r"==y?f[m]="n":l.test(b)&&(y=b,"r"==b&&(f[m]="R"))}for(var w=1,x=f[0];w<c-1;++w){var C=f[w];"+"==C&&"1"==x&&"1"==f[w+1]?f[w]="1":","!=C||x!=f[w+1]||"1"!=x&&"n"!=x||(f[w]=x),x=C}for(var S=0;S<c;++S){var L=f[S];if(","==L)f[S]="N";else if("%"==L){var k=void 0;for(k=S+1;k<c&&"%"==f[k];++k);for(var T=S&&"!"==f[S-1]||k<c&&"1"==f[k]?"1":"N",M=S;M<k;++M)f[M]=T;S=k-1}}for(var N=0,O=u;N<c;++N){var A=f[N];"L"==O&&"1"==A?f[N]="L":l.test(A)&&(O=A)}for(var W=0;W<c;++W)if(o.test(f[W])){var D=void 0;for(D=W+1;D<c&&o.test(f[D]);++D);for(var H="L"==(W?f[W-1]:u),F=H==("L"==(D<c?f[D]:u))?H?"L":"R":u,E=W;E<D;++E)f[E]=F;W=D-1}for(var P,I=[],z=0;z<c;)if(s.test(f[z])){var R=z;for(++z;z<c&&s.test(f[z]);++z);I.push(new t(0,R,z))}else{var B=z,G=I.length;for(++z;z<c&&"L"!=f[z];++z);for(var U=B;U<z;)if(a.test(f[U])){B<U&&I.splice(G,0,new t(1,B,U));var V=U;for(++U;U<z&&a.test(f[U]);++U);I.splice(G,0,new t(2,V,U)),B=U}else++U;B<z&&I.splice(G,0,new t(1,B,z))}return 1==I[0].level&&(P=r.match(/^\s+/))&&(I[0].from=P[0].length,I.unshift(new t(0,0,P[0].length))),1==g(I).level&&(P=r.match(/\s+$/))&&(g(I).to-=P[0].length,I.push(new t(0,c-P[0].length,c))),"rtl"==n?I.reverse():I}}(),Zl=[],Ql=function(e,t,r){if(e.addEventListener)e.addEventListener(t,r,!1);else if(e.attachEvent)e.attachEvent("on"+t,r);else{var n=e._handlers||(e._handlers={});n[t]=(n[t]||Zl).concat(r)}},Jl=function(){if(gl&&vl<9)return!1;var e=n("div");return"draggable"in e||"dragDrop"in e}(),es=3!="\n\nb".split(/\n/).length?function(e){for(var t=0,r=[],n=e.length;t<=n;){var i=e.indexOf("\n",t);-1==i&&(i=e.length);var o=e.slice(t,"\r"==e.charAt(i-1)?i-1:i),l=o.indexOf("\r");-1!=l?(r.push(o.slice(0,l)),t+=l+1):(r.push(o),t=i+1)}return r}:function(e){return e.split(/\r\n?|\n/)},ts=window.getSelection?function(e){try{return e.selectionStart!=e.selectionEnd}catch(e){return!1}}:function(e){var t;try{t=e.ownerDocument.selection.createRange()}catch(e){}return!(!t||t.parentElement()!=e)&&0!=t.compareEndPoints("StartToEnd",t)},rs=function(){var e=n("div");return"oncopy"in e||(e.setAttribute("oncopy","return;"),"function"==typeof e.oncopy)}(),ns=null,is={},os={},ls={},ss=function(e,t,r){this.pos=this.start=0,this.string=e,this.tabSize=t||8,this.lastColumnPos=this.lastColumnValue=0,this.lineStart=0,this.lineOracle=r};ss.prototype.eol=function(){return this.pos>=this.string.length},ss.prototype.sol=function(){return this.pos==this.lineStart},ss.prototype.peek=function(){return this.string.charAt(this.pos)||void 0},ss.prototype.next=function(){if(this.pos<this.string.length)return this.string.charAt(this.pos++)},ss.prototype.eat=function(e){var t=this.string.charAt(this.pos);if("string"==typeof e?t==e:t&&(e.test?e.test(t):e(t)))return++this.pos,t},ss.prototype.eatWhile=function(e){for(var t=this.pos;this.eat(e););return this.pos>t},ss.prototype.eatSpace=function(){for(var e=this,t=this.pos;/[\s\u00a0]/.test(this.string.charAt(this.pos));)++e.pos;return this.pos>t},ss.prototype.skipToEnd=function(){this.pos=this.string.length},ss.prototype.skipTo=function(e){var t=this.string.indexOf(e,this.pos);if(t>-1)return this.pos=t,!0},ss.prototype.backUp=function(e){this.pos-=e},ss.prototype.column=function(){return this.lastColumnPos<this.start&&(this.lastColumnValue=f(this.string,this.start,this.tabSize,this.lastColumnPos,this.lastColumnValue),this.lastColumnPos=this.start),this.lastColumnValue-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.indentation=function(){return f(this.string,null,this.tabSize)-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.match=function(e,t,r){if("string"!=typeof e){var n=this.string.slice(this.pos).match(e);return n&&n.index>0?null:(n&&!1!==t&&(this.pos+=n[0].length),n)}var i=function(e){return r?e.toLowerCase():e};if(i(this.string.substr(this.pos,e.length))==i(e))return!1!==t&&(this.pos+=e.length),!0},ss.prototype.current=function(){return this.string.slice(this.start,this.pos)},ss.prototype.hideFirstChars=function(e,t){this.lineStart+=e;try{return t()}finally{this.lineStart-=e}},ss.prototype.lookAhead=function(e){var t=this.lineOracle;return t&&t.lookAhead(e)};var as=function(e,t){this.state=e,this.lookAhead=t},us=function(e,t,r,n){this.state=t,this.doc=e,this.line=r,this.maxLookAhead=n||0};us.prototype.lookAhead=function(e){var t=this.doc.getLine(this.line+e);return null!=t&&e>this.maxLookAhead&&(this.maxLookAhead=e),t},us.prototype.nextLine=function(){this.line++,this.maxLookAhead>0&&this.maxLookAhead--},us.fromSaved=function(e,t,r){return t instanceof as?new us(e,Ke(e.mode,t.state),r,t.lookAhead):new us(e,Ke(e.mode,t),r)},us.prototype.save=function(e){var t=!1!==e?Ke(this.doc.mode,this.state):this.state;return this.maxLookAhead>0?new as(t,this.maxLookAhead):t};var cs=function(e,t,r){this.start=e.start,this.end=e.pos,this.string=e.current(),this.type=t||null,this.state=r},fs=function(e,t,r){this.text=e,ne(this,t),this.height=r?r(this):1};fs.prototype.lineNo=function(){return W(this)},Ae(fs);var hs,ds={},ps={},gs=null,vs=null,ms={left:0,right:0,top:0,bottom:0},ys=function(e,t,r){this.cm=r;var i=this.vert=n("div",[n("div",null,null,"min-width: 1px")],"CodeMirror-vscrollbar"),o=this.horiz=n("div",[n("div",null,null,"height: 100%; min-height: 1px")],"CodeMirror-hscrollbar");e(i),e(o),Ql(i,"scroll",function(){i.clientHeight&&t(i.scrollTop,"vertical")}),Ql(o,"scroll",function(){o.clientWidth&&t(o.scrollLeft,"horizontal")}),this.checkedZeroWidth=!1,gl&&vl<8&&(this.horiz.style.minHeight=this.vert.style.minWidth="18px")};ys.prototype.update=function(e){var t=e.scrollWidth>e.clientWidth+1,r=e.scrollHeight>e.clientHeight+1,n=e.nativeBarWidth;if(r){this.vert.style.display="block",this.vert.style.bottom=t?n+"px":"0";var i=e.viewHeight-(t?n:0);this.vert.firstChild.style.height=Math.max(0,e.scrollHeight-e.clientHeight+i)+"px"}else this.vert.style.display="",this.vert.firstChild.style.height="0";if(t){this.horiz.style.display="block",this.horiz.style.right=r?n+"px":"0",this.horiz.style.left=e.barLeft+"px";var o=e.viewWidth-e.barLeft-(r?n:0);this.horiz.firstChild.style.width=Math.max(0,e.scrollWidth-e.clientWidth+o)+"px"}else this.horiz.style.display="",this.horiz.firstChild.style.width="0";return!this.checkedZeroWidth&&e.clientHeight>0&&(0==n&&this.zeroWidthHack(),this.checkedZeroWidth=!0),{right:r?n:0,bottom:t?n:0}},ys.prototype.setScrollLeft=function(e){this.horiz.scrollLeft!=e&&(this.horiz.scrollLeft=e),this.disableHoriz&&this.enableZeroWidthBar(this.horiz,this.disableHoriz,"horiz")},ys.prototype.setScrollTop=function(e){this.vert.scrollTop!=e&&(this.vert.scrollTop=e),this.disableVert&&this.enableZeroWidthBar(this.vert,this.disableVert,"vert")},ys.prototype.zeroWidthHack=function(){var e=Ml&&!Cl?"12px":"18px";this.horiz.style.height=this.vert.style.width=e,this.horiz.style.pointerEvents=this.vert.style.pointerEvents="none",this.disableHoriz=new Pl,this.disableVert=new Pl},ys.prototype.enableZeroWidthBar=function(e,t,r){function n(){var i=e.getBoundingClientRect();("vert"==r?document.elementFromPoint(i.right-1,(i.top+i.bottom)/2):document.elementFromPoint((i.right+i.left)/2,i.bottom-1))!=e?e.style.pointerEvents="none":t.set(1e3,n)}e.style.pointerEvents="auto",t.set(1e3,n)},ys.prototype.clear=function(){var e=this.horiz.parentNode;e.removeChild(this.horiz),e.removeChild(this.vert)};var bs=function(){};bs.prototype.update=function(){return{bottom:0,right:0}},bs.prototype.setScrollLeft=function(){},bs.prototype.setScrollTop=function(){},bs.prototype.clear=function(){};var ws={native:ys,null:bs},xs=0,Cs=function(e,t,r){var n=e.display;this.viewport=t,this.visible=Ir(n,e.doc,t),this.editorIsHidden=!n.wrapper.offsetWidth,this.wrapperHeight=n.wrapper.clientHeight,this.wrapperWidth=n.wrapper.clientWidth,this.oldDisplayWidth=Rt(e),this.force=r,this.dims=br(e),this.events=[]};Cs.prototype.signal=function(e,t){Oe(e,t)&&this.events.push(arguments)},Cs.prototype.finish=function(){for(var e=this,t=0;t<this.events.length;t++)Te.apply(null,e.events[t])};var Ss=0,Ls=null;gl?Ls=-.53:fl?Ls=15:bl?Ls=-.7:xl&&(Ls=-1/3);var ks=function(e,t){this.ranges=e,this.primIndex=t};ks.prototype.primary=function(){return this.ranges[this.primIndex]},ks.prototype.equals=function(e){var t=this;if(e==this)return!0;if(e.primIndex!=this.primIndex||e.ranges.length!=this.ranges.length)return!1;for(var r=0;r<this.ranges.length;r++){var n=t.ranges[r],i=e.ranges[r];if(!I(n.anchor,i.anchor)||!I(n.head,i.head))return!1}return!0},ks.prototype.deepCopy=function(){for(var e=this,t=[],r=0;r<this.ranges.length;r++)t[r]=new Ts(z(e.ranges[r].anchor),z(e.ranges[r].head));return new ks(t,this.primIndex)},ks.prototype.somethingSelected=function(){for(var e=this,t=0;t<this.ranges.length;t++)if(!e.ranges[t].empty())return!0;return!1},ks.prototype.contains=function(e,t){var r=this;t||(t=e);for(var n=0;n<this.ranges.length;n++){var i=r.ranges[n];if(P(t,i.from())>=0&&P(e,i.to())<=0)return n}return-1};var Ts=function(e,t){this.anchor=e,this.head=t};Ts.prototype.from=function(){return B(this.anchor,this.head)},Ts.prototype.to=function(){return R(this.anchor,this.head)},Ts.prototype.empty=function(){return this.head.line==this.anchor.line&&this.head.ch==this.anchor.ch},Bi.prototype={chunkSize:function(){return this.lines.length},removeInner:function(e,t){for(var r=this,n=e,i=e+t;n<i;++n){var o=r.lines[n];r.height-=o.height,ot(o),bt(o,"delete")}this.lines.splice(e,t)},collapse:function(e){e.push.apply(e,this.lines)},insertInner:function(e,t,r){var n=this;this.height+=r,this.lines=this.lines.slice(0,e).concat(t).concat(this.lines.slice(e));for(var i=0;i<t.length;++i)t[i].parent=n},iterN:function(e,t,r){for(var n=this,i=e+t;e<i;++e)if(r(n.lines[e]))return!0}},Gi.prototype={chunkSize:function(){return this.size},removeInner:function(e,t){var r=this;this.size-=t;for(var n=0;n<this.children.length;++n){var i=r.children[n],o=i.chunkSize();if(e<o){var l=Math.min(t,o-e),s=i.height;if(i.removeInner(e,l),r.height-=s-i.height,o==l&&(r.children.splice(n--,1),i.parent=null),0==(t-=l))break;e=0}else e-=o}if(this.size-t<25&&(this.children.length>1||!(this.children[0]instanceof Bi))){var a=[];this.collapse(a),this.children=[new Bi(a)],this.children[0].parent=this}},collapse:function(e){for(var t=this,r=0;r<this.children.length;++r)t.children[r].collapse(e)},insertInner:function(e,t,r){var n=this;this.size+=t.length,this.height+=r;for(var i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<=l){if(o.insertInner(e,t,r),o.lines&&o.lines.length>50){for(var s=o.lines.length%25+25,a=s;a<o.lines.length;){var u=new Bi(o.lines.slice(a,a+=25));o.height-=u.height,n.children.splice(++i,0,u),u.parent=n}o.lines=o.lines.slice(0,s),n.maybeSpill()}break}e-=l}},maybeSpill:function(){if(!(this.children.length<=10)){var e=this;do{var t=new Gi(e.children.splice(e.children.length-5,5));if(e.parent){e.size-=t.size,e.height-=t.height;var r=h(e.parent.children,e);e.parent.children.splice(r+1,0,t)}else{var n=new Gi(e.children);n.parent=e,e.children=[n,t],e=n}t.parent=e.parent}while(e.children.length>10);e.parent.maybeSpill()}},iterN:function(e,t,r){for(var n=this,i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<l){var s=Math.min(t,l-e);if(o.iterN(e,s,r))return!0;if(0==(t-=s))break;e=0}else e-=l}}};var Ms=function(e,t,r){var n=this;if(r)for(var i in r)r.hasOwnProperty(i)&&(n[i]=r[i]);this.doc=e,this.node=t};Ms.prototype.clear=function(){var e=this,t=this.doc.cm,r=this.line.widgets,n=this.line,i=W(n);if(null!=i&&r){for(var o=0;o<r.length;++o)r[o]==e&&r.splice(o--,1);r.length||(n.widgets=null);var l=Ht(this);A(n,Math.max(0,n.height-l)),t&&(hn(t,function(){Ui(t,n,-l),mn(t,i,"widget")}),bt(t,"lineWidgetCleared",t,this,i))}},Ms.prototype.changed=function(){var e=this,t=this.height,r=this.doc.cm,n=this.line;this.height=null;var i=Ht(this)-t;i&&(A(n,n.height+i),r&&hn(r,function(){r.curOp.forceUpdate=!0,Ui(r,n,i),bt(r,"lineWidgetChanged",r,e,W(n))}))},Ae(Ms);var Ns=0,Os=function(e,t){this.lines=[],this.type=t,this.doc=e,this.id=++Ns};Os.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){var t=this.doc.cm,r=t&&!t.curOp;if(r&&nn(t),Oe(this,"clear")){var n=this.find();n&&bt(this,"clear",n.from,n.to)}for(var i=null,o=null,l=0;l<this.lines.length;++l){var s=e.lines[l],a=_(s.markedSpans,e);t&&!e.collapsed?mn(t,W(s),"text"):t&&(null!=a.to&&(o=W(s)),null!=a.from&&(i=W(s))),s.markedSpans=$(s.markedSpans,a),null==a.from&&e.collapsed&&!ve(e.doc,s)&&t&&A(s,mr(t.display))}if(t&&this.collapsed&&!t.options.lineWrapping)for(var u=0;u<this.lines.length;++u){var c=fe(e.lines[u]),f=be(c);f>t.display.maxLineLength&&(t.display.maxLine=c,t.display.maxLineLength=f,t.display.maxLineChanged=!0)}null!=i&&t&&this.collapsed&&vn(t,i,o+1),this.lines.length=0,this.explicitlyCleared=!0,this.atomic&&this.doc.cantEdit&&(this.doc.cantEdit=!1,t&&Ci(t.doc)),t&&bt(t,"markerCleared",t,this,i,o),r&&on(t),this.parent&&this.parent.clear()}},Os.prototype.find=function(e,t){var r=this;null==e&&"bookmark"==this.type&&(e=1);for(var n,i,o=0;o<this.lines.length;++o){var l=r.lines[o],s=_(l.markedSpans,r);if(null!=s.from&&(n=E(t?l:W(l),s.from),-1==e))return n;if(null!=s.to&&(i=E(t?l:W(l),s.to),1==e))return i}return n&&{from:n,to:i}},Os.prototype.changed=function(){var e=this,t=this.find(-1,!0),r=this,n=this.doc.cm;t&&n&&hn(n,function(){var i=t.line,o=W(t.line),l=jt(n,o);if(l&&(Qt(l),n.curOp.selectionChanged=n.curOp.forceUpdate=!0),n.curOp.updateMaxLine=!0,!ve(r.doc,i)&&null!=r.height){var s=r.height;r.height=null;var a=Ht(r)-s;a&&A(i,i.height+a)}bt(n,"markerChanged",n,e)})},Os.prototype.attachLine=function(e){if(!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;t.maybeHiddenMarkers&&-1!=h(t.maybeHiddenMarkers,this)||(t.maybeUnhiddenMarkers||(t.maybeUnhiddenMarkers=[])).push(this)}this.lines.push(e)},Os.prototype.detachLine=function(e){if(this.lines.splice(h(this.lines,e),1),!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;(t.maybeHiddenMarkers||(t.maybeHiddenMarkers=[])).push(this)}},Ae(Os);var As=function(e,t){var r=this;this.markers=e,this.primary=t;for(var n=0;n<e.length;++n)e[n].parent=r};As.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){this.explicitlyCleared=!0;for(var t=0;t<this.markers.length;++t)e.markers[t].clear();bt(this,"clear")}},As.prototype.find=function(e,t){return this.primary.find(e,t)},Ae(As);var Ws=0,Ds=function(e,t,r,n,i){if(!(this instanceof Ds))return new Ds(e,t,r,n,i);null==r&&(r=0),Gi.call(this,[new Bi([new fs("",null)])]),this.first=r,this.scrollTop=this.scrollLeft=0,this.cantEdit=!1,this.cleanGeneration=1,this.modeFrontier=this.highlightFrontier=r;var o=E(r,0);this.sel=Rn(o),this.history=new Jn(null),this.id=++Ws,this.modeOption=t,this.lineSep=n,this.direction="rtl"==i?"rtl":"ltr",this.extend=!1,"string"==typeof e&&(e=this.splitLines(e)),_n(this,{from:o,to:o,text:e}),bi(this,Rn(o),Gl)};Ds.prototype=b(Gi.prototype,{constructor:Ds,iter:function(e,t,r){r?this.iterN(e-this.first,t-e,r):this.iterN(this.first,this.first+this.size,e)},insert:function(e,t){for(var r=0,n=0;n<t.length;++n)r+=t[n].height;this.insertInner(e-this.first,t,r)},remove:function(e,t){this.removeInner(e-this.first,t)},getValue:function(e){var t=O(this,this.first,this.first+this.size);return!1===e?t:t.join(e||this.lineSeparator())},setValue:gn(function(e){var t=E(this.first,0),r=this.first+this.size-1;Oi(this,{from:t,to:E(r,M(this,r).text.length),text:this.splitLines(e),origin:"setValue",full:!0},!0),this.cm&&Xr(this.cm,0,0),bi(this,Rn(t),Gl)}),replaceRange:function(e,t,r,n){Ei(this,e,t=U(this,t),r=r?U(this,r):t,n)},getRange:function(e,t,r){var n=N(this,U(this,e),U(this,t));return!1===r?n:n.join(r||this.lineSeparator())},getLine:function(e){var t=this.getLineHandle(e);return t&&t.text},getLineHandle:function(e){if(H(this,e))return M(this,e)},getLineNumber:function(e){return W(e)},getLineHandleVisualStart:function(e){return"number"==typeof e&&(e=M(this,e)),fe(e)},lineCount:function(){return this.size},firstLine:function(){return this.first},lastLine:function(){return this.first+this.size-1},clipPos:function(e){return U(this,e)},getCursor:function(e){var t=this.sel.primary();return null==e||"head"==e?t.head:"anchor"==e?t.anchor:"end"==e||"to"==e||!1===e?t.to():t.from()},listSelections:function(){return this.sel.ranges},somethingSelected:function(){return this.sel.somethingSelected()},setCursor:gn(function(e,t,r){vi(this,U(this,"number"==typeof e?E(e,t||0):e),null,r)}),setSelection:gn(function(e,t,r){vi(this,U(this,e),U(this,t||e),r)}),extendSelection:gn(function(e,t,r){di(this,U(this,e),t&&U(this,t),r)}),extendSelections:gn(function(e,t){pi(this,K(this,e),t)}),extendSelectionsBy:gn(function(e,t){pi(this,K(this,v(this.sel.ranges,e)),t)}),setSelections:gn(function(e,t,r){var n=this;if(e.length){for(var i=[],o=0;o<e.length;o++)i[o]=new Ts(U(n,e[o].anchor),U(n,e[o].head));null==t&&(t=Math.min(e.length-1,this.sel.primIndex)),bi(this,zn(i,t),r)}}),addSelection:gn(function(e,t,r){var n=this.sel.ranges.slice(0);n.push(new Ts(U(this,e),U(this,t||e))),bi(this,zn(n,n.length-1),r)}),getSelection:function(e){for(var t,r=this,n=this.sel.ranges,i=0;i<n.length;i++){var o=N(r,n[i].from(),n[i].to());t=t?t.concat(o):o}return!1===e?t:t.join(e||this.lineSeparator())},getSelections:function(e){for(var t=this,r=[],n=this.sel.ranges,i=0;i<n.length;i++){var o=N(t,n[i].from(),n[i].to());!1!==e&&(o=o.join(e||t.lineSeparator())),r[i]=o}return r},replaceSelection:function(e,t,r){for(var n=[],i=0;i<this.sel.ranges.length;i++)n[i]=e;this.replaceSelections(n,t,r||"+input")},replaceSelections:gn(function(e,t,r){for(var n=this,i=[],o=this.sel,l=0;l<o.ranges.length;l++){var s=o.ranges[l];i[l]={from:s.from(),to:s.to(),text:n.splitLines(e[l]),origin:r}}for(var a=t&&"end"!=t&&Kn(this,i,t),u=i.length-1;u>=0;u--)Oi(n,i[u]);a?yi(this,a):this.cm&&jr(this.cm)}),undo:gn(function(){Wi(this,"undo")}),redo:gn(function(){Wi(this,"redo")}),undoSelection:gn(function(){Wi(this,"undo",!0)}),redoSelection:gn(function(){Wi(this,"redo",!0)}),setExtending:function(e){this.extend=e},getExtending:function(){return this.extend},historySize:function(){for(var e=this.history,t=0,r=0,n=0;n<e.done.length;n++)e.done[n].ranges||++t;for(var i=0;i<e.undone.length;i++)e.undone[i].ranges||++r;return{undo:t,redo:r}},clearHistory:function(){this.history=new Jn(this.history.maxGeneration)},markClean:function(){this.cleanGeneration=this.changeGeneration(!0)},changeGeneration:function(e){return e&&(this.history.lastOp=this.history.lastSelOp=this.history.lastOrigin=null),this.history.generation},isClean:function(e){return this.history.generation==(e||this.cleanGeneration)},getHistory:function(){return{done:fi(this.history.done),undone:fi(this.history.undone)}},setHistory:function(e){var t=this.history=new Jn(this.history.maxGeneration);t.done=fi(e.done.slice(0),null,!0),t.undone=fi(e.undone.slice(0),null,!0)},setGutterMarker:gn(function(e,t,r){return Ri(this,e,"gutter",function(e){var n=e.gutterMarkers||(e.gutterMarkers={});return n[t]=r,!r&&C(n)&&(e.gutterMarkers=null),!0})}),clearGutter:gn(function(e){var t=this;this.iter(function(r){r.gutterMarkers&&r.gutterMarkers[e]&&Ri(t,r,"gutter",function(){return r.gutterMarkers[e]=null,C(r.gutterMarkers)&&(r.gutterMarkers=null),!0})})}),lineInfo:function(e){var t;if("number"==typeof e){if(!H(this,e))return null;if(t=e,!(e=M(this,e)))return null}else if(null==(t=W(e)))return null;return{line:t,handle:e,text:e.text,gutterMarkers:e.gutterMarkers,textClass:e.textClass,bgClass:e.bgClass,wrapClass:e.wrapClass,widgets:e.widgets}},addLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass";if(t[i]){if(e(n).test(t[i]))return!1;t[i]+=" "+n}else t[i]=n;return!0})}),removeLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass",o=t[i];if(!o)return!1;if(null==n)t[i]=null;else{var l=o.match(e(n));if(!l)return!1;var s=l.index+l[0].length;t[i]=o.slice(0,l.index)+(l.index&&s!=o.length?" ":"")+o.slice(s)||null}return!0})}),addLineWidget:gn(function(e,t,r){return Vi(this,e,t,r)}),removeLineWidget:function(e){e.clear()},markText:function(e,t,r){return Ki(this,U(this,e),U(this,t),r,r&&r.type||"range")},setBookmark:function(e,t){var r={replacedWith:t&&(null==t.nodeType?t.widget:t),insertLeft:t&&t.insertLeft,clearWhenEmpty:!1,shared:t&&t.shared,handleMouseEvents:t&&t.handleMouseEvents};return e=U(this,e),Ki(this,e,e,r,"bookmark")},findMarksAt:function(e){var t=[],r=M(this,(e=U(this,e)).line).markedSpans;if(r)for(var n=0;n<r.length;++n){var i=r[n];(null==i.from||i.from<=e.ch)&&(null==i.to||i.to>=e.ch)&&t.push(i.marker.parent||i.marker)}return t},findMarks:function(e,t,r){e=U(this,e),t=U(this,t);var n=[],i=e.line;return this.iter(e.line,t.line+1,function(o){var l=o.markedSpans;if(l)for(var s=0;s<l.length;s++){var a=l[s];null!=a.to&&i==e.line&&e.ch>=a.to||null==a.from&&i!=e.line||null!=a.from&&i==t.line&&a.from>=t.ch||r&&!r(a.marker)||n.push(a.marker.parent||a.marker)}++i}),n},getAllMarks:function(){var e=[];return this.iter(function(t){var r=t.markedSpans;if(r)for(var n=0;n<r.length;++n)null!=r[n].from&&e.push(r[n].marker)}),e},posFromIndex:function(e){var t,r=this.first,n=this.lineSeparator().length;return this.iter(function(i){var o=i.text.length+n;if(o>e)return t=e,!0;e-=o,++r}),U(this,E(r,t))},indexFromPos:function(e){var t=(e=U(this,e)).ch;if(e.line<this.first||e.ch<0)return 0;var r=this.lineSeparator().length;return this.iter(this.first,e.line,function(e){t+=e.text.length+r}),t},copy:function(e){var t=new Ds(O(this,this.first,this.first+this.size),this.modeOption,this.first,this.lineSep,this.direction);return t.scrollTop=this.scrollTop,t.scrollLeft=this.scrollLeft,t.sel=this.sel,t.extend=!1,e&&(t.history.undoDepth=this.history.undoDepth,t.setHistory(this.getHistory())),t},linkedDoc:function(e){e||(e={});var t=this.first,r=this.first+this.size;null!=e.from&&e.from>t&&(t=e.from),null!=e.to&&e.to<r&&(r=e.to);var n=new Ds(O(this,t,r),e.mode||this.modeOption,t,this.lineSep,this.direction);return e.sharedHist&&(n.history=this.history),(this.linked||(this.linked=[])).push({doc:n,sharedHist:e.sharedHist}),n.linked=[{doc:this,isParent:!0,sharedHist:e.sharedHist}],Yi(n,Xi(this)),n},unlinkDoc:function(e){var t=this;if(e instanceof jo&&(e=e.doc),this.linked)for(var r=0;r<this.linked.length;++r)if(t.linked[r].doc==e){t.linked.splice(r,1),e.unlinkDoc(t),_i(Xi(t));break}if(e.history==this.history){var n=[e.id];$n(e,function(e){return n.push(e.id)},!0),e.history=new Jn(null),e.history.done=fi(this.history.done,n),e.history.undone=fi(this.history.undone,n)}},iterLinkedDocs:function(e){$n(this,e)},getMode:function(){return this.mode},getEditor:function(){return this.cm},splitLines:function(e){return this.lineSep?e.split(this.lineSep):es(e)},lineSeparator:function(){return this.lineSep||"\n"},setDirection:gn(function(e){"rtl"!=e&&(e="ltr"),e!=this.direction&&(this.direction=e,this.iter(function(e){return e.order=null}),this.cm&&Qn(this.cm))})}),Ds.prototype.eachLine=Ds.prototype.iter;for(var Hs=0,Fs=!1,Es={3:"Enter",8:"Backspace",9:"Tab",13:"Enter",16:"Shift",17:"Ctrl",18:"Alt",19:"Pause",20:"CapsLock",27:"Esc",32:"Space",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"Left",38:"Up",39:"Right",40:"Down",44:"PrintScrn",45:"Insert",46:"Delete",59:";",61:"=",91:"Mod",92:"Mod",93:"Mod",106:"*",107:"=",109:"-",110:".",111:"/",127:"Delete",173:"-",186:";",187:"=",188:",",189:"-",190:".",191:"/",192:"`",219:"[",220:"\\",221:"]",222:"'",63232:"Up",63233:"Down",63234:"Left",63235:"Right",63272:"Delete",63273:"Home",63275:"End",63276:"PageUp",63277:"PageDown",63302:"Insert"},Ps=0;Ps<10;Ps++)Es[Ps+48]=Es[Ps+96]=String(Ps);for(var Is=65;Is<=90;Is++)Es[Is]=String.fromCharCode(Is);for(var zs=1;zs<=12;zs++)Es[zs+111]=Es[zs+63235]="F"+zs;var Rs={};Rs.basic={Left:"goCharLeft",Right:"goCharRight",Up:"goLineUp",Down:"goLineDown",End:"goLineEnd",Home:"goLineStartSmart",PageUp:"goPageUp",PageDown:"goPageDown",Delete:"delCharAfter",Backspace:"delCharBefore","Shift-Backspace":"delCharBefore",Tab:"defaultTab","Shift-Tab":"indentAuto",Enter:"newlineAndIndent",Insert:"toggleOverwrite",Esc:"singleSelection"},Rs.pcDefault={"Ctrl-A":"selectAll","Ctrl-D":"deleteLine","Ctrl-Z":"undo","Shift-Ctrl-Z":"redo","Ctrl-Y":"redo","Ctrl-Home":"goDocStart","Ctrl-End":"goDocEnd","Ctrl-Up":"goLineUp","Ctrl-Down":"goLineDown","Ctrl-Left":"goGroupLeft","Ctrl-Right":"goGroupRight","Alt-Left":"goLineStart","Alt-Right":"goLineEnd","Ctrl-Backspace":"delGroupBefore","Ctrl-Delete":"delGroupAfter","Ctrl-S":"save","Ctrl-F":"find","Ctrl-G":"findNext","Shift-Ctrl-G":"findPrev","Shift-Ctrl-F":"replace","Shift-Ctrl-R":"replaceAll","Ctrl-[":"indentLess","Ctrl-]":"indentMore","Ctrl-U":"undoSelection","Shift-Ctrl-U":"redoSelection","Alt-U":"redoSelection",fallthrough:"basic"},Rs.emacsy={"Ctrl-F":"goCharRight","Ctrl-B":"goCharLeft","Ctrl-P":"goLineUp","Ctrl-N":"goLineDown","Alt-F":"goWordRight","Alt-B":"goWordLeft","Ctrl-A":"goLineStart","Ctrl-E":"goLineEnd","Ctrl-V":"goPageDown","Shift-Ctrl-V":"goPageUp","Ctrl-D":"delCharAfter","Ctrl-H":"delCharBefore","Alt-D":"delWordAfter","Alt-Backspace":"delWordBefore","Ctrl-K":"killLine","Ctrl-T":"transposeChars","Ctrl-O":"openLine"},Rs.macDefault={"Cmd-A":"selectAll","Cmd-D":"deleteLine","Cmd-Z":"undo","Shift-Cmd-Z":"redo","Cmd-Y":"redo","Cmd-Home":"goDocStart","Cmd-Up":"goDocStart","Cmd-End":"goDocEnd","Cmd-Down":"goDocEnd","Alt-Left":"goGroupLeft","Alt-Right":"goGroupRight","Cmd-Left":"goLineLeft","Cmd-Right":"goLineRight","Alt-Backspace":"delGroupBefore","Ctrl-Alt-Backspace":"delGroupAfter","Alt-Delete":"delGroupAfter","Cmd-S":"save","Cmd-F":"find","Cmd-G":"findNext","Shift-Cmd-G":"findPrev","Cmd-Alt-F":"replace","Shift-Cmd-Alt-F":"replaceAll","Cmd-[":"indentLess","Cmd-]":"indentMore","Cmd-Backspace":"delWrappedLineLeft","Cmd-Delete":"delWrappedLineRight","Cmd-U":"undoSelection","Shift-Cmd-U":"redoSelection","Ctrl-Up":"goDocStart","Ctrl-Down":"goDocEnd",fallthrough:["basic","emacsy"]},Rs.default=Ml?Rs.macDefault:Rs.pcDefault;var Bs={selectAll:Mi,singleSelection:function(e){return e.setSelection(e.getCursor("anchor"),e.getCursor("head"),Gl)},killLine:function(e){return co(e,function(t){if(t.empty()){var r=M(e.doc,t.head.line).text.length;return t.head.ch==r&&t.head.line<e.lastLine()?{from:t.head,to:E(t.head.line+1,0)}:{from:t.head,to:E(t.head.line,r)}}return{from:t.from(),to:t.to()}})},deleteLine:function(e){return co(e,function(t){return{from:E(t.from().line,0),to:U(e.doc,E(t.to().line+1,0))}})},delLineLeft:function(e){return co(e,function(e){return{from:E(e.from().line,0),to:e.from()}})},delWrappedLineLeft:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5;return{from:e.coordsChar({left:0,top:r},"div"),to:t.from()}})},delWrappedLineRight:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5,n=e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div");return{from:t.from(),to:n}})},undo:function(e){return e.undo()},redo:function(e){return e.redo()},undoSelection:function(e){return e.undoSelection()},redoSelection:function(e){return e.redoSelection()},goDocStart:function(e){return e.extendSelection(E(e.firstLine(),0))},goDocEnd:function(e){return e.extendSelection(E(e.lastLine()))},goLineStart:function(e){return e.extendSelectionsBy(function(t){return vo(e,t.head.line)},{origin:"+move",bias:1})},goLineStartSmart:function(e){return e.extendSelectionsBy(function(t){return yo(e,t.head)},{origin:"+move",bias:1})},goLineEnd:function(e){return e.extendSelectionsBy(function(t){return mo(e,t.head.line)},{origin:"+move",bias:-1})},goLineRight:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div")},Vl)},goLineLeft:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:0,top:r},"div")},Vl)},goLineLeftSmart:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5,n=e.coordsChar({left:0,top:r},"div");return n.ch<e.getLine(n.line).search(/\S/)?yo(e,t.head):n},Vl)},goLineUp:function(e){return e.moveV(-1,"line")},goLineDown:function(e){return e.moveV(1,"line")},goPageUp:function(e){return e.moveV(-1,"page")},goPageDown:function(e){return e.moveV(1,"page")},goCharLeft:function(e){return e.moveH(-1,"char")},goCharRight:function(e){return e.moveH(1,"char")},goColumnLeft:function(e){return e.moveH(-1,"column")},goColumnRight:function(e){return e.moveH(1,"column")},goWordLeft:function(e){return e.moveH(-1,"word")},goGroupRight:function(e){return e.moveH(1,"group")},goGroupLeft:function(e){return e.moveH(-1,"group")},goWordRight:function(e){return e.moveH(1,"word")},delCharBefore:function(e){return e.deleteH(-1,"char")},delCharAfter:function(e){return e.deleteH(1,"char")},delWordBefore:function(e){return e.deleteH(-1,"word")},delWordAfter:function(e){return e.deleteH(1,"word")},delGroupBefore:function(e){return e.deleteH(-1,"group")},delGroupAfter:function(e){return e.deleteH(1,"group")},indentAuto:function(e){return e.indentSelection("smart")},indentMore:function(e){return e.indentSelection("add")},indentLess:function(e){return e.indentSelection("subtract")},insertTab:function(e){return e.replaceSelection("\t")},insertSoftTab:function(e){for(var t=[],r=e.listSelections(),n=e.options.tabSize,i=0;i<r.length;i++){var o=r[i].from(),l=f(e.getLine(o.line),o.ch,n);t.push(p(n-l%n))}e.replaceSelections(t)},defaultTab:function(e){e.somethingSelected()?e.indentSelection("add"):e.execCommand("insertTab")},transposeChars:function(e){return hn(e,function(){for(var t=e.listSelections(),r=[],n=0;n<t.length;n++)if(t[n].empty()){var i=t[n].head,o=M(e.doc,i.line).text;if(o)if(i.ch==o.length&&(i=new E(i.line,i.ch-1)),i.ch>0)i=new E(i.line,i.ch+1),e.replaceRange(o.charAt(i.ch-1)+o.charAt(i.ch-2),E(i.line,i.ch-2),i,"+transpose");else if(i.line>e.doc.first){var l=M(e.doc,i.line-1).text;l&&(i=new E(i.line,1),e.replaceRange(o.charAt(0)+e.doc.lineSeparator()+l.charAt(l.length-1),E(i.line-1,l.length-1),i,"+transpose"))}r.push(new Ts(i,i))}e.setSelections(r)})},newlineAndIndent:function(e){return hn(e,function(){for(var t=e.listSelections(),r=t.length-1;r>=0;r--)e.replaceRange(e.doc.lineSeparator(),t[r].anchor,t[r].head,"+input");t=e.listSelections();for(var n=0;n<t.length;n++)e.indentLine(t[n].from().line,null,!0);jr(e)})},openLine:function(e){return e.replaceSelection("\n","start")},toggleOverwrite:function(e){return e.toggleOverwrite()}},Gs=new Pl,Us=null,Vs=function(e,t,r){this.time=e,this.pos=t,this.button=r};Vs.prototype.compare=function(e,t,r){return this.time+400>e&&0==P(t,this.pos)&&r==this.button};var Ks,js,Xs={toString:function(){return"CodeMirror.Init"}},Ys={},_s={};jo.defaults=Ys,jo.optionHandlers=_s;var $s=[];jo.defineInitHook=function(e){return $s.push(e)};var qs=null,Zs=function(e){this.cm=e,this.lastAnchorNode=this.lastAnchorOffset=this.lastFocusNode=this.lastFocusOffset=null,this.polling=new Pl,this.composing=null,this.gracePeriod=!1,this.readDOMTimeout=null};Zs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()}),"cut"==e.type&&i.replaceSelection("",null,"cut");else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type&&i.operation(function(){i.setSelections(t.ranges,0,Gl),i.replaceSelection("",null,"cut")})}if(e.clipboardData){e.clipboardData.clearData();var r=qs.text.join("\n");if(e.clipboardData.setData("Text",r),e.clipboardData.getData("Text")==r)return void e.preventDefault()}var l=el(),s=l.firstChild;i.display.lineSpace.insertBefore(l,i.display.lineSpace.firstChild),s.value=qs.text.join("\n");var a=document.activeElement;El(s),setTimeout(function(){i.display.lineSpace.removeChild(l),a.focus(),a==o&&n.showPrimarySelection()},50)}}var r=this,n=this,i=n.cm,o=n.div=e.lineDiv;Jo(o,i.options.spellcheck),Ql(o,"paste",function(e){Me(i,e)||qo(e,i)||vl<=11&&setTimeout(dn(i,function(){return r.updateFromDOM()}),20)}),Ql(o,"compositionstart",function(e){r.composing={data:e.data,done:!1}}),Ql(o,"compositionupdate",function(e){r.composing||(r.composing={data:e.data,done:!1})}),Ql(o,"compositionend",function(e){r.composing&&(e.data!=r.composing.data&&r.readFromDOMSoon(),r.composing.done=!0)}),Ql(o,"touchstart",function(){return n.forceCompositionEnd()}),Ql(o,"input",function(){r.composing||r.readFromDOMSoon()}),Ql(o,"copy",t),Ql(o,"cut",t)},Zs.prototype.prepareSelection=function(){var e=Tr(this.cm,!1);return e.focus=this.cm.state.focused,e},Zs.prototype.showSelection=function(e,t){e&&this.cm.display.view.length&&((e.focus||t)&&this.showPrimarySelection(),this.showMultipleSelections(e))},Zs.prototype.showPrimarySelection=function(){var e=window.getSelection(),t=this.cm,r=t.doc.sel.primary(),n=r.from(),i=r.to();if(t.display.viewTo==t.display.viewFrom||n.line>=t.display.viewTo||i.line<t.display.viewFrom)e.removeAllRanges();else{var o=sl(t,e.anchorNode,e.anchorOffset),l=sl(t,e.focusNode,e.focusOffset);if(!o||o.bad||!l||l.bad||0!=P(B(o,l),n)||0!=P(R(o,l),i)){var s=t.display.view,a=n.line>=t.display.viewFrom&&nl(t,n)||{node:s[0].measure.map[2],offset:0},u=i.line<t.display.viewTo&&nl(t,i);if(!u){var c=s[s.length-1].measure,f=c.maps?c.maps[c.maps.length-1]:c.map;u={node:f[f.length-1],offset:f[f.length-2]-f[f.length-3]}}if(a&&u){var h,d=e.rangeCount&&e.getRangeAt(0);try{h=Wl(a.node,a.offset,u.offset,u.node)}catch(e){}h&&(!fl&&t.state.focused?(e.collapse(a.node,a.offset),h.collapsed||(e.removeAllRanges(),e.addRange(h))):(e.removeAllRanges(),e.addRange(h)),d&&null==e.anchorNode?e.addRange(d):fl&&this.startGracePeriod()),this.rememberSelection()}else e.removeAllRanges()}}},Zs.prototype.startGracePeriod=function(){var e=this;clearTimeout(this.gracePeriod),this.gracePeriod=setTimeout(function(){e.gracePeriod=!1,e.selectionChanged()&&e.cm.operation(function(){return e.cm.curOp.selectionChanged=!0})},20)},Zs.prototype.showMultipleSelections=function(e){r(this.cm.display.cursorDiv,e.cursors),r(this.cm.display.selectionDiv,e.selection)},Zs.prototype.rememberSelection=function(){var e=window.getSelection();this.lastAnchorNode=e.anchorNode,this.lastAnchorOffset=e.anchorOffset,this.lastFocusNode=e.focusNode,this.lastFocusOffset=e.focusOffset},Zs.prototype.selectionInEditor=function(){var e=window.getSelection();if(!e.rangeCount)return!1;var t=e.getRangeAt(0).commonAncestorContainer;return o(this.div,t)},Zs.prototype.focus=function(){"nocursor"!=this.cm.options.readOnly&&(this.selectionInEditor()||this.showSelection(this.prepareSelection(),!0),this.div.focus())},Zs.prototype.blur=function(){this.div.blur()},Zs.prototype.getField=function(){return this.div},Zs.prototype.supportsTouch=function(){return!0},Zs.prototype.receivedFocus=function(){function e(){t.cm.state.focused&&(t.pollSelection(),t.polling.set(t.cm.options.pollInterval,e))}var t=this;this.selectionInEditor()?this.pollSelection():hn(this.cm,function(){return t.cm.curOp.selectionChanged=!0}),this.polling.set(this.cm.options.pollInterval,e)},Zs.prototype.selectionChanged=function(){var e=window.getSelection();return e.anchorNode!=this.lastAnchorNode||e.anchorOffset!=this.lastAnchorOffset||e.focusNode!=this.lastFocusNode||e.focusOffset!=this.lastFocusOffset},Zs.prototype.pollSelection=function(){if(null==this.readDOMTimeout&&!this.gracePeriod&&this.selectionChanged()){var e=window.getSelection(),t=this.cm;if(kl&&bl&&this.cm.options.gutters.length&&il(e.anchorNode))return this.cm.triggerOnKeyDown({type:"keydown",keyCode:8,preventDefault:Math.abs}),this.blur(),void this.focus();if(!this.composing){this.rememberSelection();var r=sl(t,e.anchorNode,e.anchorOffset),n=sl(t,e.focusNode,e.focusOffset);r&&n&&hn(t,function(){bi(t.doc,Rn(r,n),Gl),(r.bad||n.bad)&&(t.curOp.selectionChanged=!0)})}}},Zs.prototype.pollContent=function(){null!=this.readDOMTimeout&&(clearTimeout(this.readDOMTimeout),this.readDOMTimeout=null);var e=this.cm,t=e.display,r=e.doc.sel.primary(),n=r.from(),i=r.to();if(0==n.ch&&n.line>e.firstLine()&&(n=E(n.line-1,M(e.doc,n.line-1).length)),i.ch==M(e.doc,i.line).text.length&&i.line<e.lastLine()&&(i=E(i.line+1,0)),n.line<t.viewFrom||i.line>t.viewTo-1)return!1;var o,l,s;n.line==t.viewFrom||0==(o=Lr(e,n.line))?(l=W(t.view[0].line),s=t.view[0].node):(l=W(t.view[o].line),s=t.view[o-1].node.nextSibling);var a,u,c=Lr(e,i.line);if(c==t.view.length-1?(a=t.viewTo-1,u=t.lineDiv.lastChild):(a=W(t.view[c+1].line)-1,u=t.view[c+1].node.previousSibling),!s)return!1;for(var f=e.doc.splitLines(ll(e,s,u,l,a)),h=N(e.doc,E(l,0),E(a,M(e.doc,a).text.length));f.length>1&&h.length>1;)if(g(f)==g(h))f.pop(),h.pop(),a--;else{if(f[0]!=h[0])break;f.shift(),h.shift(),l++}for(var d=0,p=0,v=f[0],m=h[0],y=Math.min(v.length,m.length);d<y&&v.charCodeAt(d)==m.charCodeAt(d);)++d;for(var b=g(f),w=g(h),x=Math.min(b.length-(1==f.length?d:0),w.length-(1==h.length?d:0));p<x&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)++p;if(1==f.length&&1==h.length&&l==n.line)for(;d&&d>n.ch&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)d--,p++;f[f.length-1]=b.slice(0,b.length-p).replace(/^\u200b+/,""),f[0]=f[0].slice(d).replace(/\u200b+$/,"");var C=E(l,d),S=E(a,h.length?g(h).length-p:0);return f.length>1||f[0]||P(C,S)?(Ei(e.doc,f,C,S,"+input"),!0):void 0},Zs.prototype.ensurePolled=function(){this.forceCompositionEnd()},Zs.prototype.reset=function(){this.forceCompositionEnd()},Zs.prototype.forceCompositionEnd=function(){this.composing&&(clearTimeout(this.readDOMTimeout),this.composing=null,this.updateFromDOM(),this.div.blur(),this.div.focus())},Zs.prototype.readFromDOMSoon=function(){var e=this;null==this.readDOMTimeout&&(this.readDOMTimeout=setTimeout(function(){if(e.readDOMTimeout=null,e.composing){if(!e.composing.done)return;e.composing=null}e.updateFromDOM()},80))},Zs.prototype.updateFromDOM=function(){var e=this;!this.cm.isReadOnly()&&this.pollContent()||hn(this.cm,function(){return vn(e.cm)})},Zs.prototype.setUneditable=function(e){e.contentEditable="false"},Zs.prototype.onKeyPress=function(e){0!=e.charCode&&(e.preventDefault(),this.cm.isReadOnly()||dn(this.cm,$o)(this.cm,String.fromCharCode(null==e.charCode?e.keyCode:e.charCode),0))},Zs.prototype.readOnlyChanged=function(e){this.div.contentEditable=String("nocursor"!=e)},Zs.prototype.onContextMenu=function(){},Zs.prototype.resetPosition=function(){},Zs.prototype.needsContentAttribute=!0;var Qs=function(e){this.cm=e,this.prevInput="",this.pollingFast=!1,this.polling=new Pl,this.hasSelection=!1,this.composing=null};Qs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()});else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type?i.setSelections(t.ranges,null,Gl):(n.prevInput="",l.value=t.text.join("\n"),El(l))}"cut"==e.type&&(i.state.cutIncoming=!0)}}var r=this,n=this,i=this.cm,o=this.wrapper=el(),l=this.textarea=o.firstChild;e.wrapper.insertBefore(o,e.wrapper.firstChild),Ll&&(l.style.width="0px"),Ql(l,"input",function(){gl&&vl>=9&&r.hasSelection&&(r.hasSelection=null),n.poll()}),Ql(l,"paste",function(e){Me(i,e)||qo(e,i)||(i.state.pasteIncoming=!0,n.fastPoll())}),Ql(l,"cut",t),Ql(l,"copy",t),Ql(e.scroller,"paste",function(t){Ft(e,t)||Me(i,t)||(i.state.pasteIncoming=!0,n.focus())}),Ql(e.lineSpace,"selectstart",function(t){Ft(e,t)||We(t)}),Ql(l,"compositionstart",function(){var e=i.getCursor("from");n.composing&&n.composing.range.clear(),n.composing={start:e,range:i.markText(e,i.getCursor("to"),{className:"CodeMirror-composing"})}}),Ql(l,"compositionend",function(){n.composing&&(n.poll(),n.composing.range.clear(),n.composing=null)})},Qs.prototype.prepareSelection=function(){var e=this.cm,t=e.display,r=e.doc,n=Tr(e);if(e.options.moveInputWithCursor){var i=sr(e,r.sel.primary().head,"div"),o=t.wrapper.getBoundingClientRect(),l=t.lineDiv.getBoundingClientRect();n.teTop=Math.max(0,Math.min(t.wrapper.clientHeight-10,i.top+l.top-o.top)),n.teLeft=Math.max(0,Math.min(t.wrapper.clientWidth-10,i.left+l.left-o.left))}return n},Qs.prototype.showSelection=function(e){var t=this.cm.display;r(t.cursorDiv,e.cursors),r(t.selectionDiv,e.selection),null!=e.teTop&&(this.wrapper.style.top=e.teTop+"px",this.wrapper.style.left=e.teLeft+"px")},Qs.prototype.reset=function(e){if(!this.contextMenuPending&&!this.composing){var t=this.cm;if(t.somethingSelected()){this.prevInput="";var r=t.getSelection();this.textarea.value=r,t.state.focused&&El(this.textarea),gl&&vl>=9&&(this.hasSelection=r)}else e||(this.prevInput=this.textarea.value="",gl&&vl>=9&&(this.hasSelection=null))}},Qs.prototype.getField=function(){return this.textarea},Qs.prototype.supportsTouch=function(){return!1},Qs.prototype.focus=function(){if("nocursor"!=this.cm.options.readOnly&&(!Tl||l()!=this.textarea))try{this.textarea.focus()}catch(e){}},Qs.prototype.blur=function(){this.textarea.blur()},Qs.prototype.resetPosition=function(){this.wrapper.style.top=this.wrapper.style.left=0},Qs.prototype.receivedFocus=function(){this.slowPoll()},Qs.prototype.slowPoll=function(){var e=this;this.pollingFast||this.polling.set(this.cm.options.pollInterval,function(){e.poll(),e.cm.state.focused&&e.slowPoll()})},Qs.prototype.fastPoll=function(){function e(){r.poll()||t?(r.pollingFast=!1,r.slowPoll()):(t=!0,r.polling.set(60,e))}var t=!1,r=this;r.pollingFast=!0,r.polling.set(20,e)},Qs.prototype.poll=function(){var e=this,t=this.cm,r=this.textarea,n=this.prevInput;if(this.contextMenuPending||!t.state.focused||ts(r)&&!n&&!this.composing||t.isReadOnly()||t.options.disableInput||t.state.keySeq)return!1;var i=r.value;if(i==n&&!t.somethingSelected())return!1;if(gl&&vl>=9&&this.hasSelection===i||Ml&&/[\uf700-\uf7ff]/.test(i))return t.display.input.reset(),!1;if(t.doc.sel==t.display.selForContextMenu){var o=i.charCodeAt(0);if(8203!=o||n||(n="​"),8666==o)return this.reset(),this.cm.execCommand("undo")}for(var l=0,s=Math.min(n.length,i.length);l<s&&n.charCodeAt(l)==i.charCodeAt(l);)++l;return hn(t,function(){$o(t,i.slice(l),n.length-l,null,e.composing?"*compose":null),i.length>1e3||i.indexOf("\n")>-1?r.value=e.prevInput="":e.prevInput=i,e.composing&&(e.composing.range.clear(),e.composing.range=t.markText(e.composing.start,t.getCursor("to"),{className:"CodeMirror-composing"}))}),!0},Qs.prototype.ensurePolled=function(){this.pollingFast&&this.poll()&&(this.pollingFast=!1)},Qs.prototype.onKeyPress=function(){gl&&vl>=9&&(this.hasSelection=null),this.fastPoll()},Qs.prototype.onContextMenu=function(e){function t(){if(null!=l.selectionStart){var e=i.somethingSelected(),t="​"+(e?l.value:"");l.value="⇚",l.value=t,n.prevInput=e?"":"​",l.selectionStart=1,l.selectionEnd=t.length,o.selForContextMenu=i.doc.sel}}function r(){if(n.contextMenuPending=!1,n.wrapper.style.cssText=c,l.style.cssText=u,gl&&vl<9&&o.scrollbars.setScrollTop(o.scroller.scrollTop=a),null!=l.selectionStart){(!gl||gl&&vl<9)&&t();var e=0,r=function(){o.selForContextMenu==i.doc.sel&&0==l.selectionStart&&l.selectionEnd>0&&"​"==n.prevInput?dn(i,Mi)(i):e++<10?o.detectingSelectAll=setTimeout(r,500):(o.selForContextMenu=null,o.input.reset())};o.detectingSelectAll=setTimeout(r,200)}}var n=this,i=n.cm,o=i.display,l=n.textarea,s=Sr(i,e),a=o.scroller.scrollTop;if(s&&!wl){i.options.resetSelectionOnContextMenu&&-1==i.doc.sel.contains(s)&&dn(i,bi)(i.doc,Rn(s),Gl);var u=l.style.cssText,c=n.wrapper.style.cssText;n.wrapper.style.cssText="position: absolute";var f=n.wrapper.getBoundingClientRect();l.style.cssText="position: absolute; width: 30px; height: 30px;\n      top: "+(e.clientY-f.top-5)+"px; left: "+(e.clientX-f.left-5)+"px;\n      z-index: 1000; background: "+(gl?"rgba(255, 255, 255, .05)":"transparent")+";\n      outline: none; border-width: 0; outline: none; overflow: hidden; opacity: .05; filter: alpha(opacity=5);";var h;if(ml&&(h=window.scrollY),o.input.focus(),ml&&window.scrollTo(null,h),o.input.reset(),i.somethingSelected()||(l.value=n.prevInput=" "),n.contextMenuPending=!0,o.selForContextMenu=i.doc.sel,clearTimeout(o.detectingSelectAll),gl&&vl>=9&&t(),Hl){Fe(e);var d=function(){ke(window,"mouseup",d),setTimeout(r,20)};Ql(window,"mouseup",d)}else setTimeout(r,50)}},Qs.prototype.readOnlyChanged=function(e){e||this.reset(),this.textarea.disabled="nocursor"==e},Qs.prototype.setUneditable=function(){},Qs.prototype.needsContentAttribute=!1,function(e){function t(t,n,i,o){e.defaults[t]=n,i&&(r[t]=o?function(e,t,r){r!=Xs&&i(e,t,r)}:i)}var r=e.optionHandlers;e.defineOption=t,e.Init=Xs,t("value","",function(e,t){return e.setValue(t)},!0),t("mode",null,function(e,t){e.doc.modeOption=t,jn(e)},!0),t("indentUnit",2,jn,!0),t("indentWithTabs",!1),t("smartIndent",!0),t("tabSize",4,function(e){Xn(e),er(e),vn(e)},!0),t("lineSeparator",null,function(e,t){if(e.doc.lineSep=t,t){var r=[],n=e.doc.first;e.doc.iter(function(e){for(var i=0;;){var o=e.text.indexOf(t,i);if(-1==o)break;i=o+t.length,r.push(E(n,o))}n++});for(var i=r.length-1;i>=0;i--)Ei(e.doc,t,r[i],E(r[i].line,r[i].ch+t.length))}}),t("specialChars",/[\u0000-\u001f\u007f-\u009f\u00ad\u061c\u200b-\u200f\u2028\u2029\ufeff]/g,function(e,t,r){e.state.specialChars=new RegExp(t.source+(t.test("\t")?"":"|\t"),"g"),r!=Xs&&e.refresh()}),t("specialCharPlaceholder",at,function(e){return e.refresh()},!0),t("electricChars",!0),t("inputStyle",Tl?"contenteditable":"textarea",function(){throw new Error("inputStyle can not (yet) be changed in a running editor")},!0),t("spellcheck",!1,function(e,t){return e.getInputField().spellcheck=t},!0),t("rtlMoveVisually",!Ol),t("wholeLineUpdateBefore",!0),t("theme","default",function(e){Go(e),Uo(e)},!0),t("keyMap","default",function(e,t,r){var n=uo(t),i=r!=Xs&&uo(r);i&&i.detach&&i.detach(e,n),n.attach&&n.attach(e,i||null)}),t("extraKeys",null),t("configureMouse",null),t("lineWrapping",!1,Ko,!0),t("gutters",[],function(e){Fn(e.options),Uo(e)},!0),t("fixedGutter",!0,function(e,t){e.display.gutters.style.left=t?wr(e.display)+"px":"0",e.refresh()},!0),t("coverGutterNextToScrollbar",!1,function(e){return en(e)},!0),t("scrollbarStyle","native",function(e){rn(e),en(e),e.display.scrollbars.setScrollTop(e.doc.scrollTop),e.display.scrollbars.setScrollLeft(e.doc.scrollLeft)},!0),t("lineNumbers",!1,function(e){Fn(e.options),Uo(e)},!0),t("firstLineNumber",1,Uo,!0),t("lineNumberFormatter",function(e){return e},Uo,!0),t("showCursorWhenSelecting",!1,kr,!0),t("resetSelectionOnContextMenu",!0),t("lineWiseCopyCut",!0),t("pasteLinesPerSelection",!0),t("readOnly",!1,function(e,t){"nocursor"==t&&(Fr(e),e.display.input.blur()),e.display.input.readOnlyChanged(t)}),t("disableInput",!1,function(e,t){t||e.display.input.reset()},!0),t("dragDrop",!0,Vo),t("allowDropFileTypes",null),t("cursorBlinkRate",530),t("cursorScrollMargin",0),t("cursorHeight",1,kr,!0),t("singleCursorHeightPerLine",!0,kr,!0),t("workTime",100),t("workDelay",100),t("flattenSpans",!0,Xn,!0),t("addModeClass",!1,Xn,!0),t("pollInterval",100),t("undoDepth",200,function(e,t){return e.doc.history.undoDepth=t}),t("historyEventDelay",1250),t("viewportMargin",10,function(e){return e.refresh()},!0),t("maxHighlightLength",1e4,Xn,!0),t("moveInputWithCursor",!0,function(e,t){t||e.display.input.resetPosition()}),t("tabindex",null,function(e,t){return e.display.input.getField().tabIndex=t||""}),t("autofocus",null),t("direction","ltr",function(e,t){return e.doc.setDirection(t)},!0)}(jo),function(e){var t=e.optionHandlers,r=e.helpers={};e.prototype={constructor:e,focus:function(){window.focus(),this.display.input.focus()},setOption:function(e,r){var n=this.options,i=n[e];n[e]==r&&"mode"!=e||(n[e]=r,t.hasOwnProperty(e)&&dn(this,t[e])(this,r,i),Te(this,"optionChange",this,e))},getOption:function(e){return this.options[e]},getDoc:function(){return this.doc},addKeyMap:function(e,t){this.state.keyMaps[t?"push":"unshift"](uo(e))},removeKeyMap:function(e){for(var t=this.state.keyMaps,r=0;r<t.length;++r)if(t[r]==e||t[r].name==e)return t.splice(r,1),!0},addOverlay:pn(function(t,r){var n=t.token?t:e.getMode(this.options,t);if(n.startState)throw new Error("Overlays may not be stateful.");m(this.state.overlays,{mode:n,modeSpec:t,opaque:r&&r.opaque,priority:r&&r.priority||0},function(e){return e.priority}),this.state.modeGen++,vn(this)}),removeOverlay:pn(function(e){for(var t=this,r=this.state.overlays,n=0;n<r.length;++n){var i=r[n].modeSpec;if(i==e||"string"==typeof e&&i.name==e)return r.splice(n,1),t.state.modeGen++,void vn(t)}}),indentLine:pn(function(e,t,r){"string"!=typeof t&&"number"!=typeof t&&(t=null==t?this.options.smartIndent?"smart":"prev":t?"add":"subtract"),H(this.doc,e)&&Yo(this,e,t,r)}),indentSelection:pn(function(e){for(var t=this,r=this.doc.sel.ranges,n=-1,i=0;i<r.length;i++){var o=r[i];if(o.empty())o.head.line>n&&(Yo(t,o.head.line,e,!0),n=o.head.line,i==t.doc.sel.primIndex&&jr(t));else{var l=o.from(),s=o.to(),a=Math.max(n,l.line);n=Math.min(t.lastLine(),s.line-(s.ch?0:1))+1;for(var u=a;u<n;++u)Yo(t,u,e);var c=t.doc.sel.ranges;0==l.ch&&r.length==c.length&&c[i].from().ch>0&&gi(t.doc,i,new Ts(l,c[i].to()),Gl)}}}),getTokenAt:function(e,t){return Je(this,e,t)},getLineTokens:function(e,t){return Je(this,E(e),t,!0)},getTokenTypeAt:function(e){e=U(this.doc,e);var t,r=_e(this,M(this.doc,e.line)),n=0,i=(r.length-1)/2,o=e.ch;if(0==o)t=r[2];else for(;;){var l=n+i>>1;if((l?r[2*l-1]:0)>=o)i=l;else{if(!(r[2*l+1]<o)){t=r[2*l+2];break}n=l+1}}var s=t?t.indexOf("overlay "):-1;return s<0?t:0==s?null:t.slice(0,s-1)},getModeAt:function(t){var r=this.doc.mode;return r.innerMode?e.innerMode(r,this.getTokenAt(t).state).mode:r},getHelper:function(e,t){return this.getHelpers(e,t)[0]},getHelpers:function(e,t){var n=this,i=[];if(!r.hasOwnProperty(t))return i;var o=r[t],l=this.getModeAt(e);if("string"==typeof l[t])o[l[t]]&&i.push(o[l[t]]);else if(l[t])for(var s=0;s<l[t].length;s++){var a=o[l[t][s]];a&&i.push(a)}else l.helperType&&o[l.helperType]?i.push(o[l.helperType]):o[l.name]&&i.push(o[l.name]);for(var u=0;u<o._global.length;u++){var c=o._global[u];c.pred(l,n)&&-1==h(i,c.val)&&i.push(c.val)}return i},getStateAfter:function(e,t){var r=this.doc;return e=G(r,null==e?r.first+r.size-1:e),$e(this,e+1,t).state},cursorCoords:function(e,t){var r,n=this.doc.sel.primary();return r=null==e?n.head:"object"==typeof e?U(this.doc,e):e?n.from():n.to(),sr(this,r,t||"page")},charCoords:function(e,t){return lr(this,U(this.doc,e),t||"page")},coordsChar:function(e,t){return e=or(this,e,t||"page"),cr(this,e.left,e.top)},lineAtHeight:function(e,t){return e=or(this,{top:e,left:0},t||"page").top,D(this.doc,e+this.display.viewOffset)},heightAtLine:function(e,t,r){var n,i=!1;if("number"==typeof e){var o=this.doc.first+this.doc.size-1;e<this.doc.first?e=this.doc.first:e>o&&(e=o,i=!0),n=M(this.doc,e)}else n=e;return ir(this,n,{top:0,left:0},t||"page",r||i).top+(i?this.doc.height-ye(n):0)},defaultTextHeight:function(){return mr(this.display)},defaultCharWidth:function(){return yr(this.display)},getViewport:function(){return{from:this.display.viewFrom,to:this.display.viewTo}},addWidget:function(e,t,r,n,i){var o=this.display,l=(e=sr(this,U(this.doc,e))).bottom,s=e.left;if(t.style.position="absolute",t.setAttribute("cm-ignore-events","true"),this.display.input.setUneditable(t),o.sizer.appendChild(t),"over"==n)l=e.top;else if("above"==n||"near"==n){var a=Math.max(o.wrapper.clientHeight,this.doc.height),u=Math.max(o.sizer.clientWidth,o.lineSpace.clientWidth);("above"==n||e.bottom+t.offsetHeight>a)&&e.top>t.offsetHeight?l=e.top-t.offsetHeight:e.bottom+t.offsetHeight<=a&&(l=e.bottom),s+t.offsetWidth>u&&(s=u-t.offsetWidth)}t.style.top=l+"px",t.style.left=t.style.right="","right"==i?(s=o.sizer.clientWidth-t.offsetWidth,t.style.right="0px"):("left"==i?s=0:"middle"==i&&(s=(o.sizer.clientWidth-t.offsetWidth)/2),t.style.left=s+"px"),r&&Ur(this,{left:s,top:l,right:s+t.offsetWidth,bottom:l+t.offsetHeight})},triggerOnKeyDown:pn(Lo),triggerOnKeyPress:pn(Mo),triggerOnKeyUp:To,triggerOnMouseDown:pn(Oo),execCommand:function(e){if(Bs.hasOwnProperty(e))return Bs[e].call(null,this)},triggerElectric:pn(function(e){Zo(this,e)}),findPosH:function(e,t,r,n){var i=this,o=1;t<0&&(o=-1,t=-t);for(var l=U(this.doc,e),s=0;s<t&&!(l=tl(i.doc,l,o,r,n)).hitSide;++s);return l},moveH:pn(function(e,t){var r=this;this.extendSelectionsBy(function(n){return r.display.shift||r.doc.extend||n.empty()?tl(r.doc,n.head,e,t,r.options.rtlMoveVisually):e<0?n.from():n.to()},Vl)}),deleteH:pn(function(e,t){var r=this.doc.sel,n=this.doc;r.somethingSelected()?n.replaceSelection("",null,"+delete"):co(this,function(r){var i=tl(n,r.head,e,t,!1);return e<0?{from:i,to:r.head}:{from:r.head,to:i}})}),findPosV:function(e,t,r,n){var i=this,o=1,l=n;t<0&&(o=-1,t=-t);for(var s=U(this.doc,e),a=0;a<t;++a){var u=sr(i,s,"div");if(null==l?l=u.left:u.left=l,(s=rl(i,u,o,r)).hitSide)break}return s},moveV:pn(function(e,t){var r=this,n=this.doc,i=[],o=!this.display.shift&&!n.extend&&n.sel.somethingSelected();if(n.extendSelectionsBy(function(l){if(o)return e<0?l.from():l.to();var s=sr(r,l.head,"div");null!=l.goalColumn&&(s.left=l.goalColumn),i.push(s.left);var a=rl(r,s,e,t);return"page"==t&&l==n.sel.primary()&&Kr(r,lr(r,a,"div").top-s.top),a},Vl),i.length)for(var l=0;l<n.sel.ranges.length;l++)n.sel.ranges[l].goalColumn=i[l]}),findWordAt:function(e){var t=M(this.doc,e.line).text,r=e.ch,n=e.ch;if(t){var i=this.getHelper(e,"wordChars");"before"!=e.sticky&&n!=t.length||!r?++n:--r;for(var o=t.charAt(r),l=x(o,i)?function(e){return x(e,i)}:/\s/.test(o)?function(e){return/\s/.test(e)}:function(e){return!/\s/.test(e)&&!x(e)};r>0&&l(t.charAt(r-1));)--r;for(;n<t.length&&l(t.charAt(n));)++n}return new Ts(E(e.line,r),E(e.line,n))},toggleOverwrite:function(e){null!=e&&e==this.state.overwrite||((this.state.overwrite=!this.state.overwrite)?s(this.display.cursorDiv,"CodeMirror-overwrite"):Fl(this.display.cursorDiv,"CodeMirror-overwrite"),Te(this,"overwriteToggle",this,this.state.overwrite))},hasFocus:function(){return this.display.input.getField()==l()},isReadOnly:function(){return!(!this.options.readOnly&&!this.doc.cantEdit)},scrollTo:pn(function(e,t){Xr(this,e,t)}),getScrollInfo:function(){var e=this.display.scroller;return{left:e.scrollLeft,top:e.scrollTop,height:e.scrollHeight-zt(this)-this.display.barHeight,width:e.scrollWidth-zt(this)-this.display.barWidth,clientHeight:Bt(this),clientWidth:Rt(this)}},scrollIntoView:pn(function(e,t){null==e?(e={from:this.doc.sel.primary().head,to:null},null==t&&(t=this.options.cursorScrollMargin)):"number"==typeof e?e={from:E(e,0),to:null}:null==e.from&&(e={from:e,to:null}),e.to||(e.to=e.from),e.margin=t||0,null!=e.from.line?Yr(this,e):$r(this,e.from,e.to,e.margin)}),setSize:pn(function(e,t){var r=this,n=function(e){return"number"==typeof e||/^\d+$/.test(String(e))?e+"px":e};null!=e&&(this.display.wrapper.style.width=n(e)),null!=t&&(this.display.wrapper.style.height=n(t)),this.options.lineWrapping&&Jt(this);var i=this.display.viewFrom;this.doc.iter(i,this.display.viewTo,function(e){if(e.widgets)for(var t=0;t<e.widgets.length;t++)if(e.widgets[t].noHScroll){mn(r,i,"widget");break}++i}),this.curOp.forceUpdate=!0,Te(this,"refresh",this)}),operation:function(e){return hn(this,e)},startOperation:function(){return nn(this)},endOperation:function(){return on(this)},refresh:pn(function(){var e=this.display.cachedTextHeight;vn(this),this.curOp.forceUpdate=!0,er(this),Xr(this,this.doc.scrollLeft,this.doc.scrollTop),Wn(this),(null==e||Math.abs(e-mr(this.display))>.5)&&Cr(this),Te(this,"refresh",this)}),swapDoc:pn(function(e){var t=this.doc;return t.cm=null,qn(this,e),er(this),this.display.input.reset(),Xr(this,e.scrollLeft,e.scrollTop),this.curOp.forceScroll=!0,bt(this,"swapDoc",this,t),t}),getInputField:function(){return this.display.input.getField()},getWrapperElement:function(){return this.display.wrapper},getScrollerElement:function(){return this.display.scroller},getGutterElement:function(){return this.display.gutters}},Ae(e),e.registerHelper=function(t,n,i){r.hasOwnProperty(t)||(r[t]=e[t]={_global:[]}),r[t][n]=i},e.registerGlobalHelper=function(t,n,i,o){e.registerHelper(t,n,o),r[t]._global.push({pred:i,val:o})}}(jo);var Js="iter insert remove copy getEditor constructor".split(" ");for(var ea in Ds.prototype)Ds.prototype.hasOwnProperty(ea)&&h(Js,ea)<0&&(jo.prototype[ea]=function(e){return function(){return e.apply(this.doc,arguments)}}(Ds.prototype[ea]));return Ae(Ds),jo.inputStyles={textarea:Qs,contenteditable:Zs},jo.defineMode=function(e){jo.defaults.mode||"null"==e||(jo.defaults.mode=e),Be.apply(this,arguments)},jo.defineMIME=function(e,t){os[e]=t},jo.defineMode("null",function(){return{token:function(e){return e.skipToEnd()}}}),jo.defineMIME("text/plain","null"),jo.defineExtension=function(e,t){jo.prototype[e]=t},jo.defineDocExtension=function(e,t){Ds.prototype[e]=t},jo.fromTextArea=function(e,t){function r(){e.value=a.getValue()}if(t=t?c(t):{},t.value=e.value,!t.tabindex&&e.tabIndex&&(t.tabindex=e.tabIndex),!t.placeholder&&e.placeholder&&(t.placeholder=e.placeholder),null==t.autofocus){var n=l();t.autofocus=n==e||null!=e.getAttribute("autofocus")&&n==document.body}var i;if(e.form&&(Ql(e.form,"submit",r),!t.leaveSubmitMethodAlone)){var o=e.form;i=o.submit;try{var s=o.submit=function(){r(),o.submit=i,o.submit(),o.submit=s}}catch(e){}}t.finishInit=function(t){t.save=r,t.getTextArea=function(){return e},t.toTextArea=function(){t.toTextArea=isNaN,r(),e.parentNode.removeChild(t.getWrapperElement()),e.style.display="",e.form&&(ke(e.form,"submit",r),"function"==typeof e.form.submit&&(e.form.submit=i))}},e.style.display="none";var a=jo(function(t){return e.parentNode.insertBefore(t,e.nextSibling)},t);return a},function(e){e.off=ke,e.on=Ql,e.wheelEventPixels=Pn,e.Doc=Ds,e.splitLines=es,e.countColumn=f,e.findColumn=d,e.isWordChar=w,e.Pass=Bl,e.signal=Te,e.Line=fs,e.changeEnd=Bn,e.scrollbarModel=ws,e.Pos=E,e.cmpPos=P,e.modes=is,e.mimeModes=os,e.resolveMode=Ge,e.getMode=Ue,e.modeExtensions=ls,e.extendMode=Ve,e.copyState=Ke,e.startState=Xe,e.innerMode=je,e.commands=Bs,e.keyMap=Rs,e.keyName=ao,e.isModifierKey=lo,e.lookupKey=oo,e.normalizeKeyMap=io,e.StringStream=ss,e.SharedTextMarker=As,e.TextMarker=Os,e.LineWidget=Ms,e.e_preventDefault=We,e.e_stopPropagation=De,e.e_stop=Fe,e.addClass=s,e.contains=o,e.rmClass=Fl,e.keyNames=Es}(jo),jo.version="5.30.0",jo});
      !function(e){"object"==typeof exports&&"object"==typeof module?e(require("../../lib/codemirror")):"function"==typeof define&&define.amd?define(["../../lib/codemirror"],e):e(CodeMirror)}(function(e){"use strict";function t(e,t,n,r,o,a){this.indented=e,this.column=t,this.type=n,this.info=r,this.align=o,this.prev=a}function n(e,n,r,o){var a=e.indented;return e.context&&"statement"==e.context.type&&"statement"!=r&&(a=e.context.indented),e.context=new t(a,n,r,o,null,e.context)}function r(e){var t=e.context.type;return")"!=t&&"]"!=t&&"}"!=t||(e.indented=e.context.indented),e.context=e.context.prev}function o(e,t,n){return"variable"==t.prevToken||"type"==t.prevToken||(!!/\S(?:[^- ]>|[*\]])\s*$|\*$/.test(e.string.slice(0,n))||(!(!t.typeAtEndOfLine||e.column()!=e.indentation())||void 0))}function a(e){for(;;){if(!e||"top"==e.type)return!0;if("}"==e.type&&"namespace"!=e.prev.info)return!1;e=e.prev}}function i(e){for(var t={},n=e.split(" "),r=0;r<n.length;++r)t[n[r]]=!0;return t}function l(e,t){return"function"==typeof e?e(t):e.propertyIsEnumerable(t)}function s(e,t){if(!t.startOfLine)return!1;for(var n,r=null;n=e.peek();){if("\\"==n&&e.match(/^.$/)){r=s;break}if("/"==n&&e.match(/^\/[\/\*]/,!1))break;e.next()}return t.tokenize=r,"meta"}function c(e,t){return"type"==t.prevToken&&"type"}function u(e){return e.eatWhile(/[\w\.']/),"number"}function d(e,t){if(e.backUp(1),e.match(/(R|u8R|uR|UR|LR)/)){var n=e.match(/"([^\s\\()]{0,16})\(/);return!!n&&(t.cpp11RawStringDelim=n[1],t.tokenize=m,m(e,t))}return e.match(/(u8|u|U|L)/)?!!e.match(/["']/,!1)&&"string":(e.next(),!1)}function f(e){var t=/(\w+)::~?(\w+)$/.exec(e);return t&&t[1]==t[2]}function p(e,t){for(var n;null!=(n=e.next());)if('"'==n&&!e.eat('"')){t.tokenize=null;break}return"string"}function m(e,t){var n=t.cpp11RawStringDelim.replace(/[^\w\s]/g,"\\$&");return e.match(new RegExp(".*?\\)"+n+'"'))?t.tokenize=null:e.skipToEnd(),"string"}function h(t,n){function r(e){if(e)for(var t in e)e.hasOwnProperty(t)&&o.push(t)}"string"==typeof t&&(t=[t]);var o=[];r(n.keywords),r(n.types),r(n.builtin),r(n.atoms),o.length&&(n.helperType=t[0],e.registerHelper("hintWords",t[0],o));for(var a=0;a<t.length;++a)e.defineMIME(t[a],n)}function g(e,t){for(var n=!1;!e.eol();){if(!n&&e.match('"""')){t.tokenize=null;break}n="\\"==e.next()&&!n}return"string"}function y(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!e&&!o&&t.match('"')){a=!0;break}if(e&&t.match('"""')){a=!0;break}r=t.next(),!o&&"$"==r&&t.match("{")&&t.skipTo("}"),o=!o&&"\\"==r&&!e}return!a&&e||(n.tokenize=null),"string"}}function x(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!o&&t.match('"')&&("single"==e||t.match('""'))){a=!0;break}if(!o&&t.match("``")){w=x(e),a=!0;break}r=t.next(),o="single"==e&&!o&&"\\"==r}return a&&(n.tokenize=null),"string"}}e.defineMode("clike",function(i,s){function c(e,t){var n=e.next();if(S[n]){var r=S[n](e,t);if(!1!==r)return r}if('"'==n||"'"==n)return t.tokenize=u(n),t.tokenize(e,t);if(D.test(n))return p=n,null;if(L.test(n)){if(e.backUp(1),e.match(I))return"number";e.next()}if("/"==n){if(e.eat("*"))return t.tokenize=d,d(e,t);if(e.eat("/"))return e.skipToEnd(),"comment"}if(F.test(n)){for(;!e.match(/^\/[\/*]/,!1)&&e.eat(F););return"operator"}if(e.eatWhile(z),P)for(;e.match(P);)e.eatWhile(z);var o=e.current();return l(x,o)?(l(w,o)&&(p="newstatement"),l(v,o)&&(m=!0),"keyword"):l(b,o)?"type":l(k,o)?(l(w,o)&&(p="newstatement"),"builtin"):l(_,o)?"atom":"variable"}function u(e){return function(t,n){for(var r,o=!1,a=!1;null!=(r=t.next());){if(r==e&&!o){a=!0;break}o=!o&&"\\"==r}return(a||!o&&!C)&&(n.tokenize=null),"string"}}function d(e,t){for(var n,r=!1;n=e.next();){if("/"==n&&r){t.tokenize=null;break}r="*"==n}return"comment"}function f(e,t){s.typeFirstDefinitions&&e.eol()&&a(t.context)&&(t.typeAtEndOfLine=o(e,t,e.pos))}var p,m,h=i.indentUnit,g=s.statementIndentUnit||h,y=s.dontAlignCalls,x=s.keywords||{},b=s.types||{},k=s.builtin||{},w=s.blockKeywords||{},v=s.defKeywords||{},_=s.atoms||{},S=s.hooks||{},C=s.multiLineStrings,T=!1!==s.indentStatements,M=!1!==s.indentSwitch,P=s.namespaceSeparator,D=s.isPunctuationChar||/[\[\]{}\(\),;\:\.]/,L=s.numberStart||/[\d\.]/,I=s.number||/^(?:0x[a-f\d]+|0b[01]+|(?:\d+\.?\d*|\.\d+)(?:e[-+]?\d+)?)(u|ll?|l|f)?/i,F=s.isOperatorChar||/[+\-*&%=<>!?|\/]/,z=s.isIdentifierChar||/[\w\$_\xa1-\uffff]/;return{startState:function(e){return{tokenize:null,context:new t((e||0)-h,0,"top",null,!1),indented:0,startOfLine:!0,prevToken:null}},token:function(e,t){var i=t.context;if(e.sol()&&(null==i.align&&(i.align=!1),t.indented=e.indentation(),t.startOfLine=!0),e.eatSpace())return f(e,t),null;p=m=null;var l=(t.tokenize||c)(e,t);if("comment"==l||"meta"==l)return l;if(null==i.align&&(i.align=!0),";"==p||":"==p||","==p&&e.match(/^\s*(?:\/\/.*)?$/,!1))for(;"statement"==t.context.type;)r(t);else if("{"==p)n(t,e.column(),"}");else if("["==p)n(t,e.column(),"]");else if("("==p)n(t,e.column(),")");else if("}"==p){for(;"statement"==i.type;)i=r(t);for("}"==i.type&&(i=r(t));"statement"==i.type;)i=r(t)}else p==i.type?r(t):T&&(("}"==i.type||"top"==i.type)&&";"!=p||"statement"==i.type&&"newstatement"==p)&&n(t,e.column(),"statement",e.current());if("variable"==l&&("def"==t.prevToken||s.typeFirstDefinitions&&o(e,t,e.start)&&a(t.context)&&e.match(/^\s*\(/,!1))&&(l="def"),S.token){var u=S.token(e,t,l);void 0!==u&&(l=u)}return"def"==l&&!1===s.styleDefs&&(l="variable"),t.startOfLine=!1,t.prevToken=m?"def":l||p,f(e,t),l},indent:function(t,n){if(t.tokenize!=c&&null!=t.tokenize||t.typeAtEndOfLine)return e.Pass;var r=t.context,o=n&&n.charAt(0);if("statement"==r.type&&"}"==o&&(r=r.prev),s.dontIndentStatements)for(;"statement"==r.type&&s.dontIndentStatements.test(r.info);)r=r.prev;if(S.indent){var a=S.indent(t,r,n);if("number"==typeof a)return a}var i=o==r.type,l=r.prev&&"switch"==r.prev.info;if(s.allmanIndentation&&/[{(]/.test(o)){for(;"top"!=r.type&&"}"!=r.type;)r=r.prev;return r.indented}return"statement"==r.type?r.indented+("{"==o?0:g):!r.align||y&&")"==r.type?")"!=r.type||i?r.indented+(i?0:h)+(i||!l||/^(?:case|default)\b/.test(n)?0:h):r.indented+g:r.column+(i?0:1)},electricInput:M?/^\s*(?:case .*?:|default:|\{\}?|\})$/:/^\s*[{}]$/,blockCommentStart:"/*",blockCommentEnd:"*/",lineComment:"//",fold:"brace"}});var b="auto if break case register continue return default do sizeof static else struct switch extern typedef union for goto while enum const volatile",k="int long char short double float unsigned signed void size_t ptrdiff_t";h(["text/x-csrc","text/x-c","text/x-chdr"],{name:"clike",keywords:i(b),types:i(k+" bool _Complex _Bool float_t double_t intptr_t intmax_t int8_t int16_t int32_t int64_t uintptr_t uintmax_t uint8_t uint16_t uint32_t uint64_t"),blockKeywords:i("case do else for if switch while struct"),defKeywords:i("struct"),typeFirstDefinitions:!0,atoms:i("null true false"),hooks:{"#":s,"*":c},modeProps:{fold:["brace","include"]}}),h(["text/x-c++src","text/x-c++hdr"],{name:"clike",keywords:i(b+" asm dynamic_cast namespace reinterpret_cast try explicit new static_cast typeid catch operator template typename class friend private this using const_cast inline public throw virtual delete mutable protected alignas alignof constexpr decltype nullptr noexcept thread_local final static_assert override"),types:i(k+" bool wchar_t"),blockKeywords:i("catch class do else finally for if struct switch try while"),defKeywords:i("class namespace struct enum union"),typeFirstDefinitions:!0,atoms:i("true false null"),dontIndentStatements:/^template$/,isIdentifierChar:/[\w\$_~\xa1-\uffff]/,hooks:{"#":s,"*":c,u:d,U:d,L:d,R:d,0:u,1:u,2:u,3:u,4:u,5:u,6:u,7:u,8:u,9:u,token:function(e,t,n){if("variable"==n&&"("==e.peek()&&(";"==t.prevToken||null==t.prevToken||"}"==t.prevToken)&&f(e.current()))return"def"}},namespaceSeparator:"::",modeProps:{fold:["brace","include"]}}),h("text/x-java",{name:"clike",keywords:i("abstract assert break case catch class const continue default do else enum extends final finally float for goto if implements import instanceof interface native new package private protected public return static strictfp super switch synchronized this throw throws transient try volatile while @interface"),types:i("byte short int long float double boolean char void Boolean Byte Character Double Float Integer Long Number Object Short String StringBuffer StringBuilder Void"),blockKeywords:i("catch class do else finally for if switch try while"),defKeywords:i("class interface package enum @interface"),typeFirstDefinitions:!0,atoms:i("true false null"),number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,hooks:{"@":function(e){return!e.match("interface",!1)&&(e.eatWhile(/[\w\$_]/),"meta")}},modeProps:{fold:["brace","import"]}}),h("text/x-csharp",{name:"clike",keywords:i("abstract as async await base break case catch checked class const continue default delegate do else enum event explicit extern finally fixed for foreach goto if implicit in interface internal is lock namespace new operator out override params private protected public readonly ref return sealed sizeof stackalloc static struct switch this throw try typeof unchecked unsafe using virtual void volatile while add alias ascending descending dynamic from get global group into join let orderby partial remove select set value var yield"),types:i("Action Boolean Byte Char DateTime DateTimeOffset Decimal Double Func Guid Int16 Int32 Int64 Object SByte Single String Task TimeSpan UInt16 UInt32 UInt64 bool byte char decimal double short int long object sbyte float string ushort uint ulong"),blockKeywords:i("catch class do else finally for foreach if struct switch try while"),defKeywords:i("class interface namespace struct var"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"@":function(e,t){return e.eat('"')?(t.tokenize=p,p(e,t)):(e.eatWhile(/[\w\$_]/),"meta")}}}),h("text/x-scala",{name:"clike",keywords:i("abstract case catch class def do else extends final finally for forSome if implicit import lazy match new null object override package private protected return sealed super this throw trait try type val var while with yield _ assert assume require print println printf readLine readBoolean readByte readShort readChar readInt readLong readFloat readDouble"),types:i("AnyVal App Application Array BufferedIterator BigDecimal BigInt Char Console Either Enumeration Equiv Error Exception Fractional Function IndexedSeq Int Integral Iterable Iterator List Map Numeric Nil NotNull Option Ordered Ordering PartialFunction PartialOrdering Product Proxy Range Responder Seq Serializable Set Specializable Stream StringBuilder StringContext Symbol Throwable Traversable TraversableOnce Tuple Unit Vector Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),multiLineStrings:!0,blockKeywords:i("catch class enum do else finally for forSome if match switch try while"),defKeywords:i("class enum def object package trait type val var"),atoms:i("true false null"),indentStatements:!1,indentSwitch:!1,isOperatorChar:/[+\-*&%=<>!?|\/#:@]/,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return!!e.match('""')&&(t.tokenize=g,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},"=":function(e,n){var r=n.context;return!("}"!=r.type||!r.align||!e.eat(">"))&&(n.context=new t(r.indented,r.column,r.type,r.info,null,r.prev),"operator")}},modeProps:{closeBrackets:{triples:'"'}}}),h("text/x-kotlin",{name:"clike",keywords:i("package as typealias class interface this super val var fun for is in This throw return break continue object if else while do try when !in !is as? file import where by get set abstract enum open inner override private public internal protected catch finally out final vararg reified dynamic companion constructor init sealed field property receiver param sparam lateinit data inline noinline tailrec external annotation crossinline const operator infix suspend"),types:i("Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),intendSwitch:!1,indentStatements:!1,multiLineStrings:!0,number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,blockKeywords:i("catch class do else finally for if where try while enum"),defKeywords:i("class val var object package interface fun"),atoms:i("true false null this"),hooks:{'"':function(e,t){return t.tokenize=y(e.match('""')),t.tokenize(e,t)}},modeProps:{closeBrackets:{triples:'"'}}}),h(["x-shader/x-vertex","x-shader/x-fragment"],{name:"clike",keywords:i("sampler1D sampler2D sampler3D samplerCube sampler1DShadow sampler2DShadow const attribute uniform varying break continue discard return for while do if else struct in out inout"),types:i("float int bool void vec2 vec3 vec4 ivec2 ivec3 ivec4 bvec2 bvec3 bvec4 mat2 mat3 mat4"),blockKeywords:i("for while do if else struct"),builtin:i("radians degrees sin cos tan asin acos atan pow exp log exp2 sqrt inversesqrt abs sign floor ceil fract mod min max clamp mix step smoothstep length distance dot cross normalize ftransform faceforward reflect refract matrixCompMult lessThan lessThanEqual greaterThan greaterThanEqual equal notEqual any all not texture1D texture1DProj texture1DLod texture1DProjLod texture2D texture2DProj texture2DLod texture2DProjLod texture3D texture3DProj texture3DLod texture3DProjLod textureCube textureCubeLod shadow1D shadow2D shadow1DProj shadow2DProj shadow1DLod shadow2DLod shadow1DProjLod shadow2DProjLod dFdx dFdy fwidth noise1 noise2 noise3 noise4"),atoms:i("true false gl_FragColor gl_SecondaryColor gl_Normal gl_Vertex gl_MultiTexCoord0 gl_MultiTexCoord1 gl_MultiTexCoord2 gl_MultiTexCoord3 gl_MultiTexCoord4 gl_MultiTexCoord5 gl_MultiTexCoord6 gl_MultiTexCoord7 gl_FogCoord gl_PointCoord gl_Position gl_PointSize gl_ClipVertex gl_FrontColor gl_BackColor gl_FrontSecondaryColor gl_BackSecondaryColor gl_TexCoord gl_FogFragCoord gl_FragCoord gl_FrontFacing gl_FragData gl_FragDepth gl_ModelViewMatrix gl_ProjectionMatrix gl_ModelViewProjectionMatrix gl_TextureMatrix gl_NormalMatrix gl_ModelViewMatrixInverse gl_ProjectionMatrixInverse gl_ModelViewProjectionMatrixInverse gl_TexureMatrixTranspose gl_ModelViewMatrixInverseTranspose gl_ProjectionMatrixInverseTranspose gl_ModelViewProjectionMatrixInverseTranspose gl_TextureMatrixInverseTranspose gl_NormalScale gl_DepthRange gl_ClipPlane gl_Point gl_FrontMaterial gl_BackMaterial gl_LightSource gl_LightModel gl_FrontLightModelProduct gl_BackLightModelProduct gl_TextureColor gl_EyePlaneS gl_EyePlaneT gl_EyePlaneR gl_EyePlaneQ gl_FogParameters gl_MaxLights gl_MaxClipPlanes gl_MaxTextureUnits gl_MaxTextureCoords gl_MaxVertexAttribs gl_MaxVertexUniformComponents gl_MaxVaryingFloats gl_MaxVertexTextureImageUnits gl_MaxTextureImageUnits gl_MaxFragmentUniformComponents gl_MaxCombineTextureImageUnits gl_MaxDrawBuffers"),indentSwitch:!1,hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-nesc",{name:"clike",keywords:i(b+"as atomic async call command component components configuration event generic implementation includes interface module new norace nx_struct nx_union post provides signal task uses abstract extends"),types:i(k),blockKeywords:i("case do else for if switch while struct"),atoms:i("null true false"),hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-objectivec",{name:"clike",keywords:i(b+"inline restrict _Bool _Complex _Imaginary BOOL Class bycopy byref id IMP in inout nil oneway out Protocol SEL self super atomic nonatomic retain copy readwrite readonly"),types:i(k),atoms:i("YES NO NULL NILL ON OFF true false"),hooks:{"@":function(e){return e.eatWhile(/[\w\$]/),"keyword"},"#":s,indent:function(e,t,n){if("statement"==t.type&&/^@\w/.test(n))return t.indented}},modeProps:{fold:"brace"}}),h("text/x-squirrel",{name:"clike",keywords:i("base break clone continue const default delete enum extends function in class foreach local resume return this throw typeof yield constructor instanceof static"),types:i(k),blockKeywords:i("case catch class else for foreach if switch try while"),defKeywords:i("function local class"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"#":s},modeProps:{fold:["brace","include"]}});var w=null;h("text/x-ceylon",{name:"clike",keywords:i("abstracts alias assembly assert assign break case catch class continue dynamic else exists extends finally for function given if import in interface is let module new nonempty object of out outer package return satisfies super switch then this throw try value void while"),types:function(e){var t=e.charAt(0);return t===t.toUpperCase()&&t!==t.toLowerCase()},blockKeywords:i("case catch class dynamic else finally for function if interface module new object switch try while"),defKeywords:i("class dynamic function interface module object package value"),builtin:i("abstract actual aliased annotation by default deprecated doc final formal late license native optional sealed see serializable shared suppressWarnings tagged throws variable"),isPunctuationChar:/[\[\]{}\(\),;\:\.`]/,isOperatorChar:/[+\-*&%=<>!?|^~:\/]/,numberStart:/[\d#$]/,number:/^(?:#[\da-fA-F_]+|\$[01_]+|[\d_]+[kMGTPmunpf]?|[\d_]+\.[\d_]+(?:[eE][-+]?\d+|[kMGTPmunpf]|)|)/i,multiLineStrings:!0,typeFirstDefinitions:!0,atoms:i("true false null larger smaller equal empty finished"),indentSwitch:!1,styleDefs:!1,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return t.tokenize=x(e.match('""')?"triple":"single"),t.tokenize(e,t)},"`":function(e,t){return!(!w||!e.match("`"))&&(t.tokenize=w,w=null,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},token:function(e,t,n){if(("variable"==n||"type"==n)&&"."==t.prevToken)return"variable-2"}},modeProps:{fold:["brace","import"],closeBrackets:{triples:'"'}}})});
      // -------------------------------------------------------------------------
//  Part of the CodeChecker project, under the Apache License v2.0 with
//  LLVM Exceptions. See LICENSE for license information.
//  SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
// -------------------------------------------------------------------------

var BugViewer = {
  _files : [],
  _reports : [],
  _lineWidgets : [],
  _navigationMenuItems : [],
  _sourceFileData : null,
  _currentReport : null,
  _lastBugEvent  : null,

  init : function (files, reports) {
    this._files = files;
    this._reports = reports;

    this.initEscapeChars();
  },

  initEscapeChars : function () {
    this.escapeChars = {
      ' ' : 'nbsp',
      '<' : 'lt',
      '>' : 'gt',
      '"' : 'quot',
      '&' : 'amp'
    };

    var regexString = '[';
    for (var key in this.escapeChars) {
      regexString += key;
    }
    regexString += ']';

    this.escapeRegExp = new RegExp( regexString, 'g');
  },

  escapeHTML : function (str) {
    var that = this;

    return str.replace(this.escapeRegExp, function (m) {
      return '&' + that.escapeChars[m] + ';';
    });
  },

  initByUrl : function () {
    if (!this._reports) return;

    var state = {};
    window.location.hash.substr(1).split('&').forEach(function (s) {
      var parts = s.split('=');
      state[parts[0]] = parts[1];
    });

    for (var key in this._reports) {
      var report = this._reports[key];
      if (report.reportHash === state['reportHash']) {
        this.navigate(report);
        return;
      }
    }

    this.navigate(this._reports[0]);
  },

  create : function () {
    this._content = document.getElementById('editor-wrapper');
    this._filepath = document.getElementById('file-path');
    this._checkerName = document.getElementById('checker-name');
    this._reviewStatusWrapper =
      document.getElementById('review-status-wrapper');
    this._reviewStatus = document.getElementById('review-status');
    this._editor = document.getElementById('editor');

    this._codeMirror = CodeMirror(this._editor, {
      mode: 'text/x-c++src',
      matchBrackets : true,
      lineNumbers : true,
      readOnly : true,
      foldGutter : true,
      extraKeys : {},
      viewportMargin : 100
    });

    this._createNavigationMenu();
  },

  navigate : function (report, item) {
    if (!item) {
      var items = this._navigationMenuItems.filter(function (navItem) {
        return navItem.report.reportHash === report.reportHash;
      });

      if (!items.length) return;

      item = items[0].widget;
    }

    this._selectedReport.classList.remove('active');
    this._selectedReport = item;
    this._selectedReport.classList.add('active');
    this.setReport(report);
  },

  _createNavigationMenu : function () {
    var that = this;

    var nav = document.getElementById('report-nav');
    var list = document.createElement('ul');
    this._reports.forEach(function (report) {
      var events = report['events'];
      var lastBugEvent = events[events.length - 1];
      var item = document.createElement('li');

      var severity = document.createElement('i');
      severity.className = 'severity-' + report.severity.toLowerCase();

      item.appendChild(severity);
      item.appendChild(document.createTextNode(lastBugEvent.message));

      item.addEventListener('click', function () {
        that.navigate(report, item);
      })
      list.appendChild(item);
      that._navigationMenuItems.push({ report : report, widget : item });
    });

    if (!this._selectedReport && list.childNodes.length) {
      this._selectedReport = list.childNodes[0];
      this._selectedReport.classList.add('active');
    }

    nav.appendChild(list);
  },

  setReport : function (report) {
    this._currentReport = report;
    var events = report['events'];
    var lastBugEvent = events[events.length - 1];
    this.setCurrentBugEvent(lastBugEvent, events.length - 1);
    this.setCheckerName(report.checkerName);
    this.setReviewStatus(report.reviewStatus);

    window.location.hash = '#reportHash=' + report.reportHash;
  },

  setCurrentBugEvent : function (event, idx) {
    this._currentBugEvent = event;
    this.setSourceFileData(this._files[event.location.file]);
    this.drawBugPath();

    this.jumpTo(event.location.line, 0);
    this.highlightBugEvent(event, idx);
  },

  highlightBugEvent : function (event, idx) {
    this._lineWidgets.forEach(function (widget) {
      var lineIdx = widget.node.getAttribute('idx');
      if (parseInt(lineIdx) === idx) {
        widget.node.classList.add('current');
      }
    });
  },

  setCheckerName : function (checkerName) {
    this._checkerName.innerHTML = checkerName;
  },

  setReviewStatus : function (status) {
    if (status) {
      var className =
        'review-status-' + status.toLowerCase().split(' ').join('-');
      this._reviewStatus.className = "review-status " + className;

      this._reviewStatus.innerHTML = status;
      this._reviewStatusWrapper.style.display = 'block';
    } else {
      this._reviewStatusWrapper.style.display = 'none';
    }
  },

  setSourceFileData : function (file) {
    if (this._sourceFileData && file.id === this._sourceFileData.id) {
      return;
    }

    this._sourceFileData = file;
    this._filepath.innerHTML = file.path;
    this._codeMirror.doc.setValue(file.content);
    this._refresh();
  },

  _refresh : function () {
    var that = this;
    setTimeout(function () {
      var fullHeight = parseInt(that._content.clientHeight);
      var headerHeight = that._filepath.clientHeight;

      that._codeMirror.setSize('auto', fullHeight - headerHeight);
      that._codeMirror.refresh();
    }, 200);
  },

  clearBubbles : function () {
    this._lineWidgets.forEach(function (widget) { widget.clear(); });
    this._lineWidgets = [];
  },

  getMessage : function (event, kind) {
    if (kind === 'macro') {
      var name = 'macro expansion' + (event.name ? ': ' + event.name : '');

      return '<span class="tag macro">' + name + '</span>'
        + this.escapeHTML(event.expansion).replace(/(?:\r\n|\r|\n)/g, '<br>');
    } else if (kind === 'note') {
      return '<span class="tag note">note</span>'
        +  this.escapeHTML(event.message).replace(/(?:\r\n|\r|\n)/g, '<br>');
    }
  },

  addExtraPathEvents : function (events, kind) {
    var that = this;

    if (!events) {
      return;
    }

    events.forEach(function (event) {
      if (event.location.file !== that._currentBugEvent.location.file) {
        return;
      }

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + kind);

      var msg = document.createElement('span');
      msg.innerHTML = that.getMessage(event, kind);
      element.appendChild(msg);

      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  drawBugPath : function () {
    var that = this;

    this.clearBubbles();

    this.addExtraPathEvents(this._currentReport.macros, 'macro');
    this.addExtraPathEvents(this._currentReport.notes, 'note');

    // Processing bug path events.
    var currentEvents = this._currentReport.events;
    currentEvents.forEach(function (event, step) {
      if (event.location.file !== that._currentBugEvent.location.file)
        return;

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';
      var type = step === currentEvents.length - 1 ? 'error' : 'info';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + type);
      element.setAttribute('idx', step);

      var enumeration = document.createElement('span');
      enumeration.setAttribute('class', 'checker-enum ' + type);
      enumeration.innerHTML = step + 1;

      if (currentEvents.length > 1)
        element.appendChild(enumeration);

      var prevBugEvent = step - 1;
      if (step > 0) {
        var prevBug = document.createElement('span');
        prevBug.setAttribute('class', 'arrow left-arrow');
        prevBug.addEventListener('click', function () {
          var event = currentEvents[prevBugEvent];
          that.setCurrentBugEvent(event, prevBugEvent);
        });
        element.appendChild(prevBug);
      }

      var msg = document.createElement('span');
      msg.innerHTML = that.escapeHTML(event.message)
        .replace(/(?:\r\n|\r|\n)/g, '<br>');

      element.appendChild(msg);

      var nextBugEvent = step + 1;
      if (nextBugEvent < currentEvents.length) {
        var nextBug = document.createElement('span');
        nextBug.setAttribute('class', 'arrow right-arrow');
        nextBug.addEventListener('click', function () {
          var event = currentEvents[nextBugEvent];
          that.setCurrentBugEvent(event, nextBugEvent);
        });
        element.appendChild(nextBug);
      }


      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  jumpTo : function (line, column) {
    var that = this;

    setTimeout(function () {
      var selPosPixel
        = that._codeMirror.charCoords({ line : line, ch : column }, 'local');
      var editorSize = {
        width  : that._editor.clientWidth,
        height : that._editor.clientHeight
      };

      that._codeMirror.scrollIntoView({
        top    : selPosPixel.top - 100,
        bottom : selPosPixel.top + editorSize.height - 150,
        left   : selPosPixel.left < editorSize.width - 100
               ? 0
               : selPosPixel.left - 50,
        right  : selPosPixel.left < editorSize.width - 100
               ? 10
               : selPosPixel.left + editorSize.width - 100
      });
    }, 0);
  }
}


      var data = {"files": {"0": {"id": 0, "path": "/src/mm/memcontrol.c", "content": "// SPDX-License-Identifier: GPL-2.0-or-later\n/* memcontrol.c - Memory Controller\n *\n * Copyright IBM Corporation, 2007\n * Author Balbir Singh <balbir@linux.vnet.ibm.com>\n *\n * Copyright 2007 OpenVZ SWsoft Inc\n * Author: Pavel Emelianov <xemul@openvz.org>\n *\n * Memory thresholds\n * Copyright (C) 2009 Nokia Corporation\n * Author: Kirill A. Shutemov\n *\n * Kernel Memory Controller\n * Copyright (C) 2012 Parallels Inc. and Google Inc.\n * Authors: Glauber Costa and Suleiman Souhlal\n *\n * Native page reclaim\n * Charge lifetime sanitation\n * Lockless page tracking & accounting\n * Unified hierarchy configuration model\n * Copyright (C) 2015 Red Hat, Inc., Johannes Weiner\n */\n\n#include <linux/page_counter.h>\n#include <linux/memcontrol.h>\n#include <linux/cgroup.h>\n#include <linux/pagewalk.h>\n#include <linux/sched/mm.h>\n#include <linux/shmem_fs.h>\n#include <linux/hugetlb.h>\n#include <linux/pagemap.h>\n#include <linux/vm_event_item.h>\n#include <linux/smp.h>\n#include <linux/page-flags.h>\n#include <linux/backing-dev.h>\n#include <linux/bit_spinlock.h>\n#include <linux/rcupdate.h>\n#include <linux/limits.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/rbtree.h>\n#include <linux/slab.h>\n#include <linux/swap.h>\n#include <linux/swapops.h>\n#include <linux/spinlock.h>\n#include <linux/eventfd.h>\n#include <linux/poll.h>\n#include <linux/sort.h>\n#include <linux/fs.h>\n#include <linux/seq_file.h>\n#include <linux/vmpressure.h>\n#include <linux/mm_inline.h>\n#include <linux/swap_cgroup.h>\n#include <linux/cpu.h>\n#include <linux/oom.h>\n#include <linux/lockdep.h>\n#include <linux/file.h>\n#include <linux/tracehook.h>\n#include <linux/psi.h>\n#include <linux/seq_buf.h>\n#include \"internal.h\"\n#include <net/sock.h>\n#include <net/ip.h>\n#include \"slab.h\"\n\n#include <linux/uaccess.h>\n\n#include <trace/events/vmscan.h>\n\nstruct cgroup_subsys memory_cgrp_subsys __read_mostly;\nEXPORT_SYMBOL(memory_cgrp_subsys);\n\nstruct mem_cgroup *root_mem_cgroup __read_mostly;\n\n/* Active memory cgroup to use from an interrupt context */\nDEFINE_PER_CPU(struct mem_cgroup *, int_active_memcg);\n\n/* Socket memory accounting disabled? */\nstatic bool cgroup_memory_nosocket;\n\n/* Kernel memory accounting disabled? */\nstatic bool cgroup_memory_nokmem;\n\n/* Whether the swap controller is active */\n#ifdef CONFIG_MEMCG_SWAP\nbool cgroup_memory_noswap __read_mostly;\n#else\n#define cgroup_memory_noswap\t\t1\n#endif\n\n#ifdef CONFIG_CGROUP_WRITEBACK\nstatic DECLARE_WAIT_QUEUE_HEAD(memcg_cgwb_frn_waitq);\n#endif\n\n/* Whether legacy memory+swap accounting is active */\nstatic bool do_memsw_account(void)\n{\n\treturn !cgroup_subsys_on_dfl(memory_cgrp_subsys) && !cgroup_memory_noswap;\n}\n\n#define THRESHOLDS_EVENTS_TARGET 128\n#define SOFTLIMIT_EVENTS_TARGET 1024\n\n/*\n * Cgroups above their limits are maintained in a RB-Tree, independent of\n * their hierarchy representation\n */\n\nstruct mem_cgroup_tree_per_node {\n\tstruct rb_root rb_root;\n\tstruct rb_node *rb_rightmost;\n\tspinlock_t lock;\n};\n\nstruct mem_cgroup_tree {\n\tstruct mem_cgroup_tree_per_node *rb_tree_per_node[MAX_NUMNODES];\n};\n\nstatic struct mem_cgroup_tree soft_limit_tree __read_mostly;\n\n/* for OOM */\nstruct mem_cgroup_eventfd_list {\n\tstruct list_head list;\n\tstruct eventfd_ctx *eventfd;\n};\n\n/*\n * cgroup_event represents events which userspace want to receive.\n */\nstruct mem_cgroup_event {\n\t/*\n\t * memcg which the event belongs to.\n\t */\n\tstruct mem_cgroup *memcg;\n\t/*\n\t * eventfd to signal userspace about the event.\n\t */\n\tstruct eventfd_ctx *eventfd;\n\t/*\n\t * Each of these stored in a list by the cgroup.\n\t */\n\tstruct list_head list;\n\t/*\n\t * register_event() callback will be used to add new userspace\n\t * waiter for changes related to this event.  Use eventfd_signal()\n\t * on eventfd to send notification to userspace.\n\t */\n\tint (*register_event)(struct mem_cgroup *memcg,\n\t\t\t      struct eventfd_ctx *eventfd, const char *args);\n\t/*\n\t * unregister_event() callback will be called when userspace closes\n\t * the eventfd or on cgroup removing.  This callback must be set,\n\t * if you want provide notification functionality.\n\t */\n\tvoid (*unregister_event)(struct mem_cgroup *memcg,\n\t\t\t\t struct eventfd_ctx *eventfd);\n\t/*\n\t * All fields below needed to unregister event when\n\t * userspace closes eventfd.\n\t */\n\tpoll_table pt;\n\twait_queue_head_t *wqh;\n\twait_queue_entry_t wait;\n\tstruct work_struct remove;\n};\n\nstatic void mem_cgroup_threshold(struct mem_cgroup *memcg);\nstatic void mem_cgroup_oom_notify(struct mem_cgroup *memcg);\n\n/* Stuffs for move charges at task migration. */\n/*\n * Types of charges to be moved.\n */\n#define MOVE_ANON\t0x1U\n#define MOVE_FILE\t0x2U\n#define MOVE_MASK\t(MOVE_ANON | MOVE_FILE)\n\n/* \"mc\" and its members are protected by cgroup_mutex */\nstatic struct move_charge_struct {\n\tspinlock_t\t  lock; /* for from, to */\n\tstruct mm_struct  *mm;\n\tstruct mem_cgroup *from;\n\tstruct mem_cgroup *to;\n\tunsigned long flags;\n\tunsigned long precharge;\n\tunsigned long moved_charge;\n\tunsigned long moved_swap;\n\tstruct task_struct *moving_task;\t/* a task moving charges */\n\twait_queue_head_t waitq;\t\t/* a waitq for other context */\n} mc = {\n\t.lock = __SPIN_LOCK_UNLOCKED(mc.lock),\n\t.waitq = __WAIT_QUEUE_HEAD_INITIALIZER(mc.waitq),\n};\n\n/*\n * Maximum loops in mem_cgroup_hierarchical_reclaim(), used for soft\n * limit reclaim to prevent infinite loops, if they ever occur.\n */\n#define\tMEM_CGROUP_MAX_RECLAIM_LOOPS\t\t100\n#define\tMEM_CGROUP_MAX_SOFT_LIMIT_RECLAIM_LOOPS\t2\n\n/* for encoding cft->private value on file */\nenum res_type {\n\t_MEM,\n\t_MEMSWAP,\n\t_OOM_TYPE,\n\t_KMEM,\n\t_TCP,\n};\n\n#define MEMFILE_PRIVATE(x, val)\t((x) << 16 | (val))\n#define MEMFILE_TYPE(val)\t((val) >> 16 & 0xffff)\n#define MEMFILE_ATTR(val)\t((val) & 0xffff)\n/* Used for OOM nofiier */\n#define OOM_CONTROL\t\t(0)\n\n/*\n * Iteration constructs for visiting all cgroups (under a tree).  If\n * loops are exited prematurely (break), mem_cgroup_iter_break() must\n * be used for reference counting.\n */\n#define for_each_mem_cgroup_tree(iter, root)\t\t\\\n\tfor (iter = mem_cgroup_iter(root, NULL, NULL);\t\\\n\t     iter != NULL;\t\t\t\t\\\n\t     iter = mem_cgroup_iter(root, iter, NULL))\n\n#define for_each_mem_cgroup(iter)\t\t\t\\\n\tfor (iter = mem_cgroup_iter(NULL, NULL, NULL);\t\\\n\t     iter != NULL;\t\t\t\t\\\n\t     iter = mem_cgroup_iter(NULL, iter, NULL))\n\nstatic inline bool should_force_charge(void)\n{\n\treturn tsk_is_oom_victim(current) || fatal_signal_pending(current) ||\n\t\t(current->flags & PF_EXITING);\n}\n\n/* Some nice accessors for the vmpressure. */\nstruct vmpressure *memcg_to_vmpressure(struct mem_cgroup *memcg)\n{\n\tif (!memcg)\n\t\tmemcg = root_mem_cgroup;\n\treturn &memcg->vmpressure;\n}\n\nstruct cgroup_subsys_state *vmpressure_to_css(struct vmpressure *vmpr)\n{\n\treturn &container_of(vmpr, struct mem_cgroup, vmpressure)->css;\n}\n\n#ifdef CONFIG_MEMCG_KMEM\nextern spinlock_t css_set_lock;\n\nstatic void obj_cgroup_release(struct percpu_ref *ref)\n{\n\tstruct obj_cgroup *objcg = container_of(ref, struct obj_cgroup, refcnt);\n\tstruct mem_cgroup *memcg;\n\tunsigned int nr_bytes;\n\tunsigned int nr_pages;\n\tunsigned long flags;\n\n\t/*\n\t * At this point all allocated objects are freed, and\n\t * objcg->nr_charged_bytes can't have an arbitrary byte value.\n\t * However, it can be PAGE_SIZE or (x * PAGE_SIZE).\n\t *\n\t * The following sequence can lead to it:\n\t * 1) CPU0: objcg == stock->cached_objcg\n\t * 2) CPU1: we do a small allocation (e.g. 92 bytes),\n\t *          PAGE_SIZE bytes are charged\n\t * 3) CPU1: a process from another memcg is allocating something,\n\t *          the stock if flushed,\n\t *          objcg->nr_charged_bytes = PAGE_SIZE - 92\n\t * 5) CPU0: we do release this object,\n\t *          92 bytes are added to stock->nr_bytes\n\t * 6) CPU0: stock is flushed,\n\t *          92 bytes are added to objcg->nr_charged_bytes\n\t *\n\t * In the result, nr_charged_bytes == PAGE_SIZE.\n\t * This page will be uncharged in obj_cgroup_release().\n\t */\n\tnr_bytes = atomic_read(&objcg->nr_charged_bytes);\n\tWARN_ON_ONCE(nr_bytes & (PAGE_SIZE - 1));\n\tnr_pages = nr_bytes >> PAGE_SHIFT;\n\n\tspin_lock_irqsave(&css_set_lock, flags);\n\tmemcg = obj_cgroup_memcg(objcg);\n\tif (nr_pages)\n\t\t__memcg_kmem_uncharge(memcg, nr_pages);\n\tlist_del(&objcg->list);\n\tmem_cgroup_put(memcg);\n\tspin_unlock_irqrestore(&css_set_lock, flags);\n\n\tpercpu_ref_exit(ref);\n\tkfree_rcu(objcg, rcu);\n}\n\nstatic struct obj_cgroup *obj_cgroup_alloc(void)\n{\n\tstruct obj_cgroup *objcg;\n\tint ret;\n\n\tobjcg = kzalloc(sizeof(struct obj_cgroup), GFP_KERNEL);\n\tif (!objcg)\n\t\treturn NULL;\n\n\tret = percpu_ref_init(&objcg->refcnt, obj_cgroup_release, 0,\n\t\t\t      GFP_KERNEL);\n\tif (ret) {\n\t\tkfree(objcg);\n\t\treturn NULL;\n\t}\n\tINIT_LIST_HEAD(&objcg->list);\n\treturn objcg;\n}\n\nstatic void memcg_reparent_objcgs(struct mem_cgroup *memcg,\n\t\t\t\t  struct mem_cgroup *parent)\n{\n\tstruct obj_cgroup *objcg, *iter;\n\n\tobjcg = rcu_replace_pointer(memcg->objcg, NULL, true);\n\n\tspin_lock_irq(&css_set_lock);\n\n\t/* Move active objcg to the parent's list */\n\txchg(&objcg->memcg, parent);\n\tcss_get(&parent->css);\n\tlist_add(&objcg->list, &parent->objcg_list);\n\n\t/* Move already reparented objcgs to the parent's list */\n\tlist_for_each_entry(iter, &memcg->objcg_list, list) {\n\t\tcss_get(&parent->css);\n\t\txchg(&iter->memcg, parent);\n\t\tcss_put(&memcg->css);\n\t}\n\tlist_splice(&memcg->objcg_list, &parent->objcg_list);\n\n\tspin_unlock_irq(&css_set_lock);\n\n\tpercpu_ref_kill(&objcg->refcnt);\n}\n\n/*\n * This will be used as a shrinker list's index.\n * The main reason for not using cgroup id for this:\n *  this works better in sparse environments, where we have a lot of memcgs,\n *  but only a few kmem-limited. Or also, if we have, for instance, 200\n *  memcgs, and none but the 200th is kmem-limited, we'd have to have a\n *  200 entry array for that.\n *\n * The current size of the caches array is stored in memcg_nr_cache_ids. It\n * will double each time we have to increase it.\n */\nstatic DEFINE_IDA(memcg_cache_ida);\nint memcg_nr_cache_ids;\n\n/* Protects memcg_nr_cache_ids */\nstatic DECLARE_RWSEM(memcg_cache_ids_sem);\n\nvoid memcg_get_cache_ids(void)\n{\n\tdown_read(&memcg_cache_ids_sem);\n}\n\nvoid memcg_put_cache_ids(void)\n{\n\tup_read(&memcg_cache_ids_sem);\n}\n\n/*\n * MIN_SIZE is different than 1, because we would like to avoid going through\n * the alloc/free process all the time. In a small machine, 4 kmem-limited\n * cgroups is a reasonable guess. In the future, it could be a parameter or\n * tunable, but that is strictly not necessary.\n *\n * MAX_SIZE should be as large as the number of cgrp_ids. Ideally, we could get\n * this constant directly from cgroup, but it is understandable that this is\n * better kept as an internal representation in cgroup.c. In any case, the\n * cgrp_id space is not getting any smaller, and we don't have to necessarily\n * increase ours as well if it increases.\n */\n#define MEMCG_CACHES_MIN_SIZE 4\n#define MEMCG_CACHES_MAX_SIZE MEM_CGROUP_ID_MAX\n\n/*\n * A lot of the calls to the cache allocation functions are expected to be\n * inlined by the compiler. Since the calls to memcg_slab_pre_alloc_hook() are\n * conditional to this static branch, we'll have to allow modules that does\n * kmem_cache_alloc and the such to see this symbol as well\n */\nDEFINE_STATIC_KEY_FALSE(memcg_kmem_enabled_key);\nEXPORT_SYMBOL(memcg_kmem_enabled_key);\n#endif\n\nstatic int memcg_shrinker_map_size;\nstatic DEFINE_MUTEX(memcg_shrinker_map_mutex);\n\nstatic void memcg_free_shrinker_map_rcu(struct rcu_head *head)\n{\n\tkvfree(container_of(head, struct memcg_shrinker_map, rcu));\n}\n\nstatic int memcg_expand_one_shrinker_map(struct mem_cgroup *memcg,\n\t\t\t\t\t int size, int old_size)\n{\n\tstruct memcg_shrinker_map *new, *old;\n\tint nid;\n\n\tlockdep_assert_held(&memcg_shrinker_map_mutex);\n\n\tfor_each_node(nid) {\n\t\told = rcu_dereference_protected(\n\t\t\tmem_cgroup_nodeinfo(memcg, nid)->shrinker_map, true);\n\t\t/* Not yet online memcg */\n\t\tif (!old)\n\t\t\treturn 0;\n\n\t\tnew = kvmalloc_node(sizeof(*new) + size, GFP_KERNEL, nid);\n\t\tif (!new)\n\t\t\treturn -ENOMEM;\n\n\t\t/* Set all old bits, clear all new bits */\n\t\tmemset(new->map, (int)0xff, old_size);\n\t\tmemset((void *)new->map + old_size, 0, size - old_size);\n\n\t\trcu_assign_pointer(memcg->nodeinfo[nid]->shrinker_map, new);\n\t\tcall_rcu(&old->rcu, memcg_free_shrinker_map_rcu);\n\t}\n\n\treturn 0;\n}\n\nstatic void memcg_free_shrinker_maps(struct mem_cgroup *memcg)\n{\n\tstruct mem_cgroup_per_node *pn;\n\tstruct memcg_shrinker_map *map;\n\tint nid;\n\n\tif (mem_cgroup_is_root(memcg))\n\t\treturn;\n\n\tfor_each_node(nid) {\n\t\tpn = mem_cgroup_nodeinfo(memcg, nid);\n\t\tmap = rcu_dereference_protected(pn->shrinker_map, true);\n\t\tif (map)\n\t\t\tkvfree(map);\n\t\trcu_assign_pointer(pn->shrinker_map, NULL);\n\t}\n}\n\nstatic int memcg_alloc_shrinker_maps(struct mem_cgroup *memcg)\n{\n\tstruct memcg_shrinker_map *map;\n\tint nid, size, ret = 0;\n\n\tif (mem_cgroup_is_root(memcg))\n\t\treturn 0;\n\n\tmutex_lock(&memcg_shrinker_map_mutex);\n\tsize = memcg_shrinker_map_size;\n\tfor_each_node(nid) {\n\t\tmap = kvzalloc_node(sizeof(*map) + size, GFP_KERNEL, nid);\n\t\tif (!map) {\n\t\t\tmemcg_free_shrinker_maps(memcg);\n\t\t\tret = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\t\trcu_assign_pointer(memcg->nodeinfo[nid]->shrinker_map, map);\n\t}\n\tmutex_unlock(&memcg_shrinker_map_mutex);\n\n\treturn ret;\n}\n\nint memcg_expand_shrinker_maps(int new_id)\n{\n\tint size, old_size, ret = 0;\n\tstruct mem_cgroup *memcg;\n\n\tsize = DIV_ROUND_UP(new_id + 1, BITS_PER_LONG) * sizeof(unsigned long);\n\told_size = memcg_shrinker_map_size;\n\tif (size <= old_size)\n\t\treturn 0;\n\n\tmutex_lock(&memcg_shrinker_map_mutex);\n\tif (!root_mem_cgroup)\n\t\tgoto unlock;\n\n\tfor_each_mem_cgroup(memcg) {\n\t\tif (mem_cgroup_is_root(memcg))\n\t\t\tcontinue;\n\t\tret = memcg_expand_one_shrinker_map(memcg, size, old_size);\n\t\tif (ret) {\n\t\t\tmem_cgroup_iter_break(NULL, memcg);\n\t\t\tgoto unlock;\n\t\t}\n\t}\nunlock:\n\tif (!ret)\n\t\tmemcg_shrinker_map_size = size;\n\tmutex_unlock(&memcg_shrinker_map_mutex);\n\treturn ret;\n}\n\nvoid memcg_set_shrinker_bit(struct mem_cgroup *memcg, int nid, int shrinker_id)\n{\n\tif (shrinker_id >= 0 && memcg && !mem_cgroup_is_root(memcg)) {\n\t\tstruct memcg_shrinker_map *map;\n\n\t\trcu_read_lock();\n\t\tmap = rcu_dereference(memcg->nodeinfo[nid]->shrinker_map);\n\t\t/* Pairs with smp mb in shrink_slab() */\n\t\tsmp_mb__before_atomic();\n\t\tset_bit(shrinker_id, map->map);\n\t\trcu_read_unlock();\n\t}\n}\n\n/**\n * mem_cgroup_css_from_page - css of the memcg associated with a page\n * @page: page of interest\n *\n * If memcg is bound to the default hierarchy, css of the memcg associated\n * with @page is returned.  The returned css remains associated with @page\n * until it is released.\n *\n * If memcg is bound to a traditional hierarchy, the css of root_mem_cgroup\n * is returned.\n */\nstruct cgroup_subsys_state *mem_cgroup_css_from_page(struct page *page)\n{\n\tstruct mem_cgroup *memcg;\n\n\tmemcg = page->mem_cgroup;\n\n\tif (!memcg || !cgroup_subsys_on_dfl(memory_cgrp_subsys))\n\t\tmemcg = root_mem_cgroup;\n\n\treturn &memcg->css;\n}\n\n/**\n * page_cgroup_ino - return inode number of the memcg a page is charged to\n * @page: the page\n *\n * Look up the closest online ancestor of the memory cgroup @page is charged to\n * and return its inode number or 0 if @page is not charged to any cgroup. It\n * is safe to call this function without holding a reference to @page.\n *\n * Note, this function is inherently racy, because there is nothing to prevent\n * the cgroup inode from getting torn down and potentially reallocated a moment\n * after page_cgroup_ino() returns, so it only should be used by callers that\n * do not care (such as procfs interfaces).\n */\nino_t page_cgroup_ino(struct page *page)\n{\n\tstruct mem_cgroup *memcg;\n\tunsigned long ino = 0;\n\n\trcu_read_lock();\n\tmemcg = page->mem_cgroup;\n\n\t/*\n\t * The lowest bit set means that memcg isn't a valid\n\t * memcg pointer, but a obj_cgroups pointer.\n\t * In this case the page is shared and doesn't belong\n\t * to any specific memory cgroup.\n\t */\n\tif ((unsigned long) memcg & 0x1UL)\n\t\tmemcg = NULL;\n\n\twhile (memcg && !(memcg->css.flags & CSS_ONLINE))\n\t\tmemcg = parent_mem_cgroup(memcg);\n\tif (memcg)\n\t\tino = cgroup_ino(memcg->css.cgroup);\n\trcu_read_unlock();\n\treturn ino;\n}\n\nstatic struct mem_cgroup_per_node *\nmem_cgroup_page_nodeinfo(struct mem_cgroup *memcg, struct page *page)\n{\n\tint nid = page_to_nid(page);\n\n\treturn memcg->nodeinfo[nid];\n}\n\nstatic struct mem_cgroup_tree_per_node *\nsoft_limit_tree_node(int nid)\n{\n\treturn soft_limit_tree.rb_tree_per_node[nid];\n}\n\nstatic struct mem_cgroup_tree_per_node *\nsoft_limit_tree_from_page(struct page *page)\n{\n\tint nid = page_to_nid(page);\n\n\treturn soft_limit_tree.rb_tree_per_node[nid];\n}\n\nstatic void __mem_cgroup_insert_exceeded(struct mem_cgroup_per_node *mz,\n\t\t\t\t\t struct mem_cgroup_tree_per_node *mctz,\n\t\t\t\t\t unsigned long new_usage_in_excess)\n{\n\tstruct rb_node **p = &mctz->rb_root.rb_node;\n\tstruct rb_node *parent = NULL;\n\tstruct mem_cgroup_per_node *mz_node;\n\tbool rightmost = true;\n\n\tif (mz->on_tree)\n\t\treturn;\n\n\tmz->usage_in_excess = new_usage_in_excess;\n\tif (!mz->usage_in_excess)\n\t\treturn;\n\twhile (*p) {\n\t\tparent = *p;\n\t\tmz_node = rb_entry(parent, struct mem_cgroup_per_node,\n\t\t\t\t\ttree_node);\n\t\tif (mz->usage_in_excess < mz_node->usage_in_excess) {\n\t\t\tp = &(*p)->rb_left;\n\t\t\trightmost = false;\n\t\t} else {\n\t\t\tp = &(*p)->rb_right;\n\t\t}\n\t}\n\n\tif (rightmost)\n\t\tmctz->rb_rightmost = &mz->tree_node;\n\n\trb_link_node(&mz->tree_node, parent, p);\n\trb_insert_color(&mz->tree_node, &mctz->rb_root);\n\tmz->on_tree = true;\n}\n\nstatic void __mem_cgroup_remove_exceeded(struct mem_cgroup_per_node *mz,\n\t\t\t\t\t struct mem_cgroup_tree_per_node *mctz)\n{\n\tif (!mz->on_tree)\n\t\treturn;\n\n\tif (&mz->tree_node == mctz->rb_rightmost)\n\t\tmctz->rb_rightmost = rb_prev(&mz->tree_node);\n\n\trb_erase(&mz->tree_node, &mctz->rb_root);\n\tmz->on_tree = false;\n}\n\nstatic void mem_cgroup_remove_exceeded(struct mem_cgroup_per_node *mz,\n\t\t\t\t       struct mem_cgroup_tree_per_node *mctz)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&mctz->lock, flags);\n\t__mem_cgroup_remove_exceeded(mz, mctz);\n\tspin_unlock_irqrestore(&mctz->lock, flags);\n}\n\nstatic unsigned long soft_limit_excess(struct mem_cgroup *memcg)\n{\n\tunsigned long nr_pages = page_counter_read(&memcg->memory);\n\tunsigned long soft_limit = READ_ONCE(memcg->soft_limit);\n\tunsigned long excess = 0;\n\n\tif (nr_pages > soft_limit)\n\t\texcess = nr_pages - soft_limit;\n\n\treturn excess;\n}\n\nstatic void mem_cgroup_update_tree(struct mem_cgroup *memcg, struct page *page)\n{\n\tunsigned long excess;\n\tstruct mem_cgroup_per_node *mz;\n\tstruct mem_cgroup_tree_per_node *mctz;\n\n\tmctz = soft_limit_tree_from_page(page);\n\tif (!mctz)\n\t\treturn;\n\t/*\n\t * Necessary to update all ancestors when hierarchy is used.\n\t * because their event counter is not touched.\n\t */\n\tfor (; memcg; memcg = parent_mem_cgroup(memcg)) {\n\t\tmz = mem_cgroup_page_nodeinfo(memcg, page);\n\t\texcess = soft_limit_excess(memcg);\n\t\t/*\n\t\t * We have to update the tree if mz is on RB-tree or\n\t\t * mem is over its softlimit.\n\t\t */\n\t\tif (excess || mz->on_tree) {\n\t\t\tunsigned long flags;\n\n\t\t\tspin_lock_irqsave(&mctz->lock, flags);\n\t\t\t/* if on-tree, remove it */\n\t\t\tif (mz->on_tree)\n\t\t\t\t__mem_cgroup_remove_exceeded(mz, mctz);\n\t\t\t/*\n\t\t\t * Insert again. mz->usage_in_excess will be updated.\n\t\t\t * If excess is 0, no tree ops.\n\t\t\t */\n\t\t\t__mem_cgroup_insert_exceeded(mz, mctz, excess);\n\t\t\tspin_unlock_irqrestore(&mctz->lock, flags);\n\t\t}\n\t}\n}\n\nstatic void mem_cgroup_remove_from_trees(struct mem_cgroup *memcg)\n{\n\tstruct mem_cgroup_tree_per_node *mctz;\n\tstruct mem_cgroup_per_node *mz;\n\tint nid;\n\n\tfor_each_node(nid) {\n\t\tmz = mem_cgroup_nodeinfo(memcg, nid);\n\t\tmctz = soft_limit_tree_node(nid);\n\t\tif (mctz)\n\t\t\tmem_cgroup_remove_exceeded(mz, mctz);\n\t}\n}\n\nstatic struct mem_cgroup_per_node *\n__mem_cgroup_largest_soft_limit_node(struct mem_cgroup_tree_per_node *mctz)\n{\n\tstruct mem_cgroup_per_node *mz;\n\nretry:\n\tmz = NULL;\n\tif (!mctz->rb_rightmost)\n\t\tgoto done;\t\t/* Nothing to reclaim from */\n\n\tmz = rb_entry(mctz->rb_rightmost,\n\t\t      struct mem_cgroup_per_node, tree_node);\n\t/*\n\t * Remove the node now but someone else can add it back,\n\t * we will to add it back at the end of reclaim to its correct\n\t * position in the tree.\n\t */\n\t__mem_cgroup_remove_exceeded(mz, mctz);\n\tif (!soft_limit_excess(mz->memcg) ||\n\t    !css_tryget(&mz->memcg->css))\n\t\tgoto retry;\ndone:\n\treturn mz;\n}\n\nstatic struct mem_cgroup_per_node *\nmem_cgroup_largest_soft_limit_node(struct mem_cgroup_tree_per_node *mctz)\n{\n\tstruct mem_cgroup_per_node *mz;\n\n\tspin_lock_irq(&mctz->lock);\n\tmz = __mem_cgroup_largest_soft_limit_node(mctz);\n\tspin_unlock_irq(&mctz->lock);\n\treturn mz;\n}\n\n/**\n * __mod_memcg_state - update cgroup memory statistics\n * @memcg: the memory cgroup\n * @idx: the stat item - can be enum memcg_stat_item or enum node_stat_item\n * @val: delta to add to the counter, can be negative\n */\nvoid __mod_memcg_state(struct mem_cgroup *memcg, int idx, int val)\n{\n\tlong x, threshold = MEMCG_CHARGE_BATCH;\n\n\tif (mem_cgroup_disabled())\n\t\treturn;\n\n\tif (memcg_stat_item_in_bytes(idx))\n\t\tthreshold <<= PAGE_SHIFT;\n\n\tx = val + __this_cpu_read(memcg->vmstats_percpu->stat[idx]);\n\tif (unlikely(abs(x) > threshold)) {\n\t\tstruct mem_cgroup *mi;\n\n\t\t/*\n\t\t * Batch local counters to keep them in sync with\n\t\t * the hierarchical ones.\n\t\t */\n\t\t__this_cpu_add(memcg->vmstats_local->stat[idx], x);\n\t\tfor (mi = memcg; mi; mi = parent_mem_cgroup(mi))\n\t\t\tatomic_long_add(x, &mi->vmstats[idx]);\n\t\tx = 0;\n\t}\n\t__this_cpu_write(memcg->vmstats_percpu->stat[idx], x);\n}\n\nstatic struct mem_cgroup_per_node *\nparent_nodeinfo(struct mem_cgroup_per_node *pn, int nid)\n{\n\tstruct mem_cgroup *parent;\n\n\tparent = parent_mem_cgroup(pn->memcg);\n\tif (!parent)\n\t\treturn NULL;\n\treturn mem_cgroup_nodeinfo(parent, nid);\n}\n\nvoid __mod_memcg_lruvec_state(struct lruvec *lruvec, enum node_stat_item idx,\n\t\t\t      int val)\n{\n\tstruct mem_cgroup_per_node *pn;\n\tstruct mem_cgroup *memcg;\n\tlong x, threshold = MEMCG_CHARGE_BATCH;\n\n\tpn = container_of(lruvec, struct mem_cgroup_per_node, lruvec);\n\tmemcg = pn->memcg;\n\n\t/* Update memcg */\n\t__mod_memcg_state(memcg, idx, val);\n\n\t/* Update lruvec */\n\t__this_cpu_add(pn->lruvec_stat_local->count[idx], val);\n\n\tif (vmstat_item_in_bytes(idx))\n\t\tthreshold <<= PAGE_SHIFT;\n\n\tx = val + __this_cpu_read(pn->lruvec_stat_cpu->count[idx]);\n\tif (unlikely(abs(x) > threshold)) {\n\t\tpg_data_t *pgdat = lruvec_pgdat(lruvec);\n\t\tstruct mem_cgroup_per_node *pi;\n\n\t\tfor (pi = pn; pi; pi = parent_nodeinfo(pi, pgdat->node_id))\n\t\t\tatomic_long_add(x, &pi->lruvec_stat[idx]);\n\t\tx = 0;\n\t}\n\t__this_cpu_write(pn->lruvec_stat_cpu->count[idx], x);\n}\n\n/**\n * __mod_lruvec_state - update lruvec memory statistics\n * @lruvec: the lruvec\n * @idx: the stat item\n * @val: delta to add to the counter, can be negative\n *\n * The lruvec is the intersection of the NUMA node and a cgroup. This\n * function updates the all three counters that are affected by a\n * change of state at this level: per-node, per-cgroup, per-lruvec.\n */\nvoid __mod_lruvec_state(struct lruvec *lruvec, enum node_stat_item idx,\n\t\t\tint val)\n{\n\t/* Update node */\n\t__mod_node_page_state(lruvec_pgdat(lruvec), idx, val);\n\n\t/* Update memcg and lruvec */\n\tif (!mem_cgroup_disabled())\n\t\t__mod_memcg_lruvec_state(lruvec, idx, val);\n}\n\nvoid __mod_lruvec_slab_state(void *p, enum node_stat_item idx, int val)\n{\n\tpg_data_t *pgdat = page_pgdat(virt_to_page(p));\n\tstruct mem_cgroup *memcg;\n\tstruct lruvec *lruvec;\n\n\trcu_read_lock();\n\tmemcg = mem_cgroup_from_obj(p);\n\n\t/* Untracked pages have no memcg, no lruvec. Update only the node */\n\tif (!memcg || memcg == root_mem_cgroup) {\n\t\t__mod_node_page_state(pgdat, idx, val);\n\t} else {\n\t\tlruvec = mem_cgroup_lruvec(memcg, pgdat);\n\t\t__mod_lruvec_state(lruvec, idx, val);\n\t}\n\trcu_read_unlock();\n}\n\n/**\n * __count_memcg_events - account VM events in a cgroup\n * @memcg: the memory cgroup\n * @idx: the event item\n * @count: the number of events that occured\n */\nvoid __count_memcg_events(struct mem_cgroup *memcg, enum vm_event_item idx,\n\t\t\t  unsigned long count)\n{\n\tunsigned long x;\n\n\tif (mem_cgroup_disabled())\n\t\treturn;\n\n\tx = count + __this_cpu_read(memcg->vmstats_percpu->events[idx]);\n\tif (unlikely(x > MEMCG_CHARGE_BATCH)) {\n\t\tstruct mem_cgroup *mi;\n\n\t\t/*\n\t\t * Batch local counters to keep them in sync with\n\t\t * the hierarchical ones.\n\t\t */\n\t\t__this_cpu_add(memcg->vmstats_local->events[idx], x);\n\t\tfor (mi = memcg; mi; mi = parent_mem_cgroup(mi))\n\t\t\tatomic_long_add(x, &mi->vmevents[idx]);\n\t\tx = 0;\n\t}\n\t__this_cpu_write(memcg->vmstats_percpu->events[idx], x);\n}\n\nstatic unsigned long memcg_events(struct mem_cgroup *memcg, int event)\n{\n\treturn atomic_long_read(&memcg->vmevents[event]);\n}\n\nstatic unsigned long memcg_events_local(struct mem_cgroup *memcg, int event)\n{\n\tlong x = 0;\n\tint cpu;\n\n\tfor_each_possible_cpu(cpu)\n\t\tx += per_cpu(memcg->vmstats_local->events[event], cpu);\n\treturn x;\n}\n\nstatic void mem_cgroup_charge_statistics(struct mem_cgroup *memcg,\n\t\t\t\t\t struct page *page,\n\t\t\t\t\t int nr_pages)\n{\n\t/* pagein of a big page is an event. So, ignore page size */\n\tif (nr_pages > 0)\n\t\t__count_memcg_events(memcg, PGPGIN, 1);\n\telse {\n\t\t__count_memcg_events(memcg, PGPGOUT, 1);\n\t\tnr_pages = -nr_pages; /* for event */\n\t}\n\n\t__this_cpu_add(memcg->vmstats_percpu->nr_page_events, nr_pages);\n}\n\nstatic bool mem_cgroup_event_ratelimit(struct mem_cgroup *memcg,\n\t\t\t\t       enum mem_cgroup_events_target target)\n{\n\tunsigned long val, next;\n\n\tval = __this_cpu_read(memcg->vmstats_percpu->nr_page_events);\n\tnext = __this_cpu_read(memcg->vmstats_percpu->targets[target]);\n\t/* from time_after() in jiffies.h */\n\tif ((long)(next - val) < 0) {\n\t\tswitch (target) {\n\t\tcase MEM_CGROUP_TARGET_THRESH:\n\t\t\tnext = val + THRESHOLDS_EVENTS_TARGET;\n\t\t\tbreak;\n\t\tcase MEM_CGROUP_TARGET_SOFTLIMIT:\n\t\t\tnext = val + SOFTLIMIT_EVENTS_TARGET;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t\t__this_cpu_write(memcg->vmstats_percpu->targets[target], next);\n\t\treturn true;\n\t}\n\treturn false;\n}\n\n/*\n * Check events in order.\n *\n */\nstatic void memcg_check_events(struct mem_cgroup *memcg, struct page *page)\n{\n\t/* threshold event is triggered in finer grain than soft limit */\n\tif (unlikely(mem_cgroup_event_ratelimit(memcg,\n\t\t\t\t\t\tMEM_CGROUP_TARGET_THRESH))) {\n\t\tbool do_softlimit;\n\n\t\tdo_softlimit = mem_cgroup_event_ratelimit(memcg,\n\t\t\t\t\t\tMEM_CGROUP_TARGET_SOFTLIMIT);\n\t\tmem_cgroup_threshold(memcg);\n\t\tif (unlikely(do_softlimit))\n\t\t\tmem_cgroup_update_tree(memcg, page);\n\t}\n}\n\nstruct mem_cgroup *mem_cgroup_from_task(struct task_struct *p)\n{\n\t/*\n\t * mm_update_next_owner() may clear mm->owner to NULL\n\t * if it races with swapoff, page migration, etc.\n\t * So this can be called with p == NULL.\n\t */\n\tif (unlikely(!p))\n\t\treturn NULL;\n\n\treturn mem_cgroup_from_css(task_css(p, memory_cgrp_id));\n}\nEXPORT_SYMBOL(mem_cgroup_from_task);\n\n/**\n * get_mem_cgroup_from_mm: Obtain a reference on given mm_struct's memcg.\n * @mm: mm from which memcg should be extracted. It can be NULL.\n *\n * Obtain a reference on mm->memcg and returns it if successful. Otherwise\n * root_mem_cgroup is returned. However if mem_cgroup is disabled, NULL is\n * returned.\n */\nstruct mem_cgroup *get_mem_cgroup_from_mm(struct mm_struct *mm)\n{\n\tstruct mem_cgroup *memcg;\n\n\tif (mem_cgroup_disabled())\n\t\treturn NULL;\n\n\trcu_read_lock();\n\tdo {\n\t\t/*\n\t\t * Page cache insertions can happen withou an\n\t\t * actual mm context, e.g. during disk probing\n\t\t * on boot, loopback IO, acct() writes etc.\n\t\t */\n\t\tif (unlikely(!mm))\n\t\t\tmemcg = root_mem_cgroup;\n\t\telse {\n\t\t\tmemcg = mem_cgroup_from_task(rcu_dereference(mm->owner));\n\t\t\tif (unlikely(!memcg))\n\t\t\t\tmemcg = root_mem_cgroup;\n\t\t}\n\t} while (!css_tryget(&memcg->css));\n\trcu_read_unlock();\n\treturn memcg;\n}\nEXPORT_SYMBOL(get_mem_cgroup_from_mm);\n\n/**\n * get_mem_cgroup_from_page: Obtain a reference on given page's memcg.\n * @page: page from which memcg should be extracted.\n *\n * Obtain a reference on page->memcg and returns it if successful. Otherwise\n * root_mem_cgroup is returned.\n */\nstruct mem_cgroup *get_mem_cgroup_from_page(struct page *page)\n{\n\tstruct mem_cgroup *memcg = page->mem_cgroup;\n\n\tif (mem_cgroup_disabled())\n\t\treturn NULL;\n\n\trcu_read_lock();\n\t/* Page should not get uncharged and freed memcg under us. */\n\tif (!memcg || WARN_ON_ONCE(!css_tryget(&memcg->css)))\n\t\tmemcg = root_mem_cgroup;\n\trcu_read_unlock();\n\treturn memcg;\n}\nEXPORT_SYMBOL(get_mem_cgroup_from_page);\n\nstatic __always_inline struct mem_cgroup *active_memcg(void)\n{\n\tif (in_interrupt())\n\t\treturn this_cpu_read(int_active_memcg);\n\telse\n\t\treturn current->active_memcg;\n}\n\nstatic __always_inline struct mem_cgroup *get_active_memcg(void)\n{\n\tstruct mem_cgroup *memcg;\n\n\trcu_read_lock();\n\tmemcg = active_memcg();\n\tif (memcg) {\n\t\t/* current->active_memcg must hold a ref. */\n\t\tif (WARN_ON_ONCE(!css_tryget(&memcg->css)))\n\t\t\tmemcg = root_mem_cgroup;\n\t\telse\n\t\t\tmemcg = current->active_memcg;\n\t}\n\trcu_read_unlock();\n\n\treturn memcg;\n}\n\nstatic __always_inline bool memcg_kmem_bypass(void)\n{\n\t/* Allow remote memcg charging from any context. */\n\tif (unlikely(active_memcg()))\n\t\treturn false;\n\n\t/* Memcg to charge can't be determined. */\n\tif (in_interrupt() || !current->mm || (current->flags & PF_KTHREAD))\n\t\treturn true;\n\n\treturn false;\n}\n\n/**\n * If active memcg is set, do not fallback to current->mm->memcg.\n */\nstatic __always_inline struct mem_cgroup *get_mem_cgroup_from_current(void)\n{\n\tif (memcg_kmem_bypass())\n\t\treturn NULL;\n\n\tif (unlikely(active_memcg()))\n\t\treturn get_active_memcg();\n\n\treturn get_mem_cgroup_from_mm(current->mm);\n}\n\n/**\n * mem_cgroup_iter - iterate over memory cgroup hierarchy\n * @root: hierarchy root\n * @prev: previously returned memcg, NULL on first invocation\n * @reclaim: cookie for shared reclaim walks, NULL for full walks\n *\n * Returns references to children of the hierarchy below @root, or\n * @root itself, or %NULL after a full round-trip.\n *\n * Caller must pass the return value in @prev on subsequent\n * invocations for reference counting, or use mem_cgroup_iter_break()\n * to cancel a hierarchy walk before the round-trip is complete.\n *\n * Reclaimers can specify a node in @reclaim to divide up the memcgs\n * in the hierarchy among all concurrent reclaimers operating on the\n * same node.\n */\nstruct mem_cgroup *mem_cgroup_iter(struct mem_cgroup *root,\n\t\t\t\t   struct mem_cgroup *prev,\n\t\t\t\t   struct mem_cgroup_reclaim_cookie *reclaim)\n{\n\tstruct mem_cgroup_reclaim_iter *iter;\n\tstruct cgroup_subsys_state *css = NULL;\n\tstruct mem_cgroup *memcg = NULL;\n\tstruct mem_cgroup *pos = NULL;\n\n\tif (mem_cgroup_disabled())\n\t\treturn NULL;\n\n\tif (!root)\n\t\troot = root_mem_cgroup;\n\n\tif (prev && !reclaim)\n\t\tpos = prev;\n\n\tif (!root->use_hierarchy && root != root_mem_cgroup) {\n\t\tif (prev)\n\t\t\tgoto out;\n\t\treturn root;\n\t}\n\n\trcu_read_lock();\n\n\tif (reclaim) {\n\t\tstruct mem_cgroup_per_node *mz;\n\n\t\tmz = mem_cgroup_nodeinfo(root, reclaim->pgdat->node_id);\n\t\titer = &mz->iter;\n\n\t\tif (prev && reclaim->generation != iter->generation)\n\t\t\tgoto out_unlock;\n\n\t\twhile (1) {\n\t\t\tpos = READ_ONCE(iter->position);\n\t\t\tif (!pos || css_tryget(&pos->css))\n\t\t\t\tbreak;\n\t\t\t/*\n\t\t\t * css reference reached zero, so iter->position will\n\t\t\t * be cleared by ->css_released. However, we should not\n\t\t\t * rely on this happening soon, because ->css_released\n\t\t\t * is called from a work queue, and by busy-waiting we\n\t\t\t * might block it. So we clear iter->position right\n\t\t\t * away.\n\t\t\t */\n\t\t\t(void)cmpxchg(&iter->position, pos, NULL);\n\t\t}\n\t}\n\n\tif (pos)\n\t\tcss = &pos->css;\n\n\tfor (;;) {\n\t\tcss = css_next_descendant_pre(css, &root->css);\n\t\tif (!css) {\n\t\t\t/*\n\t\t\t * Reclaimers share the hierarchy walk, and a\n\t\t\t * new one might jump in right at the end of\n\t\t\t * the hierarchy - make sure they see at least\n\t\t\t * one group and restart from the beginning.\n\t\t\t */\n\t\t\tif (!prev)\n\t\t\t\tcontinue;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Verify the css and acquire a reference.  The root\n\t\t * is provided by the caller, so we know it's alive\n\t\t * and kicking, and don't take an extra reference.\n\t\t */\n\t\tmemcg = mem_cgroup_from_css(css);\n\n\t\tif (css == &root->css)\n\t\t\tbreak;\n\n\t\tif (css_tryget(css))\n\t\t\tbreak;\n\n\t\tmemcg = NULL;\n\t}\n\n\tif (reclaim) {\n\t\t/*\n\t\t * The position could have already been updated by a competing\n\t\t * thread, so check that the value hasn't changed since we read\n\t\t * it to avoid reclaiming from the same cgroup twice.\n\t\t */\n\t\t(void)cmpxchg(&iter->position, pos, memcg);\n\n\t\tif (pos)\n\t\t\tcss_put(&pos->css);\n\n\t\tif (!memcg)\n\t\t\titer->generation++;\n\t\telse if (!prev)\n\t\t\treclaim->generation = iter->generation;\n\t}\n\nout_unlock:\n\trcu_read_unlock();\nout:\n\tif (prev && prev != root)\n\t\tcss_put(&prev->css);\n\n\treturn memcg;\n}\n\n/**\n * mem_cgroup_iter_break - abort a hierarchy walk prematurely\n * @root: hierarchy root\n * @prev: last visited hierarchy member as returned by mem_cgroup_iter()\n */\nvoid mem_cgroup_iter_break(struct mem_cgroup *root,\n\t\t\t   struct mem_cgroup *prev)\n{\n\tif (!root)\n\t\troot = root_mem_cgroup;\n\tif (prev && prev != root)\n\t\tcss_put(&prev->css);\n}\n\nstatic void __invalidate_reclaim_iterators(struct mem_cgroup *from,\n\t\t\t\t\tstruct mem_cgroup *dead_memcg)\n{\n\tstruct mem_cgroup_reclaim_iter *iter;\n\tstruct mem_cgroup_per_node *mz;\n\tint nid;\n\n\tfor_each_node(nid) {\n\t\tmz = mem_cgroup_nodeinfo(from, nid);\n\t\titer = &mz->iter;\n\t\tcmpxchg(&iter->position, dead_memcg, NULL);\n\t}\n}\n\nstatic void invalidate_reclaim_iterators(struct mem_cgroup *dead_memcg)\n{\n\tstruct mem_cgroup *memcg = dead_memcg;\n\tstruct mem_cgroup *last;\n\n\tdo {\n\t\t__invalidate_reclaim_iterators(memcg, dead_memcg);\n\t\tlast = memcg;\n\t} while ((memcg = parent_mem_cgroup(memcg)));\n\n\t/*\n\t * When cgruop1 non-hierarchy mode is used,\n\t * parent_mem_cgroup() does not walk all the way up to the\n\t * cgroup root (root_mem_cgroup). So we have to handle\n\t * dead_memcg from cgroup root separately.\n\t */\n\tif (last != root_mem_cgroup)\n\t\t__invalidate_reclaim_iterators(root_mem_cgroup,\n\t\t\t\t\t\tdead_memcg);\n}\n\n/**\n * mem_cgroup_scan_tasks - iterate over tasks of a memory cgroup hierarchy\n * @memcg: hierarchy root\n * @fn: function to call for each task\n * @arg: argument passed to @fn\n *\n * This function iterates over tasks attached to @memcg or to any of its\n * descendants and calls @fn for each task. If @fn returns a non-zero\n * value, the function breaks the iteration loop and returns the value.\n * Otherwise, it will iterate over all tasks and return 0.\n *\n * This function must not be called for the root memory cgroup.\n */\nint mem_cgroup_scan_tasks(struct mem_cgroup *memcg,\n\t\t\t  int (*fn)(struct task_struct *, void *), void *arg)\n{\n\tstruct mem_cgroup *iter;\n\tint ret = 0;\n\n\tBUG_ON(memcg == root_mem_cgroup);\n\n\tfor_each_mem_cgroup_tree(iter, memcg) {\n\t\tstruct css_task_iter it;\n\t\tstruct task_struct *task;\n\n\t\tcss_task_iter_start(&iter->css, CSS_TASK_ITER_PROCS, &it);\n\t\twhile (!ret && (task = css_task_iter_next(&it)))\n\t\t\tret = fn(task, arg);\n\t\tcss_task_iter_end(&it);\n\t\tif (ret) {\n\t\t\tmem_cgroup_iter_break(memcg, iter);\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn ret;\n}\n\n/**\n * mem_cgroup_page_lruvec - return lruvec for isolating/putting an LRU page\n * @page: the page\n * @pgdat: pgdat of the page\n *\n * This function relies on page->mem_cgroup being stable - see the\n * access rules in commit_charge().\n */\nstruct lruvec *mem_cgroup_page_lruvec(struct page *page, struct pglist_data *pgdat)\n{\n\tstruct mem_cgroup_per_node *mz;\n\tstruct mem_cgroup *memcg;\n\tstruct lruvec *lruvec;\n\n\tif (mem_cgroup_disabled()) {\n\t\tlruvec = &pgdat->__lruvec;\n\t\tgoto out;\n\t}\n\n\tmemcg = page->mem_cgroup;\n\t/*\n\t * Swapcache readahead pages are added to the LRU - and\n\t * possibly migrated - before they are charged.\n\t */\n\tif (!memcg)\n\t\tmemcg = root_mem_cgroup;\n\n\tmz = mem_cgroup_page_nodeinfo(memcg, page);\n\tlruvec = &mz->lruvec;\nout:\n\t/*\n\t * Since a node can be onlined after the mem_cgroup was created,\n\t * we have to be prepared to initialize lruvec->zone here;\n\t * and if offlined then reonlined, we need to reinitialize it.\n\t */\n\tif (unlikely(lruvec->pgdat != pgdat))\n\t\tlruvec->pgdat = pgdat;\n\treturn lruvec;\n}\n\n/**\n * mem_cgroup_update_lru_size - account for adding or removing an lru page\n * @lruvec: mem_cgroup per zone lru vector\n * @lru: index of lru list the page is sitting on\n * @zid: zone id of the accounted pages\n * @nr_pages: positive when adding or negative when removing\n *\n * This function must be called under lru_lock, just before a page is added\n * to or just after a page is removed from an lru list (that ordering being\n * so as to allow it to check that lru_size 0 is consistent with list_empty).\n */\nvoid mem_cgroup_update_lru_size(struct lruvec *lruvec, enum lru_list lru,\n\t\t\t\tint zid, int nr_pages)\n{\n\tstruct mem_cgroup_per_node *mz;\n\tunsigned long *lru_size;\n\tlong size;\n\n\tif (mem_cgroup_disabled())\n\t\treturn;\n\n\tmz = container_of(lruvec, struct mem_cgroup_per_node, lruvec);\n\tlru_size = &mz->lru_zone_size[zid][lru];\n\n\tif (nr_pages < 0)\n\t\t*lru_size += nr_pages;\n\n\tsize = *lru_size;\n\tif (WARN_ONCE(size < 0,\n\t\t\"%s(%p, %d, %d): lru_size %ld\\n\",\n\t\t__func__, lruvec, lru, nr_pages, size)) {\n\t\tVM_BUG_ON(1);\n\t\t*lru_size = 0;\n\t}\n\n\tif (nr_pages > 0)\n\t\t*lru_size += nr_pages;\n}\n\n/**\n * mem_cgroup_margin - calculate chargeable space of a memory cgroup\n * @memcg: the memory cgroup\n *\n * Returns the maximum amount of memory @mem can be charged with, in\n * pages.\n */\nstatic unsigned long mem_cgroup_margin(struct mem_cgroup *memcg)\n{\n\tunsigned long margin = 0;\n\tunsigned long count;\n\tunsigned long limit;\n\n\tcount = page_counter_read(&memcg->memory);\n\tlimit = READ_ONCE(memcg->memory.max);\n\tif (count < limit)\n\t\tmargin = limit - count;\n\n\tif (do_memsw_account()) {\n\t\tcount = page_counter_read(&memcg->memsw);\n\t\tlimit = READ_ONCE(memcg->memsw.max);\n\t\tif (count < limit)\n\t\t\tmargin = min(margin, limit - count);\n\t\telse\n\t\t\tmargin = 0;\n\t}\n\n\treturn margin;\n}\n\n/*\n * A routine for checking \"mem\" is under move_account() or not.\n *\n * Checking a cgroup is mc.from or mc.to or under hierarchy of\n * moving cgroups. This is for waiting at high-memory pressure\n * caused by \"move\".\n */\nstatic bool mem_cgroup_under_move(struct mem_cgroup *memcg)\n{\n\tstruct mem_cgroup *from;\n\tstruct mem_cgroup *to;\n\tbool ret = false;\n\t/*\n\t * Unlike task_move routines, we access mc.to, mc.from not under\n\t * mutual exclusion by cgroup_mutex. Here, we take spinlock instead.\n\t */\n\tspin_lock(&mc.lock);\n\tfrom = mc.from;\n\tto = mc.to;\n\tif (!from)\n\t\tgoto unlock;\n\n\tret = mem_cgroup_is_descendant(from, memcg) ||\n\t\tmem_cgroup_is_descendant(to, memcg);\nunlock:\n\tspin_unlock(&mc.lock);\n\treturn ret;\n}\n\nstatic bool mem_cgroup_wait_acct_move(struct mem_cgroup *memcg)\n{\n\tif (mc.moving_task && current != mc.moving_task) {\n\t\tif (mem_cgroup_under_move(memcg)) {\n\t\t\tDEFINE_WAIT(wait);\n\t\t\tprepare_to_wait(&mc.waitq, &wait, TASK_INTERRUPTIBLE);\n\t\t\t/* moving charge context might have finished. */\n\t\t\tif (mc.moving_task)\n\t\t\t\tschedule();\n\t\t\tfinish_wait(&mc.waitq, &wait);\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}\n\nstruct memory_stat {\n\tconst char *name;\n\tunsigned int ratio;\n\tunsigned int idx;\n};\n\nstatic struct memory_stat memory_stats[] = {\n\t{ \"anon\", PAGE_SIZE, NR_ANON_MAPPED },\n\t{ \"file\", PAGE_SIZE, NR_FILE_PAGES },\n\t{ \"kernel_stack\", 1024, NR_KERNEL_STACK_KB },\n\t{ \"percpu\", 1, MEMCG_PERCPU_B },\n\t{ \"sock\", PAGE_SIZE, MEMCG_SOCK },\n\t{ \"shmem\", PAGE_SIZE, NR_SHMEM },\n\t{ \"file_mapped\", PAGE_SIZE, NR_FILE_MAPPED },\n\t{ \"file_dirty\", PAGE_SIZE, NR_FILE_DIRTY },\n\t{ \"file_writeback\", PAGE_SIZE, NR_WRITEBACK },\n#ifdef CONFIG_TRANSPARENT_HUGEPAGE\n\t/*\n\t * The ratio will be initialized in memory_stats_init(). Because\n\t * on some architectures, the macro of HPAGE_PMD_SIZE is not\n\t * constant(e.g. powerpc).\n\t */\n\t{ \"anon_thp\", 0, NR_ANON_THPS },\n\t{ \"file_thp\", 0, NR_FILE_THPS },\n\t{ \"shmem_thp\", 0, NR_SHMEM_THPS },\n#endif\n\t{ \"inactive_anon\", PAGE_SIZE, NR_INACTIVE_ANON },\n\t{ \"active_anon\", PAGE_SIZE, NR_ACTIVE_ANON },\n\t{ \"inactive_file\", PAGE_SIZE, NR_INACTIVE_FILE },\n\t{ \"active_file\", PAGE_SIZE, NR_ACTIVE_FILE },\n\t{ \"unevictable\", PAGE_SIZE, NR_UNEVICTABLE },\n\n\t/*\n\t * Note: The slab_reclaimable and slab_unreclaimable must be\n\t * together and slab_reclaimable must be in front.\n\t */\n\t{ \"slab_reclaimable\", 1, NR_SLAB_RECLAIMABLE_B },\n\t{ \"slab_unreclaimable\", 1, NR_SLAB_UNRECLAIMABLE_B },\n\n\t/* The memory events */\n\t{ \"workingset_refault_anon\", 1, WORKINGSET_REFAULT_ANON },\n\t{ \"workingset_refault_file\", 1, WORKINGSET_REFAULT_FILE },\n\t{ \"workingset_activate_anon\", 1, WORKINGSET_ACTIVATE_ANON },\n\t{ \"workingset_activate_file\", 1, WORKINGSET_ACTIVATE_FILE },\n\t{ \"workingset_restore_anon\", 1, WORKINGSET_RESTORE_ANON },\n\t{ \"workingset_restore_file\", 1, WORKINGSET_RESTORE_FILE },\n\t{ \"workingset_nodereclaim\", 1, WORKINGSET_NODERECLAIM },\n};\n\nstatic int __init memory_stats_init(void)\n{\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(memory_stats); i++) {\n#ifdef CONFIG_TRANSPARENT_HUGEPAGE\n\t\tif (memory_stats[i].idx == NR_ANON_THPS ||\n\t\t    memory_stats[i].idx == NR_FILE_THPS ||\n\t\t    memory_stats[i].idx == NR_SHMEM_THPS)\n\t\t\tmemory_stats[i].ratio = HPAGE_PMD_SIZE;\n#endif\n\t\tVM_BUG_ON(!memory_stats[i].ratio);\n\t\tVM_BUG_ON(memory_stats[i].idx >= MEMCG_NR_STAT);\n\t}\n\n\treturn 0;\n}\npure_initcall(memory_stats_init);\n\nstatic char *memory_stat_format(struct mem_cgroup *memcg)\n{\n\tstruct seq_buf s;\n\tint i;\n\n\tseq_buf_init(&s, kmalloc(PAGE_SIZE, GFP_KERNEL), PAGE_SIZE);\n\tif (!s.buffer)\n\t\treturn NULL;\n\n\t/*\n\t * Provide statistics on the state of the memory subsystem as\n\t * well as cumulative event counters that show past behavior.\n\t *\n\t * This list is ordered following a combination of these gradients:\n\t * 1) generic big picture -> specifics and details\n\t * 2) reflecting userspace activity -> reflecting kernel heuristics\n\t *\n\t * Current memory state:\n\t */\n\n\tfor (i = 0; i < ARRAY_SIZE(memory_stats); i++) {\n\t\tu64 size;\n\n\t\tsize = memcg_page_state(memcg, memory_stats[i].idx);\n\t\tsize *= memory_stats[i].ratio;\n\t\tseq_buf_printf(&s, \"%s %llu\\n\", memory_stats[i].name, size);\n\n\t\tif (unlikely(memory_stats[i].idx == NR_SLAB_UNRECLAIMABLE_B)) {\n\t\t\tsize = memcg_page_state(memcg, NR_SLAB_RECLAIMABLE_B) +\n\t\t\t       memcg_page_state(memcg, NR_SLAB_UNRECLAIMABLE_B);\n\t\t\tseq_buf_printf(&s, \"slab %llu\\n\", size);\n\t\t}\n\t}\n\n\t/* Accumulated memory events */\n\n\tseq_buf_printf(&s, \"%s %lu\\n\", vm_event_name(PGFAULT),\n\t\t       memcg_events(memcg, PGFAULT));\n\tseq_buf_printf(&s, \"%s %lu\\n\", vm_event_name(PGMAJFAULT),\n\t\t       memcg_events(memcg, PGMAJFAULT));\n\tseq_buf_printf(&s, \"%s %lu\\n\",  vm_event_name(PGREFILL),\n\t\t       memcg_events(memcg, PGREFILL));\n\tseq_buf_printf(&s, \"pgscan %lu\\n\",\n\t\t       memcg_events(memcg, PGSCAN_KSWAPD) +\n\t\t       memcg_events(memcg, PGSCAN_DIRECT));\n\tseq_buf_printf(&s, \"pgsteal %lu\\n\",\n\t\t       memcg_events(memcg, PGSTEAL_KSWAPD) +\n\t\t       memcg_events(memcg, PGSTEAL_DIRECT));\n\tseq_buf_printf(&s, \"%s %lu\\n\", vm_event_name(PGACTIVATE),\n\t\t       memcg_events(memcg, PGACTIVATE));\n\tseq_buf_printf(&s, \"%s %lu\\n\", vm_event_name(PGDEACTIVATE),\n\t\t       memcg_events(memcg, PGDEACTIVATE));\n\tseq_buf_printf(&s, \"%s %lu\\n\", vm_event_name(PGLAZYFREE),\n\t\t       memcg_events(memcg, PGLAZYFREE));\n\tseq_buf_printf(&s, \"%s %lu\\n\", vm_event_name(PGLAZYFREED),\n\t\t       memcg_events(memcg, PGLAZYFREED));\n\n#ifdef CONFIG_TRANSPARENT_HUGEPAGE\n\tseq_buf_printf(&s, \"%s %lu\\n\", vm_event_name(THP_FAULT_ALLOC),\n\t\t       memcg_events(memcg, THP_FAULT_ALLOC));\n\tseq_buf_printf(&s, \"%s %lu\\n\", vm_event_name(THP_COLLAPSE_ALLOC),\n\t\t       memcg_events(memcg, THP_COLLAPSE_ALLOC));\n#endif /* CONFIG_TRANSPARENT_HUGEPAGE */\n\n\t/* The above should easily fit into one page */\n\tWARN_ON_ONCE(seq_buf_has_overflowed(&s));\n\n\treturn s.buffer;\n}\n\n#define K(x) ((x) << (PAGE_SHIFT-10))\n/**\n * mem_cgroup_print_oom_context: Print OOM information relevant to\n * memory controller.\n * @memcg: The memory cgroup that went over limit\n * @p: Task that is going to be killed\n *\n * NOTE: @memcg and @p's mem_cgroup can be different when hierarchy is\n * enabled\n */\nvoid mem_cgroup_print_oom_context(struct mem_cgroup *memcg, struct task_struct *p)\n{\n\trcu_read_lock();\n\n\tif (memcg) {\n\t\tpr_cont(\",oom_memcg=\");\n\t\tpr_cont_cgroup_path(memcg->css.cgroup);\n\t} else\n\t\tpr_cont(\",global_oom\");\n\tif (p) {\n\t\tpr_cont(\",task_memcg=\");\n\t\tpr_cont_cgroup_path(task_cgroup(p, memory_cgrp_id));\n\t}\n\trcu_read_unlock();\n}\n\n/**\n * mem_cgroup_print_oom_meminfo: Print OOM memory information relevant to\n * memory controller.\n * @memcg: The memory cgroup that went over limit\n */\nvoid mem_cgroup_print_oom_meminfo(struct mem_cgroup *memcg)\n{\n\tchar *buf;\n\n\tpr_info(\"memory: usage %llukB, limit %llukB, failcnt %lu\\n\",\n\t\tK((u64)page_counter_read(&memcg->memory)),\n\t\tK((u64)READ_ONCE(memcg->memory.max)), memcg->memory.failcnt);\n\tif (cgroup_subsys_on_dfl(memory_cgrp_subsys))\n\t\tpr_info(\"swap: usage %llukB, limit %llukB, failcnt %lu\\n\",\n\t\t\tK((u64)page_counter_read(&memcg->swap)),\n\t\t\tK((u64)READ_ONCE(memcg->swap.max)), memcg->swap.failcnt);\n\telse {\n\t\tpr_info(\"memory+swap: usage %llukB, limit %llukB, failcnt %lu\\n\",\n\t\t\tK((u64)page_counter_read(&memcg->memsw)),\n\t\t\tK((u64)memcg->memsw.max), memcg->memsw.failcnt);\n\t\tpr_info(\"kmem: usage %llukB, limit %llukB, failcnt %lu\\n\",\n\t\t\tK((u64)page_counter_read(&memcg->kmem)),\n\t\t\tK((u64)memcg->kmem.max), memcg->kmem.failcnt);\n\t}\n\n\tpr_info(\"Memory cgroup stats for \");\n\tpr_cont_cgroup_path(memcg->css.cgroup);\n\tpr_cont(\":\");\n\tbuf = memory_stat_format(memcg);\n\tif (!buf)\n\t\treturn;\n\tpr_info(\"%s\", buf);\n\tkfree(buf);\n}\n\n/*\n * Return the memory (and swap, if configured) limit for a memcg.\n */\nunsigned long mem_cgroup_get_max(struct mem_cgroup *memcg)\n{\n\tunsigned long max = READ_ONCE(memcg->memory.max);\n\n\tif (cgroup_subsys_on_dfl(memory_cgrp_subsys)) {\n\t\tif (mem_cgroup_swappiness(memcg))\n\t\t\tmax += min(READ_ONCE(memcg->swap.max),\n\t\t\t\t   (unsigned long)total_swap_pages);\n\t} else { /* v1 */\n\t\tif (mem_cgroup_swappiness(memcg)) {\n\t\t\t/* Calculate swap excess capacity from memsw limit */\n\t\t\tunsigned long swap = READ_ONCE(memcg->memsw.max) - max;\n\n\t\t\tmax += min(swap, (unsigned long)total_swap_pages);\n\t\t}\n\t}\n\treturn max;\n}\n\nunsigned long mem_cgroup_size(struct mem_cgroup *memcg)\n{\n\treturn page_counter_read(&memcg->memory);\n}\n\nstatic bool mem_cgroup_out_of_memory(struct mem_cgroup *memcg, gfp_t gfp_mask,\n\t\t\t\t     int order)\n{\n\tstruct oom_control oc = {\n\t\t.zonelist = NULL,\n\t\t.nodemask = NULL,\n\t\t.memcg = memcg,\n\t\t.gfp_mask = gfp_mask,\n\t\t.order = order,\n\t};\n\tbool ret = true;\n\n\tif (mutex_lock_killable(&oom_lock))\n\t\treturn true;\n\n\tif (mem_cgroup_margin(memcg) >= (1 << order))\n\t\tgoto unlock;\n\n\t/*\n\t * A few threads which were not waiting at mutex_lock_killable() can\n\t * fail to bail out. Therefore, check again after holding oom_lock.\n\t */\n\tret = should_force_charge() || out_of_memory(&oc);\n\nunlock:\n\tmutex_unlock(&oom_lock);\n\treturn ret;\n}\n\nstatic int mem_cgroup_soft_reclaim(struct mem_cgroup *root_memcg,\n\t\t\t\t   pg_data_t *pgdat,\n\t\t\t\t   gfp_t gfp_mask,\n\t\t\t\t   unsigned long *total_scanned)\n{\n\tstruct mem_cgroup *victim = NULL;\n\tint total = 0;\n\tint loop = 0;\n\tunsigned long excess;\n\tunsigned long nr_scanned;\n\tstruct mem_cgroup_reclaim_cookie reclaim = {\n\t\t.pgdat = pgdat,\n\t};\n\n\texcess = soft_limit_excess(root_memcg);\n\n\twhile (1) {\n\t\tvictim = mem_cgroup_iter(root_memcg, victim, &reclaim);\n\t\tif (!victim) {\n\t\t\tloop++;\n\t\t\tif (loop >= 2) {\n\t\t\t\t/*\n\t\t\t\t * If we have not been able to reclaim\n\t\t\t\t * anything, it might because there are\n\t\t\t\t * no reclaimable pages under this hierarchy\n\t\t\t\t */\n\t\t\t\tif (!total)\n\t\t\t\t\tbreak;\n\t\t\t\t/*\n\t\t\t\t * We want to do more targeted reclaim.\n\t\t\t\t * excess >> 2 is not to excessive so as to\n\t\t\t\t * reclaim too much, nor too less that we keep\n\t\t\t\t * coming back to reclaim from this cgroup\n\t\t\t\t */\n\t\t\t\tif (total >= (excess >> 2) ||\n\t\t\t\t\t(loop > MEM_CGROUP_MAX_RECLAIM_LOOPS))\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\t\ttotal += mem_cgroup_shrink_node(victim, gfp_mask, false,\n\t\t\t\t\tpgdat, &nr_scanned);\n\t\t*total_scanned += nr_scanned;\n\t\tif (!soft_limit_excess(root_memcg))\n\t\t\tbreak;\n\t}\n\tmem_cgroup_iter_break(root_memcg, victim);\n\treturn total;\n}\n\n#ifdef CONFIG_LOCKDEP\nstatic struct lockdep_map memcg_oom_lock_dep_map = {\n\t.name = \"memcg_oom_lock\",\n};\n#endif\n\nstatic DEFINE_SPINLOCK(memcg_oom_lock);\n\n/*\n * Check OOM-Killer is already running under our hierarchy.\n * If someone is running, return false.\n */\nstatic bool mem_cgroup_oom_trylock(struct mem_cgroup *memcg)\n{\n\tstruct mem_cgroup *iter, *failed = NULL;\n\n\tspin_lock(&memcg_oom_lock);\n\n\tfor_each_mem_cgroup_tree(iter, memcg) {\n\t\tif (iter->oom_lock) {\n\t\t\t/*\n\t\t\t * this subtree of our hierarchy is already locked\n\t\t\t * so we cannot give a lock.\n\t\t\t */\n\t\t\tfailed = iter;\n\t\t\tmem_cgroup_iter_break(memcg, iter);\n\t\t\tbreak;\n\t\t} else\n\t\t\titer->oom_lock = true;\n\t}\n\n\tif (failed) {\n\t\t/*\n\t\t * OK, we failed to lock the whole subtree so we have\n\t\t * to clean up what we set up to the failing subtree\n\t\t */\n\t\tfor_each_mem_cgroup_tree(iter, memcg) {\n\t\t\tif (iter == failed) {\n\t\t\t\tmem_cgroup_iter_break(memcg, iter);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\titer->oom_lock = false;\n\t\t}\n\t} else\n\t\tmutex_acquire(&memcg_oom_lock_dep_map, 0, 1, _RET_IP_);\n\n\tspin_unlock(&memcg_oom_lock);\n\n\treturn !failed;\n}\n\nstatic void mem_cgroup_oom_unlock(struct mem_cgroup *memcg)\n{\n\tstruct mem_cgroup *iter;\n\n\tspin_lock(&memcg_oom_lock);\n\tmutex_release(&memcg_oom_lock_dep_map, _RET_IP_);\n\tfor_each_mem_cgroup_tree(iter, memcg)\n\t\titer->oom_lock = false;\n\tspin_unlock(&memcg_oom_lock);\n}\n\nstatic void mem_cgroup_mark_under_oom(struct mem_cgroup *memcg)\n{\n\tstruct mem_cgroup *iter;\n\n\tspin_lock(&memcg_oom_lock);\n\tfor_each_mem_cgroup_tree(iter, memcg)\n\t\titer->under_oom++;\n\tspin_unlock(&memcg_oom_lock);\n}\n\nstatic void mem_cgroup_unmark_under_oom(struct mem_cgroup *memcg)\n{\n\tstruct mem_cgroup *iter;\n\n\t/*\n\t * Be careful about under_oom underflows becase a child memcg\n\t * could have been added after mem_cgroup_mark_under_oom.\n\t */\n\tspin_lock(&memcg_oom_lock);\n\tfor_each_mem_cgroup_tree(iter, memcg)\n\t\tif (iter->under_oom > 0)\n\t\t\titer->under_oom--;\n\tspin_unlock(&memcg_oom_lock);\n}\n\nstatic DECLARE_WAIT_QUEUE_HEAD(memcg_oom_waitq);\n\nstruct oom_wait_info {\n\tstruct mem_cgroup *memcg;\n\twait_queue_entry_t\twait;\n};\n\nstatic int memcg_oom_wake_function(wait_queue_entry_t *wait,\n\tunsigned mode, int sync, void *arg)\n{\n\tstruct mem_cgroup *wake_memcg = (struct mem_cgroup *)arg;\n\tstruct mem_cgroup *oom_wait_memcg;\n\tstruct oom_wait_info *oom_wait_info;\n\n\toom_wait_info = container_of(wait, struct oom_wait_info, wait);\n\toom_wait_memcg = oom_wait_info->memcg;\n\n\tif (!mem_cgroup_is_descendant(wake_memcg, oom_wait_memcg) &&\n\t    !mem_cgroup_is_descendant(oom_wait_memcg, wake_memcg))\n\t\treturn 0;\n\treturn autoremove_wake_function(wait, mode, sync, arg);\n}\n\nstatic void memcg_oom_recover(struct mem_cgroup *memcg)\n{\n\t/*\n\t * For the following lockless ->under_oom test, the only required\n\t * guarantee is that it must see the state asserted by an OOM when\n\t * this function is called as a result of userland actions\n\t * triggered by the notification of the OOM.  This is trivially\n\t * achieved by invoking mem_cgroup_mark_under_oom() before\n\t * triggering notification.\n\t */\n\tif (memcg && memcg->under_oom)\n\t\t__wake_up(&memcg_oom_waitq, TASK_NORMAL, 0, memcg);\n}\n\nenum oom_status {\n\tOOM_SUCCESS,\n\tOOM_FAILED,\n\tOOM_ASYNC,\n\tOOM_SKIPPED\n};\n\nstatic enum oom_status mem_cgroup_oom(struct mem_cgroup *memcg, gfp_t mask, int order)\n{\n\tenum oom_status ret;\n\tbool locked;\n\n\tif (order > PAGE_ALLOC_COSTLY_ORDER)\n\t\treturn OOM_SKIPPED;\n\n\tmemcg_memory_event(memcg, MEMCG_OOM);\n\n\t/*\n\t * We are in the middle of the charge context here, so we\n\t * don't want to block when potentially sitting on a callstack\n\t * that holds all kinds of filesystem and mm locks.\n\t *\n\t * cgroup1 allows disabling the OOM killer and waiting for outside\n\t * handling until the charge can succeed; remember the context and put\n\t * the task to sleep at the end of the page fault when all locks are\n\t * released.\n\t *\n\t * On the other hand, in-kernel OOM killer allows for an async victim\n\t * memory reclaim (oom_reaper) and that means that we are not solely\n\t * relying on the oom victim to make a forward progress and we can\n\t * invoke the oom killer here.\n\t *\n\t * Please note that mem_cgroup_out_of_memory might fail to find a\n\t * victim and then we have to bail out from the charge path.\n\t */\n\tif (memcg->oom_kill_disable) {\n\t\tif (!current->in_user_fault)\n\t\t\treturn OOM_SKIPPED;\n\t\tcss_get(&memcg->css);\n\t\tcurrent->memcg_in_oom = memcg;\n\t\tcurrent->memcg_oom_gfp_mask = mask;\n\t\tcurrent->memcg_oom_order = order;\n\n\t\treturn OOM_ASYNC;\n\t}\n\n\tmem_cgroup_mark_under_oom(memcg);\n\n\tlocked = mem_cgroup_oom_trylock(memcg);\n\n\tif (locked)\n\t\tmem_cgroup_oom_notify(memcg);\n\n\tmem_cgroup_unmark_under_oom(memcg);\n\tif (mem_cgroup_out_of_memory(memcg, mask, order))\n\t\tret = OOM_SUCCESS;\n\telse\n\t\tret = OOM_FAILED;\n\n\tif (locked)\n\t\tmem_cgroup_oom_unlock(memcg);\n\n\treturn ret;\n}\n\n/**\n * mem_cgroup_oom_synchronize - complete memcg OOM handling\n * @handle: actually kill/wait or just clean up the OOM state\n *\n * This has to be called at the end of a page fault if the memcg OOM\n * handler was enabled.\n *\n * Memcg supports userspace OOM handling where failed allocations must\n * sleep on a waitqueue until the userspace task resolves the\n * situation.  Sleeping directly in the charge context with all kinds\n * of locks held is not a good idea, instead we remember an OOM state\n * in the task and mem_cgroup_oom_synchronize() has to be called at\n * the end of the page fault to complete the OOM handling.\n *\n * Returns %true if an ongoing memcg OOM situation was detected and\n * completed, %false otherwise.\n */\nbool mem_cgroup_oom_synchronize(bool handle)\n{\n\tstruct mem_cgroup *memcg = current->memcg_in_oom;\n\tstruct oom_wait_info owait;\n\tbool locked;\n\n\t/* OOM is global, do not handle */\n\tif (!memcg)\n\t\treturn false;\n\n\tif (!handle)\n\t\tgoto cleanup;\n\n\towait.memcg = memcg;\n\towait.wait.flags = 0;\n\towait.wait.func = memcg_oom_wake_function;\n\towait.wait.private = current;\n\tINIT_LIST_HEAD(&owait.wait.entry);\n\n\tprepare_to_wait(&memcg_oom_waitq, &owait.wait, TASK_KILLABLE);\n\tmem_cgroup_mark_under_oom(memcg);\n\n\tlocked = mem_cgroup_oom_trylock(memcg);\n\n\tif (locked)\n\t\tmem_cgroup_oom_notify(memcg);\n\n\tif (locked && !memcg->oom_kill_disable) {\n\t\tmem_cgroup_unmark_under_oom(memcg);\n\t\tfinish_wait(&memcg_oom_waitq, &owait.wait);\n\t\tmem_cgroup_out_of_memory(memcg, current->memcg_oom_gfp_mask,\n\t\t\t\t\t current->memcg_oom_order);\n\t} else {\n\t\tschedule();\n\t\tmem_cgroup_unmark_under_oom(memcg);\n\t\tfinish_wait(&memcg_oom_waitq, &owait.wait);\n\t}\n\n\tif (locked) {\n\t\tmem_cgroup_oom_unlock(memcg);\n\t\t/*\n\t\t * There is no guarantee that an OOM-lock contender\n\t\t * sees the wakeups triggered by the OOM kill\n\t\t * uncharges.  Wake any sleepers explicitely.\n\t\t */\n\t\tmemcg_oom_recover(memcg);\n\t}\ncleanup:\n\tcurrent->memcg_in_oom = NULL;\n\tcss_put(&memcg->css);\n\treturn true;\n}\n\n/**\n * mem_cgroup_get_oom_group - get a memory cgroup to clean up after OOM\n * @victim: task to be killed by the OOM killer\n * @oom_domain: memcg in case of memcg OOM, NULL in case of system-wide OOM\n *\n * Returns a pointer to a memory cgroup, which has to be cleaned up\n * by killing all belonging OOM-killable tasks.\n *\n * Caller has to call mem_cgroup_put() on the returned non-NULL memcg.\n */\nstruct mem_cgroup *mem_cgroup_get_oom_group(struct task_struct *victim,\n\t\t\t\t\t    struct mem_cgroup *oom_domain)\n{\n\tstruct mem_cgroup *oom_group = NULL;\n\tstruct mem_cgroup *memcg;\n\n\tif (!cgroup_subsys_on_dfl(memory_cgrp_subsys))\n\t\treturn NULL;\n\n\tif (!oom_domain)\n\t\toom_domain = root_mem_cgroup;\n\n\trcu_read_lock();\n\n\tmemcg = mem_cgroup_from_task(victim);\n\tif (memcg == root_mem_cgroup)\n\t\tgoto out;\n\n\t/*\n\t * If the victim task has been asynchronously moved to a different\n\t * memory cgroup, we might end up killing tasks outside oom_domain.\n\t * In this case it's better to ignore memory.group.oom.\n\t */\n\tif (unlikely(!mem_cgroup_is_descendant(memcg, oom_domain)))\n\t\tgoto out;\n\n\t/*\n\t * Traverse the memory cgroup hierarchy from the victim task's\n\t * cgroup up to the OOMing cgroup (or root) to find the\n\t * highest-level memory cgroup with oom.group set.\n\t */\n\tfor (; memcg; memcg = parent_mem_cgroup(memcg)) {\n\t\tif (memcg->oom_group)\n\t\t\toom_group = memcg;\n\n\t\tif (memcg == oom_domain)\n\t\t\tbreak;\n\t}\n\n\tif (oom_group)\n\t\tcss_get(&oom_group->css);\nout:\n\trcu_read_unlock();\n\n\treturn oom_group;\n}\n\nvoid mem_cgroup_print_oom_group(struct mem_cgroup *memcg)\n{\n\tpr_info(\"Tasks in \");\n\tpr_cont_cgroup_path(memcg->css.cgroup);\n\tpr_cont(\" are going to be killed due to memory.oom.group set\\n\");\n}\n\n/**\n * lock_page_memcg - lock a page->mem_cgroup binding\n * @page: the page\n *\n * This function protects unlocked LRU pages from being moved to\n * another cgroup.\n *\n * It ensures lifetime of the returned memcg. Caller is responsible\n * for the lifetime of the page; __unlock_page_memcg() is available\n * when @page might get freed inside the locked section.\n */\nstruct mem_cgroup *lock_page_memcg(struct page *page)\n{\n\tstruct page *head = compound_head(page); /* rmap on tail pages */\n\tstruct mem_cgroup *memcg;\n\tunsigned long flags;\n\n\t/*\n\t * The RCU lock is held throughout the transaction.  The fast\n\t * path can get away without acquiring the memcg->move_lock\n\t * because page moving starts with an RCU grace period.\n\t *\n\t * The RCU lock also protects the memcg from being freed when\n\t * the page state that is going to change is the only thing\n\t * preventing the page itself from being freed. E.g. writeback\n\t * doesn't hold a page reference and relies on PG_writeback to\n\t * keep off truncation, migration and so forth.\n         */\n\trcu_read_lock();\n\n\tif (mem_cgroup_disabled())\n\t\treturn NULL;\nagain:\n\tmemcg = head->mem_cgroup;\n\tif (unlikely(!memcg))\n\t\treturn NULL;\n\n\tif (atomic_read(&memcg->moving_account) <= 0)\n\t\treturn memcg;\n\n\tspin_lock_irqsave(&memcg->move_lock, flags);\n\tif (memcg != head->mem_cgroup) {\n\t\tspin_unlock_irqrestore(&memcg->move_lock, flags);\n\t\tgoto again;\n\t}\n\n\t/*\n\t * When charge migration first begins, we can have locked and\n\t * unlocked page stat updates happening concurrently.  Track\n\t * the task who has the lock for unlock_page_memcg().\n\t */\n\tmemcg->move_lock_task = current;\n\tmemcg->move_lock_flags = flags;\n\n\treturn memcg;\n}\nEXPORT_SYMBOL(lock_page_memcg);\n\n/**\n * __unlock_page_memcg - unlock and unpin a memcg\n * @memcg: the memcg\n *\n * Unlock and unpin a memcg returned by lock_page_memcg().\n */\nvoid __unlock_page_memcg(struct mem_cgroup *memcg)\n{\n\tif (memcg && memcg->move_lock_task == current) {\n\t\tunsigned long flags = memcg->move_lock_flags;\n\n\t\tmemcg->move_lock_task = NULL;\n\t\tmemcg->move_lock_flags = 0;\n\n\t\tspin_unlock_irqrestore(&memcg->move_lock, flags);\n\t}\n\n\trcu_read_unlock();\n}\n\n/**\n * unlock_page_memcg - unlock a page->mem_cgroup binding\n * @page: the page\n */\nvoid unlock_page_memcg(struct page *page)\n{\n\tstruct page *head = compound_head(page);\n\n\t__unlock_page_memcg(head->mem_cgroup);\n}\nEXPORT_SYMBOL(unlock_page_memcg);\n\nstruct memcg_stock_pcp {\n\tstruct mem_cgroup *cached; /* this never be root cgroup */\n\tunsigned int nr_pages;\n\n#ifdef CONFIG_MEMCG_KMEM\n\tstruct obj_cgroup *cached_objcg;\n\tunsigned int nr_bytes;\n#endif\n\n\tstruct work_struct work;\n\tunsigned long flags;\n#define FLUSHING_CACHED_CHARGE\t0\n};\nstatic DEFINE_PER_CPU(struct memcg_stock_pcp, memcg_stock);\nstatic DEFINE_MUTEX(percpu_charge_mutex);\n\n#ifdef CONFIG_MEMCG_KMEM\nstatic void drain_obj_stock(struct memcg_stock_pcp *stock);\nstatic bool obj_stock_flush_required(struct memcg_stock_pcp *stock,\n\t\t\t\t     struct mem_cgroup *root_memcg);\n\n#else\nstatic inline void drain_obj_stock(struct memcg_stock_pcp *stock)\n{\n}\nstatic bool obj_stock_flush_required(struct memcg_stock_pcp *stock,\n\t\t\t\t     struct mem_cgroup *root_memcg)\n{\n\treturn false;\n}\n#endif\n\n/**\n * consume_stock: Try to consume stocked charge on this cpu.\n * @memcg: memcg to consume from.\n * @nr_pages: how many pages to charge.\n *\n * The charges will only happen if @memcg matches the current cpu's memcg\n * stock, and at least @nr_pages are available in that stock.  Failure to\n * service an allocation will refill the stock.\n *\n * returns true if successful, false otherwise.\n */\nstatic bool consume_stock(struct mem_cgroup *memcg, unsigned int nr_pages)\n{\n\tstruct memcg_stock_pcp *stock;\n\tunsigned long flags;\n\tbool ret = false;\n\n\tif (nr_pages > MEMCG_CHARGE_BATCH)\n\t\treturn ret;\n\n\tlocal_irq_save(flags);\n\n\tstock = this_cpu_ptr(&memcg_stock);\n\tif (memcg == stock->cached && stock->nr_pages >= nr_pages) {\n\t\tstock->nr_pages -= nr_pages;\n\t\tret = true;\n\t}\n\n\tlocal_irq_restore(flags);\n\n\treturn ret;\n}\n\n/*\n * Returns stocks cached in percpu and reset cached information.\n */\nstatic void drain_stock(struct memcg_stock_pcp *stock)\n{\n\tstruct mem_cgroup *old = stock->cached;\n\n\tif (!old)\n\t\treturn;\n\n\tif (stock->nr_pages) {\n\t\tpage_counter_uncharge(&old->memory, stock->nr_pages);\n\t\tif (do_memsw_account())\n\t\t\tpage_counter_uncharge(&old->memsw, stock->nr_pages);\n\t\tstock->nr_pages = 0;\n\t}\n\n\tcss_put(&old->css);\n\tstock->cached = NULL;\n}\n\nstatic void drain_local_stock(struct work_struct *dummy)\n{\n\tstruct memcg_stock_pcp *stock;\n\tunsigned long flags;\n\n\t/*\n\t * The only protection from memory hotplug vs. drain_stock races is\n\t * that we always operate on local CPU stock here with IRQ disabled\n\t */\n\tlocal_irq_save(flags);\n\n\tstock = this_cpu_ptr(&memcg_stock);\n\tdrain_obj_stock(stock);\n\tdrain_stock(stock);\n\tclear_bit(FLUSHING_CACHED_CHARGE, &stock->flags);\n\n\tlocal_irq_restore(flags);\n}\n\n/*\n * Cache charges(val) to local per_cpu area.\n * This will be consumed by consume_stock() function, later.\n */\nstatic void refill_stock(struct mem_cgroup *memcg, unsigned int nr_pages)\n{\n\tstruct memcg_stock_pcp *stock;\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\n\tstock = this_cpu_ptr(&memcg_stock);\n\tif (stock->cached != memcg) { /* reset if necessary */\n\t\tdrain_stock(stock);\n\t\tcss_get(&memcg->css);\n\t\tstock->cached = memcg;\n\t}\n\tstock->nr_pages += nr_pages;\n\n\tif (stock->nr_pages > MEMCG_CHARGE_BATCH)\n\t\tdrain_stock(stock);\n\n\tlocal_irq_restore(flags);\n}\n\n/*\n * Drains all per-CPU charge caches for given root_memcg resp. subtree\n * of the hierarchy under it.\n */\nstatic void drain_all_stock(struct mem_cgroup *root_memcg)\n{\n\tint cpu, curcpu;\n\n\t/* If someone's already draining, avoid adding running more workers. */\n\tif (!mutex_trylock(&percpu_charge_mutex))\n\t\treturn;\n\t/*\n\t * Notify other cpus that system-wide \"drain\" is running\n\t * We do not care about races with the cpu hotplug because cpu down\n\t * as well as workers from this path always operate on the local\n\t * per-cpu data. CPU up doesn't touch memcg_stock at all.\n\t */\n\tcurcpu = get_cpu();\n\tfor_each_online_cpu(cpu) {\n\t\tstruct memcg_stock_pcp *stock = &per_cpu(memcg_stock, cpu);\n\t\tstruct mem_cgroup *memcg;\n\t\tbool flush = false;\n\n\t\trcu_read_lock();\n\t\tmemcg = stock->cached;\n\t\tif (memcg && stock->nr_pages &&\n\t\t    mem_cgroup_is_descendant(memcg, root_memcg))\n\t\t\tflush = true;\n\t\tif (obj_stock_flush_required(stock, root_memcg))\n\t\t\tflush = true;\n\t\trcu_read_unlock();\n\n\t\tif (flush &&\n\t\t    !test_and_set_bit(FLUSHING_CACHED_CHARGE, &stock->flags)) {\n\t\t\tif (cpu == curcpu)\n\t\t\t\tdrain_local_stock(&stock->work);\n\t\t\telse\n\t\t\t\tschedule_work_on(cpu, &stock->work);\n\t\t}\n\t}\n\tput_cpu();\n\tmutex_unlock(&percpu_charge_mutex);\n}\n\nstatic int memcg_hotplug_cpu_dead(unsigned int cpu)\n{\n\tstruct memcg_stock_pcp *stock;\n\tstruct mem_cgroup *memcg, *mi;\n\n\tstock = &per_cpu(memcg_stock, cpu);\n\tdrain_stock(stock);\n\n\tfor_each_mem_cgroup(memcg) {\n\t\tint i;\n\n\t\tfor (i = 0; i < MEMCG_NR_STAT; i++) {\n\t\t\tint nid;\n\t\t\tlong x;\n\n\t\t\tx = this_cpu_xchg(memcg->vmstats_percpu->stat[i], 0);\n\t\t\tif (x)\n\t\t\t\tfor (mi = memcg; mi; mi = parent_mem_cgroup(mi))\n\t\t\t\t\tatomic_long_add(x, &memcg->vmstats[i]);\n\n\t\t\tif (i >= NR_VM_NODE_STAT_ITEMS)\n\t\t\t\tcontinue;\n\n\t\t\tfor_each_node(nid) {\n\t\t\t\tstruct mem_cgroup_per_node *pn;\n\n\t\t\t\tpn = mem_cgroup_nodeinfo(memcg, nid);\n\t\t\t\tx = this_cpu_xchg(pn->lruvec_stat_cpu->count[i], 0);\n\t\t\t\tif (x)\n\t\t\t\t\tdo {\n\t\t\t\t\t\tatomic_long_add(x, &pn->lruvec_stat[i]);\n\t\t\t\t\t} while ((pn = parent_nodeinfo(pn, nid)));\n\t\t\t}\n\t\t}\n\n\t\tfor (i = 0; i < NR_VM_EVENT_ITEMS; i++) {\n\t\t\tlong x;\n\n\t\t\tx = this_cpu_xchg(memcg->vmstats_percpu->events[i], 0);\n\t\t\tif (x)\n\t\t\t\tfor (mi = memcg; mi; mi = parent_mem_cgroup(mi))\n\t\t\t\t\tatomic_long_add(x, &memcg->vmevents[i]);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic unsigned long reclaim_high(struct mem_cgroup *memcg,\n\t\t\t\t  unsigned int nr_pages,\n\t\t\t\t  gfp_t gfp_mask)\n{\n\tunsigned long nr_reclaimed = 0;\n\n\tdo {\n\t\tunsigned long pflags;\n\n\t\tif (page_counter_read(&memcg->memory) <=\n\t\t    READ_ONCE(memcg->memory.high))\n\t\t\tcontinue;\n\n\t\tmemcg_memory_event(memcg, MEMCG_HIGH);\n\n\t\tpsi_memstall_enter(&pflags);\n\t\tnr_reclaimed += try_to_free_mem_cgroup_pages(memcg, nr_pages,\n\t\t\t\t\t\t\t     gfp_mask, true);\n\t\tpsi_memstall_leave(&pflags);\n\t} while ((memcg = parent_mem_cgroup(memcg)) &&\n\t\t !mem_cgroup_is_root(memcg));\n\n\treturn nr_reclaimed;\n}\n\nstatic void high_work_func(struct work_struct *work)\n{\n\tstruct mem_cgroup *memcg;\n\n\tmemcg = container_of(work, struct mem_cgroup, high_work);\n\treclaim_high(memcg, MEMCG_CHARGE_BATCH, GFP_KERNEL);\n}\n\n/*\n * Clamp the maximum sleep time per allocation batch to 2 seconds. This is\n * enough to still cause a significant slowdown in most cases, while still\n * allowing diagnostics and tracing to proceed without becoming stuck.\n */\n#define MEMCG_MAX_HIGH_DELAY_JIFFIES (2UL*HZ)\n\n/*\n * When calculating the delay, we use these either side of the exponentiation to\n * maintain precision and scale to a reasonable number of jiffies (see the table\n * below.\n *\n * - MEMCG_DELAY_PRECISION_SHIFT: Extra precision bits while translating the\n *   overage ratio to a delay.\n * - MEMCG_DELAY_SCALING_SHIFT: The number of bits to scale down the\n *   proposed penalty in order to reduce to a reasonable number of jiffies, and\n *   to produce a reasonable delay curve.\n *\n * MEMCG_DELAY_SCALING_SHIFT just happens to be a number that produces a\n * reasonable delay curve compared to precision-adjusted overage, not\n * penalising heavily at first, but still making sure that growth beyond the\n * limit penalises misbehaviour cgroups by slowing them down exponentially. For\n * example, with a high of 100 megabytes:\n *\n *  +-------+------------------------+\n *  | usage | time to allocate in ms |\n *  +-------+------------------------+\n *  | 100M  |                      0 |\n *  | 101M  |                      6 |\n *  | 102M  |                     25 |\n *  | 103M  |                     57 |\n *  | 104M  |                    102 |\n *  | 105M  |                    159 |\n *  | 106M  |                    230 |\n *  | 107M  |                    313 |\n *  | 108M  |                    409 |\n *  | 109M  |                    518 |\n *  | 110M  |                    639 |\n *  | 111M  |                    774 |\n *  | 112M  |                    921 |\n *  | 113M  |                   1081 |\n *  | 114M  |                   1254 |\n *  | 115M  |                   1439 |\n *  | 116M  |                   1638 |\n *  | 117M  |                   1849 |\n *  | 118M  |                   2000 |\n *  | 119M  |                   2000 |\n *  | 120M  |                   2000 |\n *  +-------+------------------------+\n */\n #define MEMCG_DELAY_PRECISION_SHIFT 20\n #define MEMCG_DELAY_SCALING_SHIFT 14\n\nstatic u64 calculate_overage(unsigned long usage, unsigned long high)\n{\n\tu64 overage;\n\n\tif (usage <= high)\n\t\treturn 0;\n\n\t/*\n\t * Prevent division by 0 in overage calculation by acting as if\n\t * it was a threshold of 1 page\n\t */\n\thigh = max(high, 1UL);\n\n\toverage = usage - high;\n\toverage <<= MEMCG_DELAY_PRECISION_SHIFT;\n\treturn div64_u64(overage, high);\n}\n\nstatic u64 mem_find_max_overage(struct mem_cgroup *memcg)\n{\n\tu64 overage, max_overage = 0;\n\n\tdo {\n\t\toverage = calculate_overage(page_counter_read(&memcg->memory),\n\t\t\t\t\t    READ_ONCE(memcg->memory.high));\n\t\tmax_overage = max(overage, max_overage);\n\t} while ((memcg = parent_mem_cgroup(memcg)) &&\n\t\t !mem_cgroup_is_root(memcg));\n\n\treturn max_overage;\n}\n\nstatic u64 swap_find_max_overage(struct mem_cgroup *memcg)\n{\n\tu64 overage, max_overage = 0;\n\n\tdo {\n\t\toverage = calculate_overage(page_counter_read(&memcg->swap),\n\t\t\t\t\t    READ_ONCE(memcg->swap.high));\n\t\tif (overage)\n\t\t\tmemcg_memory_event(memcg, MEMCG_SWAP_HIGH);\n\t\tmax_overage = max(overage, max_overage);\n\t} while ((memcg = parent_mem_cgroup(memcg)) &&\n\t\t !mem_cgroup_is_root(memcg));\n\n\treturn max_overage;\n}\n\n/*\n * Get the number of jiffies that we should penalise a mischievous cgroup which\n * is exceeding its memory.high by checking both it and its ancestors.\n */\nstatic unsigned long calculate_high_delay(struct mem_cgroup *memcg,\n\t\t\t\t\t  unsigned int nr_pages,\n\t\t\t\t\t  u64 max_overage)\n{\n\tunsigned long penalty_jiffies;\n\n\tif (!max_overage)\n\t\treturn 0;\n\n\t/*\n\t * We use overage compared to memory.high to calculate the number of\n\t * jiffies to sleep (penalty_jiffies). Ideally this value should be\n\t * fairly lenient on small overages, and increasingly harsh when the\n\t * memcg in question makes it clear that it has no intention of stopping\n\t * its crazy behaviour, so we exponentially increase the delay based on\n\t * overage amount.\n\t */\n\tpenalty_jiffies = max_overage * max_overage * HZ;\n\tpenalty_jiffies >>= MEMCG_DELAY_PRECISION_SHIFT;\n\tpenalty_jiffies >>= MEMCG_DELAY_SCALING_SHIFT;\n\n\t/*\n\t * Factor in the task's own contribution to the overage, such that four\n\t * N-sized allocations are throttled approximately the same as one\n\t * 4N-sized allocation.\n\t *\n\t * MEMCG_CHARGE_BATCH pages is nominal, so work out how much smaller or\n\t * larger the current charge patch is than that.\n\t */\n\treturn penalty_jiffies * nr_pages / MEMCG_CHARGE_BATCH;\n}\n\n/*\n * Scheduled by try_charge() to be executed from the userland return path\n * and reclaims memory over the high limit.\n */\nvoid mem_cgroup_handle_over_high(void)\n{\n\tunsigned long penalty_jiffies;\n\tunsigned long pflags;\n\tunsigned long nr_reclaimed;\n\tunsigned int nr_pages = current->memcg_nr_pages_over_high;\n\tint nr_retries = MAX_RECLAIM_RETRIES;\n\tstruct mem_cgroup *memcg;\n\tbool in_retry = false;\n\n\tif (likely(!nr_pages))\n\t\treturn;\n\n\tmemcg = get_mem_cgroup_from_mm(current->mm);\n\tcurrent->memcg_nr_pages_over_high = 0;\n\nretry_reclaim:\n\t/*\n\t * The allocating task should reclaim at least the batch size, but for\n\t * subsequent retries we only want to do what's necessary to prevent oom\n\t * or breaching resource isolation.\n\t *\n\t * This is distinct from memory.max or page allocator behaviour because\n\t * memory.high is currently batched, whereas memory.max and the page\n\t * allocator run every time an allocation is made.\n\t */\n\tnr_reclaimed = reclaim_high(memcg,\n\t\t\t\t    in_retry ? SWAP_CLUSTER_MAX : nr_pages,\n\t\t\t\t    GFP_KERNEL);\n\n\t/*\n\t * memory.high is breached and reclaim is unable to keep up. Throttle\n\t * allocators proactively to slow down excessive growth.\n\t */\n\tpenalty_jiffies = calculate_high_delay(memcg, nr_pages,\n\t\t\t\t\t       mem_find_max_overage(memcg));\n\n\tpenalty_jiffies += calculate_high_delay(memcg, nr_pages,\n\t\t\t\t\t\tswap_find_max_overage(memcg));\n\n\t/*\n\t * Clamp the max delay per usermode return so as to still keep the\n\t * application moving forwards and also permit diagnostics, albeit\n\t * extremely slowly.\n\t */\n\tpenalty_jiffies = min(penalty_jiffies, MEMCG_MAX_HIGH_DELAY_JIFFIES);\n\n\t/*\n\t * Don't sleep if the amount of jiffies this memcg owes us is so low\n\t * that it's not even worth doing, in an attempt to be nice to those who\n\t * go only a small amount over their memory.high value and maybe haven't\n\t * been aggressively reclaimed enough yet.\n\t */\n\tif (penalty_jiffies <= HZ / 100)\n\t\tgoto out;\n\n\t/*\n\t * If reclaim is making forward progress but we're still over\n\t * memory.high, we want to encourage that rather than doing allocator\n\t * throttling.\n\t */\n\tif (nr_reclaimed || nr_retries--) {\n\t\tin_retry = true;\n\t\tgoto retry_reclaim;\n\t}\n\n\t/*\n\t * If we exit early, we're guaranteed to die (since\n\t * schedule_timeout_killable sets TASK_KILLABLE). This means we don't\n\t * need to account for any ill-begotten jiffies to pay them off later.\n\t */\n\tpsi_memstall_enter(&pflags);\n\tschedule_timeout_killable(penalty_jiffies);\n\tpsi_memstall_leave(&pflags);\n\nout:\n\tcss_put(&memcg->css);\n}\n\nstatic int try_charge(struct mem_cgroup *memcg, gfp_t gfp_mask,\n\t\t      unsigned int nr_pages)\n{\n\tunsigned int batch = max(MEMCG_CHARGE_BATCH, nr_pages);\n\tint nr_retries = MAX_RECLAIM_RETRIES;\n\tstruct mem_cgroup *mem_over_limit;\n\tstruct page_counter *counter;\n\tenum oom_status oom_status;\n\tunsigned long nr_reclaimed;\n\tbool may_swap = true;\n\tbool drained = false;\n\tunsigned long pflags;\n\n\tif (mem_cgroup_is_root(memcg))\n\t\treturn 0;\nretry:\n\tif (consume_stock(memcg, nr_pages))\n\t\treturn 0;\n\n\tif (!do_memsw_account() ||\n\t    page_counter_try_charge(&memcg->memsw, batch, &counter)) {\n\t\tif (page_counter_try_charge(&memcg->memory, batch, &counter))\n\t\t\tgoto done_restock;\n\t\tif (do_memsw_account())\n\t\t\tpage_counter_uncharge(&memcg->memsw, batch);\n\t\tmem_over_limit = mem_cgroup_from_counter(counter, memory);\n\t} else {\n\t\tmem_over_limit = mem_cgroup_from_counter(counter, memsw);\n\t\tmay_swap = false;\n\t}\n\n\tif (batch > nr_pages) {\n\t\tbatch = nr_pages;\n\t\tgoto retry;\n\t}\n\n\t/*\n\t * Memcg doesn't have a dedicated reserve for atomic\n\t * allocations. But like the global atomic pool, we need to\n\t * put the burden of reclaim on regular allocation requests\n\t * and let these go through as privileged allocations.\n\t */\n\tif (gfp_mask & __GFP_ATOMIC)\n\t\tgoto force;\n\n\t/*\n\t * Unlike in global OOM situations, memcg is not in a physical\n\t * memory shortage.  Allow dying and OOM-killed tasks to\n\t * bypass the last charges so that they can exit quickly and\n\t * free their memory.\n\t */\n\tif (unlikely(should_force_charge()))\n\t\tgoto force;\n\n\t/*\n\t * Prevent unbounded recursion when reclaim operations need to\n\t * allocate memory. This might exceed the limits temporarily,\n\t * but we prefer facilitating memory reclaim and getting back\n\t * under the limit over triggering OOM kills in these cases.\n\t */\n\tif (unlikely(current->flags & PF_MEMALLOC))\n\t\tgoto force;\n\n\tif (unlikely(task_in_memcg_oom(current)))\n\t\tgoto nomem;\n\n\tif (!gfpflags_allow_blocking(gfp_mask))\n\t\tgoto nomem;\n\n\tmemcg_memory_event(mem_over_limit, MEMCG_MAX);\n\n\tpsi_memstall_enter(&pflags);\n\tnr_reclaimed = try_to_free_mem_cgroup_pages(mem_over_limit, nr_pages,\n\t\t\t\t\t\t    gfp_mask, may_swap);\n\tpsi_memstall_leave(&pflags);\n\n\tif (mem_cgroup_margin(mem_over_limit) >= nr_pages)\n\t\tgoto retry;\n\n\tif (!drained) {\n\t\tdrain_all_stock(mem_over_limit);\n\t\tdrained = true;\n\t\tgoto retry;\n\t}\n\n\tif (gfp_mask & __GFP_NORETRY)\n\t\tgoto nomem;\n\t/*\n\t * Even though the limit is exceeded at this point, reclaim\n\t * may have been able to free some pages.  Retry the charge\n\t * before killing the task.\n\t *\n\t * Only for regular pages, though: huge pages are rather\n\t * unlikely to succeed so close to the limit, and we fall back\n\t * to regular pages anyway in case of failure.\n\t */\n\tif (nr_reclaimed && nr_pages <= (1 << PAGE_ALLOC_COSTLY_ORDER))\n\t\tgoto retry;\n\t/*\n\t * At task move, charge accounts can be doubly counted. So, it's\n\t * better to wait until the end of task_move if something is going on.\n\t */\n\tif (mem_cgroup_wait_acct_move(mem_over_limit))\n\t\tgoto retry;\n\n\tif (nr_retries--)\n\t\tgoto retry;\n\n\tif (gfp_mask & __GFP_RETRY_MAYFAIL)\n\t\tgoto nomem;\n\n\tif (gfp_mask & __GFP_NOFAIL)\n\t\tgoto force;\n\n\tif (fatal_signal_pending(current))\n\t\tgoto force;\n\n\t/*\n\t * keep retrying as long as the memcg oom killer is able to make\n\t * a forward progress or bypass the charge if the oom killer\n\t * couldn't make any progress.\n\t */\n\toom_status = mem_cgroup_oom(mem_over_limit, gfp_mask,\n\t\t       get_order(nr_pages * PAGE_SIZE));\n\tswitch (oom_status) {\n\tcase OOM_SUCCESS:\n\t\tnr_retries = MAX_RECLAIM_RETRIES;\n\t\tgoto retry;\n\tcase OOM_FAILED:\n\t\tgoto force;\n\tdefault:\n\t\tgoto nomem;\n\t}\nnomem:\n\tif (!(gfp_mask & __GFP_NOFAIL))\n\t\treturn -ENOMEM;\nforce:\n\t/*\n\t * The allocation either can't fail or will lead to more memory\n\t * being freed very soon.  Allow memory usage go over the limit\n\t * temporarily by force charging it.\n\t */\n\tpage_counter_charge(&memcg->memory, nr_pages);\n\tif (do_memsw_account())\n\t\tpage_counter_charge(&memcg->memsw, nr_pages);\n\n\treturn 0;\n\ndone_restock:\n\tif (batch > nr_pages)\n\t\trefill_stock(memcg, batch - nr_pages);\n\n\t/*\n\t * If the hierarchy is above the normal consumption range, schedule\n\t * reclaim on returning to userland.  We can perform reclaim here\n\t * if __GFP_RECLAIM but let's always punt for simplicity and so that\n\t * GFP_KERNEL can consistently be used during reclaim.  @memcg is\n\t * not recorded as it most likely matches current's and won't\n\t * change in the meantime.  As high limit is checked again before\n\t * reclaim, the cost of mismatch is negligible.\n\t */\n\tdo {\n\t\tbool mem_high, swap_high;\n\n\t\tmem_high = page_counter_read(&memcg->memory) >\n\t\t\tREAD_ONCE(memcg->memory.high);\n\t\tswap_high = page_counter_read(&memcg->swap) >\n\t\t\tREAD_ONCE(memcg->swap.high);\n\n\t\t/* Don't bother a random interrupted task */\n\t\tif (in_interrupt()) {\n\t\t\tif (mem_high) {\n\t\t\t\tschedule_work(&memcg->high_work);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (mem_high || swap_high) {\n\t\t\t/*\n\t\t\t * The allocating tasks in this cgroup will need to do\n\t\t\t * reclaim or be throttled to prevent further growth\n\t\t\t * of the memory or swap footprints.\n\t\t\t *\n\t\t\t * Target some best-effort fairness between the tasks,\n\t\t\t * and distribute reclaim work and delay penalties\n\t\t\t * based on how much each task is actually allocating.\n\t\t\t */\n\t\t\tcurrent->memcg_nr_pages_over_high += batch;\n\t\t\tset_notify_resume(current);\n\t\t\tbreak;\n\t\t}\n\t} while ((memcg = parent_mem_cgroup(memcg)));\n\n\treturn 0;\n}\n\n#if defined(CONFIG_MEMCG_KMEM) || defined(CONFIG_MMU)\nstatic void cancel_charge(struct mem_cgroup *memcg, unsigned int nr_pages)\n{\n\tif (mem_cgroup_is_root(memcg))\n\t\treturn;\n\n\tpage_counter_uncharge(&memcg->memory, nr_pages);\n\tif (do_memsw_account())\n\t\tpage_counter_uncharge(&memcg->memsw, nr_pages);\n}\n#endif\n\nstatic void commit_charge(struct page *page, struct mem_cgroup *memcg)\n{\n\tVM_BUG_ON_PAGE(page->mem_cgroup, page);\n\t/*\n\t * Any of the following ensures page->mem_cgroup stability:\n\t *\n\t * - the page lock\n\t * - LRU isolation\n\t * - lock_page_memcg()\n\t * - exclusive reference\n\t */\n\tpage->mem_cgroup = memcg;\n}\n\n#ifdef CONFIG_MEMCG_KMEM\nint memcg_alloc_page_obj_cgroups(struct page *page, struct kmem_cache *s,\n\t\t\t\t gfp_t gfp)\n{\n\tunsigned int objects = objs_per_slab_page(s, page);\n\tvoid *vec;\n\n\tvec = kcalloc_node(objects, sizeof(struct obj_cgroup *), gfp,\n\t\t\t   page_to_nid(page));\n\tif (!vec)\n\t\treturn -ENOMEM;\n\n\tif (cmpxchg(&page->obj_cgroups, NULL,\n\t\t    (struct obj_cgroup **) ((unsigned long)vec | 0x1UL)))\n\t\tkfree(vec);\n\telse\n\t\tkmemleak_not_leak(vec);\n\n\treturn 0;\n}\n\n/*\n * Returns a pointer to the memory cgroup to which the kernel object is charged.\n *\n * The caller must ensure the memcg lifetime, e.g. by taking rcu_read_lock(),\n * cgroup_mutex, etc.\n */\nstruct mem_cgroup *mem_cgroup_from_obj(void *p)\n{\n\tstruct page *page;\n\n\tif (mem_cgroup_disabled())\n\t\treturn NULL;\n\n\tpage = virt_to_head_page(p);\n\n\t/*\n\t * If page->mem_cgroup is set, it's either a simple mem_cgroup pointer\n\t * or a pointer to obj_cgroup vector. In the latter case the lowest\n\t * bit of the pointer is set.\n\t * The page->mem_cgroup pointer can be asynchronously changed\n\t * from NULL to (obj_cgroup_vec | 0x1UL), but can't be changed\n\t * from a valid memcg pointer to objcg vector or back.\n\t */\n\tif (!page->mem_cgroup)\n\t\treturn NULL;\n\n\t/*\n\t * Slab objects are accounted individually, not per-page.\n\t * Memcg membership data for each individual object is saved in\n\t * the page->obj_cgroups.\n\t */\n\tif (page_has_obj_cgroups(page)) {\n\t\tstruct obj_cgroup *objcg;\n\t\tunsigned int off;\n\n\t\toff = obj_to_index(page->slab_cache, page, p);\n\t\tobjcg = page_obj_cgroups(page)[off];\n\t\tif (objcg)\n\t\t\treturn obj_cgroup_memcg(objcg);\n\n\t\treturn NULL;\n\t}\n\n\t/* All other pages use page->mem_cgroup */\n\treturn page->mem_cgroup;\n}\n\n__always_inline struct obj_cgroup *get_obj_cgroup_from_current(void)\n{\n\tstruct obj_cgroup *objcg = NULL;\n\tstruct mem_cgroup *memcg;\n\n\tif (memcg_kmem_bypass())\n\t\treturn NULL;\n\n\trcu_read_lock();\n\tif (unlikely(active_memcg()))\n\t\tmemcg = active_memcg();\n\telse\n\t\tmemcg = mem_cgroup_from_task(current);\n\n\tfor (; memcg != root_mem_cgroup; memcg = parent_mem_cgroup(memcg)) {\n\t\tobjcg = rcu_dereference(memcg->objcg);\n\t\tif (objcg && obj_cgroup_tryget(objcg))\n\t\t\tbreak;\n\t}\n\trcu_read_unlock();\n\n\treturn objcg;\n}\n\nstatic int memcg_alloc_cache_id(void)\n{\n\tint id, size;\n\tint err;\n\n\tid = ida_simple_get(&memcg_cache_ida,\n\t\t\t    0, MEMCG_CACHES_MAX_SIZE, GFP_KERNEL);\n\tif (id < 0)\n\t\treturn id;\n\n\tif (id < memcg_nr_cache_ids)\n\t\treturn id;\n\n\t/*\n\t * There's no space for the new id in memcg_caches arrays,\n\t * so we have to grow them.\n\t */\n\tdown_write(&memcg_cache_ids_sem);\n\n\tsize = 2 * (id + 1);\n\tif (size < MEMCG_CACHES_MIN_SIZE)\n\t\tsize = MEMCG_CACHES_MIN_SIZE;\n\telse if (size > MEMCG_CACHES_MAX_SIZE)\n\t\tsize = MEMCG_CACHES_MAX_SIZE;\n\n\terr = memcg_update_all_list_lrus(size);\n\tif (!err)\n\t\tmemcg_nr_cache_ids = size;\n\n\tup_write(&memcg_cache_ids_sem);\n\n\tif (err) {\n\t\tida_simple_remove(&memcg_cache_ida, id);\n\t\treturn err;\n\t}\n\treturn id;\n}\n\nstatic void memcg_free_cache_id(int id)\n{\n\tida_simple_remove(&memcg_cache_ida, id);\n}\n\n/**\n * __memcg_kmem_charge: charge a number of kernel pages to a memcg\n * @memcg: memory cgroup to charge\n * @gfp: reclaim mode\n * @nr_pages: number of pages to charge\n *\n * Returns 0 on success, an error code on failure.\n */\nint __memcg_kmem_charge(struct mem_cgroup *memcg, gfp_t gfp,\n\t\t\tunsigned int nr_pages)\n{\n\tstruct page_counter *counter;\n\tint ret;\n\n\tret = try_charge(memcg, gfp, nr_pages);\n\tif (ret)\n\t\treturn ret;\n\n\tif (!cgroup_subsys_on_dfl(memory_cgrp_subsys) &&\n\t    !page_counter_try_charge(&memcg->kmem, nr_pages, &counter)) {\n\n\t\t/*\n\t\t * Enforce __GFP_NOFAIL allocation because callers are not\n\t\t * prepared to see failures and likely do not have any failure\n\t\t * handling code.\n\t\t */\n\t\tif (gfp & __GFP_NOFAIL) {\n\t\t\tpage_counter_charge(&memcg->kmem, nr_pages);\n\t\t\treturn 0;\n\t\t}\n\t\tcancel_charge(memcg, nr_pages);\n\t\treturn -ENOMEM;\n\t}\n\treturn 0;\n}\n\n/**\n * __memcg_kmem_uncharge: uncharge a number of kernel pages from a memcg\n * @memcg: memcg to uncharge\n * @nr_pages: number of pages to uncharge\n */\nvoid __memcg_kmem_uncharge(struct mem_cgroup *memcg, unsigned int nr_pages)\n{\n\tif (!cgroup_subsys_on_dfl(memory_cgrp_subsys))\n\t\tpage_counter_uncharge(&memcg->kmem, nr_pages);\n\n\tpage_counter_uncharge(&memcg->memory, nr_pages);\n\tif (do_memsw_account())\n\t\tpage_counter_uncharge(&memcg->memsw, nr_pages);\n}\n\n/**\n * __memcg_kmem_charge_page: charge a kmem page to the current memory cgroup\n * @page: page to charge\n * @gfp: reclaim mode\n * @order: allocation order\n *\n * Returns 0 on success, an error code on failure.\n */\nint __memcg_kmem_charge_page(struct page *page, gfp_t gfp, int order)\n{\n\tstruct mem_cgroup *memcg;\n\tint ret = 0;\n\n\tmemcg = get_mem_cgroup_from_current();\n\tif (memcg && !mem_cgroup_is_root(memcg)) {\n\t\tret = __memcg_kmem_charge(memcg, gfp, 1 << order);\n\t\tif (!ret) {\n\t\t\tpage->mem_cgroup = memcg;\n\t\t\t__SetPageKmemcg(page);\n\t\t\treturn 0;\n\t\t}\n\t\tcss_put(&memcg->css);\n\t}\n\treturn ret;\n}\n\n/**\n * __memcg_kmem_uncharge_page: uncharge a kmem page\n * @page: page to uncharge\n * @order: allocation order\n */\nvoid __memcg_kmem_uncharge_page(struct page *page, int order)\n{\n\tstruct mem_cgroup *memcg = page->mem_cgroup;\n\tunsigned int nr_pages = 1 << order;\n\n\tif (!memcg)\n\t\treturn;\n\n\tVM_BUG_ON_PAGE(mem_cgroup_is_root(memcg), page);\n\t__memcg_kmem_uncharge(memcg, nr_pages);\n\tpage->mem_cgroup = NULL;\n\tcss_put(&memcg->css);\n\n\t/* slab pages do not have PageKmemcg flag set */\n\tif (PageKmemcg(page))\n\t\t__ClearPageKmemcg(page);\n}\n\nstatic bool consume_obj_stock(struct obj_cgroup *objcg, unsigned int nr_bytes)\n{\n\tstruct memcg_stock_pcp *stock;\n\tunsigned long flags;\n\tbool ret = false;\n\n\tlocal_irq_save(flags);\n\n\tstock = this_cpu_ptr(&memcg_stock);\n\tif (objcg == stock->cached_objcg && stock->nr_bytes >= nr_bytes) {\n\t\tstock->nr_bytes -= nr_bytes;\n\t\tret = true;\n\t}\n\n\tlocal_irq_restore(flags);\n\n\treturn ret;\n}\n\nstatic void drain_obj_stock(struct memcg_stock_pcp *stock)\n{\n\tstruct obj_cgroup *old = stock->cached_objcg;\n\n\tif (!old)\n\t\treturn;\n\n\tif (stock->nr_bytes) {\n\t\tunsigned int nr_pages = stock->nr_bytes >> PAGE_SHIFT;\n\t\tunsigned int nr_bytes = stock->nr_bytes & (PAGE_SIZE - 1);\n\n\t\tif (nr_pages) {\n\t\t\trcu_read_lock();\n\t\t\t__memcg_kmem_uncharge(obj_cgroup_memcg(old), nr_pages);\n\t\t\trcu_read_unlock();\n\t\t}\n\n\t\t/*\n\t\t * The leftover is flushed to the centralized per-memcg value.\n\t\t * On the next attempt to refill obj stock it will be moved\n\t\t * to a per-cpu stock (probably, on an other CPU), see\n\t\t * refill_obj_stock().\n\t\t *\n\t\t * How often it's flushed is a trade-off between the memory\n\t\t * limit enforcement accuracy and potential CPU contention,\n\t\t * so it might be changed in the future.\n\t\t */\n\t\tatomic_add(nr_bytes, &old->nr_charged_bytes);\n\t\tstock->nr_bytes = 0;\n\t}\n\n\tobj_cgroup_put(old);\n\tstock->cached_objcg = NULL;\n}\n\nstatic bool obj_stock_flush_required(struct memcg_stock_pcp *stock,\n\t\t\t\t     struct mem_cgroup *root_memcg)\n{\n\tstruct mem_cgroup *memcg;\n\n\tif (stock->cached_objcg) {\n\t\tmemcg = obj_cgroup_memcg(stock->cached_objcg);\n\t\tif (memcg && mem_cgroup_is_descendant(memcg, root_memcg))\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic void refill_obj_stock(struct obj_cgroup *objcg, unsigned int nr_bytes)\n{\n\tstruct memcg_stock_pcp *stock;\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\n\tstock = this_cpu_ptr(&memcg_stock);\n\tif (stock->cached_objcg != objcg) { /* reset if necessary */\n\t\tdrain_obj_stock(stock);\n\t\tobj_cgroup_get(objcg);\n\t\tstock->cached_objcg = objcg;\n\t\tstock->nr_bytes = atomic_xchg(&objcg->nr_charged_bytes, 0);\n\t}\n\tstock->nr_bytes += nr_bytes;\n\n\tif (stock->nr_bytes > PAGE_SIZE)\n\t\tdrain_obj_stock(stock);\n\n\tlocal_irq_restore(flags);\n}\n\nint obj_cgroup_charge(struct obj_cgroup *objcg, gfp_t gfp, size_t size)\n{\n\tstruct mem_cgroup *memcg;\n\tunsigned int nr_pages, nr_bytes;\n\tint ret;\n\n\tif (consume_obj_stock(objcg, size))\n\t\treturn 0;\n\n\t/*\n\t * In theory, memcg->nr_charged_bytes can have enough\n\t * pre-charged bytes to satisfy the allocation. However,\n\t * flushing memcg->nr_charged_bytes requires two atomic\n\t * operations, and memcg->nr_charged_bytes can't be big,\n\t * so it's better to ignore it and try grab some new pages.\n\t * memcg->nr_charged_bytes will be flushed in\n\t * refill_obj_stock(), called from this function or\n\t * independently later.\n\t */\n\trcu_read_lock();\n\tmemcg = obj_cgroup_memcg(objcg);\n\tcss_get(&memcg->css);\n\trcu_read_unlock();\n\n\tnr_pages = size >> PAGE_SHIFT;\n\tnr_bytes = size & (PAGE_SIZE - 1);\n\n\tif (nr_bytes)\n\t\tnr_pages += 1;\n\n\tret = __memcg_kmem_charge(memcg, gfp, nr_pages);\n\tif (!ret && nr_bytes)\n\t\trefill_obj_stock(objcg, PAGE_SIZE - nr_bytes);\n\n\tcss_put(&memcg->css);\n\treturn ret;\n}\n\nvoid obj_cgroup_uncharge(struct obj_cgroup *objcg, size_t size)\n{\n\trefill_obj_stock(objcg, size);\n}\n\n#endif /* CONFIG_MEMCG_KMEM */\n\n#ifdef CONFIG_TRANSPARENT_HUGEPAGE\n\n/*\n * Because tail pages are not marked as \"used\", set it. We're under\n * pgdat->lru_lock and migration entries setup in all page mappings.\n */\nvoid mem_cgroup_split_huge_fixup(struct page *head)\n{\n\tstruct mem_cgroup *memcg = head->mem_cgroup;\n\tint i;\n\n\tif (mem_cgroup_disabled())\n\t\treturn;\n\n\tfor (i = 1; i < HPAGE_PMD_NR; i++) {\n\t\tcss_get(&memcg->css);\n\t\thead[i].mem_cgroup = memcg;\n\t}\n}\n#endif /* CONFIG_TRANSPARENT_HUGEPAGE */\n\n#ifdef CONFIG_MEMCG_SWAP\n/**\n * mem_cgroup_move_swap_account - move swap charge and swap_cgroup's record.\n * @entry: swap entry to be moved\n * @from:  mem_cgroup which the entry is moved from\n * @to:  mem_cgroup which the entry is moved to\n *\n * It succeeds only when the swap_cgroup's record for this entry is the same\n * as the mem_cgroup's id of @from.\n *\n * Returns 0 on success, -EINVAL on failure.\n *\n * The caller must have charged to @to, IOW, called page_counter_charge() about\n * both res and memsw, and called css_get().\n */\nstatic int mem_cgroup_move_swap_account(swp_entry_t entry,\n\t\t\t\tstruct mem_cgroup *from, struct mem_cgroup *to)\n{\n\tunsigned short old_id, new_id;\n\n\told_id = mem_cgroup_id(from);\n\tnew_id = mem_cgroup_id(to);\n\n\tif (swap_cgroup_cmpxchg(entry, old_id, new_id) == old_id) {\n\t\tmod_memcg_state(from, MEMCG_SWAP, -1);\n\t\tmod_memcg_state(to, MEMCG_SWAP, 1);\n\t\treturn 0;\n\t}\n\treturn -EINVAL;\n}\n#else\nstatic inline int mem_cgroup_move_swap_account(swp_entry_t entry,\n\t\t\t\tstruct mem_cgroup *from, struct mem_cgroup *to)\n{\n\treturn -EINVAL;\n}\n#endif\n\nstatic DEFINE_MUTEX(memcg_max_mutex);\n\nstatic int mem_cgroup_resize_max(struct mem_cgroup *memcg,\n\t\t\t\t unsigned long max, bool memsw)\n{\n\tbool enlarge = false;\n\tbool drained = false;\n\tint ret;\n\tbool limits_invariant;\n\tstruct page_counter *counter = memsw ? &memcg->memsw : &memcg->memory;\n\n\tdo {\n\t\tif (signal_pending(current)) {\n\t\t\tret = -EINTR;\n\t\t\tbreak;\n\t\t}\n\n\t\tmutex_lock(&memcg_max_mutex);\n\t\t/*\n\t\t * Make sure that the new limit (memsw or memory limit) doesn't\n\t\t * break our basic invariant rule memory.max <= memsw.max.\n\t\t */\n\t\tlimits_invariant = memsw ? max >= READ_ONCE(memcg->memory.max) :\n\t\t\t\t\t   max <= memcg->memsw.max;\n\t\tif (!limits_invariant) {\n\t\t\tmutex_unlock(&memcg_max_mutex);\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\tif (max > counter->max)\n\t\t\tenlarge = true;\n\t\tret = page_counter_set_max(counter, max);\n\t\tmutex_unlock(&memcg_max_mutex);\n\n\t\tif (!ret)\n\t\t\tbreak;\n\n\t\tif (!drained) {\n\t\t\tdrain_all_stock(memcg);\n\t\t\tdrained = true;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!try_to_free_mem_cgroup_pages(memcg, 1,\n\t\t\t\t\tGFP_KERNEL, !memsw)) {\n\t\t\tret = -EBUSY;\n\t\t\tbreak;\n\t\t}\n\t} while (true);\n\n\tif (!ret && enlarge)\n\t\tmemcg_oom_recover(memcg);\n\n\treturn ret;\n}\n\nunsigned long mem_cgroup_soft_limit_reclaim(pg_data_t *pgdat, int order,\n\t\t\t\t\t    gfp_t gfp_mask,\n\t\t\t\t\t    unsigned long *total_scanned)\n{\n\tunsigned long nr_reclaimed = 0;\n\tstruct mem_cgroup_per_node *mz, *next_mz = NULL;\n\tunsigned long reclaimed;\n\tint loop = 0;\n\tstruct mem_cgroup_tree_per_node *mctz;\n\tunsigned long excess;\n\tunsigned long nr_scanned;\n\n\tif (order > 0)\n\t\treturn 0;\n\n\tmctz = soft_limit_tree_node(pgdat->node_id);\n\n\t/*\n\t * Do not even bother to check the largest node if the root\n\t * is empty. Do it lockless to prevent lock bouncing. Races\n\t * are acceptable as soft limit is best effort anyway.\n\t */\n\tif (!mctz || RB_EMPTY_ROOT(&mctz->rb_root))\n\t\treturn 0;\n\n\t/*\n\t * This loop can run a while, specially if mem_cgroup's continuously\n\t * keep exceeding their soft limit and putting the system under\n\t * pressure\n\t */\n\tdo {\n\t\tif (next_mz)\n\t\t\tmz = next_mz;\n\t\telse\n\t\t\tmz = mem_cgroup_largest_soft_limit_node(mctz);\n\t\tif (!mz)\n\t\t\tbreak;\n\n\t\tnr_scanned = 0;\n\t\treclaimed = mem_cgroup_soft_reclaim(mz->memcg, pgdat,\n\t\t\t\t\t\t    gfp_mask, &nr_scanned);\n\t\tnr_reclaimed += reclaimed;\n\t\t*total_scanned += nr_scanned;\n\t\tspin_lock_irq(&mctz->lock);\n\t\t__mem_cgroup_remove_exceeded(mz, mctz);\n\n\t\t/*\n\t\t * If we failed to reclaim anything from this memory cgroup\n\t\t * it is time to move on to the next cgroup\n\t\t */\n\t\tnext_mz = NULL;\n\t\tif (!reclaimed)\n\t\t\tnext_mz = __mem_cgroup_largest_soft_limit_node(mctz);\n\n\t\texcess = soft_limit_excess(mz->memcg);\n\t\t/*\n\t\t * One school of thought says that we should not add\n\t\t * back the node to the tree if reclaim returns 0.\n\t\t * But our reclaim could return 0, simply because due\n\t\t * to priority we are exposing a smaller subset of\n\t\t * memory to reclaim from. Consider this as a longer\n\t\t * term TODO.\n\t\t */\n\t\t/* If excess == 0, no tree ops */\n\t\t__mem_cgroup_insert_exceeded(mz, mctz, excess);\n\t\tspin_unlock_irq(&mctz->lock);\n\t\tcss_put(&mz->memcg->css);\n\t\tloop++;\n\t\t/*\n\t\t * Could not reclaim anything and there are no more\n\t\t * mem cgroups to try or we seem to be looping without\n\t\t * reclaiming anything.\n\t\t */\n\t\tif (!nr_reclaimed &&\n\t\t\t(next_mz == NULL ||\n\t\t\tloop > MEM_CGROUP_MAX_SOFT_LIMIT_RECLAIM_LOOPS))\n\t\t\tbreak;\n\t} while (!nr_reclaimed);\n\tif (next_mz)\n\t\tcss_put(&next_mz->memcg->css);\n\treturn nr_reclaimed;\n}\n\n/*\n * Test whether @memcg has children, dead or alive.  Note that this\n * function doesn't care whether @memcg has use_hierarchy enabled and\n * returns %true if there are child csses according to the cgroup\n * hierarchy.  Testing use_hierarchy is the caller's responsibility.\n */\nstatic inline bool memcg_has_children(struct mem_cgroup *memcg)\n{\n\tbool ret;\n\n\trcu_read_lock();\n\tret = css_next_child(NULL, &memcg->css);\n\trcu_read_unlock();\n\treturn ret;\n}\n\n/*\n * Reclaims as many pages from the given memcg as possible.\n *\n * Caller is responsible for holding css reference for memcg.\n */\nstatic int mem_cgroup_force_empty(struct mem_cgroup *memcg)\n{\n\tint nr_retries = MAX_RECLAIM_RETRIES;\n\n\t/* we call try-to-free pages for make this cgroup empty */\n\tlru_add_drain_all();\n\n\tdrain_all_stock(memcg);\n\n\t/* try to free all pages in this cgroup */\n\twhile (nr_retries && page_counter_read(&memcg->memory)) {\n\t\tint progress;\n\n\t\tif (signal_pending(current))\n\t\t\treturn -EINTR;\n\n\t\tprogress = try_to_free_mem_cgroup_pages(memcg, 1,\n\t\t\t\t\t\t\tGFP_KERNEL, true);\n\t\tif (!progress) {\n\t\t\tnr_retries--;\n\t\t\t/* maybe some writeback is necessary */\n\t\t\tcongestion_wait(BLK_RW_ASYNC, HZ/10);\n\t\t}\n\n\t}\n\n\treturn 0;\n}\n\nstatic ssize_t mem_cgroup_force_empty_write(struct kernfs_open_file *of,\n\t\t\t\t\t    char *buf, size_t nbytes,\n\t\t\t\t\t    loff_t off)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_css(of_css(of));\n\n\tif (mem_cgroup_is_root(memcg))\n\t\treturn -EINVAL;\n\treturn mem_cgroup_force_empty(memcg) ?: nbytes;\n}\n\nstatic u64 mem_cgroup_hierarchy_read(struct cgroup_subsys_state *css,\n\t\t\t\t     struct cftype *cft)\n{\n\treturn mem_cgroup_from_css(css)->use_hierarchy;\n}\n\nstatic int mem_cgroup_hierarchy_write(struct cgroup_subsys_state *css,\n\t\t\t\t      struct cftype *cft, u64 val)\n{\n\tint retval = 0;\n\tstruct mem_cgroup *memcg = mem_cgroup_from_css(css);\n\tstruct mem_cgroup *parent_memcg = mem_cgroup_from_css(memcg->css.parent);\n\n\tif (memcg->use_hierarchy == val)\n\t\treturn 0;\n\n\t/*\n\t * If parent's use_hierarchy is set, we can't make any modifications\n\t * in the child subtrees. If it is unset, then the change can\n\t * occur, provided the current cgroup has no children.\n\t *\n\t * For the root cgroup, parent_mem is NULL, we allow value to be\n\t * set if there are no children.\n\t */\n\tif ((!parent_memcg || !parent_memcg->use_hierarchy) &&\n\t\t\t\t(val == 1 || val == 0)) {\n\t\tif (!memcg_has_children(memcg))\n\t\t\tmemcg->use_hierarchy = val;\n\t\telse\n\t\t\tretval = -EBUSY;\n\t} else\n\t\tretval = -EINVAL;\n\n\treturn retval;\n}\n\nstatic unsigned long mem_cgroup_usage(struct mem_cgroup *memcg, bool swap)\n{\n\tunsigned long val;\n\n\tif (mem_cgroup_is_root(memcg)) {\n\t\tval = memcg_page_state(memcg, NR_FILE_PAGES) +\n\t\t\tmemcg_page_state(memcg, NR_ANON_MAPPED);\n\t\tif (swap)\n\t\t\tval += memcg_page_state(memcg, MEMCG_SWAP);\n\t} else {\n\t\tif (!swap)\n\t\t\tval = page_counter_read(&memcg->memory);\n\t\telse\n\t\t\tval = page_counter_read(&memcg->memsw);\n\t}\n\treturn val;\n}\n\nenum {\n\tRES_USAGE,\n\tRES_LIMIT,\n\tRES_MAX_USAGE,\n\tRES_FAILCNT,\n\tRES_SOFT_LIMIT,\n};\n\nstatic u64 mem_cgroup_read_u64(struct cgroup_subsys_state *css,\n\t\t\t       struct cftype *cft)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_css(css);\n\tstruct page_counter *counter;\n\n\tswitch (MEMFILE_TYPE(cft->private)) {\n\tcase _MEM:\n\t\tcounter = &memcg->memory;\n\t\tbreak;\n\tcase _MEMSWAP:\n\t\tcounter = &memcg->memsw;\n\t\tbreak;\n\tcase _KMEM:\n\t\tcounter = &memcg->kmem;\n\t\tbreak;\n\tcase _TCP:\n\t\tcounter = &memcg->tcpmem;\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n\n\tswitch (MEMFILE_ATTR(cft->private)) {\n\tcase RES_USAGE:\n\t\tif (counter == &memcg->memory)\n\t\t\treturn (u64)mem_cgroup_usage(memcg, false) * PAGE_SIZE;\n\t\tif (counter == &memcg->memsw)\n\t\t\treturn (u64)mem_cgroup_usage(memcg, true) * PAGE_SIZE;\n\t\treturn (u64)page_counter_read(counter) * PAGE_SIZE;\n\tcase RES_LIMIT:\n\t\treturn (u64)counter->max * PAGE_SIZE;\n\tcase RES_MAX_USAGE:\n\t\treturn (u64)counter->watermark * PAGE_SIZE;\n\tcase RES_FAILCNT:\n\t\treturn counter->failcnt;\n\tcase RES_SOFT_LIMIT:\n\t\treturn (u64)memcg->soft_limit * PAGE_SIZE;\n\tdefault:\n\t\tBUG();\n\t}\n}\n\nstatic void memcg_flush_percpu_vmstats(struct mem_cgroup *memcg)\n{\n\tunsigned long stat[MEMCG_NR_STAT] = {0};\n\tstruct mem_cgroup *mi;\n\tint node, cpu, i;\n\n\tfor_each_online_cpu(cpu)\n\t\tfor (i = 0; i < MEMCG_NR_STAT; i++)\n\t\t\tstat[i] += per_cpu(memcg->vmstats_percpu->stat[i], cpu);\n\n\tfor (mi = memcg; mi; mi = parent_mem_cgroup(mi))\n\t\tfor (i = 0; i < MEMCG_NR_STAT; i++)\n\t\t\tatomic_long_add(stat[i], &mi->vmstats[i]);\n\n\tfor_each_node(node) {\n\t\tstruct mem_cgroup_per_node *pn = memcg->nodeinfo[node];\n\t\tstruct mem_cgroup_per_node *pi;\n\n\t\tfor (i = 0; i < NR_VM_NODE_STAT_ITEMS; i++)\n\t\t\tstat[i] = 0;\n\n\t\tfor_each_online_cpu(cpu)\n\t\t\tfor (i = 0; i < NR_VM_NODE_STAT_ITEMS; i++)\n\t\t\t\tstat[i] += per_cpu(\n\t\t\t\t\tpn->lruvec_stat_cpu->count[i], cpu);\n\n\t\tfor (pi = pn; pi; pi = parent_nodeinfo(pi, node))\n\t\t\tfor (i = 0; i < NR_VM_NODE_STAT_ITEMS; i++)\n\t\t\t\tatomic_long_add(stat[i], &pi->lruvec_stat[i]);\n\t}\n}\n\nstatic void memcg_flush_percpu_vmevents(struct mem_cgroup *memcg)\n{\n\tunsigned long events[NR_VM_EVENT_ITEMS];\n\tstruct mem_cgroup *mi;\n\tint cpu, i;\n\n\tfor (i = 0; i < NR_VM_EVENT_ITEMS; i++)\n\t\tevents[i] = 0;\n\n\tfor_each_online_cpu(cpu)\n\t\tfor (i = 0; i < NR_VM_EVENT_ITEMS; i++)\n\t\t\tevents[i] += per_cpu(memcg->vmstats_percpu->events[i],\n\t\t\t\t\t     cpu);\n\n\tfor (mi = memcg; mi; mi = parent_mem_cgroup(mi))\n\t\tfor (i = 0; i < NR_VM_EVENT_ITEMS; i++)\n\t\t\tatomic_long_add(events[i], &mi->vmevents[i]);\n}\n\n#ifdef CONFIG_MEMCG_KMEM\nstatic int memcg_online_kmem(struct mem_cgroup *memcg)\n{\n\tstruct obj_cgroup *objcg;\n\tint memcg_id;\n\n\tif (cgroup_memory_nokmem)\n\t\treturn 0;\n\n\tBUG_ON(memcg->kmemcg_id >= 0);\n\tBUG_ON(memcg->kmem_state);\n\n\tmemcg_id = memcg_alloc_cache_id();\n\tif (memcg_id < 0)\n\t\treturn memcg_id;\n\n\tobjcg = obj_cgroup_alloc();\n\tif (!objcg) {\n\t\tmemcg_free_cache_id(memcg_id);\n\t\treturn -ENOMEM;\n\t}\n\tobjcg->memcg = memcg;\n\trcu_assign_pointer(memcg->objcg, objcg);\n\n\tstatic_branch_enable(&memcg_kmem_enabled_key);\n\n\t/*\n\t * A memory cgroup is considered kmem-online as soon as it gets\n\t * kmemcg_id. Setting the id after enabling static branching will\n\t * guarantee no one starts accounting before all call sites are\n\t * patched.\n\t */\n\tmemcg->kmemcg_id = memcg_id;\n\tmemcg->kmem_state = KMEM_ONLINE;\n\n\treturn 0;\n}\n\nstatic void memcg_offline_kmem(struct mem_cgroup *memcg)\n{\n\tstruct cgroup_subsys_state *css;\n\tstruct mem_cgroup *parent, *child;\n\tint kmemcg_id;\n\n\tif (memcg->kmem_state != KMEM_ONLINE)\n\t\treturn;\n\n\tmemcg->kmem_state = KMEM_ALLOCATED;\n\n\tparent = parent_mem_cgroup(memcg);\n\tif (!parent)\n\t\tparent = root_mem_cgroup;\n\n\tmemcg_reparent_objcgs(memcg, parent);\n\n\tkmemcg_id = memcg->kmemcg_id;\n\tBUG_ON(kmemcg_id < 0);\n\n\t/*\n\t * Change kmemcg_id of this cgroup and all its descendants to the\n\t * parent's id, and then move all entries from this cgroup's list_lrus\n\t * to ones of the parent. After we have finished, all list_lrus\n\t * corresponding to this cgroup are guaranteed to remain empty. The\n\t * ordering is imposed by list_lru_node->lock taken by\n\t * memcg_drain_all_list_lrus().\n\t */\n\trcu_read_lock(); /* can be called from css_free w/o cgroup_mutex */\n\tcss_for_each_descendant_pre(css, &memcg->css) {\n\t\tchild = mem_cgroup_from_css(css);\n\t\tBUG_ON(child->kmemcg_id != kmemcg_id);\n\t\tchild->kmemcg_id = parent->kmemcg_id;\n\t\tif (!memcg->use_hierarchy)\n\t\t\tbreak;\n\t}\n\trcu_read_unlock();\n\n\tmemcg_drain_all_list_lrus(kmemcg_id, parent);\n\n\tmemcg_free_cache_id(kmemcg_id);\n}\n\nstatic void memcg_free_kmem(struct mem_cgroup *memcg)\n{\n\t/* css_alloc() failed, offlining didn't happen */\n\tif (unlikely(memcg->kmem_state == KMEM_ONLINE))\n\t\tmemcg_offline_kmem(memcg);\n}\n#else\nstatic int memcg_online_kmem(struct mem_cgroup *memcg)\n{\n\treturn 0;\n}\nstatic void memcg_offline_kmem(struct mem_cgroup *memcg)\n{\n}\nstatic void memcg_free_kmem(struct mem_cgroup *memcg)\n{\n}\n#endif /* CONFIG_MEMCG_KMEM */\n\nstatic int memcg_update_kmem_max(struct mem_cgroup *memcg,\n\t\t\t\t unsigned long max)\n{\n\tint ret;\n\n\tmutex_lock(&memcg_max_mutex);\n\tret = page_counter_set_max(&memcg->kmem, max);\n\tmutex_unlock(&memcg_max_mutex);\n\treturn ret;\n}\n\nstatic int memcg_update_tcp_max(struct mem_cgroup *memcg, unsigned long max)\n{\n\tint ret;\n\n\tmutex_lock(&memcg_max_mutex);\n\n\tret = page_counter_set_max(&memcg->tcpmem, max);\n\tif (ret)\n\t\tgoto out;\n\n\tif (!memcg->tcpmem_active) {\n\t\t/*\n\t\t * The active flag needs to be written after the static_key\n\t\t * update. This is what guarantees that the socket activation\n\t\t * function is the last one to run. See mem_cgroup_sk_alloc()\n\t\t * for details, and note that we don't mark any socket as\n\t\t * belonging to this memcg until that flag is up.\n\t\t *\n\t\t * We need to do this, because static_keys will span multiple\n\t\t * sites, but we can't control their order. If we mark a socket\n\t\t * as accounted, but the accounting functions are not patched in\n\t\t * yet, we'll lose accounting.\n\t\t *\n\t\t * We never race with the readers in mem_cgroup_sk_alloc(),\n\t\t * because when this value change, the code to process it is not\n\t\t * patched in yet.\n\t\t */\n\t\tstatic_branch_inc(&memcg_sockets_enabled_key);\n\t\tmemcg->tcpmem_active = true;\n\t}\nout:\n\tmutex_unlock(&memcg_max_mutex);\n\treturn ret;\n}\n\n/*\n * The user of this function is...\n * RES_LIMIT.\n */\nstatic ssize_t mem_cgroup_write(struct kernfs_open_file *of,\n\t\t\t\tchar *buf, size_t nbytes, loff_t off)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_css(of_css(of));\n\tunsigned long nr_pages;\n\tint ret;\n\n\tbuf = strstrip(buf);\n\tret = page_counter_memparse(buf, \"-1\", &nr_pages);\n\tif (ret)\n\t\treturn ret;\n\n\tswitch (MEMFILE_ATTR(of_cft(of)->private)) {\n\tcase RES_LIMIT:\n\t\tif (mem_cgroup_is_root(memcg)) { /* Can't set limit on root */\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\tswitch (MEMFILE_TYPE(of_cft(of)->private)) {\n\t\tcase _MEM:\n\t\t\tret = mem_cgroup_resize_max(memcg, nr_pages, false);\n\t\t\tbreak;\n\t\tcase _MEMSWAP:\n\t\t\tret = mem_cgroup_resize_max(memcg, nr_pages, true);\n\t\t\tbreak;\n\t\tcase _KMEM:\n\t\t\tpr_warn_once(\"kmem.limit_in_bytes is deprecated and will be removed. \"\n\t\t\t\t     \"Please report your usecase to linux-mm@kvack.org if you \"\n\t\t\t\t     \"depend on this functionality.\\n\");\n\t\t\tret = memcg_update_kmem_max(memcg, nr_pages);\n\t\t\tbreak;\n\t\tcase _TCP:\n\t\t\tret = memcg_update_tcp_max(memcg, nr_pages);\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase RES_SOFT_LIMIT:\n\t\tmemcg->soft_limit = nr_pages;\n\t\tret = 0;\n\t\tbreak;\n\t}\n\treturn ret ?: nbytes;\n}\n\nstatic ssize_t mem_cgroup_reset(struct kernfs_open_file *of, char *buf,\n\t\t\t\tsize_t nbytes, loff_t off)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_css(of_css(of));\n\tstruct page_counter *counter;\n\n\tswitch (MEMFILE_TYPE(of_cft(of)->private)) {\n\tcase _MEM:\n\t\tcounter = &memcg->memory;\n\t\tbreak;\n\tcase _MEMSWAP:\n\t\tcounter = &memcg->memsw;\n\t\tbreak;\n\tcase _KMEM:\n\t\tcounter = &memcg->kmem;\n\t\tbreak;\n\tcase _TCP:\n\t\tcounter = &memcg->tcpmem;\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n\n\tswitch (MEMFILE_ATTR(of_cft(of)->private)) {\n\tcase RES_MAX_USAGE:\n\t\tpage_counter_reset_watermark(counter);\n\t\tbreak;\n\tcase RES_FAILCNT:\n\t\tcounter->failcnt = 0;\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n\n\treturn nbytes;\n}\n\nstatic u64 mem_cgroup_move_charge_read(struct cgroup_subsys_state *css,\n\t\t\t\t\tstruct cftype *cft)\n{\n\treturn mem_cgroup_from_css(css)->move_charge_at_immigrate;\n}\n\n#ifdef CONFIG_MMU\nstatic int mem_cgroup_move_charge_write(struct cgroup_subsys_state *css,\n\t\t\t\t\tstruct cftype *cft, u64 val)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_css(css);\n\n\tif (val & ~MOVE_MASK)\n\t\treturn -EINVAL;\n\n\t/*\n\t * No kind of locking is needed in here, because ->can_attach() will\n\t * check this value once in the beginning of the process, and then carry\n\t * on with stale data. This means that changes to this value will only\n\t * affect task migrations starting after the change.\n\t */\n\tmemcg->move_charge_at_immigrate = val;\n\treturn 0;\n}\n#else\nstatic int mem_cgroup_move_charge_write(struct cgroup_subsys_state *css,\n\t\t\t\t\tstruct cftype *cft, u64 val)\n{\n\treturn -ENOSYS;\n}\n#endif\n\n#ifdef CONFIG_NUMA\n\n#define LRU_ALL_FILE (BIT(LRU_INACTIVE_FILE) | BIT(LRU_ACTIVE_FILE))\n#define LRU_ALL_ANON (BIT(LRU_INACTIVE_ANON) | BIT(LRU_ACTIVE_ANON))\n#define LRU_ALL\t     ((1 << NR_LRU_LISTS) - 1)\n\nstatic unsigned long mem_cgroup_node_nr_lru_pages(struct mem_cgroup *memcg,\n\t\t\t\tint nid, unsigned int lru_mask, bool tree)\n{\n\tstruct lruvec *lruvec = mem_cgroup_lruvec(memcg, NODE_DATA(nid));\n\tunsigned long nr = 0;\n\tenum lru_list lru;\n\n\tVM_BUG_ON((unsigned)nid >= nr_node_ids);\n\n\tfor_each_lru(lru) {\n\t\tif (!(BIT(lru) & lru_mask))\n\t\t\tcontinue;\n\t\tif (tree)\n\t\t\tnr += lruvec_page_state(lruvec, NR_LRU_BASE + lru);\n\t\telse\n\t\t\tnr += lruvec_page_state_local(lruvec, NR_LRU_BASE + lru);\n\t}\n\treturn nr;\n}\n\nstatic unsigned long mem_cgroup_nr_lru_pages(struct mem_cgroup *memcg,\n\t\t\t\t\t     unsigned int lru_mask,\n\t\t\t\t\t     bool tree)\n{\n\tunsigned long nr = 0;\n\tenum lru_list lru;\n\n\tfor_each_lru(lru) {\n\t\tif (!(BIT(lru) & lru_mask))\n\t\t\tcontinue;\n\t\tif (tree)\n\t\t\tnr += memcg_page_state(memcg, NR_LRU_BASE + lru);\n\t\telse\n\t\t\tnr += memcg_page_state_local(memcg, NR_LRU_BASE + lru);\n\t}\n\treturn nr;\n}\n\nstatic int memcg_numa_stat_show(struct seq_file *m, void *v)\n{\n\tstruct numa_stat {\n\t\tconst char *name;\n\t\tunsigned int lru_mask;\n\t};\n\n\tstatic const struct numa_stat stats[] = {\n\t\t{ \"total\", LRU_ALL },\n\t\t{ \"file\", LRU_ALL_FILE },\n\t\t{ \"anon\", LRU_ALL_ANON },\n\t\t{ \"unevictable\", BIT(LRU_UNEVICTABLE) },\n\t};\n\tconst struct numa_stat *stat;\n\tint nid;\n\tstruct mem_cgroup *memcg = mem_cgroup_from_seq(m);\n\n\tfor (stat = stats; stat < stats + ARRAY_SIZE(stats); stat++) {\n\t\tseq_printf(m, \"%s=%lu\", stat->name,\n\t\t\t   mem_cgroup_nr_lru_pages(memcg, stat->lru_mask,\n\t\t\t\t\t\t   false));\n\t\tfor_each_node_state(nid, N_MEMORY)\n\t\t\tseq_printf(m, \" N%d=%lu\", nid,\n\t\t\t\t   mem_cgroup_node_nr_lru_pages(memcg, nid,\n\t\t\t\t\t\t\tstat->lru_mask, false));\n\t\tseq_putc(m, '\\n');\n\t}\n\n\tfor (stat = stats; stat < stats + ARRAY_SIZE(stats); stat++) {\n\n\t\tseq_printf(m, \"hierarchical_%s=%lu\", stat->name,\n\t\t\t   mem_cgroup_nr_lru_pages(memcg, stat->lru_mask,\n\t\t\t\t\t\t   true));\n\t\tfor_each_node_state(nid, N_MEMORY)\n\t\t\tseq_printf(m, \" N%d=%lu\", nid,\n\t\t\t\t   mem_cgroup_node_nr_lru_pages(memcg, nid,\n\t\t\t\t\t\t\tstat->lru_mask, true));\n\t\tseq_putc(m, '\\n');\n\t}\n\n\treturn 0;\n}\n#endif /* CONFIG_NUMA */\n\nstatic const unsigned int memcg1_stats[] = {\n\tNR_FILE_PAGES,\n\tNR_ANON_MAPPED,\n#ifdef CONFIG_TRANSPARENT_HUGEPAGE\n\tNR_ANON_THPS,\n#endif\n\tNR_SHMEM,\n\tNR_FILE_MAPPED,\n\tNR_FILE_DIRTY,\n\tNR_WRITEBACK,\n\tMEMCG_SWAP,\n};\n\nstatic const char *const memcg1_stat_names[] = {\n\t\"cache\",\n\t\"rss\",\n#ifdef CONFIG_TRANSPARENT_HUGEPAGE\n\t\"rss_huge\",\n#endif\n\t\"shmem\",\n\t\"mapped_file\",\n\t\"dirty\",\n\t\"writeback\",\n\t\"swap\",\n};\n\n/* Universal VM events cgroup1 shows, original sort order */\nstatic const unsigned int memcg1_events[] = {\n\tPGPGIN,\n\tPGPGOUT,\n\tPGFAULT,\n\tPGMAJFAULT,\n};\n\nstatic int memcg_stat_show(struct seq_file *m, void *v)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_seq(m);\n\tunsigned long memory, memsw;\n\tstruct mem_cgroup *mi;\n\tunsigned int i;\n\n\tBUILD_BUG_ON(ARRAY_SIZE(memcg1_stat_names) != ARRAY_SIZE(memcg1_stats));\n\n\tfor (i = 0; i < ARRAY_SIZE(memcg1_stats); i++) {\n\t\tunsigned long nr;\n\n\t\tif (memcg1_stats[i] == MEMCG_SWAP && !do_memsw_account())\n\t\t\tcontinue;\n\t\tnr = memcg_page_state_local(memcg, memcg1_stats[i]);\n#ifdef CONFIG_TRANSPARENT_HUGEPAGE\n\t\tif (memcg1_stats[i] == NR_ANON_THPS)\n\t\t\tnr *= HPAGE_PMD_NR;\n#endif\n\t\tseq_printf(m, \"%s %lu\\n\", memcg1_stat_names[i], nr * PAGE_SIZE);\n\t}\n\n\tfor (i = 0; i < ARRAY_SIZE(memcg1_events); i++)\n\t\tseq_printf(m, \"%s %lu\\n\", vm_event_name(memcg1_events[i]),\n\t\t\t   memcg_events_local(memcg, memcg1_events[i]));\n\n\tfor (i = 0; i < NR_LRU_LISTS; i++)\n\t\tseq_printf(m, \"%s %lu\\n\", lru_list_name(i),\n\t\t\t   memcg_page_state_local(memcg, NR_LRU_BASE + i) *\n\t\t\t   PAGE_SIZE);\n\n\t/* Hierarchical information */\n\tmemory = memsw = PAGE_COUNTER_MAX;\n\tfor (mi = memcg; mi; mi = parent_mem_cgroup(mi)) {\n\t\tmemory = min(memory, READ_ONCE(mi->memory.max));\n\t\tmemsw = min(memsw, READ_ONCE(mi->memsw.max));\n\t}\n\tseq_printf(m, \"hierarchical_memory_limit %llu\\n\",\n\t\t   (u64)memory * PAGE_SIZE);\n\tif (do_memsw_account())\n\t\tseq_printf(m, \"hierarchical_memsw_limit %llu\\n\",\n\t\t\t   (u64)memsw * PAGE_SIZE);\n\n\tfor (i = 0; i < ARRAY_SIZE(memcg1_stats); i++) {\n\t\tunsigned long nr;\n\n\t\tif (memcg1_stats[i] == MEMCG_SWAP && !do_memsw_account())\n\t\t\tcontinue;\n\t\tnr = memcg_page_state(memcg, memcg1_stats[i]);\n#ifdef CONFIG_TRANSPARENT_HUGEPAGE\n\t\tif (memcg1_stats[i] == NR_ANON_THPS)\n\t\t\tnr *= HPAGE_PMD_NR;\n#endif\n\t\tseq_printf(m, \"total_%s %lu\\n\", memcg1_stat_names[i],\n\t\t\t\t\t\tnr * PAGE_SIZE);\n\t}\n\n\tfor (i = 0; i < ARRAY_SIZE(memcg1_events); i++)\n\t\tseq_printf(m, \"total_%s %llu\\n\",\n\t\t\t   vm_event_name(memcg1_events[i]),\n\t\t\t   (u64)memcg_events(memcg, memcg1_events[i]));\n\n\tfor (i = 0; i < NR_LRU_LISTS; i++)\n\t\tseq_printf(m, \"total_%s %llu\\n\", lru_list_name(i),\n\t\t\t   (u64)memcg_page_state(memcg, NR_LRU_BASE + i) *\n\t\t\t   PAGE_SIZE);\n\n#ifdef CONFIG_DEBUG_VM\n\t{\n\t\tpg_data_t *pgdat;\n\t\tstruct mem_cgroup_per_node *mz;\n\t\tunsigned long anon_cost = 0;\n\t\tunsigned long file_cost = 0;\n\n\t\tfor_each_online_pgdat(pgdat) {\n\t\t\tmz = mem_cgroup_nodeinfo(memcg, pgdat->node_id);\n\n\t\t\tanon_cost += mz->lruvec.anon_cost;\n\t\t\tfile_cost += mz->lruvec.file_cost;\n\t\t}\n\t\tseq_printf(m, \"anon_cost %lu\\n\", anon_cost);\n\t\tseq_printf(m, \"file_cost %lu\\n\", file_cost);\n\t}\n#endif\n\n\treturn 0;\n}\n\nstatic u64 mem_cgroup_swappiness_read(struct cgroup_subsys_state *css,\n\t\t\t\t      struct cftype *cft)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_css(css);\n\n\treturn mem_cgroup_swappiness(memcg);\n}\n\nstatic int mem_cgroup_swappiness_write(struct cgroup_subsys_state *css,\n\t\t\t\t       struct cftype *cft, u64 val)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_css(css);\n\n\tif (val > 100)\n\t\treturn -EINVAL;\n\n\tif (css->parent)\n\t\tmemcg->swappiness = val;\n\telse\n\t\tvm_swappiness = val;\n\n\treturn 0;\n}\n\nstatic void __mem_cgroup_threshold(struct mem_cgroup *memcg, bool swap)\n{\n\tstruct mem_cgroup_threshold_ary *t;\n\tunsigned long usage;\n\tint i;\n\n\trcu_read_lock();\n\tif (!swap)\n\t\tt = rcu_dereference(memcg->thresholds.primary);\n\telse\n\t\tt = rcu_dereference(memcg->memsw_thresholds.primary);\n\n\tif (!t)\n\t\tgoto unlock;\n\n\tusage = mem_cgroup_usage(memcg, swap);\n\n\t/*\n\t * current_threshold points to threshold just below or equal to usage.\n\t * If it's not true, a threshold was crossed after last\n\t * call of __mem_cgroup_threshold().\n\t */\n\ti = t->current_threshold;\n\n\t/*\n\t * Iterate backward over array of thresholds starting from\n\t * current_threshold and check if a threshold is crossed.\n\t * If none of thresholds below usage is crossed, we read\n\t * only one element of the array here.\n\t */\n\tfor (; i >= 0 && unlikely(t->entries[i].threshold > usage); i--)\n\t\teventfd_signal(t->entries[i].eventfd, 1);\n\n\t/* i = current_threshold + 1 */\n\ti++;\n\n\t/*\n\t * Iterate forward over array of thresholds starting from\n\t * current_threshold+1 and check if a threshold is crossed.\n\t * If none of thresholds above usage is crossed, we read\n\t * only one element of the array here.\n\t */\n\tfor (; i < t->size && unlikely(t->entries[i].threshold <= usage); i++)\n\t\teventfd_signal(t->entries[i].eventfd, 1);\n\n\t/* Update current_threshold */\n\tt->current_threshold = i - 1;\nunlock:\n\trcu_read_unlock();\n}\n\nstatic void mem_cgroup_threshold(struct mem_cgroup *memcg)\n{\n\twhile (memcg) {\n\t\t__mem_cgroup_threshold(memcg, false);\n\t\tif (do_memsw_account())\n\t\t\t__mem_cgroup_threshold(memcg, true);\n\n\t\tmemcg = parent_mem_cgroup(memcg);\n\t}\n}\n\nstatic int compare_thresholds(const void *a, const void *b)\n{\n\tconst struct mem_cgroup_threshold *_a = a;\n\tconst struct mem_cgroup_threshold *_b = b;\n\n\tif (_a->threshold > _b->threshold)\n\t\treturn 1;\n\n\tif (_a->threshold < _b->threshold)\n\t\treturn -1;\n\n\treturn 0;\n}\n\nstatic int mem_cgroup_oom_notify_cb(struct mem_cgroup *memcg)\n{\n\tstruct mem_cgroup_eventfd_list *ev;\n\n\tspin_lock(&memcg_oom_lock);\n\n\tlist_for_each_entry(ev, &memcg->oom_notify, list)\n\t\teventfd_signal(ev->eventfd, 1);\n\n\tspin_unlock(&memcg_oom_lock);\n\treturn 0;\n}\n\nstatic void mem_cgroup_oom_notify(struct mem_cgroup *memcg)\n{\n\tstruct mem_cgroup *iter;\n\n\tfor_each_mem_cgroup_tree(iter, memcg)\n\t\tmem_cgroup_oom_notify_cb(iter);\n}\n\nstatic int __mem_cgroup_usage_register_event(struct mem_cgroup *memcg,\n\tstruct eventfd_ctx *eventfd, const char *args, enum res_type type)\n{\n\tstruct mem_cgroup_thresholds *thresholds;\n\tstruct mem_cgroup_threshold_ary *new;\n\tunsigned long threshold;\n\tunsigned long usage;\n\tint i, size, ret;\n\n\tret = page_counter_memparse(args, \"-1\", &threshold);\n\tif (ret)\n\t\treturn ret;\n\n\tmutex_lock(&memcg->thresholds_lock);\n\n\tif (type == _MEM) {\n\t\tthresholds = &memcg->thresholds;\n\t\tusage = mem_cgroup_usage(memcg, false);\n\t} else if (type == _MEMSWAP) {\n\t\tthresholds = &memcg->memsw_thresholds;\n\t\tusage = mem_cgroup_usage(memcg, true);\n\t} else\n\t\tBUG();\n\n\t/* Check if a threshold crossed before adding a new one */\n\tif (thresholds->primary)\n\t\t__mem_cgroup_threshold(memcg, type == _MEMSWAP);\n\n\tsize = thresholds->primary ? thresholds->primary->size + 1 : 1;\n\n\t/* Allocate memory for new array of thresholds */\n\tnew = kmalloc(struct_size(new, entries, size), GFP_KERNEL);\n\tif (!new) {\n\t\tret = -ENOMEM;\n\t\tgoto unlock;\n\t}\n\tnew->size = size;\n\n\t/* Copy thresholds (if any) to new array */\n\tif (thresholds->primary)\n\t\tmemcpy(new->entries, thresholds->primary->entries,\n\t\t       flex_array_size(new, entries, size - 1));\n\n\t/* Add new threshold */\n\tnew->entries[size - 1].eventfd = eventfd;\n\tnew->entries[size - 1].threshold = threshold;\n\n\t/* Sort thresholds. Registering of new threshold isn't time-critical */\n\tsort(new->entries, size, sizeof(*new->entries),\n\t\t\tcompare_thresholds, NULL);\n\n\t/* Find current threshold */\n\tnew->current_threshold = -1;\n\tfor (i = 0; i < size; i++) {\n\t\tif (new->entries[i].threshold <= usage) {\n\t\t\t/*\n\t\t\t * new->current_threshold will not be used until\n\t\t\t * rcu_assign_pointer(), so it's safe to increment\n\t\t\t * it here.\n\t\t\t */\n\t\t\t++new->current_threshold;\n\t\t} else\n\t\t\tbreak;\n\t}\n\n\t/* Free old spare buffer and save old primary buffer as spare */\n\tkfree(thresholds->spare);\n\tthresholds->spare = thresholds->primary;\n\n\trcu_assign_pointer(thresholds->primary, new);\n\n\t/* To be sure that nobody uses thresholds */\n\tsynchronize_rcu();\n\nunlock:\n\tmutex_unlock(&memcg->thresholds_lock);\n\n\treturn ret;\n}\n\nstatic int mem_cgroup_usage_register_event(struct mem_cgroup *memcg,\n\tstruct eventfd_ctx *eventfd, const char *args)\n{\n\treturn __mem_cgroup_usage_register_event(memcg, eventfd, args, _MEM);\n}\n\nstatic int memsw_cgroup_usage_register_event(struct mem_cgroup *memcg,\n\tstruct eventfd_ctx *eventfd, const char *args)\n{\n\treturn __mem_cgroup_usage_register_event(memcg, eventfd, args, _MEMSWAP);\n}\n\nstatic void __mem_cgroup_usage_unregister_event(struct mem_cgroup *memcg,\n\tstruct eventfd_ctx *eventfd, enum res_type type)\n{\n\tstruct mem_cgroup_thresholds *thresholds;\n\tstruct mem_cgroup_threshold_ary *new;\n\tunsigned long usage;\n\tint i, j, size, entries;\n\n\tmutex_lock(&memcg->thresholds_lock);\n\n\tif (type == _MEM) {\n\t\tthresholds = &memcg->thresholds;\n\t\tusage = mem_cgroup_usage(memcg, false);\n\t} else if (type == _MEMSWAP) {\n\t\tthresholds = &memcg->memsw_thresholds;\n\t\tusage = mem_cgroup_usage(memcg, true);\n\t} else\n\t\tBUG();\n\n\tif (!thresholds->primary)\n\t\tgoto unlock;\n\n\t/* Check if a threshold crossed before removing */\n\t__mem_cgroup_threshold(memcg, type == _MEMSWAP);\n\n\t/* Calculate new number of threshold */\n\tsize = entries = 0;\n\tfor (i = 0; i < thresholds->primary->size; i++) {\n\t\tif (thresholds->primary->entries[i].eventfd != eventfd)\n\t\t\tsize++;\n\t\telse\n\t\t\tentries++;\n\t}\n\n\tnew = thresholds->spare;\n\n\t/* If no items related to eventfd have been cleared, nothing to do */\n\tif (!entries)\n\t\tgoto unlock;\n\n\t/* Set thresholds array to NULL if we don't have thresholds */\n\tif (!size) {\n\t\tkfree(new);\n\t\tnew = NULL;\n\t\tgoto swap_buffers;\n\t}\n\n\tnew->size = size;\n\n\t/* Copy thresholds and find current threshold */\n\tnew->current_threshold = -1;\n\tfor (i = 0, j = 0; i < thresholds->primary->size; i++) {\n\t\tif (thresholds->primary->entries[i].eventfd == eventfd)\n\t\t\tcontinue;\n\n\t\tnew->entries[j] = thresholds->primary->entries[i];\n\t\tif (new->entries[j].threshold <= usage) {\n\t\t\t/*\n\t\t\t * new->current_threshold will not be used\n\t\t\t * until rcu_assign_pointer(), so it's safe to increment\n\t\t\t * it here.\n\t\t\t */\n\t\t\t++new->current_threshold;\n\t\t}\n\t\tj++;\n\t}\n\nswap_buffers:\n\t/* Swap primary and spare array */\n\tthresholds->spare = thresholds->primary;\n\n\trcu_assign_pointer(thresholds->primary, new);\n\n\t/* To be sure that nobody uses thresholds */\n\tsynchronize_rcu();\n\n\t/* If all events are unregistered, free the spare array */\n\tif (!new) {\n\t\tkfree(thresholds->spare);\n\t\tthresholds->spare = NULL;\n\t}\nunlock:\n\tmutex_unlock(&memcg->thresholds_lock);\n}\n\nstatic void mem_cgroup_usage_unregister_event(struct mem_cgroup *memcg,\n\tstruct eventfd_ctx *eventfd)\n{\n\treturn __mem_cgroup_usage_unregister_event(memcg, eventfd, _MEM);\n}\n\nstatic void memsw_cgroup_usage_unregister_event(struct mem_cgroup *memcg,\n\tstruct eventfd_ctx *eventfd)\n{\n\treturn __mem_cgroup_usage_unregister_event(memcg, eventfd, _MEMSWAP);\n}\n\nstatic int mem_cgroup_oom_register_event(struct mem_cgroup *memcg,\n\tstruct eventfd_ctx *eventfd, const char *args)\n{\n\tstruct mem_cgroup_eventfd_list *event;\n\n\tevent = kmalloc(sizeof(*event),\tGFP_KERNEL);\n\tif (!event)\n\t\treturn -ENOMEM;\n\n\tspin_lock(&memcg_oom_lock);\n\n\tevent->eventfd = eventfd;\n\tlist_add(&event->list, &memcg->oom_notify);\n\n\t/* already in OOM ? */\n\tif (memcg->under_oom)\n\t\teventfd_signal(eventfd, 1);\n\tspin_unlock(&memcg_oom_lock);\n\n\treturn 0;\n}\n\nstatic void mem_cgroup_oom_unregister_event(struct mem_cgroup *memcg,\n\tstruct eventfd_ctx *eventfd)\n{\n\tstruct mem_cgroup_eventfd_list *ev, *tmp;\n\n\tspin_lock(&memcg_oom_lock);\n\n\tlist_for_each_entry_safe(ev, tmp, &memcg->oom_notify, list) {\n\t\tif (ev->eventfd == eventfd) {\n\t\t\tlist_del(&ev->list);\n\t\t\tkfree(ev);\n\t\t}\n\t}\n\n\tspin_unlock(&memcg_oom_lock);\n}\n\nstatic int mem_cgroup_oom_control_read(struct seq_file *sf, void *v)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_seq(sf);\n\n\tseq_printf(sf, \"oom_kill_disable %d\\n\", memcg->oom_kill_disable);\n\tseq_printf(sf, \"under_oom %d\\n\", (bool)memcg->under_oom);\n\tseq_printf(sf, \"oom_kill %lu\\n\",\n\t\t   atomic_long_read(&memcg->memory_events[MEMCG_OOM_KILL]));\n\treturn 0;\n}\n\nstatic int mem_cgroup_oom_control_write(struct cgroup_subsys_state *css,\n\tstruct cftype *cft, u64 val)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_css(css);\n\n\t/* cannot set to root cgroup and only 0 and 1 are allowed */\n\tif (!css->parent || !((val == 0) || (val == 1)))\n\t\treturn -EINVAL;\n\n\tmemcg->oom_kill_disable = val;\n\tif (!val)\n\t\tmemcg_oom_recover(memcg);\n\n\treturn 0;\n}\n\n#ifdef CONFIG_CGROUP_WRITEBACK\n\n#include <trace/events/writeback.h>\n\nstatic int memcg_wb_domain_init(struct mem_cgroup *memcg, gfp_t gfp)\n{\n\treturn wb_domain_init(&memcg->cgwb_domain, gfp);\n}\n\nstatic void memcg_wb_domain_exit(struct mem_cgroup *memcg)\n{\n\twb_domain_exit(&memcg->cgwb_domain);\n}\n\nstatic void memcg_wb_domain_size_changed(struct mem_cgroup *memcg)\n{\n\twb_domain_size_changed(&memcg->cgwb_domain);\n}\n\nstruct wb_domain *mem_cgroup_wb_domain(struct bdi_writeback *wb)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_css(wb->memcg_css);\n\n\tif (!memcg->css.parent)\n\t\treturn NULL;\n\n\treturn &memcg->cgwb_domain;\n}\n\n/*\n * idx can be of type enum memcg_stat_item or node_stat_item.\n * Keep in sync with memcg_exact_page().\n */\nstatic unsigned long memcg_exact_page_state(struct mem_cgroup *memcg, int idx)\n{\n\tlong x = atomic_long_read(&memcg->vmstats[idx]);\n\tint cpu;\n\n\tfor_each_online_cpu(cpu)\n\t\tx += per_cpu_ptr(memcg->vmstats_percpu, cpu)->stat[idx];\n\tif (x < 0)\n\t\tx = 0;\n\treturn x;\n}\n\n/**\n * mem_cgroup_wb_stats - retrieve writeback related stats from its memcg\n * @wb: bdi_writeback in question\n * @pfilepages: out parameter for number of file pages\n * @pheadroom: out parameter for number of allocatable pages according to memcg\n * @pdirty: out parameter for number of dirty pages\n * @pwriteback: out parameter for number of pages under writeback\n *\n * Determine the numbers of file, headroom, dirty, and writeback pages in\n * @wb's memcg.  File, dirty and writeback are self-explanatory.  Headroom\n * is a bit more involved.\n *\n * A memcg's headroom is \"min(max, high) - used\".  In the hierarchy, the\n * headroom is calculated as the lowest headroom of itself and the\n * ancestors.  Note that this doesn't consider the actual amount of\n * available memory in the system.  The caller should further cap\n * *@pheadroom accordingly.\n */\nvoid mem_cgroup_wb_stats(struct bdi_writeback *wb, unsigned long *pfilepages,\n\t\t\t unsigned long *pheadroom, unsigned long *pdirty,\n\t\t\t unsigned long *pwriteback)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_css(wb->memcg_css);\n\tstruct mem_cgroup *parent;\n\n\t*pdirty = memcg_exact_page_state(memcg, NR_FILE_DIRTY);\n\n\t*pwriteback = memcg_exact_page_state(memcg, NR_WRITEBACK);\n\t*pfilepages = memcg_exact_page_state(memcg, NR_INACTIVE_FILE) +\n\t\t\tmemcg_exact_page_state(memcg, NR_ACTIVE_FILE);\n\t*pheadroom = PAGE_COUNTER_MAX;\n\n\twhile ((parent = parent_mem_cgroup(memcg))) {\n\t\tunsigned long ceiling = min(READ_ONCE(memcg->memory.max),\n\t\t\t\t\t    READ_ONCE(memcg->memory.high));\n\t\tunsigned long used = page_counter_read(&memcg->memory);\n\n\t\t*pheadroom = min(*pheadroom, ceiling - min(ceiling, used));\n\t\tmemcg = parent;\n\t}\n}\n\n/*\n * Foreign dirty flushing\n *\n * There's an inherent mismatch between memcg and writeback.  The former\n * trackes ownership per-page while the latter per-inode.  This was a\n * deliberate design decision because honoring per-page ownership in the\n * writeback path is complicated, may lead to higher CPU and IO overheads\n * and deemed unnecessary given that write-sharing an inode across\n * different cgroups isn't a common use-case.\n *\n * Combined with inode majority-writer ownership switching, this works well\n * enough in most cases but there are some pathological cases.  For\n * example, let's say there are two cgroups A and B which keep writing to\n * different but confined parts of the same inode.  B owns the inode and\n * A's memory is limited far below B's.  A's dirty ratio can rise enough to\n * trigger balance_dirty_pages() sleeps but B's can be low enough to avoid\n * triggering background writeback.  A will be slowed down without a way to\n * make writeback of the dirty pages happen.\n *\n * Conditions like the above can lead to a cgroup getting repatedly and\n * severely throttled after making some progress after each\n * dirty_expire_interval while the underyling IO device is almost\n * completely idle.\n *\n * Solving this problem completely requires matching the ownership tracking\n * granularities between memcg and writeback in either direction.  However,\n * the more egregious behaviors can be avoided by simply remembering the\n * most recent foreign dirtying events and initiating remote flushes on\n * them when local writeback isn't enough to keep the memory clean enough.\n *\n * The following two functions implement such mechanism.  When a foreign\n * page - a page whose memcg and writeback ownerships don't match - is\n * dirtied, mem_cgroup_track_foreign_dirty() records the inode owning\n * bdi_writeback on the page owning memcg.  When balance_dirty_pages()\n * decides that the memcg needs to sleep due to high dirty ratio, it calls\n * mem_cgroup_flush_foreign() which queues writeback on the recorded\n * foreign bdi_writebacks which haven't expired.  Both the numbers of\n * recorded bdi_writebacks and concurrent in-flight foreign writebacks are\n * limited to MEMCG_CGWB_FRN_CNT.\n *\n * The mechanism only remembers IDs and doesn't hold any object references.\n * As being wrong occasionally doesn't matter, updates and accesses to the\n * records are lockless and racy.\n */\nvoid mem_cgroup_track_foreign_dirty_slowpath(struct page *page,\n\t\t\t\t\t     struct bdi_writeback *wb)\n{\n\tstruct mem_cgroup *memcg = page->mem_cgroup;\n\tstruct memcg_cgwb_frn *frn;\n\tu64 now = get_jiffies_64();\n\tu64 oldest_at = now;\n\tint oldest = -1;\n\tint i;\n\n\ttrace_track_foreign_dirty(page, wb);\n\n\t/*\n\t * Pick the slot to use.  If there is already a slot for @wb, keep\n\t * using it.  If not replace the oldest one which isn't being\n\t * written out.\n\t */\n\tfor (i = 0; i < MEMCG_CGWB_FRN_CNT; i++) {\n\t\tfrn = &memcg->cgwb_frn[i];\n\t\tif (frn->bdi_id == wb->bdi->id &&\n\t\t    frn->memcg_id == wb->memcg_css->id)\n\t\t\tbreak;\n\t\tif (time_before64(frn->at, oldest_at) &&\n\t\t    atomic_read(&frn->done.cnt) == 1) {\n\t\t\toldest = i;\n\t\t\toldest_at = frn->at;\n\t\t}\n\t}\n\n\tif (i < MEMCG_CGWB_FRN_CNT) {\n\t\t/*\n\t\t * Re-using an existing one.  Update timestamp lazily to\n\t\t * avoid making the cacheline hot.  We want them to be\n\t\t * reasonably up-to-date and significantly shorter than\n\t\t * dirty_expire_interval as that's what expires the record.\n\t\t * Use the shorter of 1s and dirty_expire_interval / 8.\n\t\t */\n\t\tunsigned long update_intv =\n\t\t\tmin_t(unsigned long, HZ,\n\t\t\t      msecs_to_jiffies(dirty_expire_interval * 10) / 8);\n\n\t\tif (time_before64(frn->at, now - update_intv))\n\t\t\tfrn->at = now;\n\t} else if (oldest >= 0) {\n\t\t/* replace the oldest free one */\n\t\tfrn = &memcg->cgwb_frn[oldest];\n\t\tfrn->bdi_id = wb->bdi->id;\n\t\tfrn->memcg_id = wb->memcg_css->id;\n\t\tfrn->at = now;\n\t}\n}\n\n/* issue foreign writeback flushes for recorded foreign dirtying events */\nvoid mem_cgroup_flush_foreign(struct bdi_writeback *wb)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_css(wb->memcg_css);\n\tunsigned long intv = msecs_to_jiffies(dirty_expire_interval * 10);\n\tu64 now = jiffies_64;\n\tint i;\n\n\tfor (i = 0; i < MEMCG_CGWB_FRN_CNT; i++) {\n\t\tstruct memcg_cgwb_frn *frn = &memcg->cgwb_frn[i];\n\n\t\t/*\n\t\t * If the record is older than dirty_expire_interval,\n\t\t * writeback on it has already started.  No need to kick it\n\t\t * off again.  Also, don't start a new one if there's\n\t\t * already one in flight.\n\t\t */\n\t\tif (time_after64(frn->at, now - intv) &&\n\t\t    atomic_read(&frn->done.cnt) == 1) {\n\t\t\tfrn->at = 0;\n\t\t\ttrace_flush_foreign(wb, frn->bdi_id, frn->memcg_id);\n\t\t\tcgroup_writeback_by_id(frn->bdi_id, frn->memcg_id, 0,\n\t\t\t\t\t       WB_REASON_FOREIGN_FLUSH,\n\t\t\t\t\t       &frn->done);\n\t\t}\n\t}\n}\n\n#else\t/* CONFIG_CGROUP_WRITEBACK */\n\nstatic int memcg_wb_domain_init(struct mem_cgroup *memcg, gfp_t gfp)\n{\n\treturn 0;\n}\n\nstatic void memcg_wb_domain_exit(struct mem_cgroup *memcg)\n{\n}\n\nstatic void memcg_wb_domain_size_changed(struct mem_cgroup *memcg)\n{\n}\n\n#endif\t/* CONFIG_CGROUP_WRITEBACK */\n\n/*\n * DO NOT USE IN NEW FILES.\n *\n * \"cgroup.event_control\" implementation.\n *\n * This is way over-engineered.  It tries to support fully configurable\n * events for each user.  Such level of flexibility is completely\n * unnecessary especially in the light of the planned unified hierarchy.\n *\n * Please deprecate this and replace with something simpler if at all\n * possible.\n */\n\n/*\n * Unregister event and free resources.\n *\n * Gets called from workqueue.\n */\nstatic void memcg_event_remove(struct work_struct *work)\n{\n\tstruct mem_cgroup_event *event =\n\t\tcontainer_of(work, struct mem_cgroup_event, remove);\n\tstruct mem_cgroup *memcg = event->memcg;\n\n\tremove_wait_queue(event->wqh, &event->wait);\n\n\tevent->unregister_event(memcg, event->eventfd);\n\n\t/* Notify userspace the event is going away. */\n\teventfd_signal(event->eventfd, 1);\n\n\teventfd_ctx_put(event->eventfd);\n\tkfree(event);\n\tcss_put(&memcg->css);\n}\n\n/*\n * Gets called on EPOLLHUP on eventfd when user closes it.\n *\n * Called with wqh->lock held and interrupts disabled.\n */\nstatic int memcg_event_wake(wait_queue_entry_t *wait, unsigned mode,\n\t\t\t    int sync, void *key)\n{\n\tstruct mem_cgroup_event *event =\n\t\tcontainer_of(wait, struct mem_cgroup_event, wait);\n\tstruct mem_cgroup *memcg = event->memcg;\n\t__poll_t flags = key_to_poll(key);\n\n\tif (flags & EPOLLHUP) {\n\t\t/*\n\t\t * If the event has been detached at cgroup removal, we\n\t\t * can simply return knowing the other side will cleanup\n\t\t * for us.\n\t\t *\n\t\t * We can't race against event freeing since the other\n\t\t * side will require wqh->lock via remove_wait_queue(),\n\t\t * which we hold.\n\t\t */\n\t\tspin_lock(&memcg->event_list_lock);\n\t\tif (!list_empty(&event->list)) {\n\t\t\tlist_del_init(&event->list);\n\t\t\t/*\n\t\t\t * We are in atomic context, but cgroup_event_remove()\n\t\t\t * may sleep, so we have to call it in workqueue.\n\t\t\t */\n\t\t\tschedule_work(&event->remove);\n\t\t}\n\t\tspin_unlock(&memcg->event_list_lock);\n\t}\n\n\treturn 0;\n}\n\nstatic void memcg_event_ptable_queue_proc(struct file *file,\n\t\twait_queue_head_t *wqh, poll_table *pt)\n{\n\tstruct mem_cgroup_event *event =\n\t\tcontainer_of(pt, struct mem_cgroup_event, pt);\n\n\tevent->wqh = wqh;\n\tadd_wait_queue(wqh, &event->wait);\n}\n\n/*\n * DO NOT USE IN NEW FILES.\n *\n * Parse input and register new cgroup event handler.\n *\n * Input must be in format '<event_fd> <control_fd> <args>'.\n * Interpretation of args is defined by control file implementation.\n */\nstatic ssize_t memcg_write_event_control(struct kernfs_open_file *of,\n\t\t\t\t\t char *buf, size_t nbytes, loff_t off)\n{\n\tstruct cgroup_subsys_state *css = of_css(of);\n\tstruct mem_cgroup *memcg = mem_cgroup_from_css(css);\n\tstruct mem_cgroup_event *event;\n\tstruct cgroup_subsys_state *cfile_css;\n\tunsigned int efd, cfd;\n\tstruct fd efile;\n\tstruct fd cfile;\n\tconst char *name;\n\tchar *endp;\n\tint ret;\n\n\tbuf = strstrip(buf);\n\n\tefd = simple_strtoul(buf, &endp, 10);\n\tif (*endp != ' ')\n\t\treturn -EINVAL;\n\tbuf = endp + 1;\n\n\tcfd = simple_strtoul(buf, &endp, 10);\n\tif ((*endp != ' ') && (*endp != '\\0'))\n\t\treturn -EINVAL;\n\tbuf = endp + 1;\n\n\tevent = kzalloc(sizeof(*event), GFP_KERNEL);\n\tif (!event)\n\t\treturn -ENOMEM;\n\n\tevent->memcg = memcg;\n\tINIT_LIST_HEAD(&event->list);\n\tinit_poll_funcptr(&event->pt, memcg_event_ptable_queue_proc);\n\tinit_waitqueue_func_entry(&event->wait, memcg_event_wake);\n\tINIT_WORK(&event->remove, memcg_event_remove);\n\n\tefile = fdget(efd);\n\tif (!efile.file) {\n\t\tret = -EBADF;\n\t\tgoto out_kfree;\n\t}\n\n\tevent->eventfd = eventfd_ctx_fileget(efile.file);\n\tif (IS_ERR(event->eventfd)) {\n\t\tret = PTR_ERR(event->eventfd);\n\t\tgoto out_put_efile;\n\t}\n\n\tcfile = fdget(cfd);\n\tif (!cfile.file) {\n\t\tret = -EBADF;\n\t\tgoto out_put_eventfd;\n\t}\n\n\t/* the process need read permission on control file */\n\t/* AV: shouldn't we check that it's been opened for read instead? */\n\tret = inode_permission(file_inode(cfile.file), MAY_READ);\n\tif (ret < 0)\n\t\tgoto out_put_cfile;\n\n\t/*\n\t * Determine the event callbacks and set them in @event.  This used\n\t * to be done via struct cftype but cgroup core no longer knows\n\t * about these events.  The following is crude but the whole thing\n\t * is for compatibility anyway.\n\t *\n\t * DO NOT ADD NEW FILES.\n\t */\n\tname = cfile.file->f_path.dentry->d_name.name;\n\n\tif (!strcmp(name, \"memory.usage_in_bytes\")) {\n\t\tevent->register_event = mem_cgroup_usage_register_event;\n\t\tevent->unregister_event = mem_cgroup_usage_unregister_event;\n\t} else if (!strcmp(name, \"memory.oom_control\")) {\n\t\tevent->register_event = mem_cgroup_oom_register_event;\n\t\tevent->unregister_event = mem_cgroup_oom_unregister_event;\n\t} else if (!strcmp(name, \"memory.pressure_level\")) {\n\t\tevent->register_event = vmpressure_register_event;\n\t\tevent->unregister_event = vmpressure_unregister_event;\n\t} else if (!strcmp(name, \"memory.memsw.usage_in_bytes\")) {\n\t\tevent->register_event = memsw_cgroup_usage_register_event;\n\t\tevent->unregister_event = memsw_cgroup_usage_unregister_event;\n\t} else {\n\t\tret = -EINVAL;\n\t\tgoto out_put_cfile;\n\t}\n\n\t/*\n\t * Verify @cfile should belong to @css.  Also, remaining events are\n\t * automatically removed on cgroup destruction but the removal is\n\t * asynchronous, so take an extra ref on @css.\n\t */\n\tcfile_css = css_tryget_online_from_dir(cfile.file->f_path.dentry->d_parent,\n\t\t\t\t\t       &memory_cgrp_subsys);\n\tret = -EINVAL;\n\tif (IS_ERR(cfile_css))\n\t\tgoto out_put_cfile;\n\tif (cfile_css != css) {\n\t\tcss_put(cfile_css);\n\t\tgoto out_put_cfile;\n\t}\n\n\tret = event->register_event(memcg, event->eventfd, buf);\n\tif (ret)\n\t\tgoto out_put_css;\n\n\tvfs_poll(efile.file, &event->pt);\n\n\tspin_lock(&memcg->event_list_lock);\n\tlist_add(&event->list, &memcg->event_list);\n\tspin_unlock(&memcg->event_list_lock);\n\n\tfdput(cfile);\n\tfdput(efile);\n\n\treturn nbytes;\n\nout_put_css:\n\tcss_put(css);\nout_put_cfile:\n\tfdput(cfile);\nout_put_eventfd:\n\teventfd_ctx_put(event->eventfd);\nout_put_efile:\n\tfdput(efile);\nout_kfree:\n\tkfree(event);\n\n\treturn ret;\n}\n\nstatic struct cftype mem_cgroup_legacy_files[] = {\n\t{\n\t\t.name = \"usage_in_bytes\",\n\t\t.private = MEMFILE_PRIVATE(_MEM, RES_USAGE),\n\t\t.read_u64 = mem_cgroup_read_u64,\n\t},\n\t{\n\t\t.name = \"max_usage_in_bytes\",\n\t\t.private = MEMFILE_PRIVATE(_MEM, RES_MAX_USAGE),\n\t\t.write = mem_cgroup_reset,\n\t\t.read_u64 = mem_cgroup_read_u64,\n\t},\n\t{\n\t\t.name = \"limit_in_bytes\",\n\t\t.private = MEMFILE_PRIVATE(_MEM, RES_LIMIT),\n\t\t.write = mem_cgroup_write,\n\t\t.read_u64 = mem_cgroup_read_u64,\n\t},\n\t{\n\t\t.name = \"soft_limit_in_bytes\",\n\t\t.private = MEMFILE_PRIVATE(_MEM, RES_SOFT_LIMIT),\n\t\t.write = mem_cgroup_write,\n\t\t.read_u64 = mem_cgroup_read_u64,\n\t},\n\t{\n\t\t.name = \"failcnt\",\n\t\t.private = MEMFILE_PRIVATE(_MEM, RES_FAILCNT),\n\t\t.write = mem_cgroup_reset,\n\t\t.read_u64 = mem_cgroup_read_u64,\n\t},\n\t{\n\t\t.name = \"stat\",\n\t\t.seq_show = memcg_stat_show,\n\t},\n\t{\n\t\t.name = \"force_empty\",\n\t\t.write = mem_cgroup_force_empty_write,\n\t},\n\t{\n\t\t.name = \"use_hierarchy\",\n\t\t.write_u64 = mem_cgroup_hierarchy_write,\n\t\t.read_u64 = mem_cgroup_hierarchy_read,\n\t},\n\t{\n\t\t.name = \"cgroup.event_control\",\t\t/* XXX: for compat */\n\t\t.write = memcg_write_event_control,\n\t\t.flags = CFTYPE_NO_PREFIX | CFTYPE_WORLD_WRITABLE,\n\t},\n\t{\n\t\t.name = \"swappiness\",\n\t\t.read_u64 = mem_cgroup_swappiness_read,\n\t\t.write_u64 = mem_cgroup_swappiness_write,\n\t},\n\t{\n\t\t.name = \"move_charge_at_immigrate\",\n\t\t.read_u64 = mem_cgroup_move_charge_read,\n\t\t.write_u64 = mem_cgroup_move_charge_write,\n\t},\n\t{\n\t\t.name = \"oom_control\",\n\t\t.seq_show = mem_cgroup_oom_control_read,\n\t\t.write_u64 = mem_cgroup_oom_control_write,\n\t\t.private = MEMFILE_PRIVATE(_OOM_TYPE, OOM_CONTROL),\n\t},\n\t{\n\t\t.name = \"pressure_level\",\n\t},\n#ifdef CONFIG_NUMA\n\t{\n\t\t.name = \"numa_stat\",\n\t\t.seq_show = memcg_numa_stat_show,\n\t},\n#endif\n\t{\n\t\t.name = \"kmem.limit_in_bytes\",\n\t\t.private = MEMFILE_PRIVATE(_KMEM, RES_LIMIT),\n\t\t.write = mem_cgroup_write,\n\t\t.read_u64 = mem_cgroup_read_u64,\n\t},\n\t{\n\t\t.name = \"kmem.usage_in_bytes\",\n\t\t.private = MEMFILE_PRIVATE(_KMEM, RES_USAGE),\n\t\t.read_u64 = mem_cgroup_read_u64,\n\t},\n\t{\n\t\t.name = \"kmem.failcnt\",\n\t\t.private = MEMFILE_PRIVATE(_KMEM, RES_FAILCNT),\n\t\t.write = mem_cgroup_reset,\n\t\t.read_u64 = mem_cgroup_read_u64,\n\t},\n\t{\n\t\t.name = \"kmem.max_usage_in_bytes\",\n\t\t.private = MEMFILE_PRIVATE(_KMEM, RES_MAX_USAGE),\n\t\t.write = mem_cgroup_reset,\n\t\t.read_u64 = mem_cgroup_read_u64,\n\t},\n#if defined(CONFIG_MEMCG_KMEM) && \\\n\t(defined(CONFIG_SLAB) || defined(CONFIG_SLUB_DEBUG))\n\t{\n\t\t.name = \"kmem.slabinfo\",\n\t\t.seq_show = memcg_slab_show,\n\t},\n#endif\n\t{\n\t\t.name = \"kmem.tcp.limit_in_bytes\",\n\t\t.private = MEMFILE_PRIVATE(_TCP, RES_LIMIT),\n\t\t.write = mem_cgroup_write,\n\t\t.read_u64 = mem_cgroup_read_u64,\n\t},\n\t{\n\t\t.name = \"kmem.tcp.usage_in_bytes\",\n\t\t.private = MEMFILE_PRIVATE(_TCP, RES_USAGE),\n\t\t.read_u64 = mem_cgroup_read_u64,\n\t},\n\t{\n\t\t.name = \"kmem.tcp.failcnt\",\n\t\t.private = MEMFILE_PRIVATE(_TCP, RES_FAILCNT),\n\t\t.write = mem_cgroup_reset,\n\t\t.read_u64 = mem_cgroup_read_u64,\n\t},\n\t{\n\t\t.name = \"kmem.tcp.max_usage_in_bytes\",\n\t\t.private = MEMFILE_PRIVATE(_TCP, RES_MAX_USAGE),\n\t\t.write = mem_cgroup_reset,\n\t\t.read_u64 = mem_cgroup_read_u64,\n\t},\n\t{ },\t/* terminate */\n};\n\n/*\n * Private memory cgroup IDR\n *\n * Swap-out records and page cache shadow entries need to store memcg\n * references in constrained space, so we maintain an ID space that is\n * limited to 16 bit (MEM_CGROUP_ID_MAX), limiting the total number of\n * memory-controlled cgroups to 64k.\n *\n * However, there usually are many references to the offline CSS after\n * the cgroup has been destroyed, such as page cache or reclaimable\n * slab objects, that don't need to hang on to the ID. We want to keep\n * those dead CSS from occupying IDs, or we might quickly exhaust the\n * relatively small ID space and prevent the creation of new cgroups\n * even when there are much fewer than 64k cgroups - possibly none.\n *\n * Maintain a private 16-bit ID space for memcg, and allow the ID to\n * be freed and recycled when it's no longer needed, which is usually\n * when the CSS is offlined.\n *\n * The only exception to that are records of swapped out tmpfs/shmem\n * pages that need to be attributed to live ancestors on swapin. But\n * those references are manageable from userspace.\n */\n\nstatic DEFINE_IDR(mem_cgroup_idr);\n\nstatic void mem_cgroup_id_remove(struct mem_cgroup *memcg)\n{\n\tif (memcg->id.id > 0) {\n\t\tidr_remove(&mem_cgroup_idr, memcg->id.id);\n\t\tmemcg->id.id = 0;\n\t}\n}\n\nstatic void __maybe_unused mem_cgroup_id_get_many(struct mem_cgroup *memcg,\n\t\t\t\t\t\t  unsigned int n)\n{\n\trefcount_add(n, &memcg->id.ref);\n}\n\nstatic void mem_cgroup_id_put_many(struct mem_cgroup *memcg, unsigned int n)\n{\n\tif (refcount_sub_and_test(n, &memcg->id.ref)) {\n\t\tmem_cgroup_id_remove(memcg);\n\n\t\t/* Memcg ID pins CSS */\n\t\tcss_put(&memcg->css);\n\t}\n}\n\nstatic inline void mem_cgroup_id_put(struct mem_cgroup *memcg)\n{\n\tmem_cgroup_id_put_many(memcg, 1);\n}\n\n/**\n * mem_cgroup_from_id - look up a memcg from a memcg id\n * @id: the memcg id to look up\n *\n * Caller must hold rcu_read_lock().\n */\nstruct mem_cgroup *mem_cgroup_from_id(unsigned short id)\n{\n\tWARN_ON_ONCE(!rcu_read_lock_held());\n\treturn idr_find(&mem_cgroup_idr, id);\n}\n\nstatic int alloc_mem_cgroup_per_node_info(struct mem_cgroup *memcg, int node)\n{\n\tstruct mem_cgroup_per_node *pn;\n\tint tmp = node;\n\t/*\n\t * This routine is called against possible nodes.\n\t * But it's BUG to call kmalloc() against offline node.\n\t *\n\t * TODO: this routine can waste much memory for nodes which will\n\t *       never be onlined. It's better to use memory hotplug callback\n\t *       function.\n\t */\n\tif (!node_state(node, N_NORMAL_MEMORY))\n\t\ttmp = -1;\n\tpn = kzalloc_node(sizeof(*pn), GFP_KERNEL, tmp);\n\tif (!pn)\n\t\treturn 1;\n\n\tpn->lruvec_stat_local = alloc_percpu_gfp(struct lruvec_stat,\n\t\t\t\t\t\t GFP_KERNEL_ACCOUNT);\n\tif (!pn->lruvec_stat_local) {\n\t\tkfree(pn);\n\t\treturn 1;\n\t}\n\n\tpn->lruvec_stat_cpu = alloc_percpu_gfp(struct lruvec_stat,\n\t\t\t\t\t       GFP_KERNEL_ACCOUNT);\n\tif (!pn->lruvec_stat_cpu) {\n\t\tfree_percpu(pn->lruvec_stat_local);\n\t\tkfree(pn);\n\t\treturn 1;\n\t}\n\n\tlruvec_init(&pn->lruvec);\n\tpn->usage_in_excess = 0;\n\tpn->on_tree = false;\n\tpn->memcg = memcg;\n\n\tmemcg->nodeinfo[node] = pn;\n\treturn 0;\n}\n\nstatic void free_mem_cgroup_per_node_info(struct mem_cgroup *memcg, int node)\n{\n\tstruct mem_cgroup_per_node *pn = memcg->nodeinfo[node];\n\n\tif (!pn)\n\t\treturn;\n\n\tfree_percpu(pn->lruvec_stat_cpu);\n\tfree_percpu(pn->lruvec_stat_local);\n\tkfree(pn);\n}\n\nstatic void __mem_cgroup_free(struct mem_cgroup *memcg)\n{\n\tint node;\n\n\tfor_each_node(node)\n\t\tfree_mem_cgroup_per_node_info(memcg, node);\n\tfree_percpu(memcg->vmstats_percpu);\n\tfree_percpu(memcg->vmstats_local);\n\tkfree(memcg);\n}\n\nstatic void mem_cgroup_free(struct mem_cgroup *memcg)\n{\n\tmemcg_wb_domain_exit(memcg);\n\t/*\n\t * Flush percpu vmstats and vmevents to guarantee the value correctness\n\t * on parent's and all ancestor levels.\n\t */\n\tmemcg_flush_percpu_vmstats(memcg);\n\tmemcg_flush_percpu_vmevents(memcg);\n\t__mem_cgroup_free(memcg);\n}\n\nstatic struct mem_cgroup *mem_cgroup_alloc(void)\n{\n\tstruct mem_cgroup *memcg;\n\tunsigned int size;\n\tint node;\n\tint __maybe_unused i;\n\tlong error = -ENOMEM;\n\n\tsize = sizeof(struct mem_cgroup);\n\tsize += nr_node_ids * sizeof(struct mem_cgroup_per_node *);\n\n\tmemcg = kzalloc(size, GFP_KERNEL);\n\tif (!memcg)\n\t\treturn ERR_PTR(error);\n\n\tmemcg->id.id = idr_alloc(&mem_cgroup_idr, NULL,\n\t\t\t\t 1, MEM_CGROUP_ID_MAX,\n\t\t\t\t GFP_KERNEL);\n\tif (memcg->id.id < 0) {\n\t\terror = memcg->id.id;\n\t\tgoto fail;\n\t}\n\n\tmemcg->vmstats_local = alloc_percpu_gfp(struct memcg_vmstats_percpu,\n\t\t\t\t\t\tGFP_KERNEL_ACCOUNT);\n\tif (!memcg->vmstats_local)\n\t\tgoto fail;\n\n\tmemcg->vmstats_percpu = alloc_percpu_gfp(struct memcg_vmstats_percpu,\n\t\t\t\t\t\t GFP_KERNEL_ACCOUNT);\n\tif (!memcg->vmstats_percpu)\n\t\tgoto fail;\n\n\tfor_each_node(node)\n\t\tif (alloc_mem_cgroup_per_node_info(memcg, node))\n\t\t\tgoto fail;\n\n\tif (memcg_wb_domain_init(memcg, GFP_KERNEL))\n\t\tgoto fail;\n\n\tINIT_WORK(&memcg->high_work, high_work_func);\n\tINIT_LIST_HEAD(&memcg->oom_notify);\n\tmutex_init(&memcg->thresholds_lock);\n\tspin_lock_init(&memcg->move_lock);\n\tvmpressure_init(&memcg->vmpressure);\n\tINIT_LIST_HEAD(&memcg->event_list);\n\tspin_lock_init(&memcg->event_list_lock);\n\tmemcg->socket_pressure = jiffies;\n#ifdef CONFIG_MEMCG_KMEM\n\tmemcg->kmemcg_id = -1;\n\tINIT_LIST_HEAD(&memcg->objcg_list);\n#endif\n#ifdef CONFIG_CGROUP_WRITEBACK\n\tINIT_LIST_HEAD(&memcg->cgwb_list);\n\tfor (i = 0; i < MEMCG_CGWB_FRN_CNT; i++)\n\t\tmemcg->cgwb_frn[i].done =\n\t\t\t__WB_COMPLETION_INIT(&memcg_cgwb_frn_waitq);\n#endif\n#ifdef CONFIG_TRANSPARENT_HUGEPAGE\n\tspin_lock_init(&memcg->deferred_split_queue.split_queue_lock);\n\tINIT_LIST_HEAD(&memcg->deferred_split_queue.split_queue);\n\tmemcg->deferred_split_queue.split_queue_len = 0;\n#endif\n\tidr_replace(&mem_cgroup_idr, memcg, memcg->id.id);\n\treturn memcg;\nfail:\n\tmem_cgroup_id_remove(memcg);\n\t__mem_cgroup_free(memcg);\n\treturn ERR_PTR(error);\n}\n\nstatic struct cgroup_subsys_state * __ref\nmem_cgroup_css_alloc(struct cgroup_subsys_state *parent_css)\n{\n\tstruct mem_cgroup *parent = mem_cgroup_from_css(parent_css);\n\tstruct mem_cgroup *memcg, *old_memcg;\n\tlong error = -ENOMEM;\n\n\told_memcg = set_active_memcg(parent);\n\tmemcg = mem_cgroup_alloc();\n\tset_active_memcg(old_memcg);\n\tif (IS_ERR(memcg))\n\t\treturn ERR_CAST(memcg);\n\n\tpage_counter_set_high(&memcg->memory, PAGE_COUNTER_MAX);\n\tmemcg->soft_limit = PAGE_COUNTER_MAX;\n\tpage_counter_set_high(&memcg->swap, PAGE_COUNTER_MAX);\n\tif (parent) {\n\t\tmemcg->swappiness = mem_cgroup_swappiness(parent);\n\t\tmemcg->oom_kill_disable = parent->oom_kill_disable;\n\t}\n\tif (parent && parent->use_hierarchy) {\n\t\tmemcg->use_hierarchy = true;\n\t\tpage_counter_init(&memcg->memory, &parent->memory);\n\t\tpage_counter_init(&memcg->swap, &parent->swap);\n\t\tpage_counter_init(&memcg->kmem, &parent->kmem);\n\t\tpage_counter_init(&memcg->tcpmem, &parent->tcpmem);\n\t} else {\n\t\tpage_counter_init(&memcg->memory, NULL);\n\t\tpage_counter_init(&memcg->swap, NULL);\n\t\tpage_counter_init(&memcg->kmem, NULL);\n\t\tpage_counter_init(&memcg->tcpmem, NULL);\n\t\t/*\n\t\t * Deeper hierachy with use_hierarchy == false doesn't make\n\t\t * much sense so let cgroup subsystem know about this\n\t\t * unfortunate state in our controller.\n\t\t */\n\t\tif (parent != root_mem_cgroup)\n\t\t\tmemory_cgrp_subsys.broken_hierarchy = true;\n\t}\n\n\t/* The following stuff does not apply to the root */\n\tif (!parent) {\n\t\troot_mem_cgroup = memcg;\n\t\treturn &memcg->css;\n\t}\n\n\terror = memcg_online_kmem(memcg);\n\tif (error)\n\t\tgoto fail;\n\n\tif (cgroup_subsys_on_dfl(memory_cgrp_subsys) && !cgroup_memory_nosocket)\n\t\tstatic_branch_inc(&memcg_sockets_enabled_key);\n\n\treturn &memcg->css;\nfail:\n\tmem_cgroup_id_remove(memcg);\n\tmem_cgroup_free(memcg);\n\treturn ERR_PTR(error);\n}\n\nstatic int mem_cgroup_css_online(struct cgroup_subsys_state *css)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_css(css);\n\n\t/*\n\t * A memcg must be visible for memcg_expand_shrinker_maps()\n\t * by the time the maps are allocated. So, we allocate maps\n\t * here, when for_each_mem_cgroup() can't skip it.\n\t */\n\tif (memcg_alloc_shrinker_maps(memcg)) {\n\t\tmem_cgroup_id_remove(memcg);\n\t\treturn -ENOMEM;\n\t}\n\n\t/* Online state pins memcg ID, memcg ID pins CSS */\n\trefcount_set(&memcg->id.ref, 1);\n\tcss_get(css);\n\treturn 0;\n}\n\nstatic void mem_cgroup_css_offline(struct cgroup_subsys_state *css)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_css(css);\n\tstruct mem_cgroup_event *event, *tmp;\n\n\t/*\n\t * Unregister events and notify userspace.\n\t * Notify userspace about cgroup removing only after rmdir of cgroup\n\t * directory to avoid race between userspace and kernelspace.\n\t */\n\tspin_lock(&memcg->event_list_lock);\n\tlist_for_each_entry_safe(event, tmp, &memcg->event_list, list) {\n\t\tlist_del_init(&event->list);\n\t\tschedule_work(&event->remove);\n\t}\n\tspin_unlock(&memcg->event_list_lock);\n\n\tpage_counter_set_min(&memcg->memory, 0);\n\tpage_counter_set_low(&memcg->memory, 0);\n\n\tmemcg_offline_kmem(memcg);\n\twb_memcg_offline(memcg);\n\n\tdrain_all_stock(memcg);\n\n\tmem_cgroup_id_put(memcg);\n}\n\nstatic void mem_cgroup_css_released(struct cgroup_subsys_state *css)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_css(css);\n\n\tinvalidate_reclaim_iterators(memcg);\n}\n\nstatic void mem_cgroup_css_free(struct cgroup_subsys_state *css)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_css(css);\n\tint __maybe_unused i;\n\n#ifdef CONFIG_CGROUP_WRITEBACK\n\tfor (i = 0; i < MEMCG_CGWB_FRN_CNT; i++)\n\t\twb_wait_for_completion(&memcg->cgwb_frn[i].done);\n#endif\n\tif (cgroup_subsys_on_dfl(memory_cgrp_subsys) && !cgroup_memory_nosocket)\n\t\tstatic_branch_dec(&memcg_sockets_enabled_key);\n\n\tif (!cgroup_subsys_on_dfl(memory_cgrp_subsys) && memcg->tcpmem_active)\n\t\tstatic_branch_dec(&memcg_sockets_enabled_key);\n\n\tvmpressure_cleanup(&memcg->vmpressure);\n\tcancel_work_sync(&memcg->high_work);\n\tmem_cgroup_remove_from_trees(memcg);\n\tmemcg_free_shrinker_maps(memcg);\n\tmemcg_free_kmem(memcg);\n\tmem_cgroup_free(memcg);\n}\n\n/**\n * mem_cgroup_css_reset - reset the states of a mem_cgroup\n * @css: the target css\n *\n * Reset the states of the mem_cgroup associated with @css.  This is\n * invoked when the userland requests disabling on the default hierarchy\n * but the memcg is pinned through dependency.  The memcg should stop\n * applying policies and should revert to the vanilla state as it may be\n * made visible again.\n *\n * The current implementation only resets the essential configurations.\n * This needs to be expanded to cover all the visible parts.\n */\nstatic void mem_cgroup_css_reset(struct cgroup_subsys_state *css)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_css(css);\n\n\tpage_counter_set_max(&memcg->memory, PAGE_COUNTER_MAX);\n\tpage_counter_set_max(&memcg->swap, PAGE_COUNTER_MAX);\n\tpage_counter_set_max(&memcg->kmem, PAGE_COUNTER_MAX);\n\tpage_counter_set_max(&memcg->tcpmem, PAGE_COUNTER_MAX);\n\tpage_counter_set_min(&memcg->memory, 0);\n\tpage_counter_set_low(&memcg->memory, 0);\n\tpage_counter_set_high(&memcg->memory, PAGE_COUNTER_MAX);\n\tmemcg->soft_limit = PAGE_COUNTER_MAX;\n\tpage_counter_set_high(&memcg->swap, PAGE_COUNTER_MAX);\n\tmemcg_wb_domain_size_changed(memcg);\n}\n\n#ifdef CONFIG_MMU\n/* Handlers for move charge at task migration. */\nstatic int mem_cgroup_do_precharge(unsigned long count)\n{\n\tint ret;\n\n\t/* Try a single bulk charge without reclaim first, kswapd may wake */\n\tret = try_charge(mc.to, GFP_KERNEL & ~__GFP_DIRECT_RECLAIM, count);\n\tif (!ret) {\n\t\tmc.precharge += count;\n\t\treturn ret;\n\t}\n\n\t/* Try charges one by one with reclaim, but do not retry */\n\twhile (count--) {\n\t\tret = try_charge(mc.to, GFP_KERNEL | __GFP_NORETRY, 1);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tmc.precharge++;\n\t\tcond_resched();\n\t}\n\treturn 0;\n}\n\nunion mc_target {\n\tstruct page\t*page;\n\tswp_entry_t\tent;\n};\n\nenum mc_target_type {\n\tMC_TARGET_NONE = 0,\n\tMC_TARGET_PAGE,\n\tMC_TARGET_SWAP,\n\tMC_TARGET_DEVICE,\n};\n\nstatic struct page *mc_handle_present_pte(struct vm_area_struct *vma,\n\t\t\t\t\t\tunsigned long addr, pte_t ptent)\n{\n\tstruct page *page = vm_normal_page(vma, addr, ptent);\n\n\tif (!page || !page_mapped(page))\n\t\treturn NULL;\n\tif (PageAnon(page)) {\n\t\tif (!(mc.flags & MOVE_ANON))\n\t\t\treturn NULL;\n\t} else {\n\t\tif (!(mc.flags & MOVE_FILE))\n\t\t\treturn NULL;\n\t}\n\tif (!get_page_unless_zero(page))\n\t\treturn NULL;\n\n\treturn page;\n}\n\n#if defined(CONFIG_SWAP) || defined(CONFIG_DEVICE_PRIVATE)\nstatic struct page *mc_handle_swap_pte(struct vm_area_struct *vma,\n\t\t\tpte_t ptent, swp_entry_t *entry)\n{\n\tstruct page *page = NULL;\n\tswp_entry_t ent = pte_to_swp_entry(ptent);\n\n\tif (!(mc.flags & MOVE_ANON))\n\t\treturn NULL;\n\n\t/*\n\t * Handle MEMORY_DEVICE_PRIVATE which are ZONE_DEVICE page belonging to\n\t * a device and because they are not accessible by CPU they are store\n\t * as special swap entry in the CPU page table.\n\t */\n\tif (is_device_private_entry(ent)) {\n\t\tpage = device_private_entry_to_page(ent);\n\t\t/*\n\t\t * MEMORY_DEVICE_PRIVATE means ZONE_DEVICE page and which have\n\t\t * a refcount of 1 when free (unlike normal page)\n\t\t */\n\t\tif (!page_ref_add_unless(page, 1, 1))\n\t\t\treturn NULL;\n\t\treturn page;\n\t}\n\n\tif (non_swap_entry(ent))\n\t\treturn NULL;\n\n\t/*\n\t * Because lookup_swap_cache() updates some statistics counter,\n\t * we call find_get_page() with swapper_space directly.\n\t */\n\tpage = find_get_page(swap_address_space(ent), swp_offset(ent));\n\tentry->val = ent.val;\n\n\treturn page;\n}\n#else\nstatic struct page *mc_handle_swap_pte(struct vm_area_struct *vma,\n\t\t\tpte_t ptent, swp_entry_t *entry)\n{\n\treturn NULL;\n}\n#endif\n\nstatic struct page *mc_handle_file_pte(struct vm_area_struct *vma,\n\t\t\tunsigned long addr, pte_t ptent, swp_entry_t *entry)\n{\n\tif (!vma->vm_file) /* anonymous vma */\n\t\treturn NULL;\n\tif (!(mc.flags & MOVE_FILE))\n\t\treturn NULL;\n\n\t/* page is moved even if it's not RSS of this task(page-faulted). */\n\t/* shmem/tmpfs may report page out on swap: account for that too. */\n\treturn find_get_incore_page(vma->vm_file->f_mapping,\n\t\t\tlinear_page_index(vma, addr));\n}\n\n/**\n * mem_cgroup_move_account - move account of the page\n * @page: the page\n * @compound: charge the page as compound or small page\n * @from: mem_cgroup which the page is moved from.\n * @to:\tmem_cgroup which the page is moved to. @from != @to.\n *\n * The caller must make sure the page is not on LRU (isolate_page() is useful.)\n *\n * This function doesn't do \"charge\" to new cgroup and doesn't do \"uncharge\"\n * from old cgroup.\n */\nstatic int mem_cgroup_move_account(struct page *page,\n\t\t\t\t   bool compound,\n\t\t\t\t   struct mem_cgroup *from,\n\t\t\t\t   struct mem_cgroup *to)\n{\n\tstruct lruvec *from_vec, *to_vec;\n\tstruct pglist_data *pgdat;\n\tunsigned int nr_pages = compound ? thp_nr_pages(page) : 1;\n\tint ret;\n\n\tVM_BUG_ON(from == to);\n\tVM_BUG_ON_PAGE(PageLRU(page), page);\n\tVM_BUG_ON(compound && !PageTransHuge(page));\n\n\t/*\n\t * Prevent mem_cgroup_migrate() from looking at\n\t * page->mem_cgroup of its source page while we change it.\n\t */\n\tret = -EBUSY;\n\tif (!trylock_page(page))\n\t\tgoto out;\n\n\tret = -EINVAL;\n\tif (page->mem_cgroup != from)\n\t\tgoto out_unlock;\n\n\tpgdat = page_pgdat(page);\n\tfrom_vec = mem_cgroup_lruvec(from, pgdat);\n\tto_vec = mem_cgroup_lruvec(to, pgdat);\n\n\tlock_page_memcg(page);\n\n\tif (PageAnon(page)) {\n\t\tif (page_mapped(page)) {\n\t\t\t__mod_lruvec_state(from_vec, NR_ANON_MAPPED, -nr_pages);\n\t\t\t__mod_lruvec_state(to_vec, NR_ANON_MAPPED, nr_pages);\n\t\t\tif (PageTransHuge(page)) {\n\t\t\t\t__mod_lruvec_state(from_vec, NR_ANON_THPS,\n\t\t\t\t\t\t   -nr_pages);\n\t\t\t\t__mod_lruvec_state(to_vec, NR_ANON_THPS,\n\t\t\t\t\t\t   nr_pages);\n\t\t\t}\n\n\t\t}\n\t} else {\n\t\t__mod_lruvec_state(from_vec, NR_FILE_PAGES, -nr_pages);\n\t\t__mod_lruvec_state(to_vec, NR_FILE_PAGES, nr_pages);\n\n\t\tif (PageSwapBacked(page)) {\n\t\t\t__mod_lruvec_state(from_vec, NR_SHMEM, -nr_pages);\n\t\t\t__mod_lruvec_state(to_vec, NR_SHMEM, nr_pages);\n\t\t}\n\n\t\tif (page_mapped(page)) {\n\t\t\t__mod_lruvec_state(from_vec, NR_FILE_MAPPED, -nr_pages);\n\t\t\t__mod_lruvec_state(to_vec, NR_FILE_MAPPED, nr_pages);\n\t\t}\n\n\t\tif (PageDirty(page)) {\n\t\t\tstruct address_space *mapping = page_mapping(page);\n\n\t\t\tif (mapping_can_writeback(mapping)) {\n\t\t\t\t__mod_lruvec_state(from_vec, NR_FILE_DIRTY,\n\t\t\t\t\t\t   -nr_pages);\n\t\t\t\t__mod_lruvec_state(to_vec, NR_FILE_DIRTY,\n\t\t\t\t\t\t   nr_pages);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (PageWriteback(page)) {\n\t\t__mod_lruvec_state(from_vec, NR_WRITEBACK, -nr_pages);\n\t\t__mod_lruvec_state(to_vec, NR_WRITEBACK, nr_pages);\n\t}\n\n\t/*\n\t * All state has been migrated, let's switch to the new memcg.\n\t *\n\t * It is safe to change page->mem_cgroup here because the page\n\t * is referenced, charged, isolated, and locked: we can't race\n\t * with (un)charging, migration, LRU putback, or anything else\n\t * that would rely on a stable page->mem_cgroup.\n\t *\n\t * Note that lock_page_memcg is a memcg lock, not a page lock,\n\t * to save space. As soon as we switch page->mem_cgroup to a\n\t * new memcg that isn't locked, the above state can change\n\t * concurrently again. Make sure we're truly done with it.\n\t */\n\tsmp_mb();\n\n\tcss_get(&to->css);\n\tcss_put(&from->css);\n\n\tpage->mem_cgroup = to;\n\n\t__unlock_page_memcg(from);\n\n\tret = 0;\n\n\tlocal_irq_disable();\n\tmem_cgroup_charge_statistics(to, page, nr_pages);\n\tmemcg_check_events(to, page);\n\tmem_cgroup_charge_statistics(from, page, -nr_pages);\n\tmemcg_check_events(from, page);\n\tlocal_irq_enable();\nout_unlock:\n\tunlock_page(page);\nout:\n\treturn ret;\n}\n\n/**\n * get_mctgt_type - get target type of moving charge\n * @vma: the vma the pte to be checked belongs\n * @addr: the address corresponding to the pte to be checked\n * @ptent: the pte to be checked\n * @target: the pointer the target page or swap ent will be stored(can be NULL)\n *\n * Returns\n *   0(MC_TARGET_NONE): if the pte is not a target for move charge.\n *   1(MC_TARGET_PAGE): if the page corresponding to this pte is a target for\n *     move charge. if @target is not NULL, the page is stored in target->page\n *     with extra refcnt got(Callers should handle it).\n *   2(MC_TARGET_SWAP): if the swap entry corresponding to this pte is a\n *     target for charge migration. if @target is not NULL, the entry is stored\n *     in target->ent.\n *   3(MC_TARGET_DEVICE): like MC_TARGET_PAGE  but page is MEMORY_DEVICE_PRIVATE\n *     (so ZONE_DEVICE page and thus not on the lru).\n *     For now we such page is charge like a regular page would be as for all\n *     intent and purposes it is just special memory taking the place of a\n *     regular page.\n *\n *     See Documentations/vm/hmm.txt and include/linux/hmm.h\n *\n * Called with pte lock held.\n */\n\nstatic enum mc_target_type get_mctgt_type(struct vm_area_struct *vma,\n\t\tunsigned long addr, pte_t ptent, union mc_target *target)\n{\n\tstruct page *page = NULL;\n\tenum mc_target_type ret = MC_TARGET_NONE;\n\tswp_entry_t ent = { .val = 0 };\n\n\tif (pte_present(ptent))\n\t\tpage = mc_handle_present_pte(vma, addr, ptent);\n\telse if (is_swap_pte(ptent))\n\t\tpage = mc_handle_swap_pte(vma, ptent, &ent);\n\telse if (pte_none(ptent))\n\t\tpage = mc_handle_file_pte(vma, addr, ptent, &ent);\n\n\tif (!page && !ent.val)\n\t\treturn ret;\n\tif (page) {\n\t\t/*\n\t\t * Do only loose check w/o serialization.\n\t\t * mem_cgroup_move_account() checks the page is valid or\n\t\t * not under LRU exclusion.\n\t\t */\n\t\tif (page->mem_cgroup == mc.from) {\n\t\t\tret = MC_TARGET_PAGE;\n\t\t\tif (is_device_private_page(page))\n\t\t\t\tret = MC_TARGET_DEVICE;\n\t\t\tif (target)\n\t\t\t\ttarget->page = page;\n\t\t}\n\t\tif (!ret || !target)\n\t\t\tput_page(page);\n\t}\n\t/*\n\t * There is a swap entry and a page doesn't exist or isn't charged.\n\t * But we cannot move a tail-page in a THP.\n\t */\n\tif (ent.val && !ret && (!page || !PageTransCompound(page)) &&\n\t    mem_cgroup_id(mc.from) == lookup_swap_cgroup_id(ent)) {\n\t\tret = MC_TARGET_SWAP;\n\t\tif (target)\n\t\t\ttarget->ent = ent;\n\t}\n\treturn ret;\n}\n\n#ifdef CONFIG_TRANSPARENT_HUGEPAGE\n/*\n * We don't consider PMD mapped swapping or file mapped pages because THP does\n * not support them for now.\n * Caller should make sure that pmd_trans_huge(pmd) is true.\n */\nstatic enum mc_target_type get_mctgt_type_thp(struct vm_area_struct *vma,\n\t\tunsigned long addr, pmd_t pmd, union mc_target *target)\n{\n\tstruct page *page = NULL;\n\tenum mc_target_type ret = MC_TARGET_NONE;\n\n\tif (unlikely(is_swap_pmd(pmd))) {\n\t\tVM_BUG_ON(thp_migration_supported() &&\n\t\t\t\t  !is_pmd_migration_entry(pmd));\n\t\treturn ret;\n\t}\n\tpage = pmd_page(pmd);\n\tVM_BUG_ON_PAGE(!page || !PageHead(page), page);\n\tif (!(mc.flags & MOVE_ANON))\n\t\treturn ret;\n\tif (page->mem_cgroup == mc.from) {\n\t\tret = MC_TARGET_PAGE;\n\t\tif (target) {\n\t\t\tget_page(page);\n\t\t\ttarget->page = page;\n\t\t}\n\t}\n\treturn ret;\n}\n#else\nstatic inline enum mc_target_type get_mctgt_type_thp(struct vm_area_struct *vma,\n\t\tunsigned long addr, pmd_t pmd, union mc_target *target)\n{\n\treturn MC_TARGET_NONE;\n}\n#endif\n\nstatic int mem_cgroup_count_precharge_pte_range(pmd_t *pmd,\n\t\t\t\t\tunsigned long addr, unsigned long end,\n\t\t\t\t\tstruct mm_walk *walk)\n{\n\tstruct vm_area_struct *vma = walk->vma;\n\tpte_t *pte;\n\tspinlock_t *ptl;\n\n\tptl = pmd_trans_huge_lock(pmd, vma);\n\tif (ptl) {\n\t\t/*\n\t\t * Note their can not be MC_TARGET_DEVICE for now as we do not\n\t\t * support transparent huge page with MEMORY_DEVICE_PRIVATE but\n\t\t * this might change.\n\t\t */\n\t\tif (get_mctgt_type_thp(vma, addr, *pmd, NULL) == MC_TARGET_PAGE)\n\t\t\tmc.precharge += HPAGE_PMD_NR;\n\t\tspin_unlock(ptl);\n\t\treturn 0;\n\t}\n\n\tif (pmd_trans_unstable(pmd))\n\t\treturn 0;\n\tpte = pte_offset_map_lock(vma->vm_mm, pmd, addr, &ptl);\n\tfor (; addr != end; pte++, addr += PAGE_SIZE)\n\t\tif (get_mctgt_type(vma, addr, *pte, NULL))\n\t\t\tmc.precharge++;\t/* increment precharge temporarily */\n\tpte_unmap_unlock(pte - 1, ptl);\n\tcond_resched();\n\n\treturn 0;\n}\n\nstatic const struct mm_walk_ops precharge_walk_ops = {\n\t.pmd_entry\t= mem_cgroup_count_precharge_pte_range,\n};\n\nstatic unsigned long mem_cgroup_count_precharge(struct mm_struct *mm)\n{\n\tunsigned long precharge;\n\n\tmmap_read_lock(mm);\n\twalk_page_range(mm, 0, mm->highest_vm_end, &precharge_walk_ops, NULL);\n\tmmap_read_unlock(mm);\n\n\tprecharge = mc.precharge;\n\tmc.precharge = 0;\n\n\treturn precharge;\n}\n\nstatic int mem_cgroup_precharge_mc(struct mm_struct *mm)\n{\n\tunsigned long precharge = mem_cgroup_count_precharge(mm);\n\n\tVM_BUG_ON(mc.moving_task);\n\tmc.moving_task = current;\n\treturn mem_cgroup_do_precharge(precharge);\n}\n\n/* cancels all extra charges on mc.from and mc.to, and wakes up all waiters. */\nstatic void __mem_cgroup_clear_mc(void)\n{\n\tstruct mem_cgroup *from = mc.from;\n\tstruct mem_cgroup *to = mc.to;\n\n\t/* we must uncharge all the leftover precharges from mc.to */\n\tif (mc.precharge) {\n\t\tcancel_charge(mc.to, mc.precharge);\n\t\tmc.precharge = 0;\n\t}\n\t/*\n\t * we didn't uncharge from mc.from at mem_cgroup_move_account(), so\n\t * we must uncharge here.\n\t */\n\tif (mc.moved_charge) {\n\t\tcancel_charge(mc.from, mc.moved_charge);\n\t\tmc.moved_charge = 0;\n\t}\n\t/* we must fixup refcnts and charges */\n\tif (mc.moved_swap) {\n\t\t/* uncharge swap account from the old cgroup */\n\t\tif (!mem_cgroup_is_root(mc.from))\n\t\t\tpage_counter_uncharge(&mc.from->memsw, mc.moved_swap);\n\n\t\tmem_cgroup_id_put_many(mc.from, mc.moved_swap);\n\n\t\t/*\n\t\t * we charged both to->memory and to->memsw, so we\n\t\t * should uncharge to->memory.\n\t\t */\n\t\tif (!mem_cgroup_is_root(mc.to))\n\t\t\tpage_counter_uncharge(&mc.to->memory, mc.moved_swap);\n\n\t\tmc.moved_swap = 0;\n\t}\n\tmemcg_oom_recover(from);\n\tmemcg_oom_recover(to);\n\twake_up_all(&mc.waitq);\n}\n\nstatic void mem_cgroup_clear_mc(void)\n{\n\tstruct mm_struct *mm = mc.mm;\n\n\t/*\n\t * we must clear moving_task before waking up waiters at the end of\n\t * task migration.\n\t */\n\tmc.moving_task = NULL;\n\t__mem_cgroup_clear_mc();\n\tspin_lock(&mc.lock);\n\tmc.from = NULL;\n\tmc.to = NULL;\n\tmc.mm = NULL;\n\tspin_unlock(&mc.lock);\n\n\tmmput(mm);\n}\n\nstatic int mem_cgroup_can_attach(struct cgroup_taskset *tset)\n{\n\tstruct cgroup_subsys_state *css;\n\tstruct mem_cgroup *memcg = NULL; /* unneeded init to make gcc happy */\n\tstruct mem_cgroup *from;\n\tstruct task_struct *leader, *p;\n\tstruct mm_struct *mm;\n\tunsigned long move_flags;\n\tint ret = 0;\n\n\t/* charge immigration isn't supported on the default hierarchy */\n\tif (cgroup_subsys_on_dfl(memory_cgrp_subsys))\n\t\treturn 0;\n\n\t/*\n\t * Multi-process migrations only happen on the default hierarchy\n\t * where charge immigration is not used.  Perform charge\n\t * immigration if @tset contains a leader and whine if there are\n\t * multiple.\n\t */\n\tp = NULL;\n\tcgroup_taskset_for_each_leader(leader, css, tset) {\n\t\tWARN_ON_ONCE(p);\n\t\tp = leader;\n\t\tmemcg = mem_cgroup_from_css(css);\n\t}\n\tif (!p)\n\t\treturn 0;\n\n\t/*\n\t * We are now commited to this value whatever it is. Changes in this\n\t * tunable will only affect upcoming migrations, not the current one.\n\t * So we need to save it, and keep it going.\n\t */\n\tmove_flags = READ_ONCE(memcg->move_charge_at_immigrate);\n\tif (!move_flags)\n\t\treturn 0;\n\n\tfrom = mem_cgroup_from_task(p);\n\n\tVM_BUG_ON(from == memcg);\n\n\tmm = get_task_mm(p);\n\tif (!mm)\n\t\treturn 0;\n\t/* We move charges only when we move a owner of the mm */\n\tif (mm->owner == p) {\n\t\tVM_BUG_ON(mc.from);\n\t\tVM_BUG_ON(mc.to);\n\t\tVM_BUG_ON(mc.precharge);\n\t\tVM_BUG_ON(mc.moved_charge);\n\t\tVM_BUG_ON(mc.moved_swap);\n\n\t\tspin_lock(&mc.lock);\n\t\tmc.mm = mm;\n\t\tmc.from = from;\n\t\tmc.to = memcg;\n\t\tmc.flags = move_flags;\n\t\tspin_unlock(&mc.lock);\n\t\t/* We set mc.moving_task later */\n\n\t\tret = mem_cgroup_precharge_mc(mm);\n\t\tif (ret)\n\t\t\tmem_cgroup_clear_mc();\n\t} else {\n\t\tmmput(mm);\n\t}\n\treturn ret;\n}\n\nstatic void mem_cgroup_cancel_attach(struct cgroup_taskset *tset)\n{\n\tif (mc.to)\n\t\tmem_cgroup_clear_mc();\n}\n\nstatic int mem_cgroup_move_charge_pte_range(pmd_t *pmd,\n\t\t\t\tunsigned long addr, unsigned long end,\n\t\t\t\tstruct mm_walk *walk)\n{\n\tint ret = 0;\n\tstruct vm_area_struct *vma = walk->vma;\n\tpte_t *pte;\n\tspinlock_t *ptl;\n\tenum mc_target_type target_type;\n\tunion mc_target target;\n\tstruct page *page;\n\n\tptl = pmd_trans_huge_lock(pmd, vma);\n\tif (ptl) {\n\t\tif (mc.precharge < HPAGE_PMD_NR) {\n\t\t\tspin_unlock(ptl);\n\t\t\treturn 0;\n\t\t}\n\t\ttarget_type = get_mctgt_type_thp(vma, addr, *pmd, &target);\n\t\tif (target_type == MC_TARGET_PAGE) {\n\t\t\tpage = target.page;\n\t\t\tif (!isolate_lru_page(page)) {\n\t\t\t\tif (!mem_cgroup_move_account(page, true,\n\t\t\t\t\t\t\t     mc.from, mc.to)) {\n\t\t\t\t\tmc.precharge -= HPAGE_PMD_NR;\n\t\t\t\t\tmc.moved_charge += HPAGE_PMD_NR;\n\t\t\t\t}\n\t\t\t\tputback_lru_page(page);\n\t\t\t}\n\t\t\tput_page(page);\n\t\t} else if (target_type == MC_TARGET_DEVICE) {\n\t\t\tpage = target.page;\n\t\t\tif (!mem_cgroup_move_account(page, true,\n\t\t\t\t\t\t     mc.from, mc.to)) {\n\t\t\t\tmc.precharge -= HPAGE_PMD_NR;\n\t\t\t\tmc.moved_charge += HPAGE_PMD_NR;\n\t\t\t}\n\t\t\tput_page(page);\n\t\t}\n\t\tspin_unlock(ptl);\n\t\treturn 0;\n\t}\n\n\tif (pmd_trans_unstable(pmd))\n\t\treturn 0;\nretry:\n\tpte = pte_offset_map_lock(vma->vm_mm, pmd, addr, &ptl);\n\tfor (; addr != end; addr += PAGE_SIZE) {\n\t\tpte_t ptent = *(pte++);\n\t\tbool device = false;\n\t\tswp_entry_t ent;\n\n\t\tif (!mc.precharge)\n\t\t\tbreak;\n\n\t\tswitch (get_mctgt_type(vma, addr, ptent, &target)) {\n\t\tcase MC_TARGET_DEVICE:\n\t\t\tdevice = true;\n\t\t\tfallthrough;\n\t\tcase MC_TARGET_PAGE:\n\t\t\tpage = target.page;\n\t\t\t/*\n\t\t\t * We can have a part of the split pmd here. Moving it\n\t\t\t * can be done but it would be too convoluted so simply\n\t\t\t * ignore such a partial THP and keep it in original\n\t\t\t * memcg. There should be somebody mapping the head.\n\t\t\t */\n\t\t\tif (PageTransCompound(page))\n\t\t\t\tgoto put;\n\t\t\tif (!device && isolate_lru_page(page))\n\t\t\t\tgoto put;\n\t\t\tif (!mem_cgroup_move_account(page, false,\n\t\t\t\t\t\tmc.from, mc.to)) {\n\t\t\t\tmc.precharge--;\n\t\t\t\t/* we uncharge from mc.from later. */\n\t\t\t\tmc.moved_charge++;\n\t\t\t}\n\t\t\tif (!device)\n\t\t\t\tputback_lru_page(page);\nput:\t\t\t/* get_mctgt_type() gets the page */\n\t\t\tput_page(page);\n\t\t\tbreak;\n\t\tcase MC_TARGET_SWAP:\n\t\t\tent = target.ent;\n\t\t\tif (!mem_cgroup_move_swap_account(ent, mc.from, mc.to)) {\n\t\t\t\tmc.precharge--;\n\t\t\t\tmem_cgroup_id_get_many(mc.to, 1);\n\t\t\t\t/* we fixup other refcnts and charges later. */\n\t\t\t\tmc.moved_swap++;\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\tpte_unmap_unlock(pte - 1, ptl);\n\tcond_resched();\n\n\tif (addr != end) {\n\t\t/*\n\t\t * We have consumed all precharges we got in can_attach().\n\t\t * We try charge one by one, but don't do any additional\n\t\t * charges to mc.to if we have failed in charge once in attach()\n\t\t * phase.\n\t\t */\n\t\tret = mem_cgroup_do_precharge(1);\n\t\tif (!ret)\n\t\t\tgoto retry;\n\t}\n\n\treturn ret;\n}\n\nstatic const struct mm_walk_ops charge_walk_ops = {\n\t.pmd_entry\t= mem_cgroup_move_charge_pte_range,\n};\n\nstatic void mem_cgroup_move_charge(void)\n{\n\tlru_add_drain_all();\n\t/*\n\t * Signal lock_page_memcg() to take the memcg's move_lock\n\t * while we're moving its pages to another memcg. Then wait\n\t * for already started RCU-only updates to finish.\n\t */\n\tatomic_inc(&mc.from->moving_account);\n\tsynchronize_rcu();\nretry:\n\tif (unlikely(!mmap_read_trylock(mc.mm))) {\n\t\t/*\n\t\t * Someone who are holding the mmap_lock might be waiting in\n\t\t * waitq. So we cancel all extra charges, wake up all waiters,\n\t\t * and retry. Because we cancel precharges, we might not be able\n\t\t * to move enough charges, but moving charge is a best-effort\n\t\t * feature anyway, so it wouldn't be a big problem.\n\t\t */\n\t\t__mem_cgroup_clear_mc();\n\t\tcond_resched();\n\t\tgoto retry;\n\t}\n\t/*\n\t * When we have consumed all precharges and failed in doing\n\t * additional charge, the page walk just aborts.\n\t */\n\twalk_page_range(mc.mm, 0, mc.mm->highest_vm_end, &charge_walk_ops,\n\t\t\tNULL);\n\n\tmmap_read_unlock(mc.mm);\n\tatomic_dec(&mc.from->moving_account);\n}\n\nstatic void mem_cgroup_move_task(void)\n{\n\tif (mc.to) {\n\t\tmem_cgroup_move_charge();\n\t\tmem_cgroup_clear_mc();\n\t}\n}\n#else\t/* !CONFIG_MMU */\nstatic int mem_cgroup_can_attach(struct cgroup_taskset *tset)\n{\n\treturn 0;\n}\nstatic void mem_cgroup_cancel_attach(struct cgroup_taskset *tset)\n{\n}\nstatic void mem_cgroup_move_task(void)\n{\n}\n#endif\n\n/*\n * Cgroup retains root cgroups across [un]mount cycles making it necessary\n * to verify whether we're attached to the default hierarchy on each mount\n * attempt.\n */\nstatic void mem_cgroup_bind(struct cgroup_subsys_state *root_css)\n{\n\t/*\n\t * use_hierarchy is forced on the default hierarchy.  cgroup core\n\t * guarantees that @root doesn't have any children, so turning it\n\t * on for the root memcg is enough.\n\t */\n\tif (cgroup_subsys_on_dfl(memory_cgrp_subsys))\n\t\troot_mem_cgroup->use_hierarchy = true;\n\telse\n\t\troot_mem_cgroup->use_hierarchy = false;\n}\n\nstatic int seq_puts_memcg_tunable(struct seq_file *m, unsigned long value)\n{\n\tif (value == PAGE_COUNTER_MAX)\n\t\tseq_puts(m, \"max\\n\");\n\telse\n\t\tseq_printf(m, \"%llu\\n\", (u64)value * PAGE_SIZE);\n\n\treturn 0;\n}\n\nstatic u64 memory_current_read(struct cgroup_subsys_state *css,\n\t\t\t       struct cftype *cft)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_css(css);\n\n\treturn (u64)page_counter_read(&memcg->memory) * PAGE_SIZE;\n}\n\nstatic int memory_min_show(struct seq_file *m, void *v)\n{\n\treturn seq_puts_memcg_tunable(m,\n\t\tREAD_ONCE(mem_cgroup_from_seq(m)->memory.min));\n}\n\nstatic ssize_t memory_min_write(struct kernfs_open_file *of,\n\t\t\t\tchar *buf, size_t nbytes, loff_t off)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_css(of_css(of));\n\tunsigned long min;\n\tint err;\n\n\tbuf = strstrip(buf);\n\terr = page_counter_memparse(buf, \"max\", &min);\n\tif (err)\n\t\treturn err;\n\n\tpage_counter_set_min(&memcg->memory, min);\n\n\treturn nbytes;\n}\n\nstatic int memory_low_show(struct seq_file *m, void *v)\n{\n\treturn seq_puts_memcg_tunable(m,\n\t\tREAD_ONCE(mem_cgroup_from_seq(m)->memory.low));\n}\n\nstatic ssize_t memory_low_write(struct kernfs_open_file *of,\n\t\t\t\tchar *buf, size_t nbytes, loff_t off)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_css(of_css(of));\n\tunsigned long low;\n\tint err;\n\n\tbuf = strstrip(buf);\n\terr = page_counter_memparse(buf, \"max\", &low);\n\tif (err)\n\t\treturn err;\n\n\tpage_counter_set_low(&memcg->memory, low);\n\n\treturn nbytes;\n}\n\nstatic int memory_high_show(struct seq_file *m, void *v)\n{\n\treturn seq_puts_memcg_tunable(m,\n\t\tREAD_ONCE(mem_cgroup_from_seq(m)->memory.high));\n}\n\nstatic ssize_t memory_high_write(struct kernfs_open_file *of,\n\t\t\t\t char *buf, size_t nbytes, loff_t off)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_css(of_css(of));\n\tunsigned int nr_retries = MAX_RECLAIM_RETRIES;\n\tbool drained = false;\n\tunsigned long high;\n\tint err;\n\n\tbuf = strstrip(buf);\n\terr = page_counter_memparse(buf, \"max\", &high);\n\tif (err)\n\t\treturn err;\n\n\tfor (;;) {\n\t\tunsigned long nr_pages = page_counter_read(&memcg->memory);\n\t\tunsigned long reclaimed;\n\n\t\tif (nr_pages <= high)\n\t\t\tbreak;\n\n\t\tif (signal_pending(current))\n\t\t\tbreak;\n\n\t\tif (!drained) {\n\t\t\tdrain_all_stock(memcg);\n\t\t\tdrained = true;\n\t\t\tcontinue;\n\t\t}\n\n\t\treclaimed = try_to_free_mem_cgroup_pages(memcg, nr_pages - high,\n\t\t\t\t\t\t\t GFP_KERNEL, true);\n\n\t\tif (!reclaimed && !nr_retries--)\n\t\t\tbreak;\n\t}\n\n\tpage_counter_set_high(&memcg->memory, high);\n\n\tmemcg_wb_domain_size_changed(memcg);\n\n\treturn nbytes;\n}\n\nstatic int memory_max_show(struct seq_file *m, void *v)\n{\n\treturn seq_puts_memcg_tunable(m,\n\t\tREAD_ONCE(mem_cgroup_from_seq(m)->memory.max));\n}\n\nstatic ssize_t memory_max_write(struct kernfs_open_file *of,\n\t\t\t\tchar *buf, size_t nbytes, loff_t off)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_css(of_css(of));\n\tunsigned int nr_reclaims = MAX_RECLAIM_RETRIES;\n\tbool drained = false;\n\tunsigned long max;\n\tint err;\n\n\tbuf = strstrip(buf);\n\terr = page_counter_memparse(buf, \"max\", &max);\n\tif (err)\n\t\treturn err;\n\n\txchg(&memcg->memory.max, max);\n\n\tfor (;;) {\n\t\tunsigned long nr_pages = page_counter_read(&memcg->memory);\n\n\t\tif (nr_pages <= max)\n\t\t\tbreak;\n\n\t\tif (signal_pending(current))\n\t\t\tbreak;\n\n\t\tif (!drained) {\n\t\t\tdrain_all_stock(memcg);\n\t\t\tdrained = true;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (nr_reclaims) {\n\t\t\tif (!try_to_free_mem_cgroup_pages(memcg, nr_pages - max,\n\t\t\t\t\t\t\t  GFP_KERNEL, true))\n\t\t\t\tnr_reclaims--;\n\t\t\tcontinue;\n\t\t}\n\n\t\tmemcg_memory_event(memcg, MEMCG_OOM);\n\t\tif (!mem_cgroup_out_of_memory(memcg, GFP_KERNEL, 0))\n\t\t\tbreak;\n\t}\n\n\tmemcg_wb_domain_size_changed(memcg);\n\treturn nbytes;\n}\n\nstatic void __memory_events_show(struct seq_file *m, atomic_long_t *events)\n{\n\tseq_printf(m, \"low %lu\\n\", atomic_long_read(&events[MEMCG_LOW]));\n\tseq_printf(m, \"high %lu\\n\", atomic_long_read(&events[MEMCG_HIGH]));\n\tseq_printf(m, \"max %lu\\n\", atomic_long_read(&events[MEMCG_MAX]));\n\tseq_printf(m, \"oom %lu\\n\", atomic_long_read(&events[MEMCG_OOM]));\n\tseq_printf(m, \"oom_kill %lu\\n\",\n\t\t   atomic_long_read(&events[MEMCG_OOM_KILL]));\n}\n\nstatic int memory_events_show(struct seq_file *m, void *v)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_seq(m);\n\n\t__memory_events_show(m, memcg->memory_events);\n\treturn 0;\n}\n\nstatic int memory_events_local_show(struct seq_file *m, void *v)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_seq(m);\n\n\t__memory_events_show(m, memcg->memory_events_local);\n\treturn 0;\n}\n\nstatic int memory_stat_show(struct seq_file *m, void *v)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_seq(m);\n\tchar *buf;\n\n\tbuf = memory_stat_format(memcg);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\tseq_puts(m, buf);\n\tkfree(buf);\n\treturn 0;\n}\n\n#ifdef CONFIG_NUMA\nstatic int memory_numa_stat_show(struct seq_file *m, void *v)\n{\n\tint i;\n\tstruct mem_cgroup *memcg = mem_cgroup_from_seq(m);\n\n\tfor (i = 0; i < ARRAY_SIZE(memory_stats); i++) {\n\t\tint nid;\n\n\t\tif (memory_stats[i].idx >= NR_VM_NODE_STAT_ITEMS)\n\t\t\tcontinue;\n\n\t\tseq_printf(m, \"%s\", memory_stats[i].name);\n\t\tfor_each_node_state(nid, N_MEMORY) {\n\t\t\tu64 size;\n\t\t\tstruct lruvec *lruvec;\n\n\t\t\tlruvec = mem_cgroup_lruvec(memcg, NODE_DATA(nid));\n\t\t\tsize = lruvec_page_state(lruvec, memory_stats[i].idx);\n\t\t\tsize *= memory_stats[i].ratio;\n\t\t\tseq_printf(m, \" N%d=%llu\", nid, size);\n\t\t}\n\t\tseq_putc(m, '\\n');\n\t}\n\n\treturn 0;\n}\n#endif\n\nstatic int memory_oom_group_show(struct seq_file *m, void *v)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_seq(m);\n\n\tseq_printf(m, \"%d\\n\", memcg->oom_group);\n\n\treturn 0;\n}\n\nstatic ssize_t memory_oom_group_write(struct kernfs_open_file *of,\n\t\t\t\t      char *buf, size_t nbytes, loff_t off)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_css(of_css(of));\n\tint ret, oom_group;\n\n\tbuf = strstrip(buf);\n\tif (!buf)\n\t\treturn -EINVAL;\n\n\tret = kstrtoint(buf, 0, &oom_group);\n\tif (ret)\n\t\treturn ret;\n\n\tif (oom_group != 0 && oom_group != 1)\n\t\treturn -EINVAL;\n\n\tmemcg->oom_group = oom_group;\n\n\treturn nbytes;\n}\n\nstatic struct cftype memory_files[] = {\n\t{\n\t\t.name = \"current\",\n\t\t.flags = CFTYPE_NOT_ON_ROOT,\n\t\t.read_u64 = memory_current_read,\n\t},\n\t{\n\t\t.name = \"min\",\n\t\t.flags = CFTYPE_NOT_ON_ROOT,\n\t\t.seq_show = memory_min_show,\n\t\t.write = memory_min_write,\n\t},\n\t{\n\t\t.name = \"low\",\n\t\t.flags = CFTYPE_NOT_ON_ROOT,\n\t\t.seq_show = memory_low_show,\n\t\t.write = memory_low_write,\n\t},\n\t{\n\t\t.name = \"high\",\n\t\t.flags = CFTYPE_NOT_ON_ROOT,\n\t\t.seq_show = memory_high_show,\n\t\t.write = memory_high_write,\n\t},\n\t{\n\t\t.name = \"max\",\n\t\t.flags = CFTYPE_NOT_ON_ROOT,\n\t\t.seq_show = memory_max_show,\n\t\t.write = memory_max_write,\n\t},\n\t{\n\t\t.name = \"events\",\n\t\t.flags = CFTYPE_NOT_ON_ROOT,\n\t\t.file_offset = offsetof(struct mem_cgroup, events_file),\n\t\t.seq_show = memory_events_show,\n\t},\n\t{\n\t\t.name = \"events.local\",\n\t\t.flags = CFTYPE_NOT_ON_ROOT,\n\t\t.file_offset = offsetof(struct mem_cgroup, events_local_file),\n\t\t.seq_show = memory_events_local_show,\n\t},\n\t{\n\t\t.name = \"stat\",\n\t\t.seq_show = memory_stat_show,\n\t},\n#ifdef CONFIG_NUMA\n\t{\n\t\t.name = \"numa_stat\",\n\t\t.seq_show = memory_numa_stat_show,\n\t},\n#endif\n\t{\n\t\t.name = \"oom.group\",\n\t\t.flags = CFTYPE_NOT_ON_ROOT | CFTYPE_NS_DELEGATABLE,\n\t\t.seq_show = memory_oom_group_show,\n\t\t.write = memory_oom_group_write,\n\t},\n\t{ }\t/* terminate */\n};\n\nstruct cgroup_subsys memory_cgrp_subsys = {\n\t.css_alloc = mem_cgroup_css_alloc,\n\t.css_online = mem_cgroup_css_online,\n\t.css_offline = mem_cgroup_css_offline,\n\t.css_released = mem_cgroup_css_released,\n\t.css_free = mem_cgroup_css_free,\n\t.css_reset = mem_cgroup_css_reset,\n\t.can_attach = mem_cgroup_can_attach,\n\t.cancel_attach = mem_cgroup_cancel_attach,\n\t.post_attach = mem_cgroup_move_task,\n\t.bind = mem_cgroup_bind,\n\t.dfl_cftypes = memory_files,\n\t.legacy_cftypes = mem_cgroup_legacy_files,\n\t.early_init = 0,\n};\n\n/*\n * This function calculates an individual cgroup's effective\n * protection which is derived from its own memory.min/low, its\n * parent's and siblings' settings, as well as the actual memory\n * distribution in the tree.\n *\n * The following rules apply to the effective protection values:\n *\n * 1. At the first level of reclaim, effective protection is equal to\n *    the declared protection in memory.min and memory.low.\n *\n * 2. To enable safe delegation of the protection configuration, at\n *    subsequent levels the effective protection is capped to the\n *    parent's effective protection.\n *\n * 3. To make complex and dynamic subtrees easier to configure, the\n *    user is allowed to overcommit the declared protection at a given\n *    level. If that is the case, the parent's effective protection is\n *    distributed to the children in proportion to how much protection\n *    they have declared and how much of it they are utilizing.\n *\n *    This makes distribution proportional, but also work-conserving:\n *    if one cgroup claims much more protection than it uses memory,\n *    the unused remainder is available to its siblings.\n *\n * 4. Conversely, when the declared protection is undercommitted at a\n *    given level, the distribution of the larger parental protection\n *    budget is NOT proportional. A cgroup's protection from a sibling\n *    is capped to its own memory.min/low setting.\n *\n * 5. However, to allow protecting recursive subtrees from each other\n *    without having to declare each individual cgroup's fixed share\n *    of the ancestor's claim to protection, any unutilized -\n *    \"floating\" - protection from up the tree is distributed in\n *    proportion to each cgroup's *usage*. This makes the protection\n *    neutral wrt sibling cgroups and lets them compete freely over\n *    the shared parental protection budget, but it protects the\n *    subtree as a whole from neighboring subtrees.\n *\n * Note that 4. and 5. are not in conflict: 4. is about protecting\n * against immediate siblings whereas 5. is about protecting against\n * neighboring subtrees.\n */\nstatic unsigned long effective_protection(unsigned long usage,\n\t\t\t\t\t  unsigned long parent_usage,\n\t\t\t\t\t  unsigned long setting,\n\t\t\t\t\t  unsigned long parent_effective,\n\t\t\t\t\t  unsigned long siblings_protected)\n{\n\tunsigned long protected;\n\tunsigned long ep;\n\n\tprotected = min(usage, setting);\n\t/*\n\t * If all cgroups at this level combined claim and use more\n\t * protection then what the parent affords them, distribute\n\t * shares in proportion to utilization.\n\t *\n\t * We are using actual utilization rather than the statically\n\t * claimed protection in order to be work-conserving: claimed\n\t * but unused protection is available to siblings that would\n\t * otherwise get a smaller chunk than what they claimed.\n\t */\n\tif (siblings_protected > parent_effective)\n\t\treturn protected * parent_effective / siblings_protected;\n\n\t/*\n\t * Ok, utilized protection of all children is within what the\n\t * parent affords them, so we know whatever this child claims\n\t * and utilizes is effectively protected.\n\t *\n\t * If there is unprotected usage beyond this value, reclaim\n\t * will apply pressure in proportion to that amount.\n\t *\n\t * If there is unutilized protection, the cgroup will be fully\n\t * shielded from reclaim, but we do return a smaller value for\n\t * protection than what the group could enjoy in theory. This\n\t * is okay. With the overcommit distribution above, effective\n\t * protection is always dependent on how memory is actually\n\t * consumed among the siblings anyway.\n\t */\n\tep = protected;\n\n\t/*\n\t * If the children aren't claiming (all of) the protection\n\t * afforded to them by the parent, distribute the remainder in\n\t * proportion to the (unprotected) memory of each cgroup. That\n\t * way, cgroups that aren't explicitly prioritized wrt each\n\t * other compete freely over the allowance, but they are\n\t * collectively protected from neighboring trees.\n\t *\n\t * We're using unprotected memory for the weight so that if\n\t * some cgroups DO claim explicit protection, we don't protect\n\t * the same bytes twice.\n\t *\n\t * Check both usage and parent_usage against the respective\n\t * protected values. One should imply the other, but they\n\t * aren't read atomically - make sure the division is sane.\n\t */\n\tif (!(cgrp_dfl_root.flags & CGRP_ROOT_MEMORY_RECURSIVE_PROT))\n\t\treturn ep;\n\tif (parent_effective > siblings_protected &&\n\t    parent_usage > siblings_protected &&\n\t    usage > protected) {\n\t\tunsigned long unclaimed;\n\n\t\tunclaimed = parent_effective - siblings_protected;\n\t\tunclaimed *= usage - protected;\n\t\tunclaimed /= parent_usage - siblings_protected;\n\n\t\tep += unclaimed;\n\t}\n\n\treturn ep;\n}\n\n/**\n * mem_cgroup_protected - check if memory consumption is in the normal range\n * @root: the top ancestor of the sub-tree being checked\n * @memcg: the memory cgroup to check\n *\n * WARNING: This function is not stateless! It can only be used as part\n *          of a top-down tree iteration, not for isolated queries.\n */\nvoid mem_cgroup_calculate_protection(struct mem_cgroup *root,\n\t\t\t\t     struct mem_cgroup *memcg)\n{\n\tunsigned long usage, parent_usage;\n\tstruct mem_cgroup *parent;\n\n\tif (mem_cgroup_disabled())\n\t\treturn;\n\n\tif (!root)\n\t\troot = root_mem_cgroup;\n\n\t/*\n\t * Effective values of the reclaim targets are ignored so they\n\t * can be stale. Have a look at mem_cgroup_protection for more\n\t * details.\n\t * TODO: calculation should be more robust so that we do not need\n\t * that special casing.\n\t */\n\tif (memcg == root)\n\t\treturn;\n\n\tusage = page_counter_read(&memcg->memory);\n\tif (!usage)\n\t\treturn;\n\n\tparent = parent_mem_cgroup(memcg);\n\t/* No parent means a non-hierarchical mode on v1 memcg */\n\tif (!parent)\n\t\treturn;\n\n\tif (parent == root) {\n\t\tmemcg->memory.emin = READ_ONCE(memcg->memory.min);\n\t\tmemcg->memory.elow = READ_ONCE(memcg->memory.low);\n\t\treturn;\n\t}\n\n\tparent_usage = page_counter_read(&parent->memory);\n\n\tWRITE_ONCE(memcg->memory.emin, effective_protection(usage, parent_usage,\n\t\t\tREAD_ONCE(memcg->memory.min),\n\t\t\tREAD_ONCE(parent->memory.emin),\n\t\t\tatomic_long_read(&parent->memory.children_min_usage)));\n\n\tWRITE_ONCE(memcg->memory.elow, effective_protection(usage, parent_usage,\n\t\t\tREAD_ONCE(memcg->memory.low),\n\t\t\tREAD_ONCE(parent->memory.elow),\n\t\t\tatomic_long_read(&parent->memory.children_low_usage)));\n}\n\n/**\n * mem_cgroup_charge - charge a newly allocated page to a cgroup\n * @page: page to charge\n * @mm: mm context of the victim\n * @gfp_mask: reclaim mode\n *\n * Try to charge @page to the memcg that @mm belongs to, reclaiming\n * pages according to @gfp_mask if necessary.\n *\n * Returns 0 on success. Otherwise, an error code is returned.\n */\nint mem_cgroup_charge(struct page *page, struct mm_struct *mm, gfp_t gfp_mask)\n{\n\tunsigned int nr_pages = thp_nr_pages(page);\n\tstruct mem_cgroup *memcg = NULL;\n\tint ret = 0;\n\n\tif (mem_cgroup_disabled())\n\t\tgoto out;\n\n\tif (PageSwapCache(page)) {\n\t\tswp_entry_t ent = { .val = page_private(page), };\n\t\tunsigned short id;\n\n\t\t/*\n\t\t * Every swap fault against a single page tries to charge the\n\t\t * page, bail as early as possible.  shmem_unuse() encounters\n\t\t * already charged pages, too.  page->mem_cgroup is protected\n\t\t * by the page lock, which serializes swap cache removal, which\n\t\t * in turn serializes uncharging.\n\t\t */\n\t\tVM_BUG_ON_PAGE(!PageLocked(page), page);\n\t\tif (compound_head(page)->mem_cgroup)\n\t\t\tgoto out;\n\n\t\tid = lookup_swap_cgroup_id(ent);\n\t\trcu_read_lock();\n\t\tmemcg = mem_cgroup_from_id(id);\n\t\tif (memcg && !css_tryget_online(&memcg->css))\n\t\t\tmemcg = NULL;\n\t\trcu_read_unlock();\n\t}\n\n\tif (!memcg)\n\t\tmemcg = get_mem_cgroup_from_mm(mm);\n\n\tret = try_charge(memcg, gfp_mask, nr_pages);\n\tif (ret)\n\t\tgoto out_put;\n\n\tcss_get(&memcg->css);\n\tcommit_charge(page, memcg);\n\n\tlocal_irq_disable();\n\tmem_cgroup_charge_statistics(memcg, page, nr_pages);\n\tmemcg_check_events(memcg, page);\n\tlocal_irq_enable();\n\n\tif (PageSwapCache(page)) {\n\t\tswp_entry_t entry = { .val = page_private(page) };\n\t\t/*\n\t\t * The swap entry might not get freed for a long time,\n\t\t * let's not wait for it.  The page already received a\n\t\t * memory+swap charge, drop the swap entry duplicate.\n\t\t */\n\t\tmem_cgroup_uncharge_swap(entry, nr_pages);\n\t}\n\nout_put:\n\tcss_put(&memcg->css);\nout:\n\treturn ret;\n}\n\nstruct uncharge_gather {\n\tstruct mem_cgroup *memcg;\n\tunsigned long nr_pages;\n\tunsigned long pgpgout;\n\tunsigned long nr_kmem;\n\tstruct page *dummy_page;\n};\n\nstatic inline void uncharge_gather_clear(struct uncharge_gather *ug)\n{\n\tmemset(ug, 0, sizeof(*ug));\n}\n\nstatic void uncharge_batch(const struct uncharge_gather *ug)\n{\n\tunsigned long flags;\n\n\tif (!mem_cgroup_is_root(ug->memcg)) {\n\t\tpage_counter_uncharge(&ug->memcg->memory, ug->nr_pages);\n\t\tif (do_memsw_account())\n\t\t\tpage_counter_uncharge(&ug->memcg->memsw, ug->nr_pages);\n\t\tif (!cgroup_subsys_on_dfl(memory_cgrp_subsys) && ug->nr_kmem)\n\t\t\tpage_counter_uncharge(&ug->memcg->kmem, ug->nr_kmem);\n\t\tmemcg_oom_recover(ug->memcg);\n\t}\n\n\tlocal_irq_save(flags);\n\t__count_memcg_events(ug->memcg, PGPGOUT, ug->pgpgout);\n\t__this_cpu_add(ug->memcg->vmstats_percpu->nr_page_events, ug->nr_pages);\n\tmemcg_check_events(ug->memcg, ug->dummy_page);\n\tlocal_irq_restore(flags);\n\n\t/* drop reference from uncharge_page */\n\tcss_put(&ug->memcg->css);\n}\n\nstatic void uncharge_page(struct page *page, struct uncharge_gather *ug)\n{\n\tunsigned long nr_pages;\n\n\tVM_BUG_ON_PAGE(PageLRU(page), page);\n\n\tif (!page->mem_cgroup)\n\t\treturn;\n\n\t/*\n\t * Nobody should be changing or seriously looking at\n\t * page->mem_cgroup at this point, we have fully\n\t * exclusive access to the page.\n\t */\n\n\tif (ug->memcg != page->mem_cgroup) {\n\t\tif (ug->memcg) {\n\t\t\tuncharge_batch(ug);\n\t\t\tuncharge_gather_clear(ug);\n\t\t}\n\t\tug->memcg = page->mem_cgroup;\n\n\t\t/* pairs with css_put in uncharge_batch */\n\t\tcss_get(&ug->memcg->css);\n\t}\n\n\tnr_pages = compound_nr(page);\n\tug->nr_pages += nr_pages;\n\n\tif (!PageKmemcg(page)) {\n\t\tug->pgpgout++;\n\t} else {\n\t\tug->nr_kmem += nr_pages;\n\t\t__ClearPageKmemcg(page);\n\t}\n\n\tug->dummy_page = page;\n\tpage->mem_cgroup = NULL;\n\tcss_put(&ug->memcg->css);\n}\n\nstatic void uncharge_list(struct list_head *page_list)\n{\n\tstruct uncharge_gather ug;\n\tstruct list_head *next;\n\n\tuncharge_gather_clear(&ug);\n\n\t/*\n\t * Note that the list can be a single page->lru; hence the\n\t * do-while loop instead of a simple list_for_each_entry().\n\t */\n\tnext = page_list->next;\n\tdo {\n\t\tstruct page *page;\n\n\t\tpage = list_entry(next, struct page, lru);\n\t\tnext = page->lru.next;\n\n\t\tuncharge_page(page, &ug);\n\t} while (next != page_list);\n\n\tif (ug.memcg)\n\t\tuncharge_batch(&ug);\n}\n\n/**\n * mem_cgroup_uncharge - uncharge a page\n * @page: page to uncharge\n *\n * Uncharge a page previously charged with mem_cgroup_charge().\n */\nvoid mem_cgroup_uncharge(struct page *page)\n{\n\tstruct uncharge_gather ug;\n\n\tif (mem_cgroup_disabled())\n\t\treturn;\n\n\t/* Don't touch page->lru of any random page, pre-check: */\n\tif (!page->mem_cgroup)\n\t\treturn;\n\n\tuncharge_gather_clear(&ug);\n\tuncharge_page(page, &ug);\n\tuncharge_batch(&ug);\n}\n\n/**\n * mem_cgroup_uncharge_list - uncharge a list of page\n * @page_list: list of pages to uncharge\n *\n * Uncharge a list of pages previously charged with\n * mem_cgroup_charge().\n */\nvoid mem_cgroup_uncharge_list(struct list_head *page_list)\n{\n\tif (mem_cgroup_disabled())\n\t\treturn;\n\n\tif (!list_empty(page_list))\n\t\tuncharge_list(page_list);\n}\n\n/**\n * mem_cgroup_migrate - charge a page's replacement\n * @oldpage: currently circulating page\n * @newpage: replacement page\n *\n * Charge @newpage as a replacement page for @oldpage. @oldpage will\n * be uncharged upon free.\n *\n * Both pages must be locked, @newpage->mapping must be set up.\n */\nvoid mem_cgroup_migrate(struct page *oldpage, struct page *newpage)\n{\n\tstruct mem_cgroup *memcg;\n\tunsigned int nr_pages;\n\tunsigned long flags;\n\n\tVM_BUG_ON_PAGE(!PageLocked(oldpage), oldpage);\n\tVM_BUG_ON_PAGE(!PageLocked(newpage), newpage);\n\tVM_BUG_ON_PAGE(PageAnon(oldpage) != PageAnon(newpage), newpage);\n\tVM_BUG_ON_PAGE(PageTransHuge(oldpage) != PageTransHuge(newpage),\n\t\t       newpage);\n\n\tif (mem_cgroup_disabled())\n\t\treturn;\n\n\t/* Page cache replacement: new page already charged? */\n\tif (newpage->mem_cgroup)\n\t\treturn;\n\n\t/* Swapcache readahead pages can get replaced before being charged */\n\tmemcg = oldpage->mem_cgroup;\n\tif (!memcg)\n\t\treturn;\n\n\t/* Force-charge the new page. The old one will be freed soon */\n\tnr_pages = thp_nr_pages(newpage);\n\n\tpage_counter_charge(&memcg->memory, nr_pages);\n\tif (do_memsw_account())\n\t\tpage_counter_charge(&memcg->memsw, nr_pages);\n\n\tcss_get(&memcg->css);\n\tcommit_charge(newpage, memcg);\n\n\tlocal_irq_save(flags);\n\tmem_cgroup_charge_statistics(memcg, newpage, nr_pages);\n\tmemcg_check_events(memcg, newpage);\n\tlocal_irq_restore(flags);\n}\n\nDEFINE_STATIC_KEY_FALSE(memcg_sockets_enabled_key);\nEXPORT_SYMBOL(memcg_sockets_enabled_key);\n\nvoid mem_cgroup_sk_alloc(struct sock *sk)\n{\n\tstruct mem_cgroup *memcg;\n\n\tif (!mem_cgroup_sockets_enabled)\n\t\treturn;\n\n\t/* Do not associate the sock with unrelated interrupted task's memcg. */\n\tif (in_interrupt())\n\t\treturn;\n\n\trcu_read_lock();\n\tmemcg = mem_cgroup_from_task(current);\n\tif (memcg == root_mem_cgroup)\n\t\tgoto out;\n\tif (!cgroup_subsys_on_dfl(memory_cgrp_subsys) && !memcg->tcpmem_active)\n\t\tgoto out;\n\tif (css_tryget(&memcg->css))\n\t\tsk->sk_memcg = memcg;\nout:\n\trcu_read_unlock();\n}\n\nvoid mem_cgroup_sk_free(struct sock *sk)\n{\n\tif (sk->sk_memcg)\n\t\tcss_put(&sk->sk_memcg->css);\n}\n\n/**\n * mem_cgroup_charge_skmem - charge socket memory\n * @memcg: memcg to charge\n * @nr_pages: number of pages to charge\n *\n * Charges @nr_pages to @memcg. Returns %true if the charge fit within\n * @memcg's configured limit, %false if the charge had to be forced.\n */\nbool mem_cgroup_charge_skmem(struct mem_cgroup *memcg, unsigned int nr_pages)\n{\n\tgfp_t gfp_mask = GFP_KERNEL;\n\n\tif (!cgroup_subsys_on_dfl(memory_cgrp_subsys)) {\n\t\tstruct page_counter *fail;\n\n\t\tif (page_counter_try_charge(&memcg->tcpmem, nr_pages, &fail)) {\n\t\t\tmemcg->tcpmem_pressure = 0;\n\t\t\treturn true;\n\t\t}\n\t\tpage_counter_charge(&memcg->tcpmem, nr_pages);\n\t\tmemcg->tcpmem_pressure = 1;\n\t\treturn false;\n\t}\n\n\t/* Don't block in the packet receive path */\n\tif (in_softirq())\n\t\tgfp_mask = GFP_NOWAIT;\n\n\tmod_memcg_state(memcg, MEMCG_SOCK, nr_pages);\n\n\tif (try_charge(memcg, gfp_mask, nr_pages) == 0)\n\t\treturn true;\n\n\ttry_charge(memcg, gfp_mask|__GFP_NOFAIL, nr_pages);\n\treturn false;\n}\n\n/**\n * mem_cgroup_uncharge_skmem - uncharge socket memory\n * @memcg: memcg to uncharge\n * @nr_pages: number of pages to uncharge\n */\nvoid mem_cgroup_uncharge_skmem(struct mem_cgroup *memcg, unsigned int nr_pages)\n{\n\tif (!cgroup_subsys_on_dfl(memory_cgrp_subsys)) {\n\t\tpage_counter_uncharge(&memcg->tcpmem, nr_pages);\n\t\treturn;\n\t}\n\n\tmod_memcg_state(memcg, MEMCG_SOCK, -nr_pages);\n\n\trefill_stock(memcg, nr_pages);\n}\n\nstatic int __init cgroup_memory(char *s)\n{\n\tchar *token;\n\n\twhile ((token = strsep(&s, \",\")) != NULL) {\n\t\tif (!*token)\n\t\t\tcontinue;\n\t\tif (!strcmp(token, \"nosocket\"))\n\t\t\tcgroup_memory_nosocket = true;\n\t\tif (!strcmp(token, \"nokmem\"))\n\t\t\tcgroup_memory_nokmem = true;\n\t}\n\treturn 0;\n}\n__setup(\"cgroup.memory=\", cgroup_memory);\n\n/*\n * subsys_initcall() for memory controller.\n *\n * Some parts like memcg_hotplug_cpu_dead() have to be initialized from this\n * context because of lock dependencies (cgroup_lock -> cpu hotplug) but\n * basically everything that doesn't depend on a specific mem_cgroup structure\n * should be initialized from here.\n */\nstatic int __init mem_cgroup_init(void)\n{\n\tint cpu, node;\n\n\tcpuhp_setup_state_nocalls(CPUHP_MM_MEMCQ_DEAD, \"mm/memctrl:dead\", NULL,\n\t\t\t\t  memcg_hotplug_cpu_dead);\n\n\tfor_each_possible_cpu(cpu)\n\t\tINIT_WORK(&per_cpu_ptr(&memcg_stock, cpu)->work,\n\t\t\t  drain_local_stock);\n\n\tfor_each_node(node) {\n\t\tstruct mem_cgroup_tree_per_node *rtpn;\n\n\t\trtpn = kzalloc_node(sizeof(*rtpn), GFP_KERNEL,\n\t\t\t\t    node_online(node) ? node : NUMA_NO_NODE);\n\n\t\trtpn->rb_root = RB_ROOT;\n\t\trtpn->rb_rightmost = NULL;\n\t\tspin_lock_init(&rtpn->lock);\n\t\tsoft_limit_tree.rb_tree_per_node[node] = rtpn;\n\t}\n\n\treturn 0;\n}\nsubsys_initcall(mem_cgroup_init);\n\n#ifdef CONFIG_MEMCG_SWAP\nstatic struct mem_cgroup *mem_cgroup_id_get_online(struct mem_cgroup *memcg)\n{\n\twhile (!refcount_inc_not_zero(&memcg->id.ref)) {\n\t\t/*\n\t\t * The root cgroup cannot be destroyed, so it's refcount must\n\t\t * always be >= 1.\n\t\t */\n\t\tif (WARN_ON_ONCE(memcg == root_mem_cgroup)) {\n\t\t\tVM_BUG_ON(1);\n\t\t\tbreak;\n\t\t}\n\t\tmemcg = parent_mem_cgroup(memcg);\n\t\tif (!memcg)\n\t\t\tmemcg = root_mem_cgroup;\n\t}\n\treturn memcg;\n}\n\n/**\n * mem_cgroup_swapout - transfer a memsw charge to swap\n * @page: page whose memsw charge to transfer\n * @entry: swap entry to move the charge to\n *\n * Transfer the memsw charge of @page to @entry.\n */\nvoid mem_cgroup_swapout(struct page *page, swp_entry_t entry)\n{\n\tstruct mem_cgroup *memcg, *swap_memcg;\n\tunsigned int nr_entries;\n\tunsigned short oldid;\n\n\tVM_BUG_ON_PAGE(PageLRU(page), page);\n\tVM_BUG_ON_PAGE(page_count(page), page);\n\n\tif (cgroup_subsys_on_dfl(memory_cgrp_subsys))\n\t\treturn;\n\n\tmemcg = page->mem_cgroup;\n\n\t/* Readahead page, never charged */\n\tif (!memcg)\n\t\treturn;\n\n\t/*\n\t * In case the memcg owning these pages has been offlined and doesn't\n\t * have an ID allocated to it anymore, charge the closest online\n\t * ancestor for the swap instead and transfer the memory+swap charge.\n\t */\n\tswap_memcg = mem_cgroup_id_get_online(memcg);\n\tnr_entries = thp_nr_pages(page);\n\t/* Get references for the tail pages, too */\n\tif (nr_entries > 1)\n\t\tmem_cgroup_id_get_many(swap_memcg, nr_entries - 1);\n\toldid = swap_cgroup_record(entry, mem_cgroup_id(swap_memcg),\n\t\t\t\t   nr_entries);\n\tVM_BUG_ON_PAGE(oldid, page);\n\tmod_memcg_state(swap_memcg, MEMCG_SWAP, nr_entries);\n\n\tpage->mem_cgroup = NULL;\n\n\tif (!mem_cgroup_is_root(memcg))\n\t\tpage_counter_uncharge(&memcg->memory, nr_entries);\n\n\tif (!cgroup_memory_noswap && memcg != swap_memcg) {\n\t\tif (!mem_cgroup_is_root(swap_memcg))\n\t\t\tpage_counter_charge(&swap_memcg->memsw, nr_entries);\n\t\tpage_counter_uncharge(&memcg->memsw, nr_entries);\n\t}\n\n\t/*\n\t * Interrupts should be disabled here because the caller holds the\n\t * i_pages lock which is taken with interrupts-off. It is\n\t * important here to have the interrupts disabled because it is the\n\t * only synchronisation we have for updating the per-CPU variables.\n\t */\n\tVM_BUG_ON(!irqs_disabled());\n\tmem_cgroup_charge_statistics(memcg, page, -nr_entries);\n\tmemcg_check_events(memcg, page);\n\n\tcss_put(&memcg->css);\n}\n\n/**\n * mem_cgroup_try_charge_swap - try charging swap space for a page\n * @page: page being added to swap\n * @entry: swap entry to charge\n *\n * Try to charge @page's memcg for the swap space at @entry.\n *\n * Returns 0 on success, -ENOMEM on failure.\n */\nint mem_cgroup_try_charge_swap(struct page *page, swp_entry_t entry)\n{\n\tunsigned int nr_pages = thp_nr_pages(page);\n\tstruct page_counter *counter;\n\tstruct mem_cgroup *memcg;\n\tunsigned short oldid;\n\n\tif (!cgroup_subsys_on_dfl(memory_cgrp_subsys))\n\t\treturn 0;\n\n\tmemcg = page->mem_cgroup;\n\n\t/* Readahead page, never charged */\n\tif (!memcg)\n\t\treturn 0;\n\n\tif (!entry.val) {\n\t\tmemcg_memory_event(memcg, MEMCG_SWAP_FAIL);\n\t\treturn 0;\n\t}\n\n\tmemcg = mem_cgroup_id_get_online(memcg);\n\n\tif (!cgroup_memory_noswap && !mem_cgroup_is_root(memcg) &&\n\t    !page_counter_try_charge(&memcg->swap, nr_pages, &counter)) {\n\t\tmemcg_memory_event(memcg, MEMCG_SWAP_MAX);\n\t\tmemcg_memory_event(memcg, MEMCG_SWAP_FAIL);\n\t\tmem_cgroup_id_put(memcg);\n\t\treturn -ENOMEM;\n\t}\n\n\t/* Get references for the tail pages, too */\n\tif (nr_pages > 1)\n\t\tmem_cgroup_id_get_many(memcg, nr_pages - 1);\n\toldid = swap_cgroup_record(entry, mem_cgroup_id(memcg), nr_pages);\n\tVM_BUG_ON_PAGE(oldid, page);\n\tmod_memcg_state(memcg, MEMCG_SWAP, nr_pages);\n\n\treturn 0;\n}\n\n/**\n * mem_cgroup_uncharge_swap - uncharge swap space\n * @entry: swap entry to uncharge\n * @nr_pages: the amount of swap space to uncharge\n */\nvoid mem_cgroup_uncharge_swap(swp_entry_t entry, unsigned int nr_pages)\n{\n\tstruct mem_cgroup *memcg;\n\tunsigned short id;\n\n\tid = swap_cgroup_record(entry, 0, nr_pages);\n\trcu_read_lock();\n\tmemcg = mem_cgroup_from_id(id);\n\tif (memcg) {\n\t\tif (!cgroup_memory_noswap && !mem_cgroup_is_root(memcg)) {\n\t\t\tif (cgroup_subsys_on_dfl(memory_cgrp_subsys))\n\t\t\t\tpage_counter_uncharge(&memcg->swap, nr_pages);\n\t\t\telse\n\t\t\t\tpage_counter_uncharge(&memcg->memsw, nr_pages);\n\t\t}\n\t\tmod_memcg_state(memcg, MEMCG_SWAP, -nr_pages);\n\t\tmem_cgroup_id_put_many(memcg, nr_pages);\n\t}\n\trcu_read_unlock();\n}\n\nlong mem_cgroup_get_nr_swap_pages(struct mem_cgroup *memcg)\n{\n\tlong nr_swap_pages = get_nr_swap_pages();\n\n\tif (cgroup_memory_noswap || !cgroup_subsys_on_dfl(memory_cgrp_subsys))\n\t\treturn nr_swap_pages;\n\tfor (; memcg != root_mem_cgroup; memcg = parent_mem_cgroup(memcg))\n\t\tnr_swap_pages = min_t(long, nr_swap_pages,\n\t\t\t\t      READ_ONCE(memcg->swap.max) -\n\t\t\t\t      page_counter_read(&memcg->swap));\n\treturn nr_swap_pages;\n}\n\nbool mem_cgroup_swap_full(struct page *page)\n{\n\tstruct mem_cgroup *memcg;\n\n\tVM_BUG_ON_PAGE(!PageLocked(page), page);\n\n\tif (vm_swap_full())\n\t\treturn true;\n\tif (cgroup_memory_noswap || !cgroup_subsys_on_dfl(memory_cgrp_subsys))\n\t\treturn false;\n\n\tmemcg = page->mem_cgroup;\n\tif (!memcg)\n\t\treturn false;\n\n\tfor (; memcg != root_mem_cgroup; memcg = parent_mem_cgroup(memcg)) {\n\t\tunsigned long usage = page_counter_read(&memcg->swap);\n\n\t\tif (usage * 2 >= READ_ONCE(memcg->swap.high) ||\n\t\t    usage * 2 >= READ_ONCE(memcg->swap.max))\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic int __init setup_swap_account(char *s)\n{\n\tif (!strcmp(s, \"1\"))\n\t\tcgroup_memory_noswap = 0;\n\telse if (!strcmp(s, \"0\"))\n\t\tcgroup_memory_noswap = 1;\n\treturn 1;\n}\n__setup(\"swapaccount=\", setup_swap_account);\n\nstatic u64 swap_current_read(struct cgroup_subsys_state *css,\n\t\t\t     struct cftype *cft)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_css(css);\n\n\treturn (u64)page_counter_read(&memcg->swap) * PAGE_SIZE;\n}\n\nstatic int swap_high_show(struct seq_file *m, void *v)\n{\n\treturn seq_puts_memcg_tunable(m,\n\t\tREAD_ONCE(mem_cgroup_from_seq(m)->swap.high));\n}\n\nstatic ssize_t swap_high_write(struct kernfs_open_file *of,\n\t\t\t       char *buf, size_t nbytes, loff_t off)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_css(of_css(of));\n\tunsigned long high;\n\tint err;\n\n\tbuf = strstrip(buf);\n\terr = page_counter_memparse(buf, \"max\", &high);\n\tif (err)\n\t\treturn err;\n\n\tpage_counter_set_high(&memcg->swap, high);\n\n\treturn nbytes;\n}\n\nstatic int swap_max_show(struct seq_file *m, void *v)\n{\n\treturn seq_puts_memcg_tunable(m,\n\t\tREAD_ONCE(mem_cgroup_from_seq(m)->swap.max));\n}\n\nstatic ssize_t swap_max_write(struct kernfs_open_file *of,\n\t\t\t      char *buf, size_t nbytes, loff_t off)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_css(of_css(of));\n\tunsigned long max;\n\tint err;\n\n\tbuf = strstrip(buf);\n\terr = page_counter_memparse(buf, \"max\", &max);\n\tif (err)\n\t\treturn err;\n\n\txchg(&memcg->swap.max, max);\n\n\treturn nbytes;\n}\n\nstatic int swap_events_show(struct seq_file *m, void *v)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_seq(m);\n\n\tseq_printf(m, \"high %lu\\n\",\n\t\t   atomic_long_read(&memcg->memory_events[MEMCG_SWAP_HIGH]));\n\tseq_printf(m, \"max %lu\\n\",\n\t\t   atomic_long_read(&memcg->memory_events[MEMCG_SWAP_MAX]));\n\tseq_printf(m, \"fail %lu\\n\",\n\t\t   atomic_long_read(&memcg->memory_events[MEMCG_SWAP_FAIL]));\n\n\treturn 0;\n}\n\nstatic struct cftype swap_files[] = {\n\t{\n\t\t.name = \"swap.current\",\n\t\t.flags = CFTYPE_NOT_ON_ROOT,\n\t\t.read_u64 = swap_current_read,\n\t},\n\t{\n\t\t.name = \"swap.high\",\n\t\t.flags = CFTYPE_NOT_ON_ROOT,\n\t\t.seq_show = swap_high_show,\n\t\t.write = swap_high_write,\n\t},\n\t{\n\t\t.name = \"swap.max\",\n\t\t.flags = CFTYPE_NOT_ON_ROOT,\n\t\t.seq_show = swap_max_show,\n\t\t.write = swap_max_write,\n\t},\n\t{\n\t\t.name = \"swap.events\",\n\t\t.flags = CFTYPE_NOT_ON_ROOT,\n\t\t.file_offset = offsetof(struct mem_cgroup, swap_events_file),\n\t\t.seq_show = swap_events_show,\n\t},\n\t{ }\t/* terminate */\n};\n\nstatic struct cftype memsw_files[] = {\n\t{\n\t\t.name = \"memsw.usage_in_bytes\",\n\t\t.private = MEMFILE_PRIVATE(_MEMSWAP, RES_USAGE),\n\t\t.read_u64 = mem_cgroup_read_u64,\n\t},\n\t{\n\t\t.name = \"memsw.max_usage_in_bytes\",\n\t\t.private = MEMFILE_PRIVATE(_MEMSWAP, RES_MAX_USAGE),\n\t\t.write = mem_cgroup_reset,\n\t\t.read_u64 = mem_cgroup_read_u64,\n\t},\n\t{\n\t\t.name = \"memsw.limit_in_bytes\",\n\t\t.private = MEMFILE_PRIVATE(_MEMSWAP, RES_LIMIT),\n\t\t.write = mem_cgroup_write,\n\t\t.read_u64 = mem_cgroup_read_u64,\n\t},\n\t{\n\t\t.name = \"memsw.failcnt\",\n\t\t.private = MEMFILE_PRIVATE(_MEMSWAP, RES_FAILCNT),\n\t\t.write = mem_cgroup_reset,\n\t\t.read_u64 = mem_cgroup_read_u64,\n\t},\n\t{ },\t/* terminate */\n};\n\n/*\n * If mem_cgroup_swap_init() is implemented as a subsys_initcall()\n * instead of a core_initcall(), this could mean cgroup_memory_noswap still\n * remains set to false even when memcg is disabled via \"cgroup_disable=memory\"\n * boot parameter. This may result in premature OOPS inside\n * mem_cgroup_get_nr_swap_pages() function in corner cases.\n */\nstatic int __init mem_cgroup_swap_init(void)\n{\n\t/* No memory control -> no swap control */\n\tif (mem_cgroup_disabled())\n\t\tcgroup_memory_noswap = true;\n\n\tif (cgroup_memory_noswap)\n\t\treturn 0;\n\n\tWARN_ON(cgroup_add_dfl_cftypes(&memory_cgrp_subsys, swap_files));\n\tWARN_ON(cgroup_add_legacy_cftypes(&memory_cgrp_subsys, memsw_files));\n\n\treturn 0;\n}\ncore_initcall(mem_cgroup_swap_init);\n\n#endif /* CONFIG_MEMCG_SWAP */\n"}}, "reports": [{"events": [{"location": {"col": 2, "file": 0, "line": 7335}, "message": "WARNING: Assignment of 0/1 to bool variable"}], "macros": [], "notes": [], "path": "/src/mm/memcontrol.c", "reportHash": "e6abfc822d9e8aec44b60e0c7f4ef378", "checkerName": "coccinelle", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 2, "file": 0, "line": 7337}, "message": "WARNING: Assignment of 0/1 to bool variable"}], "macros": [], "notes": [], "path": "/src/mm/memcontrol.c", "reportHash": "94fdaf708518f7872fc197ad093292f8", "checkerName": "coccinelle", "reviewStatus": null, "severity": "UNSPECIFIED"}]};
      window.onload = function() {
        if (!browserCompatible) {
          setNonCompatibleBrowserMessage();
        } else {
          BugViewer.init(data.files, data.reports);
          BugViewer.create();
          BugViewer.initByUrl();
        }
      };
    </script>
  </head>
  <body>
  <div class="container">
    <div id="content">
      <div id="side-bar">
        <div class="header">
          <a href="index.html" class="button">&#8249; Return to List</a>
        </div>
        <div id="report-nav">
          <div class="header">Reports</div>
        </div>
      </div>
      <div id="editor-wrapper">
        <div class="header">
          <div id="file">
            <span class="label">File:</span>
            <span id="file-path"></span>
          </div>
          <div id="checker">
            <span class="label">Checker name:</span>
            <span id="checker-name"></span>
          </div>
          <div id="review-status-wrapper">
            <span class="label">Review status:</span>
            <span id="review-status"></span>
          </div>
        </div>
        <div id="editor"></div>
      </div>
    </div>
  </div>
  </body>
</html>
