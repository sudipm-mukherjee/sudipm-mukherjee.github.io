<!DOCTYPE html>
<html>
  <head>
    <title>Plist HTML Viewer</title>

    <meta charset="UTF-8">

    <style type="text/css">
      .CodeMirror{font-family:monospace;height:300px;color:#000;direction:ltr}.CodeMirror-lines{padding:4px 0}.CodeMirror pre{padding:0 4px}.CodeMirror-gutter-filler,.CodeMirror-scrollbar-filler{background-color:#fff}.CodeMirror-gutters{border-right:1px solid #ddd;background-color:#f7f7f7;white-space:nowrap}.CodeMirror-linenumber{padding:0 3px 0 5px;min-width:20px;text-align:right;color:#999;white-space:nowrap}.CodeMirror-guttermarker{color:#000}.CodeMirror-guttermarker-subtle{color:#999}.CodeMirror-cursor{border-left:1px solid #000;border-right:none;width:0}.CodeMirror div.CodeMirror-secondarycursor{border-left:1px solid silver}.cm-fat-cursor .CodeMirror-cursor{width:auto;border:0!important;background:#7e7}.cm-fat-cursor div.CodeMirror-cursors{z-index:1}.cm-animate-fat-cursor{width:auto;border:0;-webkit-animation:blink 1.06s steps(1) infinite;-moz-animation:blink 1.06s steps(1) infinite;animation:blink 1.06s steps(1) infinite;background-color:#7e7}@-moz-keyframes blink{50%{background-color:transparent}}@-webkit-keyframes blink{50%{background-color:transparent}}@keyframes blink{50%{background-color:transparent}}.cm-tab{display:inline-block;text-decoration:inherit}.CodeMirror-rulers{position:absolute;left:0;right:0;top:-50px;bottom:-20px;overflow:hidden}.CodeMirror-ruler{border-left:1px solid #ccc;top:0;bottom:0;position:absolute}.cm-s-default .cm-header{color:#00f}.cm-s-default .cm-quote{color:#090}.cm-negative{color:#d44}.cm-positive{color:#292}.cm-header,.cm-strong{font-weight:700}.cm-em{font-style:italic}.cm-link{text-decoration:underline}.cm-strikethrough{text-decoration:line-through}.cm-s-default .cm-keyword{color:#708}.cm-s-default .cm-atom{color:#219}.cm-s-default .cm-number{color:#164}.cm-s-default .cm-def{color:#00f}.cm-s-default .cm-variable-2{color:#05a}.cm-s-default .cm-type,.cm-s-default .cm-variable-3{color:#085}.cm-s-default .cm-comment{color:#a50}.cm-s-default .cm-string{color:#a11}.cm-s-default .cm-string-2{color:#f50}.cm-s-default .cm-meta{color:#555}.cm-s-default .cm-qualifier{color:#555}.cm-s-default .cm-builtin{color:#30a}.cm-s-default .cm-bracket{color:#997}.cm-s-default .cm-tag{color:#170}.cm-s-default .cm-attribute{color:#00c}.cm-s-default .cm-hr{color:#999}.cm-s-default .cm-link{color:#00c}.cm-s-default .cm-error{color:red}.cm-invalidchar{color:red}.CodeMirror-composing{border-bottom:2px solid}div.CodeMirror span.CodeMirror-matchingbracket{color:#0f0}div.CodeMirror span.CodeMirror-nonmatchingbracket{color:#f22}.CodeMirror-matchingtag{background:rgba(255,150,0,.3)}.CodeMirror-activeline-background{background:#e8f2ff}.CodeMirror{position:relative;overflow:hidden;background:#fff}.CodeMirror-scroll{overflow:scroll!important;margin-bottom:-30px;margin-right:-30px;padding-bottom:30px;height:100%;outline:0;position:relative}.CodeMirror-sizer{position:relative;border-right:30px solid transparent}.CodeMirror-gutter-filler,.CodeMirror-hscrollbar,.CodeMirror-scrollbar-filler,.CodeMirror-vscrollbar{position:absolute;z-index:6;display:none}.CodeMirror-vscrollbar{right:0;top:0;overflow-x:hidden;overflow-y:scroll}.CodeMirror-hscrollbar{bottom:0;left:0;overflow-y:hidden;overflow-x:scroll}.CodeMirror-scrollbar-filler{right:0;bottom:0}.CodeMirror-gutter-filler{left:0;bottom:0}.CodeMirror-gutters{position:absolute;left:0;top:0;min-height:100%;z-index:3}.CodeMirror-gutter{white-space:normal;height:100%;display:inline-block;vertical-align:top;margin-bottom:-30px}.CodeMirror-gutter-wrapper{position:absolute;z-index:4;background:0 0!important;border:none!important}.CodeMirror-gutter-background{position:absolute;top:0;bottom:0;z-index:4}.CodeMirror-gutter-elt{position:absolute;cursor:default;z-index:4}.CodeMirror-gutter-wrapper ::selection{background-color:transparent}.CodeMirror-gutter-wrapper ::-moz-selection{background-color:transparent}.CodeMirror-lines{cursor:text;min-height:1px}.CodeMirror pre{-moz-border-radius:0;-webkit-border-radius:0;border-radius:0;border-width:0;background:0 0;font-family:inherit;font-size:inherit;margin:0;white-space:pre;word-wrap:normal;line-height:inherit;color:inherit;z-index:2;position:relative;overflow:visible;-webkit-tap-highlight-color:transparent;-webkit-font-variant-ligatures:contextual;font-variant-ligatures:contextual}.CodeMirror-wrap pre{word-wrap:break-word;white-space:pre-wrap;word-break:normal}.CodeMirror-linebackground{position:absolute;left:0;right:0;top:0;bottom:0;z-index:0}.CodeMirror-linewidget{position:relative;z-index:2;overflow:auto}.CodeMirror-rtl pre{direction:rtl}.CodeMirror-code{outline:0}.CodeMirror-gutter,.CodeMirror-gutters,.CodeMirror-linenumber,.CodeMirror-scroll,.CodeMirror-sizer{-moz-box-sizing:content-box;box-sizing:content-box}.CodeMirror-measure{position:absolute;width:100%;height:0;overflow:hidden;visibility:hidden}.CodeMirror-cursor{position:absolute;pointer-events:none}.CodeMirror-measure pre{position:static}div.CodeMirror-cursors{visibility:hidden;position:relative;z-index:3}div.CodeMirror-dragcursors{visibility:visible}.CodeMirror-focused div.CodeMirror-cursors{visibility:visible}.CodeMirror-selected{background:#d9d9d9}.CodeMirror-focused .CodeMirror-selected{background:#d7d4f0}.CodeMirror-crosshair{cursor:crosshair}.CodeMirror-line::selection,.CodeMirror-line>span::selection,.CodeMirror-line>span>span::selection{background:#d7d4f0}.CodeMirror-line::-moz-selection,.CodeMirror-line>span::-moz-selection,.CodeMirror-line>span>span::-moz-selection{background:#d7d4f0}.cm-searching{background-color:#ffa;background-color:rgba(255,255,0,.4)}.cm-force-border{padding-right:.1px}@media print{.CodeMirror div.CodeMirror-cursors{visibility:hidden}}.cm-tab-wrap-hack:after{content:''}span.CodeMirror-selectedtext{background:0 0}
/*# sourceMappingURL=codemirror.min.css.map */

      .severity-low {
  background-color: #669603;
}

.severity-low:after {
  content : 'L';
}

.severity-unspecified {
  background-color: #666666;
}

.severity-unspecified:after {
  content : 'U';
}

.severity-style {
  background-color: #9932cc;
}

.severity-style:after {
  content : 'S';
}

.severity-medium {
  background-color: #a9d323;
  color: black;
}

.severity-medium:after {
  content : 'M';
}

.severity-high {
  background-color: #ffa800;
}

.severity-high:after {
  content : 'H';
}

.severity-critical {
  background-color: #e92625;
}

.severity-critical:after {
  content : 'C';
}

i[class*="severity-"] {
  line-height: normal;
  text-transform: capitalize;
  font-size: 0.8em;
  font-weight: bold;
  color: white;
  display: inline-block;
  width: 16px;
  height: 16px;
  text-align: center;
  font-family: sans-serif;
}

      html, body {
  width: 100%;
  height: 100%;
  padding: 0px;
  margin: 0px;
}

div.container {
  padding: 10px;
}

#content {
  height: 100%;
  display: block;
  overflow: hidden;
}

#content > div {
  margin: 10px;
  overflow: hidden;
  border: 1px solid #ddd;
  border-radius: 3px;
  overflow: hidden;
  height: 97%;
}

.button {
  background-color: #f1f1f1;
  text-decoration: none;
  display: inline-block;
  padding: 8px 16px;
  color: black;
  cursor: pointer;
}

.button:hover {
  background-color: #ddd;
  color: black;
}

.review-status {
  color: white;
  text-align: center;
}

.review-status-confirmed {
  background-color: #e92625;
}

.review-status-false-positive {
  background-color: grey;
}

.review-status-intentional {
  background-color: #669603;
}

      div.container {
  width: 100%;
  height: 100%;
  padding: 0px;
}

#editor-wrapper {
  margin: 10px;
}

#side-bar {
  float: left;
  width: 260px;
  margin: 0px;
}

#report-nav ul {
  list-style-type: none;
  padding: 0;
  margin: 0;
  overflow-y: auto;
  height: 100%;
}

#report-nav ul > li {
  padding: .4em;
  background-color: #fff;
  border-bottom: 1px solid rgba(0,0,0,.125);
  text-align: left;
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

#report-nav ul > li.active {
  background-color: #427ea9;
  color: white;
}

#report-nav ul > li:hover {
  background-color: #427ea9;
  color: white;
  cursor: pointer;
}

#report-nav ul a {
  text-decoration: none;
}

#report-nav i[class*="severity-"] {
  margin-right: 5px;
}

.header {
  border-bottom: 1px solid lightgrey;
  font-family: monospace;
  padding: 10px;
  background-color: #fafbfc;
  border-bottom: 1px solid #e1e4e8;
  border-top-left-radius: 2px;
  border-top-right-radius: 2px;
}

#report-nav .header {
  font-weight: bold;
}

#editor-wrapper .header > div {
  padding-top: 2px;
}

#file-path,
#checker-name {
  color: #195ea2;
}

#review-status {
  padding: 0px 5px;
}

#file-path {
  font-family: monospace;
}

.check-msg {
  display: inline-block;
  padding: 3px 6px;
  margin: 1px;
  -webkit-border-radius: 5px;
  -moz-border-radius: 5px;
  border-radius: 5px;
}

.check-msg.info {
  color: #00546f;
  background-color: #bfdfe9;
  border: 1px solid #87a8b3;
}

.check-msg.error {
  background-color: #f2dede;
  color: #a94442;
  border: 1px solid #ebcccc;
}

.check-msg.macro {
  background-color: #d7dac2;
  color: #4f5c6d;
  border: 1px solid #d7dac2;
}

.check-msg.note {
  background-color: #d7d7d7;
  color: #4f5c6d;
  border: 1px solid #bfbfbf;
}

.check-msg.current {
  border: 2px dashed #3692ff;
}

.check-msg .tag {
  padding: 1px 5px;
  text-align: center;
  border-radius: 2px;
  margin-right: 5px;
  text-decoration: inherit;
}

.check-msg .tag.macro {
  background-color: #83876a;
  color: white;
  text-transform: capitalize;
}

.check-msg .tag.note {
  background-color: #9299a1;
  color: white;
  text-transform: capitalize;
}

.checker-enum {
  color: white;
  padding: 1px 5px;
  text-align: center;
  border-radius: 25px;
  margin-right: 5px;
  text-decoration: inherit;
}

.checker-enum.info {
  background-color: #427ea9;
}

.checker-enum.error {
  background-color: #a94442;
}

.arrow {
  border: solid black;
  border-width: 0 3px 3px 0;
  display: inline-block;
  padding: 3px;
  cursor: pointer;
  margin: 0px 5px;
}

.arrow:hover {
  border: solid #437ea8;
  border-width: 0 3px 3px 0;
}

.left-arrow {
  transform: rotate(135deg);
  -webkit-transform: rotate(135deg);
}

.right-arrow {
  transform: rotate(-45deg);
  -webkit-transform: rotate(-45deg);
}

    </style>

    <script type="text/javascript">
      function setNonCompatibleBrowserMessage() {
  document.body.innerHTML =
    '<h2 style="margin-left: 20px;">Your browser is not compatible with CodeChecker Viewer!</h2> \
     <p style="margin-left: 20px;">The version required for the following browsers are:</p> \
     <ul style="margin-left: 20px;"> \
     <li>Internet Explorer: version 9 or newer</li> \
     <li>Firefox: version 22.0 or newer</li> \
     </ul>';
}

// http://stackoverflow.com/questions/5916900/how-can-you-detect-the-version-of-a-browser
var browserVersion = (function(){
  var ua = navigator.userAgent, tem,
    M = ua.match(/(opera|chrome|safari|firefox|msie|trident(?=\/))\/?\s*(\d+)/i) || [];

  if (/trident/i.test(M[1])) {
    tem = /\brv[ :]+(\d+)/g.exec(ua) || [];
    return 'IE ' + (tem[1] || '');
  }

  if (M[1] === 'Chrome') {
    tem = ua.match(/\b(OPR|Edge)\/(\d+)/);
    if (tem != null) return tem.slice(1).join(' ').replace('OPR', 'Opera');
  }

  M = M[2] ? [M[1], M[2]] : [navigator.appName, navigator.appVersion, '-?'];
  if ((tem = ua.match(/version\/(\d+)/i)) != null) M.splice(1, 1, tem[1]);
    return M.join(' ');
})();

var pos = browserVersion.indexOf(' ');
var browser = browserVersion.substr(0, pos);
var version = parseInt(browserVersion.substr(pos + 1));

var browserCompatible
  = browser === 'Firefox'
  ? version >= 22
  : browser === 'IE'
  ? version >= 9
  : true;


      /* MIT License

Copyright (C) 2017 by Marijn Haverbeke <marijnh@gmail.com> and others

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
 */
      !function(e,t){"object"==typeof exports&&"undefined"!=typeof module?module.exports=t():"function"==typeof define&&define.amd?define(t):e.CodeMirror=t()}(this,function(){"use strict";function e(e){return new RegExp("(^|\\s)"+e+"(?:$|\\s)\\s*")}function t(e){for(var t=e.childNodes.length;t>0;--t)e.removeChild(e.firstChild);return e}function r(e,r){return t(e).appendChild(r)}function n(e,t,r,n){var i=document.createElement(e);if(r&&(i.className=r),n&&(i.style.cssText=n),"string"==typeof t)i.appendChild(document.createTextNode(t));else if(t)for(var o=0;o<t.length;++o)i.appendChild(t[o]);return i}function i(e,t,r,i){var o=n(e,t,r,i);return o.setAttribute("role","presentation"),o}function o(e,t){if(3==t.nodeType&&(t=t.parentNode),e.contains)return e.contains(t);do{if(11==t.nodeType&&(t=t.host),t==e)return!0}while(t=t.parentNode)}function l(){var e;try{e=document.activeElement}catch(t){e=document.body||null}for(;e&&e.shadowRoot&&e.shadowRoot.activeElement;)e=e.shadowRoot.activeElement;return e}function s(t,r){var n=t.className;e(r).test(n)||(t.className+=(n?" ":"")+r)}function a(t,r){for(var n=t.split(" "),i=0;i<n.length;i++)n[i]&&!e(n[i]).test(r)&&(r+=" "+n[i]);return r}function u(e){var t=Array.prototype.slice.call(arguments,1);return function(){return e.apply(null,t)}}function c(e,t,r){t||(t={});for(var n in e)!e.hasOwnProperty(n)||!1===r&&t.hasOwnProperty(n)||(t[n]=e[n]);return t}function f(e,t,r,n,i){null==t&&-1==(t=e.search(/[^\s\u00a0]/))&&(t=e.length);for(var o=n||0,l=i||0;;){var s=e.indexOf("\t",o);if(s<0||s>=t)return l+(t-o);l+=s-o,l+=r-l%r,o=s+1}}function h(e,t){for(var r=0;r<e.length;++r)if(e[r]==t)return r;return-1}function d(e,t,r){for(var n=0,i=0;;){var o=e.indexOf("\t",n);-1==o&&(o=e.length);var l=o-n;if(o==e.length||i+l>=t)return n+Math.min(l,t-i);if(i+=o-n,i+=r-i%r,n=o+1,i>=t)return n}}function p(e){for(;Kl.length<=e;)Kl.push(g(Kl)+" ");return Kl[e]}function g(e){return e[e.length-1]}function v(e,t){for(var r=[],n=0;n<e.length;n++)r[n]=t(e[n],n);return r}function m(e,t,r){for(var n=0,i=r(t);n<e.length&&r(e[n])<=i;)n++;e.splice(n,0,t)}function y(){}function b(e,t){var r;return Object.create?r=Object.create(e):(y.prototype=e,r=new y),t&&c(t,r),r}function w(e){return/\w/.test(e)||e>""&&(e.toUpperCase()!=e.toLowerCase()||jl.test(e))}function x(e,t){return t?!!(t.source.indexOf("\\w")>-1&&w(e))||t.test(e):w(e)}function C(e){for(var t in e)if(e.hasOwnProperty(t)&&e[t])return!1;return!0}function S(e){return e.charCodeAt(0)>=768&&Xl.test(e)}function L(e,t,r){for(;(r<0?t>0:t<e.length)&&S(e.charAt(t));)t+=r;return t}function k(e,t,r){for(var n=t>r?-1:1;;){if(t==r)return t;var i=(t+r)/2,o=n<0?Math.ceil(i):Math.floor(i);if(o==t)return e(o)?t:r;e(o)?r=o:t=o+n}}function T(e,t,r){var o=this;this.input=r,o.scrollbarFiller=n("div",null,"CodeMirror-scrollbar-filler"),o.scrollbarFiller.setAttribute("cm-not-content","true"),o.gutterFiller=n("div",null,"CodeMirror-gutter-filler"),o.gutterFiller.setAttribute("cm-not-content","true"),o.lineDiv=i("div",null,"CodeMirror-code"),o.selectionDiv=n("div",null,null,"position: relative; z-index: 1"),o.cursorDiv=n("div",null,"CodeMirror-cursors"),o.measure=n("div",null,"CodeMirror-measure"),o.lineMeasure=n("div",null,"CodeMirror-measure"),o.lineSpace=i("div",[o.measure,o.lineMeasure,o.selectionDiv,o.cursorDiv,o.lineDiv],null,"position: relative; outline: none");var l=i("div",[o.lineSpace],"CodeMirror-lines");o.mover=n("div",[l],null,"position: relative"),o.sizer=n("div",[o.mover],"CodeMirror-sizer"),o.sizerWidth=null,o.heightForcer=n("div",null,null,"position: absolute; height: "+Rl+"px; width: 1px;"),o.gutters=n("div",null,"CodeMirror-gutters"),o.lineGutter=null,o.scroller=n("div",[o.sizer,o.heightForcer,o.gutters],"CodeMirror-scroll"),o.scroller.setAttribute("tabIndex","-1"),o.wrapper=n("div",[o.scrollbarFiller,o.gutterFiller,o.scroller],"CodeMirror"),gl&&vl<8&&(o.gutters.style.zIndex=-1,o.scroller.style.paddingRight=0),ml||fl&&Tl||(o.scroller.draggable=!0),e&&(e.appendChild?e.appendChild(o.wrapper):e(o.wrapper)),o.viewFrom=o.viewTo=t.first,o.reportedViewFrom=o.reportedViewTo=t.first,o.view=[],o.renderedView=null,o.externalMeasured=null,o.viewOffset=0,o.lastWrapHeight=o.lastWrapWidth=0,o.updateLineNumbers=null,o.nativeBarWidth=o.barHeight=o.barWidth=0,o.scrollbarsClipped=!1,o.lineNumWidth=o.lineNumInnerWidth=o.lineNumChars=null,o.alignWidgets=!1,o.cachedCharWidth=o.cachedTextHeight=o.cachedPaddingH=null,o.maxLine=null,o.maxLineLength=0,o.maxLineChanged=!1,o.wheelDX=o.wheelDY=o.wheelStartX=o.wheelStartY=null,o.shift=!1,o.selForContextMenu=null,o.activeTouch=null,r.init(o)}function M(e,t){if((t-=e.first)<0||t>=e.size)throw new Error("There is no line "+(t+e.first)+" in the document.");for(var r=e;!r.lines;)for(var n=0;;++n){var i=r.children[n],o=i.chunkSize();if(t<o){r=i;break}t-=o}return r.lines[t]}function N(e,t,r){var n=[],i=t.line;return e.iter(t.line,r.line+1,function(e){var o=e.text;i==r.line&&(o=o.slice(0,r.ch)),i==t.line&&(o=o.slice(t.ch)),n.push(o),++i}),n}function O(e,t,r){var n=[];return e.iter(t,r,function(e){n.push(e.text)}),n}function A(e,t){var r=t-e.height;if(r)for(var n=e;n;n=n.parent)n.height+=r}function W(e){if(null==e.parent)return null;for(var t=e.parent,r=h(t.lines,e),n=t.parent;n;t=n,n=n.parent)for(var i=0;n.children[i]!=t;++i)r+=n.children[i].chunkSize();return r+t.first}function D(e,t){var r=e.first;e:do{for(var n=0;n<e.children.length;++n){var i=e.children[n],o=i.height;if(t<o){e=i;continue e}t-=o,r+=i.chunkSize()}return r}while(!e.lines);for(var l=0;l<e.lines.length;++l){var s=e.lines[l].height;if(t<s)break;t-=s}return r+l}function H(e,t){return t>=e.first&&t<e.first+e.size}function F(e,t){return String(e.lineNumberFormatter(t+e.firstLineNumber))}function E(e,t,r){if(void 0===r&&(r=null),!(this instanceof E))return new E(e,t,r);this.line=e,this.ch=t,this.sticky=r}function P(e,t){return e.line-t.line||e.ch-t.ch}function I(e,t){return e.sticky==t.sticky&&0==P(e,t)}function z(e){return E(e.line,e.ch)}function R(e,t){return P(e,t)<0?t:e}function B(e,t){return P(e,t)<0?e:t}function G(e,t){return Math.max(e.first,Math.min(t,e.first+e.size-1))}function U(e,t){if(t.line<e.first)return E(e.first,0);var r=e.first+e.size-1;return t.line>r?E(r,M(e,r).text.length):V(t,M(e,t.line).text.length)}function V(e,t){var r=e.ch;return null==r||r>t?E(e.line,t):r<0?E(e.line,0):e}function K(e,t){for(var r=[],n=0;n<t.length;n++)r[n]=U(e,t[n]);return r}function j(){Yl=!0}function X(){_l=!0}function Y(e,t,r){this.marker=e,this.from=t,this.to=r}function _(e,t){if(e)for(var r=0;r<e.length;++r){var n=e[r];if(n.marker==t)return n}}function $(e,t){for(var r,n=0;n<e.length;++n)e[n]!=t&&(r||(r=[])).push(e[n]);return r}function q(e,t){e.markedSpans=e.markedSpans?e.markedSpans.concat([t]):[t],t.marker.attachLine(e)}function Z(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t)||o.from==t&&"bookmark"==l.type&&(!r||!o.marker.insertLeft)){var s=null==o.to||(l.inclusiveRight?o.to>=t:o.to>t);(n||(n=[])).push(new Y(l,o.from,s?null:o.to))}}return n}function Q(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.to||(l.inclusiveRight?o.to>=t:o.to>t)||o.from==t&&"bookmark"==l.type&&(!r||o.marker.insertLeft)){var s=null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t);(n||(n=[])).push(new Y(l,s?null:o.from-t,null==o.to?null:o.to-t))}}return n}function J(e,t){if(t.full)return null;var r=H(e,t.from.line)&&M(e,t.from.line).markedSpans,n=H(e,t.to.line)&&M(e,t.to.line).markedSpans;if(!r&&!n)return null;var i=t.from.ch,o=t.to.ch,l=0==P(t.from,t.to),s=Z(r,i,l),a=Q(n,o,l),u=1==t.text.length,c=g(t.text).length+(u?i:0);if(s)for(var f=0;f<s.length;++f){var h=s[f];if(null==h.to){var d=_(a,h.marker);d?u&&(h.to=null==d.to?null:d.to+c):h.to=i}}if(a)for(var p=0;p<a.length;++p){var v=a[p];null!=v.to&&(v.to+=c),null==v.from?_(s,v.marker)||(v.from=c,u&&(s||(s=[])).push(v)):(v.from+=c,u&&(s||(s=[])).push(v))}s&&(s=ee(s)),a&&a!=s&&(a=ee(a));var m=[s];if(!u){var y,b=t.text.length-2;if(b>0&&s)for(var w=0;w<s.length;++w)null==s[w].to&&(y||(y=[])).push(new Y(s[w].marker,null,null));for(var x=0;x<b;++x)m.push(y);m.push(a)}return m}function ee(e){for(var t=0;t<e.length;++t){var r=e[t];null!=r.from&&r.from==r.to&&!1!==r.marker.clearWhenEmpty&&e.splice(t--,1)}return e.length?e:null}function te(e,t,r){var n=null;if(e.iter(t.line,r.line+1,function(e){if(e.markedSpans)for(var t=0;t<e.markedSpans.length;++t){var r=e.markedSpans[t].marker;!r.readOnly||n&&-1!=h(n,r)||(n||(n=[])).push(r)}}),!n)return null;for(var i=[{from:t,to:r}],o=0;o<n.length;++o)for(var l=n[o],s=l.find(0),a=0;a<i.length;++a){var u=i[a];if(!(P(u.to,s.from)<0||P(u.from,s.to)>0)){var c=[a,1],f=P(u.from,s.from),d=P(u.to,s.to);(f<0||!l.inclusiveLeft&&!f)&&c.push({from:u.from,to:s.from}),(d>0||!l.inclusiveRight&&!d)&&c.push({from:s.to,to:u.to}),i.splice.apply(i,c),a+=c.length-3}}return i}function re(e){var t=e.markedSpans;if(t){for(var r=0;r<t.length;++r)t[r].marker.detachLine(e);e.markedSpans=null}}function ne(e,t){if(t){for(var r=0;r<t.length;++r)t[r].marker.attachLine(e);e.markedSpans=t}}function ie(e){return e.inclusiveLeft?-1:0}function oe(e){return e.inclusiveRight?1:0}function le(e,t){var r=e.lines.length-t.lines.length;if(0!=r)return r;var n=e.find(),i=t.find(),o=P(n.from,i.from)||ie(e)-ie(t);if(o)return-o;var l=P(n.to,i.to)||oe(e)-oe(t);return l||t.id-e.id}function se(e,t){var r,n=_l&&e.markedSpans;if(n)for(var i=void 0,o=0;o<n.length;++o)(i=n[o]).marker.collapsed&&null==(t?i.from:i.to)&&(!r||le(r,i.marker)<0)&&(r=i.marker);return r}function ae(e){return se(e,!0)}function ue(e){return se(e,!1)}function ce(e,t,r,n,i){var o=M(e,t),l=_l&&o.markedSpans;if(l)for(var s=0;s<l.length;++s){var a=l[s];if(a.marker.collapsed){var u=a.marker.find(0),c=P(u.from,r)||ie(a.marker)-ie(i),f=P(u.to,n)||oe(a.marker)-oe(i);if(!(c>=0&&f<=0||c<=0&&f>=0)&&(c<=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.to,r)>=0:P(u.to,r)>0)||c>=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.from,n)<=0:P(u.from,n)<0)))return!0}}}function fe(e){for(var t;t=ae(e);)e=t.find(-1,!0).line;return e}function he(e){for(var t;t=ue(e);)e=t.find(1,!0).line;return e}function de(e){for(var t,r;t=ue(e);)e=t.find(1,!0).line,(r||(r=[])).push(e);return r}function pe(e,t){var r=M(e,t),n=fe(r);return r==n?t:W(n)}function ge(e,t){if(t>e.lastLine())return t;var r,n=M(e,t);if(!ve(e,n))return t;for(;r=ue(n);)n=r.find(1,!0).line;return W(n)+1}function ve(e,t){var r=_l&&t.markedSpans;if(r)for(var n=void 0,i=0;i<r.length;++i)if((n=r[i]).marker.collapsed){if(null==n.from)return!0;if(!n.marker.widgetNode&&0==n.from&&n.marker.inclusiveLeft&&me(e,t,n))return!0}}function me(e,t,r){if(null==r.to){var n=r.marker.find(1,!0);return me(e,n.line,_(n.line.markedSpans,r.marker))}if(r.marker.inclusiveRight&&r.to==t.text.length)return!0;for(var i=void 0,o=0;o<t.markedSpans.length;++o)if((i=t.markedSpans[o]).marker.collapsed&&!i.marker.widgetNode&&i.from==r.to&&(null==i.to||i.to!=r.from)&&(i.marker.inclusiveLeft||r.marker.inclusiveRight)&&me(e,t,i))return!0}function ye(e){for(var t=0,r=(e=fe(e)).parent,n=0;n<r.lines.length;++n){var i=r.lines[n];if(i==e)break;t+=i.height}for(var o=r.parent;o;r=o,o=r.parent)for(var l=0;l<o.children.length;++l){var s=o.children[l];if(s==r)break;t+=s.height}return t}function be(e){if(0==e.height)return 0;for(var t,r=e.text.length,n=e;t=ae(n);){var i=t.find(0,!0);n=i.from.line,r+=i.from.ch-i.to.ch}for(n=e;t=ue(n);){var o=t.find(0,!0);r-=n.text.length-o.from.ch,r+=(n=o.to.line).text.length-o.to.ch}return r}function we(e){var t=e.display,r=e.doc;t.maxLine=M(r,r.first),t.maxLineLength=be(t.maxLine),t.maxLineChanged=!0,r.iter(function(e){var r=be(e);r>t.maxLineLength&&(t.maxLineLength=r,t.maxLine=e)})}function xe(e,t,r,n){if(!e)return n(t,r,"ltr",0);for(var i=!1,o=0;o<e.length;++o){var l=e[o];(l.from<r&&l.to>t||t==r&&l.to==t)&&(n(Math.max(l.from,t),Math.min(l.to,r),1==l.level?"rtl":"ltr",o),i=!0)}i||n(t,r,"ltr")}function Ce(e,t,r){var n;$l=null;for(var i=0;i<e.length;++i){var o=e[i];if(o.from<t&&o.to>t)return i;o.to==t&&(o.from!=o.to&&"before"==r?n=i:$l=i),o.from==t&&(o.from!=o.to&&"before"!=r?n=i:$l=i)}return null!=n?n:$l}function Se(e,t){var r=e.order;return null==r&&(r=e.order=ql(e.text,t)),r}function Le(e,t){return e._handlers&&e._handlers[t]||Zl}function ke(e,t,r){if(e.removeEventListener)e.removeEventListener(t,r,!1);else if(e.detachEvent)e.detachEvent("on"+t,r);else{var n=e._handlers,i=n&&n[t];if(i){var o=h(i,r);o>-1&&(n[t]=i.slice(0,o).concat(i.slice(o+1)))}}}function Te(e,t){var r=Le(e,t);if(r.length)for(var n=Array.prototype.slice.call(arguments,2),i=0;i<r.length;++i)r[i].apply(null,n)}function Me(e,t,r){return"string"==typeof t&&(t={type:t,preventDefault:function(){this.defaultPrevented=!0}}),Te(e,r||t.type,e,t),He(t)||t.codemirrorIgnore}function Ne(e){var t=e._handlers&&e._handlers.cursorActivity;if(t)for(var r=e.curOp.cursorActivityHandlers||(e.curOp.cursorActivityHandlers=[]),n=0;n<t.length;++n)-1==h(r,t[n])&&r.push(t[n])}function Oe(e,t){return Le(e,t).length>0}function Ae(e){e.prototype.on=function(e,t){Ql(this,e,t)},e.prototype.off=function(e,t){ke(this,e,t)}}function We(e){e.preventDefault?e.preventDefault():e.returnValue=!1}function De(e){e.stopPropagation?e.stopPropagation():e.cancelBubble=!0}function He(e){return null!=e.defaultPrevented?e.defaultPrevented:0==e.returnValue}function Fe(e){We(e),De(e)}function Ee(e){return e.target||e.srcElement}function Pe(e){var t=e.which;return null==t&&(1&e.button?t=1:2&e.button?t=3:4&e.button&&(t=2)),Ml&&e.ctrlKey&&1==t&&(t=3),t}function Ie(e){if(null==Il){var t=n("span","​");r(e,n("span",[t,document.createTextNode("x")])),0!=e.firstChild.offsetHeight&&(Il=t.offsetWidth<=1&&t.offsetHeight>2&&!(gl&&vl<8))}var i=Il?n("span","​"):n("span"," ",null,"display: inline-block; width: 1px; margin-right: -1px");return i.setAttribute("cm-text",""),i}function ze(e){if(null!=zl)return zl;var n=r(e,document.createTextNode("AخA")),i=Wl(n,0,1).getBoundingClientRect(),o=Wl(n,1,2).getBoundingClientRect();return t(e),!(!i||i.left==i.right)&&(zl=o.right-i.right<3)}function Re(e){if(null!=ns)return ns;var t=r(e,n("span","x")),i=t.getBoundingClientRect(),o=Wl(t,0,1).getBoundingClientRect();return ns=Math.abs(i.left-o.left)>1}function Be(e,t){arguments.length>2&&(t.dependencies=Array.prototype.slice.call(arguments,2)),is[e]=t}function Ge(e){if("string"==typeof e&&os.hasOwnProperty(e))e=os[e];else if(e&&"string"==typeof e.name&&os.hasOwnProperty(e.name)){var t=os[e.name];"string"==typeof t&&(t={name:t}),(e=b(t,e)).name=t.name}else{if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+xml$/.test(e))return Ge("application/xml");if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+json$/.test(e))return Ge("application/json")}return"string"==typeof e?{name:e}:e||{name:"null"}}function Ue(e,t){t=Ge(t);var r=is[t.name];if(!r)return Ue(e,"text/plain");var n=r(e,t);if(ls.hasOwnProperty(t.name)){var i=ls[t.name];for(var o in i)i.hasOwnProperty(o)&&(n.hasOwnProperty(o)&&(n["_"+o]=n[o]),n[o]=i[o])}if(n.name=t.name,t.helperType&&(n.helperType=t.helperType),t.modeProps)for(var l in t.modeProps)n[l]=t.modeProps[l];return n}function Ve(e,t){c(t,ls.hasOwnProperty(e)?ls[e]:ls[e]={})}function Ke(e,t){if(!0===t)return t;if(e.copyState)return e.copyState(t);var r={};for(var n in t){var i=t[n];i instanceof Array&&(i=i.concat([])),r[n]=i}return r}function je(e,t){for(var r;e.innerMode&&(r=e.innerMode(t))&&r.mode!=e;)t=r.state,e=r.mode;return r||{mode:e,state:t}}function Xe(e,t,r){return!e.startState||e.startState(t,r)}function Ye(e,t,r,n){var i=[e.state.modeGen],o={};tt(e,t.text,e.doc.mode,r,function(e,t){return i.push(e,t)},o,n);for(var l=r.state,s=0;s<e.state.overlays.length;++s)!function(n){var l=e.state.overlays[n],s=1,a=0;r.state=!0,tt(e,t.text,l.mode,r,function(e,t){for(var r=s;a<e;){var n=i[s];n>e&&i.splice(s,1,e,i[s+1],n),s+=2,a=Math.min(e,n)}if(t)if(l.opaque)i.splice(r,s-r,e,"overlay "+t),s=r+2;else for(;r<s;r+=2){var o=i[r+1];i[r+1]=(o?o+" ":"")+"overlay "+t}},o)}(s);return r.state=l,{styles:i,classes:o.bgClass||o.textClass?o:null}}function _e(e,t,r){if(!t.styles||t.styles[0]!=e.state.modeGen){var n=$e(e,W(t)),i=t.text.length>e.options.maxHighlightLength&&Ke(e.doc.mode,n.state),o=Ye(e,t,n);i&&(n.state=i),t.stateAfter=n.save(!i),t.styles=o.styles,o.classes?t.styleClasses=o.classes:t.styleClasses&&(t.styleClasses=null),r===e.doc.highlightFrontier&&(e.doc.modeFrontier=Math.max(e.doc.modeFrontier,++e.doc.highlightFrontier))}return t.styles}function $e(e,t,r){var n=e.doc,i=e.display;if(!n.mode.startState)return new us(n,!0,t);var o=rt(e,t,r),l=o>n.first&&M(n,o-1).stateAfter,s=l?us.fromSaved(n,l,o):new us(n,Xe(n.mode),o);return n.iter(o,t,function(r){qe(e,r.text,s);var n=s.line;r.stateAfter=n==t-1||n%5==0||n>=i.viewFrom&&n<i.viewTo?s.save():null,s.nextLine()}),r&&(n.modeFrontier=s.line),s}function qe(e,t,r,n){var i=e.doc.mode,o=new ss(t,e.options.tabSize,r);for(o.start=o.pos=n||0,""==t&&Ze(i,r.state);!o.eol();)Qe(i,o,r.state),o.start=o.pos}function Ze(e,t){if(e.blankLine)return e.blankLine(t);if(e.innerMode){var r=je(e,t);return r.mode.blankLine?r.mode.blankLine(r.state):void 0}}function Qe(e,t,r,n){for(var i=0;i<10;i++){n&&(n[0]=je(e,r).mode);var o=e.token(t,r);if(t.pos>t.start)return o}throw new Error("Mode "+e.name+" failed to advance stream.")}function Je(e,t,r,n){var i,o,l=e.doc,s=l.mode,a=M(l,(t=U(l,t)).line),u=$e(e,t.line,r),c=new ss(a.text,e.options.tabSize,u);for(n&&(o=[]);(n||c.pos<t.ch)&&!c.eol();)c.start=c.pos,i=Qe(s,c,u.state),n&&o.push(new cs(c,i,Ke(l.mode,u.state)));return n?o:new cs(c,i,u.state)}function et(e,t){if(e)for(;;){var r=e.match(/(?:^|\s+)line-(background-)?(\S+)/);if(!r)break;e=e.slice(0,r.index)+e.slice(r.index+r[0].length);var n=r[1]?"bgClass":"textClass";null==t[n]?t[n]=r[2]:new RegExp("(?:^|s)"+r[2]+"(?:$|s)").test(t[n])||(t[n]+=" "+r[2])}return e}function tt(e,t,r,n,i,o,l){var s=r.flattenSpans;null==s&&(s=e.options.flattenSpans);var a,u=0,c=null,f=new ss(t,e.options.tabSize,n),h=e.options.addModeClass&&[null];for(""==t&&et(Ze(r,n.state),o);!f.eol();){if(f.pos>e.options.maxHighlightLength?(s=!1,l&&qe(e,t,n,f.pos),f.pos=t.length,a=null):a=et(Qe(r,f,n.state,h),o),h){var d=h[0].name;d&&(a="m-"+(a?d+" "+a:d))}if(!s||c!=a){for(;u<f.start;)i(u=Math.min(f.start,u+5e3),c);c=a}f.start=f.pos}for(;u<f.pos;){var p=Math.min(f.pos,u+5e3);i(p,c),u=p}}function rt(e,t,r){for(var n,i,o=e.doc,l=r?-1:t-(e.doc.mode.innerMode?1e3:100),s=t;s>l;--s){if(s<=o.first)return o.first;var a=M(o,s-1),u=a.stateAfter;if(u&&(!r||s+(u instanceof as?u.lookAhead:0)<=o.modeFrontier))return s;var c=f(a.text,null,e.options.tabSize);(null==i||n>c)&&(i=s-1,n=c)}return i}function nt(e,t){if(e.modeFrontier=Math.min(e.modeFrontier,t),!(e.highlightFrontier<t-10)){for(var r=e.first,n=t-1;n>r;n--){var i=M(e,n).stateAfter;if(i&&(!(i instanceof as)||n+i.lookAhead<t)){r=n+1;break}}e.highlightFrontier=Math.min(e.highlightFrontier,r)}}function it(e,t,r,n){e.text=t,e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null),null!=e.order&&(e.order=null),re(e),ne(e,r);var i=n?n(e):1;i!=e.height&&A(e,i)}function ot(e){e.parent=null,re(e)}function lt(e,t){if(!e||/^\s*$/.test(e))return null;var r=t.addModeClass?ps:ds;return r[e]||(r[e]=e.replace(/\S+/g,"cm-$&"))}function st(e,t){var r=i("span",null,null,ml?"padding-right: .1px":null),n={pre:i("pre",[r],"CodeMirror-line"),content:r,col:0,pos:0,cm:e,trailingSpace:!1,splitSpaces:(gl||ml)&&e.getOption("lineWrapping")};t.measure={};for(var o=0;o<=(t.rest?t.rest.length:0);o++){var l=o?t.rest[o-1]:t.line,s=void 0;n.pos=0,n.addToken=ut,ze(e.display.measure)&&(s=Se(l,e.doc.direction))&&(n.addToken=ft(n.addToken,s)),n.map=[],dt(l,n,_e(e,l,t!=e.display.externalMeasured&&W(l))),l.styleClasses&&(l.styleClasses.bgClass&&(n.bgClass=a(l.styleClasses.bgClass,n.bgClass||"")),l.styleClasses.textClass&&(n.textClass=a(l.styleClasses.textClass,n.textClass||""))),0==n.map.length&&n.map.push(0,0,n.content.appendChild(Ie(e.display.measure))),0==o?(t.measure.map=n.map,t.measure.cache={}):((t.measure.maps||(t.measure.maps=[])).push(n.map),(t.measure.caches||(t.measure.caches=[])).push({}))}if(ml){var u=n.content.lastChild;(/\bcm-tab\b/.test(u.className)||u.querySelector&&u.querySelector(".cm-tab"))&&(n.content.className="cm-tab-wrap-hack")}return Te(e,"renderLine",e,t.line,n.pre),n.pre.className&&(n.textClass=a(n.pre.className,n.textClass||"")),n}function at(e){var t=n("span","•","cm-invalidchar");return t.title="\\u"+e.charCodeAt(0).toString(16),t.setAttribute("aria-label",t.title),t}function ut(e,t,r,i,o,l,s){if(t){var a,u=e.splitSpaces?ct(t,e.trailingSpace):t,c=e.cm.state.specialChars,f=!1;if(c.test(t)){a=document.createDocumentFragment();for(var h=0;;){c.lastIndex=h;var d=c.exec(t),g=d?d.index-h:t.length-h;if(g){var v=document.createTextNode(u.slice(h,h+g));gl&&vl<9?a.appendChild(n("span",[v])):a.appendChild(v),e.map.push(e.pos,e.pos+g,v),e.col+=g,e.pos+=g}if(!d)break;h+=g+1;var m=void 0;if("\t"==d[0]){var y=e.cm.options.tabSize,b=y-e.col%y;(m=a.appendChild(n("span",p(b),"cm-tab"))).setAttribute("role","presentation"),m.setAttribute("cm-text","\t"),e.col+=b}else"\r"==d[0]||"\n"==d[0]?((m=a.appendChild(n("span","\r"==d[0]?"␍":"␤","cm-invalidchar"))).setAttribute("cm-text",d[0]),e.col+=1):((m=e.cm.options.specialCharPlaceholder(d[0])).setAttribute("cm-text",d[0]),gl&&vl<9?a.appendChild(n("span",[m])):a.appendChild(m),e.col+=1);e.map.push(e.pos,e.pos+1,m),e.pos++}}else e.col+=t.length,a=document.createTextNode(u),e.map.push(e.pos,e.pos+t.length,a),gl&&vl<9&&(f=!0),e.pos+=t.length;if(e.trailingSpace=32==u.charCodeAt(t.length-1),r||i||o||f||s){var w=r||"";i&&(w+=i),o&&(w+=o);var x=n("span",[a],w,s);return l&&(x.title=l),e.content.appendChild(x)}e.content.appendChild(a)}}function ct(e,t){if(e.length>1&&!/  /.test(e))return e;for(var r=t,n="",i=0;i<e.length;i++){var o=e.charAt(i);" "!=o||!r||i!=e.length-1&&32!=e.charCodeAt(i+1)||(o=" "),n+=o,r=" "==o}return n}function ft(e,t){return function(r,n,i,o,l,s,a){i=i?i+" cm-force-border":"cm-force-border";for(var u=r.pos,c=u+n.length;;){for(var f=void 0,h=0;h<t.length&&!((f=t[h]).to>u&&f.from<=u);h++);if(f.to>=c)return e(r,n,i,o,l,s,a);e(r,n.slice(0,f.to-u),i,o,null,s,a),o=null,n=n.slice(f.to-u),u=f.to}}}function ht(e,t,r,n){var i=!n&&r.widgetNode;i&&e.map.push(e.pos,e.pos+t,i),!n&&e.cm.display.input.needsContentAttribute&&(i||(i=e.content.appendChild(document.createElement("span"))),i.setAttribute("cm-marker",r.id)),i&&(e.cm.display.input.setUneditable(i),e.content.appendChild(i)),e.pos+=t,e.trailingSpace=!1}function dt(e,t,r){var n=e.markedSpans,i=e.text,o=0;if(n)for(var l,s,a,u,c,f,h,d=i.length,p=0,g=1,v="",m=0;;){if(m==p){a=u=c=f=s="",h=null,m=1/0;for(var y=[],b=void 0,w=0;w<n.length;++w){var x=n[w],C=x.marker;"bookmark"==C.type&&x.from==p&&C.widgetNode?y.push(C):x.from<=p&&(null==x.to||x.to>p||C.collapsed&&x.to==p&&x.from==p)?(null!=x.to&&x.to!=p&&m>x.to&&(m=x.to,u=""),C.className&&(a+=" "+C.className),C.css&&(s=(s?s+";":"")+C.css),C.startStyle&&x.from==p&&(c+=" "+C.startStyle),C.endStyle&&x.to==m&&(b||(b=[])).push(C.endStyle,x.to),C.title&&!f&&(f=C.title),C.collapsed&&(!h||le(h.marker,C)<0)&&(h=x)):x.from>p&&m>x.from&&(m=x.from)}if(b)for(var S=0;S<b.length;S+=2)b[S+1]==m&&(u+=" "+b[S]);if(!h||h.from==p)for(var L=0;L<y.length;++L)ht(t,0,y[L]);if(h&&(h.from||0)==p){if(ht(t,(null==h.to?d+1:h.to)-p,h.marker,null==h.from),null==h.to)return;h.to==p&&(h=!1)}}if(p>=d)break;for(var k=Math.min(d,m);;){if(v){var T=p+v.length;if(!h){var M=T>k?v.slice(0,k-p):v;t.addToken(t,M,l?l+a:a,c,p+M.length==m?u:"",f,s)}if(T>=k){v=v.slice(k-p),p=k;break}p=T,c=""}v=i.slice(o,o=r[g++]),l=lt(r[g++],t.cm.options)}}else for(var N=1;N<r.length;N+=2)t.addToken(t,i.slice(o,o=r[N]),lt(r[N+1],t.cm.options))}function pt(e,t,r){this.line=t,this.rest=de(t),this.size=this.rest?W(g(this.rest))-r+1:1,this.node=this.text=null,this.hidden=ve(e,t)}function gt(e,t,r){for(var n,i=[],o=t;o<r;o=n){var l=new pt(e.doc,M(e.doc,o),o);n=o+l.size,i.push(l)}return i}function vt(e){gs?gs.ops.push(e):e.ownsGroup=gs={ops:[e],delayedCallbacks:[]}}function mt(e){var t=e.delayedCallbacks,r=0;do{for(;r<t.length;r++)t[r].call(null);for(var n=0;n<e.ops.length;n++){var i=e.ops[n];if(i.cursorActivityHandlers)for(;i.cursorActivityCalled<i.cursorActivityHandlers.length;)i.cursorActivityHandlers[i.cursorActivityCalled++].call(null,i.cm)}}while(r<t.length)}function yt(e,t){var r=e.ownsGroup;if(r)try{mt(r)}finally{gs=null,t(r)}}function bt(e,t){var r=Le(e,t);if(r.length){var n,i=Array.prototype.slice.call(arguments,2);gs?n=gs.delayedCallbacks:vs?n=vs:(n=vs=[],setTimeout(wt,0));for(var o=0;o<r.length;++o)!function(e){n.push(function(){return r[e].apply(null,i)})}(o)}}function wt(){var e=vs;vs=null;for(var t=0;t<e.length;++t)e[t]()}function xt(e,t,r,n){for(var i=0;i<t.changes.length;i++){var o=t.changes[i];"text"==o?kt(e,t):"gutter"==o?Mt(e,t,r,n):"class"==o?Tt(e,t):"widget"==o&&Nt(e,t,n)}t.changes=null}function Ct(e){return e.node==e.text&&(e.node=n("div",null,null,"position: relative"),e.text.parentNode&&e.text.parentNode.replaceChild(e.node,e.text),e.node.appendChild(e.text),gl&&vl<8&&(e.node.style.zIndex=2)),e.node}function St(e,t){var r=t.bgClass?t.bgClass+" "+(t.line.bgClass||""):t.line.bgClass;if(r&&(r+=" CodeMirror-linebackground"),t.background)r?t.background.className=r:(t.background.parentNode.removeChild(t.background),t.background=null);else if(r){var i=Ct(t);t.background=i.insertBefore(n("div",null,r),i.firstChild),e.display.input.setUneditable(t.background)}}function Lt(e,t){var r=e.display.externalMeasured;return r&&r.line==t.line?(e.display.externalMeasured=null,t.measure=r.measure,r.built):st(e,t)}function kt(e,t){var r=t.text.className,n=Lt(e,t);t.text==t.node&&(t.node=n.pre),t.text.parentNode.replaceChild(n.pre,t.text),t.text=n.pre,n.bgClass!=t.bgClass||n.textClass!=t.textClass?(t.bgClass=n.bgClass,t.textClass=n.textClass,Tt(e,t)):r&&(t.text.className=r)}function Tt(e,t){St(e,t),t.line.wrapClass?Ct(t).className=t.line.wrapClass:t.node!=t.text&&(t.node.className="");var r=t.textClass?t.textClass+" "+(t.line.textClass||""):t.line.textClass;t.text.className=r||""}function Mt(e,t,r,i){if(t.gutter&&(t.node.removeChild(t.gutter),t.gutter=null),t.gutterBackground&&(t.node.removeChild(t.gutterBackground),t.gutterBackground=null),t.line.gutterClass){var o=Ct(t);t.gutterBackground=n("div",null,"CodeMirror-gutter-background "+t.line.gutterClass,"left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px; width: "+i.gutterTotalWidth+"px"),e.display.input.setUneditable(t.gutterBackground),o.insertBefore(t.gutterBackground,t.text)}var l=t.line.gutterMarkers;if(e.options.lineNumbers||l){var s=Ct(t),a=t.gutter=n("div",null,"CodeMirror-gutter-wrapper","left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px");if(e.display.input.setUneditable(a),s.insertBefore(a,t.text),t.line.gutterClass&&(a.className+=" "+t.line.gutterClass),!e.options.lineNumbers||l&&l["CodeMirror-linenumbers"]||(t.lineNumber=a.appendChild(n("div",F(e.options,r),"CodeMirror-linenumber CodeMirror-gutter-elt","left: "+i.gutterLeft["CodeMirror-linenumbers"]+"px; width: "+e.display.lineNumInnerWidth+"px"))),l)for(var u=0;u<e.options.gutters.length;++u){var c=e.options.gutters[u],f=l.hasOwnProperty(c)&&l[c];f&&a.appendChild(n("div",[f],"CodeMirror-gutter-elt","left: "+i.gutterLeft[c]+"px; width: "+i.gutterWidth[c]+"px"))}}}function Nt(e,t,r){t.alignable&&(t.alignable=null);for(var n=t.node.firstChild,i=void 0;n;n=i)i=n.nextSibling,"CodeMirror-linewidget"==n.className&&t.node.removeChild(n);At(e,t,r)}function Ot(e,t,r,n){var i=Lt(e,t);return t.text=t.node=i.pre,i.bgClass&&(t.bgClass=i.bgClass),i.textClass&&(t.textClass=i.textClass),Tt(e,t),Mt(e,t,r,n),At(e,t,n),t.node}function At(e,t,r){if(Wt(e,t.line,t,r,!0),t.rest)for(var n=0;n<t.rest.length;n++)Wt(e,t.rest[n],t,r,!1)}function Wt(e,t,r,i,o){if(t.widgets)for(var l=Ct(r),s=0,a=t.widgets;s<a.length;++s){var u=a[s],c=n("div",[u.node],"CodeMirror-linewidget");u.handleMouseEvents||c.setAttribute("cm-ignore-events","true"),Dt(u,c,r,i),e.display.input.setUneditable(c),o&&u.above?l.insertBefore(c,r.gutter||r.text):l.appendChild(c),bt(u,"redraw")}}function Dt(e,t,r,n){if(e.noHScroll){(r.alignable||(r.alignable=[])).push(t);var i=n.wrapperWidth;t.style.left=n.fixedPos+"px",e.coverGutter||(i-=n.gutterTotalWidth,t.style.paddingLeft=n.gutterTotalWidth+"px"),t.style.width=i+"px"}e.coverGutter&&(t.style.zIndex=5,t.style.position="relative",e.noHScroll||(t.style.marginLeft=-n.gutterTotalWidth+"px"))}function Ht(e){if(null!=e.height)return e.height;var t=e.doc.cm;if(!t)return 0;if(!o(document.body,e.node)){var i="position: relative;";e.coverGutter&&(i+="margin-left: -"+t.display.gutters.offsetWidth+"px;"),e.noHScroll&&(i+="width: "+t.display.wrapper.clientWidth+"px;"),r(t.display.measure,n("div",[e.node],null,i))}return e.height=e.node.parentNode.offsetHeight}function Ft(e,t){for(var r=Ee(t);r!=e.wrapper;r=r.parentNode)if(!r||1==r.nodeType&&"true"==r.getAttribute("cm-ignore-events")||r.parentNode==e.sizer&&r!=e.mover)return!0}function Et(e){return e.lineSpace.offsetTop}function Pt(e){return e.mover.offsetHeight-e.lineSpace.offsetHeight}function It(e){if(e.cachedPaddingH)return e.cachedPaddingH;var t=r(e.measure,n("pre","x")),i=window.getComputedStyle?window.getComputedStyle(t):t.currentStyle,o={left:parseInt(i.paddingLeft),right:parseInt(i.paddingRight)};return isNaN(o.left)||isNaN(o.right)||(e.cachedPaddingH=o),o}function zt(e){return Rl-e.display.nativeBarWidth}function Rt(e){return e.display.scroller.clientWidth-zt(e)-e.display.barWidth}function Bt(e){return e.display.scroller.clientHeight-zt(e)-e.display.barHeight}function Gt(e,t,r){var n=e.options.lineWrapping,i=n&&Rt(e);if(!t.measure.heights||n&&t.measure.width!=i){var o=t.measure.heights=[];if(n){t.measure.width=i;for(var l=t.text.firstChild.getClientRects(),s=0;s<l.length-1;s++){var a=l[s],u=l[s+1];Math.abs(a.bottom-u.bottom)>2&&o.push((a.bottom+u.top)/2-r.top)}}o.push(r.bottom-r.top)}}function Ut(e,t,r){if(e.line==t)return{map:e.measure.map,cache:e.measure.cache};for(var n=0;n<e.rest.length;n++)if(e.rest[n]==t)return{map:e.measure.maps[n],cache:e.measure.caches[n]};for(var i=0;i<e.rest.length;i++)if(W(e.rest[i])>r)return{map:e.measure.maps[i],cache:e.measure.caches[i],before:!0}}function Vt(e,t){var n=W(t=fe(t)),i=e.display.externalMeasured=new pt(e.doc,t,n);i.lineN=n;var o=i.built=st(e,i);return i.text=o.pre,r(e.display.lineMeasure,o.pre),i}function Kt(e,t,r,n){return Yt(e,Xt(e,t),r,n)}function jt(e,t){if(t>=e.display.viewFrom&&t<e.display.viewTo)return e.display.view[Lr(e,t)];var r=e.display.externalMeasured;return r&&t>=r.lineN&&t<r.lineN+r.size?r:void 0}function Xt(e,t){var r=W(t),n=jt(e,r);n&&!n.text?n=null:n&&n.changes&&(xt(e,n,r,br(e)),e.curOp.forceUpdate=!0),n||(n=Vt(e,t));var i=Ut(n,t,r);return{line:t,view:n,rect:null,map:i.map,cache:i.cache,before:i.before,hasHeights:!1}}function Yt(e,t,r,n,i){t.before&&(r=-1);var o,l=r+(n||"");return t.cache.hasOwnProperty(l)?o=t.cache[l]:(t.rect||(t.rect=t.view.text.getBoundingClientRect()),t.hasHeights||(Gt(e,t.view,t.rect),t.hasHeights=!0),(o=qt(e,t,r,n)).bogus||(t.cache[l]=o)),{left:o.left,right:o.right,top:i?o.rtop:o.top,bottom:i?o.rbottom:o.bottom}}function _t(e,t,r){for(var n,i,o,l,s,a,u=0;u<e.length;u+=3)if(s=e[u],a=e[u+1],t<s?(i=0,o=1,l="left"):t<a?o=(i=t-s)+1:(u==e.length-3||t==a&&e[u+3]>t)&&(i=(o=a-s)-1,t>=a&&(l="right")),null!=i){if(n=e[u+2],s==a&&r==(n.insertLeft?"left":"right")&&(l=r),"left"==r&&0==i)for(;u&&e[u-2]==e[u-3]&&e[u-1].insertLeft;)n=e[2+(u-=3)],l="left";if("right"==r&&i==a-s)for(;u<e.length-3&&e[u+3]==e[u+4]&&!e[u+5].insertLeft;)n=e[(u+=3)+2],l="right";break}return{node:n,start:i,end:o,collapse:l,coverStart:s,coverEnd:a}}function $t(e,t){var r=ms;if("left"==t)for(var n=0;n<e.length&&(r=e[n]).left==r.right;n++);else for(var i=e.length-1;i>=0&&(r=e[i]).left==r.right;i--);return r}function qt(e,t,r,n){var i,o=_t(t.map,r,n),l=o.node,s=o.start,a=o.end,u=o.collapse;if(3==l.nodeType){for(var c=0;c<4;c++){for(;s&&S(t.line.text.charAt(o.coverStart+s));)--s;for(;o.coverStart+a<o.coverEnd&&S(t.line.text.charAt(o.coverStart+a));)++a;if((i=gl&&vl<9&&0==s&&a==o.coverEnd-o.coverStart?l.parentNode.getBoundingClientRect():$t(Wl(l,s,a).getClientRects(),n)).left||i.right||0==s)break;a=s,s-=1,u="right"}gl&&vl<11&&(i=Zt(e.display.measure,i))}else{s>0&&(u=n="right");var f;i=e.options.lineWrapping&&(f=l.getClientRects()).length>1?f["right"==n?f.length-1:0]:l.getBoundingClientRect()}if(gl&&vl<9&&!s&&(!i||!i.left&&!i.right)){var h=l.parentNode.getClientRects()[0];i=h?{left:h.left,right:h.left+yr(e.display),top:h.top,bottom:h.bottom}:ms}for(var d=i.top-t.rect.top,p=i.bottom-t.rect.top,g=(d+p)/2,v=t.view.measure.heights,m=0;m<v.length-1&&!(g<v[m]);m++);var y=m?v[m-1]:0,b=v[m],w={left:("right"==u?i.right:i.left)-t.rect.left,right:("left"==u?i.left:i.right)-t.rect.left,top:y,bottom:b};return i.left||i.right||(w.bogus=!0),e.options.singleCursorHeightPerLine||(w.rtop=d,w.rbottom=p),w}function Zt(e,t){if(!window.screen||null==screen.logicalXDPI||screen.logicalXDPI==screen.deviceXDPI||!Re(e))return t;var r=screen.logicalXDPI/screen.deviceXDPI,n=screen.logicalYDPI/screen.deviceYDPI;return{left:t.left*r,right:t.right*r,top:t.top*n,bottom:t.bottom*n}}function Qt(e){if(e.measure&&(e.measure.cache={},e.measure.heights=null,e.rest))for(var t=0;t<e.rest.length;t++)e.measure.caches[t]={}}function Jt(e){e.display.externalMeasure=null,t(e.display.lineMeasure);for(var r=0;r<e.display.view.length;r++)Qt(e.display.view[r])}function er(e){Jt(e),e.display.cachedCharWidth=e.display.cachedTextHeight=e.display.cachedPaddingH=null,e.options.lineWrapping||(e.display.maxLineChanged=!0),e.display.lineNumChars=null}function tr(){return bl&&kl?-(document.body.getBoundingClientRect().left-parseInt(getComputedStyle(document.body).marginLeft)):window.pageXOffset||(document.documentElement||document.body).scrollLeft}function rr(){return bl&&kl?-(document.body.getBoundingClientRect().top-parseInt(getComputedStyle(document.body).marginTop)):window.pageYOffset||(document.documentElement||document.body).scrollTop}function nr(e){var t=0;if(e.widgets)for(var r=0;r<e.widgets.length;++r)e.widgets[r].above&&(t+=Ht(e.widgets[r]));return t}function ir(e,t,r,n,i){if(!i){var o=nr(t);r.top+=o,r.bottom+=o}if("line"==n)return r;n||(n="local");var l=ye(t);if("local"==n?l+=Et(e.display):l-=e.display.viewOffset,"page"==n||"window"==n){var s=e.display.lineSpace.getBoundingClientRect();l+=s.top+("window"==n?0:rr());var a=s.left+("window"==n?0:tr());r.left+=a,r.right+=a}return r.top+=l,r.bottom+=l,r}function or(e,t,r){if("div"==r)return t;var n=t.left,i=t.top;if("page"==r)n-=tr(),i-=rr();else if("local"==r||!r){var o=e.display.sizer.getBoundingClientRect();n+=o.left,i+=o.top}var l=e.display.lineSpace.getBoundingClientRect();return{left:n-l.left,top:i-l.top}}function lr(e,t,r,n,i){return n||(n=M(e.doc,t.line)),ir(e,n,Kt(e,n,t.ch,i),r)}function sr(e,t,r,n,i,o){function l(t,l){var s=Yt(e,i,t,l?"right":"left",o);return l?s.left=s.right:s.right=s.left,ir(e,n,s,r)}function s(e,t,r){var n=1==a[t].level;return l(r?e-1:e,n!=r)}n=n||M(e.doc,t.line),i||(i=Xt(e,n));var a=Se(n,e.doc.direction),u=t.ch,c=t.sticky;if(u>=n.text.length?(u=n.text.length,c="before"):u<=0&&(u=0,c="after"),!a)return l("before"==c?u-1:u,"before"==c);var f=Ce(a,u,c),h=$l,d=s(u,f,"before"==c);return null!=h&&(d.other=s(u,h,"before"!=c)),d}function ar(e,t){var r=0;t=U(e.doc,t),e.options.lineWrapping||(r=yr(e.display)*t.ch);var n=M(e.doc,t.line),i=ye(n)+Et(e.display);return{left:r,right:r,top:i,bottom:i+n.height}}function ur(e,t,r,n,i){var o=E(e,t,r);return o.xRel=i,n&&(o.outside=!0),o}function cr(e,t,r){var n=e.doc;if((r+=e.display.viewOffset)<0)return ur(n.first,0,null,!0,-1);var i=D(n,r),o=n.first+n.size-1;if(i>o)return ur(n.first+n.size-1,M(n,o).text.length,null,!0,1);t<0&&(t=0);for(var l=M(n,i);;){var s=pr(e,l,i,t,r),a=ue(l),u=a&&a.find(0,!0);if(!a||!(s.ch>u.from.ch||s.ch==u.from.ch&&s.xRel>0))return s;i=W(l=u.to.line)}}function fr(e,t,r,n){n-=nr(t);var i=t.text.length,o=k(function(t){return Yt(e,r,t-1).bottom<=n},i,0);return i=k(function(t){return Yt(e,r,t).top>n},o,i),{begin:o,end:i}}function hr(e,t,r,n){return r||(r=Xt(e,t)),fr(e,t,r,ir(e,t,Yt(e,r,n),"line").top)}function dr(e,t,r,n){return!(e.bottom<=r)&&(e.top>r||(n?e.left:e.right)>t)}function pr(e,t,r,n,i){i-=ye(t);var o=Xt(e,t),l=nr(t),s=0,a=t.text.length,u=!0,c=Se(t,e.doc.direction);if(c){var f=(e.options.lineWrapping?vr:gr)(e,t,r,o,c,n,i);s=(u=1!=f.level)?f.from:f.to-1,a=u?f.to:f.from-1}var h,d,p=null,g=null,v=k(function(t){var r=Yt(e,o,t);return r.top+=l,r.bottom+=l,!!dr(r,n,i,!1)&&(r.top<=i&&r.left<=n&&(p=t,g=r),!0)},s,a),m=!1;if(g){var y=n-g.left<g.right-n,b=y==u;v=p+(b?0:1),d=b?"after":"before",h=y?g.left:g.right}else{u||v!=a&&v!=s||v++,d=0==v?"after":v==t.text.length?"before":Yt(e,o,v-(u?1:0)).bottom+l<=i==u?"after":"before";var w=sr(e,E(r,v,d),"line",t,o);h=w.left,m=i<w.top||i>=w.bottom}return v=L(t.text,v,1),ur(r,v,d,m,n-h)}function gr(e,t,r,n,i,o,l){var s=k(function(s){var a=i[s],u=1!=a.level;return dr(sr(e,E(r,u?a.to:a.from,u?"before":"after"),"line",t,n),o,l,!0)},0,i.length-1),a=i[s];if(s>0){var u=1!=a.level,c=sr(e,E(r,u?a.from:a.to,u?"after":"before"),"line",t,n);dr(c,o,l,!0)&&c.top>l&&(a=i[s-1])}return a}function vr(e,t,r,n,i,o,l){for(var s=fr(e,t,n,l),a=s.begin,u=s.end,c=null,f=null,h=0;h<i.length;h++){var d=i[h];if(!(d.from>=u||d.to<=a)){var p=Yt(e,n,1!=d.level?Math.min(u,d.to)-1:Math.max(a,d.from)).right,g=p<o?o-p+1e9:p-o;(!c||f>g)&&(c=d,f=g)}}return c||(c=i[i.length-1]),c.from<a&&(c={from:a,to:c.to,level:c.level}),c.to>u&&(c={from:c.from,to:u,level:c.level}),c}function mr(e){if(null!=e.cachedTextHeight)return e.cachedTextHeight;if(null==hs){hs=n("pre");for(var i=0;i<49;++i)hs.appendChild(document.createTextNode("x")),hs.appendChild(n("br"));hs.appendChild(document.createTextNode("x"))}r(e.measure,hs);var o=hs.offsetHeight/50;return o>3&&(e.cachedTextHeight=o),t(e.measure),o||1}function yr(e){if(null!=e.cachedCharWidth)return e.cachedCharWidth;var t=n("span","xxxxxxxxxx"),i=n("pre",[t]);r(e.measure,i);var o=t.getBoundingClientRect(),l=(o.right-o.left)/10;return l>2&&(e.cachedCharWidth=l),l||10}function br(e){for(var t=e.display,r={},n={},i=t.gutters.clientLeft,o=t.gutters.firstChild,l=0;o;o=o.nextSibling,++l)r[e.options.gutters[l]]=o.offsetLeft+o.clientLeft+i,n[e.options.gutters[l]]=o.clientWidth;return{fixedPos:wr(t),gutterTotalWidth:t.gutters.offsetWidth,gutterLeft:r,gutterWidth:n,wrapperWidth:t.wrapper.clientWidth}}function wr(e){return e.scroller.getBoundingClientRect().left-e.sizer.getBoundingClientRect().left}function xr(e){var t=mr(e.display),r=e.options.lineWrapping,n=r&&Math.max(5,e.display.scroller.clientWidth/yr(e.display)-3);return function(i){if(ve(e.doc,i))return 0;var o=0;if(i.widgets)for(var l=0;l<i.widgets.length;l++)i.widgets[l].height&&(o+=i.widgets[l].height);return r?o+(Math.ceil(i.text.length/n)||1)*t:o+t}}function Cr(e){var t=e.doc,r=xr(e);t.iter(function(e){var t=r(e);t!=e.height&&A(e,t)})}function Sr(e,t,r,n){var i=e.display;if(!r&&"true"==Ee(t).getAttribute("cm-not-content"))return null;var o,l,s=i.lineSpace.getBoundingClientRect();try{o=t.clientX-s.left,l=t.clientY-s.top}catch(t){return null}var a,u=cr(e,o,l);if(n&&1==u.xRel&&(a=M(e.doc,u.line).text).length==u.ch){var c=f(a,a.length,e.options.tabSize)-a.length;u=E(u.line,Math.max(0,Math.round((o-It(e.display).left)/yr(e.display))-c))}return u}function Lr(e,t){if(t>=e.display.viewTo)return null;if((t-=e.display.viewFrom)<0)return null;for(var r=e.display.view,n=0;n<r.length;n++)if((t-=r[n].size)<0)return n}function kr(e){e.display.input.showSelection(e.display.input.prepareSelection())}function Tr(e,t){void 0===t&&(t=!0);for(var r=e.doc,n={},i=n.cursors=document.createDocumentFragment(),o=n.selection=document.createDocumentFragment(),l=0;l<r.sel.ranges.length;l++)if(t||l!=r.sel.primIndex){var s=r.sel.ranges[l];if(!(s.from().line>=e.display.viewTo||s.to().line<e.display.viewFrom)){var a=s.empty();(a||e.options.showCursorWhenSelecting)&&Mr(e,s.head,i),a||Or(e,s,o)}}return n}function Mr(e,t,r){var i=sr(e,t,"div",null,null,!e.options.singleCursorHeightPerLine),o=r.appendChild(n("div"," ","CodeMirror-cursor"));if(o.style.left=i.left+"px",o.style.top=i.top+"px",o.style.height=Math.max(0,i.bottom-i.top)*e.options.cursorHeight+"px",i.other){var l=r.appendChild(n("div"," ","CodeMirror-cursor CodeMirror-secondarycursor"));l.style.display="",l.style.left=i.other.left+"px",l.style.top=i.other.top+"px",l.style.height=.85*(i.other.bottom-i.other.top)+"px"}}function Nr(e,t){return e.top-t.top||e.left-t.left}function Or(e,t,r){function i(e,t,r,i){t<0&&(t=0),t=Math.round(t),i=Math.round(i),a.appendChild(n("div",null,"CodeMirror-selected","position: absolute; left: "+e+"px;\n                             top: "+t+"px; width: "+(null==r?f-e:r)+"px;\n                             height: "+(i-t)+"px"))}function o(t,r,n){function o(r,n){return lr(e,E(t,r),"div",u,n)}var l,a,u=M(s,t),h=u.text.length,d=Se(u,s.direction);return xe(d,r||0,null==n?h:n,function(t,s,p,g){var v=o(t,"ltr"==p?"left":"right"),m=o(s-1,"ltr"==p?"right":"left");if("ltr"==p){var y=null==r&&0==t?c:v.left,b=null==n&&s==h?f:m.right;m.top-v.top<=3?i(y,m.top,b-y,m.bottom):(i(y,v.top,null,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top),i(c,m.top,m.right,m.bottom))}else if(t<s){var w=null==r&&0==t?f:v.right,x=null==n&&s==h?c:m.left;if(m.top-v.top<=3)i(x,m.top,w-x,m.bottom);else{var C=c;if(g){var S=hr(e,u,null,t).end;C=o(S-(/\s/.test(u.text.charAt(S-1))?2:1),"left").left}i(C,v.top,w-C,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top);var L=null;d.length,L=o(hr(e,u,null,s).begin,"right").right-x,i(x,m.top,L,m.bottom)}}(!l||Nr(v,l)<0)&&(l=v),Nr(m,l)<0&&(l=m),(!a||Nr(v,a)<0)&&(a=v),Nr(m,a)<0&&(a=m)}),{start:l,end:a}}var l=e.display,s=e.doc,a=document.createDocumentFragment(),u=It(e.display),c=u.left,f=Math.max(l.sizerWidth,Rt(e)-l.sizer.offsetLeft)-u.right,h=t.from(),d=t.to();if(h.line==d.line)o(h.line,h.ch,d.ch);else{var p=M(s,h.line),g=M(s,d.line),v=fe(p)==fe(g),m=o(h.line,h.ch,v?p.text.length+1:null).end,y=o(d.line,v?0:null,d.ch).start;v&&(m.top<y.top-2?(i(m.right,m.top,null,m.bottom),i(c,y.top,y.left,y.bottom)):i(m.right,m.top,y.left-m.right,m.bottom)),m.bottom<y.top&&i(c,m.bottom,null,y.top)}r.appendChild(a)}function Ar(e){if(e.state.focused){var t=e.display;clearInterval(t.blinker);var r=!0;t.cursorDiv.style.visibility="",e.options.cursorBlinkRate>0?t.blinker=setInterval(function(){return t.cursorDiv.style.visibility=(r=!r)?"":"hidden"},e.options.cursorBlinkRate):e.options.cursorBlinkRate<0&&(t.cursorDiv.style.visibility="hidden")}}function Wr(e){e.state.focused||(e.display.input.focus(),Hr(e))}function Dr(e){e.state.delayingBlurEvent=!0,setTimeout(function(){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1,Fr(e))},100)}function Hr(e,t){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1),"nocursor"!=e.options.readOnly&&(e.state.focused||(Te(e,"focus",e,t),e.state.focused=!0,s(e.display.wrapper,"CodeMirror-focused"),e.curOp||e.display.selForContextMenu==e.doc.sel||(e.display.input.reset(),ml&&setTimeout(function(){return e.display.input.reset(!0)},20)),e.display.input.receivedFocus()),Ar(e))}function Fr(e,t){e.state.delayingBlurEvent||(e.state.focused&&(Te(e,"blur",e,t),e.state.focused=!1,Fl(e.display.wrapper,"CodeMirror-focused")),clearInterval(e.display.blinker),setTimeout(function(){e.state.focused||(e.display.shift=!1)},150))}function Er(e){for(var t=e.display,r=t.lineDiv.offsetTop,n=0;n<t.view.length;n++){var i=t.view[n],o=void 0;if(!i.hidden){if(gl&&vl<8){var l=i.node.offsetTop+i.node.offsetHeight;o=l-r,r=l}else{var s=i.node.getBoundingClientRect();o=s.bottom-s.top}var a=i.line.height-o;if(o<2&&(o=mr(t)),(a>.005||a<-.005)&&(A(i.line,o),Pr(i.line),i.rest))for(var u=0;u<i.rest.length;u++)Pr(i.rest[u])}}}function Pr(e){if(e.widgets)for(var t=0;t<e.widgets.length;++t)e.widgets[t].height=e.widgets[t].node.parentNode.offsetHeight}function Ir(e,t,r){var n=r&&null!=r.top?Math.max(0,r.top):e.scroller.scrollTop;n=Math.floor(n-Et(e));var i=r&&null!=r.bottom?r.bottom:n+e.wrapper.clientHeight,o=D(t,n),l=D(t,i);if(r&&r.ensure){var s=r.ensure.from.line,a=r.ensure.to.line;s<o?(o=s,l=D(t,ye(M(t,s))+e.wrapper.clientHeight)):Math.min(a,t.lastLine())>=l&&(o=D(t,ye(M(t,a))-e.wrapper.clientHeight),l=a)}return{from:o,to:Math.max(l,o+1)}}function zr(e){var t=e.display,r=t.view;if(t.alignWidgets||t.gutters.firstChild&&e.options.fixedGutter){for(var n=wr(t)-t.scroller.scrollLeft+e.doc.scrollLeft,i=t.gutters.offsetWidth,o=n+"px",l=0;l<r.length;l++)if(!r[l].hidden){e.options.fixedGutter&&(r[l].gutter&&(r[l].gutter.style.left=o),r[l].gutterBackground&&(r[l].gutterBackground.style.left=o));var s=r[l].alignable;if(s)for(var a=0;a<s.length;a++)s[a].style.left=o}e.options.fixedGutter&&(t.gutters.style.left=n+i+"px")}}function Rr(e){if(!e.options.lineNumbers)return!1;var t=e.doc,r=F(e.options,t.first+t.size-1),i=e.display;if(r.length!=i.lineNumChars){var o=i.measure.appendChild(n("div",[n("div",r)],"CodeMirror-linenumber CodeMirror-gutter-elt")),l=o.firstChild.offsetWidth,s=o.offsetWidth-l;return i.lineGutter.style.width="",i.lineNumInnerWidth=Math.max(l,i.lineGutter.offsetWidth-s)+1,i.lineNumWidth=i.lineNumInnerWidth+s,i.lineNumChars=i.lineNumInnerWidth?r.length:-1,i.lineGutter.style.width=i.lineNumWidth+"px",Wn(e),!0}return!1}function Br(e,t){if(!Me(e,"scrollCursorIntoView")){var r=e.display,i=r.sizer.getBoundingClientRect(),o=null;if(t.top+i.top<0?o=!0:t.bottom+i.top>(window.innerHeight||document.documentElement.clientHeight)&&(o=!1),null!=o&&!Sl){var l=n("div","​",null,"position: absolute;\n                         top: "+(t.top-r.viewOffset-Et(e.display))+"px;\n                         height: "+(t.bottom-t.top+zt(e)+r.barHeight)+"px;\n                         left: "+t.left+"px; width: "+Math.max(2,t.right-t.left)+"px;");e.display.lineSpace.appendChild(l),l.scrollIntoView(o),e.display.lineSpace.removeChild(l)}}}function Gr(e,t,r,n){null==n&&(n=0);var i;e.options.lineWrapping||t!=r||(r="before"==(t=t.ch?E(t.line,"before"==t.sticky?t.ch-1:t.ch,"after"):t).sticky?E(t.line,t.ch+1,"before"):t);for(var o=0;o<5;o++){var l=!1,s=sr(e,t),a=r&&r!=t?sr(e,r):s,u=Vr(e,i={left:Math.min(s.left,a.left),top:Math.min(s.top,a.top)-n,right:Math.max(s.left,a.left),bottom:Math.max(s.bottom,a.bottom)+n}),c=e.doc.scrollTop,f=e.doc.scrollLeft;if(null!=u.scrollTop&&(qr(e,u.scrollTop),Math.abs(e.doc.scrollTop-c)>1&&(l=!0)),null!=u.scrollLeft&&(Qr(e,u.scrollLeft),Math.abs(e.doc.scrollLeft-f)>1&&(l=!0)),!l)break}return i}function Ur(e,t){var r=Vr(e,t);null!=r.scrollTop&&qr(e,r.scrollTop),null!=r.scrollLeft&&Qr(e,r.scrollLeft)}function Vr(e,t){var r=e.display,n=mr(e.display);t.top<0&&(t.top=0);var i=e.curOp&&null!=e.curOp.scrollTop?e.curOp.scrollTop:r.scroller.scrollTop,o=Bt(e),l={};t.bottom-t.top>o&&(t.bottom=t.top+o);var s=e.doc.height+Pt(r),a=t.top<n,u=t.bottom>s-n;if(t.top<i)l.scrollTop=a?0:t.top;else if(t.bottom>i+o){var c=Math.min(t.top,(u?s:t.bottom)-o);c!=i&&(l.scrollTop=c)}var f=e.curOp&&null!=e.curOp.scrollLeft?e.curOp.scrollLeft:r.scroller.scrollLeft,h=Rt(e)-(e.options.fixedGutter?r.gutters.offsetWidth:0),d=t.right-t.left>h;return d&&(t.right=t.left+h),t.left<10?l.scrollLeft=0:t.left<f?l.scrollLeft=Math.max(0,t.left-(d?0:10)):t.right>h+f-3&&(l.scrollLeft=t.right+(d?0:10)-h),l}function Kr(e,t){null!=t&&(_r(e),e.curOp.scrollTop=(null==e.curOp.scrollTop?e.doc.scrollTop:e.curOp.scrollTop)+t)}function jr(e){_r(e);var t=e.getCursor();e.curOp.scrollToPos={from:t,to:t,margin:e.options.cursorScrollMargin}}function Xr(e,t,r){null==t&&null==r||_r(e),null!=t&&(e.curOp.scrollLeft=t),null!=r&&(e.curOp.scrollTop=r)}function Yr(e,t){_r(e),e.curOp.scrollToPos=t}function _r(e){var t=e.curOp.scrollToPos;t&&(e.curOp.scrollToPos=null,$r(e,ar(e,t.from),ar(e,t.to),t.margin))}function $r(e,t,r,n){var i=Vr(e,{left:Math.min(t.left,r.left),top:Math.min(t.top,r.top)-n,right:Math.max(t.right,r.right),bottom:Math.max(t.bottom,r.bottom)+n});Xr(e,i.scrollLeft,i.scrollTop)}function qr(e,t){Math.abs(e.doc.scrollTop-t)<2||(fl||On(e,{top:t}),Zr(e,t,!0),fl&&On(e),Cn(e,100))}function Zr(e,t,r){t=Math.min(e.display.scroller.scrollHeight-e.display.scroller.clientHeight,t),(e.display.scroller.scrollTop!=t||r)&&(e.doc.scrollTop=t,e.display.scrollbars.setScrollTop(t),e.display.scroller.scrollTop!=t&&(e.display.scroller.scrollTop=t))}function Qr(e,t,r,n){t=Math.min(t,e.display.scroller.scrollWidth-e.display.scroller.clientWidth),(r?t==e.doc.scrollLeft:Math.abs(e.doc.scrollLeft-t)<2)&&!n||(e.doc.scrollLeft=t,zr(e),e.display.scroller.scrollLeft!=t&&(e.display.scroller.scrollLeft=t),e.display.scrollbars.setScrollLeft(t))}function Jr(e){var t=e.display,r=t.gutters.offsetWidth,n=Math.round(e.doc.height+Pt(e.display));return{clientHeight:t.scroller.clientHeight,viewHeight:t.wrapper.clientHeight,scrollWidth:t.scroller.scrollWidth,clientWidth:t.scroller.clientWidth,viewWidth:t.wrapper.clientWidth,barLeft:e.options.fixedGutter?r:0,docHeight:n,scrollHeight:n+zt(e)+t.barHeight,nativeBarWidth:t.nativeBarWidth,gutterWidth:r}}function en(e,t){t||(t=Jr(e));var r=e.display.barWidth,n=e.display.barHeight;tn(e,t);for(var i=0;i<4&&r!=e.display.barWidth||n!=e.display.barHeight;i++)r!=e.display.barWidth&&e.options.lineWrapping&&Er(e),tn(e,Jr(e)),r=e.display.barWidth,n=e.display.barHeight}function tn(e,t){var r=e.display,n=r.scrollbars.update(t);r.sizer.style.paddingRight=(r.barWidth=n.right)+"px",r.sizer.style.paddingBottom=(r.barHeight=n.bottom)+"px",r.heightForcer.style.borderBottom=n.bottom+"px solid transparent",n.right&&n.bottom?(r.scrollbarFiller.style.display="block",r.scrollbarFiller.style.height=n.bottom+"px",r.scrollbarFiller.style.width=n.right+"px"):r.scrollbarFiller.style.display="",n.bottom&&e.options.coverGutterNextToScrollbar&&e.options.fixedGutter?(r.gutterFiller.style.display="block",r.gutterFiller.style.height=n.bottom+"px",r.gutterFiller.style.width=t.gutterWidth+"px"):r.gutterFiller.style.display=""}function rn(e){e.display.scrollbars&&(e.display.scrollbars.clear(),e.display.scrollbars.addClass&&Fl(e.display.wrapper,e.display.scrollbars.addClass)),e.display.scrollbars=new ws[e.options.scrollbarStyle](function(t){e.display.wrapper.insertBefore(t,e.display.scrollbarFiller),Ql(t,"mousedown",function(){e.state.focused&&setTimeout(function(){return e.display.input.focus()},0)}),t.setAttribute("cm-not-content","true")},function(t,r){"horizontal"==r?Qr(e,t):qr(e,t)},e),e.display.scrollbars.addClass&&s(e.display.wrapper,e.display.scrollbars.addClass)}function nn(e){e.curOp={cm:e,viewChanged:!1,startHeight:e.doc.height,forceUpdate:!1,updateInput:null,typing:!1,changeObjs:null,cursorActivityHandlers:null,cursorActivityCalled:0,selectionChanged:!1,updateMaxLine:!1,scrollLeft:null,scrollTop:null,scrollToPos:null,focus:!1,id:++xs},vt(e.curOp)}function on(e){yt(e.curOp,function(e){for(var t=0;t<e.ops.length;t++)e.ops[t].cm.curOp=null;ln(e)})}function ln(e){for(var t=e.ops,r=0;r<t.length;r++)sn(t[r]);for(var n=0;n<t.length;n++)an(t[n]);for(var i=0;i<t.length;i++)un(t[i]);for(var o=0;o<t.length;o++)cn(t[o]);for(var l=0;l<t.length;l++)fn(t[l])}function sn(e){var t=e.cm,r=t.display;Ln(t),e.updateMaxLine&&we(t),e.mustUpdate=e.viewChanged||e.forceUpdate||null!=e.scrollTop||e.scrollToPos&&(e.scrollToPos.from.line<r.viewFrom||e.scrollToPos.to.line>=r.viewTo)||r.maxLineChanged&&t.options.lineWrapping,e.update=e.mustUpdate&&new Cs(t,e.mustUpdate&&{top:e.scrollTop,ensure:e.scrollToPos},e.forceUpdate)}function an(e){e.updatedDisplay=e.mustUpdate&&Mn(e.cm,e.update)}function un(e){var t=e.cm,r=t.display;e.updatedDisplay&&Er(t),e.barMeasure=Jr(t),r.maxLineChanged&&!t.options.lineWrapping&&(e.adjustWidthTo=Kt(t,r.maxLine,r.maxLine.text.length).left+3,t.display.sizerWidth=e.adjustWidthTo,e.barMeasure.scrollWidth=Math.max(r.scroller.clientWidth,r.sizer.offsetLeft+e.adjustWidthTo+zt(t)+t.display.barWidth),e.maxScrollLeft=Math.max(0,r.sizer.offsetLeft+e.adjustWidthTo-Rt(t))),(e.updatedDisplay||e.selectionChanged)&&(e.preparedSelection=r.input.prepareSelection())}function cn(e){var t=e.cm;null!=e.adjustWidthTo&&(t.display.sizer.style.minWidth=e.adjustWidthTo+"px",e.maxScrollLeft<t.doc.scrollLeft&&Qr(t,Math.min(t.display.scroller.scrollLeft,e.maxScrollLeft),!0),t.display.maxLineChanged=!1);var r=e.focus&&e.focus==l();e.preparedSelection&&t.display.input.showSelection(e.preparedSelection,r),(e.updatedDisplay||e.startHeight!=t.doc.height)&&en(t,e.barMeasure),e.updatedDisplay&&Dn(t,e.barMeasure),e.selectionChanged&&Ar(t),t.state.focused&&e.updateInput&&t.display.input.reset(e.typing),r&&Wr(e.cm)}function fn(e){var t=e.cm,r=t.display,n=t.doc;e.updatedDisplay&&Nn(t,e.update),null==r.wheelStartX||null==e.scrollTop&&null==e.scrollLeft&&!e.scrollToPos||(r.wheelStartX=r.wheelStartY=null),null!=e.scrollTop&&Zr(t,e.scrollTop,e.forceScroll),null!=e.scrollLeft&&Qr(t,e.scrollLeft,!0,!0),e.scrollToPos&&Br(t,Gr(t,U(n,e.scrollToPos.from),U(n,e.scrollToPos.to),e.scrollToPos.margin));var i=e.maybeHiddenMarkers,o=e.maybeUnhiddenMarkers;if(i)for(var l=0;l<i.length;++l)i[l].lines.length||Te(i[l],"hide");if(o)for(var s=0;s<o.length;++s)o[s].lines.length&&Te(o[s],"unhide");r.wrapper.offsetHeight&&(n.scrollTop=t.display.scroller.scrollTop),e.changeObjs&&Te(t,"changes",t,e.changeObjs),e.update&&e.update.finish()}function hn(e,t){if(e.curOp)return t();nn(e);try{return t()}finally{on(e)}}function dn(e,t){return function(){if(e.curOp)return t.apply(e,arguments);nn(e);try{return t.apply(e,arguments)}finally{on(e)}}}function pn(e){return function(){if(this.curOp)return e.apply(this,arguments);nn(this);try{return e.apply(this,arguments)}finally{on(this)}}}function gn(e){return function(){var t=this.cm;if(!t||t.curOp)return e.apply(this,arguments);nn(t);try{return e.apply(this,arguments)}finally{on(t)}}}function vn(e,t,r,n){null==t&&(t=e.doc.first),null==r&&(r=e.doc.first+e.doc.size),n||(n=0);var i=e.display;if(n&&r<i.viewTo&&(null==i.updateLineNumbers||i.updateLineNumbers>t)&&(i.updateLineNumbers=t),e.curOp.viewChanged=!0,t>=i.viewTo)_l&&pe(e.doc,t)<i.viewTo&&yn(e);else if(r<=i.viewFrom)_l&&ge(e.doc,r+n)>i.viewFrom?yn(e):(i.viewFrom+=n,i.viewTo+=n);else if(t<=i.viewFrom&&r>=i.viewTo)yn(e);else if(t<=i.viewFrom){var o=bn(e,r,r+n,1);o?(i.view=i.view.slice(o.index),i.viewFrom=o.lineN,i.viewTo+=n):yn(e)}else if(r>=i.viewTo){var l=bn(e,t,t,-1);l?(i.view=i.view.slice(0,l.index),i.viewTo=l.lineN):yn(e)}else{var s=bn(e,t,t,-1),a=bn(e,r,r+n,1);s&&a?(i.view=i.view.slice(0,s.index).concat(gt(e,s.lineN,a.lineN)).concat(i.view.slice(a.index)),i.viewTo+=n):yn(e)}var u=i.externalMeasured;u&&(r<u.lineN?u.lineN+=n:t<u.lineN+u.size&&(i.externalMeasured=null))}function mn(e,t,r){e.curOp.viewChanged=!0;var n=e.display,i=e.display.externalMeasured;if(i&&t>=i.lineN&&t<i.lineN+i.size&&(n.externalMeasured=null),!(t<n.viewFrom||t>=n.viewTo)){var o=n.view[Lr(e,t)];if(null!=o.node){var l=o.changes||(o.changes=[]);-1==h(l,r)&&l.push(r)}}}function yn(e){e.display.viewFrom=e.display.viewTo=e.doc.first,e.display.view=[],e.display.viewOffset=0}function bn(e,t,r,n){var i,o=Lr(e,t),l=e.display.view;if(!_l||r==e.doc.first+e.doc.size)return{index:o,lineN:r};for(var s=e.display.viewFrom,a=0;a<o;a++)s+=l[a].size;if(s!=t){if(n>0){if(o==l.length-1)return null;i=s+l[o].size-t,o++}else i=s-t;t+=i,r+=i}for(;pe(e.doc,r)!=r;){if(o==(n<0?0:l.length-1))return null;r+=n*l[o-(n<0?1:0)].size,o+=n}return{index:o,lineN:r}}function wn(e,t,r){var n=e.display;0==n.view.length||t>=n.viewTo||r<=n.viewFrom?(n.view=gt(e,t,r),n.viewFrom=t):(n.viewFrom>t?n.view=gt(e,t,n.viewFrom).concat(n.view):n.viewFrom<t&&(n.view=n.view.slice(Lr(e,t))),n.viewFrom=t,n.viewTo<r?n.view=n.view.concat(gt(e,n.viewTo,r)):n.viewTo>r&&(n.view=n.view.slice(0,Lr(e,r)))),n.viewTo=r}function xn(e){for(var t=e.display.view,r=0,n=0;n<t.length;n++){var i=t[n];i.hidden||i.node&&!i.changes||++r}return r}function Cn(e,t){e.doc.highlightFrontier<e.display.viewTo&&e.state.highlight.set(t,u(Sn,e))}function Sn(e){var t=e.doc;if(!(t.highlightFrontier>=e.display.viewTo)){var r=+new Date+e.options.workTime,n=$e(e,t.highlightFrontier),i=[];t.iter(n.line,Math.min(t.first+t.size,e.display.viewTo+500),function(o){if(n.line>=e.display.viewFrom){var l=o.styles,s=o.text.length>e.options.maxHighlightLength?Ke(t.mode,n.state):null,a=Ye(e,o,n,!0);s&&(n.state=s),o.styles=a.styles;var u=o.styleClasses,c=a.classes;c?o.styleClasses=c:u&&(o.styleClasses=null);for(var f=!l||l.length!=o.styles.length||u!=c&&(!u||!c||u.bgClass!=c.bgClass||u.textClass!=c.textClass),h=0;!f&&h<l.length;++h)f=l[h]!=o.styles[h];f&&i.push(n.line),o.stateAfter=n.save(),n.nextLine()}else o.text.length<=e.options.maxHighlightLength&&qe(e,o.text,n),o.stateAfter=n.line%5==0?n.save():null,n.nextLine();if(+new Date>r)return Cn(e,e.options.workDelay),!0}),t.highlightFrontier=n.line,t.modeFrontier=Math.max(t.modeFrontier,n.line),i.length&&hn(e,function(){for(var t=0;t<i.length;t++)mn(e,i[t],"text")})}}function Ln(e){var t=e.display;!t.scrollbarsClipped&&t.scroller.offsetWidth&&(t.nativeBarWidth=t.scroller.offsetWidth-t.scroller.clientWidth,t.heightForcer.style.height=zt(e)+"px",t.sizer.style.marginBottom=-t.nativeBarWidth+"px",t.sizer.style.borderRightWidth=zt(e)+"px",t.scrollbarsClipped=!0)}function kn(e){if(e.hasFocus())return null;var t=l();if(!t||!o(e.display.lineDiv,t))return null;var r={activeElt:t};if(window.getSelection){var n=window.getSelection();n.anchorNode&&n.extend&&o(e.display.lineDiv,n.anchorNode)&&(r.anchorNode=n.anchorNode,r.anchorOffset=n.anchorOffset,r.focusNode=n.focusNode,r.focusOffset=n.focusOffset)}return r}function Tn(e){if(e&&e.activeElt&&e.activeElt!=l()&&(e.activeElt.focus(),e.anchorNode&&o(document.body,e.anchorNode)&&o(document.body,e.focusNode))){var t=window.getSelection(),r=document.createRange();r.setEnd(e.anchorNode,e.anchorOffset),r.collapse(!1),t.removeAllRanges(),t.addRange(r),t.extend(e.focusNode,e.focusOffset)}}function Mn(e,r){var n=e.display,i=e.doc;if(r.editorIsHidden)return yn(e),!1;if(!r.force&&r.visible.from>=n.viewFrom&&r.visible.to<=n.viewTo&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo)&&n.renderedView==n.view&&0==xn(e))return!1;Rr(e)&&(yn(e),r.dims=br(e));var o=i.first+i.size,l=Math.max(r.visible.from-e.options.viewportMargin,i.first),s=Math.min(o,r.visible.to+e.options.viewportMargin);n.viewFrom<l&&l-n.viewFrom<20&&(l=Math.max(i.first,n.viewFrom)),n.viewTo>s&&n.viewTo-s<20&&(s=Math.min(o,n.viewTo)),_l&&(l=pe(e.doc,l),s=ge(e.doc,s));var a=l!=n.viewFrom||s!=n.viewTo||n.lastWrapHeight!=r.wrapperHeight||n.lastWrapWidth!=r.wrapperWidth;wn(e,l,s),n.viewOffset=ye(M(e.doc,n.viewFrom)),e.display.mover.style.top=n.viewOffset+"px";var u=xn(e);if(!a&&0==u&&!r.force&&n.renderedView==n.view&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo))return!1;var c=kn(e);return u>4&&(n.lineDiv.style.display="none"),An(e,n.updateLineNumbers,r.dims),u>4&&(n.lineDiv.style.display=""),n.renderedView=n.view,Tn(c),t(n.cursorDiv),t(n.selectionDiv),n.gutters.style.height=n.sizer.style.minHeight=0,a&&(n.lastWrapHeight=r.wrapperHeight,n.lastWrapWidth=r.wrapperWidth,Cn(e,400)),n.updateLineNumbers=null,!0}function Nn(e,t){for(var r=t.viewport,n=!0;(n&&e.options.lineWrapping&&t.oldDisplayWidth!=Rt(e)||(r&&null!=r.top&&(r={top:Math.min(e.doc.height+Pt(e.display)-Bt(e),r.top)}),t.visible=Ir(e.display,e.doc,r),!(t.visible.from>=e.display.viewFrom&&t.visible.to<=e.display.viewTo)))&&Mn(e,t);n=!1){Er(e);var i=Jr(e);kr(e),en(e,i),Dn(e,i),t.force=!1}t.signal(e,"update",e),e.display.viewFrom==e.display.reportedViewFrom&&e.display.viewTo==e.display.reportedViewTo||(t.signal(e,"viewportChange",e,e.display.viewFrom,e.display.viewTo),e.display.reportedViewFrom=e.display.viewFrom,e.display.reportedViewTo=e.display.viewTo)}function On(e,t){var r=new Cs(e,t);if(Mn(e,r)){Er(e),Nn(e,r);var n=Jr(e);kr(e),en(e,n),Dn(e,n),r.finish()}}function An(e,r,n){function i(t){var r=t.nextSibling;return ml&&Ml&&e.display.currentWheelTarget==t?t.style.display="none":t.parentNode.removeChild(t),r}for(var o=e.display,l=e.options.lineNumbers,s=o.lineDiv,a=s.firstChild,u=o.view,c=o.viewFrom,f=0;f<u.length;f++){var d=u[f];if(d.hidden);else if(d.node&&d.node.parentNode==s){for(;a!=d.node;)a=i(a);var p=l&&null!=r&&r<=c&&d.lineNumber;d.changes&&(h(d.changes,"gutter")>-1&&(p=!1),xt(e,d,c,n)),p&&(t(d.lineNumber),d.lineNumber.appendChild(document.createTextNode(F(e.options,c)))),a=d.node.nextSibling}else{var g=Ot(e,d,c,n);s.insertBefore(g,a)}c+=d.size}for(;a;)a=i(a)}function Wn(e){var t=e.display.gutters.offsetWidth;e.display.sizer.style.marginLeft=t+"px"}function Dn(e,t){e.display.sizer.style.minHeight=t.docHeight+"px",e.display.heightForcer.style.top=t.docHeight+"px",e.display.gutters.style.height=t.docHeight+e.display.barHeight+zt(e)+"px"}function Hn(e){var r=e.display.gutters,i=e.options.gutters;t(r);for(var o=0;o<i.length;++o){var l=i[o],s=r.appendChild(n("div",null,"CodeMirror-gutter "+l));"CodeMirror-linenumbers"==l&&(e.display.lineGutter=s,s.style.width=(e.display.lineNumWidth||1)+"px")}r.style.display=o?"":"none",Wn(e)}function Fn(e){var t=h(e.gutters,"CodeMirror-linenumbers");-1==t&&e.lineNumbers?e.gutters=e.gutters.concat(["CodeMirror-linenumbers"]):t>-1&&!e.lineNumbers&&(e.gutters=e.gutters.slice(0),e.gutters.splice(t,1))}function En(e){var t=e.wheelDeltaX,r=e.wheelDeltaY;return null==t&&e.detail&&e.axis==e.HORIZONTAL_AXIS&&(t=e.detail),null==r&&e.detail&&e.axis==e.VERTICAL_AXIS?r=e.detail:null==r&&(r=e.wheelDelta),{x:t,y:r}}function Pn(e){var t=En(e);return t.x*=Ls,t.y*=Ls,t}function In(e,t){var r=En(t),n=r.x,i=r.y,o=e.display,l=o.scroller,s=l.scrollWidth>l.clientWidth,a=l.scrollHeight>l.clientHeight;if(n&&s||i&&a){if(i&&Ml&&ml)e:for(var u=t.target,c=o.view;u!=l;u=u.parentNode)for(var f=0;f<c.length;f++)if(c[f].node==u){e.display.currentWheelTarget=u;break e}if(n&&!fl&&!wl&&null!=Ls)return i&&a&&qr(e,Math.max(0,l.scrollTop+i*Ls)),Qr(e,Math.max(0,l.scrollLeft+n*Ls)),(!i||i&&a)&&We(t),void(o.wheelStartX=null);if(i&&null!=Ls){var h=i*Ls,d=e.doc.scrollTop,p=d+o.wrapper.clientHeight;h<0?d=Math.max(0,d+h-50):p=Math.min(e.doc.height,p+h+50),On(e,{top:d,bottom:p})}Ss<20&&(null==o.wheelStartX?(o.wheelStartX=l.scrollLeft,o.wheelStartY=l.scrollTop,o.wheelDX=n,o.wheelDY=i,setTimeout(function(){if(null!=o.wheelStartX){var e=l.scrollLeft-o.wheelStartX,t=l.scrollTop-o.wheelStartY,r=t&&o.wheelDY&&t/o.wheelDY||e&&o.wheelDX&&e/o.wheelDX;o.wheelStartX=o.wheelStartY=null,r&&(Ls=(Ls*Ss+r)/(Ss+1),++Ss)}},200)):(o.wheelDX+=n,o.wheelDY+=i))}}function zn(e,t){var r=e[t];e.sort(function(e,t){return P(e.from(),t.from())}),t=h(e,r);for(var n=1;n<e.length;n++){var i=e[n],o=e[n-1];if(P(o.to(),i.from())>=0){var l=B(o.from(),i.from()),s=R(o.to(),i.to()),a=o.empty()?i.from()==i.head:o.from()==o.head;n<=t&&--t,e.splice(--n,2,new Ts(a?s:l,a?l:s))}}return new ks(e,t)}function Rn(e,t){return new ks([new Ts(e,t||e)],0)}function Bn(e){return e.text?E(e.from.line+e.text.length-1,g(e.text).length+(1==e.text.length?e.from.ch:0)):e.to}function Gn(e,t){if(P(e,t.from)<0)return e;if(P(e,t.to)<=0)return Bn(t);var r=e.line+t.text.length-(t.to.line-t.from.line)-1,n=e.ch;return e.line==t.to.line&&(n+=Bn(t).ch-t.to.ch),E(r,n)}function Un(e,t){for(var r=[],n=0;n<e.sel.ranges.length;n++){var i=e.sel.ranges[n];r.push(new Ts(Gn(i.anchor,t),Gn(i.head,t)))}return zn(r,e.sel.primIndex)}function Vn(e,t,r){return e.line==t.line?E(r.line,e.ch-t.ch+r.ch):E(r.line+(e.line-t.line),e.ch)}function Kn(e,t,r){for(var n=[],i=E(e.first,0),o=i,l=0;l<t.length;l++){var s=t[l],a=Vn(s.from,i,o),u=Vn(Bn(s),i,o);if(i=s.to,o=u,"around"==r){var c=e.sel.ranges[l],f=P(c.head,c.anchor)<0;n[l]=new Ts(f?u:a,f?a:u)}else n[l]=new Ts(a,a)}return new ks(n,e.sel.primIndex)}function jn(e){e.doc.mode=Ue(e.options,e.doc.modeOption),Xn(e)}function Xn(e){e.doc.iter(function(e){e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null)}),e.doc.modeFrontier=e.doc.highlightFrontier=e.doc.first,Cn(e,100),e.state.modeGen++,e.curOp&&vn(e)}function Yn(e,t){return 0==t.from.ch&&0==t.to.ch&&""==g(t.text)&&(!e.cm||e.cm.options.wholeLineUpdateBefore)}function _n(e,t,r,n){function i(e){return r?r[e]:null}function o(e,r,i){it(e,r,i,n),bt(e,"change",e,t)}function l(e,t){for(var r=[],o=e;o<t;++o)r.push(new fs(u[o],i(o),n));return r}var s=t.from,a=t.to,u=t.text,c=M(e,s.line),f=M(e,a.line),h=g(u),d=i(u.length-1),p=a.line-s.line;if(t.full)e.insert(0,l(0,u.length)),e.remove(u.length,e.size-u.length);else if(Yn(e,t)){var v=l(0,u.length-1);o(f,f.text,d),p&&e.remove(s.line,p),v.length&&e.insert(s.line,v)}else if(c==f)if(1==u.length)o(c,c.text.slice(0,s.ch)+h+c.text.slice(a.ch),d);else{var m=l(1,u.length-1);m.push(new fs(h+c.text.slice(a.ch),d,n)),o(c,c.text.slice(0,s.ch)+u[0],i(0)),e.insert(s.line+1,m)}else if(1==u.length)o(c,c.text.slice(0,s.ch)+u[0]+f.text.slice(a.ch),i(0)),e.remove(s.line+1,p);else{o(c,c.text.slice(0,s.ch)+u[0],i(0)),o(f,h+f.text.slice(a.ch),d);var y=l(1,u.length-1);p>1&&e.remove(s.line+1,p-1),e.insert(s.line+1,y)}bt(e,"change",e,t)}function $n(e,t,r){function n(e,i,o){if(e.linked)for(var l=0;l<e.linked.length;++l){var s=e.linked[l];if(s.doc!=i){var a=o&&s.sharedHist;r&&!a||(t(s.doc,a),n(s.doc,e,a))}}}n(e,null,!0)}function qn(e,t){if(t.cm)throw new Error("This document is already in use.");e.doc=t,t.cm=e,Cr(e),jn(e),Zn(e),e.options.lineWrapping||we(e),e.options.mode=t.modeOption,vn(e)}function Zn(e){("rtl"==e.doc.direction?s:Fl)(e.display.lineDiv,"CodeMirror-rtl")}function Qn(e){hn(e,function(){Zn(e),vn(e)})}function Jn(e){this.done=[],this.undone=[],this.undoDepth=1/0,this.lastModTime=this.lastSelTime=0,this.lastOp=this.lastSelOp=null,this.lastOrigin=this.lastSelOrigin=null,this.generation=this.maxGeneration=e||1}function ei(e,t){var r={from:z(t.from),to:Bn(t),text:N(e,t.from,t.to)};return si(e,r,t.from.line,t.to.line+1),$n(e,function(e){return si(e,r,t.from.line,t.to.line+1)},!0),r}function ti(e){for(;e.length&&g(e).ranges;)e.pop()}function ri(e,t){return t?(ti(e.done),g(e.done)):e.done.length&&!g(e.done).ranges?g(e.done):e.done.length>1&&!e.done[e.done.length-2].ranges?(e.done.pop(),g(e.done)):void 0}function ni(e,t,r,n){var i=e.history;i.undone.length=0;var o,l,s=+new Date;if((i.lastOp==n||i.lastOrigin==t.origin&&t.origin&&("+"==t.origin.charAt(0)&&e.cm&&i.lastModTime>s-e.cm.options.historyEventDelay||"*"==t.origin.charAt(0)))&&(o=ri(i,i.lastOp==n)))l=g(o.changes),0==P(t.from,t.to)&&0==P(t.from,l.to)?l.to=Bn(t):o.changes.push(ei(e,t));else{var a=g(i.done);for(a&&a.ranges||li(e.sel,i.done),o={changes:[ei(e,t)],generation:i.generation},i.done.push(o);i.done.length>i.undoDepth;)i.done.shift(),i.done[0].ranges||i.done.shift()}i.done.push(r),i.generation=++i.maxGeneration,i.lastModTime=i.lastSelTime=s,i.lastOp=i.lastSelOp=n,i.lastOrigin=i.lastSelOrigin=t.origin,l||Te(e,"historyAdded")}function ii(e,t,r,n){var i=t.charAt(0);return"*"==i||"+"==i&&r.ranges.length==n.ranges.length&&r.somethingSelected()==n.somethingSelected()&&new Date-e.history.lastSelTime<=(e.cm?e.cm.options.historyEventDelay:500)}function oi(e,t,r,n){var i=e.history,o=n&&n.origin;r==i.lastSelOp||o&&i.lastSelOrigin==o&&(i.lastModTime==i.lastSelTime&&i.lastOrigin==o||ii(e,o,g(i.done),t))?i.done[i.done.length-1]=t:li(t,i.done),i.lastSelTime=+new Date,i.lastSelOrigin=o,i.lastSelOp=r,n&&!1!==n.clearRedo&&ti(i.undone)}function li(e,t){var r=g(t);r&&r.ranges&&r.equals(e)||t.push(e)}function si(e,t,r,n){var i=t["spans_"+e.id],o=0;e.iter(Math.max(e.first,r),Math.min(e.first+e.size,n),function(r){r.markedSpans&&((i||(i=t["spans_"+e.id]={}))[o]=r.markedSpans),++o})}function ai(e){if(!e)return null;for(var t,r=0;r<e.length;++r)e[r].marker.explicitlyCleared?t||(t=e.slice(0,r)):t&&t.push(e[r]);return t?t.length?t:null:e}function ui(e,t){var r=t["spans_"+e.id];if(!r)return null;for(var n=[],i=0;i<t.text.length;++i)n.push(ai(r[i]));return n}function ci(e,t){var r=ui(e,t),n=J(e,t);if(!r)return n;if(!n)return r;for(var i=0;i<r.length;++i){var o=r[i],l=n[i];if(o&&l)e:for(var s=0;s<l.length;++s){for(var a=l[s],u=0;u<o.length;++u)if(o[u].marker==a.marker)continue e;o.push(a)}else l&&(r[i]=l)}return r}function fi(e,t,r){for(var n=[],i=0;i<e.length;++i){var o=e[i];if(o.ranges)n.push(r?ks.prototype.deepCopy.call(o):o);else{var l=o.changes,s=[];n.push({changes:s});for(var a=0;a<l.length;++a){var u=l[a],c=void 0;if(s.push({from:u.from,to:u.to,text:u.text}),t)for(var f in u)(c=f.match(/^spans_(\d+)$/))&&h(t,Number(c[1]))>-1&&(g(s)[f]=u[f],delete u[f])}}}return n}function hi(e,t,r,n){if(n){var i=e.anchor;if(r){var o=P(t,i)<0;o!=P(r,i)<0?(i=t,t=r):o!=P(t,r)<0&&(t=r)}return new Ts(i,t)}return new Ts(r||t,t)}function di(e,t,r,n,i){null==i&&(i=e.cm&&(e.cm.display.shift||e.extend)),bi(e,new ks([hi(e.sel.primary(),t,r,i)],0),n)}function pi(e,t,r){for(var n=[],i=e.cm&&(e.cm.display.shift||e.extend),o=0;o<e.sel.ranges.length;o++)n[o]=hi(e.sel.ranges[o],t[o],null,i);bi(e,zn(n,e.sel.primIndex),r)}function gi(e,t,r,n){var i=e.sel.ranges.slice(0);i[t]=r,bi(e,zn(i,e.sel.primIndex),n)}function vi(e,t,r,n){bi(e,Rn(t,r),n)}function mi(e,t,r){var n={ranges:t.ranges,update:function(t){var r=this;this.ranges=[];for(var n=0;n<t.length;n++)r.ranges[n]=new Ts(U(e,t[n].anchor),U(e,t[n].head))},origin:r&&r.origin};return Te(e,"beforeSelectionChange",e,n),e.cm&&Te(e.cm,"beforeSelectionChange",e.cm,n),n.ranges!=t.ranges?zn(n.ranges,n.ranges.length-1):t}function yi(e,t,r){var n=e.history.done,i=g(n);i&&i.ranges?(n[n.length-1]=t,wi(e,t,r)):bi(e,t,r)}function bi(e,t,r){wi(e,t,r),oi(e,e.sel,e.cm?e.cm.curOp.id:NaN,r)}function wi(e,t,r){(Oe(e,"beforeSelectionChange")||e.cm&&Oe(e.cm,"beforeSelectionChange"))&&(t=mi(e,t,r)),xi(e,Si(e,t,r&&r.bias||(P(t.primary().head,e.sel.primary().head)<0?-1:1),!0)),r&&!1===r.scroll||!e.cm||jr(e.cm)}function xi(e,t){t.equals(e.sel)||(e.sel=t,e.cm&&(e.cm.curOp.updateInput=e.cm.curOp.selectionChanged=!0,Ne(e.cm)),bt(e,"cursorActivity",e))}function Ci(e){xi(e,Si(e,e.sel,null,!1))}function Si(e,t,r,n){for(var i,o=0;o<t.ranges.length;o++){var l=t.ranges[o],s=t.ranges.length==e.sel.ranges.length&&e.sel.ranges[o],a=ki(e,l.anchor,s&&s.anchor,r,n),u=ki(e,l.head,s&&s.head,r,n);(i||a!=l.anchor||u!=l.head)&&(i||(i=t.ranges.slice(0,o)),i[o]=new Ts(a,u))}return i?zn(i,t.primIndex):t}function Li(e,t,r,n,i){var o=M(e,t.line);if(o.markedSpans)for(var l=0;l<o.markedSpans.length;++l){var s=o.markedSpans[l],a=s.marker;if((null==s.from||(a.inclusiveLeft?s.from<=t.ch:s.from<t.ch))&&(null==s.to||(a.inclusiveRight?s.to>=t.ch:s.to>t.ch))){if(i&&(Te(a,"beforeCursorEnter"),a.explicitlyCleared)){if(o.markedSpans){--l;continue}break}if(!a.atomic)continue;if(r){var u=a.find(n<0?1:-1),c=void 0;if((n<0?a.inclusiveRight:a.inclusiveLeft)&&(u=Ti(e,u,-n,u&&u.line==t.line?o:null)),u&&u.line==t.line&&(c=P(u,r))&&(n<0?c<0:c>0))return Li(e,u,t,n,i)}var f=a.find(n<0?-1:1);return(n<0?a.inclusiveLeft:a.inclusiveRight)&&(f=Ti(e,f,n,f.line==t.line?o:null)),f?Li(e,f,t,n,i):null}}return t}function ki(e,t,r,n,i){var o=n||1,l=Li(e,t,r,o,i)||!i&&Li(e,t,r,o,!0)||Li(e,t,r,-o,i)||!i&&Li(e,t,r,-o,!0);return l||(e.cantEdit=!0,E(e.first,0))}function Ti(e,t,r,n){return r<0&&0==t.ch?t.line>e.first?U(e,E(t.line-1)):null:r>0&&t.ch==(n||M(e,t.line)).text.length?t.line<e.first+e.size-1?E(t.line+1,0):null:new E(t.line,t.ch+r)}function Mi(e){e.setSelection(E(e.firstLine(),0),E(e.lastLine()),Gl)}function Ni(e,t,r){var n={canceled:!1,from:t.from,to:t.to,text:t.text,origin:t.origin,cancel:function(){return n.canceled=!0}};return r&&(n.update=function(t,r,i,o){t&&(n.from=U(e,t)),r&&(n.to=U(e,r)),i&&(n.text=i),void 0!==o&&(n.origin=o)}),Te(e,"beforeChange",e,n),e.cm&&Te(e.cm,"beforeChange",e.cm,n),n.canceled?null:{from:n.from,to:n.to,text:n.text,origin:n.origin}}function Oi(e,t,r){if(e.cm){if(!e.cm.curOp)return dn(e.cm,Oi)(e,t,r);if(e.cm.state.suppressEdits)return}if(!(Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"))||(t=Ni(e,t,!0))){var n=Yl&&!r&&te(e,t.from,t.to);if(n)for(var i=n.length-1;i>=0;--i)Ai(e,{from:n[i].from,to:n[i].to,text:i?[""]:t.text,origin:t.origin});else Ai(e,t)}}function Ai(e,t){if(1!=t.text.length||""!=t.text[0]||0!=P(t.from,t.to)){var r=Un(e,t);ni(e,t,r,e.cm?e.cm.curOp.id:NaN),Hi(e,t,r,J(e,t));var n=[];$n(e,function(e,r){r||-1!=h(n,e.history)||(zi(e.history,t),n.push(e.history)),Hi(e,t,null,J(e,t))})}}function Wi(e,t,r){if(!e.cm||!e.cm.state.suppressEdits||r){for(var n,i=e.history,o=e.sel,l="undo"==t?i.done:i.undone,s="undo"==t?i.undone:i.done,a=0;a<l.length&&(n=l[a],r?!n.ranges||n.equals(e.sel):n.ranges);a++);if(a!=l.length){for(i.lastOrigin=i.lastSelOrigin=null;(n=l.pop()).ranges;){if(li(n,s),r&&!n.equals(e.sel))return void bi(e,n,{clearRedo:!1});o=n}var u=[];li(o,s),s.push({changes:u,generation:i.generation}),i.generation=n.generation||++i.maxGeneration;for(var c=Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"),f=n.changes.length-1;f>=0;--f){var d=function(r){var i=n.changes[r];if(i.origin=t,c&&!Ni(e,i,!1))return l.length=0,{};u.push(ei(e,i));var o=r?Un(e,i):g(l);Hi(e,i,o,ci(e,i)),!r&&e.cm&&e.cm.scrollIntoView({from:i.from,to:Bn(i)});var s=[];$n(e,function(e,t){t||-1!=h(s,e.history)||(zi(e.history,i),s.push(e.history)),Hi(e,i,null,ci(e,i))})}(f);if(d)return d.v}}}}function Di(e,t){if(0!=t&&(e.first+=t,e.sel=new ks(v(e.sel.ranges,function(e){return new Ts(E(e.anchor.line+t,e.anchor.ch),E(e.head.line+t,e.head.ch))}),e.sel.primIndex),e.cm)){vn(e.cm,e.first,e.first-t,t);for(var r=e.cm.display,n=r.viewFrom;n<r.viewTo;n++)mn(e.cm,n,"gutter")}}function Hi(e,t,r,n){if(e.cm&&!e.cm.curOp)return dn(e.cm,Hi)(e,t,r,n);if(t.to.line<e.first)Di(e,t.text.length-1-(t.to.line-t.from.line));else if(!(t.from.line>e.lastLine())){if(t.from.line<e.first){var i=t.text.length-1-(e.first-t.from.line);Di(e,i),t={from:E(e.first,0),to:E(t.to.line+i,t.to.ch),text:[g(t.text)],origin:t.origin}}var o=e.lastLine();t.to.line>o&&(t={from:t.from,to:E(o,M(e,o).text.length),text:[t.text[0]],origin:t.origin}),t.removed=N(e,t.from,t.to),r||(r=Un(e,t)),e.cm?Fi(e.cm,t,n):_n(e,t,n),wi(e,r,Gl)}}function Fi(e,t,r){var n=e.doc,i=e.display,o=t.from,l=t.to,s=!1,a=o.line;e.options.lineWrapping||(a=W(fe(M(n,o.line))),n.iter(a,l.line+1,function(e){if(e==i.maxLine)return s=!0,!0})),n.sel.contains(t.from,t.to)>-1&&Ne(e),_n(n,t,r,xr(e)),e.options.lineWrapping||(n.iter(a,o.line+t.text.length,function(e){var t=be(e);t>i.maxLineLength&&(i.maxLine=e,i.maxLineLength=t,i.maxLineChanged=!0,s=!1)}),s&&(e.curOp.updateMaxLine=!0)),nt(n,o.line),Cn(e,400);var u=t.text.length-(l.line-o.line)-1;t.full?vn(e):o.line!=l.line||1!=t.text.length||Yn(e.doc,t)?vn(e,o.line,l.line+1,u):mn(e,o.line,"text");var c=Oe(e,"changes"),f=Oe(e,"change");if(f||c){var h={from:o,to:l,text:t.text,removed:t.removed,origin:t.origin};f&&bt(e,"change",e,h),c&&(e.curOp.changeObjs||(e.curOp.changeObjs=[])).push(h)}e.display.selForContextMenu=null}function Ei(e,t,r,n,i){if(n||(n=r),P(n,r)<0){var o;r=(o=[n,r])[0],n=o[1]}"string"==typeof t&&(t=e.splitLines(t)),Oi(e,{from:r,to:n,text:t,origin:i})}function Pi(e,t,r,n){r<e.line?e.line+=n:t<e.line&&(e.line=t,e.ch=0)}function Ii(e,t,r,n){for(var i=0;i<e.length;++i){var o=e[i],l=!0;if(o.ranges){o.copied||((o=e[i]=o.deepCopy()).copied=!0);for(var s=0;s<o.ranges.length;s++)Pi(o.ranges[s].anchor,t,r,n),Pi(o.ranges[s].head,t,r,n)}else{for(var a=0;a<o.changes.length;++a){var u=o.changes[a];if(r<u.from.line)u.from=E(u.from.line+n,u.from.ch),u.to=E(u.to.line+n,u.to.ch);else if(t<=u.to.line){l=!1;break}}l||(e.splice(0,i+1),i=0)}}}function zi(e,t){var r=t.from.line,n=t.to.line,i=t.text.length-(n-r)-1;Ii(e.done,r,n,i),Ii(e.undone,r,n,i)}function Ri(e,t,r,n){var i=t,o=t;return"number"==typeof t?o=M(e,G(e,t)):i=W(t),null==i?null:(n(o,i)&&e.cm&&mn(e.cm,i,r),o)}function Bi(e){var t=this;this.lines=e,this.parent=null;for(var r=0,n=0;n<e.length;++n)e[n].parent=t,r+=e[n].height;this.height=r}function Gi(e){var t=this;this.children=e;for(var r=0,n=0,i=0;i<e.length;++i){var o=e[i];r+=o.chunkSize(),n+=o.height,o.parent=t}this.size=r,this.height=n,this.parent=null}function Ui(e,t,r){ye(t)<(e.curOp&&e.curOp.scrollTop||e.doc.scrollTop)&&Kr(e,r)}function Vi(e,t,r,n){var i=new Ms(e,r,n),o=e.cm;return o&&i.noHScroll&&(o.display.alignWidgets=!0),Ri(e,t,"widget",function(t){var r=t.widgets||(t.widgets=[]);if(null==i.insertAt?r.push(i):r.splice(Math.min(r.length-1,Math.max(0,i.insertAt)),0,i),i.line=t,o&&!ve(e,t)){var n=ye(t)<e.scrollTop;A(t,t.height+Ht(i)),n&&Kr(o,i.height),o.curOp.forceUpdate=!0}return!0}),bt(o,"lineWidgetAdded",o,i,"number"==typeof t?t:W(t)),i}function Ki(e,t,r,n,o){if(n&&n.shared)return ji(e,t,r,n,o);if(e.cm&&!e.cm.curOp)return dn(e.cm,Ki)(e,t,r,n,o);var l=new Os(e,o),s=P(t,r);if(n&&c(n,l,!1),s>0||0==s&&!1!==l.clearWhenEmpty)return l;if(l.replacedWith&&(l.collapsed=!0,l.widgetNode=i("span",[l.replacedWith],"CodeMirror-widget"),n.handleMouseEvents||l.widgetNode.setAttribute("cm-ignore-events","true"),n.insertLeft&&(l.widgetNode.insertLeft=!0)),l.collapsed){if(ce(e,t.line,t,r,l)||t.line!=r.line&&ce(e,r.line,t,r,l))throw new Error("Inserting collapsed marker partially overlapping an existing one");X()}l.addToHistory&&ni(e,{from:t,to:r,origin:"markText"},e.sel,NaN);var a,u=t.line,f=e.cm;if(e.iter(u,r.line+1,function(e){f&&l.collapsed&&!f.options.lineWrapping&&fe(e)==f.display.maxLine&&(a=!0),l.collapsed&&u!=t.line&&A(e,0),q(e,new Y(l,u==t.line?t.ch:null,u==r.line?r.ch:null)),++u}),l.collapsed&&e.iter(t.line,r.line+1,function(t){ve(e,t)&&A(t,0)}),l.clearOnEnter&&Ql(l,"beforeCursorEnter",function(){return l.clear()}),l.readOnly&&(j(),(e.history.done.length||e.history.undone.length)&&e.clearHistory()),l.collapsed&&(l.id=++Ns,l.atomic=!0),f){if(a&&(f.curOp.updateMaxLine=!0),l.collapsed)vn(f,t.line,r.line+1);else if(l.className||l.title||l.startStyle||l.endStyle||l.css)for(var h=t.line;h<=r.line;h++)mn(f,h,"text");l.atomic&&Ci(f.doc),bt(f,"markerAdded",f,l)}return l}function ji(e,t,r,n,i){(n=c(n)).shared=!1;var o=[Ki(e,t,r,n,i)],l=o[0],s=n.widgetNode;return $n(e,function(e){s&&(n.widgetNode=s.cloneNode(!0)),o.push(Ki(e,U(e,t),U(e,r),n,i));for(var a=0;a<e.linked.length;++a)if(e.linked[a].isParent)return;l=g(o)}),new As(o,l)}function Xi(e){return e.findMarks(E(e.first,0),e.clipPos(E(e.lastLine())),function(e){return e.parent})}function Yi(e,t){for(var r=0;r<t.length;r++){var n=t[r],i=n.find(),o=e.clipPos(i.from),l=e.clipPos(i.to);if(P(o,l)){var s=Ki(e,o,l,n.primary,n.primary.type);n.markers.push(s),s.parent=n}}}function _i(e){for(var t=0;t<e.length;t++)!function(t){var r=e[t],n=[r.primary.doc];$n(r.primary.doc,function(e){return n.push(e)});for(var i=0;i<r.markers.length;i++){var o=r.markers[i];-1==h(n,o.doc)&&(o.parent=null,r.markers.splice(i--,1))}}(t)}function $i(e){var t=this;if(Qi(t),!Me(t,e)&&!Ft(t.display,e)){We(e),gl&&(Hs=+new Date);var r=Sr(t,e,!0),n=e.dataTransfer.files;if(r&&!t.isReadOnly())if(n&&n.length&&window.FileReader&&window.File)for(var i=n.length,o=Array(i),l=0,s=0;s<i;++s)!function(e,n){if(!t.options.allowDropFileTypes||-1!=h(t.options.allowDropFileTypes,e.type)){var s=new FileReader;s.onload=dn(t,function(){var e=s.result;if(/[\x00-\x08\x0e-\x1f]{2}/.test(e)&&(e=""),o[n]=e,++l==i){var a={from:r=U(t.doc,r),to:r,text:t.doc.splitLines(o.join(t.doc.lineSeparator())),origin:"paste"};Oi(t.doc,a),yi(t.doc,Rn(r,Bn(a)))}}),s.readAsText(e)}}(n[s],s);else{if(t.state.draggingText&&t.doc.sel.contains(r)>-1)return t.state.draggingText(e),void setTimeout(function(){return t.display.input.focus()},20);try{var a=e.dataTransfer.getData("Text");if(a){var u;if(t.state.draggingText&&!t.state.draggingText.copy&&(u=t.listSelections()),wi(t.doc,Rn(r,r)),u)for(var c=0;c<u.length;++c)Ei(t.doc,"",u[c].anchor,u[c].head,"drag");t.replaceSelection(a,"around","paste"),t.display.input.focus()}}catch(e){}}}}function qi(e,t){if(gl&&(!e.state.draggingText||+new Date-Hs<100))Fe(t);else if(!Me(e,t)&&!Ft(e.display,t)&&(t.dataTransfer.setData("Text",e.getSelection()),t.dataTransfer.effectAllowed="copyMove",t.dataTransfer.setDragImage&&!xl)){var r=n("img",null,null,"position: fixed; left: 0; top: 0;");r.src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==",wl&&(r.width=r.height=1,e.display.wrapper.appendChild(r),r._top=r.offsetTop),t.dataTransfer.setDragImage(r,0,0),wl&&r.parentNode.removeChild(r)}}function Zi(e,t){var i=Sr(e,t);if(i){var o=document.createDocumentFragment();Mr(e,i,o),e.display.dragCursor||(e.display.dragCursor=n("div",null,"CodeMirror-cursors CodeMirror-dragcursors"),e.display.lineSpace.insertBefore(e.display.dragCursor,e.display.cursorDiv)),r(e.display.dragCursor,o)}}function Qi(e){e.display.dragCursor&&(e.display.lineSpace.removeChild(e.display.dragCursor),e.display.dragCursor=null)}function Ji(e){if(document.getElementsByClassName)for(var t=document.getElementsByClassName("CodeMirror"),r=0;r<t.length;r++){var n=t[r].CodeMirror;n&&e(n)}}function eo(){Fs||(to(),Fs=!0)}function to(){var e;Ql(window,"resize",function(){null==e&&(e=setTimeout(function(){e=null,Ji(ro)},100))}),Ql(window,"blur",function(){return Ji(Fr)})}function ro(e){var t=e.display;t.lastWrapHeight==t.wrapper.clientHeight&&t.lastWrapWidth==t.wrapper.clientWidth||(t.cachedCharWidth=t.cachedTextHeight=t.cachedPaddingH=null,t.scrollbarsClipped=!1,e.setSize())}function no(e){var t=e.split(/-(?!$)/);e=t[t.length-1];for(var r,n,i,o,l=0;l<t.length-1;l++){var s=t[l];if(/^(cmd|meta|m)$/i.test(s))o=!0;else if(/^a(lt)?$/i.test(s))r=!0;else if(/^(c|ctrl|control)$/i.test(s))n=!0;else{if(!/^s(hift)?$/i.test(s))throw new Error("Unrecognized modifier name: "+s);i=!0}}return r&&(e="Alt-"+e),n&&(e="Ctrl-"+e),o&&(e="Cmd-"+e),i&&(e="Shift-"+e),e}function io(e){var t={};for(var r in e)if(e.hasOwnProperty(r)){var n=e[r];if(/^(name|fallthrough|(de|at)tach)$/.test(r))continue;if("..."==n){delete e[r];continue}for(var i=v(r.split(" "),no),o=0;o<i.length;o++){var l=void 0,s=void 0;o==i.length-1?(s=i.join(" "),l=n):(s=i.slice(0,o+1).join(" "),l="...");var a=t[s];if(a){if(a!=l)throw new Error("Inconsistent bindings for "+s)}else t[s]=l}delete e[r]}for(var u in t)e[u]=t[u];return e}function oo(e,t,r,n){var i=(t=uo(t)).call?t.call(e,n):t[e];if(!1===i)return"nothing";if("..."===i)return"multi";if(null!=i&&r(i))return"handled";if(t.fallthrough){if("[object Array]"!=Object.prototype.toString.call(t.fallthrough))return oo(e,t.fallthrough,r,n);for(var o=0;o<t.fallthrough.length;o++){var l=oo(e,t.fallthrough[o],r,n);if(l)return l}}}function lo(e){var t="string"==typeof e?e:Es[e.keyCode];return"Ctrl"==t||"Alt"==t||"Shift"==t||"Mod"==t}function so(e,t,r){var n=e;return t.altKey&&"Alt"!=n&&(e="Alt-"+e),(Dl?t.metaKey:t.ctrlKey)&&"Ctrl"!=n&&(e="Ctrl-"+e),(Dl?t.ctrlKey:t.metaKey)&&"Cmd"!=n&&(e="Cmd-"+e),!r&&t.shiftKey&&"Shift"!=n&&(e="Shift-"+e),e}function ao(e,t){if(wl&&34==e.keyCode&&e.char)return!1;var r=Es[e.keyCode];return null!=r&&!e.altGraphKey&&so(r,e,t)}function uo(e){return"string"==typeof e?Rs[e]:e}function co(e,t){for(var r=e.doc.sel.ranges,n=[],i=0;i<r.length;i++){for(var o=t(r[i]);n.length&&P(o.from,g(n).to)<=0;){var l=n.pop();if(P(l.from,o.from)<0){o.from=l.from;break}}n.push(o)}hn(e,function(){for(var t=n.length-1;t>=0;t--)Ei(e.doc,"",n[t].from,n[t].to,"+delete");jr(e)})}function fo(e,t,r){var n=L(e.text,t+r,r);return n<0||n>e.text.length?null:n}function ho(e,t,r){var n=fo(e,t.ch,r);return null==n?null:new E(t.line,n,r<0?"after":"before")}function po(e,t,r,n,i){if(e){var o=Se(r,t.doc.direction);if(o){var l,s=i<0?g(o):o[0],a=i<0==(1==s.level)?"after":"before";if(s.level>0){var u=Xt(t,r);l=i<0?r.text.length-1:0;var c=Yt(t,u,l).top;l=k(function(e){return Yt(t,u,e).top==c},i<0==(1==s.level)?s.from:s.to-1,l),"before"==a&&(l=fo(r,l,1))}else l=i<0?s.to:s.from;return new E(n,l,a)}}return new E(n,i<0?r.text.length:0,i<0?"before":"after")}function go(e,t,r,n){var i=Se(t,e.doc.direction);if(!i)return ho(t,r,n);r.ch>=t.text.length?(r.ch=t.text.length,r.sticky="before"):r.ch<=0&&(r.ch=0,r.sticky="after");var o=Ce(i,r.ch,r.sticky),l=i[o];if("ltr"==e.doc.direction&&l.level%2==0&&(n>0?l.to>r.ch:l.from<r.ch))return ho(t,r,n);var s,a=function(e,r){return fo(t,e instanceof E?e.ch:e,r)},u=function(r){return e.options.lineWrapping?(s=s||Xt(e,t),hr(e,t,s,r)):{begin:0,end:t.text.length}},c=u("before"==r.sticky?a(r,-1):r.ch);if("rtl"==e.doc.direction||1==l.level){var f=1==l.level==n<0,h=a(r,f?1:-1);if(null!=h&&(f?h<=l.to&&h<=c.end:h>=l.from&&h>=c.begin)){var d=f?"before":"after";return new E(r.line,h,d)}}var p=function(e,t,n){for(var o=function(e,t){return t?new E(r.line,a(e,1),"before"):new E(r.line,e,"after")};e>=0&&e<i.length;e+=t){var l=i[e],s=t>0==(1!=l.level),u=s?n.begin:a(n.end,-1);if(l.from<=u&&u<l.to)return o(u,s);if(u=s?l.from:a(l.to,-1),n.begin<=u&&u<n.end)return o(u,s)}},g=p(o+n,n,c);if(g)return g;var v=n>0?c.end:a(c.begin,-1);return null==v||n>0&&v==t.text.length||!(g=p(n>0?0:i.length-1,n,u(v)))?null:g}function vo(e,t){var r=M(e.doc,t),n=fe(r);return n!=r&&(t=W(n)),po(!0,e,n,t,1)}function mo(e,t){var r=M(e.doc,t),n=he(r);return n!=r&&(t=W(n)),po(!0,e,r,t,-1)}function yo(e,t){var r=vo(e,t.line),n=M(e.doc,r.line),i=Se(n,e.doc.direction);if(!i||0==i[0].level){var o=Math.max(0,n.text.search(/\S/)),l=t.line==r.line&&t.ch<=o&&t.ch;return E(r.line,l?0:o,r.sticky)}return r}function bo(e,t,r){if("string"==typeof t&&!(t=Bs[t]))return!1;e.display.input.ensurePolled();var n=e.display.shift,i=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),r&&(e.display.shift=!1),i=t(e)!=Bl}finally{e.display.shift=n,e.state.suppressEdits=!1}return i}function wo(e,t,r){for(var n=0;n<e.state.keyMaps.length;n++){var i=oo(t,e.state.keyMaps[n],r,e);if(i)return i}return e.options.extraKeys&&oo(t,e.options.extraKeys,r,e)||oo(t,e.options.keyMap,r,e)}function xo(e,t,r,n){var i=e.state.keySeq;if(i){if(lo(t))return"handled";Gs.set(50,function(){e.state.keySeq==i&&(e.state.keySeq=null,e.display.input.reset())}),t=i+" "+t}var o=wo(e,t,n);return"multi"==o&&(e.state.keySeq=t),"handled"==o&&bt(e,"keyHandled",e,t,r),"handled"!=o&&"multi"!=o||(We(r),Ar(e)),i&&!o&&/\'$/.test(t)?(We(r),!0):!!o}function Co(e,t){var r=ao(t,!0);return!!r&&(t.shiftKey&&!e.state.keySeq?xo(e,"Shift-"+r,t,function(t){return bo(e,t,!0)})||xo(e,r,t,function(t){if("string"==typeof t?/^go[A-Z]/.test(t):t.motion)return bo(e,t)}):xo(e,r,t,function(t){return bo(e,t)}))}function So(e,t,r){return xo(e,"'"+r+"'",t,function(t){return bo(e,t,!0)})}function Lo(e){var t=this;if(t.curOp.focus=l(),!Me(t,e)){gl&&vl<11&&27==e.keyCode&&(e.returnValue=!1);var r=e.keyCode;t.display.shift=16==r||e.shiftKey;var n=Co(t,e);wl&&(Us=n?r:null,!n&&88==r&&!rs&&(Ml?e.metaKey:e.ctrlKey)&&t.replaceSelection("",null,"cut")),18!=r||/\bCodeMirror-crosshair\b/.test(t.display.lineDiv.className)||ko(t)}}function ko(e){function t(e){18!=e.keyCode&&e.altKey||(Fl(r,"CodeMirror-crosshair"),ke(document,"keyup",t),ke(document,"mouseover",t))}var r=e.display.lineDiv;s(r,"CodeMirror-crosshair"),Ql(document,"keyup",t),Ql(document,"mouseover",t)}function To(e){16==e.keyCode&&(this.doc.sel.shift=!1),Me(this,e)}function Mo(e){var t=this;if(!(Ft(t.display,e)||Me(t,e)||e.ctrlKey&&!e.altKey||Ml&&e.metaKey)){var r=e.keyCode,n=e.charCode;if(wl&&r==Us)return Us=null,void We(e);if(!wl||e.which&&!(e.which<10)||!Co(t,e)){var i=String.fromCharCode(null==n?r:n);"\b"!=i&&(So(t,e,i)||t.display.input.onKeyPress(e))}}}function No(e,t){var r=+new Date;return js&&js.compare(r,e,t)?(Ks=js=null,"triple"):Ks&&Ks.compare(r,e,t)?(js=new Vs(r,e,t),Ks=null,"double"):(Ks=new Vs(r,e,t),js=null,"single")}function Oo(e){var t=this,r=t.display;if(!(Me(t,e)||r.activeTouch&&r.input.supportsTouch()))if(r.input.ensurePolled(),r.shift=e.shiftKey,Ft(r,e))ml||(r.scroller.draggable=!1,setTimeout(function(){return r.scroller.draggable=!0},100));else if(!zo(t,e)){var n=Sr(t,e),i=Pe(e),o=n?No(n,i):"single";window.focus(),1==i&&t.state.selectingText&&t.state.selectingText(e),n&&Ao(t,i,n,o,e)||(1==i?n?Do(t,n,o,e):Ee(e)==r.scroller&&We(e):2==i?(n&&di(t.doc,n),setTimeout(function(){return r.input.focus()},20)):3==i&&(Hl?Ro(t,e):Dr(t)))}}function Ao(e,t,r,n,i){var o="Click";return"double"==n?o="Double"+o:"triple"==n&&(o="Triple"+o),o=(1==t?"Left":2==t?"Middle":"Right")+o,xo(e,so(o,i),i,function(t){if("string"==typeof t&&(t=Bs[t]),!t)return!1;var n=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),n=t(e,r)!=Bl}finally{e.state.suppressEdits=!1}return n})}function Wo(e,t,r){var n=e.getOption("configureMouse"),i=n?n(e,t,r):{};if(null==i.unit){var o=Nl?r.shiftKey&&r.metaKey:r.altKey;i.unit=o?"rectangle":"single"==t?"char":"double"==t?"word":"line"}return(null==i.extend||e.doc.extend)&&(i.extend=e.doc.extend||r.shiftKey),null==i.addNew&&(i.addNew=Ml?r.metaKey:r.ctrlKey),null==i.moveOnDrag&&(i.moveOnDrag=!(Ml?r.altKey:r.ctrlKey)),i}function Do(e,t,r,n){gl?setTimeout(u(Wr,e),0):e.curOp.focus=l();var i,o=Wo(e,r,n),s=e.doc.sel;e.options.dragDrop&&Jl&&!e.isReadOnly()&&"single"==r&&(i=s.contains(t))>-1&&(P((i=s.ranges[i]).from(),t)<0||t.xRel>0)&&(P(i.to(),t)>0||t.xRel<0)?Ho(e,n,t,o):Eo(e,n,t,o)}function Ho(e,t,r,n){var i=e.display,o=!1,l=dn(e,function(t){ml&&(i.scroller.draggable=!1),e.state.draggingText=!1,ke(document,"mouseup",l),ke(document,"mousemove",s),ke(i.scroller,"dragstart",a),ke(i.scroller,"drop",l),o||(We(t),n.addNew||di(e.doc,r,null,null,n.extend),ml||gl&&9==vl?setTimeout(function(){document.body.focus(),i.input.focus()},20):i.input.focus())}),s=function(e){o=o||Math.abs(t.clientX-e.clientX)+Math.abs(t.clientY-e.clientY)>=10},a=function(){return o=!0};ml&&(i.scroller.draggable=!0),e.state.draggingText=l,l.copy=!n.moveOnDrag,i.scroller.dragDrop&&i.scroller.dragDrop(),Ql(document,"mouseup",l),Ql(document,"mousemove",s),Ql(i.scroller,"dragstart",a),Ql(i.scroller,"drop",l),Dr(e),setTimeout(function(){return i.input.focus()},20)}function Fo(e,t,r){if("char"==r)return new Ts(t,t);if("word"==r)return e.findWordAt(t);if("line"==r)return new Ts(E(t.line,0),U(e.doc,E(t.line+1,0)));var n=r(e,t);return new Ts(n.from,n.to)}function Eo(e,t,r,n){function i(t){if(0!=P(m,t))if(m=t,"rectangle"==n.unit){for(var i=[],o=e.options.tabSize,l=f(M(u,r.line).text,r.ch,o),s=f(M(u,t.line).text,t.ch,o),a=Math.min(l,s),g=Math.max(l,s),v=Math.min(r.line,t.line),y=Math.min(e.lastLine(),Math.max(r.line,t.line));v<=y;v++){var b=M(u,v).text,w=d(b,a,o);a==g?i.push(new Ts(E(v,w),E(v,w))):b.length>w&&i.push(new Ts(E(v,w),E(v,d(b,g,o))))}i.length||i.push(new Ts(r,r)),bi(u,zn(p.ranges.slice(0,h).concat(i),h),{origin:"*mouse",scroll:!1}),e.scrollIntoView(t)}else{var x,C=c,S=Fo(e,t,n.unit),L=C.anchor;P(S.anchor,L)>0?(x=S.head,L=B(C.from(),S.anchor)):(x=S.anchor,L=R(C.to(),S.head));var k=p.ranges.slice(0);k[h]=Po(e,new Ts(U(u,L),x)),bi(u,zn(k,h),Ul)}}function o(t){var r=++b,s=Sr(e,t,!0,"rectangle"==n.unit);if(s)if(0!=P(s,m)){e.curOp.focus=l(),i(s);var c=Ir(a,u);(s.line>=c.to||s.line<c.from)&&setTimeout(dn(e,function(){b==r&&o(t)}),150)}else{var f=t.clientY<y.top?-20:t.clientY>y.bottom?20:0;f&&setTimeout(dn(e,function(){b==r&&(a.scroller.scrollTop+=f,o(t))}),50)}}function s(t){e.state.selectingText=!1,b=1/0,We(t),a.input.focus(),ke(document,"mousemove",w),ke(document,"mouseup",x),u.history.lastSelOrigin=null}var a=e.display,u=e.doc;We(t);var c,h,p=u.sel,g=p.ranges;if(n.addNew&&!n.extend?(h=u.sel.contains(r),c=h>-1?g[h]:new Ts(r,r)):(c=u.sel.primary(),h=u.sel.primIndex),"rectangle"==n.unit)n.addNew||(c=new Ts(r,r)),r=Sr(e,t,!0,!0),h=-1;else{var v=Fo(e,r,n.unit);c=n.extend?hi(c,v.anchor,v.head,n.extend):v}n.addNew?-1==h?(h=g.length,bi(u,zn(g.concat([c]),h),{scroll:!1,origin:"*mouse"})):g.length>1&&g[h].empty()&&"char"==n.unit&&!n.extend?(bi(u,zn(g.slice(0,h).concat(g.slice(h+1)),0),{scroll:!1,origin:"*mouse"}),p=u.sel):gi(u,h,c,Ul):(h=0,bi(u,new ks([c],0),Ul),p=u.sel);var m=r,y=a.wrapper.getBoundingClientRect(),b=0,w=dn(e,function(e){Pe(e)?o(e):s(e)}),x=dn(e,s);e.state.selectingText=x,Ql(document,"mousemove",w),Ql(document,"mouseup",x)}function Po(e,t){var r=t.anchor,n=t.head,i=M(e.doc,r.line);if(0==P(r,n)&&r.sticky==n.sticky)return t;var o=Se(i);if(!o)return t;var l=Ce(o,r.ch,r.sticky),s=o[l];if(s.from!=r.ch&&s.to!=r.ch)return t;var a=l+(s.from==r.ch==(1!=s.level)?0:1);if(0==a||a==o.length)return t;var u;if(n.line!=r.line)u=(n.line-r.line)*("ltr"==e.doc.direction?1:-1)>0;else{var c=Ce(o,n.ch,n.sticky),f=c-l||(n.ch-r.ch)*(1==s.level?-1:1);u=c==a-1||c==a?f<0:f>0}var h=o[a+(u?-1:0)],d=u==(1==h.level),p=d?h.from:h.to,g=d?"after":"before";return r.ch==p&&r.sticky==g?t:new Ts(new E(r.line,p,g),n)}function Io(e,t,r,n){var i,o;if(t.touches)i=t.touches[0].clientX,o=t.touches[0].clientY;else try{i=t.clientX,o=t.clientY}catch(t){return!1}if(i>=Math.floor(e.display.gutters.getBoundingClientRect().right))return!1;n&&We(t);var l=e.display,s=l.lineDiv.getBoundingClientRect();if(o>s.bottom||!Oe(e,r))return He(t);o-=s.top-l.viewOffset;for(var a=0;a<e.options.gutters.length;++a){var u=l.gutters.childNodes[a];if(u&&u.getBoundingClientRect().right>=i)return Te(e,r,e,D(e.doc,o),e.options.gutters[a],t),He(t)}}function zo(e,t){return Io(e,t,"gutterClick",!0)}function Ro(e,t){Ft(e.display,t)||Bo(e,t)||Me(e,t,"contextmenu")||e.display.input.onContextMenu(t)}function Bo(e,t){return!!Oe(e,"gutterContextMenu")&&Io(e,t,"gutterContextMenu",!1)}function Go(e){e.display.wrapper.className=e.display.wrapper.className.replace(/\s*cm-s-\S+/g,"")+e.options.theme.replace(/(^|\s)\s*/g," cm-s-"),er(e)}function Uo(e){Hn(e),vn(e),zr(e)}function Vo(e,t,r){if(!t!=!(r&&r!=Xs)){var n=e.display.dragFunctions,i=t?Ql:ke;i(e.display.scroller,"dragstart",n.start),i(e.display.scroller,"dragenter",n.enter),i(e.display.scroller,"dragover",n.over),i(e.display.scroller,"dragleave",n.leave),i(e.display.scroller,"drop",n.drop)}}function Ko(e){e.options.lineWrapping?(s(e.display.wrapper,"CodeMirror-wrap"),e.display.sizer.style.minWidth="",e.display.sizerWidth=null):(Fl(e.display.wrapper,"CodeMirror-wrap"),we(e)),Cr(e),vn(e),er(e),setTimeout(function(){return en(e)},100)}function jo(e,t){var r=this;if(!(this instanceof jo))return new jo(e,t);this.options=t=t?c(t):{},c(Ys,t,!1),Fn(t);var n=t.value;"string"==typeof n&&(n=new Ds(n,t.mode,null,t.lineSeparator,t.direction)),this.doc=n;var i=new jo.inputStyles[t.inputStyle](this),o=this.display=new T(e,n,i);o.wrapper.CodeMirror=this,Hn(this),Go(this),t.lineWrapping&&(this.display.wrapper.className+=" CodeMirror-wrap"),rn(this),this.state={keyMaps:[],overlays:[],modeGen:0,overwrite:!1,delayingBlurEvent:!1,focused:!1,suppressEdits:!1,pasteIncoming:!1,cutIncoming:!1,selectingText:!1,draggingText:!1,highlight:new Pl,keySeq:null,specialChars:null},t.autofocus&&!Tl&&o.input.focus(),gl&&vl<11&&setTimeout(function(){return r.display.input.reset(!0)},20),Xo(this),eo(),nn(this),this.curOp.forceUpdate=!0,qn(this,n),t.autofocus&&!Tl||this.hasFocus()?setTimeout(u(Hr,this),20):Fr(this);for(var l in _s)_s.hasOwnProperty(l)&&_s[l](r,t[l],Xs);Rr(this),t.finishInit&&t.finishInit(this);for(var s=0;s<$s.length;++s)$s[s](r);on(this),ml&&t.lineWrapping&&"optimizelegibility"==getComputedStyle(o.lineDiv).textRendering&&(o.lineDiv.style.textRendering="auto")}function Xo(e){function t(){i.activeTouch&&(o=setTimeout(function(){return i.activeTouch=null},1e3),(l=i.activeTouch).end=+new Date)}function r(e){if(1!=e.touches.length)return!1;var t=e.touches[0];return t.radiusX<=1&&t.radiusY<=1}function n(e,t){if(null==t.left)return!0;var r=t.left-e.left,n=t.top-e.top;return r*r+n*n>400}var i=e.display;Ql(i.scroller,"mousedown",dn(e,Oo)),gl&&vl<11?Ql(i.scroller,"dblclick",dn(e,function(t){if(!Me(e,t)){var r=Sr(e,t);if(r&&!zo(e,t)&&!Ft(e.display,t)){We(t);var n=e.findWordAt(r);di(e.doc,n.anchor,n.head)}}})):Ql(i.scroller,"dblclick",function(t){return Me(e,t)||We(t)}),Hl||Ql(i.scroller,"contextmenu",function(t){return Ro(e,t)});var o,l={end:0};Ql(i.scroller,"touchstart",function(t){if(!Me(e,t)&&!r(t)&&!zo(e,t)){i.input.ensurePolled(),clearTimeout(o);var n=+new Date;i.activeTouch={start:n,moved:!1,prev:n-l.end<=300?l:null},1==t.touches.length&&(i.activeTouch.left=t.touches[0].pageX,i.activeTouch.top=t.touches[0].pageY)}}),Ql(i.scroller,"touchmove",function(){i.activeTouch&&(i.activeTouch.moved=!0)}),Ql(i.scroller,"touchend",function(r){var o=i.activeTouch;if(o&&!Ft(i,r)&&null!=o.left&&!o.moved&&new Date-o.start<300){var l,s=e.coordsChar(i.activeTouch,"page");l=!o.prev||n(o,o.prev)?new Ts(s,s):!o.prev.prev||n(o,o.prev.prev)?e.findWordAt(s):new Ts(E(s.line,0),U(e.doc,E(s.line+1,0))),e.setSelection(l.anchor,l.head),e.focus(),We(r)}t()}),Ql(i.scroller,"touchcancel",t),Ql(i.scroller,"scroll",function(){i.scroller.clientHeight&&(qr(e,i.scroller.scrollTop),Qr(e,i.scroller.scrollLeft,!0),Te(e,"scroll",e))}),Ql(i.scroller,"mousewheel",function(t){return In(e,t)}),Ql(i.scroller,"DOMMouseScroll",function(t){return In(e,t)}),Ql(i.wrapper,"scroll",function(){return i.wrapper.scrollTop=i.wrapper.scrollLeft=0}),i.dragFunctions={enter:function(t){Me(e,t)||Fe(t)},over:function(t){Me(e,t)||(Zi(e,t),Fe(t))},start:function(t){return qi(e,t)},drop:dn(e,$i),leave:function(t){Me(e,t)||Qi(e)}};var s=i.input.getField();Ql(s,"keyup",function(t){return To.call(e,t)}),Ql(s,"keydown",dn(e,Lo)),Ql(s,"keypress",dn(e,Mo)),Ql(s,"focus",function(t){return Hr(e,t)}),Ql(s,"blur",function(t){return Fr(e,t)})}function Yo(e,t,r,n){var i,o=e.doc;null==r&&(r="add"),"smart"==r&&(o.mode.indent?i=$e(e,t).state:r="prev");var l=e.options.tabSize,s=M(o,t),a=f(s.text,null,l);s.stateAfter&&(s.stateAfter=null);var u,c=s.text.match(/^\s*/)[0];if(n||/\S/.test(s.text)){if("smart"==r&&((u=o.mode.indent(i,s.text.slice(c.length),s.text))==Bl||u>150)){if(!n)return;r="prev"}}else u=0,r="not";"prev"==r?u=t>o.first?f(M(o,t-1).text,null,l):0:"add"==r?u=a+e.options.indentUnit:"subtract"==r?u=a-e.options.indentUnit:"number"==typeof r&&(u=a+r),u=Math.max(0,u);var h="",d=0;if(e.options.indentWithTabs)for(var g=Math.floor(u/l);g;--g)d+=l,h+="\t";if(d<u&&(h+=p(u-d)),h!=c)return Ei(o,h,E(t,0),E(t,c.length),"+input"),s.stateAfter=null,!0;for(var v=0;v<o.sel.ranges.length;v++){var m=o.sel.ranges[v];if(m.head.line==t&&m.head.ch<c.length){var y=E(t,c.length);gi(o,v,new Ts(y,y));break}}}function _o(e){qs=e}function $o(e,t,r,n,i){var o=e.doc;e.display.shift=!1,n||(n=o.sel);var l=e.state.pasteIncoming||"paste"==i,s=es(t),a=null;if(l&&n.ranges.length>1)if(qs&&qs.text.join("\n")==t){if(n.ranges.length%qs.text.length==0){a=[];for(var u=0;u<qs.text.length;u++)a.push(o.splitLines(qs.text[u]))}}else s.length==n.ranges.length&&e.options.pasteLinesPerSelection&&(a=v(s,function(e){return[e]}));for(var c,f=n.ranges.length-1;f>=0;f--){var h=n.ranges[f],d=h.from(),p=h.to();h.empty()&&(r&&r>0?d=E(d.line,d.ch-r):e.state.overwrite&&!l?p=E(p.line,Math.min(M(o,p.line).text.length,p.ch+g(s).length)):qs&&qs.lineWise&&qs.text.join("\n")==t&&(d=p=E(d.line,0))),c=e.curOp.updateInput;var m={from:d,to:p,text:a?a[f%a.length]:s,origin:i||(l?"paste":e.state.cutIncoming?"cut":"+input")};Oi(e.doc,m),bt(e,"inputRead",e,m)}t&&!l&&Zo(e,t),jr(e),e.curOp.updateInput=c,e.curOp.typing=!0,e.state.pasteIncoming=e.state.cutIncoming=!1}function qo(e,t){var r=e.clipboardData&&e.clipboardData.getData("Text");if(r)return e.preventDefault(),t.isReadOnly()||t.options.disableInput||hn(t,function(){return $o(t,r,0,null,"paste")}),!0}function Zo(e,t){if(e.options.electricChars&&e.options.smartIndent)for(var r=e.doc.sel,n=r.ranges.length-1;n>=0;n--){var i=r.ranges[n];if(!(i.head.ch>100||n&&r.ranges[n-1].head.line==i.head.line)){var o=e.getModeAt(i.head),l=!1;if(o.electricChars){for(var s=0;s<o.electricChars.length;s++)if(t.indexOf(o.electricChars.charAt(s))>-1){l=Yo(e,i.head.line,"smart");break}}else o.electricInput&&o.electricInput.test(M(e.doc,i.head.line).text.slice(0,i.head.ch))&&(l=Yo(e,i.head.line,"smart"));l&&bt(e,"electricInput",e,i.head.line)}}}function Qo(e){for(var t=[],r=[],n=0;n<e.doc.sel.ranges.length;n++){var i=e.doc.sel.ranges[n].head.line,o={anchor:E(i,0),head:E(i+1,0)};r.push(o),t.push(e.getRange(o.anchor,o.head))}return{text:t,ranges:r}}function Jo(e,t){e.setAttribute("autocorrect","off"),e.setAttribute("autocapitalize","off"),e.setAttribute("spellcheck",!!t)}function el(){var e=n("textarea",null,null,"position: absolute; bottom: -1em; padding: 0; width: 1px; height: 1em; outline: none"),t=n("div",[e],null,"overflow: hidden; position: relative; width: 3px; height: 0px;");return ml?e.style.width="1000px":e.setAttribute("wrap","off"),Ll&&(e.style.border="1px solid black"),Jo(e),t}function tl(e,t,r,n,i){function o(){var n=t.line+r;return!(n<e.first||n>=e.first+e.size)&&(t=new E(n,t.ch,t.sticky),u=M(e,n))}function l(n){var l;if(null==(l=i?go(e.cm,u,t,r):ho(u,t,r))){if(n||!o())return!1;t=po(i,e.cm,u,t.line,r)}else t=l;return!0}var s=t,a=r,u=M(e,t.line);if("char"==n)l();else if("column"==n)l(!0);else if("word"==n||"group"==n)for(var c=null,f="group"==n,h=e.cm&&e.cm.getHelper(t,"wordChars"),d=!0;!(r<0)||l(!d);d=!1){var p=u.text.charAt(t.ch)||"\n",g=x(p,h)?"w":f&&"\n"==p?"n":!f||/\s/.test(p)?null:"p";if(!f||d||g||(g="s"),c&&c!=g){r<0&&(r=1,l(),t.sticky="after");break}if(g&&(c=g),r>0&&!l(!d))break}var v=ki(e,t,s,a,!0);return I(s,v)&&(v.hitSide=!0),v}function rl(e,t,r,n){var i,o=e.doc,l=t.left;if("page"==n){var s=Math.min(e.display.wrapper.clientHeight,window.innerHeight||document.documentElement.clientHeight),a=Math.max(s-.5*mr(e.display),3);i=(r>0?t.bottom:t.top)+r*a}else"line"==n&&(i=r>0?t.bottom+3:t.top-3);for(var u;(u=cr(e,l,i)).outside;){if(r<0?i<=0:i>=o.height){u.hitSide=!0;break}i+=5*r}return u}function nl(e,t){var r=jt(e,t.line);if(!r||r.hidden)return null;var n=M(e.doc,t.line),i=Ut(r,n,t.line),o=Se(n,e.doc.direction),l="left";o&&(l=Ce(o,t.ch)%2?"right":"left");var s=_t(i.map,t.ch,l);return s.offset="right"==s.collapse?s.end:s.start,s}function il(e){for(var t=e;t;t=t.parentNode)if(/CodeMirror-gutter-wrapper/.test(t.className))return!0;return!1}function ol(e,t){return t&&(e.bad=!0),e}function ll(e,t,r,n,i){function o(e){return function(t){return t.id==e}}function l(){c&&(u+=f,c=!1)}function s(e){e&&(l(),u+=e)}function a(t){if(1==t.nodeType){var r=t.getAttribute("cm-text");if(null!=r)return void s(r||t.textContent.replace(/\u200b/g,""));var u,h=t.getAttribute("cm-marker");if(h){var d=e.findMarks(E(n,0),E(i+1,0),o(+h));return void(d.length&&(u=d[0].find(0))&&s(N(e.doc,u.from,u.to).join(f)))}if("false"==t.getAttribute("contenteditable"))return;var p=/^(pre|div|p)$/i.test(t.nodeName);p&&l();for(var g=0;g<t.childNodes.length;g++)a(t.childNodes[g]);p&&(c=!0)}else 3==t.nodeType&&s(t.nodeValue)}for(var u="",c=!1,f=e.doc.lineSeparator();a(t),t!=r;)t=t.nextSibling;return u}function sl(e,t,r){var n;if(t==e.display.lineDiv){if(!(n=e.display.lineDiv.childNodes[r]))return ol(e.clipPos(E(e.display.viewTo-1)),!0);t=null,r=0}else for(n=t;;n=n.parentNode){if(!n||n==e.display.lineDiv)return null;if(n.parentNode&&n.parentNode==e.display.lineDiv)break}for(var i=0;i<e.display.view.length;i++){var o=e.display.view[i];if(o.node==n)return al(o,t,r)}}function al(e,t,r){function n(t,r,n){for(var i=-1;i<(f?f.length:0);i++)for(var o=i<0?c.map:f[i],l=0;l<o.length;l+=3){var s=o[l+2];if(s==t||s==r){var a=W(i<0?e.line:e.rest[i]),u=o[l]+n;return(n<0||s!=t)&&(u=o[l+(n?1:0)]),E(a,u)}}}var i=e.text.firstChild,l=!1;if(!t||!o(i,t))return ol(E(W(e.line),0),!0);if(t==i&&(l=!0,t=i.childNodes[r],r=0,!t)){var s=e.rest?g(e.rest):e.line;return ol(E(W(s),s.text.length),l)}var a=3==t.nodeType?t:null,u=t;for(a||1!=t.childNodes.length||3!=t.firstChild.nodeType||(a=t.firstChild,r&&(r=a.nodeValue.length));u.parentNode!=i;)u=u.parentNode;var c=e.measure,f=c.maps,h=n(a,u,r);if(h)return ol(h,l);for(var d=u.nextSibling,p=a?a.nodeValue.length-r:0;d;d=d.nextSibling){if(h=n(d,d.firstChild,0))return ol(E(h.line,h.ch-p),l);p+=d.textContent.length}for(var v=u.previousSibling,m=r;v;v=v.previousSibling){if(h=n(v,v.firstChild,-1))return ol(E(h.line,h.ch+m),l);m+=v.textContent.length}}var ul=navigator.userAgent,cl=navigator.platform,fl=/gecko\/\d/i.test(ul),hl=/MSIE \d/.test(ul),dl=/Trident\/(?:[7-9]|\d{2,})\..*rv:(\d+)/.exec(ul),pl=/Edge\/(\d+)/.exec(ul),gl=hl||dl||pl,vl=gl&&(hl?document.documentMode||6:+(pl||dl)[1]),ml=!pl&&/WebKit\//.test(ul),yl=ml&&/Qt\/\d+\.\d+/.test(ul),bl=!pl&&/Chrome\//.test(ul),wl=/Opera\//.test(ul),xl=/Apple Computer/.test(navigator.vendor),Cl=/Mac OS X 1\d\D([8-9]|\d\d)\D/.test(ul),Sl=/PhantomJS/.test(ul),Ll=!pl&&/AppleWebKit/.test(ul)&&/Mobile\/\w+/.test(ul),kl=/Android/.test(ul),Tl=Ll||kl||/webOS|BlackBerry|Opera Mini|Opera Mobi|IEMobile/i.test(ul),Ml=Ll||/Mac/.test(cl),Nl=/\bCrOS\b/.test(ul),Ol=/win/i.test(cl),Al=wl&&ul.match(/Version\/(\d*\.\d*)/);Al&&(Al=Number(Al[1])),Al&&Al>=15&&(wl=!1,ml=!0);var Wl,Dl=Ml&&(yl||wl&&(null==Al||Al<12.11)),Hl=fl||gl&&vl>=9,Fl=function(t,r){var n=t.className,i=e(r).exec(n);if(i){var o=n.slice(i.index+i[0].length);t.className=n.slice(0,i.index)+(o?i[1]+o:"")}};Wl=document.createRange?function(e,t,r,n){var i=document.createRange();return i.setEnd(n||e,r),i.setStart(e,t),i}:function(e,t,r){var n=document.body.createTextRange();try{n.moveToElementText(e.parentNode)}catch(e){return n}return n.collapse(!0),n.moveEnd("character",r),n.moveStart("character",t),n};var El=function(e){e.select()};Ll?El=function(e){e.selectionStart=0,e.selectionEnd=e.value.length}:gl&&(El=function(e){try{e.select()}catch(e){}});var Pl=function(){this.id=null};Pl.prototype.set=function(e,t){clearTimeout(this.id),this.id=setTimeout(t,e)};var Il,zl,Rl=30,Bl={toString:function(){return"CodeMirror.Pass"}},Gl={scroll:!1},Ul={origin:"*mouse"},Vl={origin:"+move"},Kl=[""],jl=/[\u00df\u0587\u0590-\u05f4\u0600-\u06ff\u3040-\u309f\u30a0-\u30ff\u3400-\u4db5\u4e00-\u9fcc\uac00-\ud7af]/,Xl=/[\u0300-\u036f\u0483-\u0489\u0591-\u05bd\u05bf\u05c1\u05c2\u05c4\u05c5\u05c7\u0610-\u061a\u064b-\u065e\u0670\u06d6-\u06dc\u06de-\u06e4\u06e7\u06e8\u06ea-\u06ed\u0711\u0730-\u074a\u07a6-\u07b0\u07eb-\u07f3\u0816-\u0819\u081b-\u0823\u0825-\u0827\u0829-\u082d\u0900-\u0902\u093c\u0941-\u0948\u094d\u0951-\u0955\u0962\u0963\u0981\u09bc\u09be\u09c1-\u09c4\u09cd\u09d7\u09e2\u09e3\u0a01\u0a02\u0a3c\u0a41\u0a42\u0a47\u0a48\u0a4b-\u0a4d\u0a51\u0a70\u0a71\u0a75\u0a81\u0a82\u0abc\u0ac1-\u0ac5\u0ac7\u0ac8\u0acd\u0ae2\u0ae3\u0b01\u0b3c\u0b3e\u0b3f\u0b41-\u0b44\u0b4d\u0b56\u0b57\u0b62\u0b63\u0b82\u0bbe\u0bc0\u0bcd\u0bd7\u0c3e-\u0c40\u0c46-\u0c48\u0c4a-\u0c4d\u0c55\u0c56\u0c62\u0c63\u0cbc\u0cbf\u0cc2\u0cc6\u0ccc\u0ccd\u0cd5\u0cd6\u0ce2\u0ce3\u0d3e\u0d41-\u0d44\u0d4d\u0d57\u0d62\u0d63\u0dca\u0dcf\u0dd2-\u0dd4\u0dd6\u0ddf\u0e31\u0e34-\u0e3a\u0e47-\u0e4e\u0eb1\u0eb4-\u0eb9\u0ebb\u0ebc\u0ec8-\u0ecd\u0f18\u0f19\u0f35\u0f37\u0f39\u0f71-\u0f7e\u0f80-\u0f84\u0f86\u0f87\u0f90-\u0f97\u0f99-\u0fbc\u0fc6\u102d-\u1030\u1032-\u1037\u1039\u103a\u103d\u103e\u1058\u1059\u105e-\u1060\u1071-\u1074\u1082\u1085\u1086\u108d\u109d\u135f\u1712-\u1714\u1732-\u1734\u1752\u1753\u1772\u1773\u17b7-\u17bd\u17c6\u17c9-\u17d3\u17dd\u180b-\u180d\u18a9\u1920-\u1922\u1927\u1928\u1932\u1939-\u193b\u1a17\u1a18\u1a56\u1a58-\u1a5e\u1a60\u1a62\u1a65-\u1a6c\u1a73-\u1a7c\u1a7f\u1b00-\u1b03\u1b34\u1b36-\u1b3a\u1b3c\u1b42\u1b6b-\u1b73\u1b80\u1b81\u1ba2-\u1ba5\u1ba8\u1ba9\u1c2c-\u1c33\u1c36\u1c37\u1cd0-\u1cd2\u1cd4-\u1ce0\u1ce2-\u1ce8\u1ced\u1dc0-\u1de6\u1dfd-\u1dff\u200c\u200d\u20d0-\u20f0\u2cef-\u2cf1\u2de0-\u2dff\u302a-\u302f\u3099\u309a\ua66f-\ua672\ua67c\ua67d\ua6f0\ua6f1\ua802\ua806\ua80b\ua825\ua826\ua8c4\ua8e0-\ua8f1\ua926-\ua92d\ua947-\ua951\ua980-\ua982\ua9b3\ua9b6-\ua9b9\ua9bc\uaa29-\uaa2e\uaa31\uaa32\uaa35\uaa36\uaa43\uaa4c\uaab0\uaab2-\uaab4\uaab7\uaab8\uaabe\uaabf\uaac1\uabe5\uabe8\uabed\udc00-\udfff\ufb1e\ufe00-\ufe0f\ufe20-\ufe26\uff9e\uff9f]/,Yl=!1,_l=!1,$l=null,ql=function(){function e(e){return e<=247?r.charAt(e):1424<=e&&e<=1524?"R":1536<=e&&e<=1785?n.charAt(e-1536):1774<=e&&e<=2220?"r":8192<=e&&e<=8203?"w":8204==e?"b":"L"}function t(e,t,r){this.level=e,this.from=t,this.to=r}var r="bbbbbbbbbtstwsbbbbbbbbbbbbbbssstwNN%%%NNNNNN,N,N1111111111NNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNbbbbbbsbbbbbbbbbbbbbbbbbbbbbbbbbb,N%%%%NNNNLNNNNN%%11NLNNN1LNNNNNLLLLLLLLLLLLLLLLLLLLLLLNLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLN",n="nnnnnnNNr%%r,rNNmmmmmmmmmmmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmmmmmmmmmmmmmmmnnnnnnnnnn%nnrrrmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmnNmmmmmmrrmmNmmmmrr1111111111",i=/[\u0590-\u05f4\u0600-\u06ff\u0700-\u08ac]/,o=/[stwN]/,l=/[LRr]/,s=/[Lb1n]/,a=/[1n]/;return function(r,n){var u="ltr"==n?"L":"R";if(0==r.length||"ltr"==n&&!i.test(r))return!1;for(var c=r.length,f=[],h=0;h<c;++h)f.push(e(r.charCodeAt(h)));for(var d=0,p=u;d<c;++d){var v=f[d];"m"==v?f[d]=p:p=v}for(var m=0,y=u;m<c;++m){var b=f[m];"1"==b&&"r"==y?f[m]="n":l.test(b)&&(y=b,"r"==b&&(f[m]="R"))}for(var w=1,x=f[0];w<c-1;++w){var C=f[w];"+"==C&&"1"==x&&"1"==f[w+1]?f[w]="1":","!=C||x!=f[w+1]||"1"!=x&&"n"!=x||(f[w]=x),x=C}for(var S=0;S<c;++S){var L=f[S];if(","==L)f[S]="N";else if("%"==L){var k=void 0;for(k=S+1;k<c&&"%"==f[k];++k);for(var T=S&&"!"==f[S-1]||k<c&&"1"==f[k]?"1":"N",M=S;M<k;++M)f[M]=T;S=k-1}}for(var N=0,O=u;N<c;++N){var A=f[N];"L"==O&&"1"==A?f[N]="L":l.test(A)&&(O=A)}for(var W=0;W<c;++W)if(o.test(f[W])){var D=void 0;for(D=W+1;D<c&&o.test(f[D]);++D);for(var H="L"==(W?f[W-1]:u),F=H==("L"==(D<c?f[D]:u))?H?"L":"R":u,E=W;E<D;++E)f[E]=F;W=D-1}for(var P,I=[],z=0;z<c;)if(s.test(f[z])){var R=z;for(++z;z<c&&s.test(f[z]);++z);I.push(new t(0,R,z))}else{var B=z,G=I.length;for(++z;z<c&&"L"!=f[z];++z);for(var U=B;U<z;)if(a.test(f[U])){B<U&&I.splice(G,0,new t(1,B,U));var V=U;for(++U;U<z&&a.test(f[U]);++U);I.splice(G,0,new t(2,V,U)),B=U}else++U;B<z&&I.splice(G,0,new t(1,B,z))}return 1==I[0].level&&(P=r.match(/^\s+/))&&(I[0].from=P[0].length,I.unshift(new t(0,0,P[0].length))),1==g(I).level&&(P=r.match(/\s+$/))&&(g(I).to-=P[0].length,I.push(new t(0,c-P[0].length,c))),"rtl"==n?I.reverse():I}}(),Zl=[],Ql=function(e,t,r){if(e.addEventListener)e.addEventListener(t,r,!1);else if(e.attachEvent)e.attachEvent("on"+t,r);else{var n=e._handlers||(e._handlers={});n[t]=(n[t]||Zl).concat(r)}},Jl=function(){if(gl&&vl<9)return!1;var e=n("div");return"draggable"in e||"dragDrop"in e}(),es=3!="\n\nb".split(/\n/).length?function(e){for(var t=0,r=[],n=e.length;t<=n;){var i=e.indexOf("\n",t);-1==i&&(i=e.length);var o=e.slice(t,"\r"==e.charAt(i-1)?i-1:i),l=o.indexOf("\r");-1!=l?(r.push(o.slice(0,l)),t+=l+1):(r.push(o),t=i+1)}return r}:function(e){return e.split(/\r\n?|\n/)},ts=window.getSelection?function(e){try{return e.selectionStart!=e.selectionEnd}catch(e){return!1}}:function(e){var t;try{t=e.ownerDocument.selection.createRange()}catch(e){}return!(!t||t.parentElement()!=e)&&0!=t.compareEndPoints("StartToEnd",t)},rs=function(){var e=n("div");return"oncopy"in e||(e.setAttribute("oncopy","return;"),"function"==typeof e.oncopy)}(),ns=null,is={},os={},ls={},ss=function(e,t,r){this.pos=this.start=0,this.string=e,this.tabSize=t||8,this.lastColumnPos=this.lastColumnValue=0,this.lineStart=0,this.lineOracle=r};ss.prototype.eol=function(){return this.pos>=this.string.length},ss.prototype.sol=function(){return this.pos==this.lineStart},ss.prototype.peek=function(){return this.string.charAt(this.pos)||void 0},ss.prototype.next=function(){if(this.pos<this.string.length)return this.string.charAt(this.pos++)},ss.prototype.eat=function(e){var t=this.string.charAt(this.pos);if("string"==typeof e?t==e:t&&(e.test?e.test(t):e(t)))return++this.pos,t},ss.prototype.eatWhile=function(e){for(var t=this.pos;this.eat(e););return this.pos>t},ss.prototype.eatSpace=function(){for(var e=this,t=this.pos;/[\s\u00a0]/.test(this.string.charAt(this.pos));)++e.pos;return this.pos>t},ss.prototype.skipToEnd=function(){this.pos=this.string.length},ss.prototype.skipTo=function(e){var t=this.string.indexOf(e,this.pos);if(t>-1)return this.pos=t,!0},ss.prototype.backUp=function(e){this.pos-=e},ss.prototype.column=function(){return this.lastColumnPos<this.start&&(this.lastColumnValue=f(this.string,this.start,this.tabSize,this.lastColumnPos,this.lastColumnValue),this.lastColumnPos=this.start),this.lastColumnValue-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.indentation=function(){return f(this.string,null,this.tabSize)-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.match=function(e,t,r){if("string"!=typeof e){var n=this.string.slice(this.pos).match(e);return n&&n.index>0?null:(n&&!1!==t&&(this.pos+=n[0].length),n)}var i=function(e){return r?e.toLowerCase():e};if(i(this.string.substr(this.pos,e.length))==i(e))return!1!==t&&(this.pos+=e.length),!0},ss.prototype.current=function(){return this.string.slice(this.start,this.pos)},ss.prototype.hideFirstChars=function(e,t){this.lineStart+=e;try{return t()}finally{this.lineStart-=e}},ss.prototype.lookAhead=function(e){var t=this.lineOracle;return t&&t.lookAhead(e)};var as=function(e,t){this.state=e,this.lookAhead=t},us=function(e,t,r,n){this.state=t,this.doc=e,this.line=r,this.maxLookAhead=n||0};us.prototype.lookAhead=function(e){var t=this.doc.getLine(this.line+e);return null!=t&&e>this.maxLookAhead&&(this.maxLookAhead=e),t},us.prototype.nextLine=function(){this.line++,this.maxLookAhead>0&&this.maxLookAhead--},us.fromSaved=function(e,t,r){return t instanceof as?new us(e,Ke(e.mode,t.state),r,t.lookAhead):new us(e,Ke(e.mode,t),r)},us.prototype.save=function(e){var t=!1!==e?Ke(this.doc.mode,this.state):this.state;return this.maxLookAhead>0?new as(t,this.maxLookAhead):t};var cs=function(e,t,r){this.start=e.start,this.end=e.pos,this.string=e.current(),this.type=t||null,this.state=r},fs=function(e,t,r){this.text=e,ne(this,t),this.height=r?r(this):1};fs.prototype.lineNo=function(){return W(this)},Ae(fs);var hs,ds={},ps={},gs=null,vs=null,ms={left:0,right:0,top:0,bottom:0},ys=function(e,t,r){this.cm=r;var i=this.vert=n("div",[n("div",null,null,"min-width: 1px")],"CodeMirror-vscrollbar"),o=this.horiz=n("div",[n("div",null,null,"height: 100%; min-height: 1px")],"CodeMirror-hscrollbar");e(i),e(o),Ql(i,"scroll",function(){i.clientHeight&&t(i.scrollTop,"vertical")}),Ql(o,"scroll",function(){o.clientWidth&&t(o.scrollLeft,"horizontal")}),this.checkedZeroWidth=!1,gl&&vl<8&&(this.horiz.style.minHeight=this.vert.style.minWidth="18px")};ys.prototype.update=function(e){var t=e.scrollWidth>e.clientWidth+1,r=e.scrollHeight>e.clientHeight+1,n=e.nativeBarWidth;if(r){this.vert.style.display="block",this.vert.style.bottom=t?n+"px":"0";var i=e.viewHeight-(t?n:0);this.vert.firstChild.style.height=Math.max(0,e.scrollHeight-e.clientHeight+i)+"px"}else this.vert.style.display="",this.vert.firstChild.style.height="0";if(t){this.horiz.style.display="block",this.horiz.style.right=r?n+"px":"0",this.horiz.style.left=e.barLeft+"px";var o=e.viewWidth-e.barLeft-(r?n:0);this.horiz.firstChild.style.width=Math.max(0,e.scrollWidth-e.clientWidth+o)+"px"}else this.horiz.style.display="",this.horiz.firstChild.style.width="0";return!this.checkedZeroWidth&&e.clientHeight>0&&(0==n&&this.zeroWidthHack(),this.checkedZeroWidth=!0),{right:r?n:0,bottom:t?n:0}},ys.prototype.setScrollLeft=function(e){this.horiz.scrollLeft!=e&&(this.horiz.scrollLeft=e),this.disableHoriz&&this.enableZeroWidthBar(this.horiz,this.disableHoriz,"horiz")},ys.prototype.setScrollTop=function(e){this.vert.scrollTop!=e&&(this.vert.scrollTop=e),this.disableVert&&this.enableZeroWidthBar(this.vert,this.disableVert,"vert")},ys.prototype.zeroWidthHack=function(){var e=Ml&&!Cl?"12px":"18px";this.horiz.style.height=this.vert.style.width=e,this.horiz.style.pointerEvents=this.vert.style.pointerEvents="none",this.disableHoriz=new Pl,this.disableVert=new Pl},ys.prototype.enableZeroWidthBar=function(e,t,r){function n(){var i=e.getBoundingClientRect();("vert"==r?document.elementFromPoint(i.right-1,(i.top+i.bottom)/2):document.elementFromPoint((i.right+i.left)/2,i.bottom-1))!=e?e.style.pointerEvents="none":t.set(1e3,n)}e.style.pointerEvents="auto",t.set(1e3,n)},ys.prototype.clear=function(){var e=this.horiz.parentNode;e.removeChild(this.horiz),e.removeChild(this.vert)};var bs=function(){};bs.prototype.update=function(){return{bottom:0,right:0}},bs.prototype.setScrollLeft=function(){},bs.prototype.setScrollTop=function(){},bs.prototype.clear=function(){};var ws={native:ys,null:bs},xs=0,Cs=function(e,t,r){var n=e.display;this.viewport=t,this.visible=Ir(n,e.doc,t),this.editorIsHidden=!n.wrapper.offsetWidth,this.wrapperHeight=n.wrapper.clientHeight,this.wrapperWidth=n.wrapper.clientWidth,this.oldDisplayWidth=Rt(e),this.force=r,this.dims=br(e),this.events=[]};Cs.prototype.signal=function(e,t){Oe(e,t)&&this.events.push(arguments)},Cs.prototype.finish=function(){for(var e=this,t=0;t<this.events.length;t++)Te.apply(null,e.events[t])};var Ss=0,Ls=null;gl?Ls=-.53:fl?Ls=15:bl?Ls=-.7:xl&&(Ls=-1/3);var ks=function(e,t){this.ranges=e,this.primIndex=t};ks.prototype.primary=function(){return this.ranges[this.primIndex]},ks.prototype.equals=function(e){var t=this;if(e==this)return!0;if(e.primIndex!=this.primIndex||e.ranges.length!=this.ranges.length)return!1;for(var r=0;r<this.ranges.length;r++){var n=t.ranges[r],i=e.ranges[r];if(!I(n.anchor,i.anchor)||!I(n.head,i.head))return!1}return!0},ks.prototype.deepCopy=function(){for(var e=this,t=[],r=0;r<this.ranges.length;r++)t[r]=new Ts(z(e.ranges[r].anchor),z(e.ranges[r].head));return new ks(t,this.primIndex)},ks.prototype.somethingSelected=function(){for(var e=this,t=0;t<this.ranges.length;t++)if(!e.ranges[t].empty())return!0;return!1},ks.prototype.contains=function(e,t){var r=this;t||(t=e);for(var n=0;n<this.ranges.length;n++){var i=r.ranges[n];if(P(t,i.from())>=0&&P(e,i.to())<=0)return n}return-1};var Ts=function(e,t){this.anchor=e,this.head=t};Ts.prototype.from=function(){return B(this.anchor,this.head)},Ts.prototype.to=function(){return R(this.anchor,this.head)},Ts.prototype.empty=function(){return this.head.line==this.anchor.line&&this.head.ch==this.anchor.ch},Bi.prototype={chunkSize:function(){return this.lines.length},removeInner:function(e,t){for(var r=this,n=e,i=e+t;n<i;++n){var o=r.lines[n];r.height-=o.height,ot(o),bt(o,"delete")}this.lines.splice(e,t)},collapse:function(e){e.push.apply(e,this.lines)},insertInner:function(e,t,r){var n=this;this.height+=r,this.lines=this.lines.slice(0,e).concat(t).concat(this.lines.slice(e));for(var i=0;i<t.length;++i)t[i].parent=n},iterN:function(e,t,r){for(var n=this,i=e+t;e<i;++e)if(r(n.lines[e]))return!0}},Gi.prototype={chunkSize:function(){return this.size},removeInner:function(e,t){var r=this;this.size-=t;for(var n=0;n<this.children.length;++n){var i=r.children[n],o=i.chunkSize();if(e<o){var l=Math.min(t,o-e),s=i.height;if(i.removeInner(e,l),r.height-=s-i.height,o==l&&(r.children.splice(n--,1),i.parent=null),0==(t-=l))break;e=0}else e-=o}if(this.size-t<25&&(this.children.length>1||!(this.children[0]instanceof Bi))){var a=[];this.collapse(a),this.children=[new Bi(a)],this.children[0].parent=this}},collapse:function(e){for(var t=this,r=0;r<this.children.length;++r)t.children[r].collapse(e)},insertInner:function(e,t,r){var n=this;this.size+=t.length,this.height+=r;for(var i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<=l){if(o.insertInner(e,t,r),o.lines&&o.lines.length>50){for(var s=o.lines.length%25+25,a=s;a<o.lines.length;){var u=new Bi(o.lines.slice(a,a+=25));o.height-=u.height,n.children.splice(++i,0,u),u.parent=n}o.lines=o.lines.slice(0,s),n.maybeSpill()}break}e-=l}},maybeSpill:function(){if(!(this.children.length<=10)){var e=this;do{var t=new Gi(e.children.splice(e.children.length-5,5));if(e.parent){e.size-=t.size,e.height-=t.height;var r=h(e.parent.children,e);e.parent.children.splice(r+1,0,t)}else{var n=new Gi(e.children);n.parent=e,e.children=[n,t],e=n}t.parent=e.parent}while(e.children.length>10);e.parent.maybeSpill()}},iterN:function(e,t,r){for(var n=this,i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<l){var s=Math.min(t,l-e);if(o.iterN(e,s,r))return!0;if(0==(t-=s))break;e=0}else e-=l}}};var Ms=function(e,t,r){var n=this;if(r)for(var i in r)r.hasOwnProperty(i)&&(n[i]=r[i]);this.doc=e,this.node=t};Ms.prototype.clear=function(){var e=this,t=this.doc.cm,r=this.line.widgets,n=this.line,i=W(n);if(null!=i&&r){for(var o=0;o<r.length;++o)r[o]==e&&r.splice(o--,1);r.length||(n.widgets=null);var l=Ht(this);A(n,Math.max(0,n.height-l)),t&&(hn(t,function(){Ui(t,n,-l),mn(t,i,"widget")}),bt(t,"lineWidgetCleared",t,this,i))}},Ms.prototype.changed=function(){var e=this,t=this.height,r=this.doc.cm,n=this.line;this.height=null;var i=Ht(this)-t;i&&(A(n,n.height+i),r&&hn(r,function(){r.curOp.forceUpdate=!0,Ui(r,n,i),bt(r,"lineWidgetChanged",r,e,W(n))}))},Ae(Ms);var Ns=0,Os=function(e,t){this.lines=[],this.type=t,this.doc=e,this.id=++Ns};Os.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){var t=this.doc.cm,r=t&&!t.curOp;if(r&&nn(t),Oe(this,"clear")){var n=this.find();n&&bt(this,"clear",n.from,n.to)}for(var i=null,o=null,l=0;l<this.lines.length;++l){var s=e.lines[l],a=_(s.markedSpans,e);t&&!e.collapsed?mn(t,W(s),"text"):t&&(null!=a.to&&(o=W(s)),null!=a.from&&(i=W(s))),s.markedSpans=$(s.markedSpans,a),null==a.from&&e.collapsed&&!ve(e.doc,s)&&t&&A(s,mr(t.display))}if(t&&this.collapsed&&!t.options.lineWrapping)for(var u=0;u<this.lines.length;++u){var c=fe(e.lines[u]),f=be(c);f>t.display.maxLineLength&&(t.display.maxLine=c,t.display.maxLineLength=f,t.display.maxLineChanged=!0)}null!=i&&t&&this.collapsed&&vn(t,i,o+1),this.lines.length=0,this.explicitlyCleared=!0,this.atomic&&this.doc.cantEdit&&(this.doc.cantEdit=!1,t&&Ci(t.doc)),t&&bt(t,"markerCleared",t,this,i,o),r&&on(t),this.parent&&this.parent.clear()}},Os.prototype.find=function(e,t){var r=this;null==e&&"bookmark"==this.type&&(e=1);for(var n,i,o=0;o<this.lines.length;++o){var l=r.lines[o],s=_(l.markedSpans,r);if(null!=s.from&&(n=E(t?l:W(l),s.from),-1==e))return n;if(null!=s.to&&(i=E(t?l:W(l),s.to),1==e))return i}return n&&{from:n,to:i}},Os.prototype.changed=function(){var e=this,t=this.find(-1,!0),r=this,n=this.doc.cm;t&&n&&hn(n,function(){var i=t.line,o=W(t.line),l=jt(n,o);if(l&&(Qt(l),n.curOp.selectionChanged=n.curOp.forceUpdate=!0),n.curOp.updateMaxLine=!0,!ve(r.doc,i)&&null!=r.height){var s=r.height;r.height=null;var a=Ht(r)-s;a&&A(i,i.height+a)}bt(n,"markerChanged",n,e)})},Os.prototype.attachLine=function(e){if(!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;t.maybeHiddenMarkers&&-1!=h(t.maybeHiddenMarkers,this)||(t.maybeUnhiddenMarkers||(t.maybeUnhiddenMarkers=[])).push(this)}this.lines.push(e)},Os.prototype.detachLine=function(e){if(this.lines.splice(h(this.lines,e),1),!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;(t.maybeHiddenMarkers||(t.maybeHiddenMarkers=[])).push(this)}},Ae(Os);var As=function(e,t){var r=this;this.markers=e,this.primary=t;for(var n=0;n<e.length;++n)e[n].parent=r};As.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){this.explicitlyCleared=!0;for(var t=0;t<this.markers.length;++t)e.markers[t].clear();bt(this,"clear")}},As.prototype.find=function(e,t){return this.primary.find(e,t)},Ae(As);var Ws=0,Ds=function(e,t,r,n,i){if(!(this instanceof Ds))return new Ds(e,t,r,n,i);null==r&&(r=0),Gi.call(this,[new Bi([new fs("",null)])]),this.first=r,this.scrollTop=this.scrollLeft=0,this.cantEdit=!1,this.cleanGeneration=1,this.modeFrontier=this.highlightFrontier=r;var o=E(r,0);this.sel=Rn(o),this.history=new Jn(null),this.id=++Ws,this.modeOption=t,this.lineSep=n,this.direction="rtl"==i?"rtl":"ltr",this.extend=!1,"string"==typeof e&&(e=this.splitLines(e)),_n(this,{from:o,to:o,text:e}),bi(this,Rn(o),Gl)};Ds.prototype=b(Gi.prototype,{constructor:Ds,iter:function(e,t,r){r?this.iterN(e-this.first,t-e,r):this.iterN(this.first,this.first+this.size,e)},insert:function(e,t){for(var r=0,n=0;n<t.length;++n)r+=t[n].height;this.insertInner(e-this.first,t,r)},remove:function(e,t){this.removeInner(e-this.first,t)},getValue:function(e){var t=O(this,this.first,this.first+this.size);return!1===e?t:t.join(e||this.lineSeparator())},setValue:gn(function(e){var t=E(this.first,0),r=this.first+this.size-1;Oi(this,{from:t,to:E(r,M(this,r).text.length),text:this.splitLines(e),origin:"setValue",full:!0},!0),this.cm&&Xr(this.cm,0,0),bi(this,Rn(t),Gl)}),replaceRange:function(e,t,r,n){Ei(this,e,t=U(this,t),r=r?U(this,r):t,n)},getRange:function(e,t,r){var n=N(this,U(this,e),U(this,t));return!1===r?n:n.join(r||this.lineSeparator())},getLine:function(e){var t=this.getLineHandle(e);return t&&t.text},getLineHandle:function(e){if(H(this,e))return M(this,e)},getLineNumber:function(e){return W(e)},getLineHandleVisualStart:function(e){return"number"==typeof e&&(e=M(this,e)),fe(e)},lineCount:function(){return this.size},firstLine:function(){return this.first},lastLine:function(){return this.first+this.size-1},clipPos:function(e){return U(this,e)},getCursor:function(e){var t=this.sel.primary();return null==e||"head"==e?t.head:"anchor"==e?t.anchor:"end"==e||"to"==e||!1===e?t.to():t.from()},listSelections:function(){return this.sel.ranges},somethingSelected:function(){return this.sel.somethingSelected()},setCursor:gn(function(e,t,r){vi(this,U(this,"number"==typeof e?E(e,t||0):e),null,r)}),setSelection:gn(function(e,t,r){vi(this,U(this,e),U(this,t||e),r)}),extendSelection:gn(function(e,t,r){di(this,U(this,e),t&&U(this,t),r)}),extendSelections:gn(function(e,t){pi(this,K(this,e),t)}),extendSelectionsBy:gn(function(e,t){pi(this,K(this,v(this.sel.ranges,e)),t)}),setSelections:gn(function(e,t,r){var n=this;if(e.length){for(var i=[],o=0;o<e.length;o++)i[o]=new Ts(U(n,e[o].anchor),U(n,e[o].head));null==t&&(t=Math.min(e.length-1,this.sel.primIndex)),bi(this,zn(i,t),r)}}),addSelection:gn(function(e,t,r){var n=this.sel.ranges.slice(0);n.push(new Ts(U(this,e),U(this,t||e))),bi(this,zn(n,n.length-1),r)}),getSelection:function(e){for(var t,r=this,n=this.sel.ranges,i=0;i<n.length;i++){var o=N(r,n[i].from(),n[i].to());t=t?t.concat(o):o}return!1===e?t:t.join(e||this.lineSeparator())},getSelections:function(e){for(var t=this,r=[],n=this.sel.ranges,i=0;i<n.length;i++){var o=N(t,n[i].from(),n[i].to());!1!==e&&(o=o.join(e||t.lineSeparator())),r[i]=o}return r},replaceSelection:function(e,t,r){for(var n=[],i=0;i<this.sel.ranges.length;i++)n[i]=e;this.replaceSelections(n,t,r||"+input")},replaceSelections:gn(function(e,t,r){for(var n=this,i=[],o=this.sel,l=0;l<o.ranges.length;l++){var s=o.ranges[l];i[l]={from:s.from(),to:s.to(),text:n.splitLines(e[l]),origin:r}}for(var a=t&&"end"!=t&&Kn(this,i,t),u=i.length-1;u>=0;u--)Oi(n,i[u]);a?yi(this,a):this.cm&&jr(this.cm)}),undo:gn(function(){Wi(this,"undo")}),redo:gn(function(){Wi(this,"redo")}),undoSelection:gn(function(){Wi(this,"undo",!0)}),redoSelection:gn(function(){Wi(this,"redo",!0)}),setExtending:function(e){this.extend=e},getExtending:function(){return this.extend},historySize:function(){for(var e=this.history,t=0,r=0,n=0;n<e.done.length;n++)e.done[n].ranges||++t;for(var i=0;i<e.undone.length;i++)e.undone[i].ranges||++r;return{undo:t,redo:r}},clearHistory:function(){this.history=new Jn(this.history.maxGeneration)},markClean:function(){this.cleanGeneration=this.changeGeneration(!0)},changeGeneration:function(e){return e&&(this.history.lastOp=this.history.lastSelOp=this.history.lastOrigin=null),this.history.generation},isClean:function(e){return this.history.generation==(e||this.cleanGeneration)},getHistory:function(){return{done:fi(this.history.done),undone:fi(this.history.undone)}},setHistory:function(e){var t=this.history=new Jn(this.history.maxGeneration);t.done=fi(e.done.slice(0),null,!0),t.undone=fi(e.undone.slice(0),null,!0)},setGutterMarker:gn(function(e,t,r){return Ri(this,e,"gutter",function(e){var n=e.gutterMarkers||(e.gutterMarkers={});return n[t]=r,!r&&C(n)&&(e.gutterMarkers=null),!0})}),clearGutter:gn(function(e){var t=this;this.iter(function(r){r.gutterMarkers&&r.gutterMarkers[e]&&Ri(t,r,"gutter",function(){return r.gutterMarkers[e]=null,C(r.gutterMarkers)&&(r.gutterMarkers=null),!0})})}),lineInfo:function(e){var t;if("number"==typeof e){if(!H(this,e))return null;if(t=e,!(e=M(this,e)))return null}else if(null==(t=W(e)))return null;return{line:t,handle:e,text:e.text,gutterMarkers:e.gutterMarkers,textClass:e.textClass,bgClass:e.bgClass,wrapClass:e.wrapClass,widgets:e.widgets}},addLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass";if(t[i]){if(e(n).test(t[i]))return!1;t[i]+=" "+n}else t[i]=n;return!0})}),removeLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass",o=t[i];if(!o)return!1;if(null==n)t[i]=null;else{var l=o.match(e(n));if(!l)return!1;var s=l.index+l[0].length;t[i]=o.slice(0,l.index)+(l.index&&s!=o.length?" ":"")+o.slice(s)||null}return!0})}),addLineWidget:gn(function(e,t,r){return Vi(this,e,t,r)}),removeLineWidget:function(e){e.clear()},markText:function(e,t,r){return Ki(this,U(this,e),U(this,t),r,r&&r.type||"range")},setBookmark:function(e,t){var r={replacedWith:t&&(null==t.nodeType?t.widget:t),insertLeft:t&&t.insertLeft,clearWhenEmpty:!1,shared:t&&t.shared,handleMouseEvents:t&&t.handleMouseEvents};return e=U(this,e),Ki(this,e,e,r,"bookmark")},findMarksAt:function(e){var t=[],r=M(this,(e=U(this,e)).line).markedSpans;if(r)for(var n=0;n<r.length;++n){var i=r[n];(null==i.from||i.from<=e.ch)&&(null==i.to||i.to>=e.ch)&&t.push(i.marker.parent||i.marker)}return t},findMarks:function(e,t,r){e=U(this,e),t=U(this,t);var n=[],i=e.line;return this.iter(e.line,t.line+1,function(o){var l=o.markedSpans;if(l)for(var s=0;s<l.length;s++){var a=l[s];null!=a.to&&i==e.line&&e.ch>=a.to||null==a.from&&i!=e.line||null!=a.from&&i==t.line&&a.from>=t.ch||r&&!r(a.marker)||n.push(a.marker.parent||a.marker)}++i}),n},getAllMarks:function(){var e=[];return this.iter(function(t){var r=t.markedSpans;if(r)for(var n=0;n<r.length;++n)null!=r[n].from&&e.push(r[n].marker)}),e},posFromIndex:function(e){var t,r=this.first,n=this.lineSeparator().length;return this.iter(function(i){var o=i.text.length+n;if(o>e)return t=e,!0;e-=o,++r}),U(this,E(r,t))},indexFromPos:function(e){var t=(e=U(this,e)).ch;if(e.line<this.first||e.ch<0)return 0;var r=this.lineSeparator().length;return this.iter(this.first,e.line,function(e){t+=e.text.length+r}),t},copy:function(e){var t=new Ds(O(this,this.first,this.first+this.size),this.modeOption,this.first,this.lineSep,this.direction);return t.scrollTop=this.scrollTop,t.scrollLeft=this.scrollLeft,t.sel=this.sel,t.extend=!1,e&&(t.history.undoDepth=this.history.undoDepth,t.setHistory(this.getHistory())),t},linkedDoc:function(e){e||(e={});var t=this.first,r=this.first+this.size;null!=e.from&&e.from>t&&(t=e.from),null!=e.to&&e.to<r&&(r=e.to);var n=new Ds(O(this,t,r),e.mode||this.modeOption,t,this.lineSep,this.direction);return e.sharedHist&&(n.history=this.history),(this.linked||(this.linked=[])).push({doc:n,sharedHist:e.sharedHist}),n.linked=[{doc:this,isParent:!0,sharedHist:e.sharedHist}],Yi(n,Xi(this)),n},unlinkDoc:function(e){var t=this;if(e instanceof jo&&(e=e.doc),this.linked)for(var r=0;r<this.linked.length;++r)if(t.linked[r].doc==e){t.linked.splice(r,1),e.unlinkDoc(t),_i(Xi(t));break}if(e.history==this.history){var n=[e.id];$n(e,function(e){return n.push(e.id)},!0),e.history=new Jn(null),e.history.done=fi(this.history.done,n),e.history.undone=fi(this.history.undone,n)}},iterLinkedDocs:function(e){$n(this,e)},getMode:function(){return this.mode},getEditor:function(){return this.cm},splitLines:function(e){return this.lineSep?e.split(this.lineSep):es(e)},lineSeparator:function(){return this.lineSep||"\n"},setDirection:gn(function(e){"rtl"!=e&&(e="ltr"),e!=this.direction&&(this.direction=e,this.iter(function(e){return e.order=null}),this.cm&&Qn(this.cm))})}),Ds.prototype.eachLine=Ds.prototype.iter;for(var Hs=0,Fs=!1,Es={3:"Enter",8:"Backspace",9:"Tab",13:"Enter",16:"Shift",17:"Ctrl",18:"Alt",19:"Pause",20:"CapsLock",27:"Esc",32:"Space",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"Left",38:"Up",39:"Right",40:"Down",44:"PrintScrn",45:"Insert",46:"Delete",59:";",61:"=",91:"Mod",92:"Mod",93:"Mod",106:"*",107:"=",109:"-",110:".",111:"/",127:"Delete",173:"-",186:";",187:"=",188:",",189:"-",190:".",191:"/",192:"`",219:"[",220:"\\",221:"]",222:"'",63232:"Up",63233:"Down",63234:"Left",63235:"Right",63272:"Delete",63273:"Home",63275:"End",63276:"PageUp",63277:"PageDown",63302:"Insert"},Ps=0;Ps<10;Ps++)Es[Ps+48]=Es[Ps+96]=String(Ps);for(var Is=65;Is<=90;Is++)Es[Is]=String.fromCharCode(Is);for(var zs=1;zs<=12;zs++)Es[zs+111]=Es[zs+63235]="F"+zs;var Rs={};Rs.basic={Left:"goCharLeft",Right:"goCharRight",Up:"goLineUp",Down:"goLineDown",End:"goLineEnd",Home:"goLineStartSmart",PageUp:"goPageUp",PageDown:"goPageDown",Delete:"delCharAfter",Backspace:"delCharBefore","Shift-Backspace":"delCharBefore",Tab:"defaultTab","Shift-Tab":"indentAuto",Enter:"newlineAndIndent",Insert:"toggleOverwrite",Esc:"singleSelection"},Rs.pcDefault={"Ctrl-A":"selectAll","Ctrl-D":"deleteLine","Ctrl-Z":"undo","Shift-Ctrl-Z":"redo","Ctrl-Y":"redo","Ctrl-Home":"goDocStart","Ctrl-End":"goDocEnd","Ctrl-Up":"goLineUp","Ctrl-Down":"goLineDown","Ctrl-Left":"goGroupLeft","Ctrl-Right":"goGroupRight","Alt-Left":"goLineStart","Alt-Right":"goLineEnd","Ctrl-Backspace":"delGroupBefore","Ctrl-Delete":"delGroupAfter","Ctrl-S":"save","Ctrl-F":"find","Ctrl-G":"findNext","Shift-Ctrl-G":"findPrev","Shift-Ctrl-F":"replace","Shift-Ctrl-R":"replaceAll","Ctrl-[":"indentLess","Ctrl-]":"indentMore","Ctrl-U":"undoSelection","Shift-Ctrl-U":"redoSelection","Alt-U":"redoSelection",fallthrough:"basic"},Rs.emacsy={"Ctrl-F":"goCharRight","Ctrl-B":"goCharLeft","Ctrl-P":"goLineUp","Ctrl-N":"goLineDown","Alt-F":"goWordRight","Alt-B":"goWordLeft","Ctrl-A":"goLineStart","Ctrl-E":"goLineEnd","Ctrl-V":"goPageDown","Shift-Ctrl-V":"goPageUp","Ctrl-D":"delCharAfter","Ctrl-H":"delCharBefore","Alt-D":"delWordAfter","Alt-Backspace":"delWordBefore","Ctrl-K":"killLine","Ctrl-T":"transposeChars","Ctrl-O":"openLine"},Rs.macDefault={"Cmd-A":"selectAll","Cmd-D":"deleteLine","Cmd-Z":"undo","Shift-Cmd-Z":"redo","Cmd-Y":"redo","Cmd-Home":"goDocStart","Cmd-Up":"goDocStart","Cmd-End":"goDocEnd","Cmd-Down":"goDocEnd","Alt-Left":"goGroupLeft","Alt-Right":"goGroupRight","Cmd-Left":"goLineLeft","Cmd-Right":"goLineRight","Alt-Backspace":"delGroupBefore","Ctrl-Alt-Backspace":"delGroupAfter","Alt-Delete":"delGroupAfter","Cmd-S":"save","Cmd-F":"find","Cmd-G":"findNext","Shift-Cmd-G":"findPrev","Cmd-Alt-F":"replace","Shift-Cmd-Alt-F":"replaceAll","Cmd-[":"indentLess","Cmd-]":"indentMore","Cmd-Backspace":"delWrappedLineLeft","Cmd-Delete":"delWrappedLineRight","Cmd-U":"undoSelection","Shift-Cmd-U":"redoSelection","Ctrl-Up":"goDocStart","Ctrl-Down":"goDocEnd",fallthrough:["basic","emacsy"]},Rs.default=Ml?Rs.macDefault:Rs.pcDefault;var Bs={selectAll:Mi,singleSelection:function(e){return e.setSelection(e.getCursor("anchor"),e.getCursor("head"),Gl)},killLine:function(e){return co(e,function(t){if(t.empty()){var r=M(e.doc,t.head.line).text.length;return t.head.ch==r&&t.head.line<e.lastLine()?{from:t.head,to:E(t.head.line+1,0)}:{from:t.head,to:E(t.head.line,r)}}return{from:t.from(),to:t.to()}})},deleteLine:function(e){return co(e,function(t){return{from:E(t.from().line,0),to:U(e.doc,E(t.to().line+1,0))}})},delLineLeft:function(e){return co(e,function(e){return{from:E(e.from().line,0),to:e.from()}})},delWrappedLineLeft:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5;return{from:e.coordsChar({left:0,top:r},"div"),to:t.from()}})},delWrappedLineRight:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5,n=e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div");return{from:t.from(),to:n}})},undo:function(e){return e.undo()},redo:function(e){return e.redo()},undoSelection:function(e){return e.undoSelection()},redoSelection:function(e){return e.redoSelection()},goDocStart:function(e){return e.extendSelection(E(e.firstLine(),0))},goDocEnd:function(e){return e.extendSelection(E(e.lastLine()))},goLineStart:function(e){return e.extendSelectionsBy(function(t){return vo(e,t.head.line)},{origin:"+move",bias:1})},goLineStartSmart:function(e){return e.extendSelectionsBy(function(t){return yo(e,t.head)},{origin:"+move",bias:1})},goLineEnd:function(e){return e.extendSelectionsBy(function(t){return mo(e,t.head.line)},{origin:"+move",bias:-1})},goLineRight:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div")},Vl)},goLineLeft:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:0,top:r},"div")},Vl)},goLineLeftSmart:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5,n=e.coordsChar({left:0,top:r},"div");return n.ch<e.getLine(n.line).search(/\S/)?yo(e,t.head):n},Vl)},goLineUp:function(e){return e.moveV(-1,"line")},goLineDown:function(e){return e.moveV(1,"line")},goPageUp:function(e){return e.moveV(-1,"page")},goPageDown:function(e){return e.moveV(1,"page")},goCharLeft:function(e){return e.moveH(-1,"char")},goCharRight:function(e){return e.moveH(1,"char")},goColumnLeft:function(e){return e.moveH(-1,"column")},goColumnRight:function(e){return e.moveH(1,"column")},goWordLeft:function(e){return e.moveH(-1,"word")},goGroupRight:function(e){return e.moveH(1,"group")},goGroupLeft:function(e){return e.moveH(-1,"group")},goWordRight:function(e){return e.moveH(1,"word")},delCharBefore:function(e){return e.deleteH(-1,"char")},delCharAfter:function(e){return e.deleteH(1,"char")},delWordBefore:function(e){return e.deleteH(-1,"word")},delWordAfter:function(e){return e.deleteH(1,"word")},delGroupBefore:function(e){return e.deleteH(-1,"group")},delGroupAfter:function(e){return e.deleteH(1,"group")},indentAuto:function(e){return e.indentSelection("smart")},indentMore:function(e){return e.indentSelection("add")},indentLess:function(e){return e.indentSelection("subtract")},insertTab:function(e){return e.replaceSelection("\t")},insertSoftTab:function(e){for(var t=[],r=e.listSelections(),n=e.options.tabSize,i=0;i<r.length;i++){var o=r[i].from(),l=f(e.getLine(o.line),o.ch,n);t.push(p(n-l%n))}e.replaceSelections(t)},defaultTab:function(e){e.somethingSelected()?e.indentSelection("add"):e.execCommand("insertTab")},transposeChars:function(e){return hn(e,function(){for(var t=e.listSelections(),r=[],n=0;n<t.length;n++)if(t[n].empty()){var i=t[n].head,o=M(e.doc,i.line).text;if(o)if(i.ch==o.length&&(i=new E(i.line,i.ch-1)),i.ch>0)i=new E(i.line,i.ch+1),e.replaceRange(o.charAt(i.ch-1)+o.charAt(i.ch-2),E(i.line,i.ch-2),i,"+transpose");else if(i.line>e.doc.first){var l=M(e.doc,i.line-1).text;l&&(i=new E(i.line,1),e.replaceRange(o.charAt(0)+e.doc.lineSeparator()+l.charAt(l.length-1),E(i.line-1,l.length-1),i,"+transpose"))}r.push(new Ts(i,i))}e.setSelections(r)})},newlineAndIndent:function(e){return hn(e,function(){for(var t=e.listSelections(),r=t.length-1;r>=0;r--)e.replaceRange(e.doc.lineSeparator(),t[r].anchor,t[r].head,"+input");t=e.listSelections();for(var n=0;n<t.length;n++)e.indentLine(t[n].from().line,null,!0);jr(e)})},openLine:function(e){return e.replaceSelection("\n","start")},toggleOverwrite:function(e){return e.toggleOverwrite()}},Gs=new Pl,Us=null,Vs=function(e,t,r){this.time=e,this.pos=t,this.button=r};Vs.prototype.compare=function(e,t,r){return this.time+400>e&&0==P(t,this.pos)&&r==this.button};var Ks,js,Xs={toString:function(){return"CodeMirror.Init"}},Ys={},_s={};jo.defaults=Ys,jo.optionHandlers=_s;var $s=[];jo.defineInitHook=function(e){return $s.push(e)};var qs=null,Zs=function(e){this.cm=e,this.lastAnchorNode=this.lastAnchorOffset=this.lastFocusNode=this.lastFocusOffset=null,this.polling=new Pl,this.composing=null,this.gracePeriod=!1,this.readDOMTimeout=null};Zs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()}),"cut"==e.type&&i.replaceSelection("",null,"cut");else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type&&i.operation(function(){i.setSelections(t.ranges,0,Gl),i.replaceSelection("",null,"cut")})}if(e.clipboardData){e.clipboardData.clearData();var r=qs.text.join("\n");if(e.clipboardData.setData("Text",r),e.clipboardData.getData("Text")==r)return void e.preventDefault()}var l=el(),s=l.firstChild;i.display.lineSpace.insertBefore(l,i.display.lineSpace.firstChild),s.value=qs.text.join("\n");var a=document.activeElement;El(s),setTimeout(function(){i.display.lineSpace.removeChild(l),a.focus(),a==o&&n.showPrimarySelection()},50)}}var r=this,n=this,i=n.cm,o=n.div=e.lineDiv;Jo(o,i.options.spellcheck),Ql(o,"paste",function(e){Me(i,e)||qo(e,i)||vl<=11&&setTimeout(dn(i,function(){return r.updateFromDOM()}),20)}),Ql(o,"compositionstart",function(e){r.composing={data:e.data,done:!1}}),Ql(o,"compositionupdate",function(e){r.composing||(r.composing={data:e.data,done:!1})}),Ql(o,"compositionend",function(e){r.composing&&(e.data!=r.composing.data&&r.readFromDOMSoon(),r.composing.done=!0)}),Ql(o,"touchstart",function(){return n.forceCompositionEnd()}),Ql(o,"input",function(){r.composing||r.readFromDOMSoon()}),Ql(o,"copy",t),Ql(o,"cut",t)},Zs.prototype.prepareSelection=function(){var e=Tr(this.cm,!1);return e.focus=this.cm.state.focused,e},Zs.prototype.showSelection=function(e,t){e&&this.cm.display.view.length&&((e.focus||t)&&this.showPrimarySelection(),this.showMultipleSelections(e))},Zs.prototype.showPrimarySelection=function(){var e=window.getSelection(),t=this.cm,r=t.doc.sel.primary(),n=r.from(),i=r.to();if(t.display.viewTo==t.display.viewFrom||n.line>=t.display.viewTo||i.line<t.display.viewFrom)e.removeAllRanges();else{var o=sl(t,e.anchorNode,e.anchorOffset),l=sl(t,e.focusNode,e.focusOffset);if(!o||o.bad||!l||l.bad||0!=P(B(o,l),n)||0!=P(R(o,l),i)){var s=t.display.view,a=n.line>=t.display.viewFrom&&nl(t,n)||{node:s[0].measure.map[2],offset:0},u=i.line<t.display.viewTo&&nl(t,i);if(!u){var c=s[s.length-1].measure,f=c.maps?c.maps[c.maps.length-1]:c.map;u={node:f[f.length-1],offset:f[f.length-2]-f[f.length-3]}}if(a&&u){var h,d=e.rangeCount&&e.getRangeAt(0);try{h=Wl(a.node,a.offset,u.offset,u.node)}catch(e){}h&&(!fl&&t.state.focused?(e.collapse(a.node,a.offset),h.collapsed||(e.removeAllRanges(),e.addRange(h))):(e.removeAllRanges(),e.addRange(h)),d&&null==e.anchorNode?e.addRange(d):fl&&this.startGracePeriod()),this.rememberSelection()}else e.removeAllRanges()}}},Zs.prototype.startGracePeriod=function(){var e=this;clearTimeout(this.gracePeriod),this.gracePeriod=setTimeout(function(){e.gracePeriod=!1,e.selectionChanged()&&e.cm.operation(function(){return e.cm.curOp.selectionChanged=!0})},20)},Zs.prototype.showMultipleSelections=function(e){r(this.cm.display.cursorDiv,e.cursors),r(this.cm.display.selectionDiv,e.selection)},Zs.prototype.rememberSelection=function(){var e=window.getSelection();this.lastAnchorNode=e.anchorNode,this.lastAnchorOffset=e.anchorOffset,this.lastFocusNode=e.focusNode,this.lastFocusOffset=e.focusOffset},Zs.prototype.selectionInEditor=function(){var e=window.getSelection();if(!e.rangeCount)return!1;var t=e.getRangeAt(0).commonAncestorContainer;return o(this.div,t)},Zs.prototype.focus=function(){"nocursor"!=this.cm.options.readOnly&&(this.selectionInEditor()||this.showSelection(this.prepareSelection(),!0),this.div.focus())},Zs.prototype.blur=function(){this.div.blur()},Zs.prototype.getField=function(){return this.div},Zs.prototype.supportsTouch=function(){return!0},Zs.prototype.receivedFocus=function(){function e(){t.cm.state.focused&&(t.pollSelection(),t.polling.set(t.cm.options.pollInterval,e))}var t=this;this.selectionInEditor()?this.pollSelection():hn(this.cm,function(){return t.cm.curOp.selectionChanged=!0}),this.polling.set(this.cm.options.pollInterval,e)},Zs.prototype.selectionChanged=function(){var e=window.getSelection();return e.anchorNode!=this.lastAnchorNode||e.anchorOffset!=this.lastAnchorOffset||e.focusNode!=this.lastFocusNode||e.focusOffset!=this.lastFocusOffset},Zs.prototype.pollSelection=function(){if(null==this.readDOMTimeout&&!this.gracePeriod&&this.selectionChanged()){var e=window.getSelection(),t=this.cm;if(kl&&bl&&this.cm.options.gutters.length&&il(e.anchorNode))return this.cm.triggerOnKeyDown({type:"keydown",keyCode:8,preventDefault:Math.abs}),this.blur(),void this.focus();if(!this.composing){this.rememberSelection();var r=sl(t,e.anchorNode,e.anchorOffset),n=sl(t,e.focusNode,e.focusOffset);r&&n&&hn(t,function(){bi(t.doc,Rn(r,n),Gl),(r.bad||n.bad)&&(t.curOp.selectionChanged=!0)})}}},Zs.prototype.pollContent=function(){null!=this.readDOMTimeout&&(clearTimeout(this.readDOMTimeout),this.readDOMTimeout=null);var e=this.cm,t=e.display,r=e.doc.sel.primary(),n=r.from(),i=r.to();if(0==n.ch&&n.line>e.firstLine()&&(n=E(n.line-1,M(e.doc,n.line-1).length)),i.ch==M(e.doc,i.line).text.length&&i.line<e.lastLine()&&(i=E(i.line+1,0)),n.line<t.viewFrom||i.line>t.viewTo-1)return!1;var o,l,s;n.line==t.viewFrom||0==(o=Lr(e,n.line))?(l=W(t.view[0].line),s=t.view[0].node):(l=W(t.view[o].line),s=t.view[o-1].node.nextSibling);var a,u,c=Lr(e,i.line);if(c==t.view.length-1?(a=t.viewTo-1,u=t.lineDiv.lastChild):(a=W(t.view[c+1].line)-1,u=t.view[c+1].node.previousSibling),!s)return!1;for(var f=e.doc.splitLines(ll(e,s,u,l,a)),h=N(e.doc,E(l,0),E(a,M(e.doc,a).text.length));f.length>1&&h.length>1;)if(g(f)==g(h))f.pop(),h.pop(),a--;else{if(f[0]!=h[0])break;f.shift(),h.shift(),l++}for(var d=0,p=0,v=f[0],m=h[0],y=Math.min(v.length,m.length);d<y&&v.charCodeAt(d)==m.charCodeAt(d);)++d;for(var b=g(f),w=g(h),x=Math.min(b.length-(1==f.length?d:0),w.length-(1==h.length?d:0));p<x&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)++p;if(1==f.length&&1==h.length&&l==n.line)for(;d&&d>n.ch&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)d--,p++;f[f.length-1]=b.slice(0,b.length-p).replace(/^\u200b+/,""),f[0]=f[0].slice(d).replace(/\u200b+$/,"");var C=E(l,d),S=E(a,h.length?g(h).length-p:0);return f.length>1||f[0]||P(C,S)?(Ei(e.doc,f,C,S,"+input"),!0):void 0},Zs.prototype.ensurePolled=function(){this.forceCompositionEnd()},Zs.prototype.reset=function(){this.forceCompositionEnd()},Zs.prototype.forceCompositionEnd=function(){this.composing&&(clearTimeout(this.readDOMTimeout),this.composing=null,this.updateFromDOM(),this.div.blur(),this.div.focus())},Zs.prototype.readFromDOMSoon=function(){var e=this;null==this.readDOMTimeout&&(this.readDOMTimeout=setTimeout(function(){if(e.readDOMTimeout=null,e.composing){if(!e.composing.done)return;e.composing=null}e.updateFromDOM()},80))},Zs.prototype.updateFromDOM=function(){var e=this;!this.cm.isReadOnly()&&this.pollContent()||hn(this.cm,function(){return vn(e.cm)})},Zs.prototype.setUneditable=function(e){e.contentEditable="false"},Zs.prototype.onKeyPress=function(e){0!=e.charCode&&(e.preventDefault(),this.cm.isReadOnly()||dn(this.cm,$o)(this.cm,String.fromCharCode(null==e.charCode?e.keyCode:e.charCode),0))},Zs.prototype.readOnlyChanged=function(e){this.div.contentEditable=String("nocursor"!=e)},Zs.prototype.onContextMenu=function(){},Zs.prototype.resetPosition=function(){},Zs.prototype.needsContentAttribute=!0;var Qs=function(e){this.cm=e,this.prevInput="",this.pollingFast=!1,this.polling=new Pl,this.hasSelection=!1,this.composing=null};Qs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()});else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type?i.setSelections(t.ranges,null,Gl):(n.prevInput="",l.value=t.text.join("\n"),El(l))}"cut"==e.type&&(i.state.cutIncoming=!0)}}var r=this,n=this,i=this.cm,o=this.wrapper=el(),l=this.textarea=o.firstChild;e.wrapper.insertBefore(o,e.wrapper.firstChild),Ll&&(l.style.width="0px"),Ql(l,"input",function(){gl&&vl>=9&&r.hasSelection&&(r.hasSelection=null),n.poll()}),Ql(l,"paste",function(e){Me(i,e)||qo(e,i)||(i.state.pasteIncoming=!0,n.fastPoll())}),Ql(l,"cut",t),Ql(l,"copy",t),Ql(e.scroller,"paste",function(t){Ft(e,t)||Me(i,t)||(i.state.pasteIncoming=!0,n.focus())}),Ql(e.lineSpace,"selectstart",function(t){Ft(e,t)||We(t)}),Ql(l,"compositionstart",function(){var e=i.getCursor("from");n.composing&&n.composing.range.clear(),n.composing={start:e,range:i.markText(e,i.getCursor("to"),{className:"CodeMirror-composing"})}}),Ql(l,"compositionend",function(){n.composing&&(n.poll(),n.composing.range.clear(),n.composing=null)})},Qs.prototype.prepareSelection=function(){var e=this.cm,t=e.display,r=e.doc,n=Tr(e);if(e.options.moveInputWithCursor){var i=sr(e,r.sel.primary().head,"div"),o=t.wrapper.getBoundingClientRect(),l=t.lineDiv.getBoundingClientRect();n.teTop=Math.max(0,Math.min(t.wrapper.clientHeight-10,i.top+l.top-o.top)),n.teLeft=Math.max(0,Math.min(t.wrapper.clientWidth-10,i.left+l.left-o.left))}return n},Qs.prototype.showSelection=function(e){var t=this.cm.display;r(t.cursorDiv,e.cursors),r(t.selectionDiv,e.selection),null!=e.teTop&&(this.wrapper.style.top=e.teTop+"px",this.wrapper.style.left=e.teLeft+"px")},Qs.prototype.reset=function(e){if(!this.contextMenuPending&&!this.composing){var t=this.cm;if(t.somethingSelected()){this.prevInput="";var r=t.getSelection();this.textarea.value=r,t.state.focused&&El(this.textarea),gl&&vl>=9&&(this.hasSelection=r)}else e||(this.prevInput=this.textarea.value="",gl&&vl>=9&&(this.hasSelection=null))}},Qs.prototype.getField=function(){return this.textarea},Qs.prototype.supportsTouch=function(){return!1},Qs.prototype.focus=function(){if("nocursor"!=this.cm.options.readOnly&&(!Tl||l()!=this.textarea))try{this.textarea.focus()}catch(e){}},Qs.prototype.blur=function(){this.textarea.blur()},Qs.prototype.resetPosition=function(){this.wrapper.style.top=this.wrapper.style.left=0},Qs.prototype.receivedFocus=function(){this.slowPoll()},Qs.prototype.slowPoll=function(){var e=this;this.pollingFast||this.polling.set(this.cm.options.pollInterval,function(){e.poll(),e.cm.state.focused&&e.slowPoll()})},Qs.prototype.fastPoll=function(){function e(){r.poll()||t?(r.pollingFast=!1,r.slowPoll()):(t=!0,r.polling.set(60,e))}var t=!1,r=this;r.pollingFast=!0,r.polling.set(20,e)},Qs.prototype.poll=function(){var e=this,t=this.cm,r=this.textarea,n=this.prevInput;if(this.contextMenuPending||!t.state.focused||ts(r)&&!n&&!this.composing||t.isReadOnly()||t.options.disableInput||t.state.keySeq)return!1;var i=r.value;if(i==n&&!t.somethingSelected())return!1;if(gl&&vl>=9&&this.hasSelection===i||Ml&&/[\uf700-\uf7ff]/.test(i))return t.display.input.reset(),!1;if(t.doc.sel==t.display.selForContextMenu){var o=i.charCodeAt(0);if(8203!=o||n||(n="​"),8666==o)return this.reset(),this.cm.execCommand("undo")}for(var l=0,s=Math.min(n.length,i.length);l<s&&n.charCodeAt(l)==i.charCodeAt(l);)++l;return hn(t,function(){$o(t,i.slice(l),n.length-l,null,e.composing?"*compose":null),i.length>1e3||i.indexOf("\n")>-1?r.value=e.prevInput="":e.prevInput=i,e.composing&&(e.composing.range.clear(),e.composing.range=t.markText(e.composing.start,t.getCursor("to"),{className:"CodeMirror-composing"}))}),!0},Qs.prototype.ensurePolled=function(){this.pollingFast&&this.poll()&&(this.pollingFast=!1)},Qs.prototype.onKeyPress=function(){gl&&vl>=9&&(this.hasSelection=null),this.fastPoll()},Qs.prototype.onContextMenu=function(e){function t(){if(null!=l.selectionStart){var e=i.somethingSelected(),t="​"+(e?l.value:"");l.value="⇚",l.value=t,n.prevInput=e?"":"​",l.selectionStart=1,l.selectionEnd=t.length,o.selForContextMenu=i.doc.sel}}function r(){if(n.contextMenuPending=!1,n.wrapper.style.cssText=c,l.style.cssText=u,gl&&vl<9&&o.scrollbars.setScrollTop(o.scroller.scrollTop=a),null!=l.selectionStart){(!gl||gl&&vl<9)&&t();var e=0,r=function(){o.selForContextMenu==i.doc.sel&&0==l.selectionStart&&l.selectionEnd>0&&"​"==n.prevInput?dn(i,Mi)(i):e++<10?o.detectingSelectAll=setTimeout(r,500):(o.selForContextMenu=null,o.input.reset())};o.detectingSelectAll=setTimeout(r,200)}}var n=this,i=n.cm,o=i.display,l=n.textarea,s=Sr(i,e),a=o.scroller.scrollTop;if(s&&!wl){i.options.resetSelectionOnContextMenu&&-1==i.doc.sel.contains(s)&&dn(i,bi)(i.doc,Rn(s),Gl);var u=l.style.cssText,c=n.wrapper.style.cssText;n.wrapper.style.cssText="position: absolute";var f=n.wrapper.getBoundingClientRect();l.style.cssText="position: absolute; width: 30px; height: 30px;\n      top: "+(e.clientY-f.top-5)+"px; left: "+(e.clientX-f.left-5)+"px;\n      z-index: 1000; background: "+(gl?"rgba(255, 255, 255, .05)":"transparent")+";\n      outline: none; border-width: 0; outline: none; overflow: hidden; opacity: .05; filter: alpha(opacity=5);";var h;if(ml&&(h=window.scrollY),o.input.focus(),ml&&window.scrollTo(null,h),o.input.reset(),i.somethingSelected()||(l.value=n.prevInput=" "),n.contextMenuPending=!0,o.selForContextMenu=i.doc.sel,clearTimeout(o.detectingSelectAll),gl&&vl>=9&&t(),Hl){Fe(e);var d=function(){ke(window,"mouseup",d),setTimeout(r,20)};Ql(window,"mouseup",d)}else setTimeout(r,50)}},Qs.prototype.readOnlyChanged=function(e){e||this.reset(),this.textarea.disabled="nocursor"==e},Qs.prototype.setUneditable=function(){},Qs.prototype.needsContentAttribute=!1,function(e){function t(t,n,i,o){e.defaults[t]=n,i&&(r[t]=o?function(e,t,r){r!=Xs&&i(e,t,r)}:i)}var r=e.optionHandlers;e.defineOption=t,e.Init=Xs,t("value","",function(e,t){return e.setValue(t)},!0),t("mode",null,function(e,t){e.doc.modeOption=t,jn(e)},!0),t("indentUnit",2,jn,!0),t("indentWithTabs",!1),t("smartIndent",!0),t("tabSize",4,function(e){Xn(e),er(e),vn(e)},!0),t("lineSeparator",null,function(e,t){if(e.doc.lineSep=t,t){var r=[],n=e.doc.first;e.doc.iter(function(e){for(var i=0;;){var o=e.text.indexOf(t,i);if(-1==o)break;i=o+t.length,r.push(E(n,o))}n++});for(var i=r.length-1;i>=0;i--)Ei(e.doc,t,r[i],E(r[i].line,r[i].ch+t.length))}}),t("specialChars",/[\u0000-\u001f\u007f-\u009f\u00ad\u061c\u200b-\u200f\u2028\u2029\ufeff]/g,function(e,t,r){e.state.specialChars=new RegExp(t.source+(t.test("\t")?"":"|\t"),"g"),r!=Xs&&e.refresh()}),t("specialCharPlaceholder",at,function(e){return e.refresh()},!0),t("electricChars",!0),t("inputStyle",Tl?"contenteditable":"textarea",function(){throw new Error("inputStyle can not (yet) be changed in a running editor")},!0),t("spellcheck",!1,function(e,t){return e.getInputField().spellcheck=t},!0),t("rtlMoveVisually",!Ol),t("wholeLineUpdateBefore",!0),t("theme","default",function(e){Go(e),Uo(e)},!0),t("keyMap","default",function(e,t,r){var n=uo(t),i=r!=Xs&&uo(r);i&&i.detach&&i.detach(e,n),n.attach&&n.attach(e,i||null)}),t("extraKeys",null),t("configureMouse",null),t("lineWrapping",!1,Ko,!0),t("gutters",[],function(e){Fn(e.options),Uo(e)},!0),t("fixedGutter",!0,function(e,t){e.display.gutters.style.left=t?wr(e.display)+"px":"0",e.refresh()},!0),t("coverGutterNextToScrollbar",!1,function(e){return en(e)},!0),t("scrollbarStyle","native",function(e){rn(e),en(e),e.display.scrollbars.setScrollTop(e.doc.scrollTop),e.display.scrollbars.setScrollLeft(e.doc.scrollLeft)},!0),t("lineNumbers",!1,function(e){Fn(e.options),Uo(e)},!0),t("firstLineNumber",1,Uo,!0),t("lineNumberFormatter",function(e){return e},Uo,!0),t("showCursorWhenSelecting",!1,kr,!0),t("resetSelectionOnContextMenu",!0),t("lineWiseCopyCut",!0),t("pasteLinesPerSelection",!0),t("readOnly",!1,function(e,t){"nocursor"==t&&(Fr(e),e.display.input.blur()),e.display.input.readOnlyChanged(t)}),t("disableInput",!1,function(e,t){t||e.display.input.reset()},!0),t("dragDrop",!0,Vo),t("allowDropFileTypes",null),t("cursorBlinkRate",530),t("cursorScrollMargin",0),t("cursorHeight",1,kr,!0),t("singleCursorHeightPerLine",!0,kr,!0),t("workTime",100),t("workDelay",100),t("flattenSpans",!0,Xn,!0),t("addModeClass",!1,Xn,!0),t("pollInterval",100),t("undoDepth",200,function(e,t){return e.doc.history.undoDepth=t}),t("historyEventDelay",1250),t("viewportMargin",10,function(e){return e.refresh()},!0),t("maxHighlightLength",1e4,Xn,!0),t("moveInputWithCursor",!0,function(e,t){t||e.display.input.resetPosition()}),t("tabindex",null,function(e,t){return e.display.input.getField().tabIndex=t||""}),t("autofocus",null),t("direction","ltr",function(e,t){return e.doc.setDirection(t)},!0)}(jo),function(e){var t=e.optionHandlers,r=e.helpers={};e.prototype={constructor:e,focus:function(){window.focus(),this.display.input.focus()},setOption:function(e,r){var n=this.options,i=n[e];n[e]==r&&"mode"!=e||(n[e]=r,t.hasOwnProperty(e)&&dn(this,t[e])(this,r,i),Te(this,"optionChange",this,e))},getOption:function(e){return this.options[e]},getDoc:function(){return this.doc},addKeyMap:function(e,t){this.state.keyMaps[t?"push":"unshift"](uo(e))},removeKeyMap:function(e){for(var t=this.state.keyMaps,r=0;r<t.length;++r)if(t[r]==e||t[r].name==e)return t.splice(r,1),!0},addOverlay:pn(function(t,r){var n=t.token?t:e.getMode(this.options,t);if(n.startState)throw new Error("Overlays may not be stateful.");m(this.state.overlays,{mode:n,modeSpec:t,opaque:r&&r.opaque,priority:r&&r.priority||0},function(e){return e.priority}),this.state.modeGen++,vn(this)}),removeOverlay:pn(function(e){for(var t=this,r=this.state.overlays,n=0;n<r.length;++n){var i=r[n].modeSpec;if(i==e||"string"==typeof e&&i.name==e)return r.splice(n,1),t.state.modeGen++,void vn(t)}}),indentLine:pn(function(e,t,r){"string"!=typeof t&&"number"!=typeof t&&(t=null==t?this.options.smartIndent?"smart":"prev":t?"add":"subtract"),H(this.doc,e)&&Yo(this,e,t,r)}),indentSelection:pn(function(e){for(var t=this,r=this.doc.sel.ranges,n=-1,i=0;i<r.length;i++){var o=r[i];if(o.empty())o.head.line>n&&(Yo(t,o.head.line,e,!0),n=o.head.line,i==t.doc.sel.primIndex&&jr(t));else{var l=o.from(),s=o.to(),a=Math.max(n,l.line);n=Math.min(t.lastLine(),s.line-(s.ch?0:1))+1;for(var u=a;u<n;++u)Yo(t,u,e);var c=t.doc.sel.ranges;0==l.ch&&r.length==c.length&&c[i].from().ch>0&&gi(t.doc,i,new Ts(l,c[i].to()),Gl)}}}),getTokenAt:function(e,t){return Je(this,e,t)},getLineTokens:function(e,t){return Je(this,E(e),t,!0)},getTokenTypeAt:function(e){e=U(this.doc,e);var t,r=_e(this,M(this.doc,e.line)),n=0,i=(r.length-1)/2,o=e.ch;if(0==o)t=r[2];else for(;;){var l=n+i>>1;if((l?r[2*l-1]:0)>=o)i=l;else{if(!(r[2*l+1]<o)){t=r[2*l+2];break}n=l+1}}var s=t?t.indexOf("overlay "):-1;return s<0?t:0==s?null:t.slice(0,s-1)},getModeAt:function(t){var r=this.doc.mode;return r.innerMode?e.innerMode(r,this.getTokenAt(t).state).mode:r},getHelper:function(e,t){return this.getHelpers(e,t)[0]},getHelpers:function(e,t){var n=this,i=[];if(!r.hasOwnProperty(t))return i;var o=r[t],l=this.getModeAt(e);if("string"==typeof l[t])o[l[t]]&&i.push(o[l[t]]);else if(l[t])for(var s=0;s<l[t].length;s++){var a=o[l[t][s]];a&&i.push(a)}else l.helperType&&o[l.helperType]?i.push(o[l.helperType]):o[l.name]&&i.push(o[l.name]);for(var u=0;u<o._global.length;u++){var c=o._global[u];c.pred(l,n)&&-1==h(i,c.val)&&i.push(c.val)}return i},getStateAfter:function(e,t){var r=this.doc;return e=G(r,null==e?r.first+r.size-1:e),$e(this,e+1,t).state},cursorCoords:function(e,t){var r,n=this.doc.sel.primary();return r=null==e?n.head:"object"==typeof e?U(this.doc,e):e?n.from():n.to(),sr(this,r,t||"page")},charCoords:function(e,t){return lr(this,U(this.doc,e),t||"page")},coordsChar:function(e,t){return e=or(this,e,t||"page"),cr(this,e.left,e.top)},lineAtHeight:function(e,t){return e=or(this,{top:e,left:0},t||"page").top,D(this.doc,e+this.display.viewOffset)},heightAtLine:function(e,t,r){var n,i=!1;if("number"==typeof e){var o=this.doc.first+this.doc.size-1;e<this.doc.first?e=this.doc.first:e>o&&(e=o,i=!0),n=M(this.doc,e)}else n=e;return ir(this,n,{top:0,left:0},t||"page",r||i).top+(i?this.doc.height-ye(n):0)},defaultTextHeight:function(){return mr(this.display)},defaultCharWidth:function(){return yr(this.display)},getViewport:function(){return{from:this.display.viewFrom,to:this.display.viewTo}},addWidget:function(e,t,r,n,i){var o=this.display,l=(e=sr(this,U(this.doc,e))).bottom,s=e.left;if(t.style.position="absolute",t.setAttribute("cm-ignore-events","true"),this.display.input.setUneditable(t),o.sizer.appendChild(t),"over"==n)l=e.top;else if("above"==n||"near"==n){var a=Math.max(o.wrapper.clientHeight,this.doc.height),u=Math.max(o.sizer.clientWidth,o.lineSpace.clientWidth);("above"==n||e.bottom+t.offsetHeight>a)&&e.top>t.offsetHeight?l=e.top-t.offsetHeight:e.bottom+t.offsetHeight<=a&&(l=e.bottom),s+t.offsetWidth>u&&(s=u-t.offsetWidth)}t.style.top=l+"px",t.style.left=t.style.right="","right"==i?(s=o.sizer.clientWidth-t.offsetWidth,t.style.right="0px"):("left"==i?s=0:"middle"==i&&(s=(o.sizer.clientWidth-t.offsetWidth)/2),t.style.left=s+"px"),r&&Ur(this,{left:s,top:l,right:s+t.offsetWidth,bottom:l+t.offsetHeight})},triggerOnKeyDown:pn(Lo),triggerOnKeyPress:pn(Mo),triggerOnKeyUp:To,triggerOnMouseDown:pn(Oo),execCommand:function(e){if(Bs.hasOwnProperty(e))return Bs[e].call(null,this)},triggerElectric:pn(function(e){Zo(this,e)}),findPosH:function(e,t,r,n){var i=this,o=1;t<0&&(o=-1,t=-t);for(var l=U(this.doc,e),s=0;s<t&&!(l=tl(i.doc,l,o,r,n)).hitSide;++s);return l},moveH:pn(function(e,t){var r=this;this.extendSelectionsBy(function(n){return r.display.shift||r.doc.extend||n.empty()?tl(r.doc,n.head,e,t,r.options.rtlMoveVisually):e<0?n.from():n.to()},Vl)}),deleteH:pn(function(e,t){var r=this.doc.sel,n=this.doc;r.somethingSelected()?n.replaceSelection("",null,"+delete"):co(this,function(r){var i=tl(n,r.head,e,t,!1);return e<0?{from:i,to:r.head}:{from:r.head,to:i}})}),findPosV:function(e,t,r,n){var i=this,o=1,l=n;t<0&&(o=-1,t=-t);for(var s=U(this.doc,e),a=0;a<t;++a){var u=sr(i,s,"div");if(null==l?l=u.left:u.left=l,(s=rl(i,u,o,r)).hitSide)break}return s},moveV:pn(function(e,t){var r=this,n=this.doc,i=[],o=!this.display.shift&&!n.extend&&n.sel.somethingSelected();if(n.extendSelectionsBy(function(l){if(o)return e<0?l.from():l.to();var s=sr(r,l.head,"div");null!=l.goalColumn&&(s.left=l.goalColumn),i.push(s.left);var a=rl(r,s,e,t);return"page"==t&&l==n.sel.primary()&&Kr(r,lr(r,a,"div").top-s.top),a},Vl),i.length)for(var l=0;l<n.sel.ranges.length;l++)n.sel.ranges[l].goalColumn=i[l]}),findWordAt:function(e){var t=M(this.doc,e.line).text,r=e.ch,n=e.ch;if(t){var i=this.getHelper(e,"wordChars");"before"!=e.sticky&&n!=t.length||!r?++n:--r;for(var o=t.charAt(r),l=x(o,i)?function(e){return x(e,i)}:/\s/.test(o)?function(e){return/\s/.test(e)}:function(e){return!/\s/.test(e)&&!x(e)};r>0&&l(t.charAt(r-1));)--r;for(;n<t.length&&l(t.charAt(n));)++n}return new Ts(E(e.line,r),E(e.line,n))},toggleOverwrite:function(e){null!=e&&e==this.state.overwrite||((this.state.overwrite=!this.state.overwrite)?s(this.display.cursorDiv,"CodeMirror-overwrite"):Fl(this.display.cursorDiv,"CodeMirror-overwrite"),Te(this,"overwriteToggle",this,this.state.overwrite))},hasFocus:function(){return this.display.input.getField()==l()},isReadOnly:function(){return!(!this.options.readOnly&&!this.doc.cantEdit)},scrollTo:pn(function(e,t){Xr(this,e,t)}),getScrollInfo:function(){var e=this.display.scroller;return{left:e.scrollLeft,top:e.scrollTop,height:e.scrollHeight-zt(this)-this.display.barHeight,width:e.scrollWidth-zt(this)-this.display.barWidth,clientHeight:Bt(this),clientWidth:Rt(this)}},scrollIntoView:pn(function(e,t){null==e?(e={from:this.doc.sel.primary().head,to:null},null==t&&(t=this.options.cursorScrollMargin)):"number"==typeof e?e={from:E(e,0),to:null}:null==e.from&&(e={from:e,to:null}),e.to||(e.to=e.from),e.margin=t||0,null!=e.from.line?Yr(this,e):$r(this,e.from,e.to,e.margin)}),setSize:pn(function(e,t){var r=this,n=function(e){return"number"==typeof e||/^\d+$/.test(String(e))?e+"px":e};null!=e&&(this.display.wrapper.style.width=n(e)),null!=t&&(this.display.wrapper.style.height=n(t)),this.options.lineWrapping&&Jt(this);var i=this.display.viewFrom;this.doc.iter(i,this.display.viewTo,function(e){if(e.widgets)for(var t=0;t<e.widgets.length;t++)if(e.widgets[t].noHScroll){mn(r,i,"widget");break}++i}),this.curOp.forceUpdate=!0,Te(this,"refresh",this)}),operation:function(e){return hn(this,e)},startOperation:function(){return nn(this)},endOperation:function(){return on(this)},refresh:pn(function(){var e=this.display.cachedTextHeight;vn(this),this.curOp.forceUpdate=!0,er(this),Xr(this,this.doc.scrollLeft,this.doc.scrollTop),Wn(this),(null==e||Math.abs(e-mr(this.display))>.5)&&Cr(this),Te(this,"refresh",this)}),swapDoc:pn(function(e){var t=this.doc;return t.cm=null,qn(this,e),er(this),this.display.input.reset(),Xr(this,e.scrollLeft,e.scrollTop),this.curOp.forceScroll=!0,bt(this,"swapDoc",this,t),t}),getInputField:function(){return this.display.input.getField()},getWrapperElement:function(){return this.display.wrapper},getScrollerElement:function(){return this.display.scroller},getGutterElement:function(){return this.display.gutters}},Ae(e),e.registerHelper=function(t,n,i){r.hasOwnProperty(t)||(r[t]=e[t]={_global:[]}),r[t][n]=i},e.registerGlobalHelper=function(t,n,i,o){e.registerHelper(t,n,o),r[t]._global.push({pred:i,val:o})}}(jo);var Js="iter insert remove copy getEditor constructor".split(" ");for(var ea in Ds.prototype)Ds.prototype.hasOwnProperty(ea)&&h(Js,ea)<0&&(jo.prototype[ea]=function(e){return function(){return e.apply(this.doc,arguments)}}(Ds.prototype[ea]));return Ae(Ds),jo.inputStyles={textarea:Qs,contenteditable:Zs},jo.defineMode=function(e){jo.defaults.mode||"null"==e||(jo.defaults.mode=e),Be.apply(this,arguments)},jo.defineMIME=function(e,t){os[e]=t},jo.defineMode("null",function(){return{token:function(e){return e.skipToEnd()}}}),jo.defineMIME("text/plain","null"),jo.defineExtension=function(e,t){jo.prototype[e]=t},jo.defineDocExtension=function(e,t){Ds.prototype[e]=t},jo.fromTextArea=function(e,t){function r(){e.value=a.getValue()}if(t=t?c(t):{},t.value=e.value,!t.tabindex&&e.tabIndex&&(t.tabindex=e.tabIndex),!t.placeholder&&e.placeholder&&(t.placeholder=e.placeholder),null==t.autofocus){var n=l();t.autofocus=n==e||null!=e.getAttribute("autofocus")&&n==document.body}var i;if(e.form&&(Ql(e.form,"submit",r),!t.leaveSubmitMethodAlone)){var o=e.form;i=o.submit;try{var s=o.submit=function(){r(),o.submit=i,o.submit(),o.submit=s}}catch(e){}}t.finishInit=function(t){t.save=r,t.getTextArea=function(){return e},t.toTextArea=function(){t.toTextArea=isNaN,r(),e.parentNode.removeChild(t.getWrapperElement()),e.style.display="",e.form&&(ke(e.form,"submit",r),"function"==typeof e.form.submit&&(e.form.submit=i))}},e.style.display="none";var a=jo(function(t){return e.parentNode.insertBefore(t,e.nextSibling)},t);return a},function(e){e.off=ke,e.on=Ql,e.wheelEventPixels=Pn,e.Doc=Ds,e.splitLines=es,e.countColumn=f,e.findColumn=d,e.isWordChar=w,e.Pass=Bl,e.signal=Te,e.Line=fs,e.changeEnd=Bn,e.scrollbarModel=ws,e.Pos=E,e.cmpPos=P,e.modes=is,e.mimeModes=os,e.resolveMode=Ge,e.getMode=Ue,e.modeExtensions=ls,e.extendMode=Ve,e.copyState=Ke,e.startState=Xe,e.innerMode=je,e.commands=Bs,e.keyMap=Rs,e.keyName=ao,e.isModifierKey=lo,e.lookupKey=oo,e.normalizeKeyMap=io,e.StringStream=ss,e.SharedTextMarker=As,e.TextMarker=Os,e.LineWidget=Ms,e.e_preventDefault=We,e.e_stopPropagation=De,e.e_stop=Fe,e.addClass=s,e.contains=o,e.rmClass=Fl,e.keyNames=Es}(jo),jo.version="5.30.0",jo});
      !function(e){"object"==typeof exports&&"object"==typeof module?e(require("../../lib/codemirror")):"function"==typeof define&&define.amd?define(["../../lib/codemirror"],e):e(CodeMirror)}(function(e){"use strict";function t(e,t,n,r,o,a){this.indented=e,this.column=t,this.type=n,this.info=r,this.align=o,this.prev=a}function n(e,n,r,o){var a=e.indented;return e.context&&"statement"==e.context.type&&"statement"!=r&&(a=e.context.indented),e.context=new t(a,n,r,o,null,e.context)}function r(e){var t=e.context.type;return")"!=t&&"]"!=t&&"}"!=t||(e.indented=e.context.indented),e.context=e.context.prev}function o(e,t,n){return"variable"==t.prevToken||"type"==t.prevToken||(!!/\S(?:[^- ]>|[*\]])\s*$|\*$/.test(e.string.slice(0,n))||(!(!t.typeAtEndOfLine||e.column()!=e.indentation())||void 0))}function a(e){for(;;){if(!e||"top"==e.type)return!0;if("}"==e.type&&"namespace"!=e.prev.info)return!1;e=e.prev}}function i(e){for(var t={},n=e.split(" "),r=0;r<n.length;++r)t[n[r]]=!0;return t}function l(e,t){return"function"==typeof e?e(t):e.propertyIsEnumerable(t)}function s(e,t){if(!t.startOfLine)return!1;for(var n,r=null;n=e.peek();){if("\\"==n&&e.match(/^.$/)){r=s;break}if("/"==n&&e.match(/^\/[\/\*]/,!1))break;e.next()}return t.tokenize=r,"meta"}function c(e,t){return"type"==t.prevToken&&"type"}function u(e){return e.eatWhile(/[\w\.']/),"number"}function d(e,t){if(e.backUp(1),e.match(/(R|u8R|uR|UR|LR)/)){var n=e.match(/"([^\s\\()]{0,16})\(/);return!!n&&(t.cpp11RawStringDelim=n[1],t.tokenize=m,m(e,t))}return e.match(/(u8|u|U|L)/)?!!e.match(/["']/,!1)&&"string":(e.next(),!1)}function f(e){var t=/(\w+)::~?(\w+)$/.exec(e);return t&&t[1]==t[2]}function p(e,t){for(var n;null!=(n=e.next());)if('"'==n&&!e.eat('"')){t.tokenize=null;break}return"string"}function m(e,t){var n=t.cpp11RawStringDelim.replace(/[^\w\s]/g,"\\$&");return e.match(new RegExp(".*?\\)"+n+'"'))?t.tokenize=null:e.skipToEnd(),"string"}function h(t,n){function r(e){if(e)for(var t in e)e.hasOwnProperty(t)&&o.push(t)}"string"==typeof t&&(t=[t]);var o=[];r(n.keywords),r(n.types),r(n.builtin),r(n.atoms),o.length&&(n.helperType=t[0],e.registerHelper("hintWords",t[0],o));for(var a=0;a<t.length;++a)e.defineMIME(t[a],n)}function g(e,t){for(var n=!1;!e.eol();){if(!n&&e.match('"""')){t.tokenize=null;break}n="\\"==e.next()&&!n}return"string"}function y(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!e&&!o&&t.match('"')){a=!0;break}if(e&&t.match('"""')){a=!0;break}r=t.next(),!o&&"$"==r&&t.match("{")&&t.skipTo("}"),o=!o&&"\\"==r&&!e}return!a&&e||(n.tokenize=null),"string"}}function x(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!o&&t.match('"')&&("single"==e||t.match('""'))){a=!0;break}if(!o&&t.match("``")){w=x(e),a=!0;break}r=t.next(),o="single"==e&&!o&&"\\"==r}return a&&(n.tokenize=null),"string"}}e.defineMode("clike",function(i,s){function c(e,t){var n=e.next();if(S[n]){var r=S[n](e,t);if(!1!==r)return r}if('"'==n||"'"==n)return t.tokenize=u(n),t.tokenize(e,t);if(D.test(n))return p=n,null;if(L.test(n)){if(e.backUp(1),e.match(I))return"number";e.next()}if("/"==n){if(e.eat("*"))return t.tokenize=d,d(e,t);if(e.eat("/"))return e.skipToEnd(),"comment"}if(F.test(n)){for(;!e.match(/^\/[\/*]/,!1)&&e.eat(F););return"operator"}if(e.eatWhile(z),P)for(;e.match(P);)e.eatWhile(z);var o=e.current();return l(x,o)?(l(w,o)&&(p="newstatement"),l(v,o)&&(m=!0),"keyword"):l(b,o)?"type":l(k,o)?(l(w,o)&&(p="newstatement"),"builtin"):l(_,o)?"atom":"variable"}function u(e){return function(t,n){for(var r,o=!1,a=!1;null!=(r=t.next());){if(r==e&&!o){a=!0;break}o=!o&&"\\"==r}return(a||!o&&!C)&&(n.tokenize=null),"string"}}function d(e,t){for(var n,r=!1;n=e.next();){if("/"==n&&r){t.tokenize=null;break}r="*"==n}return"comment"}function f(e,t){s.typeFirstDefinitions&&e.eol()&&a(t.context)&&(t.typeAtEndOfLine=o(e,t,e.pos))}var p,m,h=i.indentUnit,g=s.statementIndentUnit||h,y=s.dontAlignCalls,x=s.keywords||{},b=s.types||{},k=s.builtin||{},w=s.blockKeywords||{},v=s.defKeywords||{},_=s.atoms||{},S=s.hooks||{},C=s.multiLineStrings,T=!1!==s.indentStatements,M=!1!==s.indentSwitch,P=s.namespaceSeparator,D=s.isPunctuationChar||/[\[\]{}\(\),;\:\.]/,L=s.numberStart||/[\d\.]/,I=s.number||/^(?:0x[a-f\d]+|0b[01]+|(?:\d+\.?\d*|\.\d+)(?:e[-+]?\d+)?)(u|ll?|l|f)?/i,F=s.isOperatorChar||/[+\-*&%=<>!?|\/]/,z=s.isIdentifierChar||/[\w\$_\xa1-\uffff]/;return{startState:function(e){return{tokenize:null,context:new t((e||0)-h,0,"top",null,!1),indented:0,startOfLine:!0,prevToken:null}},token:function(e,t){var i=t.context;if(e.sol()&&(null==i.align&&(i.align=!1),t.indented=e.indentation(),t.startOfLine=!0),e.eatSpace())return f(e,t),null;p=m=null;var l=(t.tokenize||c)(e,t);if("comment"==l||"meta"==l)return l;if(null==i.align&&(i.align=!0),";"==p||":"==p||","==p&&e.match(/^\s*(?:\/\/.*)?$/,!1))for(;"statement"==t.context.type;)r(t);else if("{"==p)n(t,e.column(),"}");else if("["==p)n(t,e.column(),"]");else if("("==p)n(t,e.column(),")");else if("}"==p){for(;"statement"==i.type;)i=r(t);for("}"==i.type&&(i=r(t));"statement"==i.type;)i=r(t)}else p==i.type?r(t):T&&(("}"==i.type||"top"==i.type)&&";"!=p||"statement"==i.type&&"newstatement"==p)&&n(t,e.column(),"statement",e.current());if("variable"==l&&("def"==t.prevToken||s.typeFirstDefinitions&&o(e,t,e.start)&&a(t.context)&&e.match(/^\s*\(/,!1))&&(l="def"),S.token){var u=S.token(e,t,l);void 0!==u&&(l=u)}return"def"==l&&!1===s.styleDefs&&(l="variable"),t.startOfLine=!1,t.prevToken=m?"def":l||p,f(e,t),l},indent:function(t,n){if(t.tokenize!=c&&null!=t.tokenize||t.typeAtEndOfLine)return e.Pass;var r=t.context,o=n&&n.charAt(0);if("statement"==r.type&&"}"==o&&(r=r.prev),s.dontIndentStatements)for(;"statement"==r.type&&s.dontIndentStatements.test(r.info);)r=r.prev;if(S.indent){var a=S.indent(t,r,n);if("number"==typeof a)return a}var i=o==r.type,l=r.prev&&"switch"==r.prev.info;if(s.allmanIndentation&&/[{(]/.test(o)){for(;"top"!=r.type&&"}"!=r.type;)r=r.prev;return r.indented}return"statement"==r.type?r.indented+("{"==o?0:g):!r.align||y&&")"==r.type?")"!=r.type||i?r.indented+(i?0:h)+(i||!l||/^(?:case|default)\b/.test(n)?0:h):r.indented+g:r.column+(i?0:1)},electricInput:M?/^\s*(?:case .*?:|default:|\{\}?|\})$/:/^\s*[{}]$/,blockCommentStart:"/*",blockCommentEnd:"*/",lineComment:"//",fold:"brace"}});var b="auto if break case register continue return default do sizeof static else struct switch extern typedef union for goto while enum const volatile",k="int long char short double float unsigned signed void size_t ptrdiff_t";h(["text/x-csrc","text/x-c","text/x-chdr"],{name:"clike",keywords:i(b),types:i(k+" bool _Complex _Bool float_t double_t intptr_t intmax_t int8_t int16_t int32_t int64_t uintptr_t uintmax_t uint8_t uint16_t uint32_t uint64_t"),blockKeywords:i("case do else for if switch while struct"),defKeywords:i("struct"),typeFirstDefinitions:!0,atoms:i("null true false"),hooks:{"#":s,"*":c},modeProps:{fold:["brace","include"]}}),h(["text/x-c++src","text/x-c++hdr"],{name:"clike",keywords:i(b+" asm dynamic_cast namespace reinterpret_cast try explicit new static_cast typeid catch operator template typename class friend private this using const_cast inline public throw virtual delete mutable protected alignas alignof constexpr decltype nullptr noexcept thread_local final static_assert override"),types:i(k+" bool wchar_t"),blockKeywords:i("catch class do else finally for if struct switch try while"),defKeywords:i("class namespace struct enum union"),typeFirstDefinitions:!0,atoms:i("true false null"),dontIndentStatements:/^template$/,isIdentifierChar:/[\w\$_~\xa1-\uffff]/,hooks:{"#":s,"*":c,u:d,U:d,L:d,R:d,0:u,1:u,2:u,3:u,4:u,5:u,6:u,7:u,8:u,9:u,token:function(e,t,n){if("variable"==n&&"("==e.peek()&&(";"==t.prevToken||null==t.prevToken||"}"==t.prevToken)&&f(e.current()))return"def"}},namespaceSeparator:"::",modeProps:{fold:["brace","include"]}}),h("text/x-java",{name:"clike",keywords:i("abstract assert break case catch class const continue default do else enum extends final finally float for goto if implements import instanceof interface native new package private protected public return static strictfp super switch synchronized this throw throws transient try volatile while @interface"),types:i("byte short int long float double boolean char void Boolean Byte Character Double Float Integer Long Number Object Short String StringBuffer StringBuilder Void"),blockKeywords:i("catch class do else finally for if switch try while"),defKeywords:i("class interface package enum @interface"),typeFirstDefinitions:!0,atoms:i("true false null"),number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,hooks:{"@":function(e){return!e.match("interface",!1)&&(e.eatWhile(/[\w\$_]/),"meta")}},modeProps:{fold:["brace","import"]}}),h("text/x-csharp",{name:"clike",keywords:i("abstract as async await base break case catch checked class const continue default delegate do else enum event explicit extern finally fixed for foreach goto if implicit in interface internal is lock namespace new operator out override params private protected public readonly ref return sealed sizeof stackalloc static struct switch this throw try typeof unchecked unsafe using virtual void volatile while add alias ascending descending dynamic from get global group into join let orderby partial remove select set value var yield"),types:i("Action Boolean Byte Char DateTime DateTimeOffset Decimal Double Func Guid Int16 Int32 Int64 Object SByte Single String Task TimeSpan UInt16 UInt32 UInt64 bool byte char decimal double short int long object sbyte float string ushort uint ulong"),blockKeywords:i("catch class do else finally for foreach if struct switch try while"),defKeywords:i("class interface namespace struct var"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"@":function(e,t){return e.eat('"')?(t.tokenize=p,p(e,t)):(e.eatWhile(/[\w\$_]/),"meta")}}}),h("text/x-scala",{name:"clike",keywords:i("abstract case catch class def do else extends final finally for forSome if implicit import lazy match new null object override package private protected return sealed super this throw trait try type val var while with yield _ assert assume require print println printf readLine readBoolean readByte readShort readChar readInt readLong readFloat readDouble"),types:i("AnyVal App Application Array BufferedIterator BigDecimal BigInt Char Console Either Enumeration Equiv Error Exception Fractional Function IndexedSeq Int Integral Iterable Iterator List Map Numeric Nil NotNull Option Ordered Ordering PartialFunction PartialOrdering Product Proxy Range Responder Seq Serializable Set Specializable Stream StringBuilder StringContext Symbol Throwable Traversable TraversableOnce Tuple Unit Vector Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),multiLineStrings:!0,blockKeywords:i("catch class enum do else finally for forSome if match switch try while"),defKeywords:i("class enum def object package trait type val var"),atoms:i("true false null"),indentStatements:!1,indentSwitch:!1,isOperatorChar:/[+\-*&%=<>!?|\/#:@]/,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return!!e.match('""')&&(t.tokenize=g,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},"=":function(e,n){var r=n.context;return!("}"!=r.type||!r.align||!e.eat(">"))&&(n.context=new t(r.indented,r.column,r.type,r.info,null,r.prev),"operator")}},modeProps:{closeBrackets:{triples:'"'}}}),h("text/x-kotlin",{name:"clike",keywords:i("package as typealias class interface this super val var fun for is in This throw return break continue object if else while do try when !in !is as? file import where by get set abstract enum open inner override private public internal protected catch finally out final vararg reified dynamic companion constructor init sealed field property receiver param sparam lateinit data inline noinline tailrec external annotation crossinline const operator infix suspend"),types:i("Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),intendSwitch:!1,indentStatements:!1,multiLineStrings:!0,number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,blockKeywords:i("catch class do else finally for if where try while enum"),defKeywords:i("class val var object package interface fun"),atoms:i("true false null this"),hooks:{'"':function(e,t){return t.tokenize=y(e.match('""')),t.tokenize(e,t)}},modeProps:{closeBrackets:{triples:'"'}}}),h(["x-shader/x-vertex","x-shader/x-fragment"],{name:"clike",keywords:i("sampler1D sampler2D sampler3D samplerCube sampler1DShadow sampler2DShadow const attribute uniform varying break continue discard return for while do if else struct in out inout"),types:i("float int bool void vec2 vec3 vec4 ivec2 ivec3 ivec4 bvec2 bvec3 bvec4 mat2 mat3 mat4"),blockKeywords:i("for while do if else struct"),builtin:i("radians degrees sin cos tan asin acos atan pow exp log exp2 sqrt inversesqrt abs sign floor ceil fract mod min max clamp mix step smoothstep length distance dot cross normalize ftransform faceforward reflect refract matrixCompMult lessThan lessThanEqual greaterThan greaterThanEqual equal notEqual any all not texture1D texture1DProj texture1DLod texture1DProjLod texture2D texture2DProj texture2DLod texture2DProjLod texture3D texture3DProj texture3DLod texture3DProjLod textureCube textureCubeLod shadow1D shadow2D shadow1DProj shadow2DProj shadow1DLod shadow2DLod shadow1DProjLod shadow2DProjLod dFdx dFdy fwidth noise1 noise2 noise3 noise4"),atoms:i("true false gl_FragColor gl_SecondaryColor gl_Normal gl_Vertex gl_MultiTexCoord0 gl_MultiTexCoord1 gl_MultiTexCoord2 gl_MultiTexCoord3 gl_MultiTexCoord4 gl_MultiTexCoord5 gl_MultiTexCoord6 gl_MultiTexCoord7 gl_FogCoord gl_PointCoord gl_Position gl_PointSize gl_ClipVertex gl_FrontColor gl_BackColor gl_FrontSecondaryColor gl_BackSecondaryColor gl_TexCoord gl_FogFragCoord gl_FragCoord gl_FrontFacing gl_FragData gl_FragDepth gl_ModelViewMatrix gl_ProjectionMatrix gl_ModelViewProjectionMatrix gl_TextureMatrix gl_NormalMatrix gl_ModelViewMatrixInverse gl_ProjectionMatrixInverse gl_ModelViewProjectionMatrixInverse gl_TexureMatrixTranspose gl_ModelViewMatrixInverseTranspose gl_ProjectionMatrixInverseTranspose gl_ModelViewProjectionMatrixInverseTranspose gl_TextureMatrixInverseTranspose gl_NormalScale gl_DepthRange gl_ClipPlane gl_Point gl_FrontMaterial gl_BackMaterial gl_LightSource gl_LightModel gl_FrontLightModelProduct gl_BackLightModelProduct gl_TextureColor gl_EyePlaneS gl_EyePlaneT gl_EyePlaneR gl_EyePlaneQ gl_FogParameters gl_MaxLights gl_MaxClipPlanes gl_MaxTextureUnits gl_MaxTextureCoords gl_MaxVertexAttribs gl_MaxVertexUniformComponents gl_MaxVaryingFloats gl_MaxVertexTextureImageUnits gl_MaxTextureImageUnits gl_MaxFragmentUniformComponents gl_MaxCombineTextureImageUnits gl_MaxDrawBuffers"),indentSwitch:!1,hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-nesc",{name:"clike",keywords:i(b+"as atomic async call command component components configuration event generic implementation includes interface module new norace nx_struct nx_union post provides signal task uses abstract extends"),types:i(k),blockKeywords:i("case do else for if switch while struct"),atoms:i("null true false"),hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-objectivec",{name:"clike",keywords:i(b+"inline restrict _Bool _Complex _Imaginary BOOL Class bycopy byref id IMP in inout nil oneway out Protocol SEL self super atomic nonatomic retain copy readwrite readonly"),types:i(k),atoms:i("YES NO NULL NILL ON OFF true false"),hooks:{"@":function(e){return e.eatWhile(/[\w\$]/),"keyword"},"#":s,indent:function(e,t,n){if("statement"==t.type&&/^@\w/.test(n))return t.indented}},modeProps:{fold:"brace"}}),h("text/x-squirrel",{name:"clike",keywords:i("base break clone continue const default delete enum extends function in class foreach local resume return this throw typeof yield constructor instanceof static"),types:i(k),blockKeywords:i("case catch class else for foreach if switch try while"),defKeywords:i("function local class"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"#":s},modeProps:{fold:["brace","include"]}});var w=null;h("text/x-ceylon",{name:"clike",keywords:i("abstracts alias assembly assert assign break case catch class continue dynamic else exists extends finally for function given if import in interface is let module new nonempty object of out outer package return satisfies super switch then this throw try value void while"),types:function(e){var t=e.charAt(0);return t===t.toUpperCase()&&t!==t.toLowerCase()},blockKeywords:i("case catch class dynamic else finally for function if interface module new object switch try while"),defKeywords:i("class dynamic function interface module object package value"),builtin:i("abstract actual aliased annotation by default deprecated doc final formal late license native optional sealed see serializable shared suppressWarnings tagged throws variable"),isPunctuationChar:/[\[\]{}\(\),;\:\.`]/,isOperatorChar:/[+\-*&%=<>!?|^~:\/]/,numberStart:/[\d#$]/,number:/^(?:#[\da-fA-F_]+|\$[01_]+|[\d_]+[kMGTPmunpf]?|[\d_]+\.[\d_]+(?:[eE][-+]?\d+|[kMGTPmunpf]|)|)/i,multiLineStrings:!0,typeFirstDefinitions:!0,atoms:i("true false null larger smaller equal empty finished"),indentSwitch:!1,styleDefs:!1,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return t.tokenize=x(e.match('""')?"triple":"single"),t.tokenize(e,t)},"`":function(e,t){return!(!w||!e.match("`"))&&(t.tokenize=w,w=null,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},token:function(e,t,n){if(("variable"==n||"type"==n)&&"."==t.prevToken)return"variable-2"}},modeProps:{fold:["brace","import"],closeBrackets:{triples:'"'}}})});
      // -------------------------------------------------------------------------
//  Part of the CodeChecker project, under the Apache License v2.0 with
//  LLVM Exceptions. See LICENSE for license information.
//  SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
// -------------------------------------------------------------------------

var BugViewer = {
  _files : [],
  _reports : [],
  _lineWidgets : [],
  _navigationMenuItems : [],
  _sourceFileData : null,
  _currentReport : null,
  _lastBugEvent  : null,

  init : function (files, reports) {
    this._files = files;
    this._reports = reports;

    this.initEscapeChars();
  },

  initEscapeChars : function () {
    this.escapeChars = {
      ' ' : 'nbsp',
      '<' : 'lt',
      '>' : 'gt',
      '"' : 'quot',
      '&' : 'amp'
    };

    var regexString = '[';
    for (var key in this.escapeChars) {
      regexString += key;
    }
    regexString += ']';

    this.escapeRegExp = new RegExp( regexString, 'g');
  },

  escapeHTML : function (str) {
    var that = this;

    return str.replace(this.escapeRegExp, function (m) {
      return '&' + that.escapeChars[m] + ';';
    });
  },

  initByUrl : function () {
    if (!this._reports) return;

    var state = {};
    window.location.hash.substr(1).split('&').forEach(function (s) {
      var parts = s.split('=');
      state[parts[0]] = parts[1];
    });

    for (var key in this._reports) {
      var report = this._reports[key];
      if (report.reportHash === state['reportHash']) {
        this.navigate(report);
        return;
      }
    }

    this.navigate(this._reports[0]);
  },

  create : function () {
    this._content = document.getElementById('editor-wrapper');
    this._filepath = document.getElementById('file-path');
    this._checkerName = document.getElementById('checker-name');
    this._reviewStatusWrapper =
      document.getElementById('review-status-wrapper');
    this._reviewStatus = document.getElementById('review-status');
    this._editor = document.getElementById('editor');

    this._codeMirror = CodeMirror(this._editor, {
      mode: 'text/x-c++src',
      matchBrackets : true,
      lineNumbers : true,
      readOnly : true,
      foldGutter : true,
      extraKeys : {},
      viewportMargin : 100
    });

    this._createNavigationMenu();
  },

  navigate : function (report, item) {
    if (!item) {
      var items = this._navigationMenuItems.filter(function (navItem) {
        return navItem.report.reportHash === report.reportHash;
      });

      if (!items.length) return;

      item = items[0].widget;
    }

    this._selectedReport.classList.remove('active');
    this._selectedReport = item;
    this._selectedReport.classList.add('active');
    this.setReport(report);
  },

  _createNavigationMenu : function () {
    var that = this;

    var nav = document.getElementById('report-nav');
    var list = document.createElement('ul');
    this._reports.forEach(function (report) {
      var events = report['events'];
      var lastBugEvent = events[events.length - 1];
      var item = document.createElement('li');

      var severity = document.createElement('i');
      severity.className = 'severity-' + report.severity.toLowerCase();

      item.appendChild(severity);
      item.appendChild(document.createTextNode(lastBugEvent.message));

      item.addEventListener('click', function () {
        that.navigate(report, item);
      })
      list.appendChild(item);
      that._navigationMenuItems.push({ report : report, widget : item });
    });

    if (!this._selectedReport && list.childNodes.length) {
      this._selectedReport = list.childNodes[0];
      this._selectedReport.classList.add('active');
    }

    nav.appendChild(list);
  },

  setReport : function (report) {
    this._currentReport = report;
    var events = report['events'];
    var lastBugEvent = events[events.length - 1];
    this.setCurrentBugEvent(lastBugEvent, events.length - 1);
    this.setCheckerName(report.checkerName);
    this.setReviewStatus(report.reviewStatus);

    window.location.hash = '#reportHash=' + report.reportHash;
  },

  setCurrentBugEvent : function (event, idx) {
    this._currentBugEvent = event;
    this.setSourceFileData(this._files[event.location.file]);
    this.drawBugPath();

    this.jumpTo(event.location.line, 0);
    this.highlightBugEvent(event, idx);
  },

  highlightBugEvent : function (event, idx) {
    this._lineWidgets.forEach(function (widget) {
      var lineIdx = widget.node.getAttribute('idx');
      if (parseInt(lineIdx) === idx) {
        widget.node.classList.add('current');
      }
    });
  },

  setCheckerName : function (checkerName) {
    this._checkerName.innerHTML = checkerName;
  },

  setReviewStatus : function (status) {
    if (status) {
      var className =
        'review-status-' + status.toLowerCase().split(' ').join('-');
      this._reviewStatus.className = "review-status " + className;

      this._reviewStatus.innerHTML = status;
      this._reviewStatusWrapper.style.display = 'block';
    } else {
      this._reviewStatusWrapper.style.display = 'none';
    }
  },

  setSourceFileData : function (file) {
    if (this._sourceFileData && file.id === this._sourceFileData.id) {
      return;
    }

    this._sourceFileData = file;
    this._filepath.innerHTML = file.path;
    this._codeMirror.doc.setValue(file.content);
    this._refresh();
  },

  _refresh : function () {
    var that = this;
    setTimeout(function () {
      var fullHeight = parseInt(that._content.clientHeight);
      var headerHeight = that._filepath.clientHeight;

      that._codeMirror.setSize('auto', fullHeight - headerHeight);
      that._codeMirror.refresh();
    }, 200);
  },

  clearBubbles : function () {
    this._lineWidgets.forEach(function (widget) { widget.clear(); });
    this._lineWidgets = [];
  },

  getMessage : function (event, kind) {
    if (kind === 'macro') {
      var name = 'macro expansion' + (event.name ? ': ' + event.name : '');

      return '<span class="tag macro">' + name + '</span>'
        + this.escapeHTML(event.expansion).replace(/(?:\r\n|\r|\n)/g, '<br>');
    } else if (kind === 'note') {
      return '<span class="tag note">note</span>'
        +  this.escapeHTML(event.message).replace(/(?:\r\n|\r|\n)/g, '<br>');
    }
  },

  addExtraPathEvents : function (events, kind) {
    var that = this;

    if (!events) {
      return;
    }

    events.forEach(function (event) {
      if (event.location.file !== that._currentBugEvent.location.file) {
        return;
      }

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + kind);

      var msg = document.createElement('span');
      msg.innerHTML = that.getMessage(event, kind);
      element.appendChild(msg);

      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  drawBugPath : function () {
    var that = this;

    this.clearBubbles();

    this.addExtraPathEvents(this._currentReport.macros, 'macro');
    this.addExtraPathEvents(this._currentReport.notes, 'note');

    // Processing bug path events.
    var currentEvents = this._currentReport.events;
    currentEvents.forEach(function (event, step) {
      if (event.location.file !== that._currentBugEvent.location.file)
        return;

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';
      var type = step === currentEvents.length - 1 ? 'error' : 'info';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + type);
      element.setAttribute('idx', step);

      var enumeration = document.createElement('span');
      enumeration.setAttribute('class', 'checker-enum ' + type);
      enumeration.innerHTML = step + 1;

      if (currentEvents.length > 1)
        element.appendChild(enumeration);

      var prevBugEvent = step - 1;
      if (step > 0) {
        var prevBug = document.createElement('span');
        prevBug.setAttribute('class', 'arrow left-arrow');
        prevBug.addEventListener('click', function () {
          var event = currentEvents[prevBugEvent];
          that.setCurrentBugEvent(event, prevBugEvent);
        });
        element.appendChild(prevBug);
      }

      var msg = document.createElement('span');
      msg.innerHTML = that.escapeHTML(event.message)
        .replace(/(?:\r\n|\r|\n)/g, '<br>');

      element.appendChild(msg);

      var nextBugEvent = step + 1;
      if (nextBugEvent < currentEvents.length) {
        var nextBug = document.createElement('span');
        nextBug.setAttribute('class', 'arrow right-arrow');
        nextBug.addEventListener('click', function () {
          var event = currentEvents[nextBugEvent];
          that.setCurrentBugEvent(event, nextBugEvent);
        });
        element.appendChild(nextBug);
      }


      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  jumpTo : function (line, column) {
    var that = this;

    setTimeout(function () {
      var selPosPixel
        = that._codeMirror.charCoords({ line : line, ch : column }, 'local');
      var editorSize = {
        width  : that._editor.clientWidth,
        height : that._editor.clientHeight
      };

      that._codeMirror.scrollIntoView({
        top    : selPosPixel.top - 100,
        bottom : selPosPixel.top + editorSize.height - 150,
        left   : selPosPixel.left < editorSize.width - 100
               ? 0
               : selPosPixel.left - 50,
        right  : selPosPixel.left < editorSize.width - 100
               ? 10
               : selPosPixel.left + editorSize.width - 100
      });
    }, 0);
  }
}


      var data = {"files": {"0": {"id": 0, "path": "/src/arch/x86/kvm/mmu/mmu.c", "content": "// SPDX-License-Identifier: GPL-2.0-only\n/*\n * Kernel-based Virtual Machine driver for Linux\n *\n * This module enables machines with Intel VT-x extensions to run virtual\n * machines without emulation or binary translation.\n *\n * MMU support\n *\n * Copyright (C) 2006 Qumranet, Inc.\n * Copyright 2010 Red Hat, Inc. and/or its affiliates.\n *\n * Authors:\n *   Yaniv Kamay  <yaniv@qumranet.com>\n *   Avi Kivity   <avi@qumranet.com>\n */\n\n#include \"irq.h\"\n#include \"ioapic.h\"\n#include \"mmu.h\"\n#include \"mmu_internal.h\"\n#include \"tdp_mmu.h\"\n#include \"x86.h\"\n#include \"kvm_cache_regs.h\"\n#include \"kvm_emulate.h\"\n#include \"cpuid.h\"\n#include \"spte.h\"\n\n#include <linux/kvm_host.h>\n#include <linux/types.h>\n#include <linux/string.h>\n#include <linux/mm.h>\n#include <linux/highmem.h>\n#include <linux/moduleparam.h>\n#include <linux/export.h>\n#include <linux/swap.h>\n#include <linux/hugetlb.h>\n#include <linux/compiler.h>\n#include <linux/srcu.h>\n#include <linux/slab.h>\n#include <linux/sched/signal.h>\n#include <linux/uaccess.h>\n#include <linux/hash.h>\n#include <linux/kern_levels.h>\n#include <linux/kthread.h>\n\n#include <asm/page.h>\n#include <asm/memtype.h>\n#include <asm/cmpxchg.h>\n#include <asm/io.h>\n#include <asm/vmx.h>\n#include <asm/kvm_page_track.h>\n#include \"trace.h\"\n\nextern bool itlb_multihit_kvm_mitigation;\n\nstatic int __read_mostly nx_huge_pages = -1;\n#ifdef CONFIG_PREEMPT_RT\n/* Recovery can cause latency spikes, disable it for PREEMPT_RT.  */\nstatic uint __read_mostly nx_huge_pages_recovery_ratio = 0;\n#else\nstatic uint __read_mostly nx_huge_pages_recovery_ratio = 60;\n#endif\n\nstatic int set_nx_huge_pages(const char *val, const struct kernel_param *kp);\nstatic int set_nx_huge_pages_recovery_ratio(const char *val, const struct kernel_param *kp);\n\nstatic const struct kernel_param_ops nx_huge_pages_ops = {\n\t.set = set_nx_huge_pages,\n\t.get = param_get_bool,\n};\n\nstatic const struct kernel_param_ops nx_huge_pages_recovery_ratio_ops = {\n\t.set = set_nx_huge_pages_recovery_ratio,\n\t.get = param_get_uint,\n};\n\nmodule_param_cb(nx_huge_pages, &nx_huge_pages_ops, &nx_huge_pages, 0644);\n__MODULE_PARM_TYPE(nx_huge_pages, \"bool\");\nmodule_param_cb(nx_huge_pages_recovery_ratio, &nx_huge_pages_recovery_ratio_ops,\n\t\t&nx_huge_pages_recovery_ratio, 0644);\n__MODULE_PARM_TYPE(nx_huge_pages_recovery_ratio, \"uint\");\n\nstatic bool __read_mostly force_flush_and_sync_on_reuse;\nmodule_param_named(flush_on_reuse, force_flush_and_sync_on_reuse, bool, 0644);\n\n/*\n * When setting this variable to true it enables Two-Dimensional-Paging\n * where the hardware walks 2 page tables:\n * 1. the guest-virtual to guest-physical\n * 2. while doing 1. it walks guest-physical to host-physical\n * If the hardware supports that we don't need to do shadow paging.\n */\nbool tdp_enabled = false;\n\nstatic int max_huge_page_level __read_mostly;\nstatic int max_tdp_level __read_mostly;\n\nenum {\n\tAUDIT_PRE_PAGE_FAULT,\n\tAUDIT_POST_PAGE_FAULT,\n\tAUDIT_PRE_PTE_WRITE,\n\tAUDIT_POST_PTE_WRITE,\n\tAUDIT_PRE_SYNC,\n\tAUDIT_POST_SYNC\n};\n\n#ifdef MMU_DEBUG\nbool dbg = 0;\nmodule_param(dbg, bool, 0644);\n#endif\n\n#define PTE_PREFETCH_NUM\t\t8\n\n#define PT32_LEVEL_BITS 10\n\n#define PT32_LEVEL_SHIFT(level) \\\n\t\t(PAGE_SHIFT + (level - 1) * PT32_LEVEL_BITS)\n\n#define PT32_LVL_OFFSET_MASK(level) \\\n\t(PT32_BASE_ADDR_MASK & ((1ULL << (PAGE_SHIFT + (((level) - 1) \\\n\t\t\t\t\t\t* PT32_LEVEL_BITS))) - 1))\n\n#define PT32_INDEX(address, level)\\\n\t(((address) >> PT32_LEVEL_SHIFT(level)) & ((1 << PT32_LEVEL_BITS) - 1))\n\n\n#define PT32_BASE_ADDR_MASK PAGE_MASK\n#define PT32_DIR_BASE_ADDR_MASK \\\n\t(PAGE_MASK & ~((1ULL << (PAGE_SHIFT + PT32_LEVEL_BITS)) - 1))\n#define PT32_LVL_ADDR_MASK(level) \\\n\t(PAGE_MASK & ~((1ULL << (PAGE_SHIFT + (((level) - 1) \\\n\t\t\t\t\t    * PT32_LEVEL_BITS))) - 1))\n\n#include <trace/events/kvm.h>\n\n/* make pte_list_desc fit well in cache line */\n#define PTE_LIST_EXT 3\n\nstruct pte_list_desc {\n\tu64 *sptes[PTE_LIST_EXT];\n\tstruct pte_list_desc *more;\n};\n\nstruct kvm_shadow_walk_iterator {\n\tu64 addr;\n\thpa_t shadow_addr;\n\tu64 *sptep;\n\tint level;\n\tunsigned index;\n};\n\n#define for_each_shadow_entry_using_root(_vcpu, _root, _addr, _walker)     \\\n\tfor (shadow_walk_init_using_root(&(_walker), (_vcpu),              \\\n\t\t\t\t\t (_root), (_addr));                \\\n\t     shadow_walk_okay(&(_walker));\t\t\t           \\\n\t     shadow_walk_next(&(_walker)))\n\n#define for_each_shadow_entry(_vcpu, _addr, _walker)            \\\n\tfor (shadow_walk_init(&(_walker), _vcpu, _addr);\t\\\n\t     shadow_walk_okay(&(_walker));\t\t\t\\\n\t     shadow_walk_next(&(_walker)))\n\n#define for_each_shadow_entry_lockless(_vcpu, _addr, _walker, spte)\t\\\n\tfor (shadow_walk_init(&(_walker), _vcpu, _addr);\t\t\\\n\t     shadow_walk_okay(&(_walker)) &&\t\t\t\t\\\n\t\t({ spte = mmu_spte_get_lockless(_walker.sptep); 1; });\t\\\n\t     __shadow_walk_next(&(_walker), spte))\n\nstatic struct kmem_cache *pte_list_desc_cache;\nstruct kmem_cache *mmu_page_header_cache;\nstatic struct percpu_counter kvm_total_used_mmu_pages;\n\nstatic void mmu_spte_set(u64 *sptep, u64 spte);\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);\n\n#define CREATE_TRACE_POINTS\n#include \"mmutrace.h\"\n\n\nstatic inline bool kvm_available_flush_tlb_with_range(void)\n{\n\treturn kvm_x86_ops.tlb_remote_flush_with_range;\n}\n\nstatic void kvm_flush_remote_tlbs_with_range(struct kvm *kvm,\n\t\tstruct kvm_tlb_range *range)\n{\n\tint ret = -ENOTSUPP;\n\n\tif (range && kvm_x86_ops.tlb_remote_flush_with_range)\n\t\tret = kvm_x86_ops.tlb_remote_flush_with_range(kvm, range);\n\n\tif (ret)\n\t\tkvm_flush_remote_tlbs(kvm);\n}\n\nvoid kvm_flush_remote_tlbs_with_address(struct kvm *kvm,\n\t\tu64 start_gfn, u64 pages)\n{\n\tstruct kvm_tlb_range range;\n\n\trange.start_gfn = start_gfn;\n\trange.pages = pages;\n\n\tkvm_flush_remote_tlbs_with_range(kvm, &range);\n}\n\nbool is_nx_huge_page_enabled(void)\n{\n\treturn READ_ONCE(nx_huge_pages);\n}\n\nstatic void mark_mmio_spte(struct kvm_vcpu *vcpu, u64 *sptep, u64 gfn,\n\t\t\t   unsigned int access)\n{\n\tu64 mask = make_mmio_spte(vcpu, gfn, access);\n\n\ttrace_mark_mmio_spte(sptep, gfn, mask);\n\tmmu_spte_set(sptep, mask);\n}\n\nstatic gfn_t get_mmio_spte_gfn(u64 spte)\n{\n\tu64 gpa = spte & shadow_nonpresent_or_rsvd_lower_gfn_mask;\n\n\tgpa |= (spte >> SHADOW_NONPRESENT_OR_RSVD_MASK_LEN)\n\t       & shadow_nonpresent_or_rsvd_mask;\n\n\treturn gpa >> PAGE_SHIFT;\n}\n\nstatic unsigned get_mmio_spte_access(u64 spte)\n{\n\treturn spte & shadow_mmio_access_mask;\n}\n\nstatic bool set_mmio_spte(struct kvm_vcpu *vcpu, u64 *sptep, gfn_t gfn,\n\t\t\t  kvm_pfn_t pfn, unsigned int access)\n{\n\tif (unlikely(is_noslot_pfn(pfn))) {\n\t\tmark_mmio_spte(vcpu, sptep, gfn, access);\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic bool check_mmio_spte(struct kvm_vcpu *vcpu, u64 spte)\n{\n\tu64 kvm_gen, spte_gen, gen;\n\n\tgen = kvm_vcpu_memslots(vcpu)->generation;\n\tif (unlikely(gen & KVM_MEMSLOT_GEN_UPDATE_IN_PROGRESS))\n\t\treturn false;\n\n\tkvm_gen = gen & MMIO_SPTE_GEN_MASK;\n\tspte_gen = get_mmio_spte_generation(spte);\n\n\ttrace_check_mmio_spte(spte, kvm_gen, spte_gen);\n\treturn likely(kvm_gen == spte_gen);\n}\n\nstatic gpa_t translate_gpa(struct kvm_vcpu *vcpu, gpa_t gpa, u32 access,\n                                  struct x86_exception *exception)\n{\n\t/* Check if guest physical address doesn't exceed guest maximum */\n\tif (kvm_vcpu_is_illegal_gpa(vcpu, gpa)) {\n\t\texception->error_code |= PFERR_RSVD_MASK;\n\t\treturn UNMAPPED_GVA;\n\t}\n\n        return gpa;\n}\n\nstatic int is_cpuid_PSE36(void)\n{\n\treturn 1;\n}\n\nstatic int is_nx(struct kvm_vcpu *vcpu)\n{\n\treturn vcpu->arch.efer & EFER_NX;\n}\n\nstatic gfn_t pse36_gfn_delta(u32 gpte)\n{\n\tint shift = 32 - PT32_DIR_PSE36_SHIFT - PAGE_SHIFT;\n\n\treturn (gpte & PT32_DIR_PSE36_MASK) << shift;\n}\n\n#ifdef CONFIG_X86_64\nstatic void __set_spte(u64 *sptep, u64 spte)\n{\n\tWRITE_ONCE(*sptep, spte);\n}\n\nstatic void __update_clear_spte_fast(u64 *sptep, u64 spte)\n{\n\tWRITE_ONCE(*sptep, spte);\n}\n\nstatic u64 __update_clear_spte_slow(u64 *sptep, u64 spte)\n{\n\treturn xchg(sptep, spte);\n}\n\nstatic u64 __get_spte_lockless(u64 *sptep)\n{\n\treturn READ_ONCE(*sptep);\n}\n#else\nunion split_spte {\n\tstruct {\n\t\tu32 spte_low;\n\t\tu32 spte_high;\n\t};\n\tu64 spte;\n};\n\nstatic void count_spte_clear(u64 *sptep, u64 spte)\n{\n\tstruct kvm_mmu_page *sp =  sptep_to_sp(sptep);\n\n\tif (is_shadow_present_pte(spte))\n\t\treturn;\n\n\t/* Ensure the spte is completely set before we increase the count */\n\tsmp_wmb();\n\tsp->clear_spte_count++;\n}\n\nstatic void __set_spte(u64 *sptep, u64 spte)\n{\n\tunion split_spte *ssptep, sspte;\n\n\tssptep = (union split_spte *)sptep;\n\tsspte = (union split_spte)spte;\n\n\tssptep->spte_high = sspte.spte_high;\n\n\t/*\n\t * If we map the spte from nonpresent to present, We should store\n\t * the high bits firstly, then set present bit, so cpu can not\n\t * fetch this spte while we are setting the spte.\n\t */\n\tsmp_wmb();\n\n\tWRITE_ONCE(ssptep->spte_low, sspte.spte_low);\n}\n\nstatic void __update_clear_spte_fast(u64 *sptep, u64 spte)\n{\n\tunion split_spte *ssptep, sspte;\n\n\tssptep = (union split_spte *)sptep;\n\tsspte = (union split_spte)spte;\n\n\tWRITE_ONCE(ssptep->spte_low, sspte.spte_low);\n\n\t/*\n\t * If we map the spte from present to nonpresent, we should clear\n\t * present bit firstly to avoid vcpu fetch the old high bits.\n\t */\n\tsmp_wmb();\n\n\tssptep->spte_high = sspte.spte_high;\n\tcount_spte_clear(sptep, spte);\n}\n\nstatic u64 __update_clear_spte_slow(u64 *sptep, u64 spte)\n{\n\tunion split_spte *ssptep, sspte, orig;\n\n\tssptep = (union split_spte *)sptep;\n\tsspte = (union split_spte)spte;\n\n\t/* xchg acts as a barrier before the setting of the high bits */\n\torig.spte_low = xchg(&ssptep->spte_low, sspte.spte_low);\n\torig.spte_high = ssptep->spte_high;\n\tssptep->spte_high = sspte.spte_high;\n\tcount_spte_clear(sptep, spte);\n\n\treturn orig.spte;\n}\n\n/*\n * The idea using the light way get the spte on x86_32 guest is from\n * gup_get_pte (mm/gup.c).\n *\n * An spte tlb flush may be pending, because kvm_set_pte_rmapp\n * coalesces them and we are running out of the MMU lock.  Therefore\n * we need to protect against in-progress updates of the spte.\n *\n * Reading the spte while an update is in progress may get the old value\n * for the high part of the spte.  The race is fine for a present->non-present\n * change (because the high part of the spte is ignored for non-present spte),\n * but for a present->present change we must reread the spte.\n *\n * All such changes are done in two steps (present->non-present and\n * non-present->present), hence it is enough to count the number of\n * present->non-present updates: if it changed while reading the spte,\n * we might have hit the race.  This is done using clear_spte_count.\n */\nstatic u64 __get_spte_lockless(u64 *sptep)\n{\n\tstruct kvm_mmu_page *sp =  sptep_to_sp(sptep);\n\tunion split_spte spte, *orig = (union split_spte *)sptep;\n\tint count;\n\nretry:\n\tcount = sp->clear_spte_count;\n\tsmp_rmb();\n\n\tspte.spte_low = orig->spte_low;\n\tsmp_rmb();\n\n\tspte.spte_high = orig->spte_high;\n\tsmp_rmb();\n\n\tif (unlikely(spte.spte_low != orig->spte_low ||\n\t      count != sp->clear_spte_count))\n\t\tgoto retry;\n\n\treturn spte.spte;\n}\n#endif\n\nstatic bool spte_has_volatile_bits(u64 spte)\n{\n\tif (!is_shadow_present_pte(spte))\n\t\treturn false;\n\n\t/*\n\t * Always atomically update spte if it can be updated\n\t * out of mmu-lock, it can ensure dirty bit is not lost,\n\t * also, it can help us to get a stable is_writable_pte()\n\t * to ensure tlb flush is not missed.\n\t */\n\tif (spte_can_locklessly_be_made_writable(spte) ||\n\t    is_access_track_spte(spte))\n\t\treturn true;\n\n\tif (spte_ad_enabled(spte)) {\n\t\tif ((spte & shadow_accessed_mask) == 0 ||\n\t    \t    (is_writable_pte(spte) && (spte & shadow_dirty_mask) == 0))\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\n/* Rules for using mmu_spte_set:\n * Set the sptep from nonpresent to present.\n * Note: the sptep being assigned *must* be either not present\n * or in a state where the hardware will not attempt to update\n * the spte.\n */\nstatic void mmu_spte_set(u64 *sptep, u64 new_spte)\n{\n\tWARN_ON(is_shadow_present_pte(*sptep));\n\t__set_spte(sptep, new_spte);\n}\n\n/*\n * Update the SPTE (excluding the PFN), but do not track changes in its\n * accessed/dirty status.\n */\nstatic u64 mmu_spte_update_no_track(u64 *sptep, u64 new_spte)\n{\n\tu64 old_spte = *sptep;\n\n\tWARN_ON(!is_shadow_present_pte(new_spte));\n\n\tif (!is_shadow_present_pte(old_spte)) {\n\t\tmmu_spte_set(sptep, new_spte);\n\t\treturn old_spte;\n\t}\n\n\tif (!spte_has_volatile_bits(old_spte))\n\t\t__update_clear_spte_fast(sptep, new_spte);\n\telse\n\t\told_spte = __update_clear_spte_slow(sptep, new_spte);\n\n\tWARN_ON(spte_to_pfn(old_spte) != spte_to_pfn(new_spte));\n\n\treturn old_spte;\n}\n\n/* Rules for using mmu_spte_update:\n * Update the state bits, it means the mapped pfn is not changed.\n *\n * Whenever we overwrite a writable spte with a read-only one we\n * should flush remote TLBs. Otherwise rmap_write_protect\n * will find a read-only spte, even though the writable spte\n * might be cached on a CPU's TLB, the return value indicates this\n * case.\n *\n * Returns true if the TLB needs to be flushed\n */\nstatic bool mmu_spte_update(u64 *sptep, u64 new_spte)\n{\n\tbool flush = false;\n\tu64 old_spte = mmu_spte_update_no_track(sptep, new_spte);\n\n\tif (!is_shadow_present_pte(old_spte))\n\t\treturn false;\n\n\t/*\n\t * For the spte updated out of mmu-lock is safe, since\n\t * we always atomically update it, see the comments in\n\t * spte_has_volatile_bits().\n\t */\n\tif (spte_can_locklessly_be_made_writable(old_spte) &&\n\t      !is_writable_pte(new_spte))\n\t\tflush = true;\n\n\t/*\n\t * Flush TLB when accessed/dirty states are changed in the page tables,\n\t * to guarantee consistency between TLB and page tables.\n\t */\n\n\tif (is_accessed_spte(old_spte) && !is_accessed_spte(new_spte)) {\n\t\tflush = true;\n\t\tkvm_set_pfn_accessed(spte_to_pfn(old_spte));\n\t}\n\n\tif (is_dirty_spte(old_spte) && !is_dirty_spte(new_spte)) {\n\t\tflush = true;\n\t\tkvm_set_pfn_dirty(spte_to_pfn(old_spte));\n\t}\n\n\treturn flush;\n}\n\n/*\n * Rules for using mmu_spte_clear_track_bits:\n * It sets the sptep from present to nonpresent, and track the\n * state bits, it is used to clear the last level sptep.\n * Returns non-zero if the PTE was previously valid.\n */\nstatic int mmu_spte_clear_track_bits(u64 *sptep)\n{\n\tkvm_pfn_t pfn;\n\tu64 old_spte = *sptep;\n\n\tif (!spte_has_volatile_bits(old_spte))\n\t\t__update_clear_spte_fast(sptep, 0ull);\n\telse\n\t\told_spte = __update_clear_spte_slow(sptep, 0ull);\n\n\tif (!is_shadow_present_pte(old_spte))\n\t\treturn 0;\n\n\tpfn = spte_to_pfn(old_spte);\n\n\t/*\n\t * KVM does not hold the refcount of the page used by\n\t * kvm mmu, before reclaiming the page, we should\n\t * unmap it from mmu first.\n\t */\n\tWARN_ON(!kvm_is_reserved_pfn(pfn) && !page_count(pfn_to_page(pfn)));\n\n\tif (is_accessed_spte(old_spte))\n\t\tkvm_set_pfn_accessed(pfn);\n\n\tif (is_dirty_spte(old_spte))\n\t\tkvm_set_pfn_dirty(pfn);\n\n\treturn 1;\n}\n\n/*\n * Rules for using mmu_spte_clear_no_track:\n * Directly clear spte without caring the state bits of sptep,\n * it is used to set the upper level spte.\n */\nstatic void mmu_spte_clear_no_track(u64 *sptep)\n{\n\t__update_clear_spte_fast(sptep, 0ull);\n}\n\nstatic u64 mmu_spte_get_lockless(u64 *sptep)\n{\n\treturn __get_spte_lockless(sptep);\n}\n\n/* Restore an acc-track PTE back to a regular PTE */\nstatic u64 restore_acc_track_spte(u64 spte)\n{\n\tu64 new_spte = spte;\n\tu64 saved_bits = (spte >> SHADOW_ACC_TRACK_SAVED_BITS_SHIFT)\n\t\t\t & SHADOW_ACC_TRACK_SAVED_BITS_MASK;\n\n\tWARN_ON_ONCE(spte_ad_enabled(spte));\n\tWARN_ON_ONCE(!is_access_track_spte(spte));\n\n\tnew_spte &= ~shadow_acc_track_mask;\n\tnew_spte &= ~(SHADOW_ACC_TRACK_SAVED_BITS_MASK <<\n\t\t      SHADOW_ACC_TRACK_SAVED_BITS_SHIFT);\n\tnew_spte |= saved_bits;\n\n\treturn new_spte;\n}\n\n/* Returns the Accessed status of the PTE and resets it at the same time. */\nstatic bool mmu_spte_age(u64 *sptep)\n{\n\tu64 spte = mmu_spte_get_lockless(sptep);\n\n\tif (!is_accessed_spte(spte))\n\t\treturn false;\n\n\tif (spte_ad_enabled(spte)) {\n\t\tclear_bit((ffs(shadow_accessed_mask) - 1),\n\t\t\t  (unsigned long *)sptep);\n\t} else {\n\t\t/*\n\t\t * Capture the dirty status of the page, so that it doesn't get\n\t\t * lost when the SPTE is marked for access tracking.\n\t\t */\n\t\tif (is_writable_pte(spte))\n\t\t\tkvm_set_pfn_dirty(spte_to_pfn(spte));\n\n\t\tspte = mark_spte_for_access_track(spte);\n\t\tmmu_spte_update_no_track(sptep, spte);\n\t}\n\n\treturn true;\n}\n\nstatic void walk_shadow_page_lockless_begin(struct kvm_vcpu *vcpu)\n{\n\t/*\n\t * Prevent page table teardown by making any free-er wait during\n\t * kvm_flush_remote_tlbs() IPI to all active vcpus.\n\t */\n\tlocal_irq_disable();\n\n\t/*\n\t * Make sure a following spte read is not reordered ahead of the write\n\t * to vcpu->mode.\n\t */\n\tsmp_store_mb(vcpu->mode, READING_SHADOW_PAGE_TABLES);\n}\n\nstatic void walk_shadow_page_lockless_end(struct kvm_vcpu *vcpu)\n{\n\t/*\n\t * Make sure the write to vcpu->mode is not reordered in front of\n\t * reads to sptes.  If it does, kvm_mmu_commit_zap_page() can see us\n\t * OUTSIDE_GUEST_MODE and proceed to free the shadow page table.\n\t */\n\tsmp_store_release(&vcpu->mode, OUTSIDE_GUEST_MODE);\n\tlocal_irq_enable();\n}\n\nstatic int mmu_topup_memory_caches(struct kvm_vcpu *vcpu, bool maybe_indirect)\n{\n\tint r;\n\n\t/* 1 rmap, 1 parent PTE per level, and the prefetched rmaps. */\n\tr = kvm_mmu_topup_memory_cache(&vcpu->arch.mmu_pte_list_desc_cache,\n\t\t\t\t       1 + PT64_ROOT_MAX_LEVEL + PTE_PREFETCH_NUM);\n\tif (r)\n\t\treturn r;\n\tr = kvm_mmu_topup_memory_cache(&vcpu->arch.mmu_shadow_page_cache,\n\t\t\t\t       PT64_ROOT_MAX_LEVEL);\n\tif (r)\n\t\treturn r;\n\tif (maybe_indirect) {\n\t\tr = kvm_mmu_topup_memory_cache(&vcpu->arch.mmu_gfn_array_cache,\n\t\t\t\t\t       PT64_ROOT_MAX_LEVEL);\n\t\tif (r)\n\t\t\treturn r;\n\t}\n\treturn kvm_mmu_topup_memory_cache(&vcpu->arch.mmu_page_header_cache,\n\t\t\t\t\t  PT64_ROOT_MAX_LEVEL);\n}\n\nstatic void mmu_free_memory_caches(struct kvm_vcpu *vcpu)\n{\n\tkvm_mmu_free_memory_cache(&vcpu->arch.mmu_pte_list_desc_cache);\n\tkvm_mmu_free_memory_cache(&vcpu->arch.mmu_shadow_page_cache);\n\tkvm_mmu_free_memory_cache(&vcpu->arch.mmu_gfn_array_cache);\n\tkvm_mmu_free_memory_cache(&vcpu->arch.mmu_page_header_cache);\n}\n\nstatic struct pte_list_desc *mmu_alloc_pte_list_desc(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_mmu_memory_cache_alloc(&vcpu->arch.mmu_pte_list_desc_cache);\n}\n\nstatic void mmu_free_pte_list_desc(struct pte_list_desc *pte_list_desc)\n{\n\tkmem_cache_free(pte_list_desc_cache, pte_list_desc);\n}\n\nstatic gfn_t kvm_mmu_page_get_gfn(struct kvm_mmu_page *sp, int index)\n{\n\tif (!sp->role.direct)\n\t\treturn sp->gfns[index];\n\n\treturn sp->gfn + (index << ((sp->role.level - 1) * PT64_LEVEL_BITS));\n}\n\nstatic void kvm_mmu_page_set_gfn(struct kvm_mmu_page *sp, int index, gfn_t gfn)\n{\n\tif (!sp->role.direct) {\n\t\tsp->gfns[index] = gfn;\n\t\treturn;\n\t}\n\n\tif (WARN_ON(gfn != kvm_mmu_page_get_gfn(sp, index)))\n\t\tpr_err_ratelimited(\"gfn mismatch under direct page %llx \"\n\t\t\t\t   \"(expected %llx, got %llx)\\n\",\n\t\t\t\t   sp->gfn,\n\t\t\t\t   kvm_mmu_page_get_gfn(sp, index), gfn);\n}\n\n/*\n * Return the pointer to the large page information for a given gfn,\n * handling slots that are not large page aligned.\n */\nstatic struct kvm_lpage_info *lpage_info_slot(gfn_t gfn,\n\t\t\t\t\t      struct kvm_memory_slot *slot,\n\t\t\t\t\t      int level)\n{\n\tunsigned long idx;\n\n\tidx = gfn_to_index(gfn, slot->base_gfn, level);\n\treturn &slot->arch.lpage_info[level - 2][idx];\n}\n\nstatic void update_gfn_disallow_lpage_count(struct kvm_memory_slot *slot,\n\t\t\t\t\t    gfn_t gfn, int count)\n{\n\tstruct kvm_lpage_info *linfo;\n\tint i;\n\n\tfor (i = PG_LEVEL_2M; i <= KVM_MAX_HUGEPAGE_LEVEL; ++i) {\n\t\tlinfo = lpage_info_slot(gfn, slot, i);\n\t\tlinfo->disallow_lpage += count;\n\t\tWARN_ON(linfo->disallow_lpage < 0);\n\t}\n}\n\nvoid kvm_mmu_gfn_disallow_lpage(struct kvm_memory_slot *slot, gfn_t gfn)\n{\n\tupdate_gfn_disallow_lpage_count(slot, gfn, 1);\n}\n\nvoid kvm_mmu_gfn_allow_lpage(struct kvm_memory_slot *slot, gfn_t gfn)\n{\n\tupdate_gfn_disallow_lpage_count(slot, gfn, -1);\n}\n\nstatic void account_shadowed(struct kvm *kvm, struct kvm_mmu_page *sp)\n{\n\tstruct kvm_memslots *slots;\n\tstruct kvm_memory_slot *slot;\n\tgfn_t gfn;\n\n\tkvm->arch.indirect_shadow_pages++;\n\tgfn = sp->gfn;\n\tslots = kvm_memslots_for_spte_role(kvm, sp->role);\n\tslot = __gfn_to_memslot(slots, gfn);\n\n\t/* the non-leaf shadow pages are keeping readonly. */\n\tif (sp->role.level > PG_LEVEL_4K)\n\t\treturn kvm_slot_page_track_add_page(kvm, slot, gfn,\n\t\t\t\t\t\t    KVM_PAGE_TRACK_WRITE);\n\n\tkvm_mmu_gfn_disallow_lpage(slot, gfn);\n}\n\nvoid account_huge_nx_page(struct kvm *kvm, struct kvm_mmu_page *sp)\n{\n\tif (sp->lpage_disallowed)\n\t\treturn;\n\n\t++kvm->stat.nx_lpage_splits;\n\tlist_add_tail(&sp->lpage_disallowed_link,\n\t\t      &kvm->arch.lpage_disallowed_mmu_pages);\n\tsp->lpage_disallowed = true;\n}\n\nstatic void unaccount_shadowed(struct kvm *kvm, struct kvm_mmu_page *sp)\n{\n\tstruct kvm_memslots *slots;\n\tstruct kvm_memory_slot *slot;\n\tgfn_t gfn;\n\n\tkvm->arch.indirect_shadow_pages--;\n\tgfn = sp->gfn;\n\tslots = kvm_memslots_for_spte_role(kvm, sp->role);\n\tslot = __gfn_to_memslot(slots, gfn);\n\tif (sp->role.level > PG_LEVEL_4K)\n\t\treturn kvm_slot_page_track_remove_page(kvm, slot, gfn,\n\t\t\t\t\t\t       KVM_PAGE_TRACK_WRITE);\n\n\tkvm_mmu_gfn_allow_lpage(slot, gfn);\n}\n\nvoid unaccount_huge_nx_page(struct kvm *kvm, struct kvm_mmu_page *sp)\n{\n\t--kvm->stat.nx_lpage_splits;\n\tsp->lpage_disallowed = false;\n\tlist_del(&sp->lpage_disallowed_link);\n}\n\nstatic struct kvm_memory_slot *\ngfn_to_memslot_dirty_bitmap(struct kvm_vcpu *vcpu, gfn_t gfn,\n\t\t\t    bool no_dirty_log)\n{\n\tstruct kvm_memory_slot *slot;\n\n\tslot = kvm_vcpu_gfn_to_memslot(vcpu, gfn);\n\tif (!slot || slot->flags & KVM_MEMSLOT_INVALID)\n\t\treturn NULL;\n\tif (no_dirty_log && kvm_slot_dirty_track_enabled(slot))\n\t\treturn NULL;\n\n\treturn slot;\n}\n\n/*\n * About rmap_head encoding:\n *\n * If the bit zero of rmap_head->val is clear, then it points to the only spte\n * in this rmap chain. Otherwise, (rmap_head->val & ~1) points to a struct\n * pte_list_desc containing more mappings.\n */\n\n/*\n * Returns the number of pointers in the rmap chain, not counting the new one.\n */\nstatic int pte_list_add(struct kvm_vcpu *vcpu, u64 *spte,\n\t\t\tstruct kvm_rmap_head *rmap_head)\n{\n\tstruct pte_list_desc *desc;\n\tint i, count = 0;\n\n\tif (!rmap_head->val) {\n\t\trmap_printk(\"pte_list_add: %p %llx 0->1\\n\", spte, *spte);\n\t\trmap_head->val = (unsigned long)spte;\n\t} else if (!(rmap_head->val & 1)) {\n\t\trmap_printk(\"pte_list_add: %p %llx 1->many\\n\", spte, *spte);\n\t\tdesc = mmu_alloc_pte_list_desc(vcpu);\n\t\tdesc->sptes[0] = (u64 *)rmap_head->val;\n\t\tdesc->sptes[1] = spte;\n\t\trmap_head->val = (unsigned long)desc | 1;\n\t\t++count;\n\t} else {\n\t\trmap_printk(\"pte_list_add: %p %llx many->many\\n\", spte, *spte);\n\t\tdesc = (struct pte_list_desc *)(rmap_head->val & ~1ul);\n\t\twhile (desc->sptes[PTE_LIST_EXT-1]) {\n\t\t\tcount += PTE_LIST_EXT;\n\n\t\t\tif (!desc->more) {\n\t\t\t\tdesc->more = mmu_alloc_pte_list_desc(vcpu);\n\t\t\t\tdesc = desc->more;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tdesc = desc->more;\n\t\t}\n\t\tfor (i = 0; desc->sptes[i]; ++i)\n\t\t\t++count;\n\t\tdesc->sptes[i] = spte;\n\t}\n\treturn count;\n}\n\nstatic void\npte_list_desc_remove_entry(struct kvm_rmap_head *rmap_head,\n\t\t\t   struct pte_list_desc *desc, int i,\n\t\t\t   struct pte_list_desc *prev_desc)\n{\n\tint j;\n\n\tfor (j = PTE_LIST_EXT - 1; !desc->sptes[j] && j > i; --j)\n\t\t;\n\tdesc->sptes[i] = desc->sptes[j];\n\tdesc->sptes[j] = NULL;\n\tif (j != 0)\n\t\treturn;\n\tif (!prev_desc && !desc->more)\n\t\trmap_head->val = 0;\n\telse\n\t\tif (prev_desc)\n\t\t\tprev_desc->more = desc->more;\n\t\telse\n\t\t\trmap_head->val = (unsigned long)desc->more | 1;\n\tmmu_free_pte_list_desc(desc);\n}\n\nstatic void __pte_list_remove(u64 *spte, struct kvm_rmap_head *rmap_head)\n{\n\tstruct pte_list_desc *desc;\n\tstruct pte_list_desc *prev_desc;\n\tint i;\n\n\tif (!rmap_head->val) {\n\t\tpr_err(\"%s: %p 0->BUG\\n\", __func__, spte);\n\t\tBUG();\n\t} else if (!(rmap_head->val & 1)) {\n\t\trmap_printk(\"%s:  %p 1->0\\n\", __func__, spte);\n\t\tif ((u64 *)rmap_head->val != spte) {\n\t\t\tpr_err(\"%s:  %p 1->BUG\\n\", __func__, spte);\n\t\t\tBUG();\n\t\t}\n\t\trmap_head->val = 0;\n\t} else {\n\t\trmap_printk(\"%s:  %p many->many\\n\", __func__, spte);\n\t\tdesc = (struct pte_list_desc *)(rmap_head->val & ~1ul);\n\t\tprev_desc = NULL;\n\t\twhile (desc) {\n\t\t\tfor (i = 0; i < PTE_LIST_EXT && desc->sptes[i]; ++i) {\n\t\t\t\tif (desc->sptes[i] == spte) {\n\t\t\t\t\tpte_list_desc_remove_entry(rmap_head,\n\t\t\t\t\t\t\tdesc, i, prev_desc);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t\tprev_desc = desc;\n\t\t\tdesc = desc->more;\n\t\t}\n\t\tpr_err(\"%s: %p many->many\\n\", __func__, spte);\n\t\tBUG();\n\t}\n}\n\nstatic void pte_list_remove(struct kvm_rmap_head *rmap_head, u64 *sptep)\n{\n\tmmu_spte_clear_track_bits(sptep);\n\t__pte_list_remove(sptep, rmap_head);\n}\n\nstatic struct kvm_rmap_head *__gfn_to_rmap(gfn_t gfn, int level,\n\t\t\t\t\t   struct kvm_memory_slot *slot)\n{\n\tunsigned long idx;\n\n\tidx = gfn_to_index(gfn, slot->base_gfn, level);\n\treturn &slot->arch.rmap[level - PG_LEVEL_4K][idx];\n}\n\nstatic struct kvm_rmap_head *gfn_to_rmap(struct kvm *kvm, gfn_t gfn,\n\t\t\t\t\t struct kvm_mmu_page *sp)\n{\n\tstruct kvm_memslots *slots;\n\tstruct kvm_memory_slot *slot;\n\n\tslots = kvm_memslots_for_spte_role(kvm, sp->role);\n\tslot = __gfn_to_memslot(slots, gfn);\n\treturn __gfn_to_rmap(gfn, sp->role.level, slot);\n}\n\nstatic bool rmap_can_add(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_mmu_memory_cache *mc;\n\n\tmc = &vcpu->arch.mmu_pte_list_desc_cache;\n\treturn kvm_mmu_memory_cache_nr_free_objects(mc);\n}\n\nstatic int rmap_add(struct kvm_vcpu *vcpu, u64 *spte, gfn_t gfn)\n{\n\tstruct kvm_mmu_page *sp;\n\tstruct kvm_rmap_head *rmap_head;\n\n\tsp = sptep_to_sp(spte);\n\tkvm_mmu_page_set_gfn(sp, spte - sp->spt, gfn);\n\trmap_head = gfn_to_rmap(vcpu->kvm, gfn, sp);\n\treturn pte_list_add(vcpu, spte, rmap_head);\n}\n\nstatic void rmap_remove(struct kvm *kvm, u64 *spte)\n{\n\tstruct kvm_mmu_page *sp;\n\tgfn_t gfn;\n\tstruct kvm_rmap_head *rmap_head;\n\n\tsp = sptep_to_sp(spte);\n\tgfn = kvm_mmu_page_get_gfn(sp, spte - sp->spt);\n\trmap_head = gfn_to_rmap(kvm, gfn, sp);\n\t__pte_list_remove(spte, rmap_head);\n}\n\n/*\n * Used by the following functions to iterate through the sptes linked by a\n * rmap.  All fields are private and not assumed to be used outside.\n */\nstruct rmap_iterator {\n\t/* private fields */\n\tstruct pte_list_desc *desc;\t/* holds the sptep if not NULL */\n\tint pos;\t\t\t/* index of the sptep */\n};\n\n/*\n * Iteration must be started by this function.  This should also be used after\n * removing/dropping sptes from the rmap link because in such cases the\n * information in the iterator may not be valid.\n *\n * Returns sptep if found, NULL otherwise.\n */\nstatic u64 *rmap_get_first(struct kvm_rmap_head *rmap_head,\n\t\t\t   struct rmap_iterator *iter)\n{\n\tu64 *sptep;\n\n\tif (!rmap_head->val)\n\t\treturn NULL;\n\n\tif (!(rmap_head->val & 1)) {\n\t\titer->desc = NULL;\n\t\tsptep = (u64 *)rmap_head->val;\n\t\tgoto out;\n\t}\n\n\titer->desc = (struct pte_list_desc *)(rmap_head->val & ~1ul);\n\titer->pos = 0;\n\tsptep = iter->desc->sptes[iter->pos];\nout:\n\tBUG_ON(!is_shadow_present_pte(*sptep));\n\treturn sptep;\n}\n\n/*\n * Must be used with a valid iterator: e.g. after rmap_get_first().\n *\n * Returns sptep if found, NULL otherwise.\n */\nstatic u64 *rmap_get_next(struct rmap_iterator *iter)\n{\n\tu64 *sptep;\n\n\tif (iter->desc) {\n\t\tif (iter->pos < PTE_LIST_EXT - 1) {\n\t\t\t++iter->pos;\n\t\t\tsptep = iter->desc->sptes[iter->pos];\n\t\t\tif (sptep)\n\t\t\t\tgoto out;\n\t\t}\n\n\t\titer->desc = iter->desc->more;\n\n\t\tif (iter->desc) {\n\t\t\titer->pos = 0;\n\t\t\t/* desc->sptes[0] cannot be NULL */\n\t\t\tsptep = iter->desc->sptes[iter->pos];\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\treturn NULL;\nout:\n\tBUG_ON(!is_shadow_present_pte(*sptep));\n\treturn sptep;\n}\n\n#define for_each_rmap_spte(_rmap_head_, _iter_, _spte_)\t\t\t\\\n\tfor (_spte_ = rmap_get_first(_rmap_head_, _iter_);\t\t\\\n\t     _spte_; _spte_ = rmap_get_next(_iter_))\n\nstatic void drop_spte(struct kvm *kvm, u64 *sptep)\n{\n\tif (mmu_spte_clear_track_bits(sptep))\n\t\trmap_remove(kvm, sptep);\n}\n\n\nstatic bool __drop_large_spte(struct kvm *kvm, u64 *sptep)\n{\n\tif (is_large_pte(*sptep)) {\n\t\tWARN_ON(sptep_to_sp(sptep)->role.level == PG_LEVEL_4K);\n\t\tdrop_spte(kvm, sptep);\n\t\t--kvm->stat.lpages;\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic void drop_large_spte(struct kvm_vcpu *vcpu, u64 *sptep)\n{\n\tif (__drop_large_spte(vcpu->kvm, sptep)) {\n\t\tstruct kvm_mmu_page *sp = sptep_to_sp(sptep);\n\n\t\tkvm_flush_remote_tlbs_with_address(vcpu->kvm, sp->gfn,\n\t\t\tKVM_PAGES_PER_HPAGE(sp->role.level));\n\t}\n}\n\n/*\n * Write-protect on the specified @sptep, @pt_protect indicates whether\n * spte write-protection is caused by protecting shadow page table.\n *\n * Note: write protection is difference between dirty logging and spte\n * protection:\n * - for dirty logging, the spte can be set to writable at anytime if\n *   its dirty bitmap is properly set.\n * - for spte protection, the spte can be writable only after unsync-ing\n *   shadow page.\n *\n * Return true if tlb need be flushed.\n */\nstatic bool spte_write_protect(u64 *sptep, bool pt_protect)\n{\n\tu64 spte = *sptep;\n\n\tif (!is_writable_pte(spte) &&\n\t      !(pt_protect && spte_can_locklessly_be_made_writable(spte)))\n\t\treturn false;\n\n\trmap_printk(\"rmap_write_protect: spte %p %llx\\n\", sptep, *sptep);\n\n\tif (pt_protect)\n\t\tspte &= ~SPTE_MMU_WRITEABLE;\n\tspte = spte & ~PT_WRITABLE_MASK;\n\n\treturn mmu_spte_update(sptep, spte);\n}\n\nstatic bool __rmap_write_protect(struct kvm *kvm,\n\t\t\t\t struct kvm_rmap_head *rmap_head,\n\t\t\t\t bool pt_protect)\n{\n\tu64 *sptep;\n\tstruct rmap_iterator iter;\n\tbool flush = false;\n\n\tfor_each_rmap_spte(rmap_head, &iter, sptep)\n\t\tflush |= spte_write_protect(sptep, pt_protect);\n\n\treturn flush;\n}\n\nstatic bool spte_clear_dirty(u64 *sptep)\n{\n\tu64 spte = *sptep;\n\n\trmap_printk(\"rmap_clear_dirty: spte %p %llx\\n\", sptep, *sptep);\n\n\tMMU_WARN_ON(!spte_ad_enabled(spte));\n\tspte &= ~shadow_dirty_mask;\n\treturn mmu_spte_update(sptep, spte);\n}\n\nstatic bool spte_wrprot_for_clear_dirty(u64 *sptep)\n{\n\tbool was_writable = test_and_clear_bit(PT_WRITABLE_SHIFT,\n\t\t\t\t\t       (unsigned long *)sptep);\n\tif (was_writable && !spte_ad_enabled(*sptep))\n\t\tkvm_set_pfn_dirty(spte_to_pfn(*sptep));\n\n\treturn was_writable;\n}\n\n/*\n * Gets the GFN ready for another round of dirty logging by clearing the\n *\t- D bit on ad-enabled SPTEs, and\n *\t- W bit on ad-disabled SPTEs.\n * Returns true iff any D or W bits were cleared.\n */\nstatic bool __rmap_clear_dirty(struct kvm *kvm, struct kvm_rmap_head *rmap_head)\n{\n\tu64 *sptep;\n\tstruct rmap_iterator iter;\n\tbool flush = false;\n\n\tfor_each_rmap_spte(rmap_head, &iter, sptep)\n\t\tif (spte_ad_need_write_protect(*sptep))\n\t\t\tflush |= spte_wrprot_for_clear_dirty(sptep);\n\t\telse\n\t\t\tflush |= spte_clear_dirty(sptep);\n\n\treturn flush;\n}\n\nstatic bool spte_set_dirty(u64 *sptep)\n{\n\tu64 spte = *sptep;\n\n\trmap_printk(\"rmap_set_dirty: spte %p %llx\\n\", sptep, *sptep);\n\n\t/*\n\t * Similar to the !kvm_x86_ops.slot_disable_log_dirty case,\n\t * do not bother adding back write access to pages marked\n\t * SPTE_AD_WRPROT_ONLY_MASK.\n\t */\n\tspte |= shadow_dirty_mask;\n\n\treturn mmu_spte_update(sptep, spte);\n}\n\nstatic bool __rmap_set_dirty(struct kvm *kvm, struct kvm_rmap_head *rmap_head)\n{\n\tu64 *sptep;\n\tstruct rmap_iterator iter;\n\tbool flush = false;\n\n\tfor_each_rmap_spte(rmap_head, &iter, sptep)\n\t\tif (spte_ad_enabled(*sptep))\n\t\t\tflush |= spte_set_dirty(sptep);\n\n\treturn flush;\n}\n\n/**\n * kvm_mmu_write_protect_pt_masked - write protect selected PT level pages\n * @kvm: kvm instance\n * @slot: slot to protect\n * @gfn_offset: start of the BITS_PER_LONG pages we care about\n * @mask: indicates which pages we should protect\n *\n * Used when we do not need to care about huge page mappings: e.g. during dirty\n * logging we do not have any such mappings.\n */\nstatic void kvm_mmu_write_protect_pt_masked(struct kvm *kvm,\n\t\t\t\t     struct kvm_memory_slot *slot,\n\t\t\t\t     gfn_t gfn_offset, unsigned long mask)\n{\n\tstruct kvm_rmap_head *rmap_head;\n\n\tif (kvm->arch.tdp_mmu_enabled)\n\t\tkvm_tdp_mmu_clear_dirty_pt_masked(kvm, slot,\n\t\t\t\tslot->base_gfn + gfn_offset, mask, true);\n\twhile (mask) {\n\t\trmap_head = __gfn_to_rmap(slot->base_gfn + gfn_offset + __ffs(mask),\n\t\t\t\t\t  PG_LEVEL_4K, slot);\n\t\t__rmap_write_protect(kvm, rmap_head, false);\n\n\t\t/* clear the first set bit */\n\t\tmask &= mask - 1;\n\t}\n}\n\n/**\n * kvm_mmu_clear_dirty_pt_masked - clear MMU D-bit for PT level pages, or write\n * protect the page if the D-bit isn't supported.\n * @kvm: kvm instance\n * @slot: slot to clear D-bit\n * @gfn_offset: start of the BITS_PER_LONG pages we care about\n * @mask: indicates which pages we should clear D-bit\n *\n * Used for PML to re-log the dirty GPAs after userspace querying dirty_bitmap.\n */\nvoid kvm_mmu_clear_dirty_pt_masked(struct kvm *kvm,\n\t\t\t\t     struct kvm_memory_slot *slot,\n\t\t\t\t     gfn_t gfn_offset, unsigned long mask)\n{\n\tstruct kvm_rmap_head *rmap_head;\n\n\tif (kvm->arch.tdp_mmu_enabled)\n\t\tkvm_tdp_mmu_clear_dirty_pt_masked(kvm, slot,\n\t\t\t\tslot->base_gfn + gfn_offset, mask, false);\n\twhile (mask) {\n\t\trmap_head = __gfn_to_rmap(slot->base_gfn + gfn_offset + __ffs(mask),\n\t\t\t\t\t  PG_LEVEL_4K, slot);\n\t\t__rmap_clear_dirty(kvm, rmap_head);\n\n\t\t/* clear the first set bit */\n\t\tmask &= mask - 1;\n\t}\n}\nEXPORT_SYMBOL_GPL(kvm_mmu_clear_dirty_pt_masked);\n\n/**\n * kvm_arch_mmu_enable_log_dirty_pt_masked - enable dirty logging for selected\n * PT level pages.\n *\n * It calls kvm_mmu_write_protect_pt_masked to write protect selected pages to\n * enable dirty logging for them.\n *\n * Used when we do not need to care about huge page mappings: e.g. during dirty\n * logging we do not have any such mappings.\n */\nvoid kvm_arch_mmu_enable_log_dirty_pt_masked(struct kvm *kvm,\n\t\t\t\tstruct kvm_memory_slot *slot,\n\t\t\t\tgfn_t gfn_offset, unsigned long mask)\n{\n\tif (kvm_x86_ops.enable_log_dirty_pt_masked)\n\t\tkvm_x86_ops.enable_log_dirty_pt_masked(kvm, slot, gfn_offset,\n\t\t\t\tmask);\n\telse\n\t\tkvm_mmu_write_protect_pt_masked(kvm, slot, gfn_offset, mask);\n}\n\nint kvm_cpu_dirty_log_size(void)\n{\n\tif (kvm_x86_ops.cpu_dirty_log_size)\n\t\treturn kvm_x86_ops.cpu_dirty_log_size();\n\n\treturn 0;\n}\n\nbool kvm_mmu_slot_gfn_write_protect(struct kvm *kvm,\n\t\t\t\t    struct kvm_memory_slot *slot, u64 gfn)\n{\n\tstruct kvm_rmap_head *rmap_head;\n\tint i;\n\tbool write_protected = false;\n\n\tfor (i = PG_LEVEL_4K; i <= KVM_MAX_HUGEPAGE_LEVEL; ++i) {\n\t\trmap_head = __gfn_to_rmap(gfn, i, slot);\n\t\twrite_protected |= __rmap_write_protect(kvm, rmap_head, true);\n\t}\n\n\tif (kvm->arch.tdp_mmu_enabled)\n\t\twrite_protected |=\n\t\t\tkvm_tdp_mmu_write_protect_gfn(kvm, slot, gfn);\n\n\treturn write_protected;\n}\n\nstatic bool rmap_write_protect(struct kvm_vcpu *vcpu, u64 gfn)\n{\n\tstruct kvm_memory_slot *slot;\n\n\tslot = kvm_vcpu_gfn_to_memslot(vcpu, gfn);\n\treturn kvm_mmu_slot_gfn_write_protect(vcpu->kvm, slot, gfn);\n}\n\nstatic bool kvm_zap_rmapp(struct kvm *kvm, struct kvm_rmap_head *rmap_head)\n{\n\tu64 *sptep;\n\tstruct rmap_iterator iter;\n\tbool flush = false;\n\n\twhile ((sptep = rmap_get_first(rmap_head, &iter))) {\n\t\trmap_printk(\"%s: spte %p %llx.\\n\", __func__, sptep, *sptep);\n\n\t\tpte_list_remove(rmap_head, sptep);\n\t\tflush = true;\n\t}\n\n\treturn flush;\n}\n\nstatic int kvm_unmap_rmapp(struct kvm *kvm, struct kvm_rmap_head *rmap_head,\n\t\t\t   struct kvm_memory_slot *slot, gfn_t gfn, int level,\n\t\t\t   unsigned long data)\n{\n\treturn kvm_zap_rmapp(kvm, rmap_head);\n}\n\nstatic int kvm_set_pte_rmapp(struct kvm *kvm, struct kvm_rmap_head *rmap_head,\n\t\t\t     struct kvm_memory_slot *slot, gfn_t gfn, int level,\n\t\t\t     unsigned long data)\n{\n\tu64 *sptep;\n\tstruct rmap_iterator iter;\n\tint need_flush = 0;\n\tu64 new_spte;\n\tpte_t *ptep = (pte_t *)data;\n\tkvm_pfn_t new_pfn;\n\n\tWARN_ON(pte_huge(*ptep));\n\tnew_pfn = pte_pfn(*ptep);\n\nrestart:\n\tfor_each_rmap_spte(rmap_head, &iter, sptep) {\n\t\trmap_printk(\"kvm_set_pte_rmapp: spte %p %llx gfn %llx (%d)\\n\",\n\t\t\t    sptep, *sptep, gfn, level);\n\n\t\tneed_flush = 1;\n\n\t\tif (pte_write(*ptep)) {\n\t\t\tpte_list_remove(rmap_head, sptep);\n\t\t\tgoto restart;\n\t\t} else {\n\t\t\tnew_spte = kvm_mmu_changed_pte_notifier_make_spte(\n\t\t\t\t\t*sptep, new_pfn);\n\n\t\t\tmmu_spte_clear_track_bits(sptep);\n\t\t\tmmu_spte_set(sptep, new_spte);\n\t\t}\n\t}\n\n\tif (need_flush && kvm_available_flush_tlb_with_range()) {\n\t\tkvm_flush_remote_tlbs_with_address(kvm, gfn, 1);\n\t\treturn 0;\n\t}\n\n\treturn need_flush;\n}\n\nstruct slot_rmap_walk_iterator {\n\t/* input fields. */\n\tstruct kvm_memory_slot *slot;\n\tgfn_t start_gfn;\n\tgfn_t end_gfn;\n\tint start_level;\n\tint end_level;\n\n\t/* output fields. */\n\tgfn_t gfn;\n\tstruct kvm_rmap_head *rmap;\n\tint level;\n\n\t/* private field. */\n\tstruct kvm_rmap_head *end_rmap;\n};\n\nstatic void\nrmap_walk_init_level(struct slot_rmap_walk_iterator *iterator, int level)\n{\n\titerator->level = level;\n\titerator->gfn = iterator->start_gfn;\n\titerator->rmap = __gfn_to_rmap(iterator->gfn, level, iterator->slot);\n\titerator->end_rmap = __gfn_to_rmap(iterator->end_gfn, level,\n\t\t\t\t\t   iterator->slot);\n}\n\nstatic void\nslot_rmap_walk_init(struct slot_rmap_walk_iterator *iterator,\n\t\t    struct kvm_memory_slot *slot, int start_level,\n\t\t    int end_level, gfn_t start_gfn, gfn_t end_gfn)\n{\n\titerator->slot = slot;\n\titerator->start_level = start_level;\n\titerator->end_level = end_level;\n\titerator->start_gfn = start_gfn;\n\titerator->end_gfn = end_gfn;\n\n\trmap_walk_init_level(iterator, iterator->start_level);\n}\n\nstatic bool slot_rmap_walk_okay(struct slot_rmap_walk_iterator *iterator)\n{\n\treturn !!iterator->rmap;\n}\n\nstatic void slot_rmap_walk_next(struct slot_rmap_walk_iterator *iterator)\n{\n\tif (++iterator->rmap <= iterator->end_rmap) {\n\t\titerator->gfn += (1UL << KVM_HPAGE_GFN_SHIFT(iterator->level));\n\t\treturn;\n\t}\n\n\tif (++iterator->level > iterator->end_level) {\n\t\titerator->rmap = NULL;\n\t\treturn;\n\t}\n\n\trmap_walk_init_level(iterator, iterator->level);\n}\n\n#define for_each_slot_rmap_range(_slot_, _start_level_, _end_level_,\t\\\n\t   _start_gfn, _end_gfn, _iter_)\t\t\t\t\\\n\tfor (slot_rmap_walk_init(_iter_, _slot_, _start_level_,\t\t\\\n\t\t\t\t _end_level_, _start_gfn, _end_gfn);\t\\\n\t     slot_rmap_walk_okay(_iter_);\t\t\t\t\\\n\t     slot_rmap_walk_next(_iter_))\n\nstatic int kvm_handle_hva_range(struct kvm *kvm,\n\t\t\t\tunsigned long start,\n\t\t\t\tunsigned long end,\n\t\t\t\tunsigned long data,\n\t\t\t\tint (*handler)(struct kvm *kvm,\n\t\t\t\t\t       struct kvm_rmap_head *rmap_head,\n\t\t\t\t\t       struct kvm_memory_slot *slot,\n\t\t\t\t\t       gfn_t gfn,\n\t\t\t\t\t       int level,\n\t\t\t\t\t       unsigned long data))\n{\n\tstruct kvm_memslots *slots;\n\tstruct kvm_memory_slot *memslot;\n\tstruct slot_rmap_walk_iterator iterator;\n\tint ret = 0;\n\tint i;\n\n\tfor (i = 0; i < KVM_ADDRESS_SPACE_NUM; i++) {\n\t\tslots = __kvm_memslots(kvm, i);\n\t\tkvm_for_each_memslot(memslot, slots) {\n\t\t\tunsigned long hva_start, hva_end;\n\t\t\tgfn_t gfn_start, gfn_end;\n\n\t\t\thva_start = max(start, memslot->userspace_addr);\n\t\t\thva_end = min(end, memslot->userspace_addr +\n\t\t\t\t      (memslot->npages << PAGE_SHIFT));\n\t\t\tif (hva_start >= hva_end)\n\t\t\t\tcontinue;\n\t\t\t/*\n\t\t\t * {gfn(page) | page intersects with [hva_start, hva_end)} =\n\t\t\t * {gfn_start, gfn_start+1, ..., gfn_end-1}.\n\t\t\t */\n\t\t\tgfn_start = hva_to_gfn_memslot(hva_start, memslot);\n\t\t\tgfn_end = hva_to_gfn_memslot(hva_end + PAGE_SIZE - 1, memslot);\n\n\t\t\tfor_each_slot_rmap_range(memslot, PG_LEVEL_4K,\n\t\t\t\t\t\t KVM_MAX_HUGEPAGE_LEVEL,\n\t\t\t\t\t\t gfn_start, gfn_end - 1,\n\t\t\t\t\t\t &iterator)\n\t\t\t\tret |= handler(kvm, iterator.rmap, memslot,\n\t\t\t\t\t       iterator.gfn, iterator.level, data);\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nstatic int kvm_handle_hva(struct kvm *kvm, unsigned long hva,\n\t\t\t  unsigned long data,\n\t\t\t  int (*handler)(struct kvm *kvm,\n\t\t\t\t\t struct kvm_rmap_head *rmap_head,\n\t\t\t\t\t struct kvm_memory_slot *slot,\n\t\t\t\t\t gfn_t gfn, int level,\n\t\t\t\t\t unsigned long data))\n{\n\treturn kvm_handle_hva_range(kvm, hva, hva + 1, data, handler);\n}\n\nint kvm_unmap_hva_range(struct kvm *kvm, unsigned long start, unsigned long end,\n\t\t\tunsigned flags)\n{\n\tint r;\n\n\tr = kvm_handle_hva_range(kvm, start, end, 0, kvm_unmap_rmapp);\n\n\tif (kvm->arch.tdp_mmu_enabled)\n\t\tr |= kvm_tdp_mmu_zap_hva_range(kvm, start, end);\n\n\treturn r;\n}\n\nint kvm_set_spte_hva(struct kvm *kvm, unsigned long hva, pte_t pte)\n{\n\tint r;\n\n\tr = kvm_handle_hva(kvm, hva, (unsigned long)&pte, kvm_set_pte_rmapp);\n\n\tif (kvm->arch.tdp_mmu_enabled)\n\t\tr |= kvm_tdp_mmu_set_spte_hva(kvm, hva, &pte);\n\n\treturn r;\n}\n\nstatic int kvm_age_rmapp(struct kvm *kvm, struct kvm_rmap_head *rmap_head,\n\t\t\t struct kvm_memory_slot *slot, gfn_t gfn, int level,\n\t\t\t unsigned long data)\n{\n\tu64 *sptep;\n\tstruct rmap_iterator iter;\n\tint young = 0;\n\n\tfor_each_rmap_spte(rmap_head, &iter, sptep)\n\t\tyoung |= mmu_spte_age(sptep);\n\n\ttrace_kvm_age_page(gfn, level, slot, young);\n\treturn young;\n}\n\nstatic int kvm_test_age_rmapp(struct kvm *kvm, struct kvm_rmap_head *rmap_head,\n\t\t\t      struct kvm_memory_slot *slot, gfn_t gfn,\n\t\t\t      int level, unsigned long data)\n{\n\tu64 *sptep;\n\tstruct rmap_iterator iter;\n\n\tfor_each_rmap_spte(rmap_head, &iter, sptep)\n\t\tif (is_accessed_spte(*sptep))\n\t\t\treturn 1;\n\treturn 0;\n}\n\n#define RMAP_RECYCLE_THRESHOLD 1000\n\nstatic void rmap_recycle(struct kvm_vcpu *vcpu, u64 *spte, gfn_t gfn)\n{\n\tstruct kvm_rmap_head *rmap_head;\n\tstruct kvm_mmu_page *sp;\n\n\tsp = sptep_to_sp(spte);\n\n\trmap_head = gfn_to_rmap(vcpu->kvm, gfn, sp);\n\n\tkvm_unmap_rmapp(vcpu->kvm, rmap_head, NULL, gfn, sp->role.level, 0);\n\tkvm_flush_remote_tlbs_with_address(vcpu->kvm, sp->gfn,\n\t\t\tKVM_PAGES_PER_HPAGE(sp->role.level));\n}\n\nint kvm_age_hva(struct kvm *kvm, unsigned long start, unsigned long end)\n{\n\tint young = false;\n\n\tyoung = kvm_handle_hva_range(kvm, start, end, 0, kvm_age_rmapp);\n\tif (kvm->arch.tdp_mmu_enabled)\n\t\tyoung |= kvm_tdp_mmu_age_hva_range(kvm, start, end);\n\n\treturn young;\n}\n\nint kvm_test_age_hva(struct kvm *kvm, unsigned long hva)\n{\n\tint young = false;\n\n\tyoung = kvm_handle_hva(kvm, hva, 0, kvm_test_age_rmapp);\n\tif (kvm->arch.tdp_mmu_enabled)\n\t\tyoung |= kvm_tdp_mmu_test_age_hva(kvm, hva);\n\n\treturn young;\n}\n\n#ifdef MMU_DEBUG\nstatic int is_empty_shadow_page(u64 *spt)\n{\n\tu64 *pos;\n\tu64 *end;\n\n\tfor (pos = spt, end = pos + PAGE_SIZE / sizeof(u64); pos != end; pos++)\n\t\tif (is_shadow_present_pte(*pos)) {\n\t\t\tprintk(KERN_ERR \"%s: %p %llx\\n\", __func__,\n\t\t\t       pos, *pos);\n\t\t\treturn 0;\n\t\t}\n\treturn 1;\n}\n#endif\n\n/*\n * This value is the sum of all of the kvm instances's\n * kvm->arch.n_used_mmu_pages values.  We need a global,\n * aggregate version in order to make the slab shrinker\n * faster\n */\nstatic inline void kvm_mod_used_mmu_pages(struct kvm *kvm, unsigned long nr)\n{\n\tkvm->arch.n_used_mmu_pages += nr;\n\tpercpu_counter_add(&kvm_total_used_mmu_pages, nr);\n}\n\nstatic void kvm_mmu_free_page(struct kvm_mmu_page *sp)\n{\n\tMMU_WARN_ON(!is_empty_shadow_page(sp->spt));\n\thlist_del(&sp->hash_link);\n\tlist_del(&sp->link);\n\tfree_page((unsigned long)sp->spt);\n\tif (!sp->role.direct)\n\t\tfree_page((unsigned long)sp->gfns);\n\tkmem_cache_free(mmu_page_header_cache, sp);\n}\n\nstatic unsigned kvm_page_table_hashfn(gfn_t gfn)\n{\n\treturn hash_64(gfn, KVM_MMU_HASH_SHIFT);\n}\n\nstatic void mmu_page_add_parent_pte(struct kvm_vcpu *vcpu,\n\t\t\t\t    struct kvm_mmu_page *sp, u64 *parent_pte)\n{\n\tif (!parent_pte)\n\t\treturn;\n\n\tpte_list_add(vcpu, parent_pte, &sp->parent_ptes);\n}\n\nstatic void mmu_page_remove_parent_pte(struct kvm_mmu_page *sp,\n\t\t\t\t       u64 *parent_pte)\n{\n\t__pte_list_remove(parent_pte, &sp->parent_ptes);\n}\n\nstatic void drop_parent_pte(struct kvm_mmu_page *sp,\n\t\t\t    u64 *parent_pte)\n{\n\tmmu_page_remove_parent_pte(sp, parent_pte);\n\tmmu_spte_clear_no_track(parent_pte);\n}\n\nstatic struct kvm_mmu_page *kvm_mmu_alloc_page(struct kvm_vcpu *vcpu, int direct)\n{\n\tstruct kvm_mmu_page *sp;\n\n\tsp = kvm_mmu_memory_cache_alloc(&vcpu->arch.mmu_page_header_cache);\n\tsp->spt = kvm_mmu_memory_cache_alloc(&vcpu->arch.mmu_shadow_page_cache);\n\tif (!direct)\n\t\tsp->gfns = kvm_mmu_memory_cache_alloc(&vcpu->arch.mmu_gfn_array_cache);\n\tset_page_private(virt_to_page(sp->spt), (unsigned long)sp);\n\n\t/*\n\t * active_mmu_pages must be a FIFO list, as kvm_zap_obsolete_pages()\n\t * depends on valid pages being added to the head of the list.  See\n\t * comments in kvm_zap_obsolete_pages().\n\t */\n\tsp->mmu_valid_gen = vcpu->kvm->arch.mmu_valid_gen;\n\tlist_add(&sp->link, &vcpu->kvm->arch.active_mmu_pages);\n\tkvm_mod_used_mmu_pages(vcpu->kvm, +1);\n\treturn sp;\n}\n\nstatic void mark_unsync(u64 *spte);\nstatic void kvm_mmu_mark_parents_unsync(struct kvm_mmu_page *sp)\n{\n\tu64 *sptep;\n\tstruct rmap_iterator iter;\n\n\tfor_each_rmap_spte(&sp->parent_ptes, &iter, sptep) {\n\t\tmark_unsync(sptep);\n\t}\n}\n\nstatic void mark_unsync(u64 *spte)\n{\n\tstruct kvm_mmu_page *sp;\n\tunsigned int index;\n\n\tsp = sptep_to_sp(spte);\n\tindex = spte - sp->spt;\n\tif (__test_and_set_bit(index, sp->unsync_child_bitmap))\n\t\treturn;\n\tif (sp->unsync_children++)\n\t\treturn;\n\tkvm_mmu_mark_parents_unsync(sp);\n}\n\nstatic int nonpaging_sync_page(struct kvm_vcpu *vcpu,\n\t\t\t       struct kvm_mmu_page *sp)\n{\n\treturn 0;\n}\n\nstatic void nonpaging_update_pte(struct kvm_vcpu *vcpu,\n\t\t\t\t struct kvm_mmu_page *sp, u64 *spte,\n\t\t\t\t const void *pte)\n{\n\tWARN_ON(1);\n}\n\n#define KVM_PAGE_ARRAY_NR 16\n\nstruct kvm_mmu_pages {\n\tstruct mmu_page_and_offset {\n\t\tstruct kvm_mmu_page *sp;\n\t\tunsigned int idx;\n\t} page[KVM_PAGE_ARRAY_NR];\n\tunsigned int nr;\n};\n\nstatic int mmu_pages_add(struct kvm_mmu_pages *pvec, struct kvm_mmu_page *sp,\n\t\t\t int idx)\n{\n\tint i;\n\n\tif (sp->unsync)\n\t\tfor (i=0; i < pvec->nr; i++)\n\t\t\tif (pvec->page[i].sp == sp)\n\t\t\t\treturn 0;\n\n\tpvec->page[pvec->nr].sp = sp;\n\tpvec->page[pvec->nr].idx = idx;\n\tpvec->nr++;\n\treturn (pvec->nr == KVM_PAGE_ARRAY_NR);\n}\n\nstatic inline void clear_unsync_child_bit(struct kvm_mmu_page *sp, int idx)\n{\n\t--sp->unsync_children;\n\tWARN_ON((int)sp->unsync_children < 0);\n\t__clear_bit(idx, sp->unsync_child_bitmap);\n}\n\nstatic int __mmu_unsync_walk(struct kvm_mmu_page *sp,\n\t\t\t   struct kvm_mmu_pages *pvec)\n{\n\tint i, ret, nr_unsync_leaf = 0;\n\n\tfor_each_set_bit(i, sp->unsync_child_bitmap, 512) {\n\t\tstruct kvm_mmu_page *child;\n\t\tu64 ent = sp->spt[i];\n\n\t\tif (!is_shadow_present_pte(ent) || is_large_pte(ent)) {\n\t\t\tclear_unsync_child_bit(sp, i);\n\t\t\tcontinue;\n\t\t}\n\n\t\tchild = to_shadow_page(ent & PT64_BASE_ADDR_MASK);\n\n\t\tif (child->unsync_children) {\n\t\t\tif (mmu_pages_add(pvec, child, i))\n\t\t\t\treturn -ENOSPC;\n\n\t\t\tret = __mmu_unsync_walk(child, pvec);\n\t\t\tif (!ret) {\n\t\t\t\tclear_unsync_child_bit(sp, i);\n\t\t\t\tcontinue;\n\t\t\t} else if (ret > 0) {\n\t\t\t\tnr_unsync_leaf += ret;\n\t\t\t} else\n\t\t\t\treturn ret;\n\t\t} else if (child->unsync) {\n\t\t\tnr_unsync_leaf++;\n\t\t\tif (mmu_pages_add(pvec, child, i))\n\t\t\t\treturn -ENOSPC;\n\t\t} else\n\t\t\tclear_unsync_child_bit(sp, i);\n\t}\n\n\treturn nr_unsync_leaf;\n}\n\n#define INVALID_INDEX (-1)\n\nstatic int mmu_unsync_walk(struct kvm_mmu_page *sp,\n\t\t\t   struct kvm_mmu_pages *pvec)\n{\n\tpvec->nr = 0;\n\tif (!sp->unsync_children)\n\t\treturn 0;\n\n\tmmu_pages_add(pvec, sp, INVALID_INDEX);\n\treturn __mmu_unsync_walk(sp, pvec);\n}\n\nstatic void kvm_unlink_unsync_page(struct kvm *kvm, struct kvm_mmu_page *sp)\n{\n\tWARN_ON(!sp->unsync);\n\ttrace_kvm_mmu_sync_page(sp);\n\tsp->unsync = 0;\n\t--kvm->stat.mmu_unsync;\n}\n\nstatic bool kvm_mmu_prepare_zap_page(struct kvm *kvm, struct kvm_mmu_page *sp,\n\t\t\t\t     struct list_head *invalid_list);\nstatic void kvm_mmu_commit_zap_page(struct kvm *kvm,\n\t\t\t\t    struct list_head *invalid_list);\n\n#define for_each_valid_sp(_kvm, _sp, _list)\t\t\t\t\\\n\thlist_for_each_entry(_sp, _list, hash_link)\t\t\t\\\n\t\tif (is_obsolete_sp((_kvm), (_sp))) {\t\t\t\\\n\t\t} else\n\n#define for_each_gfn_indirect_valid_sp(_kvm, _sp, _gfn)\t\t\t\\\n\tfor_each_valid_sp(_kvm, _sp,\t\t\t\t\t\\\n\t  &(_kvm)->arch.mmu_page_hash[kvm_page_table_hashfn(_gfn)])\t\\\n\t\tif ((_sp)->gfn != (_gfn) || (_sp)->role.direct) {} else\n\nstatic inline bool is_ept_sp(struct kvm_mmu_page *sp)\n{\n\treturn sp->role.cr0_wp && sp->role.smap_andnot_wp;\n}\n\n/* @sp->gfn should be write-protected at the call site */\nstatic bool __kvm_sync_page(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp,\n\t\t\t    struct list_head *invalid_list)\n{\n\tif ((!is_ept_sp(sp) && sp->role.gpte_is_8_bytes != !!is_pae(vcpu)) ||\n\t    vcpu->arch.mmu->sync_page(vcpu, sp) == 0) {\n\t\tkvm_mmu_prepare_zap_page(vcpu->kvm, sp, invalid_list);\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic bool kvm_mmu_remote_flush_or_zap(struct kvm *kvm,\n\t\t\t\t\tstruct list_head *invalid_list,\n\t\t\t\t\tbool remote_flush)\n{\n\tif (!remote_flush && list_empty(invalid_list))\n\t\treturn false;\n\n\tif (!list_empty(invalid_list))\n\t\tkvm_mmu_commit_zap_page(kvm, invalid_list);\n\telse\n\t\tkvm_flush_remote_tlbs(kvm);\n\treturn true;\n}\n\nstatic void kvm_mmu_flush_or_zap(struct kvm_vcpu *vcpu,\n\t\t\t\t struct list_head *invalid_list,\n\t\t\t\t bool remote_flush, bool local_flush)\n{\n\tif (kvm_mmu_remote_flush_or_zap(vcpu->kvm, invalid_list, remote_flush))\n\t\treturn;\n\n\tif (local_flush)\n\t\tkvm_make_request(KVM_REQ_TLB_FLUSH_CURRENT, vcpu);\n}\n\n#ifdef CONFIG_KVM_MMU_AUDIT\n#include \"mmu_audit.c\"\n#else\nstatic void kvm_mmu_audit(struct kvm_vcpu *vcpu, int point) { }\nstatic void mmu_audit_disable(void) { }\n#endif\n\nstatic bool is_obsolete_sp(struct kvm *kvm, struct kvm_mmu_page *sp)\n{\n\treturn sp->role.invalid ||\n\t       unlikely(sp->mmu_valid_gen != kvm->arch.mmu_valid_gen);\n}\n\nstatic bool kvm_sync_page(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp,\n\t\t\t struct list_head *invalid_list)\n{\n\tkvm_unlink_unsync_page(vcpu->kvm, sp);\n\treturn __kvm_sync_page(vcpu, sp, invalid_list);\n}\n\n/* @gfn should be write-protected at the call site */\nstatic bool kvm_sync_pages(struct kvm_vcpu *vcpu, gfn_t gfn,\n\t\t\t   struct list_head *invalid_list)\n{\n\tstruct kvm_mmu_page *s;\n\tbool ret = false;\n\n\tfor_each_gfn_indirect_valid_sp(vcpu->kvm, s, gfn) {\n\t\tif (!s->unsync)\n\t\t\tcontinue;\n\n\t\tWARN_ON(s->role.level != PG_LEVEL_4K);\n\t\tret |= kvm_sync_page(vcpu, s, invalid_list);\n\t}\n\n\treturn ret;\n}\n\nstruct mmu_page_path {\n\tstruct kvm_mmu_page *parent[PT64_ROOT_MAX_LEVEL];\n\tunsigned int idx[PT64_ROOT_MAX_LEVEL];\n};\n\n#define for_each_sp(pvec, sp, parents, i)\t\t\t\\\n\t\tfor (i = mmu_pages_first(&pvec, &parents);\t\\\n\t\t\ti < pvec.nr && ({ sp = pvec.page[i].sp; 1;});\t\\\n\t\t\ti = mmu_pages_next(&pvec, &parents, i))\n\nstatic int mmu_pages_next(struct kvm_mmu_pages *pvec,\n\t\t\t  struct mmu_page_path *parents,\n\t\t\t  int i)\n{\n\tint n;\n\n\tfor (n = i+1; n < pvec->nr; n++) {\n\t\tstruct kvm_mmu_page *sp = pvec->page[n].sp;\n\t\tunsigned idx = pvec->page[n].idx;\n\t\tint level = sp->role.level;\n\n\t\tparents->idx[level-1] = idx;\n\t\tif (level == PG_LEVEL_4K)\n\t\t\tbreak;\n\n\t\tparents->parent[level-2] = sp;\n\t}\n\n\treturn n;\n}\n\nstatic int mmu_pages_first(struct kvm_mmu_pages *pvec,\n\t\t\t   struct mmu_page_path *parents)\n{\n\tstruct kvm_mmu_page *sp;\n\tint level;\n\n\tif (pvec->nr == 0)\n\t\treturn 0;\n\n\tWARN_ON(pvec->page[0].idx != INVALID_INDEX);\n\n\tsp = pvec->page[0].sp;\n\tlevel = sp->role.level;\n\tWARN_ON(level == PG_LEVEL_4K);\n\n\tparents->parent[level-2] = sp;\n\n\t/* Also set up a sentinel.  Further entries in pvec are all\n\t * children of sp, so this element is never overwritten.\n\t */\n\tparents->parent[level-1] = NULL;\n\treturn mmu_pages_next(pvec, parents, 0);\n}\n\nstatic void mmu_pages_clear_parents(struct mmu_page_path *parents)\n{\n\tstruct kvm_mmu_page *sp;\n\tunsigned int level = 0;\n\n\tdo {\n\t\tunsigned int idx = parents->idx[level];\n\t\tsp = parents->parent[level];\n\t\tif (!sp)\n\t\t\treturn;\n\n\t\tWARN_ON(idx == INVALID_INDEX);\n\t\tclear_unsync_child_bit(sp, idx);\n\t\tlevel++;\n\t} while (!sp->unsync_children);\n}\n\nstatic void mmu_sync_children(struct kvm_vcpu *vcpu,\n\t\t\t      struct kvm_mmu_page *parent)\n{\n\tint i;\n\tstruct kvm_mmu_page *sp;\n\tstruct mmu_page_path parents;\n\tstruct kvm_mmu_pages pages;\n\tLIST_HEAD(invalid_list);\n\tbool flush = false;\n\n\twhile (mmu_unsync_walk(parent, &pages)) {\n\t\tbool protected = false;\n\n\t\tfor_each_sp(pages, sp, parents, i)\n\t\t\tprotected |= rmap_write_protect(vcpu, sp->gfn);\n\n\t\tif (protected) {\n\t\t\tkvm_flush_remote_tlbs(vcpu->kvm);\n\t\t\tflush = false;\n\t\t}\n\n\t\tfor_each_sp(pages, sp, parents, i) {\n\t\t\tflush |= kvm_sync_page(vcpu, sp, &invalid_list);\n\t\t\tmmu_pages_clear_parents(&parents);\n\t\t}\n\t\tif (need_resched() || spin_needbreak(&vcpu->kvm->mmu_lock)) {\n\t\t\tkvm_mmu_flush_or_zap(vcpu, &invalid_list, false, flush);\n\t\t\tcond_resched_lock(&vcpu->kvm->mmu_lock);\n\t\t\tflush = false;\n\t\t}\n\t}\n\n\tkvm_mmu_flush_or_zap(vcpu, &invalid_list, false, flush);\n}\n\nstatic void __clear_sp_write_flooding_count(struct kvm_mmu_page *sp)\n{\n\tatomic_set(&sp->write_flooding_count,  0);\n}\n\nstatic void clear_sp_write_flooding_count(u64 *spte)\n{\n\t__clear_sp_write_flooding_count(sptep_to_sp(spte));\n}\n\nstatic struct kvm_mmu_page *kvm_mmu_get_page(struct kvm_vcpu *vcpu,\n\t\t\t\t\t     gfn_t gfn,\n\t\t\t\t\t     gva_t gaddr,\n\t\t\t\t\t     unsigned level,\n\t\t\t\t\t     int direct,\n\t\t\t\t\t     unsigned int access)\n{\n\tbool direct_mmu = vcpu->arch.mmu->direct_map;\n\tunion kvm_mmu_page_role role;\n\tstruct hlist_head *sp_list;\n\tunsigned quadrant;\n\tstruct kvm_mmu_page *sp;\n\tbool need_sync = false;\n\tbool flush = false;\n\tint collisions = 0;\n\tLIST_HEAD(invalid_list);\n\n\trole = vcpu->arch.mmu->mmu_role.base;\n\trole.level = level;\n\trole.direct = direct;\n\tif (role.direct)\n\t\trole.gpte_is_8_bytes = true;\n\trole.access = access;\n\tif (!direct_mmu && vcpu->arch.mmu->root_level <= PT32_ROOT_LEVEL) {\n\t\tquadrant = gaddr >> (PAGE_SHIFT + (PT64_PT_BITS * level));\n\t\tquadrant &= (1 << ((PT32_PT_BITS - PT64_PT_BITS) * level)) - 1;\n\t\trole.quadrant = quadrant;\n\t}\n\n\tsp_list = &vcpu->kvm->arch.mmu_page_hash[kvm_page_table_hashfn(gfn)];\n\tfor_each_valid_sp(vcpu->kvm, sp, sp_list) {\n\t\tif (sp->gfn != gfn) {\n\t\t\tcollisions++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!need_sync && sp->unsync)\n\t\t\tneed_sync = true;\n\n\t\tif (sp->role.word != role.word)\n\t\t\tcontinue;\n\n\t\tif (direct_mmu)\n\t\t\tgoto trace_get_page;\n\n\t\tif (sp->unsync) {\n\t\t\t/* The page is good, but __kvm_sync_page might still end\n\t\t\t * up zapping it.  If so, break in order to rebuild it.\n\t\t\t */\n\t\t\tif (!__kvm_sync_page(vcpu, sp, &invalid_list))\n\t\t\t\tbreak;\n\n\t\t\tWARN_ON(!list_empty(&invalid_list));\n\t\t\tkvm_make_request(KVM_REQ_TLB_FLUSH_CURRENT, vcpu);\n\t\t}\n\n\t\tif (sp->unsync_children)\n\t\t\tkvm_make_request(KVM_REQ_MMU_SYNC, vcpu);\n\n\t\t__clear_sp_write_flooding_count(sp);\n\ntrace_get_page:\n\t\ttrace_kvm_mmu_get_page(sp, false);\n\t\tgoto out;\n\t}\n\n\t++vcpu->kvm->stat.mmu_cache_miss;\n\n\tsp = kvm_mmu_alloc_page(vcpu, direct);\n\n\tsp->gfn = gfn;\n\tsp->role = role;\n\thlist_add_head(&sp->hash_link, sp_list);\n\tif (!direct) {\n\t\t/*\n\t\t * we should do write protection before syncing pages\n\t\t * otherwise the content of the synced shadow page may\n\t\t * be inconsistent with guest page table.\n\t\t */\n\t\taccount_shadowed(vcpu->kvm, sp);\n\t\tif (level == PG_LEVEL_4K && rmap_write_protect(vcpu, gfn))\n\t\t\tkvm_flush_remote_tlbs_with_address(vcpu->kvm, gfn, 1);\n\n\t\tif (level > PG_LEVEL_4K && need_sync)\n\t\t\tflush |= kvm_sync_pages(vcpu, gfn, &invalid_list);\n\t}\n\ttrace_kvm_mmu_get_page(sp, true);\n\n\tkvm_mmu_flush_or_zap(vcpu, &invalid_list, false, flush);\nout:\n\tif (collisions > vcpu->kvm->stat.max_mmu_page_hash_collisions)\n\t\tvcpu->kvm->stat.max_mmu_page_hash_collisions = collisions;\n\treturn sp;\n}\n\nstatic void shadow_walk_init_using_root(struct kvm_shadow_walk_iterator *iterator,\n\t\t\t\t\tstruct kvm_vcpu *vcpu, hpa_t root,\n\t\t\t\t\tu64 addr)\n{\n\titerator->addr = addr;\n\titerator->shadow_addr = root;\n\titerator->level = vcpu->arch.mmu->shadow_root_level;\n\n\tif (iterator->level == PT64_ROOT_4LEVEL &&\n\t    vcpu->arch.mmu->root_level < PT64_ROOT_4LEVEL &&\n\t    !vcpu->arch.mmu->direct_map)\n\t\t--iterator->level;\n\n\tif (iterator->level == PT32E_ROOT_LEVEL) {\n\t\t/*\n\t\t * prev_root is currently only used for 64-bit hosts. So only\n\t\t * the active root_hpa is valid here.\n\t\t */\n\t\tBUG_ON(root != vcpu->arch.mmu->root_hpa);\n\n\t\titerator->shadow_addr\n\t\t\t= vcpu->arch.mmu->pae_root[(addr >> 30) & 3];\n\t\titerator->shadow_addr &= PT64_BASE_ADDR_MASK;\n\t\t--iterator->level;\n\t\tif (!iterator->shadow_addr)\n\t\t\titerator->level = 0;\n\t}\n}\n\nstatic void shadow_walk_init(struct kvm_shadow_walk_iterator *iterator,\n\t\t\t     struct kvm_vcpu *vcpu, u64 addr)\n{\n\tshadow_walk_init_using_root(iterator, vcpu, vcpu->arch.mmu->root_hpa,\n\t\t\t\t    addr);\n}\n\nstatic bool shadow_walk_okay(struct kvm_shadow_walk_iterator *iterator)\n{\n\tif (iterator->level < PG_LEVEL_4K)\n\t\treturn false;\n\n\titerator->index = SHADOW_PT_INDEX(iterator->addr, iterator->level);\n\titerator->sptep\t= ((u64 *)__va(iterator->shadow_addr)) + iterator->index;\n\treturn true;\n}\n\nstatic void __shadow_walk_next(struct kvm_shadow_walk_iterator *iterator,\n\t\t\t       u64 spte)\n{\n\tif (is_last_spte(spte, iterator->level)) {\n\t\titerator->level = 0;\n\t\treturn;\n\t}\n\n\titerator->shadow_addr = spte & PT64_BASE_ADDR_MASK;\n\t--iterator->level;\n}\n\nstatic void shadow_walk_next(struct kvm_shadow_walk_iterator *iterator)\n{\n\t__shadow_walk_next(iterator, *iterator->sptep);\n}\n\nstatic void link_shadow_page(struct kvm_vcpu *vcpu, u64 *sptep,\n\t\t\t     struct kvm_mmu_page *sp)\n{\n\tu64 spte;\n\n\tBUILD_BUG_ON(VMX_EPT_WRITABLE_MASK != PT_WRITABLE_MASK);\n\n\tspte = make_nonleaf_spte(sp->spt, sp_ad_disabled(sp));\n\n\tmmu_spte_set(sptep, spte);\n\n\tmmu_page_add_parent_pte(vcpu, sp, sptep);\n\n\tif (sp->unsync_children || sp->unsync)\n\t\tmark_unsync(sptep);\n}\n\nstatic void validate_direct_spte(struct kvm_vcpu *vcpu, u64 *sptep,\n\t\t\t\t   unsigned direct_access)\n{\n\tif (is_shadow_present_pte(*sptep) && !is_large_pte(*sptep)) {\n\t\tstruct kvm_mmu_page *child;\n\n\t\t/*\n\t\t * For the direct sp, if the guest pte's dirty bit\n\t\t * changed form clean to dirty, it will corrupt the\n\t\t * sp's access: allow writable in the read-only sp,\n\t\t * so we should update the spte at this point to get\n\t\t * a new sp with the correct access.\n\t\t */\n\t\tchild = to_shadow_page(*sptep & PT64_BASE_ADDR_MASK);\n\t\tif (child->role.access == direct_access)\n\t\t\treturn;\n\n\t\tdrop_parent_pte(child, sptep);\n\t\tkvm_flush_remote_tlbs_with_address(vcpu->kvm, child->gfn, 1);\n\t}\n}\n\n/* Returns the number of zapped non-leaf child shadow pages. */\nstatic int mmu_page_zap_pte(struct kvm *kvm, struct kvm_mmu_page *sp,\n\t\t\t    u64 *spte, struct list_head *invalid_list)\n{\n\tu64 pte;\n\tstruct kvm_mmu_page *child;\n\n\tpte = *spte;\n\tif (is_shadow_present_pte(pte)) {\n\t\tif (is_last_spte(pte, sp->role.level)) {\n\t\t\tdrop_spte(kvm, spte);\n\t\t\tif (is_large_pte(pte))\n\t\t\t\t--kvm->stat.lpages;\n\t\t} else {\n\t\t\tchild = to_shadow_page(pte & PT64_BASE_ADDR_MASK);\n\t\t\tdrop_parent_pte(child, spte);\n\n\t\t\t/*\n\t\t\t * Recursively zap nested TDP SPs, parentless SPs are\n\t\t\t * unlikely to be used again in the near future.  This\n\t\t\t * avoids retaining a large number of stale nested SPs.\n\t\t\t */\n\t\t\tif (tdp_enabled && invalid_list &&\n\t\t\t    child->role.guest_mode && !child->parent_ptes.val)\n\t\t\t\treturn kvm_mmu_prepare_zap_page(kvm, child,\n\t\t\t\t\t\t\t\tinvalid_list);\n\t\t}\n\t} else if (is_mmio_spte(pte)) {\n\t\tmmu_spte_clear_no_track(spte);\n\t}\n\treturn 0;\n}\n\nstatic int kvm_mmu_page_unlink_children(struct kvm *kvm,\n\t\t\t\t\tstruct kvm_mmu_page *sp,\n\t\t\t\t\tstruct list_head *invalid_list)\n{\n\tint zapped = 0;\n\tunsigned i;\n\n\tfor (i = 0; i < PT64_ENT_PER_PAGE; ++i)\n\t\tzapped += mmu_page_zap_pte(kvm, sp, sp->spt + i, invalid_list);\n\n\treturn zapped;\n}\n\nstatic void kvm_mmu_unlink_parents(struct kvm *kvm, struct kvm_mmu_page *sp)\n{\n\tu64 *sptep;\n\tstruct rmap_iterator iter;\n\n\twhile ((sptep = rmap_get_first(&sp->parent_ptes, &iter)))\n\t\tdrop_parent_pte(sp, sptep);\n}\n\nstatic int mmu_zap_unsync_children(struct kvm *kvm,\n\t\t\t\t   struct kvm_mmu_page *parent,\n\t\t\t\t   struct list_head *invalid_list)\n{\n\tint i, zapped = 0;\n\tstruct mmu_page_path parents;\n\tstruct kvm_mmu_pages pages;\n\n\tif (parent->role.level == PG_LEVEL_4K)\n\t\treturn 0;\n\n\twhile (mmu_unsync_walk(parent, &pages)) {\n\t\tstruct kvm_mmu_page *sp;\n\n\t\tfor_each_sp(pages, sp, parents, i) {\n\t\t\tkvm_mmu_prepare_zap_page(kvm, sp, invalid_list);\n\t\t\tmmu_pages_clear_parents(&parents);\n\t\t\tzapped++;\n\t\t}\n\t}\n\n\treturn zapped;\n}\n\nstatic bool __kvm_mmu_prepare_zap_page(struct kvm *kvm,\n\t\t\t\t       struct kvm_mmu_page *sp,\n\t\t\t\t       struct list_head *invalid_list,\n\t\t\t\t       int *nr_zapped)\n{\n\tbool list_unstable;\n\n\ttrace_kvm_mmu_prepare_zap_page(sp);\n\t++kvm->stat.mmu_shadow_zapped;\n\t*nr_zapped = mmu_zap_unsync_children(kvm, sp, invalid_list);\n\t*nr_zapped += kvm_mmu_page_unlink_children(kvm, sp, invalid_list);\n\tkvm_mmu_unlink_parents(kvm, sp);\n\n\t/* Zapping children means active_mmu_pages has become unstable. */\n\tlist_unstable = *nr_zapped;\n\n\tif (!sp->role.invalid && !sp->role.direct)\n\t\tunaccount_shadowed(kvm, sp);\n\n\tif (sp->unsync)\n\t\tkvm_unlink_unsync_page(kvm, sp);\n\tif (!sp->root_count) {\n\t\t/* Count self */\n\t\t(*nr_zapped)++;\n\n\t\t/*\n\t\t * Already invalid pages (previously active roots) are not on\n\t\t * the active page list.  See list_del() in the \"else\" case of\n\t\t * !sp->root_count.\n\t\t */\n\t\tif (sp->role.invalid)\n\t\t\tlist_add(&sp->link, invalid_list);\n\t\telse\n\t\t\tlist_move(&sp->link, invalid_list);\n\t\tkvm_mod_used_mmu_pages(kvm, -1);\n\t} else {\n\t\t/*\n\t\t * Remove the active root from the active page list, the root\n\t\t * will be explicitly freed when the root_count hits zero.\n\t\t */\n\t\tlist_del(&sp->link);\n\n\t\t/*\n\t\t * Obsolete pages cannot be used on any vCPUs, see the comment\n\t\t * in kvm_mmu_zap_all_fast().  Note, is_obsolete_sp() also\n\t\t * treats invalid shadow pages as being obsolete.\n\t\t */\n\t\tif (!is_obsolete_sp(kvm, sp))\n\t\t\tkvm_reload_remote_mmus(kvm);\n\t}\n\n\tif (sp->lpage_disallowed)\n\t\tunaccount_huge_nx_page(kvm, sp);\n\n\tsp->role.invalid = 1;\n\treturn list_unstable;\n}\n\nstatic bool kvm_mmu_prepare_zap_page(struct kvm *kvm, struct kvm_mmu_page *sp,\n\t\t\t\t     struct list_head *invalid_list)\n{\n\tint nr_zapped;\n\n\t__kvm_mmu_prepare_zap_page(kvm, sp, invalid_list, &nr_zapped);\n\treturn nr_zapped;\n}\n\nstatic void kvm_mmu_commit_zap_page(struct kvm *kvm,\n\t\t\t\t    struct list_head *invalid_list)\n{\n\tstruct kvm_mmu_page *sp, *nsp;\n\n\tif (list_empty(invalid_list))\n\t\treturn;\n\n\t/*\n\t * We need to make sure everyone sees our modifications to\n\t * the page tables and see changes to vcpu->mode here. The barrier\n\t * in the kvm_flush_remote_tlbs() achieves this. This pairs\n\t * with vcpu_enter_guest and walk_shadow_page_lockless_begin/end.\n\t *\n\t * In addition, kvm_flush_remote_tlbs waits for all vcpus to exit\n\t * guest mode and/or lockless shadow page table walks.\n\t */\n\tkvm_flush_remote_tlbs(kvm);\n\n\tlist_for_each_entry_safe(sp, nsp, invalid_list, link) {\n\t\tWARN_ON(!sp->role.invalid || sp->root_count);\n\t\tkvm_mmu_free_page(sp);\n\t}\n}\n\nstatic unsigned long kvm_mmu_zap_oldest_mmu_pages(struct kvm *kvm,\n\t\t\t\t\t\t  unsigned long nr_to_zap)\n{\n\tunsigned long total_zapped = 0;\n\tstruct kvm_mmu_page *sp, *tmp;\n\tLIST_HEAD(invalid_list);\n\tbool unstable;\n\tint nr_zapped;\n\n\tif (list_empty(&kvm->arch.active_mmu_pages))\n\t\treturn 0;\n\nrestart:\n\tlist_for_each_entry_safe(sp, tmp, &kvm->arch.active_mmu_pages, link) {\n\t\t/*\n\t\t * Don't zap active root pages, the page itself can't be freed\n\t\t * and zapping it will just force vCPUs to realloc and reload.\n\t\t */\n\t\tif (sp->root_count)\n\t\t\tcontinue;\n\n\t\tunstable = __kvm_mmu_prepare_zap_page(kvm, sp, &invalid_list,\n\t\t\t\t\t\t      &nr_zapped);\n\t\ttotal_zapped += nr_zapped;\n\t\tif (total_zapped >= nr_to_zap)\n\t\t\tbreak;\n\n\t\tif (unstable)\n\t\t\tgoto restart;\n\t}\n\n\tkvm_mmu_commit_zap_page(kvm, &invalid_list);\n\n\tkvm->stat.mmu_recycled += total_zapped;\n\treturn total_zapped;\n}\n\nstatic inline unsigned long kvm_mmu_available_pages(struct kvm *kvm)\n{\n\tif (kvm->arch.n_max_mmu_pages > kvm->arch.n_used_mmu_pages)\n\t\treturn kvm->arch.n_max_mmu_pages -\n\t\t\tkvm->arch.n_used_mmu_pages;\n\n\treturn 0;\n}\n\nstatic int make_mmu_pages_available(struct kvm_vcpu *vcpu)\n{\n\tunsigned long avail = kvm_mmu_available_pages(vcpu->kvm);\n\n\tif (likely(avail >= KVM_MIN_FREE_MMU_PAGES))\n\t\treturn 0;\n\n\tkvm_mmu_zap_oldest_mmu_pages(vcpu->kvm, KVM_REFILL_PAGES - avail);\n\n\tif (!kvm_mmu_available_pages(vcpu->kvm))\n\t\treturn -ENOSPC;\n\treturn 0;\n}\n\n/*\n * Changing the number of mmu pages allocated to the vm\n * Note: if goal_nr_mmu_pages is too small, you will get dead lock\n */\nvoid kvm_mmu_change_mmu_pages(struct kvm *kvm, unsigned long goal_nr_mmu_pages)\n{\n\tspin_lock(&kvm->mmu_lock);\n\n\tif (kvm->arch.n_used_mmu_pages > goal_nr_mmu_pages) {\n\t\tkvm_mmu_zap_oldest_mmu_pages(kvm, kvm->arch.n_used_mmu_pages -\n\t\t\t\t\t\t  goal_nr_mmu_pages);\n\n\t\tgoal_nr_mmu_pages = kvm->arch.n_used_mmu_pages;\n\t}\n\n\tkvm->arch.n_max_mmu_pages = goal_nr_mmu_pages;\n\n\tspin_unlock(&kvm->mmu_lock);\n}\n\nint kvm_mmu_unprotect_page(struct kvm *kvm, gfn_t gfn)\n{\n\tstruct kvm_mmu_page *sp;\n\tLIST_HEAD(invalid_list);\n\tint r;\n\n\tpgprintk(\"%s: looking for gfn %llx\\n\", __func__, gfn);\n\tr = 0;\n\tspin_lock(&kvm->mmu_lock);\n\tfor_each_gfn_indirect_valid_sp(kvm, sp, gfn) {\n\t\tpgprintk(\"%s: gfn %llx role %x\\n\", __func__, gfn,\n\t\t\t sp->role.word);\n\t\tr = 1;\n\t\tkvm_mmu_prepare_zap_page(kvm, sp, &invalid_list);\n\t}\n\tkvm_mmu_commit_zap_page(kvm, &invalid_list);\n\tspin_unlock(&kvm->mmu_lock);\n\n\treturn r;\n}\nEXPORT_SYMBOL_GPL(kvm_mmu_unprotect_page);\n\nstatic void kvm_unsync_page(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp)\n{\n\ttrace_kvm_mmu_unsync_page(sp);\n\t++vcpu->kvm->stat.mmu_unsync;\n\tsp->unsync = 1;\n\n\tkvm_mmu_mark_parents_unsync(sp);\n}\n\nbool mmu_need_write_protect(struct kvm_vcpu *vcpu, gfn_t gfn,\n\t\t\t    bool can_unsync)\n{\n\tstruct kvm_mmu_page *sp;\n\n\tif (kvm_page_track_is_active(vcpu, gfn, KVM_PAGE_TRACK_WRITE))\n\t\treturn true;\n\n\tfor_each_gfn_indirect_valid_sp(vcpu->kvm, sp, gfn) {\n\t\tif (!can_unsync)\n\t\t\treturn true;\n\n\t\tif (sp->unsync)\n\t\t\tcontinue;\n\n\t\tWARN_ON(sp->role.level != PG_LEVEL_4K);\n\t\tkvm_unsync_page(vcpu, sp);\n\t}\n\n\t/*\n\t * We need to ensure that the marking of unsync pages is visible\n\t * before the SPTE is updated to allow writes because\n\t * kvm_mmu_sync_roots() checks the unsync flags without holding\n\t * the MMU lock and so can race with this. If the SPTE was updated\n\t * before the page had been marked as unsync-ed, something like the\n\t * following could happen:\n\t *\n\t * CPU 1                    CPU 2\n\t * ---------------------------------------------------------------------\n\t * 1.2 Host updates SPTE\n\t *     to be writable\n\t *                      2.1 Guest writes a GPTE for GVA X.\n\t *                          (GPTE being in the guest page table shadowed\n\t *                           by the SP from CPU 1.)\n\t *                          This reads SPTE during the page table walk.\n\t *                          Since SPTE.W is read as 1, there is no\n\t *                          fault.\n\t *\n\t *                      2.2 Guest issues TLB flush.\n\t *                          That causes a VM Exit.\n\t *\n\t *                      2.3 kvm_mmu_sync_pages() reads sp->unsync.\n\t *                          Since it is false, so it just returns.\n\t *\n\t *                      2.4 Guest accesses GVA X.\n\t *                          Since the mapping in the SP was not updated,\n\t *                          so the old mapping for GVA X incorrectly\n\t *                          gets used.\n\t * 1.1 Host marks SP\n\t *     as unsync\n\t *     (sp->unsync = true)\n\t *\n\t * The write barrier below ensures that 1.1 happens before 1.2 and thus\n\t * the situation in 2.4 does not arise. The implicit barrier in 2.2\n\t * pairs with this write barrier.\n\t */\n\tsmp_wmb();\n\n\treturn false;\n}\n\nstatic int set_spte(struct kvm_vcpu *vcpu, u64 *sptep,\n\t\t    unsigned int pte_access, int level,\n\t\t    gfn_t gfn, kvm_pfn_t pfn, bool speculative,\n\t\t    bool can_unsync, bool host_writable)\n{\n\tu64 spte;\n\tstruct kvm_mmu_page *sp;\n\tint ret;\n\n\tif (set_mmio_spte(vcpu, sptep, gfn, pfn, pte_access))\n\t\treturn 0;\n\n\tsp = sptep_to_sp(sptep);\n\n\tret = make_spte(vcpu, pte_access, level, gfn, pfn, *sptep, speculative,\n\t\t\tcan_unsync, host_writable, sp_ad_disabled(sp), &spte);\n\n\tif (spte & PT_WRITABLE_MASK)\n\t\tkvm_vcpu_mark_page_dirty(vcpu, gfn);\n\n\tif (*sptep == spte)\n\t\tret |= SET_SPTE_SPURIOUS;\n\telse if (mmu_spte_update(sptep, spte))\n\t\tret |= SET_SPTE_NEED_REMOTE_TLB_FLUSH;\n\treturn ret;\n}\n\nstatic int mmu_set_spte(struct kvm_vcpu *vcpu, u64 *sptep,\n\t\t\tunsigned int pte_access, bool write_fault, int level,\n\t\t\tgfn_t gfn, kvm_pfn_t pfn, bool speculative,\n\t\t\tbool host_writable)\n{\n\tint was_rmapped = 0;\n\tint rmap_count;\n\tint set_spte_ret;\n\tint ret = RET_PF_FIXED;\n\tbool flush = false;\n\n\tpgprintk(\"%s: spte %llx write_fault %d gfn %llx\\n\", __func__,\n\t\t *sptep, write_fault, gfn);\n\n\tif (is_shadow_present_pte(*sptep)) {\n\t\t/*\n\t\t * If we overwrite a PTE page pointer with a 2MB PMD, unlink\n\t\t * the parent of the now unreachable PTE.\n\t\t */\n\t\tif (level > PG_LEVEL_4K && !is_large_pte(*sptep)) {\n\t\t\tstruct kvm_mmu_page *child;\n\t\t\tu64 pte = *sptep;\n\n\t\t\tchild = to_shadow_page(pte & PT64_BASE_ADDR_MASK);\n\t\t\tdrop_parent_pte(child, sptep);\n\t\t\tflush = true;\n\t\t} else if (pfn != spte_to_pfn(*sptep)) {\n\t\t\tpgprintk(\"hfn old %llx new %llx\\n\",\n\t\t\t\t spte_to_pfn(*sptep), pfn);\n\t\t\tdrop_spte(vcpu->kvm, sptep);\n\t\t\tflush = true;\n\t\t} else\n\t\t\twas_rmapped = 1;\n\t}\n\n\tset_spte_ret = set_spte(vcpu, sptep, pte_access, level, gfn, pfn,\n\t\t\t\tspeculative, true, host_writable);\n\tif (set_spte_ret & SET_SPTE_WRITE_PROTECTED_PT) {\n\t\tif (write_fault)\n\t\t\tret = RET_PF_EMULATE;\n\t\tkvm_make_request(KVM_REQ_TLB_FLUSH_CURRENT, vcpu);\n\t}\n\n\tif (set_spte_ret & SET_SPTE_NEED_REMOTE_TLB_FLUSH || flush)\n\t\tkvm_flush_remote_tlbs_with_address(vcpu->kvm, gfn,\n\t\t\t\tKVM_PAGES_PER_HPAGE(level));\n\n\tif (unlikely(is_mmio_spte(*sptep)))\n\t\tret = RET_PF_EMULATE;\n\n\t/*\n\t * The fault is fully spurious if and only if the new SPTE and old SPTE\n\t * are identical, and emulation is not required.\n\t */\n\tif ((set_spte_ret & SET_SPTE_SPURIOUS) && ret == RET_PF_FIXED) {\n\t\tWARN_ON_ONCE(!was_rmapped);\n\t\treturn RET_PF_SPURIOUS;\n\t}\n\n\tpgprintk(\"%s: setting spte %llx\\n\", __func__, *sptep);\n\ttrace_kvm_mmu_set_spte(level, gfn, sptep);\n\tif (!was_rmapped && is_large_pte(*sptep))\n\t\t++vcpu->kvm->stat.lpages;\n\n\tif (is_shadow_present_pte(*sptep)) {\n\t\tif (!was_rmapped) {\n\t\t\trmap_count = rmap_add(vcpu, sptep, gfn);\n\t\t\tif (rmap_count > RMAP_RECYCLE_THRESHOLD)\n\t\t\t\trmap_recycle(vcpu, sptep, gfn);\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nstatic kvm_pfn_t pte_prefetch_gfn_to_pfn(struct kvm_vcpu *vcpu, gfn_t gfn,\n\t\t\t\t     bool no_dirty_log)\n{\n\tstruct kvm_memory_slot *slot;\n\n\tslot = gfn_to_memslot_dirty_bitmap(vcpu, gfn, no_dirty_log);\n\tif (!slot)\n\t\treturn KVM_PFN_ERR_FAULT;\n\n\treturn gfn_to_pfn_memslot_atomic(slot, gfn);\n}\n\nstatic int direct_pte_prefetch_many(struct kvm_vcpu *vcpu,\n\t\t\t\t    struct kvm_mmu_page *sp,\n\t\t\t\t    u64 *start, u64 *end)\n{\n\tstruct page *pages[PTE_PREFETCH_NUM];\n\tstruct kvm_memory_slot *slot;\n\tunsigned int access = sp->role.access;\n\tint i, ret;\n\tgfn_t gfn;\n\n\tgfn = kvm_mmu_page_get_gfn(sp, start - sp->spt);\n\tslot = gfn_to_memslot_dirty_bitmap(vcpu, gfn, access & ACC_WRITE_MASK);\n\tif (!slot)\n\t\treturn -1;\n\n\tret = gfn_to_page_many_atomic(slot, gfn, pages, end - start);\n\tif (ret <= 0)\n\t\treturn -1;\n\n\tfor (i = 0; i < ret; i++, gfn++, start++) {\n\t\tmmu_set_spte(vcpu, start, access, false, sp->role.level, gfn,\n\t\t\t     page_to_pfn(pages[i]), true, true);\n\t\tput_page(pages[i]);\n\t}\n\n\treturn 0;\n}\n\nstatic void __direct_pte_prefetch(struct kvm_vcpu *vcpu,\n\t\t\t\t  struct kvm_mmu_page *sp, u64 *sptep)\n{\n\tu64 *spte, *start = NULL;\n\tint i;\n\n\tWARN_ON(!sp->role.direct);\n\n\ti = (sptep - sp->spt) & ~(PTE_PREFETCH_NUM - 1);\n\tspte = sp->spt + i;\n\n\tfor (i = 0; i < PTE_PREFETCH_NUM; i++, spte++) {\n\t\tif (is_shadow_present_pte(*spte) || spte == sptep) {\n\t\t\tif (!start)\n\t\t\t\tcontinue;\n\t\t\tif (direct_pte_prefetch_many(vcpu, sp, start, spte) < 0)\n\t\t\t\tbreak;\n\t\t\tstart = NULL;\n\t\t} else if (!start)\n\t\t\tstart = spte;\n\t}\n}\n\nstatic void direct_pte_prefetch(struct kvm_vcpu *vcpu, u64 *sptep)\n{\n\tstruct kvm_mmu_page *sp;\n\n\tsp = sptep_to_sp(sptep);\n\n\t/*\n\t * Without accessed bits, there's no way to distinguish between\n\t * actually accessed translations and prefetched, so disable pte\n\t * prefetch if accessed bits aren't available.\n\t */\n\tif (sp_ad_disabled(sp))\n\t\treturn;\n\n\tif (sp->role.level > PG_LEVEL_4K)\n\t\treturn;\n\n\t__direct_pte_prefetch(vcpu, sp, sptep);\n}\n\nstatic int host_pfn_mapping_level(struct kvm_vcpu *vcpu, gfn_t gfn,\n\t\t\t\t  kvm_pfn_t pfn, struct kvm_memory_slot *slot)\n{\n\tunsigned long hva;\n\tpte_t *pte;\n\tint level;\n\n\tif (!PageCompound(pfn_to_page(pfn)) && !kvm_is_zone_device_pfn(pfn))\n\t\treturn PG_LEVEL_4K;\n\n\t/*\n\t * Note, using the already-retrieved memslot and __gfn_to_hva_memslot()\n\t * is not solely for performance, it's also necessary to avoid the\n\t * \"writable\" check in __gfn_to_hva_many(), which will always fail on\n\t * read-only memslots due to gfn_to_hva() assuming writes.  Earlier\n\t * page fault steps have already verified the guest isn't writing a\n\t * read-only memslot.\n\t */\n\thva = __gfn_to_hva_memslot(slot, gfn);\n\n\tpte = lookup_address_in_mm(vcpu->kvm->mm, hva, &level);\n\tif (unlikely(!pte))\n\t\treturn PG_LEVEL_4K;\n\n\treturn level;\n}\n\nint kvm_mmu_hugepage_adjust(struct kvm_vcpu *vcpu, gfn_t gfn,\n\t\t\t    int max_level, kvm_pfn_t *pfnp,\n\t\t\t    bool huge_page_disallowed, int *req_level)\n{\n\tstruct kvm_memory_slot *slot;\n\tstruct kvm_lpage_info *linfo;\n\tkvm_pfn_t pfn = *pfnp;\n\tkvm_pfn_t mask;\n\tint level;\n\n\t*req_level = PG_LEVEL_4K;\n\n\tif (unlikely(max_level == PG_LEVEL_4K))\n\t\treturn PG_LEVEL_4K;\n\n\tif (is_error_noslot_pfn(pfn) || kvm_is_reserved_pfn(pfn))\n\t\treturn PG_LEVEL_4K;\n\n\tslot = gfn_to_memslot_dirty_bitmap(vcpu, gfn, true);\n\tif (!slot)\n\t\treturn PG_LEVEL_4K;\n\n\tmax_level = min(max_level, max_huge_page_level);\n\tfor ( ; max_level > PG_LEVEL_4K; max_level--) {\n\t\tlinfo = lpage_info_slot(gfn, slot, max_level);\n\t\tif (!linfo->disallow_lpage)\n\t\t\tbreak;\n\t}\n\n\tif (max_level == PG_LEVEL_4K)\n\t\treturn PG_LEVEL_4K;\n\n\tlevel = host_pfn_mapping_level(vcpu, gfn, pfn, slot);\n\tif (level == PG_LEVEL_4K)\n\t\treturn level;\n\n\t*req_level = level = min(level, max_level);\n\n\t/*\n\t * Enforce the iTLB multihit workaround after capturing the requested\n\t * level, which will be used to do precise, accurate accounting.\n\t */\n\tif (huge_page_disallowed)\n\t\treturn PG_LEVEL_4K;\n\n\t/*\n\t * mmu_notifier_retry() was successful and mmu_lock is held, so\n\t * the pmd can't be split from under us.\n\t */\n\tmask = KVM_PAGES_PER_HPAGE(level) - 1;\n\tVM_BUG_ON((gfn & mask) != (pfn & mask));\n\t*pfnp = pfn & ~mask;\n\n\treturn level;\n}\n\nvoid disallowed_hugepage_adjust(u64 spte, gfn_t gfn, int cur_level,\n\t\t\t\tkvm_pfn_t *pfnp, int *goal_levelp)\n{\n\tint level = *goal_levelp;\n\n\tif (cur_level == level && level > PG_LEVEL_4K &&\n\t    is_shadow_present_pte(spte) &&\n\t    !is_large_pte(spte)) {\n\t\t/*\n\t\t * A small SPTE exists for this pfn, but FNAME(fetch)\n\t\t * and __direct_map would like to create a large PTE\n\t\t * instead: just force them to go down another level,\n\t\t * patching back for them into pfn the next 9 bits of\n\t\t * the address.\n\t\t */\n\t\tu64 page_mask = KVM_PAGES_PER_HPAGE(level) -\n\t\t\t\tKVM_PAGES_PER_HPAGE(level - 1);\n\t\t*pfnp |= gfn & page_mask;\n\t\t(*goal_levelp)--;\n\t}\n}\n\nstatic int __direct_map(struct kvm_vcpu *vcpu, gpa_t gpa, u32 error_code,\n\t\t\tint map_writable, int max_level, kvm_pfn_t pfn,\n\t\t\tbool prefault, bool is_tdp)\n{\n\tbool nx_huge_page_workaround_enabled = is_nx_huge_page_enabled();\n\tbool write = error_code & PFERR_WRITE_MASK;\n\tbool exec = error_code & PFERR_FETCH_MASK;\n\tbool huge_page_disallowed = exec && nx_huge_page_workaround_enabled;\n\tstruct kvm_shadow_walk_iterator it;\n\tstruct kvm_mmu_page *sp;\n\tint level, req_level, ret;\n\tgfn_t gfn = gpa >> PAGE_SHIFT;\n\tgfn_t base_gfn = gfn;\n\n\tif (WARN_ON(!VALID_PAGE(vcpu->arch.mmu->root_hpa)))\n\t\treturn RET_PF_RETRY;\n\n\tlevel = kvm_mmu_hugepage_adjust(vcpu, gfn, max_level, &pfn,\n\t\t\t\t\thuge_page_disallowed, &req_level);\n\n\ttrace_kvm_mmu_spte_requested(gpa, level, pfn);\n\tfor_each_shadow_entry(vcpu, gpa, it) {\n\t\t/*\n\t\t * We cannot overwrite existing page tables with an NX\n\t\t * large page, as the leaf could be executable.\n\t\t */\n\t\tif (nx_huge_page_workaround_enabled)\n\t\t\tdisallowed_hugepage_adjust(*it.sptep, gfn, it.level,\n\t\t\t\t\t\t   &pfn, &level);\n\n\t\tbase_gfn = gfn & ~(KVM_PAGES_PER_HPAGE(it.level) - 1);\n\t\tif (it.level == level)\n\t\t\tbreak;\n\n\t\tdrop_large_spte(vcpu, it.sptep);\n\t\tif (!is_shadow_present_pte(*it.sptep)) {\n\t\t\tsp = kvm_mmu_get_page(vcpu, base_gfn, it.addr,\n\t\t\t\t\t      it.level - 1, true, ACC_ALL);\n\n\t\t\tlink_shadow_page(vcpu, it.sptep, sp);\n\t\t\tif (is_tdp && huge_page_disallowed &&\n\t\t\t    req_level >= it.level)\n\t\t\t\taccount_huge_nx_page(vcpu->kvm, sp);\n\t\t}\n\t}\n\n\tret = mmu_set_spte(vcpu, it.sptep, ACC_ALL,\n\t\t\t   write, level, base_gfn, pfn, prefault,\n\t\t\t   map_writable);\n\tif (ret == RET_PF_SPURIOUS)\n\t\treturn ret;\n\n\tdirect_pte_prefetch(vcpu, it.sptep);\n\t++vcpu->stat.pf_fixed;\n\treturn ret;\n}\n\nstatic void kvm_send_hwpoison_signal(unsigned long address, struct task_struct *tsk)\n{\n\tsend_sig_mceerr(BUS_MCEERR_AR, (void __user *)address, PAGE_SHIFT, tsk);\n}\n\nstatic int kvm_handle_bad_page(struct kvm_vcpu *vcpu, gfn_t gfn, kvm_pfn_t pfn)\n{\n\t/*\n\t * Do not cache the mmio info caused by writing the readonly gfn\n\t * into the spte otherwise read access on readonly gfn also can\n\t * caused mmio page fault and treat it as mmio access.\n\t */\n\tif (pfn == KVM_PFN_ERR_RO_FAULT)\n\t\treturn RET_PF_EMULATE;\n\n\tif (pfn == KVM_PFN_ERR_HWPOISON) {\n\t\tkvm_send_hwpoison_signal(kvm_vcpu_gfn_to_hva(vcpu, gfn), current);\n\t\treturn RET_PF_RETRY;\n\t}\n\n\treturn -EFAULT;\n}\n\nstatic bool handle_abnormal_pfn(struct kvm_vcpu *vcpu, gva_t gva, gfn_t gfn,\n\t\t\t\tkvm_pfn_t pfn, unsigned int access,\n\t\t\t\tint *ret_val)\n{\n\t/* The pfn is invalid, report the error! */\n\tif (unlikely(is_error_pfn(pfn))) {\n\t\t*ret_val = kvm_handle_bad_page(vcpu, gfn, pfn);\n\t\treturn true;\n\t}\n\n\tif (unlikely(is_noslot_pfn(pfn)))\n\t\tvcpu_cache_mmio_info(vcpu, gva, gfn,\n\t\t\t\t     access & shadow_mmio_access_mask);\n\n\treturn false;\n}\n\nstatic bool page_fault_can_be_fast(u32 error_code)\n{\n\t/*\n\t * Do not fix the mmio spte with invalid generation number which\n\t * need to be updated by slow page fault path.\n\t */\n\tif (unlikely(error_code & PFERR_RSVD_MASK))\n\t\treturn false;\n\n\t/* See if the page fault is due to an NX violation */\n\tif (unlikely(((error_code & (PFERR_FETCH_MASK | PFERR_PRESENT_MASK))\n\t\t      == (PFERR_FETCH_MASK | PFERR_PRESENT_MASK))))\n\t\treturn false;\n\n\t/*\n\t * #PF can be fast if:\n\t * 1. The shadow page table entry is not present, which could mean that\n\t *    the fault is potentially caused by access tracking (if enabled).\n\t * 2. The shadow page table entry is present and the fault\n\t *    is caused by write-protect, that means we just need change the W\n\t *    bit of the spte which can be done out of mmu-lock.\n\t *\n\t * However, if access tracking is disabled we know that a non-present\n\t * page must be a genuine page fault where we have to create a new SPTE.\n\t * So, if access tracking is disabled, we return true only for write\n\t * accesses to a present page.\n\t */\n\n\treturn shadow_acc_track_mask != 0 ||\n\t       ((error_code & (PFERR_WRITE_MASK | PFERR_PRESENT_MASK))\n\t\t== (PFERR_WRITE_MASK | PFERR_PRESENT_MASK));\n}\n\n/*\n * Returns true if the SPTE was fixed successfully. Otherwise,\n * someone else modified the SPTE from its original value.\n */\nstatic bool\nfast_pf_fix_direct_spte(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp,\n\t\t\tu64 *sptep, u64 old_spte, u64 new_spte)\n{\n\tgfn_t gfn;\n\n\tWARN_ON(!sp->role.direct);\n\n\t/*\n\t * Theoretically we could also set dirty bit (and flush TLB) here in\n\t * order to eliminate unnecessary PML logging. See comments in\n\t * set_spte. But fast_page_fault is very unlikely to happen with PML\n\t * enabled, so we do not do this. This might result in the same GPA\n\t * to be logged in PML buffer again when the write really happens, and\n\t * eventually to be called by mark_page_dirty twice. But it's also no\n\t * harm. This also avoids the TLB flush needed after setting dirty bit\n\t * so non-PML cases won't be impacted.\n\t *\n\t * Compare with set_spte where instead shadow_dirty_mask is set.\n\t */\n\tif (cmpxchg64(sptep, old_spte, new_spte) != old_spte)\n\t\treturn false;\n\n\tif (is_writable_pte(new_spte) && !is_writable_pte(old_spte)) {\n\t\t/*\n\t\t * The gfn of direct spte is stable since it is\n\t\t * calculated by sp->gfn.\n\t\t */\n\t\tgfn = kvm_mmu_page_get_gfn(sp, sptep - sp->spt);\n\t\tkvm_vcpu_mark_page_dirty(vcpu, gfn);\n\t}\n\n\treturn true;\n}\n\nstatic bool is_access_allowed(u32 fault_err_code, u64 spte)\n{\n\tif (fault_err_code & PFERR_FETCH_MASK)\n\t\treturn is_executable_pte(spte);\n\n\tif (fault_err_code & PFERR_WRITE_MASK)\n\t\treturn is_writable_pte(spte);\n\n\t/* Fault was on Read access */\n\treturn spte & PT_PRESENT_MASK;\n}\n\n/*\n * Returns one of RET_PF_INVALID, RET_PF_FIXED or RET_PF_SPURIOUS.\n */\nstatic int fast_page_fault(struct kvm_vcpu *vcpu, gpa_t cr2_or_gpa,\n\t\t\t   u32 error_code)\n{\n\tstruct kvm_shadow_walk_iterator iterator;\n\tstruct kvm_mmu_page *sp;\n\tint ret = RET_PF_INVALID;\n\tu64 spte = 0ull;\n\tuint retry_count = 0;\n\n\tif (!page_fault_can_be_fast(error_code))\n\t\treturn ret;\n\n\twalk_shadow_page_lockless_begin(vcpu);\n\n\tdo {\n\t\tu64 new_spte;\n\n\t\tfor_each_shadow_entry_lockless(vcpu, cr2_or_gpa, iterator, spte)\n\t\t\tif (!is_shadow_present_pte(spte))\n\t\t\t\tbreak;\n\n\t\tsp = sptep_to_sp(iterator.sptep);\n\t\tif (!is_last_spte(spte, sp->role.level))\n\t\t\tbreak;\n\n\t\t/*\n\t\t * Check whether the memory access that caused the fault would\n\t\t * still cause it if it were to be performed right now. If not,\n\t\t * then this is a spurious fault caused by TLB lazily flushed,\n\t\t * or some other CPU has already fixed the PTE after the\n\t\t * current CPU took the fault.\n\t\t *\n\t\t * Need not check the access of upper level table entries since\n\t\t * they are always ACC_ALL.\n\t\t */\n\t\tif (is_access_allowed(error_code, spte)) {\n\t\t\tret = RET_PF_SPURIOUS;\n\t\t\tbreak;\n\t\t}\n\n\t\tnew_spte = spte;\n\n\t\tif (is_access_track_spte(spte))\n\t\t\tnew_spte = restore_acc_track_spte(new_spte);\n\n\t\t/*\n\t\t * Currently, to simplify the code, write-protection can\n\t\t * be removed in the fast path only if the SPTE was\n\t\t * write-protected for dirty-logging or access tracking.\n\t\t */\n\t\tif ((error_code & PFERR_WRITE_MASK) &&\n\t\t    spte_can_locklessly_be_made_writable(spte)) {\n\t\t\tnew_spte |= PT_WRITABLE_MASK;\n\n\t\t\t/*\n\t\t\t * Do not fix write-permission on the large spte.  Since\n\t\t\t * we only dirty the first page into the dirty-bitmap in\n\t\t\t * fast_pf_fix_direct_spte(), other pages are missed\n\t\t\t * if its slot has dirty logging enabled.\n\t\t\t *\n\t\t\t * Instead, we let the slow page fault path create a\n\t\t\t * normal spte to fix the access.\n\t\t\t *\n\t\t\t * See the comments in kvm_arch_commit_memory_region().\n\t\t\t */\n\t\t\tif (sp->role.level > PG_LEVEL_4K)\n\t\t\t\tbreak;\n\t\t}\n\n\t\t/* Verify that the fault can be handled in the fast path */\n\t\tif (new_spte == spte ||\n\t\t    !is_access_allowed(error_code, new_spte))\n\t\t\tbreak;\n\n\t\t/*\n\t\t * Currently, fast page fault only works for direct mapping\n\t\t * since the gfn is not stable for indirect shadow page. See\n\t\t * Documentation/virt/kvm/locking.rst to get more detail.\n\t\t */\n\t\tif (fast_pf_fix_direct_spte(vcpu, sp, iterator.sptep, spte,\n\t\t\t\t\t    new_spte)) {\n\t\t\tret = RET_PF_FIXED;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (++retry_count > 4) {\n\t\t\tprintk_once(KERN_WARNING\n\t\t\t\t\"kvm: Fast #PF retrying more than 4 times.\\n\");\n\t\t\tbreak;\n\t\t}\n\n\t} while (true);\n\n\ttrace_fast_page_fault(vcpu, cr2_or_gpa, error_code, iterator.sptep,\n\t\t\t      spte, ret);\n\twalk_shadow_page_lockless_end(vcpu);\n\n\treturn ret;\n}\n\nstatic void mmu_free_root_page(struct kvm *kvm, hpa_t *root_hpa,\n\t\t\t       struct list_head *invalid_list)\n{\n\tstruct kvm_mmu_page *sp;\n\n\tif (!VALID_PAGE(*root_hpa))\n\t\treturn;\n\n\tsp = to_shadow_page(*root_hpa & PT64_BASE_ADDR_MASK);\n\n\tif (kvm_mmu_put_root(kvm, sp)) {\n\t\tif (sp->tdp_mmu_page)\n\t\t\tkvm_tdp_mmu_free_root(kvm, sp);\n\t\telse if (sp->role.invalid)\n\t\t\tkvm_mmu_prepare_zap_page(kvm, sp, invalid_list);\n\t}\n\n\t*root_hpa = INVALID_PAGE;\n}\n\n/* roots_to_free must be some combination of the KVM_MMU_ROOT_* flags */\nvoid kvm_mmu_free_roots(struct kvm_vcpu *vcpu, struct kvm_mmu *mmu,\n\t\t\tulong roots_to_free)\n{\n\tstruct kvm *kvm = vcpu->kvm;\n\tint i;\n\tLIST_HEAD(invalid_list);\n\tbool free_active_root = roots_to_free & KVM_MMU_ROOT_CURRENT;\n\n\tBUILD_BUG_ON(KVM_MMU_NUM_PREV_ROOTS >= BITS_PER_LONG);\n\n\t/* Before acquiring the MMU lock, see if we need to do any real work. */\n\tif (!(free_active_root && VALID_PAGE(mmu->root_hpa))) {\n\t\tfor (i = 0; i < KVM_MMU_NUM_PREV_ROOTS; i++)\n\t\t\tif ((roots_to_free & KVM_MMU_ROOT_PREVIOUS(i)) &&\n\t\t\t    VALID_PAGE(mmu->prev_roots[i].hpa))\n\t\t\t\tbreak;\n\n\t\tif (i == KVM_MMU_NUM_PREV_ROOTS)\n\t\t\treturn;\n\t}\n\n\tspin_lock(&kvm->mmu_lock);\n\n\tfor (i = 0; i < KVM_MMU_NUM_PREV_ROOTS; i++)\n\t\tif (roots_to_free & KVM_MMU_ROOT_PREVIOUS(i))\n\t\t\tmmu_free_root_page(kvm, &mmu->prev_roots[i].hpa,\n\t\t\t\t\t   &invalid_list);\n\n\tif (free_active_root) {\n\t\tif (mmu->shadow_root_level >= PT64_ROOT_4LEVEL &&\n\t\t    (mmu->root_level >= PT64_ROOT_4LEVEL || mmu->direct_map)) {\n\t\t\tmmu_free_root_page(kvm, &mmu->root_hpa, &invalid_list);\n\t\t} else {\n\t\t\tfor (i = 0; i < 4; ++i)\n\t\t\t\tif (mmu->pae_root[i] != 0)\n\t\t\t\t\tmmu_free_root_page(kvm,\n\t\t\t\t\t\t\t   &mmu->pae_root[i],\n\t\t\t\t\t\t\t   &invalid_list);\n\t\t\tmmu->root_hpa = INVALID_PAGE;\n\t\t}\n\t\tmmu->root_pgd = 0;\n\t}\n\n\tkvm_mmu_commit_zap_page(kvm, &invalid_list);\n\tspin_unlock(&kvm->mmu_lock);\n}\nEXPORT_SYMBOL_GPL(kvm_mmu_free_roots);\n\nstatic int mmu_check_root(struct kvm_vcpu *vcpu, gfn_t root_gfn)\n{\n\tint ret = 0;\n\n\tif (!kvm_vcpu_is_visible_gfn(vcpu, root_gfn)) {\n\t\tkvm_make_request(KVM_REQ_TRIPLE_FAULT, vcpu);\n\t\tret = 1;\n\t}\n\n\treturn ret;\n}\n\nstatic hpa_t mmu_alloc_root(struct kvm_vcpu *vcpu, gfn_t gfn, gva_t gva,\n\t\t\t    u8 level, bool direct)\n{\n\tstruct kvm_mmu_page *sp;\n\n\tspin_lock(&vcpu->kvm->mmu_lock);\n\n\tif (make_mmu_pages_available(vcpu)) {\n\t\tspin_unlock(&vcpu->kvm->mmu_lock);\n\t\treturn INVALID_PAGE;\n\t}\n\tsp = kvm_mmu_get_page(vcpu, gfn, gva, level, direct, ACC_ALL);\n\t++sp->root_count;\n\n\tspin_unlock(&vcpu->kvm->mmu_lock);\n\treturn __pa(sp->spt);\n}\n\nstatic int mmu_alloc_direct_roots(struct kvm_vcpu *vcpu)\n{\n\tu8 shadow_root_level = vcpu->arch.mmu->shadow_root_level;\n\thpa_t root;\n\tunsigned i;\n\n\tif (vcpu->kvm->arch.tdp_mmu_enabled) {\n\t\troot = kvm_tdp_mmu_get_vcpu_root_hpa(vcpu);\n\n\t\tif (!VALID_PAGE(root))\n\t\t\treturn -ENOSPC;\n\t\tvcpu->arch.mmu->root_hpa = root;\n\t} else if (shadow_root_level >= PT64_ROOT_4LEVEL) {\n\t\troot = mmu_alloc_root(vcpu, 0, 0, shadow_root_level,\n\t\t\t\t      true);\n\n\t\tif (!VALID_PAGE(root))\n\t\t\treturn -ENOSPC;\n\t\tvcpu->arch.mmu->root_hpa = root;\n\t} else if (shadow_root_level == PT32E_ROOT_LEVEL) {\n\t\tfor (i = 0; i < 4; ++i) {\n\t\t\tMMU_WARN_ON(VALID_PAGE(vcpu->arch.mmu->pae_root[i]));\n\n\t\t\troot = mmu_alloc_root(vcpu, i << (30 - PAGE_SHIFT),\n\t\t\t\t\t      i << 30, PT32_ROOT_LEVEL, true);\n\t\t\tif (!VALID_PAGE(root))\n\t\t\t\treturn -ENOSPC;\n\t\t\tvcpu->arch.mmu->pae_root[i] = root | PT_PRESENT_MASK;\n\t\t}\n\t\tvcpu->arch.mmu->root_hpa = __pa(vcpu->arch.mmu->pae_root);\n\t} else\n\t\tBUG();\n\n\t/* root_pgd is ignored for direct MMUs. */\n\tvcpu->arch.mmu->root_pgd = 0;\n\n\treturn 0;\n}\n\nstatic int mmu_alloc_shadow_roots(struct kvm_vcpu *vcpu)\n{\n\tu64 pdptr, pm_mask;\n\tgfn_t root_gfn, root_pgd;\n\thpa_t root;\n\tint i;\n\n\troot_pgd = vcpu->arch.mmu->get_guest_pgd(vcpu);\n\troot_gfn = root_pgd >> PAGE_SHIFT;\n\n\tif (mmu_check_root(vcpu, root_gfn))\n\t\treturn 1;\n\n\t/*\n\t * Do we shadow a long mode page table? If so we need to\n\t * write-protect the guests page table root.\n\t */\n\tif (vcpu->arch.mmu->root_level >= PT64_ROOT_4LEVEL) {\n\t\tMMU_WARN_ON(VALID_PAGE(vcpu->arch.mmu->root_hpa));\n\n\t\troot = mmu_alloc_root(vcpu, root_gfn, 0,\n\t\t\t\t      vcpu->arch.mmu->shadow_root_level, false);\n\t\tif (!VALID_PAGE(root))\n\t\t\treturn -ENOSPC;\n\t\tvcpu->arch.mmu->root_hpa = root;\n\t\tgoto set_root_pgd;\n\t}\n\n\t/*\n\t * We shadow a 32 bit page table. This may be a legacy 2-level\n\t * or a PAE 3-level page table. In either case we need to be aware that\n\t * the shadow page table may be a PAE or a long mode page table.\n\t */\n\tpm_mask = PT_PRESENT_MASK;\n\tif (vcpu->arch.mmu->shadow_root_level == PT64_ROOT_4LEVEL)\n\t\tpm_mask |= PT_ACCESSED_MASK | PT_WRITABLE_MASK | PT_USER_MASK;\n\n\tfor (i = 0; i < 4; ++i) {\n\t\tMMU_WARN_ON(VALID_PAGE(vcpu->arch.mmu->pae_root[i]));\n\t\tif (vcpu->arch.mmu->root_level == PT32E_ROOT_LEVEL) {\n\t\t\tpdptr = vcpu->arch.mmu->get_pdptr(vcpu, i);\n\t\t\tif (!(pdptr & PT_PRESENT_MASK)) {\n\t\t\t\tvcpu->arch.mmu->pae_root[i] = 0;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\troot_gfn = pdptr >> PAGE_SHIFT;\n\t\t\tif (mmu_check_root(vcpu, root_gfn))\n\t\t\t\treturn 1;\n\t\t}\n\n\t\troot = mmu_alloc_root(vcpu, root_gfn, i << 30,\n\t\t\t\t      PT32_ROOT_LEVEL, false);\n\t\tif (!VALID_PAGE(root))\n\t\t\treturn -ENOSPC;\n\t\tvcpu->arch.mmu->pae_root[i] = root | pm_mask;\n\t}\n\tvcpu->arch.mmu->root_hpa = __pa(vcpu->arch.mmu->pae_root);\n\n\t/*\n\t * If we shadow a 32 bit page table with a long mode page\n\t * table we enter this path.\n\t */\n\tif (vcpu->arch.mmu->shadow_root_level == PT64_ROOT_4LEVEL) {\n\t\tif (vcpu->arch.mmu->lm_root == NULL) {\n\t\t\t/*\n\t\t\t * The additional page necessary for this is only\n\t\t\t * allocated on demand.\n\t\t\t */\n\n\t\t\tu64 *lm_root;\n\n\t\t\tlm_root = (void*)get_zeroed_page(GFP_KERNEL_ACCOUNT);\n\t\t\tif (lm_root == NULL)\n\t\t\t\treturn 1;\n\n\t\t\tlm_root[0] = __pa(vcpu->arch.mmu->pae_root) | pm_mask;\n\n\t\t\tvcpu->arch.mmu->lm_root = lm_root;\n\t\t}\n\n\t\tvcpu->arch.mmu->root_hpa = __pa(vcpu->arch.mmu->lm_root);\n\t}\n\nset_root_pgd:\n\tvcpu->arch.mmu->root_pgd = root_pgd;\n\n\treturn 0;\n}\n\nstatic int mmu_alloc_roots(struct kvm_vcpu *vcpu)\n{\n\tif (vcpu->arch.mmu->direct_map)\n\t\treturn mmu_alloc_direct_roots(vcpu);\n\telse\n\t\treturn mmu_alloc_shadow_roots(vcpu);\n}\n\nvoid kvm_mmu_sync_roots(struct kvm_vcpu *vcpu)\n{\n\tint i;\n\tstruct kvm_mmu_page *sp;\n\n\tif (vcpu->arch.mmu->direct_map)\n\t\treturn;\n\n\tif (!VALID_PAGE(vcpu->arch.mmu->root_hpa))\n\t\treturn;\n\n\tvcpu_clear_mmio_info(vcpu, MMIO_GVA_ANY);\n\n\tif (vcpu->arch.mmu->root_level >= PT64_ROOT_4LEVEL) {\n\t\thpa_t root = vcpu->arch.mmu->root_hpa;\n\t\tsp = to_shadow_page(root);\n\n\t\t/*\n\t\t * Even if another CPU was marking the SP as unsync-ed\n\t\t * simultaneously, any guest page table changes are not\n\t\t * guaranteed to be visible anyway until this VCPU issues a TLB\n\t\t * flush strictly after those changes are made. We only need to\n\t\t * ensure that the other CPU sets these flags before any actual\n\t\t * changes to the page tables are made. The comments in\n\t\t * mmu_need_write_protect() describe what could go wrong if this\n\t\t * requirement isn't satisfied.\n\t\t */\n\t\tif (!smp_load_acquire(&sp->unsync) &&\n\t\t    !smp_load_acquire(&sp->unsync_children))\n\t\t\treturn;\n\n\t\tspin_lock(&vcpu->kvm->mmu_lock);\n\t\tkvm_mmu_audit(vcpu, AUDIT_PRE_SYNC);\n\n\t\tmmu_sync_children(vcpu, sp);\n\n\t\tkvm_mmu_audit(vcpu, AUDIT_POST_SYNC);\n\t\tspin_unlock(&vcpu->kvm->mmu_lock);\n\t\treturn;\n\t}\n\n\tspin_lock(&vcpu->kvm->mmu_lock);\n\tkvm_mmu_audit(vcpu, AUDIT_PRE_SYNC);\n\n\tfor (i = 0; i < 4; ++i) {\n\t\thpa_t root = vcpu->arch.mmu->pae_root[i];\n\n\t\tif (root && VALID_PAGE(root)) {\n\t\t\troot &= PT64_BASE_ADDR_MASK;\n\t\t\tsp = to_shadow_page(root);\n\t\t\tmmu_sync_children(vcpu, sp);\n\t\t}\n\t}\n\n\tkvm_mmu_audit(vcpu, AUDIT_POST_SYNC);\n\tspin_unlock(&vcpu->kvm->mmu_lock);\n}\nEXPORT_SYMBOL_GPL(kvm_mmu_sync_roots);\n\nstatic gpa_t nonpaging_gva_to_gpa(struct kvm_vcpu *vcpu, gpa_t vaddr,\n\t\t\t\t  u32 access, struct x86_exception *exception)\n{\n\tif (exception)\n\t\texception->error_code = 0;\n\treturn vaddr;\n}\n\nstatic gpa_t nonpaging_gva_to_gpa_nested(struct kvm_vcpu *vcpu, gpa_t vaddr,\n\t\t\t\t\t u32 access,\n\t\t\t\t\t struct x86_exception *exception)\n{\n\tif (exception)\n\t\texception->error_code = 0;\n\treturn vcpu->arch.nested_mmu.translate_gpa(vcpu, vaddr, access, exception);\n}\n\nstatic bool\n__is_rsvd_bits_set(struct rsvd_bits_validate *rsvd_check, u64 pte, int level)\n{\n\tint bit7 = (pte >> 7) & 1;\n\n\treturn pte & rsvd_check->rsvd_bits_mask[bit7][level-1];\n}\n\nstatic bool __is_bad_mt_xwr(struct rsvd_bits_validate *rsvd_check, u64 pte)\n{\n\treturn rsvd_check->bad_mt_xwr & BIT_ULL(pte & 0x3f);\n}\n\nstatic bool mmio_info_in_cache(struct kvm_vcpu *vcpu, u64 addr, bool direct)\n{\n\t/*\n\t * A nested guest cannot use the MMIO cache if it is using nested\n\t * page tables, because cr2 is a nGPA while the cache stores GPAs.\n\t */\n\tif (mmu_is_nested(vcpu))\n\t\treturn false;\n\n\tif (direct)\n\t\treturn vcpu_match_mmio_gpa(vcpu, addr);\n\n\treturn vcpu_match_mmio_gva(vcpu, addr);\n}\n\n/*\n * Return the level of the lowest level SPTE added to sptes.\n * That SPTE may be non-present.\n */\nstatic int get_walk(struct kvm_vcpu *vcpu, u64 addr, u64 *sptes, int *root_level)\n{\n\tstruct kvm_shadow_walk_iterator iterator;\n\tint leaf = -1;\n\tu64 spte;\n\n\twalk_shadow_page_lockless_begin(vcpu);\n\n\tfor (shadow_walk_init(&iterator, vcpu, addr),\n\t     *root_level = iterator.level;\n\t     shadow_walk_okay(&iterator);\n\t     __shadow_walk_next(&iterator, spte)) {\n\t\tleaf = iterator.level;\n\t\tspte = mmu_spte_get_lockless(iterator.sptep);\n\n\t\tsptes[leaf] = spte;\n\n\t\tif (!is_shadow_present_pte(spte))\n\t\t\tbreak;\n\t}\n\n\twalk_shadow_page_lockless_end(vcpu);\n\n\treturn leaf;\n}\n\n/* return true if reserved bit(s) are detected on a valid, non-MMIO SPTE. */\nstatic bool get_mmio_spte(struct kvm_vcpu *vcpu, u64 addr, u64 *sptep)\n{\n\tu64 sptes[PT64_ROOT_MAX_LEVEL + 1];\n\tstruct rsvd_bits_validate *rsvd_check;\n\tint root, leaf, level;\n\tbool reserved = false;\n\n\tif (!VALID_PAGE(vcpu->arch.mmu->root_hpa)) {\n\t\t*sptep = 0ull;\n\t\treturn reserved;\n\t}\n\n\tif (is_tdp_mmu_root(vcpu->kvm, vcpu->arch.mmu->root_hpa))\n\t\tleaf = kvm_tdp_mmu_get_walk(vcpu, addr, sptes, &root);\n\telse\n\t\tleaf = get_walk(vcpu, addr, sptes, &root);\n\n\tif (unlikely(leaf < 0)) {\n\t\t*sptep = 0ull;\n\t\treturn reserved;\n\t}\n\n\t*sptep = sptes[leaf];\n\n\t/*\n\t * Skip reserved bits checks on the terminal leaf if it's not a valid\n\t * SPTE.  Note, this also (intentionally) skips MMIO SPTEs, which, by\n\t * design, always have reserved bits set.  The purpose of the checks is\n\t * to detect reserved bits on non-MMIO SPTEs. i.e. buggy SPTEs.\n\t */\n\tif (!is_shadow_present_pte(sptes[leaf]))\n\t\tleaf++;\n\n\trsvd_check = &vcpu->arch.mmu->shadow_zero_check;\n\n\tfor (level = root; level >= leaf; level--)\n\t\t/*\n\t\t * Use a bitwise-OR instead of a logical-OR to aggregate the\n\t\t * reserved bit and EPT's invalid memtype/XWR checks to avoid\n\t\t * adding a Jcc in the loop.\n\t\t */\n\t\treserved |= __is_bad_mt_xwr(rsvd_check, sptes[level]) |\n\t\t\t    __is_rsvd_bits_set(rsvd_check, sptes[level], level);\n\n\tif (reserved) {\n\t\tpr_err(\"%s: detect reserved bits on spte, addr 0x%llx, dump hierarchy:\\n\",\n\t\t       __func__, addr);\n\t\tfor (level = root; level >= leaf; level--)\n\t\t\tpr_err(\"------ spte 0x%llx level %d.\\n\",\n\t\t\t       sptes[level], level);\n\t}\n\n\treturn reserved;\n}\n\nstatic int handle_mmio_page_fault(struct kvm_vcpu *vcpu, u64 addr, bool direct)\n{\n\tu64 spte;\n\tbool reserved;\n\n\tif (mmio_info_in_cache(vcpu, addr, direct))\n\t\treturn RET_PF_EMULATE;\n\n\treserved = get_mmio_spte(vcpu, addr, &spte);\n\tif (WARN_ON(reserved))\n\t\treturn -EINVAL;\n\n\tif (is_mmio_spte(spte)) {\n\t\tgfn_t gfn = get_mmio_spte_gfn(spte);\n\t\tunsigned int access = get_mmio_spte_access(spte);\n\n\t\tif (!check_mmio_spte(vcpu, spte))\n\t\t\treturn RET_PF_INVALID;\n\n\t\tif (direct)\n\t\t\taddr = 0;\n\n\t\ttrace_handle_mmio_page_fault(addr, gfn, access);\n\t\tvcpu_cache_mmio_info(vcpu, addr, gfn, access);\n\t\treturn RET_PF_EMULATE;\n\t}\n\n\t/*\n\t * If the page table is zapped by other cpus, let CPU fault again on\n\t * the address.\n\t */\n\treturn RET_PF_RETRY;\n}\n\nstatic bool page_fault_handle_page_track(struct kvm_vcpu *vcpu,\n\t\t\t\t\t u32 error_code, gfn_t gfn)\n{\n\tif (unlikely(error_code & PFERR_RSVD_MASK))\n\t\treturn false;\n\n\tif (!(error_code & PFERR_PRESENT_MASK) ||\n\t      !(error_code & PFERR_WRITE_MASK))\n\t\treturn false;\n\n\t/*\n\t * guest is writing the page which is write tracked which can\n\t * not be fixed by page fault handler.\n\t */\n\tif (kvm_page_track_is_active(vcpu, gfn, KVM_PAGE_TRACK_WRITE))\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic void shadow_page_table_clear_flood(struct kvm_vcpu *vcpu, gva_t addr)\n{\n\tstruct kvm_shadow_walk_iterator iterator;\n\tu64 spte;\n\n\twalk_shadow_page_lockless_begin(vcpu);\n\tfor_each_shadow_entry_lockless(vcpu, addr, iterator, spte) {\n\t\tclear_sp_write_flooding_count(iterator.sptep);\n\t\tif (!is_shadow_present_pte(spte))\n\t\t\tbreak;\n\t}\n\twalk_shadow_page_lockless_end(vcpu);\n}\n\nstatic bool kvm_arch_setup_async_pf(struct kvm_vcpu *vcpu, gpa_t cr2_or_gpa,\n\t\t\t\t    gfn_t gfn)\n{\n\tstruct kvm_arch_async_pf arch;\n\n\tarch.token = (vcpu->arch.apf.id++ << 12) | vcpu->vcpu_id;\n\tarch.gfn = gfn;\n\tarch.direct_map = vcpu->arch.mmu->direct_map;\n\tarch.cr3 = vcpu->arch.mmu->get_guest_pgd(vcpu);\n\n\treturn kvm_setup_async_pf(vcpu, cr2_or_gpa,\n\t\t\t\t  kvm_vcpu_gfn_to_hva(vcpu, gfn), &arch);\n}\n\nstatic bool try_async_pf(struct kvm_vcpu *vcpu, bool prefault, gfn_t gfn,\n\t\t\t gpa_t cr2_or_gpa, kvm_pfn_t *pfn, bool write,\n\t\t\t bool *writable)\n{\n\tstruct kvm_memory_slot *slot = kvm_vcpu_gfn_to_memslot(vcpu, gfn);\n\tbool async;\n\n\t/* Don't expose private memslots to L2. */\n\tif (is_guest_mode(vcpu) && !kvm_is_visible_memslot(slot)) {\n\t\t*pfn = KVM_PFN_NOSLOT;\n\t\t*writable = false;\n\t\treturn false;\n\t}\n\n\tasync = false;\n\t*pfn = __gfn_to_pfn_memslot(slot, gfn, false, &async, write, writable);\n\tif (!async)\n\t\treturn false; /* *pfn has correct page already */\n\n\tif (!prefault && kvm_can_do_async_pf(vcpu)) {\n\t\ttrace_kvm_try_async_get_page(cr2_or_gpa, gfn);\n\t\tif (kvm_find_async_pf_gfn(vcpu, gfn)) {\n\t\t\ttrace_kvm_async_pf_doublefault(cr2_or_gpa, gfn);\n\t\t\tkvm_make_request(KVM_REQ_APF_HALT, vcpu);\n\t\t\treturn true;\n\t\t} else if (kvm_arch_setup_async_pf(vcpu, cr2_or_gpa, gfn))\n\t\t\treturn true;\n\t}\n\n\t*pfn = __gfn_to_pfn_memslot(slot, gfn, false, NULL, write, writable);\n\treturn false;\n}\n\nstatic int direct_page_fault(struct kvm_vcpu *vcpu, gpa_t gpa, u32 error_code,\n\t\t\t     bool prefault, int max_level, bool is_tdp)\n{\n\tbool write = error_code & PFERR_WRITE_MASK;\n\tbool map_writable;\n\n\tgfn_t gfn = gpa >> PAGE_SHIFT;\n\tunsigned long mmu_seq;\n\tkvm_pfn_t pfn;\n\tint r;\n\n\tif (page_fault_handle_page_track(vcpu, error_code, gfn))\n\t\treturn RET_PF_EMULATE;\n\n\tif (!is_tdp_mmu_root(vcpu->kvm, vcpu->arch.mmu->root_hpa)) {\n\t\tr = fast_page_fault(vcpu, gpa, error_code);\n\t\tif (r != RET_PF_INVALID)\n\t\t\treturn r;\n\t}\n\n\tr = mmu_topup_memory_caches(vcpu, false);\n\tif (r)\n\t\treturn r;\n\n\tmmu_seq = vcpu->kvm->mmu_notifier_seq;\n\tsmp_rmb();\n\n\tif (try_async_pf(vcpu, prefault, gfn, gpa, &pfn, write, &map_writable))\n\t\treturn RET_PF_RETRY;\n\n\tif (handle_abnormal_pfn(vcpu, is_tdp ? 0 : gpa, gfn, pfn, ACC_ALL, &r))\n\t\treturn r;\n\n\tr = RET_PF_RETRY;\n\tspin_lock(&vcpu->kvm->mmu_lock);\n\tif (mmu_notifier_retry(vcpu->kvm, mmu_seq))\n\t\tgoto out_unlock;\n\tr = make_mmu_pages_available(vcpu);\n\tif (r)\n\t\tgoto out_unlock;\n\n\tif (is_tdp_mmu_root(vcpu->kvm, vcpu->arch.mmu->root_hpa))\n\t\tr = kvm_tdp_mmu_map(vcpu, gpa, error_code, map_writable, max_level,\n\t\t\t\t    pfn, prefault);\n\telse\n\t\tr = __direct_map(vcpu, gpa, error_code, map_writable, max_level, pfn,\n\t\t\t\t prefault, is_tdp);\n\nout_unlock:\n\tspin_unlock(&vcpu->kvm->mmu_lock);\n\tkvm_release_pfn_clean(pfn);\n\treturn r;\n}\n\nstatic int nonpaging_page_fault(struct kvm_vcpu *vcpu, gpa_t gpa,\n\t\t\t\tu32 error_code, bool prefault)\n{\n\tpgprintk(\"%s: gva %lx error %x\\n\", __func__, gpa, error_code);\n\n\t/* This path builds a PAE pagetable, we can map 2mb pages at maximum. */\n\treturn direct_page_fault(vcpu, gpa & PAGE_MASK, error_code, prefault,\n\t\t\t\t PG_LEVEL_2M, false);\n}\n\nint kvm_handle_page_fault(struct kvm_vcpu *vcpu, u64 error_code,\n\t\t\t\tu64 fault_address, char *insn, int insn_len)\n{\n\tint r = 1;\n\tu32 flags = vcpu->arch.apf.host_apf_flags;\n\n#ifndef CONFIG_X86_64\n\t/* A 64-bit CR2 should be impossible on 32-bit KVM. */\n\tif (WARN_ON_ONCE(fault_address >> 32))\n\t\treturn -EFAULT;\n#endif\n\n\tvcpu->arch.l1tf_flush_l1d = true;\n\tif (!flags) {\n\t\ttrace_kvm_page_fault(fault_address, error_code);\n\n\t\tif (kvm_event_needs_reinjection(vcpu))\n\t\t\tkvm_mmu_unprotect_page_virt(vcpu, fault_address);\n\t\tr = kvm_mmu_page_fault(vcpu, fault_address, error_code, insn,\n\t\t\t\tinsn_len);\n\t} else if (flags & KVM_PV_REASON_PAGE_NOT_PRESENT) {\n\t\tvcpu->arch.apf.host_apf_flags = 0;\n\t\tlocal_irq_disable();\n\t\tkvm_async_pf_task_wait_schedule(fault_address);\n\t\tlocal_irq_enable();\n\t} else {\n\t\tWARN_ONCE(1, \"Unexpected host async PF flags: %x\\n\", flags);\n\t}\n\n\treturn r;\n}\nEXPORT_SYMBOL_GPL(kvm_handle_page_fault);\n\nint kvm_tdp_page_fault(struct kvm_vcpu *vcpu, gpa_t gpa, u32 error_code,\n\t\t       bool prefault)\n{\n\tint max_level;\n\n\tfor (max_level = KVM_MAX_HUGEPAGE_LEVEL;\n\t     max_level > PG_LEVEL_4K;\n\t     max_level--) {\n\t\tint page_num = KVM_PAGES_PER_HPAGE(max_level);\n\t\tgfn_t base = (gpa >> PAGE_SHIFT) & ~(page_num - 1);\n\n\t\tif (kvm_mtrr_check_gfn_range_consistency(vcpu, base, page_num))\n\t\t\tbreak;\n\t}\n\n\treturn direct_page_fault(vcpu, gpa, error_code, prefault,\n\t\t\t\t max_level, true);\n}\n\nstatic void nonpaging_init_context(struct kvm_vcpu *vcpu,\n\t\t\t\t   struct kvm_mmu *context)\n{\n\tcontext->page_fault = nonpaging_page_fault;\n\tcontext->gva_to_gpa = nonpaging_gva_to_gpa;\n\tcontext->sync_page = nonpaging_sync_page;\n\tcontext->invlpg = NULL;\n\tcontext->update_pte = nonpaging_update_pte;\n\tcontext->root_level = 0;\n\tcontext->shadow_root_level = PT32E_ROOT_LEVEL;\n\tcontext->direct_map = true;\n\tcontext->nx = false;\n}\n\nstatic inline bool is_root_usable(struct kvm_mmu_root_info *root, gpa_t pgd,\n\t\t\t\t  union kvm_mmu_page_role role)\n{\n\treturn (role.direct || pgd == root->pgd) &&\n\t       VALID_PAGE(root->hpa) && to_shadow_page(root->hpa) &&\n\t       role.word == to_shadow_page(root->hpa)->role.word;\n}\n\n/*\n * Find out if a previously cached root matching the new pgd/role is available.\n * The current root is also inserted into the cache.\n * If a matching root was found, it is assigned to kvm_mmu->root_hpa and true is\n * returned.\n * Otherwise, the LRU root from the cache is assigned to kvm_mmu->root_hpa and\n * false is returned. This root should now be freed by the caller.\n */\nstatic bool cached_root_available(struct kvm_vcpu *vcpu, gpa_t new_pgd,\n\t\t\t\t  union kvm_mmu_page_role new_role)\n{\n\tuint i;\n\tstruct kvm_mmu_root_info root;\n\tstruct kvm_mmu *mmu = vcpu->arch.mmu;\n\n\troot.pgd = mmu->root_pgd;\n\troot.hpa = mmu->root_hpa;\n\n\tif (is_root_usable(&root, new_pgd, new_role))\n\t\treturn true;\n\n\tfor (i = 0; i < KVM_MMU_NUM_PREV_ROOTS; i++) {\n\t\tswap(root, mmu->prev_roots[i]);\n\n\t\tif (is_root_usable(&root, new_pgd, new_role))\n\t\t\tbreak;\n\t}\n\n\tmmu->root_hpa = root.hpa;\n\tmmu->root_pgd = root.pgd;\n\n\treturn i < KVM_MMU_NUM_PREV_ROOTS;\n}\n\nstatic bool fast_pgd_switch(struct kvm_vcpu *vcpu, gpa_t new_pgd,\n\t\t\t    union kvm_mmu_page_role new_role)\n{\n\tstruct kvm_mmu *mmu = vcpu->arch.mmu;\n\n\t/*\n\t * For now, limit the fast switch to 64-bit hosts+VMs in order to avoid\n\t * having to deal with PDPTEs. We may add support for 32-bit hosts/VMs\n\t * later if necessary.\n\t */\n\tif (mmu->shadow_root_level >= PT64_ROOT_4LEVEL &&\n\t    mmu->root_level >= PT64_ROOT_4LEVEL)\n\t\treturn cached_root_available(vcpu, new_pgd, new_role);\n\n\treturn false;\n}\n\nstatic void __kvm_mmu_new_pgd(struct kvm_vcpu *vcpu, gpa_t new_pgd,\n\t\t\t      union kvm_mmu_page_role new_role,\n\t\t\t      bool skip_tlb_flush, bool skip_mmu_sync)\n{\n\tif (!fast_pgd_switch(vcpu, new_pgd, new_role)) {\n\t\tkvm_mmu_free_roots(vcpu, vcpu->arch.mmu, KVM_MMU_ROOT_CURRENT);\n\t\treturn;\n\t}\n\n\t/*\n\t * It's possible that the cached previous root page is obsolete because\n\t * of a change in the MMU generation number. However, changing the\n\t * generation number is accompanied by KVM_REQ_MMU_RELOAD, which will\n\t * free the root set here and allocate a new one.\n\t */\n\tkvm_make_request(KVM_REQ_LOAD_MMU_PGD, vcpu);\n\n\tif (!skip_mmu_sync || force_flush_and_sync_on_reuse)\n\t\tkvm_make_request(KVM_REQ_MMU_SYNC, vcpu);\n\tif (!skip_tlb_flush || force_flush_and_sync_on_reuse)\n\t\tkvm_make_request(KVM_REQ_TLB_FLUSH_CURRENT, vcpu);\n\n\t/*\n\t * The last MMIO access's GVA and GPA are cached in the VCPU. When\n\t * switching to a new CR3, that GVA->GPA mapping may no longer be\n\t * valid. So clear any cached MMIO info even when we don't need to sync\n\t * the shadow page tables.\n\t */\n\tvcpu_clear_mmio_info(vcpu, MMIO_GVA_ANY);\n\n\t/*\n\t * If this is a direct root page, it doesn't have a write flooding\n\t * count. Otherwise, clear the write flooding count.\n\t */\n\tif (!new_role.direct)\n\t\t__clear_sp_write_flooding_count(\n\t\t\t\tto_shadow_page(vcpu->arch.mmu->root_hpa));\n}\n\nvoid kvm_mmu_new_pgd(struct kvm_vcpu *vcpu, gpa_t new_pgd, bool skip_tlb_flush,\n\t\t     bool skip_mmu_sync)\n{\n\t__kvm_mmu_new_pgd(vcpu, new_pgd, kvm_mmu_calc_root_page_role(vcpu),\n\t\t\t  skip_tlb_flush, skip_mmu_sync);\n}\nEXPORT_SYMBOL_GPL(kvm_mmu_new_pgd);\n\nstatic unsigned long get_cr3(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_read_cr3(vcpu);\n}\n\nstatic bool sync_mmio_spte(struct kvm_vcpu *vcpu, u64 *sptep, gfn_t gfn,\n\t\t\t   unsigned int access, int *nr_present)\n{\n\tif (unlikely(is_mmio_spte(*sptep))) {\n\t\tif (gfn != get_mmio_spte_gfn(*sptep)) {\n\t\t\tmmu_spte_clear_no_track(sptep);\n\t\t\treturn true;\n\t\t}\n\n\t\t(*nr_present)++;\n\t\tmark_mmio_spte(vcpu, sptep, gfn, access);\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic inline bool is_last_gpte(struct kvm_mmu *mmu,\n\t\t\t\tunsigned level, unsigned gpte)\n{\n\t/*\n\t * The RHS has bit 7 set iff level < mmu->last_nonleaf_level.\n\t * If it is clear, there are no large pages at this level, so clear\n\t * PT_PAGE_SIZE_MASK in gpte if that is the case.\n\t */\n\tgpte &= level - mmu->last_nonleaf_level;\n\n\t/*\n\t * PG_LEVEL_4K always terminates.  The RHS has bit 7 set\n\t * iff level <= PG_LEVEL_4K, which for our purpose means\n\t * level == PG_LEVEL_4K; set PT_PAGE_SIZE_MASK in gpte then.\n\t */\n\tgpte |= level - PG_LEVEL_4K - 1;\n\n\treturn gpte & PT_PAGE_SIZE_MASK;\n}\n\n#define PTTYPE_EPT 18 /* arbitrary */\n#define PTTYPE PTTYPE_EPT\n#include \"paging_tmpl.h\"\n#undef PTTYPE\n\n#define PTTYPE 64\n#include \"paging_tmpl.h\"\n#undef PTTYPE\n\n#define PTTYPE 32\n#include \"paging_tmpl.h\"\n#undef PTTYPE\n\nstatic void\n__reset_rsvds_bits_mask(struct kvm_vcpu *vcpu,\n\t\t\tstruct rsvd_bits_validate *rsvd_check,\n\t\t\tint maxphyaddr, int level, bool nx, bool gbpages,\n\t\t\tbool pse, bool amd)\n{\n\tu64 exb_bit_rsvd = 0;\n\tu64 gbpages_bit_rsvd = 0;\n\tu64 nonleaf_bit8_rsvd = 0;\n\n\trsvd_check->bad_mt_xwr = 0;\n\n\tif (!nx)\n\t\texb_bit_rsvd = rsvd_bits(63, 63);\n\tif (!gbpages)\n\t\tgbpages_bit_rsvd = rsvd_bits(7, 7);\n\n\t/*\n\t * Non-leaf PML4Es and PDPEs reserve bit 8 (which would be the G bit for\n\t * leaf entries) on AMD CPUs only.\n\t */\n\tif (amd)\n\t\tnonleaf_bit8_rsvd = rsvd_bits(8, 8);\n\n\tswitch (level) {\n\tcase PT32_ROOT_LEVEL:\n\t\t/* no rsvd bits for 2 level 4K page table entries */\n\t\trsvd_check->rsvd_bits_mask[0][1] = 0;\n\t\trsvd_check->rsvd_bits_mask[0][0] = 0;\n\t\trsvd_check->rsvd_bits_mask[1][0] =\n\t\t\trsvd_check->rsvd_bits_mask[0][0];\n\n\t\tif (!pse) {\n\t\t\trsvd_check->rsvd_bits_mask[1][1] = 0;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (is_cpuid_PSE36())\n\t\t\t/* 36bits PSE 4MB page */\n\t\t\trsvd_check->rsvd_bits_mask[1][1] = rsvd_bits(17, 21);\n\t\telse\n\t\t\t/* 32 bits PSE 4MB page */\n\t\t\trsvd_check->rsvd_bits_mask[1][1] = rsvd_bits(13, 21);\n\t\tbreak;\n\tcase PT32E_ROOT_LEVEL:\n\t\trsvd_check->rsvd_bits_mask[0][2] =\n\t\t\trsvd_bits(maxphyaddr, 63) |\n\t\t\trsvd_bits(5, 8) | rsvd_bits(1, 2);\t/* PDPTE */\n\t\trsvd_check->rsvd_bits_mask[0][1] = exb_bit_rsvd |\n\t\t\trsvd_bits(maxphyaddr, 62);\t/* PDE */\n\t\trsvd_check->rsvd_bits_mask[0][0] = exb_bit_rsvd |\n\t\t\trsvd_bits(maxphyaddr, 62); \t/* PTE */\n\t\trsvd_check->rsvd_bits_mask[1][1] = exb_bit_rsvd |\n\t\t\trsvd_bits(maxphyaddr, 62) |\n\t\t\trsvd_bits(13, 20);\t\t/* large page */\n\t\trsvd_check->rsvd_bits_mask[1][0] =\n\t\t\trsvd_check->rsvd_bits_mask[0][0];\n\t\tbreak;\n\tcase PT64_ROOT_5LEVEL:\n\t\trsvd_check->rsvd_bits_mask[0][4] = exb_bit_rsvd |\n\t\t\tnonleaf_bit8_rsvd | rsvd_bits(7, 7) |\n\t\t\trsvd_bits(maxphyaddr, 51);\n\t\trsvd_check->rsvd_bits_mask[1][4] =\n\t\t\trsvd_check->rsvd_bits_mask[0][4];\n\t\tfallthrough;\n\tcase PT64_ROOT_4LEVEL:\n\t\trsvd_check->rsvd_bits_mask[0][3] = exb_bit_rsvd |\n\t\t\tnonleaf_bit8_rsvd | rsvd_bits(7, 7) |\n\t\t\trsvd_bits(maxphyaddr, 51);\n\t\trsvd_check->rsvd_bits_mask[0][2] = exb_bit_rsvd |\n\t\t\tgbpages_bit_rsvd |\n\t\t\trsvd_bits(maxphyaddr, 51);\n\t\trsvd_check->rsvd_bits_mask[0][1] = exb_bit_rsvd |\n\t\t\trsvd_bits(maxphyaddr, 51);\n\t\trsvd_check->rsvd_bits_mask[0][0] = exb_bit_rsvd |\n\t\t\trsvd_bits(maxphyaddr, 51);\n\t\trsvd_check->rsvd_bits_mask[1][3] =\n\t\t\trsvd_check->rsvd_bits_mask[0][3];\n\t\trsvd_check->rsvd_bits_mask[1][2] = exb_bit_rsvd |\n\t\t\tgbpages_bit_rsvd | rsvd_bits(maxphyaddr, 51) |\n\t\t\trsvd_bits(13, 29);\n\t\trsvd_check->rsvd_bits_mask[1][1] = exb_bit_rsvd |\n\t\t\trsvd_bits(maxphyaddr, 51) |\n\t\t\trsvd_bits(13, 20);\t\t/* large page */\n\t\trsvd_check->rsvd_bits_mask[1][0] =\n\t\t\trsvd_check->rsvd_bits_mask[0][0];\n\t\tbreak;\n\t}\n}\n\nstatic void reset_rsvds_bits_mask(struct kvm_vcpu *vcpu,\n\t\t\t\t  struct kvm_mmu *context)\n{\n\t__reset_rsvds_bits_mask(vcpu, &context->guest_rsvd_check,\n\t\t\t\tcpuid_maxphyaddr(vcpu), context->root_level,\n\t\t\t\tcontext->nx,\n\t\t\t\tguest_cpuid_has(vcpu, X86_FEATURE_GBPAGES),\n\t\t\t\tis_pse(vcpu),\n\t\t\t\tguest_cpuid_is_amd_or_hygon(vcpu));\n}\n\nstatic void\n__reset_rsvds_bits_mask_ept(struct rsvd_bits_validate *rsvd_check,\n\t\t\t    int maxphyaddr, bool execonly)\n{\n\tu64 bad_mt_xwr;\n\n\trsvd_check->rsvd_bits_mask[0][4] =\n\t\trsvd_bits(maxphyaddr, 51) | rsvd_bits(3, 7);\n\trsvd_check->rsvd_bits_mask[0][3] =\n\t\trsvd_bits(maxphyaddr, 51) | rsvd_bits(3, 7);\n\trsvd_check->rsvd_bits_mask[0][2] =\n\t\trsvd_bits(maxphyaddr, 51) | rsvd_bits(3, 6);\n\trsvd_check->rsvd_bits_mask[0][1] =\n\t\trsvd_bits(maxphyaddr, 51) | rsvd_bits(3, 6);\n\trsvd_check->rsvd_bits_mask[0][0] = rsvd_bits(maxphyaddr, 51);\n\n\t/* large page */\n\trsvd_check->rsvd_bits_mask[1][4] = rsvd_check->rsvd_bits_mask[0][4];\n\trsvd_check->rsvd_bits_mask[1][3] = rsvd_check->rsvd_bits_mask[0][3];\n\trsvd_check->rsvd_bits_mask[1][2] =\n\t\trsvd_bits(maxphyaddr, 51) | rsvd_bits(12, 29);\n\trsvd_check->rsvd_bits_mask[1][1] =\n\t\trsvd_bits(maxphyaddr, 51) | rsvd_bits(12, 20);\n\trsvd_check->rsvd_bits_mask[1][0] = rsvd_check->rsvd_bits_mask[0][0];\n\n\tbad_mt_xwr = 0xFFull << (2 * 8);\t/* bits 3..5 must not be 2 */\n\tbad_mt_xwr |= 0xFFull << (3 * 8);\t/* bits 3..5 must not be 3 */\n\tbad_mt_xwr |= 0xFFull << (7 * 8);\t/* bits 3..5 must not be 7 */\n\tbad_mt_xwr |= REPEAT_BYTE(1ull << 2);\t/* bits 0..2 must not be 010 */\n\tbad_mt_xwr |= REPEAT_BYTE(1ull << 6);\t/* bits 0..2 must not be 110 */\n\tif (!execonly) {\n\t\t/* bits 0..2 must not be 100 unless VMX capabilities allow it */\n\t\tbad_mt_xwr |= REPEAT_BYTE(1ull << 4);\n\t}\n\trsvd_check->bad_mt_xwr = bad_mt_xwr;\n}\n\nstatic void reset_rsvds_bits_mask_ept(struct kvm_vcpu *vcpu,\n\t\tstruct kvm_mmu *context, bool execonly)\n{\n\t__reset_rsvds_bits_mask_ept(&context->guest_rsvd_check,\n\t\t\t\t    cpuid_maxphyaddr(vcpu), execonly);\n}\n\n/*\n * the page table on host is the shadow page table for the page\n * table in guest or amd nested guest, its mmu features completely\n * follow the features in guest.\n */\nvoid\nreset_shadow_zero_bits_mask(struct kvm_vcpu *vcpu, struct kvm_mmu *context)\n{\n\tbool uses_nx = context->nx ||\n\t\tcontext->mmu_role.base.smep_andnot_wp;\n\tstruct rsvd_bits_validate *shadow_zero_check;\n\tint i;\n\n\t/*\n\t * Passing \"true\" to the last argument is okay; it adds a check\n\t * on bit 8 of the SPTEs which KVM doesn't use anyway.\n\t */\n\tshadow_zero_check = &context->shadow_zero_check;\n\t__reset_rsvds_bits_mask(vcpu, shadow_zero_check,\n\t\t\t\tshadow_phys_bits,\n\t\t\t\tcontext->shadow_root_level, uses_nx,\n\t\t\t\tguest_cpuid_has(vcpu, X86_FEATURE_GBPAGES),\n\t\t\t\tis_pse(vcpu), true);\n\n\tif (!shadow_me_mask)\n\t\treturn;\n\n\tfor (i = context->shadow_root_level; --i >= 0;) {\n\t\tshadow_zero_check->rsvd_bits_mask[0][i] &= ~shadow_me_mask;\n\t\tshadow_zero_check->rsvd_bits_mask[1][i] &= ~shadow_me_mask;\n\t}\n\n}\nEXPORT_SYMBOL_GPL(reset_shadow_zero_bits_mask);\n\nstatic inline bool boot_cpu_is_amd(void)\n{\n\tWARN_ON_ONCE(!tdp_enabled);\n\treturn shadow_x_mask == 0;\n}\n\n/*\n * the direct page table on host, use as much mmu features as\n * possible, however, kvm currently does not do execution-protection.\n */\nstatic void\nreset_tdp_shadow_zero_bits_mask(struct kvm_vcpu *vcpu,\n\t\t\t\tstruct kvm_mmu *context)\n{\n\tstruct rsvd_bits_validate *shadow_zero_check;\n\tint i;\n\n\tshadow_zero_check = &context->shadow_zero_check;\n\n\tif (boot_cpu_is_amd())\n\t\t__reset_rsvds_bits_mask(vcpu, shadow_zero_check,\n\t\t\t\t\tshadow_phys_bits,\n\t\t\t\t\tcontext->shadow_root_level, false,\n\t\t\t\t\tboot_cpu_has(X86_FEATURE_GBPAGES),\n\t\t\t\t\ttrue, true);\n\telse\n\t\t__reset_rsvds_bits_mask_ept(shadow_zero_check,\n\t\t\t\t\t    shadow_phys_bits,\n\t\t\t\t\t    false);\n\n\tif (!shadow_me_mask)\n\t\treturn;\n\n\tfor (i = context->shadow_root_level; --i >= 0;) {\n\t\tshadow_zero_check->rsvd_bits_mask[0][i] &= ~shadow_me_mask;\n\t\tshadow_zero_check->rsvd_bits_mask[1][i] &= ~shadow_me_mask;\n\t}\n}\n\n/*\n * as the comments in reset_shadow_zero_bits_mask() except it\n * is the shadow page table for intel nested guest.\n */\nstatic void\nreset_ept_shadow_zero_bits_mask(struct kvm_vcpu *vcpu,\n\t\t\t\tstruct kvm_mmu *context, bool execonly)\n{\n\t__reset_rsvds_bits_mask_ept(&context->shadow_zero_check,\n\t\t\t\t    shadow_phys_bits, execonly);\n}\n\n#define BYTE_MASK(access) \\\n\t((1 & (access) ? 2 : 0) | \\\n\t (2 & (access) ? 4 : 0) | \\\n\t (3 & (access) ? 8 : 0) | \\\n\t (4 & (access) ? 16 : 0) | \\\n\t (5 & (access) ? 32 : 0) | \\\n\t (6 & (access) ? 64 : 0) | \\\n\t (7 & (access) ? 128 : 0))\n\n\nstatic void update_permission_bitmask(struct kvm_vcpu *vcpu,\n\t\t\t\t      struct kvm_mmu *mmu, bool ept)\n{\n\tunsigned byte;\n\n\tconst u8 x = BYTE_MASK(ACC_EXEC_MASK);\n\tconst u8 w = BYTE_MASK(ACC_WRITE_MASK);\n\tconst u8 u = BYTE_MASK(ACC_USER_MASK);\n\n\tbool cr4_smep = kvm_read_cr4_bits(vcpu, X86_CR4_SMEP) != 0;\n\tbool cr4_smap = kvm_read_cr4_bits(vcpu, X86_CR4_SMAP) != 0;\n\tbool cr0_wp = is_write_protection(vcpu);\n\n\tfor (byte = 0; byte < ARRAY_SIZE(mmu->permissions); ++byte) {\n\t\tunsigned pfec = byte << 1;\n\n\t\t/*\n\t\t * Each \"*f\" variable has a 1 bit for each UWX value\n\t\t * that causes a fault with the given PFEC.\n\t\t */\n\n\t\t/* Faults from writes to non-writable pages */\n\t\tu8 wf = (pfec & PFERR_WRITE_MASK) ? (u8)~w : 0;\n\t\t/* Faults from user mode accesses to supervisor pages */\n\t\tu8 uf = (pfec & PFERR_USER_MASK) ? (u8)~u : 0;\n\t\t/* Faults from fetches of non-executable pages*/\n\t\tu8 ff = (pfec & PFERR_FETCH_MASK) ? (u8)~x : 0;\n\t\t/* Faults from kernel mode fetches of user pages */\n\t\tu8 smepf = 0;\n\t\t/* Faults from kernel mode accesses of user pages */\n\t\tu8 smapf = 0;\n\n\t\tif (!ept) {\n\t\t\t/* Faults from kernel mode accesses to user pages */\n\t\t\tu8 kf = (pfec & PFERR_USER_MASK) ? 0 : u;\n\n\t\t\t/* Not really needed: !nx will cause pte.nx to fault */\n\t\t\tif (!mmu->nx)\n\t\t\t\tff = 0;\n\n\t\t\t/* Allow supervisor writes if !cr0.wp */\n\t\t\tif (!cr0_wp)\n\t\t\t\twf = (pfec & PFERR_USER_MASK) ? wf : 0;\n\n\t\t\t/* Disallow supervisor fetches of user code if cr4.smep */\n\t\t\tif (cr4_smep)\n\t\t\t\tsmepf = (pfec & PFERR_FETCH_MASK) ? kf : 0;\n\n\t\t\t/*\n\t\t\t * SMAP:kernel-mode data accesses from user-mode\n\t\t\t * mappings should fault. A fault is considered\n\t\t\t * as a SMAP violation if all of the following\n\t\t\t * conditions are true:\n\t\t\t *   - X86_CR4_SMAP is set in CR4\n\t\t\t *   - A user page is accessed\n\t\t\t *   - The access is not a fetch\n\t\t\t *   - Page fault in kernel mode\n\t\t\t *   - if CPL = 3 or X86_EFLAGS_AC is clear\n\t\t\t *\n\t\t\t * Here, we cover the first three conditions.\n\t\t\t * The fourth is computed dynamically in permission_fault();\n\t\t\t * PFERR_RSVD_MASK bit will be set in PFEC if the access is\n\t\t\t * *not* subject to SMAP restrictions.\n\t\t\t */\n\t\t\tif (cr4_smap)\n\t\t\t\tsmapf = (pfec & (PFERR_RSVD_MASK|PFERR_FETCH_MASK)) ? 0 : kf;\n\t\t}\n\n\t\tmmu->permissions[byte] = ff | uf | wf | smepf | smapf;\n\t}\n}\n\n/*\n* PKU is an additional mechanism by which the paging controls access to\n* user-mode addresses based on the value in the PKRU register.  Protection\n* key violations are reported through a bit in the page fault error code.\n* Unlike other bits of the error code, the PK bit is not known at the\n* call site of e.g. gva_to_gpa; it must be computed directly in\n* permission_fault based on two bits of PKRU, on some machine state (CR4,\n* CR0, EFER, CPL), and on other bits of the error code and the page tables.\n*\n* In particular the following conditions come from the error code, the\n* page tables and the machine state:\n* - PK is always zero unless CR4.PKE=1 and EFER.LMA=1\n* - PK is always zero if RSVD=1 (reserved bit set) or F=1 (instruction fetch)\n* - PK is always zero if U=0 in the page tables\n* - PKRU.WD is ignored if CR0.WP=0 and the access is a supervisor access.\n*\n* The PKRU bitmask caches the result of these four conditions.  The error\n* code (minus the P bit) and the page table's U bit form an index into the\n* PKRU bitmask.  Two bits of the PKRU bitmask are then extracted and ANDed\n* with the two bits of the PKRU register corresponding to the protection key.\n* For the first three conditions above the bits will be 00, thus masking\n* away both AD and WD.  For all reads or if the last condition holds, WD\n* only will be masked away.\n*/\nstatic void update_pkru_bitmask(struct kvm_vcpu *vcpu, struct kvm_mmu *mmu,\n\t\t\t\tbool ept)\n{\n\tunsigned bit;\n\tbool wp;\n\n\tif (ept) {\n\t\tmmu->pkru_mask = 0;\n\t\treturn;\n\t}\n\n\t/* PKEY is enabled only if CR4.PKE and EFER.LMA are both set. */\n\tif (!kvm_read_cr4_bits(vcpu, X86_CR4_PKE) || !is_long_mode(vcpu)) {\n\t\tmmu->pkru_mask = 0;\n\t\treturn;\n\t}\n\n\twp = is_write_protection(vcpu);\n\n\tfor (bit = 0; bit < ARRAY_SIZE(mmu->permissions); ++bit) {\n\t\tunsigned pfec, pkey_bits;\n\t\tbool check_pkey, check_write, ff, uf, wf, pte_user;\n\n\t\tpfec = bit << 1;\n\t\tff = pfec & PFERR_FETCH_MASK;\n\t\tuf = pfec & PFERR_USER_MASK;\n\t\twf = pfec & PFERR_WRITE_MASK;\n\n\t\t/* PFEC.RSVD is replaced by ACC_USER_MASK. */\n\t\tpte_user = pfec & PFERR_RSVD_MASK;\n\n\t\t/*\n\t\t * Only need to check the access which is not an\n\t\t * instruction fetch and is to a user page.\n\t\t */\n\t\tcheck_pkey = (!ff && pte_user);\n\t\t/*\n\t\t * write access is controlled by PKRU if it is a\n\t\t * user access or CR0.WP = 1.\n\t\t */\n\t\tcheck_write = check_pkey && wf && (uf || wp);\n\n\t\t/* PKRU.AD stops both read and write access. */\n\t\tpkey_bits = !!check_pkey;\n\t\t/* PKRU.WD stops write access. */\n\t\tpkey_bits |= (!!check_write) << 1;\n\n\t\tmmu->pkru_mask |= (pkey_bits & 3) << pfec;\n\t}\n}\n\nstatic void update_last_nonleaf_level(struct kvm_vcpu *vcpu, struct kvm_mmu *mmu)\n{\n\tunsigned root_level = mmu->root_level;\n\n\tmmu->last_nonleaf_level = root_level;\n\tif (root_level == PT32_ROOT_LEVEL && is_pse(vcpu))\n\t\tmmu->last_nonleaf_level++;\n}\n\nstatic void paging64_init_context_common(struct kvm_vcpu *vcpu,\n\t\t\t\t\t struct kvm_mmu *context,\n\t\t\t\t\t int level)\n{\n\tcontext->nx = is_nx(vcpu);\n\tcontext->root_level = level;\n\n\treset_rsvds_bits_mask(vcpu, context);\n\tupdate_permission_bitmask(vcpu, context, false);\n\tupdate_pkru_bitmask(vcpu, context, false);\n\tupdate_last_nonleaf_level(vcpu, context);\n\n\tMMU_WARN_ON(!is_pae(vcpu));\n\tcontext->page_fault = paging64_page_fault;\n\tcontext->gva_to_gpa = paging64_gva_to_gpa;\n\tcontext->sync_page = paging64_sync_page;\n\tcontext->invlpg = paging64_invlpg;\n\tcontext->update_pte = paging64_update_pte;\n\tcontext->shadow_root_level = level;\n\tcontext->direct_map = false;\n}\n\nstatic void paging64_init_context(struct kvm_vcpu *vcpu,\n\t\t\t\t  struct kvm_mmu *context)\n{\n\tint root_level = is_la57_mode(vcpu) ?\n\t\t\t PT64_ROOT_5LEVEL : PT64_ROOT_4LEVEL;\n\n\tpaging64_init_context_common(vcpu, context, root_level);\n}\n\nstatic void paging32_init_context(struct kvm_vcpu *vcpu,\n\t\t\t\t  struct kvm_mmu *context)\n{\n\tcontext->nx = false;\n\tcontext->root_level = PT32_ROOT_LEVEL;\n\n\treset_rsvds_bits_mask(vcpu, context);\n\tupdate_permission_bitmask(vcpu, context, false);\n\tupdate_pkru_bitmask(vcpu, context, false);\n\tupdate_last_nonleaf_level(vcpu, context);\n\n\tcontext->page_fault = paging32_page_fault;\n\tcontext->gva_to_gpa = paging32_gva_to_gpa;\n\tcontext->sync_page = paging32_sync_page;\n\tcontext->invlpg = paging32_invlpg;\n\tcontext->update_pte = paging32_update_pte;\n\tcontext->shadow_root_level = PT32E_ROOT_LEVEL;\n\tcontext->direct_map = false;\n}\n\nstatic void paging32E_init_context(struct kvm_vcpu *vcpu,\n\t\t\t\t   struct kvm_mmu *context)\n{\n\tpaging64_init_context_common(vcpu, context, PT32E_ROOT_LEVEL);\n}\n\nstatic union kvm_mmu_extended_role kvm_calc_mmu_role_ext(struct kvm_vcpu *vcpu)\n{\n\tunion kvm_mmu_extended_role ext = {0};\n\n\text.cr0_pg = !!is_paging(vcpu);\n\text.cr4_pae = !!is_pae(vcpu);\n\text.cr4_smep = !!kvm_read_cr4_bits(vcpu, X86_CR4_SMEP);\n\text.cr4_smap = !!kvm_read_cr4_bits(vcpu, X86_CR4_SMAP);\n\text.cr4_pse = !!is_pse(vcpu);\n\text.cr4_pke = !!kvm_read_cr4_bits(vcpu, X86_CR4_PKE);\n\text.maxphyaddr = cpuid_maxphyaddr(vcpu);\n\n\text.valid = 1;\n\n\treturn ext;\n}\n\nstatic union kvm_mmu_role kvm_calc_mmu_role_common(struct kvm_vcpu *vcpu,\n\t\t\t\t\t\t   bool base_only)\n{\n\tunion kvm_mmu_role role = {0};\n\n\trole.base.access = ACC_ALL;\n\trole.base.nxe = !!is_nx(vcpu);\n\trole.base.cr0_wp = is_write_protection(vcpu);\n\trole.base.smm = is_smm(vcpu);\n\trole.base.guest_mode = is_guest_mode(vcpu);\n\n\tif (base_only)\n\t\treturn role;\n\n\trole.ext = kvm_calc_mmu_role_ext(vcpu);\n\n\treturn role;\n}\n\nstatic inline int kvm_mmu_get_tdp_level(struct kvm_vcpu *vcpu)\n{\n\t/* Use 5-level TDP if and only if it's useful/necessary. */\n\tif (max_tdp_level == 5 && cpuid_maxphyaddr(vcpu) <= 48)\n\t\treturn 4;\n\n\treturn max_tdp_level;\n}\n\nstatic union kvm_mmu_role\nkvm_calc_tdp_mmu_root_page_role(struct kvm_vcpu *vcpu, bool base_only)\n{\n\tunion kvm_mmu_role role = kvm_calc_mmu_role_common(vcpu, base_only);\n\n\trole.base.ad_disabled = (shadow_accessed_mask == 0);\n\trole.base.level = kvm_mmu_get_tdp_level(vcpu);\n\trole.base.direct = true;\n\trole.base.gpte_is_8_bytes = true;\n\n\treturn role;\n}\n\nstatic void init_kvm_tdp_mmu(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_mmu *context = &vcpu->arch.root_mmu;\n\tunion kvm_mmu_role new_role =\n\t\tkvm_calc_tdp_mmu_root_page_role(vcpu, false);\n\n\tif (new_role.as_u64 == context->mmu_role.as_u64)\n\t\treturn;\n\n\tcontext->mmu_role.as_u64 = new_role.as_u64;\n\tcontext->page_fault = kvm_tdp_page_fault;\n\tcontext->sync_page = nonpaging_sync_page;\n\tcontext->invlpg = NULL;\n\tcontext->update_pte = nonpaging_update_pte;\n\tcontext->shadow_root_level = kvm_mmu_get_tdp_level(vcpu);\n\tcontext->direct_map = true;\n\tcontext->get_guest_pgd = get_cr3;\n\tcontext->get_pdptr = kvm_pdptr_read;\n\tcontext->inject_page_fault = kvm_inject_page_fault;\n\n\tif (!is_paging(vcpu)) {\n\t\tcontext->nx = false;\n\t\tcontext->gva_to_gpa = nonpaging_gva_to_gpa;\n\t\tcontext->root_level = 0;\n\t} else if (is_long_mode(vcpu)) {\n\t\tcontext->nx = is_nx(vcpu);\n\t\tcontext->root_level = is_la57_mode(vcpu) ?\n\t\t\t\tPT64_ROOT_5LEVEL : PT64_ROOT_4LEVEL;\n\t\treset_rsvds_bits_mask(vcpu, context);\n\t\tcontext->gva_to_gpa = paging64_gva_to_gpa;\n\t} else if (is_pae(vcpu)) {\n\t\tcontext->nx = is_nx(vcpu);\n\t\tcontext->root_level = PT32E_ROOT_LEVEL;\n\t\treset_rsvds_bits_mask(vcpu, context);\n\t\tcontext->gva_to_gpa = paging64_gva_to_gpa;\n\t} else {\n\t\tcontext->nx = false;\n\t\tcontext->root_level = PT32_ROOT_LEVEL;\n\t\treset_rsvds_bits_mask(vcpu, context);\n\t\tcontext->gva_to_gpa = paging32_gva_to_gpa;\n\t}\n\n\tupdate_permission_bitmask(vcpu, context, false);\n\tupdate_pkru_bitmask(vcpu, context, false);\n\tupdate_last_nonleaf_level(vcpu, context);\n\treset_tdp_shadow_zero_bits_mask(vcpu, context);\n}\n\nstatic union kvm_mmu_role\nkvm_calc_shadow_root_page_role_common(struct kvm_vcpu *vcpu, bool base_only)\n{\n\tunion kvm_mmu_role role = kvm_calc_mmu_role_common(vcpu, base_only);\n\n\trole.base.smep_andnot_wp = role.ext.cr4_smep &&\n\t\t!is_write_protection(vcpu);\n\trole.base.smap_andnot_wp = role.ext.cr4_smap &&\n\t\t!is_write_protection(vcpu);\n\trole.base.gpte_is_8_bytes = !!is_pae(vcpu);\n\n\treturn role;\n}\n\nstatic union kvm_mmu_role\nkvm_calc_shadow_mmu_root_page_role(struct kvm_vcpu *vcpu, bool base_only)\n{\n\tunion kvm_mmu_role role =\n\t\tkvm_calc_shadow_root_page_role_common(vcpu, base_only);\n\n\trole.base.direct = !is_paging(vcpu);\n\n\tif (!is_long_mode(vcpu))\n\t\trole.base.level = PT32E_ROOT_LEVEL;\n\telse if (is_la57_mode(vcpu))\n\t\trole.base.level = PT64_ROOT_5LEVEL;\n\telse\n\t\trole.base.level = PT64_ROOT_4LEVEL;\n\n\treturn role;\n}\n\nstatic void shadow_mmu_init_context(struct kvm_vcpu *vcpu, struct kvm_mmu *context,\n\t\t\t\t    u32 cr0, u32 cr4, u32 efer,\n\t\t\t\t    union kvm_mmu_role new_role)\n{\n\tif (!(cr0 & X86_CR0_PG))\n\t\tnonpaging_init_context(vcpu, context);\n\telse if (efer & EFER_LMA)\n\t\tpaging64_init_context(vcpu, context);\n\telse if (cr4 & X86_CR4_PAE)\n\t\tpaging32E_init_context(vcpu, context);\n\telse\n\t\tpaging32_init_context(vcpu, context);\n\n\tcontext->mmu_role.as_u64 = new_role.as_u64;\n\treset_shadow_zero_bits_mask(vcpu, context);\n}\n\nstatic void kvm_init_shadow_mmu(struct kvm_vcpu *vcpu, u32 cr0, u32 cr4, u32 efer)\n{\n\tstruct kvm_mmu *context = &vcpu->arch.root_mmu;\n\tunion kvm_mmu_role new_role =\n\t\tkvm_calc_shadow_mmu_root_page_role(vcpu, false);\n\n\tif (new_role.as_u64 != context->mmu_role.as_u64)\n\t\tshadow_mmu_init_context(vcpu, context, cr0, cr4, efer, new_role);\n}\n\nstatic union kvm_mmu_role\nkvm_calc_shadow_npt_root_page_role(struct kvm_vcpu *vcpu)\n{\n\tunion kvm_mmu_role role =\n\t\tkvm_calc_shadow_root_page_role_common(vcpu, false);\n\n\trole.base.direct = false;\n\trole.base.level = kvm_mmu_get_tdp_level(vcpu);\n\n\treturn role;\n}\n\nvoid kvm_init_shadow_npt_mmu(struct kvm_vcpu *vcpu, u32 cr0, u32 cr4, u32 efer,\n\t\t\t     gpa_t nested_cr3)\n{\n\tstruct kvm_mmu *context = &vcpu->arch.guest_mmu;\n\tunion kvm_mmu_role new_role = kvm_calc_shadow_npt_root_page_role(vcpu);\n\n\tcontext->shadow_root_level = new_role.base.level;\n\n\t__kvm_mmu_new_pgd(vcpu, nested_cr3, new_role.base, false, false);\n\n\tif (new_role.as_u64 != context->mmu_role.as_u64)\n\t\tshadow_mmu_init_context(vcpu, context, cr0, cr4, efer, new_role);\n}\nEXPORT_SYMBOL_GPL(kvm_init_shadow_npt_mmu);\n\nstatic union kvm_mmu_role\nkvm_calc_shadow_ept_root_page_role(struct kvm_vcpu *vcpu, bool accessed_dirty,\n\t\t\t\t   bool execonly, u8 level)\n{\n\tunion kvm_mmu_role role = {0};\n\n\t/* SMM flag is inherited from root_mmu */\n\trole.base.smm = vcpu->arch.root_mmu.mmu_role.base.smm;\n\n\trole.base.level = level;\n\trole.base.gpte_is_8_bytes = true;\n\trole.base.direct = false;\n\trole.base.ad_disabled = !accessed_dirty;\n\trole.base.guest_mode = true;\n\trole.base.access = ACC_ALL;\n\n\t/*\n\t * WP=1 and NOT_WP=1 is an impossible combination, use WP and the\n\t * SMAP variation to denote shadow EPT entries.\n\t */\n\trole.base.cr0_wp = true;\n\trole.base.smap_andnot_wp = true;\n\n\trole.ext = kvm_calc_mmu_role_ext(vcpu);\n\trole.ext.execonly = execonly;\n\n\treturn role;\n}\n\nvoid kvm_init_shadow_ept_mmu(struct kvm_vcpu *vcpu, bool execonly,\n\t\t\t     bool accessed_dirty, gpa_t new_eptp)\n{\n\tstruct kvm_mmu *context = &vcpu->arch.guest_mmu;\n\tu8 level = vmx_eptp_page_walk_level(new_eptp);\n\tunion kvm_mmu_role new_role =\n\t\tkvm_calc_shadow_ept_root_page_role(vcpu, accessed_dirty,\n\t\t\t\t\t\t   execonly, level);\n\n\t__kvm_mmu_new_pgd(vcpu, new_eptp, new_role.base, true, true);\n\n\tif (new_role.as_u64 == context->mmu_role.as_u64)\n\t\treturn;\n\n\tcontext->shadow_root_level = level;\n\n\tcontext->nx = true;\n\tcontext->ept_ad = accessed_dirty;\n\tcontext->page_fault = ept_page_fault;\n\tcontext->gva_to_gpa = ept_gva_to_gpa;\n\tcontext->sync_page = ept_sync_page;\n\tcontext->invlpg = ept_invlpg;\n\tcontext->update_pte = ept_update_pte;\n\tcontext->root_level = level;\n\tcontext->direct_map = false;\n\tcontext->mmu_role.as_u64 = new_role.as_u64;\n\n\tupdate_permission_bitmask(vcpu, context, true);\n\tupdate_pkru_bitmask(vcpu, context, true);\n\tupdate_last_nonleaf_level(vcpu, context);\n\treset_rsvds_bits_mask_ept(vcpu, context, execonly);\n\treset_ept_shadow_zero_bits_mask(vcpu, context, execonly);\n}\nEXPORT_SYMBOL_GPL(kvm_init_shadow_ept_mmu);\n\nstatic void init_kvm_softmmu(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_mmu *context = &vcpu->arch.root_mmu;\n\n\tkvm_init_shadow_mmu(vcpu,\n\t\t\t    kvm_read_cr0_bits(vcpu, X86_CR0_PG),\n\t\t\t    kvm_read_cr4_bits(vcpu, X86_CR4_PAE),\n\t\t\t    vcpu->arch.efer);\n\n\tcontext->get_guest_pgd     = get_cr3;\n\tcontext->get_pdptr         = kvm_pdptr_read;\n\tcontext->inject_page_fault = kvm_inject_page_fault;\n}\n\nstatic void init_kvm_nested_mmu(struct kvm_vcpu *vcpu)\n{\n\tunion kvm_mmu_role new_role = kvm_calc_mmu_role_common(vcpu, false);\n\tstruct kvm_mmu *g_context = &vcpu->arch.nested_mmu;\n\n\tif (new_role.as_u64 == g_context->mmu_role.as_u64)\n\t\treturn;\n\n\tg_context->mmu_role.as_u64 = new_role.as_u64;\n\tg_context->get_guest_pgd     = get_cr3;\n\tg_context->get_pdptr         = kvm_pdptr_read;\n\tg_context->inject_page_fault = kvm_inject_page_fault;\n\n\t/*\n\t * L2 page tables are never shadowed, so there is no need to sync\n\t * SPTEs.\n\t */\n\tg_context->invlpg            = NULL;\n\n\t/*\n\t * Note that arch.mmu->gva_to_gpa translates l2_gpa to l1_gpa using\n\t * L1's nested page tables (e.g. EPT12). The nested translation\n\t * of l2_gva to l1_gpa is done by arch.nested_mmu.gva_to_gpa using\n\t * L2's page tables as the first level of translation and L1's\n\t * nested page tables as the second level of translation. Basically\n\t * the gva_to_gpa functions between mmu and nested_mmu are swapped.\n\t */\n\tif (!is_paging(vcpu)) {\n\t\tg_context->nx = false;\n\t\tg_context->root_level = 0;\n\t\tg_context->gva_to_gpa = nonpaging_gva_to_gpa_nested;\n\t} else if (is_long_mode(vcpu)) {\n\t\tg_context->nx = is_nx(vcpu);\n\t\tg_context->root_level = is_la57_mode(vcpu) ?\n\t\t\t\t\tPT64_ROOT_5LEVEL : PT64_ROOT_4LEVEL;\n\t\treset_rsvds_bits_mask(vcpu, g_context);\n\t\tg_context->gva_to_gpa = paging64_gva_to_gpa_nested;\n\t} else if (is_pae(vcpu)) {\n\t\tg_context->nx = is_nx(vcpu);\n\t\tg_context->root_level = PT32E_ROOT_LEVEL;\n\t\treset_rsvds_bits_mask(vcpu, g_context);\n\t\tg_context->gva_to_gpa = paging64_gva_to_gpa_nested;\n\t} else {\n\t\tg_context->nx = false;\n\t\tg_context->root_level = PT32_ROOT_LEVEL;\n\t\treset_rsvds_bits_mask(vcpu, g_context);\n\t\tg_context->gva_to_gpa = paging32_gva_to_gpa_nested;\n\t}\n\n\tupdate_permission_bitmask(vcpu, g_context, false);\n\tupdate_pkru_bitmask(vcpu, g_context, false);\n\tupdate_last_nonleaf_level(vcpu, g_context);\n}\n\nvoid kvm_init_mmu(struct kvm_vcpu *vcpu, bool reset_roots)\n{\n\tif (reset_roots) {\n\t\tuint i;\n\n\t\tvcpu->arch.mmu->root_hpa = INVALID_PAGE;\n\n\t\tfor (i = 0; i < KVM_MMU_NUM_PREV_ROOTS; i++)\n\t\t\tvcpu->arch.mmu->prev_roots[i] = KVM_MMU_ROOT_INFO_INVALID;\n\t}\n\n\tif (mmu_is_nested(vcpu))\n\t\tinit_kvm_nested_mmu(vcpu);\n\telse if (tdp_enabled)\n\t\tinit_kvm_tdp_mmu(vcpu);\n\telse\n\t\tinit_kvm_softmmu(vcpu);\n}\nEXPORT_SYMBOL_GPL(kvm_init_mmu);\n\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu)\n{\n\tunion kvm_mmu_role role;\n\n\tif (tdp_enabled)\n\t\trole = kvm_calc_tdp_mmu_root_page_role(vcpu, true);\n\telse\n\t\trole = kvm_calc_shadow_mmu_root_page_role(vcpu, true);\n\n\treturn role.base;\n}\n\nvoid kvm_mmu_reset_context(struct kvm_vcpu *vcpu)\n{\n\tkvm_mmu_unload(vcpu);\n\tkvm_init_mmu(vcpu, true);\n}\nEXPORT_SYMBOL_GPL(kvm_mmu_reset_context);\n\nint kvm_mmu_load(struct kvm_vcpu *vcpu)\n{\n\tint r;\n\n\tr = mmu_topup_memory_caches(vcpu, !vcpu->arch.mmu->direct_map);\n\tif (r)\n\t\tgoto out;\n\tr = mmu_alloc_roots(vcpu);\n\tkvm_mmu_sync_roots(vcpu);\n\tif (r)\n\t\tgoto out;\n\tkvm_mmu_load_pgd(vcpu);\n\tkvm_x86_ops.tlb_flush_current(vcpu);\nout:\n\treturn r;\n}\nEXPORT_SYMBOL_GPL(kvm_mmu_load);\n\nvoid kvm_mmu_unload(struct kvm_vcpu *vcpu)\n{\n\tkvm_mmu_free_roots(vcpu, &vcpu->arch.root_mmu, KVM_MMU_ROOTS_ALL);\n\tWARN_ON(VALID_PAGE(vcpu->arch.root_mmu.root_hpa));\n\tkvm_mmu_free_roots(vcpu, &vcpu->arch.guest_mmu, KVM_MMU_ROOTS_ALL);\n\tWARN_ON(VALID_PAGE(vcpu->arch.guest_mmu.root_hpa));\n}\nEXPORT_SYMBOL_GPL(kvm_mmu_unload);\n\nstatic void mmu_pte_write_new_pte(struct kvm_vcpu *vcpu,\n\t\t\t\t  struct kvm_mmu_page *sp, u64 *spte,\n\t\t\t\t  const void *new)\n{\n\tif (sp->role.level != PG_LEVEL_4K) {\n\t\t++vcpu->kvm->stat.mmu_pde_zapped;\n\t\treturn;\n        }\n\n\t++vcpu->kvm->stat.mmu_pte_updated;\n\tvcpu->arch.mmu->update_pte(vcpu, sp, spte, new);\n}\n\nstatic bool need_remote_flush(u64 old, u64 new)\n{\n\tif (!is_shadow_present_pte(old))\n\t\treturn false;\n\tif (!is_shadow_present_pte(new))\n\t\treturn true;\n\tif ((old ^ new) & PT64_BASE_ADDR_MASK)\n\t\treturn true;\n\told ^= shadow_nx_mask;\n\tnew ^= shadow_nx_mask;\n\treturn (old & ~new & PT64_PERM_MASK) != 0;\n}\n\nstatic u64 mmu_pte_write_fetch_gpte(struct kvm_vcpu *vcpu, gpa_t *gpa,\n\t\t\t\t    int *bytes)\n{\n\tu64 gentry = 0;\n\tint r;\n\n\t/*\n\t * Assume that the pte write on a page table of the same type\n\t * as the current vcpu paging mode since we update the sptes only\n\t * when they have the same mode.\n\t */\n\tif (is_pae(vcpu) && *bytes == 4) {\n\t\t/* Handle a 32-bit guest writing two halves of a 64-bit gpte */\n\t\t*gpa &= ~(gpa_t)7;\n\t\t*bytes = 8;\n\t}\n\n\tif (*bytes == 4 || *bytes == 8) {\n\t\tr = kvm_vcpu_read_guest_atomic(vcpu, *gpa, &gentry, *bytes);\n\t\tif (r)\n\t\t\tgentry = 0;\n\t}\n\n\treturn gentry;\n}\n\n/*\n * If we're seeing too many writes to a page, it may no longer be a page table,\n * or we may be forking, in which case it is better to unmap the page.\n */\nstatic bool detect_write_flooding(struct kvm_mmu_page *sp)\n{\n\t/*\n\t * Skip write-flooding detected for the sp whose level is 1, because\n\t * it can become unsync, then the guest page is not write-protected.\n\t */\n\tif (sp->role.level == PG_LEVEL_4K)\n\t\treturn false;\n\n\tatomic_inc(&sp->write_flooding_count);\n\treturn atomic_read(&sp->write_flooding_count) >= 3;\n}\n\n/*\n * Misaligned accesses are too much trouble to fix up; also, they usually\n * indicate a page is not used as a page table.\n */\nstatic bool detect_write_misaligned(struct kvm_mmu_page *sp, gpa_t gpa,\n\t\t\t\t    int bytes)\n{\n\tunsigned offset, pte_size, misaligned;\n\n\tpgprintk(\"misaligned: gpa %llx bytes %d role %x\\n\",\n\t\t gpa, bytes, sp->role.word);\n\n\toffset = offset_in_page(gpa);\n\tpte_size = sp->role.gpte_is_8_bytes ? 8 : 4;\n\n\t/*\n\t * Sometimes, the OS only writes the last one bytes to update status\n\t * bits, for example, in linux, andb instruction is used in clear_bit().\n\t */\n\tif (!(offset & (pte_size - 1)) && bytes == 1)\n\t\treturn false;\n\n\tmisaligned = (offset ^ (offset + bytes - 1)) & ~(pte_size - 1);\n\tmisaligned |= bytes < 4;\n\n\treturn misaligned;\n}\n\nstatic u64 *get_written_sptes(struct kvm_mmu_page *sp, gpa_t gpa, int *nspte)\n{\n\tunsigned page_offset, quadrant;\n\tu64 *spte;\n\tint level;\n\n\tpage_offset = offset_in_page(gpa);\n\tlevel = sp->role.level;\n\t*nspte = 1;\n\tif (!sp->role.gpte_is_8_bytes) {\n\t\tpage_offset <<= 1;\t/* 32->64 */\n\t\t/*\n\t\t * A 32-bit pde maps 4MB while the shadow pdes map\n\t\t * only 2MB.  So we need to double the offset again\n\t\t * and zap two pdes instead of one.\n\t\t */\n\t\tif (level == PT32_ROOT_LEVEL) {\n\t\t\tpage_offset &= ~7; /* kill rounding error */\n\t\t\tpage_offset <<= 1;\n\t\t\t*nspte = 2;\n\t\t}\n\t\tquadrant = page_offset >> PAGE_SHIFT;\n\t\tpage_offset &= ~PAGE_MASK;\n\t\tif (quadrant != sp->role.quadrant)\n\t\t\treturn NULL;\n\t}\n\n\tspte = &sp->spt[page_offset / sizeof(*spte)];\n\treturn spte;\n}\n\n/*\n * Ignore various flags when determining if a SPTE can be immediately\n * overwritten for the current MMU.\n *  - level: explicitly checked in mmu_pte_write_new_pte(), and will never\n *    match the current MMU role, as MMU's level tracks the root level.\n *  - access: updated based on the new guest PTE\n *  - quadrant: handled by get_written_sptes()\n *  - invalid: always false (loop only walks valid shadow pages)\n */\nstatic const union kvm_mmu_page_role role_ign = {\n\t.level = 0xf,\n\t.access = 0x7,\n\t.quadrant = 0x3,\n\t.invalid = 0x1,\n};\n\nstatic void kvm_mmu_pte_write(struct kvm_vcpu *vcpu, gpa_t gpa,\n\t\t\t      const u8 *new, int bytes,\n\t\t\t      struct kvm_page_track_notifier_node *node)\n{\n\tgfn_t gfn = gpa >> PAGE_SHIFT;\n\tstruct kvm_mmu_page *sp;\n\tLIST_HEAD(invalid_list);\n\tu64 entry, gentry, *spte;\n\tint npte;\n\tbool remote_flush, local_flush;\n\n\t/*\n\t * If we don't have indirect shadow pages, it means no page is\n\t * write-protected, so we can exit simply.\n\t */\n\tif (!READ_ONCE(vcpu->kvm->arch.indirect_shadow_pages))\n\t\treturn;\n\n\tremote_flush = local_flush = false;\n\n\tpgprintk(\"%s: gpa %llx bytes %d\\n\", __func__, gpa, bytes);\n\n\t/*\n\t * No need to care whether allocation memory is successful\n\t * or not since pte prefetch is skiped if it does not have\n\t * enough objects in the cache.\n\t */\n\tmmu_topup_memory_caches(vcpu, true);\n\n\tspin_lock(&vcpu->kvm->mmu_lock);\n\n\tgentry = mmu_pte_write_fetch_gpte(vcpu, &gpa, &bytes);\n\n\t++vcpu->kvm->stat.mmu_pte_write;\n\tkvm_mmu_audit(vcpu, AUDIT_PRE_PTE_WRITE);\n\n\tfor_each_gfn_indirect_valid_sp(vcpu->kvm, sp, gfn) {\n\t\tif (detect_write_misaligned(sp, gpa, bytes) ||\n\t\t      detect_write_flooding(sp)) {\n\t\t\tkvm_mmu_prepare_zap_page(vcpu->kvm, sp, &invalid_list);\n\t\t\t++vcpu->kvm->stat.mmu_flooded;\n\t\t\tcontinue;\n\t\t}\n\n\t\tspte = get_written_sptes(sp, gpa, &npte);\n\t\tif (!spte)\n\t\t\tcontinue;\n\n\t\tlocal_flush = true;\n\t\twhile (npte--) {\n\t\t\tu32 base_role = vcpu->arch.mmu->mmu_role.base.word;\n\n\t\t\tentry = *spte;\n\t\t\tmmu_page_zap_pte(vcpu->kvm, sp, spte, NULL);\n\t\t\tif (gentry &&\n\t\t\t    !((sp->role.word ^ base_role) & ~role_ign.word) &&\n\t\t\t    rmap_can_add(vcpu))\n\t\t\t\tmmu_pte_write_new_pte(vcpu, sp, spte, &gentry);\n\t\t\tif (need_remote_flush(entry, *spte))\n\t\t\t\tremote_flush = true;\n\t\t\t++spte;\n\t\t}\n\t}\n\tkvm_mmu_flush_or_zap(vcpu, &invalid_list, remote_flush, local_flush);\n\tkvm_mmu_audit(vcpu, AUDIT_POST_PTE_WRITE);\n\tspin_unlock(&vcpu->kvm->mmu_lock);\n}\n\nint kvm_mmu_unprotect_page_virt(struct kvm_vcpu *vcpu, gva_t gva)\n{\n\tgpa_t gpa;\n\tint r;\n\n\tif (vcpu->arch.mmu->direct_map)\n\t\treturn 0;\n\n\tgpa = kvm_mmu_gva_to_gpa_read(vcpu, gva, NULL);\n\n\tr = kvm_mmu_unprotect_page(vcpu->kvm, gpa >> PAGE_SHIFT);\n\n\treturn r;\n}\nEXPORT_SYMBOL_GPL(kvm_mmu_unprotect_page_virt);\n\nint kvm_mmu_page_fault(struct kvm_vcpu *vcpu, gpa_t cr2_or_gpa, u64 error_code,\n\t\t       void *insn, int insn_len)\n{\n\tint r, emulation_type = EMULTYPE_PF;\n\tbool direct = vcpu->arch.mmu->direct_map;\n\n\tif (WARN_ON(!VALID_PAGE(vcpu->arch.mmu->root_hpa)))\n\t\treturn RET_PF_RETRY;\n\n\tr = RET_PF_INVALID;\n\tif (unlikely(error_code & PFERR_RSVD_MASK)) {\n\t\tr = handle_mmio_page_fault(vcpu, cr2_or_gpa, direct);\n\t\tif (r == RET_PF_EMULATE)\n\t\t\tgoto emulate;\n\t}\n\n\tif (r == RET_PF_INVALID) {\n\t\tr = kvm_mmu_do_page_fault(vcpu, cr2_or_gpa,\n\t\t\t\t\t  lower_32_bits(error_code), false);\n\t\tif (WARN_ON_ONCE(r == RET_PF_INVALID))\n\t\t\treturn -EIO;\n\t}\n\n\tif (r < 0)\n\t\treturn r;\n\tif (r != RET_PF_EMULATE)\n\t\treturn 1;\n\n\t/*\n\t * Before emulating the instruction, check if the error code\n\t * was due to a RO violation while translating the guest page.\n\t * This can occur when using nested virtualization with nested\n\t * paging in both guests. If true, we simply unprotect the page\n\t * and resume the guest.\n\t */\n\tif (vcpu->arch.mmu->direct_map &&\n\t    (error_code & PFERR_NESTED_GUEST_PAGE) == PFERR_NESTED_GUEST_PAGE) {\n\t\tkvm_mmu_unprotect_page(vcpu->kvm, gpa_to_gfn(cr2_or_gpa));\n\t\treturn 1;\n\t}\n\n\t/*\n\t * vcpu->arch.mmu.page_fault returned RET_PF_EMULATE, but we can still\n\t * optimistically try to just unprotect the page and let the processor\n\t * re-execute the instruction that caused the page fault.  Do not allow\n\t * retrying MMIO emulation, as it's not only pointless but could also\n\t * cause us to enter an infinite loop because the processor will keep\n\t * faulting on the non-existent MMIO address.  Retrying an instruction\n\t * from a nested guest is also pointless and dangerous as we are only\n\t * explicitly shadowing L1's page tables, i.e. unprotecting something\n\t * for L1 isn't going to magically fix whatever issue cause L2 to fail.\n\t */\n\tif (!mmio_info_in_cache(vcpu, cr2_or_gpa, direct) && !is_guest_mode(vcpu))\n\t\temulation_type |= EMULTYPE_ALLOW_RETRY_PF;\nemulate:\n\treturn x86_emulate_instruction(vcpu, cr2_or_gpa, emulation_type, insn,\n\t\t\t\t       insn_len);\n}\nEXPORT_SYMBOL_GPL(kvm_mmu_page_fault);\n\nvoid kvm_mmu_invalidate_gva(struct kvm_vcpu *vcpu, struct kvm_mmu *mmu,\n\t\t\t    gva_t gva, hpa_t root_hpa)\n{\n\tint i;\n\n\t/* It's actually a GPA for vcpu->arch.guest_mmu.  */\n\tif (mmu != &vcpu->arch.guest_mmu) {\n\t\t/* INVLPG on a non-canonical address is a NOP according to the SDM.  */\n\t\tif (is_noncanonical_address(gva, vcpu))\n\t\t\treturn;\n\n\t\tkvm_x86_ops.tlb_flush_gva(vcpu, gva);\n\t}\n\n\tif (!mmu->invlpg)\n\t\treturn;\n\n\tif (root_hpa == INVALID_PAGE) {\n\t\tmmu->invlpg(vcpu, gva, mmu->root_hpa);\n\n\t\t/*\n\t\t * INVLPG is required to invalidate any global mappings for the VA,\n\t\t * irrespective of PCID. Since it would take us roughly similar amount\n\t\t * of work to determine whether any of the prev_root mappings of the VA\n\t\t * is marked global, or to just sync it blindly, so we might as well\n\t\t * just always sync it.\n\t\t *\n\t\t * Mappings not reachable via the current cr3 or the prev_roots will be\n\t\t * synced when switching to that cr3, so nothing needs to be done here\n\t\t * for them.\n\t\t */\n\t\tfor (i = 0; i < KVM_MMU_NUM_PREV_ROOTS; i++)\n\t\t\tif (VALID_PAGE(mmu->prev_roots[i].hpa))\n\t\t\t\tmmu->invlpg(vcpu, gva, mmu->prev_roots[i].hpa);\n\t} else {\n\t\tmmu->invlpg(vcpu, gva, root_hpa);\n\t}\n}\nEXPORT_SYMBOL_GPL(kvm_mmu_invalidate_gva);\n\nvoid kvm_mmu_invlpg(struct kvm_vcpu *vcpu, gva_t gva)\n{\n\tkvm_mmu_invalidate_gva(vcpu, vcpu->arch.mmu, gva, INVALID_PAGE);\n\t++vcpu->stat.invlpg;\n}\nEXPORT_SYMBOL_GPL(kvm_mmu_invlpg);\n\n\nvoid kvm_mmu_invpcid_gva(struct kvm_vcpu *vcpu, gva_t gva, unsigned long pcid)\n{\n\tstruct kvm_mmu *mmu = vcpu->arch.mmu;\n\tbool tlb_flush = false;\n\tuint i;\n\n\tif (pcid == kvm_get_active_pcid(vcpu)) {\n\t\tmmu->invlpg(vcpu, gva, mmu->root_hpa);\n\t\ttlb_flush = true;\n\t}\n\n\tfor (i = 0; i < KVM_MMU_NUM_PREV_ROOTS; i++) {\n\t\tif (VALID_PAGE(mmu->prev_roots[i].hpa) &&\n\t\t    pcid == kvm_get_pcid(vcpu, mmu->prev_roots[i].pgd)) {\n\t\t\tmmu->invlpg(vcpu, gva, mmu->prev_roots[i].hpa);\n\t\t\ttlb_flush = true;\n\t\t}\n\t}\n\n\tif (tlb_flush)\n\t\tkvm_x86_ops.tlb_flush_gva(vcpu, gva);\n\n\t++vcpu->stat.invlpg;\n\n\t/*\n\t * Mappings not reachable via the current cr3 or the prev_roots will be\n\t * synced when switching to that cr3, so nothing needs to be done here\n\t * for them.\n\t */\n}\nEXPORT_SYMBOL_GPL(kvm_mmu_invpcid_gva);\n\nvoid kvm_configure_mmu(bool enable_tdp, int tdp_max_root_level,\n\t\t       int tdp_huge_page_level)\n{\n\ttdp_enabled = enable_tdp;\n\tmax_tdp_level = tdp_max_root_level;\n\n\t/*\n\t * max_huge_page_level reflects KVM's MMU capabilities irrespective\n\t * of kernel support, e.g. KVM may be capable of using 1GB pages when\n\t * the kernel is not.  But, KVM never creates a page size greater than\n\t * what is used by the kernel for any given HVA, i.e. the kernel's\n\t * capabilities are ultimately consulted by kvm_mmu_hugepage_adjust().\n\t */\n\tif (tdp_enabled)\n\t\tmax_huge_page_level = tdp_huge_page_level;\n\telse if (boot_cpu_has(X86_FEATURE_GBPAGES))\n\t\tmax_huge_page_level = PG_LEVEL_1G;\n\telse\n\t\tmax_huge_page_level = PG_LEVEL_2M;\n}\nEXPORT_SYMBOL_GPL(kvm_configure_mmu);\n\n/* The return value indicates if tlb flush on all vcpus is needed. */\ntypedef bool (*slot_level_handler) (struct kvm *kvm, struct kvm_rmap_head *rmap_head);\n\n/* The caller should hold mmu-lock before calling this function. */\nstatic __always_inline bool\nslot_handle_level_range(struct kvm *kvm, struct kvm_memory_slot *memslot,\n\t\t\tslot_level_handler fn, int start_level, int end_level,\n\t\t\tgfn_t start_gfn, gfn_t end_gfn, bool lock_flush_tlb)\n{\n\tstruct slot_rmap_walk_iterator iterator;\n\tbool flush = false;\n\n\tfor_each_slot_rmap_range(memslot, start_level, end_level, start_gfn,\n\t\t\tend_gfn, &iterator) {\n\t\tif (iterator.rmap)\n\t\t\tflush |= fn(kvm, iterator.rmap);\n\n\t\tif (need_resched() || spin_needbreak(&kvm->mmu_lock)) {\n\t\t\tif (flush && lock_flush_tlb) {\n\t\t\t\tkvm_flush_remote_tlbs_with_address(kvm,\n\t\t\t\t\t\tstart_gfn,\n\t\t\t\t\t\titerator.gfn - start_gfn + 1);\n\t\t\t\tflush = false;\n\t\t\t}\n\t\t\tcond_resched_lock(&kvm->mmu_lock);\n\t\t}\n\t}\n\n\tif (flush && lock_flush_tlb) {\n\t\tkvm_flush_remote_tlbs_with_address(kvm, start_gfn,\n\t\t\t\t\t\t   end_gfn - start_gfn + 1);\n\t\tflush = false;\n\t}\n\n\treturn flush;\n}\n\nstatic __always_inline bool\nslot_handle_level(struct kvm *kvm, struct kvm_memory_slot *memslot,\n\t\t  slot_level_handler fn, int start_level, int end_level,\n\t\t  bool lock_flush_tlb)\n{\n\treturn slot_handle_level_range(kvm, memslot, fn, start_level,\n\t\t\tend_level, memslot->base_gfn,\n\t\t\tmemslot->base_gfn + memslot->npages - 1,\n\t\t\tlock_flush_tlb);\n}\n\nstatic __always_inline bool\nslot_handle_all_level(struct kvm *kvm, struct kvm_memory_slot *memslot,\n\t\t      slot_level_handler fn, bool lock_flush_tlb)\n{\n\treturn slot_handle_level(kvm, memslot, fn, PG_LEVEL_4K,\n\t\t\t\t KVM_MAX_HUGEPAGE_LEVEL, lock_flush_tlb);\n}\n\nstatic __always_inline bool\nslot_handle_large_level(struct kvm *kvm, struct kvm_memory_slot *memslot,\n\t\t\tslot_level_handler fn, bool lock_flush_tlb)\n{\n\treturn slot_handle_level(kvm, memslot, fn, PG_LEVEL_4K + 1,\n\t\t\t\t KVM_MAX_HUGEPAGE_LEVEL, lock_flush_tlb);\n}\n\nstatic __always_inline bool\nslot_handle_leaf(struct kvm *kvm, struct kvm_memory_slot *memslot,\n\t\t slot_level_handler fn, bool lock_flush_tlb)\n{\n\treturn slot_handle_level(kvm, memslot, fn, PG_LEVEL_4K,\n\t\t\t\t PG_LEVEL_4K, lock_flush_tlb);\n}\n\nstatic void free_mmu_pages(struct kvm_mmu *mmu)\n{\n\tfree_page((unsigned long)mmu->pae_root);\n\tfree_page((unsigned long)mmu->lm_root);\n}\n\nstatic int __kvm_mmu_create(struct kvm_vcpu *vcpu, struct kvm_mmu *mmu)\n{\n\tstruct page *page;\n\tint i;\n\n\tmmu->root_hpa = INVALID_PAGE;\n\tmmu->root_pgd = 0;\n\tmmu->translate_gpa = translate_gpa;\n\tfor (i = 0; i < KVM_MMU_NUM_PREV_ROOTS; i++)\n\t\tmmu->prev_roots[i] = KVM_MMU_ROOT_INFO_INVALID;\n\n\t/*\n\t * When using PAE paging, the four PDPTEs are treated as 'root' pages,\n\t * while the PDP table is a per-vCPU construct that's allocated at MMU\n\t * creation.  When emulating 32-bit mode, cr3 is only 32 bits even on\n\t * x86_64.  Therefore we need to allocate the PDP table in the first\n\t * 4GB of memory, which happens to fit the DMA32 zone.  Except for\n\t * SVM's 32-bit NPT support, TDP paging doesn't use PAE paging and can\n\t * skip allocating the PDP table.\n\t */\n\tif (tdp_enabled && kvm_mmu_get_tdp_level(vcpu) > PT32E_ROOT_LEVEL)\n\t\treturn 0;\n\n\tpage = alloc_page(GFP_KERNEL_ACCOUNT | __GFP_DMA32);\n\tif (!page)\n\t\treturn -ENOMEM;\n\n\tmmu->pae_root = page_address(page);\n\tfor (i = 0; i < 4; ++i)\n\t\tmmu->pae_root[i] = INVALID_PAGE;\n\n\treturn 0;\n}\n\nint kvm_mmu_create(struct kvm_vcpu *vcpu)\n{\n\tint ret;\n\n\tvcpu->arch.mmu_pte_list_desc_cache.kmem_cache = pte_list_desc_cache;\n\tvcpu->arch.mmu_pte_list_desc_cache.gfp_zero = __GFP_ZERO;\n\n\tvcpu->arch.mmu_page_header_cache.kmem_cache = mmu_page_header_cache;\n\tvcpu->arch.mmu_page_header_cache.gfp_zero = __GFP_ZERO;\n\n\tvcpu->arch.mmu_shadow_page_cache.gfp_zero = __GFP_ZERO;\n\n\tvcpu->arch.mmu = &vcpu->arch.root_mmu;\n\tvcpu->arch.walk_mmu = &vcpu->arch.root_mmu;\n\n\tvcpu->arch.nested_mmu.translate_gpa = translate_nested_gpa;\n\n\tret = __kvm_mmu_create(vcpu, &vcpu->arch.guest_mmu);\n\tif (ret)\n\t\treturn ret;\n\n\tret = __kvm_mmu_create(vcpu, &vcpu->arch.root_mmu);\n\tif (ret)\n\t\tgoto fail_allocate_root;\n\n\treturn ret;\n fail_allocate_root:\n\tfree_mmu_pages(&vcpu->arch.guest_mmu);\n\treturn ret;\n}\n\n#define BATCH_ZAP_PAGES\t10\nstatic void kvm_zap_obsolete_pages(struct kvm *kvm)\n{\n\tstruct kvm_mmu_page *sp, *node;\n\tint nr_zapped, batch = 0;\n\nrestart:\n\tlist_for_each_entry_safe_reverse(sp, node,\n\t      &kvm->arch.active_mmu_pages, link) {\n\t\t/*\n\t\t * No obsolete valid page exists before a newly created page\n\t\t * since active_mmu_pages is a FIFO list.\n\t\t */\n\t\tif (!is_obsolete_sp(kvm, sp))\n\t\t\tbreak;\n\n\t\t/*\n\t\t * Invalid pages should never land back on the list of active\n\t\t * pages.  Skip the bogus page, otherwise we'll get stuck in an\n\t\t * infinite loop if the page gets put back on the list (again).\n\t\t */\n\t\tif (WARN_ON(sp->role.invalid))\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * No need to flush the TLB since we're only zapping shadow\n\t\t * pages with an obsolete generation number and all vCPUS have\n\t\t * loaded a new root, i.e. the shadow pages being zapped cannot\n\t\t * be in active use by the guest.\n\t\t */\n\t\tif (batch >= BATCH_ZAP_PAGES &&\n\t\t    cond_resched_lock(&kvm->mmu_lock)) {\n\t\t\tbatch = 0;\n\t\t\tgoto restart;\n\t\t}\n\n\t\tif (__kvm_mmu_prepare_zap_page(kvm, sp,\n\t\t\t\t&kvm->arch.zapped_obsolete_pages, &nr_zapped)) {\n\t\t\tbatch += nr_zapped;\n\t\t\tgoto restart;\n\t\t}\n\t}\n\n\t/*\n\t * Trigger a remote TLB flush before freeing the page tables to ensure\n\t * KVM is not in the middle of a lockless shadow page table walk, which\n\t * may reference the pages.\n\t */\n\tkvm_mmu_commit_zap_page(kvm, &kvm->arch.zapped_obsolete_pages);\n}\n\n/*\n * Fast invalidate all shadow pages and use lock-break technique\n * to zap obsolete pages.\n *\n * It's required when memslot is being deleted or VM is being\n * destroyed, in these cases, we should ensure that KVM MMU does\n * not use any resource of the being-deleted slot or all slots\n * after calling the function.\n */\nstatic void kvm_mmu_zap_all_fast(struct kvm *kvm)\n{\n\tlockdep_assert_held(&kvm->slots_lock);\n\n\tspin_lock(&kvm->mmu_lock);\n\ttrace_kvm_mmu_zap_all_fast(kvm);\n\n\t/*\n\t * Toggle mmu_valid_gen between '0' and '1'.  Because slots_lock is\n\t * held for the entire duration of zapping obsolete pages, it's\n\t * impossible for there to be multiple invalid generations associated\n\t * with *valid* shadow pages at any given time, i.e. there is exactly\n\t * one valid generation and (at most) one invalid generation.\n\t */\n\tkvm->arch.mmu_valid_gen = kvm->arch.mmu_valid_gen ? 0 : 1;\n\n\t/*\n\t * Notify all vcpus to reload its shadow page table and flush TLB.\n\t * Then all vcpus will switch to new shadow page table with the new\n\t * mmu_valid_gen.\n\t *\n\t * Note: we need to do this under the protection of mmu_lock,\n\t * otherwise, vcpu would purge shadow page but miss tlb flush.\n\t */\n\tkvm_reload_remote_mmus(kvm);\n\n\tkvm_zap_obsolete_pages(kvm);\n\n\tif (kvm->arch.tdp_mmu_enabled)\n\t\tkvm_tdp_mmu_zap_all(kvm);\n\n\tspin_unlock(&kvm->mmu_lock);\n}\n\nstatic bool kvm_has_zapped_obsolete_pages(struct kvm *kvm)\n{\n\treturn unlikely(!list_empty_careful(&kvm->arch.zapped_obsolete_pages));\n}\n\nstatic void kvm_mmu_invalidate_zap_pages_in_memslot(struct kvm *kvm,\n\t\t\tstruct kvm_memory_slot *slot,\n\t\t\tstruct kvm_page_track_notifier_node *node)\n{\n\tkvm_mmu_zap_all_fast(kvm);\n}\n\nvoid kvm_mmu_init_vm(struct kvm *kvm)\n{\n\tstruct kvm_page_track_notifier_node *node = &kvm->arch.mmu_sp_tracker;\n\n\tkvm_mmu_init_tdp_mmu(kvm);\n\n\tnode->track_write = kvm_mmu_pte_write;\n\tnode->track_flush_slot = kvm_mmu_invalidate_zap_pages_in_memslot;\n\tkvm_page_track_register_notifier(kvm, node);\n}\n\nvoid kvm_mmu_uninit_vm(struct kvm *kvm)\n{\n\tstruct kvm_page_track_notifier_node *node = &kvm->arch.mmu_sp_tracker;\n\n\tkvm_page_track_unregister_notifier(kvm, node);\n\n\tkvm_mmu_uninit_tdp_mmu(kvm);\n}\n\nvoid kvm_zap_gfn_range(struct kvm *kvm, gfn_t gfn_start, gfn_t gfn_end)\n{\n\tstruct kvm_memslots *slots;\n\tstruct kvm_memory_slot *memslot;\n\tint i;\n\tbool flush;\n\n\tspin_lock(&kvm->mmu_lock);\n\tfor (i = 0; i < KVM_ADDRESS_SPACE_NUM; i++) {\n\t\tslots = __kvm_memslots(kvm, i);\n\t\tkvm_for_each_memslot(memslot, slots) {\n\t\t\tgfn_t start, end;\n\n\t\t\tstart = max(gfn_start, memslot->base_gfn);\n\t\t\tend = min(gfn_end, memslot->base_gfn + memslot->npages);\n\t\t\tif (start >= end)\n\t\t\t\tcontinue;\n\n\t\t\tslot_handle_level_range(kvm, memslot, kvm_zap_rmapp,\n\t\t\t\t\t\tPG_LEVEL_4K,\n\t\t\t\t\t\tKVM_MAX_HUGEPAGE_LEVEL,\n\t\t\t\t\t\tstart, end - 1, true);\n\t\t}\n\t}\n\n\tif (kvm->arch.tdp_mmu_enabled) {\n\t\tflush = kvm_tdp_mmu_zap_gfn_range(kvm, gfn_start, gfn_end);\n\t\tif (flush)\n\t\t\tkvm_flush_remote_tlbs(kvm);\n\t}\n\n\tspin_unlock(&kvm->mmu_lock);\n}\n\nstatic bool slot_rmap_write_protect(struct kvm *kvm,\n\t\t\t\t    struct kvm_rmap_head *rmap_head)\n{\n\treturn __rmap_write_protect(kvm, rmap_head, false);\n}\n\nvoid kvm_mmu_slot_remove_write_access(struct kvm *kvm,\n\t\t\t\t      struct kvm_memory_slot *memslot,\n\t\t\t\t      int start_level)\n{\n\tbool flush;\n\n\tspin_lock(&kvm->mmu_lock);\n\tflush = slot_handle_level(kvm, memslot, slot_rmap_write_protect,\n\t\t\t\tstart_level, KVM_MAX_HUGEPAGE_LEVEL, false);\n\tif (kvm->arch.tdp_mmu_enabled)\n\t\tflush |= kvm_tdp_mmu_wrprot_slot(kvm, memslot, PG_LEVEL_4K);\n\tspin_unlock(&kvm->mmu_lock);\n\n\t/*\n\t * We can flush all the TLBs out of the mmu lock without TLB\n\t * corruption since we just change the spte from writable to\n\t * readonly so that we only need to care the case of changing\n\t * spte from present to present (changing the spte from present\n\t * to nonpresent will flush all the TLBs immediately), in other\n\t * words, the only case we care is mmu_spte_update() where we\n\t * have checked SPTE_HOST_WRITEABLE | SPTE_MMU_WRITEABLE\n\t * instead of PT_WRITABLE_MASK, that means it does not depend\n\t * on PT_WRITABLE_MASK anymore.\n\t */\n\tif (flush)\n\t\tkvm_arch_flush_remote_tlbs_memslot(kvm, memslot);\n}\n\nstatic bool kvm_mmu_zap_collapsible_spte(struct kvm *kvm,\n\t\t\t\t\t struct kvm_rmap_head *rmap_head)\n{\n\tu64 *sptep;\n\tstruct rmap_iterator iter;\n\tint need_tlb_flush = 0;\n\tkvm_pfn_t pfn;\n\tstruct kvm_mmu_page *sp;\n\nrestart:\n\tfor_each_rmap_spte(rmap_head, &iter, sptep) {\n\t\tsp = sptep_to_sp(sptep);\n\t\tpfn = spte_to_pfn(*sptep);\n\n\t\t/*\n\t\t * We cannot do huge page mapping for indirect shadow pages,\n\t\t * which are found on the last rmap (level = 1) when not using\n\t\t * tdp; such shadow pages are synced with the page table in\n\t\t * the guest, and the guest page table is using 4K page size\n\t\t * mapping if the indirect sp has level = 1.\n\t\t */\n\t\tif (sp->role.direct && !kvm_is_reserved_pfn(pfn) &&\n\t\t    (kvm_is_zone_device_pfn(pfn) ||\n\t\t     PageCompound(pfn_to_page(pfn)))) {\n\t\t\tpte_list_remove(rmap_head, sptep);\n\n\t\t\tif (kvm_available_flush_tlb_with_range())\n\t\t\t\tkvm_flush_remote_tlbs_with_address(kvm, sp->gfn,\n\t\t\t\t\tKVM_PAGES_PER_HPAGE(sp->role.level));\n\t\t\telse\n\t\t\t\tneed_tlb_flush = 1;\n\n\t\t\tgoto restart;\n\t\t}\n\t}\n\n\treturn need_tlb_flush;\n}\n\nvoid kvm_mmu_zap_collapsible_sptes(struct kvm *kvm,\n\t\t\t\t   const struct kvm_memory_slot *memslot)\n{\n\t/* FIXME: const-ify all uses of struct kvm_memory_slot.  */\n\tspin_lock(&kvm->mmu_lock);\n\tslot_handle_leaf(kvm, (struct kvm_memory_slot *)memslot,\n\t\t\t kvm_mmu_zap_collapsible_spte, true);\n\n\tif (kvm->arch.tdp_mmu_enabled)\n\t\tkvm_tdp_mmu_zap_collapsible_sptes(kvm, memslot);\n\tspin_unlock(&kvm->mmu_lock);\n}\n\nvoid kvm_arch_flush_remote_tlbs_memslot(struct kvm *kvm,\n\t\t\t\t\tstruct kvm_memory_slot *memslot)\n{\n\t/*\n\t * All current use cases for flushing the TLBs for a specific memslot\n\t * are related to dirty logging, and do the TLB flush out of mmu_lock.\n\t * The interaction between the various operations on memslot must be\n\t * serialized by slots_locks to ensure the TLB flush from one operation\n\t * is observed by any other operation on the same memslot.\n\t */\n\tlockdep_assert_held(&kvm->slots_lock);\n\tkvm_flush_remote_tlbs_with_address(kvm, memslot->base_gfn,\n\t\t\t\t\t   memslot->npages);\n}\n\nvoid kvm_mmu_slot_leaf_clear_dirty(struct kvm *kvm,\n\t\t\t\t   struct kvm_memory_slot *memslot)\n{\n\tbool flush;\n\n\tspin_lock(&kvm->mmu_lock);\n\tflush = slot_handle_leaf(kvm, memslot, __rmap_clear_dirty, false);\n\tif (kvm->arch.tdp_mmu_enabled)\n\t\tflush |= kvm_tdp_mmu_clear_dirty_slot(kvm, memslot);\n\tspin_unlock(&kvm->mmu_lock);\n\n\t/*\n\t * It's also safe to flush TLBs out of mmu lock here as currently this\n\t * function is only used for dirty logging, in which case flushing TLB\n\t * out of mmu lock also guarantees no dirty pages will be lost in\n\t * dirty_bitmap.\n\t */\n\tif (flush)\n\t\tkvm_arch_flush_remote_tlbs_memslot(kvm, memslot);\n}\nEXPORT_SYMBOL_GPL(kvm_mmu_slot_leaf_clear_dirty);\n\nvoid kvm_mmu_slot_largepage_remove_write_access(struct kvm *kvm,\n\t\t\t\t\tstruct kvm_memory_slot *memslot)\n{\n\tbool flush;\n\n\tspin_lock(&kvm->mmu_lock);\n\tflush = slot_handle_large_level(kvm, memslot, slot_rmap_write_protect,\n\t\t\t\t\tfalse);\n\tif (kvm->arch.tdp_mmu_enabled)\n\t\tflush |= kvm_tdp_mmu_wrprot_slot(kvm, memslot, PG_LEVEL_2M);\n\tspin_unlock(&kvm->mmu_lock);\n\n\tif (flush)\n\t\tkvm_arch_flush_remote_tlbs_memslot(kvm, memslot);\n}\nEXPORT_SYMBOL_GPL(kvm_mmu_slot_largepage_remove_write_access);\n\nvoid kvm_mmu_slot_set_dirty(struct kvm *kvm,\n\t\t\t    struct kvm_memory_slot *memslot)\n{\n\tbool flush;\n\n\tspin_lock(&kvm->mmu_lock);\n\tflush = slot_handle_all_level(kvm, memslot, __rmap_set_dirty, false);\n\tif (kvm->arch.tdp_mmu_enabled)\n\t\tflush |= kvm_tdp_mmu_slot_set_dirty(kvm, memslot);\n\tspin_unlock(&kvm->mmu_lock);\n\n\tif (flush)\n\t\tkvm_arch_flush_remote_tlbs_memslot(kvm, memslot);\n}\nEXPORT_SYMBOL_GPL(kvm_mmu_slot_set_dirty);\n\nvoid kvm_mmu_zap_all(struct kvm *kvm)\n{\n\tstruct kvm_mmu_page *sp, *node;\n\tLIST_HEAD(invalid_list);\n\tint ign;\n\n\tspin_lock(&kvm->mmu_lock);\nrestart:\n\tlist_for_each_entry_safe(sp, node, &kvm->arch.active_mmu_pages, link) {\n\t\tif (WARN_ON(sp->role.invalid))\n\t\t\tcontinue;\n\t\tif (__kvm_mmu_prepare_zap_page(kvm, sp, &invalid_list, &ign))\n\t\t\tgoto restart;\n\t\tif (cond_resched_lock(&kvm->mmu_lock))\n\t\t\tgoto restart;\n\t}\n\n\tkvm_mmu_commit_zap_page(kvm, &invalid_list);\n\n\tif (kvm->arch.tdp_mmu_enabled)\n\t\tkvm_tdp_mmu_zap_all(kvm);\n\n\tspin_unlock(&kvm->mmu_lock);\n}\n\nvoid kvm_mmu_invalidate_mmio_sptes(struct kvm *kvm, u64 gen)\n{\n\tWARN_ON(gen & KVM_MEMSLOT_GEN_UPDATE_IN_PROGRESS);\n\n\tgen &= MMIO_SPTE_GEN_MASK;\n\n\t/*\n\t * Generation numbers are incremented in multiples of the number of\n\t * address spaces in order to provide unique generations across all\n\t * address spaces.  Strip what is effectively the address space\n\t * modifier prior to checking for a wrap of the MMIO generation so\n\t * that a wrap in any address space is detected.\n\t */\n\tgen &= ~((u64)KVM_ADDRESS_SPACE_NUM - 1);\n\n\t/*\n\t * The very rare case: if the MMIO generation number has wrapped,\n\t * zap all shadow pages.\n\t */\n\tif (unlikely(gen == 0)) {\n\t\tkvm_debug_ratelimited(\"kvm: zapping shadow pages for mmio generation wraparound\\n\");\n\t\tkvm_mmu_zap_all_fast(kvm);\n\t}\n}\n\nstatic unsigned long\nmmu_shrink_scan(struct shrinker *shrink, struct shrink_control *sc)\n{\n\tstruct kvm *kvm;\n\tint nr_to_scan = sc->nr_to_scan;\n\tunsigned long freed = 0;\n\n\tmutex_lock(&kvm_lock);\n\n\tlist_for_each_entry(kvm, &vm_list, vm_list) {\n\t\tint idx;\n\t\tLIST_HEAD(invalid_list);\n\n\t\t/*\n\t\t * Never scan more than sc->nr_to_scan VM instances.\n\t\t * Will not hit this condition practically since we do not try\n\t\t * to shrink more than one VM and it is very unlikely to see\n\t\t * !n_used_mmu_pages so many times.\n\t\t */\n\t\tif (!nr_to_scan--)\n\t\t\tbreak;\n\t\t/*\n\t\t * n_used_mmu_pages is accessed without holding kvm->mmu_lock\n\t\t * here. We may skip a VM instance errorneosly, but we do not\n\t\t * want to shrink a VM that only started to populate its MMU\n\t\t * anyway.\n\t\t */\n\t\tif (!kvm->arch.n_used_mmu_pages &&\n\t\t    !kvm_has_zapped_obsolete_pages(kvm))\n\t\t\tcontinue;\n\n\t\tidx = srcu_read_lock(&kvm->srcu);\n\t\tspin_lock(&kvm->mmu_lock);\n\n\t\tif (kvm_has_zapped_obsolete_pages(kvm)) {\n\t\t\tkvm_mmu_commit_zap_page(kvm,\n\t\t\t      &kvm->arch.zapped_obsolete_pages);\n\t\t\tgoto unlock;\n\t\t}\n\n\t\tfreed = kvm_mmu_zap_oldest_mmu_pages(kvm, sc->nr_to_scan);\n\nunlock:\n\t\tspin_unlock(&kvm->mmu_lock);\n\t\tsrcu_read_unlock(&kvm->srcu, idx);\n\n\t\t/*\n\t\t * unfair on small ones\n\t\t * per-vm shrinkers cry out\n\t\t * sadness comes quickly\n\t\t */\n\t\tlist_move_tail(&kvm->vm_list, &vm_list);\n\t\tbreak;\n\t}\n\n\tmutex_unlock(&kvm_lock);\n\treturn freed;\n}\n\nstatic unsigned long\nmmu_shrink_count(struct shrinker *shrink, struct shrink_control *sc)\n{\n\treturn percpu_counter_read_positive(&kvm_total_used_mmu_pages);\n}\n\nstatic struct shrinker mmu_shrinker = {\n\t.count_objects = mmu_shrink_count,\n\t.scan_objects = mmu_shrink_scan,\n\t.seeks = DEFAULT_SEEKS * 10,\n};\n\nstatic void mmu_destroy_caches(void)\n{\n\tkmem_cache_destroy(pte_list_desc_cache);\n\tkmem_cache_destroy(mmu_page_header_cache);\n}\n\nstatic void kvm_set_mmio_spte_mask(void)\n{\n\tu64 mask;\n\n\t/*\n\t * Set a reserved PA bit in MMIO SPTEs to generate page faults with\n\t * PFEC.RSVD=1 on MMIO accesses.  64-bit PTEs (PAE, x86-64, and EPT\n\t * paging) support a maximum of 52 bits of PA, i.e. if the CPU supports\n\t * 52-bit physical addresses then there are no reserved PA bits in the\n\t * PTEs and so the reserved PA approach must be disabled.\n\t */\n\tif (shadow_phys_bits < 52)\n\t\tmask = BIT_ULL(51) | PT_PRESENT_MASK;\n\telse\n\t\tmask = 0;\n\n\tkvm_mmu_set_mmio_spte_mask(mask, ACC_WRITE_MASK | ACC_USER_MASK);\n}\n\nstatic bool get_nx_auto_mode(void)\n{\n\t/* Return true when CPU has the bug, and mitigations are ON */\n\treturn boot_cpu_has_bug(X86_BUG_ITLB_MULTIHIT) && !cpu_mitigations_off();\n}\n\nstatic void __set_nx_huge_pages(bool val)\n{\n\tnx_huge_pages = itlb_multihit_kvm_mitigation = val;\n}\n\nstatic int set_nx_huge_pages(const char *val, const struct kernel_param *kp)\n{\n\tbool old_val = nx_huge_pages;\n\tbool new_val;\n\n\t/* In \"auto\" mode deploy workaround only if CPU has the bug. */\n\tif (sysfs_streq(val, \"off\"))\n\t\tnew_val = 0;\n\telse if (sysfs_streq(val, \"force\"))\n\t\tnew_val = 1;\n\telse if (sysfs_streq(val, \"auto\"))\n\t\tnew_val = get_nx_auto_mode();\n\telse if (strtobool(val, &new_val) < 0)\n\t\treturn -EINVAL;\n\n\t__set_nx_huge_pages(new_val);\n\n\tif (new_val != old_val) {\n\t\tstruct kvm *kvm;\n\n\t\tmutex_lock(&kvm_lock);\n\n\t\tlist_for_each_entry(kvm, &vm_list, vm_list) {\n\t\t\tmutex_lock(&kvm->slots_lock);\n\t\t\tkvm_mmu_zap_all_fast(kvm);\n\t\t\tmutex_unlock(&kvm->slots_lock);\n\n\t\t\twake_up_process(kvm->arch.nx_lpage_recovery_thread);\n\t\t}\n\t\tmutex_unlock(&kvm_lock);\n\t}\n\n\treturn 0;\n}\n\nint kvm_mmu_module_init(void)\n{\n\tint ret = -ENOMEM;\n\n\tif (nx_huge_pages == -1)\n\t\t__set_nx_huge_pages(get_nx_auto_mode());\n\n\t/*\n\t * MMU roles use union aliasing which is, generally speaking, an\n\t * undefined behavior. However, we supposedly know how compilers behave\n\t * and the current status quo is unlikely to change. Guardians below are\n\t * supposed to let us know if the assumption becomes false.\n\t */\n\tBUILD_BUG_ON(sizeof(union kvm_mmu_page_role) != sizeof(u32));\n\tBUILD_BUG_ON(sizeof(union kvm_mmu_extended_role) != sizeof(u32));\n\tBUILD_BUG_ON(sizeof(union kvm_mmu_role) != sizeof(u64));\n\n\tkvm_mmu_reset_all_pte_masks();\n\n\tkvm_set_mmio_spte_mask();\n\n\tpte_list_desc_cache = kmem_cache_create(\"pte_list_desc\",\n\t\t\t\t\t    sizeof(struct pte_list_desc),\n\t\t\t\t\t    0, SLAB_ACCOUNT, NULL);\n\tif (!pte_list_desc_cache)\n\t\tgoto out;\n\n\tmmu_page_header_cache = kmem_cache_create(\"kvm_mmu_page_header\",\n\t\t\t\t\t\t  sizeof(struct kvm_mmu_page),\n\t\t\t\t\t\t  0, SLAB_ACCOUNT, NULL);\n\tif (!mmu_page_header_cache)\n\t\tgoto out;\n\n\tif (percpu_counter_init(&kvm_total_used_mmu_pages, 0, GFP_KERNEL))\n\t\tgoto out;\n\n\tret = register_shrinker(&mmu_shrinker);\n\tif (ret)\n\t\tgoto out;\n\n\treturn 0;\n\nout:\n\tmmu_destroy_caches();\n\treturn ret;\n}\n\n/*\n * Calculate mmu pages needed for kvm.\n */\nunsigned long kvm_mmu_calculate_default_mmu_pages(struct kvm *kvm)\n{\n\tunsigned long nr_mmu_pages;\n\tunsigned long nr_pages = 0;\n\tstruct kvm_memslots *slots;\n\tstruct kvm_memory_slot *memslot;\n\tint i;\n\n\tfor (i = 0; i < KVM_ADDRESS_SPACE_NUM; i++) {\n\t\tslots = __kvm_memslots(kvm, i);\n\n\t\tkvm_for_each_memslot(memslot, slots)\n\t\t\tnr_pages += memslot->npages;\n\t}\n\n\tnr_mmu_pages = nr_pages * KVM_PERMILLE_MMU_PAGES / 1000;\n\tnr_mmu_pages = max(nr_mmu_pages, KVM_MIN_ALLOC_MMU_PAGES);\n\n\treturn nr_mmu_pages;\n}\n\nvoid kvm_mmu_destroy(struct kvm_vcpu *vcpu)\n{\n\tkvm_mmu_unload(vcpu);\n\tfree_mmu_pages(&vcpu->arch.root_mmu);\n\tfree_mmu_pages(&vcpu->arch.guest_mmu);\n\tmmu_free_memory_caches(vcpu);\n}\n\nvoid kvm_mmu_module_exit(void)\n{\n\tmmu_destroy_caches();\n\tpercpu_counter_destroy(&kvm_total_used_mmu_pages);\n\tunregister_shrinker(&mmu_shrinker);\n\tmmu_audit_disable();\n}\n\nstatic int set_nx_huge_pages_recovery_ratio(const char *val, const struct kernel_param *kp)\n{\n\tunsigned int old_val;\n\tint err;\n\n\told_val = nx_huge_pages_recovery_ratio;\n\terr = param_set_uint(val, kp);\n\tif (err)\n\t\treturn err;\n\n\tif (READ_ONCE(nx_huge_pages) &&\n\t    !old_val && nx_huge_pages_recovery_ratio) {\n\t\tstruct kvm *kvm;\n\n\t\tmutex_lock(&kvm_lock);\n\n\t\tlist_for_each_entry(kvm, &vm_list, vm_list)\n\t\t\twake_up_process(kvm->arch.nx_lpage_recovery_thread);\n\n\t\tmutex_unlock(&kvm_lock);\n\t}\n\n\treturn err;\n}\n\nstatic void kvm_recover_nx_lpages(struct kvm *kvm)\n{\n\tint rcu_idx;\n\tstruct kvm_mmu_page *sp;\n\tunsigned int ratio;\n\tLIST_HEAD(invalid_list);\n\tulong to_zap;\n\n\trcu_idx = srcu_read_lock(&kvm->srcu);\n\tspin_lock(&kvm->mmu_lock);\n\n\tratio = READ_ONCE(nx_huge_pages_recovery_ratio);\n\tto_zap = ratio ? DIV_ROUND_UP(kvm->stat.nx_lpage_splits, ratio) : 0;\n\tfor ( ; to_zap; --to_zap) {\n\t\tif (list_empty(&kvm->arch.lpage_disallowed_mmu_pages))\n\t\t\tbreak;\n\n\t\t/*\n\t\t * We use a separate list instead of just using active_mmu_pages\n\t\t * because the number of lpage_disallowed pages is expected to\n\t\t * be relatively small compared to the total.\n\t\t */\n\t\tsp = list_first_entry(&kvm->arch.lpage_disallowed_mmu_pages,\n\t\t\t\t      struct kvm_mmu_page,\n\t\t\t\t      lpage_disallowed_link);\n\t\tWARN_ON_ONCE(!sp->lpage_disallowed);\n\t\tif (sp->tdp_mmu_page)\n\t\t\tkvm_tdp_mmu_zap_gfn_range(kvm, sp->gfn,\n\t\t\t\tsp->gfn + KVM_PAGES_PER_HPAGE(sp->role.level));\n\t\telse {\n\t\t\tkvm_mmu_prepare_zap_page(kvm, sp, &invalid_list);\n\t\t\tWARN_ON_ONCE(sp->lpage_disallowed);\n\t\t}\n\n\t\tif (need_resched() || spin_needbreak(&kvm->mmu_lock)) {\n\t\t\tkvm_mmu_commit_zap_page(kvm, &invalid_list);\n\t\t\tcond_resched_lock(&kvm->mmu_lock);\n\t\t}\n\t}\n\tkvm_mmu_commit_zap_page(kvm, &invalid_list);\n\n\tspin_unlock(&kvm->mmu_lock);\n\tsrcu_read_unlock(&kvm->srcu, rcu_idx);\n}\n\nstatic long get_nx_lpage_recovery_timeout(u64 start_time)\n{\n\treturn READ_ONCE(nx_huge_pages) && READ_ONCE(nx_huge_pages_recovery_ratio)\n\t\t? start_time + 60 * HZ - get_jiffies_64()\n\t\t: MAX_SCHEDULE_TIMEOUT;\n}\n\nstatic int kvm_nx_lpage_recovery_worker(struct kvm *kvm, uintptr_t data)\n{\n\tu64 start_time;\n\tlong remaining_time;\n\n\twhile (true) {\n\t\tstart_time = get_jiffies_64();\n\t\tremaining_time = get_nx_lpage_recovery_timeout(start_time);\n\n\t\tset_current_state(TASK_INTERRUPTIBLE);\n\t\twhile (!kthread_should_stop() && remaining_time > 0) {\n\t\t\tschedule_timeout(remaining_time);\n\t\t\tremaining_time = get_nx_lpage_recovery_timeout(start_time);\n\t\t\tset_current_state(TASK_INTERRUPTIBLE);\n\t\t}\n\n\t\tset_current_state(TASK_RUNNING);\n\n\t\tif (kthread_should_stop())\n\t\t\treturn 0;\n\n\t\tkvm_recover_nx_lpages(kvm);\n\t}\n}\n\nint kvm_mmu_post_init_vm(struct kvm *kvm)\n{\n\tint err;\n\n\terr = kvm_vm_create_worker_thread(kvm, kvm_nx_lpage_recovery_worker, 0,\n\t\t\t\t\t  \"kvm-nx-lpage-recovery\",\n\t\t\t\t\t  &kvm->arch.nx_lpage_recovery_thread);\n\tif (!err)\n\t\tkthread_unpark(kvm->arch.nx_lpage_recovery_thread);\n\n\treturn err;\n}\n\nvoid kvm_mmu_pre_destroy_vm(struct kvm *kvm)\n{\n\tif (kvm->arch.nx_lpage_recovery_thread)\n\t\tkthread_stop(kvm->arch.nx_lpage_recovery_thread);\n}\n"}}, "reports": [{"events": [{"location": {"col": 0, "file": 0, "line": 947}, "message": "warn: potential spectre issue 'slot->arch.rmap[level - 1]' [w]"}], "macros": [], "notes": [], "path": "/src/arch/x86/kvm/mmu/mmu.c", "reportHash": "498f23a4cd01d7c32a500f55cca45ba5", "checkerName": "smatch.check_spectre", "reviewStatus": null, "severity": "UNSPECIFIED"}]};
      window.onload = function() {
        if (!browserCompatible) {
          setNonCompatibleBrowserMessage();
        } else {
          BugViewer.init(data.files, data.reports);
          BugViewer.create();
          BugViewer.initByUrl();
        }
      };
    </script>
  </head>
  <body>
  <div class="container">
    <div id="content">
      <div id="side-bar">
        <div class="header">
          <a href="index.html" class="button">&#8249; Return to List</a>
        </div>
        <div id="report-nav">
          <div class="header">Reports</div>
        </div>
      </div>
      <div id="editor-wrapper">
        <div class="header">
          <div id="file">
            <span class="label">File:</span>
            <span id="file-path"></span>
          </div>
          <div id="checker">
            <span class="label">Checker name:</span>
            <span id="checker-name"></span>
          </div>
          <div id="review-status-wrapper">
            <span class="label">Review status:</span>
            <span id="review-status"></span>
          </div>
        </div>
        <div id="editor"></div>
      </div>
    </div>
  </div>
  </body>
</html>
