<!DOCTYPE html>
<html>
  <head>
    <title>Plist HTML Viewer</title>

    <meta charset="UTF-8">

    <style type="text/css">
      .CodeMirror{font-family:monospace;height:300px;color:#000;direction:ltr}.CodeMirror-lines{padding:4px 0}.CodeMirror pre{padding:0 4px}.CodeMirror-gutter-filler,.CodeMirror-scrollbar-filler{background-color:#fff}.CodeMirror-gutters{border-right:1px solid #ddd;background-color:#f7f7f7;white-space:nowrap}.CodeMirror-linenumber{padding:0 3px 0 5px;min-width:20px;text-align:right;color:#999;white-space:nowrap}.CodeMirror-guttermarker{color:#000}.CodeMirror-guttermarker-subtle{color:#999}.CodeMirror-cursor{border-left:1px solid #000;border-right:none;width:0}.CodeMirror div.CodeMirror-secondarycursor{border-left:1px solid silver}.cm-fat-cursor .CodeMirror-cursor{width:auto;border:0!important;background:#7e7}.cm-fat-cursor div.CodeMirror-cursors{z-index:1}.cm-animate-fat-cursor{width:auto;border:0;-webkit-animation:blink 1.06s steps(1) infinite;-moz-animation:blink 1.06s steps(1) infinite;animation:blink 1.06s steps(1) infinite;background-color:#7e7}@-moz-keyframes blink{50%{background-color:transparent}}@-webkit-keyframes blink{50%{background-color:transparent}}@keyframes blink{50%{background-color:transparent}}.cm-tab{display:inline-block;text-decoration:inherit}.CodeMirror-rulers{position:absolute;left:0;right:0;top:-50px;bottom:-20px;overflow:hidden}.CodeMirror-ruler{border-left:1px solid #ccc;top:0;bottom:0;position:absolute}.cm-s-default .cm-header{color:#00f}.cm-s-default .cm-quote{color:#090}.cm-negative{color:#d44}.cm-positive{color:#292}.cm-header,.cm-strong{font-weight:700}.cm-em{font-style:italic}.cm-link{text-decoration:underline}.cm-strikethrough{text-decoration:line-through}.cm-s-default .cm-keyword{color:#708}.cm-s-default .cm-atom{color:#219}.cm-s-default .cm-number{color:#164}.cm-s-default .cm-def{color:#00f}.cm-s-default .cm-variable-2{color:#05a}.cm-s-default .cm-type,.cm-s-default .cm-variable-3{color:#085}.cm-s-default .cm-comment{color:#a50}.cm-s-default .cm-string{color:#a11}.cm-s-default .cm-string-2{color:#f50}.cm-s-default .cm-meta{color:#555}.cm-s-default .cm-qualifier{color:#555}.cm-s-default .cm-builtin{color:#30a}.cm-s-default .cm-bracket{color:#997}.cm-s-default .cm-tag{color:#170}.cm-s-default .cm-attribute{color:#00c}.cm-s-default .cm-hr{color:#999}.cm-s-default .cm-link{color:#00c}.cm-s-default .cm-error{color:red}.cm-invalidchar{color:red}.CodeMirror-composing{border-bottom:2px solid}div.CodeMirror span.CodeMirror-matchingbracket{color:#0f0}div.CodeMirror span.CodeMirror-nonmatchingbracket{color:#f22}.CodeMirror-matchingtag{background:rgba(255,150,0,.3)}.CodeMirror-activeline-background{background:#e8f2ff}.CodeMirror{position:relative;overflow:hidden;background:#fff}.CodeMirror-scroll{overflow:scroll!important;margin-bottom:-30px;margin-right:-30px;padding-bottom:30px;height:100%;outline:0;position:relative}.CodeMirror-sizer{position:relative;border-right:30px solid transparent}.CodeMirror-gutter-filler,.CodeMirror-hscrollbar,.CodeMirror-scrollbar-filler,.CodeMirror-vscrollbar{position:absolute;z-index:6;display:none}.CodeMirror-vscrollbar{right:0;top:0;overflow-x:hidden;overflow-y:scroll}.CodeMirror-hscrollbar{bottom:0;left:0;overflow-y:hidden;overflow-x:scroll}.CodeMirror-scrollbar-filler{right:0;bottom:0}.CodeMirror-gutter-filler{left:0;bottom:0}.CodeMirror-gutters{position:absolute;left:0;top:0;min-height:100%;z-index:3}.CodeMirror-gutter{white-space:normal;height:100%;display:inline-block;vertical-align:top;margin-bottom:-30px}.CodeMirror-gutter-wrapper{position:absolute;z-index:4;background:0 0!important;border:none!important}.CodeMirror-gutter-background{position:absolute;top:0;bottom:0;z-index:4}.CodeMirror-gutter-elt{position:absolute;cursor:default;z-index:4}.CodeMirror-gutter-wrapper ::selection{background-color:transparent}.CodeMirror-gutter-wrapper ::-moz-selection{background-color:transparent}.CodeMirror-lines{cursor:text;min-height:1px}.CodeMirror pre{-moz-border-radius:0;-webkit-border-radius:0;border-radius:0;border-width:0;background:0 0;font-family:inherit;font-size:inherit;margin:0;white-space:pre;word-wrap:normal;line-height:inherit;color:inherit;z-index:2;position:relative;overflow:visible;-webkit-tap-highlight-color:transparent;-webkit-font-variant-ligatures:contextual;font-variant-ligatures:contextual}.CodeMirror-wrap pre{word-wrap:break-word;white-space:pre-wrap;word-break:normal}.CodeMirror-linebackground{position:absolute;left:0;right:0;top:0;bottom:0;z-index:0}.CodeMirror-linewidget{position:relative;z-index:2;overflow:auto}.CodeMirror-rtl pre{direction:rtl}.CodeMirror-code{outline:0}.CodeMirror-gutter,.CodeMirror-gutters,.CodeMirror-linenumber,.CodeMirror-scroll,.CodeMirror-sizer{-moz-box-sizing:content-box;box-sizing:content-box}.CodeMirror-measure{position:absolute;width:100%;height:0;overflow:hidden;visibility:hidden}.CodeMirror-cursor{position:absolute;pointer-events:none}.CodeMirror-measure pre{position:static}div.CodeMirror-cursors{visibility:hidden;position:relative;z-index:3}div.CodeMirror-dragcursors{visibility:visible}.CodeMirror-focused div.CodeMirror-cursors{visibility:visible}.CodeMirror-selected{background:#d9d9d9}.CodeMirror-focused .CodeMirror-selected{background:#d7d4f0}.CodeMirror-crosshair{cursor:crosshair}.CodeMirror-line::selection,.CodeMirror-line>span::selection,.CodeMirror-line>span>span::selection{background:#d7d4f0}.CodeMirror-line::-moz-selection,.CodeMirror-line>span::-moz-selection,.CodeMirror-line>span>span::-moz-selection{background:#d7d4f0}.cm-searching{background-color:#ffa;background-color:rgba(255,255,0,.4)}.cm-force-border{padding-right:.1px}@media print{.CodeMirror div.CodeMirror-cursors{visibility:hidden}}.cm-tab-wrap-hack:after{content:''}span.CodeMirror-selectedtext{background:0 0}
/*# sourceMappingURL=codemirror.min.css.map */

      .severity-low {
  background-color: #669603;
}

.severity-low:after {
  content : 'L';
}

.severity-unspecified {
  background-color: #666666;
}

.severity-unspecified:after {
  content : 'U';
}

.severity-style {
  background-color: #9932cc;
}

.severity-style:after {
  content : 'S';
}

.severity-medium {
  background-color: #a9d323;
  color: black;
}

.severity-medium:after {
  content : 'M';
}

.severity-high {
  background-color: #ffa800;
}

.severity-high:after {
  content : 'H';
}

.severity-critical {
  background-color: #e92625;
}

.severity-critical:after {
  content : 'C';
}

i[class*="severity-"] {
  line-height: normal;
  text-transform: capitalize;
  font-size: 0.8em;
  font-weight: bold;
  color: white;
  display: inline-block;
  width: 16px;
  height: 16px;
  text-align: center;
  font-family: sans-serif;
}

      html, body {
  width: 100%;
  height: 100%;
  padding: 0px;
  margin: 0px;
}

div.container {
  padding: 10px;
}

#content {
  height: 100%;
  display: block;
  overflow: hidden;
}

#content > div {
  margin: 10px;
  overflow: hidden;
  border: 1px solid #ddd;
  border-radius: 3px;
  overflow: hidden;
  height: 97%;
}

.button {
  background-color: #f1f1f1;
  text-decoration: none;
  display: inline-block;
  padding: 8px 16px;
  color: black;
  cursor: pointer;
}

.button:hover {
  background-color: #ddd;
  color: black;
}

.review-status {
  color: white;
  text-align: center;
}

.review-status-confirmed {
  background-color: #e92625;
}

.review-status-false-positive {
  background-color: grey;
}

.review-status-intentional {
  background-color: #669603;
}

      div.container {
  width: 100%;
  height: 100%;
  padding: 0px;
}

#editor-wrapper {
  margin: 10px;
}

#side-bar {
  float: left;
  width: 260px;
  margin: 0px;
}

#report-nav ul {
  list-style-type: none;
  padding: 0;
  margin: 0;
  overflow-y: auto;
  height: 100%;
}

#report-nav ul > li {
  padding: .4em;
  background-color: #fff;
  border-bottom: 1px solid rgba(0,0,0,.125);
  text-align: left;
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

#report-nav ul > li.active {
  background-color: #427ea9;
  color: white;
}

#report-nav ul > li:hover {
  background-color: #427ea9;
  color: white;
  cursor: pointer;
}

#report-nav ul a {
  text-decoration: none;
}

#report-nav i[class*="severity-"] {
  margin-right: 5px;
}

.header {
  border-bottom: 1px solid lightgrey;
  font-family: monospace;
  padding: 10px;
  background-color: #fafbfc;
  border-bottom: 1px solid #e1e4e8;
  border-top-left-radius: 2px;
  border-top-right-radius: 2px;
}

#report-nav .header {
  font-weight: bold;
}

#editor-wrapper .header > div {
  padding-top: 2px;
}

#file-path,
#checker-name {
  color: #195ea2;
}

#review-status {
  padding: 0px 5px;
}

#file-path {
  font-family: monospace;
}

.check-msg {
  display: inline-block;
  padding: 3px 6px;
  margin: 1px;
  -webkit-border-radius: 5px;
  -moz-border-radius: 5px;
  border-radius: 5px;
}

.check-msg.info {
  color: #00546f;
  background-color: #bfdfe9;
  border: 1px solid #87a8b3;
}

.check-msg.error {
  background-color: #f2dede;
  color: #a94442;
  border: 1px solid #ebcccc;
}

.check-msg.macro {
  background-color: #d7dac2;
  color: #4f5c6d;
  border: 1px solid #d7dac2;
}

.check-msg.note {
  background-color: #d7d7d7;
  color: #4f5c6d;
  border: 1px solid #bfbfbf;
}

.check-msg.current {
  border: 2px dashed #3692ff;
}

.check-msg .tag {
  padding: 1px 5px;
  text-align: center;
  border-radius: 2px;
  margin-right: 5px;
  text-decoration: inherit;
}

.check-msg .tag.macro {
  background-color: #83876a;
  color: white;
  text-transform: capitalize;
}

.check-msg .tag.note {
  background-color: #9299a1;
  color: white;
  text-transform: capitalize;
}

.checker-enum {
  color: white;
  padding: 1px 5px;
  text-align: center;
  border-radius: 25px;
  margin-right: 5px;
  text-decoration: inherit;
}

.checker-enum.info {
  background-color: #427ea9;
}

.checker-enum.error {
  background-color: #a94442;
}

.arrow {
  border: solid black;
  border-width: 0 3px 3px 0;
  display: inline-block;
  padding: 3px;
  cursor: pointer;
  margin: 0px 5px;
}

.arrow:hover {
  border: solid #437ea8;
  border-width: 0 3px 3px 0;
}

.left-arrow {
  transform: rotate(135deg);
  -webkit-transform: rotate(135deg);
}

.right-arrow {
  transform: rotate(-45deg);
  -webkit-transform: rotate(-45deg);
}

    </style>

    <script type="text/javascript">
      function setNonCompatibleBrowserMessage() {
  document.body.innerHTML =
    '<h2 style="margin-left: 20px;">Your browser is not compatible with CodeChecker Viewer!</h2> \
     <p style="margin-left: 20px;">The version required for the following browsers are:</p> \
     <ul style="margin-left: 20px;"> \
     <li>Internet Explorer: version 9 or newer</li> \
     <li>Firefox: version 22.0 or newer</li> \
     </ul>';
}

// http://stackoverflow.com/questions/5916900/how-can-you-detect-the-version-of-a-browser
var browserVersion = (function(){
  var ua = navigator.userAgent, tem,
    M = ua.match(/(opera|chrome|safari|firefox|msie|trident(?=\/))\/?\s*(\d+)/i) || [];

  if (/trident/i.test(M[1])) {
    tem = /\brv[ :]+(\d+)/g.exec(ua) || [];
    return 'IE ' + (tem[1] || '');
  }

  if (M[1] === 'Chrome') {
    tem = ua.match(/\b(OPR|Edge)\/(\d+)/);
    if (tem != null) return tem.slice(1).join(' ').replace('OPR', 'Opera');
  }

  M = M[2] ? [M[1], M[2]] : [navigator.appName, navigator.appVersion, '-?'];
  if ((tem = ua.match(/version\/(\d+)/i)) != null) M.splice(1, 1, tem[1]);
    return M.join(' ');
})();

var pos = browserVersion.indexOf(' ');
var browser = browserVersion.substr(0, pos);
var version = parseInt(browserVersion.substr(pos + 1));

var browserCompatible
  = browser === 'Firefox'
  ? version >= 22
  : browser === 'IE'
  ? version >= 9
  : true;


      /* MIT License

Copyright (C) 2017 by Marijn Haverbeke <marijnh@gmail.com> and others

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
 */
      !function(e,t){"object"==typeof exports&&"undefined"!=typeof module?module.exports=t():"function"==typeof define&&define.amd?define(t):e.CodeMirror=t()}(this,function(){"use strict";function e(e){return new RegExp("(^|\\s)"+e+"(?:$|\\s)\\s*")}function t(e){for(var t=e.childNodes.length;t>0;--t)e.removeChild(e.firstChild);return e}function r(e,r){return t(e).appendChild(r)}function n(e,t,r,n){var i=document.createElement(e);if(r&&(i.className=r),n&&(i.style.cssText=n),"string"==typeof t)i.appendChild(document.createTextNode(t));else if(t)for(var o=0;o<t.length;++o)i.appendChild(t[o]);return i}function i(e,t,r,i){var o=n(e,t,r,i);return o.setAttribute("role","presentation"),o}function o(e,t){if(3==t.nodeType&&(t=t.parentNode),e.contains)return e.contains(t);do{if(11==t.nodeType&&(t=t.host),t==e)return!0}while(t=t.parentNode)}function l(){var e;try{e=document.activeElement}catch(t){e=document.body||null}for(;e&&e.shadowRoot&&e.shadowRoot.activeElement;)e=e.shadowRoot.activeElement;return e}function s(t,r){var n=t.className;e(r).test(n)||(t.className+=(n?" ":"")+r)}function a(t,r){for(var n=t.split(" "),i=0;i<n.length;i++)n[i]&&!e(n[i]).test(r)&&(r+=" "+n[i]);return r}function u(e){var t=Array.prototype.slice.call(arguments,1);return function(){return e.apply(null,t)}}function c(e,t,r){t||(t={});for(var n in e)!e.hasOwnProperty(n)||!1===r&&t.hasOwnProperty(n)||(t[n]=e[n]);return t}function f(e,t,r,n,i){null==t&&-1==(t=e.search(/[^\s\u00a0]/))&&(t=e.length);for(var o=n||0,l=i||0;;){var s=e.indexOf("\t",o);if(s<0||s>=t)return l+(t-o);l+=s-o,l+=r-l%r,o=s+1}}function h(e,t){for(var r=0;r<e.length;++r)if(e[r]==t)return r;return-1}function d(e,t,r){for(var n=0,i=0;;){var o=e.indexOf("\t",n);-1==o&&(o=e.length);var l=o-n;if(o==e.length||i+l>=t)return n+Math.min(l,t-i);if(i+=o-n,i+=r-i%r,n=o+1,i>=t)return n}}function p(e){for(;Kl.length<=e;)Kl.push(g(Kl)+" ");return Kl[e]}function g(e){return e[e.length-1]}function v(e,t){for(var r=[],n=0;n<e.length;n++)r[n]=t(e[n],n);return r}function m(e,t,r){for(var n=0,i=r(t);n<e.length&&r(e[n])<=i;)n++;e.splice(n,0,t)}function y(){}function b(e,t){var r;return Object.create?r=Object.create(e):(y.prototype=e,r=new y),t&&c(t,r),r}function w(e){return/\w/.test(e)||e>""&&(e.toUpperCase()!=e.toLowerCase()||jl.test(e))}function x(e,t){return t?!!(t.source.indexOf("\\w")>-1&&w(e))||t.test(e):w(e)}function C(e){for(var t in e)if(e.hasOwnProperty(t)&&e[t])return!1;return!0}function S(e){return e.charCodeAt(0)>=768&&Xl.test(e)}function L(e,t,r){for(;(r<0?t>0:t<e.length)&&S(e.charAt(t));)t+=r;return t}function k(e,t,r){for(var n=t>r?-1:1;;){if(t==r)return t;var i=(t+r)/2,o=n<0?Math.ceil(i):Math.floor(i);if(o==t)return e(o)?t:r;e(o)?r=o:t=o+n}}function T(e,t,r){var o=this;this.input=r,o.scrollbarFiller=n("div",null,"CodeMirror-scrollbar-filler"),o.scrollbarFiller.setAttribute("cm-not-content","true"),o.gutterFiller=n("div",null,"CodeMirror-gutter-filler"),o.gutterFiller.setAttribute("cm-not-content","true"),o.lineDiv=i("div",null,"CodeMirror-code"),o.selectionDiv=n("div",null,null,"position: relative; z-index: 1"),o.cursorDiv=n("div",null,"CodeMirror-cursors"),o.measure=n("div",null,"CodeMirror-measure"),o.lineMeasure=n("div",null,"CodeMirror-measure"),o.lineSpace=i("div",[o.measure,o.lineMeasure,o.selectionDiv,o.cursorDiv,o.lineDiv],null,"position: relative; outline: none");var l=i("div",[o.lineSpace],"CodeMirror-lines");o.mover=n("div",[l],null,"position: relative"),o.sizer=n("div",[o.mover],"CodeMirror-sizer"),o.sizerWidth=null,o.heightForcer=n("div",null,null,"position: absolute; height: "+Rl+"px; width: 1px;"),o.gutters=n("div",null,"CodeMirror-gutters"),o.lineGutter=null,o.scroller=n("div",[o.sizer,o.heightForcer,o.gutters],"CodeMirror-scroll"),o.scroller.setAttribute("tabIndex","-1"),o.wrapper=n("div",[o.scrollbarFiller,o.gutterFiller,o.scroller],"CodeMirror"),gl&&vl<8&&(o.gutters.style.zIndex=-1,o.scroller.style.paddingRight=0),ml||fl&&Tl||(o.scroller.draggable=!0),e&&(e.appendChild?e.appendChild(o.wrapper):e(o.wrapper)),o.viewFrom=o.viewTo=t.first,o.reportedViewFrom=o.reportedViewTo=t.first,o.view=[],o.renderedView=null,o.externalMeasured=null,o.viewOffset=0,o.lastWrapHeight=o.lastWrapWidth=0,o.updateLineNumbers=null,o.nativeBarWidth=o.barHeight=o.barWidth=0,o.scrollbarsClipped=!1,o.lineNumWidth=o.lineNumInnerWidth=o.lineNumChars=null,o.alignWidgets=!1,o.cachedCharWidth=o.cachedTextHeight=o.cachedPaddingH=null,o.maxLine=null,o.maxLineLength=0,o.maxLineChanged=!1,o.wheelDX=o.wheelDY=o.wheelStartX=o.wheelStartY=null,o.shift=!1,o.selForContextMenu=null,o.activeTouch=null,r.init(o)}function M(e,t){if((t-=e.first)<0||t>=e.size)throw new Error("There is no line "+(t+e.first)+" in the document.");for(var r=e;!r.lines;)for(var n=0;;++n){var i=r.children[n],o=i.chunkSize();if(t<o){r=i;break}t-=o}return r.lines[t]}function N(e,t,r){var n=[],i=t.line;return e.iter(t.line,r.line+1,function(e){var o=e.text;i==r.line&&(o=o.slice(0,r.ch)),i==t.line&&(o=o.slice(t.ch)),n.push(o),++i}),n}function O(e,t,r){var n=[];return e.iter(t,r,function(e){n.push(e.text)}),n}function A(e,t){var r=t-e.height;if(r)for(var n=e;n;n=n.parent)n.height+=r}function W(e){if(null==e.parent)return null;for(var t=e.parent,r=h(t.lines,e),n=t.parent;n;t=n,n=n.parent)for(var i=0;n.children[i]!=t;++i)r+=n.children[i].chunkSize();return r+t.first}function D(e,t){var r=e.first;e:do{for(var n=0;n<e.children.length;++n){var i=e.children[n],o=i.height;if(t<o){e=i;continue e}t-=o,r+=i.chunkSize()}return r}while(!e.lines);for(var l=0;l<e.lines.length;++l){var s=e.lines[l].height;if(t<s)break;t-=s}return r+l}function H(e,t){return t>=e.first&&t<e.first+e.size}function F(e,t){return String(e.lineNumberFormatter(t+e.firstLineNumber))}function E(e,t,r){if(void 0===r&&(r=null),!(this instanceof E))return new E(e,t,r);this.line=e,this.ch=t,this.sticky=r}function P(e,t){return e.line-t.line||e.ch-t.ch}function I(e,t){return e.sticky==t.sticky&&0==P(e,t)}function z(e){return E(e.line,e.ch)}function R(e,t){return P(e,t)<0?t:e}function B(e,t){return P(e,t)<0?e:t}function G(e,t){return Math.max(e.first,Math.min(t,e.first+e.size-1))}function U(e,t){if(t.line<e.first)return E(e.first,0);var r=e.first+e.size-1;return t.line>r?E(r,M(e,r).text.length):V(t,M(e,t.line).text.length)}function V(e,t){var r=e.ch;return null==r||r>t?E(e.line,t):r<0?E(e.line,0):e}function K(e,t){for(var r=[],n=0;n<t.length;n++)r[n]=U(e,t[n]);return r}function j(){Yl=!0}function X(){_l=!0}function Y(e,t,r){this.marker=e,this.from=t,this.to=r}function _(e,t){if(e)for(var r=0;r<e.length;++r){var n=e[r];if(n.marker==t)return n}}function $(e,t){for(var r,n=0;n<e.length;++n)e[n]!=t&&(r||(r=[])).push(e[n]);return r}function q(e,t){e.markedSpans=e.markedSpans?e.markedSpans.concat([t]):[t],t.marker.attachLine(e)}function Z(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t)||o.from==t&&"bookmark"==l.type&&(!r||!o.marker.insertLeft)){var s=null==o.to||(l.inclusiveRight?o.to>=t:o.to>t);(n||(n=[])).push(new Y(l,o.from,s?null:o.to))}}return n}function Q(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.to||(l.inclusiveRight?o.to>=t:o.to>t)||o.from==t&&"bookmark"==l.type&&(!r||o.marker.insertLeft)){var s=null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t);(n||(n=[])).push(new Y(l,s?null:o.from-t,null==o.to?null:o.to-t))}}return n}function J(e,t){if(t.full)return null;var r=H(e,t.from.line)&&M(e,t.from.line).markedSpans,n=H(e,t.to.line)&&M(e,t.to.line).markedSpans;if(!r&&!n)return null;var i=t.from.ch,o=t.to.ch,l=0==P(t.from,t.to),s=Z(r,i,l),a=Q(n,o,l),u=1==t.text.length,c=g(t.text).length+(u?i:0);if(s)for(var f=0;f<s.length;++f){var h=s[f];if(null==h.to){var d=_(a,h.marker);d?u&&(h.to=null==d.to?null:d.to+c):h.to=i}}if(a)for(var p=0;p<a.length;++p){var v=a[p];null!=v.to&&(v.to+=c),null==v.from?_(s,v.marker)||(v.from=c,u&&(s||(s=[])).push(v)):(v.from+=c,u&&(s||(s=[])).push(v))}s&&(s=ee(s)),a&&a!=s&&(a=ee(a));var m=[s];if(!u){var y,b=t.text.length-2;if(b>0&&s)for(var w=0;w<s.length;++w)null==s[w].to&&(y||(y=[])).push(new Y(s[w].marker,null,null));for(var x=0;x<b;++x)m.push(y);m.push(a)}return m}function ee(e){for(var t=0;t<e.length;++t){var r=e[t];null!=r.from&&r.from==r.to&&!1!==r.marker.clearWhenEmpty&&e.splice(t--,1)}return e.length?e:null}function te(e,t,r){var n=null;if(e.iter(t.line,r.line+1,function(e){if(e.markedSpans)for(var t=0;t<e.markedSpans.length;++t){var r=e.markedSpans[t].marker;!r.readOnly||n&&-1!=h(n,r)||(n||(n=[])).push(r)}}),!n)return null;for(var i=[{from:t,to:r}],o=0;o<n.length;++o)for(var l=n[o],s=l.find(0),a=0;a<i.length;++a){var u=i[a];if(!(P(u.to,s.from)<0||P(u.from,s.to)>0)){var c=[a,1],f=P(u.from,s.from),d=P(u.to,s.to);(f<0||!l.inclusiveLeft&&!f)&&c.push({from:u.from,to:s.from}),(d>0||!l.inclusiveRight&&!d)&&c.push({from:s.to,to:u.to}),i.splice.apply(i,c),a+=c.length-3}}return i}function re(e){var t=e.markedSpans;if(t){for(var r=0;r<t.length;++r)t[r].marker.detachLine(e);e.markedSpans=null}}function ne(e,t){if(t){for(var r=0;r<t.length;++r)t[r].marker.attachLine(e);e.markedSpans=t}}function ie(e){return e.inclusiveLeft?-1:0}function oe(e){return e.inclusiveRight?1:0}function le(e,t){var r=e.lines.length-t.lines.length;if(0!=r)return r;var n=e.find(),i=t.find(),o=P(n.from,i.from)||ie(e)-ie(t);if(o)return-o;var l=P(n.to,i.to)||oe(e)-oe(t);return l||t.id-e.id}function se(e,t){var r,n=_l&&e.markedSpans;if(n)for(var i=void 0,o=0;o<n.length;++o)(i=n[o]).marker.collapsed&&null==(t?i.from:i.to)&&(!r||le(r,i.marker)<0)&&(r=i.marker);return r}function ae(e){return se(e,!0)}function ue(e){return se(e,!1)}function ce(e,t,r,n,i){var o=M(e,t),l=_l&&o.markedSpans;if(l)for(var s=0;s<l.length;++s){var a=l[s];if(a.marker.collapsed){var u=a.marker.find(0),c=P(u.from,r)||ie(a.marker)-ie(i),f=P(u.to,n)||oe(a.marker)-oe(i);if(!(c>=0&&f<=0||c<=0&&f>=0)&&(c<=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.to,r)>=0:P(u.to,r)>0)||c>=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.from,n)<=0:P(u.from,n)<0)))return!0}}}function fe(e){for(var t;t=ae(e);)e=t.find(-1,!0).line;return e}function he(e){for(var t;t=ue(e);)e=t.find(1,!0).line;return e}function de(e){for(var t,r;t=ue(e);)e=t.find(1,!0).line,(r||(r=[])).push(e);return r}function pe(e,t){var r=M(e,t),n=fe(r);return r==n?t:W(n)}function ge(e,t){if(t>e.lastLine())return t;var r,n=M(e,t);if(!ve(e,n))return t;for(;r=ue(n);)n=r.find(1,!0).line;return W(n)+1}function ve(e,t){var r=_l&&t.markedSpans;if(r)for(var n=void 0,i=0;i<r.length;++i)if((n=r[i]).marker.collapsed){if(null==n.from)return!0;if(!n.marker.widgetNode&&0==n.from&&n.marker.inclusiveLeft&&me(e,t,n))return!0}}function me(e,t,r){if(null==r.to){var n=r.marker.find(1,!0);return me(e,n.line,_(n.line.markedSpans,r.marker))}if(r.marker.inclusiveRight&&r.to==t.text.length)return!0;for(var i=void 0,o=0;o<t.markedSpans.length;++o)if((i=t.markedSpans[o]).marker.collapsed&&!i.marker.widgetNode&&i.from==r.to&&(null==i.to||i.to!=r.from)&&(i.marker.inclusiveLeft||r.marker.inclusiveRight)&&me(e,t,i))return!0}function ye(e){for(var t=0,r=(e=fe(e)).parent,n=0;n<r.lines.length;++n){var i=r.lines[n];if(i==e)break;t+=i.height}for(var o=r.parent;o;r=o,o=r.parent)for(var l=0;l<o.children.length;++l){var s=o.children[l];if(s==r)break;t+=s.height}return t}function be(e){if(0==e.height)return 0;for(var t,r=e.text.length,n=e;t=ae(n);){var i=t.find(0,!0);n=i.from.line,r+=i.from.ch-i.to.ch}for(n=e;t=ue(n);){var o=t.find(0,!0);r-=n.text.length-o.from.ch,r+=(n=o.to.line).text.length-o.to.ch}return r}function we(e){var t=e.display,r=e.doc;t.maxLine=M(r,r.first),t.maxLineLength=be(t.maxLine),t.maxLineChanged=!0,r.iter(function(e){var r=be(e);r>t.maxLineLength&&(t.maxLineLength=r,t.maxLine=e)})}function xe(e,t,r,n){if(!e)return n(t,r,"ltr",0);for(var i=!1,o=0;o<e.length;++o){var l=e[o];(l.from<r&&l.to>t||t==r&&l.to==t)&&(n(Math.max(l.from,t),Math.min(l.to,r),1==l.level?"rtl":"ltr",o),i=!0)}i||n(t,r,"ltr")}function Ce(e,t,r){var n;$l=null;for(var i=0;i<e.length;++i){var o=e[i];if(o.from<t&&o.to>t)return i;o.to==t&&(o.from!=o.to&&"before"==r?n=i:$l=i),o.from==t&&(o.from!=o.to&&"before"!=r?n=i:$l=i)}return null!=n?n:$l}function Se(e,t){var r=e.order;return null==r&&(r=e.order=ql(e.text,t)),r}function Le(e,t){return e._handlers&&e._handlers[t]||Zl}function ke(e,t,r){if(e.removeEventListener)e.removeEventListener(t,r,!1);else if(e.detachEvent)e.detachEvent("on"+t,r);else{var n=e._handlers,i=n&&n[t];if(i){var o=h(i,r);o>-1&&(n[t]=i.slice(0,o).concat(i.slice(o+1)))}}}function Te(e,t){var r=Le(e,t);if(r.length)for(var n=Array.prototype.slice.call(arguments,2),i=0;i<r.length;++i)r[i].apply(null,n)}function Me(e,t,r){return"string"==typeof t&&(t={type:t,preventDefault:function(){this.defaultPrevented=!0}}),Te(e,r||t.type,e,t),He(t)||t.codemirrorIgnore}function Ne(e){var t=e._handlers&&e._handlers.cursorActivity;if(t)for(var r=e.curOp.cursorActivityHandlers||(e.curOp.cursorActivityHandlers=[]),n=0;n<t.length;++n)-1==h(r,t[n])&&r.push(t[n])}function Oe(e,t){return Le(e,t).length>0}function Ae(e){e.prototype.on=function(e,t){Ql(this,e,t)},e.prototype.off=function(e,t){ke(this,e,t)}}function We(e){e.preventDefault?e.preventDefault():e.returnValue=!1}function De(e){e.stopPropagation?e.stopPropagation():e.cancelBubble=!0}function He(e){return null!=e.defaultPrevented?e.defaultPrevented:0==e.returnValue}function Fe(e){We(e),De(e)}function Ee(e){return e.target||e.srcElement}function Pe(e){var t=e.which;return null==t&&(1&e.button?t=1:2&e.button?t=3:4&e.button&&(t=2)),Ml&&e.ctrlKey&&1==t&&(t=3),t}function Ie(e){if(null==Il){var t=n("span","​");r(e,n("span",[t,document.createTextNode("x")])),0!=e.firstChild.offsetHeight&&(Il=t.offsetWidth<=1&&t.offsetHeight>2&&!(gl&&vl<8))}var i=Il?n("span","​"):n("span"," ",null,"display: inline-block; width: 1px; margin-right: -1px");return i.setAttribute("cm-text",""),i}function ze(e){if(null!=zl)return zl;var n=r(e,document.createTextNode("AخA")),i=Wl(n,0,1).getBoundingClientRect(),o=Wl(n,1,2).getBoundingClientRect();return t(e),!(!i||i.left==i.right)&&(zl=o.right-i.right<3)}function Re(e){if(null!=ns)return ns;var t=r(e,n("span","x")),i=t.getBoundingClientRect(),o=Wl(t,0,1).getBoundingClientRect();return ns=Math.abs(i.left-o.left)>1}function Be(e,t){arguments.length>2&&(t.dependencies=Array.prototype.slice.call(arguments,2)),is[e]=t}function Ge(e){if("string"==typeof e&&os.hasOwnProperty(e))e=os[e];else if(e&&"string"==typeof e.name&&os.hasOwnProperty(e.name)){var t=os[e.name];"string"==typeof t&&(t={name:t}),(e=b(t,e)).name=t.name}else{if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+xml$/.test(e))return Ge("application/xml");if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+json$/.test(e))return Ge("application/json")}return"string"==typeof e?{name:e}:e||{name:"null"}}function Ue(e,t){t=Ge(t);var r=is[t.name];if(!r)return Ue(e,"text/plain");var n=r(e,t);if(ls.hasOwnProperty(t.name)){var i=ls[t.name];for(var o in i)i.hasOwnProperty(o)&&(n.hasOwnProperty(o)&&(n["_"+o]=n[o]),n[o]=i[o])}if(n.name=t.name,t.helperType&&(n.helperType=t.helperType),t.modeProps)for(var l in t.modeProps)n[l]=t.modeProps[l];return n}function Ve(e,t){c(t,ls.hasOwnProperty(e)?ls[e]:ls[e]={})}function Ke(e,t){if(!0===t)return t;if(e.copyState)return e.copyState(t);var r={};for(var n in t){var i=t[n];i instanceof Array&&(i=i.concat([])),r[n]=i}return r}function je(e,t){for(var r;e.innerMode&&(r=e.innerMode(t))&&r.mode!=e;)t=r.state,e=r.mode;return r||{mode:e,state:t}}function Xe(e,t,r){return!e.startState||e.startState(t,r)}function Ye(e,t,r,n){var i=[e.state.modeGen],o={};tt(e,t.text,e.doc.mode,r,function(e,t){return i.push(e,t)},o,n);for(var l=r.state,s=0;s<e.state.overlays.length;++s)!function(n){var l=e.state.overlays[n],s=1,a=0;r.state=!0,tt(e,t.text,l.mode,r,function(e,t){for(var r=s;a<e;){var n=i[s];n>e&&i.splice(s,1,e,i[s+1],n),s+=2,a=Math.min(e,n)}if(t)if(l.opaque)i.splice(r,s-r,e,"overlay "+t),s=r+2;else for(;r<s;r+=2){var o=i[r+1];i[r+1]=(o?o+" ":"")+"overlay "+t}},o)}(s);return r.state=l,{styles:i,classes:o.bgClass||o.textClass?o:null}}function _e(e,t,r){if(!t.styles||t.styles[0]!=e.state.modeGen){var n=$e(e,W(t)),i=t.text.length>e.options.maxHighlightLength&&Ke(e.doc.mode,n.state),o=Ye(e,t,n);i&&(n.state=i),t.stateAfter=n.save(!i),t.styles=o.styles,o.classes?t.styleClasses=o.classes:t.styleClasses&&(t.styleClasses=null),r===e.doc.highlightFrontier&&(e.doc.modeFrontier=Math.max(e.doc.modeFrontier,++e.doc.highlightFrontier))}return t.styles}function $e(e,t,r){var n=e.doc,i=e.display;if(!n.mode.startState)return new us(n,!0,t);var o=rt(e,t,r),l=o>n.first&&M(n,o-1).stateAfter,s=l?us.fromSaved(n,l,o):new us(n,Xe(n.mode),o);return n.iter(o,t,function(r){qe(e,r.text,s);var n=s.line;r.stateAfter=n==t-1||n%5==0||n>=i.viewFrom&&n<i.viewTo?s.save():null,s.nextLine()}),r&&(n.modeFrontier=s.line),s}function qe(e,t,r,n){var i=e.doc.mode,o=new ss(t,e.options.tabSize,r);for(o.start=o.pos=n||0,""==t&&Ze(i,r.state);!o.eol();)Qe(i,o,r.state),o.start=o.pos}function Ze(e,t){if(e.blankLine)return e.blankLine(t);if(e.innerMode){var r=je(e,t);return r.mode.blankLine?r.mode.blankLine(r.state):void 0}}function Qe(e,t,r,n){for(var i=0;i<10;i++){n&&(n[0]=je(e,r).mode);var o=e.token(t,r);if(t.pos>t.start)return o}throw new Error("Mode "+e.name+" failed to advance stream.")}function Je(e,t,r,n){var i,o,l=e.doc,s=l.mode,a=M(l,(t=U(l,t)).line),u=$e(e,t.line,r),c=new ss(a.text,e.options.tabSize,u);for(n&&(o=[]);(n||c.pos<t.ch)&&!c.eol();)c.start=c.pos,i=Qe(s,c,u.state),n&&o.push(new cs(c,i,Ke(l.mode,u.state)));return n?o:new cs(c,i,u.state)}function et(e,t){if(e)for(;;){var r=e.match(/(?:^|\s+)line-(background-)?(\S+)/);if(!r)break;e=e.slice(0,r.index)+e.slice(r.index+r[0].length);var n=r[1]?"bgClass":"textClass";null==t[n]?t[n]=r[2]:new RegExp("(?:^|s)"+r[2]+"(?:$|s)").test(t[n])||(t[n]+=" "+r[2])}return e}function tt(e,t,r,n,i,o,l){var s=r.flattenSpans;null==s&&(s=e.options.flattenSpans);var a,u=0,c=null,f=new ss(t,e.options.tabSize,n),h=e.options.addModeClass&&[null];for(""==t&&et(Ze(r,n.state),o);!f.eol();){if(f.pos>e.options.maxHighlightLength?(s=!1,l&&qe(e,t,n,f.pos),f.pos=t.length,a=null):a=et(Qe(r,f,n.state,h),o),h){var d=h[0].name;d&&(a="m-"+(a?d+" "+a:d))}if(!s||c!=a){for(;u<f.start;)i(u=Math.min(f.start,u+5e3),c);c=a}f.start=f.pos}for(;u<f.pos;){var p=Math.min(f.pos,u+5e3);i(p,c),u=p}}function rt(e,t,r){for(var n,i,o=e.doc,l=r?-1:t-(e.doc.mode.innerMode?1e3:100),s=t;s>l;--s){if(s<=o.first)return o.first;var a=M(o,s-1),u=a.stateAfter;if(u&&(!r||s+(u instanceof as?u.lookAhead:0)<=o.modeFrontier))return s;var c=f(a.text,null,e.options.tabSize);(null==i||n>c)&&(i=s-1,n=c)}return i}function nt(e,t){if(e.modeFrontier=Math.min(e.modeFrontier,t),!(e.highlightFrontier<t-10)){for(var r=e.first,n=t-1;n>r;n--){var i=M(e,n).stateAfter;if(i&&(!(i instanceof as)||n+i.lookAhead<t)){r=n+1;break}}e.highlightFrontier=Math.min(e.highlightFrontier,r)}}function it(e,t,r,n){e.text=t,e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null),null!=e.order&&(e.order=null),re(e),ne(e,r);var i=n?n(e):1;i!=e.height&&A(e,i)}function ot(e){e.parent=null,re(e)}function lt(e,t){if(!e||/^\s*$/.test(e))return null;var r=t.addModeClass?ps:ds;return r[e]||(r[e]=e.replace(/\S+/g,"cm-$&"))}function st(e,t){var r=i("span",null,null,ml?"padding-right: .1px":null),n={pre:i("pre",[r],"CodeMirror-line"),content:r,col:0,pos:0,cm:e,trailingSpace:!1,splitSpaces:(gl||ml)&&e.getOption("lineWrapping")};t.measure={};for(var o=0;o<=(t.rest?t.rest.length:0);o++){var l=o?t.rest[o-1]:t.line,s=void 0;n.pos=0,n.addToken=ut,ze(e.display.measure)&&(s=Se(l,e.doc.direction))&&(n.addToken=ft(n.addToken,s)),n.map=[],dt(l,n,_e(e,l,t!=e.display.externalMeasured&&W(l))),l.styleClasses&&(l.styleClasses.bgClass&&(n.bgClass=a(l.styleClasses.bgClass,n.bgClass||"")),l.styleClasses.textClass&&(n.textClass=a(l.styleClasses.textClass,n.textClass||""))),0==n.map.length&&n.map.push(0,0,n.content.appendChild(Ie(e.display.measure))),0==o?(t.measure.map=n.map,t.measure.cache={}):((t.measure.maps||(t.measure.maps=[])).push(n.map),(t.measure.caches||(t.measure.caches=[])).push({}))}if(ml){var u=n.content.lastChild;(/\bcm-tab\b/.test(u.className)||u.querySelector&&u.querySelector(".cm-tab"))&&(n.content.className="cm-tab-wrap-hack")}return Te(e,"renderLine",e,t.line,n.pre),n.pre.className&&(n.textClass=a(n.pre.className,n.textClass||"")),n}function at(e){var t=n("span","•","cm-invalidchar");return t.title="\\u"+e.charCodeAt(0).toString(16),t.setAttribute("aria-label",t.title),t}function ut(e,t,r,i,o,l,s){if(t){var a,u=e.splitSpaces?ct(t,e.trailingSpace):t,c=e.cm.state.specialChars,f=!1;if(c.test(t)){a=document.createDocumentFragment();for(var h=0;;){c.lastIndex=h;var d=c.exec(t),g=d?d.index-h:t.length-h;if(g){var v=document.createTextNode(u.slice(h,h+g));gl&&vl<9?a.appendChild(n("span",[v])):a.appendChild(v),e.map.push(e.pos,e.pos+g,v),e.col+=g,e.pos+=g}if(!d)break;h+=g+1;var m=void 0;if("\t"==d[0]){var y=e.cm.options.tabSize,b=y-e.col%y;(m=a.appendChild(n("span",p(b),"cm-tab"))).setAttribute("role","presentation"),m.setAttribute("cm-text","\t"),e.col+=b}else"\r"==d[0]||"\n"==d[0]?((m=a.appendChild(n("span","\r"==d[0]?"␍":"␤","cm-invalidchar"))).setAttribute("cm-text",d[0]),e.col+=1):((m=e.cm.options.specialCharPlaceholder(d[0])).setAttribute("cm-text",d[0]),gl&&vl<9?a.appendChild(n("span",[m])):a.appendChild(m),e.col+=1);e.map.push(e.pos,e.pos+1,m),e.pos++}}else e.col+=t.length,a=document.createTextNode(u),e.map.push(e.pos,e.pos+t.length,a),gl&&vl<9&&(f=!0),e.pos+=t.length;if(e.trailingSpace=32==u.charCodeAt(t.length-1),r||i||o||f||s){var w=r||"";i&&(w+=i),o&&(w+=o);var x=n("span",[a],w,s);return l&&(x.title=l),e.content.appendChild(x)}e.content.appendChild(a)}}function ct(e,t){if(e.length>1&&!/  /.test(e))return e;for(var r=t,n="",i=0;i<e.length;i++){var o=e.charAt(i);" "!=o||!r||i!=e.length-1&&32!=e.charCodeAt(i+1)||(o=" "),n+=o,r=" "==o}return n}function ft(e,t){return function(r,n,i,o,l,s,a){i=i?i+" cm-force-border":"cm-force-border";for(var u=r.pos,c=u+n.length;;){for(var f=void 0,h=0;h<t.length&&!((f=t[h]).to>u&&f.from<=u);h++);if(f.to>=c)return e(r,n,i,o,l,s,a);e(r,n.slice(0,f.to-u),i,o,null,s,a),o=null,n=n.slice(f.to-u),u=f.to}}}function ht(e,t,r,n){var i=!n&&r.widgetNode;i&&e.map.push(e.pos,e.pos+t,i),!n&&e.cm.display.input.needsContentAttribute&&(i||(i=e.content.appendChild(document.createElement("span"))),i.setAttribute("cm-marker",r.id)),i&&(e.cm.display.input.setUneditable(i),e.content.appendChild(i)),e.pos+=t,e.trailingSpace=!1}function dt(e,t,r){var n=e.markedSpans,i=e.text,o=0;if(n)for(var l,s,a,u,c,f,h,d=i.length,p=0,g=1,v="",m=0;;){if(m==p){a=u=c=f=s="",h=null,m=1/0;for(var y=[],b=void 0,w=0;w<n.length;++w){var x=n[w],C=x.marker;"bookmark"==C.type&&x.from==p&&C.widgetNode?y.push(C):x.from<=p&&(null==x.to||x.to>p||C.collapsed&&x.to==p&&x.from==p)?(null!=x.to&&x.to!=p&&m>x.to&&(m=x.to,u=""),C.className&&(a+=" "+C.className),C.css&&(s=(s?s+";":"")+C.css),C.startStyle&&x.from==p&&(c+=" "+C.startStyle),C.endStyle&&x.to==m&&(b||(b=[])).push(C.endStyle,x.to),C.title&&!f&&(f=C.title),C.collapsed&&(!h||le(h.marker,C)<0)&&(h=x)):x.from>p&&m>x.from&&(m=x.from)}if(b)for(var S=0;S<b.length;S+=2)b[S+1]==m&&(u+=" "+b[S]);if(!h||h.from==p)for(var L=0;L<y.length;++L)ht(t,0,y[L]);if(h&&(h.from||0)==p){if(ht(t,(null==h.to?d+1:h.to)-p,h.marker,null==h.from),null==h.to)return;h.to==p&&(h=!1)}}if(p>=d)break;for(var k=Math.min(d,m);;){if(v){var T=p+v.length;if(!h){var M=T>k?v.slice(0,k-p):v;t.addToken(t,M,l?l+a:a,c,p+M.length==m?u:"",f,s)}if(T>=k){v=v.slice(k-p),p=k;break}p=T,c=""}v=i.slice(o,o=r[g++]),l=lt(r[g++],t.cm.options)}}else for(var N=1;N<r.length;N+=2)t.addToken(t,i.slice(o,o=r[N]),lt(r[N+1],t.cm.options))}function pt(e,t,r){this.line=t,this.rest=de(t),this.size=this.rest?W(g(this.rest))-r+1:1,this.node=this.text=null,this.hidden=ve(e,t)}function gt(e,t,r){for(var n,i=[],o=t;o<r;o=n){var l=new pt(e.doc,M(e.doc,o),o);n=o+l.size,i.push(l)}return i}function vt(e){gs?gs.ops.push(e):e.ownsGroup=gs={ops:[e],delayedCallbacks:[]}}function mt(e){var t=e.delayedCallbacks,r=0;do{for(;r<t.length;r++)t[r].call(null);for(var n=0;n<e.ops.length;n++){var i=e.ops[n];if(i.cursorActivityHandlers)for(;i.cursorActivityCalled<i.cursorActivityHandlers.length;)i.cursorActivityHandlers[i.cursorActivityCalled++].call(null,i.cm)}}while(r<t.length)}function yt(e,t){var r=e.ownsGroup;if(r)try{mt(r)}finally{gs=null,t(r)}}function bt(e,t){var r=Le(e,t);if(r.length){var n,i=Array.prototype.slice.call(arguments,2);gs?n=gs.delayedCallbacks:vs?n=vs:(n=vs=[],setTimeout(wt,0));for(var o=0;o<r.length;++o)!function(e){n.push(function(){return r[e].apply(null,i)})}(o)}}function wt(){var e=vs;vs=null;for(var t=0;t<e.length;++t)e[t]()}function xt(e,t,r,n){for(var i=0;i<t.changes.length;i++){var o=t.changes[i];"text"==o?kt(e,t):"gutter"==o?Mt(e,t,r,n):"class"==o?Tt(e,t):"widget"==o&&Nt(e,t,n)}t.changes=null}function Ct(e){return e.node==e.text&&(e.node=n("div",null,null,"position: relative"),e.text.parentNode&&e.text.parentNode.replaceChild(e.node,e.text),e.node.appendChild(e.text),gl&&vl<8&&(e.node.style.zIndex=2)),e.node}function St(e,t){var r=t.bgClass?t.bgClass+" "+(t.line.bgClass||""):t.line.bgClass;if(r&&(r+=" CodeMirror-linebackground"),t.background)r?t.background.className=r:(t.background.parentNode.removeChild(t.background),t.background=null);else if(r){var i=Ct(t);t.background=i.insertBefore(n("div",null,r),i.firstChild),e.display.input.setUneditable(t.background)}}function Lt(e,t){var r=e.display.externalMeasured;return r&&r.line==t.line?(e.display.externalMeasured=null,t.measure=r.measure,r.built):st(e,t)}function kt(e,t){var r=t.text.className,n=Lt(e,t);t.text==t.node&&(t.node=n.pre),t.text.parentNode.replaceChild(n.pre,t.text),t.text=n.pre,n.bgClass!=t.bgClass||n.textClass!=t.textClass?(t.bgClass=n.bgClass,t.textClass=n.textClass,Tt(e,t)):r&&(t.text.className=r)}function Tt(e,t){St(e,t),t.line.wrapClass?Ct(t).className=t.line.wrapClass:t.node!=t.text&&(t.node.className="");var r=t.textClass?t.textClass+" "+(t.line.textClass||""):t.line.textClass;t.text.className=r||""}function Mt(e,t,r,i){if(t.gutter&&(t.node.removeChild(t.gutter),t.gutter=null),t.gutterBackground&&(t.node.removeChild(t.gutterBackground),t.gutterBackground=null),t.line.gutterClass){var o=Ct(t);t.gutterBackground=n("div",null,"CodeMirror-gutter-background "+t.line.gutterClass,"left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px; width: "+i.gutterTotalWidth+"px"),e.display.input.setUneditable(t.gutterBackground),o.insertBefore(t.gutterBackground,t.text)}var l=t.line.gutterMarkers;if(e.options.lineNumbers||l){var s=Ct(t),a=t.gutter=n("div",null,"CodeMirror-gutter-wrapper","left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px");if(e.display.input.setUneditable(a),s.insertBefore(a,t.text),t.line.gutterClass&&(a.className+=" "+t.line.gutterClass),!e.options.lineNumbers||l&&l["CodeMirror-linenumbers"]||(t.lineNumber=a.appendChild(n("div",F(e.options,r),"CodeMirror-linenumber CodeMirror-gutter-elt","left: "+i.gutterLeft["CodeMirror-linenumbers"]+"px; width: "+e.display.lineNumInnerWidth+"px"))),l)for(var u=0;u<e.options.gutters.length;++u){var c=e.options.gutters[u],f=l.hasOwnProperty(c)&&l[c];f&&a.appendChild(n("div",[f],"CodeMirror-gutter-elt","left: "+i.gutterLeft[c]+"px; width: "+i.gutterWidth[c]+"px"))}}}function Nt(e,t,r){t.alignable&&(t.alignable=null);for(var n=t.node.firstChild,i=void 0;n;n=i)i=n.nextSibling,"CodeMirror-linewidget"==n.className&&t.node.removeChild(n);At(e,t,r)}function Ot(e,t,r,n){var i=Lt(e,t);return t.text=t.node=i.pre,i.bgClass&&(t.bgClass=i.bgClass),i.textClass&&(t.textClass=i.textClass),Tt(e,t),Mt(e,t,r,n),At(e,t,n),t.node}function At(e,t,r){if(Wt(e,t.line,t,r,!0),t.rest)for(var n=0;n<t.rest.length;n++)Wt(e,t.rest[n],t,r,!1)}function Wt(e,t,r,i,o){if(t.widgets)for(var l=Ct(r),s=0,a=t.widgets;s<a.length;++s){var u=a[s],c=n("div",[u.node],"CodeMirror-linewidget");u.handleMouseEvents||c.setAttribute("cm-ignore-events","true"),Dt(u,c,r,i),e.display.input.setUneditable(c),o&&u.above?l.insertBefore(c,r.gutter||r.text):l.appendChild(c),bt(u,"redraw")}}function Dt(e,t,r,n){if(e.noHScroll){(r.alignable||(r.alignable=[])).push(t);var i=n.wrapperWidth;t.style.left=n.fixedPos+"px",e.coverGutter||(i-=n.gutterTotalWidth,t.style.paddingLeft=n.gutterTotalWidth+"px"),t.style.width=i+"px"}e.coverGutter&&(t.style.zIndex=5,t.style.position="relative",e.noHScroll||(t.style.marginLeft=-n.gutterTotalWidth+"px"))}function Ht(e){if(null!=e.height)return e.height;var t=e.doc.cm;if(!t)return 0;if(!o(document.body,e.node)){var i="position: relative;";e.coverGutter&&(i+="margin-left: -"+t.display.gutters.offsetWidth+"px;"),e.noHScroll&&(i+="width: "+t.display.wrapper.clientWidth+"px;"),r(t.display.measure,n("div",[e.node],null,i))}return e.height=e.node.parentNode.offsetHeight}function Ft(e,t){for(var r=Ee(t);r!=e.wrapper;r=r.parentNode)if(!r||1==r.nodeType&&"true"==r.getAttribute("cm-ignore-events")||r.parentNode==e.sizer&&r!=e.mover)return!0}function Et(e){return e.lineSpace.offsetTop}function Pt(e){return e.mover.offsetHeight-e.lineSpace.offsetHeight}function It(e){if(e.cachedPaddingH)return e.cachedPaddingH;var t=r(e.measure,n("pre","x")),i=window.getComputedStyle?window.getComputedStyle(t):t.currentStyle,o={left:parseInt(i.paddingLeft),right:parseInt(i.paddingRight)};return isNaN(o.left)||isNaN(o.right)||(e.cachedPaddingH=o),o}function zt(e){return Rl-e.display.nativeBarWidth}function Rt(e){return e.display.scroller.clientWidth-zt(e)-e.display.barWidth}function Bt(e){return e.display.scroller.clientHeight-zt(e)-e.display.barHeight}function Gt(e,t,r){var n=e.options.lineWrapping,i=n&&Rt(e);if(!t.measure.heights||n&&t.measure.width!=i){var o=t.measure.heights=[];if(n){t.measure.width=i;for(var l=t.text.firstChild.getClientRects(),s=0;s<l.length-1;s++){var a=l[s],u=l[s+1];Math.abs(a.bottom-u.bottom)>2&&o.push((a.bottom+u.top)/2-r.top)}}o.push(r.bottom-r.top)}}function Ut(e,t,r){if(e.line==t)return{map:e.measure.map,cache:e.measure.cache};for(var n=0;n<e.rest.length;n++)if(e.rest[n]==t)return{map:e.measure.maps[n],cache:e.measure.caches[n]};for(var i=0;i<e.rest.length;i++)if(W(e.rest[i])>r)return{map:e.measure.maps[i],cache:e.measure.caches[i],before:!0}}function Vt(e,t){var n=W(t=fe(t)),i=e.display.externalMeasured=new pt(e.doc,t,n);i.lineN=n;var o=i.built=st(e,i);return i.text=o.pre,r(e.display.lineMeasure,o.pre),i}function Kt(e,t,r,n){return Yt(e,Xt(e,t),r,n)}function jt(e,t){if(t>=e.display.viewFrom&&t<e.display.viewTo)return e.display.view[Lr(e,t)];var r=e.display.externalMeasured;return r&&t>=r.lineN&&t<r.lineN+r.size?r:void 0}function Xt(e,t){var r=W(t),n=jt(e,r);n&&!n.text?n=null:n&&n.changes&&(xt(e,n,r,br(e)),e.curOp.forceUpdate=!0),n||(n=Vt(e,t));var i=Ut(n,t,r);return{line:t,view:n,rect:null,map:i.map,cache:i.cache,before:i.before,hasHeights:!1}}function Yt(e,t,r,n,i){t.before&&(r=-1);var o,l=r+(n||"");return t.cache.hasOwnProperty(l)?o=t.cache[l]:(t.rect||(t.rect=t.view.text.getBoundingClientRect()),t.hasHeights||(Gt(e,t.view,t.rect),t.hasHeights=!0),(o=qt(e,t,r,n)).bogus||(t.cache[l]=o)),{left:o.left,right:o.right,top:i?o.rtop:o.top,bottom:i?o.rbottom:o.bottom}}function _t(e,t,r){for(var n,i,o,l,s,a,u=0;u<e.length;u+=3)if(s=e[u],a=e[u+1],t<s?(i=0,o=1,l="left"):t<a?o=(i=t-s)+1:(u==e.length-3||t==a&&e[u+3]>t)&&(i=(o=a-s)-1,t>=a&&(l="right")),null!=i){if(n=e[u+2],s==a&&r==(n.insertLeft?"left":"right")&&(l=r),"left"==r&&0==i)for(;u&&e[u-2]==e[u-3]&&e[u-1].insertLeft;)n=e[2+(u-=3)],l="left";if("right"==r&&i==a-s)for(;u<e.length-3&&e[u+3]==e[u+4]&&!e[u+5].insertLeft;)n=e[(u+=3)+2],l="right";break}return{node:n,start:i,end:o,collapse:l,coverStart:s,coverEnd:a}}function $t(e,t){var r=ms;if("left"==t)for(var n=0;n<e.length&&(r=e[n]).left==r.right;n++);else for(var i=e.length-1;i>=0&&(r=e[i]).left==r.right;i--);return r}function qt(e,t,r,n){var i,o=_t(t.map,r,n),l=o.node,s=o.start,a=o.end,u=o.collapse;if(3==l.nodeType){for(var c=0;c<4;c++){for(;s&&S(t.line.text.charAt(o.coverStart+s));)--s;for(;o.coverStart+a<o.coverEnd&&S(t.line.text.charAt(o.coverStart+a));)++a;if((i=gl&&vl<9&&0==s&&a==o.coverEnd-o.coverStart?l.parentNode.getBoundingClientRect():$t(Wl(l,s,a).getClientRects(),n)).left||i.right||0==s)break;a=s,s-=1,u="right"}gl&&vl<11&&(i=Zt(e.display.measure,i))}else{s>0&&(u=n="right");var f;i=e.options.lineWrapping&&(f=l.getClientRects()).length>1?f["right"==n?f.length-1:0]:l.getBoundingClientRect()}if(gl&&vl<9&&!s&&(!i||!i.left&&!i.right)){var h=l.parentNode.getClientRects()[0];i=h?{left:h.left,right:h.left+yr(e.display),top:h.top,bottom:h.bottom}:ms}for(var d=i.top-t.rect.top,p=i.bottom-t.rect.top,g=(d+p)/2,v=t.view.measure.heights,m=0;m<v.length-1&&!(g<v[m]);m++);var y=m?v[m-1]:0,b=v[m],w={left:("right"==u?i.right:i.left)-t.rect.left,right:("left"==u?i.left:i.right)-t.rect.left,top:y,bottom:b};return i.left||i.right||(w.bogus=!0),e.options.singleCursorHeightPerLine||(w.rtop=d,w.rbottom=p),w}function Zt(e,t){if(!window.screen||null==screen.logicalXDPI||screen.logicalXDPI==screen.deviceXDPI||!Re(e))return t;var r=screen.logicalXDPI/screen.deviceXDPI,n=screen.logicalYDPI/screen.deviceYDPI;return{left:t.left*r,right:t.right*r,top:t.top*n,bottom:t.bottom*n}}function Qt(e){if(e.measure&&(e.measure.cache={},e.measure.heights=null,e.rest))for(var t=0;t<e.rest.length;t++)e.measure.caches[t]={}}function Jt(e){e.display.externalMeasure=null,t(e.display.lineMeasure);for(var r=0;r<e.display.view.length;r++)Qt(e.display.view[r])}function er(e){Jt(e),e.display.cachedCharWidth=e.display.cachedTextHeight=e.display.cachedPaddingH=null,e.options.lineWrapping||(e.display.maxLineChanged=!0),e.display.lineNumChars=null}function tr(){return bl&&kl?-(document.body.getBoundingClientRect().left-parseInt(getComputedStyle(document.body).marginLeft)):window.pageXOffset||(document.documentElement||document.body).scrollLeft}function rr(){return bl&&kl?-(document.body.getBoundingClientRect().top-parseInt(getComputedStyle(document.body).marginTop)):window.pageYOffset||(document.documentElement||document.body).scrollTop}function nr(e){var t=0;if(e.widgets)for(var r=0;r<e.widgets.length;++r)e.widgets[r].above&&(t+=Ht(e.widgets[r]));return t}function ir(e,t,r,n,i){if(!i){var o=nr(t);r.top+=o,r.bottom+=o}if("line"==n)return r;n||(n="local");var l=ye(t);if("local"==n?l+=Et(e.display):l-=e.display.viewOffset,"page"==n||"window"==n){var s=e.display.lineSpace.getBoundingClientRect();l+=s.top+("window"==n?0:rr());var a=s.left+("window"==n?0:tr());r.left+=a,r.right+=a}return r.top+=l,r.bottom+=l,r}function or(e,t,r){if("div"==r)return t;var n=t.left,i=t.top;if("page"==r)n-=tr(),i-=rr();else if("local"==r||!r){var o=e.display.sizer.getBoundingClientRect();n+=o.left,i+=o.top}var l=e.display.lineSpace.getBoundingClientRect();return{left:n-l.left,top:i-l.top}}function lr(e,t,r,n,i){return n||(n=M(e.doc,t.line)),ir(e,n,Kt(e,n,t.ch,i),r)}function sr(e,t,r,n,i,o){function l(t,l){var s=Yt(e,i,t,l?"right":"left",o);return l?s.left=s.right:s.right=s.left,ir(e,n,s,r)}function s(e,t,r){var n=1==a[t].level;return l(r?e-1:e,n!=r)}n=n||M(e.doc,t.line),i||(i=Xt(e,n));var a=Se(n,e.doc.direction),u=t.ch,c=t.sticky;if(u>=n.text.length?(u=n.text.length,c="before"):u<=0&&(u=0,c="after"),!a)return l("before"==c?u-1:u,"before"==c);var f=Ce(a,u,c),h=$l,d=s(u,f,"before"==c);return null!=h&&(d.other=s(u,h,"before"!=c)),d}function ar(e,t){var r=0;t=U(e.doc,t),e.options.lineWrapping||(r=yr(e.display)*t.ch);var n=M(e.doc,t.line),i=ye(n)+Et(e.display);return{left:r,right:r,top:i,bottom:i+n.height}}function ur(e,t,r,n,i){var o=E(e,t,r);return o.xRel=i,n&&(o.outside=!0),o}function cr(e,t,r){var n=e.doc;if((r+=e.display.viewOffset)<0)return ur(n.first,0,null,!0,-1);var i=D(n,r),o=n.first+n.size-1;if(i>o)return ur(n.first+n.size-1,M(n,o).text.length,null,!0,1);t<0&&(t=0);for(var l=M(n,i);;){var s=pr(e,l,i,t,r),a=ue(l),u=a&&a.find(0,!0);if(!a||!(s.ch>u.from.ch||s.ch==u.from.ch&&s.xRel>0))return s;i=W(l=u.to.line)}}function fr(e,t,r,n){n-=nr(t);var i=t.text.length,o=k(function(t){return Yt(e,r,t-1).bottom<=n},i,0);return i=k(function(t){return Yt(e,r,t).top>n},o,i),{begin:o,end:i}}function hr(e,t,r,n){return r||(r=Xt(e,t)),fr(e,t,r,ir(e,t,Yt(e,r,n),"line").top)}function dr(e,t,r,n){return!(e.bottom<=r)&&(e.top>r||(n?e.left:e.right)>t)}function pr(e,t,r,n,i){i-=ye(t);var o=Xt(e,t),l=nr(t),s=0,a=t.text.length,u=!0,c=Se(t,e.doc.direction);if(c){var f=(e.options.lineWrapping?vr:gr)(e,t,r,o,c,n,i);s=(u=1!=f.level)?f.from:f.to-1,a=u?f.to:f.from-1}var h,d,p=null,g=null,v=k(function(t){var r=Yt(e,o,t);return r.top+=l,r.bottom+=l,!!dr(r,n,i,!1)&&(r.top<=i&&r.left<=n&&(p=t,g=r),!0)},s,a),m=!1;if(g){var y=n-g.left<g.right-n,b=y==u;v=p+(b?0:1),d=b?"after":"before",h=y?g.left:g.right}else{u||v!=a&&v!=s||v++,d=0==v?"after":v==t.text.length?"before":Yt(e,o,v-(u?1:0)).bottom+l<=i==u?"after":"before";var w=sr(e,E(r,v,d),"line",t,o);h=w.left,m=i<w.top||i>=w.bottom}return v=L(t.text,v,1),ur(r,v,d,m,n-h)}function gr(e,t,r,n,i,o,l){var s=k(function(s){var a=i[s],u=1!=a.level;return dr(sr(e,E(r,u?a.to:a.from,u?"before":"after"),"line",t,n),o,l,!0)},0,i.length-1),a=i[s];if(s>0){var u=1!=a.level,c=sr(e,E(r,u?a.from:a.to,u?"after":"before"),"line",t,n);dr(c,o,l,!0)&&c.top>l&&(a=i[s-1])}return a}function vr(e,t,r,n,i,o,l){for(var s=fr(e,t,n,l),a=s.begin,u=s.end,c=null,f=null,h=0;h<i.length;h++){var d=i[h];if(!(d.from>=u||d.to<=a)){var p=Yt(e,n,1!=d.level?Math.min(u,d.to)-1:Math.max(a,d.from)).right,g=p<o?o-p+1e9:p-o;(!c||f>g)&&(c=d,f=g)}}return c||(c=i[i.length-1]),c.from<a&&(c={from:a,to:c.to,level:c.level}),c.to>u&&(c={from:c.from,to:u,level:c.level}),c}function mr(e){if(null!=e.cachedTextHeight)return e.cachedTextHeight;if(null==hs){hs=n("pre");for(var i=0;i<49;++i)hs.appendChild(document.createTextNode("x")),hs.appendChild(n("br"));hs.appendChild(document.createTextNode("x"))}r(e.measure,hs);var o=hs.offsetHeight/50;return o>3&&(e.cachedTextHeight=o),t(e.measure),o||1}function yr(e){if(null!=e.cachedCharWidth)return e.cachedCharWidth;var t=n("span","xxxxxxxxxx"),i=n("pre",[t]);r(e.measure,i);var o=t.getBoundingClientRect(),l=(o.right-o.left)/10;return l>2&&(e.cachedCharWidth=l),l||10}function br(e){for(var t=e.display,r={},n={},i=t.gutters.clientLeft,o=t.gutters.firstChild,l=0;o;o=o.nextSibling,++l)r[e.options.gutters[l]]=o.offsetLeft+o.clientLeft+i,n[e.options.gutters[l]]=o.clientWidth;return{fixedPos:wr(t),gutterTotalWidth:t.gutters.offsetWidth,gutterLeft:r,gutterWidth:n,wrapperWidth:t.wrapper.clientWidth}}function wr(e){return e.scroller.getBoundingClientRect().left-e.sizer.getBoundingClientRect().left}function xr(e){var t=mr(e.display),r=e.options.lineWrapping,n=r&&Math.max(5,e.display.scroller.clientWidth/yr(e.display)-3);return function(i){if(ve(e.doc,i))return 0;var o=0;if(i.widgets)for(var l=0;l<i.widgets.length;l++)i.widgets[l].height&&(o+=i.widgets[l].height);return r?o+(Math.ceil(i.text.length/n)||1)*t:o+t}}function Cr(e){var t=e.doc,r=xr(e);t.iter(function(e){var t=r(e);t!=e.height&&A(e,t)})}function Sr(e,t,r,n){var i=e.display;if(!r&&"true"==Ee(t).getAttribute("cm-not-content"))return null;var o,l,s=i.lineSpace.getBoundingClientRect();try{o=t.clientX-s.left,l=t.clientY-s.top}catch(t){return null}var a,u=cr(e,o,l);if(n&&1==u.xRel&&(a=M(e.doc,u.line).text).length==u.ch){var c=f(a,a.length,e.options.tabSize)-a.length;u=E(u.line,Math.max(0,Math.round((o-It(e.display).left)/yr(e.display))-c))}return u}function Lr(e,t){if(t>=e.display.viewTo)return null;if((t-=e.display.viewFrom)<0)return null;for(var r=e.display.view,n=0;n<r.length;n++)if((t-=r[n].size)<0)return n}function kr(e){e.display.input.showSelection(e.display.input.prepareSelection())}function Tr(e,t){void 0===t&&(t=!0);for(var r=e.doc,n={},i=n.cursors=document.createDocumentFragment(),o=n.selection=document.createDocumentFragment(),l=0;l<r.sel.ranges.length;l++)if(t||l!=r.sel.primIndex){var s=r.sel.ranges[l];if(!(s.from().line>=e.display.viewTo||s.to().line<e.display.viewFrom)){var a=s.empty();(a||e.options.showCursorWhenSelecting)&&Mr(e,s.head,i),a||Or(e,s,o)}}return n}function Mr(e,t,r){var i=sr(e,t,"div",null,null,!e.options.singleCursorHeightPerLine),o=r.appendChild(n("div"," ","CodeMirror-cursor"));if(o.style.left=i.left+"px",o.style.top=i.top+"px",o.style.height=Math.max(0,i.bottom-i.top)*e.options.cursorHeight+"px",i.other){var l=r.appendChild(n("div"," ","CodeMirror-cursor CodeMirror-secondarycursor"));l.style.display="",l.style.left=i.other.left+"px",l.style.top=i.other.top+"px",l.style.height=.85*(i.other.bottom-i.other.top)+"px"}}function Nr(e,t){return e.top-t.top||e.left-t.left}function Or(e,t,r){function i(e,t,r,i){t<0&&(t=0),t=Math.round(t),i=Math.round(i),a.appendChild(n("div",null,"CodeMirror-selected","position: absolute; left: "+e+"px;\n                             top: "+t+"px; width: "+(null==r?f-e:r)+"px;\n                             height: "+(i-t)+"px"))}function o(t,r,n){function o(r,n){return lr(e,E(t,r),"div",u,n)}var l,a,u=M(s,t),h=u.text.length,d=Se(u,s.direction);return xe(d,r||0,null==n?h:n,function(t,s,p,g){var v=o(t,"ltr"==p?"left":"right"),m=o(s-1,"ltr"==p?"right":"left");if("ltr"==p){var y=null==r&&0==t?c:v.left,b=null==n&&s==h?f:m.right;m.top-v.top<=3?i(y,m.top,b-y,m.bottom):(i(y,v.top,null,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top),i(c,m.top,m.right,m.bottom))}else if(t<s){var w=null==r&&0==t?f:v.right,x=null==n&&s==h?c:m.left;if(m.top-v.top<=3)i(x,m.top,w-x,m.bottom);else{var C=c;if(g){var S=hr(e,u,null,t).end;C=o(S-(/\s/.test(u.text.charAt(S-1))?2:1),"left").left}i(C,v.top,w-C,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top);var L=null;d.length,L=o(hr(e,u,null,s).begin,"right").right-x,i(x,m.top,L,m.bottom)}}(!l||Nr(v,l)<0)&&(l=v),Nr(m,l)<0&&(l=m),(!a||Nr(v,a)<0)&&(a=v),Nr(m,a)<0&&(a=m)}),{start:l,end:a}}var l=e.display,s=e.doc,a=document.createDocumentFragment(),u=It(e.display),c=u.left,f=Math.max(l.sizerWidth,Rt(e)-l.sizer.offsetLeft)-u.right,h=t.from(),d=t.to();if(h.line==d.line)o(h.line,h.ch,d.ch);else{var p=M(s,h.line),g=M(s,d.line),v=fe(p)==fe(g),m=o(h.line,h.ch,v?p.text.length+1:null).end,y=o(d.line,v?0:null,d.ch).start;v&&(m.top<y.top-2?(i(m.right,m.top,null,m.bottom),i(c,y.top,y.left,y.bottom)):i(m.right,m.top,y.left-m.right,m.bottom)),m.bottom<y.top&&i(c,m.bottom,null,y.top)}r.appendChild(a)}function Ar(e){if(e.state.focused){var t=e.display;clearInterval(t.blinker);var r=!0;t.cursorDiv.style.visibility="",e.options.cursorBlinkRate>0?t.blinker=setInterval(function(){return t.cursorDiv.style.visibility=(r=!r)?"":"hidden"},e.options.cursorBlinkRate):e.options.cursorBlinkRate<0&&(t.cursorDiv.style.visibility="hidden")}}function Wr(e){e.state.focused||(e.display.input.focus(),Hr(e))}function Dr(e){e.state.delayingBlurEvent=!0,setTimeout(function(){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1,Fr(e))},100)}function Hr(e,t){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1),"nocursor"!=e.options.readOnly&&(e.state.focused||(Te(e,"focus",e,t),e.state.focused=!0,s(e.display.wrapper,"CodeMirror-focused"),e.curOp||e.display.selForContextMenu==e.doc.sel||(e.display.input.reset(),ml&&setTimeout(function(){return e.display.input.reset(!0)},20)),e.display.input.receivedFocus()),Ar(e))}function Fr(e,t){e.state.delayingBlurEvent||(e.state.focused&&(Te(e,"blur",e,t),e.state.focused=!1,Fl(e.display.wrapper,"CodeMirror-focused")),clearInterval(e.display.blinker),setTimeout(function(){e.state.focused||(e.display.shift=!1)},150))}function Er(e){for(var t=e.display,r=t.lineDiv.offsetTop,n=0;n<t.view.length;n++){var i=t.view[n],o=void 0;if(!i.hidden){if(gl&&vl<8){var l=i.node.offsetTop+i.node.offsetHeight;o=l-r,r=l}else{var s=i.node.getBoundingClientRect();o=s.bottom-s.top}var a=i.line.height-o;if(o<2&&(o=mr(t)),(a>.005||a<-.005)&&(A(i.line,o),Pr(i.line),i.rest))for(var u=0;u<i.rest.length;u++)Pr(i.rest[u])}}}function Pr(e){if(e.widgets)for(var t=0;t<e.widgets.length;++t)e.widgets[t].height=e.widgets[t].node.parentNode.offsetHeight}function Ir(e,t,r){var n=r&&null!=r.top?Math.max(0,r.top):e.scroller.scrollTop;n=Math.floor(n-Et(e));var i=r&&null!=r.bottom?r.bottom:n+e.wrapper.clientHeight,o=D(t,n),l=D(t,i);if(r&&r.ensure){var s=r.ensure.from.line,a=r.ensure.to.line;s<o?(o=s,l=D(t,ye(M(t,s))+e.wrapper.clientHeight)):Math.min(a,t.lastLine())>=l&&(o=D(t,ye(M(t,a))-e.wrapper.clientHeight),l=a)}return{from:o,to:Math.max(l,o+1)}}function zr(e){var t=e.display,r=t.view;if(t.alignWidgets||t.gutters.firstChild&&e.options.fixedGutter){for(var n=wr(t)-t.scroller.scrollLeft+e.doc.scrollLeft,i=t.gutters.offsetWidth,o=n+"px",l=0;l<r.length;l++)if(!r[l].hidden){e.options.fixedGutter&&(r[l].gutter&&(r[l].gutter.style.left=o),r[l].gutterBackground&&(r[l].gutterBackground.style.left=o));var s=r[l].alignable;if(s)for(var a=0;a<s.length;a++)s[a].style.left=o}e.options.fixedGutter&&(t.gutters.style.left=n+i+"px")}}function Rr(e){if(!e.options.lineNumbers)return!1;var t=e.doc,r=F(e.options,t.first+t.size-1),i=e.display;if(r.length!=i.lineNumChars){var o=i.measure.appendChild(n("div",[n("div",r)],"CodeMirror-linenumber CodeMirror-gutter-elt")),l=o.firstChild.offsetWidth,s=o.offsetWidth-l;return i.lineGutter.style.width="",i.lineNumInnerWidth=Math.max(l,i.lineGutter.offsetWidth-s)+1,i.lineNumWidth=i.lineNumInnerWidth+s,i.lineNumChars=i.lineNumInnerWidth?r.length:-1,i.lineGutter.style.width=i.lineNumWidth+"px",Wn(e),!0}return!1}function Br(e,t){if(!Me(e,"scrollCursorIntoView")){var r=e.display,i=r.sizer.getBoundingClientRect(),o=null;if(t.top+i.top<0?o=!0:t.bottom+i.top>(window.innerHeight||document.documentElement.clientHeight)&&(o=!1),null!=o&&!Sl){var l=n("div","​",null,"position: absolute;\n                         top: "+(t.top-r.viewOffset-Et(e.display))+"px;\n                         height: "+(t.bottom-t.top+zt(e)+r.barHeight)+"px;\n                         left: "+t.left+"px; width: "+Math.max(2,t.right-t.left)+"px;");e.display.lineSpace.appendChild(l),l.scrollIntoView(o),e.display.lineSpace.removeChild(l)}}}function Gr(e,t,r,n){null==n&&(n=0);var i;e.options.lineWrapping||t!=r||(r="before"==(t=t.ch?E(t.line,"before"==t.sticky?t.ch-1:t.ch,"after"):t).sticky?E(t.line,t.ch+1,"before"):t);for(var o=0;o<5;o++){var l=!1,s=sr(e,t),a=r&&r!=t?sr(e,r):s,u=Vr(e,i={left:Math.min(s.left,a.left),top:Math.min(s.top,a.top)-n,right:Math.max(s.left,a.left),bottom:Math.max(s.bottom,a.bottom)+n}),c=e.doc.scrollTop,f=e.doc.scrollLeft;if(null!=u.scrollTop&&(qr(e,u.scrollTop),Math.abs(e.doc.scrollTop-c)>1&&(l=!0)),null!=u.scrollLeft&&(Qr(e,u.scrollLeft),Math.abs(e.doc.scrollLeft-f)>1&&(l=!0)),!l)break}return i}function Ur(e,t){var r=Vr(e,t);null!=r.scrollTop&&qr(e,r.scrollTop),null!=r.scrollLeft&&Qr(e,r.scrollLeft)}function Vr(e,t){var r=e.display,n=mr(e.display);t.top<0&&(t.top=0);var i=e.curOp&&null!=e.curOp.scrollTop?e.curOp.scrollTop:r.scroller.scrollTop,o=Bt(e),l={};t.bottom-t.top>o&&(t.bottom=t.top+o);var s=e.doc.height+Pt(r),a=t.top<n,u=t.bottom>s-n;if(t.top<i)l.scrollTop=a?0:t.top;else if(t.bottom>i+o){var c=Math.min(t.top,(u?s:t.bottom)-o);c!=i&&(l.scrollTop=c)}var f=e.curOp&&null!=e.curOp.scrollLeft?e.curOp.scrollLeft:r.scroller.scrollLeft,h=Rt(e)-(e.options.fixedGutter?r.gutters.offsetWidth:0),d=t.right-t.left>h;return d&&(t.right=t.left+h),t.left<10?l.scrollLeft=0:t.left<f?l.scrollLeft=Math.max(0,t.left-(d?0:10)):t.right>h+f-3&&(l.scrollLeft=t.right+(d?0:10)-h),l}function Kr(e,t){null!=t&&(_r(e),e.curOp.scrollTop=(null==e.curOp.scrollTop?e.doc.scrollTop:e.curOp.scrollTop)+t)}function jr(e){_r(e);var t=e.getCursor();e.curOp.scrollToPos={from:t,to:t,margin:e.options.cursorScrollMargin}}function Xr(e,t,r){null==t&&null==r||_r(e),null!=t&&(e.curOp.scrollLeft=t),null!=r&&(e.curOp.scrollTop=r)}function Yr(e,t){_r(e),e.curOp.scrollToPos=t}function _r(e){var t=e.curOp.scrollToPos;t&&(e.curOp.scrollToPos=null,$r(e,ar(e,t.from),ar(e,t.to),t.margin))}function $r(e,t,r,n){var i=Vr(e,{left:Math.min(t.left,r.left),top:Math.min(t.top,r.top)-n,right:Math.max(t.right,r.right),bottom:Math.max(t.bottom,r.bottom)+n});Xr(e,i.scrollLeft,i.scrollTop)}function qr(e,t){Math.abs(e.doc.scrollTop-t)<2||(fl||On(e,{top:t}),Zr(e,t,!0),fl&&On(e),Cn(e,100))}function Zr(e,t,r){t=Math.min(e.display.scroller.scrollHeight-e.display.scroller.clientHeight,t),(e.display.scroller.scrollTop!=t||r)&&(e.doc.scrollTop=t,e.display.scrollbars.setScrollTop(t),e.display.scroller.scrollTop!=t&&(e.display.scroller.scrollTop=t))}function Qr(e,t,r,n){t=Math.min(t,e.display.scroller.scrollWidth-e.display.scroller.clientWidth),(r?t==e.doc.scrollLeft:Math.abs(e.doc.scrollLeft-t)<2)&&!n||(e.doc.scrollLeft=t,zr(e),e.display.scroller.scrollLeft!=t&&(e.display.scroller.scrollLeft=t),e.display.scrollbars.setScrollLeft(t))}function Jr(e){var t=e.display,r=t.gutters.offsetWidth,n=Math.round(e.doc.height+Pt(e.display));return{clientHeight:t.scroller.clientHeight,viewHeight:t.wrapper.clientHeight,scrollWidth:t.scroller.scrollWidth,clientWidth:t.scroller.clientWidth,viewWidth:t.wrapper.clientWidth,barLeft:e.options.fixedGutter?r:0,docHeight:n,scrollHeight:n+zt(e)+t.barHeight,nativeBarWidth:t.nativeBarWidth,gutterWidth:r}}function en(e,t){t||(t=Jr(e));var r=e.display.barWidth,n=e.display.barHeight;tn(e,t);for(var i=0;i<4&&r!=e.display.barWidth||n!=e.display.barHeight;i++)r!=e.display.barWidth&&e.options.lineWrapping&&Er(e),tn(e,Jr(e)),r=e.display.barWidth,n=e.display.barHeight}function tn(e,t){var r=e.display,n=r.scrollbars.update(t);r.sizer.style.paddingRight=(r.barWidth=n.right)+"px",r.sizer.style.paddingBottom=(r.barHeight=n.bottom)+"px",r.heightForcer.style.borderBottom=n.bottom+"px solid transparent",n.right&&n.bottom?(r.scrollbarFiller.style.display="block",r.scrollbarFiller.style.height=n.bottom+"px",r.scrollbarFiller.style.width=n.right+"px"):r.scrollbarFiller.style.display="",n.bottom&&e.options.coverGutterNextToScrollbar&&e.options.fixedGutter?(r.gutterFiller.style.display="block",r.gutterFiller.style.height=n.bottom+"px",r.gutterFiller.style.width=t.gutterWidth+"px"):r.gutterFiller.style.display=""}function rn(e){e.display.scrollbars&&(e.display.scrollbars.clear(),e.display.scrollbars.addClass&&Fl(e.display.wrapper,e.display.scrollbars.addClass)),e.display.scrollbars=new ws[e.options.scrollbarStyle](function(t){e.display.wrapper.insertBefore(t,e.display.scrollbarFiller),Ql(t,"mousedown",function(){e.state.focused&&setTimeout(function(){return e.display.input.focus()},0)}),t.setAttribute("cm-not-content","true")},function(t,r){"horizontal"==r?Qr(e,t):qr(e,t)},e),e.display.scrollbars.addClass&&s(e.display.wrapper,e.display.scrollbars.addClass)}function nn(e){e.curOp={cm:e,viewChanged:!1,startHeight:e.doc.height,forceUpdate:!1,updateInput:null,typing:!1,changeObjs:null,cursorActivityHandlers:null,cursorActivityCalled:0,selectionChanged:!1,updateMaxLine:!1,scrollLeft:null,scrollTop:null,scrollToPos:null,focus:!1,id:++xs},vt(e.curOp)}function on(e){yt(e.curOp,function(e){for(var t=0;t<e.ops.length;t++)e.ops[t].cm.curOp=null;ln(e)})}function ln(e){for(var t=e.ops,r=0;r<t.length;r++)sn(t[r]);for(var n=0;n<t.length;n++)an(t[n]);for(var i=0;i<t.length;i++)un(t[i]);for(var o=0;o<t.length;o++)cn(t[o]);for(var l=0;l<t.length;l++)fn(t[l])}function sn(e){var t=e.cm,r=t.display;Ln(t),e.updateMaxLine&&we(t),e.mustUpdate=e.viewChanged||e.forceUpdate||null!=e.scrollTop||e.scrollToPos&&(e.scrollToPos.from.line<r.viewFrom||e.scrollToPos.to.line>=r.viewTo)||r.maxLineChanged&&t.options.lineWrapping,e.update=e.mustUpdate&&new Cs(t,e.mustUpdate&&{top:e.scrollTop,ensure:e.scrollToPos},e.forceUpdate)}function an(e){e.updatedDisplay=e.mustUpdate&&Mn(e.cm,e.update)}function un(e){var t=e.cm,r=t.display;e.updatedDisplay&&Er(t),e.barMeasure=Jr(t),r.maxLineChanged&&!t.options.lineWrapping&&(e.adjustWidthTo=Kt(t,r.maxLine,r.maxLine.text.length).left+3,t.display.sizerWidth=e.adjustWidthTo,e.barMeasure.scrollWidth=Math.max(r.scroller.clientWidth,r.sizer.offsetLeft+e.adjustWidthTo+zt(t)+t.display.barWidth),e.maxScrollLeft=Math.max(0,r.sizer.offsetLeft+e.adjustWidthTo-Rt(t))),(e.updatedDisplay||e.selectionChanged)&&(e.preparedSelection=r.input.prepareSelection())}function cn(e){var t=e.cm;null!=e.adjustWidthTo&&(t.display.sizer.style.minWidth=e.adjustWidthTo+"px",e.maxScrollLeft<t.doc.scrollLeft&&Qr(t,Math.min(t.display.scroller.scrollLeft,e.maxScrollLeft),!0),t.display.maxLineChanged=!1);var r=e.focus&&e.focus==l();e.preparedSelection&&t.display.input.showSelection(e.preparedSelection,r),(e.updatedDisplay||e.startHeight!=t.doc.height)&&en(t,e.barMeasure),e.updatedDisplay&&Dn(t,e.barMeasure),e.selectionChanged&&Ar(t),t.state.focused&&e.updateInput&&t.display.input.reset(e.typing),r&&Wr(e.cm)}function fn(e){var t=e.cm,r=t.display,n=t.doc;e.updatedDisplay&&Nn(t,e.update),null==r.wheelStartX||null==e.scrollTop&&null==e.scrollLeft&&!e.scrollToPos||(r.wheelStartX=r.wheelStartY=null),null!=e.scrollTop&&Zr(t,e.scrollTop,e.forceScroll),null!=e.scrollLeft&&Qr(t,e.scrollLeft,!0,!0),e.scrollToPos&&Br(t,Gr(t,U(n,e.scrollToPos.from),U(n,e.scrollToPos.to),e.scrollToPos.margin));var i=e.maybeHiddenMarkers,o=e.maybeUnhiddenMarkers;if(i)for(var l=0;l<i.length;++l)i[l].lines.length||Te(i[l],"hide");if(o)for(var s=0;s<o.length;++s)o[s].lines.length&&Te(o[s],"unhide");r.wrapper.offsetHeight&&(n.scrollTop=t.display.scroller.scrollTop),e.changeObjs&&Te(t,"changes",t,e.changeObjs),e.update&&e.update.finish()}function hn(e,t){if(e.curOp)return t();nn(e);try{return t()}finally{on(e)}}function dn(e,t){return function(){if(e.curOp)return t.apply(e,arguments);nn(e);try{return t.apply(e,arguments)}finally{on(e)}}}function pn(e){return function(){if(this.curOp)return e.apply(this,arguments);nn(this);try{return e.apply(this,arguments)}finally{on(this)}}}function gn(e){return function(){var t=this.cm;if(!t||t.curOp)return e.apply(this,arguments);nn(t);try{return e.apply(this,arguments)}finally{on(t)}}}function vn(e,t,r,n){null==t&&(t=e.doc.first),null==r&&(r=e.doc.first+e.doc.size),n||(n=0);var i=e.display;if(n&&r<i.viewTo&&(null==i.updateLineNumbers||i.updateLineNumbers>t)&&(i.updateLineNumbers=t),e.curOp.viewChanged=!0,t>=i.viewTo)_l&&pe(e.doc,t)<i.viewTo&&yn(e);else if(r<=i.viewFrom)_l&&ge(e.doc,r+n)>i.viewFrom?yn(e):(i.viewFrom+=n,i.viewTo+=n);else if(t<=i.viewFrom&&r>=i.viewTo)yn(e);else if(t<=i.viewFrom){var o=bn(e,r,r+n,1);o?(i.view=i.view.slice(o.index),i.viewFrom=o.lineN,i.viewTo+=n):yn(e)}else if(r>=i.viewTo){var l=bn(e,t,t,-1);l?(i.view=i.view.slice(0,l.index),i.viewTo=l.lineN):yn(e)}else{var s=bn(e,t,t,-1),a=bn(e,r,r+n,1);s&&a?(i.view=i.view.slice(0,s.index).concat(gt(e,s.lineN,a.lineN)).concat(i.view.slice(a.index)),i.viewTo+=n):yn(e)}var u=i.externalMeasured;u&&(r<u.lineN?u.lineN+=n:t<u.lineN+u.size&&(i.externalMeasured=null))}function mn(e,t,r){e.curOp.viewChanged=!0;var n=e.display,i=e.display.externalMeasured;if(i&&t>=i.lineN&&t<i.lineN+i.size&&(n.externalMeasured=null),!(t<n.viewFrom||t>=n.viewTo)){var o=n.view[Lr(e,t)];if(null!=o.node){var l=o.changes||(o.changes=[]);-1==h(l,r)&&l.push(r)}}}function yn(e){e.display.viewFrom=e.display.viewTo=e.doc.first,e.display.view=[],e.display.viewOffset=0}function bn(e,t,r,n){var i,o=Lr(e,t),l=e.display.view;if(!_l||r==e.doc.first+e.doc.size)return{index:o,lineN:r};for(var s=e.display.viewFrom,a=0;a<o;a++)s+=l[a].size;if(s!=t){if(n>0){if(o==l.length-1)return null;i=s+l[o].size-t,o++}else i=s-t;t+=i,r+=i}for(;pe(e.doc,r)!=r;){if(o==(n<0?0:l.length-1))return null;r+=n*l[o-(n<0?1:0)].size,o+=n}return{index:o,lineN:r}}function wn(e,t,r){var n=e.display;0==n.view.length||t>=n.viewTo||r<=n.viewFrom?(n.view=gt(e,t,r),n.viewFrom=t):(n.viewFrom>t?n.view=gt(e,t,n.viewFrom).concat(n.view):n.viewFrom<t&&(n.view=n.view.slice(Lr(e,t))),n.viewFrom=t,n.viewTo<r?n.view=n.view.concat(gt(e,n.viewTo,r)):n.viewTo>r&&(n.view=n.view.slice(0,Lr(e,r)))),n.viewTo=r}function xn(e){for(var t=e.display.view,r=0,n=0;n<t.length;n++){var i=t[n];i.hidden||i.node&&!i.changes||++r}return r}function Cn(e,t){e.doc.highlightFrontier<e.display.viewTo&&e.state.highlight.set(t,u(Sn,e))}function Sn(e){var t=e.doc;if(!(t.highlightFrontier>=e.display.viewTo)){var r=+new Date+e.options.workTime,n=$e(e,t.highlightFrontier),i=[];t.iter(n.line,Math.min(t.first+t.size,e.display.viewTo+500),function(o){if(n.line>=e.display.viewFrom){var l=o.styles,s=o.text.length>e.options.maxHighlightLength?Ke(t.mode,n.state):null,a=Ye(e,o,n,!0);s&&(n.state=s),o.styles=a.styles;var u=o.styleClasses,c=a.classes;c?o.styleClasses=c:u&&(o.styleClasses=null);for(var f=!l||l.length!=o.styles.length||u!=c&&(!u||!c||u.bgClass!=c.bgClass||u.textClass!=c.textClass),h=0;!f&&h<l.length;++h)f=l[h]!=o.styles[h];f&&i.push(n.line),o.stateAfter=n.save(),n.nextLine()}else o.text.length<=e.options.maxHighlightLength&&qe(e,o.text,n),o.stateAfter=n.line%5==0?n.save():null,n.nextLine();if(+new Date>r)return Cn(e,e.options.workDelay),!0}),t.highlightFrontier=n.line,t.modeFrontier=Math.max(t.modeFrontier,n.line),i.length&&hn(e,function(){for(var t=0;t<i.length;t++)mn(e,i[t],"text")})}}function Ln(e){var t=e.display;!t.scrollbarsClipped&&t.scroller.offsetWidth&&(t.nativeBarWidth=t.scroller.offsetWidth-t.scroller.clientWidth,t.heightForcer.style.height=zt(e)+"px",t.sizer.style.marginBottom=-t.nativeBarWidth+"px",t.sizer.style.borderRightWidth=zt(e)+"px",t.scrollbarsClipped=!0)}function kn(e){if(e.hasFocus())return null;var t=l();if(!t||!o(e.display.lineDiv,t))return null;var r={activeElt:t};if(window.getSelection){var n=window.getSelection();n.anchorNode&&n.extend&&o(e.display.lineDiv,n.anchorNode)&&(r.anchorNode=n.anchorNode,r.anchorOffset=n.anchorOffset,r.focusNode=n.focusNode,r.focusOffset=n.focusOffset)}return r}function Tn(e){if(e&&e.activeElt&&e.activeElt!=l()&&(e.activeElt.focus(),e.anchorNode&&o(document.body,e.anchorNode)&&o(document.body,e.focusNode))){var t=window.getSelection(),r=document.createRange();r.setEnd(e.anchorNode,e.anchorOffset),r.collapse(!1),t.removeAllRanges(),t.addRange(r),t.extend(e.focusNode,e.focusOffset)}}function Mn(e,r){var n=e.display,i=e.doc;if(r.editorIsHidden)return yn(e),!1;if(!r.force&&r.visible.from>=n.viewFrom&&r.visible.to<=n.viewTo&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo)&&n.renderedView==n.view&&0==xn(e))return!1;Rr(e)&&(yn(e),r.dims=br(e));var o=i.first+i.size,l=Math.max(r.visible.from-e.options.viewportMargin,i.first),s=Math.min(o,r.visible.to+e.options.viewportMargin);n.viewFrom<l&&l-n.viewFrom<20&&(l=Math.max(i.first,n.viewFrom)),n.viewTo>s&&n.viewTo-s<20&&(s=Math.min(o,n.viewTo)),_l&&(l=pe(e.doc,l),s=ge(e.doc,s));var a=l!=n.viewFrom||s!=n.viewTo||n.lastWrapHeight!=r.wrapperHeight||n.lastWrapWidth!=r.wrapperWidth;wn(e,l,s),n.viewOffset=ye(M(e.doc,n.viewFrom)),e.display.mover.style.top=n.viewOffset+"px";var u=xn(e);if(!a&&0==u&&!r.force&&n.renderedView==n.view&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo))return!1;var c=kn(e);return u>4&&(n.lineDiv.style.display="none"),An(e,n.updateLineNumbers,r.dims),u>4&&(n.lineDiv.style.display=""),n.renderedView=n.view,Tn(c),t(n.cursorDiv),t(n.selectionDiv),n.gutters.style.height=n.sizer.style.minHeight=0,a&&(n.lastWrapHeight=r.wrapperHeight,n.lastWrapWidth=r.wrapperWidth,Cn(e,400)),n.updateLineNumbers=null,!0}function Nn(e,t){for(var r=t.viewport,n=!0;(n&&e.options.lineWrapping&&t.oldDisplayWidth!=Rt(e)||(r&&null!=r.top&&(r={top:Math.min(e.doc.height+Pt(e.display)-Bt(e),r.top)}),t.visible=Ir(e.display,e.doc,r),!(t.visible.from>=e.display.viewFrom&&t.visible.to<=e.display.viewTo)))&&Mn(e,t);n=!1){Er(e);var i=Jr(e);kr(e),en(e,i),Dn(e,i),t.force=!1}t.signal(e,"update",e),e.display.viewFrom==e.display.reportedViewFrom&&e.display.viewTo==e.display.reportedViewTo||(t.signal(e,"viewportChange",e,e.display.viewFrom,e.display.viewTo),e.display.reportedViewFrom=e.display.viewFrom,e.display.reportedViewTo=e.display.viewTo)}function On(e,t){var r=new Cs(e,t);if(Mn(e,r)){Er(e),Nn(e,r);var n=Jr(e);kr(e),en(e,n),Dn(e,n),r.finish()}}function An(e,r,n){function i(t){var r=t.nextSibling;return ml&&Ml&&e.display.currentWheelTarget==t?t.style.display="none":t.parentNode.removeChild(t),r}for(var o=e.display,l=e.options.lineNumbers,s=o.lineDiv,a=s.firstChild,u=o.view,c=o.viewFrom,f=0;f<u.length;f++){var d=u[f];if(d.hidden);else if(d.node&&d.node.parentNode==s){for(;a!=d.node;)a=i(a);var p=l&&null!=r&&r<=c&&d.lineNumber;d.changes&&(h(d.changes,"gutter")>-1&&(p=!1),xt(e,d,c,n)),p&&(t(d.lineNumber),d.lineNumber.appendChild(document.createTextNode(F(e.options,c)))),a=d.node.nextSibling}else{var g=Ot(e,d,c,n);s.insertBefore(g,a)}c+=d.size}for(;a;)a=i(a)}function Wn(e){var t=e.display.gutters.offsetWidth;e.display.sizer.style.marginLeft=t+"px"}function Dn(e,t){e.display.sizer.style.minHeight=t.docHeight+"px",e.display.heightForcer.style.top=t.docHeight+"px",e.display.gutters.style.height=t.docHeight+e.display.barHeight+zt(e)+"px"}function Hn(e){var r=e.display.gutters,i=e.options.gutters;t(r);for(var o=0;o<i.length;++o){var l=i[o],s=r.appendChild(n("div",null,"CodeMirror-gutter "+l));"CodeMirror-linenumbers"==l&&(e.display.lineGutter=s,s.style.width=(e.display.lineNumWidth||1)+"px")}r.style.display=o?"":"none",Wn(e)}function Fn(e){var t=h(e.gutters,"CodeMirror-linenumbers");-1==t&&e.lineNumbers?e.gutters=e.gutters.concat(["CodeMirror-linenumbers"]):t>-1&&!e.lineNumbers&&(e.gutters=e.gutters.slice(0),e.gutters.splice(t,1))}function En(e){var t=e.wheelDeltaX,r=e.wheelDeltaY;return null==t&&e.detail&&e.axis==e.HORIZONTAL_AXIS&&(t=e.detail),null==r&&e.detail&&e.axis==e.VERTICAL_AXIS?r=e.detail:null==r&&(r=e.wheelDelta),{x:t,y:r}}function Pn(e){var t=En(e);return t.x*=Ls,t.y*=Ls,t}function In(e,t){var r=En(t),n=r.x,i=r.y,o=e.display,l=o.scroller,s=l.scrollWidth>l.clientWidth,a=l.scrollHeight>l.clientHeight;if(n&&s||i&&a){if(i&&Ml&&ml)e:for(var u=t.target,c=o.view;u!=l;u=u.parentNode)for(var f=0;f<c.length;f++)if(c[f].node==u){e.display.currentWheelTarget=u;break e}if(n&&!fl&&!wl&&null!=Ls)return i&&a&&qr(e,Math.max(0,l.scrollTop+i*Ls)),Qr(e,Math.max(0,l.scrollLeft+n*Ls)),(!i||i&&a)&&We(t),void(o.wheelStartX=null);if(i&&null!=Ls){var h=i*Ls,d=e.doc.scrollTop,p=d+o.wrapper.clientHeight;h<0?d=Math.max(0,d+h-50):p=Math.min(e.doc.height,p+h+50),On(e,{top:d,bottom:p})}Ss<20&&(null==o.wheelStartX?(o.wheelStartX=l.scrollLeft,o.wheelStartY=l.scrollTop,o.wheelDX=n,o.wheelDY=i,setTimeout(function(){if(null!=o.wheelStartX){var e=l.scrollLeft-o.wheelStartX,t=l.scrollTop-o.wheelStartY,r=t&&o.wheelDY&&t/o.wheelDY||e&&o.wheelDX&&e/o.wheelDX;o.wheelStartX=o.wheelStartY=null,r&&(Ls=(Ls*Ss+r)/(Ss+1),++Ss)}},200)):(o.wheelDX+=n,o.wheelDY+=i))}}function zn(e,t){var r=e[t];e.sort(function(e,t){return P(e.from(),t.from())}),t=h(e,r);for(var n=1;n<e.length;n++){var i=e[n],o=e[n-1];if(P(o.to(),i.from())>=0){var l=B(o.from(),i.from()),s=R(o.to(),i.to()),a=o.empty()?i.from()==i.head:o.from()==o.head;n<=t&&--t,e.splice(--n,2,new Ts(a?s:l,a?l:s))}}return new ks(e,t)}function Rn(e,t){return new ks([new Ts(e,t||e)],0)}function Bn(e){return e.text?E(e.from.line+e.text.length-1,g(e.text).length+(1==e.text.length?e.from.ch:0)):e.to}function Gn(e,t){if(P(e,t.from)<0)return e;if(P(e,t.to)<=0)return Bn(t);var r=e.line+t.text.length-(t.to.line-t.from.line)-1,n=e.ch;return e.line==t.to.line&&(n+=Bn(t).ch-t.to.ch),E(r,n)}function Un(e,t){for(var r=[],n=0;n<e.sel.ranges.length;n++){var i=e.sel.ranges[n];r.push(new Ts(Gn(i.anchor,t),Gn(i.head,t)))}return zn(r,e.sel.primIndex)}function Vn(e,t,r){return e.line==t.line?E(r.line,e.ch-t.ch+r.ch):E(r.line+(e.line-t.line),e.ch)}function Kn(e,t,r){for(var n=[],i=E(e.first,0),o=i,l=0;l<t.length;l++){var s=t[l],a=Vn(s.from,i,o),u=Vn(Bn(s),i,o);if(i=s.to,o=u,"around"==r){var c=e.sel.ranges[l],f=P(c.head,c.anchor)<0;n[l]=new Ts(f?u:a,f?a:u)}else n[l]=new Ts(a,a)}return new ks(n,e.sel.primIndex)}function jn(e){e.doc.mode=Ue(e.options,e.doc.modeOption),Xn(e)}function Xn(e){e.doc.iter(function(e){e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null)}),e.doc.modeFrontier=e.doc.highlightFrontier=e.doc.first,Cn(e,100),e.state.modeGen++,e.curOp&&vn(e)}function Yn(e,t){return 0==t.from.ch&&0==t.to.ch&&""==g(t.text)&&(!e.cm||e.cm.options.wholeLineUpdateBefore)}function _n(e,t,r,n){function i(e){return r?r[e]:null}function o(e,r,i){it(e,r,i,n),bt(e,"change",e,t)}function l(e,t){for(var r=[],o=e;o<t;++o)r.push(new fs(u[o],i(o),n));return r}var s=t.from,a=t.to,u=t.text,c=M(e,s.line),f=M(e,a.line),h=g(u),d=i(u.length-1),p=a.line-s.line;if(t.full)e.insert(0,l(0,u.length)),e.remove(u.length,e.size-u.length);else if(Yn(e,t)){var v=l(0,u.length-1);o(f,f.text,d),p&&e.remove(s.line,p),v.length&&e.insert(s.line,v)}else if(c==f)if(1==u.length)o(c,c.text.slice(0,s.ch)+h+c.text.slice(a.ch),d);else{var m=l(1,u.length-1);m.push(new fs(h+c.text.slice(a.ch),d,n)),o(c,c.text.slice(0,s.ch)+u[0],i(0)),e.insert(s.line+1,m)}else if(1==u.length)o(c,c.text.slice(0,s.ch)+u[0]+f.text.slice(a.ch),i(0)),e.remove(s.line+1,p);else{o(c,c.text.slice(0,s.ch)+u[0],i(0)),o(f,h+f.text.slice(a.ch),d);var y=l(1,u.length-1);p>1&&e.remove(s.line+1,p-1),e.insert(s.line+1,y)}bt(e,"change",e,t)}function $n(e,t,r){function n(e,i,o){if(e.linked)for(var l=0;l<e.linked.length;++l){var s=e.linked[l];if(s.doc!=i){var a=o&&s.sharedHist;r&&!a||(t(s.doc,a),n(s.doc,e,a))}}}n(e,null,!0)}function qn(e,t){if(t.cm)throw new Error("This document is already in use.");e.doc=t,t.cm=e,Cr(e),jn(e),Zn(e),e.options.lineWrapping||we(e),e.options.mode=t.modeOption,vn(e)}function Zn(e){("rtl"==e.doc.direction?s:Fl)(e.display.lineDiv,"CodeMirror-rtl")}function Qn(e){hn(e,function(){Zn(e),vn(e)})}function Jn(e){this.done=[],this.undone=[],this.undoDepth=1/0,this.lastModTime=this.lastSelTime=0,this.lastOp=this.lastSelOp=null,this.lastOrigin=this.lastSelOrigin=null,this.generation=this.maxGeneration=e||1}function ei(e,t){var r={from:z(t.from),to:Bn(t),text:N(e,t.from,t.to)};return si(e,r,t.from.line,t.to.line+1),$n(e,function(e){return si(e,r,t.from.line,t.to.line+1)},!0),r}function ti(e){for(;e.length&&g(e).ranges;)e.pop()}function ri(e,t){return t?(ti(e.done),g(e.done)):e.done.length&&!g(e.done).ranges?g(e.done):e.done.length>1&&!e.done[e.done.length-2].ranges?(e.done.pop(),g(e.done)):void 0}function ni(e,t,r,n){var i=e.history;i.undone.length=0;var o,l,s=+new Date;if((i.lastOp==n||i.lastOrigin==t.origin&&t.origin&&("+"==t.origin.charAt(0)&&e.cm&&i.lastModTime>s-e.cm.options.historyEventDelay||"*"==t.origin.charAt(0)))&&(o=ri(i,i.lastOp==n)))l=g(o.changes),0==P(t.from,t.to)&&0==P(t.from,l.to)?l.to=Bn(t):o.changes.push(ei(e,t));else{var a=g(i.done);for(a&&a.ranges||li(e.sel,i.done),o={changes:[ei(e,t)],generation:i.generation},i.done.push(o);i.done.length>i.undoDepth;)i.done.shift(),i.done[0].ranges||i.done.shift()}i.done.push(r),i.generation=++i.maxGeneration,i.lastModTime=i.lastSelTime=s,i.lastOp=i.lastSelOp=n,i.lastOrigin=i.lastSelOrigin=t.origin,l||Te(e,"historyAdded")}function ii(e,t,r,n){var i=t.charAt(0);return"*"==i||"+"==i&&r.ranges.length==n.ranges.length&&r.somethingSelected()==n.somethingSelected()&&new Date-e.history.lastSelTime<=(e.cm?e.cm.options.historyEventDelay:500)}function oi(e,t,r,n){var i=e.history,o=n&&n.origin;r==i.lastSelOp||o&&i.lastSelOrigin==o&&(i.lastModTime==i.lastSelTime&&i.lastOrigin==o||ii(e,o,g(i.done),t))?i.done[i.done.length-1]=t:li(t,i.done),i.lastSelTime=+new Date,i.lastSelOrigin=o,i.lastSelOp=r,n&&!1!==n.clearRedo&&ti(i.undone)}function li(e,t){var r=g(t);r&&r.ranges&&r.equals(e)||t.push(e)}function si(e,t,r,n){var i=t["spans_"+e.id],o=0;e.iter(Math.max(e.first,r),Math.min(e.first+e.size,n),function(r){r.markedSpans&&((i||(i=t["spans_"+e.id]={}))[o]=r.markedSpans),++o})}function ai(e){if(!e)return null;for(var t,r=0;r<e.length;++r)e[r].marker.explicitlyCleared?t||(t=e.slice(0,r)):t&&t.push(e[r]);return t?t.length?t:null:e}function ui(e,t){var r=t["spans_"+e.id];if(!r)return null;for(var n=[],i=0;i<t.text.length;++i)n.push(ai(r[i]));return n}function ci(e,t){var r=ui(e,t),n=J(e,t);if(!r)return n;if(!n)return r;for(var i=0;i<r.length;++i){var o=r[i],l=n[i];if(o&&l)e:for(var s=0;s<l.length;++s){for(var a=l[s],u=0;u<o.length;++u)if(o[u].marker==a.marker)continue e;o.push(a)}else l&&(r[i]=l)}return r}function fi(e,t,r){for(var n=[],i=0;i<e.length;++i){var o=e[i];if(o.ranges)n.push(r?ks.prototype.deepCopy.call(o):o);else{var l=o.changes,s=[];n.push({changes:s});for(var a=0;a<l.length;++a){var u=l[a],c=void 0;if(s.push({from:u.from,to:u.to,text:u.text}),t)for(var f in u)(c=f.match(/^spans_(\d+)$/))&&h(t,Number(c[1]))>-1&&(g(s)[f]=u[f],delete u[f])}}}return n}function hi(e,t,r,n){if(n){var i=e.anchor;if(r){var o=P(t,i)<0;o!=P(r,i)<0?(i=t,t=r):o!=P(t,r)<0&&(t=r)}return new Ts(i,t)}return new Ts(r||t,t)}function di(e,t,r,n,i){null==i&&(i=e.cm&&(e.cm.display.shift||e.extend)),bi(e,new ks([hi(e.sel.primary(),t,r,i)],0),n)}function pi(e,t,r){for(var n=[],i=e.cm&&(e.cm.display.shift||e.extend),o=0;o<e.sel.ranges.length;o++)n[o]=hi(e.sel.ranges[o],t[o],null,i);bi(e,zn(n,e.sel.primIndex),r)}function gi(e,t,r,n){var i=e.sel.ranges.slice(0);i[t]=r,bi(e,zn(i,e.sel.primIndex),n)}function vi(e,t,r,n){bi(e,Rn(t,r),n)}function mi(e,t,r){var n={ranges:t.ranges,update:function(t){var r=this;this.ranges=[];for(var n=0;n<t.length;n++)r.ranges[n]=new Ts(U(e,t[n].anchor),U(e,t[n].head))},origin:r&&r.origin};return Te(e,"beforeSelectionChange",e,n),e.cm&&Te(e.cm,"beforeSelectionChange",e.cm,n),n.ranges!=t.ranges?zn(n.ranges,n.ranges.length-1):t}function yi(e,t,r){var n=e.history.done,i=g(n);i&&i.ranges?(n[n.length-1]=t,wi(e,t,r)):bi(e,t,r)}function bi(e,t,r){wi(e,t,r),oi(e,e.sel,e.cm?e.cm.curOp.id:NaN,r)}function wi(e,t,r){(Oe(e,"beforeSelectionChange")||e.cm&&Oe(e.cm,"beforeSelectionChange"))&&(t=mi(e,t,r)),xi(e,Si(e,t,r&&r.bias||(P(t.primary().head,e.sel.primary().head)<0?-1:1),!0)),r&&!1===r.scroll||!e.cm||jr(e.cm)}function xi(e,t){t.equals(e.sel)||(e.sel=t,e.cm&&(e.cm.curOp.updateInput=e.cm.curOp.selectionChanged=!0,Ne(e.cm)),bt(e,"cursorActivity",e))}function Ci(e){xi(e,Si(e,e.sel,null,!1))}function Si(e,t,r,n){for(var i,o=0;o<t.ranges.length;o++){var l=t.ranges[o],s=t.ranges.length==e.sel.ranges.length&&e.sel.ranges[o],a=ki(e,l.anchor,s&&s.anchor,r,n),u=ki(e,l.head,s&&s.head,r,n);(i||a!=l.anchor||u!=l.head)&&(i||(i=t.ranges.slice(0,o)),i[o]=new Ts(a,u))}return i?zn(i,t.primIndex):t}function Li(e,t,r,n,i){var o=M(e,t.line);if(o.markedSpans)for(var l=0;l<o.markedSpans.length;++l){var s=o.markedSpans[l],a=s.marker;if((null==s.from||(a.inclusiveLeft?s.from<=t.ch:s.from<t.ch))&&(null==s.to||(a.inclusiveRight?s.to>=t.ch:s.to>t.ch))){if(i&&(Te(a,"beforeCursorEnter"),a.explicitlyCleared)){if(o.markedSpans){--l;continue}break}if(!a.atomic)continue;if(r){var u=a.find(n<0?1:-1),c=void 0;if((n<0?a.inclusiveRight:a.inclusiveLeft)&&(u=Ti(e,u,-n,u&&u.line==t.line?o:null)),u&&u.line==t.line&&(c=P(u,r))&&(n<0?c<0:c>0))return Li(e,u,t,n,i)}var f=a.find(n<0?-1:1);return(n<0?a.inclusiveLeft:a.inclusiveRight)&&(f=Ti(e,f,n,f.line==t.line?o:null)),f?Li(e,f,t,n,i):null}}return t}function ki(e,t,r,n,i){var o=n||1,l=Li(e,t,r,o,i)||!i&&Li(e,t,r,o,!0)||Li(e,t,r,-o,i)||!i&&Li(e,t,r,-o,!0);return l||(e.cantEdit=!0,E(e.first,0))}function Ti(e,t,r,n){return r<0&&0==t.ch?t.line>e.first?U(e,E(t.line-1)):null:r>0&&t.ch==(n||M(e,t.line)).text.length?t.line<e.first+e.size-1?E(t.line+1,0):null:new E(t.line,t.ch+r)}function Mi(e){e.setSelection(E(e.firstLine(),0),E(e.lastLine()),Gl)}function Ni(e,t,r){var n={canceled:!1,from:t.from,to:t.to,text:t.text,origin:t.origin,cancel:function(){return n.canceled=!0}};return r&&(n.update=function(t,r,i,o){t&&(n.from=U(e,t)),r&&(n.to=U(e,r)),i&&(n.text=i),void 0!==o&&(n.origin=o)}),Te(e,"beforeChange",e,n),e.cm&&Te(e.cm,"beforeChange",e.cm,n),n.canceled?null:{from:n.from,to:n.to,text:n.text,origin:n.origin}}function Oi(e,t,r){if(e.cm){if(!e.cm.curOp)return dn(e.cm,Oi)(e,t,r);if(e.cm.state.suppressEdits)return}if(!(Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"))||(t=Ni(e,t,!0))){var n=Yl&&!r&&te(e,t.from,t.to);if(n)for(var i=n.length-1;i>=0;--i)Ai(e,{from:n[i].from,to:n[i].to,text:i?[""]:t.text,origin:t.origin});else Ai(e,t)}}function Ai(e,t){if(1!=t.text.length||""!=t.text[0]||0!=P(t.from,t.to)){var r=Un(e,t);ni(e,t,r,e.cm?e.cm.curOp.id:NaN),Hi(e,t,r,J(e,t));var n=[];$n(e,function(e,r){r||-1!=h(n,e.history)||(zi(e.history,t),n.push(e.history)),Hi(e,t,null,J(e,t))})}}function Wi(e,t,r){if(!e.cm||!e.cm.state.suppressEdits||r){for(var n,i=e.history,o=e.sel,l="undo"==t?i.done:i.undone,s="undo"==t?i.undone:i.done,a=0;a<l.length&&(n=l[a],r?!n.ranges||n.equals(e.sel):n.ranges);a++);if(a!=l.length){for(i.lastOrigin=i.lastSelOrigin=null;(n=l.pop()).ranges;){if(li(n,s),r&&!n.equals(e.sel))return void bi(e,n,{clearRedo:!1});o=n}var u=[];li(o,s),s.push({changes:u,generation:i.generation}),i.generation=n.generation||++i.maxGeneration;for(var c=Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"),f=n.changes.length-1;f>=0;--f){var d=function(r){var i=n.changes[r];if(i.origin=t,c&&!Ni(e,i,!1))return l.length=0,{};u.push(ei(e,i));var o=r?Un(e,i):g(l);Hi(e,i,o,ci(e,i)),!r&&e.cm&&e.cm.scrollIntoView({from:i.from,to:Bn(i)});var s=[];$n(e,function(e,t){t||-1!=h(s,e.history)||(zi(e.history,i),s.push(e.history)),Hi(e,i,null,ci(e,i))})}(f);if(d)return d.v}}}}function Di(e,t){if(0!=t&&(e.first+=t,e.sel=new ks(v(e.sel.ranges,function(e){return new Ts(E(e.anchor.line+t,e.anchor.ch),E(e.head.line+t,e.head.ch))}),e.sel.primIndex),e.cm)){vn(e.cm,e.first,e.first-t,t);for(var r=e.cm.display,n=r.viewFrom;n<r.viewTo;n++)mn(e.cm,n,"gutter")}}function Hi(e,t,r,n){if(e.cm&&!e.cm.curOp)return dn(e.cm,Hi)(e,t,r,n);if(t.to.line<e.first)Di(e,t.text.length-1-(t.to.line-t.from.line));else if(!(t.from.line>e.lastLine())){if(t.from.line<e.first){var i=t.text.length-1-(e.first-t.from.line);Di(e,i),t={from:E(e.first,0),to:E(t.to.line+i,t.to.ch),text:[g(t.text)],origin:t.origin}}var o=e.lastLine();t.to.line>o&&(t={from:t.from,to:E(o,M(e,o).text.length),text:[t.text[0]],origin:t.origin}),t.removed=N(e,t.from,t.to),r||(r=Un(e,t)),e.cm?Fi(e.cm,t,n):_n(e,t,n),wi(e,r,Gl)}}function Fi(e,t,r){var n=e.doc,i=e.display,o=t.from,l=t.to,s=!1,a=o.line;e.options.lineWrapping||(a=W(fe(M(n,o.line))),n.iter(a,l.line+1,function(e){if(e==i.maxLine)return s=!0,!0})),n.sel.contains(t.from,t.to)>-1&&Ne(e),_n(n,t,r,xr(e)),e.options.lineWrapping||(n.iter(a,o.line+t.text.length,function(e){var t=be(e);t>i.maxLineLength&&(i.maxLine=e,i.maxLineLength=t,i.maxLineChanged=!0,s=!1)}),s&&(e.curOp.updateMaxLine=!0)),nt(n,o.line),Cn(e,400);var u=t.text.length-(l.line-o.line)-1;t.full?vn(e):o.line!=l.line||1!=t.text.length||Yn(e.doc,t)?vn(e,o.line,l.line+1,u):mn(e,o.line,"text");var c=Oe(e,"changes"),f=Oe(e,"change");if(f||c){var h={from:o,to:l,text:t.text,removed:t.removed,origin:t.origin};f&&bt(e,"change",e,h),c&&(e.curOp.changeObjs||(e.curOp.changeObjs=[])).push(h)}e.display.selForContextMenu=null}function Ei(e,t,r,n,i){if(n||(n=r),P(n,r)<0){var o;r=(o=[n,r])[0],n=o[1]}"string"==typeof t&&(t=e.splitLines(t)),Oi(e,{from:r,to:n,text:t,origin:i})}function Pi(e,t,r,n){r<e.line?e.line+=n:t<e.line&&(e.line=t,e.ch=0)}function Ii(e,t,r,n){for(var i=0;i<e.length;++i){var o=e[i],l=!0;if(o.ranges){o.copied||((o=e[i]=o.deepCopy()).copied=!0);for(var s=0;s<o.ranges.length;s++)Pi(o.ranges[s].anchor,t,r,n),Pi(o.ranges[s].head,t,r,n)}else{for(var a=0;a<o.changes.length;++a){var u=o.changes[a];if(r<u.from.line)u.from=E(u.from.line+n,u.from.ch),u.to=E(u.to.line+n,u.to.ch);else if(t<=u.to.line){l=!1;break}}l||(e.splice(0,i+1),i=0)}}}function zi(e,t){var r=t.from.line,n=t.to.line,i=t.text.length-(n-r)-1;Ii(e.done,r,n,i),Ii(e.undone,r,n,i)}function Ri(e,t,r,n){var i=t,o=t;return"number"==typeof t?o=M(e,G(e,t)):i=W(t),null==i?null:(n(o,i)&&e.cm&&mn(e.cm,i,r),o)}function Bi(e){var t=this;this.lines=e,this.parent=null;for(var r=0,n=0;n<e.length;++n)e[n].parent=t,r+=e[n].height;this.height=r}function Gi(e){var t=this;this.children=e;for(var r=0,n=0,i=0;i<e.length;++i){var o=e[i];r+=o.chunkSize(),n+=o.height,o.parent=t}this.size=r,this.height=n,this.parent=null}function Ui(e,t,r){ye(t)<(e.curOp&&e.curOp.scrollTop||e.doc.scrollTop)&&Kr(e,r)}function Vi(e,t,r,n){var i=new Ms(e,r,n),o=e.cm;return o&&i.noHScroll&&(o.display.alignWidgets=!0),Ri(e,t,"widget",function(t){var r=t.widgets||(t.widgets=[]);if(null==i.insertAt?r.push(i):r.splice(Math.min(r.length-1,Math.max(0,i.insertAt)),0,i),i.line=t,o&&!ve(e,t)){var n=ye(t)<e.scrollTop;A(t,t.height+Ht(i)),n&&Kr(o,i.height),o.curOp.forceUpdate=!0}return!0}),bt(o,"lineWidgetAdded",o,i,"number"==typeof t?t:W(t)),i}function Ki(e,t,r,n,o){if(n&&n.shared)return ji(e,t,r,n,o);if(e.cm&&!e.cm.curOp)return dn(e.cm,Ki)(e,t,r,n,o);var l=new Os(e,o),s=P(t,r);if(n&&c(n,l,!1),s>0||0==s&&!1!==l.clearWhenEmpty)return l;if(l.replacedWith&&(l.collapsed=!0,l.widgetNode=i("span",[l.replacedWith],"CodeMirror-widget"),n.handleMouseEvents||l.widgetNode.setAttribute("cm-ignore-events","true"),n.insertLeft&&(l.widgetNode.insertLeft=!0)),l.collapsed){if(ce(e,t.line,t,r,l)||t.line!=r.line&&ce(e,r.line,t,r,l))throw new Error("Inserting collapsed marker partially overlapping an existing one");X()}l.addToHistory&&ni(e,{from:t,to:r,origin:"markText"},e.sel,NaN);var a,u=t.line,f=e.cm;if(e.iter(u,r.line+1,function(e){f&&l.collapsed&&!f.options.lineWrapping&&fe(e)==f.display.maxLine&&(a=!0),l.collapsed&&u!=t.line&&A(e,0),q(e,new Y(l,u==t.line?t.ch:null,u==r.line?r.ch:null)),++u}),l.collapsed&&e.iter(t.line,r.line+1,function(t){ve(e,t)&&A(t,0)}),l.clearOnEnter&&Ql(l,"beforeCursorEnter",function(){return l.clear()}),l.readOnly&&(j(),(e.history.done.length||e.history.undone.length)&&e.clearHistory()),l.collapsed&&(l.id=++Ns,l.atomic=!0),f){if(a&&(f.curOp.updateMaxLine=!0),l.collapsed)vn(f,t.line,r.line+1);else if(l.className||l.title||l.startStyle||l.endStyle||l.css)for(var h=t.line;h<=r.line;h++)mn(f,h,"text");l.atomic&&Ci(f.doc),bt(f,"markerAdded",f,l)}return l}function ji(e,t,r,n,i){(n=c(n)).shared=!1;var o=[Ki(e,t,r,n,i)],l=o[0],s=n.widgetNode;return $n(e,function(e){s&&(n.widgetNode=s.cloneNode(!0)),o.push(Ki(e,U(e,t),U(e,r),n,i));for(var a=0;a<e.linked.length;++a)if(e.linked[a].isParent)return;l=g(o)}),new As(o,l)}function Xi(e){return e.findMarks(E(e.first,0),e.clipPos(E(e.lastLine())),function(e){return e.parent})}function Yi(e,t){for(var r=0;r<t.length;r++){var n=t[r],i=n.find(),o=e.clipPos(i.from),l=e.clipPos(i.to);if(P(o,l)){var s=Ki(e,o,l,n.primary,n.primary.type);n.markers.push(s),s.parent=n}}}function _i(e){for(var t=0;t<e.length;t++)!function(t){var r=e[t],n=[r.primary.doc];$n(r.primary.doc,function(e){return n.push(e)});for(var i=0;i<r.markers.length;i++){var o=r.markers[i];-1==h(n,o.doc)&&(o.parent=null,r.markers.splice(i--,1))}}(t)}function $i(e){var t=this;if(Qi(t),!Me(t,e)&&!Ft(t.display,e)){We(e),gl&&(Hs=+new Date);var r=Sr(t,e,!0),n=e.dataTransfer.files;if(r&&!t.isReadOnly())if(n&&n.length&&window.FileReader&&window.File)for(var i=n.length,o=Array(i),l=0,s=0;s<i;++s)!function(e,n){if(!t.options.allowDropFileTypes||-1!=h(t.options.allowDropFileTypes,e.type)){var s=new FileReader;s.onload=dn(t,function(){var e=s.result;if(/[\x00-\x08\x0e-\x1f]{2}/.test(e)&&(e=""),o[n]=e,++l==i){var a={from:r=U(t.doc,r),to:r,text:t.doc.splitLines(o.join(t.doc.lineSeparator())),origin:"paste"};Oi(t.doc,a),yi(t.doc,Rn(r,Bn(a)))}}),s.readAsText(e)}}(n[s],s);else{if(t.state.draggingText&&t.doc.sel.contains(r)>-1)return t.state.draggingText(e),void setTimeout(function(){return t.display.input.focus()},20);try{var a=e.dataTransfer.getData("Text");if(a){var u;if(t.state.draggingText&&!t.state.draggingText.copy&&(u=t.listSelections()),wi(t.doc,Rn(r,r)),u)for(var c=0;c<u.length;++c)Ei(t.doc,"",u[c].anchor,u[c].head,"drag");t.replaceSelection(a,"around","paste"),t.display.input.focus()}}catch(e){}}}}function qi(e,t){if(gl&&(!e.state.draggingText||+new Date-Hs<100))Fe(t);else if(!Me(e,t)&&!Ft(e.display,t)&&(t.dataTransfer.setData("Text",e.getSelection()),t.dataTransfer.effectAllowed="copyMove",t.dataTransfer.setDragImage&&!xl)){var r=n("img",null,null,"position: fixed; left: 0; top: 0;");r.src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==",wl&&(r.width=r.height=1,e.display.wrapper.appendChild(r),r._top=r.offsetTop),t.dataTransfer.setDragImage(r,0,0),wl&&r.parentNode.removeChild(r)}}function Zi(e,t){var i=Sr(e,t);if(i){var o=document.createDocumentFragment();Mr(e,i,o),e.display.dragCursor||(e.display.dragCursor=n("div",null,"CodeMirror-cursors CodeMirror-dragcursors"),e.display.lineSpace.insertBefore(e.display.dragCursor,e.display.cursorDiv)),r(e.display.dragCursor,o)}}function Qi(e){e.display.dragCursor&&(e.display.lineSpace.removeChild(e.display.dragCursor),e.display.dragCursor=null)}function Ji(e){if(document.getElementsByClassName)for(var t=document.getElementsByClassName("CodeMirror"),r=0;r<t.length;r++){var n=t[r].CodeMirror;n&&e(n)}}function eo(){Fs||(to(),Fs=!0)}function to(){var e;Ql(window,"resize",function(){null==e&&(e=setTimeout(function(){e=null,Ji(ro)},100))}),Ql(window,"blur",function(){return Ji(Fr)})}function ro(e){var t=e.display;t.lastWrapHeight==t.wrapper.clientHeight&&t.lastWrapWidth==t.wrapper.clientWidth||(t.cachedCharWidth=t.cachedTextHeight=t.cachedPaddingH=null,t.scrollbarsClipped=!1,e.setSize())}function no(e){var t=e.split(/-(?!$)/);e=t[t.length-1];for(var r,n,i,o,l=0;l<t.length-1;l++){var s=t[l];if(/^(cmd|meta|m)$/i.test(s))o=!0;else if(/^a(lt)?$/i.test(s))r=!0;else if(/^(c|ctrl|control)$/i.test(s))n=!0;else{if(!/^s(hift)?$/i.test(s))throw new Error("Unrecognized modifier name: "+s);i=!0}}return r&&(e="Alt-"+e),n&&(e="Ctrl-"+e),o&&(e="Cmd-"+e),i&&(e="Shift-"+e),e}function io(e){var t={};for(var r in e)if(e.hasOwnProperty(r)){var n=e[r];if(/^(name|fallthrough|(de|at)tach)$/.test(r))continue;if("..."==n){delete e[r];continue}for(var i=v(r.split(" "),no),o=0;o<i.length;o++){var l=void 0,s=void 0;o==i.length-1?(s=i.join(" "),l=n):(s=i.slice(0,o+1).join(" "),l="...");var a=t[s];if(a){if(a!=l)throw new Error("Inconsistent bindings for "+s)}else t[s]=l}delete e[r]}for(var u in t)e[u]=t[u];return e}function oo(e,t,r,n){var i=(t=uo(t)).call?t.call(e,n):t[e];if(!1===i)return"nothing";if("..."===i)return"multi";if(null!=i&&r(i))return"handled";if(t.fallthrough){if("[object Array]"!=Object.prototype.toString.call(t.fallthrough))return oo(e,t.fallthrough,r,n);for(var o=0;o<t.fallthrough.length;o++){var l=oo(e,t.fallthrough[o],r,n);if(l)return l}}}function lo(e){var t="string"==typeof e?e:Es[e.keyCode];return"Ctrl"==t||"Alt"==t||"Shift"==t||"Mod"==t}function so(e,t,r){var n=e;return t.altKey&&"Alt"!=n&&(e="Alt-"+e),(Dl?t.metaKey:t.ctrlKey)&&"Ctrl"!=n&&(e="Ctrl-"+e),(Dl?t.ctrlKey:t.metaKey)&&"Cmd"!=n&&(e="Cmd-"+e),!r&&t.shiftKey&&"Shift"!=n&&(e="Shift-"+e),e}function ao(e,t){if(wl&&34==e.keyCode&&e.char)return!1;var r=Es[e.keyCode];return null!=r&&!e.altGraphKey&&so(r,e,t)}function uo(e){return"string"==typeof e?Rs[e]:e}function co(e,t){for(var r=e.doc.sel.ranges,n=[],i=0;i<r.length;i++){for(var o=t(r[i]);n.length&&P(o.from,g(n).to)<=0;){var l=n.pop();if(P(l.from,o.from)<0){o.from=l.from;break}}n.push(o)}hn(e,function(){for(var t=n.length-1;t>=0;t--)Ei(e.doc,"",n[t].from,n[t].to,"+delete");jr(e)})}function fo(e,t,r){var n=L(e.text,t+r,r);return n<0||n>e.text.length?null:n}function ho(e,t,r){var n=fo(e,t.ch,r);return null==n?null:new E(t.line,n,r<0?"after":"before")}function po(e,t,r,n,i){if(e){var o=Se(r,t.doc.direction);if(o){var l,s=i<0?g(o):o[0],a=i<0==(1==s.level)?"after":"before";if(s.level>0){var u=Xt(t,r);l=i<0?r.text.length-1:0;var c=Yt(t,u,l).top;l=k(function(e){return Yt(t,u,e).top==c},i<0==(1==s.level)?s.from:s.to-1,l),"before"==a&&(l=fo(r,l,1))}else l=i<0?s.to:s.from;return new E(n,l,a)}}return new E(n,i<0?r.text.length:0,i<0?"before":"after")}function go(e,t,r,n){var i=Se(t,e.doc.direction);if(!i)return ho(t,r,n);r.ch>=t.text.length?(r.ch=t.text.length,r.sticky="before"):r.ch<=0&&(r.ch=0,r.sticky="after");var o=Ce(i,r.ch,r.sticky),l=i[o];if("ltr"==e.doc.direction&&l.level%2==0&&(n>0?l.to>r.ch:l.from<r.ch))return ho(t,r,n);var s,a=function(e,r){return fo(t,e instanceof E?e.ch:e,r)},u=function(r){return e.options.lineWrapping?(s=s||Xt(e,t),hr(e,t,s,r)):{begin:0,end:t.text.length}},c=u("before"==r.sticky?a(r,-1):r.ch);if("rtl"==e.doc.direction||1==l.level){var f=1==l.level==n<0,h=a(r,f?1:-1);if(null!=h&&(f?h<=l.to&&h<=c.end:h>=l.from&&h>=c.begin)){var d=f?"before":"after";return new E(r.line,h,d)}}var p=function(e,t,n){for(var o=function(e,t){return t?new E(r.line,a(e,1),"before"):new E(r.line,e,"after")};e>=0&&e<i.length;e+=t){var l=i[e],s=t>0==(1!=l.level),u=s?n.begin:a(n.end,-1);if(l.from<=u&&u<l.to)return o(u,s);if(u=s?l.from:a(l.to,-1),n.begin<=u&&u<n.end)return o(u,s)}},g=p(o+n,n,c);if(g)return g;var v=n>0?c.end:a(c.begin,-1);return null==v||n>0&&v==t.text.length||!(g=p(n>0?0:i.length-1,n,u(v)))?null:g}function vo(e,t){var r=M(e.doc,t),n=fe(r);return n!=r&&(t=W(n)),po(!0,e,n,t,1)}function mo(e,t){var r=M(e.doc,t),n=he(r);return n!=r&&(t=W(n)),po(!0,e,r,t,-1)}function yo(e,t){var r=vo(e,t.line),n=M(e.doc,r.line),i=Se(n,e.doc.direction);if(!i||0==i[0].level){var o=Math.max(0,n.text.search(/\S/)),l=t.line==r.line&&t.ch<=o&&t.ch;return E(r.line,l?0:o,r.sticky)}return r}function bo(e,t,r){if("string"==typeof t&&!(t=Bs[t]))return!1;e.display.input.ensurePolled();var n=e.display.shift,i=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),r&&(e.display.shift=!1),i=t(e)!=Bl}finally{e.display.shift=n,e.state.suppressEdits=!1}return i}function wo(e,t,r){for(var n=0;n<e.state.keyMaps.length;n++){var i=oo(t,e.state.keyMaps[n],r,e);if(i)return i}return e.options.extraKeys&&oo(t,e.options.extraKeys,r,e)||oo(t,e.options.keyMap,r,e)}function xo(e,t,r,n){var i=e.state.keySeq;if(i){if(lo(t))return"handled";Gs.set(50,function(){e.state.keySeq==i&&(e.state.keySeq=null,e.display.input.reset())}),t=i+" "+t}var o=wo(e,t,n);return"multi"==o&&(e.state.keySeq=t),"handled"==o&&bt(e,"keyHandled",e,t,r),"handled"!=o&&"multi"!=o||(We(r),Ar(e)),i&&!o&&/\'$/.test(t)?(We(r),!0):!!o}function Co(e,t){var r=ao(t,!0);return!!r&&(t.shiftKey&&!e.state.keySeq?xo(e,"Shift-"+r,t,function(t){return bo(e,t,!0)})||xo(e,r,t,function(t){if("string"==typeof t?/^go[A-Z]/.test(t):t.motion)return bo(e,t)}):xo(e,r,t,function(t){return bo(e,t)}))}function So(e,t,r){return xo(e,"'"+r+"'",t,function(t){return bo(e,t,!0)})}function Lo(e){var t=this;if(t.curOp.focus=l(),!Me(t,e)){gl&&vl<11&&27==e.keyCode&&(e.returnValue=!1);var r=e.keyCode;t.display.shift=16==r||e.shiftKey;var n=Co(t,e);wl&&(Us=n?r:null,!n&&88==r&&!rs&&(Ml?e.metaKey:e.ctrlKey)&&t.replaceSelection("",null,"cut")),18!=r||/\bCodeMirror-crosshair\b/.test(t.display.lineDiv.className)||ko(t)}}function ko(e){function t(e){18!=e.keyCode&&e.altKey||(Fl(r,"CodeMirror-crosshair"),ke(document,"keyup",t),ke(document,"mouseover",t))}var r=e.display.lineDiv;s(r,"CodeMirror-crosshair"),Ql(document,"keyup",t),Ql(document,"mouseover",t)}function To(e){16==e.keyCode&&(this.doc.sel.shift=!1),Me(this,e)}function Mo(e){var t=this;if(!(Ft(t.display,e)||Me(t,e)||e.ctrlKey&&!e.altKey||Ml&&e.metaKey)){var r=e.keyCode,n=e.charCode;if(wl&&r==Us)return Us=null,void We(e);if(!wl||e.which&&!(e.which<10)||!Co(t,e)){var i=String.fromCharCode(null==n?r:n);"\b"!=i&&(So(t,e,i)||t.display.input.onKeyPress(e))}}}function No(e,t){var r=+new Date;return js&&js.compare(r,e,t)?(Ks=js=null,"triple"):Ks&&Ks.compare(r,e,t)?(js=new Vs(r,e,t),Ks=null,"double"):(Ks=new Vs(r,e,t),js=null,"single")}function Oo(e){var t=this,r=t.display;if(!(Me(t,e)||r.activeTouch&&r.input.supportsTouch()))if(r.input.ensurePolled(),r.shift=e.shiftKey,Ft(r,e))ml||(r.scroller.draggable=!1,setTimeout(function(){return r.scroller.draggable=!0},100));else if(!zo(t,e)){var n=Sr(t,e),i=Pe(e),o=n?No(n,i):"single";window.focus(),1==i&&t.state.selectingText&&t.state.selectingText(e),n&&Ao(t,i,n,o,e)||(1==i?n?Do(t,n,o,e):Ee(e)==r.scroller&&We(e):2==i?(n&&di(t.doc,n),setTimeout(function(){return r.input.focus()},20)):3==i&&(Hl?Ro(t,e):Dr(t)))}}function Ao(e,t,r,n,i){var o="Click";return"double"==n?o="Double"+o:"triple"==n&&(o="Triple"+o),o=(1==t?"Left":2==t?"Middle":"Right")+o,xo(e,so(o,i),i,function(t){if("string"==typeof t&&(t=Bs[t]),!t)return!1;var n=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),n=t(e,r)!=Bl}finally{e.state.suppressEdits=!1}return n})}function Wo(e,t,r){var n=e.getOption("configureMouse"),i=n?n(e,t,r):{};if(null==i.unit){var o=Nl?r.shiftKey&&r.metaKey:r.altKey;i.unit=o?"rectangle":"single"==t?"char":"double"==t?"word":"line"}return(null==i.extend||e.doc.extend)&&(i.extend=e.doc.extend||r.shiftKey),null==i.addNew&&(i.addNew=Ml?r.metaKey:r.ctrlKey),null==i.moveOnDrag&&(i.moveOnDrag=!(Ml?r.altKey:r.ctrlKey)),i}function Do(e,t,r,n){gl?setTimeout(u(Wr,e),0):e.curOp.focus=l();var i,o=Wo(e,r,n),s=e.doc.sel;e.options.dragDrop&&Jl&&!e.isReadOnly()&&"single"==r&&(i=s.contains(t))>-1&&(P((i=s.ranges[i]).from(),t)<0||t.xRel>0)&&(P(i.to(),t)>0||t.xRel<0)?Ho(e,n,t,o):Eo(e,n,t,o)}function Ho(e,t,r,n){var i=e.display,o=!1,l=dn(e,function(t){ml&&(i.scroller.draggable=!1),e.state.draggingText=!1,ke(document,"mouseup",l),ke(document,"mousemove",s),ke(i.scroller,"dragstart",a),ke(i.scroller,"drop",l),o||(We(t),n.addNew||di(e.doc,r,null,null,n.extend),ml||gl&&9==vl?setTimeout(function(){document.body.focus(),i.input.focus()},20):i.input.focus())}),s=function(e){o=o||Math.abs(t.clientX-e.clientX)+Math.abs(t.clientY-e.clientY)>=10},a=function(){return o=!0};ml&&(i.scroller.draggable=!0),e.state.draggingText=l,l.copy=!n.moveOnDrag,i.scroller.dragDrop&&i.scroller.dragDrop(),Ql(document,"mouseup",l),Ql(document,"mousemove",s),Ql(i.scroller,"dragstart",a),Ql(i.scroller,"drop",l),Dr(e),setTimeout(function(){return i.input.focus()},20)}function Fo(e,t,r){if("char"==r)return new Ts(t,t);if("word"==r)return e.findWordAt(t);if("line"==r)return new Ts(E(t.line,0),U(e.doc,E(t.line+1,0)));var n=r(e,t);return new Ts(n.from,n.to)}function Eo(e,t,r,n){function i(t){if(0!=P(m,t))if(m=t,"rectangle"==n.unit){for(var i=[],o=e.options.tabSize,l=f(M(u,r.line).text,r.ch,o),s=f(M(u,t.line).text,t.ch,o),a=Math.min(l,s),g=Math.max(l,s),v=Math.min(r.line,t.line),y=Math.min(e.lastLine(),Math.max(r.line,t.line));v<=y;v++){var b=M(u,v).text,w=d(b,a,o);a==g?i.push(new Ts(E(v,w),E(v,w))):b.length>w&&i.push(new Ts(E(v,w),E(v,d(b,g,o))))}i.length||i.push(new Ts(r,r)),bi(u,zn(p.ranges.slice(0,h).concat(i),h),{origin:"*mouse",scroll:!1}),e.scrollIntoView(t)}else{var x,C=c,S=Fo(e,t,n.unit),L=C.anchor;P(S.anchor,L)>0?(x=S.head,L=B(C.from(),S.anchor)):(x=S.anchor,L=R(C.to(),S.head));var k=p.ranges.slice(0);k[h]=Po(e,new Ts(U(u,L),x)),bi(u,zn(k,h),Ul)}}function o(t){var r=++b,s=Sr(e,t,!0,"rectangle"==n.unit);if(s)if(0!=P(s,m)){e.curOp.focus=l(),i(s);var c=Ir(a,u);(s.line>=c.to||s.line<c.from)&&setTimeout(dn(e,function(){b==r&&o(t)}),150)}else{var f=t.clientY<y.top?-20:t.clientY>y.bottom?20:0;f&&setTimeout(dn(e,function(){b==r&&(a.scroller.scrollTop+=f,o(t))}),50)}}function s(t){e.state.selectingText=!1,b=1/0,We(t),a.input.focus(),ke(document,"mousemove",w),ke(document,"mouseup",x),u.history.lastSelOrigin=null}var a=e.display,u=e.doc;We(t);var c,h,p=u.sel,g=p.ranges;if(n.addNew&&!n.extend?(h=u.sel.contains(r),c=h>-1?g[h]:new Ts(r,r)):(c=u.sel.primary(),h=u.sel.primIndex),"rectangle"==n.unit)n.addNew||(c=new Ts(r,r)),r=Sr(e,t,!0,!0),h=-1;else{var v=Fo(e,r,n.unit);c=n.extend?hi(c,v.anchor,v.head,n.extend):v}n.addNew?-1==h?(h=g.length,bi(u,zn(g.concat([c]),h),{scroll:!1,origin:"*mouse"})):g.length>1&&g[h].empty()&&"char"==n.unit&&!n.extend?(bi(u,zn(g.slice(0,h).concat(g.slice(h+1)),0),{scroll:!1,origin:"*mouse"}),p=u.sel):gi(u,h,c,Ul):(h=0,bi(u,new ks([c],0),Ul),p=u.sel);var m=r,y=a.wrapper.getBoundingClientRect(),b=0,w=dn(e,function(e){Pe(e)?o(e):s(e)}),x=dn(e,s);e.state.selectingText=x,Ql(document,"mousemove",w),Ql(document,"mouseup",x)}function Po(e,t){var r=t.anchor,n=t.head,i=M(e.doc,r.line);if(0==P(r,n)&&r.sticky==n.sticky)return t;var o=Se(i);if(!o)return t;var l=Ce(o,r.ch,r.sticky),s=o[l];if(s.from!=r.ch&&s.to!=r.ch)return t;var a=l+(s.from==r.ch==(1!=s.level)?0:1);if(0==a||a==o.length)return t;var u;if(n.line!=r.line)u=(n.line-r.line)*("ltr"==e.doc.direction?1:-1)>0;else{var c=Ce(o,n.ch,n.sticky),f=c-l||(n.ch-r.ch)*(1==s.level?-1:1);u=c==a-1||c==a?f<0:f>0}var h=o[a+(u?-1:0)],d=u==(1==h.level),p=d?h.from:h.to,g=d?"after":"before";return r.ch==p&&r.sticky==g?t:new Ts(new E(r.line,p,g),n)}function Io(e,t,r,n){var i,o;if(t.touches)i=t.touches[0].clientX,o=t.touches[0].clientY;else try{i=t.clientX,o=t.clientY}catch(t){return!1}if(i>=Math.floor(e.display.gutters.getBoundingClientRect().right))return!1;n&&We(t);var l=e.display,s=l.lineDiv.getBoundingClientRect();if(o>s.bottom||!Oe(e,r))return He(t);o-=s.top-l.viewOffset;for(var a=0;a<e.options.gutters.length;++a){var u=l.gutters.childNodes[a];if(u&&u.getBoundingClientRect().right>=i)return Te(e,r,e,D(e.doc,o),e.options.gutters[a],t),He(t)}}function zo(e,t){return Io(e,t,"gutterClick",!0)}function Ro(e,t){Ft(e.display,t)||Bo(e,t)||Me(e,t,"contextmenu")||e.display.input.onContextMenu(t)}function Bo(e,t){return!!Oe(e,"gutterContextMenu")&&Io(e,t,"gutterContextMenu",!1)}function Go(e){e.display.wrapper.className=e.display.wrapper.className.replace(/\s*cm-s-\S+/g,"")+e.options.theme.replace(/(^|\s)\s*/g," cm-s-"),er(e)}function Uo(e){Hn(e),vn(e),zr(e)}function Vo(e,t,r){if(!t!=!(r&&r!=Xs)){var n=e.display.dragFunctions,i=t?Ql:ke;i(e.display.scroller,"dragstart",n.start),i(e.display.scroller,"dragenter",n.enter),i(e.display.scroller,"dragover",n.over),i(e.display.scroller,"dragleave",n.leave),i(e.display.scroller,"drop",n.drop)}}function Ko(e){e.options.lineWrapping?(s(e.display.wrapper,"CodeMirror-wrap"),e.display.sizer.style.minWidth="",e.display.sizerWidth=null):(Fl(e.display.wrapper,"CodeMirror-wrap"),we(e)),Cr(e),vn(e),er(e),setTimeout(function(){return en(e)},100)}function jo(e,t){var r=this;if(!(this instanceof jo))return new jo(e,t);this.options=t=t?c(t):{},c(Ys,t,!1),Fn(t);var n=t.value;"string"==typeof n&&(n=new Ds(n,t.mode,null,t.lineSeparator,t.direction)),this.doc=n;var i=new jo.inputStyles[t.inputStyle](this),o=this.display=new T(e,n,i);o.wrapper.CodeMirror=this,Hn(this),Go(this),t.lineWrapping&&(this.display.wrapper.className+=" CodeMirror-wrap"),rn(this),this.state={keyMaps:[],overlays:[],modeGen:0,overwrite:!1,delayingBlurEvent:!1,focused:!1,suppressEdits:!1,pasteIncoming:!1,cutIncoming:!1,selectingText:!1,draggingText:!1,highlight:new Pl,keySeq:null,specialChars:null},t.autofocus&&!Tl&&o.input.focus(),gl&&vl<11&&setTimeout(function(){return r.display.input.reset(!0)},20),Xo(this),eo(),nn(this),this.curOp.forceUpdate=!0,qn(this,n),t.autofocus&&!Tl||this.hasFocus()?setTimeout(u(Hr,this),20):Fr(this);for(var l in _s)_s.hasOwnProperty(l)&&_s[l](r,t[l],Xs);Rr(this),t.finishInit&&t.finishInit(this);for(var s=0;s<$s.length;++s)$s[s](r);on(this),ml&&t.lineWrapping&&"optimizelegibility"==getComputedStyle(o.lineDiv).textRendering&&(o.lineDiv.style.textRendering="auto")}function Xo(e){function t(){i.activeTouch&&(o=setTimeout(function(){return i.activeTouch=null},1e3),(l=i.activeTouch).end=+new Date)}function r(e){if(1!=e.touches.length)return!1;var t=e.touches[0];return t.radiusX<=1&&t.radiusY<=1}function n(e,t){if(null==t.left)return!0;var r=t.left-e.left,n=t.top-e.top;return r*r+n*n>400}var i=e.display;Ql(i.scroller,"mousedown",dn(e,Oo)),gl&&vl<11?Ql(i.scroller,"dblclick",dn(e,function(t){if(!Me(e,t)){var r=Sr(e,t);if(r&&!zo(e,t)&&!Ft(e.display,t)){We(t);var n=e.findWordAt(r);di(e.doc,n.anchor,n.head)}}})):Ql(i.scroller,"dblclick",function(t){return Me(e,t)||We(t)}),Hl||Ql(i.scroller,"contextmenu",function(t){return Ro(e,t)});var o,l={end:0};Ql(i.scroller,"touchstart",function(t){if(!Me(e,t)&&!r(t)&&!zo(e,t)){i.input.ensurePolled(),clearTimeout(o);var n=+new Date;i.activeTouch={start:n,moved:!1,prev:n-l.end<=300?l:null},1==t.touches.length&&(i.activeTouch.left=t.touches[0].pageX,i.activeTouch.top=t.touches[0].pageY)}}),Ql(i.scroller,"touchmove",function(){i.activeTouch&&(i.activeTouch.moved=!0)}),Ql(i.scroller,"touchend",function(r){var o=i.activeTouch;if(o&&!Ft(i,r)&&null!=o.left&&!o.moved&&new Date-o.start<300){var l,s=e.coordsChar(i.activeTouch,"page");l=!o.prev||n(o,o.prev)?new Ts(s,s):!o.prev.prev||n(o,o.prev.prev)?e.findWordAt(s):new Ts(E(s.line,0),U(e.doc,E(s.line+1,0))),e.setSelection(l.anchor,l.head),e.focus(),We(r)}t()}),Ql(i.scroller,"touchcancel",t),Ql(i.scroller,"scroll",function(){i.scroller.clientHeight&&(qr(e,i.scroller.scrollTop),Qr(e,i.scroller.scrollLeft,!0),Te(e,"scroll",e))}),Ql(i.scroller,"mousewheel",function(t){return In(e,t)}),Ql(i.scroller,"DOMMouseScroll",function(t){return In(e,t)}),Ql(i.wrapper,"scroll",function(){return i.wrapper.scrollTop=i.wrapper.scrollLeft=0}),i.dragFunctions={enter:function(t){Me(e,t)||Fe(t)},over:function(t){Me(e,t)||(Zi(e,t),Fe(t))},start:function(t){return qi(e,t)},drop:dn(e,$i),leave:function(t){Me(e,t)||Qi(e)}};var s=i.input.getField();Ql(s,"keyup",function(t){return To.call(e,t)}),Ql(s,"keydown",dn(e,Lo)),Ql(s,"keypress",dn(e,Mo)),Ql(s,"focus",function(t){return Hr(e,t)}),Ql(s,"blur",function(t){return Fr(e,t)})}function Yo(e,t,r,n){var i,o=e.doc;null==r&&(r="add"),"smart"==r&&(o.mode.indent?i=$e(e,t).state:r="prev");var l=e.options.tabSize,s=M(o,t),a=f(s.text,null,l);s.stateAfter&&(s.stateAfter=null);var u,c=s.text.match(/^\s*/)[0];if(n||/\S/.test(s.text)){if("smart"==r&&((u=o.mode.indent(i,s.text.slice(c.length),s.text))==Bl||u>150)){if(!n)return;r="prev"}}else u=0,r="not";"prev"==r?u=t>o.first?f(M(o,t-1).text,null,l):0:"add"==r?u=a+e.options.indentUnit:"subtract"==r?u=a-e.options.indentUnit:"number"==typeof r&&(u=a+r),u=Math.max(0,u);var h="",d=0;if(e.options.indentWithTabs)for(var g=Math.floor(u/l);g;--g)d+=l,h+="\t";if(d<u&&(h+=p(u-d)),h!=c)return Ei(o,h,E(t,0),E(t,c.length),"+input"),s.stateAfter=null,!0;for(var v=0;v<o.sel.ranges.length;v++){var m=o.sel.ranges[v];if(m.head.line==t&&m.head.ch<c.length){var y=E(t,c.length);gi(o,v,new Ts(y,y));break}}}function _o(e){qs=e}function $o(e,t,r,n,i){var o=e.doc;e.display.shift=!1,n||(n=o.sel);var l=e.state.pasteIncoming||"paste"==i,s=es(t),a=null;if(l&&n.ranges.length>1)if(qs&&qs.text.join("\n")==t){if(n.ranges.length%qs.text.length==0){a=[];for(var u=0;u<qs.text.length;u++)a.push(o.splitLines(qs.text[u]))}}else s.length==n.ranges.length&&e.options.pasteLinesPerSelection&&(a=v(s,function(e){return[e]}));for(var c,f=n.ranges.length-1;f>=0;f--){var h=n.ranges[f],d=h.from(),p=h.to();h.empty()&&(r&&r>0?d=E(d.line,d.ch-r):e.state.overwrite&&!l?p=E(p.line,Math.min(M(o,p.line).text.length,p.ch+g(s).length)):qs&&qs.lineWise&&qs.text.join("\n")==t&&(d=p=E(d.line,0))),c=e.curOp.updateInput;var m={from:d,to:p,text:a?a[f%a.length]:s,origin:i||(l?"paste":e.state.cutIncoming?"cut":"+input")};Oi(e.doc,m),bt(e,"inputRead",e,m)}t&&!l&&Zo(e,t),jr(e),e.curOp.updateInput=c,e.curOp.typing=!0,e.state.pasteIncoming=e.state.cutIncoming=!1}function qo(e,t){var r=e.clipboardData&&e.clipboardData.getData("Text");if(r)return e.preventDefault(),t.isReadOnly()||t.options.disableInput||hn(t,function(){return $o(t,r,0,null,"paste")}),!0}function Zo(e,t){if(e.options.electricChars&&e.options.smartIndent)for(var r=e.doc.sel,n=r.ranges.length-1;n>=0;n--){var i=r.ranges[n];if(!(i.head.ch>100||n&&r.ranges[n-1].head.line==i.head.line)){var o=e.getModeAt(i.head),l=!1;if(o.electricChars){for(var s=0;s<o.electricChars.length;s++)if(t.indexOf(o.electricChars.charAt(s))>-1){l=Yo(e,i.head.line,"smart");break}}else o.electricInput&&o.electricInput.test(M(e.doc,i.head.line).text.slice(0,i.head.ch))&&(l=Yo(e,i.head.line,"smart"));l&&bt(e,"electricInput",e,i.head.line)}}}function Qo(e){for(var t=[],r=[],n=0;n<e.doc.sel.ranges.length;n++){var i=e.doc.sel.ranges[n].head.line,o={anchor:E(i,0),head:E(i+1,0)};r.push(o),t.push(e.getRange(o.anchor,o.head))}return{text:t,ranges:r}}function Jo(e,t){e.setAttribute("autocorrect","off"),e.setAttribute("autocapitalize","off"),e.setAttribute("spellcheck",!!t)}function el(){var e=n("textarea",null,null,"position: absolute; bottom: -1em; padding: 0; width: 1px; height: 1em; outline: none"),t=n("div",[e],null,"overflow: hidden; position: relative; width: 3px; height: 0px;");return ml?e.style.width="1000px":e.setAttribute("wrap","off"),Ll&&(e.style.border="1px solid black"),Jo(e),t}function tl(e,t,r,n,i){function o(){var n=t.line+r;return!(n<e.first||n>=e.first+e.size)&&(t=new E(n,t.ch,t.sticky),u=M(e,n))}function l(n){var l;if(null==(l=i?go(e.cm,u,t,r):ho(u,t,r))){if(n||!o())return!1;t=po(i,e.cm,u,t.line,r)}else t=l;return!0}var s=t,a=r,u=M(e,t.line);if("char"==n)l();else if("column"==n)l(!0);else if("word"==n||"group"==n)for(var c=null,f="group"==n,h=e.cm&&e.cm.getHelper(t,"wordChars"),d=!0;!(r<0)||l(!d);d=!1){var p=u.text.charAt(t.ch)||"\n",g=x(p,h)?"w":f&&"\n"==p?"n":!f||/\s/.test(p)?null:"p";if(!f||d||g||(g="s"),c&&c!=g){r<0&&(r=1,l(),t.sticky="after");break}if(g&&(c=g),r>0&&!l(!d))break}var v=ki(e,t,s,a,!0);return I(s,v)&&(v.hitSide=!0),v}function rl(e,t,r,n){var i,o=e.doc,l=t.left;if("page"==n){var s=Math.min(e.display.wrapper.clientHeight,window.innerHeight||document.documentElement.clientHeight),a=Math.max(s-.5*mr(e.display),3);i=(r>0?t.bottom:t.top)+r*a}else"line"==n&&(i=r>0?t.bottom+3:t.top-3);for(var u;(u=cr(e,l,i)).outside;){if(r<0?i<=0:i>=o.height){u.hitSide=!0;break}i+=5*r}return u}function nl(e,t){var r=jt(e,t.line);if(!r||r.hidden)return null;var n=M(e.doc,t.line),i=Ut(r,n,t.line),o=Se(n,e.doc.direction),l="left";o&&(l=Ce(o,t.ch)%2?"right":"left");var s=_t(i.map,t.ch,l);return s.offset="right"==s.collapse?s.end:s.start,s}function il(e){for(var t=e;t;t=t.parentNode)if(/CodeMirror-gutter-wrapper/.test(t.className))return!0;return!1}function ol(e,t){return t&&(e.bad=!0),e}function ll(e,t,r,n,i){function o(e){return function(t){return t.id==e}}function l(){c&&(u+=f,c=!1)}function s(e){e&&(l(),u+=e)}function a(t){if(1==t.nodeType){var r=t.getAttribute("cm-text");if(null!=r)return void s(r||t.textContent.replace(/\u200b/g,""));var u,h=t.getAttribute("cm-marker");if(h){var d=e.findMarks(E(n,0),E(i+1,0),o(+h));return void(d.length&&(u=d[0].find(0))&&s(N(e.doc,u.from,u.to).join(f)))}if("false"==t.getAttribute("contenteditable"))return;var p=/^(pre|div|p)$/i.test(t.nodeName);p&&l();for(var g=0;g<t.childNodes.length;g++)a(t.childNodes[g]);p&&(c=!0)}else 3==t.nodeType&&s(t.nodeValue)}for(var u="",c=!1,f=e.doc.lineSeparator();a(t),t!=r;)t=t.nextSibling;return u}function sl(e,t,r){var n;if(t==e.display.lineDiv){if(!(n=e.display.lineDiv.childNodes[r]))return ol(e.clipPos(E(e.display.viewTo-1)),!0);t=null,r=0}else for(n=t;;n=n.parentNode){if(!n||n==e.display.lineDiv)return null;if(n.parentNode&&n.parentNode==e.display.lineDiv)break}for(var i=0;i<e.display.view.length;i++){var o=e.display.view[i];if(o.node==n)return al(o,t,r)}}function al(e,t,r){function n(t,r,n){for(var i=-1;i<(f?f.length:0);i++)for(var o=i<0?c.map:f[i],l=0;l<o.length;l+=3){var s=o[l+2];if(s==t||s==r){var a=W(i<0?e.line:e.rest[i]),u=o[l]+n;return(n<0||s!=t)&&(u=o[l+(n?1:0)]),E(a,u)}}}var i=e.text.firstChild,l=!1;if(!t||!o(i,t))return ol(E(W(e.line),0),!0);if(t==i&&(l=!0,t=i.childNodes[r],r=0,!t)){var s=e.rest?g(e.rest):e.line;return ol(E(W(s),s.text.length),l)}var a=3==t.nodeType?t:null,u=t;for(a||1!=t.childNodes.length||3!=t.firstChild.nodeType||(a=t.firstChild,r&&(r=a.nodeValue.length));u.parentNode!=i;)u=u.parentNode;var c=e.measure,f=c.maps,h=n(a,u,r);if(h)return ol(h,l);for(var d=u.nextSibling,p=a?a.nodeValue.length-r:0;d;d=d.nextSibling){if(h=n(d,d.firstChild,0))return ol(E(h.line,h.ch-p),l);p+=d.textContent.length}for(var v=u.previousSibling,m=r;v;v=v.previousSibling){if(h=n(v,v.firstChild,-1))return ol(E(h.line,h.ch+m),l);m+=v.textContent.length}}var ul=navigator.userAgent,cl=navigator.platform,fl=/gecko\/\d/i.test(ul),hl=/MSIE \d/.test(ul),dl=/Trident\/(?:[7-9]|\d{2,})\..*rv:(\d+)/.exec(ul),pl=/Edge\/(\d+)/.exec(ul),gl=hl||dl||pl,vl=gl&&(hl?document.documentMode||6:+(pl||dl)[1]),ml=!pl&&/WebKit\//.test(ul),yl=ml&&/Qt\/\d+\.\d+/.test(ul),bl=!pl&&/Chrome\//.test(ul),wl=/Opera\//.test(ul),xl=/Apple Computer/.test(navigator.vendor),Cl=/Mac OS X 1\d\D([8-9]|\d\d)\D/.test(ul),Sl=/PhantomJS/.test(ul),Ll=!pl&&/AppleWebKit/.test(ul)&&/Mobile\/\w+/.test(ul),kl=/Android/.test(ul),Tl=Ll||kl||/webOS|BlackBerry|Opera Mini|Opera Mobi|IEMobile/i.test(ul),Ml=Ll||/Mac/.test(cl),Nl=/\bCrOS\b/.test(ul),Ol=/win/i.test(cl),Al=wl&&ul.match(/Version\/(\d*\.\d*)/);Al&&(Al=Number(Al[1])),Al&&Al>=15&&(wl=!1,ml=!0);var Wl,Dl=Ml&&(yl||wl&&(null==Al||Al<12.11)),Hl=fl||gl&&vl>=9,Fl=function(t,r){var n=t.className,i=e(r).exec(n);if(i){var o=n.slice(i.index+i[0].length);t.className=n.slice(0,i.index)+(o?i[1]+o:"")}};Wl=document.createRange?function(e,t,r,n){var i=document.createRange();return i.setEnd(n||e,r),i.setStart(e,t),i}:function(e,t,r){var n=document.body.createTextRange();try{n.moveToElementText(e.parentNode)}catch(e){return n}return n.collapse(!0),n.moveEnd("character",r),n.moveStart("character",t),n};var El=function(e){e.select()};Ll?El=function(e){e.selectionStart=0,e.selectionEnd=e.value.length}:gl&&(El=function(e){try{e.select()}catch(e){}});var Pl=function(){this.id=null};Pl.prototype.set=function(e,t){clearTimeout(this.id),this.id=setTimeout(t,e)};var Il,zl,Rl=30,Bl={toString:function(){return"CodeMirror.Pass"}},Gl={scroll:!1},Ul={origin:"*mouse"},Vl={origin:"+move"},Kl=[""],jl=/[\u00df\u0587\u0590-\u05f4\u0600-\u06ff\u3040-\u309f\u30a0-\u30ff\u3400-\u4db5\u4e00-\u9fcc\uac00-\ud7af]/,Xl=/[\u0300-\u036f\u0483-\u0489\u0591-\u05bd\u05bf\u05c1\u05c2\u05c4\u05c5\u05c7\u0610-\u061a\u064b-\u065e\u0670\u06d6-\u06dc\u06de-\u06e4\u06e7\u06e8\u06ea-\u06ed\u0711\u0730-\u074a\u07a6-\u07b0\u07eb-\u07f3\u0816-\u0819\u081b-\u0823\u0825-\u0827\u0829-\u082d\u0900-\u0902\u093c\u0941-\u0948\u094d\u0951-\u0955\u0962\u0963\u0981\u09bc\u09be\u09c1-\u09c4\u09cd\u09d7\u09e2\u09e3\u0a01\u0a02\u0a3c\u0a41\u0a42\u0a47\u0a48\u0a4b-\u0a4d\u0a51\u0a70\u0a71\u0a75\u0a81\u0a82\u0abc\u0ac1-\u0ac5\u0ac7\u0ac8\u0acd\u0ae2\u0ae3\u0b01\u0b3c\u0b3e\u0b3f\u0b41-\u0b44\u0b4d\u0b56\u0b57\u0b62\u0b63\u0b82\u0bbe\u0bc0\u0bcd\u0bd7\u0c3e-\u0c40\u0c46-\u0c48\u0c4a-\u0c4d\u0c55\u0c56\u0c62\u0c63\u0cbc\u0cbf\u0cc2\u0cc6\u0ccc\u0ccd\u0cd5\u0cd6\u0ce2\u0ce3\u0d3e\u0d41-\u0d44\u0d4d\u0d57\u0d62\u0d63\u0dca\u0dcf\u0dd2-\u0dd4\u0dd6\u0ddf\u0e31\u0e34-\u0e3a\u0e47-\u0e4e\u0eb1\u0eb4-\u0eb9\u0ebb\u0ebc\u0ec8-\u0ecd\u0f18\u0f19\u0f35\u0f37\u0f39\u0f71-\u0f7e\u0f80-\u0f84\u0f86\u0f87\u0f90-\u0f97\u0f99-\u0fbc\u0fc6\u102d-\u1030\u1032-\u1037\u1039\u103a\u103d\u103e\u1058\u1059\u105e-\u1060\u1071-\u1074\u1082\u1085\u1086\u108d\u109d\u135f\u1712-\u1714\u1732-\u1734\u1752\u1753\u1772\u1773\u17b7-\u17bd\u17c6\u17c9-\u17d3\u17dd\u180b-\u180d\u18a9\u1920-\u1922\u1927\u1928\u1932\u1939-\u193b\u1a17\u1a18\u1a56\u1a58-\u1a5e\u1a60\u1a62\u1a65-\u1a6c\u1a73-\u1a7c\u1a7f\u1b00-\u1b03\u1b34\u1b36-\u1b3a\u1b3c\u1b42\u1b6b-\u1b73\u1b80\u1b81\u1ba2-\u1ba5\u1ba8\u1ba9\u1c2c-\u1c33\u1c36\u1c37\u1cd0-\u1cd2\u1cd4-\u1ce0\u1ce2-\u1ce8\u1ced\u1dc0-\u1de6\u1dfd-\u1dff\u200c\u200d\u20d0-\u20f0\u2cef-\u2cf1\u2de0-\u2dff\u302a-\u302f\u3099\u309a\ua66f-\ua672\ua67c\ua67d\ua6f0\ua6f1\ua802\ua806\ua80b\ua825\ua826\ua8c4\ua8e0-\ua8f1\ua926-\ua92d\ua947-\ua951\ua980-\ua982\ua9b3\ua9b6-\ua9b9\ua9bc\uaa29-\uaa2e\uaa31\uaa32\uaa35\uaa36\uaa43\uaa4c\uaab0\uaab2-\uaab4\uaab7\uaab8\uaabe\uaabf\uaac1\uabe5\uabe8\uabed\udc00-\udfff\ufb1e\ufe00-\ufe0f\ufe20-\ufe26\uff9e\uff9f]/,Yl=!1,_l=!1,$l=null,ql=function(){function e(e){return e<=247?r.charAt(e):1424<=e&&e<=1524?"R":1536<=e&&e<=1785?n.charAt(e-1536):1774<=e&&e<=2220?"r":8192<=e&&e<=8203?"w":8204==e?"b":"L"}function t(e,t,r){this.level=e,this.from=t,this.to=r}var r="bbbbbbbbbtstwsbbbbbbbbbbbbbbssstwNN%%%NNNNNN,N,N1111111111NNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNbbbbbbsbbbbbbbbbbbbbbbbbbbbbbbbbb,N%%%%NNNNLNNNNN%%11NLNNN1LNNNNNLLLLLLLLLLLLLLLLLLLLLLLNLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLN",n="nnnnnnNNr%%r,rNNmmmmmmmmmmmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmmmmmmmmmmmmmmmnnnnnnnnnn%nnrrrmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmnNmmmmmmrrmmNmmmmrr1111111111",i=/[\u0590-\u05f4\u0600-\u06ff\u0700-\u08ac]/,o=/[stwN]/,l=/[LRr]/,s=/[Lb1n]/,a=/[1n]/;return function(r,n){var u="ltr"==n?"L":"R";if(0==r.length||"ltr"==n&&!i.test(r))return!1;for(var c=r.length,f=[],h=0;h<c;++h)f.push(e(r.charCodeAt(h)));for(var d=0,p=u;d<c;++d){var v=f[d];"m"==v?f[d]=p:p=v}for(var m=0,y=u;m<c;++m){var b=f[m];"1"==b&&"r"==y?f[m]="n":l.test(b)&&(y=b,"r"==b&&(f[m]="R"))}for(var w=1,x=f[0];w<c-1;++w){var C=f[w];"+"==C&&"1"==x&&"1"==f[w+1]?f[w]="1":","!=C||x!=f[w+1]||"1"!=x&&"n"!=x||(f[w]=x),x=C}for(var S=0;S<c;++S){var L=f[S];if(","==L)f[S]="N";else if("%"==L){var k=void 0;for(k=S+1;k<c&&"%"==f[k];++k);for(var T=S&&"!"==f[S-1]||k<c&&"1"==f[k]?"1":"N",M=S;M<k;++M)f[M]=T;S=k-1}}for(var N=0,O=u;N<c;++N){var A=f[N];"L"==O&&"1"==A?f[N]="L":l.test(A)&&(O=A)}for(var W=0;W<c;++W)if(o.test(f[W])){var D=void 0;for(D=W+1;D<c&&o.test(f[D]);++D);for(var H="L"==(W?f[W-1]:u),F=H==("L"==(D<c?f[D]:u))?H?"L":"R":u,E=W;E<D;++E)f[E]=F;W=D-1}for(var P,I=[],z=0;z<c;)if(s.test(f[z])){var R=z;for(++z;z<c&&s.test(f[z]);++z);I.push(new t(0,R,z))}else{var B=z,G=I.length;for(++z;z<c&&"L"!=f[z];++z);for(var U=B;U<z;)if(a.test(f[U])){B<U&&I.splice(G,0,new t(1,B,U));var V=U;for(++U;U<z&&a.test(f[U]);++U);I.splice(G,0,new t(2,V,U)),B=U}else++U;B<z&&I.splice(G,0,new t(1,B,z))}return 1==I[0].level&&(P=r.match(/^\s+/))&&(I[0].from=P[0].length,I.unshift(new t(0,0,P[0].length))),1==g(I).level&&(P=r.match(/\s+$/))&&(g(I).to-=P[0].length,I.push(new t(0,c-P[0].length,c))),"rtl"==n?I.reverse():I}}(),Zl=[],Ql=function(e,t,r){if(e.addEventListener)e.addEventListener(t,r,!1);else if(e.attachEvent)e.attachEvent("on"+t,r);else{var n=e._handlers||(e._handlers={});n[t]=(n[t]||Zl).concat(r)}},Jl=function(){if(gl&&vl<9)return!1;var e=n("div");return"draggable"in e||"dragDrop"in e}(),es=3!="\n\nb".split(/\n/).length?function(e){for(var t=0,r=[],n=e.length;t<=n;){var i=e.indexOf("\n",t);-1==i&&(i=e.length);var o=e.slice(t,"\r"==e.charAt(i-1)?i-1:i),l=o.indexOf("\r");-1!=l?(r.push(o.slice(0,l)),t+=l+1):(r.push(o),t=i+1)}return r}:function(e){return e.split(/\r\n?|\n/)},ts=window.getSelection?function(e){try{return e.selectionStart!=e.selectionEnd}catch(e){return!1}}:function(e){var t;try{t=e.ownerDocument.selection.createRange()}catch(e){}return!(!t||t.parentElement()!=e)&&0!=t.compareEndPoints("StartToEnd",t)},rs=function(){var e=n("div");return"oncopy"in e||(e.setAttribute("oncopy","return;"),"function"==typeof e.oncopy)}(),ns=null,is={},os={},ls={},ss=function(e,t,r){this.pos=this.start=0,this.string=e,this.tabSize=t||8,this.lastColumnPos=this.lastColumnValue=0,this.lineStart=0,this.lineOracle=r};ss.prototype.eol=function(){return this.pos>=this.string.length},ss.prototype.sol=function(){return this.pos==this.lineStart},ss.prototype.peek=function(){return this.string.charAt(this.pos)||void 0},ss.prototype.next=function(){if(this.pos<this.string.length)return this.string.charAt(this.pos++)},ss.prototype.eat=function(e){var t=this.string.charAt(this.pos);if("string"==typeof e?t==e:t&&(e.test?e.test(t):e(t)))return++this.pos,t},ss.prototype.eatWhile=function(e){for(var t=this.pos;this.eat(e););return this.pos>t},ss.prototype.eatSpace=function(){for(var e=this,t=this.pos;/[\s\u00a0]/.test(this.string.charAt(this.pos));)++e.pos;return this.pos>t},ss.prototype.skipToEnd=function(){this.pos=this.string.length},ss.prototype.skipTo=function(e){var t=this.string.indexOf(e,this.pos);if(t>-1)return this.pos=t,!0},ss.prototype.backUp=function(e){this.pos-=e},ss.prototype.column=function(){return this.lastColumnPos<this.start&&(this.lastColumnValue=f(this.string,this.start,this.tabSize,this.lastColumnPos,this.lastColumnValue),this.lastColumnPos=this.start),this.lastColumnValue-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.indentation=function(){return f(this.string,null,this.tabSize)-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.match=function(e,t,r){if("string"!=typeof e){var n=this.string.slice(this.pos).match(e);return n&&n.index>0?null:(n&&!1!==t&&(this.pos+=n[0].length),n)}var i=function(e){return r?e.toLowerCase():e};if(i(this.string.substr(this.pos,e.length))==i(e))return!1!==t&&(this.pos+=e.length),!0},ss.prototype.current=function(){return this.string.slice(this.start,this.pos)},ss.prototype.hideFirstChars=function(e,t){this.lineStart+=e;try{return t()}finally{this.lineStart-=e}},ss.prototype.lookAhead=function(e){var t=this.lineOracle;return t&&t.lookAhead(e)};var as=function(e,t){this.state=e,this.lookAhead=t},us=function(e,t,r,n){this.state=t,this.doc=e,this.line=r,this.maxLookAhead=n||0};us.prototype.lookAhead=function(e){var t=this.doc.getLine(this.line+e);return null!=t&&e>this.maxLookAhead&&(this.maxLookAhead=e),t},us.prototype.nextLine=function(){this.line++,this.maxLookAhead>0&&this.maxLookAhead--},us.fromSaved=function(e,t,r){return t instanceof as?new us(e,Ke(e.mode,t.state),r,t.lookAhead):new us(e,Ke(e.mode,t),r)},us.prototype.save=function(e){var t=!1!==e?Ke(this.doc.mode,this.state):this.state;return this.maxLookAhead>0?new as(t,this.maxLookAhead):t};var cs=function(e,t,r){this.start=e.start,this.end=e.pos,this.string=e.current(),this.type=t||null,this.state=r},fs=function(e,t,r){this.text=e,ne(this,t),this.height=r?r(this):1};fs.prototype.lineNo=function(){return W(this)},Ae(fs);var hs,ds={},ps={},gs=null,vs=null,ms={left:0,right:0,top:0,bottom:0},ys=function(e,t,r){this.cm=r;var i=this.vert=n("div",[n("div",null,null,"min-width: 1px")],"CodeMirror-vscrollbar"),o=this.horiz=n("div",[n("div",null,null,"height: 100%; min-height: 1px")],"CodeMirror-hscrollbar");e(i),e(o),Ql(i,"scroll",function(){i.clientHeight&&t(i.scrollTop,"vertical")}),Ql(o,"scroll",function(){o.clientWidth&&t(o.scrollLeft,"horizontal")}),this.checkedZeroWidth=!1,gl&&vl<8&&(this.horiz.style.minHeight=this.vert.style.minWidth="18px")};ys.prototype.update=function(e){var t=e.scrollWidth>e.clientWidth+1,r=e.scrollHeight>e.clientHeight+1,n=e.nativeBarWidth;if(r){this.vert.style.display="block",this.vert.style.bottom=t?n+"px":"0";var i=e.viewHeight-(t?n:0);this.vert.firstChild.style.height=Math.max(0,e.scrollHeight-e.clientHeight+i)+"px"}else this.vert.style.display="",this.vert.firstChild.style.height="0";if(t){this.horiz.style.display="block",this.horiz.style.right=r?n+"px":"0",this.horiz.style.left=e.barLeft+"px";var o=e.viewWidth-e.barLeft-(r?n:0);this.horiz.firstChild.style.width=Math.max(0,e.scrollWidth-e.clientWidth+o)+"px"}else this.horiz.style.display="",this.horiz.firstChild.style.width="0";return!this.checkedZeroWidth&&e.clientHeight>0&&(0==n&&this.zeroWidthHack(),this.checkedZeroWidth=!0),{right:r?n:0,bottom:t?n:0}},ys.prototype.setScrollLeft=function(e){this.horiz.scrollLeft!=e&&(this.horiz.scrollLeft=e),this.disableHoriz&&this.enableZeroWidthBar(this.horiz,this.disableHoriz,"horiz")},ys.prototype.setScrollTop=function(e){this.vert.scrollTop!=e&&(this.vert.scrollTop=e),this.disableVert&&this.enableZeroWidthBar(this.vert,this.disableVert,"vert")},ys.prototype.zeroWidthHack=function(){var e=Ml&&!Cl?"12px":"18px";this.horiz.style.height=this.vert.style.width=e,this.horiz.style.pointerEvents=this.vert.style.pointerEvents="none",this.disableHoriz=new Pl,this.disableVert=new Pl},ys.prototype.enableZeroWidthBar=function(e,t,r){function n(){var i=e.getBoundingClientRect();("vert"==r?document.elementFromPoint(i.right-1,(i.top+i.bottom)/2):document.elementFromPoint((i.right+i.left)/2,i.bottom-1))!=e?e.style.pointerEvents="none":t.set(1e3,n)}e.style.pointerEvents="auto",t.set(1e3,n)},ys.prototype.clear=function(){var e=this.horiz.parentNode;e.removeChild(this.horiz),e.removeChild(this.vert)};var bs=function(){};bs.prototype.update=function(){return{bottom:0,right:0}},bs.prototype.setScrollLeft=function(){},bs.prototype.setScrollTop=function(){},bs.prototype.clear=function(){};var ws={native:ys,null:bs},xs=0,Cs=function(e,t,r){var n=e.display;this.viewport=t,this.visible=Ir(n,e.doc,t),this.editorIsHidden=!n.wrapper.offsetWidth,this.wrapperHeight=n.wrapper.clientHeight,this.wrapperWidth=n.wrapper.clientWidth,this.oldDisplayWidth=Rt(e),this.force=r,this.dims=br(e),this.events=[]};Cs.prototype.signal=function(e,t){Oe(e,t)&&this.events.push(arguments)},Cs.prototype.finish=function(){for(var e=this,t=0;t<this.events.length;t++)Te.apply(null,e.events[t])};var Ss=0,Ls=null;gl?Ls=-.53:fl?Ls=15:bl?Ls=-.7:xl&&(Ls=-1/3);var ks=function(e,t){this.ranges=e,this.primIndex=t};ks.prototype.primary=function(){return this.ranges[this.primIndex]},ks.prototype.equals=function(e){var t=this;if(e==this)return!0;if(e.primIndex!=this.primIndex||e.ranges.length!=this.ranges.length)return!1;for(var r=0;r<this.ranges.length;r++){var n=t.ranges[r],i=e.ranges[r];if(!I(n.anchor,i.anchor)||!I(n.head,i.head))return!1}return!0},ks.prototype.deepCopy=function(){for(var e=this,t=[],r=0;r<this.ranges.length;r++)t[r]=new Ts(z(e.ranges[r].anchor),z(e.ranges[r].head));return new ks(t,this.primIndex)},ks.prototype.somethingSelected=function(){for(var e=this,t=0;t<this.ranges.length;t++)if(!e.ranges[t].empty())return!0;return!1},ks.prototype.contains=function(e,t){var r=this;t||(t=e);for(var n=0;n<this.ranges.length;n++){var i=r.ranges[n];if(P(t,i.from())>=0&&P(e,i.to())<=0)return n}return-1};var Ts=function(e,t){this.anchor=e,this.head=t};Ts.prototype.from=function(){return B(this.anchor,this.head)},Ts.prototype.to=function(){return R(this.anchor,this.head)},Ts.prototype.empty=function(){return this.head.line==this.anchor.line&&this.head.ch==this.anchor.ch},Bi.prototype={chunkSize:function(){return this.lines.length},removeInner:function(e,t){for(var r=this,n=e,i=e+t;n<i;++n){var o=r.lines[n];r.height-=o.height,ot(o),bt(o,"delete")}this.lines.splice(e,t)},collapse:function(e){e.push.apply(e,this.lines)},insertInner:function(e,t,r){var n=this;this.height+=r,this.lines=this.lines.slice(0,e).concat(t).concat(this.lines.slice(e));for(var i=0;i<t.length;++i)t[i].parent=n},iterN:function(e,t,r){for(var n=this,i=e+t;e<i;++e)if(r(n.lines[e]))return!0}},Gi.prototype={chunkSize:function(){return this.size},removeInner:function(e,t){var r=this;this.size-=t;for(var n=0;n<this.children.length;++n){var i=r.children[n],o=i.chunkSize();if(e<o){var l=Math.min(t,o-e),s=i.height;if(i.removeInner(e,l),r.height-=s-i.height,o==l&&(r.children.splice(n--,1),i.parent=null),0==(t-=l))break;e=0}else e-=o}if(this.size-t<25&&(this.children.length>1||!(this.children[0]instanceof Bi))){var a=[];this.collapse(a),this.children=[new Bi(a)],this.children[0].parent=this}},collapse:function(e){for(var t=this,r=0;r<this.children.length;++r)t.children[r].collapse(e)},insertInner:function(e,t,r){var n=this;this.size+=t.length,this.height+=r;for(var i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<=l){if(o.insertInner(e,t,r),o.lines&&o.lines.length>50){for(var s=o.lines.length%25+25,a=s;a<o.lines.length;){var u=new Bi(o.lines.slice(a,a+=25));o.height-=u.height,n.children.splice(++i,0,u),u.parent=n}o.lines=o.lines.slice(0,s),n.maybeSpill()}break}e-=l}},maybeSpill:function(){if(!(this.children.length<=10)){var e=this;do{var t=new Gi(e.children.splice(e.children.length-5,5));if(e.parent){e.size-=t.size,e.height-=t.height;var r=h(e.parent.children,e);e.parent.children.splice(r+1,0,t)}else{var n=new Gi(e.children);n.parent=e,e.children=[n,t],e=n}t.parent=e.parent}while(e.children.length>10);e.parent.maybeSpill()}},iterN:function(e,t,r){for(var n=this,i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<l){var s=Math.min(t,l-e);if(o.iterN(e,s,r))return!0;if(0==(t-=s))break;e=0}else e-=l}}};var Ms=function(e,t,r){var n=this;if(r)for(var i in r)r.hasOwnProperty(i)&&(n[i]=r[i]);this.doc=e,this.node=t};Ms.prototype.clear=function(){var e=this,t=this.doc.cm,r=this.line.widgets,n=this.line,i=W(n);if(null!=i&&r){for(var o=0;o<r.length;++o)r[o]==e&&r.splice(o--,1);r.length||(n.widgets=null);var l=Ht(this);A(n,Math.max(0,n.height-l)),t&&(hn(t,function(){Ui(t,n,-l),mn(t,i,"widget")}),bt(t,"lineWidgetCleared",t,this,i))}},Ms.prototype.changed=function(){var e=this,t=this.height,r=this.doc.cm,n=this.line;this.height=null;var i=Ht(this)-t;i&&(A(n,n.height+i),r&&hn(r,function(){r.curOp.forceUpdate=!0,Ui(r,n,i),bt(r,"lineWidgetChanged",r,e,W(n))}))},Ae(Ms);var Ns=0,Os=function(e,t){this.lines=[],this.type=t,this.doc=e,this.id=++Ns};Os.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){var t=this.doc.cm,r=t&&!t.curOp;if(r&&nn(t),Oe(this,"clear")){var n=this.find();n&&bt(this,"clear",n.from,n.to)}for(var i=null,o=null,l=0;l<this.lines.length;++l){var s=e.lines[l],a=_(s.markedSpans,e);t&&!e.collapsed?mn(t,W(s),"text"):t&&(null!=a.to&&(o=W(s)),null!=a.from&&(i=W(s))),s.markedSpans=$(s.markedSpans,a),null==a.from&&e.collapsed&&!ve(e.doc,s)&&t&&A(s,mr(t.display))}if(t&&this.collapsed&&!t.options.lineWrapping)for(var u=0;u<this.lines.length;++u){var c=fe(e.lines[u]),f=be(c);f>t.display.maxLineLength&&(t.display.maxLine=c,t.display.maxLineLength=f,t.display.maxLineChanged=!0)}null!=i&&t&&this.collapsed&&vn(t,i,o+1),this.lines.length=0,this.explicitlyCleared=!0,this.atomic&&this.doc.cantEdit&&(this.doc.cantEdit=!1,t&&Ci(t.doc)),t&&bt(t,"markerCleared",t,this,i,o),r&&on(t),this.parent&&this.parent.clear()}},Os.prototype.find=function(e,t){var r=this;null==e&&"bookmark"==this.type&&(e=1);for(var n,i,o=0;o<this.lines.length;++o){var l=r.lines[o],s=_(l.markedSpans,r);if(null!=s.from&&(n=E(t?l:W(l),s.from),-1==e))return n;if(null!=s.to&&(i=E(t?l:W(l),s.to),1==e))return i}return n&&{from:n,to:i}},Os.prototype.changed=function(){var e=this,t=this.find(-1,!0),r=this,n=this.doc.cm;t&&n&&hn(n,function(){var i=t.line,o=W(t.line),l=jt(n,o);if(l&&(Qt(l),n.curOp.selectionChanged=n.curOp.forceUpdate=!0),n.curOp.updateMaxLine=!0,!ve(r.doc,i)&&null!=r.height){var s=r.height;r.height=null;var a=Ht(r)-s;a&&A(i,i.height+a)}bt(n,"markerChanged",n,e)})},Os.prototype.attachLine=function(e){if(!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;t.maybeHiddenMarkers&&-1!=h(t.maybeHiddenMarkers,this)||(t.maybeUnhiddenMarkers||(t.maybeUnhiddenMarkers=[])).push(this)}this.lines.push(e)},Os.prototype.detachLine=function(e){if(this.lines.splice(h(this.lines,e),1),!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;(t.maybeHiddenMarkers||(t.maybeHiddenMarkers=[])).push(this)}},Ae(Os);var As=function(e,t){var r=this;this.markers=e,this.primary=t;for(var n=0;n<e.length;++n)e[n].parent=r};As.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){this.explicitlyCleared=!0;for(var t=0;t<this.markers.length;++t)e.markers[t].clear();bt(this,"clear")}},As.prototype.find=function(e,t){return this.primary.find(e,t)},Ae(As);var Ws=0,Ds=function(e,t,r,n,i){if(!(this instanceof Ds))return new Ds(e,t,r,n,i);null==r&&(r=0),Gi.call(this,[new Bi([new fs("",null)])]),this.first=r,this.scrollTop=this.scrollLeft=0,this.cantEdit=!1,this.cleanGeneration=1,this.modeFrontier=this.highlightFrontier=r;var o=E(r,0);this.sel=Rn(o),this.history=new Jn(null),this.id=++Ws,this.modeOption=t,this.lineSep=n,this.direction="rtl"==i?"rtl":"ltr",this.extend=!1,"string"==typeof e&&(e=this.splitLines(e)),_n(this,{from:o,to:o,text:e}),bi(this,Rn(o),Gl)};Ds.prototype=b(Gi.prototype,{constructor:Ds,iter:function(e,t,r){r?this.iterN(e-this.first,t-e,r):this.iterN(this.first,this.first+this.size,e)},insert:function(e,t){for(var r=0,n=0;n<t.length;++n)r+=t[n].height;this.insertInner(e-this.first,t,r)},remove:function(e,t){this.removeInner(e-this.first,t)},getValue:function(e){var t=O(this,this.first,this.first+this.size);return!1===e?t:t.join(e||this.lineSeparator())},setValue:gn(function(e){var t=E(this.first,0),r=this.first+this.size-1;Oi(this,{from:t,to:E(r,M(this,r).text.length),text:this.splitLines(e),origin:"setValue",full:!0},!0),this.cm&&Xr(this.cm,0,0),bi(this,Rn(t),Gl)}),replaceRange:function(e,t,r,n){Ei(this,e,t=U(this,t),r=r?U(this,r):t,n)},getRange:function(e,t,r){var n=N(this,U(this,e),U(this,t));return!1===r?n:n.join(r||this.lineSeparator())},getLine:function(e){var t=this.getLineHandle(e);return t&&t.text},getLineHandle:function(e){if(H(this,e))return M(this,e)},getLineNumber:function(e){return W(e)},getLineHandleVisualStart:function(e){return"number"==typeof e&&(e=M(this,e)),fe(e)},lineCount:function(){return this.size},firstLine:function(){return this.first},lastLine:function(){return this.first+this.size-1},clipPos:function(e){return U(this,e)},getCursor:function(e){var t=this.sel.primary();return null==e||"head"==e?t.head:"anchor"==e?t.anchor:"end"==e||"to"==e||!1===e?t.to():t.from()},listSelections:function(){return this.sel.ranges},somethingSelected:function(){return this.sel.somethingSelected()},setCursor:gn(function(e,t,r){vi(this,U(this,"number"==typeof e?E(e,t||0):e),null,r)}),setSelection:gn(function(e,t,r){vi(this,U(this,e),U(this,t||e),r)}),extendSelection:gn(function(e,t,r){di(this,U(this,e),t&&U(this,t),r)}),extendSelections:gn(function(e,t){pi(this,K(this,e),t)}),extendSelectionsBy:gn(function(e,t){pi(this,K(this,v(this.sel.ranges,e)),t)}),setSelections:gn(function(e,t,r){var n=this;if(e.length){for(var i=[],o=0;o<e.length;o++)i[o]=new Ts(U(n,e[o].anchor),U(n,e[o].head));null==t&&(t=Math.min(e.length-1,this.sel.primIndex)),bi(this,zn(i,t),r)}}),addSelection:gn(function(e,t,r){var n=this.sel.ranges.slice(0);n.push(new Ts(U(this,e),U(this,t||e))),bi(this,zn(n,n.length-1),r)}),getSelection:function(e){for(var t,r=this,n=this.sel.ranges,i=0;i<n.length;i++){var o=N(r,n[i].from(),n[i].to());t=t?t.concat(o):o}return!1===e?t:t.join(e||this.lineSeparator())},getSelections:function(e){for(var t=this,r=[],n=this.sel.ranges,i=0;i<n.length;i++){var o=N(t,n[i].from(),n[i].to());!1!==e&&(o=o.join(e||t.lineSeparator())),r[i]=o}return r},replaceSelection:function(e,t,r){for(var n=[],i=0;i<this.sel.ranges.length;i++)n[i]=e;this.replaceSelections(n,t,r||"+input")},replaceSelections:gn(function(e,t,r){for(var n=this,i=[],o=this.sel,l=0;l<o.ranges.length;l++){var s=o.ranges[l];i[l]={from:s.from(),to:s.to(),text:n.splitLines(e[l]),origin:r}}for(var a=t&&"end"!=t&&Kn(this,i,t),u=i.length-1;u>=0;u--)Oi(n,i[u]);a?yi(this,a):this.cm&&jr(this.cm)}),undo:gn(function(){Wi(this,"undo")}),redo:gn(function(){Wi(this,"redo")}),undoSelection:gn(function(){Wi(this,"undo",!0)}),redoSelection:gn(function(){Wi(this,"redo",!0)}),setExtending:function(e){this.extend=e},getExtending:function(){return this.extend},historySize:function(){for(var e=this.history,t=0,r=0,n=0;n<e.done.length;n++)e.done[n].ranges||++t;for(var i=0;i<e.undone.length;i++)e.undone[i].ranges||++r;return{undo:t,redo:r}},clearHistory:function(){this.history=new Jn(this.history.maxGeneration)},markClean:function(){this.cleanGeneration=this.changeGeneration(!0)},changeGeneration:function(e){return e&&(this.history.lastOp=this.history.lastSelOp=this.history.lastOrigin=null),this.history.generation},isClean:function(e){return this.history.generation==(e||this.cleanGeneration)},getHistory:function(){return{done:fi(this.history.done),undone:fi(this.history.undone)}},setHistory:function(e){var t=this.history=new Jn(this.history.maxGeneration);t.done=fi(e.done.slice(0),null,!0),t.undone=fi(e.undone.slice(0),null,!0)},setGutterMarker:gn(function(e,t,r){return Ri(this,e,"gutter",function(e){var n=e.gutterMarkers||(e.gutterMarkers={});return n[t]=r,!r&&C(n)&&(e.gutterMarkers=null),!0})}),clearGutter:gn(function(e){var t=this;this.iter(function(r){r.gutterMarkers&&r.gutterMarkers[e]&&Ri(t,r,"gutter",function(){return r.gutterMarkers[e]=null,C(r.gutterMarkers)&&(r.gutterMarkers=null),!0})})}),lineInfo:function(e){var t;if("number"==typeof e){if(!H(this,e))return null;if(t=e,!(e=M(this,e)))return null}else if(null==(t=W(e)))return null;return{line:t,handle:e,text:e.text,gutterMarkers:e.gutterMarkers,textClass:e.textClass,bgClass:e.bgClass,wrapClass:e.wrapClass,widgets:e.widgets}},addLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass";if(t[i]){if(e(n).test(t[i]))return!1;t[i]+=" "+n}else t[i]=n;return!0})}),removeLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass",o=t[i];if(!o)return!1;if(null==n)t[i]=null;else{var l=o.match(e(n));if(!l)return!1;var s=l.index+l[0].length;t[i]=o.slice(0,l.index)+(l.index&&s!=o.length?" ":"")+o.slice(s)||null}return!0})}),addLineWidget:gn(function(e,t,r){return Vi(this,e,t,r)}),removeLineWidget:function(e){e.clear()},markText:function(e,t,r){return Ki(this,U(this,e),U(this,t),r,r&&r.type||"range")},setBookmark:function(e,t){var r={replacedWith:t&&(null==t.nodeType?t.widget:t),insertLeft:t&&t.insertLeft,clearWhenEmpty:!1,shared:t&&t.shared,handleMouseEvents:t&&t.handleMouseEvents};return e=U(this,e),Ki(this,e,e,r,"bookmark")},findMarksAt:function(e){var t=[],r=M(this,(e=U(this,e)).line).markedSpans;if(r)for(var n=0;n<r.length;++n){var i=r[n];(null==i.from||i.from<=e.ch)&&(null==i.to||i.to>=e.ch)&&t.push(i.marker.parent||i.marker)}return t},findMarks:function(e,t,r){e=U(this,e),t=U(this,t);var n=[],i=e.line;return this.iter(e.line,t.line+1,function(o){var l=o.markedSpans;if(l)for(var s=0;s<l.length;s++){var a=l[s];null!=a.to&&i==e.line&&e.ch>=a.to||null==a.from&&i!=e.line||null!=a.from&&i==t.line&&a.from>=t.ch||r&&!r(a.marker)||n.push(a.marker.parent||a.marker)}++i}),n},getAllMarks:function(){var e=[];return this.iter(function(t){var r=t.markedSpans;if(r)for(var n=0;n<r.length;++n)null!=r[n].from&&e.push(r[n].marker)}),e},posFromIndex:function(e){var t,r=this.first,n=this.lineSeparator().length;return this.iter(function(i){var o=i.text.length+n;if(o>e)return t=e,!0;e-=o,++r}),U(this,E(r,t))},indexFromPos:function(e){var t=(e=U(this,e)).ch;if(e.line<this.first||e.ch<0)return 0;var r=this.lineSeparator().length;return this.iter(this.first,e.line,function(e){t+=e.text.length+r}),t},copy:function(e){var t=new Ds(O(this,this.first,this.first+this.size),this.modeOption,this.first,this.lineSep,this.direction);return t.scrollTop=this.scrollTop,t.scrollLeft=this.scrollLeft,t.sel=this.sel,t.extend=!1,e&&(t.history.undoDepth=this.history.undoDepth,t.setHistory(this.getHistory())),t},linkedDoc:function(e){e||(e={});var t=this.first,r=this.first+this.size;null!=e.from&&e.from>t&&(t=e.from),null!=e.to&&e.to<r&&(r=e.to);var n=new Ds(O(this,t,r),e.mode||this.modeOption,t,this.lineSep,this.direction);return e.sharedHist&&(n.history=this.history),(this.linked||(this.linked=[])).push({doc:n,sharedHist:e.sharedHist}),n.linked=[{doc:this,isParent:!0,sharedHist:e.sharedHist}],Yi(n,Xi(this)),n},unlinkDoc:function(e){var t=this;if(e instanceof jo&&(e=e.doc),this.linked)for(var r=0;r<this.linked.length;++r)if(t.linked[r].doc==e){t.linked.splice(r,1),e.unlinkDoc(t),_i(Xi(t));break}if(e.history==this.history){var n=[e.id];$n(e,function(e){return n.push(e.id)},!0),e.history=new Jn(null),e.history.done=fi(this.history.done,n),e.history.undone=fi(this.history.undone,n)}},iterLinkedDocs:function(e){$n(this,e)},getMode:function(){return this.mode},getEditor:function(){return this.cm},splitLines:function(e){return this.lineSep?e.split(this.lineSep):es(e)},lineSeparator:function(){return this.lineSep||"\n"},setDirection:gn(function(e){"rtl"!=e&&(e="ltr"),e!=this.direction&&(this.direction=e,this.iter(function(e){return e.order=null}),this.cm&&Qn(this.cm))})}),Ds.prototype.eachLine=Ds.prototype.iter;for(var Hs=0,Fs=!1,Es={3:"Enter",8:"Backspace",9:"Tab",13:"Enter",16:"Shift",17:"Ctrl",18:"Alt",19:"Pause",20:"CapsLock",27:"Esc",32:"Space",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"Left",38:"Up",39:"Right",40:"Down",44:"PrintScrn",45:"Insert",46:"Delete",59:";",61:"=",91:"Mod",92:"Mod",93:"Mod",106:"*",107:"=",109:"-",110:".",111:"/",127:"Delete",173:"-",186:";",187:"=",188:",",189:"-",190:".",191:"/",192:"`",219:"[",220:"\\",221:"]",222:"'",63232:"Up",63233:"Down",63234:"Left",63235:"Right",63272:"Delete",63273:"Home",63275:"End",63276:"PageUp",63277:"PageDown",63302:"Insert"},Ps=0;Ps<10;Ps++)Es[Ps+48]=Es[Ps+96]=String(Ps);for(var Is=65;Is<=90;Is++)Es[Is]=String.fromCharCode(Is);for(var zs=1;zs<=12;zs++)Es[zs+111]=Es[zs+63235]="F"+zs;var Rs={};Rs.basic={Left:"goCharLeft",Right:"goCharRight",Up:"goLineUp",Down:"goLineDown",End:"goLineEnd",Home:"goLineStartSmart",PageUp:"goPageUp",PageDown:"goPageDown",Delete:"delCharAfter",Backspace:"delCharBefore","Shift-Backspace":"delCharBefore",Tab:"defaultTab","Shift-Tab":"indentAuto",Enter:"newlineAndIndent",Insert:"toggleOverwrite",Esc:"singleSelection"},Rs.pcDefault={"Ctrl-A":"selectAll","Ctrl-D":"deleteLine","Ctrl-Z":"undo","Shift-Ctrl-Z":"redo","Ctrl-Y":"redo","Ctrl-Home":"goDocStart","Ctrl-End":"goDocEnd","Ctrl-Up":"goLineUp","Ctrl-Down":"goLineDown","Ctrl-Left":"goGroupLeft","Ctrl-Right":"goGroupRight","Alt-Left":"goLineStart","Alt-Right":"goLineEnd","Ctrl-Backspace":"delGroupBefore","Ctrl-Delete":"delGroupAfter","Ctrl-S":"save","Ctrl-F":"find","Ctrl-G":"findNext","Shift-Ctrl-G":"findPrev","Shift-Ctrl-F":"replace","Shift-Ctrl-R":"replaceAll","Ctrl-[":"indentLess","Ctrl-]":"indentMore","Ctrl-U":"undoSelection","Shift-Ctrl-U":"redoSelection","Alt-U":"redoSelection",fallthrough:"basic"},Rs.emacsy={"Ctrl-F":"goCharRight","Ctrl-B":"goCharLeft","Ctrl-P":"goLineUp","Ctrl-N":"goLineDown","Alt-F":"goWordRight","Alt-B":"goWordLeft","Ctrl-A":"goLineStart","Ctrl-E":"goLineEnd","Ctrl-V":"goPageDown","Shift-Ctrl-V":"goPageUp","Ctrl-D":"delCharAfter","Ctrl-H":"delCharBefore","Alt-D":"delWordAfter","Alt-Backspace":"delWordBefore","Ctrl-K":"killLine","Ctrl-T":"transposeChars","Ctrl-O":"openLine"},Rs.macDefault={"Cmd-A":"selectAll","Cmd-D":"deleteLine","Cmd-Z":"undo","Shift-Cmd-Z":"redo","Cmd-Y":"redo","Cmd-Home":"goDocStart","Cmd-Up":"goDocStart","Cmd-End":"goDocEnd","Cmd-Down":"goDocEnd","Alt-Left":"goGroupLeft","Alt-Right":"goGroupRight","Cmd-Left":"goLineLeft","Cmd-Right":"goLineRight","Alt-Backspace":"delGroupBefore","Ctrl-Alt-Backspace":"delGroupAfter","Alt-Delete":"delGroupAfter","Cmd-S":"save","Cmd-F":"find","Cmd-G":"findNext","Shift-Cmd-G":"findPrev","Cmd-Alt-F":"replace","Shift-Cmd-Alt-F":"replaceAll","Cmd-[":"indentLess","Cmd-]":"indentMore","Cmd-Backspace":"delWrappedLineLeft","Cmd-Delete":"delWrappedLineRight","Cmd-U":"undoSelection","Shift-Cmd-U":"redoSelection","Ctrl-Up":"goDocStart","Ctrl-Down":"goDocEnd",fallthrough:["basic","emacsy"]},Rs.default=Ml?Rs.macDefault:Rs.pcDefault;var Bs={selectAll:Mi,singleSelection:function(e){return e.setSelection(e.getCursor("anchor"),e.getCursor("head"),Gl)},killLine:function(e){return co(e,function(t){if(t.empty()){var r=M(e.doc,t.head.line).text.length;return t.head.ch==r&&t.head.line<e.lastLine()?{from:t.head,to:E(t.head.line+1,0)}:{from:t.head,to:E(t.head.line,r)}}return{from:t.from(),to:t.to()}})},deleteLine:function(e){return co(e,function(t){return{from:E(t.from().line,0),to:U(e.doc,E(t.to().line+1,0))}})},delLineLeft:function(e){return co(e,function(e){return{from:E(e.from().line,0),to:e.from()}})},delWrappedLineLeft:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5;return{from:e.coordsChar({left:0,top:r},"div"),to:t.from()}})},delWrappedLineRight:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5,n=e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div");return{from:t.from(),to:n}})},undo:function(e){return e.undo()},redo:function(e){return e.redo()},undoSelection:function(e){return e.undoSelection()},redoSelection:function(e){return e.redoSelection()},goDocStart:function(e){return e.extendSelection(E(e.firstLine(),0))},goDocEnd:function(e){return e.extendSelection(E(e.lastLine()))},goLineStart:function(e){return e.extendSelectionsBy(function(t){return vo(e,t.head.line)},{origin:"+move",bias:1})},goLineStartSmart:function(e){return e.extendSelectionsBy(function(t){return yo(e,t.head)},{origin:"+move",bias:1})},goLineEnd:function(e){return e.extendSelectionsBy(function(t){return mo(e,t.head.line)},{origin:"+move",bias:-1})},goLineRight:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div")},Vl)},goLineLeft:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:0,top:r},"div")},Vl)},goLineLeftSmart:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5,n=e.coordsChar({left:0,top:r},"div");return n.ch<e.getLine(n.line).search(/\S/)?yo(e,t.head):n},Vl)},goLineUp:function(e){return e.moveV(-1,"line")},goLineDown:function(e){return e.moveV(1,"line")},goPageUp:function(e){return e.moveV(-1,"page")},goPageDown:function(e){return e.moveV(1,"page")},goCharLeft:function(e){return e.moveH(-1,"char")},goCharRight:function(e){return e.moveH(1,"char")},goColumnLeft:function(e){return e.moveH(-1,"column")},goColumnRight:function(e){return e.moveH(1,"column")},goWordLeft:function(e){return e.moveH(-1,"word")},goGroupRight:function(e){return e.moveH(1,"group")},goGroupLeft:function(e){return e.moveH(-1,"group")},goWordRight:function(e){return e.moveH(1,"word")},delCharBefore:function(e){return e.deleteH(-1,"char")},delCharAfter:function(e){return e.deleteH(1,"char")},delWordBefore:function(e){return e.deleteH(-1,"word")},delWordAfter:function(e){return e.deleteH(1,"word")},delGroupBefore:function(e){return e.deleteH(-1,"group")},delGroupAfter:function(e){return e.deleteH(1,"group")},indentAuto:function(e){return e.indentSelection("smart")},indentMore:function(e){return e.indentSelection("add")},indentLess:function(e){return e.indentSelection("subtract")},insertTab:function(e){return e.replaceSelection("\t")},insertSoftTab:function(e){for(var t=[],r=e.listSelections(),n=e.options.tabSize,i=0;i<r.length;i++){var o=r[i].from(),l=f(e.getLine(o.line),o.ch,n);t.push(p(n-l%n))}e.replaceSelections(t)},defaultTab:function(e){e.somethingSelected()?e.indentSelection("add"):e.execCommand("insertTab")},transposeChars:function(e){return hn(e,function(){for(var t=e.listSelections(),r=[],n=0;n<t.length;n++)if(t[n].empty()){var i=t[n].head,o=M(e.doc,i.line).text;if(o)if(i.ch==o.length&&(i=new E(i.line,i.ch-1)),i.ch>0)i=new E(i.line,i.ch+1),e.replaceRange(o.charAt(i.ch-1)+o.charAt(i.ch-2),E(i.line,i.ch-2),i,"+transpose");else if(i.line>e.doc.first){var l=M(e.doc,i.line-1).text;l&&(i=new E(i.line,1),e.replaceRange(o.charAt(0)+e.doc.lineSeparator()+l.charAt(l.length-1),E(i.line-1,l.length-1),i,"+transpose"))}r.push(new Ts(i,i))}e.setSelections(r)})},newlineAndIndent:function(e){return hn(e,function(){for(var t=e.listSelections(),r=t.length-1;r>=0;r--)e.replaceRange(e.doc.lineSeparator(),t[r].anchor,t[r].head,"+input");t=e.listSelections();for(var n=0;n<t.length;n++)e.indentLine(t[n].from().line,null,!0);jr(e)})},openLine:function(e){return e.replaceSelection("\n","start")},toggleOverwrite:function(e){return e.toggleOverwrite()}},Gs=new Pl,Us=null,Vs=function(e,t,r){this.time=e,this.pos=t,this.button=r};Vs.prototype.compare=function(e,t,r){return this.time+400>e&&0==P(t,this.pos)&&r==this.button};var Ks,js,Xs={toString:function(){return"CodeMirror.Init"}},Ys={},_s={};jo.defaults=Ys,jo.optionHandlers=_s;var $s=[];jo.defineInitHook=function(e){return $s.push(e)};var qs=null,Zs=function(e){this.cm=e,this.lastAnchorNode=this.lastAnchorOffset=this.lastFocusNode=this.lastFocusOffset=null,this.polling=new Pl,this.composing=null,this.gracePeriod=!1,this.readDOMTimeout=null};Zs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()}),"cut"==e.type&&i.replaceSelection("",null,"cut");else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type&&i.operation(function(){i.setSelections(t.ranges,0,Gl),i.replaceSelection("",null,"cut")})}if(e.clipboardData){e.clipboardData.clearData();var r=qs.text.join("\n");if(e.clipboardData.setData("Text",r),e.clipboardData.getData("Text")==r)return void e.preventDefault()}var l=el(),s=l.firstChild;i.display.lineSpace.insertBefore(l,i.display.lineSpace.firstChild),s.value=qs.text.join("\n");var a=document.activeElement;El(s),setTimeout(function(){i.display.lineSpace.removeChild(l),a.focus(),a==o&&n.showPrimarySelection()},50)}}var r=this,n=this,i=n.cm,o=n.div=e.lineDiv;Jo(o,i.options.spellcheck),Ql(o,"paste",function(e){Me(i,e)||qo(e,i)||vl<=11&&setTimeout(dn(i,function(){return r.updateFromDOM()}),20)}),Ql(o,"compositionstart",function(e){r.composing={data:e.data,done:!1}}),Ql(o,"compositionupdate",function(e){r.composing||(r.composing={data:e.data,done:!1})}),Ql(o,"compositionend",function(e){r.composing&&(e.data!=r.composing.data&&r.readFromDOMSoon(),r.composing.done=!0)}),Ql(o,"touchstart",function(){return n.forceCompositionEnd()}),Ql(o,"input",function(){r.composing||r.readFromDOMSoon()}),Ql(o,"copy",t),Ql(o,"cut",t)},Zs.prototype.prepareSelection=function(){var e=Tr(this.cm,!1);return e.focus=this.cm.state.focused,e},Zs.prototype.showSelection=function(e,t){e&&this.cm.display.view.length&&((e.focus||t)&&this.showPrimarySelection(),this.showMultipleSelections(e))},Zs.prototype.showPrimarySelection=function(){var e=window.getSelection(),t=this.cm,r=t.doc.sel.primary(),n=r.from(),i=r.to();if(t.display.viewTo==t.display.viewFrom||n.line>=t.display.viewTo||i.line<t.display.viewFrom)e.removeAllRanges();else{var o=sl(t,e.anchorNode,e.anchorOffset),l=sl(t,e.focusNode,e.focusOffset);if(!o||o.bad||!l||l.bad||0!=P(B(o,l),n)||0!=P(R(o,l),i)){var s=t.display.view,a=n.line>=t.display.viewFrom&&nl(t,n)||{node:s[0].measure.map[2],offset:0},u=i.line<t.display.viewTo&&nl(t,i);if(!u){var c=s[s.length-1].measure,f=c.maps?c.maps[c.maps.length-1]:c.map;u={node:f[f.length-1],offset:f[f.length-2]-f[f.length-3]}}if(a&&u){var h,d=e.rangeCount&&e.getRangeAt(0);try{h=Wl(a.node,a.offset,u.offset,u.node)}catch(e){}h&&(!fl&&t.state.focused?(e.collapse(a.node,a.offset),h.collapsed||(e.removeAllRanges(),e.addRange(h))):(e.removeAllRanges(),e.addRange(h)),d&&null==e.anchorNode?e.addRange(d):fl&&this.startGracePeriod()),this.rememberSelection()}else e.removeAllRanges()}}},Zs.prototype.startGracePeriod=function(){var e=this;clearTimeout(this.gracePeriod),this.gracePeriod=setTimeout(function(){e.gracePeriod=!1,e.selectionChanged()&&e.cm.operation(function(){return e.cm.curOp.selectionChanged=!0})},20)},Zs.prototype.showMultipleSelections=function(e){r(this.cm.display.cursorDiv,e.cursors),r(this.cm.display.selectionDiv,e.selection)},Zs.prototype.rememberSelection=function(){var e=window.getSelection();this.lastAnchorNode=e.anchorNode,this.lastAnchorOffset=e.anchorOffset,this.lastFocusNode=e.focusNode,this.lastFocusOffset=e.focusOffset},Zs.prototype.selectionInEditor=function(){var e=window.getSelection();if(!e.rangeCount)return!1;var t=e.getRangeAt(0).commonAncestorContainer;return o(this.div,t)},Zs.prototype.focus=function(){"nocursor"!=this.cm.options.readOnly&&(this.selectionInEditor()||this.showSelection(this.prepareSelection(),!0),this.div.focus())},Zs.prototype.blur=function(){this.div.blur()},Zs.prototype.getField=function(){return this.div},Zs.prototype.supportsTouch=function(){return!0},Zs.prototype.receivedFocus=function(){function e(){t.cm.state.focused&&(t.pollSelection(),t.polling.set(t.cm.options.pollInterval,e))}var t=this;this.selectionInEditor()?this.pollSelection():hn(this.cm,function(){return t.cm.curOp.selectionChanged=!0}),this.polling.set(this.cm.options.pollInterval,e)},Zs.prototype.selectionChanged=function(){var e=window.getSelection();return e.anchorNode!=this.lastAnchorNode||e.anchorOffset!=this.lastAnchorOffset||e.focusNode!=this.lastFocusNode||e.focusOffset!=this.lastFocusOffset},Zs.prototype.pollSelection=function(){if(null==this.readDOMTimeout&&!this.gracePeriod&&this.selectionChanged()){var e=window.getSelection(),t=this.cm;if(kl&&bl&&this.cm.options.gutters.length&&il(e.anchorNode))return this.cm.triggerOnKeyDown({type:"keydown",keyCode:8,preventDefault:Math.abs}),this.blur(),void this.focus();if(!this.composing){this.rememberSelection();var r=sl(t,e.anchorNode,e.anchorOffset),n=sl(t,e.focusNode,e.focusOffset);r&&n&&hn(t,function(){bi(t.doc,Rn(r,n),Gl),(r.bad||n.bad)&&(t.curOp.selectionChanged=!0)})}}},Zs.prototype.pollContent=function(){null!=this.readDOMTimeout&&(clearTimeout(this.readDOMTimeout),this.readDOMTimeout=null);var e=this.cm,t=e.display,r=e.doc.sel.primary(),n=r.from(),i=r.to();if(0==n.ch&&n.line>e.firstLine()&&(n=E(n.line-1,M(e.doc,n.line-1).length)),i.ch==M(e.doc,i.line).text.length&&i.line<e.lastLine()&&(i=E(i.line+1,0)),n.line<t.viewFrom||i.line>t.viewTo-1)return!1;var o,l,s;n.line==t.viewFrom||0==(o=Lr(e,n.line))?(l=W(t.view[0].line),s=t.view[0].node):(l=W(t.view[o].line),s=t.view[o-1].node.nextSibling);var a,u,c=Lr(e,i.line);if(c==t.view.length-1?(a=t.viewTo-1,u=t.lineDiv.lastChild):(a=W(t.view[c+1].line)-1,u=t.view[c+1].node.previousSibling),!s)return!1;for(var f=e.doc.splitLines(ll(e,s,u,l,a)),h=N(e.doc,E(l,0),E(a,M(e.doc,a).text.length));f.length>1&&h.length>1;)if(g(f)==g(h))f.pop(),h.pop(),a--;else{if(f[0]!=h[0])break;f.shift(),h.shift(),l++}for(var d=0,p=0,v=f[0],m=h[0],y=Math.min(v.length,m.length);d<y&&v.charCodeAt(d)==m.charCodeAt(d);)++d;for(var b=g(f),w=g(h),x=Math.min(b.length-(1==f.length?d:0),w.length-(1==h.length?d:0));p<x&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)++p;if(1==f.length&&1==h.length&&l==n.line)for(;d&&d>n.ch&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)d--,p++;f[f.length-1]=b.slice(0,b.length-p).replace(/^\u200b+/,""),f[0]=f[0].slice(d).replace(/\u200b+$/,"");var C=E(l,d),S=E(a,h.length?g(h).length-p:0);return f.length>1||f[0]||P(C,S)?(Ei(e.doc,f,C,S,"+input"),!0):void 0},Zs.prototype.ensurePolled=function(){this.forceCompositionEnd()},Zs.prototype.reset=function(){this.forceCompositionEnd()},Zs.prototype.forceCompositionEnd=function(){this.composing&&(clearTimeout(this.readDOMTimeout),this.composing=null,this.updateFromDOM(),this.div.blur(),this.div.focus())},Zs.prototype.readFromDOMSoon=function(){var e=this;null==this.readDOMTimeout&&(this.readDOMTimeout=setTimeout(function(){if(e.readDOMTimeout=null,e.composing){if(!e.composing.done)return;e.composing=null}e.updateFromDOM()},80))},Zs.prototype.updateFromDOM=function(){var e=this;!this.cm.isReadOnly()&&this.pollContent()||hn(this.cm,function(){return vn(e.cm)})},Zs.prototype.setUneditable=function(e){e.contentEditable="false"},Zs.prototype.onKeyPress=function(e){0!=e.charCode&&(e.preventDefault(),this.cm.isReadOnly()||dn(this.cm,$o)(this.cm,String.fromCharCode(null==e.charCode?e.keyCode:e.charCode),0))},Zs.prototype.readOnlyChanged=function(e){this.div.contentEditable=String("nocursor"!=e)},Zs.prototype.onContextMenu=function(){},Zs.prototype.resetPosition=function(){},Zs.prototype.needsContentAttribute=!0;var Qs=function(e){this.cm=e,this.prevInput="",this.pollingFast=!1,this.polling=new Pl,this.hasSelection=!1,this.composing=null};Qs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()});else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type?i.setSelections(t.ranges,null,Gl):(n.prevInput="",l.value=t.text.join("\n"),El(l))}"cut"==e.type&&(i.state.cutIncoming=!0)}}var r=this,n=this,i=this.cm,o=this.wrapper=el(),l=this.textarea=o.firstChild;e.wrapper.insertBefore(o,e.wrapper.firstChild),Ll&&(l.style.width="0px"),Ql(l,"input",function(){gl&&vl>=9&&r.hasSelection&&(r.hasSelection=null),n.poll()}),Ql(l,"paste",function(e){Me(i,e)||qo(e,i)||(i.state.pasteIncoming=!0,n.fastPoll())}),Ql(l,"cut",t),Ql(l,"copy",t),Ql(e.scroller,"paste",function(t){Ft(e,t)||Me(i,t)||(i.state.pasteIncoming=!0,n.focus())}),Ql(e.lineSpace,"selectstart",function(t){Ft(e,t)||We(t)}),Ql(l,"compositionstart",function(){var e=i.getCursor("from");n.composing&&n.composing.range.clear(),n.composing={start:e,range:i.markText(e,i.getCursor("to"),{className:"CodeMirror-composing"})}}),Ql(l,"compositionend",function(){n.composing&&(n.poll(),n.composing.range.clear(),n.composing=null)})},Qs.prototype.prepareSelection=function(){var e=this.cm,t=e.display,r=e.doc,n=Tr(e);if(e.options.moveInputWithCursor){var i=sr(e,r.sel.primary().head,"div"),o=t.wrapper.getBoundingClientRect(),l=t.lineDiv.getBoundingClientRect();n.teTop=Math.max(0,Math.min(t.wrapper.clientHeight-10,i.top+l.top-o.top)),n.teLeft=Math.max(0,Math.min(t.wrapper.clientWidth-10,i.left+l.left-o.left))}return n},Qs.prototype.showSelection=function(e){var t=this.cm.display;r(t.cursorDiv,e.cursors),r(t.selectionDiv,e.selection),null!=e.teTop&&(this.wrapper.style.top=e.teTop+"px",this.wrapper.style.left=e.teLeft+"px")},Qs.prototype.reset=function(e){if(!this.contextMenuPending&&!this.composing){var t=this.cm;if(t.somethingSelected()){this.prevInput="";var r=t.getSelection();this.textarea.value=r,t.state.focused&&El(this.textarea),gl&&vl>=9&&(this.hasSelection=r)}else e||(this.prevInput=this.textarea.value="",gl&&vl>=9&&(this.hasSelection=null))}},Qs.prototype.getField=function(){return this.textarea},Qs.prototype.supportsTouch=function(){return!1},Qs.prototype.focus=function(){if("nocursor"!=this.cm.options.readOnly&&(!Tl||l()!=this.textarea))try{this.textarea.focus()}catch(e){}},Qs.prototype.blur=function(){this.textarea.blur()},Qs.prototype.resetPosition=function(){this.wrapper.style.top=this.wrapper.style.left=0},Qs.prototype.receivedFocus=function(){this.slowPoll()},Qs.prototype.slowPoll=function(){var e=this;this.pollingFast||this.polling.set(this.cm.options.pollInterval,function(){e.poll(),e.cm.state.focused&&e.slowPoll()})},Qs.prototype.fastPoll=function(){function e(){r.poll()||t?(r.pollingFast=!1,r.slowPoll()):(t=!0,r.polling.set(60,e))}var t=!1,r=this;r.pollingFast=!0,r.polling.set(20,e)},Qs.prototype.poll=function(){var e=this,t=this.cm,r=this.textarea,n=this.prevInput;if(this.contextMenuPending||!t.state.focused||ts(r)&&!n&&!this.composing||t.isReadOnly()||t.options.disableInput||t.state.keySeq)return!1;var i=r.value;if(i==n&&!t.somethingSelected())return!1;if(gl&&vl>=9&&this.hasSelection===i||Ml&&/[\uf700-\uf7ff]/.test(i))return t.display.input.reset(),!1;if(t.doc.sel==t.display.selForContextMenu){var o=i.charCodeAt(0);if(8203!=o||n||(n="​"),8666==o)return this.reset(),this.cm.execCommand("undo")}for(var l=0,s=Math.min(n.length,i.length);l<s&&n.charCodeAt(l)==i.charCodeAt(l);)++l;return hn(t,function(){$o(t,i.slice(l),n.length-l,null,e.composing?"*compose":null),i.length>1e3||i.indexOf("\n")>-1?r.value=e.prevInput="":e.prevInput=i,e.composing&&(e.composing.range.clear(),e.composing.range=t.markText(e.composing.start,t.getCursor("to"),{className:"CodeMirror-composing"}))}),!0},Qs.prototype.ensurePolled=function(){this.pollingFast&&this.poll()&&(this.pollingFast=!1)},Qs.prototype.onKeyPress=function(){gl&&vl>=9&&(this.hasSelection=null),this.fastPoll()},Qs.prototype.onContextMenu=function(e){function t(){if(null!=l.selectionStart){var e=i.somethingSelected(),t="​"+(e?l.value:"");l.value="⇚",l.value=t,n.prevInput=e?"":"​",l.selectionStart=1,l.selectionEnd=t.length,o.selForContextMenu=i.doc.sel}}function r(){if(n.contextMenuPending=!1,n.wrapper.style.cssText=c,l.style.cssText=u,gl&&vl<9&&o.scrollbars.setScrollTop(o.scroller.scrollTop=a),null!=l.selectionStart){(!gl||gl&&vl<9)&&t();var e=0,r=function(){o.selForContextMenu==i.doc.sel&&0==l.selectionStart&&l.selectionEnd>0&&"​"==n.prevInput?dn(i,Mi)(i):e++<10?o.detectingSelectAll=setTimeout(r,500):(o.selForContextMenu=null,o.input.reset())};o.detectingSelectAll=setTimeout(r,200)}}var n=this,i=n.cm,o=i.display,l=n.textarea,s=Sr(i,e),a=o.scroller.scrollTop;if(s&&!wl){i.options.resetSelectionOnContextMenu&&-1==i.doc.sel.contains(s)&&dn(i,bi)(i.doc,Rn(s),Gl);var u=l.style.cssText,c=n.wrapper.style.cssText;n.wrapper.style.cssText="position: absolute";var f=n.wrapper.getBoundingClientRect();l.style.cssText="position: absolute; width: 30px; height: 30px;\n      top: "+(e.clientY-f.top-5)+"px; left: "+(e.clientX-f.left-5)+"px;\n      z-index: 1000; background: "+(gl?"rgba(255, 255, 255, .05)":"transparent")+";\n      outline: none; border-width: 0; outline: none; overflow: hidden; opacity: .05; filter: alpha(opacity=5);";var h;if(ml&&(h=window.scrollY),o.input.focus(),ml&&window.scrollTo(null,h),o.input.reset(),i.somethingSelected()||(l.value=n.prevInput=" "),n.contextMenuPending=!0,o.selForContextMenu=i.doc.sel,clearTimeout(o.detectingSelectAll),gl&&vl>=9&&t(),Hl){Fe(e);var d=function(){ke(window,"mouseup",d),setTimeout(r,20)};Ql(window,"mouseup",d)}else setTimeout(r,50)}},Qs.prototype.readOnlyChanged=function(e){e||this.reset(),this.textarea.disabled="nocursor"==e},Qs.prototype.setUneditable=function(){},Qs.prototype.needsContentAttribute=!1,function(e){function t(t,n,i,o){e.defaults[t]=n,i&&(r[t]=o?function(e,t,r){r!=Xs&&i(e,t,r)}:i)}var r=e.optionHandlers;e.defineOption=t,e.Init=Xs,t("value","",function(e,t){return e.setValue(t)},!0),t("mode",null,function(e,t){e.doc.modeOption=t,jn(e)},!0),t("indentUnit",2,jn,!0),t("indentWithTabs",!1),t("smartIndent",!0),t("tabSize",4,function(e){Xn(e),er(e),vn(e)},!0),t("lineSeparator",null,function(e,t){if(e.doc.lineSep=t,t){var r=[],n=e.doc.first;e.doc.iter(function(e){for(var i=0;;){var o=e.text.indexOf(t,i);if(-1==o)break;i=o+t.length,r.push(E(n,o))}n++});for(var i=r.length-1;i>=0;i--)Ei(e.doc,t,r[i],E(r[i].line,r[i].ch+t.length))}}),t("specialChars",/[\u0000-\u001f\u007f-\u009f\u00ad\u061c\u200b-\u200f\u2028\u2029\ufeff]/g,function(e,t,r){e.state.specialChars=new RegExp(t.source+(t.test("\t")?"":"|\t"),"g"),r!=Xs&&e.refresh()}),t("specialCharPlaceholder",at,function(e){return e.refresh()},!0),t("electricChars",!0),t("inputStyle",Tl?"contenteditable":"textarea",function(){throw new Error("inputStyle can not (yet) be changed in a running editor")},!0),t("spellcheck",!1,function(e,t){return e.getInputField().spellcheck=t},!0),t("rtlMoveVisually",!Ol),t("wholeLineUpdateBefore",!0),t("theme","default",function(e){Go(e),Uo(e)},!0),t("keyMap","default",function(e,t,r){var n=uo(t),i=r!=Xs&&uo(r);i&&i.detach&&i.detach(e,n),n.attach&&n.attach(e,i||null)}),t("extraKeys",null),t("configureMouse",null),t("lineWrapping",!1,Ko,!0),t("gutters",[],function(e){Fn(e.options),Uo(e)},!0),t("fixedGutter",!0,function(e,t){e.display.gutters.style.left=t?wr(e.display)+"px":"0",e.refresh()},!0),t("coverGutterNextToScrollbar",!1,function(e){return en(e)},!0),t("scrollbarStyle","native",function(e){rn(e),en(e),e.display.scrollbars.setScrollTop(e.doc.scrollTop),e.display.scrollbars.setScrollLeft(e.doc.scrollLeft)},!0),t("lineNumbers",!1,function(e){Fn(e.options),Uo(e)},!0),t("firstLineNumber",1,Uo,!0),t("lineNumberFormatter",function(e){return e},Uo,!0),t("showCursorWhenSelecting",!1,kr,!0),t("resetSelectionOnContextMenu",!0),t("lineWiseCopyCut",!0),t("pasteLinesPerSelection",!0),t("readOnly",!1,function(e,t){"nocursor"==t&&(Fr(e),e.display.input.blur()),e.display.input.readOnlyChanged(t)}),t("disableInput",!1,function(e,t){t||e.display.input.reset()},!0),t("dragDrop",!0,Vo),t("allowDropFileTypes",null),t("cursorBlinkRate",530),t("cursorScrollMargin",0),t("cursorHeight",1,kr,!0),t("singleCursorHeightPerLine",!0,kr,!0),t("workTime",100),t("workDelay",100),t("flattenSpans",!0,Xn,!0),t("addModeClass",!1,Xn,!0),t("pollInterval",100),t("undoDepth",200,function(e,t){return e.doc.history.undoDepth=t}),t("historyEventDelay",1250),t("viewportMargin",10,function(e){return e.refresh()},!0),t("maxHighlightLength",1e4,Xn,!0),t("moveInputWithCursor",!0,function(e,t){t||e.display.input.resetPosition()}),t("tabindex",null,function(e,t){return e.display.input.getField().tabIndex=t||""}),t("autofocus",null),t("direction","ltr",function(e,t){return e.doc.setDirection(t)},!0)}(jo),function(e){var t=e.optionHandlers,r=e.helpers={};e.prototype={constructor:e,focus:function(){window.focus(),this.display.input.focus()},setOption:function(e,r){var n=this.options,i=n[e];n[e]==r&&"mode"!=e||(n[e]=r,t.hasOwnProperty(e)&&dn(this,t[e])(this,r,i),Te(this,"optionChange",this,e))},getOption:function(e){return this.options[e]},getDoc:function(){return this.doc},addKeyMap:function(e,t){this.state.keyMaps[t?"push":"unshift"](uo(e))},removeKeyMap:function(e){for(var t=this.state.keyMaps,r=0;r<t.length;++r)if(t[r]==e||t[r].name==e)return t.splice(r,1),!0},addOverlay:pn(function(t,r){var n=t.token?t:e.getMode(this.options,t);if(n.startState)throw new Error("Overlays may not be stateful.");m(this.state.overlays,{mode:n,modeSpec:t,opaque:r&&r.opaque,priority:r&&r.priority||0},function(e){return e.priority}),this.state.modeGen++,vn(this)}),removeOverlay:pn(function(e){for(var t=this,r=this.state.overlays,n=0;n<r.length;++n){var i=r[n].modeSpec;if(i==e||"string"==typeof e&&i.name==e)return r.splice(n,1),t.state.modeGen++,void vn(t)}}),indentLine:pn(function(e,t,r){"string"!=typeof t&&"number"!=typeof t&&(t=null==t?this.options.smartIndent?"smart":"prev":t?"add":"subtract"),H(this.doc,e)&&Yo(this,e,t,r)}),indentSelection:pn(function(e){for(var t=this,r=this.doc.sel.ranges,n=-1,i=0;i<r.length;i++){var o=r[i];if(o.empty())o.head.line>n&&(Yo(t,o.head.line,e,!0),n=o.head.line,i==t.doc.sel.primIndex&&jr(t));else{var l=o.from(),s=o.to(),a=Math.max(n,l.line);n=Math.min(t.lastLine(),s.line-(s.ch?0:1))+1;for(var u=a;u<n;++u)Yo(t,u,e);var c=t.doc.sel.ranges;0==l.ch&&r.length==c.length&&c[i].from().ch>0&&gi(t.doc,i,new Ts(l,c[i].to()),Gl)}}}),getTokenAt:function(e,t){return Je(this,e,t)},getLineTokens:function(e,t){return Je(this,E(e),t,!0)},getTokenTypeAt:function(e){e=U(this.doc,e);var t,r=_e(this,M(this.doc,e.line)),n=0,i=(r.length-1)/2,o=e.ch;if(0==o)t=r[2];else for(;;){var l=n+i>>1;if((l?r[2*l-1]:0)>=o)i=l;else{if(!(r[2*l+1]<o)){t=r[2*l+2];break}n=l+1}}var s=t?t.indexOf("overlay "):-1;return s<0?t:0==s?null:t.slice(0,s-1)},getModeAt:function(t){var r=this.doc.mode;return r.innerMode?e.innerMode(r,this.getTokenAt(t).state).mode:r},getHelper:function(e,t){return this.getHelpers(e,t)[0]},getHelpers:function(e,t){var n=this,i=[];if(!r.hasOwnProperty(t))return i;var o=r[t],l=this.getModeAt(e);if("string"==typeof l[t])o[l[t]]&&i.push(o[l[t]]);else if(l[t])for(var s=0;s<l[t].length;s++){var a=o[l[t][s]];a&&i.push(a)}else l.helperType&&o[l.helperType]?i.push(o[l.helperType]):o[l.name]&&i.push(o[l.name]);for(var u=0;u<o._global.length;u++){var c=o._global[u];c.pred(l,n)&&-1==h(i,c.val)&&i.push(c.val)}return i},getStateAfter:function(e,t){var r=this.doc;return e=G(r,null==e?r.first+r.size-1:e),$e(this,e+1,t).state},cursorCoords:function(e,t){var r,n=this.doc.sel.primary();return r=null==e?n.head:"object"==typeof e?U(this.doc,e):e?n.from():n.to(),sr(this,r,t||"page")},charCoords:function(e,t){return lr(this,U(this.doc,e),t||"page")},coordsChar:function(e,t){return e=or(this,e,t||"page"),cr(this,e.left,e.top)},lineAtHeight:function(e,t){return e=or(this,{top:e,left:0},t||"page").top,D(this.doc,e+this.display.viewOffset)},heightAtLine:function(e,t,r){var n,i=!1;if("number"==typeof e){var o=this.doc.first+this.doc.size-1;e<this.doc.first?e=this.doc.first:e>o&&(e=o,i=!0),n=M(this.doc,e)}else n=e;return ir(this,n,{top:0,left:0},t||"page",r||i).top+(i?this.doc.height-ye(n):0)},defaultTextHeight:function(){return mr(this.display)},defaultCharWidth:function(){return yr(this.display)},getViewport:function(){return{from:this.display.viewFrom,to:this.display.viewTo}},addWidget:function(e,t,r,n,i){var o=this.display,l=(e=sr(this,U(this.doc,e))).bottom,s=e.left;if(t.style.position="absolute",t.setAttribute("cm-ignore-events","true"),this.display.input.setUneditable(t),o.sizer.appendChild(t),"over"==n)l=e.top;else if("above"==n||"near"==n){var a=Math.max(o.wrapper.clientHeight,this.doc.height),u=Math.max(o.sizer.clientWidth,o.lineSpace.clientWidth);("above"==n||e.bottom+t.offsetHeight>a)&&e.top>t.offsetHeight?l=e.top-t.offsetHeight:e.bottom+t.offsetHeight<=a&&(l=e.bottom),s+t.offsetWidth>u&&(s=u-t.offsetWidth)}t.style.top=l+"px",t.style.left=t.style.right="","right"==i?(s=o.sizer.clientWidth-t.offsetWidth,t.style.right="0px"):("left"==i?s=0:"middle"==i&&(s=(o.sizer.clientWidth-t.offsetWidth)/2),t.style.left=s+"px"),r&&Ur(this,{left:s,top:l,right:s+t.offsetWidth,bottom:l+t.offsetHeight})},triggerOnKeyDown:pn(Lo),triggerOnKeyPress:pn(Mo),triggerOnKeyUp:To,triggerOnMouseDown:pn(Oo),execCommand:function(e){if(Bs.hasOwnProperty(e))return Bs[e].call(null,this)},triggerElectric:pn(function(e){Zo(this,e)}),findPosH:function(e,t,r,n){var i=this,o=1;t<0&&(o=-1,t=-t);for(var l=U(this.doc,e),s=0;s<t&&!(l=tl(i.doc,l,o,r,n)).hitSide;++s);return l},moveH:pn(function(e,t){var r=this;this.extendSelectionsBy(function(n){return r.display.shift||r.doc.extend||n.empty()?tl(r.doc,n.head,e,t,r.options.rtlMoveVisually):e<0?n.from():n.to()},Vl)}),deleteH:pn(function(e,t){var r=this.doc.sel,n=this.doc;r.somethingSelected()?n.replaceSelection("",null,"+delete"):co(this,function(r){var i=tl(n,r.head,e,t,!1);return e<0?{from:i,to:r.head}:{from:r.head,to:i}})}),findPosV:function(e,t,r,n){var i=this,o=1,l=n;t<0&&(o=-1,t=-t);for(var s=U(this.doc,e),a=0;a<t;++a){var u=sr(i,s,"div");if(null==l?l=u.left:u.left=l,(s=rl(i,u,o,r)).hitSide)break}return s},moveV:pn(function(e,t){var r=this,n=this.doc,i=[],o=!this.display.shift&&!n.extend&&n.sel.somethingSelected();if(n.extendSelectionsBy(function(l){if(o)return e<0?l.from():l.to();var s=sr(r,l.head,"div");null!=l.goalColumn&&(s.left=l.goalColumn),i.push(s.left);var a=rl(r,s,e,t);return"page"==t&&l==n.sel.primary()&&Kr(r,lr(r,a,"div").top-s.top),a},Vl),i.length)for(var l=0;l<n.sel.ranges.length;l++)n.sel.ranges[l].goalColumn=i[l]}),findWordAt:function(e){var t=M(this.doc,e.line).text,r=e.ch,n=e.ch;if(t){var i=this.getHelper(e,"wordChars");"before"!=e.sticky&&n!=t.length||!r?++n:--r;for(var o=t.charAt(r),l=x(o,i)?function(e){return x(e,i)}:/\s/.test(o)?function(e){return/\s/.test(e)}:function(e){return!/\s/.test(e)&&!x(e)};r>0&&l(t.charAt(r-1));)--r;for(;n<t.length&&l(t.charAt(n));)++n}return new Ts(E(e.line,r),E(e.line,n))},toggleOverwrite:function(e){null!=e&&e==this.state.overwrite||((this.state.overwrite=!this.state.overwrite)?s(this.display.cursorDiv,"CodeMirror-overwrite"):Fl(this.display.cursorDiv,"CodeMirror-overwrite"),Te(this,"overwriteToggle",this,this.state.overwrite))},hasFocus:function(){return this.display.input.getField()==l()},isReadOnly:function(){return!(!this.options.readOnly&&!this.doc.cantEdit)},scrollTo:pn(function(e,t){Xr(this,e,t)}),getScrollInfo:function(){var e=this.display.scroller;return{left:e.scrollLeft,top:e.scrollTop,height:e.scrollHeight-zt(this)-this.display.barHeight,width:e.scrollWidth-zt(this)-this.display.barWidth,clientHeight:Bt(this),clientWidth:Rt(this)}},scrollIntoView:pn(function(e,t){null==e?(e={from:this.doc.sel.primary().head,to:null},null==t&&(t=this.options.cursorScrollMargin)):"number"==typeof e?e={from:E(e,0),to:null}:null==e.from&&(e={from:e,to:null}),e.to||(e.to=e.from),e.margin=t||0,null!=e.from.line?Yr(this,e):$r(this,e.from,e.to,e.margin)}),setSize:pn(function(e,t){var r=this,n=function(e){return"number"==typeof e||/^\d+$/.test(String(e))?e+"px":e};null!=e&&(this.display.wrapper.style.width=n(e)),null!=t&&(this.display.wrapper.style.height=n(t)),this.options.lineWrapping&&Jt(this);var i=this.display.viewFrom;this.doc.iter(i,this.display.viewTo,function(e){if(e.widgets)for(var t=0;t<e.widgets.length;t++)if(e.widgets[t].noHScroll){mn(r,i,"widget");break}++i}),this.curOp.forceUpdate=!0,Te(this,"refresh",this)}),operation:function(e){return hn(this,e)},startOperation:function(){return nn(this)},endOperation:function(){return on(this)},refresh:pn(function(){var e=this.display.cachedTextHeight;vn(this),this.curOp.forceUpdate=!0,er(this),Xr(this,this.doc.scrollLeft,this.doc.scrollTop),Wn(this),(null==e||Math.abs(e-mr(this.display))>.5)&&Cr(this),Te(this,"refresh",this)}),swapDoc:pn(function(e){var t=this.doc;return t.cm=null,qn(this,e),er(this),this.display.input.reset(),Xr(this,e.scrollLeft,e.scrollTop),this.curOp.forceScroll=!0,bt(this,"swapDoc",this,t),t}),getInputField:function(){return this.display.input.getField()},getWrapperElement:function(){return this.display.wrapper},getScrollerElement:function(){return this.display.scroller},getGutterElement:function(){return this.display.gutters}},Ae(e),e.registerHelper=function(t,n,i){r.hasOwnProperty(t)||(r[t]=e[t]={_global:[]}),r[t][n]=i},e.registerGlobalHelper=function(t,n,i,o){e.registerHelper(t,n,o),r[t]._global.push({pred:i,val:o})}}(jo);var Js="iter insert remove copy getEditor constructor".split(" ");for(var ea in Ds.prototype)Ds.prototype.hasOwnProperty(ea)&&h(Js,ea)<0&&(jo.prototype[ea]=function(e){return function(){return e.apply(this.doc,arguments)}}(Ds.prototype[ea]));return Ae(Ds),jo.inputStyles={textarea:Qs,contenteditable:Zs},jo.defineMode=function(e){jo.defaults.mode||"null"==e||(jo.defaults.mode=e),Be.apply(this,arguments)},jo.defineMIME=function(e,t){os[e]=t},jo.defineMode("null",function(){return{token:function(e){return e.skipToEnd()}}}),jo.defineMIME("text/plain","null"),jo.defineExtension=function(e,t){jo.prototype[e]=t},jo.defineDocExtension=function(e,t){Ds.prototype[e]=t},jo.fromTextArea=function(e,t){function r(){e.value=a.getValue()}if(t=t?c(t):{},t.value=e.value,!t.tabindex&&e.tabIndex&&(t.tabindex=e.tabIndex),!t.placeholder&&e.placeholder&&(t.placeholder=e.placeholder),null==t.autofocus){var n=l();t.autofocus=n==e||null!=e.getAttribute("autofocus")&&n==document.body}var i;if(e.form&&(Ql(e.form,"submit",r),!t.leaveSubmitMethodAlone)){var o=e.form;i=o.submit;try{var s=o.submit=function(){r(),o.submit=i,o.submit(),o.submit=s}}catch(e){}}t.finishInit=function(t){t.save=r,t.getTextArea=function(){return e},t.toTextArea=function(){t.toTextArea=isNaN,r(),e.parentNode.removeChild(t.getWrapperElement()),e.style.display="",e.form&&(ke(e.form,"submit",r),"function"==typeof e.form.submit&&(e.form.submit=i))}},e.style.display="none";var a=jo(function(t){return e.parentNode.insertBefore(t,e.nextSibling)},t);return a},function(e){e.off=ke,e.on=Ql,e.wheelEventPixels=Pn,e.Doc=Ds,e.splitLines=es,e.countColumn=f,e.findColumn=d,e.isWordChar=w,e.Pass=Bl,e.signal=Te,e.Line=fs,e.changeEnd=Bn,e.scrollbarModel=ws,e.Pos=E,e.cmpPos=P,e.modes=is,e.mimeModes=os,e.resolveMode=Ge,e.getMode=Ue,e.modeExtensions=ls,e.extendMode=Ve,e.copyState=Ke,e.startState=Xe,e.innerMode=je,e.commands=Bs,e.keyMap=Rs,e.keyName=ao,e.isModifierKey=lo,e.lookupKey=oo,e.normalizeKeyMap=io,e.StringStream=ss,e.SharedTextMarker=As,e.TextMarker=Os,e.LineWidget=Ms,e.e_preventDefault=We,e.e_stopPropagation=De,e.e_stop=Fe,e.addClass=s,e.contains=o,e.rmClass=Fl,e.keyNames=Es}(jo),jo.version="5.30.0",jo});
      !function(e){"object"==typeof exports&&"object"==typeof module?e(require("../../lib/codemirror")):"function"==typeof define&&define.amd?define(["../../lib/codemirror"],e):e(CodeMirror)}(function(e){"use strict";function t(e,t,n,r,o,a){this.indented=e,this.column=t,this.type=n,this.info=r,this.align=o,this.prev=a}function n(e,n,r,o){var a=e.indented;return e.context&&"statement"==e.context.type&&"statement"!=r&&(a=e.context.indented),e.context=new t(a,n,r,o,null,e.context)}function r(e){var t=e.context.type;return")"!=t&&"]"!=t&&"}"!=t||(e.indented=e.context.indented),e.context=e.context.prev}function o(e,t,n){return"variable"==t.prevToken||"type"==t.prevToken||(!!/\S(?:[^- ]>|[*\]])\s*$|\*$/.test(e.string.slice(0,n))||(!(!t.typeAtEndOfLine||e.column()!=e.indentation())||void 0))}function a(e){for(;;){if(!e||"top"==e.type)return!0;if("}"==e.type&&"namespace"!=e.prev.info)return!1;e=e.prev}}function i(e){for(var t={},n=e.split(" "),r=0;r<n.length;++r)t[n[r]]=!0;return t}function l(e,t){return"function"==typeof e?e(t):e.propertyIsEnumerable(t)}function s(e,t){if(!t.startOfLine)return!1;for(var n,r=null;n=e.peek();){if("\\"==n&&e.match(/^.$/)){r=s;break}if("/"==n&&e.match(/^\/[\/\*]/,!1))break;e.next()}return t.tokenize=r,"meta"}function c(e,t){return"type"==t.prevToken&&"type"}function u(e){return e.eatWhile(/[\w\.']/),"number"}function d(e,t){if(e.backUp(1),e.match(/(R|u8R|uR|UR|LR)/)){var n=e.match(/"([^\s\\()]{0,16})\(/);return!!n&&(t.cpp11RawStringDelim=n[1],t.tokenize=m,m(e,t))}return e.match(/(u8|u|U|L)/)?!!e.match(/["']/,!1)&&"string":(e.next(),!1)}function f(e){var t=/(\w+)::~?(\w+)$/.exec(e);return t&&t[1]==t[2]}function p(e,t){for(var n;null!=(n=e.next());)if('"'==n&&!e.eat('"')){t.tokenize=null;break}return"string"}function m(e,t){var n=t.cpp11RawStringDelim.replace(/[^\w\s]/g,"\\$&");return e.match(new RegExp(".*?\\)"+n+'"'))?t.tokenize=null:e.skipToEnd(),"string"}function h(t,n){function r(e){if(e)for(var t in e)e.hasOwnProperty(t)&&o.push(t)}"string"==typeof t&&(t=[t]);var o=[];r(n.keywords),r(n.types),r(n.builtin),r(n.atoms),o.length&&(n.helperType=t[0],e.registerHelper("hintWords",t[0],o));for(var a=0;a<t.length;++a)e.defineMIME(t[a],n)}function g(e,t){for(var n=!1;!e.eol();){if(!n&&e.match('"""')){t.tokenize=null;break}n="\\"==e.next()&&!n}return"string"}function y(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!e&&!o&&t.match('"')){a=!0;break}if(e&&t.match('"""')){a=!0;break}r=t.next(),!o&&"$"==r&&t.match("{")&&t.skipTo("}"),o=!o&&"\\"==r&&!e}return!a&&e||(n.tokenize=null),"string"}}function x(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!o&&t.match('"')&&("single"==e||t.match('""'))){a=!0;break}if(!o&&t.match("``")){w=x(e),a=!0;break}r=t.next(),o="single"==e&&!o&&"\\"==r}return a&&(n.tokenize=null),"string"}}e.defineMode("clike",function(i,s){function c(e,t){var n=e.next();if(S[n]){var r=S[n](e,t);if(!1!==r)return r}if('"'==n||"'"==n)return t.tokenize=u(n),t.tokenize(e,t);if(D.test(n))return p=n,null;if(L.test(n)){if(e.backUp(1),e.match(I))return"number";e.next()}if("/"==n){if(e.eat("*"))return t.tokenize=d,d(e,t);if(e.eat("/"))return e.skipToEnd(),"comment"}if(F.test(n)){for(;!e.match(/^\/[\/*]/,!1)&&e.eat(F););return"operator"}if(e.eatWhile(z),P)for(;e.match(P);)e.eatWhile(z);var o=e.current();return l(x,o)?(l(w,o)&&(p="newstatement"),l(v,o)&&(m=!0),"keyword"):l(b,o)?"type":l(k,o)?(l(w,o)&&(p="newstatement"),"builtin"):l(_,o)?"atom":"variable"}function u(e){return function(t,n){for(var r,o=!1,a=!1;null!=(r=t.next());){if(r==e&&!o){a=!0;break}o=!o&&"\\"==r}return(a||!o&&!C)&&(n.tokenize=null),"string"}}function d(e,t){for(var n,r=!1;n=e.next();){if("/"==n&&r){t.tokenize=null;break}r="*"==n}return"comment"}function f(e,t){s.typeFirstDefinitions&&e.eol()&&a(t.context)&&(t.typeAtEndOfLine=o(e,t,e.pos))}var p,m,h=i.indentUnit,g=s.statementIndentUnit||h,y=s.dontAlignCalls,x=s.keywords||{},b=s.types||{},k=s.builtin||{},w=s.blockKeywords||{},v=s.defKeywords||{},_=s.atoms||{},S=s.hooks||{},C=s.multiLineStrings,T=!1!==s.indentStatements,M=!1!==s.indentSwitch,P=s.namespaceSeparator,D=s.isPunctuationChar||/[\[\]{}\(\),;\:\.]/,L=s.numberStart||/[\d\.]/,I=s.number||/^(?:0x[a-f\d]+|0b[01]+|(?:\d+\.?\d*|\.\d+)(?:e[-+]?\d+)?)(u|ll?|l|f)?/i,F=s.isOperatorChar||/[+\-*&%=<>!?|\/]/,z=s.isIdentifierChar||/[\w\$_\xa1-\uffff]/;return{startState:function(e){return{tokenize:null,context:new t((e||0)-h,0,"top",null,!1),indented:0,startOfLine:!0,prevToken:null}},token:function(e,t){var i=t.context;if(e.sol()&&(null==i.align&&(i.align=!1),t.indented=e.indentation(),t.startOfLine=!0),e.eatSpace())return f(e,t),null;p=m=null;var l=(t.tokenize||c)(e,t);if("comment"==l||"meta"==l)return l;if(null==i.align&&(i.align=!0),";"==p||":"==p||","==p&&e.match(/^\s*(?:\/\/.*)?$/,!1))for(;"statement"==t.context.type;)r(t);else if("{"==p)n(t,e.column(),"}");else if("["==p)n(t,e.column(),"]");else if("("==p)n(t,e.column(),")");else if("}"==p){for(;"statement"==i.type;)i=r(t);for("}"==i.type&&(i=r(t));"statement"==i.type;)i=r(t)}else p==i.type?r(t):T&&(("}"==i.type||"top"==i.type)&&";"!=p||"statement"==i.type&&"newstatement"==p)&&n(t,e.column(),"statement",e.current());if("variable"==l&&("def"==t.prevToken||s.typeFirstDefinitions&&o(e,t,e.start)&&a(t.context)&&e.match(/^\s*\(/,!1))&&(l="def"),S.token){var u=S.token(e,t,l);void 0!==u&&(l=u)}return"def"==l&&!1===s.styleDefs&&(l="variable"),t.startOfLine=!1,t.prevToken=m?"def":l||p,f(e,t),l},indent:function(t,n){if(t.tokenize!=c&&null!=t.tokenize||t.typeAtEndOfLine)return e.Pass;var r=t.context,o=n&&n.charAt(0);if("statement"==r.type&&"}"==o&&(r=r.prev),s.dontIndentStatements)for(;"statement"==r.type&&s.dontIndentStatements.test(r.info);)r=r.prev;if(S.indent){var a=S.indent(t,r,n);if("number"==typeof a)return a}var i=o==r.type,l=r.prev&&"switch"==r.prev.info;if(s.allmanIndentation&&/[{(]/.test(o)){for(;"top"!=r.type&&"}"!=r.type;)r=r.prev;return r.indented}return"statement"==r.type?r.indented+("{"==o?0:g):!r.align||y&&")"==r.type?")"!=r.type||i?r.indented+(i?0:h)+(i||!l||/^(?:case|default)\b/.test(n)?0:h):r.indented+g:r.column+(i?0:1)},electricInput:M?/^\s*(?:case .*?:|default:|\{\}?|\})$/:/^\s*[{}]$/,blockCommentStart:"/*",blockCommentEnd:"*/",lineComment:"//",fold:"brace"}});var b="auto if break case register continue return default do sizeof static else struct switch extern typedef union for goto while enum const volatile",k="int long char short double float unsigned signed void size_t ptrdiff_t";h(["text/x-csrc","text/x-c","text/x-chdr"],{name:"clike",keywords:i(b),types:i(k+" bool _Complex _Bool float_t double_t intptr_t intmax_t int8_t int16_t int32_t int64_t uintptr_t uintmax_t uint8_t uint16_t uint32_t uint64_t"),blockKeywords:i("case do else for if switch while struct"),defKeywords:i("struct"),typeFirstDefinitions:!0,atoms:i("null true false"),hooks:{"#":s,"*":c},modeProps:{fold:["brace","include"]}}),h(["text/x-c++src","text/x-c++hdr"],{name:"clike",keywords:i(b+" asm dynamic_cast namespace reinterpret_cast try explicit new static_cast typeid catch operator template typename class friend private this using const_cast inline public throw virtual delete mutable protected alignas alignof constexpr decltype nullptr noexcept thread_local final static_assert override"),types:i(k+" bool wchar_t"),blockKeywords:i("catch class do else finally for if struct switch try while"),defKeywords:i("class namespace struct enum union"),typeFirstDefinitions:!0,atoms:i("true false null"),dontIndentStatements:/^template$/,isIdentifierChar:/[\w\$_~\xa1-\uffff]/,hooks:{"#":s,"*":c,u:d,U:d,L:d,R:d,0:u,1:u,2:u,3:u,4:u,5:u,6:u,7:u,8:u,9:u,token:function(e,t,n){if("variable"==n&&"("==e.peek()&&(";"==t.prevToken||null==t.prevToken||"}"==t.prevToken)&&f(e.current()))return"def"}},namespaceSeparator:"::",modeProps:{fold:["brace","include"]}}),h("text/x-java",{name:"clike",keywords:i("abstract assert break case catch class const continue default do else enum extends final finally float for goto if implements import instanceof interface native new package private protected public return static strictfp super switch synchronized this throw throws transient try volatile while @interface"),types:i("byte short int long float double boolean char void Boolean Byte Character Double Float Integer Long Number Object Short String StringBuffer StringBuilder Void"),blockKeywords:i("catch class do else finally for if switch try while"),defKeywords:i("class interface package enum @interface"),typeFirstDefinitions:!0,atoms:i("true false null"),number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,hooks:{"@":function(e){return!e.match("interface",!1)&&(e.eatWhile(/[\w\$_]/),"meta")}},modeProps:{fold:["brace","import"]}}),h("text/x-csharp",{name:"clike",keywords:i("abstract as async await base break case catch checked class const continue default delegate do else enum event explicit extern finally fixed for foreach goto if implicit in interface internal is lock namespace new operator out override params private protected public readonly ref return sealed sizeof stackalloc static struct switch this throw try typeof unchecked unsafe using virtual void volatile while add alias ascending descending dynamic from get global group into join let orderby partial remove select set value var yield"),types:i("Action Boolean Byte Char DateTime DateTimeOffset Decimal Double Func Guid Int16 Int32 Int64 Object SByte Single String Task TimeSpan UInt16 UInt32 UInt64 bool byte char decimal double short int long object sbyte float string ushort uint ulong"),blockKeywords:i("catch class do else finally for foreach if struct switch try while"),defKeywords:i("class interface namespace struct var"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"@":function(e,t){return e.eat('"')?(t.tokenize=p,p(e,t)):(e.eatWhile(/[\w\$_]/),"meta")}}}),h("text/x-scala",{name:"clike",keywords:i("abstract case catch class def do else extends final finally for forSome if implicit import lazy match new null object override package private protected return sealed super this throw trait try type val var while with yield _ assert assume require print println printf readLine readBoolean readByte readShort readChar readInt readLong readFloat readDouble"),types:i("AnyVal App Application Array BufferedIterator BigDecimal BigInt Char Console Either Enumeration Equiv Error Exception Fractional Function IndexedSeq Int Integral Iterable Iterator List Map Numeric Nil NotNull Option Ordered Ordering PartialFunction PartialOrdering Product Proxy Range Responder Seq Serializable Set Specializable Stream StringBuilder StringContext Symbol Throwable Traversable TraversableOnce Tuple Unit Vector Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),multiLineStrings:!0,blockKeywords:i("catch class enum do else finally for forSome if match switch try while"),defKeywords:i("class enum def object package trait type val var"),atoms:i("true false null"),indentStatements:!1,indentSwitch:!1,isOperatorChar:/[+\-*&%=<>!?|\/#:@]/,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return!!e.match('""')&&(t.tokenize=g,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},"=":function(e,n){var r=n.context;return!("}"!=r.type||!r.align||!e.eat(">"))&&(n.context=new t(r.indented,r.column,r.type,r.info,null,r.prev),"operator")}},modeProps:{closeBrackets:{triples:'"'}}}),h("text/x-kotlin",{name:"clike",keywords:i("package as typealias class interface this super val var fun for is in This throw return break continue object if else while do try when !in !is as? file import where by get set abstract enum open inner override private public internal protected catch finally out final vararg reified dynamic companion constructor init sealed field property receiver param sparam lateinit data inline noinline tailrec external annotation crossinline const operator infix suspend"),types:i("Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),intendSwitch:!1,indentStatements:!1,multiLineStrings:!0,number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,blockKeywords:i("catch class do else finally for if where try while enum"),defKeywords:i("class val var object package interface fun"),atoms:i("true false null this"),hooks:{'"':function(e,t){return t.tokenize=y(e.match('""')),t.tokenize(e,t)}},modeProps:{closeBrackets:{triples:'"'}}}),h(["x-shader/x-vertex","x-shader/x-fragment"],{name:"clike",keywords:i("sampler1D sampler2D sampler3D samplerCube sampler1DShadow sampler2DShadow const attribute uniform varying break continue discard return for while do if else struct in out inout"),types:i("float int bool void vec2 vec3 vec4 ivec2 ivec3 ivec4 bvec2 bvec3 bvec4 mat2 mat3 mat4"),blockKeywords:i("for while do if else struct"),builtin:i("radians degrees sin cos tan asin acos atan pow exp log exp2 sqrt inversesqrt abs sign floor ceil fract mod min max clamp mix step smoothstep length distance dot cross normalize ftransform faceforward reflect refract matrixCompMult lessThan lessThanEqual greaterThan greaterThanEqual equal notEqual any all not texture1D texture1DProj texture1DLod texture1DProjLod texture2D texture2DProj texture2DLod texture2DProjLod texture3D texture3DProj texture3DLod texture3DProjLod textureCube textureCubeLod shadow1D shadow2D shadow1DProj shadow2DProj shadow1DLod shadow2DLod shadow1DProjLod shadow2DProjLod dFdx dFdy fwidth noise1 noise2 noise3 noise4"),atoms:i("true false gl_FragColor gl_SecondaryColor gl_Normal gl_Vertex gl_MultiTexCoord0 gl_MultiTexCoord1 gl_MultiTexCoord2 gl_MultiTexCoord3 gl_MultiTexCoord4 gl_MultiTexCoord5 gl_MultiTexCoord6 gl_MultiTexCoord7 gl_FogCoord gl_PointCoord gl_Position gl_PointSize gl_ClipVertex gl_FrontColor gl_BackColor gl_FrontSecondaryColor gl_BackSecondaryColor gl_TexCoord gl_FogFragCoord gl_FragCoord gl_FrontFacing gl_FragData gl_FragDepth gl_ModelViewMatrix gl_ProjectionMatrix gl_ModelViewProjectionMatrix gl_TextureMatrix gl_NormalMatrix gl_ModelViewMatrixInverse gl_ProjectionMatrixInverse gl_ModelViewProjectionMatrixInverse gl_TexureMatrixTranspose gl_ModelViewMatrixInverseTranspose gl_ProjectionMatrixInverseTranspose gl_ModelViewProjectionMatrixInverseTranspose gl_TextureMatrixInverseTranspose gl_NormalScale gl_DepthRange gl_ClipPlane gl_Point gl_FrontMaterial gl_BackMaterial gl_LightSource gl_LightModel gl_FrontLightModelProduct gl_BackLightModelProduct gl_TextureColor gl_EyePlaneS gl_EyePlaneT gl_EyePlaneR gl_EyePlaneQ gl_FogParameters gl_MaxLights gl_MaxClipPlanes gl_MaxTextureUnits gl_MaxTextureCoords gl_MaxVertexAttribs gl_MaxVertexUniformComponents gl_MaxVaryingFloats gl_MaxVertexTextureImageUnits gl_MaxTextureImageUnits gl_MaxFragmentUniformComponents gl_MaxCombineTextureImageUnits gl_MaxDrawBuffers"),indentSwitch:!1,hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-nesc",{name:"clike",keywords:i(b+"as atomic async call command component components configuration event generic implementation includes interface module new norace nx_struct nx_union post provides signal task uses abstract extends"),types:i(k),blockKeywords:i("case do else for if switch while struct"),atoms:i("null true false"),hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-objectivec",{name:"clike",keywords:i(b+"inline restrict _Bool _Complex _Imaginary BOOL Class bycopy byref id IMP in inout nil oneway out Protocol SEL self super atomic nonatomic retain copy readwrite readonly"),types:i(k),atoms:i("YES NO NULL NILL ON OFF true false"),hooks:{"@":function(e){return e.eatWhile(/[\w\$]/),"keyword"},"#":s,indent:function(e,t,n){if("statement"==t.type&&/^@\w/.test(n))return t.indented}},modeProps:{fold:"brace"}}),h("text/x-squirrel",{name:"clike",keywords:i("base break clone continue const default delete enum extends function in class foreach local resume return this throw typeof yield constructor instanceof static"),types:i(k),blockKeywords:i("case catch class else for foreach if switch try while"),defKeywords:i("function local class"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"#":s},modeProps:{fold:["brace","include"]}});var w=null;h("text/x-ceylon",{name:"clike",keywords:i("abstracts alias assembly assert assign break case catch class continue dynamic else exists extends finally for function given if import in interface is let module new nonempty object of out outer package return satisfies super switch then this throw try value void while"),types:function(e){var t=e.charAt(0);return t===t.toUpperCase()&&t!==t.toLowerCase()},blockKeywords:i("case catch class dynamic else finally for function if interface module new object switch try while"),defKeywords:i("class dynamic function interface module object package value"),builtin:i("abstract actual aliased annotation by default deprecated doc final formal late license native optional sealed see serializable shared suppressWarnings tagged throws variable"),isPunctuationChar:/[\[\]{}\(\),;\:\.`]/,isOperatorChar:/[+\-*&%=<>!?|^~:\/]/,numberStart:/[\d#$]/,number:/^(?:#[\da-fA-F_]+|\$[01_]+|[\d_]+[kMGTPmunpf]?|[\d_]+\.[\d_]+(?:[eE][-+]?\d+|[kMGTPmunpf]|)|)/i,multiLineStrings:!0,typeFirstDefinitions:!0,atoms:i("true false null larger smaller equal empty finished"),indentSwitch:!1,styleDefs:!1,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return t.tokenize=x(e.match('""')?"triple":"single"),t.tokenize(e,t)},"`":function(e,t){return!(!w||!e.match("`"))&&(t.tokenize=w,w=null,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},token:function(e,t,n){if(("variable"==n||"type"==n)&&"."==t.prevToken)return"variable-2"}},modeProps:{fold:["brace","import"],closeBrackets:{triples:'"'}}})});
      // -------------------------------------------------------------------------
//  Part of the CodeChecker project, under the Apache License v2.0 with
//  LLVM Exceptions. See LICENSE for license information.
//  SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
// -------------------------------------------------------------------------

var BugViewer = {
  _files : [],
  _reports : [],
  _lineWidgets : [],
  _navigationMenuItems : [],
  _sourceFileData : null,
  _currentReport : null,
  _lastBugEvent  : null,

  init : function (files, reports) {
    this._files = files;
    this._reports = reports;

    this.initEscapeChars();
  },

  initEscapeChars : function () {
    this.escapeChars = {
      ' ' : 'nbsp',
      '<' : 'lt',
      '>' : 'gt',
      '"' : 'quot',
      '&' : 'amp'
    };

    var regexString = '[';
    for (var key in this.escapeChars) {
      regexString += key;
    }
    regexString += ']';

    this.escapeRegExp = new RegExp( regexString, 'g');
  },

  escapeHTML : function (str) {
    var that = this;

    return str.replace(this.escapeRegExp, function (m) {
      return '&' + that.escapeChars[m] + ';';
    });
  },

  initByUrl : function () {
    if (!this._reports) return;

    var state = {};
    window.location.hash.substr(1).split('&').forEach(function (s) {
      var parts = s.split('=');
      state[parts[0]] = parts[1];
    });

    for (var key in this._reports) {
      var report = this._reports[key];
      if (report.reportHash === state['reportHash']) {
        this.navigate(report);
        return;
      }
    }

    this.navigate(this._reports[0]);
  },

  create : function () {
    this._content = document.getElementById('editor-wrapper');
    this._filepath = document.getElementById('file-path');
    this._checkerName = document.getElementById('checker-name');
    this._reviewStatusWrapper =
      document.getElementById('review-status-wrapper');
    this._reviewStatus = document.getElementById('review-status');
    this._editor = document.getElementById('editor');

    this._codeMirror = CodeMirror(this._editor, {
      mode: 'text/x-c++src',
      matchBrackets : true,
      lineNumbers : true,
      readOnly : true,
      foldGutter : true,
      extraKeys : {},
      viewportMargin : 100
    });

    this._createNavigationMenu();
  },

  navigate : function (report, item) {
    if (!item) {
      var items = this._navigationMenuItems.filter(function (navItem) {
        return navItem.report.reportHash === report.reportHash;
      });

      if (!items.length) return;

      item = items[0].widget;
    }

    this._selectedReport.classList.remove('active');
    this._selectedReport = item;
    this._selectedReport.classList.add('active');
    this.setReport(report);
  },

  _createNavigationMenu : function () {
    var that = this;

    var nav = document.getElementById('report-nav');
    var list = document.createElement('ul');
    this._reports.forEach(function (report) {
      var events = report['events'];
      var lastBugEvent = events[events.length - 1];
      var item = document.createElement('li');

      var severity = document.createElement('i');
      severity.className = 'severity-' + report.severity.toLowerCase();

      item.appendChild(severity);
      item.appendChild(document.createTextNode(lastBugEvent.message));

      item.addEventListener('click', function () {
        that.navigate(report, item);
      })
      list.appendChild(item);
      that._navigationMenuItems.push({ report : report, widget : item });
    });

    if (!this._selectedReport && list.childNodes.length) {
      this._selectedReport = list.childNodes[0];
      this._selectedReport.classList.add('active');
    }

    nav.appendChild(list);
  },

  setReport : function (report) {
    this._currentReport = report;
    var events = report['events'];
    var lastBugEvent = events[events.length - 1];
    this.setCurrentBugEvent(lastBugEvent, events.length - 1);
    this.setCheckerName(report.checkerName);
    this.setReviewStatus(report.reviewStatus);

    window.location.hash = '#reportHash=' + report.reportHash;
  },

  setCurrentBugEvent : function (event, idx) {
    this._currentBugEvent = event;
    this.setSourceFileData(this._files[event.location.file]);
    this.drawBugPath();

    this.jumpTo(event.location.line, 0);
    this.highlightBugEvent(event, idx);
  },

  highlightBugEvent : function (event, idx) {
    this._lineWidgets.forEach(function (widget) {
      var lineIdx = widget.node.getAttribute('idx');
      if (parseInt(lineIdx) === idx) {
        widget.node.classList.add('current');
      }
    });
  },

  setCheckerName : function (checkerName) {
    this._checkerName.innerHTML = checkerName;
  },

  setReviewStatus : function (status) {
    if (status) {
      var className =
        'review-status-' + status.toLowerCase().split(' ').join('-');
      this._reviewStatus.className = "review-status " + className;

      this._reviewStatus.innerHTML = status;
      this._reviewStatusWrapper.style.display = 'block';
    } else {
      this._reviewStatusWrapper.style.display = 'none';
    }
  },

  setSourceFileData : function (file) {
    if (this._sourceFileData && file.id === this._sourceFileData.id) {
      return;
    }

    this._sourceFileData = file;
    this._filepath.innerHTML = file.path;
    this._codeMirror.doc.setValue(file.content);
    this._refresh();
  },

  _refresh : function () {
    var that = this;
    setTimeout(function () {
      var fullHeight = parseInt(that._content.clientHeight);
      var headerHeight = that._filepath.clientHeight;

      that._codeMirror.setSize('auto', fullHeight - headerHeight);
      that._codeMirror.refresh();
    }, 200);
  },

  clearBubbles : function () {
    this._lineWidgets.forEach(function (widget) { widget.clear(); });
    this._lineWidgets = [];
  },

  getMessage : function (event, kind) {
    if (kind === 'macro') {
      var name = 'macro expansion' + (event.name ? ': ' + event.name : '');

      return '<span class="tag macro">' + name + '</span>'
        + this.escapeHTML(event.expansion).replace(/(?:\r\n|\r|\n)/g, '<br>');
    } else if (kind === 'note') {
      return '<span class="tag note">note</span>'
        +  this.escapeHTML(event.message).replace(/(?:\r\n|\r|\n)/g, '<br>');
    }
  },

  addExtraPathEvents : function (events, kind) {
    var that = this;

    if (!events) {
      return;
    }

    events.forEach(function (event) {
      if (event.location.file !== that._currentBugEvent.location.file) {
        return;
      }

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + kind);

      var msg = document.createElement('span');
      msg.innerHTML = that.getMessage(event, kind);
      element.appendChild(msg);

      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  drawBugPath : function () {
    var that = this;

    this.clearBubbles();

    this.addExtraPathEvents(this._currentReport.macros, 'macro');
    this.addExtraPathEvents(this._currentReport.notes, 'note');

    // Processing bug path events.
    var currentEvents = this._currentReport.events;
    currentEvents.forEach(function (event, step) {
      if (event.location.file !== that._currentBugEvent.location.file)
        return;

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';
      var type = step === currentEvents.length - 1 ? 'error' : 'info';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + type);
      element.setAttribute('idx', step);

      var enumeration = document.createElement('span');
      enumeration.setAttribute('class', 'checker-enum ' + type);
      enumeration.innerHTML = step + 1;

      if (currentEvents.length > 1)
        element.appendChild(enumeration);

      var prevBugEvent = step - 1;
      if (step > 0) {
        var prevBug = document.createElement('span');
        prevBug.setAttribute('class', 'arrow left-arrow');
        prevBug.addEventListener('click', function () {
          var event = currentEvents[prevBugEvent];
          that.setCurrentBugEvent(event, prevBugEvent);
        });
        element.appendChild(prevBug);
      }

      var msg = document.createElement('span');
      msg.innerHTML = that.escapeHTML(event.message)
        .replace(/(?:\r\n|\r|\n)/g, '<br>');

      element.appendChild(msg);

      var nextBugEvent = step + 1;
      if (nextBugEvent < currentEvents.length) {
        var nextBug = document.createElement('span');
        nextBug.setAttribute('class', 'arrow right-arrow');
        nextBug.addEventListener('click', function () {
          var event = currentEvents[nextBugEvent];
          that.setCurrentBugEvent(event, nextBugEvent);
        });
        element.appendChild(nextBug);
      }


      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  jumpTo : function (line, column) {
    var that = this;

    setTimeout(function () {
      var selPosPixel
        = that._codeMirror.charCoords({ line : line, ch : column }, 'local');
      var editorSize = {
        width  : that._editor.clientWidth,
        height : that._editor.clientHeight
      };

      that._codeMirror.scrollIntoView({
        top    : selPosPixel.top - 100,
        bottom : selPosPixel.top + editorSize.height - 150,
        left   : selPosPixel.left < editorSize.width - 100
               ? 0
               : selPosPixel.left - 50,
        right  : selPosPixel.left < editorSize.width - 100
               ? 10
               : selPosPixel.left + editorSize.width - 100
      });
    }, 0);
  }
}


      var data = {"files": {"0": {"id": 0, "path": "/src/arch/x86/kvm/vmx/nested.c", "content": "// SPDX-License-Identifier: GPL-2.0\n\n#include <linux/objtool.h>\n#include <linux/percpu.h>\n\n#include <asm/debugreg.h>\n#include <asm/mmu_context.h>\n\n#include \"cpuid.h\"\n#include \"hyperv.h\"\n#include \"mmu.h\"\n#include \"nested.h\"\n#include \"pmu.h\"\n#include \"trace.h\"\n#include \"x86.h\"\n\nstatic bool __read_mostly enable_shadow_vmcs = 1;\nmodule_param_named(enable_shadow_vmcs, enable_shadow_vmcs, bool, S_IRUGO);\n\nstatic bool __read_mostly nested_early_check = 0;\nmodule_param(nested_early_check, bool, S_IRUGO);\n\n#define CC(consistency_check)\t\t\t\t\t\t\\\n({\t\t\t\t\t\t\t\t\t\\\n\tbool failed = (consistency_check);\t\t\t\t\\\n\tif (failed)\t\t\t\t\t\t\t\\\n\t\ttrace_kvm_nested_vmenter_failed(#consistency_check, 0);\t\\\n\tfailed;\t\t\t\t\t\t\t\t\\\n})\n\n/*\n * Hyper-V requires all of these, so mark them as supported even though\n * they are just treated the same as all-context.\n */\n#define VMX_VPID_EXTENT_SUPPORTED_MASK\t\t\\\n\t(VMX_VPID_EXTENT_INDIVIDUAL_ADDR_BIT |\t\\\n\tVMX_VPID_EXTENT_SINGLE_CONTEXT_BIT |\t\\\n\tVMX_VPID_EXTENT_GLOBAL_CONTEXT_BIT |\t\\\n\tVMX_VPID_EXTENT_SINGLE_NON_GLOBAL_BIT)\n\n#define VMX_MISC_EMULATED_PREEMPTION_TIMER_RATE 5\n\nenum {\n\tVMX_VMREAD_BITMAP,\n\tVMX_VMWRITE_BITMAP,\n\tVMX_BITMAP_NR\n};\nstatic unsigned long *vmx_bitmap[VMX_BITMAP_NR];\n\n#define vmx_vmread_bitmap                    (vmx_bitmap[VMX_VMREAD_BITMAP])\n#define vmx_vmwrite_bitmap                   (vmx_bitmap[VMX_VMWRITE_BITMAP])\n\nstruct shadow_vmcs_field {\n\tu16\tencoding;\n\tu16\toffset;\n};\nstatic struct shadow_vmcs_field shadow_read_only_fields[] = {\n#define SHADOW_FIELD_RO(x, y) { x, offsetof(struct vmcs12, y) },\n#include \"vmcs_shadow_fields.h\"\n};\nstatic int max_shadow_read_only_fields =\n\tARRAY_SIZE(shadow_read_only_fields);\n\nstatic struct shadow_vmcs_field shadow_read_write_fields[] = {\n#define SHADOW_FIELD_RW(x, y) { x, offsetof(struct vmcs12, y) },\n#include \"vmcs_shadow_fields.h\"\n};\nstatic int max_shadow_read_write_fields =\n\tARRAY_SIZE(shadow_read_write_fields);\n\nstatic void init_vmcs_shadow_fields(void)\n{\n\tint i, j;\n\n\tmemset(vmx_vmread_bitmap, 0xff, PAGE_SIZE);\n\tmemset(vmx_vmwrite_bitmap, 0xff, PAGE_SIZE);\n\n\tfor (i = j = 0; i < max_shadow_read_only_fields; i++) {\n\t\tstruct shadow_vmcs_field entry = shadow_read_only_fields[i];\n\t\tu16 field = entry.encoding;\n\n\t\tif (vmcs_field_width(field) == VMCS_FIELD_WIDTH_U64 &&\n\t\t    (i + 1 == max_shadow_read_only_fields ||\n\t\t     shadow_read_only_fields[i + 1].encoding != field + 1))\n\t\t\tpr_err(\"Missing field from shadow_read_only_field %x\\n\",\n\t\t\t       field + 1);\n\n\t\tclear_bit(field, vmx_vmread_bitmap);\n\t\tif (field & 1)\n#ifdef CONFIG_X86_64\n\t\t\tcontinue;\n#else\n\t\t\tentry.offset += sizeof(u32);\n#endif\n\t\tshadow_read_only_fields[j++] = entry;\n\t}\n\tmax_shadow_read_only_fields = j;\n\n\tfor (i = j = 0; i < max_shadow_read_write_fields; i++) {\n\t\tstruct shadow_vmcs_field entry = shadow_read_write_fields[i];\n\t\tu16 field = entry.encoding;\n\n\t\tif (vmcs_field_width(field) == VMCS_FIELD_WIDTH_U64 &&\n\t\t    (i + 1 == max_shadow_read_write_fields ||\n\t\t     shadow_read_write_fields[i + 1].encoding != field + 1))\n\t\t\tpr_err(\"Missing field from shadow_read_write_field %x\\n\",\n\t\t\t       field + 1);\n\n\t\tWARN_ONCE(field >= GUEST_ES_AR_BYTES &&\n\t\t\t  field <= GUEST_TR_AR_BYTES,\n\t\t\t  \"Update vmcs12_write_any() to drop reserved bits from AR_BYTES\");\n\n\t\t/*\n\t\t * PML and the preemption timer can be emulated, but the\n\t\t * processor cannot vmwrite to fields that don't exist\n\t\t * on bare metal.\n\t\t */\n\t\tswitch (field) {\n\t\tcase GUEST_PML_INDEX:\n\t\t\tif (!cpu_has_vmx_pml())\n\t\t\t\tcontinue;\n\t\t\tbreak;\n\t\tcase VMX_PREEMPTION_TIMER_VALUE:\n\t\t\tif (!cpu_has_vmx_preemption_timer())\n\t\t\t\tcontinue;\n\t\t\tbreak;\n\t\tcase GUEST_INTR_STATUS:\n\t\t\tif (!cpu_has_vmx_apicv())\n\t\t\t\tcontinue;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\tclear_bit(field, vmx_vmwrite_bitmap);\n\t\tclear_bit(field, vmx_vmread_bitmap);\n\t\tif (field & 1)\n#ifdef CONFIG_X86_64\n\t\t\tcontinue;\n#else\n\t\t\tentry.offset += sizeof(u32);\n#endif\n\t\tshadow_read_write_fields[j++] = entry;\n\t}\n\tmax_shadow_read_write_fields = j;\n}\n\n/*\n * The following 3 functions, nested_vmx_succeed()/failValid()/failInvalid(),\n * set the success or error code of an emulated VMX instruction (as specified\n * by Vol 2B, VMX Instruction Reference, \"Conventions\"), and skip the emulated\n * instruction.\n */\nstatic int nested_vmx_succeed(struct kvm_vcpu *vcpu)\n{\n\tvmx_set_rflags(vcpu, vmx_get_rflags(vcpu)\n\t\t\t& ~(X86_EFLAGS_CF | X86_EFLAGS_PF | X86_EFLAGS_AF |\n\t\t\t    X86_EFLAGS_ZF | X86_EFLAGS_SF | X86_EFLAGS_OF));\n\treturn kvm_skip_emulated_instruction(vcpu);\n}\n\nstatic int nested_vmx_failInvalid(struct kvm_vcpu *vcpu)\n{\n\tvmx_set_rflags(vcpu, (vmx_get_rflags(vcpu)\n\t\t\t& ~(X86_EFLAGS_PF | X86_EFLAGS_AF | X86_EFLAGS_ZF |\n\t\t\t    X86_EFLAGS_SF | X86_EFLAGS_OF))\n\t\t\t| X86_EFLAGS_CF);\n\treturn kvm_skip_emulated_instruction(vcpu);\n}\n\nstatic int nested_vmx_failValid(struct kvm_vcpu *vcpu,\n\t\t\t\tu32 vm_instruction_error)\n{\n\tvmx_set_rflags(vcpu, (vmx_get_rflags(vcpu)\n\t\t\t& ~(X86_EFLAGS_CF | X86_EFLAGS_PF | X86_EFLAGS_AF |\n\t\t\t    X86_EFLAGS_SF | X86_EFLAGS_OF))\n\t\t\t| X86_EFLAGS_ZF);\n\tget_vmcs12(vcpu)->vm_instruction_error = vm_instruction_error;\n\t/*\n\t * We don't need to force a shadow sync because\n\t * VM_INSTRUCTION_ERROR is not shadowed\n\t */\n\treturn kvm_skip_emulated_instruction(vcpu);\n}\n\nstatic int nested_vmx_fail(struct kvm_vcpu *vcpu, u32 vm_instruction_error)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\t/*\n\t * failValid writes the error number to the current VMCS, which\n\t * can't be done if there isn't a current VMCS.\n\t */\n\tif (vmx->nested.current_vmptr == -1ull && !vmx->nested.hv_evmcs)\n\t\treturn nested_vmx_failInvalid(vcpu);\n\n\treturn nested_vmx_failValid(vcpu, vm_instruction_error);\n}\n\nstatic void nested_vmx_abort(struct kvm_vcpu *vcpu, u32 indicator)\n{\n\t/* TODO: not to reset guest simply here. */\n\tkvm_make_request(KVM_REQ_TRIPLE_FAULT, vcpu);\n\tpr_debug_ratelimited(\"kvm: nested vmx abort, indicator %d\\n\", indicator);\n}\n\nstatic inline bool vmx_control_verify(u32 control, u32 low, u32 high)\n{\n\treturn fixed_bits_valid(control, low, high);\n}\n\nstatic inline u64 vmx_control_msr(u32 low, u32 high)\n{\n\treturn low | ((u64)high << 32);\n}\n\nstatic void vmx_disable_shadow_vmcs(struct vcpu_vmx *vmx)\n{\n\tsecondary_exec_controls_clearbit(vmx, SECONDARY_EXEC_SHADOW_VMCS);\n\tvmcs_write64(VMCS_LINK_POINTER, -1ull);\n\tvmx->nested.need_vmcs12_to_shadow_sync = false;\n}\n\nstatic inline void nested_release_evmcs(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\tif (!vmx->nested.hv_evmcs)\n\t\treturn;\n\n\tkvm_vcpu_unmap(vcpu, &vmx->nested.hv_evmcs_map, true);\n\tvmx->nested.hv_evmcs_vmptr = 0;\n\tvmx->nested.hv_evmcs = NULL;\n}\n\nstatic void vmx_sync_vmcs_host_state(struct vcpu_vmx *vmx,\n\t\t\t\t     struct loaded_vmcs *prev)\n{\n\tstruct vmcs_host_state *dest, *src;\n\n\tif (unlikely(!vmx->guest_state_loaded))\n\t\treturn;\n\n\tsrc = &prev->host_state;\n\tdest = &vmx->loaded_vmcs->host_state;\n\n\tvmx_set_host_fs_gs(dest, src->fs_sel, src->gs_sel, src->fs_base, src->gs_base);\n\tdest->ldt_sel = src->ldt_sel;\n#ifdef CONFIG_X86_64\n\tdest->ds_sel = src->ds_sel;\n\tdest->es_sel = src->es_sel;\n#endif\n}\n\nstatic void vmx_switch_vmcs(struct kvm_vcpu *vcpu, struct loaded_vmcs *vmcs)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tstruct loaded_vmcs *prev;\n\tint cpu;\n\n\tif (WARN_ON_ONCE(vmx->loaded_vmcs == vmcs))\n\t\treturn;\n\n\tcpu = get_cpu();\n\tprev = vmx->loaded_vmcs;\n\tvmx->loaded_vmcs = vmcs;\n\tvmx_vcpu_load_vmcs(vcpu, cpu, prev);\n\tvmx_sync_vmcs_host_state(vmx, prev);\n\tput_cpu();\n\n\tvmx_register_cache_reset(vcpu);\n}\n\n/*\n * Free whatever needs to be freed from vmx->nested when L1 goes down, or\n * just stops using VMX.\n */\nstatic void free_nested(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\tif (WARN_ON_ONCE(vmx->loaded_vmcs != &vmx->vmcs01))\n\t\tvmx_switch_vmcs(vcpu, &vmx->vmcs01);\n\n\tif (!vmx->nested.vmxon && !vmx->nested.smm.vmxon)\n\t\treturn;\n\n\tkvm_clear_request(KVM_REQ_GET_NESTED_STATE_PAGES, vcpu);\n\n\tvmx->nested.vmxon = false;\n\tvmx->nested.smm.vmxon = false;\n\tfree_vpid(vmx->nested.vpid02);\n\tvmx->nested.posted_intr_nv = -1;\n\tvmx->nested.current_vmptr = -1ull;\n\tif (enable_shadow_vmcs) {\n\t\tvmx_disable_shadow_vmcs(vmx);\n\t\tvmcs_clear(vmx->vmcs01.shadow_vmcs);\n\t\tfree_vmcs(vmx->vmcs01.shadow_vmcs);\n\t\tvmx->vmcs01.shadow_vmcs = NULL;\n\t}\n\tkfree(vmx->nested.cached_vmcs12);\n\tvmx->nested.cached_vmcs12 = NULL;\n\tkfree(vmx->nested.cached_shadow_vmcs12);\n\tvmx->nested.cached_shadow_vmcs12 = NULL;\n\t/* Unpin physical memory we referred to in the vmcs02 */\n\tif (vmx->nested.apic_access_page) {\n\t\tkvm_release_page_clean(vmx->nested.apic_access_page);\n\t\tvmx->nested.apic_access_page = NULL;\n\t}\n\tkvm_vcpu_unmap(vcpu, &vmx->nested.virtual_apic_map, true);\n\tkvm_vcpu_unmap(vcpu, &vmx->nested.pi_desc_map, true);\n\tvmx->nested.pi_desc = NULL;\n\n\tkvm_mmu_free_roots(vcpu, &vcpu->arch.guest_mmu, KVM_MMU_ROOTS_ALL);\n\n\tnested_release_evmcs(vcpu);\n\n\tfree_loaded_vmcs(&vmx->nested.vmcs02);\n}\n\n/*\n * Ensure that the current vmcs of the logical processor is the\n * vmcs01 of the vcpu before calling free_nested().\n */\nvoid nested_vmx_free_vcpu(struct kvm_vcpu *vcpu)\n{\n\tvcpu_load(vcpu);\n\tvmx_leave_nested(vcpu);\n\tvcpu_put(vcpu);\n}\n\nstatic void nested_ept_inject_page_fault(struct kvm_vcpu *vcpu,\n\t\tstruct x86_exception *fault)\n{\n\tstruct vmcs12 *vmcs12 = get_vmcs12(vcpu);\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tu32 vm_exit_reason;\n\tunsigned long exit_qualification = vcpu->arch.exit_qualification;\n\n\tif (vmx->nested.pml_full) {\n\t\tvm_exit_reason = EXIT_REASON_PML_FULL;\n\t\tvmx->nested.pml_full = false;\n\t\texit_qualification &= INTR_INFO_UNBLOCK_NMI;\n\t} else if (fault->error_code & PFERR_RSVD_MASK)\n\t\tvm_exit_reason = EXIT_REASON_EPT_MISCONFIG;\n\telse\n\t\tvm_exit_reason = EXIT_REASON_EPT_VIOLATION;\n\n\tnested_vmx_vmexit(vcpu, vm_exit_reason, 0, exit_qualification);\n\tvmcs12->guest_physical_address = fault->address;\n}\n\nstatic void nested_ept_init_mmu_context(struct kvm_vcpu *vcpu)\n{\n\tWARN_ON(mmu_is_nested(vcpu));\n\n\tvcpu->arch.mmu = &vcpu->arch.guest_mmu;\n\tkvm_init_shadow_ept_mmu(vcpu,\n\t\t\tto_vmx(vcpu)->nested.msrs.ept_caps &\n\t\t\tVMX_EPT_EXECUTE_ONLY_BIT,\n\t\t\tnested_ept_ad_enabled(vcpu),\n\t\t\tnested_ept_get_eptp(vcpu));\n\tvcpu->arch.mmu->get_guest_pgd     = nested_ept_get_eptp;\n\tvcpu->arch.mmu->inject_page_fault = nested_ept_inject_page_fault;\n\tvcpu->arch.mmu->get_pdptr         = kvm_pdptr_read;\n\n\tvcpu->arch.walk_mmu              = &vcpu->arch.nested_mmu;\n}\n\nstatic void nested_ept_uninit_mmu_context(struct kvm_vcpu *vcpu)\n{\n\tvcpu->arch.mmu = &vcpu->arch.root_mmu;\n\tvcpu->arch.walk_mmu = &vcpu->arch.root_mmu;\n}\n\nstatic bool nested_vmx_is_page_fault_vmexit(struct vmcs12 *vmcs12,\n\t\t\t\t\t    u16 error_code)\n{\n\tbool inequality, bit;\n\n\tbit = (vmcs12->exception_bitmap & (1u << PF_VECTOR)) != 0;\n\tinequality =\n\t\t(error_code & vmcs12->page_fault_error_code_mask) !=\n\t\t vmcs12->page_fault_error_code_match;\n\treturn inequality ^ bit;\n}\n\n\n/*\n * KVM wants to inject page-faults which it got to the guest. This function\n * checks whether in a nested guest, we need to inject them to L1 or L2.\n */\nstatic int nested_vmx_check_exception(struct kvm_vcpu *vcpu, unsigned long *exit_qual)\n{\n\tstruct vmcs12 *vmcs12 = get_vmcs12(vcpu);\n\tunsigned int nr = vcpu->arch.exception.nr;\n\tbool has_payload = vcpu->arch.exception.has_payload;\n\tunsigned long payload = vcpu->arch.exception.payload;\n\n\tif (nr == PF_VECTOR) {\n\t\tif (vcpu->arch.exception.nested_apf) {\n\t\t\t*exit_qual = vcpu->arch.apf.nested_apf_token;\n\t\t\treturn 1;\n\t\t}\n\t\tif (nested_vmx_is_page_fault_vmexit(vmcs12,\n\t\t\t\t\t\t    vcpu->arch.exception.error_code)) {\n\t\t\t*exit_qual = has_payload ? payload : vcpu->arch.cr2;\n\t\t\treturn 1;\n\t\t}\n\t} else if (vmcs12->exception_bitmap & (1u << nr)) {\n\t\tif (nr == DB_VECTOR) {\n\t\t\tif (!has_payload) {\n\t\t\t\tpayload = vcpu->arch.dr6;\n\t\t\t\tpayload &= ~(DR6_FIXED_1 | DR6_BT);\n\t\t\t\tpayload ^= DR6_RTM;\n\t\t\t}\n\t\t\t*exit_qual = payload;\n\t\t} else\n\t\t\t*exit_qual = 0;\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\n\nstatic void vmx_inject_page_fault_nested(struct kvm_vcpu *vcpu,\n\t\tstruct x86_exception *fault)\n{\n\tstruct vmcs12 *vmcs12 = get_vmcs12(vcpu);\n\n\tWARN_ON(!is_guest_mode(vcpu));\n\n\tif (nested_vmx_is_page_fault_vmexit(vmcs12, fault->error_code) &&\n\t\t!to_vmx(vcpu)->nested.nested_run_pending) {\n\t\tvmcs12->vm_exit_intr_error_code = fault->error_code;\n\t\tnested_vmx_vmexit(vcpu, EXIT_REASON_EXCEPTION_NMI,\n\t\t\t\t  PF_VECTOR | INTR_TYPE_HARD_EXCEPTION |\n\t\t\t\t  INTR_INFO_DELIVER_CODE_MASK | INTR_INFO_VALID_MASK,\n\t\t\t\t  fault->address);\n\t} else {\n\t\tkvm_inject_page_fault(vcpu, fault);\n\t}\n}\n\nstatic int nested_vmx_check_io_bitmap_controls(struct kvm_vcpu *vcpu,\n\t\t\t\t\t       struct vmcs12 *vmcs12)\n{\n\tif (!nested_cpu_has(vmcs12, CPU_BASED_USE_IO_BITMAPS))\n\t\treturn 0;\n\n\tif (CC(!page_address_valid(vcpu, vmcs12->io_bitmap_a)) ||\n\t    CC(!page_address_valid(vcpu, vmcs12->io_bitmap_b)))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int nested_vmx_check_msr_bitmap_controls(struct kvm_vcpu *vcpu,\n\t\t\t\t\t\tstruct vmcs12 *vmcs12)\n{\n\tif (!nested_cpu_has(vmcs12, CPU_BASED_USE_MSR_BITMAPS))\n\t\treturn 0;\n\n\tif (CC(!page_address_valid(vcpu, vmcs12->msr_bitmap)))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int nested_vmx_check_tpr_shadow_controls(struct kvm_vcpu *vcpu,\n\t\t\t\t\t\tstruct vmcs12 *vmcs12)\n{\n\tif (!nested_cpu_has(vmcs12, CPU_BASED_TPR_SHADOW))\n\t\treturn 0;\n\n\tif (CC(!page_address_valid(vcpu, vmcs12->virtual_apic_page_addr)))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\n/*\n * Check if MSR is intercepted for L01 MSR bitmap.\n */\nstatic bool msr_write_intercepted_l01(struct kvm_vcpu *vcpu, u32 msr)\n{\n\tunsigned long *msr_bitmap;\n\tint f = sizeof(unsigned long);\n\n\tif (!cpu_has_vmx_msr_bitmap())\n\t\treturn true;\n\n\tmsr_bitmap = to_vmx(vcpu)->vmcs01.msr_bitmap;\n\n\tif (msr <= 0x1fff) {\n\t\treturn !!test_bit(msr, msr_bitmap + 0x800 / f);\n\t} else if ((msr >= 0xc0000000) && (msr <= 0xc0001fff)) {\n\t\tmsr &= 0x1fff;\n\t\treturn !!test_bit(msr, msr_bitmap + 0xc00 / f);\n\t}\n\n\treturn true;\n}\n\n/*\n * If a msr is allowed by L0, we should check whether it is allowed by L1.\n * The corresponding bit will be cleared unless both of L0 and L1 allow it.\n */\nstatic void nested_vmx_disable_intercept_for_msr(unsigned long *msr_bitmap_l1,\n\t\t\t\t\t       unsigned long *msr_bitmap_nested,\n\t\t\t\t\t       u32 msr, int type)\n{\n\tint f = sizeof(unsigned long);\n\n\t/*\n\t * See Intel PRM Vol. 3, 20.6.9 (MSR-Bitmap Address). Early manuals\n\t * have the write-low and read-high bitmap offsets the wrong way round.\n\t * We can control MSRs 0x00000000-0x00001fff and 0xc0000000-0xc0001fff.\n\t */\n\tif (msr <= 0x1fff) {\n\t\tif (type & MSR_TYPE_R &&\n\t\t   !test_bit(msr, msr_bitmap_l1 + 0x000 / f))\n\t\t\t/* read-low */\n\t\t\t__clear_bit(msr, msr_bitmap_nested + 0x000 / f);\n\n\t\tif (type & MSR_TYPE_W &&\n\t\t   !test_bit(msr, msr_bitmap_l1 + 0x800 / f))\n\t\t\t/* write-low */\n\t\t\t__clear_bit(msr, msr_bitmap_nested + 0x800 / f);\n\n\t} else if ((msr >= 0xc0000000) && (msr <= 0xc0001fff)) {\n\t\tmsr &= 0x1fff;\n\t\tif (type & MSR_TYPE_R &&\n\t\t   !test_bit(msr, msr_bitmap_l1 + 0x400 / f))\n\t\t\t/* read-high */\n\t\t\t__clear_bit(msr, msr_bitmap_nested + 0x400 / f);\n\n\t\tif (type & MSR_TYPE_W &&\n\t\t   !test_bit(msr, msr_bitmap_l1 + 0xc00 / f))\n\t\t\t/* write-high */\n\t\t\t__clear_bit(msr, msr_bitmap_nested + 0xc00 / f);\n\n\t}\n}\n\nstatic inline void enable_x2apic_msr_intercepts(unsigned long *msr_bitmap)\n{\n\tint msr;\n\n\tfor (msr = 0x800; msr <= 0x8ff; msr += BITS_PER_LONG) {\n\t\tunsigned word = msr / BITS_PER_LONG;\n\n\t\tmsr_bitmap[word] = ~0;\n\t\tmsr_bitmap[word + (0x800 / sizeof(long))] = ~0;\n\t}\n}\n\n/*\n * Merge L0's and L1's MSR bitmap, return false to indicate that\n * we do not use the hardware.\n */\nstatic inline bool nested_vmx_prepare_msr_bitmap(struct kvm_vcpu *vcpu,\n\t\t\t\t\t\t struct vmcs12 *vmcs12)\n{\n\tint msr;\n\tunsigned long *msr_bitmap_l1;\n\tunsigned long *msr_bitmap_l0 = to_vmx(vcpu)->nested.vmcs02.msr_bitmap;\n\tstruct kvm_host_map *map = &to_vmx(vcpu)->nested.msr_bitmap_map;\n\n\t/* Nothing to do if the MSR bitmap is not in use.  */\n\tif (!cpu_has_vmx_msr_bitmap() ||\n\t    !nested_cpu_has(vmcs12, CPU_BASED_USE_MSR_BITMAPS))\n\t\treturn false;\n\n\tif (kvm_vcpu_map(vcpu, gpa_to_gfn(vmcs12->msr_bitmap), map))\n\t\treturn false;\n\n\tmsr_bitmap_l1 = (unsigned long *)map->hva;\n\n\t/*\n\t * To keep the control flow simple, pay eight 8-byte writes (sixteen\n\t * 4-byte writes on 32-bit systems) up front to enable intercepts for\n\t * the x2APIC MSR range and selectively disable them below.\n\t */\n\tenable_x2apic_msr_intercepts(msr_bitmap_l0);\n\n\tif (nested_cpu_has_virt_x2apic_mode(vmcs12)) {\n\t\tif (nested_cpu_has_apic_reg_virt(vmcs12)) {\n\t\t\t/*\n\t\t\t * L0 need not intercept reads for MSRs between 0x800\n\t\t\t * and 0x8ff, it just lets the processor take the value\n\t\t\t * from the virtual-APIC page; take those 256 bits\n\t\t\t * directly from the L1 bitmap.\n\t\t\t */\n\t\t\tfor (msr = 0x800; msr <= 0x8ff; msr += BITS_PER_LONG) {\n\t\t\t\tunsigned word = msr / BITS_PER_LONG;\n\n\t\t\t\tmsr_bitmap_l0[word] = msr_bitmap_l1[word];\n\t\t\t}\n\t\t}\n\n\t\tnested_vmx_disable_intercept_for_msr(\n\t\t\tmsr_bitmap_l1, msr_bitmap_l0,\n\t\t\tX2APIC_MSR(APIC_TASKPRI),\n\t\t\tMSR_TYPE_R | MSR_TYPE_W);\n\n\t\tif (nested_cpu_has_vid(vmcs12)) {\n\t\t\tnested_vmx_disable_intercept_for_msr(\n\t\t\t\tmsr_bitmap_l1, msr_bitmap_l0,\n\t\t\t\tX2APIC_MSR(APIC_EOI),\n\t\t\t\tMSR_TYPE_W);\n\t\t\tnested_vmx_disable_intercept_for_msr(\n\t\t\t\tmsr_bitmap_l1, msr_bitmap_l0,\n\t\t\t\tX2APIC_MSR(APIC_SELF_IPI),\n\t\t\t\tMSR_TYPE_W);\n\t\t}\n\t}\n\n\t/* KVM unconditionally exposes the FS/GS base MSRs to L1. */\n\tnested_vmx_disable_intercept_for_msr(msr_bitmap_l1, msr_bitmap_l0,\n\t\t\t\t\t     MSR_FS_BASE, MSR_TYPE_RW);\n\n\tnested_vmx_disable_intercept_for_msr(msr_bitmap_l1, msr_bitmap_l0,\n\t\t\t\t\t     MSR_GS_BASE, MSR_TYPE_RW);\n\n\tnested_vmx_disable_intercept_for_msr(msr_bitmap_l1, msr_bitmap_l0,\n\t\t\t\t\t     MSR_KERNEL_GS_BASE, MSR_TYPE_RW);\n\n\t/*\n\t * Checking the L0->L1 bitmap is trying to verify two things:\n\t *\n\t * 1. L0 gave a permission to L1 to actually passthrough the MSR. This\n\t *    ensures that we do not accidentally generate an L02 MSR bitmap\n\t *    from the L12 MSR bitmap that is too permissive.\n\t * 2. That L1 or L2s have actually used the MSR. This avoids\n\t *    unnecessarily merging of the bitmap if the MSR is unused. This\n\t *    works properly because we only update the L01 MSR bitmap lazily.\n\t *    So even if L0 should pass L1 these MSRs, the L01 bitmap is only\n\t *    updated to reflect this when L1 (or its L2s) actually write to\n\t *    the MSR.\n\t */\n\tif (!msr_write_intercepted_l01(vcpu, MSR_IA32_SPEC_CTRL))\n\t\tnested_vmx_disable_intercept_for_msr(\n\t\t\t\t\tmsr_bitmap_l1, msr_bitmap_l0,\n\t\t\t\t\tMSR_IA32_SPEC_CTRL,\n\t\t\t\t\tMSR_TYPE_R | MSR_TYPE_W);\n\n\tif (!msr_write_intercepted_l01(vcpu, MSR_IA32_PRED_CMD))\n\t\tnested_vmx_disable_intercept_for_msr(\n\t\t\t\t\tmsr_bitmap_l1, msr_bitmap_l0,\n\t\t\t\t\tMSR_IA32_PRED_CMD,\n\t\t\t\t\tMSR_TYPE_W);\n\n\tkvm_vcpu_unmap(vcpu, &to_vmx(vcpu)->nested.msr_bitmap_map, false);\n\n\treturn true;\n}\n\nstatic void nested_cache_shadow_vmcs12(struct kvm_vcpu *vcpu,\n\t\t\t\t       struct vmcs12 *vmcs12)\n{\n\tstruct kvm_host_map map;\n\tstruct vmcs12 *shadow;\n\n\tif (!nested_cpu_has_shadow_vmcs(vmcs12) ||\n\t    vmcs12->vmcs_link_pointer == -1ull)\n\t\treturn;\n\n\tshadow = get_shadow_vmcs12(vcpu);\n\n\tif (kvm_vcpu_map(vcpu, gpa_to_gfn(vmcs12->vmcs_link_pointer), &map))\n\t\treturn;\n\n\tmemcpy(shadow, map.hva, VMCS12_SIZE);\n\tkvm_vcpu_unmap(vcpu, &map, false);\n}\n\nstatic void nested_flush_cached_shadow_vmcs12(struct kvm_vcpu *vcpu,\n\t\t\t\t\t      struct vmcs12 *vmcs12)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\tif (!nested_cpu_has_shadow_vmcs(vmcs12) ||\n\t    vmcs12->vmcs_link_pointer == -1ull)\n\t\treturn;\n\n\tkvm_write_guest(vmx->vcpu.kvm, vmcs12->vmcs_link_pointer,\n\t\t\tget_shadow_vmcs12(vcpu), VMCS12_SIZE);\n}\n\n/*\n * In nested virtualization, check if L1 has set\n * VM_EXIT_ACK_INTR_ON_EXIT\n */\nstatic bool nested_exit_intr_ack_set(struct kvm_vcpu *vcpu)\n{\n\treturn get_vmcs12(vcpu)->vm_exit_controls &\n\t\tVM_EXIT_ACK_INTR_ON_EXIT;\n}\n\nstatic int nested_vmx_check_apic_access_controls(struct kvm_vcpu *vcpu,\n\t\t\t\t\t  struct vmcs12 *vmcs12)\n{\n\tif (nested_cpu_has2(vmcs12, SECONDARY_EXEC_VIRTUALIZE_APIC_ACCESSES) &&\n\t    CC(!page_address_valid(vcpu, vmcs12->apic_access_addr)))\n\t\treturn -EINVAL;\n\telse\n\t\treturn 0;\n}\n\nstatic int nested_vmx_check_apicv_controls(struct kvm_vcpu *vcpu,\n\t\t\t\t\t   struct vmcs12 *vmcs12)\n{\n\tif (!nested_cpu_has_virt_x2apic_mode(vmcs12) &&\n\t    !nested_cpu_has_apic_reg_virt(vmcs12) &&\n\t    !nested_cpu_has_vid(vmcs12) &&\n\t    !nested_cpu_has_posted_intr(vmcs12))\n\t\treturn 0;\n\n\t/*\n\t * If virtualize x2apic mode is enabled,\n\t * virtualize apic access must be disabled.\n\t */\n\tif (CC(nested_cpu_has_virt_x2apic_mode(vmcs12) &&\n\t       nested_cpu_has2(vmcs12, SECONDARY_EXEC_VIRTUALIZE_APIC_ACCESSES)))\n\t\treturn -EINVAL;\n\n\t/*\n\t * If virtual interrupt delivery is enabled,\n\t * we must exit on external interrupts.\n\t */\n\tif (CC(nested_cpu_has_vid(vmcs12) && !nested_exit_on_intr(vcpu)))\n\t\treturn -EINVAL;\n\n\t/*\n\t * bits 15:8 should be zero in posted_intr_nv,\n\t * the descriptor address has been already checked\n\t * in nested_get_vmcs12_pages.\n\t *\n\t * bits 5:0 of posted_intr_desc_addr should be zero.\n\t */\n\tif (nested_cpu_has_posted_intr(vmcs12) &&\n\t   (CC(!nested_cpu_has_vid(vmcs12)) ||\n\t    CC(!nested_exit_intr_ack_set(vcpu)) ||\n\t    CC((vmcs12->posted_intr_nv & 0xff00)) ||\n\t    CC((vmcs12->posted_intr_desc_addr & 0x3f)) ||\n\t    CC((vmcs12->posted_intr_desc_addr >> cpuid_maxphyaddr(vcpu)))))\n\t\treturn -EINVAL;\n\n\t/* tpr shadow is needed by all apicv features. */\n\tif (CC(!nested_cpu_has(vmcs12, CPU_BASED_TPR_SHADOW)))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int nested_vmx_check_msr_switch(struct kvm_vcpu *vcpu,\n\t\t\t\t       u32 count, u64 addr)\n{\n\tint maxphyaddr;\n\n\tif (count == 0)\n\t\treturn 0;\n\tmaxphyaddr = cpuid_maxphyaddr(vcpu);\n\tif (!IS_ALIGNED(addr, 16) || addr >> maxphyaddr ||\n\t    (addr + count * sizeof(struct vmx_msr_entry) - 1) >> maxphyaddr)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int nested_vmx_check_exit_msr_switch_controls(struct kvm_vcpu *vcpu,\n\t\t\t\t\t\t     struct vmcs12 *vmcs12)\n{\n\tif (CC(nested_vmx_check_msr_switch(vcpu,\n\t\t\t\t\t   vmcs12->vm_exit_msr_load_count,\n\t\t\t\t\t   vmcs12->vm_exit_msr_load_addr)) ||\n\t    CC(nested_vmx_check_msr_switch(vcpu,\n\t\t\t\t\t   vmcs12->vm_exit_msr_store_count,\n\t\t\t\t\t   vmcs12->vm_exit_msr_store_addr)))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int nested_vmx_check_entry_msr_switch_controls(struct kvm_vcpu *vcpu,\n                                                      struct vmcs12 *vmcs12)\n{\n\tif (CC(nested_vmx_check_msr_switch(vcpu,\n\t\t\t\t\t   vmcs12->vm_entry_msr_load_count,\n\t\t\t\t\t   vmcs12->vm_entry_msr_load_addr)))\n                return -EINVAL;\n\n\treturn 0;\n}\n\nstatic int nested_vmx_check_pml_controls(struct kvm_vcpu *vcpu,\n\t\t\t\t\t struct vmcs12 *vmcs12)\n{\n\tif (!nested_cpu_has_pml(vmcs12))\n\t\treturn 0;\n\n\tif (CC(!nested_cpu_has_ept(vmcs12)) ||\n\t    CC(!page_address_valid(vcpu, vmcs12->pml_address)))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int nested_vmx_check_unrestricted_guest_controls(struct kvm_vcpu *vcpu,\n\t\t\t\t\t\t\tstruct vmcs12 *vmcs12)\n{\n\tif (CC(nested_cpu_has2(vmcs12, SECONDARY_EXEC_UNRESTRICTED_GUEST) &&\n\t       !nested_cpu_has_ept(vmcs12)))\n\t\treturn -EINVAL;\n\treturn 0;\n}\n\nstatic int nested_vmx_check_mode_based_ept_exec_controls(struct kvm_vcpu *vcpu,\n\t\t\t\t\t\t\t struct vmcs12 *vmcs12)\n{\n\tif (CC(nested_cpu_has2(vmcs12, SECONDARY_EXEC_MODE_BASED_EPT_EXEC) &&\n\t       !nested_cpu_has_ept(vmcs12)))\n\t\treturn -EINVAL;\n\treturn 0;\n}\n\nstatic int nested_vmx_check_shadow_vmcs_controls(struct kvm_vcpu *vcpu,\n\t\t\t\t\t\t struct vmcs12 *vmcs12)\n{\n\tif (!nested_cpu_has_shadow_vmcs(vmcs12))\n\t\treturn 0;\n\n\tif (CC(!page_address_valid(vcpu, vmcs12->vmread_bitmap)) ||\n\t    CC(!page_address_valid(vcpu, vmcs12->vmwrite_bitmap)))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int nested_vmx_msr_check_common(struct kvm_vcpu *vcpu,\n\t\t\t\t       struct vmx_msr_entry *e)\n{\n\t/* x2APIC MSR accesses are not allowed */\n\tif (CC(vcpu->arch.apic_base & X2APIC_ENABLE && e->index >> 8 == 0x8))\n\t\treturn -EINVAL;\n\tif (CC(e->index == MSR_IA32_UCODE_WRITE) || /* SDM Table 35-2 */\n\t    CC(e->index == MSR_IA32_UCODE_REV))\n\t\treturn -EINVAL;\n\tif (CC(e->reserved != 0))\n\t\treturn -EINVAL;\n\treturn 0;\n}\n\nstatic int nested_vmx_load_msr_check(struct kvm_vcpu *vcpu,\n\t\t\t\t     struct vmx_msr_entry *e)\n{\n\tif (CC(e->index == MSR_FS_BASE) ||\n\t    CC(e->index == MSR_GS_BASE) ||\n\t    CC(e->index == MSR_IA32_SMM_MONITOR_CTL) || /* SMM is not supported */\n\t    nested_vmx_msr_check_common(vcpu, e))\n\t\treturn -EINVAL;\n\treturn 0;\n}\n\nstatic int nested_vmx_store_msr_check(struct kvm_vcpu *vcpu,\n\t\t\t\t      struct vmx_msr_entry *e)\n{\n\tif (CC(e->index == MSR_IA32_SMBASE) || /* SMM is not supported */\n\t    nested_vmx_msr_check_common(vcpu, e))\n\t\treturn -EINVAL;\n\treturn 0;\n}\n\nstatic u32 nested_vmx_max_atomic_switch_msrs(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tu64 vmx_misc = vmx_control_msr(vmx->nested.msrs.misc_low,\n\t\t\t\t       vmx->nested.msrs.misc_high);\n\n\treturn (vmx_misc_max_msr(vmx_misc) + 1) * VMX_MISC_MSR_LIST_MULTIPLIER;\n}\n\n/*\n * Load guest's/host's msr at nested entry/exit.\n * return 0 for success, entry index for failure.\n *\n * One of the failure modes for MSR load/store is when a list exceeds the\n * virtual hardware's capacity. To maintain compatibility with hardware inasmuch\n * as possible, process all valid entries before failing rather than precheck\n * for a capacity violation.\n */\nstatic u32 nested_vmx_load_msr(struct kvm_vcpu *vcpu, u64 gpa, u32 count)\n{\n\tu32 i;\n\tstruct vmx_msr_entry e;\n\tu32 max_msr_list_size = nested_vmx_max_atomic_switch_msrs(vcpu);\n\n\tfor (i = 0; i < count; i++) {\n\t\tif (unlikely(i >= max_msr_list_size))\n\t\t\tgoto fail;\n\n\t\tif (kvm_vcpu_read_guest(vcpu, gpa + i * sizeof(e),\n\t\t\t\t\t&e, sizeof(e))) {\n\t\t\tpr_debug_ratelimited(\n\t\t\t\t\"%s cannot read MSR entry (%u, 0x%08llx)\\n\",\n\t\t\t\t__func__, i, gpa + i * sizeof(e));\n\t\t\tgoto fail;\n\t\t}\n\t\tif (nested_vmx_load_msr_check(vcpu, &e)) {\n\t\t\tpr_debug_ratelimited(\n\t\t\t\t\"%s check failed (%u, 0x%x, 0x%x)\\n\",\n\t\t\t\t__func__, i, e.index, e.reserved);\n\t\t\tgoto fail;\n\t\t}\n\t\tif (kvm_set_msr(vcpu, e.index, e.value)) {\n\t\t\tpr_debug_ratelimited(\n\t\t\t\t\"%s cannot write MSR (%u, 0x%x, 0x%llx)\\n\",\n\t\t\t\t__func__, i, e.index, e.value);\n\t\t\tgoto fail;\n\t\t}\n\t}\n\treturn 0;\nfail:\n\t/* Note, max_msr_list_size is at most 4096, i.e. this can't wrap. */\n\treturn i + 1;\n}\n\nstatic bool nested_vmx_get_vmexit_msr_value(struct kvm_vcpu *vcpu,\n\t\t\t\t\t    u32 msr_index,\n\t\t\t\t\t    u64 *data)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\t/*\n\t * If the L0 hypervisor stored a more accurate value for the TSC that\n\t * does not include the time taken for emulation of the L2->L1\n\t * VM-exit in L0, use the more accurate value.\n\t */\n\tif (msr_index == MSR_IA32_TSC) {\n\t\tint i = vmx_find_loadstore_msr_slot(&vmx->msr_autostore.guest,\n\t\t\t\t\t\t    MSR_IA32_TSC);\n\n\t\tif (i >= 0) {\n\t\t\tu64 val = vmx->msr_autostore.guest.val[i].value;\n\n\t\t\t*data = kvm_read_l1_tsc(vcpu, val);\n\t\t\treturn true;\n\t\t}\n\t}\n\n\tif (kvm_get_msr(vcpu, msr_index, data)) {\n\t\tpr_debug_ratelimited(\"%s cannot read MSR (0x%x)\\n\", __func__,\n\t\t\tmsr_index);\n\t\treturn false;\n\t}\n\treturn true;\n}\n\nstatic bool read_and_check_msr_entry(struct kvm_vcpu *vcpu, u64 gpa, int i,\n\t\t\t\t     struct vmx_msr_entry *e)\n{\n\tif (kvm_vcpu_read_guest(vcpu,\n\t\t\t\tgpa + i * sizeof(*e),\n\t\t\t\te, 2 * sizeof(u32))) {\n\t\tpr_debug_ratelimited(\n\t\t\t\"%s cannot read MSR entry (%u, 0x%08llx)\\n\",\n\t\t\t__func__, i, gpa + i * sizeof(*e));\n\t\treturn false;\n\t}\n\tif (nested_vmx_store_msr_check(vcpu, e)) {\n\t\tpr_debug_ratelimited(\n\t\t\t\"%s check failed (%u, 0x%x, 0x%x)\\n\",\n\t\t\t__func__, i, e->index, e->reserved);\n\t\treturn false;\n\t}\n\treturn true;\n}\n\nstatic int nested_vmx_store_msr(struct kvm_vcpu *vcpu, u64 gpa, u32 count)\n{\n\tu64 data;\n\tu32 i;\n\tstruct vmx_msr_entry e;\n\tu32 max_msr_list_size = nested_vmx_max_atomic_switch_msrs(vcpu);\n\n\tfor (i = 0; i < count; i++) {\n\t\tif (unlikely(i >= max_msr_list_size))\n\t\t\treturn -EINVAL;\n\n\t\tif (!read_and_check_msr_entry(vcpu, gpa, i, &e))\n\t\t\treturn -EINVAL;\n\n\t\tif (!nested_vmx_get_vmexit_msr_value(vcpu, e.index, &data))\n\t\t\treturn -EINVAL;\n\n\t\tif (kvm_vcpu_write_guest(vcpu,\n\t\t\t\t\t gpa + i * sizeof(e) +\n\t\t\t\t\t     offsetof(struct vmx_msr_entry, value),\n\t\t\t\t\t &data, sizeof(data))) {\n\t\t\tpr_debug_ratelimited(\n\t\t\t\t\"%s cannot write MSR (%u, 0x%x, 0x%llx)\\n\",\n\t\t\t\t__func__, i, e.index, data);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic bool nested_msr_store_list_has_msr(struct kvm_vcpu *vcpu, u32 msr_index)\n{\n\tstruct vmcs12 *vmcs12 = get_vmcs12(vcpu);\n\tu32 count = vmcs12->vm_exit_msr_store_count;\n\tu64 gpa = vmcs12->vm_exit_msr_store_addr;\n\tstruct vmx_msr_entry e;\n\tu32 i;\n\n\tfor (i = 0; i < count; i++) {\n\t\tif (!read_and_check_msr_entry(vcpu, gpa, i, &e))\n\t\t\treturn false;\n\n\t\tif (e.index == msr_index)\n\t\t\treturn true;\n\t}\n\treturn false;\n}\n\nstatic void prepare_vmx_msr_autostore_list(struct kvm_vcpu *vcpu,\n\t\t\t\t\t   u32 msr_index)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tstruct vmx_msrs *autostore = &vmx->msr_autostore.guest;\n\tbool in_vmcs12_store_list;\n\tint msr_autostore_slot;\n\tbool in_autostore_list;\n\tint last;\n\n\tmsr_autostore_slot = vmx_find_loadstore_msr_slot(autostore, msr_index);\n\tin_autostore_list = msr_autostore_slot >= 0;\n\tin_vmcs12_store_list = nested_msr_store_list_has_msr(vcpu, msr_index);\n\n\tif (in_vmcs12_store_list && !in_autostore_list) {\n\t\tif (autostore->nr == MAX_NR_LOADSTORE_MSRS) {\n\t\t\t/*\n\t\t\t * Emulated VMEntry does not fail here.  Instead a less\n\t\t\t * accurate value will be returned by\n\t\t\t * nested_vmx_get_vmexit_msr_value() using kvm_get_msr()\n\t\t\t * instead of reading the value from the vmcs02 VMExit\n\t\t\t * MSR-store area.\n\t\t\t */\n\t\t\tpr_warn_ratelimited(\n\t\t\t\t\"Not enough msr entries in msr_autostore.  Can't add msr %x\\n\",\n\t\t\t\tmsr_index);\n\t\t\treturn;\n\t\t}\n\t\tlast = autostore->nr++;\n\t\tautostore->val[last].index = msr_index;\n\t} else if (!in_vmcs12_store_list && in_autostore_list) {\n\t\tlast = --autostore->nr;\n\t\tautostore->val[msr_autostore_slot] = autostore->val[last];\n\t}\n}\n\nstatic bool nested_cr3_valid(struct kvm_vcpu *vcpu, unsigned long val)\n{\n\tunsigned long invalid_mask;\n\n\tinvalid_mask = (~0ULL) << cpuid_maxphyaddr(vcpu);\n\treturn (val & invalid_mask) == 0;\n}\n\n/*\n * Returns true if the MMU needs to be sync'd on nested VM-Enter/VM-Exit.\n * tl;dr: the MMU needs a sync if L0 is using shadow paging and L1 didn't\n * enable VPID for L2 (implying it expects a TLB flush on VMX transitions).\n * Here's why.\n *\n * If EPT is enabled by L0 a sync is never needed:\n * - if it is disabled by L1, then L0 is not shadowing L1 or L2 PTEs, there\n *   cannot be unsync'd SPTEs for either L1 or L2.\n *\n * - if it is also enabled by L1, then L0 doesn't need to sync on VM-Enter\n *   VM-Enter as VM-Enter isn't required to invalidate guest-physical mappings\n *   (irrespective of VPID), i.e. L1 can't rely on the (virtual) CPU to flush\n *   stale guest-physical mappings for L2 from the TLB.  And as above, L0 isn't\n *   shadowing L1 PTEs so there are no unsync'd SPTEs to sync on VM-Exit.\n *\n * If EPT is disabled by L0:\n * - if VPID is enabled by L1 (for L2), the situation is similar to when L1\n *   enables EPT: L0 doesn't need to sync as VM-Enter and VM-Exit aren't\n *   required to invalidate linear mappings (EPT is disabled so there are\n *   no combined or guest-physical mappings), i.e. L1 can't rely on the\n *   (virtual) CPU to flush stale linear mappings for either L2 or itself (L1).\n *\n * - however if VPID is disabled by L1, then a sync is needed as L1 expects all\n *   linear mappings (EPT is disabled so there are no combined or guest-physical\n *   mappings) to be invalidated on both VM-Enter and VM-Exit.\n *\n * Note, this logic is subtly different than nested_has_guest_tlb_tag(), which\n * additionally checks that L2 has been assigned a VPID (when EPT is disabled).\n * Whether or not L2 has been assigned a VPID by L0 is irrelevant with respect\n * to L1's expectations, e.g. L0 needs to invalidate hardware TLB entries if L2\n * doesn't have a unique VPID to prevent reusing L1's entries (assuming L1 has\n * been assigned a VPID), but L0 doesn't need to do a MMU sync because L1\n * doesn't expect stale (virtual) TLB entries to be flushed, i.e. L1 doesn't\n * know that L0 will flush the TLB and so L1 will do INVVPID as needed to flush\n * stale TLB entries, at which point L0 will sync L2's MMU.\n */\nstatic bool nested_vmx_transition_mmu_sync(struct kvm_vcpu *vcpu)\n{\n\treturn !enable_ept && !nested_cpu_has_vpid(get_vmcs12(vcpu));\n}\n\n/*\n * Load guest's/host's cr3 at nested entry/exit.  @nested_ept is true if we are\n * emulating VM-Entry into a guest with EPT enabled.  On failure, the expected\n * Exit Qualification (for a VM-Entry consistency check VM-Exit) is assigned to\n * @entry_failure_code.\n */\nstatic int nested_vmx_load_cr3(struct kvm_vcpu *vcpu, unsigned long cr3, bool nested_ept,\n\t\t\t       enum vm_entry_failure_code *entry_failure_code)\n{\n\tif (CC(!nested_cr3_valid(vcpu, cr3))) {\n\t\t*entry_failure_code = ENTRY_FAIL_DEFAULT;\n\t\treturn -EINVAL;\n\t}\n\n\t/*\n\t * If PAE paging and EPT are both on, CR3 is not used by the CPU and\n\t * must not be dereferenced.\n\t */\n\tif (!nested_ept && is_pae_paging(vcpu) &&\n\t    (cr3 != kvm_read_cr3(vcpu) || pdptrs_changed(vcpu))) {\n\t\tif (CC(!load_pdptrs(vcpu, vcpu->arch.walk_mmu, cr3))) {\n\t\t\t*entry_failure_code = ENTRY_FAIL_PDPTE;\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\t/*\n\t * Unconditionally skip the TLB flush on fast CR3 switch, all TLB\n\t * flushes are handled by nested_vmx_transition_tlb_flush().  See\n\t * nested_vmx_transition_mmu_sync for details on skipping the MMU sync.\n\t */\n\tif (!nested_ept)\n\t\tkvm_mmu_new_pgd(vcpu, cr3, true,\n\t\t\t\t!nested_vmx_transition_mmu_sync(vcpu));\n\n\tvcpu->arch.cr3 = cr3;\n\tkvm_register_mark_available(vcpu, VCPU_EXREG_CR3);\n\n\tkvm_init_mmu(vcpu, false);\n\n\treturn 0;\n}\n\n/*\n * Returns if KVM is able to config CPU to tag TLB entries\n * populated by L2 differently than TLB entries populated\n * by L1.\n *\n * If L0 uses EPT, L1 and L2 run with different EPTP because\n * guest_mode is part of kvm_mmu_page_role. Thus, TLB entries\n * are tagged with different EPTP.\n *\n * If L1 uses VPID and we allocated a vpid02, TLB entries are tagged\n * with different VPID (L1 entries are tagged with vmx->vpid\n * while L2 entries are tagged with vmx->nested.vpid02).\n */\nstatic bool nested_has_guest_tlb_tag(struct kvm_vcpu *vcpu)\n{\n\tstruct vmcs12 *vmcs12 = get_vmcs12(vcpu);\n\n\treturn enable_ept ||\n\t       (nested_cpu_has_vpid(vmcs12) && to_vmx(vcpu)->nested.vpid02);\n}\n\nstatic void nested_vmx_transition_tlb_flush(struct kvm_vcpu *vcpu,\n\t\t\t\t\t    struct vmcs12 *vmcs12,\n\t\t\t\t\t    bool is_vmenter)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\t/*\n\t * If VPID is disabled, linear and combined mappings are flushed on\n\t * VM-Enter/VM-Exit, and guest-physical mappings are valid only for\n\t * their associated EPTP.\n\t */\n\tif (!enable_vpid)\n\t\treturn;\n\n\t/*\n\t * If vmcs12 doesn't use VPID, L1 expects linear and combined mappings\n\t * for *all* contexts to be flushed on VM-Enter/VM-Exit.\n\t *\n\t * If VPID is enabled and used by vmc12, but L2 does not have a unique\n\t * TLB tag (ASID), i.e. EPT is disabled and KVM was unable to allocate\n\t * a VPID for L2, flush the current context as the effective ASID is\n\t * common to both L1 and L2.\n\t *\n\t * Defer the flush so that it runs after vmcs02.EPTP has been set by\n\t * KVM_REQ_LOAD_MMU_PGD (if nested EPT is enabled) and to avoid\n\t * redundant flushes further down the nested pipeline.\n\t *\n\t * If a TLB flush isn't required due to any of the above, and vpid12 is\n\t * changing then the new \"virtual\" VPID (vpid12) will reuse the same\n\t * \"real\" VPID (vpid02), and so needs to be sync'd.  There is no direct\n\t * mapping between vpid02 and vpid12, vpid02 is per-vCPU and reused for\n\t * all nested vCPUs.\n\t */\n\tif (!nested_cpu_has_vpid(vmcs12)) {\n\t\tkvm_make_request(KVM_REQ_TLB_FLUSH, vcpu);\n\t} else if (!nested_has_guest_tlb_tag(vcpu)) {\n\t\tkvm_make_request(KVM_REQ_TLB_FLUSH_CURRENT, vcpu);\n\t} else if (is_vmenter &&\n\t\t   vmcs12->virtual_processor_id != vmx->nested.last_vpid) {\n\t\tvmx->nested.last_vpid = vmcs12->virtual_processor_id;\n\t\tvpid_sync_context(nested_get_vpid02(vcpu));\n\t}\n}\n\nstatic bool is_bitwise_subset(u64 superset, u64 subset, u64 mask)\n{\n\tsuperset &= mask;\n\tsubset &= mask;\n\n\treturn (superset | subset) == superset;\n}\n\nstatic int vmx_restore_vmx_basic(struct vcpu_vmx *vmx, u64 data)\n{\n\tconst u64 feature_and_reserved =\n\t\t/* feature (except bit 48; see below) */\n\t\tBIT_ULL(49) | BIT_ULL(54) | BIT_ULL(55) |\n\t\t/* reserved */\n\t\tBIT_ULL(31) | GENMASK_ULL(47, 45) | GENMASK_ULL(63, 56);\n\tu64 vmx_basic = vmx->nested.msrs.basic;\n\n\tif (!is_bitwise_subset(vmx_basic, data, feature_and_reserved))\n\t\treturn -EINVAL;\n\n\t/*\n\t * KVM does not emulate a version of VMX that constrains physical\n\t * addresses of VMX structures (e.g. VMCS) to 32-bits.\n\t */\n\tif (data & BIT_ULL(48))\n\t\treturn -EINVAL;\n\n\tif (vmx_basic_vmcs_revision_id(vmx_basic) !=\n\t    vmx_basic_vmcs_revision_id(data))\n\t\treturn -EINVAL;\n\n\tif (vmx_basic_vmcs_size(vmx_basic) > vmx_basic_vmcs_size(data))\n\t\treturn -EINVAL;\n\n\tvmx->nested.msrs.basic = data;\n\treturn 0;\n}\n\nstatic int\nvmx_restore_control_msr(struct vcpu_vmx *vmx, u32 msr_index, u64 data)\n{\n\tu64 supported;\n\tu32 *lowp, *highp;\n\n\tswitch (msr_index) {\n\tcase MSR_IA32_VMX_TRUE_PINBASED_CTLS:\n\t\tlowp = &vmx->nested.msrs.pinbased_ctls_low;\n\t\thighp = &vmx->nested.msrs.pinbased_ctls_high;\n\t\tbreak;\n\tcase MSR_IA32_VMX_TRUE_PROCBASED_CTLS:\n\t\tlowp = &vmx->nested.msrs.procbased_ctls_low;\n\t\thighp = &vmx->nested.msrs.procbased_ctls_high;\n\t\tbreak;\n\tcase MSR_IA32_VMX_TRUE_EXIT_CTLS:\n\t\tlowp = &vmx->nested.msrs.exit_ctls_low;\n\t\thighp = &vmx->nested.msrs.exit_ctls_high;\n\t\tbreak;\n\tcase MSR_IA32_VMX_TRUE_ENTRY_CTLS:\n\t\tlowp = &vmx->nested.msrs.entry_ctls_low;\n\t\thighp = &vmx->nested.msrs.entry_ctls_high;\n\t\tbreak;\n\tcase MSR_IA32_VMX_PROCBASED_CTLS2:\n\t\tlowp = &vmx->nested.msrs.secondary_ctls_low;\n\t\thighp = &vmx->nested.msrs.secondary_ctls_high;\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n\n\tsupported = vmx_control_msr(*lowp, *highp);\n\n\t/* Check must-be-1 bits are still 1. */\n\tif (!is_bitwise_subset(data, supported, GENMASK_ULL(31, 0)))\n\t\treturn -EINVAL;\n\n\t/* Check must-be-0 bits are still 0. */\n\tif (!is_bitwise_subset(supported, data, GENMASK_ULL(63, 32)))\n\t\treturn -EINVAL;\n\n\t*lowp = data;\n\t*highp = data >> 32;\n\treturn 0;\n}\n\nstatic int vmx_restore_vmx_misc(struct vcpu_vmx *vmx, u64 data)\n{\n\tconst u64 feature_and_reserved_bits =\n\t\t/* feature */\n\t\tBIT_ULL(5) | GENMASK_ULL(8, 6) | BIT_ULL(14) | BIT_ULL(15) |\n\t\tBIT_ULL(28) | BIT_ULL(29) | BIT_ULL(30) |\n\t\t/* reserved */\n\t\tGENMASK_ULL(13, 9) | BIT_ULL(31);\n\tu64 vmx_misc;\n\n\tvmx_misc = vmx_control_msr(vmx->nested.msrs.misc_low,\n\t\t\t\t   vmx->nested.msrs.misc_high);\n\n\tif (!is_bitwise_subset(vmx_misc, data, feature_and_reserved_bits))\n\t\treturn -EINVAL;\n\n\tif ((vmx->nested.msrs.pinbased_ctls_high &\n\t     PIN_BASED_VMX_PREEMPTION_TIMER) &&\n\t    vmx_misc_preemption_timer_rate(data) !=\n\t    vmx_misc_preemption_timer_rate(vmx_misc))\n\t\treturn -EINVAL;\n\n\tif (vmx_misc_cr3_count(data) > vmx_misc_cr3_count(vmx_misc))\n\t\treturn -EINVAL;\n\n\tif (vmx_misc_max_msr(data) > vmx_misc_max_msr(vmx_misc))\n\t\treturn -EINVAL;\n\n\tif (vmx_misc_mseg_revid(data) != vmx_misc_mseg_revid(vmx_misc))\n\t\treturn -EINVAL;\n\n\tvmx->nested.msrs.misc_low = data;\n\tvmx->nested.msrs.misc_high = data >> 32;\n\n\treturn 0;\n}\n\nstatic int vmx_restore_vmx_ept_vpid_cap(struct vcpu_vmx *vmx, u64 data)\n{\n\tu64 vmx_ept_vpid_cap;\n\n\tvmx_ept_vpid_cap = vmx_control_msr(vmx->nested.msrs.ept_caps,\n\t\t\t\t\t   vmx->nested.msrs.vpid_caps);\n\n\t/* Every bit is either reserved or a feature bit. */\n\tif (!is_bitwise_subset(vmx_ept_vpid_cap, data, -1ULL))\n\t\treturn -EINVAL;\n\n\tvmx->nested.msrs.ept_caps = data;\n\tvmx->nested.msrs.vpid_caps = data >> 32;\n\treturn 0;\n}\n\nstatic int vmx_restore_fixed0_msr(struct vcpu_vmx *vmx, u32 msr_index, u64 data)\n{\n\tu64 *msr;\n\n\tswitch (msr_index) {\n\tcase MSR_IA32_VMX_CR0_FIXED0:\n\t\tmsr = &vmx->nested.msrs.cr0_fixed0;\n\t\tbreak;\n\tcase MSR_IA32_VMX_CR4_FIXED0:\n\t\tmsr = &vmx->nested.msrs.cr4_fixed0;\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n\n\t/*\n\t * 1 bits (which indicates bits which \"must-be-1\" during VMX operation)\n\t * must be 1 in the restored value.\n\t */\n\tif (!is_bitwise_subset(data, *msr, -1ULL))\n\t\treturn -EINVAL;\n\n\t*msr = data;\n\treturn 0;\n}\n\n/*\n * Called when userspace is restoring VMX MSRs.\n *\n * Returns 0 on success, non-0 otherwise.\n */\nint vmx_set_vmx_msr(struct kvm_vcpu *vcpu, u32 msr_index, u64 data)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\t/*\n\t * Don't allow changes to the VMX capability MSRs while the vCPU\n\t * is in VMX operation.\n\t */\n\tif (vmx->nested.vmxon)\n\t\treturn -EBUSY;\n\n\tswitch (msr_index) {\n\tcase MSR_IA32_VMX_BASIC:\n\t\treturn vmx_restore_vmx_basic(vmx, data);\n\tcase MSR_IA32_VMX_PINBASED_CTLS:\n\tcase MSR_IA32_VMX_PROCBASED_CTLS:\n\tcase MSR_IA32_VMX_EXIT_CTLS:\n\tcase MSR_IA32_VMX_ENTRY_CTLS:\n\t\t/*\n\t\t * The \"non-true\" VMX capability MSRs are generated from the\n\t\t * \"true\" MSRs, so we do not support restoring them directly.\n\t\t *\n\t\t * If userspace wants to emulate VMX_BASIC[55]=0, userspace\n\t\t * should restore the \"true\" MSRs with the must-be-1 bits\n\t\t * set according to the SDM Vol 3. A.2 \"RESERVED CONTROLS AND\n\t\t * DEFAULT SETTINGS\".\n\t\t */\n\t\treturn -EINVAL;\n\tcase MSR_IA32_VMX_TRUE_PINBASED_CTLS:\n\tcase MSR_IA32_VMX_TRUE_PROCBASED_CTLS:\n\tcase MSR_IA32_VMX_TRUE_EXIT_CTLS:\n\tcase MSR_IA32_VMX_TRUE_ENTRY_CTLS:\n\tcase MSR_IA32_VMX_PROCBASED_CTLS2:\n\t\treturn vmx_restore_control_msr(vmx, msr_index, data);\n\tcase MSR_IA32_VMX_MISC:\n\t\treturn vmx_restore_vmx_misc(vmx, data);\n\tcase MSR_IA32_VMX_CR0_FIXED0:\n\tcase MSR_IA32_VMX_CR4_FIXED0:\n\t\treturn vmx_restore_fixed0_msr(vmx, msr_index, data);\n\tcase MSR_IA32_VMX_CR0_FIXED1:\n\tcase MSR_IA32_VMX_CR4_FIXED1:\n\t\t/*\n\t\t * These MSRs are generated based on the vCPU's CPUID, so we\n\t\t * do not support restoring them directly.\n\t\t */\n\t\treturn -EINVAL;\n\tcase MSR_IA32_VMX_EPT_VPID_CAP:\n\t\treturn vmx_restore_vmx_ept_vpid_cap(vmx, data);\n\tcase MSR_IA32_VMX_VMCS_ENUM:\n\t\tvmx->nested.msrs.vmcs_enum = data;\n\t\treturn 0;\n\tcase MSR_IA32_VMX_VMFUNC:\n\t\tif (data & ~vmx->nested.msrs.vmfunc_controls)\n\t\t\treturn -EINVAL;\n\t\tvmx->nested.msrs.vmfunc_controls = data;\n\t\treturn 0;\n\tdefault:\n\t\t/*\n\t\t * The rest of the VMX capability MSRs do not support restore.\n\t\t */\n\t\treturn -EINVAL;\n\t}\n}\n\n/* Returns 0 on success, non-0 otherwise. */\nint vmx_get_vmx_msr(struct nested_vmx_msrs *msrs, u32 msr_index, u64 *pdata)\n{\n\tswitch (msr_index) {\n\tcase MSR_IA32_VMX_BASIC:\n\t\t*pdata = msrs->basic;\n\t\tbreak;\n\tcase MSR_IA32_VMX_TRUE_PINBASED_CTLS:\n\tcase MSR_IA32_VMX_PINBASED_CTLS:\n\t\t*pdata = vmx_control_msr(\n\t\t\tmsrs->pinbased_ctls_low,\n\t\t\tmsrs->pinbased_ctls_high);\n\t\tif (msr_index == MSR_IA32_VMX_PINBASED_CTLS)\n\t\t\t*pdata |= PIN_BASED_ALWAYSON_WITHOUT_TRUE_MSR;\n\t\tbreak;\n\tcase MSR_IA32_VMX_TRUE_PROCBASED_CTLS:\n\tcase MSR_IA32_VMX_PROCBASED_CTLS:\n\t\t*pdata = vmx_control_msr(\n\t\t\tmsrs->procbased_ctls_low,\n\t\t\tmsrs->procbased_ctls_high);\n\t\tif (msr_index == MSR_IA32_VMX_PROCBASED_CTLS)\n\t\t\t*pdata |= CPU_BASED_ALWAYSON_WITHOUT_TRUE_MSR;\n\t\tbreak;\n\tcase MSR_IA32_VMX_TRUE_EXIT_CTLS:\n\tcase MSR_IA32_VMX_EXIT_CTLS:\n\t\t*pdata = vmx_control_msr(\n\t\t\tmsrs->exit_ctls_low,\n\t\t\tmsrs->exit_ctls_high);\n\t\tif (msr_index == MSR_IA32_VMX_EXIT_CTLS)\n\t\t\t*pdata |= VM_EXIT_ALWAYSON_WITHOUT_TRUE_MSR;\n\t\tbreak;\n\tcase MSR_IA32_VMX_TRUE_ENTRY_CTLS:\n\tcase MSR_IA32_VMX_ENTRY_CTLS:\n\t\t*pdata = vmx_control_msr(\n\t\t\tmsrs->entry_ctls_low,\n\t\t\tmsrs->entry_ctls_high);\n\t\tif (msr_index == MSR_IA32_VMX_ENTRY_CTLS)\n\t\t\t*pdata |= VM_ENTRY_ALWAYSON_WITHOUT_TRUE_MSR;\n\t\tbreak;\n\tcase MSR_IA32_VMX_MISC:\n\t\t*pdata = vmx_control_msr(\n\t\t\tmsrs->misc_low,\n\t\t\tmsrs->misc_high);\n\t\tbreak;\n\tcase MSR_IA32_VMX_CR0_FIXED0:\n\t\t*pdata = msrs->cr0_fixed0;\n\t\tbreak;\n\tcase MSR_IA32_VMX_CR0_FIXED1:\n\t\t*pdata = msrs->cr0_fixed1;\n\t\tbreak;\n\tcase MSR_IA32_VMX_CR4_FIXED0:\n\t\t*pdata = msrs->cr4_fixed0;\n\t\tbreak;\n\tcase MSR_IA32_VMX_CR4_FIXED1:\n\t\t*pdata = msrs->cr4_fixed1;\n\t\tbreak;\n\tcase MSR_IA32_VMX_VMCS_ENUM:\n\t\t*pdata = msrs->vmcs_enum;\n\t\tbreak;\n\tcase MSR_IA32_VMX_PROCBASED_CTLS2:\n\t\t*pdata = vmx_control_msr(\n\t\t\tmsrs->secondary_ctls_low,\n\t\t\tmsrs->secondary_ctls_high);\n\t\tbreak;\n\tcase MSR_IA32_VMX_EPT_VPID_CAP:\n\t\t*pdata = msrs->ept_caps |\n\t\t\t((u64)msrs->vpid_caps << 32);\n\t\tbreak;\n\tcase MSR_IA32_VMX_VMFUNC:\n\t\t*pdata = msrs->vmfunc_controls;\n\t\tbreak;\n\tdefault:\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\n/*\n * Copy the writable VMCS shadow fields back to the VMCS12, in case they have\n * been modified by the L1 guest.  Note, \"writable\" in this context means\n * \"writable by the guest\", i.e. tagged SHADOW_FIELD_RW; the set of\n * fields tagged SHADOW_FIELD_RO may or may not align with the \"read-only\"\n * VM-exit information fields (which are actually writable if the vCPU is\n * configured to support \"VMWRITE to any supported field in the VMCS\").\n */\nstatic void copy_shadow_to_vmcs12(struct vcpu_vmx *vmx)\n{\n\tstruct vmcs *shadow_vmcs = vmx->vmcs01.shadow_vmcs;\n\tstruct vmcs12 *vmcs12 = get_vmcs12(&vmx->vcpu);\n\tstruct shadow_vmcs_field field;\n\tunsigned long val;\n\tint i;\n\n\tif (WARN_ON(!shadow_vmcs))\n\t\treturn;\n\n\tpreempt_disable();\n\n\tvmcs_load(shadow_vmcs);\n\n\tfor (i = 0; i < max_shadow_read_write_fields; i++) {\n\t\tfield = shadow_read_write_fields[i];\n\t\tval = __vmcs_readl(field.encoding);\n\t\tvmcs12_write_any(vmcs12, field.encoding, field.offset, val);\n\t}\n\n\tvmcs_clear(shadow_vmcs);\n\tvmcs_load(vmx->loaded_vmcs->vmcs);\n\n\tpreempt_enable();\n}\n\nstatic void copy_vmcs12_to_shadow(struct vcpu_vmx *vmx)\n{\n\tconst struct shadow_vmcs_field *fields[] = {\n\t\tshadow_read_write_fields,\n\t\tshadow_read_only_fields\n\t};\n\tconst int max_fields[] = {\n\t\tmax_shadow_read_write_fields,\n\t\tmax_shadow_read_only_fields\n\t};\n\tstruct vmcs *shadow_vmcs = vmx->vmcs01.shadow_vmcs;\n\tstruct vmcs12 *vmcs12 = get_vmcs12(&vmx->vcpu);\n\tstruct shadow_vmcs_field field;\n\tunsigned long val;\n\tint i, q;\n\n\tif (WARN_ON(!shadow_vmcs))\n\t\treturn;\n\n\tvmcs_load(shadow_vmcs);\n\n\tfor (q = 0; q < ARRAY_SIZE(fields); q++) {\n\t\tfor (i = 0; i < max_fields[q]; i++) {\n\t\t\tfield = fields[q][i];\n\t\t\tval = vmcs12_read_any(vmcs12, field.encoding,\n\t\t\t\t\t      field.offset);\n\t\t\t__vmcs_writel(field.encoding, val);\n\t\t}\n\t}\n\n\tvmcs_clear(shadow_vmcs);\n\tvmcs_load(vmx->loaded_vmcs->vmcs);\n}\n\nstatic int copy_enlightened_to_vmcs12(struct vcpu_vmx *vmx)\n{\n\tstruct vmcs12 *vmcs12 = vmx->nested.cached_vmcs12;\n\tstruct hv_enlightened_vmcs *evmcs = vmx->nested.hv_evmcs;\n\n\t/* HV_VMX_ENLIGHTENED_CLEAN_FIELD_NONE */\n\tvmcs12->tpr_threshold = evmcs->tpr_threshold;\n\tvmcs12->guest_rip = evmcs->guest_rip;\n\n\tif (unlikely(!(evmcs->hv_clean_fields &\n\t\t       HV_VMX_ENLIGHTENED_CLEAN_FIELD_GUEST_BASIC))) {\n\t\tvmcs12->guest_rsp = evmcs->guest_rsp;\n\t\tvmcs12->guest_rflags = evmcs->guest_rflags;\n\t\tvmcs12->guest_interruptibility_info =\n\t\t\tevmcs->guest_interruptibility_info;\n\t}\n\n\tif (unlikely(!(evmcs->hv_clean_fields &\n\t\t       HV_VMX_ENLIGHTENED_CLEAN_FIELD_CONTROL_PROC))) {\n\t\tvmcs12->cpu_based_vm_exec_control =\n\t\t\tevmcs->cpu_based_vm_exec_control;\n\t}\n\n\tif (unlikely(!(evmcs->hv_clean_fields &\n\t\t       HV_VMX_ENLIGHTENED_CLEAN_FIELD_CONTROL_EXCPN))) {\n\t\tvmcs12->exception_bitmap = evmcs->exception_bitmap;\n\t}\n\n\tif (unlikely(!(evmcs->hv_clean_fields &\n\t\t       HV_VMX_ENLIGHTENED_CLEAN_FIELD_CONTROL_ENTRY))) {\n\t\tvmcs12->vm_entry_controls = evmcs->vm_entry_controls;\n\t}\n\n\tif (unlikely(!(evmcs->hv_clean_fields &\n\t\t       HV_VMX_ENLIGHTENED_CLEAN_FIELD_CONTROL_EVENT))) {\n\t\tvmcs12->vm_entry_intr_info_field =\n\t\t\tevmcs->vm_entry_intr_info_field;\n\t\tvmcs12->vm_entry_exception_error_code =\n\t\t\tevmcs->vm_entry_exception_error_code;\n\t\tvmcs12->vm_entry_instruction_len =\n\t\t\tevmcs->vm_entry_instruction_len;\n\t}\n\n\tif (unlikely(!(evmcs->hv_clean_fields &\n\t\t       HV_VMX_ENLIGHTENED_CLEAN_FIELD_HOST_GRP1))) {\n\t\tvmcs12->host_ia32_pat = evmcs->host_ia32_pat;\n\t\tvmcs12->host_ia32_efer = evmcs->host_ia32_efer;\n\t\tvmcs12->host_cr0 = evmcs->host_cr0;\n\t\tvmcs12->host_cr3 = evmcs->host_cr3;\n\t\tvmcs12->host_cr4 = evmcs->host_cr4;\n\t\tvmcs12->host_ia32_sysenter_esp = evmcs->host_ia32_sysenter_esp;\n\t\tvmcs12->host_ia32_sysenter_eip = evmcs->host_ia32_sysenter_eip;\n\t\tvmcs12->host_rip = evmcs->host_rip;\n\t\tvmcs12->host_ia32_sysenter_cs = evmcs->host_ia32_sysenter_cs;\n\t\tvmcs12->host_es_selector = evmcs->host_es_selector;\n\t\tvmcs12->host_cs_selector = evmcs->host_cs_selector;\n\t\tvmcs12->host_ss_selector = evmcs->host_ss_selector;\n\t\tvmcs12->host_ds_selector = evmcs->host_ds_selector;\n\t\tvmcs12->host_fs_selector = evmcs->host_fs_selector;\n\t\tvmcs12->host_gs_selector = evmcs->host_gs_selector;\n\t\tvmcs12->host_tr_selector = evmcs->host_tr_selector;\n\t}\n\n\tif (unlikely(!(evmcs->hv_clean_fields &\n\t\t       HV_VMX_ENLIGHTENED_CLEAN_FIELD_CONTROL_GRP1))) {\n\t\tvmcs12->pin_based_vm_exec_control =\n\t\t\tevmcs->pin_based_vm_exec_control;\n\t\tvmcs12->vm_exit_controls = evmcs->vm_exit_controls;\n\t\tvmcs12->secondary_vm_exec_control =\n\t\t\tevmcs->secondary_vm_exec_control;\n\t}\n\n\tif (unlikely(!(evmcs->hv_clean_fields &\n\t\t       HV_VMX_ENLIGHTENED_CLEAN_FIELD_IO_BITMAP))) {\n\t\tvmcs12->io_bitmap_a = evmcs->io_bitmap_a;\n\t\tvmcs12->io_bitmap_b = evmcs->io_bitmap_b;\n\t}\n\n\tif (unlikely(!(evmcs->hv_clean_fields &\n\t\t       HV_VMX_ENLIGHTENED_CLEAN_FIELD_MSR_BITMAP))) {\n\t\tvmcs12->msr_bitmap = evmcs->msr_bitmap;\n\t}\n\n\tif (unlikely(!(evmcs->hv_clean_fields &\n\t\t       HV_VMX_ENLIGHTENED_CLEAN_FIELD_GUEST_GRP2))) {\n\t\tvmcs12->guest_es_base = evmcs->guest_es_base;\n\t\tvmcs12->guest_cs_base = evmcs->guest_cs_base;\n\t\tvmcs12->guest_ss_base = evmcs->guest_ss_base;\n\t\tvmcs12->guest_ds_base = evmcs->guest_ds_base;\n\t\tvmcs12->guest_fs_base = evmcs->guest_fs_base;\n\t\tvmcs12->guest_gs_base = evmcs->guest_gs_base;\n\t\tvmcs12->guest_ldtr_base = evmcs->guest_ldtr_base;\n\t\tvmcs12->guest_tr_base = evmcs->guest_tr_base;\n\t\tvmcs12->guest_gdtr_base = evmcs->guest_gdtr_base;\n\t\tvmcs12->guest_idtr_base = evmcs->guest_idtr_base;\n\t\tvmcs12->guest_es_limit = evmcs->guest_es_limit;\n\t\tvmcs12->guest_cs_limit = evmcs->guest_cs_limit;\n\t\tvmcs12->guest_ss_limit = evmcs->guest_ss_limit;\n\t\tvmcs12->guest_ds_limit = evmcs->guest_ds_limit;\n\t\tvmcs12->guest_fs_limit = evmcs->guest_fs_limit;\n\t\tvmcs12->guest_gs_limit = evmcs->guest_gs_limit;\n\t\tvmcs12->guest_ldtr_limit = evmcs->guest_ldtr_limit;\n\t\tvmcs12->guest_tr_limit = evmcs->guest_tr_limit;\n\t\tvmcs12->guest_gdtr_limit = evmcs->guest_gdtr_limit;\n\t\tvmcs12->guest_idtr_limit = evmcs->guest_idtr_limit;\n\t\tvmcs12->guest_es_ar_bytes = evmcs->guest_es_ar_bytes;\n\t\tvmcs12->guest_cs_ar_bytes = evmcs->guest_cs_ar_bytes;\n\t\tvmcs12->guest_ss_ar_bytes = evmcs->guest_ss_ar_bytes;\n\t\tvmcs12->guest_ds_ar_bytes = evmcs->guest_ds_ar_bytes;\n\t\tvmcs12->guest_fs_ar_bytes = evmcs->guest_fs_ar_bytes;\n\t\tvmcs12->guest_gs_ar_bytes = evmcs->guest_gs_ar_bytes;\n\t\tvmcs12->guest_ldtr_ar_bytes = evmcs->guest_ldtr_ar_bytes;\n\t\tvmcs12->guest_tr_ar_bytes = evmcs->guest_tr_ar_bytes;\n\t\tvmcs12->guest_es_selector = evmcs->guest_es_selector;\n\t\tvmcs12->guest_cs_selector = evmcs->guest_cs_selector;\n\t\tvmcs12->guest_ss_selector = evmcs->guest_ss_selector;\n\t\tvmcs12->guest_ds_selector = evmcs->guest_ds_selector;\n\t\tvmcs12->guest_fs_selector = evmcs->guest_fs_selector;\n\t\tvmcs12->guest_gs_selector = evmcs->guest_gs_selector;\n\t\tvmcs12->guest_ldtr_selector = evmcs->guest_ldtr_selector;\n\t\tvmcs12->guest_tr_selector = evmcs->guest_tr_selector;\n\t}\n\n\tif (unlikely(!(evmcs->hv_clean_fields &\n\t\t       HV_VMX_ENLIGHTENED_CLEAN_FIELD_CONTROL_GRP2))) {\n\t\tvmcs12->tsc_offset = evmcs->tsc_offset;\n\t\tvmcs12->virtual_apic_page_addr = evmcs->virtual_apic_page_addr;\n\t\tvmcs12->xss_exit_bitmap = evmcs->xss_exit_bitmap;\n\t}\n\n\tif (unlikely(!(evmcs->hv_clean_fields &\n\t\t       HV_VMX_ENLIGHTENED_CLEAN_FIELD_CRDR))) {\n\t\tvmcs12->cr0_guest_host_mask = evmcs->cr0_guest_host_mask;\n\t\tvmcs12->cr4_guest_host_mask = evmcs->cr4_guest_host_mask;\n\t\tvmcs12->cr0_read_shadow = evmcs->cr0_read_shadow;\n\t\tvmcs12->cr4_read_shadow = evmcs->cr4_read_shadow;\n\t\tvmcs12->guest_cr0 = evmcs->guest_cr0;\n\t\tvmcs12->guest_cr3 = evmcs->guest_cr3;\n\t\tvmcs12->guest_cr4 = evmcs->guest_cr4;\n\t\tvmcs12->guest_dr7 = evmcs->guest_dr7;\n\t}\n\n\tif (unlikely(!(evmcs->hv_clean_fields &\n\t\t       HV_VMX_ENLIGHTENED_CLEAN_FIELD_HOST_POINTER))) {\n\t\tvmcs12->host_fs_base = evmcs->host_fs_base;\n\t\tvmcs12->host_gs_base = evmcs->host_gs_base;\n\t\tvmcs12->host_tr_base = evmcs->host_tr_base;\n\t\tvmcs12->host_gdtr_base = evmcs->host_gdtr_base;\n\t\tvmcs12->host_idtr_base = evmcs->host_idtr_base;\n\t\tvmcs12->host_rsp = evmcs->host_rsp;\n\t}\n\n\tif (unlikely(!(evmcs->hv_clean_fields &\n\t\t       HV_VMX_ENLIGHTENED_CLEAN_FIELD_CONTROL_XLAT))) {\n\t\tvmcs12->ept_pointer = evmcs->ept_pointer;\n\t\tvmcs12->virtual_processor_id = evmcs->virtual_processor_id;\n\t}\n\n\tif (unlikely(!(evmcs->hv_clean_fields &\n\t\t       HV_VMX_ENLIGHTENED_CLEAN_FIELD_GUEST_GRP1))) {\n\t\tvmcs12->vmcs_link_pointer = evmcs->vmcs_link_pointer;\n\t\tvmcs12->guest_ia32_debugctl = evmcs->guest_ia32_debugctl;\n\t\tvmcs12->guest_ia32_pat = evmcs->guest_ia32_pat;\n\t\tvmcs12->guest_ia32_efer = evmcs->guest_ia32_efer;\n\t\tvmcs12->guest_pdptr0 = evmcs->guest_pdptr0;\n\t\tvmcs12->guest_pdptr1 = evmcs->guest_pdptr1;\n\t\tvmcs12->guest_pdptr2 = evmcs->guest_pdptr2;\n\t\tvmcs12->guest_pdptr3 = evmcs->guest_pdptr3;\n\t\tvmcs12->guest_pending_dbg_exceptions =\n\t\t\tevmcs->guest_pending_dbg_exceptions;\n\t\tvmcs12->guest_sysenter_esp = evmcs->guest_sysenter_esp;\n\t\tvmcs12->guest_sysenter_eip = evmcs->guest_sysenter_eip;\n\t\tvmcs12->guest_bndcfgs = evmcs->guest_bndcfgs;\n\t\tvmcs12->guest_activity_state = evmcs->guest_activity_state;\n\t\tvmcs12->guest_sysenter_cs = evmcs->guest_sysenter_cs;\n\t}\n\n\t/*\n\t * Not used?\n\t * vmcs12->vm_exit_msr_store_addr = evmcs->vm_exit_msr_store_addr;\n\t * vmcs12->vm_exit_msr_load_addr = evmcs->vm_exit_msr_load_addr;\n\t * vmcs12->vm_entry_msr_load_addr = evmcs->vm_entry_msr_load_addr;\n\t * vmcs12->page_fault_error_code_mask =\n\t *\t\tevmcs->page_fault_error_code_mask;\n\t * vmcs12->page_fault_error_code_match =\n\t *\t\tevmcs->page_fault_error_code_match;\n\t * vmcs12->cr3_target_count = evmcs->cr3_target_count;\n\t * vmcs12->vm_exit_msr_store_count = evmcs->vm_exit_msr_store_count;\n\t * vmcs12->vm_exit_msr_load_count = evmcs->vm_exit_msr_load_count;\n\t * vmcs12->vm_entry_msr_load_count = evmcs->vm_entry_msr_load_count;\n\t */\n\n\t/*\n\t * Read only fields:\n\t * vmcs12->guest_physical_address = evmcs->guest_physical_address;\n\t * vmcs12->vm_instruction_error = evmcs->vm_instruction_error;\n\t * vmcs12->vm_exit_reason = evmcs->vm_exit_reason;\n\t * vmcs12->vm_exit_intr_info = evmcs->vm_exit_intr_info;\n\t * vmcs12->vm_exit_intr_error_code = evmcs->vm_exit_intr_error_code;\n\t * vmcs12->idt_vectoring_info_field = evmcs->idt_vectoring_info_field;\n\t * vmcs12->idt_vectoring_error_code = evmcs->idt_vectoring_error_code;\n\t * vmcs12->vm_exit_instruction_len = evmcs->vm_exit_instruction_len;\n\t * vmcs12->vmx_instruction_info = evmcs->vmx_instruction_info;\n\t * vmcs12->exit_qualification = evmcs->exit_qualification;\n\t * vmcs12->guest_linear_address = evmcs->guest_linear_address;\n\t *\n\t * Not present in struct vmcs12:\n\t * vmcs12->exit_io_instruction_ecx = evmcs->exit_io_instruction_ecx;\n\t * vmcs12->exit_io_instruction_esi = evmcs->exit_io_instruction_esi;\n\t * vmcs12->exit_io_instruction_edi = evmcs->exit_io_instruction_edi;\n\t * vmcs12->exit_io_instruction_eip = evmcs->exit_io_instruction_eip;\n\t */\n\n\treturn 0;\n}\n\nstatic int copy_vmcs12_to_enlightened(struct vcpu_vmx *vmx)\n{\n\tstruct vmcs12 *vmcs12 = vmx->nested.cached_vmcs12;\n\tstruct hv_enlightened_vmcs *evmcs = vmx->nested.hv_evmcs;\n\n\t/*\n\t * Should not be changed by KVM:\n\t *\n\t * evmcs->host_es_selector = vmcs12->host_es_selector;\n\t * evmcs->host_cs_selector = vmcs12->host_cs_selector;\n\t * evmcs->host_ss_selector = vmcs12->host_ss_selector;\n\t * evmcs->host_ds_selector = vmcs12->host_ds_selector;\n\t * evmcs->host_fs_selector = vmcs12->host_fs_selector;\n\t * evmcs->host_gs_selector = vmcs12->host_gs_selector;\n\t * evmcs->host_tr_selector = vmcs12->host_tr_selector;\n\t * evmcs->host_ia32_pat = vmcs12->host_ia32_pat;\n\t * evmcs->host_ia32_efer = vmcs12->host_ia32_efer;\n\t * evmcs->host_cr0 = vmcs12->host_cr0;\n\t * evmcs->host_cr3 = vmcs12->host_cr3;\n\t * evmcs->host_cr4 = vmcs12->host_cr4;\n\t * evmcs->host_ia32_sysenter_esp = vmcs12->host_ia32_sysenter_esp;\n\t * evmcs->host_ia32_sysenter_eip = vmcs12->host_ia32_sysenter_eip;\n\t * evmcs->host_rip = vmcs12->host_rip;\n\t * evmcs->host_ia32_sysenter_cs = vmcs12->host_ia32_sysenter_cs;\n\t * evmcs->host_fs_base = vmcs12->host_fs_base;\n\t * evmcs->host_gs_base = vmcs12->host_gs_base;\n\t * evmcs->host_tr_base = vmcs12->host_tr_base;\n\t * evmcs->host_gdtr_base = vmcs12->host_gdtr_base;\n\t * evmcs->host_idtr_base = vmcs12->host_idtr_base;\n\t * evmcs->host_rsp = vmcs12->host_rsp;\n\t * sync_vmcs02_to_vmcs12() doesn't read these:\n\t * evmcs->io_bitmap_a = vmcs12->io_bitmap_a;\n\t * evmcs->io_bitmap_b = vmcs12->io_bitmap_b;\n\t * evmcs->msr_bitmap = vmcs12->msr_bitmap;\n\t * evmcs->ept_pointer = vmcs12->ept_pointer;\n\t * evmcs->xss_exit_bitmap = vmcs12->xss_exit_bitmap;\n\t * evmcs->vm_exit_msr_store_addr = vmcs12->vm_exit_msr_store_addr;\n\t * evmcs->vm_exit_msr_load_addr = vmcs12->vm_exit_msr_load_addr;\n\t * evmcs->vm_entry_msr_load_addr = vmcs12->vm_entry_msr_load_addr;\n\t * evmcs->tpr_threshold = vmcs12->tpr_threshold;\n\t * evmcs->virtual_processor_id = vmcs12->virtual_processor_id;\n\t * evmcs->exception_bitmap = vmcs12->exception_bitmap;\n\t * evmcs->vmcs_link_pointer = vmcs12->vmcs_link_pointer;\n\t * evmcs->pin_based_vm_exec_control = vmcs12->pin_based_vm_exec_control;\n\t * evmcs->vm_exit_controls = vmcs12->vm_exit_controls;\n\t * evmcs->secondary_vm_exec_control = vmcs12->secondary_vm_exec_control;\n\t * evmcs->page_fault_error_code_mask =\n\t *\t\tvmcs12->page_fault_error_code_mask;\n\t * evmcs->page_fault_error_code_match =\n\t *\t\tvmcs12->page_fault_error_code_match;\n\t * evmcs->cr3_target_count = vmcs12->cr3_target_count;\n\t * evmcs->virtual_apic_page_addr = vmcs12->virtual_apic_page_addr;\n\t * evmcs->tsc_offset = vmcs12->tsc_offset;\n\t * evmcs->guest_ia32_debugctl = vmcs12->guest_ia32_debugctl;\n\t * evmcs->cr0_guest_host_mask = vmcs12->cr0_guest_host_mask;\n\t * evmcs->cr4_guest_host_mask = vmcs12->cr4_guest_host_mask;\n\t * evmcs->cr0_read_shadow = vmcs12->cr0_read_shadow;\n\t * evmcs->cr4_read_shadow = vmcs12->cr4_read_shadow;\n\t * evmcs->vm_exit_msr_store_count = vmcs12->vm_exit_msr_store_count;\n\t * evmcs->vm_exit_msr_load_count = vmcs12->vm_exit_msr_load_count;\n\t * evmcs->vm_entry_msr_load_count = vmcs12->vm_entry_msr_load_count;\n\t *\n\t * Not present in struct vmcs12:\n\t * evmcs->exit_io_instruction_ecx = vmcs12->exit_io_instruction_ecx;\n\t * evmcs->exit_io_instruction_esi = vmcs12->exit_io_instruction_esi;\n\t * evmcs->exit_io_instruction_edi = vmcs12->exit_io_instruction_edi;\n\t * evmcs->exit_io_instruction_eip = vmcs12->exit_io_instruction_eip;\n\t */\n\n\tevmcs->guest_es_selector = vmcs12->guest_es_selector;\n\tevmcs->guest_cs_selector = vmcs12->guest_cs_selector;\n\tevmcs->guest_ss_selector = vmcs12->guest_ss_selector;\n\tevmcs->guest_ds_selector = vmcs12->guest_ds_selector;\n\tevmcs->guest_fs_selector = vmcs12->guest_fs_selector;\n\tevmcs->guest_gs_selector = vmcs12->guest_gs_selector;\n\tevmcs->guest_ldtr_selector = vmcs12->guest_ldtr_selector;\n\tevmcs->guest_tr_selector = vmcs12->guest_tr_selector;\n\n\tevmcs->guest_es_limit = vmcs12->guest_es_limit;\n\tevmcs->guest_cs_limit = vmcs12->guest_cs_limit;\n\tevmcs->guest_ss_limit = vmcs12->guest_ss_limit;\n\tevmcs->guest_ds_limit = vmcs12->guest_ds_limit;\n\tevmcs->guest_fs_limit = vmcs12->guest_fs_limit;\n\tevmcs->guest_gs_limit = vmcs12->guest_gs_limit;\n\tevmcs->guest_ldtr_limit = vmcs12->guest_ldtr_limit;\n\tevmcs->guest_tr_limit = vmcs12->guest_tr_limit;\n\tevmcs->guest_gdtr_limit = vmcs12->guest_gdtr_limit;\n\tevmcs->guest_idtr_limit = vmcs12->guest_idtr_limit;\n\n\tevmcs->guest_es_ar_bytes = vmcs12->guest_es_ar_bytes;\n\tevmcs->guest_cs_ar_bytes = vmcs12->guest_cs_ar_bytes;\n\tevmcs->guest_ss_ar_bytes = vmcs12->guest_ss_ar_bytes;\n\tevmcs->guest_ds_ar_bytes = vmcs12->guest_ds_ar_bytes;\n\tevmcs->guest_fs_ar_bytes = vmcs12->guest_fs_ar_bytes;\n\tevmcs->guest_gs_ar_bytes = vmcs12->guest_gs_ar_bytes;\n\tevmcs->guest_ldtr_ar_bytes = vmcs12->guest_ldtr_ar_bytes;\n\tevmcs->guest_tr_ar_bytes = vmcs12->guest_tr_ar_bytes;\n\n\tevmcs->guest_es_base = vmcs12->guest_es_base;\n\tevmcs->guest_cs_base = vmcs12->guest_cs_base;\n\tevmcs->guest_ss_base = vmcs12->guest_ss_base;\n\tevmcs->guest_ds_base = vmcs12->guest_ds_base;\n\tevmcs->guest_fs_base = vmcs12->guest_fs_base;\n\tevmcs->guest_gs_base = vmcs12->guest_gs_base;\n\tevmcs->guest_ldtr_base = vmcs12->guest_ldtr_base;\n\tevmcs->guest_tr_base = vmcs12->guest_tr_base;\n\tevmcs->guest_gdtr_base = vmcs12->guest_gdtr_base;\n\tevmcs->guest_idtr_base = vmcs12->guest_idtr_base;\n\n\tevmcs->guest_ia32_pat = vmcs12->guest_ia32_pat;\n\tevmcs->guest_ia32_efer = vmcs12->guest_ia32_efer;\n\n\tevmcs->guest_pdptr0 = vmcs12->guest_pdptr0;\n\tevmcs->guest_pdptr1 = vmcs12->guest_pdptr1;\n\tevmcs->guest_pdptr2 = vmcs12->guest_pdptr2;\n\tevmcs->guest_pdptr3 = vmcs12->guest_pdptr3;\n\n\tevmcs->guest_pending_dbg_exceptions =\n\t\tvmcs12->guest_pending_dbg_exceptions;\n\tevmcs->guest_sysenter_esp = vmcs12->guest_sysenter_esp;\n\tevmcs->guest_sysenter_eip = vmcs12->guest_sysenter_eip;\n\n\tevmcs->guest_activity_state = vmcs12->guest_activity_state;\n\tevmcs->guest_sysenter_cs = vmcs12->guest_sysenter_cs;\n\n\tevmcs->guest_cr0 = vmcs12->guest_cr0;\n\tevmcs->guest_cr3 = vmcs12->guest_cr3;\n\tevmcs->guest_cr4 = vmcs12->guest_cr4;\n\tevmcs->guest_dr7 = vmcs12->guest_dr7;\n\n\tevmcs->guest_physical_address = vmcs12->guest_physical_address;\n\n\tevmcs->vm_instruction_error = vmcs12->vm_instruction_error;\n\tevmcs->vm_exit_reason = vmcs12->vm_exit_reason;\n\tevmcs->vm_exit_intr_info = vmcs12->vm_exit_intr_info;\n\tevmcs->vm_exit_intr_error_code = vmcs12->vm_exit_intr_error_code;\n\tevmcs->idt_vectoring_info_field = vmcs12->idt_vectoring_info_field;\n\tevmcs->idt_vectoring_error_code = vmcs12->idt_vectoring_error_code;\n\tevmcs->vm_exit_instruction_len = vmcs12->vm_exit_instruction_len;\n\tevmcs->vmx_instruction_info = vmcs12->vmx_instruction_info;\n\n\tevmcs->exit_qualification = vmcs12->exit_qualification;\n\n\tevmcs->guest_linear_address = vmcs12->guest_linear_address;\n\tevmcs->guest_rsp = vmcs12->guest_rsp;\n\tevmcs->guest_rflags = vmcs12->guest_rflags;\n\n\tevmcs->guest_interruptibility_info =\n\t\tvmcs12->guest_interruptibility_info;\n\tevmcs->cpu_based_vm_exec_control = vmcs12->cpu_based_vm_exec_control;\n\tevmcs->vm_entry_controls = vmcs12->vm_entry_controls;\n\tevmcs->vm_entry_intr_info_field = vmcs12->vm_entry_intr_info_field;\n\tevmcs->vm_entry_exception_error_code =\n\t\tvmcs12->vm_entry_exception_error_code;\n\tevmcs->vm_entry_instruction_len = vmcs12->vm_entry_instruction_len;\n\n\tevmcs->guest_rip = vmcs12->guest_rip;\n\n\tevmcs->guest_bndcfgs = vmcs12->guest_bndcfgs;\n\n\treturn 0;\n}\n\n/*\n * This is an equivalent of the nested hypervisor executing the vmptrld\n * instruction.\n */\nstatic enum nested_evmptrld_status nested_vmx_handle_enlightened_vmptrld(\n\tstruct kvm_vcpu *vcpu, bool from_launch)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tbool evmcs_gpa_changed = false;\n\tu64 evmcs_gpa;\n\n\tif (likely(!vmx->nested.enlightened_vmcs_enabled))\n\t\treturn EVMPTRLD_DISABLED;\n\n\tif (!nested_enlightened_vmentry(vcpu, &evmcs_gpa))\n\t\treturn EVMPTRLD_DISABLED;\n\n\tif (unlikely(!vmx->nested.hv_evmcs ||\n\t\t     evmcs_gpa != vmx->nested.hv_evmcs_vmptr)) {\n\t\tif (!vmx->nested.hv_evmcs)\n\t\t\tvmx->nested.current_vmptr = -1ull;\n\n\t\tnested_release_evmcs(vcpu);\n\n\t\tif (kvm_vcpu_map(vcpu, gpa_to_gfn(evmcs_gpa),\n\t\t\t\t &vmx->nested.hv_evmcs_map))\n\t\t\treturn EVMPTRLD_ERROR;\n\n\t\tvmx->nested.hv_evmcs = vmx->nested.hv_evmcs_map.hva;\n\n\t\t/*\n\t\t * Currently, KVM only supports eVMCS version 1\n\t\t * (== KVM_EVMCS_VERSION) and thus we expect guest to set this\n\t\t * value to first u32 field of eVMCS which should specify eVMCS\n\t\t * VersionNumber.\n\t\t *\n\t\t * Guest should be aware of supported eVMCS versions by host by\n\t\t * examining CPUID.0x4000000A.EAX[0:15]. Host userspace VMM is\n\t\t * expected to set this CPUID leaf according to the value\n\t\t * returned in vmcs_version from nested_enable_evmcs().\n\t\t *\n\t\t * However, it turns out that Microsoft Hyper-V fails to comply\n\t\t * to their own invented interface: When Hyper-V use eVMCS, it\n\t\t * just sets first u32 field of eVMCS to revision_id specified\n\t\t * in MSR_IA32_VMX_BASIC. Instead of used eVMCS version number\n\t\t * which is one of the supported versions specified in\n\t\t * CPUID.0x4000000A.EAX[0:15].\n\t\t *\n\t\t * To overcome Hyper-V bug, we accept here either a supported\n\t\t * eVMCS version or VMCS12 revision_id as valid values for first\n\t\t * u32 field of eVMCS.\n\t\t */\n\t\tif ((vmx->nested.hv_evmcs->revision_id != KVM_EVMCS_VERSION) &&\n\t\t    (vmx->nested.hv_evmcs->revision_id != VMCS12_REVISION)) {\n\t\t\tnested_release_evmcs(vcpu);\n\t\t\treturn EVMPTRLD_VMFAIL;\n\t\t}\n\n\t\tvmx->nested.dirty_vmcs12 = true;\n\t\tvmx->nested.hv_evmcs_vmptr = evmcs_gpa;\n\n\t\tevmcs_gpa_changed = true;\n\t\t/*\n\t\t * Unlike normal vmcs12, enlightened vmcs12 is not fully\n\t\t * reloaded from guest's memory (read only fields, fields not\n\t\t * present in struct hv_enlightened_vmcs, ...). Make sure there\n\t\t * are no leftovers.\n\t\t */\n\t\tif (from_launch) {\n\t\t\tstruct vmcs12 *vmcs12 = get_vmcs12(vcpu);\n\t\t\tmemset(vmcs12, 0, sizeof(*vmcs12));\n\t\t\tvmcs12->hdr.revision_id = VMCS12_REVISION;\n\t\t}\n\n\t}\n\n\t/*\n\t * Clean fields data can't be used on VMLAUNCH and when we switch\n\t * between different L2 guests as KVM keeps a single VMCS12 per L1.\n\t */\n\tif (from_launch || evmcs_gpa_changed)\n\t\tvmx->nested.hv_evmcs->hv_clean_fields &=\n\t\t\t~HV_VMX_ENLIGHTENED_CLEAN_FIELD_ALL;\n\n\treturn EVMPTRLD_SUCCEEDED;\n}\n\nvoid nested_sync_vmcs12_to_shadow(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\tif (vmx->nested.hv_evmcs) {\n\t\tcopy_vmcs12_to_enlightened(vmx);\n\t\t/* All fields are clean */\n\t\tvmx->nested.hv_evmcs->hv_clean_fields |=\n\t\t\tHV_VMX_ENLIGHTENED_CLEAN_FIELD_ALL;\n\t} else {\n\t\tcopy_vmcs12_to_shadow(vmx);\n\t}\n\n\tvmx->nested.need_vmcs12_to_shadow_sync = false;\n}\n\nstatic enum hrtimer_restart vmx_preemption_timer_fn(struct hrtimer *timer)\n{\n\tstruct vcpu_vmx *vmx =\n\t\tcontainer_of(timer, struct vcpu_vmx, nested.preemption_timer);\n\n\tvmx->nested.preemption_timer_expired = true;\n\tkvm_make_request(KVM_REQ_EVENT, &vmx->vcpu);\n\tkvm_vcpu_kick(&vmx->vcpu);\n\n\treturn HRTIMER_NORESTART;\n}\n\nstatic u64 vmx_calc_preemption_timer_value(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tstruct vmcs12 *vmcs12 = get_vmcs12(vcpu);\n\n\tu64 l1_scaled_tsc = kvm_read_l1_tsc(vcpu, rdtsc()) >>\n\t\t\t    VMX_MISC_EMULATED_PREEMPTION_TIMER_RATE;\n\n\tif (!vmx->nested.has_preemption_timer_deadline) {\n\t\tvmx->nested.preemption_timer_deadline =\n\t\t\tvmcs12->vmx_preemption_timer_value + l1_scaled_tsc;\n\t\tvmx->nested.has_preemption_timer_deadline = true;\n\t}\n\treturn vmx->nested.preemption_timer_deadline - l1_scaled_tsc;\n}\n\nstatic void vmx_start_preemption_timer(struct kvm_vcpu *vcpu,\n\t\t\t\t\tu64 preemption_timeout)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\t/*\n\t * A timer value of zero is architecturally guaranteed to cause\n\t * a VMExit prior to executing any instructions in the guest.\n\t */\n\tif (preemption_timeout == 0) {\n\t\tvmx_preemption_timer_fn(&vmx->nested.preemption_timer);\n\t\treturn;\n\t}\n\n\tif (vcpu->arch.virtual_tsc_khz == 0)\n\t\treturn;\n\n\tpreemption_timeout <<= VMX_MISC_EMULATED_PREEMPTION_TIMER_RATE;\n\tpreemption_timeout *= 1000000;\n\tdo_div(preemption_timeout, vcpu->arch.virtual_tsc_khz);\n\thrtimer_start(&vmx->nested.preemption_timer,\n\t\t      ktime_add_ns(ktime_get(), preemption_timeout),\n\t\t      HRTIMER_MODE_ABS_PINNED);\n}\n\nstatic u64 nested_vmx_calc_efer(struct vcpu_vmx *vmx, struct vmcs12 *vmcs12)\n{\n\tif (vmx->nested.nested_run_pending &&\n\t    (vmcs12->vm_entry_controls & VM_ENTRY_LOAD_IA32_EFER))\n\t\treturn vmcs12->guest_ia32_efer;\n\telse if (vmcs12->vm_entry_controls & VM_ENTRY_IA32E_MODE)\n\t\treturn vmx->vcpu.arch.efer | (EFER_LMA | EFER_LME);\n\telse\n\t\treturn vmx->vcpu.arch.efer & ~(EFER_LMA | EFER_LME);\n}\n\nstatic void prepare_vmcs02_constant_state(struct vcpu_vmx *vmx)\n{\n\t/*\n\t * If vmcs02 hasn't been initialized, set the constant vmcs02 state\n\t * according to L0's settings (vmcs12 is irrelevant here).  Host\n\t * fields that come from L0 and are not constant, e.g. HOST_CR3,\n\t * will be set as needed prior to VMLAUNCH/VMRESUME.\n\t */\n\tif (vmx->nested.vmcs02_initialized)\n\t\treturn;\n\tvmx->nested.vmcs02_initialized = true;\n\n\t/*\n\t * We don't care what the EPTP value is we just need to guarantee\n\t * it's valid so we don't get a false positive when doing early\n\t * consistency checks.\n\t */\n\tif (enable_ept && nested_early_check)\n\t\tvmcs_write64(EPT_POINTER,\n\t\t\t     construct_eptp(&vmx->vcpu, 0, PT64_ROOT_4LEVEL));\n\n\t/* All VMFUNCs are currently emulated through L0 vmexits.  */\n\tif (cpu_has_vmx_vmfunc())\n\t\tvmcs_write64(VM_FUNCTION_CONTROL, 0);\n\n\tif (cpu_has_vmx_posted_intr())\n\t\tvmcs_write16(POSTED_INTR_NV, POSTED_INTR_NESTED_VECTOR);\n\n\tif (cpu_has_vmx_msr_bitmap())\n\t\tvmcs_write64(MSR_BITMAP, __pa(vmx->nested.vmcs02.msr_bitmap));\n\n\t/*\n\t * The PML address never changes, so it is constant in vmcs02.\n\t * Conceptually we want to copy the PML index from vmcs01 here,\n\t * and then back to vmcs01 on nested vmexit.  But since we flush\n\t * the log and reset GUEST_PML_INDEX on each vmexit, the PML\n\t * index is also effectively constant in vmcs02.\n\t */\n\tif (enable_pml) {\n\t\tvmcs_write64(PML_ADDRESS, page_to_phys(vmx->pml_pg));\n\t\tvmcs_write16(GUEST_PML_INDEX, PML_ENTITY_NUM - 1);\n\t}\n\n\tif (cpu_has_vmx_encls_vmexit())\n\t\tvmcs_write64(ENCLS_EXITING_BITMAP, -1ull);\n\n\t/*\n\t * Set the MSR load/store lists to match L0's settings.  Only the\n\t * addresses are constant (for vmcs02), the counts can change based\n\t * on L2's behavior, e.g. switching to/from long mode.\n\t */\n\tvmcs_write64(VM_EXIT_MSR_STORE_ADDR, __pa(vmx->msr_autostore.guest.val));\n\tvmcs_write64(VM_EXIT_MSR_LOAD_ADDR, __pa(vmx->msr_autoload.host.val));\n\tvmcs_write64(VM_ENTRY_MSR_LOAD_ADDR, __pa(vmx->msr_autoload.guest.val));\n\n\tvmx_set_constant_host_state(vmx);\n}\n\nstatic void prepare_vmcs02_early_rare(struct vcpu_vmx *vmx,\n\t\t\t\t      struct vmcs12 *vmcs12)\n{\n\tprepare_vmcs02_constant_state(vmx);\n\n\tvmcs_write64(VMCS_LINK_POINTER, -1ull);\n\n\tif (enable_vpid) {\n\t\tif (nested_cpu_has_vpid(vmcs12) && vmx->nested.vpid02)\n\t\t\tvmcs_write16(VIRTUAL_PROCESSOR_ID, vmx->nested.vpid02);\n\t\telse\n\t\t\tvmcs_write16(VIRTUAL_PROCESSOR_ID, vmx->vpid);\n\t}\n}\n\nstatic void prepare_vmcs02_early(struct vcpu_vmx *vmx, struct vmcs12 *vmcs12)\n{\n\tu32 exec_control, vmcs12_exec_ctrl;\n\tu64 guest_efer = nested_vmx_calc_efer(vmx, vmcs12);\n\n\tif (vmx->nested.dirty_vmcs12 || vmx->nested.hv_evmcs)\n\t\tprepare_vmcs02_early_rare(vmx, vmcs12);\n\n\t/*\n\t * PIN CONTROLS\n\t */\n\texec_control = vmx_pin_based_exec_ctrl(vmx);\n\texec_control |= (vmcs12->pin_based_vm_exec_control &\n\t\t\t ~PIN_BASED_VMX_PREEMPTION_TIMER);\n\n\t/* Posted interrupts setting is only taken from vmcs12.  */\n\tif (nested_cpu_has_posted_intr(vmcs12)) {\n\t\tvmx->nested.posted_intr_nv = vmcs12->posted_intr_nv;\n\t\tvmx->nested.pi_pending = false;\n\t} else {\n\t\texec_control &= ~PIN_BASED_POSTED_INTR;\n\t}\n\tpin_controls_set(vmx, exec_control);\n\n\t/*\n\t * EXEC CONTROLS\n\t */\n\texec_control = vmx_exec_control(vmx); /* L0's desires */\n\texec_control &= ~CPU_BASED_INTR_WINDOW_EXITING;\n\texec_control &= ~CPU_BASED_NMI_WINDOW_EXITING;\n\texec_control &= ~CPU_BASED_TPR_SHADOW;\n\texec_control |= vmcs12->cpu_based_vm_exec_control;\n\n\tvmx->nested.l1_tpr_threshold = -1;\n\tif (exec_control & CPU_BASED_TPR_SHADOW)\n\t\tvmcs_write32(TPR_THRESHOLD, vmcs12->tpr_threshold);\n#ifdef CONFIG_X86_64\n\telse\n\t\texec_control |= CPU_BASED_CR8_LOAD_EXITING |\n\t\t\t\tCPU_BASED_CR8_STORE_EXITING;\n#endif\n\n\t/*\n\t * A vmexit (to either L1 hypervisor or L0 userspace) is always needed\n\t * for I/O port accesses.\n\t */\n\texec_control |= CPU_BASED_UNCOND_IO_EXITING;\n\texec_control &= ~CPU_BASED_USE_IO_BITMAPS;\n\n\t/*\n\t * This bit will be computed in nested_get_vmcs12_pages, because\n\t * we do not have access to L1's MSR bitmap yet.  For now, keep\n\t * the same bit as before, hoping to avoid multiple VMWRITEs that\n\t * only set/clear this bit.\n\t */\n\texec_control &= ~CPU_BASED_USE_MSR_BITMAPS;\n\texec_control |= exec_controls_get(vmx) & CPU_BASED_USE_MSR_BITMAPS;\n\n\texec_controls_set(vmx, exec_control);\n\n\t/*\n\t * SECONDARY EXEC CONTROLS\n\t */\n\tif (cpu_has_secondary_exec_ctrls()) {\n\t\texec_control = vmx->secondary_exec_control;\n\n\t\t/* Take the following fields only from vmcs12 */\n\t\texec_control &= ~(SECONDARY_EXEC_VIRTUALIZE_APIC_ACCESSES |\n\t\t\t\t  SECONDARY_EXEC_ENABLE_INVPCID |\n\t\t\t\t  SECONDARY_EXEC_ENABLE_RDTSCP |\n\t\t\t\t  SECONDARY_EXEC_XSAVES |\n\t\t\t\t  SECONDARY_EXEC_ENABLE_USR_WAIT_PAUSE |\n\t\t\t\t  SECONDARY_EXEC_VIRTUAL_INTR_DELIVERY |\n\t\t\t\t  SECONDARY_EXEC_APIC_REGISTER_VIRT |\n\t\t\t\t  SECONDARY_EXEC_ENABLE_VMFUNC);\n\t\tif (nested_cpu_has(vmcs12,\n\t\t\t\t   CPU_BASED_ACTIVATE_SECONDARY_CONTROLS)) {\n\t\t\tvmcs12_exec_ctrl = vmcs12->secondary_vm_exec_control &\n\t\t\t\t~SECONDARY_EXEC_ENABLE_PML;\n\t\t\texec_control |= vmcs12_exec_ctrl;\n\t\t}\n\n\t\t/* VMCS shadowing for L2 is emulated for now */\n\t\texec_control &= ~SECONDARY_EXEC_SHADOW_VMCS;\n\n\t\t/*\n\t\t * Preset *DT exiting when emulating UMIP, so that vmx_set_cr4()\n\t\t * will not have to rewrite the controls just for this bit.\n\t\t */\n\t\tif (!boot_cpu_has(X86_FEATURE_UMIP) && vmx_umip_emulated() &&\n\t\t    (vmcs12->guest_cr4 & X86_CR4_UMIP))\n\t\t\texec_control |= SECONDARY_EXEC_DESC;\n\n\t\tif (exec_control & SECONDARY_EXEC_VIRTUAL_INTR_DELIVERY)\n\t\t\tvmcs_write16(GUEST_INTR_STATUS,\n\t\t\t\tvmcs12->guest_intr_status);\n\n\t\tif (!nested_cpu_has2(vmcs12, SECONDARY_EXEC_UNRESTRICTED_GUEST))\n\t\t    exec_control &= ~SECONDARY_EXEC_UNRESTRICTED_GUEST;\n\n\t\tsecondary_exec_controls_set(vmx, exec_control);\n\t}\n\n\t/*\n\t * ENTRY CONTROLS\n\t *\n\t * vmcs12's VM_{ENTRY,EXIT}_LOAD_IA32_EFER and VM_ENTRY_IA32E_MODE\n\t * are emulated by vmx_set_efer() in prepare_vmcs02(), but speculate\n\t * on the related bits (if supported by the CPU) in the hope that\n\t * we can avoid VMWrites during vmx_set_efer().\n\t */\n\texec_control = (vmcs12->vm_entry_controls | vmx_vmentry_ctrl()) &\n\t\t\t~VM_ENTRY_IA32E_MODE & ~VM_ENTRY_LOAD_IA32_EFER;\n\tif (cpu_has_load_ia32_efer()) {\n\t\tif (guest_efer & EFER_LMA)\n\t\t\texec_control |= VM_ENTRY_IA32E_MODE;\n\t\tif (guest_efer != host_efer)\n\t\t\texec_control |= VM_ENTRY_LOAD_IA32_EFER;\n\t}\n\tvm_entry_controls_set(vmx, exec_control);\n\n\t/*\n\t * EXIT CONTROLS\n\t *\n\t * L2->L1 exit controls are emulated - the hardware exit is to L0 so\n\t * we should use its exit controls. Note that VM_EXIT_LOAD_IA32_EFER\n\t * bits may be modified by vmx_set_efer() in prepare_vmcs02().\n\t */\n\texec_control = vmx_vmexit_ctrl();\n\tif (cpu_has_load_ia32_efer() && guest_efer != host_efer)\n\t\texec_control |= VM_EXIT_LOAD_IA32_EFER;\n\tvm_exit_controls_set(vmx, exec_control);\n\n\t/*\n\t * Interrupt/Exception Fields\n\t */\n\tif (vmx->nested.nested_run_pending) {\n\t\tvmcs_write32(VM_ENTRY_INTR_INFO_FIELD,\n\t\t\t     vmcs12->vm_entry_intr_info_field);\n\t\tvmcs_write32(VM_ENTRY_EXCEPTION_ERROR_CODE,\n\t\t\t     vmcs12->vm_entry_exception_error_code);\n\t\tvmcs_write32(VM_ENTRY_INSTRUCTION_LEN,\n\t\t\t     vmcs12->vm_entry_instruction_len);\n\t\tvmcs_write32(GUEST_INTERRUPTIBILITY_INFO,\n\t\t\t     vmcs12->guest_interruptibility_info);\n\t\tvmx->loaded_vmcs->nmi_known_unmasked =\n\t\t\t!(vmcs12->guest_interruptibility_info & GUEST_INTR_STATE_NMI);\n\t} else {\n\t\tvmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);\n\t}\n}\n\nstatic void prepare_vmcs02_rare(struct vcpu_vmx *vmx, struct vmcs12 *vmcs12)\n{\n\tstruct hv_enlightened_vmcs *hv_evmcs = vmx->nested.hv_evmcs;\n\n\tif (!hv_evmcs || !(hv_evmcs->hv_clean_fields &\n\t\t\t   HV_VMX_ENLIGHTENED_CLEAN_FIELD_GUEST_GRP2)) {\n\t\tvmcs_write16(GUEST_ES_SELECTOR, vmcs12->guest_es_selector);\n\t\tvmcs_write16(GUEST_CS_SELECTOR, vmcs12->guest_cs_selector);\n\t\tvmcs_write16(GUEST_SS_SELECTOR, vmcs12->guest_ss_selector);\n\t\tvmcs_write16(GUEST_DS_SELECTOR, vmcs12->guest_ds_selector);\n\t\tvmcs_write16(GUEST_FS_SELECTOR, vmcs12->guest_fs_selector);\n\t\tvmcs_write16(GUEST_GS_SELECTOR, vmcs12->guest_gs_selector);\n\t\tvmcs_write16(GUEST_LDTR_SELECTOR, vmcs12->guest_ldtr_selector);\n\t\tvmcs_write16(GUEST_TR_SELECTOR, vmcs12->guest_tr_selector);\n\t\tvmcs_write32(GUEST_ES_LIMIT, vmcs12->guest_es_limit);\n\t\tvmcs_write32(GUEST_CS_LIMIT, vmcs12->guest_cs_limit);\n\t\tvmcs_write32(GUEST_SS_LIMIT, vmcs12->guest_ss_limit);\n\t\tvmcs_write32(GUEST_DS_LIMIT, vmcs12->guest_ds_limit);\n\t\tvmcs_write32(GUEST_FS_LIMIT, vmcs12->guest_fs_limit);\n\t\tvmcs_write32(GUEST_GS_LIMIT, vmcs12->guest_gs_limit);\n\t\tvmcs_write32(GUEST_LDTR_LIMIT, vmcs12->guest_ldtr_limit);\n\t\tvmcs_write32(GUEST_TR_LIMIT, vmcs12->guest_tr_limit);\n\t\tvmcs_write32(GUEST_GDTR_LIMIT, vmcs12->guest_gdtr_limit);\n\t\tvmcs_write32(GUEST_IDTR_LIMIT, vmcs12->guest_idtr_limit);\n\t\tvmcs_write32(GUEST_CS_AR_BYTES, vmcs12->guest_cs_ar_bytes);\n\t\tvmcs_write32(GUEST_SS_AR_BYTES, vmcs12->guest_ss_ar_bytes);\n\t\tvmcs_write32(GUEST_ES_AR_BYTES, vmcs12->guest_es_ar_bytes);\n\t\tvmcs_write32(GUEST_DS_AR_BYTES, vmcs12->guest_ds_ar_bytes);\n\t\tvmcs_write32(GUEST_FS_AR_BYTES, vmcs12->guest_fs_ar_bytes);\n\t\tvmcs_write32(GUEST_GS_AR_BYTES, vmcs12->guest_gs_ar_bytes);\n\t\tvmcs_write32(GUEST_LDTR_AR_BYTES, vmcs12->guest_ldtr_ar_bytes);\n\t\tvmcs_write32(GUEST_TR_AR_BYTES, vmcs12->guest_tr_ar_bytes);\n\t\tvmcs_writel(GUEST_ES_BASE, vmcs12->guest_es_base);\n\t\tvmcs_writel(GUEST_CS_BASE, vmcs12->guest_cs_base);\n\t\tvmcs_writel(GUEST_SS_BASE, vmcs12->guest_ss_base);\n\t\tvmcs_writel(GUEST_DS_BASE, vmcs12->guest_ds_base);\n\t\tvmcs_writel(GUEST_FS_BASE, vmcs12->guest_fs_base);\n\t\tvmcs_writel(GUEST_GS_BASE, vmcs12->guest_gs_base);\n\t\tvmcs_writel(GUEST_LDTR_BASE, vmcs12->guest_ldtr_base);\n\t\tvmcs_writel(GUEST_TR_BASE, vmcs12->guest_tr_base);\n\t\tvmcs_writel(GUEST_GDTR_BASE, vmcs12->guest_gdtr_base);\n\t\tvmcs_writel(GUEST_IDTR_BASE, vmcs12->guest_idtr_base);\n\n\t\tvmx->segment_cache.bitmask = 0;\n\t}\n\n\tif (!hv_evmcs || !(hv_evmcs->hv_clean_fields &\n\t\t\t   HV_VMX_ENLIGHTENED_CLEAN_FIELD_GUEST_GRP1)) {\n\t\tvmcs_write32(GUEST_SYSENTER_CS, vmcs12->guest_sysenter_cs);\n\t\tvmcs_writel(GUEST_PENDING_DBG_EXCEPTIONS,\n\t\t\t    vmcs12->guest_pending_dbg_exceptions);\n\t\tvmcs_writel(GUEST_SYSENTER_ESP, vmcs12->guest_sysenter_esp);\n\t\tvmcs_writel(GUEST_SYSENTER_EIP, vmcs12->guest_sysenter_eip);\n\n\t\t/*\n\t\t * L1 may access the L2's PDPTR, so save them to construct\n\t\t * vmcs12\n\t\t */\n\t\tif (enable_ept) {\n\t\t\tvmcs_write64(GUEST_PDPTR0, vmcs12->guest_pdptr0);\n\t\t\tvmcs_write64(GUEST_PDPTR1, vmcs12->guest_pdptr1);\n\t\t\tvmcs_write64(GUEST_PDPTR2, vmcs12->guest_pdptr2);\n\t\t\tvmcs_write64(GUEST_PDPTR3, vmcs12->guest_pdptr3);\n\t\t}\n\n\t\tif (kvm_mpx_supported() && vmx->nested.nested_run_pending &&\n\t\t    (vmcs12->vm_entry_controls & VM_ENTRY_LOAD_BNDCFGS))\n\t\t\tvmcs_write64(GUEST_BNDCFGS, vmcs12->guest_bndcfgs);\n\t}\n\n\tif (nested_cpu_has_xsaves(vmcs12))\n\t\tvmcs_write64(XSS_EXIT_BITMAP, vmcs12->xss_exit_bitmap);\n\n\t/*\n\t * Whether page-faults are trapped is determined by a combination of\n\t * 3 settings: PFEC_MASK, PFEC_MATCH and EXCEPTION_BITMAP.PF.  If L0\n\t * doesn't care about page faults then we should set all of these to\n\t * L1's desires. However, if L0 does care about (some) page faults, it\n\t * is not easy (if at all possible?) to merge L0 and L1's desires, we\n\t * simply ask to exit on each and every L2 page fault. This is done by\n\t * setting MASK=MATCH=0 and (see below) EB.PF=1.\n\t * Note that below we don't need special code to set EB.PF beyond the\n\t * \"or\"ing of the EB of vmcs01 and vmcs12, because when enable_ept,\n\t * vmcs01's EB.PF is 0 so the \"or\" will take vmcs12's value, and when\n\t * !enable_ept, EB.PF is 1, so the \"or\" will always be 1.\n\t */\n\tif (vmx_need_pf_intercept(&vmx->vcpu)) {\n\t\t/*\n\t\t * TODO: if both L0 and L1 need the same MASK and MATCH,\n\t\t * go ahead and use it?\n\t\t */\n\t\tvmcs_write32(PAGE_FAULT_ERROR_CODE_MASK, 0);\n\t\tvmcs_write32(PAGE_FAULT_ERROR_CODE_MATCH, 0);\n\t} else {\n\t\tvmcs_write32(PAGE_FAULT_ERROR_CODE_MASK, vmcs12->page_fault_error_code_mask);\n\t\tvmcs_write32(PAGE_FAULT_ERROR_CODE_MATCH, vmcs12->page_fault_error_code_match);\n\t}\n\n\tif (cpu_has_vmx_apicv()) {\n\t\tvmcs_write64(EOI_EXIT_BITMAP0, vmcs12->eoi_exit_bitmap0);\n\t\tvmcs_write64(EOI_EXIT_BITMAP1, vmcs12->eoi_exit_bitmap1);\n\t\tvmcs_write64(EOI_EXIT_BITMAP2, vmcs12->eoi_exit_bitmap2);\n\t\tvmcs_write64(EOI_EXIT_BITMAP3, vmcs12->eoi_exit_bitmap3);\n\t}\n\n\t/*\n\t * Make sure the msr_autostore list is up to date before we set the\n\t * count in the vmcs02.\n\t */\n\tprepare_vmx_msr_autostore_list(&vmx->vcpu, MSR_IA32_TSC);\n\n\tvmcs_write32(VM_EXIT_MSR_STORE_COUNT, vmx->msr_autostore.guest.nr);\n\tvmcs_write32(VM_EXIT_MSR_LOAD_COUNT, vmx->msr_autoload.host.nr);\n\tvmcs_write32(VM_ENTRY_MSR_LOAD_COUNT, vmx->msr_autoload.guest.nr);\n\n\tset_cr4_guest_host_mask(vmx);\n}\n\n/*\n * prepare_vmcs02 is called when the L1 guest hypervisor runs its nested\n * L2 guest. L1 has a vmcs for L2 (vmcs12), and this function \"merges\" it\n * with L0's requirements for its guest (a.k.a. vmcs01), so we can run the L2\n * guest in a way that will both be appropriate to L1's requests, and our\n * needs. In addition to modifying the active vmcs (which is vmcs02), this\n * function also has additional necessary side-effects, like setting various\n * vcpu->arch fields.\n * Returns 0 on success, 1 on failure. Invalid state exit qualification code\n * is assigned to entry_failure_code on failure.\n */\nstatic int prepare_vmcs02(struct kvm_vcpu *vcpu, struct vmcs12 *vmcs12,\n\t\t\t  enum vm_entry_failure_code *entry_failure_code)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tstruct hv_enlightened_vmcs *hv_evmcs = vmx->nested.hv_evmcs;\n\tbool load_guest_pdptrs_vmcs12 = false;\n\n\tif (vmx->nested.dirty_vmcs12 || hv_evmcs) {\n\t\tprepare_vmcs02_rare(vmx, vmcs12);\n\t\tvmx->nested.dirty_vmcs12 = false;\n\n\t\tload_guest_pdptrs_vmcs12 = !hv_evmcs ||\n\t\t\t!(hv_evmcs->hv_clean_fields &\n\t\t\t  HV_VMX_ENLIGHTENED_CLEAN_FIELD_GUEST_GRP1);\n\t}\n\n\tif (vmx->nested.nested_run_pending &&\n\t    (vmcs12->vm_entry_controls & VM_ENTRY_LOAD_DEBUG_CONTROLS)) {\n\t\tkvm_set_dr(vcpu, 7, vmcs12->guest_dr7);\n\t\tvmcs_write64(GUEST_IA32_DEBUGCTL, vmcs12->guest_ia32_debugctl);\n\t} else {\n\t\tkvm_set_dr(vcpu, 7, vcpu->arch.dr7);\n\t\tvmcs_write64(GUEST_IA32_DEBUGCTL, vmx->nested.vmcs01_debugctl);\n\t}\n\tif (kvm_mpx_supported() && (!vmx->nested.nested_run_pending ||\n\t    !(vmcs12->vm_entry_controls & VM_ENTRY_LOAD_BNDCFGS)))\n\t\tvmcs_write64(GUEST_BNDCFGS, vmx->nested.vmcs01_guest_bndcfgs);\n\tvmx_set_rflags(vcpu, vmcs12->guest_rflags);\n\n\t/* EXCEPTION_BITMAP and CR0_GUEST_HOST_MASK should basically be the\n\t * bitwise-or of what L1 wants to trap for L2, and what we want to\n\t * trap. Note that CR0.TS also needs updating - we do this later.\n\t */\n\tupdate_exception_bitmap(vcpu);\n\tvcpu->arch.cr0_guest_owned_bits &= ~vmcs12->cr0_guest_host_mask;\n\tvmcs_writel(CR0_GUEST_HOST_MASK, ~vcpu->arch.cr0_guest_owned_bits);\n\n\tif (vmx->nested.nested_run_pending &&\n\t    (vmcs12->vm_entry_controls & VM_ENTRY_LOAD_IA32_PAT)) {\n\t\tvmcs_write64(GUEST_IA32_PAT, vmcs12->guest_ia32_pat);\n\t\tvcpu->arch.pat = vmcs12->guest_ia32_pat;\n\t} else if (vmcs_config.vmentry_ctrl & VM_ENTRY_LOAD_IA32_PAT) {\n\t\tvmcs_write64(GUEST_IA32_PAT, vmx->vcpu.arch.pat);\n\t}\n\n\tvmcs_write64(TSC_OFFSET, vcpu->arch.tsc_offset);\n\n\tif (kvm_has_tsc_control)\n\t\tdecache_tsc_multiplier(vmx);\n\n\tnested_vmx_transition_tlb_flush(vcpu, vmcs12, true);\n\n\tif (nested_cpu_has_ept(vmcs12))\n\t\tnested_ept_init_mmu_context(vcpu);\n\n\t/*\n\t * This sets GUEST_CR0 to vmcs12->guest_cr0, possibly modifying those\n\t * bits which we consider mandatory enabled.\n\t * The CR0_READ_SHADOW is what L2 should have expected to read given\n\t * the specifications by L1; It's not enough to take\n\t * vmcs12->cr0_read_shadow because on our cr0_guest_host_mask we we\n\t * have more bits than L1 expected.\n\t */\n\tvmx_set_cr0(vcpu, vmcs12->guest_cr0);\n\tvmcs_writel(CR0_READ_SHADOW, nested_read_cr0(vmcs12));\n\n\tvmx_set_cr4(vcpu, vmcs12->guest_cr4);\n\tvmcs_writel(CR4_READ_SHADOW, nested_read_cr4(vmcs12));\n\n\tvcpu->arch.efer = nested_vmx_calc_efer(vmx, vmcs12);\n\t/* Note: may modify VM_ENTRY/EXIT_CONTROLS and GUEST/HOST_IA32_EFER */\n\tvmx_set_efer(vcpu, vcpu->arch.efer);\n\n\t/*\n\t * Guest state is invalid and unrestricted guest is disabled,\n\t * which means L1 attempted VMEntry to L2 with invalid state.\n\t * Fail the VMEntry.\n\t */\n\tif (CC(!vmx_guest_state_valid(vcpu))) {\n\t\t*entry_failure_code = ENTRY_FAIL_DEFAULT;\n\t\treturn -EINVAL;\n\t}\n\n\t/* Shadow page tables on either EPT or shadow page tables. */\n\tif (nested_vmx_load_cr3(vcpu, vmcs12->guest_cr3, nested_cpu_has_ept(vmcs12),\n\t\t\t\tentry_failure_code))\n\t\treturn -EINVAL;\n\n\t/*\n\t * Immediately write vmcs02.GUEST_CR3.  It will be propagated to vmcs12\n\t * on nested VM-Exit, which can occur without actually running L2 and\n\t * thus without hitting vmx_load_mmu_pgd(), e.g. if L1 is entering L2 with\n\t * vmcs12.GUEST_ACTIVITYSTATE=HLT, in which case KVM will intercept the\n\t * transition to HLT instead of running L2.\n\t */\n\tif (enable_ept)\n\t\tvmcs_writel(GUEST_CR3, vmcs12->guest_cr3);\n\n\t/* Late preparation of GUEST_PDPTRs now that EFER and CRs are set. */\n\tif (load_guest_pdptrs_vmcs12 && nested_cpu_has_ept(vmcs12) &&\n\t    is_pae_paging(vcpu)) {\n\t\tvmcs_write64(GUEST_PDPTR0, vmcs12->guest_pdptr0);\n\t\tvmcs_write64(GUEST_PDPTR1, vmcs12->guest_pdptr1);\n\t\tvmcs_write64(GUEST_PDPTR2, vmcs12->guest_pdptr2);\n\t\tvmcs_write64(GUEST_PDPTR3, vmcs12->guest_pdptr3);\n\t}\n\n\tif (!enable_ept)\n\t\tvcpu->arch.walk_mmu->inject_page_fault = vmx_inject_page_fault_nested;\n\n\tif ((vmcs12->vm_entry_controls & VM_ENTRY_LOAD_IA32_PERF_GLOBAL_CTRL) &&\n\t    WARN_ON_ONCE(kvm_set_msr(vcpu, MSR_CORE_PERF_GLOBAL_CTRL,\n\t\t\t\t     vmcs12->guest_ia32_perf_global_ctrl)))\n\t\treturn -EINVAL;\n\n\tkvm_rsp_write(vcpu, vmcs12->guest_rsp);\n\tkvm_rip_write(vcpu, vmcs12->guest_rip);\n\treturn 0;\n}\n\nstatic int nested_vmx_check_nmi_controls(struct vmcs12 *vmcs12)\n{\n\tif (CC(!nested_cpu_has_nmi_exiting(vmcs12) &&\n\t       nested_cpu_has_virtual_nmis(vmcs12)))\n\t\treturn -EINVAL;\n\n\tif (CC(!nested_cpu_has_virtual_nmis(vmcs12) &&\n\t       nested_cpu_has(vmcs12, CPU_BASED_NMI_WINDOW_EXITING)))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic bool nested_vmx_check_eptp(struct kvm_vcpu *vcpu, u64 new_eptp)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tint maxphyaddr = cpuid_maxphyaddr(vcpu);\n\n\t/* Check for memory type validity */\n\tswitch (new_eptp & VMX_EPTP_MT_MASK) {\n\tcase VMX_EPTP_MT_UC:\n\t\tif (CC(!(vmx->nested.msrs.ept_caps & VMX_EPTP_UC_BIT)))\n\t\t\treturn false;\n\t\tbreak;\n\tcase VMX_EPTP_MT_WB:\n\t\tif (CC(!(vmx->nested.msrs.ept_caps & VMX_EPTP_WB_BIT)))\n\t\t\treturn false;\n\t\tbreak;\n\tdefault:\n\t\treturn false;\n\t}\n\n\t/* Page-walk levels validity. */\n\tswitch (new_eptp & VMX_EPTP_PWL_MASK) {\n\tcase VMX_EPTP_PWL_5:\n\t\tif (CC(!(vmx->nested.msrs.ept_caps & VMX_EPT_PAGE_WALK_5_BIT)))\n\t\t\treturn false;\n\t\tbreak;\n\tcase VMX_EPTP_PWL_4:\n\t\tif (CC(!(vmx->nested.msrs.ept_caps & VMX_EPT_PAGE_WALK_4_BIT)))\n\t\t\treturn false;\n\t\tbreak;\n\tdefault:\n\t\treturn false;\n\t}\n\n\t/* Reserved bits should not be set */\n\tif (CC(new_eptp >> maxphyaddr || ((new_eptp >> 7) & 0x1f)))\n\t\treturn false;\n\n\t/* AD, if set, should be supported */\n\tif (new_eptp & VMX_EPTP_AD_ENABLE_BIT) {\n\t\tif (CC(!(vmx->nested.msrs.ept_caps & VMX_EPT_AD_BIT)))\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n\n/*\n * Checks related to VM-Execution Control Fields\n */\nstatic int nested_check_vm_execution_controls(struct kvm_vcpu *vcpu,\n                                              struct vmcs12 *vmcs12)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\tif (CC(!vmx_control_verify(vmcs12->pin_based_vm_exec_control,\n\t\t\t\t   vmx->nested.msrs.pinbased_ctls_low,\n\t\t\t\t   vmx->nested.msrs.pinbased_ctls_high)) ||\n\t    CC(!vmx_control_verify(vmcs12->cpu_based_vm_exec_control,\n\t\t\t\t   vmx->nested.msrs.procbased_ctls_low,\n\t\t\t\t   vmx->nested.msrs.procbased_ctls_high)))\n\t\treturn -EINVAL;\n\n\tif (nested_cpu_has(vmcs12, CPU_BASED_ACTIVATE_SECONDARY_CONTROLS) &&\n\t    CC(!vmx_control_verify(vmcs12->secondary_vm_exec_control,\n\t\t\t\t   vmx->nested.msrs.secondary_ctls_low,\n\t\t\t\t   vmx->nested.msrs.secondary_ctls_high)))\n\t\treturn -EINVAL;\n\n\tif (CC(vmcs12->cr3_target_count > nested_cpu_vmx_misc_cr3_count(vcpu)) ||\n\t    nested_vmx_check_io_bitmap_controls(vcpu, vmcs12) ||\n\t    nested_vmx_check_msr_bitmap_controls(vcpu, vmcs12) ||\n\t    nested_vmx_check_tpr_shadow_controls(vcpu, vmcs12) ||\n\t    nested_vmx_check_apic_access_controls(vcpu, vmcs12) ||\n\t    nested_vmx_check_apicv_controls(vcpu, vmcs12) ||\n\t    nested_vmx_check_nmi_controls(vmcs12) ||\n\t    nested_vmx_check_pml_controls(vcpu, vmcs12) ||\n\t    nested_vmx_check_unrestricted_guest_controls(vcpu, vmcs12) ||\n\t    nested_vmx_check_mode_based_ept_exec_controls(vcpu, vmcs12) ||\n\t    nested_vmx_check_shadow_vmcs_controls(vcpu, vmcs12) ||\n\t    CC(nested_cpu_has_vpid(vmcs12) && !vmcs12->virtual_processor_id))\n\t\treturn -EINVAL;\n\n\tif (!nested_cpu_has_preemption_timer(vmcs12) &&\n\t    nested_cpu_has_save_preemption_timer(vmcs12))\n\t\treturn -EINVAL;\n\n\tif (nested_cpu_has_ept(vmcs12) &&\n\t    CC(!nested_vmx_check_eptp(vcpu, vmcs12->ept_pointer)))\n\t\treturn -EINVAL;\n\n\tif (nested_cpu_has_vmfunc(vmcs12)) {\n\t\tif (CC(vmcs12->vm_function_control &\n\t\t       ~vmx->nested.msrs.vmfunc_controls))\n\t\t\treturn -EINVAL;\n\n\t\tif (nested_cpu_has_eptp_switching(vmcs12)) {\n\t\t\tif (CC(!nested_cpu_has_ept(vmcs12)) ||\n\t\t\t    CC(!page_address_valid(vcpu, vmcs12->eptp_list_address)))\n\t\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n/*\n * Checks related to VM-Exit Control Fields\n */\nstatic int nested_check_vm_exit_controls(struct kvm_vcpu *vcpu,\n                                         struct vmcs12 *vmcs12)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\tif (CC(!vmx_control_verify(vmcs12->vm_exit_controls,\n\t\t\t\t    vmx->nested.msrs.exit_ctls_low,\n\t\t\t\t    vmx->nested.msrs.exit_ctls_high)) ||\n\t    CC(nested_vmx_check_exit_msr_switch_controls(vcpu, vmcs12)))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\n/*\n * Checks related to VM-Entry Control Fields\n */\nstatic int nested_check_vm_entry_controls(struct kvm_vcpu *vcpu,\n\t\t\t\t\t  struct vmcs12 *vmcs12)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\tif (CC(!vmx_control_verify(vmcs12->vm_entry_controls,\n\t\t\t\t    vmx->nested.msrs.entry_ctls_low,\n\t\t\t\t    vmx->nested.msrs.entry_ctls_high)))\n\t\treturn -EINVAL;\n\n\t/*\n\t * From the Intel SDM, volume 3:\n\t * Fields relevant to VM-entry event injection must be set properly.\n\t * These fields are the VM-entry interruption-information field, the\n\t * VM-entry exception error code, and the VM-entry instruction length.\n\t */\n\tif (vmcs12->vm_entry_intr_info_field & INTR_INFO_VALID_MASK) {\n\t\tu32 intr_info = vmcs12->vm_entry_intr_info_field;\n\t\tu8 vector = intr_info & INTR_INFO_VECTOR_MASK;\n\t\tu32 intr_type = intr_info & INTR_INFO_INTR_TYPE_MASK;\n\t\tbool has_error_code = intr_info & INTR_INFO_DELIVER_CODE_MASK;\n\t\tbool should_have_error_code;\n\t\tbool urg = nested_cpu_has2(vmcs12,\n\t\t\t\t\t   SECONDARY_EXEC_UNRESTRICTED_GUEST);\n\t\tbool prot_mode = !urg || vmcs12->guest_cr0 & X86_CR0_PE;\n\n\t\t/* VM-entry interruption-info field: interruption type */\n\t\tif (CC(intr_type == INTR_TYPE_RESERVED) ||\n\t\t    CC(intr_type == INTR_TYPE_OTHER_EVENT &&\n\t\t       !nested_cpu_supports_monitor_trap_flag(vcpu)))\n\t\t\treturn -EINVAL;\n\n\t\t/* VM-entry interruption-info field: vector */\n\t\tif (CC(intr_type == INTR_TYPE_NMI_INTR && vector != NMI_VECTOR) ||\n\t\t    CC(intr_type == INTR_TYPE_HARD_EXCEPTION && vector > 31) ||\n\t\t    CC(intr_type == INTR_TYPE_OTHER_EVENT && vector != 0))\n\t\t\treturn -EINVAL;\n\n\t\t/* VM-entry interruption-info field: deliver error code */\n\t\tshould_have_error_code =\n\t\t\tintr_type == INTR_TYPE_HARD_EXCEPTION && prot_mode &&\n\t\t\tx86_exception_has_error_code(vector);\n\t\tif (CC(has_error_code != should_have_error_code))\n\t\t\treturn -EINVAL;\n\n\t\t/* VM-entry exception error code */\n\t\tif (CC(has_error_code &&\n\t\t       vmcs12->vm_entry_exception_error_code & GENMASK(31, 16)))\n\t\t\treturn -EINVAL;\n\n\t\t/* VM-entry interruption-info field: reserved bits */\n\t\tif (CC(intr_info & INTR_INFO_RESVD_BITS_MASK))\n\t\t\treturn -EINVAL;\n\n\t\t/* VM-entry instruction length */\n\t\tswitch (intr_type) {\n\t\tcase INTR_TYPE_SOFT_EXCEPTION:\n\t\tcase INTR_TYPE_SOFT_INTR:\n\t\tcase INTR_TYPE_PRIV_SW_EXCEPTION:\n\t\t\tif (CC(vmcs12->vm_entry_instruction_len > 15) ||\n\t\t\t    CC(vmcs12->vm_entry_instruction_len == 0 &&\n\t\t\t    CC(!nested_cpu_has_zero_length_injection(vcpu))))\n\t\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tif (nested_vmx_check_entry_msr_switch_controls(vcpu, vmcs12))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int nested_vmx_check_controls(struct kvm_vcpu *vcpu,\n\t\t\t\t     struct vmcs12 *vmcs12)\n{\n\tif (nested_check_vm_execution_controls(vcpu, vmcs12) ||\n\t    nested_check_vm_exit_controls(vcpu, vmcs12) ||\n\t    nested_check_vm_entry_controls(vcpu, vmcs12))\n\t\treturn -EINVAL;\n\n\tif (to_vmx(vcpu)->nested.enlightened_vmcs_enabled)\n\t\treturn nested_evmcs_check_controls(vmcs12);\n\n\treturn 0;\n}\n\nstatic int nested_vmx_check_host_state(struct kvm_vcpu *vcpu,\n\t\t\t\t       struct vmcs12 *vmcs12)\n{\n\tbool ia32e;\n\n\tif (CC(!nested_host_cr0_valid(vcpu, vmcs12->host_cr0)) ||\n\t    CC(!nested_host_cr4_valid(vcpu, vmcs12->host_cr4)) ||\n\t    CC(!nested_cr3_valid(vcpu, vmcs12->host_cr3)))\n\t\treturn -EINVAL;\n\n\tif (CC(is_noncanonical_address(vmcs12->host_ia32_sysenter_esp, vcpu)) ||\n\t    CC(is_noncanonical_address(vmcs12->host_ia32_sysenter_eip, vcpu)))\n\t\treturn -EINVAL;\n\n\tif ((vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_PAT) &&\n\t    CC(!kvm_pat_valid(vmcs12->host_ia32_pat)))\n\t\treturn -EINVAL;\n\n\tif ((vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_PERF_GLOBAL_CTRL) &&\n\t    CC(!kvm_valid_perf_global_ctrl(vcpu_to_pmu(vcpu),\n\t\t\t\t\t   vmcs12->host_ia32_perf_global_ctrl)))\n\t\treturn -EINVAL;\n\n#ifdef CONFIG_X86_64\n\tia32e = !!(vcpu->arch.efer & EFER_LMA);\n#else\n\tia32e = false;\n#endif\n\n\tif (ia32e) {\n\t\tif (CC(!(vmcs12->vm_exit_controls & VM_EXIT_HOST_ADDR_SPACE_SIZE)) ||\n\t\t    CC(!(vmcs12->host_cr4 & X86_CR4_PAE)))\n\t\t\treturn -EINVAL;\n\t} else {\n\t\tif (CC(vmcs12->vm_exit_controls & VM_EXIT_HOST_ADDR_SPACE_SIZE) ||\n\t\t    CC(vmcs12->vm_entry_controls & VM_ENTRY_IA32E_MODE) ||\n\t\t    CC(vmcs12->host_cr4 & X86_CR4_PCIDE) ||\n\t\t    CC((vmcs12->host_rip) >> 32))\n\t\t\treturn -EINVAL;\n\t}\n\n\tif (CC(vmcs12->host_cs_selector & (SEGMENT_RPL_MASK | SEGMENT_TI_MASK)) ||\n\t    CC(vmcs12->host_ss_selector & (SEGMENT_RPL_MASK | SEGMENT_TI_MASK)) ||\n\t    CC(vmcs12->host_ds_selector & (SEGMENT_RPL_MASK | SEGMENT_TI_MASK)) ||\n\t    CC(vmcs12->host_es_selector & (SEGMENT_RPL_MASK | SEGMENT_TI_MASK)) ||\n\t    CC(vmcs12->host_fs_selector & (SEGMENT_RPL_MASK | SEGMENT_TI_MASK)) ||\n\t    CC(vmcs12->host_gs_selector & (SEGMENT_RPL_MASK | SEGMENT_TI_MASK)) ||\n\t    CC(vmcs12->host_tr_selector & (SEGMENT_RPL_MASK | SEGMENT_TI_MASK)) ||\n\t    CC(vmcs12->host_cs_selector == 0) ||\n\t    CC(vmcs12->host_tr_selector == 0) ||\n\t    CC(vmcs12->host_ss_selector == 0 && !ia32e))\n\t\treturn -EINVAL;\n\n\tif (CC(is_noncanonical_address(vmcs12->host_fs_base, vcpu)) ||\n\t    CC(is_noncanonical_address(vmcs12->host_gs_base, vcpu)) ||\n\t    CC(is_noncanonical_address(vmcs12->host_gdtr_base, vcpu)) ||\n\t    CC(is_noncanonical_address(vmcs12->host_idtr_base, vcpu)) ||\n\t    CC(is_noncanonical_address(vmcs12->host_tr_base, vcpu)) ||\n\t    CC(is_noncanonical_address(vmcs12->host_rip, vcpu)))\n\t\treturn -EINVAL;\n\n\t/*\n\t * If the load IA32_EFER VM-exit control is 1, bits reserved in the\n\t * IA32_EFER MSR must be 0 in the field for that register. In addition,\n\t * the values of the LMA and LME bits in the field must each be that of\n\t * the host address-space size VM-exit control.\n\t */\n\tif (vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_EFER) {\n\t\tif (CC(!kvm_valid_efer(vcpu, vmcs12->host_ia32_efer)) ||\n\t\t    CC(ia32e != !!(vmcs12->host_ia32_efer & EFER_LMA)) ||\n\t\t    CC(ia32e != !!(vmcs12->host_ia32_efer & EFER_LME)))\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int nested_vmx_check_vmcs_link_ptr(struct kvm_vcpu *vcpu,\n\t\t\t\t\t  struct vmcs12 *vmcs12)\n{\n\tint r = 0;\n\tstruct vmcs12 *shadow;\n\tstruct kvm_host_map map;\n\n\tif (vmcs12->vmcs_link_pointer == -1ull)\n\t\treturn 0;\n\n\tif (CC(!page_address_valid(vcpu, vmcs12->vmcs_link_pointer)))\n\t\treturn -EINVAL;\n\n\tif (CC(kvm_vcpu_map(vcpu, gpa_to_gfn(vmcs12->vmcs_link_pointer), &map)))\n\t\treturn -EINVAL;\n\n\tshadow = map.hva;\n\n\tif (CC(shadow->hdr.revision_id != VMCS12_REVISION) ||\n\t    CC(shadow->hdr.shadow_vmcs != nested_cpu_has_shadow_vmcs(vmcs12)))\n\t\tr = -EINVAL;\n\n\tkvm_vcpu_unmap(vcpu, &map, false);\n\treturn r;\n}\n\n/*\n * Checks related to Guest Non-register State\n */\nstatic int nested_check_guest_non_reg_state(struct vmcs12 *vmcs12)\n{\n\tif (CC(vmcs12->guest_activity_state != GUEST_ACTIVITY_ACTIVE &&\n\t       vmcs12->guest_activity_state != GUEST_ACTIVITY_HLT &&\n\t       vmcs12->guest_activity_state != GUEST_ACTIVITY_WAIT_SIPI))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int nested_vmx_check_guest_state(struct kvm_vcpu *vcpu,\n\t\t\t\t\tstruct vmcs12 *vmcs12,\n\t\t\t\t\tenum vm_entry_failure_code *entry_failure_code)\n{\n\tbool ia32e;\n\n\t*entry_failure_code = ENTRY_FAIL_DEFAULT;\n\n\tif (CC(!nested_guest_cr0_valid(vcpu, vmcs12->guest_cr0)) ||\n\t    CC(!nested_guest_cr4_valid(vcpu, vmcs12->guest_cr4)))\n\t\treturn -EINVAL;\n\n\tif ((vmcs12->vm_entry_controls & VM_ENTRY_LOAD_DEBUG_CONTROLS) &&\n\t    CC(!kvm_dr7_valid(vmcs12->guest_dr7)))\n\t\treturn -EINVAL;\n\n\tif ((vmcs12->vm_entry_controls & VM_ENTRY_LOAD_IA32_PAT) &&\n\t    CC(!kvm_pat_valid(vmcs12->guest_ia32_pat)))\n\t\treturn -EINVAL;\n\n\tif (nested_vmx_check_vmcs_link_ptr(vcpu, vmcs12)) {\n\t\t*entry_failure_code = ENTRY_FAIL_VMCS_LINK_PTR;\n\t\treturn -EINVAL;\n\t}\n\n\tif ((vmcs12->vm_entry_controls & VM_ENTRY_LOAD_IA32_PERF_GLOBAL_CTRL) &&\n\t    CC(!kvm_valid_perf_global_ctrl(vcpu_to_pmu(vcpu),\n\t\t\t\t\t   vmcs12->guest_ia32_perf_global_ctrl)))\n\t\treturn -EINVAL;\n\n\t/*\n\t * If the load IA32_EFER VM-entry control is 1, the following checks\n\t * are performed on the field for the IA32_EFER MSR:\n\t * - Bits reserved in the IA32_EFER MSR must be 0.\n\t * - Bit 10 (corresponding to IA32_EFER.LMA) must equal the value of\n\t *   the IA-32e mode guest VM-exit control. It must also be identical\n\t *   to bit 8 (LME) if bit 31 in the CR0 field (corresponding to\n\t *   CR0.PG) is 1.\n\t */\n\tif (to_vmx(vcpu)->nested.nested_run_pending &&\n\t    (vmcs12->vm_entry_controls & VM_ENTRY_LOAD_IA32_EFER)) {\n\t\tia32e = (vmcs12->vm_entry_controls & VM_ENTRY_IA32E_MODE) != 0;\n\t\tif (CC(!kvm_valid_efer(vcpu, vmcs12->guest_ia32_efer)) ||\n\t\t    CC(ia32e != !!(vmcs12->guest_ia32_efer & EFER_LMA)) ||\n\t\t    CC(((vmcs12->guest_cr0 & X86_CR0_PG) &&\n\t\t     ia32e != !!(vmcs12->guest_ia32_efer & EFER_LME))))\n\t\t\treturn -EINVAL;\n\t}\n\n\tif ((vmcs12->vm_entry_controls & VM_ENTRY_LOAD_BNDCFGS) &&\n\t    (CC(is_noncanonical_address(vmcs12->guest_bndcfgs & PAGE_MASK, vcpu)) ||\n\t     CC((vmcs12->guest_bndcfgs & MSR_IA32_BNDCFGS_RSVD))))\n\t\treturn -EINVAL;\n\n\tif (nested_check_guest_non_reg_state(vmcs12))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int nested_vmx_check_vmentry_hw(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tunsigned long cr3, cr4;\n\tbool vm_fail;\n\n\tif (!nested_early_check)\n\t\treturn 0;\n\n\tif (vmx->msr_autoload.host.nr)\n\t\tvmcs_write32(VM_EXIT_MSR_LOAD_COUNT, 0);\n\tif (vmx->msr_autoload.guest.nr)\n\t\tvmcs_write32(VM_ENTRY_MSR_LOAD_COUNT, 0);\n\n\tpreempt_disable();\n\n\tvmx_prepare_switch_to_guest(vcpu);\n\n\t/*\n\t * Induce a consistency check VMExit by clearing bit 1 in GUEST_RFLAGS,\n\t * which is reserved to '1' by hardware.  GUEST_RFLAGS is guaranteed to\n\t * be written (by prepare_vmcs02()) before the \"real\" VMEnter, i.e.\n\t * there is no need to preserve other bits or save/restore the field.\n\t */\n\tvmcs_writel(GUEST_RFLAGS, 0);\n\n\tcr3 = __get_current_cr3_fast();\n\tif (unlikely(cr3 != vmx->loaded_vmcs->host_state.cr3)) {\n\t\tvmcs_writel(HOST_CR3, cr3);\n\t\tvmx->loaded_vmcs->host_state.cr3 = cr3;\n\t}\n\n\tcr4 = cr4_read_shadow();\n\tif (unlikely(cr4 != vmx->loaded_vmcs->host_state.cr4)) {\n\t\tvmcs_writel(HOST_CR4, cr4);\n\t\tvmx->loaded_vmcs->host_state.cr4 = cr4;\n\t}\n\n\tasm(\n\t\t\"sub $%c[wordsize], %%\" _ASM_SP \"\\n\\t\" /* temporarily adjust RSP for CALL */\n\t\t\"cmp %%\" _ASM_SP \", %c[host_state_rsp](%[loaded_vmcs]) \\n\\t\"\n\t\t\"je 1f \\n\\t\"\n\t\t__ex(\"vmwrite %%\" _ASM_SP \", %[HOST_RSP]\") \"\\n\\t\"\n\t\t\"mov %%\" _ASM_SP \", %c[host_state_rsp](%[loaded_vmcs]) \\n\\t\"\n\t\t\"1: \\n\\t\"\n\t\t\"add $%c[wordsize], %%\" _ASM_SP \"\\n\\t\" /* un-adjust RSP */\n\n\t\t/* Check if vmlaunch or vmresume is needed */\n\t\t\"cmpb $0, %c[launched](%[loaded_vmcs])\\n\\t\"\n\n\t\t/*\n\t\t * VMLAUNCH and VMRESUME clear RFLAGS.{CF,ZF} on VM-Exit, set\n\t\t * RFLAGS.CF on VM-Fail Invalid and set RFLAGS.ZF on VM-Fail\n\t\t * Valid.  vmx_vmenter() directly \"returns\" RFLAGS, and so the\n\t\t * results of VM-Enter is captured via CC_{SET,OUT} to vm_fail.\n\t\t */\n\t\t\"call vmx_vmenter\\n\\t\"\n\n\t\tCC_SET(be)\n\t      : ASM_CALL_CONSTRAINT, CC_OUT(be) (vm_fail)\n\t      :\t[HOST_RSP]\"r\"((unsigned long)HOST_RSP),\n\t\t[loaded_vmcs]\"r\"(vmx->loaded_vmcs),\n\t\t[launched]\"i\"(offsetof(struct loaded_vmcs, launched)),\n\t\t[host_state_rsp]\"i\"(offsetof(struct loaded_vmcs, host_state.rsp)),\n\t\t[wordsize]\"i\"(sizeof(ulong))\n\t      : \"memory\"\n\t);\n\n\tif (vmx->msr_autoload.host.nr)\n\t\tvmcs_write32(VM_EXIT_MSR_LOAD_COUNT, vmx->msr_autoload.host.nr);\n\tif (vmx->msr_autoload.guest.nr)\n\t\tvmcs_write32(VM_ENTRY_MSR_LOAD_COUNT, vmx->msr_autoload.guest.nr);\n\n\tif (vm_fail) {\n\t\tu32 error = vmcs_read32(VM_INSTRUCTION_ERROR);\n\n\t\tpreempt_enable();\n\n\t\ttrace_kvm_nested_vmenter_failed(\n\t\t\t\"early hardware check VM-instruction error: \", error);\n\t\tWARN_ON_ONCE(error != VMXERR_ENTRY_INVALID_CONTROL_FIELD);\n\t\treturn 1;\n\t}\n\n\t/*\n\t * VMExit clears RFLAGS.IF and DR7, even on a consistency check.\n\t */\n\tif (hw_breakpoint_active())\n\t\tset_debugreg(__this_cpu_read(cpu_dr7), 7);\n\tlocal_irq_enable();\n\tpreempt_enable();\n\n\t/*\n\t * A non-failing VMEntry means we somehow entered guest mode with\n\t * an illegal RIP, and that's just the tip of the iceberg.  There\n\t * is no telling what memory has been modified or what state has\n\t * been exposed to unknown code.  Hitting this all but guarantees\n\t * a (very critical) hardware issue.\n\t */\n\tWARN_ON(!(vmcs_read32(VM_EXIT_REASON) &\n\t\tVMX_EXIT_REASONS_FAILED_VMENTRY));\n\n\treturn 0;\n}\n\nstatic bool nested_get_vmcs12_pages(struct kvm_vcpu *vcpu)\n{\n\tstruct vmcs12 *vmcs12 = get_vmcs12(vcpu);\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tstruct kvm_host_map *map;\n\tstruct page *page;\n\tu64 hpa;\n\n\t/*\n\t * hv_evmcs may end up being not mapped after migration (when\n\t * L2 was running), map it here to make sure vmcs12 changes are\n\t * properly reflected.\n\t */\n\tif (vmx->nested.enlightened_vmcs_enabled && !vmx->nested.hv_evmcs) {\n\t\tenum nested_evmptrld_status evmptrld_status =\n\t\t\tnested_vmx_handle_enlightened_vmptrld(vcpu, false);\n\n\t\tif (evmptrld_status == EVMPTRLD_VMFAIL ||\n\t\t    evmptrld_status == EVMPTRLD_ERROR) {\n\t\t\tpr_debug_ratelimited(\"%s: enlightened vmptrld failed\\n\",\n\t\t\t\t\t     __func__);\n\t\t\tvcpu->run->exit_reason = KVM_EXIT_INTERNAL_ERROR;\n\t\t\tvcpu->run->internal.suberror =\n\t\t\t\tKVM_INTERNAL_ERROR_EMULATION;\n\t\t\tvcpu->run->internal.ndata = 0;\n\t\t\treturn false;\n\t\t}\n\t}\n\n\tif (nested_cpu_has2(vmcs12, SECONDARY_EXEC_VIRTUALIZE_APIC_ACCESSES)) {\n\t\t/*\n\t\t * Translate L1 physical address to host physical\n\t\t * address for vmcs02. Keep the page pinned, so this\n\t\t * physical address remains valid. We keep a reference\n\t\t * to it so we can release it later.\n\t\t */\n\t\tif (vmx->nested.apic_access_page) { /* shouldn't happen */\n\t\t\tkvm_release_page_clean(vmx->nested.apic_access_page);\n\t\t\tvmx->nested.apic_access_page = NULL;\n\t\t}\n\t\tpage = kvm_vcpu_gpa_to_page(vcpu, vmcs12->apic_access_addr);\n\t\tif (!is_error_page(page)) {\n\t\t\tvmx->nested.apic_access_page = page;\n\t\t\thpa = page_to_phys(vmx->nested.apic_access_page);\n\t\t\tvmcs_write64(APIC_ACCESS_ADDR, hpa);\n\t\t} else {\n\t\t\tpr_debug_ratelimited(\"%s: no backing 'struct page' for APIC-access address in vmcs12\\n\",\n\t\t\t\t\t     __func__);\n\t\t\tvcpu->run->exit_reason = KVM_EXIT_INTERNAL_ERROR;\n\t\t\tvcpu->run->internal.suberror =\n\t\t\t\tKVM_INTERNAL_ERROR_EMULATION;\n\t\t\tvcpu->run->internal.ndata = 0;\n\t\t\treturn false;\n\t\t}\n\t}\n\n\tif (nested_cpu_has(vmcs12, CPU_BASED_TPR_SHADOW)) {\n\t\tmap = &vmx->nested.virtual_apic_map;\n\n\t\tif (!kvm_vcpu_map(vcpu, gpa_to_gfn(vmcs12->virtual_apic_page_addr), map)) {\n\t\t\tvmcs_write64(VIRTUAL_APIC_PAGE_ADDR, pfn_to_hpa(map->pfn));\n\t\t} else if (nested_cpu_has(vmcs12, CPU_BASED_CR8_LOAD_EXITING) &&\n\t\t           nested_cpu_has(vmcs12, CPU_BASED_CR8_STORE_EXITING) &&\n\t\t\t   !nested_cpu_has2(vmcs12, SECONDARY_EXEC_VIRTUALIZE_APIC_ACCESSES)) {\n\t\t\t/*\n\t\t\t * The processor will never use the TPR shadow, simply\n\t\t\t * clear the bit from the execution control.  Such a\n\t\t\t * configuration is useless, but it happens in tests.\n\t\t\t * For any other configuration, failing the vm entry is\n\t\t\t * _not_ what the processor does but it's basically the\n\t\t\t * only possibility we have.\n\t\t\t */\n\t\t\texec_controls_clearbit(vmx, CPU_BASED_TPR_SHADOW);\n\t\t} else {\n\t\t\t/*\n\t\t\t * Write an illegal value to VIRTUAL_APIC_PAGE_ADDR to\n\t\t\t * force VM-Entry to fail.\n\t\t\t */\n\t\t\tvmcs_write64(VIRTUAL_APIC_PAGE_ADDR, -1ull);\n\t\t}\n\t}\n\n\tif (nested_cpu_has_posted_intr(vmcs12)) {\n\t\tmap = &vmx->nested.pi_desc_map;\n\n\t\tif (!kvm_vcpu_map(vcpu, gpa_to_gfn(vmcs12->posted_intr_desc_addr), map)) {\n\t\t\tvmx->nested.pi_desc =\n\t\t\t\t(struct pi_desc *)(((void *)map->hva) +\n\t\t\t\toffset_in_page(vmcs12->posted_intr_desc_addr));\n\t\t\tvmcs_write64(POSTED_INTR_DESC_ADDR,\n\t\t\t\t     pfn_to_hpa(map->pfn) + offset_in_page(vmcs12->posted_intr_desc_addr));\n\t\t}\n\t}\n\tif (nested_vmx_prepare_msr_bitmap(vcpu, vmcs12))\n\t\texec_controls_setbit(vmx, CPU_BASED_USE_MSR_BITMAPS);\n\telse\n\t\texec_controls_clearbit(vmx, CPU_BASED_USE_MSR_BITMAPS);\n\treturn true;\n}\n\nstatic int nested_vmx_write_pml_buffer(struct kvm_vcpu *vcpu, gpa_t gpa)\n{\n\tstruct vmcs12 *vmcs12;\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tgpa_t dst;\n\n\tif (WARN_ON_ONCE(!is_guest_mode(vcpu)))\n\t\treturn 0;\n\n\tif (WARN_ON_ONCE(vmx->nested.pml_full))\n\t\treturn 1;\n\n\t/*\n\t * Check if PML is enabled for the nested guest. Whether eptp bit 6 is\n\t * set is already checked as part of A/D emulation.\n\t */\n\tvmcs12 = get_vmcs12(vcpu);\n\tif (!nested_cpu_has_pml(vmcs12))\n\t\treturn 0;\n\n\tif (vmcs12->guest_pml_index >= PML_ENTITY_NUM) {\n\t\tvmx->nested.pml_full = true;\n\t\treturn 1;\n\t}\n\n\tgpa &= ~0xFFFull;\n\tdst = vmcs12->pml_address + sizeof(u64) * vmcs12->guest_pml_index;\n\n\tif (kvm_write_guest_page(vcpu->kvm, gpa_to_gfn(dst), &gpa,\n\t\t\t\t offset_in_page(dst), sizeof(gpa)))\n\t\treturn 0;\n\n\tvmcs12->guest_pml_index--;\n\n\treturn 0;\n}\n\n/*\n * Intel's VMX Instruction Reference specifies a common set of prerequisites\n * for running VMX instructions (except VMXON, whose prerequisites are\n * slightly different). It also specifies what exception to inject otherwise.\n * Note that many of these exceptions have priority over VM exits, so they\n * don't have to be checked again here.\n */\nstatic int nested_vmx_check_permission(struct kvm_vcpu *vcpu)\n{\n\tif (!to_vmx(vcpu)->nested.vmxon) {\n\t\tkvm_queue_exception(vcpu, UD_VECTOR);\n\t\treturn 0;\n\t}\n\n\tif (vmx_get_cpl(vcpu)) {\n\t\tkvm_inject_gp(vcpu, 0);\n\t\treturn 0;\n\t}\n\n\treturn 1;\n}\n\nstatic u8 vmx_has_apicv_interrupt(struct kvm_vcpu *vcpu)\n{\n\tu8 rvi = vmx_get_rvi();\n\tu8 vppr = kvm_lapic_get_reg(vcpu->arch.apic, APIC_PROCPRI);\n\n\treturn ((rvi & 0xf0) > (vppr & 0xf0));\n}\n\nstatic void load_vmcs12_host_state(struct kvm_vcpu *vcpu,\n\t\t\t\t   struct vmcs12 *vmcs12);\n\n/*\n * If from_vmentry is false, this is being called from state restore (either RSM\n * or KVM_SET_NESTED_STATE).  Otherwise it's called from vmlaunch/vmresume.\n *\n * Returns:\n *\tNVMX_VMENTRY_SUCCESS: Entered VMX non-root mode\n *\tNVMX_VMENTRY_VMFAIL:  Consistency check VMFail\n *\tNVMX_VMENTRY_VMEXIT:  Consistency check VMExit\n *\tNVMX_VMENTRY_KVM_INTERNAL_ERROR: KVM internal error\n */\nenum nvmx_vmentry_status nested_vmx_enter_non_root_mode(struct kvm_vcpu *vcpu,\n\t\t\t\t\t\t\tbool from_vmentry)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tstruct vmcs12 *vmcs12 = get_vmcs12(vcpu);\n\tenum vm_entry_failure_code entry_failure_code;\n\tbool evaluate_pending_interrupts;\n\tu32 exit_reason, failed_index;\n\n\tif (kvm_check_request(KVM_REQ_TLB_FLUSH_CURRENT, vcpu))\n\t\tkvm_vcpu_flush_tlb_current(vcpu);\n\n\tevaluate_pending_interrupts = exec_controls_get(vmx) &\n\t\t(CPU_BASED_INTR_WINDOW_EXITING | CPU_BASED_NMI_WINDOW_EXITING);\n\tif (likely(!evaluate_pending_interrupts) && kvm_vcpu_apicv_active(vcpu))\n\t\tevaluate_pending_interrupts |= vmx_has_apicv_interrupt(vcpu);\n\n\tif (!(vmcs12->vm_entry_controls & VM_ENTRY_LOAD_DEBUG_CONTROLS))\n\t\tvmx->nested.vmcs01_debugctl = vmcs_read64(GUEST_IA32_DEBUGCTL);\n\tif (kvm_mpx_supported() &&\n\t\t!(vmcs12->vm_entry_controls & VM_ENTRY_LOAD_BNDCFGS))\n\t\tvmx->nested.vmcs01_guest_bndcfgs = vmcs_read64(GUEST_BNDCFGS);\n\n\t/*\n\t * Overwrite vmcs01.GUEST_CR3 with L1's CR3 if EPT is disabled *and*\n\t * nested early checks are disabled.  In the event of a \"late\" VM-Fail,\n\t * i.e. a VM-Fail detected by hardware but not KVM, KVM must unwind its\n\t * software model to the pre-VMEntry host state.  When EPT is disabled,\n\t * GUEST_CR3 holds KVM's shadow CR3, not L1's \"real\" CR3, which causes\n\t * nested_vmx_restore_host_state() to corrupt vcpu->arch.cr3.  Stuffing\n\t * vmcs01.GUEST_CR3 results in the unwind naturally setting arch.cr3 to\n\t * the correct value.  Smashing vmcs01.GUEST_CR3 is safe because nested\n\t * VM-Exits, and the unwind, reset KVM's MMU, i.e. vmcs01.GUEST_CR3 is\n\t * guaranteed to be overwritten with a shadow CR3 prior to re-entering\n\t * L1.  Don't stuff vmcs01.GUEST_CR3 when using nested early checks as\n\t * KVM modifies vcpu->arch.cr3 if and only if the early hardware checks\n\t * pass, and early VM-Fails do not reset KVM's MMU, i.e. the VM-Fail\n\t * path would need to manually save/restore vmcs01.GUEST_CR3.\n\t */\n\tif (!enable_ept && !nested_early_check)\n\t\tvmcs_writel(GUEST_CR3, vcpu->arch.cr3);\n\n\tvmx_switch_vmcs(vcpu, &vmx->nested.vmcs02);\n\n\tprepare_vmcs02_early(vmx, vmcs12);\n\n\tif (from_vmentry) {\n\t\tif (unlikely(!nested_get_vmcs12_pages(vcpu))) {\n\t\t\tvmx_switch_vmcs(vcpu, &vmx->vmcs01);\n\t\t\treturn NVMX_VMENTRY_KVM_INTERNAL_ERROR;\n\t\t}\n\n\t\tif (nested_vmx_check_vmentry_hw(vcpu)) {\n\t\t\tvmx_switch_vmcs(vcpu, &vmx->vmcs01);\n\t\t\treturn NVMX_VMENTRY_VMFAIL;\n\t\t}\n\n\t\tif (nested_vmx_check_guest_state(vcpu, vmcs12,\n\t\t\t\t\t\t &entry_failure_code)) {\n\t\t\texit_reason = EXIT_REASON_INVALID_STATE;\n\t\t\tvmcs12->exit_qualification = entry_failure_code;\n\t\t\tgoto vmentry_fail_vmexit;\n\t\t}\n\t}\n\n\tenter_guest_mode(vcpu);\n\tif (vmcs12->cpu_based_vm_exec_control & CPU_BASED_USE_TSC_OFFSETTING)\n\t\tvcpu->arch.tsc_offset += vmcs12->tsc_offset;\n\n\tif (prepare_vmcs02(vcpu, vmcs12, &entry_failure_code)) {\n\t\texit_reason = EXIT_REASON_INVALID_STATE;\n\t\tvmcs12->exit_qualification = entry_failure_code;\n\t\tgoto vmentry_fail_vmexit_guest_mode;\n\t}\n\n\tif (from_vmentry) {\n\t\tfailed_index = nested_vmx_load_msr(vcpu,\n\t\t\t\t\t\t   vmcs12->vm_entry_msr_load_addr,\n\t\t\t\t\t\t   vmcs12->vm_entry_msr_load_count);\n\t\tif (failed_index) {\n\t\t\texit_reason = EXIT_REASON_MSR_LOAD_FAIL;\n\t\t\tvmcs12->exit_qualification = failed_index;\n\t\t\tgoto vmentry_fail_vmexit_guest_mode;\n\t\t}\n\t} else {\n\t\t/*\n\t\t * The MMU is not initialized to point at the right entities yet and\n\t\t * \"get pages\" would need to read data from the guest (i.e. we will\n\t\t * need to perform gpa to hpa translation). Request a call\n\t\t * to nested_get_vmcs12_pages before the next VM-entry.  The MSRs\n\t\t * have already been set at vmentry time and should not be reset.\n\t\t */\n\t\tkvm_make_request(KVM_REQ_GET_NESTED_STATE_PAGES, vcpu);\n\t}\n\n\t/*\n\t * If L1 had a pending IRQ/NMI until it executed\n\t * VMLAUNCH/VMRESUME which wasn't delivered because it was\n\t * disallowed (e.g. interrupts disabled), L0 needs to\n\t * evaluate if this pending event should cause an exit from L2\n\t * to L1 or delivered directly to L2 (e.g. In case L1 don't\n\t * intercept EXTERNAL_INTERRUPT).\n\t *\n\t * Usually this would be handled by the processor noticing an\n\t * IRQ/NMI window request, or checking RVI during evaluation of\n\t * pending virtual interrupts.  However, this setting was done\n\t * on VMCS01 and now VMCS02 is active instead. Thus, we force L0\n\t * to perform pending event evaluation by requesting a KVM_REQ_EVENT.\n\t */\n\tif (unlikely(evaluate_pending_interrupts))\n\t\tkvm_make_request(KVM_REQ_EVENT, vcpu);\n\n\t/*\n\t * Do not start the preemption timer hrtimer until after we know\n\t * we are successful, so that only nested_vmx_vmexit needs to cancel\n\t * the timer.\n\t */\n\tvmx->nested.preemption_timer_expired = false;\n\tif (nested_cpu_has_preemption_timer(vmcs12)) {\n\t\tu64 timer_value = vmx_calc_preemption_timer_value(vcpu);\n\t\tvmx_start_preemption_timer(vcpu, timer_value);\n\t}\n\n\t/*\n\t * Note no nested_vmx_succeed or nested_vmx_fail here. At this point\n\t * we are no longer running L1, and VMLAUNCH/VMRESUME has not yet\n\t * returned as far as L1 is concerned. It will only return (and set\n\t * the success flag) when L2 exits (see nested_vmx_vmexit()).\n\t */\n\treturn NVMX_VMENTRY_SUCCESS;\n\n\t/*\n\t * A failed consistency check that leads to a VMExit during L1's\n\t * VMEnter to L2 is a variation of a normal VMexit, as explained in\n\t * 26.7 \"VM-entry failures during or after loading guest state\".\n\t */\nvmentry_fail_vmexit_guest_mode:\n\tif (vmcs12->cpu_based_vm_exec_control & CPU_BASED_USE_TSC_OFFSETTING)\n\t\tvcpu->arch.tsc_offset -= vmcs12->tsc_offset;\n\tleave_guest_mode(vcpu);\n\nvmentry_fail_vmexit:\n\tvmx_switch_vmcs(vcpu, &vmx->vmcs01);\n\n\tif (!from_vmentry)\n\t\treturn NVMX_VMENTRY_VMEXIT;\n\n\tload_vmcs12_host_state(vcpu, vmcs12);\n\tvmcs12->vm_exit_reason = exit_reason | VMX_EXIT_REASONS_FAILED_VMENTRY;\n\tif (enable_shadow_vmcs || vmx->nested.hv_evmcs)\n\t\tvmx->nested.need_vmcs12_to_shadow_sync = true;\n\treturn NVMX_VMENTRY_VMEXIT;\n}\n\n/*\n * nested_vmx_run() handles a nested entry, i.e., a VMLAUNCH or VMRESUME on L1\n * for running an L2 nested guest.\n */\nstatic int nested_vmx_run(struct kvm_vcpu *vcpu, bool launch)\n{\n\tstruct vmcs12 *vmcs12;\n\tenum nvmx_vmentry_status status;\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tu32 interrupt_shadow = vmx_get_interrupt_shadow(vcpu);\n\tenum nested_evmptrld_status evmptrld_status;\n\n\tif (!nested_vmx_check_permission(vcpu))\n\t\treturn 1;\n\n\tevmptrld_status = nested_vmx_handle_enlightened_vmptrld(vcpu, launch);\n\tif (evmptrld_status == EVMPTRLD_ERROR) {\n\t\tkvm_queue_exception(vcpu, UD_VECTOR);\n\t\treturn 1;\n\t} else if (CC(evmptrld_status == EVMPTRLD_VMFAIL)) {\n\t\treturn nested_vmx_failInvalid(vcpu);\n\t}\n\n\tif (CC(!vmx->nested.hv_evmcs && vmx->nested.current_vmptr == -1ull))\n\t\treturn nested_vmx_failInvalid(vcpu);\n\n\tvmcs12 = get_vmcs12(vcpu);\n\n\t/*\n\t * Can't VMLAUNCH or VMRESUME a shadow VMCS. Despite the fact\n\t * that there *is* a valid VMCS pointer, RFLAGS.CF is set\n\t * rather than RFLAGS.ZF, and no error number is stored to the\n\t * VM-instruction error field.\n\t */\n\tif (CC(vmcs12->hdr.shadow_vmcs))\n\t\treturn nested_vmx_failInvalid(vcpu);\n\n\tif (vmx->nested.hv_evmcs) {\n\t\tcopy_enlightened_to_vmcs12(vmx);\n\t\t/* Enlightened VMCS doesn't have launch state */\n\t\tvmcs12->launch_state = !launch;\n\t} else if (enable_shadow_vmcs) {\n\t\tcopy_shadow_to_vmcs12(vmx);\n\t}\n\n\t/*\n\t * The nested entry process starts with enforcing various prerequisites\n\t * on vmcs12 as required by the Intel SDM, and act appropriately when\n\t * they fail: As the SDM explains, some conditions should cause the\n\t * instruction to fail, while others will cause the instruction to seem\n\t * to succeed, but return an EXIT_REASON_INVALID_STATE.\n\t * To speed up the normal (success) code path, we should avoid checking\n\t * for misconfigurations which will anyway be caught by the processor\n\t * when using the merged vmcs02.\n\t */\n\tif (CC(interrupt_shadow & KVM_X86_SHADOW_INT_MOV_SS))\n\t\treturn nested_vmx_fail(vcpu, VMXERR_ENTRY_EVENTS_BLOCKED_BY_MOV_SS);\n\n\tif (CC(vmcs12->launch_state == launch))\n\t\treturn nested_vmx_fail(vcpu,\n\t\t\tlaunch ? VMXERR_VMLAUNCH_NONCLEAR_VMCS\n\t\t\t       : VMXERR_VMRESUME_NONLAUNCHED_VMCS);\n\n\tif (nested_vmx_check_controls(vcpu, vmcs12))\n\t\treturn nested_vmx_fail(vcpu, VMXERR_ENTRY_INVALID_CONTROL_FIELD);\n\n\tif (nested_vmx_check_host_state(vcpu, vmcs12))\n\t\treturn nested_vmx_fail(vcpu, VMXERR_ENTRY_INVALID_HOST_STATE_FIELD);\n\n\t/*\n\t * We're finally done with prerequisite checking, and can start with\n\t * the nested entry.\n\t */\n\tvmx->nested.nested_run_pending = 1;\n\tvmx->nested.has_preemption_timer_deadline = false;\n\tstatus = nested_vmx_enter_non_root_mode(vcpu, true);\n\tif (unlikely(status != NVMX_VMENTRY_SUCCESS))\n\t\tgoto vmentry_failed;\n\n\t/* Emulate processing of posted interrupts on VM-Enter. */\n\tif (nested_cpu_has_posted_intr(vmcs12) &&\n\t    kvm_apic_has_interrupt(vcpu) == vmx->nested.posted_intr_nv) {\n\t\tvmx->nested.pi_pending = true;\n\t\tkvm_make_request(KVM_REQ_EVENT, vcpu);\n\t\tkvm_apic_clear_irr(vcpu, vmx->nested.posted_intr_nv);\n\t}\n\n\t/* Hide L1D cache contents from the nested guest.  */\n\tvmx->vcpu.arch.l1tf_flush_l1d = true;\n\n\t/*\n\t * Must happen outside of nested_vmx_enter_non_root_mode() as it will\n\t * also be used as part of restoring nVMX state for\n\t * snapshot restore (migration).\n\t *\n\t * In this flow, it is assumed that vmcs12 cache was\n\t * trasferred as part of captured nVMX state and should\n\t * therefore not be read from guest memory (which may not\n\t * exist on destination host yet).\n\t */\n\tnested_cache_shadow_vmcs12(vcpu, vmcs12);\n\n\tswitch (vmcs12->guest_activity_state) {\n\tcase GUEST_ACTIVITY_HLT:\n\t\t/*\n\t\t * If we're entering a halted L2 vcpu and the L2 vcpu won't be\n\t\t * awakened by event injection or by an NMI-window VM-exit or\n\t\t * by an interrupt-window VM-exit, halt the vcpu.\n\t\t */\n\t\tif (!(vmcs12->vm_entry_intr_info_field & INTR_INFO_VALID_MASK) &&\n\t\t    !nested_cpu_has(vmcs12, CPU_BASED_NMI_WINDOW_EXITING) &&\n\t\t    !(nested_cpu_has(vmcs12, CPU_BASED_INTR_WINDOW_EXITING) &&\n\t\t      (vmcs12->guest_rflags & X86_EFLAGS_IF))) {\n\t\t\tvmx->nested.nested_run_pending = 0;\n\t\t\treturn kvm_vcpu_halt(vcpu);\n\t\t}\n\t\tbreak;\n\tcase GUEST_ACTIVITY_WAIT_SIPI:\n\t\tvmx->nested.nested_run_pending = 0;\n\t\tvcpu->arch.mp_state = KVM_MP_STATE_INIT_RECEIVED;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn 1;\n\nvmentry_failed:\n\tvmx->nested.nested_run_pending = 0;\n\tif (status == NVMX_VMENTRY_KVM_INTERNAL_ERROR)\n\t\treturn 0;\n\tif (status == NVMX_VMENTRY_VMEXIT)\n\t\treturn 1;\n\tWARN_ON_ONCE(status != NVMX_VMENTRY_VMFAIL);\n\treturn nested_vmx_fail(vcpu, VMXERR_ENTRY_INVALID_CONTROL_FIELD);\n}\n\n/*\n * On a nested exit from L2 to L1, vmcs12.guest_cr0 might not be up-to-date\n * because L2 may have changed some cr0 bits directly (CR0_GUEST_HOST_MASK).\n * This function returns the new value we should put in vmcs12.guest_cr0.\n * It's not enough to just return the vmcs02 GUEST_CR0. Rather,\n *  1. Bits that neither L0 nor L1 trapped, were set directly by L2 and are now\n *     available in vmcs02 GUEST_CR0. (Note: It's enough to check that L0\n *     didn't trap the bit, because if L1 did, so would L0).\n *  2. Bits that L1 asked to trap (and therefore L0 also did) could not have\n *     been modified by L2, and L1 knows it. So just leave the old value of\n *     the bit from vmcs12.guest_cr0. Note that the bit from vmcs02 GUEST_CR0\n *     isn't relevant, because if L0 traps this bit it can set it to anything.\n *  3. Bits that L1 didn't trap, but L0 did. L1 believes the guest could have\n *     changed these bits, and therefore they need to be updated, but L0\n *     didn't necessarily allow them to be changed in GUEST_CR0 - and rather\n *     put them in vmcs02 CR0_READ_SHADOW. So take these bits from there.\n */\nstatic inline unsigned long\nvmcs12_guest_cr0(struct kvm_vcpu *vcpu, struct vmcs12 *vmcs12)\n{\n\treturn\n\t/*1*/\t(vmcs_readl(GUEST_CR0) & vcpu->arch.cr0_guest_owned_bits) |\n\t/*2*/\t(vmcs12->guest_cr0 & vmcs12->cr0_guest_host_mask) |\n\t/*3*/\t(vmcs_readl(CR0_READ_SHADOW) & ~(vmcs12->cr0_guest_host_mask |\n\t\t\tvcpu->arch.cr0_guest_owned_bits));\n}\n\nstatic inline unsigned long\nvmcs12_guest_cr4(struct kvm_vcpu *vcpu, struct vmcs12 *vmcs12)\n{\n\treturn\n\t/*1*/\t(vmcs_readl(GUEST_CR4) & vcpu->arch.cr4_guest_owned_bits) |\n\t/*2*/\t(vmcs12->guest_cr4 & vmcs12->cr4_guest_host_mask) |\n\t/*3*/\t(vmcs_readl(CR4_READ_SHADOW) & ~(vmcs12->cr4_guest_host_mask |\n\t\t\tvcpu->arch.cr4_guest_owned_bits));\n}\n\nstatic void vmcs12_save_pending_event(struct kvm_vcpu *vcpu,\n\t\t\t\t      struct vmcs12 *vmcs12)\n{\n\tu32 idt_vectoring;\n\tunsigned int nr;\n\n\tif (vcpu->arch.exception.injected) {\n\t\tnr = vcpu->arch.exception.nr;\n\t\tidt_vectoring = nr | VECTORING_INFO_VALID_MASK;\n\n\t\tif (kvm_exception_is_soft(nr)) {\n\t\t\tvmcs12->vm_exit_instruction_len =\n\t\t\t\tvcpu->arch.event_exit_inst_len;\n\t\t\tidt_vectoring |= INTR_TYPE_SOFT_EXCEPTION;\n\t\t} else\n\t\t\tidt_vectoring |= INTR_TYPE_HARD_EXCEPTION;\n\n\t\tif (vcpu->arch.exception.has_error_code) {\n\t\t\tidt_vectoring |= VECTORING_INFO_DELIVER_CODE_MASK;\n\t\t\tvmcs12->idt_vectoring_error_code =\n\t\t\t\tvcpu->arch.exception.error_code;\n\t\t}\n\n\t\tvmcs12->idt_vectoring_info_field = idt_vectoring;\n\t} else if (vcpu->arch.nmi_injected) {\n\t\tvmcs12->idt_vectoring_info_field =\n\t\t\tINTR_TYPE_NMI_INTR | INTR_INFO_VALID_MASK | NMI_VECTOR;\n\t} else if (vcpu->arch.interrupt.injected) {\n\t\tnr = vcpu->arch.interrupt.nr;\n\t\tidt_vectoring = nr | VECTORING_INFO_VALID_MASK;\n\n\t\tif (vcpu->arch.interrupt.soft) {\n\t\t\tidt_vectoring |= INTR_TYPE_SOFT_INTR;\n\t\t\tvmcs12->vm_entry_instruction_len =\n\t\t\t\tvcpu->arch.event_exit_inst_len;\n\t\t} else\n\t\t\tidt_vectoring |= INTR_TYPE_EXT_INTR;\n\n\t\tvmcs12->idt_vectoring_info_field = idt_vectoring;\n\t}\n}\n\n\nvoid nested_mark_vmcs12_pages_dirty(struct kvm_vcpu *vcpu)\n{\n\tstruct vmcs12 *vmcs12 = get_vmcs12(vcpu);\n\tgfn_t gfn;\n\n\t/*\n\t * Don't need to mark the APIC access page dirty; it is never\n\t * written to by the CPU during APIC virtualization.\n\t */\n\n\tif (nested_cpu_has(vmcs12, CPU_BASED_TPR_SHADOW)) {\n\t\tgfn = vmcs12->virtual_apic_page_addr >> PAGE_SHIFT;\n\t\tkvm_vcpu_mark_page_dirty(vcpu, gfn);\n\t}\n\n\tif (nested_cpu_has_posted_intr(vmcs12)) {\n\t\tgfn = vmcs12->posted_intr_desc_addr >> PAGE_SHIFT;\n\t\tkvm_vcpu_mark_page_dirty(vcpu, gfn);\n\t}\n}\n\nstatic void vmx_complete_nested_posted_interrupt(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tint max_irr;\n\tvoid *vapic_page;\n\tu16 status;\n\n\tif (!vmx->nested.pi_desc || !vmx->nested.pi_pending)\n\t\treturn;\n\n\tvmx->nested.pi_pending = false;\n\tif (!pi_test_and_clear_on(vmx->nested.pi_desc))\n\t\treturn;\n\n\tmax_irr = find_last_bit((unsigned long *)vmx->nested.pi_desc->pir, 256);\n\tif (max_irr != 256) {\n\t\tvapic_page = vmx->nested.virtual_apic_map.hva;\n\t\tif (!vapic_page)\n\t\t\treturn;\n\n\t\t__kvm_apic_update_irr(vmx->nested.pi_desc->pir,\n\t\t\tvapic_page, &max_irr);\n\t\tstatus = vmcs_read16(GUEST_INTR_STATUS);\n\t\tif ((u8)max_irr > ((u8)status & 0xff)) {\n\t\t\tstatus &= ~0xff;\n\t\t\tstatus |= (u8)max_irr;\n\t\t\tvmcs_write16(GUEST_INTR_STATUS, status);\n\t\t}\n\t}\n\n\tnested_mark_vmcs12_pages_dirty(vcpu);\n}\n\nstatic void nested_vmx_inject_exception_vmexit(struct kvm_vcpu *vcpu,\n\t\t\t\t\t       unsigned long exit_qual)\n{\n\tstruct vmcs12 *vmcs12 = get_vmcs12(vcpu);\n\tunsigned int nr = vcpu->arch.exception.nr;\n\tu32 intr_info = nr | INTR_INFO_VALID_MASK;\n\n\tif (vcpu->arch.exception.has_error_code) {\n\t\tvmcs12->vm_exit_intr_error_code = vcpu->arch.exception.error_code;\n\t\tintr_info |= INTR_INFO_DELIVER_CODE_MASK;\n\t}\n\n\tif (kvm_exception_is_soft(nr))\n\t\tintr_info |= INTR_TYPE_SOFT_EXCEPTION;\n\telse\n\t\tintr_info |= INTR_TYPE_HARD_EXCEPTION;\n\n\tif (!(vmcs12->idt_vectoring_info_field & VECTORING_INFO_VALID_MASK) &&\n\t    vmx_get_nmi_mask(vcpu))\n\t\tintr_info |= INTR_INFO_UNBLOCK_NMI;\n\n\tnested_vmx_vmexit(vcpu, EXIT_REASON_EXCEPTION_NMI, intr_info, exit_qual);\n}\n\n/*\n * Returns true if a debug trap is pending delivery.\n *\n * In KVM, debug traps bear an exception payload. As such, the class of a #DB\n * exception may be inferred from the presence of an exception payload.\n */\nstatic inline bool vmx_pending_dbg_trap(struct kvm_vcpu *vcpu)\n{\n\treturn vcpu->arch.exception.pending &&\n\t\t\tvcpu->arch.exception.nr == DB_VECTOR &&\n\t\t\tvcpu->arch.exception.payload;\n}\n\n/*\n * Certain VM-exits set the 'pending debug exceptions' field to indicate a\n * recognized #DB (data or single-step) that has yet to be delivered. Since KVM\n * represents these debug traps with a payload that is said to be compatible\n * with the 'pending debug exceptions' field, write the payload to the VMCS\n * field if a VM-exit is delivered before the debug trap.\n */\nstatic void nested_vmx_update_pending_dbg(struct kvm_vcpu *vcpu)\n{\n\tif (vmx_pending_dbg_trap(vcpu))\n\t\tvmcs_writel(GUEST_PENDING_DBG_EXCEPTIONS,\n\t\t\t    vcpu->arch.exception.payload);\n}\n\nstatic bool nested_vmx_preemption_timer_pending(struct kvm_vcpu *vcpu)\n{\n\treturn nested_cpu_has_preemption_timer(get_vmcs12(vcpu)) &&\n\t       to_vmx(vcpu)->nested.preemption_timer_expired;\n}\n\nstatic int vmx_check_nested_events(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tunsigned long exit_qual;\n\tbool block_nested_events =\n\t    vmx->nested.nested_run_pending || kvm_event_needs_reinjection(vcpu);\n\tbool mtf_pending = vmx->nested.mtf_pending;\n\tstruct kvm_lapic *apic = vcpu->arch.apic;\n\n\t/*\n\t * Clear the MTF state. If a higher priority VM-exit is delivered first,\n\t * this state is discarded.\n\t */\n\tif (!block_nested_events)\n\t\tvmx->nested.mtf_pending = false;\n\n\tif (lapic_in_kernel(vcpu) &&\n\t\ttest_bit(KVM_APIC_INIT, &apic->pending_events)) {\n\t\tif (block_nested_events)\n\t\t\treturn -EBUSY;\n\t\tnested_vmx_update_pending_dbg(vcpu);\n\t\tclear_bit(KVM_APIC_INIT, &apic->pending_events);\n\t\tif (vcpu->arch.mp_state != KVM_MP_STATE_INIT_RECEIVED)\n\t\t\tnested_vmx_vmexit(vcpu, EXIT_REASON_INIT_SIGNAL, 0, 0);\n\t\treturn 0;\n\t}\n\n\tif (lapic_in_kernel(vcpu) &&\n\t    test_bit(KVM_APIC_SIPI, &apic->pending_events)) {\n\t\tif (block_nested_events)\n\t\t\treturn -EBUSY;\n\n\t\tclear_bit(KVM_APIC_SIPI, &apic->pending_events);\n\t\tif (vcpu->arch.mp_state == KVM_MP_STATE_INIT_RECEIVED)\n\t\t\tnested_vmx_vmexit(vcpu, EXIT_REASON_SIPI_SIGNAL, 0,\n\t\t\t\t\t\tapic->sipi_vector & 0xFFUL);\n\t\treturn 0;\n\t}\n\n\t/*\n\t * Process any exceptions that are not debug traps before MTF.\n\t */\n\tif (vcpu->arch.exception.pending && !vmx_pending_dbg_trap(vcpu)) {\n\t\tif (block_nested_events)\n\t\t\treturn -EBUSY;\n\t\tif (!nested_vmx_check_exception(vcpu, &exit_qual))\n\t\t\tgoto no_vmexit;\n\t\tnested_vmx_inject_exception_vmexit(vcpu, exit_qual);\n\t\treturn 0;\n\t}\n\n\tif (mtf_pending) {\n\t\tif (block_nested_events)\n\t\t\treturn -EBUSY;\n\t\tnested_vmx_update_pending_dbg(vcpu);\n\t\tnested_vmx_vmexit(vcpu, EXIT_REASON_MONITOR_TRAP_FLAG, 0, 0);\n\t\treturn 0;\n\t}\n\n\tif (vcpu->arch.exception.pending) {\n\t\tif (block_nested_events)\n\t\t\treturn -EBUSY;\n\t\tif (!nested_vmx_check_exception(vcpu, &exit_qual))\n\t\t\tgoto no_vmexit;\n\t\tnested_vmx_inject_exception_vmexit(vcpu, exit_qual);\n\t\treturn 0;\n\t}\n\n\tif (nested_vmx_preemption_timer_pending(vcpu)) {\n\t\tif (block_nested_events)\n\t\t\treturn -EBUSY;\n\t\tnested_vmx_vmexit(vcpu, EXIT_REASON_PREEMPTION_TIMER, 0, 0);\n\t\treturn 0;\n\t}\n\n\tif (vcpu->arch.smi_pending && !is_smm(vcpu)) {\n\t\tif (block_nested_events)\n\t\t\treturn -EBUSY;\n\t\tgoto no_vmexit;\n\t}\n\n\tif (vcpu->arch.nmi_pending && !vmx_nmi_blocked(vcpu)) {\n\t\tif (block_nested_events)\n\t\t\treturn -EBUSY;\n\t\tif (!nested_exit_on_nmi(vcpu))\n\t\t\tgoto no_vmexit;\n\n\t\tnested_vmx_vmexit(vcpu, EXIT_REASON_EXCEPTION_NMI,\n\t\t\t\t  NMI_VECTOR | INTR_TYPE_NMI_INTR |\n\t\t\t\t  INTR_INFO_VALID_MASK, 0);\n\t\t/*\n\t\t * The NMI-triggered VM exit counts as injection:\n\t\t * clear this one and block further NMIs.\n\t\t */\n\t\tvcpu->arch.nmi_pending = 0;\n\t\tvmx_set_nmi_mask(vcpu, true);\n\t\treturn 0;\n\t}\n\n\tif (kvm_cpu_has_interrupt(vcpu) && !vmx_interrupt_blocked(vcpu)) {\n\t\tif (block_nested_events)\n\t\t\treturn -EBUSY;\n\t\tif (!nested_exit_on_intr(vcpu))\n\t\t\tgoto no_vmexit;\n\t\tnested_vmx_vmexit(vcpu, EXIT_REASON_EXTERNAL_INTERRUPT, 0, 0);\n\t\treturn 0;\n\t}\n\nno_vmexit:\n\tvmx_complete_nested_posted_interrupt(vcpu);\n\treturn 0;\n}\n\nstatic u32 vmx_get_preemption_timer_value(struct kvm_vcpu *vcpu)\n{\n\tktime_t remaining =\n\t\thrtimer_get_remaining(&to_vmx(vcpu)->nested.preemption_timer);\n\tu64 value;\n\n\tif (ktime_to_ns(remaining) <= 0)\n\t\treturn 0;\n\n\tvalue = ktime_to_ns(remaining) * vcpu->arch.virtual_tsc_khz;\n\tdo_div(value, 1000000);\n\treturn value >> VMX_MISC_EMULATED_PREEMPTION_TIMER_RATE;\n}\n\nstatic bool is_vmcs12_ext_field(unsigned long field)\n{\n\tswitch (field) {\n\tcase GUEST_ES_SELECTOR:\n\tcase GUEST_CS_SELECTOR:\n\tcase GUEST_SS_SELECTOR:\n\tcase GUEST_DS_SELECTOR:\n\tcase GUEST_FS_SELECTOR:\n\tcase GUEST_GS_SELECTOR:\n\tcase GUEST_LDTR_SELECTOR:\n\tcase GUEST_TR_SELECTOR:\n\tcase GUEST_ES_LIMIT:\n\tcase GUEST_CS_LIMIT:\n\tcase GUEST_SS_LIMIT:\n\tcase GUEST_DS_LIMIT:\n\tcase GUEST_FS_LIMIT:\n\tcase GUEST_GS_LIMIT:\n\tcase GUEST_LDTR_LIMIT:\n\tcase GUEST_TR_LIMIT:\n\tcase GUEST_GDTR_LIMIT:\n\tcase GUEST_IDTR_LIMIT:\n\tcase GUEST_ES_AR_BYTES:\n\tcase GUEST_DS_AR_BYTES:\n\tcase GUEST_FS_AR_BYTES:\n\tcase GUEST_GS_AR_BYTES:\n\tcase GUEST_LDTR_AR_BYTES:\n\tcase GUEST_TR_AR_BYTES:\n\tcase GUEST_ES_BASE:\n\tcase GUEST_CS_BASE:\n\tcase GUEST_SS_BASE:\n\tcase GUEST_DS_BASE:\n\tcase GUEST_FS_BASE:\n\tcase GUEST_GS_BASE:\n\tcase GUEST_LDTR_BASE:\n\tcase GUEST_TR_BASE:\n\tcase GUEST_GDTR_BASE:\n\tcase GUEST_IDTR_BASE:\n\tcase GUEST_PENDING_DBG_EXCEPTIONS:\n\tcase GUEST_BNDCFGS:\n\t\treturn true;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn false;\n}\n\nstatic void sync_vmcs02_to_vmcs12_rare(struct kvm_vcpu *vcpu,\n\t\t\t\t       struct vmcs12 *vmcs12)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\tvmcs12->guest_es_selector = vmcs_read16(GUEST_ES_SELECTOR);\n\tvmcs12->guest_cs_selector = vmcs_read16(GUEST_CS_SELECTOR);\n\tvmcs12->guest_ss_selector = vmcs_read16(GUEST_SS_SELECTOR);\n\tvmcs12->guest_ds_selector = vmcs_read16(GUEST_DS_SELECTOR);\n\tvmcs12->guest_fs_selector = vmcs_read16(GUEST_FS_SELECTOR);\n\tvmcs12->guest_gs_selector = vmcs_read16(GUEST_GS_SELECTOR);\n\tvmcs12->guest_ldtr_selector = vmcs_read16(GUEST_LDTR_SELECTOR);\n\tvmcs12->guest_tr_selector = vmcs_read16(GUEST_TR_SELECTOR);\n\tvmcs12->guest_es_limit = vmcs_read32(GUEST_ES_LIMIT);\n\tvmcs12->guest_cs_limit = vmcs_read32(GUEST_CS_LIMIT);\n\tvmcs12->guest_ss_limit = vmcs_read32(GUEST_SS_LIMIT);\n\tvmcs12->guest_ds_limit = vmcs_read32(GUEST_DS_LIMIT);\n\tvmcs12->guest_fs_limit = vmcs_read32(GUEST_FS_LIMIT);\n\tvmcs12->guest_gs_limit = vmcs_read32(GUEST_GS_LIMIT);\n\tvmcs12->guest_ldtr_limit = vmcs_read32(GUEST_LDTR_LIMIT);\n\tvmcs12->guest_tr_limit = vmcs_read32(GUEST_TR_LIMIT);\n\tvmcs12->guest_gdtr_limit = vmcs_read32(GUEST_GDTR_LIMIT);\n\tvmcs12->guest_idtr_limit = vmcs_read32(GUEST_IDTR_LIMIT);\n\tvmcs12->guest_es_ar_bytes = vmcs_read32(GUEST_ES_AR_BYTES);\n\tvmcs12->guest_ds_ar_bytes = vmcs_read32(GUEST_DS_AR_BYTES);\n\tvmcs12->guest_fs_ar_bytes = vmcs_read32(GUEST_FS_AR_BYTES);\n\tvmcs12->guest_gs_ar_bytes = vmcs_read32(GUEST_GS_AR_BYTES);\n\tvmcs12->guest_ldtr_ar_bytes = vmcs_read32(GUEST_LDTR_AR_BYTES);\n\tvmcs12->guest_tr_ar_bytes = vmcs_read32(GUEST_TR_AR_BYTES);\n\tvmcs12->guest_es_base = vmcs_readl(GUEST_ES_BASE);\n\tvmcs12->guest_cs_base = vmcs_readl(GUEST_CS_BASE);\n\tvmcs12->guest_ss_base = vmcs_readl(GUEST_SS_BASE);\n\tvmcs12->guest_ds_base = vmcs_readl(GUEST_DS_BASE);\n\tvmcs12->guest_fs_base = vmcs_readl(GUEST_FS_BASE);\n\tvmcs12->guest_gs_base = vmcs_readl(GUEST_GS_BASE);\n\tvmcs12->guest_ldtr_base = vmcs_readl(GUEST_LDTR_BASE);\n\tvmcs12->guest_tr_base = vmcs_readl(GUEST_TR_BASE);\n\tvmcs12->guest_gdtr_base = vmcs_readl(GUEST_GDTR_BASE);\n\tvmcs12->guest_idtr_base = vmcs_readl(GUEST_IDTR_BASE);\n\tvmcs12->guest_pending_dbg_exceptions =\n\t\tvmcs_readl(GUEST_PENDING_DBG_EXCEPTIONS);\n\tif (kvm_mpx_supported())\n\t\tvmcs12->guest_bndcfgs = vmcs_read64(GUEST_BNDCFGS);\n\n\tvmx->nested.need_sync_vmcs02_to_vmcs12_rare = false;\n}\n\nstatic void copy_vmcs02_to_vmcs12_rare(struct kvm_vcpu *vcpu,\n\t\t\t\t       struct vmcs12 *vmcs12)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tint cpu;\n\n\tif (!vmx->nested.need_sync_vmcs02_to_vmcs12_rare)\n\t\treturn;\n\n\n\tWARN_ON_ONCE(vmx->loaded_vmcs != &vmx->vmcs01);\n\n\tcpu = get_cpu();\n\tvmx->loaded_vmcs = &vmx->nested.vmcs02;\n\tvmx_vcpu_load_vmcs(vcpu, cpu, &vmx->vmcs01);\n\n\tsync_vmcs02_to_vmcs12_rare(vcpu, vmcs12);\n\n\tvmx->loaded_vmcs = &vmx->vmcs01;\n\tvmx_vcpu_load_vmcs(vcpu, cpu, &vmx->nested.vmcs02);\n\tput_cpu();\n}\n\n/*\n * Update the guest state fields of vmcs12 to reflect changes that\n * occurred while L2 was running. (The \"IA-32e mode guest\" bit of the\n * VM-entry controls is also updated, since this is really a guest\n * state bit.)\n */\nstatic void sync_vmcs02_to_vmcs12(struct kvm_vcpu *vcpu, struct vmcs12 *vmcs12)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\tif (vmx->nested.hv_evmcs)\n\t\tsync_vmcs02_to_vmcs12_rare(vcpu, vmcs12);\n\n\tvmx->nested.need_sync_vmcs02_to_vmcs12_rare = !vmx->nested.hv_evmcs;\n\n\tvmcs12->guest_cr0 = vmcs12_guest_cr0(vcpu, vmcs12);\n\tvmcs12->guest_cr4 = vmcs12_guest_cr4(vcpu, vmcs12);\n\n\tvmcs12->guest_rsp = kvm_rsp_read(vcpu);\n\tvmcs12->guest_rip = kvm_rip_read(vcpu);\n\tvmcs12->guest_rflags = vmcs_readl(GUEST_RFLAGS);\n\n\tvmcs12->guest_cs_ar_bytes = vmcs_read32(GUEST_CS_AR_BYTES);\n\tvmcs12->guest_ss_ar_bytes = vmcs_read32(GUEST_SS_AR_BYTES);\n\n\tvmcs12->guest_interruptibility_info =\n\t\tvmcs_read32(GUEST_INTERRUPTIBILITY_INFO);\n\n\tif (vcpu->arch.mp_state == KVM_MP_STATE_HALTED)\n\t\tvmcs12->guest_activity_state = GUEST_ACTIVITY_HLT;\n\telse if (vcpu->arch.mp_state == KVM_MP_STATE_INIT_RECEIVED)\n\t\tvmcs12->guest_activity_state = GUEST_ACTIVITY_WAIT_SIPI;\n\telse\n\t\tvmcs12->guest_activity_state = GUEST_ACTIVITY_ACTIVE;\n\n\tif (nested_cpu_has_preemption_timer(vmcs12) &&\n\t    vmcs12->vm_exit_controls & VM_EXIT_SAVE_VMX_PREEMPTION_TIMER &&\n\t    !vmx->nested.nested_run_pending)\n\t\tvmcs12->vmx_preemption_timer_value =\n\t\t\tvmx_get_preemption_timer_value(vcpu);\n\n\t/*\n\t * In some cases (usually, nested EPT), L2 is allowed to change its\n\t * own CR3 without exiting. If it has changed it, we must keep it.\n\t * Of course, if L0 is using shadow page tables, GUEST_CR3 was defined\n\t * by L0, not L1 or L2, so we mustn't unconditionally copy it to vmcs12.\n\t *\n\t * Additionally, restore L2's PDPTR to vmcs12.\n\t */\n\tif (enable_ept) {\n\t\tvmcs12->guest_cr3 = vmcs_readl(GUEST_CR3);\n\t\tif (nested_cpu_has_ept(vmcs12) && is_pae_paging(vcpu)) {\n\t\t\tvmcs12->guest_pdptr0 = vmcs_read64(GUEST_PDPTR0);\n\t\t\tvmcs12->guest_pdptr1 = vmcs_read64(GUEST_PDPTR1);\n\t\t\tvmcs12->guest_pdptr2 = vmcs_read64(GUEST_PDPTR2);\n\t\t\tvmcs12->guest_pdptr3 = vmcs_read64(GUEST_PDPTR3);\n\t\t}\n\t}\n\n\tvmcs12->guest_linear_address = vmcs_readl(GUEST_LINEAR_ADDRESS);\n\n\tif (nested_cpu_has_vid(vmcs12))\n\t\tvmcs12->guest_intr_status = vmcs_read16(GUEST_INTR_STATUS);\n\n\tvmcs12->vm_entry_controls =\n\t\t(vmcs12->vm_entry_controls & ~VM_ENTRY_IA32E_MODE) |\n\t\t(vm_entry_controls_get(to_vmx(vcpu)) & VM_ENTRY_IA32E_MODE);\n\n\tif (vmcs12->vm_exit_controls & VM_EXIT_SAVE_DEBUG_CONTROLS)\n\t\tkvm_get_dr(vcpu, 7, (unsigned long *)&vmcs12->guest_dr7);\n\n\tif (vmcs12->vm_exit_controls & VM_EXIT_SAVE_IA32_EFER)\n\t\tvmcs12->guest_ia32_efer = vcpu->arch.efer;\n}\n\n/*\n * prepare_vmcs12 is part of what we need to do when the nested L2 guest exits\n * and we want to prepare to run its L1 parent. L1 keeps a vmcs for L2 (vmcs12),\n * and this function updates it to reflect the changes to the guest state while\n * L2 was running (and perhaps made some exits which were handled directly by L0\n * without going back to L1), and to reflect the exit reason.\n * Note that we do not have to copy here all VMCS fields, just those that\n * could have changed by the L2 guest or the exit - i.e., the guest-state and\n * exit-information fields only. Other fields are modified by L1 with VMWRITE,\n * which already writes to vmcs12 directly.\n */\nstatic void prepare_vmcs12(struct kvm_vcpu *vcpu, struct vmcs12 *vmcs12,\n\t\t\t   u32 vm_exit_reason, u32 exit_intr_info,\n\t\t\t   unsigned long exit_qualification)\n{\n\t/* update exit information fields: */\n\tvmcs12->vm_exit_reason = vm_exit_reason;\n\tvmcs12->exit_qualification = exit_qualification;\n\tvmcs12->vm_exit_intr_info = exit_intr_info;\n\n\tvmcs12->idt_vectoring_info_field = 0;\n\tvmcs12->vm_exit_instruction_len = vmcs_read32(VM_EXIT_INSTRUCTION_LEN);\n\tvmcs12->vmx_instruction_info = vmcs_read32(VMX_INSTRUCTION_INFO);\n\n\tif (!(vmcs12->vm_exit_reason & VMX_EXIT_REASONS_FAILED_VMENTRY)) {\n\t\tvmcs12->launch_state = 1;\n\n\t\t/* vm_entry_intr_info_field is cleared on exit. Emulate this\n\t\t * instead of reading the real value. */\n\t\tvmcs12->vm_entry_intr_info_field &= ~INTR_INFO_VALID_MASK;\n\n\t\t/*\n\t\t * Transfer the event that L0 or L1 may wanted to inject into\n\t\t * L2 to IDT_VECTORING_INFO_FIELD.\n\t\t */\n\t\tvmcs12_save_pending_event(vcpu, vmcs12);\n\n\t\t/*\n\t\t * According to spec, there's no need to store the guest's\n\t\t * MSRs if the exit is due to a VM-entry failure that occurs\n\t\t * during or after loading the guest state. Since this exit\n\t\t * does not fall in that category, we need to save the MSRs.\n\t\t */\n\t\tif (nested_vmx_store_msr(vcpu,\n\t\t\t\t\t vmcs12->vm_exit_msr_store_addr,\n\t\t\t\t\t vmcs12->vm_exit_msr_store_count))\n\t\t\tnested_vmx_abort(vcpu,\n\t\t\t\t\t VMX_ABORT_SAVE_GUEST_MSR_FAIL);\n\t}\n\n\t/*\n\t * Drop what we picked up for L2 via vmx_complete_interrupts. It is\n\t * preserved above and would only end up incorrectly in L1.\n\t */\n\tvcpu->arch.nmi_injected = false;\n\tkvm_clear_exception_queue(vcpu);\n\tkvm_clear_interrupt_queue(vcpu);\n}\n\n/*\n * A part of what we need to when the nested L2 guest exits and we want to\n * run its L1 parent, is to reset L1's guest state to the host state specified\n * in vmcs12.\n * This function is to be called not only on normal nested exit, but also on\n * a nested entry failure, as explained in Intel's spec, 3B.23.7 (\"VM-Entry\n * Failures During or After Loading Guest State\").\n * This function should be called when the active VMCS is L1's (vmcs01).\n */\nstatic void load_vmcs12_host_state(struct kvm_vcpu *vcpu,\n\t\t\t\t   struct vmcs12 *vmcs12)\n{\n\tenum vm_entry_failure_code ignored;\n\tstruct kvm_segment seg;\n\n\tif (vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_EFER)\n\t\tvcpu->arch.efer = vmcs12->host_ia32_efer;\n\telse if (vmcs12->vm_exit_controls & VM_EXIT_HOST_ADDR_SPACE_SIZE)\n\t\tvcpu->arch.efer |= (EFER_LMA | EFER_LME);\n\telse\n\t\tvcpu->arch.efer &= ~(EFER_LMA | EFER_LME);\n\tvmx_set_efer(vcpu, vcpu->arch.efer);\n\n\tkvm_rsp_write(vcpu, vmcs12->host_rsp);\n\tkvm_rip_write(vcpu, vmcs12->host_rip);\n\tvmx_set_rflags(vcpu, X86_EFLAGS_FIXED);\n\tvmx_set_interrupt_shadow(vcpu, 0);\n\n\t/*\n\t * Note that calling vmx_set_cr0 is important, even if cr0 hasn't\n\t * actually changed, because vmx_set_cr0 refers to efer set above.\n\t *\n\t * CR0_GUEST_HOST_MASK is already set in the original vmcs01\n\t * (KVM doesn't change it);\n\t */\n\tvcpu->arch.cr0_guest_owned_bits = KVM_POSSIBLE_CR0_GUEST_BITS;\n\tvmx_set_cr0(vcpu, vmcs12->host_cr0);\n\n\t/* Same as above - no reason to call set_cr4_guest_host_mask().  */\n\tvcpu->arch.cr4_guest_owned_bits = ~vmcs_readl(CR4_GUEST_HOST_MASK);\n\tvmx_set_cr4(vcpu, vmcs12->host_cr4);\n\n\tnested_ept_uninit_mmu_context(vcpu);\n\n\t/*\n\t * Only PDPTE load can fail as the value of cr3 was checked on entry and\n\t * couldn't have changed.\n\t */\n\tif (nested_vmx_load_cr3(vcpu, vmcs12->host_cr3, false, &ignored))\n\t\tnested_vmx_abort(vcpu, VMX_ABORT_LOAD_HOST_PDPTE_FAIL);\n\n\tif (!enable_ept)\n\t\tvcpu->arch.walk_mmu->inject_page_fault = kvm_inject_page_fault;\n\n\tnested_vmx_transition_tlb_flush(vcpu, vmcs12, false);\n\n\tvmcs_write32(GUEST_SYSENTER_CS, vmcs12->host_ia32_sysenter_cs);\n\tvmcs_writel(GUEST_SYSENTER_ESP, vmcs12->host_ia32_sysenter_esp);\n\tvmcs_writel(GUEST_SYSENTER_EIP, vmcs12->host_ia32_sysenter_eip);\n\tvmcs_writel(GUEST_IDTR_BASE, vmcs12->host_idtr_base);\n\tvmcs_writel(GUEST_GDTR_BASE, vmcs12->host_gdtr_base);\n\tvmcs_write32(GUEST_IDTR_LIMIT, 0xFFFF);\n\tvmcs_write32(GUEST_GDTR_LIMIT, 0xFFFF);\n\n\t/* If not VM_EXIT_CLEAR_BNDCFGS, the L2 value propagates to L1.  */\n\tif (vmcs12->vm_exit_controls & VM_EXIT_CLEAR_BNDCFGS)\n\t\tvmcs_write64(GUEST_BNDCFGS, 0);\n\n\tif (vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_PAT) {\n\t\tvmcs_write64(GUEST_IA32_PAT, vmcs12->host_ia32_pat);\n\t\tvcpu->arch.pat = vmcs12->host_ia32_pat;\n\t}\n\tif (vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_PERF_GLOBAL_CTRL)\n\t\tWARN_ON_ONCE(kvm_set_msr(vcpu, MSR_CORE_PERF_GLOBAL_CTRL,\n\t\t\t\t\t vmcs12->host_ia32_perf_global_ctrl));\n\n\t/* Set L1 segment info according to Intel SDM\n\t    27.5.2 Loading Host Segment and Descriptor-Table Registers */\n\tseg = (struct kvm_segment) {\n\t\t.base = 0,\n\t\t.limit = 0xFFFFFFFF,\n\t\t.selector = vmcs12->host_cs_selector,\n\t\t.type = 11,\n\t\t.present = 1,\n\t\t.s = 1,\n\t\t.g = 1\n\t};\n\tif (vmcs12->vm_exit_controls & VM_EXIT_HOST_ADDR_SPACE_SIZE)\n\t\tseg.l = 1;\n\telse\n\t\tseg.db = 1;\n\tvmx_set_segment(vcpu, &seg, VCPU_SREG_CS);\n\tseg = (struct kvm_segment) {\n\t\t.base = 0,\n\t\t.limit = 0xFFFFFFFF,\n\t\t.type = 3,\n\t\t.present = 1,\n\t\t.s = 1,\n\t\t.db = 1,\n\t\t.g = 1\n\t};\n\tseg.selector = vmcs12->host_ds_selector;\n\tvmx_set_segment(vcpu, &seg, VCPU_SREG_DS);\n\tseg.selector = vmcs12->host_es_selector;\n\tvmx_set_segment(vcpu, &seg, VCPU_SREG_ES);\n\tseg.selector = vmcs12->host_ss_selector;\n\tvmx_set_segment(vcpu, &seg, VCPU_SREG_SS);\n\tseg.selector = vmcs12->host_fs_selector;\n\tseg.base = vmcs12->host_fs_base;\n\tvmx_set_segment(vcpu, &seg, VCPU_SREG_FS);\n\tseg.selector = vmcs12->host_gs_selector;\n\tseg.base = vmcs12->host_gs_base;\n\tvmx_set_segment(vcpu, &seg, VCPU_SREG_GS);\n\tseg = (struct kvm_segment) {\n\t\t.base = vmcs12->host_tr_base,\n\t\t.limit = 0x67,\n\t\t.selector = vmcs12->host_tr_selector,\n\t\t.type = 11,\n\t\t.present = 1\n\t};\n\tvmx_set_segment(vcpu, &seg, VCPU_SREG_TR);\n\n\tkvm_set_dr(vcpu, 7, 0x400);\n\tvmcs_write64(GUEST_IA32_DEBUGCTL, 0);\n\n\tif (cpu_has_vmx_msr_bitmap())\n\t\tvmx_update_msr_bitmap(vcpu);\n\n\tif (nested_vmx_load_msr(vcpu, vmcs12->vm_exit_msr_load_addr,\n\t\t\t\tvmcs12->vm_exit_msr_load_count))\n\t\tnested_vmx_abort(vcpu, VMX_ABORT_LOAD_HOST_MSR_FAIL);\n}\n\nstatic inline u64 nested_vmx_get_vmcs01_guest_efer(struct vcpu_vmx *vmx)\n{\n\tstruct vmx_uret_msr *efer_msr;\n\tunsigned int i;\n\n\tif (vm_entry_controls_get(vmx) & VM_ENTRY_LOAD_IA32_EFER)\n\t\treturn vmcs_read64(GUEST_IA32_EFER);\n\n\tif (cpu_has_load_ia32_efer())\n\t\treturn host_efer;\n\n\tfor (i = 0; i < vmx->msr_autoload.guest.nr; ++i) {\n\t\tif (vmx->msr_autoload.guest.val[i].index == MSR_EFER)\n\t\t\treturn vmx->msr_autoload.guest.val[i].value;\n\t}\n\n\tefer_msr = vmx_find_uret_msr(vmx, MSR_EFER);\n\tif (efer_msr)\n\t\treturn efer_msr->data;\n\n\treturn host_efer;\n}\n\nstatic void nested_vmx_restore_host_state(struct kvm_vcpu *vcpu)\n{\n\tstruct vmcs12 *vmcs12 = get_vmcs12(vcpu);\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tstruct vmx_msr_entry g, h;\n\tgpa_t gpa;\n\tu32 i, j;\n\n\tvcpu->arch.pat = vmcs_read64(GUEST_IA32_PAT);\n\n\tif (vmcs12->vm_entry_controls & VM_ENTRY_LOAD_DEBUG_CONTROLS) {\n\t\t/*\n\t\t * L1's host DR7 is lost if KVM_GUESTDBG_USE_HW_BP is set\n\t\t * as vmcs01.GUEST_DR7 contains a userspace defined value\n\t\t * and vcpu->arch.dr7 is not squirreled away before the\n\t\t * nested VMENTER (not worth adding a variable in nested_vmx).\n\t\t */\n\t\tif (vcpu->guest_debug & KVM_GUESTDBG_USE_HW_BP)\n\t\t\tkvm_set_dr(vcpu, 7, DR7_FIXED_1);\n\t\telse\n\t\t\tWARN_ON(kvm_set_dr(vcpu, 7, vmcs_readl(GUEST_DR7)));\n\t}\n\n\t/*\n\t * Note that calling vmx_set_{efer,cr0,cr4} is important as they\n\t * handle a variety of side effects to KVM's software model.\n\t */\n\tvmx_set_efer(vcpu, nested_vmx_get_vmcs01_guest_efer(vmx));\n\n\tvcpu->arch.cr0_guest_owned_bits = KVM_POSSIBLE_CR0_GUEST_BITS;\n\tvmx_set_cr0(vcpu, vmcs_readl(CR0_READ_SHADOW));\n\n\tvcpu->arch.cr4_guest_owned_bits = ~vmcs_readl(CR4_GUEST_HOST_MASK);\n\tvmx_set_cr4(vcpu, vmcs_readl(CR4_READ_SHADOW));\n\n\tnested_ept_uninit_mmu_context(vcpu);\n\tvcpu->arch.cr3 = vmcs_readl(GUEST_CR3);\n\tkvm_register_mark_available(vcpu, VCPU_EXREG_CR3);\n\n\t/*\n\t * Use ept_save_pdptrs(vcpu) to load the MMU's cached PDPTRs\n\t * from vmcs01 (if necessary).  The PDPTRs are not loaded on\n\t * VMFail, like everything else we just need to ensure our\n\t * software model is up-to-date.\n\t */\n\tif (enable_ept && is_pae_paging(vcpu))\n\t\tept_save_pdptrs(vcpu);\n\n\tkvm_mmu_reset_context(vcpu);\n\n\tif (cpu_has_vmx_msr_bitmap())\n\t\tvmx_update_msr_bitmap(vcpu);\n\n\t/*\n\t * This nasty bit of open coding is a compromise between blindly\n\t * loading L1's MSRs using the exit load lists (incorrect emulation\n\t * of VMFail), leaving the nested VM's MSRs in the software model\n\t * (incorrect behavior) and snapshotting the modified MSRs (too\n\t * expensive since the lists are unbound by hardware).  For each\n\t * MSR that was (prematurely) loaded from the nested VMEntry load\n\t * list, reload it from the exit load list if it exists and differs\n\t * from the guest value.  The intent is to stuff host state as\n\t * silently as possible, not to fully process the exit load list.\n\t */\n\tfor (i = 0; i < vmcs12->vm_entry_msr_load_count; i++) {\n\t\tgpa = vmcs12->vm_entry_msr_load_addr + (i * sizeof(g));\n\t\tif (kvm_vcpu_read_guest(vcpu, gpa, &g, sizeof(g))) {\n\t\t\tpr_debug_ratelimited(\n\t\t\t\t\"%s read MSR index failed (%u, 0x%08llx)\\n\",\n\t\t\t\t__func__, i, gpa);\n\t\t\tgoto vmabort;\n\t\t}\n\n\t\tfor (j = 0; j < vmcs12->vm_exit_msr_load_count; j++) {\n\t\t\tgpa = vmcs12->vm_exit_msr_load_addr + (j * sizeof(h));\n\t\t\tif (kvm_vcpu_read_guest(vcpu, gpa, &h, sizeof(h))) {\n\t\t\t\tpr_debug_ratelimited(\n\t\t\t\t\t\"%s read MSR failed (%u, 0x%08llx)\\n\",\n\t\t\t\t\t__func__, j, gpa);\n\t\t\t\tgoto vmabort;\n\t\t\t}\n\t\t\tif (h.index != g.index)\n\t\t\t\tcontinue;\n\t\t\tif (h.value == g.value)\n\t\t\t\tbreak;\n\n\t\t\tif (nested_vmx_load_msr_check(vcpu, &h)) {\n\t\t\t\tpr_debug_ratelimited(\n\t\t\t\t\t\"%s check failed (%u, 0x%x, 0x%x)\\n\",\n\t\t\t\t\t__func__, j, h.index, h.reserved);\n\t\t\t\tgoto vmabort;\n\t\t\t}\n\n\t\t\tif (kvm_set_msr(vcpu, h.index, h.value)) {\n\t\t\t\tpr_debug_ratelimited(\n\t\t\t\t\t\"%s WRMSR failed (%u, 0x%x, 0x%llx)\\n\",\n\t\t\t\t\t__func__, j, h.index, h.value);\n\t\t\t\tgoto vmabort;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn;\n\nvmabort:\n\tnested_vmx_abort(vcpu, VMX_ABORT_LOAD_HOST_MSR_FAIL);\n}\n\n/*\n * Emulate an exit from nested guest (L2) to L1, i.e., prepare to run L1\n * and modify vmcs12 to make it see what it would expect to see there if\n * L2 was its real guest. Must only be called when in L2 (is_guest_mode())\n */\nvoid nested_vmx_vmexit(struct kvm_vcpu *vcpu, u32 vm_exit_reason,\n\t\t       u32 exit_intr_info, unsigned long exit_qualification)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tstruct vmcs12 *vmcs12 = get_vmcs12(vcpu);\n\n\t/* trying to cancel vmlaunch/vmresume is a bug */\n\tWARN_ON_ONCE(vmx->nested.nested_run_pending);\n\n\tkvm_clear_request(KVM_REQ_GET_NESTED_STATE_PAGES, vcpu);\n\n\t/* Service the TLB flush request for L2 before switching to L1. */\n\tif (kvm_check_request(KVM_REQ_TLB_FLUSH_CURRENT, vcpu))\n\t\tkvm_vcpu_flush_tlb_current(vcpu);\n\n\t/*\n\t * VCPU_EXREG_PDPTR will be clobbered in arch/x86/kvm/vmx/vmx.h between\n\t * now and the new vmentry.  Ensure that the VMCS02 PDPTR fields are\n\t * up-to-date before switching to L1.\n\t */\n\tif (enable_ept && is_pae_paging(vcpu))\n\t\tvmx_ept_load_pdptrs(vcpu);\n\n\tleave_guest_mode(vcpu);\n\n\tif (nested_cpu_has_preemption_timer(vmcs12))\n\t\thrtimer_cancel(&to_vmx(vcpu)->nested.preemption_timer);\n\n\tif (vmcs12->cpu_based_vm_exec_control & CPU_BASED_USE_TSC_OFFSETTING)\n\t\tvcpu->arch.tsc_offset -= vmcs12->tsc_offset;\n\n\tif (likely(!vmx->fail)) {\n\t\tsync_vmcs02_to_vmcs12(vcpu, vmcs12);\n\n\t\tif (vm_exit_reason != -1)\n\t\t\tprepare_vmcs12(vcpu, vmcs12, vm_exit_reason,\n\t\t\t\t       exit_intr_info, exit_qualification);\n\n\t\t/*\n\t\t * Must happen outside of sync_vmcs02_to_vmcs12() as it will\n\t\t * also be used to capture vmcs12 cache as part of\n\t\t * capturing nVMX state for snapshot (migration).\n\t\t *\n\t\t * Otherwise, this flush will dirty guest memory at a\n\t\t * point it is already assumed by user-space to be\n\t\t * immutable.\n\t\t */\n\t\tnested_flush_cached_shadow_vmcs12(vcpu, vmcs12);\n\t} else {\n\t\t/*\n\t\t * The only expected VM-instruction error is \"VM entry with\n\t\t * invalid control field(s).\" Anything else indicates a\n\t\t * problem with L0.  And we should never get here with a\n\t\t * VMFail of any type if early consistency checks are enabled.\n\t\t */\n\t\tWARN_ON_ONCE(vmcs_read32(VM_INSTRUCTION_ERROR) !=\n\t\t\t     VMXERR_ENTRY_INVALID_CONTROL_FIELD);\n\t\tWARN_ON_ONCE(nested_early_check);\n\t}\n\n\tvmx_switch_vmcs(vcpu, &vmx->vmcs01);\n\n\t/* Update any VMCS fields that might have changed while L2 ran */\n\tvmcs_write32(VM_EXIT_MSR_LOAD_COUNT, vmx->msr_autoload.host.nr);\n\tvmcs_write32(VM_ENTRY_MSR_LOAD_COUNT, vmx->msr_autoload.guest.nr);\n\tvmcs_write64(TSC_OFFSET, vcpu->arch.tsc_offset);\n\tif (vmx->nested.l1_tpr_threshold != -1)\n\t\tvmcs_write32(TPR_THRESHOLD, vmx->nested.l1_tpr_threshold);\n\n\tif (kvm_has_tsc_control)\n\t\tdecache_tsc_multiplier(vmx);\n\n\tif (vmx->nested.change_vmcs01_virtual_apic_mode) {\n\t\tvmx->nested.change_vmcs01_virtual_apic_mode = false;\n\t\tvmx_set_virtual_apic_mode(vcpu);\n\t}\n\n\t/* Unpin physical memory we referred to in vmcs02 */\n\tif (vmx->nested.apic_access_page) {\n\t\tkvm_release_page_clean(vmx->nested.apic_access_page);\n\t\tvmx->nested.apic_access_page = NULL;\n\t}\n\tkvm_vcpu_unmap(vcpu, &vmx->nested.virtual_apic_map, true);\n\tkvm_vcpu_unmap(vcpu, &vmx->nested.pi_desc_map, true);\n\tvmx->nested.pi_desc = NULL;\n\n\tif (vmx->nested.reload_vmcs01_apic_access_page) {\n\t\tvmx->nested.reload_vmcs01_apic_access_page = false;\n\t\tkvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);\n\t}\n\n\tif ((vm_exit_reason != -1) &&\n\t    (enable_shadow_vmcs || vmx->nested.hv_evmcs))\n\t\tvmx->nested.need_vmcs12_to_shadow_sync = true;\n\n\t/* in case we halted in L2 */\n\tvcpu->arch.mp_state = KVM_MP_STATE_RUNNABLE;\n\n\tif (likely(!vmx->fail)) {\n\t\tif ((u16)vm_exit_reason == EXIT_REASON_EXTERNAL_INTERRUPT &&\n\t\t    nested_exit_intr_ack_set(vcpu)) {\n\t\t\tint irq = kvm_cpu_get_interrupt(vcpu);\n\t\t\tWARN_ON(irq < 0);\n\t\t\tvmcs12->vm_exit_intr_info = irq |\n\t\t\t\tINTR_INFO_VALID_MASK | INTR_TYPE_EXT_INTR;\n\t\t}\n\n\t\tif (vm_exit_reason != -1)\n\t\t\ttrace_kvm_nested_vmexit_inject(vmcs12->vm_exit_reason,\n\t\t\t\t\t\t       vmcs12->exit_qualification,\n\t\t\t\t\t\t       vmcs12->idt_vectoring_info_field,\n\t\t\t\t\t\t       vmcs12->vm_exit_intr_info,\n\t\t\t\t\t\t       vmcs12->vm_exit_intr_error_code,\n\t\t\t\t\t\t       KVM_ISA_VMX);\n\n\t\tload_vmcs12_host_state(vcpu, vmcs12);\n\n\t\treturn;\n\t}\n\n\t/*\n\t * After an early L2 VM-entry failure, we're now back\n\t * in L1 which thinks it just finished a VMLAUNCH or\n\t * VMRESUME instruction, so we need to set the failure\n\t * flag and the VM-instruction error field of the VMCS\n\t * accordingly, and skip the emulated instruction.\n\t */\n\t(void)nested_vmx_fail(vcpu, VMXERR_ENTRY_INVALID_CONTROL_FIELD);\n\n\t/*\n\t * Restore L1's host state to KVM's software model.  We're here\n\t * because a consistency check was caught by hardware, which\n\t * means some amount of guest state has been propagated to KVM's\n\t * model and needs to be unwound to the host's state.\n\t */\n\tnested_vmx_restore_host_state(vcpu);\n\n\tvmx->fail = 0;\n}\n\n/*\n * Decode the memory-address operand of a vmx instruction, as recorded on an\n * exit caused by such an instruction (run by a guest hypervisor).\n * On success, returns 0. When the operand is invalid, returns 1 and throws\n * #UD, #GP, or #SS.\n */\nint get_vmx_mem_address(struct kvm_vcpu *vcpu, unsigned long exit_qualification,\n\t\t\tu32 vmx_instruction_info, bool wr, int len, gva_t *ret)\n{\n\tgva_t off;\n\tbool exn;\n\tstruct kvm_segment s;\n\n\t/*\n\t * According to Vol. 3B, \"Information for VM Exits Due to Instruction\n\t * Execution\", on an exit, vmx_instruction_info holds most of the\n\t * addressing components of the operand. Only the displacement part\n\t * is put in exit_qualification (see 3B, \"Basic VM-Exit Information\").\n\t * For how an actual address is calculated from all these components,\n\t * refer to Vol. 1, \"Operand Addressing\".\n\t */\n\tint  scaling = vmx_instruction_info & 3;\n\tint  addr_size = (vmx_instruction_info >> 7) & 7;\n\tbool is_reg = vmx_instruction_info & (1u << 10);\n\tint  seg_reg = (vmx_instruction_info >> 15) & 7;\n\tint  index_reg = (vmx_instruction_info >> 18) & 0xf;\n\tbool index_is_valid = !(vmx_instruction_info & (1u << 22));\n\tint  base_reg       = (vmx_instruction_info >> 23) & 0xf;\n\tbool base_is_valid  = !(vmx_instruction_info & (1u << 27));\n\n\tif (is_reg) {\n\t\tkvm_queue_exception(vcpu, UD_VECTOR);\n\t\treturn 1;\n\t}\n\n\t/* Addr = segment_base + offset */\n\t/* offset = base + [index * scale] + displacement */\n\toff = exit_qualification; /* holds the displacement */\n\tif (addr_size == 1)\n\t\toff = (gva_t)sign_extend64(off, 31);\n\telse if (addr_size == 0)\n\t\toff = (gva_t)sign_extend64(off, 15);\n\tif (base_is_valid)\n\t\toff += kvm_register_read(vcpu, base_reg);\n\tif (index_is_valid)\n\t\toff += kvm_register_read(vcpu, index_reg) << scaling;\n\tvmx_get_segment(vcpu, &s, seg_reg);\n\n\t/*\n\t * The effective address, i.e. @off, of a memory operand is truncated\n\t * based on the address size of the instruction.  Note that this is\n\t * the *effective address*, i.e. the address prior to accounting for\n\t * the segment's base.\n\t */\n\tif (addr_size == 1) /* 32 bit */\n\t\toff &= 0xffffffff;\n\telse if (addr_size == 0) /* 16 bit */\n\t\toff &= 0xffff;\n\n\t/* Checks for #GP/#SS exceptions. */\n\texn = false;\n\tif (is_long_mode(vcpu)) {\n\t\t/*\n\t\t * The virtual/linear address is never truncated in 64-bit\n\t\t * mode, e.g. a 32-bit address size can yield a 64-bit virtual\n\t\t * address when using FS/GS with a non-zero base.\n\t\t */\n\t\tif (seg_reg == VCPU_SREG_FS || seg_reg == VCPU_SREG_GS)\n\t\t\t*ret = s.base + off;\n\t\telse\n\t\t\t*ret = off;\n\n\t\t/* Long mode: #GP(0)/#SS(0) if the memory address is in a\n\t\t * non-canonical form. This is the only check on the memory\n\t\t * destination for long mode!\n\t\t */\n\t\texn = is_noncanonical_address(*ret, vcpu);\n\t} else {\n\t\t/*\n\t\t * When not in long mode, the virtual/linear address is\n\t\t * unconditionally truncated to 32 bits regardless of the\n\t\t * address size.\n\t\t */\n\t\t*ret = (s.base + off) & 0xffffffff;\n\n\t\t/* Protected mode: apply checks for segment validity in the\n\t\t * following order:\n\t\t * - segment type check (#GP(0) may be thrown)\n\t\t * - usability check (#GP(0)/#SS(0))\n\t\t * - limit check (#GP(0)/#SS(0))\n\t\t */\n\t\tif (wr)\n\t\t\t/* #GP(0) if the destination operand is located in a\n\t\t\t * read-only data segment or any code segment.\n\t\t\t */\n\t\t\texn = ((s.type & 0xa) == 0 || (s.type & 8));\n\t\telse\n\t\t\t/* #GP(0) if the source operand is located in an\n\t\t\t * execute-only code segment\n\t\t\t */\n\t\t\texn = ((s.type & 0xa) == 8);\n\t\tif (exn) {\n\t\t\tkvm_queue_exception_e(vcpu, GP_VECTOR, 0);\n\t\t\treturn 1;\n\t\t}\n\t\t/* Protected mode: #GP(0)/#SS(0) if the segment is unusable.\n\t\t */\n\t\texn = (s.unusable != 0);\n\n\t\t/*\n\t\t * Protected mode: #GP(0)/#SS(0) if the memory operand is\n\t\t * outside the segment limit.  All CPUs that support VMX ignore\n\t\t * limit checks for flat segments, i.e. segments with base==0,\n\t\t * limit==0xffffffff and of type expand-up data or code.\n\t\t */\n\t\tif (!(s.base == 0 && s.limit == 0xffffffff &&\n\t\t     ((s.type & 8) || !(s.type & 4))))\n\t\t\texn = exn || ((u64)off + len - 1 > s.limit);\n\t}\n\tif (exn) {\n\t\tkvm_queue_exception_e(vcpu,\n\t\t\t\t      seg_reg == VCPU_SREG_SS ?\n\t\t\t\t\t\tSS_VECTOR : GP_VECTOR,\n\t\t\t\t      0);\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\nvoid nested_vmx_pmu_entry_exit_ctls_update(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx;\n\n\tif (!nested_vmx_allowed(vcpu))\n\t\treturn;\n\n\tvmx = to_vmx(vcpu);\n\tif (kvm_x86_ops.pmu_ops->is_valid_msr(vcpu, MSR_CORE_PERF_GLOBAL_CTRL)) {\n\t\tvmx->nested.msrs.entry_ctls_high |=\n\t\t\t\tVM_ENTRY_LOAD_IA32_PERF_GLOBAL_CTRL;\n\t\tvmx->nested.msrs.exit_ctls_high |=\n\t\t\t\tVM_EXIT_LOAD_IA32_PERF_GLOBAL_CTRL;\n\t} else {\n\t\tvmx->nested.msrs.entry_ctls_high &=\n\t\t\t\t~VM_ENTRY_LOAD_IA32_PERF_GLOBAL_CTRL;\n\t\tvmx->nested.msrs.exit_ctls_high &=\n\t\t\t\t~VM_EXIT_LOAD_IA32_PERF_GLOBAL_CTRL;\n\t}\n}\n\nstatic int nested_vmx_get_vmptr(struct kvm_vcpu *vcpu, gpa_t *vmpointer,\n\t\t\t\tint *ret)\n{\n\tgva_t gva;\n\tstruct x86_exception e;\n\tint r;\n\n\tif (get_vmx_mem_address(vcpu, vmx_get_exit_qual(vcpu),\n\t\t\t\tvmcs_read32(VMX_INSTRUCTION_INFO), false,\n\t\t\t\tsizeof(*vmpointer), &gva)) {\n\t\t*ret = 1;\n\t\treturn -EINVAL;\n\t}\n\n\tr = kvm_read_guest_virt(vcpu, gva, vmpointer, sizeof(*vmpointer), &e);\n\tif (r != X86EMUL_CONTINUE) {\n\t\t*ret = kvm_handle_memory_failure(vcpu, r, &e);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\n/*\n * Allocate a shadow VMCS and associate it with the currently loaded\n * VMCS, unless such a shadow VMCS already exists. The newly allocated\n * VMCS is also VMCLEARed, so that it is ready for use.\n */\nstatic struct vmcs *alloc_shadow_vmcs(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tstruct loaded_vmcs *loaded_vmcs = vmx->loaded_vmcs;\n\n\t/*\n\t * We should allocate a shadow vmcs for vmcs01 only when L1\n\t * executes VMXON and free it when L1 executes VMXOFF.\n\t * As it is invalid to execute VMXON twice, we shouldn't reach\n\t * here when vmcs01 already have an allocated shadow vmcs.\n\t */\n\tWARN_ON(loaded_vmcs == &vmx->vmcs01 && loaded_vmcs->shadow_vmcs);\n\n\tif (!loaded_vmcs->shadow_vmcs) {\n\t\tloaded_vmcs->shadow_vmcs = alloc_vmcs(true);\n\t\tif (loaded_vmcs->shadow_vmcs)\n\t\t\tvmcs_clear(loaded_vmcs->shadow_vmcs);\n\t}\n\treturn loaded_vmcs->shadow_vmcs;\n}\n\nstatic int enter_vmx_operation(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tint r;\n\n\tr = alloc_loaded_vmcs(&vmx->nested.vmcs02);\n\tif (r < 0)\n\t\tgoto out_vmcs02;\n\n\tvmx->nested.cached_vmcs12 = kzalloc(VMCS12_SIZE, GFP_KERNEL_ACCOUNT);\n\tif (!vmx->nested.cached_vmcs12)\n\t\tgoto out_cached_vmcs12;\n\n\tvmx->nested.cached_shadow_vmcs12 = kzalloc(VMCS12_SIZE, GFP_KERNEL_ACCOUNT);\n\tif (!vmx->nested.cached_shadow_vmcs12)\n\t\tgoto out_cached_shadow_vmcs12;\n\n\tif (enable_shadow_vmcs && !alloc_shadow_vmcs(vcpu))\n\t\tgoto out_shadow_vmcs;\n\n\thrtimer_init(&vmx->nested.preemption_timer, CLOCK_MONOTONIC,\n\t\t     HRTIMER_MODE_ABS_PINNED);\n\tvmx->nested.preemption_timer.function = vmx_preemption_timer_fn;\n\n\tvmx->nested.vpid02 = allocate_vpid();\n\n\tvmx->nested.vmcs02_initialized = false;\n\tvmx->nested.vmxon = true;\n\n\tif (vmx_pt_mode_is_host_guest()) {\n\t\tvmx->pt_desc.guest.ctl = 0;\n\t\tpt_update_intercept_for_msr(vcpu);\n\t}\n\n\treturn 0;\n\nout_shadow_vmcs:\n\tkfree(vmx->nested.cached_shadow_vmcs12);\n\nout_cached_shadow_vmcs12:\n\tkfree(vmx->nested.cached_vmcs12);\n\nout_cached_vmcs12:\n\tfree_loaded_vmcs(&vmx->nested.vmcs02);\n\nout_vmcs02:\n\treturn -ENOMEM;\n}\n\n/*\n * Emulate the VMXON instruction.\n * Currently, we just remember that VMX is active, and do not save or even\n * inspect the argument to VMXON (the so-called \"VMXON pointer\") because we\n * do not currently need to store anything in that guest-allocated memory\n * region. Consequently, VMCLEAR and VMPTRLD also do not verify that the their\n * argument is different from the VMXON pointer (which the spec says they do).\n */\nstatic int handle_vmon(struct kvm_vcpu *vcpu)\n{\n\tint ret;\n\tgpa_t vmptr;\n\tuint32_t revision;\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tconst u64 VMXON_NEEDED_FEATURES = FEAT_CTL_LOCKED\n\t\t| FEAT_CTL_VMX_ENABLED_OUTSIDE_SMX;\n\n\t/*\n\t * The Intel VMX Instruction Reference lists a bunch of bits that are\n\t * prerequisite to running VMXON, most notably cr4.VMXE must be set to\n\t * 1 (see vmx_is_valid_cr4() for when we allow the guest to set this).\n\t * Otherwise, we should fail with #UD.  But most faulting conditions\n\t * have already been checked by hardware, prior to the VM-exit for\n\t * VMXON.  We do test guest cr4.VMXE because processor CR4 always has\n\t * that bit set to 1 in non-root mode.\n\t */\n\tif (!kvm_read_cr4_bits(vcpu, X86_CR4_VMXE)) {\n\t\tkvm_queue_exception(vcpu, UD_VECTOR);\n\t\treturn 1;\n\t}\n\n\t/* CPL=0 must be checked manually. */\n\tif (vmx_get_cpl(vcpu)) {\n\t\tkvm_inject_gp(vcpu, 0);\n\t\treturn 1;\n\t}\n\n\tif (vmx->nested.vmxon)\n\t\treturn nested_vmx_fail(vcpu, VMXERR_VMXON_IN_VMX_ROOT_OPERATION);\n\n\tif ((vmx->msr_ia32_feature_control & VMXON_NEEDED_FEATURES)\n\t\t\t!= VMXON_NEEDED_FEATURES) {\n\t\tkvm_inject_gp(vcpu, 0);\n\t\treturn 1;\n\t}\n\n\tif (nested_vmx_get_vmptr(vcpu, &vmptr, &ret))\n\t\treturn ret;\n\n\t/*\n\t * SDM 3: 24.11.5\n\t * The first 4 bytes of VMXON region contain the supported\n\t * VMCS revision identifier\n\t *\n\t * Note - IA32_VMX_BASIC[48] will never be 1 for the nested case;\n\t * which replaces physical address width with 32\n\t */\n\tif (!page_address_valid(vcpu, vmptr))\n\t\treturn nested_vmx_failInvalid(vcpu);\n\n\tif (kvm_read_guest(vcpu->kvm, vmptr, &revision, sizeof(revision)) ||\n\t    revision != VMCS12_REVISION)\n\t\treturn nested_vmx_failInvalid(vcpu);\n\n\tvmx->nested.vmxon_ptr = vmptr;\n\tret = enter_vmx_operation(vcpu);\n\tif (ret)\n\t\treturn ret;\n\n\treturn nested_vmx_succeed(vcpu);\n}\n\nstatic inline void nested_release_vmcs12(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\tif (vmx->nested.current_vmptr == -1ull)\n\t\treturn;\n\n\tcopy_vmcs02_to_vmcs12_rare(vcpu, get_vmcs12(vcpu));\n\n\tif (enable_shadow_vmcs) {\n\t\t/* copy to memory all shadowed fields in case\n\t\t   they were modified */\n\t\tcopy_shadow_to_vmcs12(vmx);\n\t\tvmx_disable_shadow_vmcs(vmx);\n\t}\n\tvmx->nested.posted_intr_nv = -1;\n\n\t/* Flush VMCS12 to guest memory */\n\tkvm_vcpu_write_guest_page(vcpu,\n\t\t\t\t  vmx->nested.current_vmptr >> PAGE_SHIFT,\n\t\t\t\t  vmx->nested.cached_vmcs12, 0, VMCS12_SIZE);\n\n\tkvm_mmu_free_roots(vcpu, &vcpu->arch.guest_mmu, KVM_MMU_ROOTS_ALL);\n\n\tvmx->nested.current_vmptr = -1ull;\n}\n\n/* Emulate the VMXOFF instruction */\nstatic int handle_vmoff(struct kvm_vcpu *vcpu)\n{\n\tif (!nested_vmx_check_permission(vcpu))\n\t\treturn 1;\n\n\tfree_nested(vcpu);\n\n\t/* Process a latched INIT during time CPU was in VMX operation */\n\tkvm_make_request(KVM_REQ_EVENT, vcpu);\n\n\treturn nested_vmx_succeed(vcpu);\n}\n\n/* Emulate the VMCLEAR instruction */\nstatic int handle_vmclear(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tu32 zero = 0;\n\tgpa_t vmptr;\n\tu64 evmcs_gpa;\n\tint r;\n\n\tif (!nested_vmx_check_permission(vcpu))\n\t\treturn 1;\n\n\tif (nested_vmx_get_vmptr(vcpu, &vmptr, &r))\n\t\treturn r;\n\n\tif (!page_address_valid(vcpu, vmptr))\n\t\treturn nested_vmx_fail(vcpu, VMXERR_VMCLEAR_INVALID_ADDRESS);\n\n\tif (vmptr == vmx->nested.vmxon_ptr)\n\t\treturn nested_vmx_fail(vcpu, VMXERR_VMCLEAR_VMXON_POINTER);\n\n\t/*\n\t * When Enlightened VMEntry is enabled on the calling CPU we treat\n\t * memory area pointer by vmptr as Enlightened VMCS (as there's no good\n\t * way to distinguish it from VMCS12) and we must not corrupt it by\n\t * writing to the non-existent 'launch_state' field. The area doesn't\n\t * have to be the currently active EVMCS on the calling CPU and there's\n\t * nothing KVM has to do to transition it from 'active' to 'non-active'\n\t * state. It is possible that the area will stay mapped as\n\t * vmx->nested.hv_evmcs but this shouldn't be a problem.\n\t */\n\tif (likely(!vmx->nested.enlightened_vmcs_enabled ||\n\t\t   !nested_enlightened_vmentry(vcpu, &evmcs_gpa))) {\n\t\tif (vmptr == vmx->nested.current_vmptr)\n\t\t\tnested_release_vmcs12(vcpu);\n\n\t\tkvm_vcpu_write_guest(vcpu,\n\t\t\t\t     vmptr + offsetof(struct vmcs12,\n\t\t\t\t\t\t      launch_state),\n\t\t\t\t     &zero, sizeof(zero));\n\t}\n\n\treturn nested_vmx_succeed(vcpu);\n}\n\n/* Emulate the VMLAUNCH instruction */\nstatic int handle_vmlaunch(struct kvm_vcpu *vcpu)\n{\n\treturn nested_vmx_run(vcpu, true);\n}\n\n/* Emulate the VMRESUME instruction */\nstatic int handle_vmresume(struct kvm_vcpu *vcpu)\n{\n\n\treturn nested_vmx_run(vcpu, false);\n}\n\nstatic int handle_vmread(struct kvm_vcpu *vcpu)\n{\n\tstruct vmcs12 *vmcs12 = is_guest_mode(vcpu) ? get_shadow_vmcs12(vcpu)\n\t\t\t\t\t\t    : get_vmcs12(vcpu);\n\tunsigned long exit_qualification = vmx_get_exit_qual(vcpu);\n\tu32 instr_info = vmcs_read32(VMX_INSTRUCTION_INFO);\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tstruct x86_exception e;\n\tunsigned long field;\n\tu64 value;\n\tgva_t gva = 0;\n\tshort offset;\n\tint len, r;\n\n\tif (!nested_vmx_check_permission(vcpu))\n\t\treturn 1;\n\n\t/*\n\t * In VMX non-root operation, when the VMCS-link pointer is -1ull,\n\t * any VMREAD sets the ALU flags for VMfailInvalid.\n\t */\n\tif (vmx->nested.current_vmptr == -1ull ||\n\t    (is_guest_mode(vcpu) &&\n\t     get_vmcs12(vcpu)->vmcs_link_pointer == -1ull))\n\t\treturn nested_vmx_failInvalid(vcpu);\n\n\t/* Decode instruction info and find the field to read */\n\tfield = kvm_register_readl(vcpu, (((instr_info) >> 28) & 0xf));\n\n\toffset = vmcs_field_to_offset(field);\n\tif (offset < 0)\n\t\treturn nested_vmx_fail(vcpu, VMXERR_UNSUPPORTED_VMCS_COMPONENT);\n\n\tif (!is_guest_mode(vcpu) && is_vmcs12_ext_field(field))\n\t\tcopy_vmcs02_to_vmcs12_rare(vcpu, vmcs12);\n\n\t/* Read the field, zero-extended to a u64 value */\n\tvalue = vmcs12_read_any(vmcs12, field, offset);\n\n\t/*\n\t * Now copy part of this value to register or memory, as requested.\n\t * Note that the number of bits actually copied is 32 or 64 depending\n\t * on the guest's mode (32 or 64 bit), not on the given field's length.\n\t */\n\tif (instr_info & BIT(10)) {\n\t\tkvm_register_writel(vcpu, (((instr_info) >> 3) & 0xf), value);\n\t} else {\n\t\tlen = is_64_bit_mode(vcpu) ? 8 : 4;\n\t\tif (get_vmx_mem_address(vcpu, exit_qualification,\n\t\t\t\t\tinstr_info, true, len, &gva))\n\t\t\treturn 1;\n\t\t/* _system ok, nested_vmx_check_permission has verified cpl=0 */\n\t\tr = kvm_write_guest_virt_system(vcpu, gva, &value, len, &e);\n\t\tif (r != X86EMUL_CONTINUE)\n\t\t\treturn kvm_handle_memory_failure(vcpu, r, &e);\n\t}\n\n\treturn nested_vmx_succeed(vcpu);\n}\n\nstatic bool is_shadow_field_rw(unsigned long field)\n{\n\tswitch (field) {\n#define SHADOW_FIELD_RW(x, y) case x:\n#include \"vmcs_shadow_fields.h\"\n\t\treturn true;\n\tdefault:\n\t\tbreak;\n\t}\n\treturn false;\n}\n\nstatic bool is_shadow_field_ro(unsigned long field)\n{\n\tswitch (field) {\n#define SHADOW_FIELD_RO(x, y) case x:\n#include \"vmcs_shadow_fields.h\"\n\t\treturn true;\n\tdefault:\n\t\tbreak;\n\t}\n\treturn false;\n}\n\nstatic int handle_vmwrite(struct kvm_vcpu *vcpu)\n{\n\tstruct vmcs12 *vmcs12 = is_guest_mode(vcpu) ? get_shadow_vmcs12(vcpu)\n\t\t\t\t\t\t    : get_vmcs12(vcpu);\n\tunsigned long exit_qualification = vmx_get_exit_qual(vcpu);\n\tu32 instr_info = vmcs_read32(VMX_INSTRUCTION_INFO);\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tstruct x86_exception e;\n\tunsigned long field;\n\tshort offset;\n\tgva_t gva;\n\tint len, r;\n\n\t/*\n\t * The value to write might be 32 or 64 bits, depending on L1's long\n\t * mode, and eventually we need to write that into a field of several\n\t * possible lengths. The code below first zero-extends the value to 64\n\t * bit (value), and then copies only the appropriate number of\n\t * bits into the vmcs12 field.\n\t */\n\tu64 value = 0;\n\n\tif (!nested_vmx_check_permission(vcpu))\n\t\treturn 1;\n\n\t/*\n\t * In VMX non-root operation, when the VMCS-link pointer is -1ull,\n\t * any VMWRITE sets the ALU flags for VMfailInvalid.\n\t */\n\tif (vmx->nested.current_vmptr == -1ull ||\n\t    (is_guest_mode(vcpu) &&\n\t     get_vmcs12(vcpu)->vmcs_link_pointer == -1ull))\n\t\treturn nested_vmx_failInvalid(vcpu);\n\n\tif (instr_info & BIT(10))\n\t\tvalue = kvm_register_readl(vcpu, (((instr_info) >> 3) & 0xf));\n\telse {\n\t\tlen = is_64_bit_mode(vcpu) ? 8 : 4;\n\t\tif (get_vmx_mem_address(vcpu, exit_qualification,\n\t\t\t\t\tinstr_info, false, len, &gva))\n\t\t\treturn 1;\n\t\tr = kvm_read_guest_virt(vcpu, gva, &value, len, &e);\n\t\tif (r != X86EMUL_CONTINUE)\n\t\t\treturn kvm_handle_memory_failure(vcpu, r, &e);\n\t}\n\n\tfield = kvm_register_readl(vcpu, (((instr_info) >> 28) & 0xf));\n\n\toffset = vmcs_field_to_offset(field);\n\tif (offset < 0)\n\t\treturn nested_vmx_fail(vcpu, VMXERR_UNSUPPORTED_VMCS_COMPONENT);\n\n\t/*\n\t * If the vCPU supports \"VMWRITE to any supported field in the\n\t * VMCS,\" then the \"read-only\" fields are actually read/write.\n\t */\n\tif (vmcs_field_readonly(field) &&\n\t    !nested_cpu_has_vmwrite_any_field(vcpu))\n\t\treturn nested_vmx_fail(vcpu, VMXERR_VMWRITE_READ_ONLY_VMCS_COMPONENT);\n\n\t/*\n\t * Ensure vmcs12 is up-to-date before any VMWRITE that dirties\n\t * vmcs12, else we may crush a field or consume a stale value.\n\t */\n\tif (!is_guest_mode(vcpu) && !is_shadow_field_rw(field))\n\t\tcopy_vmcs02_to_vmcs12_rare(vcpu, vmcs12);\n\n\t/*\n\t * Some Intel CPUs intentionally drop the reserved bits of the AR byte\n\t * fields on VMWRITE.  Emulate this behavior to ensure consistent KVM\n\t * behavior regardless of the underlying hardware, e.g. if an AR_BYTE\n\t * field is intercepted for VMWRITE but not VMREAD (in L1), then VMREAD\n\t * from L1 will return a different value than VMREAD from L2 (L1 sees\n\t * the stripped down value, L2 sees the full value as stored by KVM).\n\t */\n\tif (field >= GUEST_ES_AR_BYTES && field <= GUEST_TR_AR_BYTES)\n\t\tvalue &= 0x1f0ff;\n\n\tvmcs12_write_any(vmcs12, field, offset, value);\n\n\t/*\n\t * Do not track vmcs12 dirty-state if in guest-mode as we actually\n\t * dirty shadow vmcs12 instead of vmcs12.  Fields that can be updated\n\t * by L1 without a vmexit are always updated in the vmcs02, i.e. don't\n\t * \"dirty\" vmcs12, all others go down the prepare_vmcs02() slow path.\n\t */\n\tif (!is_guest_mode(vcpu) && !is_shadow_field_rw(field)) {\n\t\t/*\n\t\t * L1 can read these fields without exiting, ensure the\n\t\t * shadow VMCS is up-to-date.\n\t\t */\n\t\tif (enable_shadow_vmcs && is_shadow_field_ro(field)) {\n\t\t\tpreempt_disable();\n\t\t\tvmcs_load(vmx->vmcs01.shadow_vmcs);\n\n\t\t\t__vmcs_writel(field, value);\n\n\t\t\tvmcs_clear(vmx->vmcs01.shadow_vmcs);\n\t\t\tvmcs_load(vmx->loaded_vmcs->vmcs);\n\t\t\tpreempt_enable();\n\t\t}\n\t\tvmx->nested.dirty_vmcs12 = true;\n\t}\n\n\treturn nested_vmx_succeed(vcpu);\n}\n\nstatic void set_current_vmptr(struct vcpu_vmx *vmx, gpa_t vmptr)\n{\n\tvmx->nested.current_vmptr = vmptr;\n\tif (enable_shadow_vmcs) {\n\t\tsecondary_exec_controls_setbit(vmx, SECONDARY_EXEC_SHADOW_VMCS);\n\t\tvmcs_write64(VMCS_LINK_POINTER,\n\t\t\t     __pa(vmx->vmcs01.shadow_vmcs));\n\t\tvmx->nested.need_vmcs12_to_shadow_sync = true;\n\t}\n\tvmx->nested.dirty_vmcs12 = true;\n}\n\n/* Emulate the VMPTRLD instruction */\nstatic int handle_vmptrld(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tgpa_t vmptr;\n\tint r;\n\n\tif (!nested_vmx_check_permission(vcpu))\n\t\treturn 1;\n\n\tif (nested_vmx_get_vmptr(vcpu, &vmptr, &r))\n\t\treturn r;\n\n\tif (!page_address_valid(vcpu, vmptr))\n\t\treturn nested_vmx_fail(vcpu, VMXERR_VMPTRLD_INVALID_ADDRESS);\n\n\tif (vmptr == vmx->nested.vmxon_ptr)\n\t\treturn nested_vmx_fail(vcpu, VMXERR_VMPTRLD_VMXON_POINTER);\n\n\t/* Forbid normal VMPTRLD if Enlightened version was used */\n\tif (vmx->nested.hv_evmcs)\n\t\treturn 1;\n\n\tif (vmx->nested.current_vmptr != vmptr) {\n\t\tstruct kvm_host_map map;\n\t\tstruct vmcs12 *new_vmcs12;\n\n\t\tif (kvm_vcpu_map(vcpu, gpa_to_gfn(vmptr), &map)) {\n\t\t\t/*\n\t\t\t * Reads from an unbacked page return all 1s,\n\t\t\t * which means that the 32 bits located at the\n\t\t\t * given physical address won't match the required\n\t\t\t * VMCS12_REVISION identifier.\n\t\t\t */\n\t\t\treturn nested_vmx_fail(vcpu,\n\t\t\t\tVMXERR_VMPTRLD_INCORRECT_VMCS_REVISION_ID);\n\t\t}\n\n\t\tnew_vmcs12 = map.hva;\n\n\t\tif (new_vmcs12->hdr.revision_id != VMCS12_REVISION ||\n\t\t    (new_vmcs12->hdr.shadow_vmcs &&\n\t\t     !nested_cpu_has_vmx_shadow_vmcs(vcpu))) {\n\t\t\tkvm_vcpu_unmap(vcpu, &map, false);\n\t\t\treturn nested_vmx_fail(vcpu,\n\t\t\t\tVMXERR_VMPTRLD_INCORRECT_VMCS_REVISION_ID);\n\t\t}\n\n\t\tnested_release_vmcs12(vcpu);\n\n\t\t/*\n\t\t * Load VMCS12 from guest memory since it is not already\n\t\t * cached.\n\t\t */\n\t\tmemcpy(vmx->nested.cached_vmcs12, new_vmcs12, VMCS12_SIZE);\n\t\tkvm_vcpu_unmap(vcpu, &map, false);\n\n\t\tset_current_vmptr(vmx, vmptr);\n\t}\n\n\treturn nested_vmx_succeed(vcpu);\n}\n\n/* Emulate the VMPTRST instruction */\nstatic int handle_vmptrst(struct kvm_vcpu *vcpu)\n{\n\tunsigned long exit_qual = vmx_get_exit_qual(vcpu);\n\tu32 instr_info = vmcs_read32(VMX_INSTRUCTION_INFO);\n\tgpa_t current_vmptr = to_vmx(vcpu)->nested.current_vmptr;\n\tstruct x86_exception e;\n\tgva_t gva;\n\tint r;\n\n\tif (!nested_vmx_check_permission(vcpu))\n\t\treturn 1;\n\n\tif (unlikely(to_vmx(vcpu)->nested.hv_evmcs))\n\t\treturn 1;\n\n\tif (get_vmx_mem_address(vcpu, exit_qual, instr_info,\n\t\t\t\ttrue, sizeof(gpa_t), &gva))\n\t\treturn 1;\n\t/* *_system ok, nested_vmx_check_permission has verified cpl=0 */\n\tr = kvm_write_guest_virt_system(vcpu, gva, (void *)&current_vmptr,\n\t\t\t\t\tsizeof(gpa_t), &e);\n\tif (r != X86EMUL_CONTINUE)\n\t\treturn kvm_handle_memory_failure(vcpu, r, &e);\n\n\treturn nested_vmx_succeed(vcpu);\n}\n\n#define EPTP_PA_MASK   GENMASK_ULL(51, 12)\n\nstatic bool nested_ept_root_matches(hpa_t root_hpa, u64 root_eptp, u64 eptp)\n{\n\treturn VALID_PAGE(root_hpa) &&\n\t\t((root_eptp & EPTP_PA_MASK) == (eptp & EPTP_PA_MASK));\n}\n\n/* Emulate the INVEPT instruction */\nstatic int handle_invept(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tu32 vmx_instruction_info, types;\n\tunsigned long type, roots_to_free;\n\tstruct kvm_mmu *mmu;\n\tgva_t gva;\n\tstruct x86_exception e;\n\tstruct {\n\t\tu64 eptp, gpa;\n\t} operand;\n\tint i, r;\n\n\tif (!(vmx->nested.msrs.secondary_ctls_high &\n\t      SECONDARY_EXEC_ENABLE_EPT) ||\n\t    !(vmx->nested.msrs.ept_caps & VMX_EPT_INVEPT_BIT)) {\n\t\tkvm_queue_exception(vcpu, UD_VECTOR);\n\t\treturn 1;\n\t}\n\n\tif (!nested_vmx_check_permission(vcpu))\n\t\treturn 1;\n\n\tvmx_instruction_info = vmcs_read32(VMX_INSTRUCTION_INFO);\n\ttype = kvm_register_readl(vcpu, (vmx_instruction_info >> 28) & 0xf);\n\n\ttypes = (vmx->nested.msrs.ept_caps >> VMX_EPT_EXTENT_SHIFT) & 6;\n\n\tif (type >= 32 || !(types & (1 << type)))\n\t\treturn nested_vmx_fail(vcpu, VMXERR_INVALID_OPERAND_TO_INVEPT_INVVPID);\n\n\t/* According to the Intel VMX instruction reference, the memory\n\t * operand is read even if it isn't needed (e.g., for type==global)\n\t */\n\tif (get_vmx_mem_address(vcpu, vmx_get_exit_qual(vcpu),\n\t\t\tvmx_instruction_info, false, sizeof(operand), &gva))\n\t\treturn 1;\n\tr = kvm_read_guest_virt(vcpu, gva, &operand, sizeof(operand), &e);\n\tif (r != X86EMUL_CONTINUE)\n\t\treturn kvm_handle_memory_failure(vcpu, r, &e);\n\n\t/*\n\t * Nested EPT roots are always held through guest_mmu,\n\t * not root_mmu.\n\t */\n\tmmu = &vcpu->arch.guest_mmu;\n\n\tswitch (type) {\n\tcase VMX_EPT_EXTENT_CONTEXT:\n\t\tif (!nested_vmx_check_eptp(vcpu, operand.eptp))\n\t\t\treturn nested_vmx_fail(vcpu,\n\t\t\t\tVMXERR_INVALID_OPERAND_TO_INVEPT_INVVPID);\n\n\t\troots_to_free = 0;\n\t\tif (nested_ept_root_matches(mmu->root_hpa, mmu->root_pgd,\n\t\t\t\t\t    operand.eptp))\n\t\t\troots_to_free |= KVM_MMU_ROOT_CURRENT;\n\n\t\tfor (i = 0; i < KVM_MMU_NUM_PREV_ROOTS; i++) {\n\t\t\tif (nested_ept_root_matches(mmu->prev_roots[i].hpa,\n\t\t\t\t\t\t    mmu->prev_roots[i].pgd,\n\t\t\t\t\t\t    operand.eptp))\n\t\t\t\troots_to_free |= KVM_MMU_ROOT_PREVIOUS(i);\n\t\t}\n\t\tbreak;\n\tcase VMX_EPT_EXTENT_GLOBAL:\n\t\troots_to_free = KVM_MMU_ROOTS_ALL;\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t\tbreak;\n\t}\n\n\tif (roots_to_free)\n\t\tkvm_mmu_free_roots(vcpu, mmu, roots_to_free);\n\n\treturn nested_vmx_succeed(vcpu);\n}\n\nstatic int handle_invvpid(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tu32 vmx_instruction_info;\n\tunsigned long type, types;\n\tgva_t gva;\n\tstruct x86_exception e;\n\tstruct {\n\t\tu64 vpid;\n\t\tu64 gla;\n\t} operand;\n\tu16 vpid02;\n\tint r;\n\n\tif (!(vmx->nested.msrs.secondary_ctls_high &\n\t      SECONDARY_EXEC_ENABLE_VPID) ||\n\t\t\t!(vmx->nested.msrs.vpid_caps & VMX_VPID_INVVPID_BIT)) {\n\t\tkvm_queue_exception(vcpu, UD_VECTOR);\n\t\treturn 1;\n\t}\n\n\tif (!nested_vmx_check_permission(vcpu))\n\t\treturn 1;\n\n\tvmx_instruction_info = vmcs_read32(VMX_INSTRUCTION_INFO);\n\ttype = kvm_register_readl(vcpu, (vmx_instruction_info >> 28) & 0xf);\n\n\ttypes = (vmx->nested.msrs.vpid_caps &\n\t\t\tVMX_VPID_EXTENT_SUPPORTED_MASK) >> 8;\n\n\tif (type >= 32 || !(types & (1 << type)))\n\t\treturn nested_vmx_fail(vcpu,\n\t\t\tVMXERR_INVALID_OPERAND_TO_INVEPT_INVVPID);\n\n\t/* according to the intel vmx instruction reference, the memory\n\t * operand is read even if it isn't needed (e.g., for type==global)\n\t */\n\tif (get_vmx_mem_address(vcpu, vmx_get_exit_qual(vcpu),\n\t\t\tvmx_instruction_info, false, sizeof(operand), &gva))\n\t\treturn 1;\n\tr = kvm_read_guest_virt(vcpu, gva, &operand, sizeof(operand), &e);\n\tif (r != X86EMUL_CONTINUE)\n\t\treturn kvm_handle_memory_failure(vcpu, r, &e);\n\n\tif (operand.vpid >> 16)\n\t\treturn nested_vmx_fail(vcpu,\n\t\t\tVMXERR_INVALID_OPERAND_TO_INVEPT_INVVPID);\n\n\tvpid02 = nested_get_vpid02(vcpu);\n\tswitch (type) {\n\tcase VMX_VPID_EXTENT_INDIVIDUAL_ADDR:\n\t\tif (!operand.vpid ||\n\t\t    is_noncanonical_address(operand.gla, vcpu))\n\t\t\treturn nested_vmx_fail(vcpu,\n\t\t\t\tVMXERR_INVALID_OPERAND_TO_INVEPT_INVVPID);\n\t\tvpid_sync_vcpu_addr(vpid02, operand.gla);\n\t\tbreak;\n\tcase VMX_VPID_EXTENT_SINGLE_CONTEXT:\n\tcase VMX_VPID_EXTENT_SINGLE_NON_GLOBAL:\n\t\tif (!operand.vpid)\n\t\t\treturn nested_vmx_fail(vcpu,\n\t\t\t\tVMXERR_INVALID_OPERAND_TO_INVEPT_INVVPID);\n\t\tvpid_sync_context(vpid02);\n\t\tbreak;\n\tcase VMX_VPID_EXTENT_ALL_CONTEXT:\n\t\tvpid_sync_context(vpid02);\n\t\tbreak;\n\tdefault:\n\t\tWARN_ON_ONCE(1);\n\t\treturn kvm_skip_emulated_instruction(vcpu);\n\t}\n\n\t/*\n\t * Sync the shadow page tables if EPT is disabled, L1 is invalidating\n\t * linear mappings for L2 (tagged with L2's VPID).  Free all roots as\n\t * VPIDs are not tracked in the MMU role.\n\t *\n\t * Note, this operates on root_mmu, not guest_mmu, as L1 and L2 share\n\t * an MMU when EPT is disabled.\n\t *\n\t * TODO: sync only the affected SPTEs for INVDIVIDUAL_ADDR.\n\t */\n\tif (!enable_ept)\n\t\tkvm_mmu_free_roots(vcpu, &vcpu->arch.root_mmu,\n\t\t\t\t   KVM_MMU_ROOTS_ALL);\n\n\treturn nested_vmx_succeed(vcpu);\n}\n\nstatic int nested_vmx_eptp_switching(struct kvm_vcpu *vcpu,\n\t\t\t\t     struct vmcs12 *vmcs12)\n{\n\tu32 index = kvm_rcx_read(vcpu);\n\tu64 new_eptp;\n\tbool accessed_dirty;\n\tstruct kvm_mmu *mmu = vcpu->arch.walk_mmu;\n\n\tif (!nested_cpu_has_eptp_switching(vmcs12) ||\n\t    !nested_cpu_has_ept(vmcs12))\n\t\treturn 1;\n\n\tif (index >= VMFUNC_EPTP_ENTRIES)\n\t\treturn 1;\n\n\n\tif (kvm_vcpu_read_guest_page(vcpu, vmcs12->eptp_list_address >> PAGE_SHIFT,\n\t\t\t\t     &new_eptp, index * 8, 8))\n\t\treturn 1;\n\n\taccessed_dirty = !!(new_eptp & VMX_EPTP_AD_ENABLE_BIT);\n\n\t/*\n\t * If the (L2) guest does a vmfunc to the currently\n\t * active ept pointer, we don't have to do anything else\n\t */\n\tif (vmcs12->ept_pointer != new_eptp) {\n\t\tif (!nested_vmx_check_eptp(vcpu, new_eptp))\n\t\t\treturn 1;\n\n\t\tkvm_mmu_unload(vcpu);\n\t\tmmu->ept_ad = accessed_dirty;\n\t\tmmu->mmu_role.base.ad_disabled = !accessed_dirty;\n\t\tvmcs12->ept_pointer = new_eptp;\n\t\t/*\n\t\t * TODO: Check what's the correct approach in case\n\t\t * mmu reload fails. Currently, we just let the next\n\t\t * reload potentially fail\n\t\t */\n\t\tkvm_mmu_reload(vcpu);\n\t}\n\n\treturn 0;\n}\n\nstatic int handle_vmfunc(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tstruct vmcs12 *vmcs12;\n\tu32 function = kvm_rax_read(vcpu);\n\n\t/*\n\t * VMFUNC is only supported for nested guests, but we always enable the\n\t * secondary control for simplicity; for non-nested mode, fake that we\n\t * didn't by injecting #UD.\n\t */\n\tif (!is_guest_mode(vcpu)) {\n\t\tkvm_queue_exception(vcpu, UD_VECTOR);\n\t\treturn 1;\n\t}\n\n\tvmcs12 = get_vmcs12(vcpu);\n\tif ((vmcs12->vm_function_control & (1 << function)) == 0)\n\t\tgoto fail;\n\n\tswitch (function) {\n\tcase 0:\n\t\tif (nested_vmx_eptp_switching(vcpu, vmcs12))\n\t\t\tgoto fail;\n\t\tbreak;\n\tdefault:\n\t\tgoto fail;\n\t}\n\treturn kvm_skip_emulated_instruction(vcpu);\n\nfail:\n\tnested_vmx_vmexit(vcpu, vmx->exit_reason,\n\t\t\t  vmx_get_intr_info(vcpu),\n\t\t\t  vmx_get_exit_qual(vcpu));\n\treturn 1;\n}\n\n/*\n * Return true if an IO instruction with the specified port and size should cause\n * a VM-exit into L1.\n */\nbool nested_vmx_check_io_bitmaps(struct kvm_vcpu *vcpu, unsigned int port,\n\t\t\t\t int size)\n{\n\tstruct vmcs12 *vmcs12 = get_vmcs12(vcpu);\n\tgpa_t bitmap, last_bitmap;\n\tu8 b;\n\n\tlast_bitmap = (gpa_t)-1;\n\tb = -1;\n\n\twhile (size > 0) {\n\t\tif (port < 0x8000)\n\t\t\tbitmap = vmcs12->io_bitmap_a;\n\t\telse if (port < 0x10000)\n\t\t\tbitmap = vmcs12->io_bitmap_b;\n\t\telse\n\t\t\treturn true;\n\t\tbitmap += (port & 0x7fff) / 8;\n\n\t\tif (last_bitmap != bitmap)\n\t\t\tif (kvm_vcpu_read_guest(vcpu, bitmap, &b, 1))\n\t\t\t\treturn true;\n\t\tif (b & (1 << (port & 7)))\n\t\t\treturn true;\n\n\t\tport++;\n\t\tsize--;\n\t\tlast_bitmap = bitmap;\n\t}\n\n\treturn false;\n}\n\nstatic bool nested_vmx_exit_handled_io(struct kvm_vcpu *vcpu,\n\t\t\t\t       struct vmcs12 *vmcs12)\n{\n\tunsigned long exit_qualification;\n\tunsigned short port;\n\tint size;\n\n\tif (!nested_cpu_has(vmcs12, CPU_BASED_USE_IO_BITMAPS))\n\t\treturn nested_cpu_has(vmcs12, CPU_BASED_UNCOND_IO_EXITING);\n\n\texit_qualification = vmx_get_exit_qual(vcpu);\n\n\tport = exit_qualification >> 16;\n\tsize = (exit_qualification & 7) + 1;\n\n\treturn nested_vmx_check_io_bitmaps(vcpu, port, size);\n}\n\n/*\n * Return 1 if we should exit from L2 to L1 to handle an MSR access,\n * rather than handle it ourselves in L0. I.e., check whether L1 expressed\n * disinterest in the current event (read or write a specific MSR) by using an\n * MSR bitmap. This may be the case even when L0 doesn't use MSR bitmaps.\n */\nstatic bool nested_vmx_exit_handled_msr(struct kvm_vcpu *vcpu,\n\tstruct vmcs12 *vmcs12, u32 exit_reason)\n{\n\tu32 msr_index = kvm_rcx_read(vcpu);\n\tgpa_t bitmap;\n\n\tif (!nested_cpu_has(vmcs12, CPU_BASED_USE_MSR_BITMAPS))\n\t\treturn true;\n\n\t/*\n\t * The MSR_BITMAP page is divided into four 1024-byte bitmaps,\n\t * for the four combinations of read/write and low/high MSR numbers.\n\t * First we need to figure out which of the four to use:\n\t */\n\tbitmap = vmcs12->msr_bitmap;\n\tif (exit_reason == EXIT_REASON_MSR_WRITE)\n\t\tbitmap += 2048;\n\tif (msr_index >= 0xc0000000) {\n\t\tmsr_index -= 0xc0000000;\n\t\tbitmap += 1024;\n\t}\n\n\t/* Then read the msr_index'th bit from this bitmap: */\n\tif (msr_index < 1024*8) {\n\t\tunsigned char b;\n\t\tif (kvm_vcpu_read_guest(vcpu, bitmap + msr_index/8, &b, 1))\n\t\t\treturn true;\n\t\treturn 1 & (b >> (msr_index & 7));\n\t} else\n\t\treturn true; /* let L1 handle the wrong parameter */\n}\n\n/*\n * Return 1 if we should exit from L2 to L1 to handle a CR access exit,\n * rather than handle it ourselves in L0. I.e., check if L1 wanted to\n * intercept (via guest_host_mask etc.) the current event.\n */\nstatic bool nested_vmx_exit_handled_cr(struct kvm_vcpu *vcpu,\n\tstruct vmcs12 *vmcs12)\n{\n\tunsigned long exit_qualification = vmx_get_exit_qual(vcpu);\n\tint cr = exit_qualification & 15;\n\tint reg;\n\tunsigned long val;\n\n\tswitch ((exit_qualification >> 4) & 3) {\n\tcase 0: /* mov to cr */\n\t\treg = (exit_qualification >> 8) & 15;\n\t\tval = kvm_register_readl(vcpu, reg);\n\t\tswitch (cr) {\n\t\tcase 0:\n\t\t\tif (vmcs12->cr0_guest_host_mask &\n\t\t\t    (val ^ vmcs12->cr0_read_shadow))\n\t\t\t\treturn true;\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\tif (nested_cpu_has(vmcs12, CPU_BASED_CR3_LOAD_EXITING))\n\t\t\t\treturn true;\n\t\t\tbreak;\n\t\tcase 4:\n\t\t\tif (vmcs12->cr4_guest_host_mask &\n\t\t\t    (vmcs12->cr4_read_shadow ^ val))\n\t\t\t\treturn true;\n\t\t\tbreak;\n\t\tcase 8:\n\t\t\tif (nested_cpu_has(vmcs12, CPU_BASED_CR8_LOAD_EXITING))\n\t\t\t\treturn true;\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase 2: /* clts */\n\t\tif ((vmcs12->cr0_guest_host_mask & X86_CR0_TS) &&\n\t\t    (vmcs12->cr0_read_shadow & X86_CR0_TS))\n\t\t\treturn true;\n\t\tbreak;\n\tcase 1: /* mov from cr */\n\t\tswitch (cr) {\n\t\tcase 3:\n\t\t\tif (vmcs12->cpu_based_vm_exec_control &\n\t\t\t    CPU_BASED_CR3_STORE_EXITING)\n\t\t\t\treturn true;\n\t\t\tbreak;\n\t\tcase 8:\n\t\t\tif (vmcs12->cpu_based_vm_exec_control &\n\t\t\t    CPU_BASED_CR8_STORE_EXITING)\n\t\t\t\treturn true;\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase 3: /* lmsw */\n\t\t/*\n\t\t * lmsw can change bits 1..3 of cr0, and only set bit 0 of\n\t\t * cr0. Other attempted changes are ignored, with no exit.\n\t\t */\n\t\tval = (exit_qualification >> LMSW_SOURCE_DATA_SHIFT) & 0x0f;\n\t\tif (vmcs12->cr0_guest_host_mask & 0xe &\n\t\t    (val ^ vmcs12->cr0_read_shadow))\n\t\t\treturn true;\n\t\tif ((vmcs12->cr0_guest_host_mask & 0x1) &&\n\t\t    !(vmcs12->cr0_read_shadow & 0x1) &&\n\t\t    (val & 0x1))\n\t\t\treturn true;\n\t\tbreak;\n\t}\n\treturn false;\n}\n\nstatic bool nested_vmx_exit_handled_vmcs_access(struct kvm_vcpu *vcpu,\n\tstruct vmcs12 *vmcs12, gpa_t bitmap)\n{\n\tu32 vmx_instruction_info;\n\tunsigned long field;\n\tu8 b;\n\n\tif (!nested_cpu_has_shadow_vmcs(vmcs12))\n\t\treturn true;\n\n\t/* Decode instruction info and find the field to access */\n\tvmx_instruction_info = vmcs_read32(VMX_INSTRUCTION_INFO);\n\tfield = kvm_register_read(vcpu, (((vmx_instruction_info) >> 28) & 0xf));\n\n\t/* Out-of-range fields always cause a VM exit from L2 to L1 */\n\tif (field >> 15)\n\t\treturn true;\n\n\tif (kvm_vcpu_read_guest(vcpu, bitmap + field/8, &b, 1))\n\t\treturn true;\n\n\treturn 1 & (b >> (field & 7));\n}\n\nstatic bool nested_vmx_exit_handled_mtf(struct vmcs12 *vmcs12)\n{\n\tu32 entry_intr_info = vmcs12->vm_entry_intr_info_field;\n\n\tif (nested_cpu_has_mtf(vmcs12))\n\t\treturn true;\n\n\t/*\n\t * An MTF VM-exit may be injected into the guest by setting the\n\t * interruption-type to 7 (other event) and the vector field to 0. Such\n\t * is the case regardless of the 'monitor trap flag' VM-execution\n\t * control.\n\t */\n\treturn entry_intr_info == (INTR_INFO_VALID_MASK\n\t\t\t\t   | INTR_TYPE_OTHER_EVENT);\n}\n\n/*\n * Return true if L0 wants to handle an exit from L2 regardless of whether or not\n * L1 wants the exit.  Only call this when in is_guest_mode (L2).\n */\nstatic bool nested_vmx_l0_wants_exit(struct kvm_vcpu *vcpu, u32 exit_reason)\n{\n\tu32 intr_info;\n\n\tswitch ((u16)exit_reason) {\n\tcase EXIT_REASON_EXCEPTION_NMI:\n\t\tintr_info = vmx_get_intr_info(vcpu);\n\t\tif (is_nmi(intr_info))\n\t\t\treturn true;\n\t\telse if (is_page_fault(intr_info))\n\t\t\treturn vcpu->arch.apf.host_apf_flags || !enable_ept;\n\t\telse if (is_debug(intr_info) &&\n\t\t\t vcpu->guest_debug &\n\t\t\t (KVM_GUESTDBG_SINGLESTEP | KVM_GUESTDBG_USE_HW_BP))\n\t\t\treturn true;\n\t\telse if (is_breakpoint(intr_info) &&\n\t\t\t vcpu->guest_debug & KVM_GUESTDBG_USE_SW_BP)\n\t\t\treturn true;\n\t\treturn false;\n\tcase EXIT_REASON_EXTERNAL_INTERRUPT:\n\t\treturn true;\n\tcase EXIT_REASON_MCE_DURING_VMENTRY:\n\t\treturn true;\n\tcase EXIT_REASON_EPT_VIOLATION:\n\t\t/*\n\t\t * L0 always deals with the EPT violation. If nested EPT is\n\t\t * used, and the nested mmu code discovers that the address is\n\t\t * missing in the guest EPT table (EPT12), the EPT violation\n\t\t * will be injected with nested_ept_inject_page_fault()\n\t\t */\n\t\treturn true;\n\tcase EXIT_REASON_EPT_MISCONFIG:\n\t\t/*\n\t\t * L2 never uses directly L1's EPT, but rather L0's own EPT\n\t\t * table (shadow on EPT) or a merged EPT table that L0 built\n\t\t * (EPT on EPT). So any problems with the structure of the\n\t\t * table is L0's fault.\n\t\t */\n\t\treturn true;\n\tcase EXIT_REASON_PREEMPTION_TIMER:\n\t\treturn true;\n\tcase EXIT_REASON_PML_FULL:\n\t\t/* We emulate PML support to L1. */\n\t\treturn true;\n\tcase EXIT_REASON_VMFUNC:\n\t\t/* VM functions are emulated through L2->L0 vmexits. */\n\t\treturn true;\n\tcase EXIT_REASON_ENCLS:\n\t\t/* SGX is never exposed to L1 */\n\t\treturn true;\n\tdefault:\n\t\tbreak;\n\t}\n\treturn false;\n}\n\n/*\n * Return 1 if L1 wants to intercept an exit from L2.  Only call this when in\n * is_guest_mode (L2).\n */\nstatic bool nested_vmx_l1_wants_exit(struct kvm_vcpu *vcpu, u32 exit_reason)\n{\n\tstruct vmcs12 *vmcs12 = get_vmcs12(vcpu);\n\tu32 intr_info;\n\n\tswitch ((u16)exit_reason) {\n\tcase EXIT_REASON_EXCEPTION_NMI:\n\t\tintr_info = vmx_get_intr_info(vcpu);\n\t\tif (is_nmi(intr_info))\n\t\t\treturn true;\n\t\telse if (is_page_fault(intr_info))\n\t\t\treturn true;\n\t\treturn vmcs12->exception_bitmap &\n\t\t\t\t(1u << (intr_info & INTR_INFO_VECTOR_MASK));\n\tcase EXIT_REASON_EXTERNAL_INTERRUPT:\n\t\treturn nested_exit_on_intr(vcpu);\n\tcase EXIT_REASON_TRIPLE_FAULT:\n\t\treturn true;\n\tcase EXIT_REASON_INTERRUPT_WINDOW:\n\t\treturn nested_cpu_has(vmcs12, CPU_BASED_INTR_WINDOW_EXITING);\n\tcase EXIT_REASON_NMI_WINDOW:\n\t\treturn nested_cpu_has(vmcs12, CPU_BASED_NMI_WINDOW_EXITING);\n\tcase EXIT_REASON_TASK_SWITCH:\n\t\treturn true;\n\tcase EXIT_REASON_CPUID:\n\t\treturn true;\n\tcase EXIT_REASON_HLT:\n\t\treturn nested_cpu_has(vmcs12, CPU_BASED_HLT_EXITING);\n\tcase EXIT_REASON_INVD:\n\t\treturn true;\n\tcase EXIT_REASON_INVLPG:\n\t\treturn nested_cpu_has(vmcs12, CPU_BASED_INVLPG_EXITING);\n\tcase EXIT_REASON_RDPMC:\n\t\treturn nested_cpu_has(vmcs12, CPU_BASED_RDPMC_EXITING);\n\tcase EXIT_REASON_RDRAND:\n\t\treturn nested_cpu_has2(vmcs12, SECONDARY_EXEC_RDRAND_EXITING);\n\tcase EXIT_REASON_RDSEED:\n\t\treturn nested_cpu_has2(vmcs12, SECONDARY_EXEC_RDSEED_EXITING);\n\tcase EXIT_REASON_RDTSC: case EXIT_REASON_RDTSCP:\n\t\treturn nested_cpu_has(vmcs12, CPU_BASED_RDTSC_EXITING);\n\tcase EXIT_REASON_VMREAD:\n\t\treturn nested_vmx_exit_handled_vmcs_access(vcpu, vmcs12,\n\t\t\tvmcs12->vmread_bitmap);\n\tcase EXIT_REASON_VMWRITE:\n\t\treturn nested_vmx_exit_handled_vmcs_access(vcpu, vmcs12,\n\t\t\tvmcs12->vmwrite_bitmap);\n\tcase EXIT_REASON_VMCALL: case EXIT_REASON_VMCLEAR:\n\tcase EXIT_REASON_VMLAUNCH: case EXIT_REASON_VMPTRLD:\n\tcase EXIT_REASON_VMPTRST: case EXIT_REASON_VMRESUME:\n\tcase EXIT_REASON_VMOFF: case EXIT_REASON_VMON:\n\tcase EXIT_REASON_INVEPT: case EXIT_REASON_INVVPID:\n\t\t/*\n\t\t * VMX instructions trap unconditionally. This allows L1 to\n\t\t * emulate them for its L2 guest, i.e., allows 3-level nesting!\n\t\t */\n\t\treturn true;\n\tcase EXIT_REASON_CR_ACCESS:\n\t\treturn nested_vmx_exit_handled_cr(vcpu, vmcs12);\n\tcase EXIT_REASON_DR_ACCESS:\n\t\treturn nested_cpu_has(vmcs12, CPU_BASED_MOV_DR_EXITING);\n\tcase EXIT_REASON_IO_INSTRUCTION:\n\t\treturn nested_vmx_exit_handled_io(vcpu, vmcs12);\n\tcase EXIT_REASON_GDTR_IDTR: case EXIT_REASON_LDTR_TR:\n\t\treturn nested_cpu_has2(vmcs12, SECONDARY_EXEC_DESC);\n\tcase EXIT_REASON_MSR_READ:\n\tcase EXIT_REASON_MSR_WRITE:\n\t\treturn nested_vmx_exit_handled_msr(vcpu, vmcs12, exit_reason);\n\tcase EXIT_REASON_INVALID_STATE:\n\t\treturn true;\n\tcase EXIT_REASON_MWAIT_INSTRUCTION:\n\t\treturn nested_cpu_has(vmcs12, CPU_BASED_MWAIT_EXITING);\n\tcase EXIT_REASON_MONITOR_TRAP_FLAG:\n\t\treturn nested_vmx_exit_handled_mtf(vmcs12);\n\tcase EXIT_REASON_MONITOR_INSTRUCTION:\n\t\treturn nested_cpu_has(vmcs12, CPU_BASED_MONITOR_EXITING);\n\tcase EXIT_REASON_PAUSE_INSTRUCTION:\n\t\treturn nested_cpu_has(vmcs12, CPU_BASED_PAUSE_EXITING) ||\n\t\t\tnested_cpu_has2(vmcs12,\n\t\t\t\tSECONDARY_EXEC_PAUSE_LOOP_EXITING);\n\tcase EXIT_REASON_MCE_DURING_VMENTRY:\n\t\treturn true;\n\tcase EXIT_REASON_TPR_BELOW_THRESHOLD:\n\t\treturn nested_cpu_has(vmcs12, CPU_BASED_TPR_SHADOW);\n\tcase EXIT_REASON_APIC_ACCESS:\n\tcase EXIT_REASON_APIC_WRITE:\n\tcase EXIT_REASON_EOI_INDUCED:\n\t\t/*\n\t\t * The controls for \"virtualize APIC accesses,\" \"APIC-\n\t\t * register virtualization,\" and \"virtual-interrupt\n\t\t * delivery\" only come from vmcs12.\n\t\t */\n\t\treturn true;\n\tcase EXIT_REASON_INVPCID:\n\t\treturn\n\t\t\tnested_cpu_has2(vmcs12, SECONDARY_EXEC_ENABLE_INVPCID) &&\n\t\t\tnested_cpu_has(vmcs12, CPU_BASED_INVLPG_EXITING);\n\tcase EXIT_REASON_WBINVD:\n\t\treturn nested_cpu_has2(vmcs12, SECONDARY_EXEC_WBINVD_EXITING);\n\tcase EXIT_REASON_XSETBV:\n\t\treturn true;\n\tcase EXIT_REASON_XSAVES: case EXIT_REASON_XRSTORS:\n\t\t/*\n\t\t * This should never happen, since it is not possible to\n\t\t * set XSS to a non-zero value---neither in L1 nor in L2.\n\t\t * If if it were, XSS would have to be checked against\n\t\t * the XSS exit bitmap in vmcs12.\n\t\t */\n\t\treturn nested_cpu_has2(vmcs12, SECONDARY_EXEC_XSAVES);\n\tcase EXIT_REASON_UMWAIT:\n\tcase EXIT_REASON_TPAUSE:\n\t\treturn nested_cpu_has2(vmcs12,\n\t\t\tSECONDARY_EXEC_ENABLE_USR_WAIT_PAUSE);\n\tdefault:\n\t\treturn true;\n\t}\n}\n\n/*\n * Conditionally reflect a VM-Exit into L1.  Returns %true if the VM-Exit was\n * reflected into L1.\n */\nbool nested_vmx_reflect_vmexit(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tu32 exit_reason = vmx->exit_reason;\n\tunsigned long exit_qual;\n\tu32 exit_intr_info;\n\n\tWARN_ON_ONCE(vmx->nested.nested_run_pending);\n\n\t/*\n\t * Late nested VM-Fail shares the same flow as nested VM-Exit since KVM\n\t * has already loaded L2's state.\n\t */\n\tif (unlikely(vmx->fail)) {\n\t\ttrace_kvm_nested_vmenter_failed(\n\t\t\t\"hardware VM-instruction error: \",\n\t\t\tvmcs_read32(VM_INSTRUCTION_ERROR));\n\t\texit_intr_info = 0;\n\t\texit_qual = 0;\n\t\tgoto reflect_vmexit;\n\t}\n\n\ttrace_kvm_nested_vmexit(exit_reason, vcpu, KVM_ISA_VMX);\n\n\t/* If L0 (KVM) wants the exit, it trumps L1's desires. */\n\tif (nested_vmx_l0_wants_exit(vcpu, exit_reason))\n\t\treturn false;\n\n\t/* If L1 doesn't want the exit, handle it in L0. */\n\tif (!nested_vmx_l1_wants_exit(vcpu, exit_reason))\n\t\treturn false;\n\n\t/*\n\t * vmcs.VM_EXIT_INTR_INFO is only valid for EXCEPTION_NMI exits.  For\n\t * EXTERNAL_INTERRUPT, the value for vmcs12->vm_exit_intr_info would\n\t * need to be synthesized by querying the in-kernel LAPIC, but external\n\t * interrupts are never reflected to L1 so it's a non-issue.\n\t */\n\texit_intr_info = vmx_get_intr_info(vcpu);\n\tif (is_exception_with_error_code(exit_intr_info)) {\n\t\tstruct vmcs12 *vmcs12 = get_vmcs12(vcpu);\n\n\t\tvmcs12->vm_exit_intr_error_code =\n\t\t\tvmcs_read32(VM_EXIT_INTR_ERROR_CODE);\n\t}\n\texit_qual = vmx_get_exit_qual(vcpu);\n\nreflect_vmexit:\n\tnested_vmx_vmexit(vcpu, exit_reason, exit_intr_info, exit_qual);\n\treturn true;\n}\n\nstatic int vmx_get_nested_state(struct kvm_vcpu *vcpu,\n\t\t\t\tstruct kvm_nested_state __user *user_kvm_nested_state,\n\t\t\t\tu32 user_data_size)\n{\n\tstruct vcpu_vmx *vmx;\n\tstruct vmcs12 *vmcs12;\n\tstruct kvm_nested_state kvm_state = {\n\t\t.flags = 0,\n\t\t.format = KVM_STATE_NESTED_FORMAT_VMX,\n\t\t.size = sizeof(kvm_state),\n\t\t.hdr.vmx.flags = 0,\n\t\t.hdr.vmx.vmxon_pa = -1ull,\n\t\t.hdr.vmx.vmcs12_pa = -1ull,\n\t\t.hdr.vmx.preemption_timer_deadline = 0,\n\t};\n\tstruct kvm_vmx_nested_state_data __user *user_vmx_nested_state =\n\t\t&user_kvm_nested_state->data.vmx[0];\n\n\tif (!vcpu)\n\t\treturn kvm_state.size + sizeof(*user_vmx_nested_state);\n\n\tvmx = to_vmx(vcpu);\n\tvmcs12 = get_vmcs12(vcpu);\n\n\tif (nested_vmx_allowed(vcpu) &&\n\t    (vmx->nested.vmxon || vmx->nested.smm.vmxon)) {\n\t\tkvm_state.hdr.vmx.vmxon_pa = vmx->nested.vmxon_ptr;\n\t\tkvm_state.hdr.vmx.vmcs12_pa = vmx->nested.current_vmptr;\n\n\t\tif (vmx_has_valid_vmcs12(vcpu)) {\n\t\t\tkvm_state.size += sizeof(user_vmx_nested_state->vmcs12);\n\n\t\t\tif (vmx->nested.hv_evmcs)\n\t\t\t\tkvm_state.flags |= KVM_STATE_NESTED_EVMCS;\n\n\t\t\tif (is_guest_mode(vcpu) &&\n\t\t\t    nested_cpu_has_shadow_vmcs(vmcs12) &&\n\t\t\t    vmcs12->vmcs_link_pointer != -1ull)\n\t\t\t\tkvm_state.size += sizeof(user_vmx_nested_state->shadow_vmcs12);\n\t\t}\n\n\t\tif (vmx->nested.smm.vmxon)\n\t\t\tkvm_state.hdr.vmx.smm.flags |= KVM_STATE_NESTED_SMM_VMXON;\n\n\t\tif (vmx->nested.smm.guest_mode)\n\t\t\tkvm_state.hdr.vmx.smm.flags |= KVM_STATE_NESTED_SMM_GUEST_MODE;\n\n\t\tif (is_guest_mode(vcpu)) {\n\t\t\tkvm_state.flags |= KVM_STATE_NESTED_GUEST_MODE;\n\n\t\t\tif (vmx->nested.nested_run_pending)\n\t\t\t\tkvm_state.flags |= KVM_STATE_NESTED_RUN_PENDING;\n\n\t\t\tif (vmx->nested.mtf_pending)\n\t\t\t\tkvm_state.flags |= KVM_STATE_NESTED_MTF_PENDING;\n\n\t\t\tif (nested_cpu_has_preemption_timer(vmcs12) &&\n\t\t\t    vmx->nested.has_preemption_timer_deadline) {\n\t\t\t\tkvm_state.hdr.vmx.flags |=\n\t\t\t\t\tKVM_STATE_VMX_PREEMPTION_TIMER_DEADLINE;\n\t\t\t\tkvm_state.hdr.vmx.preemption_timer_deadline =\n\t\t\t\t\tvmx->nested.preemption_timer_deadline;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (user_data_size < kvm_state.size)\n\t\tgoto out;\n\n\tif (copy_to_user(user_kvm_nested_state, &kvm_state, sizeof(kvm_state)))\n\t\treturn -EFAULT;\n\n\tif (!vmx_has_valid_vmcs12(vcpu))\n\t\tgoto out;\n\n\t/*\n\t * When running L2, the authoritative vmcs12 state is in the\n\t * vmcs02. When running L1, the authoritative vmcs12 state is\n\t * in the shadow or enlightened vmcs linked to vmcs01, unless\n\t * need_vmcs12_to_shadow_sync is set, in which case, the authoritative\n\t * vmcs12 state is in the vmcs12 already.\n\t */\n\tif (is_guest_mode(vcpu)) {\n\t\tsync_vmcs02_to_vmcs12(vcpu, vmcs12);\n\t\tsync_vmcs02_to_vmcs12_rare(vcpu, vmcs12);\n\t} else if (!vmx->nested.need_vmcs12_to_shadow_sync) {\n\t\tif (vmx->nested.hv_evmcs)\n\t\t\tcopy_enlightened_to_vmcs12(vmx);\n\t\telse if (enable_shadow_vmcs)\n\t\t\tcopy_shadow_to_vmcs12(vmx);\n\t}\n\n\tBUILD_BUG_ON(sizeof(user_vmx_nested_state->vmcs12) < VMCS12_SIZE);\n\tBUILD_BUG_ON(sizeof(user_vmx_nested_state->shadow_vmcs12) < VMCS12_SIZE);\n\n\t/*\n\t * Copy over the full allocated size of vmcs12 rather than just the size\n\t * of the struct.\n\t */\n\tif (copy_to_user(user_vmx_nested_state->vmcs12, vmcs12, VMCS12_SIZE))\n\t\treturn -EFAULT;\n\n\tif (nested_cpu_has_shadow_vmcs(vmcs12) &&\n\t    vmcs12->vmcs_link_pointer != -1ull) {\n\t\tif (copy_to_user(user_vmx_nested_state->shadow_vmcs12,\n\t\t\t\t get_shadow_vmcs12(vcpu), VMCS12_SIZE))\n\t\t\treturn -EFAULT;\n\t}\nout:\n\treturn kvm_state.size;\n}\n\n/*\n * Forcibly leave nested mode in order to be able to reset the VCPU later on.\n */\nvoid vmx_leave_nested(struct kvm_vcpu *vcpu)\n{\n\tif (is_guest_mode(vcpu)) {\n\t\tto_vmx(vcpu)->nested.nested_run_pending = 0;\n\t\tnested_vmx_vmexit(vcpu, -1, 0, 0);\n\t}\n\tfree_nested(vcpu);\n}\n\nstatic int vmx_set_nested_state(struct kvm_vcpu *vcpu,\n\t\t\t\tstruct kvm_nested_state __user *user_kvm_nested_state,\n\t\t\t\tstruct kvm_nested_state *kvm_state)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tstruct vmcs12 *vmcs12;\n\tenum vm_entry_failure_code ignored;\n\tstruct kvm_vmx_nested_state_data __user *user_vmx_nested_state =\n\t\t&user_kvm_nested_state->data.vmx[0];\n\tint ret;\n\n\tif (kvm_state->format != KVM_STATE_NESTED_FORMAT_VMX)\n\t\treturn -EINVAL;\n\n\tif (kvm_state->hdr.vmx.vmxon_pa == -1ull) {\n\t\tif (kvm_state->hdr.vmx.smm.flags)\n\t\t\treturn -EINVAL;\n\n\t\tif (kvm_state->hdr.vmx.vmcs12_pa != -1ull)\n\t\t\treturn -EINVAL;\n\n\t\t/*\n\t\t * KVM_STATE_NESTED_EVMCS used to signal that KVM should\n\t\t * enable eVMCS capability on vCPU. However, since then\n\t\t * code was changed such that flag signals vmcs12 should\n\t\t * be copied into eVMCS in guest memory.\n\t\t *\n\t\t * To preserve backwards compatability, allow user\n\t\t * to set this flag even when there is no VMXON region.\n\t\t */\n\t\tif (kvm_state->flags & ~KVM_STATE_NESTED_EVMCS)\n\t\t\treturn -EINVAL;\n\t} else {\n\t\tif (!nested_vmx_allowed(vcpu))\n\t\t\treturn -EINVAL;\n\n\t\tif (!page_address_valid(vcpu, kvm_state->hdr.vmx.vmxon_pa))\n\t\t\treturn -EINVAL;\n\t}\n\n\tif ((kvm_state->hdr.vmx.smm.flags & KVM_STATE_NESTED_SMM_GUEST_MODE) &&\n\t    (kvm_state->flags & KVM_STATE_NESTED_GUEST_MODE))\n\t\treturn -EINVAL;\n\n\tif (kvm_state->hdr.vmx.smm.flags &\n\t    ~(KVM_STATE_NESTED_SMM_GUEST_MODE | KVM_STATE_NESTED_SMM_VMXON))\n\t\treturn -EINVAL;\n\n\tif (kvm_state->hdr.vmx.flags & ~KVM_STATE_VMX_PREEMPTION_TIMER_DEADLINE)\n\t\treturn -EINVAL;\n\n\t/*\n\t * SMM temporarily disables VMX, so we cannot be in guest mode,\n\t * nor can VMLAUNCH/VMRESUME be pending.  Outside SMM, SMM flags\n\t * must be zero.\n\t */\n\tif (is_smm(vcpu) ?\n\t\t(kvm_state->flags &\n\t\t (KVM_STATE_NESTED_GUEST_MODE | KVM_STATE_NESTED_RUN_PENDING))\n\t\t: kvm_state->hdr.vmx.smm.flags)\n\t\treturn -EINVAL;\n\n\tif ((kvm_state->hdr.vmx.smm.flags & KVM_STATE_NESTED_SMM_GUEST_MODE) &&\n\t    !(kvm_state->hdr.vmx.smm.flags & KVM_STATE_NESTED_SMM_VMXON))\n\t\treturn -EINVAL;\n\n\tif ((kvm_state->flags & KVM_STATE_NESTED_EVMCS) &&\n\t\t(!nested_vmx_allowed(vcpu) || !vmx->nested.enlightened_vmcs_enabled))\n\t\t\treturn -EINVAL;\n\n\tvmx_leave_nested(vcpu);\n\n\tif (kvm_state->hdr.vmx.vmxon_pa == -1ull)\n\t\treturn 0;\n\n\tvmx->nested.vmxon_ptr = kvm_state->hdr.vmx.vmxon_pa;\n\tret = enter_vmx_operation(vcpu);\n\tif (ret)\n\t\treturn ret;\n\n\t/* Empty 'VMXON' state is permitted if no VMCS loaded */\n\tif (kvm_state->size < sizeof(*kvm_state) + sizeof(*vmcs12)) {\n\t\t/* See vmx_has_valid_vmcs12.  */\n\t\tif ((kvm_state->flags & KVM_STATE_NESTED_GUEST_MODE) ||\n\t\t    (kvm_state->flags & KVM_STATE_NESTED_EVMCS) ||\n\t\t    (kvm_state->hdr.vmx.vmcs12_pa != -1ull))\n\t\t\treturn -EINVAL;\n\t\telse\n\t\t\treturn 0;\n\t}\n\n\tif (kvm_state->hdr.vmx.vmcs12_pa != -1ull) {\n\t\tif (kvm_state->hdr.vmx.vmcs12_pa == kvm_state->hdr.vmx.vmxon_pa ||\n\t\t    !page_address_valid(vcpu, kvm_state->hdr.vmx.vmcs12_pa))\n\t\t\treturn -EINVAL;\n\n\t\tset_current_vmptr(vmx, kvm_state->hdr.vmx.vmcs12_pa);\n\t} else if (kvm_state->flags & KVM_STATE_NESTED_EVMCS) {\n\t\t/*\n\t\t * nested_vmx_handle_enlightened_vmptrld() cannot be called\n\t\t * directly from here as HV_X64_MSR_VP_ASSIST_PAGE may not be\n\t\t * restored yet. EVMCS will be mapped from\n\t\t * nested_get_vmcs12_pages().\n\t\t */\n\t\tkvm_make_request(KVM_REQ_GET_NESTED_STATE_PAGES, vcpu);\n\t} else {\n\t\treturn -EINVAL;\n\t}\n\n\tif (kvm_state->hdr.vmx.smm.flags & KVM_STATE_NESTED_SMM_VMXON) {\n\t\tvmx->nested.smm.vmxon = true;\n\t\tvmx->nested.vmxon = false;\n\n\t\tif (kvm_state->hdr.vmx.smm.flags & KVM_STATE_NESTED_SMM_GUEST_MODE)\n\t\t\tvmx->nested.smm.guest_mode = true;\n\t}\n\n\tvmcs12 = get_vmcs12(vcpu);\n\tif (copy_from_user(vmcs12, user_vmx_nested_state->vmcs12, sizeof(*vmcs12)))\n\t\treturn -EFAULT;\n\n\tif (vmcs12->hdr.revision_id != VMCS12_REVISION)\n\t\treturn -EINVAL;\n\n\tif (!(kvm_state->flags & KVM_STATE_NESTED_GUEST_MODE))\n\t\treturn 0;\n\n\tvmx->nested.nested_run_pending =\n\t\t!!(kvm_state->flags & KVM_STATE_NESTED_RUN_PENDING);\n\n\tvmx->nested.mtf_pending =\n\t\t!!(kvm_state->flags & KVM_STATE_NESTED_MTF_PENDING);\n\n\tret = -EINVAL;\n\tif (nested_cpu_has_shadow_vmcs(vmcs12) &&\n\t    vmcs12->vmcs_link_pointer != -1ull) {\n\t\tstruct vmcs12 *shadow_vmcs12 = get_shadow_vmcs12(vcpu);\n\n\t\tif (kvm_state->size <\n\t\t    sizeof(*kvm_state) +\n\t\t    sizeof(user_vmx_nested_state->vmcs12) + sizeof(*shadow_vmcs12))\n\t\t\tgoto error_guest_mode;\n\n\t\tif (copy_from_user(shadow_vmcs12,\n\t\t\t\t   user_vmx_nested_state->shadow_vmcs12,\n\t\t\t\t   sizeof(*shadow_vmcs12))) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto error_guest_mode;\n\t\t}\n\n\t\tif (shadow_vmcs12->hdr.revision_id != VMCS12_REVISION ||\n\t\t    !shadow_vmcs12->hdr.shadow_vmcs)\n\t\t\tgoto error_guest_mode;\n\t}\n\n\tvmx->nested.has_preemption_timer_deadline = false;\n\tif (kvm_state->hdr.vmx.flags & KVM_STATE_VMX_PREEMPTION_TIMER_DEADLINE) {\n\t\tvmx->nested.has_preemption_timer_deadline = true;\n\t\tvmx->nested.preemption_timer_deadline =\n\t\t\tkvm_state->hdr.vmx.preemption_timer_deadline;\n\t}\n\n\tif (nested_vmx_check_controls(vcpu, vmcs12) ||\n\t    nested_vmx_check_host_state(vcpu, vmcs12) ||\n\t    nested_vmx_check_guest_state(vcpu, vmcs12, &ignored))\n\t\tgoto error_guest_mode;\n\n\tvmx->nested.dirty_vmcs12 = true;\n\tret = nested_vmx_enter_non_root_mode(vcpu, false);\n\tif (ret)\n\t\tgoto error_guest_mode;\n\n\treturn 0;\n\nerror_guest_mode:\n\tvmx->nested.nested_run_pending = 0;\n\treturn ret;\n}\n\nvoid nested_vmx_set_vmcs_shadowing_bitmap(void)\n{\n\tif (enable_shadow_vmcs) {\n\t\tvmcs_write64(VMREAD_BITMAP, __pa(vmx_vmread_bitmap));\n\t\tvmcs_write64(VMWRITE_BITMAP, __pa(vmx_vmwrite_bitmap));\n\t}\n}\n\n/*\n * nested_vmx_setup_ctls_msrs() sets up variables containing the values to be\n * returned for the various VMX controls MSRs when nested VMX is enabled.\n * The same values should also be used to verify that vmcs12 control fields are\n * valid during nested entry from L1 to L2.\n * Each of these control msrs has a low and high 32-bit half: A low bit is on\n * if the corresponding bit in the (32-bit) control field *must* be on, and a\n * bit in the high half is on if the corresponding bit in the control field\n * may be on. See also vmx_control_verify().\n */\nvoid nested_vmx_setup_ctls_msrs(struct nested_vmx_msrs *msrs, u32 ept_caps)\n{\n\t/*\n\t * Note that as a general rule, the high half of the MSRs (bits in\n\t * the control fields which may be 1) should be initialized by the\n\t * intersection of the underlying hardware's MSR (i.e., features which\n\t * can be supported) and the list of features we want to expose -\n\t * because they are known to be properly supported in our code.\n\t * Also, usually, the low half of the MSRs (bits which must be 1) can\n\t * be set to 0, meaning that L1 may turn off any of these bits. The\n\t * reason is that if one of these bits is necessary, it will appear\n\t * in vmcs01 and prepare_vmcs02, when it bitwise-or's the control\n\t * fields of vmcs01 and vmcs02, will turn these bits off - and\n\t * nested_vmx_l1_wants_exit() will not pass related exits to L1.\n\t * These rules have exceptions below.\n\t */\n\n\t/* pin-based controls */\n\trdmsr(MSR_IA32_VMX_PINBASED_CTLS,\n\t\tmsrs->pinbased_ctls_low,\n\t\tmsrs->pinbased_ctls_high);\n\tmsrs->pinbased_ctls_low |=\n\t\tPIN_BASED_ALWAYSON_WITHOUT_TRUE_MSR;\n\tmsrs->pinbased_ctls_high &=\n\t\tPIN_BASED_EXT_INTR_MASK |\n\t\tPIN_BASED_NMI_EXITING |\n\t\tPIN_BASED_VIRTUAL_NMIS |\n\t\t(enable_apicv ? PIN_BASED_POSTED_INTR : 0);\n\tmsrs->pinbased_ctls_high |=\n\t\tPIN_BASED_ALWAYSON_WITHOUT_TRUE_MSR |\n\t\tPIN_BASED_VMX_PREEMPTION_TIMER;\n\n\t/* exit controls */\n\trdmsr(MSR_IA32_VMX_EXIT_CTLS,\n\t\tmsrs->exit_ctls_low,\n\t\tmsrs->exit_ctls_high);\n\tmsrs->exit_ctls_low =\n\t\tVM_EXIT_ALWAYSON_WITHOUT_TRUE_MSR;\n\n\tmsrs->exit_ctls_high &=\n#ifdef CONFIG_X86_64\n\t\tVM_EXIT_HOST_ADDR_SPACE_SIZE |\n#endif\n\t\tVM_EXIT_LOAD_IA32_PAT | VM_EXIT_SAVE_IA32_PAT |\n\t\tVM_EXIT_CLEAR_BNDCFGS | VM_EXIT_LOAD_IA32_PERF_GLOBAL_CTRL;\n\tmsrs->exit_ctls_high |=\n\t\tVM_EXIT_ALWAYSON_WITHOUT_TRUE_MSR |\n\t\tVM_EXIT_LOAD_IA32_EFER | VM_EXIT_SAVE_IA32_EFER |\n\t\tVM_EXIT_SAVE_VMX_PREEMPTION_TIMER | VM_EXIT_ACK_INTR_ON_EXIT;\n\n\t/* We support free control of debug control saving. */\n\tmsrs->exit_ctls_low &= ~VM_EXIT_SAVE_DEBUG_CONTROLS;\n\n\t/* entry controls */\n\trdmsr(MSR_IA32_VMX_ENTRY_CTLS,\n\t\tmsrs->entry_ctls_low,\n\t\tmsrs->entry_ctls_high);\n\tmsrs->entry_ctls_low =\n\t\tVM_ENTRY_ALWAYSON_WITHOUT_TRUE_MSR;\n\tmsrs->entry_ctls_high &=\n#ifdef CONFIG_X86_64\n\t\tVM_ENTRY_IA32E_MODE |\n#endif\n\t\tVM_ENTRY_LOAD_IA32_PAT | VM_ENTRY_LOAD_BNDCFGS |\n\t\tVM_ENTRY_LOAD_IA32_PERF_GLOBAL_CTRL;\n\tmsrs->entry_ctls_high |=\n\t\t(VM_ENTRY_ALWAYSON_WITHOUT_TRUE_MSR | VM_ENTRY_LOAD_IA32_EFER);\n\n\t/* We support free control of debug control loading. */\n\tmsrs->entry_ctls_low &= ~VM_ENTRY_LOAD_DEBUG_CONTROLS;\n\n\t/* cpu-based controls */\n\trdmsr(MSR_IA32_VMX_PROCBASED_CTLS,\n\t\tmsrs->procbased_ctls_low,\n\t\tmsrs->procbased_ctls_high);\n\tmsrs->procbased_ctls_low =\n\t\tCPU_BASED_ALWAYSON_WITHOUT_TRUE_MSR;\n\tmsrs->procbased_ctls_high &=\n\t\tCPU_BASED_INTR_WINDOW_EXITING |\n\t\tCPU_BASED_NMI_WINDOW_EXITING | CPU_BASED_USE_TSC_OFFSETTING |\n\t\tCPU_BASED_HLT_EXITING | CPU_BASED_INVLPG_EXITING |\n\t\tCPU_BASED_MWAIT_EXITING | CPU_BASED_CR3_LOAD_EXITING |\n\t\tCPU_BASED_CR3_STORE_EXITING |\n#ifdef CONFIG_X86_64\n\t\tCPU_BASED_CR8_LOAD_EXITING | CPU_BASED_CR8_STORE_EXITING |\n#endif\n\t\tCPU_BASED_MOV_DR_EXITING | CPU_BASED_UNCOND_IO_EXITING |\n\t\tCPU_BASED_USE_IO_BITMAPS | CPU_BASED_MONITOR_TRAP_FLAG |\n\t\tCPU_BASED_MONITOR_EXITING | CPU_BASED_RDPMC_EXITING |\n\t\tCPU_BASED_RDTSC_EXITING | CPU_BASED_PAUSE_EXITING |\n\t\tCPU_BASED_TPR_SHADOW | CPU_BASED_ACTIVATE_SECONDARY_CONTROLS;\n\t/*\n\t * We can allow some features even when not supported by the\n\t * hardware. For example, L1 can specify an MSR bitmap - and we\n\t * can use it to avoid exits to L1 - even when L0 runs L2\n\t * without MSR bitmaps.\n\t */\n\tmsrs->procbased_ctls_high |=\n\t\tCPU_BASED_ALWAYSON_WITHOUT_TRUE_MSR |\n\t\tCPU_BASED_USE_MSR_BITMAPS;\n\n\t/* We support free control of CR3 access interception. */\n\tmsrs->procbased_ctls_low &=\n\t\t~(CPU_BASED_CR3_LOAD_EXITING | CPU_BASED_CR3_STORE_EXITING);\n\n\t/*\n\t * secondary cpu-based controls.  Do not include those that\n\t * depend on CPUID bits, they are added later by\n\t * vmx_vcpu_after_set_cpuid.\n\t */\n\tif (msrs->procbased_ctls_high & CPU_BASED_ACTIVATE_SECONDARY_CONTROLS)\n\t\trdmsr(MSR_IA32_VMX_PROCBASED_CTLS2,\n\t\t      msrs->secondary_ctls_low,\n\t\t      msrs->secondary_ctls_high);\n\n\tmsrs->secondary_ctls_low = 0;\n\tmsrs->secondary_ctls_high &=\n\t\tSECONDARY_EXEC_DESC |\n\t\tSECONDARY_EXEC_ENABLE_RDTSCP |\n\t\tSECONDARY_EXEC_VIRTUALIZE_X2APIC_MODE |\n\t\tSECONDARY_EXEC_WBINVD_EXITING |\n\t\tSECONDARY_EXEC_APIC_REGISTER_VIRT |\n\t\tSECONDARY_EXEC_VIRTUAL_INTR_DELIVERY |\n\t\tSECONDARY_EXEC_RDRAND_EXITING |\n\t\tSECONDARY_EXEC_ENABLE_INVPCID |\n\t\tSECONDARY_EXEC_RDSEED_EXITING |\n\t\tSECONDARY_EXEC_XSAVES;\n\n\t/*\n\t * We can emulate \"VMCS shadowing,\" even if the hardware\n\t * doesn't support it.\n\t */\n\tmsrs->secondary_ctls_high |=\n\t\tSECONDARY_EXEC_SHADOW_VMCS;\n\n\tif (enable_ept) {\n\t\t/* nested EPT: emulate EPT also to L1 */\n\t\tmsrs->secondary_ctls_high |=\n\t\t\tSECONDARY_EXEC_ENABLE_EPT;\n\t\tmsrs->ept_caps =\n\t\t\tVMX_EPT_PAGE_WALK_4_BIT |\n\t\t\tVMX_EPT_PAGE_WALK_5_BIT |\n\t\t\tVMX_EPTP_WB_BIT |\n\t\t\tVMX_EPT_INVEPT_BIT |\n\t\t\tVMX_EPT_EXECUTE_ONLY_BIT;\n\n\t\tmsrs->ept_caps &= ept_caps;\n\t\tmsrs->ept_caps |= VMX_EPT_EXTENT_GLOBAL_BIT |\n\t\t\tVMX_EPT_EXTENT_CONTEXT_BIT | VMX_EPT_2MB_PAGE_BIT |\n\t\t\tVMX_EPT_1GB_PAGE_BIT;\n\t\tif (enable_ept_ad_bits) {\n\t\t\tmsrs->secondary_ctls_high |=\n\t\t\t\tSECONDARY_EXEC_ENABLE_PML;\n\t\t\tmsrs->ept_caps |= VMX_EPT_AD_BIT;\n\t\t}\n\t}\n\n\tif (cpu_has_vmx_vmfunc()) {\n\t\tmsrs->secondary_ctls_high |=\n\t\t\tSECONDARY_EXEC_ENABLE_VMFUNC;\n\t\t/*\n\t\t * Advertise EPTP switching unconditionally\n\t\t * since we emulate it\n\t\t */\n\t\tif (enable_ept)\n\t\t\tmsrs->vmfunc_controls =\n\t\t\t\tVMX_VMFUNC_EPTP_SWITCHING;\n\t}\n\n\t/*\n\t * Old versions of KVM use the single-context version without\n\t * checking for support, so declare that it is supported even\n\t * though it is treated as global context.  The alternative is\n\t * not failing the single-context invvpid, and it is worse.\n\t */\n\tif (enable_vpid) {\n\t\tmsrs->secondary_ctls_high |=\n\t\t\tSECONDARY_EXEC_ENABLE_VPID;\n\t\tmsrs->vpid_caps = VMX_VPID_INVVPID_BIT |\n\t\t\tVMX_VPID_EXTENT_SUPPORTED_MASK;\n\t}\n\n\tif (enable_unrestricted_guest)\n\t\tmsrs->secondary_ctls_high |=\n\t\t\tSECONDARY_EXEC_UNRESTRICTED_GUEST;\n\n\tif (flexpriority_enabled)\n\t\tmsrs->secondary_ctls_high |=\n\t\t\tSECONDARY_EXEC_VIRTUALIZE_APIC_ACCESSES;\n\n\t/* miscellaneous data */\n\trdmsr(MSR_IA32_VMX_MISC,\n\t\tmsrs->misc_low,\n\t\tmsrs->misc_high);\n\tmsrs->misc_low &= VMX_MISC_SAVE_EFER_LMA;\n\tmsrs->misc_low |=\n\t\tMSR_IA32_VMX_MISC_VMWRITE_SHADOW_RO_FIELDS |\n\t\tVMX_MISC_EMULATED_PREEMPTION_TIMER_RATE |\n\t\tVMX_MISC_ACTIVITY_HLT |\n\t\tVMX_MISC_ACTIVITY_WAIT_SIPI;\n\tmsrs->misc_high = 0;\n\n\t/*\n\t * This MSR reports some information about VMX support. We\n\t * should return information about the VMX we emulate for the\n\t * guest, and the VMCS structure we give it - not about the\n\t * VMX support of the underlying hardware.\n\t */\n\tmsrs->basic =\n\t\tVMCS12_REVISION |\n\t\tVMX_BASIC_TRUE_CTLS |\n\t\t((u64)VMCS12_SIZE << VMX_BASIC_VMCS_SIZE_SHIFT) |\n\t\t(VMX_BASIC_MEM_TYPE_WB << VMX_BASIC_MEM_TYPE_SHIFT);\n\n\tif (cpu_has_vmx_basic_inout())\n\t\tmsrs->basic |= VMX_BASIC_INOUT;\n\n\t/*\n\t * These MSRs specify bits which the guest must keep fixed on\n\t * while L1 is in VMXON mode (in L1's root mode, or running an L2).\n\t * We picked the standard core2 setting.\n\t */\n#define VMXON_CR0_ALWAYSON     (X86_CR0_PE | X86_CR0_PG | X86_CR0_NE)\n#define VMXON_CR4_ALWAYSON     X86_CR4_VMXE\n\tmsrs->cr0_fixed0 = VMXON_CR0_ALWAYSON;\n\tmsrs->cr4_fixed0 = VMXON_CR4_ALWAYSON;\n\n\t/* These MSRs specify bits which the guest must keep fixed off. */\n\trdmsrl(MSR_IA32_VMX_CR0_FIXED1, msrs->cr0_fixed1);\n\trdmsrl(MSR_IA32_VMX_CR4_FIXED1, msrs->cr4_fixed1);\n\n\t/* highest index: VMX_PREEMPTION_TIMER_VALUE */\n\tmsrs->vmcs_enum = VMCS12_MAX_FIELD_INDEX << 1;\n}\n\nvoid nested_vmx_hardware_unsetup(void)\n{\n\tint i;\n\n\tif (enable_shadow_vmcs) {\n\t\tfor (i = 0; i < VMX_BITMAP_NR; i++)\n\t\t\tfree_page((unsigned long)vmx_bitmap[i]);\n\t}\n}\n\n__init int nested_vmx_hardware_setup(int (*exit_handlers[])(struct kvm_vcpu *))\n{\n\tint i;\n\n\tif (!cpu_has_vmx_shadow_vmcs())\n\t\tenable_shadow_vmcs = 0;\n\tif (enable_shadow_vmcs) {\n\t\tfor (i = 0; i < VMX_BITMAP_NR; i++) {\n\t\t\t/*\n\t\t\t * The vmx_bitmap is not tied to a VM and so should\n\t\t\t * not be charged to a memcg.\n\t\t\t */\n\t\t\tvmx_bitmap[i] = (unsigned long *)\n\t\t\t\t__get_free_page(GFP_KERNEL);\n\t\t\tif (!vmx_bitmap[i]) {\n\t\t\t\tnested_vmx_hardware_unsetup();\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\t\t}\n\n\t\tinit_vmcs_shadow_fields();\n\t}\n\n\texit_handlers[EXIT_REASON_VMCLEAR]\t= handle_vmclear;\n\texit_handlers[EXIT_REASON_VMLAUNCH]\t= handle_vmlaunch;\n\texit_handlers[EXIT_REASON_VMPTRLD]\t= handle_vmptrld;\n\texit_handlers[EXIT_REASON_VMPTRST]\t= handle_vmptrst;\n\texit_handlers[EXIT_REASON_VMREAD]\t= handle_vmread;\n\texit_handlers[EXIT_REASON_VMRESUME]\t= handle_vmresume;\n\texit_handlers[EXIT_REASON_VMWRITE]\t= handle_vmwrite;\n\texit_handlers[EXIT_REASON_VMOFF]\t= handle_vmoff;\n\texit_handlers[EXIT_REASON_VMON]\t\t= handle_vmon;\n\texit_handlers[EXIT_REASON_INVEPT]\t= handle_invept;\n\texit_handlers[EXIT_REASON_INVVPID]\t= handle_invvpid;\n\texit_handlers[EXIT_REASON_VMFUNC]\t= handle_vmfunc;\n\n\treturn 0;\n}\n\nstruct kvm_x86_nested_ops vmx_nested_ops = {\n\t.check_events = vmx_check_nested_events,\n\t.hv_timer_pending = nested_vmx_preemption_timer_pending,\n\t.get_state = vmx_get_nested_state,\n\t.set_state = vmx_set_nested_state,\n\t.get_nested_state_pages = nested_get_vmcs12_pages,\n\t.write_log_dirty = nested_vmx_write_pml_buffer,\n\t.enable_evmcs = nested_enable_evmcs,\n\t.get_evmcs_version = nested_get_evmcs_version,\n};\n"}}, "reports": [{"events": [{"location": {"col": 0, "file": 0, "line": 5529}, "message": "warn: should '(1 << function)' be a 64 bit type?"}], "macros": [], "notes": [], "path": "/src/arch/x86/kvm/vmx/nested.c", "reportHash": "8ec6127db5631148edf41ad1fa67c212", "checkerName": "smatch.check_64bit_shift", "reviewStatus": null, "severity": "UNSPECIFIED"}]};
      window.onload = function() {
        if (!browserCompatible) {
          setNonCompatibleBrowserMessage();
        } else {
          BugViewer.init(data.files, data.reports);
          BugViewer.create();
          BugViewer.initByUrl();
        }
      };
    </script>
  </head>
  <body>
  <div class="container">
    <div id="content">
      <div id="side-bar">
        <div class="header">
          <a href="index.html" class="button">&#8249; Return to List</a>
        </div>
        <div id="report-nav">
          <div class="header">Reports</div>
        </div>
      </div>
      <div id="editor-wrapper">
        <div class="header">
          <div id="file">
            <span class="label">File:</span>
            <span id="file-path"></span>
          </div>
          <div id="checker">
            <span class="label">Checker name:</span>
            <span id="checker-name"></span>
          </div>
          <div id="review-status-wrapper">
            <span class="label">Review status:</span>
            <span id="review-status"></span>
          </div>
        </div>
        <div id="editor"></div>
      </div>
    </div>
  </div>
  </body>
</html>
