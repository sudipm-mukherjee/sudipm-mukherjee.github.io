<!DOCTYPE html>
<html>
  <head>
    <title>Plist HTML Viewer</title>

    <meta charset="UTF-8">

    <style type="text/css">
      .CodeMirror{font-family:monospace;height:300px;color:#000;direction:ltr}.CodeMirror-lines{padding:4px 0}.CodeMirror pre{padding:0 4px}.CodeMirror-gutter-filler,.CodeMirror-scrollbar-filler{background-color:#fff}.CodeMirror-gutters{border-right:1px solid #ddd;background-color:#f7f7f7;white-space:nowrap}.CodeMirror-linenumber{padding:0 3px 0 5px;min-width:20px;text-align:right;color:#999;white-space:nowrap}.CodeMirror-guttermarker{color:#000}.CodeMirror-guttermarker-subtle{color:#999}.CodeMirror-cursor{border-left:1px solid #000;border-right:none;width:0}.CodeMirror div.CodeMirror-secondarycursor{border-left:1px solid silver}.cm-fat-cursor .CodeMirror-cursor{width:auto;border:0!important;background:#7e7}.cm-fat-cursor div.CodeMirror-cursors{z-index:1}.cm-animate-fat-cursor{width:auto;border:0;-webkit-animation:blink 1.06s steps(1) infinite;-moz-animation:blink 1.06s steps(1) infinite;animation:blink 1.06s steps(1) infinite;background-color:#7e7}@-moz-keyframes blink{50%{background-color:transparent}}@-webkit-keyframes blink{50%{background-color:transparent}}@keyframes blink{50%{background-color:transparent}}.cm-tab{display:inline-block;text-decoration:inherit}.CodeMirror-rulers{position:absolute;left:0;right:0;top:-50px;bottom:-20px;overflow:hidden}.CodeMirror-ruler{border-left:1px solid #ccc;top:0;bottom:0;position:absolute}.cm-s-default .cm-header{color:#00f}.cm-s-default .cm-quote{color:#090}.cm-negative{color:#d44}.cm-positive{color:#292}.cm-header,.cm-strong{font-weight:700}.cm-em{font-style:italic}.cm-link{text-decoration:underline}.cm-strikethrough{text-decoration:line-through}.cm-s-default .cm-keyword{color:#708}.cm-s-default .cm-atom{color:#219}.cm-s-default .cm-number{color:#164}.cm-s-default .cm-def{color:#00f}.cm-s-default .cm-variable-2{color:#05a}.cm-s-default .cm-type,.cm-s-default .cm-variable-3{color:#085}.cm-s-default .cm-comment{color:#a50}.cm-s-default .cm-string{color:#a11}.cm-s-default .cm-string-2{color:#f50}.cm-s-default .cm-meta{color:#555}.cm-s-default .cm-qualifier{color:#555}.cm-s-default .cm-builtin{color:#30a}.cm-s-default .cm-bracket{color:#997}.cm-s-default .cm-tag{color:#170}.cm-s-default .cm-attribute{color:#00c}.cm-s-default .cm-hr{color:#999}.cm-s-default .cm-link{color:#00c}.cm-s-default .cm-error{color:red}.cm-invalidchar{color:red}.CodeMirror-composing{border-bottom:2px solid}div.CodeMirror span.CodeMirror-matchingbracket{color:#0f0}div.CodeMirror span.CodeMirror-nonmatchingbracket{color:#f22}.CodeMirror-matchingtag{background:rgba(255,150,0,.3)}.CodeMirror-activeline-background{background:#e8f2ff}.CodeMirror{position:relative;overflow:hidden;background:#fff}.CodeMirror-scroll{overflow:scroll!important;margin-bottom:-30px;margin-right:-30px;padding-bottom:30px;height:100%;outline:0;position:relative}.CodeMirror-sizer{position:relative;border-right:30px solid transparent}.CodeMirror-gutter-filler,.CodeMirror-hscrollbar,.CodeMirror-scrollbar-filler,.CodeMirror-vscrollbar{position:absolute;z-index:6;display:none}.CodeMirror-vscrollbar{right:0;top:0;overflow-x:hidden;overflow-y:scroll}.CodeMirror-hscrollbar{bottom:0;left:0;overflow-y:hidden;overflow-x:scroll}.CodeMirror-scrollbar-filler{right:0;bottom:0}.CodeMirror-gutter-filler{left:0;bottom:0}.CodeMirror-gutters{position:absolute;left:0;top:0;min-height:100%;z-index:3}.CodeMirror-gutter{white-space:normal;height:100%;display:inline-block;vertical-align:top;margin-bottom:-30px}.CodeMirror-gutter-wrapper{position:absolute;z-index:4;background:0 0!important;border:none!important}.CodeMirror-gutter-background{position:absolute;top:0;bottom:0;z-index:4}.CodeMirror-gutter-elt{position:absolute;cursor:default;z-index:4}.CodeMirror-gutter-wrapper ::selection{background-color:transparent}.CodeMirror-gutter-wrapper ::-moz-selection{background-color:transparent}.CodeMirror-lines{cursor:text;min-height:1px}.CodeMirror pre{-moz-border-radius:0;-webkit-border-radius:0;border-radius:0;border-width:0;background:0 0;font-family:inherit;font-size:inherit;margin:0;white-space:pre;word-wrap:normal;line-height:inherit;color:inherit;z-index:2;position:relative;overflow:visible;-webkit-tap-highlight-color:transparent;-webkit-font-variant-ligatures:contextual;font-variant-ligatures:contextual}.CodeMirror-wrap pre{word-wrap:break-word;white-space:pre-wrap;word-break:normal}.CodeMirror-linebackground{position:absolute;left:0;right:0;top:0;bottom:0;z-index:0}.CodeMirror-linewidget{position:relative;z-index:2;overflow:auto}.CodeMirror-rtl pre{direction:rtl}.CodeMirror-code{outline:0}.CodeMirror-gutter,.CodeMirror-gutters,.CodeMirror-linenumber,.CodeMirror-scroll,.CodeMirror-sizer{-moz-box-sizing:content-box;box-sizing:content-box}.CodeMirror-measure{position:absolute;width:100%;height:0;overflow:hidden;visibility:hidden}.CodeMirror-cursor{position:absolute;pointer-events:none}.CodeMirror-measure pre{position:static}div.CodeMirror-cursors{visibility:hidden;position:relative;z-index:3}div.CodeMirror-dragcursors{visibility:visible}.CodeMirror-focused div.CodeMirror-cursors{visibility:visible}.CodeMirror-selected{background:#d9d9d9}.CodeMirror-focused .CodeMirror-selected{background:#d7d4f0}.CodeMirror-crosshair{cursor:crosshair}.CodeMirror-line::selection,.CodeMirror-line>span::selection,.CodeMirror-line>span>span::selection{background:#d7d4f0}.CodeMirror-line::-moz-selection,.CodeMirror-line>span::-moz-selection,.CodeMirror-line>span>span::-moz-selection{background:#d7d4f0}.cm-searching{background-color:#ffa;background-color:rgba(255,255,0,.4)}.cm-force-border{padding-right:.1px}@media print{.CodeMirror div.CodeMirror-cursors{visibility:hidden}}.cm-tab-wrap-hack:after{content:''}span.CodeMirror-selectedtext{background:0 0}
/*# sourceMappingURL=codemirror.min.css.map */

      .severity-low {
  background-color: #669603;
}

.severity-low:after {
  content : 'L';
}

.severity-unspecified {
  background-color: #666666;
}

.severity-unspecified:after {
  content : 'U';
}

.severity-style {
  background-color: #9932cc;
}

.severity-style:after {
  content : 'S';
}

.severity-medium {
  background-color: #a9d323;
  color: black;
}

.severity-medium:after {
  content : 'M';
}

.severity-high {
  background-color: #ffa800;
}

.severity-high:after {
  content : 'H';
}

.severity-critical {
  background-color: #e92625;
}

.severity-critical:after {
  content : 'C';
}

i[class*="severity-"] {
  line-height: normal;
  text-transform: capitalize;
  font-size: 0.8em;
  font-weight: bold;
  color: white;
  display: inline-block;
  width: 16px;
  height: 16px;
  text-align: center;
  font-family: sans-serif;
}

      html, body {
  width: 100%;
  height: 100%;
  padding: 0px;
  margin: 0px;
}

div.container {
  padding: 10px;
}

#content {
  height: 100%;
  display: block;
  overflow: hidden;
}

#content > div {
  margin: 10px;
  overflow: hidden;
  border: 1px solid #ddd;
  border-radius: 3px;
  overflow: hidden;
  height: 97%;
}

.button {
  background-color: #f1f1f1;
  text-decoration: none;
  display: inline-block;
  padding: 8px 16px;
  color: black;
  cursor: pointer;
}

.button:hover {
  background-color: #ddd;
  color: black;
}

.review-status {
  color: white;
  text-align: center;
}

.review-status-confirmed {
  background-color: #e92625;
}

.review-status-false-positive {
  background-color: grey;
}

.review-status-intentional {
  background-color: #669603;
}

      div.container {
  width: 100%;
  height: 100%;
  padding: 0px;
}

#editor-wrapper {
  margin: 10px;
}

#side-bar {
  float: left;
  width: 260px;
  margin: 0px;
}

#report-nav ul {
  list-style-type: none;
  padding: 0;
  margin: 0;
  overflow-y: auto;
  height: 100%;
}

#report-nav ul > li {
  padding: .4em;
  background-color: #fff;
  border-bottom: 1px solid rgba(0,0,0,.125);
  text-align: left;
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

#report-nav ul > li.active {
  background-color: #427ea9;
  color: white;
}

#report-nav ul > li:hover {
  background-color: #427ea9;
  color: white;
  cursor: pointer;
}

#report-nav ul a {
  text-decoration: none;
}

#report-nav i[class*="severity-"] {
  margin-right: 5px;
}

.header {
  border-bottom: 1px solid lightgrey;
  font-family: monospace;
  padding: 10px;
  background-color: #fafbfc;
  border-bottom: 1px solid #e1e4e8;
  border-top-left-radius: 2px;
  border-top-right-radius: 2px;
}

#report-nav .header {
  font-weight: bold;
}

#editor-wrapper .header > div {
  padding-top: 2px;
}

#file-path,
#checker-name {
  color: #195ea2;
}

#review-status {
  padding: 0px 5px;
}

#file-path {
  font-family: monospace;
}

.check-msg {
  display: inline-block;
  padding: 3px 6px;
  margin: 1px;
  -webkit-border-radius: 5px;
  -moz-border-radius: 5px;
  border-radius: 5px;
}

.check-msg.info {
  color: #00546f;
  background-color: #bfdfe9;
  border: 1px solid #87a8b3;
}

.check-msg.error {
  background-color: #f2dede;
  color: #a94442;
  border: 1px solid #ebcccc;
}

.check-msg.macro {
  background-color: #d7dac2;
  color: #4f5c6d;
  border: 1px solid #d7dac2;
}

.check-msg.note {
  background-color: #d7d7d7;
  color: #4f5c6d;
  border: 1px solid #bfbfbf;
}

.check-msg.current {
  border: 2px dashed #3692ff;
}

.check-msg .tag {
  padding: 1px 5px;
  text-align: center;
  border-radius: 2px;
  margin-right: 5px;
  text-decoration: inherit;
}

.check-msg .tag.macro {
  background-color: #83876a;
  color: white;
  text-transform: capitalize;
}

.check-msg .tag.note {
  background-color: #9299a1;
  color: white;
  text-transform: capitalize;
}

.checker-enum {
  color: white;
  padding: 1px 5px;
  text-align: center;
  border-radius: 25px;
  margin-right: 5px;
  text-decoration: inherit;
}

.checker-enum.info {
  background-color: #427ea9;
}

.checker-enum.error {
  background-color: #a94442;
}

.arrow {
  border: solid black;
  border-width: 0 3px 3px 0;
  display: inline-block;
  padding: 3px;
  cursor: pointer;
  margin: 0px 5px;
}

.arrow:hover {
  border: solid #437ea8;
  border-width: 0 3px 3px 0;
}

.left-arrow {
  transform: rotate(135deg);
  -webkit-transform: rotate(135deg);
}

.right-arrow {
  transform: rotate(-45deg);
  -webkit-transform: rotate(-45deg);
}

    </style>

    <script type="text/javascript">
      function setNonCompatibleBrowserMessage() {
  document.body.innerHTML =
    '<h2 style="margin-left: 20px;">Your browser is not compatible with CodeChecker Viewer!</h2> \
     <p style="margin-left: 20px;">The version required for the following browsers are:</p> \
     <ul style="margin-left: 20px;"> \
     <li>Internet Explorer: version 9 or newer</li> \
     <li>Firefox: version 22.0 or newer</li> \
     </ul>';
}

// http://stackoverflow.com/questions/5916900/how-can-you-detect-the-version-of-a-browser
var browserVersion = (function(){
  var ua = navigator.userAgent, tem,
    M = ua.match(/(opera|chrome|safari|firefox|msie|trident(?=\/))\/?\s*(\d+)/i) || [];

  if (/trident/i.test(M[1])) {
    tem = /\brv[ :]+(\d+)/g.exec(ua) || [];
    return 'IE ' + (tem[1] || '');
  }

  if (M[1] === 'Chrome') {
    tem = ua.match(/\b(OPR|Edge)\/(\d+)/);
    if (tem != null) return tem.slice(1).join(' ').replace('OPR', 'Opera');
  }

  M = M[2] ? [M[1], M[2]] : [navigator.appName, navigator.appVersion, '-?'];
  if ((tem = ua.match(/version\/(\d+)/i)) != null) M.splice(1, 1, tem[1]);
    return M.join(' ');
})();

var pos = browserVersion.indexOf(' ');
var browser = browserVersion.substr(0, pos);
var version = parseInt(browserVersion.substr(pos + 1));

var browserCompatible
  = browser === 'Firefox'
  ? version >= 22
  : browser === 'IE'
  ? version >= 9
  : true;


      /* MIT License

Copyright (C) 2017 by Marijn Haverbeke <marijnh@gmail.com> and others

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
 */
      !function(e,t){"object"==typeof exports&&"undefined"!=typeof module?module.exports=t():"function"==typeof define&&define.amd?define(t):e.CodeMirror=t()}(this,function(){"use strict";function e(e){return new RegExp("(^|\\s)"+e+"(?:$|\\s)\\s*")}function t(e){for(var t=e.childNodes.length;t>0;--t)e.removeChild(e.firstChild);return e}function r(e,r){return t(e).appendChild(r)}function n(e,t,r,n){var i=document.createElement(e);if(r&&(i.className=r),n&&(i.style.cssText=n),"string"==typeof t)i.appendChild(document.createTextNode(t));else if(t)for(var o=0;o<t.length;++o)i.appendChild(t[o]);return i}function i(e,t,r,i){var o=n(e,t,r,i);return o.setAttribute("role","presentation"),o}function o(e,t){if(3==t.nodeType&&(t=t.parentNode),e.contains)return e.contains(t);do{if(11==t.nodeType&&(t=t.host),t==e)return!0}while(t=t.parentNode)}function l(){var e;try{e=document.activeElement}catch(t){e=document.body||null}for(;e&&e.shadowRoot&&e.shadowRoot.activeElement;)e=e.shadowRoot.activeElement;return e}function s(t,r){var n=t.className;e(r).test(n)||(t.className+=(n?" ":"")+r)}function a(t,r){for(var n=t.split(" "),i=0;i<n.length;i++)n[i]&&!e(n[i]).test(r)&&(r+=" "+n[i]);return r}function u(e){var t=Array.prototype.slice.call(arguments,1);return function(){return e.apply(null,t)}}function c(e,t,r){t||(t={});for(var n in e)!e.hasOwnProperty(n)||!1===r&&t.hasOwnProperty(n)||(t[n]=e[n]);return t}function f(e,t,r,n,i){null==t&&-1==(t=e.search(/[^\s\u00a0]/))&&(t=e.length);for(var o=n||0,l=i||0;;){var s=e.indexOf("\t",o);if(s<0||s>=t)return l+(t-o);l+=s-o,l+=r-l%r,o=s+1}}function h(e,t){for(var r=0;r<e.length;++r)if(e[r]==t)return r;return-1}function d(e,t,r){for(var n=0,i=0;;){var o=e.indexOf("\t",n);-1==o&&(o=e.length);var l=o-n;if(o==e.length||i+l>=t)return n+Math.min(l,t-i);if(i+=o-n,i+=r-i%r,n=o+1,i>=t)return n}}function p(e){for(;Kl.length<=e;)Kl.push(g(Kl)+" ");return Kl[e]}function g(e){return e[e.length-1]}function v(e,t){for(var r=[],n=0;n<e.length;n++)r[n]=t(e[n],n);return r}function m(e,t,r){for(var n=0,i=r(t);n<e.length&&r(e[n])<=i;)n++;e.splice(n,0,t)}function y(){}function b(e,t){var r;return Object.create?r=Object.create(e):(y.prototype=e,r=new y),t&&c(t,r),r}function w(e){return/\w/.test(e)||e>""&&(e.toUpperCase()!=e.toLowerCase()||jl.test(e))}function x(e,t){return t?!!(t.source.indexOf("\\w")>-1&&w(e))||t.test(e):w(e)}function C(e){for(var t in e)if(e.hasOwnProperty(t)&&e[t])return!1;return!0}function S(e){return e.charCodeAt(0)>=768&&Xl.test(e)}function L(e,t,r){for(;(r<0?t>0:t<e.length)&&S(e.charAt(t));)t+=r;return t}function k(e,t,r){for(var n=t>r?-1:1;;){if(t==r)return t;var i=(t+r)/2,o=n<0?Math.ceil(i):Math.floor(i);if(o==t)return e(o)?t:r;e(o)?r=o:t=o+n}}function T(e,t,r){var o=this;this.input=r,o.scrollbarFiller=n("div",null,"CodeMirror-scrollbar-filler"),o.scrollbarFiller.setAttribute("cm-not-content","true"),o.gutterFiller=n("div",null,"CodeMirror-gutter-filler"),o.gutterFiller.setAttribute("cm-not-content","true"),o.lineDiv=i("div",null,"CodeMirror-code"),o.selectionDiv=n("div",null,null,"position: relative; z-index: 1"),o.cursorDiv=n("div",null,"CodeMirror-cursors"),o.measure=n("div",null,"CodeMirror-measure"),o.lineMeasure=n("div",null,"CodeMirror-measure"),o.lineSpace=i("div",[o.measure,o.lineMeasure,o.selectionDiv,o.cursorDiv,o.lineDiv],null,"position: relative; outline: none");var l=i("div",[o.lineSpace],"CodeMirror-lines");o.mover=n("div",[l],null,"position: relative"),o.sizer=n("div",[o.mover],"CodeMirror-sizer"),o.sizerWidth=null,o.heightForcer=n("div",null,null,"position: absolute; height: "+Rl+"px; width: 1px;"),o.gutters=n("div",null,"CodeMirror-gutters"),o.lineGutter=null,o.scroller=n("div",[o.sizer,o.heightForcer,o.gutters],"CodeMirror-scroll"),o.scroller.setAttribute("tabIndex","-1"),o.wrapper=n("div",[o.scrollbarFiller,o.gutterFiller,o.scroller],"CodeMirror"),gl&&vl<8&&(o.gutters.style.zIndex=-1,o.scroller.style.paddingRight=0),ml||fl&&Tl||(o.scroller.draggable=!0),e&&(e.appendChild?e.appendChild(o.wrapper):e(o.wrapper)),o.viewFrom=o.viewTo=t.first,o.reportedViewFrom=o.reportedViewTo=t.first,o.view=[],o.renderedView=null,o.externalMeasured=null,o.viewOffset=0,o.lastWrapHeight=o.lastWrapWidth=0,o.updateLineNumbers=null,o.nativeBarWidth=o.barHeight=o.barWidth=0,o.scrollbarsClipped=!1,o.lineNumWidth=o.lineNumInnerWidth=o.lineNumChars=null,o.alignWidgets=!1,o.cachedCharWidth=o.cachedTextHeight=o.cachedPaddingH=null,o.maxLine=null,o.maxLineLength=0,o.maxLineChanged=!1,o.wheelDX=o.wheelDY=o.wheelStartX=o.wheelStartY=null,o.shift=!1,o.selForContextMenu=null,o.activeTouch=null,r.init(o)}function M(e,t){if((t-=e.first)<0||t>=e.size)throw new Error("There is no line "+(t+e.first)+" in the document.");for(var r=e;!r.lines;)for(var n=0;;++n){var i=r.children[n],o=i.chunkSize();if(t<o){r=i;break}t-=o}return r.lines[t]}function N(e,t,r){var n=[],i=t.line;return e.iter(t.line,r.line+1,function(e){var o=e.text;i==r.line&&(o=o.slice(0,r.ch)),i==t.line&&(o=o.slice(t.ch)),n.push(o),++i}),n}function O(e,t,r){var n=[];return e.iter(t,r,function(e){n.push(e.text)}),n}function A(e,t){var r=t-e.height;if(r)for(var n=e;n;n=n.parent)n.height+=r}function W(e){if(null==e.parent)return null;for(var t=e.parent,r=h(t.lines,e),n=t.parent;n;t=n,n=n.parent)for(var i=0;n.children[i]!=t;++i)r+=n.children[i].chunkSize();return r+t.first}function D(e,t){var r=e.first;e:do{for(var n=0;n<e.children.length;++n){var i=e.children[n],o=i.height;if(t<o){e=i;continue e}t-=o,r+=i.chunkSize()}return r}while(!e.lines);for(var l=0;l<e.lines.length;++l){var s=e.lines[l].height;if(t<s)break;t-=s}return r+l}function H(e,t){return t>=e.first&&t<e.first+e.size}function F(e,t){return String(e.lineNumberFormatter(t+e.firstLineNumber))}function E(e,t,r){if(void 0===r&&(r=null),!(this instanceof E))return new E(e,t,r);this.line=e,this.ch=t,this.sticky=r}function P(e,t){return e.line-t.line||e.ch-t.ch}function I(e,t){return e.sticky==t.sticky&&0==P(e,t)}function z(e){return E(e.line,e.ch)}function R(e,t){return P(e,t)<0?t:e}function B(e,t){return P(e,t)<0?e:t}function G(e,t){return Math.max(e.first,Math.min(t,e.first+e.size-1))}function U(e,t){if(t.line<e.first)return E(e.first,0);var r=e.first+e.size-1;return t.line>r?E(r,M(e,r).text.length):V(t,M(e,t.line).text.length)}function V(e,t){var r=e.ch;return null==r||r>t?E(e.line,t):r<0?E(e.line,0):e}function K(e,t){for(var r=[],n=0;n<t.length;n++)r[n]=U(e,t[n]);return r}function j(){Yl=!0}function X(){_l=!0}function Y(e,t,r){this.marker=e,this.from=t,this.to=r}function _(e,t){if(e)for(var r=0;r<e.length;++r){var n=e[r];if(n.marker==t)return n}}function $(e,t){for(var r,n=0;n<e.length;++n)e[n]!=t&&(r||(r=[])).push(e[n]);return r}function q(e,t){e.markedSpans=e.markedSpans?e.markedSpans.concat([t]):[t],t.marker.attachLine(e)}function Z(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t)||o.from==t&&"bookmark"==l.type&&(!r||!o.marker.insertLeft)){var s=null==o.to||(l.inclusiveRight?o.to>=t:o.to>t);(n||(n=[])).push(new Y(l,o.from,s?null:o.to))}}return n}function Q(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.to||(l.inclusiveRight?o.to>=t:o.to>t)||o.from==t&&"bookmark"==l.type&&(!r||o.marker.insertLeft)){var s=null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t);(n||(n=[])).push(new Y(l,s?null:o.from-t,null==o.to?null:o.to-t))}}return n}function J(e,t){if(t.full)return null;var r=H(e,t.from.line)&&M(e,t.from.line).markedSpans,n=H(e,t.to.line)&&M(e,t.to.line).markedSpans;if(!r&&!n)return null;var i=t.from.ch,o=t.to.ch,l=0==P(t.from,t.to),s=Z(r,i,l),a=Q(n,o,l),u=1==t.text.length,c=g(t.text).length+(u?i:0);if(s)for(var f=0;f<s.length;++f){var h=s[f];if(null==h.to){var d=_(a,h.marker);d?u&&(h.to=null==d.to?null:d.to+c):h.to=i}}if(a)for(var p=0;p<a.length;++p){var v=a[p];null!=v.to&&(v.to+=c),null==v.from?_(s,v.marker)||(v.from=c,u&&(s||(s=[])).push(v)):(v.from+=c,u&&(s||(s=[])).push(v))}s&&(s=ee(s)),a&&a!=s&&(a=ee(a));var m=[s];if(!u){var y,b=t.text.length-2;if(b>0&&s)for(var w=0;w<s.length;++w)null==s[w].to&&(y||(y=[])).push(new Y(s[w].marker,null,null));for(var x=0;x<b;++x)m.push(y);m.push(a)}return m}function ee(e){for(var t=0;t<e.length;++t){var r=e[t];null!=r.from&&r.from==r.to&&!1!==r.marker.clearWhenEmpty&&e.splice(t--,1)}return e.length?e:null}function te(e,t,r){var n=null;if(e.iter(t.line,r.line+1,function(e){if(e.markedSpans)for(var t=0;t<e.markedSpans.length;++t){var r=e.markedSpans[t].marker;!r.readOnly||n&&-1!=h(n,r)||(n||(n=[])).push(r)}}),!n)return null;for(var i=[{from:t,to:r}],o=0;o<n.length;++o)for(var l=n[o],s=l.find(0),a=0;a<i.length;++a){var u=i[a];if(!(P(u.to,s.from)<0||P(u.from,s.to)>0)){var c=[a,1],f=P(u.from,s.from),d=P(u.to,s.to);(f<0||!l.inclusiveLeft&&!f)&&c.push({from:u.from,to:s.from}),(d>0||!l.inclusiveRight&&!d)&&c.push({from:s.to,to:u.to}),i.splice.apply(i,c),a+=c.length-3}}return i}function re(e){var t=e.markedSpans;if(t){for(var r=0;r<t.length;++r)t[r].marker.detachLine(e);e.markedSpans=null}}function ne(e,t){if(t){for(var r=0;r<t.length;++r)t[r].marker.attachLine(e);e.markedSpans=t}}function ie(e){return e.inclusiveLeft?-1:0}function oe(e){return e.inclusiveRight?1:0}function le(e,t){var r=e.lines.length-t.lines.length;if(0!=r)return r;var n=e.find(),i=t.find(),o=P(n.from,i.from)||ie(e)-ie(t);if(o)return-o;var l=P(n.to,i.to)||oe(e)-oe(t);return l||t.id-e.id}function se(e,t){var r,n=_l&&e.markedSpans;if(n)for(var i=void 0,o=0;o<n.length;++o)(i=n[o]).marker.collapsed&&null==(t?i.from:i.to)&&(!r||le(r,i.marker)<0)&&(r=i.marker);return r}function ae(e){return se(e,!0)}function ue(e){return se(e,!1)}function ce(e,t,r,n,i){var o=M(e,t),l=_l&&o.markedSpans;if(l)for(var s=0;s<l.length;++s){var a=l[s];if(a.marker.collapsed){var u=a.marker.find(0),c=P(u.from,r)||ie(a.marker)-ie(i),f=P(u.to,n)||oe(a.marker)-oe(i);if(!(c>=0&&f<=0||c<=0&&f>=0)&&(c<=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.to,r)>=0:P(u.to,r)>0)||c>=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.from,n)<=0:P(u.from,n)<0)))return!0}}}function fe(e){for(var t;t=ae(e);)e=t.find(-1,!0).line;return e}function he(e){for(var t;t=ue(e);)e=t.find(1,!0).line;return e}function de(e){for(var t,r;t=ue(e);)e=t.find(1,!0).line,(r||(r=[])).push(e);return r}function pe(e,t){var r=M(e,t),n=fe(r);return r==n?t:W(n)}function ge(e,t){if(t>e.lastLine())return t;var r,n=M(e,t);if(!ve(e,n))return t;for(;r=ue(n);)n=r.find(1,!0).line;return W(n)+1}function ve(e,t){var r=_l&&t.markedSpans;if(r)for(var n=void 0,i=0;i<r.length;++i)if((n=r[i]).marker.collapsed){if(null==n.from)return!0;if(!n.marker.widgetNode&&0==n.from&&n.marker.inclusiveLeft&&me(e,t,n))return!0}}function me(e,t,r){if(null==r.to){var n=r.marker.find(1,!0);return me(e,n.line,_(n.line.markedSpans,r.marker))}if(r.marker.inclusiveRight&&r.to==t.text.length)return!0;for(var i=void 0,o=0;o<t.markedSpans.length;++o)if((i=t.markedSpans[o]).marker.collapsed&&!i.marker.widgetNode&&i.from==r.to&&(null==i.to||i.to!=r.from)&&(i.marker.inclusiveLeft||r.marker.inclusiveRight)&&me(e,t,i))return!0}function ye(e){for(var t=0,r=(e=fe(e)).parent,n=0;n<r.lines.length;++n){var i=r.lines[n];if(i==e)break;t+=i.height}for(var o=r.parent;o;r=o,o=r.parent)for(var l=0;l<o.children.length;++l){var s=o.children[l];if(s==r)break;t+=s.height}return t}function be(e){if(0==e.height)return 0;for(var t,r=e.text.length,n=e;t=ae(n);){var i=t.find(0,!0);n=i.from.line,r+=i.from.ch-i.to.ch}for(n=e;t=ue(n);){var o=t.find(0,!0);r-=n.text.length-o.from.ch,r+=(n=o.to.line).text.length-o.to.ch}return r}function we(e){var t=e.display,r=e.doc;t.maxLine=M(r,r.first),t.maxLineLength=be(t.maxLine),t.maxLineChanged=!0,r.iter(function(e){var r=be(e);r>t.maxLineLength&&(t.maxLineLength=r,t.maxLine=e)})}function xe(e,t,r,n){if(!e)return n(t,r,"ltr",0);for(var i=!1,o=0;o<e.length;++o){var l=e[o];(l.from<r&&l.to>t||t==r&&l.to==t)&&(n(Math.max(l.from,t),Math.min(l.to,r),1==l.level?"rtl":"ltr",o),i=!0)}i||n(t,r,"ltr")}function Ce(e,t,r){var n;$l=null;for(var i=0;i<e.length;++i){var o=e[i];if(o.from<t&&o.to>t)return i;o.to==t&&(o.from!=o.to&&"before"==r?n=i:$l=i),o.from==t&&(o.from!=o.to&&"before"!=r?n=i:$l=i)}return null!=n?n:$l}function Se(e,t){var r=e.order;return null==r&&(r=e.order=ql(e.text,t)),r}function Le(e,t){return e._handlers&&e._handlers[t]||Zl}function ke(e,t,r){if(e.removeEventListener)e.removeEventListener(t,r,!1);else if(e.detachEvent)e.detachEvent("on"+t,r);else{var n=e._handlers,i=n&&n[t];if(i){var o=h(i,r);o>-1&&(n[t]=i.slice(0,o).concat(i.slice(o+1)))}}}function Te(e,t){var r=Le(e,t);if(r.length)for(var n=Array.prototype.slice.call(arguments,2),i=0;i<r.length;++i)r[i].apply(null,n)}function Me(e,t,r){return"string"==typeof t&&(t={type:t,preventDefault:function(){this.defaultPrevented=!0}}),Te(e,r||t.type,e,t),He(t)||t.codemirrorIgnore}function Ne(e){var t=e._handlers&&e._handlers.cursorActivity;if(t)for(var r=e.curOp.cursorActivityHandlers||(e.curOp.cursorActivityHandlers=[]),n=0;n<t.length;++n)-1==h(r,t[n])&&r.push(t[n])}function Oe(e,t){return Le(e,t).length>0}function Ae(e){e.prototype.on=function(e,t){Ql(this,e,t)},e.prototype.off=function(e,t){ke(this,e,t)}}function We(e){e.preventDefault?e.preventDefault():e.returnValue=!1}function De(e){e.stopPropagation?e.stopPropagation():e.cancelBubble=!0}function He(e){return null!=e.defaultPrevented?e.defaultPrevented:0==e.returnValue}function Fe(e){We(e),De(e)}function Ee(e){return e.target||e.srcElement}function Pe(e){var t=e.which;return null==t&&(1&e.button?t=1:2&e.button?t=3:4&e.button&&(t=2)),Ml&&e.ctrlKey&&1==t&&(t=3),t}function Ie(e){if(null==Il){var t=n("span","​");r(e,n("span",[t,document.createTextNode("x")])),0!=e.firstChild.offsetHeight&&(Il=t.offsetWidth<=1&&t.offsetHeight>2&&!(gl&&vl<8))}var i=Il?n("span","​"):n("span"," ",null,"display: inline-block; width: 1px; margin-right: -1px");return i.setAttribute("cm-text",""),i}function ze(e){if(null!=zl)return zl;var n=r(e,document.createTextNode("AخA")),i=Wl(n,0,1).getBoundingClientRect(),o=Wl(n,1,2).getBoundingClientRect();return t(e),!(!i||i.left==i.right)&&(zl=o.right-i.right<3)}function Re(e){if(null!=ns)return ns;var t=r(e,n("span","x")),i=t.getBoundingClientRect(),o=Wl(t,0,1).getBoundingClientRect();return ns=Math.abs(i.left-o.left)>1}function Be(e,t){arguments.length>2&&(t.dependencies=Array.prototype.slice.call(arguments,2)),is[e]=t}function Ge(e){if("string"==typeof e&&os.hasOwnProperty(e))e=os[e];else if(e&&"string"==typeof e.name&&os.hasOwnProperty(e.name)){var t=os[e.name];"string"==typeof t&&(t={name:t}),(e=b(t,e)).name=t.name}else{if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+xml$/.test(e))return Ge("application/xml");if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+json$/.test(e))return Ge("application/json")}return"string"==typeof e?{name:e}:e||{name:"null"}}function Ue(e,t){t=Ge(t);var r=is[t.name];if(!r)return Ue(e,"text/plain");var n=r(e,t);if(ls.hasOwnProperty(t.name)){var i=ls[t.name];for(var o in i)i.hasOwnProperty(o)&&(n.hasOwnProperty(o)&&(n["_"+o]=n[o]),n[o]=i[o])}if(n.name=t.name,t.helperType&&(n.helperType=t.helperType),t.modeProps)for(var l in t.modeProps)n[l]=t.modeProps[l];return n}function Ve(e,t){c(t,ls.hasOwnProperty(e)?ls[e]:ls[e]={})}function Ke(e,t){if(!0===t)return t;if(e.copyState)return e.copyState(t);var r={};for(var n in t){var i=t[n];i instanceof Array&&(i=i.concat([])),r[n]=i}return r}function je(e,t){for(var r;e.innerMode&&(r=e.innerMode(t))&&r.mode!=e;)t=r.state,e=r.mode;return r||{mode:e,state:t}}function Xe(e,t,r){return!e.startState||e.startState(t,r)}function Ye(e,t,r,n){var i=[e.state.modeGen],o={};tt(e,t.text,e.doc.mode,r,function(e,t){return i.push(e,t)},o,n);for(var l=r.state,s=0;s<e.state.overlays.length;++s)!function(n){var l=e.state.overlays[n],s=1,a=0;r.state=!0,tt(e,t.text,l.mode,r,function(e,t){for(var r=s;a<e;){var n=i[s];n>e&&i.splice(s,1,e,i[s+1],n),s+=2,a=Math.min(e,n)}if(t)if(l.opaque)i.splice(r,s-r,e,"overlay "+t),s=r+2;else for(;r<s;r+=2){var o=i[r+1];i[r+1]=(o?o+" ":"")+"overlay "+t}},o)}(s);return r.state=l,{styles:i,classes:o.bgClass||o.textClass?o:null}}function _e(e,t,r){if(!t.styles||t.styles[0]!=e.state.modeGen){var n=$e(e,W(t)),i=t.text.length>e.options.maxHighlightLength&&Ke(e.doc.mode,n.state),o=Ye(e,t,n);i&&(n.state=i),t.stateAfter=n.save(!i),t.styles=o.styles,o.classes?t.styleClasses=o.classes:t.styleClasses&&(t.styleClasses=null),r===e.doc.highlightFrontier&&(e.doc.modeFrontier=Math.max(e.doc.modeFrontier,++e.doc.highlightFrontier))}return t.styles}function $e(e,t,r){var n=e.doc,i=e.display;if(!n.mode.startState)return new us(n,!0,t);var o=rt(e,t,r),l=o>n.first&&M(n,o-1).stateAfter,s=l?us.fromSaved(n,l,o):new us(n,Xe(n.mode),o);return n.iter(o,t,function(r){qe(e,r.text,s);var n=s.line;r.stateAfter=n==t-1||n%5==0||n>=i.viewFrom&&n<i.viewTo?s.save():null,s.nextLine()}),r&&(n.modeFrontier=s.line),s}function qe(e,t,r,n){var i=e.doc.mode,o=new ss(t,e.options.tabSize,r);for(o.start=o.pos=n||0,""==t&&Ze(i,r.state);!o.eol();)Qe(i,o,r.state),o.start=o.pos}function Ze(e,t){if(e.blankLine)return e.blankLine(t);if(e.innerMode){var r=je(e,t);return r.mode.blankLine?r.mode.blankLine(r.state):void 0}}function Qe(e,t,r,n){for(var i=0;i<10;i++){n&&(n[0]=je(e,r).mode);var o=e.token(t,r);if(t.pos>t.start)return o}throw new Error("Mode "+e.name+" failed to advance stream.")}function Je(e,t,r,n){var i,o,l=e.doc,s=l.mode,a=M(l,(t=U(l,t)).line),u=$e(e,t.line,r),c=new ss(a.text,e.options.tabSize,u);for(n&&(o=[]);(n||c.pos<t.ch)&&!c.eol();)c.start=c.pos,i=Qe(s,c,u.state),n&&o.push(new cs(c,i,Ke(l.mode,u.state)));return n?o:new cs(c,i,u.state)}function et(e,t){if(e)for(;;){var r=e.match(/(?:^|\s+)line-(background-)?(\S+)/);if(!r)break;e=e.slice(0,r.index)+e.slice(r.index+r[0].length);var n=r[1]?"bgClass":"textClass";null==t[n]?t[n]=r[2]:new RegExp("(?:^|s)"+r[2]+"(?:$|s)").test(t[n])||(t[n]+=" "+r[2])}return e}function tt(e,t,r,n,i,o,l){var s=r.flattenSpans;null==s&&(s=e.options.flattenSpans);var a,u=0,c=null,f=new ss(t,e.options.tabSize,n),h=e.options.addModeClass&&[null];for(""==t&&et(Ze(r,n.state),o);!f.eol();){if(f.pos>e.options.maxHighlightLength?(s=!1,l&&qe(e,t,n,f.pos),f.pos=t.length,a=null):a=et(Qe(r,f,n.state,h),o),h){var d=h[0].name;d&&(a="m-"+(a?d+" "+a:d))}if(!s||c!=a){for(;u<f.start;)i(u=Math.min(f.start,u+5e3),c);c=a}f.start=f.pos}for(;u<f.pos;){var p=Math.min(f.pos,u+5e3);i(p,c),u=p}}function rt(e,t,r){for(var n,i,o=e.doc,l=r?-1:t-(e.doc.mode.innerMode?1e3:100),s=t;s>l;--s){if(s<=o.first)return o.first;var a=M(o,s-1),u=a.stateAfter;if(u&&(!r||s+(u instanceof as?u.lookAhead:0)<=o.modeFrontier))return s;var c=f(a.text,null,e.options.tabSize);(null==i||n>c)&&(i=s-1,n=c)}return i}function nt(e,t){if(e.modeFrontier=Math.min(e.modeFrontier,t),!(e.highlightFrontier<t-10)){for(var r=e.first,n=t-1;n>r;n--){var i=M(e,n).stateAfter;if(i&&(!(i instanceof as)||n+i.lookAhead<t)){r=n+1;break}}e.highlightFrontier=Math.min(e.highlightFrontier,r)}}function it(e,t,r,n){e.text=t,e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null),null!=e.order&&(e.order=null),re(e),ne(e,r);var i=n?n(e):1;i!=e.height&&A(e,i)}function ot(e){e.parent=null,re(e)}function lt(e,t){if(!e||/^\s*$/.test(e))return null;var r=t.addModeClass?ps:ds;return r[e]||(r[e]=e.replace(/\S+/g,"cm-$&"))}function st(e,t){var r=i("span",null,null,ml?"padding-right: .1px":null),n={pre:i("pre",[r],"CodeMirror-line"),content:r,col:0,pos:0,cm:e,trailingSpace:!1,splitSpaces:(gl||ml)&&e.getOption("lineWrapping")};t.measure={};for(var o=0;o<=(t.rest?t.rest.length:0);o++){var l=o?t.rest[o-1]:t.line,s=void 0;n.pos=0,n.addToken=ut,ze(e.display.measure)&&(s=Se(l,e.doc.direction))&&(n.addToken=ft(n.addToken,s)),n.map=[],dt(l,n,_e(e,l,t!=e.display.externalMeasured&&W(l))),l.styleClasses&&(l.styleClasses.bgClass&&(n.bgClass=a(l.styleClasses.bgClass,n.bgClass||"")),l.styleClasses.textClass&&(n.textClass=a(l.styleClasses.textClass,n.textClass||""))),0==n.map.length&&n.map.push(0,0,n.content.appendChild(Ie(e.display.measure))),0==o?(t.measure.map=n.map,t.measure.cache={}):((t.measure.maps||(t.measure.maps=[])).push(n.map),(t.measure.caches||(t.measure.caches=[])).push({}))}if(ml){var u=n.content.lastChild;(/\bcm-tab\b/.test(u.className)||u.querySelector&&u.querySelector(".cm-tab"))&&(n.content.className="cm-tab-wrap-hack")}return Te(e,"renderLine",e,t.line,n.pre),n.pre.className&&(n.textClass=a(n.pre.className,n.textClass||"")),n}function at(e){var t=n("span","•","cm-invalidchar");return t.title="\\u"+e.charCodeAt(0).toString(16),t.setAttribute("aria-label",t.title),t}function ut(e,t,r,i,o,l,s){if(t){var a,u=e.splitSpaces?ct(t,e.trailingSpace):t,c=e.cm.state.specialChars,f=!1;if(c.test(t)){a=document.createDocumentFragment();for(var h=0;;){c.lastIndex=h;var d=c.exec(t),g=d?d.index-h:t.length-h;if(g){var v=document.createTextNode(u.slice(h,h+g));gl&&vl<9?a.appendChild(n("span",[v])):a.appendChild(v),e.map.push(e.pos,e.pos+g,v),e.col+=g,e.pos+=g}if(!d)break;h+=g+1;var m=void 0;if("\t"==d[0]){var y=e.cm.options.tabSize,b=y-e.col%y;(m=a.appendChild(n("span",p(b),"cm-tab"))).setAttribute("role","presentation"),m.setAttribute("cm-text","\t"),e.col+=b}else"\r"==d[0]||"\n"==d[0]?((m=a.appendChild(n("span","\r"==d[0]?"␍":"␤","cm-invalidchar"))).setAttribute("cm-text",d[0]),e.col+=1):((m=e.cm.options.specialCharPlaceholder(d[0])).setAttribute("cm-text",d[0]),gl&&vl<9?a.appendChild(n("span",[m])):a.appendChild(m),e.col+=1);e.map.push(e.pos,e.pos+1,m),e.pos++}}else e.col+=t.length,a=document.createTextNode(u),e.map.push(e.pos,e.pos+t.length,a),gl&&vl<9&&(f=!0),e.pos+=t.length;if(e.trailingSpace=32==u.charCodeAt(t.length-1),r||i||o||f||s){var w=r||"";i&&(w+=i),o&&(w+=o);var x=n("span",[a],w,s);return l&&(x.title=l),e.content.appendChild(x)}e.content.appendChild(a)}}function ct(e,t){if(e.length>1&&!/  /.test(e))return e;for(var r=t,n="",i=0;i<e.length;i++){var o=e.charAt(i);" "!=o||!r||i!=e.length-1&&32!=e.charCodeAt(i+1)||(o=" "),n+=o,r=" "==o}return n}function ft(e,t){return function(r,n,i,o,l,s,a){i=i?i+" cm-force-border":"cm-force-border";for(var u=r.pos,c=u+n.length;;){for(var f=void 0,h=0;h<t.length&&!((f=t[h]).to>u&&f.from<=u);h++);if(f.to>=c)return e(r,n,i,o,l,s,a);e(r,n.slice(0,f.to-u),i,o,null,s,a),o=null,n=n.slice(f.to-u),u=f.to}}}function ht(e,t,r,n){var i=!n&&r.widgetNode;i&&e.map.push(e.pos,e.pos+t,i),!n&&e.cm.display.input.needsContentAttribute&&(i||(i=e.content.appendChild(document.createElement("span"))),i.setAttribute("cm-marker",r.id)),i&&(e.cm.display.input.setUneditable(i),e.content.appendChild(i)),e.pos+=t,e.trailingSpace=!1}function dt(e,t,r){var n=e.markedSpans,i=e.text,o=0;if(n)for(var l,s,a,u,c,f,h,d=i.length,p=0,g=1,v="",m=0;;){if(m==p){a=u=c=f=s="",h=null,m=1/0;for(var y=[],b=void 0,w=0;w<n.length;++w){var x=n[w],C=x.marker;"bookmark"==C.type&&x.from==p&&C.widgetNode?y.push(C):x.from<=p&&(null==x.to||x.to>p||C.collapsed&&x.to==p&&x.from==p)?(null!=x.to&&x.to!=p&&m>x.to&&(m=x.to,u=""),C.className&&(a+=" "+C.className),C.css&&(s=(s?s+";":"")+C.css),C.startStyle&&x.from==p&&(c+=" "+C.startStyle),C.endStyle&&x.to==m&&(b||(b=[])).push(C.endStyle,x.to),C.title&&!f&&(f=C.title),C.collapsed&&(!h||le(h.marker,C)<0)&&(h=x)):x.from>p&&m>x.from&&(m=x.from)}if(b)for(var S=0;S<b.length;S+=2)b[S+1]==m&&(u+=" "+b[S]);if(!h||h.from==p)for(var L=0;L<y.length;++L)ht(t,0,y[L]);if(h&&(h.from||0)==p){if(ht(t,(null==h.to?d+1:h.to)-p,h.marker,null==h.from),null==h.to)return;h.to==p&&(h=!1)}}if(p>=d)break;for(var k=Math.min(d,m);;){if(v){var T=p+v.length;if(!h){var M=T>k?v.slice(0,k-p):v;t.addToken(t,M,l?l+a:a,c,p+M.length==m?u:"",f,s)}if(T>=k){v=v.slice(k-p),p=k;break}p=T,c=""}v=i.slice(o,o=r[g++]),l=lt(r[g++],t.cm.options)}}else for(var N=1;N<r.length;N+=2)t.addToken(t,i.slice(o,o=r[N]),lt(r[N+1],t.cm.options))}function pt(e,t,r){this.line=t,this.rest=de(t),this.size=this.rest?W(g(this.rest))-r+1:1,this.node=this.text=null,this.hidden=ve(e,t)}function gt(e,t,r){for(var n,i=[],o=t;o<r;o=n){var l=new pt(e.doc,M(e.doc,o),o);n=o+l.size,i.push(l)}return i}function vt(e){gs?gs.ops.push(e):e.ownsGroup=gs={ops:[e],delayedCallbacks:[]}}function mt(e){var t=e.delayedCallbacks,r=0;do{for(;r<t.length;r++)t[r].call(null);for(var n=0;n<e.ops.length;n++){var i=e.ops[n];if(i.cursorActivityHandlers)for(;i.cursorActivityCalled<i.cursorActivityHandlers.length;)i.cursorActivityHandlers[i.cursorActivityCalled++].call(null,i.cm)}}while(r<t.length)}function yt(e,t){var r=e.ownsGroup;if(r)try{mt(r)}finally{gs=null,t(r)}}function bt(e,t){var r=Le(e,t);if(r.length){var n,i=Array.prototype.slice.call(arguments,2);gs?n=gs.delayedCallbacks:vs?n=vs:(n=vs=[],setTimeout(wt,0));for(var o=0;o<r.length;++o)!function(e){n.push(function(){return r[e].apply(null,i)})}(o)}}function wt(){var e=vs;vs=null;for(var t=0;t<e.length;++t)e[t]()}function xt(e,t,r,n){for(var i=0;i<t.changes.length;i++){var o=t.changes[i];"text"==o?kt(e,t):"gutter"==o?Mt(e,t,r,n):"class"==o?Tt(e,t):"widget"==o&&Nt(e,t,n)}t.changes=null}function Ct(e){return e.node==e.text&&(e.node=n("div",null,null,"position: relative"),e.text.parentNode&&e.text.parentNode.replaceChild(e.node,e.text),e.node.appendChild(e.text),gl&&vl<8&&(e.node.style.zIndex=2)),e.node}function St(e,t){var r=t.bgClass?t.bgClass+" "+(t.line.bgClass||""):t.line.bgClass;if(r&&(r+=" CodeMirror-linebackground"),t.background)r?t.background.className=r:(t.background.parentNode.removeChild(t.background),t.background=null);else if(r){var i=Ct(t);t.background=i.insertBefore(n("div",null,r),i.firstChild),e.display.input.setUneditable(t.background)}}function Lt(e,t){var r=e.display.externalMeasured;return r&&r.line==t.line?(e.display.externalMeasured=null,t.measure=r.measure,r.built):st(e,t)}function kt(e,t){var r=t.text.className,n=Lt(e,t);t.text==t.node&&(t.node=n.pre),t.text.parentNode.replaceChild(n.pre,t.text),t.text=n.pre,n.bgClass!=t.bgClass||n.textClass!=t.textClass?(t.bgClass=n.bgClass,t.textClass=n.textClass,Tt(e,t)):r&&(t.text.className=r)}function Tt(e,t){St(e,t),t.line.wrapClass?Ct(t).className=t.line.wrapClass:t.node!=t.text&&(t.node.className="");var r=t.textClass?t.textClass+" "+(t.line.textClass||""):t.line.textClass;t.text.className=r||""}function Mt(e,t,r,i){if(t.gutter&&(t.node.removeChild(t.gutter),t.gutter=null),t.gutterBackground&&(t.node.removeChild(t.gutterBackground),t.gutterBackground=null),t.line.gutterClass){var o=Ct(t);t.gutterBackground=n("div",null,"CodeMirror-gutter-background "+t.line.gutterClass,"left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px; width: "+i.gutterTotalWidth+"px"),e.display.input.setUneditable(t.gutterBackground),o.insertBefore(t.gutterBackground,t.text)}var l=t.line.gutterMarkers;if(e.options.lineNumbers||l){var s=Ct(t),a=t.gutter=n("div",null,"CodeMirror-gutter-wrapper","left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px");if(e.display.input.setUneditable(a),s.insertBefore(a,t.text),t.line.gutterClass&&(a.className+=" "+t.line.gutterClass),!e.options.lineNumbers||l&&l["CodeMirror-linenumbers"]||(t.lineNumber=a.appendChild(n("div",F(e.options,r),"CodeMirror-linenumber CodeMirror-gutter-elt","left: "+i.gutterLeft["CodeMirror-linenumbers"]+"px; width: "+e.display.lineNumInnerWidth+"px"))),l)for(var u=0;u<e.options.gutters.length;++u){var c=e.options.gutters[u],f=l.hasOwnProperty(c)&&l[c];f&&a.appendChild(n("div",[f],"CodeMirror-gutter-elt","left: "+i.gutterLeft[c]+"px; width: "+i.gutterWidth[c]+"px"))}}}function Nt(e,t,r){t.alignable&&(t.alignable=null);for(var n=t.node.firstChild,i=void 0;n;n=i)i=n.nextSibling,"CodeMirror-linewidget"==n.className&&t.node.removeChild(n);At(e,t,r)}function Ot(e,t,r,n){var i=Lt(e,t);return t.text=t.node=i.pre,i.bgClass&&(t.bgClass=i.bgClass),i.textClass&&(t.textClass=i.textClass),Tt(e,t),Mt(e,t,r,n),At(e,t,n),t.node}function At(e,t,r){if(Wt(e,t.line,t,r,!0),t.rest)for(var n=0;n<t.rest.length;n++)Wt(e,t.rest[n],t,r,!1)}function Wt(e,t,r,i,o){if(t.widgets)for(var l=Ct(r),s=0,a=t.widgets;s<a.length;++s){var u=a[s],c=n("div",[u.node],"CodeMirror-linewidget");u.handleMouseEvents||c.setAttribute("cm-ignore-events","true"),Dt(u,c,r,i),e.display.input.setUneditable(c),o&&u.above?l.insertBefore(c,r.gutter||r.text):l.appendChild(c),bt(u,"redraw")}}function Dt(e,t,r,n){if(e.noHScroll){(r.alignable||(r.alignable=[])).push(t);var i=n.wrapperWidth;t.style.left=n.fixedPos+"px",e.coverGutter||(i-=n.gutterTotalWidth,t.style.paddingLeft=n.gutterTotalWidth+"px"),t.style.width=i+"px"}e.coverGutter&&(t.style.zIndex=5,t.style.position="relative",e.noHScroll||(t.style.marginLeft=-n.gutterTotalWidth+"px"))}function Ht(e){if(null!=e.height)return e.height;var t=e.doc.cm;if(!t)return 0;if(!o(document.body,e.node)){var i="position: relative;";e.coverGutter&&(i+="margin-left: -"+t.display.gutters.offsetWidth+"px;"),e.noHScroll&&(i+="width: "+t.display.wrapper.clientWidth+"px;"),r(t.display.measure,n("div",[e.node],null,i))}return e.height=e.node.parentNode.offsetHeight}function Ft(e,t){for(var r=Ee(t);r!=e.wrapper;r=r.parentNode)if(!r||1==r.nodeType&&"true"==r.getAttribute("cm-ignore-events")||r.parentNode==e.sizer&&r!=e.mover)return!0}function Et(e){return e.lineSpace.offsetTop}function Pt(e){return e.mover.offsetHeight-e.lineSpace.offsetHeight}function It(e){if(e.cachedPaddingH)return e.cachedPaddingH;var t=r(e.measure,n("pre","x")),i=window.getComputedStyle?window.getComputedStyle(t):t.currentStyle,o={left:parseInt(i.paddingLeft),right:parseInt(i.paddingRight)};return isNaN(o.left)||isNaN(o.right)||(e.cachedPaddingH=o),o}function zt(e){return Rl-e.display.nativeBarWidth}function Rt(e){return e.display.scroller.clientWidth-zt(e)-e.display.barWidth}function Bt(e){return e.display.scroller.clientHeight-zt(e)-e.display.barHeight}function Gt(e,t,r){var n=e.options.lineWrapping,i=n&&Rt(e);if(!t.measure.heights||n&&t.measure.width!=i){var o=t.measure.heights=[];if(n){t.measure.width=i;for(var l=t.text.firstChild.getClientRects(),s=0;s<l.length-1;s++){var a=l[s],u=l[s+1];Math.abs(a.bottom-u.bottom)>2&&o.push((a.bottom+u.top)/2-r.top)}}o.push(r.bottom-r.top)}}function Ut(e,t,r){if(e.line==t)return{map:e.measure.map,cache:e.measure.cache};for(var n=0;n<e.rest.length;n++)if(e.rest[n]==t)return{map:e.measure.maps[n],cache:e.measure.caches[n]};for(var i=0;i<e.rest.length;i++)if(W(e.rest[i])>r)return{map:e.measure.maps[i],cache:e.measure.caches[i],before:!0}}function Vt(e,t){var n=W(t=fe(t)),i=e.display.externalMeasured=new pt(e.doc,t,n);i.lineN=n;var o=i.built=st(e,i);return i.text=o.pre,r(e.display.lineMeasure,o.pre),i}function Kt(e,t,r,n){return Yt(e,Xt(e,t),r,n)}function jt(e,t){if(t>=e.display.viewFrom&&t<e.display.viewTo)return e.display.view[Lr(e,t)];var r=e.display.externalMeasured;return r&&t>=r.lineN&&t<r.lineN+r.size?r:void 0}function Xt(e,t){var r=W(t),n=jt(e,r);n&&!n.text?n=null:n&&n.changes&&(xt(e,n,r,br(e)),e.curOp.forceUpdate=!0),n||(n=Vt(e,t));var i=Ut(n,t,r);return{line:t,view:n,rect:null,map:i.map,cache:i.cache,before:i.before,hasHeights:!1}}function Yt(e,t,r,n,i){t.before&&(r=-1);var o,l=r+(n||"");return t.cache.hasOwnProperty(l)?o=t.cache[l]:(t.rect||(t.rect=t.view.text.getBoundingClientRect()),t.hasHeights||(Gt(e,t.view,t.rect),t.hasHeights=!0),(o=qt(e,t,r,n)).bogus||(t.cache[l]=o)),{left:o.left,right:o.right,top:i?o.rtop:o.top,bottom:i?o.rbottom:o.bottom}}function _t(e,t,r){for(var n,i,o,l,s,a,u=0;u<e.length;u+=3)if(s=e[u],a=e[u+1],t<s?(i=0,o=1,l="left"):t<a?o=(i=t-s)+1:(u==e.length-3||t==a&&e[u+3]>t)&&(i=(o=a-s)-1,t>=a&&(l="right")),null!=i){if(n=e[u+2],s==a&&r==(n.insertLeft?"left":"right")&&(l=r),"left"==r&&0==i)for(;u&&e[u-2]==e[u-3]&&e[u-1].insertLeft;)n=e[2+(u-=3)],l="left";if("right"==r&&i==a-s)for(;u<e.length-3&&e[u+3]==e[u+4]&&!e[u+5].insertLeft;)n=e[(u+=3)+2],l="right";break}return{node:n,start:i,end:o,collapse:l,coverStart:s,coverEnd:a}}function $t(e,t){var r=ms;if("left"==t)for(var n=0;n<e.length&&(r=e[n]).left==r.right;n++);else for(var i=e.length-1;i>=0&&(r=e[i]).left==r.right;i--);return r}function qt(e,t,r,n){var i,o=_t(t.map,r,n),l=o.node,s=o.start,a=o.end,u=o.collapse;if(3==l.nodeType){for(var c=0;c<4;c++){for(;s&&S(t.line.text.charAt(o.coverStart+s));)--s;for(;o.coverStart+a<o.coverEnd&&S(t.line.text.charAt(o.coverStart+a));)++a;if((i=gl&&vl<9&&0==s&&a==o.coverEnd-o.coverStart?l.parentNode.getBoundingClientRect():$t(Wl(l,s,a).getClientRects(),n)).left||i.right||0==s)break;a=s,s-=1,u="right"}gl&&vl<11&&(i=Zt(e.display.measure,i))}else{s>0&&(u=n="right");var f;i=e.options.lineWrapping&&(f=l.getClientRects()).length>1?f["right"==n?f.length-1:0]:l.getBoundingClientRect()}if(gl&&vl<9&&!s&&(!i||!i.left&&!i.right)){var h=l.parentNode.getClientRects()[0];i=h?{left:h.left,right:h.left+yr(e.display),top:h.top,bottom:h.bottom}:ms}for(var d=i.top-t.rect.top,p=i.bottom-t.rect.top,g=(d+p)/2,v=t.view.measure.heights,m=0;m<v.length-1&&!(g<v[m]);m++);var y=m?v[m-1]:0,b=v[m],w={left:("right"==u?i.right:i.left)-t.rect.left,right:("left"==u?i.left:i.right)-t.rect.left,top:y,bottom:b};return i.left||i.right||(w.bogus=!0),e.options.singleCursorHeightPerLine||(w.rtop=d,w.rbottom=p),w}function Zt(e,t){if(!window.screen||null==screen.logicalXDPI||screen.logicalXDPI==screen.deviceXDPI||!Re(e))return t;var r=screen.logicalXDPI/screen.deviceXDPI,n=screen.logicalYDPI/screen.deviceYDPI;return{left:t.left*r,right:t.right*r,top:t.top*n,bottom:t.bottom*n}}function Qt(e){if(e.measure&&(e.measure.cache={},e.measure.heights=null,e.rest))for(var t=0;t<e.rest.length;t++)e.measure.caches[t]={}}function Jt(e){e.display.externalMeasure=null,t(e.display.lineMeasure);for(var r=0;r<e.display.view.length;r++)Qt(e.display.view[r])}function er(e){Jt(e),e.display.cachedCharWidth=e.display.cachedTextHeight=e.display.cachedPaddingH=null,e.options.lineWrapping||(e.display.maxLineChanged=!0),e.display.lineNumChars=null}function tr(){return bl&&kl?-(document.body.getBoundingClientRect().left-parseInt(getComputedStyle(document.body).marginLeft)):window.pageXOffset||(document.documentElement||document.body).scrollLeft}function rr(){return bl&&kl?-(document.body.getBoundingClientRect().top-parseInt(getComputedStyle(document.body).marginTop)):window.pageYOffset||(document.documentElement||document.body).scrollTop}function nr(e){var t=0;if(e.widgets)for(var r=0;r<e.widgets.length;++r)e.widgets[r].above&&(t+=Ht(e.widgets[r]));return t}function ir(e,t,r,n,i){if(!i){var o=nr(t);r.top+=o,r.bottom+=o}if("line"==n)return r;n||(n="local");var l=ye(t);if("local"==n?l+=Et(e.display):l-=e.display.viewOffset,"page"==n||"window"==n){var s=e.display.lineSpace.getBoundingClientRect();l+=s.top+("window"==n?0:rr());var a=s.left+("window"==n?0:tr());r.left+=a,r.right+=a}return r.top+=l,r.bottom+=l,r}function or(e,t,r){if("div"==r)return t;var n=t.left,i=t.top;if("page"==r)n-=tr(),i-=rr();else if("local"==r||!r){var o=e.display.sizer.getBoundingClientRect();n+=o.left,i+=o.top}var l=e.display.lineSpace.getBoundingClientRect();return{left:n-l.left,top:i-l.top}}function lr(e,t,r,n,i){return n||(n=M(e.doc,t.line)),ir(e,n,Kt(e,n,t.ch,i),r)}function sr(e,t,r,n,i,o){function l(t,l){var s=Yt(e,i,t,l?"right":"left",o);return l?s.left=s.right:s.right=s.left,ir(e,n,s,r)}function s(e,t,r){var n=1==a[t].level;return l(r?e-1:e,n!=r)}n=n||M(e.doc,t.line),i||(i=Xt(e,n));var a=Se(n,e.doc.direction),u=t.ch,c=t.sticky;if(u>=n.text.length?(u=n.text.length,c="before"):u<=0&&(u=0,c="after"),!a)return l("before"==c?u-1:u,"before"==c);var f=Ce(a,u,c),h=$l,d=s(u,f,"before"==c);return null!=h&&(d.other=s(u,h,"before"!=c)),d}function ar(e,t){var r=0;t=U(e.doc,t),e.options.lineWrapping||(r=yr(e.display)*t.ch);var n=M(e.doc,t.line),i=ye(n)+Et(e.display);return{left:r,right:r,top:i,bottom:i+n.height}}function ur(e,t,r,n,i){var o=E(e,t,r);return o.xRel=i,n&&(o.outside=!0),o}function cr(e,t,r){var n=e.doc;if((r+=e.display.viewOffset)<0)return ur(n.first,0,null,!0,-1);var i=D(n,r),o=n.first+n.size-1;if(i>o)return ur(n.first+n.size-1,M(n,o).text.length,null,!0,1);t<0&&(t=0);for(var l=M(n,i);;){var s=pr(e,l,i,t,r),a=ue(l),u=a&&a.find(0,!0);if(!a||!(s.ch>u.from.ch||s.ch==u.from.ch&&s.xRel>0))return s;i=W(l=u.to.line)}}function fr(e,t,r,n){n-=nr(t);var i=t.text.length,o=k(function(t){return Yt(e,r,t-1).bottom<=n},i,0);return i=k(function(t){return Yt(e,r,t).top>n},o,i),{begin:o,end:i}}function hr(e,t,r,n){return r||(r=Xt(e,t)),fr(e,t,r,ir(e,t,Yt(e,r,n),"line").top)}function dr(e,t,r,n){return!(e.bottom<=r)&&(e.top>r||(n?e.left:e.right)>t)}function pr(e,t,r,n,i){i-=ye(t);var o=Xt(e,t),l=nr(t),s=0,a=t.text.length,u=!0,c=Se(t,e.doc.direction);if(c){var f=(e.options.lineWrapping?vr:gr)(e,t,r,o,c,n,i);s=(u=1!=f.level)?f.from:f.to-1,a=u?f.to:f.from-1}var h,d,p=null,g=null,v=k(function(t){var r=Yt(e,o,t);return r.top+=l,r.bottom+=l,!!dr(r,n,i,!1)&&(r.top<=i&&r.left<=n&&(p=t,g=r),!0)},s,a),m=!1;if(g){var y=n-g.left<g.right-n,b=y==u;v=p+(b?0:1),d=b?"after":"before",h=y?g.left:g.right}else{u||v!=a&&v!=s||v++,d=0==v?"after":v==t.text.length?"before":Yt(e,o,v-(u?1:0)).bottom+l<=i==u?"after":"before";var w=sr(e,E(r,v,d),"line",t,o);h=w.left,m=i<w.top||i>=w.bottom}return v=L(t.text,v,1),ur(r,v,d,m,n-h)}function gr(e,t,r,n,i,o,l){var s=k(function(s){var a=i[s],u=1!=a.level;return dr(sr(e,E(r,u?a.to:a.from,u?"before":"after"),"line",t,n),o,l,!0)},0,i.length-1),a=i[s];if(s>0){var u=1!=a.level,c=sr(e,E(r,u?a.from:a.to,u?"after":"before"),"line",t,n);dr(c,o,l,!0)&&c.top>l&&(a=i[s-1])}return a}function vr(e,t,r,n,i,o,l){for(var s=fr(e,t,n,l),a=s.begin,u=s.end,c=null,f=null,h=0;h<i.length;h++){var d=i[h];if(!(d.from>=u||d.to<=a)){var p=Yt(e,n,1!=d.level?Math.min(u,d.to)-1:Math.max(a,d.from)).right,g=p<o?o-p+1e9:p-o;(!c||f>g)&&(c=d,f=g)}}return c||(c=i[i.length-1]),c.from<a&&(c={from:a,to:c.to,level:c.level}),c.to>u&&(c={from:c.from,to:u,level:c.level}),c}function mr(e){if(null!=e.cachedTextHeight)return e.cachedTextHeight;if(null==hs){hs=n("pre");for(var i=0;i<49;++i)hs.appendChild(document.createTextNode("x")),hs.appendChild(n("br"));hs.appendChild(document.createTextNode("x"))}r(e.measure,hs);var o=hs.offsetHeight/50;return o>3&&(e.cachedTextHeight=o),t(e.measure),o||1}function yr(e){if(null!=e.cachedCharWidth)return e.cachedCharWidth;var t=n("span","xxxxxxxxxx"),i=n("pre",[t]);r(e.measure,i);var o=t.getBoundingClientRect(),l=(o.right-o.left)/10;return l>2&&(e.cachedCharWidth=l),l||10}function br(e){for(var t=e.display,r={},n={},i=t.gutters.clientLeft,o=t.gutters.firstChild,l=0;o;o=o.nextSibling,++l)r[e.options.gutters[l]]=o.offsetLeft+o.clientLeft+i,n[e.options.gutters[l]]=o.clientWidth;return{fixedPos:wr(t),gutterTotalWidth:t.gutters.offsetWidth,gutterLeft:r,gutterWidth:n,wrapperWidth:t.wrapper.clientWidth}}function wr(e){return e.scroller.getBoundingClientRect().left-e.sizer.getBoundingClientRect().left}function xr(e){var t=mr(e.display),r=e.options.lineWrapping,n=r&&Math.max(5,e.display.scroller.clientWidth/yr(e.display)-3);return function(i){if(ve(e.doc,i))return 0;var o=0;if(i.widgets)for(var l=0;l<i.widgets.length;l++)i.widgets[l].height&&(o+=i.widgets[l].height);return r?o+(Math.ceil(i.text.length/n)||1)*t:o+t}}function Cr(e){var t=e.doc,r=xr(e);t.iter(function(e){var t=r(e);t!=e.height&&A(e,t)})}function Sr(e,t,r,n){var i=e.display;if(!r&&"true"==Ee(t).getAttribute("cm-not-content"))return null;var o,l,s=i.lineSpace.getBoundingClientRect();try{o=t.clientX-s.left,l=t.clientY-s.top}catch(t){return null}var a,u=cr(e,o,l);if(n&&1==u.xRel&&(a=M(e.doc,u.line).text).length==u.ch){var c=f(a,a.length,e.options.tabSize)-a.length;u=E(u.line,Math.max(0,Math.round((o-It(e.display).left)/yr(e.display))-c))}return u}function Lr(e,t){if(t>=e.display.viewTo)return null;if((t-=e.display.viewFrom)<0)return null;for(var r=e.display.view,n=0;n<r.length;n++)if((t-=r[n].size)<0)return n}function kr(e){e.display.input.showSelection(e.display.input.prepareSelection())}function Tr(e,t){void 0===t&&(t=!0);for(var r=e.doc,n={},i=n.cursors=document.createDocumentFragment(),o=n.selection=document.createDocumentFragment(),l=0;l<r.sel.ranges.length;l++)if(t||l!=r.sel.primIndex){var s=r.sel.ranges[l];if(!(s.from().line>=e.display.viewTo||s.to().line<e.display.viewFrom)){var a=s.empty();(a||e.options.showCursorWhenSelecting)&&Mr(e,s.head,i),a||Or(e,s,o)}}return n}function Mr(e,t,r){var i=sr(e,t,"div",null,null,!e.options.singleCursorHeightPerLine),o=r.appendChild(n("div"," ","CodeMirror-cursor"));if(o.style.left=i.left+"px",o.style.top=i.top+"px",o.style.height=Math.max(0,i.bottom-i.top)*e.options.cursorHeight+"px",i.other){var l=r.appendChild(n("div"," ","CodeMirror-cursor CodeMirror-secondarycursor"));l.style.display="",l.style.left=i.other.left+"px",l.style.top=i.other.top+"px",l.style.height=.85*(i.other.bottom-i.other.top)+"px"}}function Nr(e,t){return e.top-t.top||e.left-t.left}function Or(e,t,r){function i(e,t,r,i){t<0&&(t=0),t=Math.round(t),i=Math.round(i),a.appendChild(n("div",null,"CodeMirror-selected","position: absolute; left: "+e+"px;\n                             top: "+t+"px; width: "+(null==r?f-e:r)+"px;\n                             height: "+(i-t)+"px"))}function o(t,r,n){function o(r,n){return lr(e,E(t,r),"div",u,n)}var l,a,u=M(s,t),h=u.text.length,d=Se(u,s.direction);return xe(d,r||0,null==n?h:n,function(t,s,p,g){var v=o(t,"ltr"==p?"left":"right"),m=o(s-1,"ltr"==p?"right":"left");if("ltr"==p){var y=null==r&&0==t?c:v.left,b=null==n&&s==h?f:m.right;m.top-v.top<=3?i(y,m.top,b-y,m.bottom):(i(y,v.top,null,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top),i(c,m.top,m.right,m.bottom))}else if(t<s){var w=null==r&&0==t?f:v.right,x=null==n&&s==h?c:m.left;if(m.top-v.top<=3)i(x,m.top,w-x,m.bottom);else{var C=c;if(g){var S=hr(e,u,null,t).end;C=o(S-(/\s/.test(u.text.charAt(S-1))?2:1),"left").left}i(C,v.top,w-C,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top);var L=null;d.length,L=o(hr(e,u,null,s).begin,"right").right-x,i(x,m.top,L,m.bottom)}}(!l||Nr(v,l)<0)&&(l=v),Nr(m,l)<0&&(l=m),(!a||Nr(v,a)<0)&&(a=v),Nr(m,a)<0&&(a=m)}),{start:l,end:a}}var l=e.display,s=e.doc,a=document.createDocumentFragment(),u=It(e.display),c=u.left,f=Math.max(l.sizerWidth,Rt(e)-l.sizer.offsetLeft)-u.right,h=t.from(),d=t.to();if(h.line==d.line)o(h.line,h.ch,d.ch);else{var p=M(s,h.line),g=M(s,d.line),v=fe(p)==fe(g),m=o(h.line,h.ch,v?p.text.length+1:null).end,y=o(d.line,v?0:null,d.ch).start;v&&(m.top<y.top-2?(i(m.right,m.top,null,m.bottom),i(c,y.top,y.left,y.bottom)):i(m.right,m.top,y.left-m.right,m.bottom)),m.bottom<y.top&&i(c,m.bottom,null,y.top)}r.appendChild(a)}function Ar(e){if(e.state.focused){var t=e.display;clearInterval(t.blinker);var r=!0;t.cursorDiv.style.visibility="",e.options.cursorBlinkRate>0?t.blinker=setInterval(function(){return t.cursorDiv.style.visibility=(r=!r)?"":"hidden"},e.options.cursorBlinkRate):e.options.cursorBlinkRate<0&&(t.cursorDiv.style.visibility="hidden")}}function Wr(e){e.state.focused||(e.display.input.focus(),Hr(e))}function Dr(e){e.state.delayingBlurEvent=!0,setTimeout(function(){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1,Fr(e))},100)}function Hr(e,t){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1),"nocursor"!=e.options.readOnly&&(e.state.focused||(Te(e,"focus",e,t),e.state.focused=!0,s(e.display.wrapper,"CodeMirror-focused"),e.curOp||e.display.selForContextMenu==e.doc.sel||(e.display.input.reset(),ml&&setTimeout(function(){return e.display.input.reset(!0)},20)),e.display.input.receivedFocus()),Ar(e))}function Fr(e,t){e.state.delayingBlurEvent||(e.state.focused&&(Te(e,"blur",e,t),e.state.focused=!1,Fl(e.display.wrapper,"CodeMirror-focused")),clearInterval(e.display.blinker),setTimeout(function(){e.state.focused||(e.display.shift=!1)},150))}function Er(e){for(var t=e.display,r=t.lineDiv.offsetTop,n=0;n<t.view.length;n++){var i=t.view[n],o=void 0;if(!i.hidden){if(gl&&vl<8){var l=i.node.offsetTop+i.node.offsetHeight;o=l-r,r=l}else{var s=i.node.getBoundingClientRect();o=s.bottom-s.top}var a=i.line.height-o;if(o<2&&(o=mr(t)),(a>.005||a<-.005)&&(A(i.line,o),Pr(i.line),i.rest))for(var u=0;u<i.rest.length;u++)Pr(i.rest[u])}}}function Pr(e){if(e.widgets)for(var t=0;t<e.widgets.length;++t)e.widgets[t].height=e.widgets[t].node.parentNode.offsetHeight}function Ir(e,t,r){var n=r&&null!=r.top?Math.max(0,r.top):e.scroller.scrollTop;n=Math.floor(n-Et(e));var i=r&&null!=r.bottom?r.bottom:n+e.wrapper.clientHeight,o=D(t,n),l=D(t,i);if(r&&r.ensure){var s=r.ensure.from.line,a=r.ensure.to.line;s<o?(o=s,l=D(t,ye(M(t,s))+e.wrapper.clientHeight)):Math.min(a,t.lastLine())>=l&&(o=D(t,ye(M(t,a))-e.wrapper.clientHeight),l=a)}return{from:o,to:Math.max(l,o+1)}}function zr(e){var t=e.display,r=t.view;if(t.alignWidgets||t.gutters.firstChild&&e.options.fixedGutter){for(var n=wr(t)-t.scroller.scrollLeft+e.doc.scrollLeft,i=t.gutters.offsetWidth,o=n+"px",l=0;l<r.length;l++)if(!r[l].hidden){e.options.fixedGutter&&(r[l].gutter&&(r[l].gutter.style.left=o),r[l].gutterBackground&&(r[l].gutterBackground.style.left=o));var s=r[l].alignable;if(s)for(var a=0;a<s.length;a++)s[a].style.left=o}e.options.fixedGutter&&(t.gutters.style.left=n+i+"px")}}function Rr(e){if(!e.options.lineNumbers)return!1;var t=e.doc,r=F(e.options,t.first+t.size-1),i=e.display;if(r.length!=i.lineNumChars){var o=i.measure.appendChild(n("div",[n("div",r)],"CodeMirror-linenumber CodeMirror-gutter-elt")),l=o.firstChild.offsetWidth,s=o.offsetWidth-l;return i.lineGutter.style.width="",i.lineNumInnerWidth=Math.max(l,i.lineGutter.offsetWidth-s)+1,i.lineNumWidth=i.lineNumInnerWidth+s,i.lineNumChars=i.lineNumInnerWidth?r.length:-1,i.lineGutter.style.width=i.lineNumWidth+"px",Wn(e),!0}return!1}function Br(e,t){if(!Me(e,"scrollCursorIntoView")){var r=e.display,i=r.sizer.getBoundingClientRect(),o=null;if(t.top+i.top<0?o=!0:t.bottom+i.top>(window.innerHeight||document.documentElement.clientHeight)&&(o=!1),null!=o&&!Sl){var l=n("div","​",null,"position: absolute;\n                         top: "+(t.top-r.viewOffset-Et(e.display))+"px;\n                         height: "+(t.bottom-t.top+zt(e)+r.barHeight)+"px;\n                         left: "+t.left+"px; width: "+Math.max(2,t.right-t.left)+"px;");e.display.lineSpace.appendChild(l),l.scrollIntoView(o),e.display.lineSpace.removeChild(l)}}}function Gr(e,t,r,n){null==n&&(n=0);var i;e.options.lineWrapping||t!=r||(r="before"==(t=t.ch?E(t.line,"before"==t.sticky?t.ch-1:t.ch,"after"):t).sticky?E(t.line,t.ch+1,"before"):t);for(var o=0;o<5;o++){var l=!1,s=sr(e,t),a=r&&r!=t?sr(e,r):s,u=Vr(e,i={left:Math.min(s.left,a.left),top:Math.min(s.top,a.top)-n,right:Math.max(s.left,a.left),bottom:Math.max(s.bottom,a.bottom)+n}),c=e.doc.scrollTop,f=e.doc.scrollLeft;if(null!=u.scrollTop&&(qr(e,u.scrollTop),Math.abs(e.doc.scrollTop-c)>1&&(l=!0)),null!=u.scrollLeft&&(Qr(e,u.scrollLeft),Math.abs(e.doc.scrollLeft-f)>1&&(l=!0)),!l)break}return i}function Ur(e,t){var r=Vr(e,t);null!=r.scrollTop&&qr(e,r.scrollTop),null!=r.scrollLeft&&Qr(e,r.scrollLeft)}function Vr(e,t){var r=e.display,n=mr(e.display);t.top<0&&(t.top=0);var i=e.curOp&&null!=e.curOp.scrollTop?e.curOp.scrollTop:r.scroller.scrollTop,o=Bt(e),l={};t.bottom-t.top>o&&(t.bottom=t.top+o);var s=e.doc.height+Pt(r),a=t.top<n,u=t.bottom>s-n;if(t.top<i)l.scrollTop=a?0:t.top;else if(t.bottom>i+o){var c=Math.min(t.top,(u?s:t.bottom)-o);c!=i&&(l.scrollTop=c)}var f=e.curOp&&null!=e.curOp.scrollLeft?e.curOp.scrollLeft:r.scroller.scrollLeft,h=Rt(e)-(e.options.fixedGutter?r.gutters.offsetWidth:0),d=t.right-t.left>h;return d&&(t.right=t.left+h),t.left<10?l.scrollLeft=0:t.left<f?l.scrollLeft=Math.max(0,t.left-(d?0:10)):t.right>h+f-3&&(l.scrollLeft=t.right+(d?0:10)-h),l}function Kr(e,t){null!=t&&(_r(e),e.curOp.scrollTop=(null==e.curOp.scrollTop?e.doc.scrollTop:e.curOp.scrollTop)+t)}function jr(e){_r(e);var t=e.getCursor();e.curOp.scrollToPos={from:t,to:t,margin:e.options.cursorScrollMargin}}function Xr(e,t,r){null==t&&null==r||_r(e),null!=t&&(e.curOp.scrollLeft=t),null!=r&&(e.curOp.scrollTop=r)}function Yr(e,t){_r(e),e.curOp.scrollToPos=t}function _r(e){var t=e.curOp.scrollToPos;t&&(e.curOp.scrollToPos=null,$r(e,ar(e,t.from),ar(e,t.to),t.margin))}function $r(e,t,r,n){var i=Vr(e,{left:Math.min(t.left,r.left),top:Math.min(t.top,r.top)-n,right:Math.max(t.right,r.right),bottom:Math.max(t.bottom,r.bottom)+n});Xr(e,i.scrollLeft,i.scrollTop)}function qr(e,t){Math.abs(e.doc.scrollTop-t)<2||(fl||On(e,{top:t}),Zr(e,t,!0),fl&&On(e),Cn(e,100))}function Zr(e,t,r){t=Math.min(e.display.scroller.scrollHeight-e.display.scroller.clientHeight,t),(e.display.scroller.scrollTop!=t||r)&&(e.doc.scrollTop=t,e.display.scrollbars.setScrollTop(t),e.display.scroller.scrollTop!=t&&(e.display.scroller.scrollTop=t))}function Qr(e,t,r,n){t=Math.min(t,e.display.scroller.scrollWidth-e.display.scroller.clientWidth),(r?t==e.doc.scrollLeft:Math.abs(e.doc.scrollLeft-t)<2)&&!n||(e.doc.scrollLeft=t,zr(e),e.display.scroller.scrollLeft!=t&&(e.display.scroller.scrollLeft=t),e.display.scrollbars.setScrollLeft(t))}function Jr(e){var t=e.display,r=t.gutters.offsetWidth,n=Math.round(e.doc.height+Pt(e.display));return{clientHeight:t.scroller.clientHeight,viewHeight:t.wrapper.clientHeight,scrollWidth:t.scroller.scrollWidth,clientWidth:t.scroller.clientWidth,viewWidth:t.wrapper.clientWidth,barLeft:e.options.fixedGutter?r:0,docHeight:n,scrollHeight:n+zt(e)+t.barHeight,nativeBarWidth:t.nativeBarWidth,gutterWidth:r}}function en(e,t){t||(t=Jr(e));var r=e.display.barWidth,n=e.display.barHeight;tn(e,t);for(var i=0;i<4&&r!=e.display.barWidth||n!=e.display.barHeight;i++)r!=e.display.barWidth&&e.options.lineWrapping&&Er(e),tn(e,Jr(e)),r=e.display.barWidth,n=e.display.barHeight}function tn(e,t){var r=e.display,n=r.scrollbars.update(t);r.sizer.style.paddingRight=(r.barWidth=n.right)+"px",r.sizer.style.paddingBottom=(r.barHeight=n.bottom)+"px",r.heightForcer.style.borderBottom=n.bottom+"px solid transparent",n.right&&n.bottom?(r.scrollbarFiller.style.display="block",r.scrollbarFiller.style.height=n.bottom+"px",r.scrollbarFiller.style.width=n.right+"px"):r.scrollbarFiller.style.display="",n.bottom&&e.options.coverGutterNextToScrollbar&&e.options.fixedGutter?(r.gutterFiller.style.display="block",r.gutterFiller.style.height=n.bottom+"px",r.gutterFiller.style.width=t.gutterWidth+"px"):r.gutterFiller.style.display=""}function rn(e){e.display.scrollbars&&(e.display.scrollbars.clear(),e.display.scrollbars.addClass&&Fl(e.display.wrapper,e.display.scrollbars.addClass)),e.display.scrollbars=new ws[e.options.scrollbarStyle](function(t){e.display.wrapper.insertBefore(t,e.display.scrollbarFiller),Ql(t,"mousedown",function(){e.state.focused&&setTimeout(function(){return e.display.input.focus()},0)}),t.setAttribute("cm-not-content","true")},function(t,r){"horizontal"==r?Qr(e,t):qr(e,t)},e),e.display.scrollbars.addClass&&s(e.display.wrapper,e.display.scrollbars.addClass)}function nn(e){e.curOp={cm:e,viewChanged:!1,startHeight:e.doc.height,forceUpdate:!1,updateInput:null,typing:!1,changeObjs:null,cursorActivityHandlers:null,cursorActivityCalled:0,selectionChanged:!1,updateMaxLine:!1,scrollLeft:null,scrollTop:null,scrollToPos:null,focus:!1,id:++xs},vt(e.curOp)}function on(e){yt(e.curOp,function(e){for(var t=0;t<e.ops.length;t++)e.ops[t].cm.curOp=null;ln(e)})}function ln(e){for(var t=e.ops,r=0;r<t.length;r++)sn(t[r]);for(var n=0;n<t.length;n++)an(t[n]);for(var i=0;i<t.length;i++)un(t[i]);for(var o=0;o<t.length;o++)cn(t[o]);for(var l=0;l<t.length;l++)fn(t[l])}function sn(e){var t=e.cm,r=t.display;Ln(t),e.updateMaxLine&&we(t),e.mustUpdate=e.viewChanged||e.forceUpdate||null!=e.scrollTop||e.scrollToPos&&(e.scrollToPos.from.line<r.viewFrom||e.scrollToPos.to.line>=r.viewTo)||r.maxLineChanged&&t.options.lineWrapping,e.update=e.mustUpdate&&new Cs(t,e.mustUpdate&&{top:e.scrollTop,ensure:e.scrollToPos},e.forceUpdate)}function an(e){e.updatedDisplay=e.mustUpdate&&Mn(e.cm,e.update)}function un(e){var t=e.cm,r=t.display;e.updatedDisplay&&Er(t),e.barMeasure=Jr(t),r.maxLineChanged&&!t.options.lineWrapping&&(e.adjustWidthTo=Kt(t,r.maxLine,r.maxLine.text.length).left+3,t.display.sizerWidth=e.adjustWidthTo,e.barMeasure.scrollWidth=Math.max(r.scroller.clientWidth,r.sizer.offsetLeft+e.adjustWidthTo+zt(t)+t.display.barWidth),e.maxScrollLeft=Math.max(0,r.sizer.offsetLeft+e.adjustWidthTo-Rt(t))),(e.updatedDisplay||e.selectionChanged)&&(e.preparedSelection=r.input.prepareSelection())}function cn(e){var t=e.cm;null!=e.adjustWidthTo&&(t.display.sizer.style.minWidth=e.adjustWidthTo+"px",e.maxScrollLeft<t.doc.scrollLeft&&Qr(t,Math.min(t.display.scroller.scrollLeft,e.maxScrollLeft),!0),t.display.maxLineChanged=!1);var r=e.focus&&e.focus==l();e.preparedSelection&&t.display.input.showSelection(e.preparedSelection,r),(e.updatedDisplay||e.startHeight!=t.doc.height)&&en(t,e.barMeasure),e.updatedDisplay&&Dn(t,e.barMeasure),e.selectionChanged&&Ar(t),t.state.focused&&e.updateInput&&t.display.input.reset(e.typing),r&&Wr(e.cm)}function fn(e){var t=e.cm,r=t.display,n=t.doc;e.updatedDisplay&&Nn(t,e.update),null==r.wheelStartX||null==e.scrollTop&&null==e.scrollLeft&&!e.scrollToPos||(r.wheelStartX=r.wheelStartY=null),null!=e.scrollTop&&Zr(t,e.scrollTop,e.forceScroll),null!=e.scrollLeft&&Qr(t,e.scrollLeft,!0,!0),e.scrollToPos&&Br(t,Gr(t,U(n,e.scrollToPos.from),U(n,e.scrollToPos.to),e.scrollToPos.margin));var i=e.maybeHiddenMarkers,o=e.maybeUnhiddenMarkers;if(i)for(var l=0;l<i.length;++l)i[l].lines.length||Te(i[l],"hide");if(o)for(var s=0;s<o.length;++s)o[s].lines.length&&Te(o[s],"unhide");r.wrapper.offsetHeight&&(n.scrollTop=t.display.scroller.scrollTop),e.changeObjs&&Te(t,"changes",t,e.changeObjs),e.update&&e.update.finish()}function hn(e,t){if(e.curOp)return t();nn(e);try{return t()}finally{on(e)}}function dn(e,t){return function(){if(e.curOp)return t.apply(e,arguments);nn(e);try{return t.apply(e,arguments)}finally{on(e)}}}function pn(e){return function(){if(this.curOp)return e.apply(this,arguments);nn(this);try{return e.apply(this,arguments)}finally{on(this)}}}function gn(e){return function(){var t=this.cm;if(!t||t.curOp)return e.apply(this,arguments);nn(t);try{return e.apply(this,arguments)}finally{on(t)}}}function vn(e,t,r,n){null==t&&(t=e.doc.first),null==r&&(r=e.doc.first+e.doc.size),n||(n=0);var i=e.display;if(n&&r<i.viewTo&&(null==i.updateLineNumbers||i.updateLineNumbers>t)&&(i.updateLineNumbers=t),e.curOp.viewChanged=!0,t>=i.viewTo)_l&&pe(e.doc,t)<i.viewTo&&yn(e);else if(r<=i.viewFrom)_l&&ge(e.doc,r+n)>i.viewFrom?yn(e):(i.viewFrom+=n,i.viewTo+=n);else if(t<=i.viewFrom&&r>=i.viewTo)yn(e);else if(t<=i.viewFrom){var o=bn(e,r,r+n,1);o?(i.view=i.view.slice(o.index),i.viewFrom=o.lineN,i.viewTo+=n):yn(e)}else if(r>=i.viewTo){var l=bn(e,t,t,-1);l?(i.view=i.view.slice(0,l.index),i.viewTo=l.lineN):yn(e)}else{var s=bn(e,t,t,-1),a=bn(e,r,r+n,1);s&&a?(i.view=i.view.slice(0,s.index).concat(gt(e,s.lineN,a.lineN)).concat(i.view.slice(a.index)),i.viewTo+=n):yn(e)}var u=i.externalMeasured;u&&(r<u.lineN?u.lineN+=n:t<u.lineN+u.size&&(i.externalMeasured=null))}function mn(e,t,r){e.curOp.viewChanged=!0;var n=e.display,i=e.display.externalMeasured;if(i&&t>=i.lineN&&t<i.lineN+i.size&&(n.externalMeasured=null),!(t<n.viewFrom||t>=n.viewTo)){var o=n.view[Lr(e,t)];if(null!=o.node){var l=o.changes||(o.changes=[]);-1==h(l,r)&&l.push(r)}}}function yn(e){e.display.viewFrom=e.display.viewTo=e.doc.first,e.display.view=[],e.display.viewOffset=0}function bn(e,t,r,n){var i,o=Lr(e,t),l=e.display.view;if(!_l||r==e.doc.first+e.doc.size)return{index:o,lineN:r};for(var s=e.display.viewFrom,a=0;a<o;a++)s+=l[a].size;if(s!=t){if(n>0){if(o==l.length-1)return null;i=s+l[o].size-t,o++}else i=s-t;t+=i,r+=i}for(;pe(e.doc,r)!=r;){if(o==(n<0?0:l.length-1))return null;r+=n*l[o-(n<0?1:0)].size,o+=n}return{index:o,lineN:r}}function wn(e,t,r){var n=e.display;0==n.view.length||t>=n.viewTo||r<=n.viewFrom?(n.view=gt(e,t,r),n.viewFrom=t):(n.viewFrom>t?n.view=gt(e,t,n.viewFrom).concat(n.view):n.viewFrom<t&&(n.view=n.view.slice(Lr(e,t))),n.viewFrom=t,n.viewTo<r?n.view=n.view.concat(gt(e,n.viewTo,r)):n.viewTo>r&&(n.view=n.view.slice(0,Lr(e,r)))),n.viewTo=r}function xn(e){for(var t=e.display.view,r=0,n=0;n<t.length;n++){var i=t[n];i.hidden||i.node&&!i.changes||++r}return r}function Cn(e,t){e.doc.highlightFrontier<e.display.viewTo&&e.state.highlight.set(t,u(Sn,e))}function Sn(e){var t=e.doc;if(!(t.highlightFrontier>=e.display.viewTo)){var r=+new Date+e.options.workTime,n=$e(e,t.highlightFrontier),i=[];t.iter(n.line,Math.min(t.first+t.size,e.display.viewTo+500),function(o){if(n.line>=e.display.viewFrom){var l=o.styles,s=o.text.length>e.options.maxHighlightLength?Ke(t.mode,n.state):null,a=Ye(e,o,n,!0);s&&(n.state=s),o.styles=a.styles;var u=o.styleClasses,c=a.classes;c?o.styleClasses=c:u&&(o.styleClasses=null);for(var f=!l||l.length!=o.styles.length||u!=c&&(!u||!c||u.bgClass!=c.bgClass||u.textClass!=c.textClass),h=0;!f&&h<l.length;++h)f=l[h]!=o.styles[h];f&&i.push(n.line),o.stateAfter=n.save(),n.nextLine()}else o.text.length<=e.options.maxHighlightLength&&qe(e,o.text,n),o.stateAfter=n.line%5==0?n.save():null,n.nextLine();if(+new Date>r)return Cn(e,e.options.workDelay),!0}),t.highlightFrontier=n.line,t.modeFrontier=Math.max(t.modeFrontier,n.line),i.length&&hn(e,function(){for(var t=0;t<i.length;t++)mn(e,i[t],"text")})}}function Ln(e){var t=e.display;!t.scrollbarsClipped&&t.scroller.offsetWidth&&(t.nativeBarWidth=t.scroller.offsetWidth-t.scroller.clientWidth,t.heightForcer.style.height=zt(e)+"px",t.sizer.style.marginBottom=-t.nativeBarWidth+"px",t.sizer.style.borderRightWidth=zt(e)+"px",t.scrollbarsClipped=!0)}function kn(e){if(e.hasFocus())return null;var t=l();if(!t||!o(e.display.lineDiv,t))return null;var r={activeElt:t};if(window.getSelection){var n=window.getSelection();n.anchorNode&&n.extend&&o(e.display.lineDiv,n.anchorNode)&&(r.anchorNode=n.anchorNode,r.anchorOffset=n.anchorOffset,r.focusNode=n.focusNode,r.focusOffset=n.focusOffset)}return r}function Tn(e){if(e&&e.activeElt&&e.activeElt!=l()&&(e.activeElt.focus(),e.anchorNode&&o(document.body,e.anchorNode)&&o(document.body,e.focusNode))){var t=window.getSelection(),r=document.createRange();r.setEnd(e.anchorNode,e.anchorOffset),r.collapse(!1),t.removeAllRanges(),t.addRange(r),t.extend(e.focusNode,e.focusOffset)}}function Mn(e,r){var n=e.display,i=e.doc;if(r.editorIsHidden)return yn(e),!1;if(!r.force&&r.visible.from>=n.viewFrom&&r.visible.to<=n.viewTo&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo)&&n.renderedView==n.view&&0==xn(e))return!1;Rr(e)&&(yn(e),r.dims=br(e));var o=i.first+i.size,l=Math.max(r.visible.from-e.options.viewportMargin,i.first),s=Math.min(o,r.visible.to+e.options.viewportMargin);n.viewFrom<l&&l-n.viewFrom<20&&(l=Math.max(i.first,n.viewFrom)),n.viewTo>s&&n.viewTo-s<20&&(s=Math.min(o,n.viewTo)),_l&&(l=pe(e.doc,l),s=ge(e.doc,s));var a=l!=n.viewFrom||s!=n.viewTo||n.lastWrapHeight!=r.wrapperHeight||n.lastWrapWidth!=r.wrapperWidth;wn(e,l,s),n.viewOffset=ye(M(e.doc,n.viewFrom)),e.display.mover.style.top=n.viewOffset+"px";var u=xn(e);if(!a&&0==u&&!r.force&&n.renderedView==n.view&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo))return!1;var c=kn(e);return u>4&&(n.lineDiv.style.display="none"),An(e,n.updateLineNumbers,r.dims),u>4&&(n.lineDiv.style.display=""),n.renderedView=n.view,Tn(c),t(n.cursorDiv),t(n.selectionDiv),n.gutters.style.height=n.sizer.style.minHeight=0,a&&(n.lastWrapHeight=r.wrapperHeight,n.lastWrapWidth=r.wrapperWidth,Cn(e,400)),n.updateLineNumbers=null,!0}function Nn(e,t){for(var r=t.viewport,n=!0;(n&&e.options.lineWrapping&&t.oldDisplayWidth!=Rt(e)||(r&&null!=r.top&&(r={top:Math.min(e.doc.height+Pt(e.display)-Bt(e),r.top)}),t.visible=Ir(e.display,e.doc,r),!(t.visible.from>=e.display.viewFrom&&t.visible.to<=e.display.viewTo)))&&Mn(e,t);n=!1){Er(e);var i=Jr(e);kr(e),en(e,i),Dn(e,i),t.force=!1}t.signal(e,"update",e),e.display.viewFrom==e.display.reportedViewFrom&&e.display.viewTo==e.display.reportedViewTo||(t.signal(e,"viewportChange",e,e.display.viewFrom,e.display.viewTo),e.display.reportedViewFrom=e.display.viewFrom,e.display.reportedViewTo=e.display.viewTo)}function On(e,t){var r=new Cs(e,t);if(Mn(e,r)){Er(e),Nn(e,r);var n=Jr(e);kr(e),en(e,n),Dn(e,n),r.finish()}}function An(e,r,n){function i(t){var r=t.nextSibling;return ml&&Ml&&e.display.currentWheelTarget==t?t.style.display="none":t.parentNode.removeChild(t),r}for(var o=e.display,l=e.options.lineNumbers,s=o.lineDiv,a=s.firstChild,u=o.view,c=o.viewFrom,f=0;f<u.length;f++){var d=u[f];if(d.hidden);else if(d.node&&d.node.parentNode==s){for(;a!=d.node;)a=i(a);var p=l&&null!=r&&r<=c&&d.lineNumber;d.changes&&(h(d.changes,"gutter")>-1&&(p=!1),xt(e,d,c,n)),p&&(t(d.lineNumber),d.lineNumber.appendChild(document.createTextNode(F(e.options,c)))),a=d.node.nextSibling}else{var g=Ot(e,d,c,n);s.insertBefore(g,a)}c+=d.size}for(;a;)a=i(a)}function Wn(e){var t=e.display.gutters.offsetWidth;e.display.sizer.style.marginLeft=t+"px"}function Dn(e,t){e.display.sizer.style.minHeight=t.docHeight+"px",e.display.heightForcer.style.top=t.docHeight+"px",e.display.gutters.style.height=t.docHeight+e.display.barHeight+zt(e)+"px"}function Hn(e){var r=e.display.gutters,i=e.options.gutters;t(r);for(var o=0;o<i.length;++o){var l=i[o],s=r.appendChild(n("div",null,"CodeMirror-gutter "+l));"CodeMirror-linenumbers"==l&&(e.display.lineGutter=s,s.style.width=(e.display.lineNumWidth||1)+"px")}r.style.display=o?"":"none",Wn(e)}function Fn(e){var t=h(e.gutters,"CodeMirror-linenumbers");-1==t&&e.lineNumbers?e.gutters=e.gutters.concat(["CodeMirror-linenumbers"]):t>-1&&!e.lineNumbers&&(e.gutters=e.gutters.slice(0),e.gutters.splice(t,1))}function En(e){var t=e.wheelDeltaX,r=e.wheelDeltaY;return null==t&&e.detail&&e.axis==e.HORIZONTAL_AXIS&&(t=e.detail),null==r&&e.detail&&e.axis==e.VERTICAL_AXIS?r=e.detail:null==r&&(r=e.wheelDelta),{x:t,y:r}}function Pn(e){var t=En(e);return t.x*=Ls,t.y*=Ls,t}function In(e,t){var r=En(t),n=r.x,i=r.y,o=e.display,l=o.scroller,s=l.scrollWidth>l.clientWidth,a=l.scrollHeight>l.clientHeight;if(n&&s||i&&a){if(i&&Ml&&ml)e:for(var u=t.target,c=o.view;u!=l;u=u.parentNode)for(var f=0;f<c.length;f++)if(c[f].node==u){e.display.currentWheelTarget=u;break e}if(n&&!fl&&!wl&&null!=Ls)return i&&a&&qr(e,Math.max(0,l.scrollTop+i*Ls)),Qr(e,Math.max(0,l.scrollLeft+n*Ls)),(!i||i&&a)&&We(t),void(o.wheelStartX=null);if(i&&null!=Ls){var h=i*Ls,d=e.doc.scrollTop,p=d+o.wrapper.clientHeight;h<0?d=Math.max(0,d+h-50):p=Math.min(e.doc.height,p+h+50),On(e,{top:d,bottom:p})}Ss<20&&(null==o.wheelStartX?(o.wheelStartX=l.scrollLeft,o.wheelStartY=l.scrollTop,o.wheelDX=n,o.wheelDY=i,setTimeout(function(){if(null!=o.wheelStartX){var e=l.scrollLeft-o.wheelStartX,t=l.scrollTop-o.wheelStartY,r=t&&o.wheelDY&&t/o.wheelDY||e&&o.wheelDX&&e/o.wheelDX;o.wheelStartX=o.wheelStartY=null,r&&(Ls=(Ls*Ss+r)/(Ss+1),++Ss)}},200)):(o.wheelDX+=n,o.wheelDY+=i))}}function zn(e,t){var r=e[t];e.sort(function(e,t){return P(e.from(),t.from())}),t=h(e,r);for(var n=1;n<e.length;n++){var i=e[n],o=e[n-1];if(P(o.to(),i.from())>=0){var l=B(o.from(),i.from()),s=R(o.to(),i.to()),a=o.empty()?i.from()==i.head:o.from()==o.head;n<=t&&--t,e.splice(--n,2,new Ts(a?s:l,a?l:s))}}return new ks(e,t)}function Rn(e,t){return new ks([new Ts(e,t||e)],0)}function Bn(e){return e.text?E(e.from.line+e.text.length-1,g(e.text).length+(1==e.text.length?e.from.ch:0)):e.to}function Gn(e,t){if(P(e,t.from)<0)return e;if(P(e,t.to)<=0)return Bn(t);var r=e.line+t.text.length-(t.to.line-t.from.line)-1,n=e.ch;return e.line==t.to.line&&(n+=Bn(t).ch-t.to.ch),E(r,n)}function Un(e,t){for(var r=[],n=0;n<e.sel.ranges.length;n++){var i=e.sel.ranges[n];r.push(new Ts(Gn(i.anchor,t),Gn(i.head,t)))}return zn(r,e.sel.primIndex)}function Vn(e,t,r){return e.line==t.line?E(r.line,e.ch-t.ch+r.ch):E(r.line+(e.line-t.line),e.ch)}function Kn(e,t,r){for(var n=[],i=E(e.first,0),o=i,l=0;l<t.length;l++){var s=t[l],a=Vn(s.from,i,o),u=Vn(Bn(s),i,o);if(i=s.to,o=u,"around"==r){var c=e.sel.ranges[l],f=P(c.head,c.anchor)<0;n[l]=new Ts(f?u:a,f?a:u)}else n[l]=new Ts(a,a)}return new ks(n,e.sel.primIndex)}function jn(e){e.doc.mode=Ue(e.options,e.doc.modeOption),Xn(e)}function Xn(e){e.doc.iter(function(e){e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null)}),e.doc.modeFrontier=e.doc.highlightFrontier=e.doc.first,Cn(e,100),e.state.modeGen++,e.curOp&&vn(e)}function Yn(e,t){return 0==t.from.ch&&0==t.to.ch&&""==g(t.text)&&(!e.cm||e.cm.options.wholeLineUpdateBefore)}function _n(e,t,r,n){function i(e){return r?r[e]:null}function o(e,r,i){it(e,r,i,n),bt(e,"change",e,t)}function l(e,t){for(var r=[],o=e;o<t;++o)r.push(new fs(u[o],i(o),n));return r}var s=t.from,a=t.to,u=t.text,c=M(e,s.line),f=M(e,a.line),h=g(u),d=i(u.length-1),p=a.line-s.line;if(t.full)e.insert(0,l(0,u.length)),e.remove(u.length,e.size-u.length);else if(Yn(e,t)){var v=l(0,u.length-1);o(f,f.text,d),p&&e.remove(s.line,p),v.length&&e.insert(s.line,v)}else if(c==f)if(1==u.length)o(c,c.text.slice(0,s.ch)+h+c.text.slice(a.ch),d);else{var m=l(1,u.length-1);m.push(new fs(h+c.text.slice(a.ch),d,n)),o(c,c.text.slice(0,s.ch)+u[0],i(0)),e.insert(s.line+1,m)}else if(1==u.length)o(c,c.text.slice(0,s.ch)+u[0]+f.text.slice(a.ch),i(0)),e.remove(s.line+1,p);else{o(c,c.text.slice(0,s.ch)+u[0],i(0)),o(f,h+f.text.slice(a.ch),d);var y=l(1,u.length-1);p>1&&e.remove(s.line+1,p-1),e.insert(s.line+1,y)}bt(e,"change",e,t)}function $n(e,t,r){function n(e,i,o){if(e.linked)for(var l=0;l<e.linked.length;++l){var s=e.linked[l];if(s.doc!=i){var a=o&&s.sharedHist;r&&!a||(t(s.doc,a),n(s.doc,e,a))}}}n(e,null,!0)}function qn(e,t){if(t.cm)throw new Error("This document is already in use.");e.doc=t,t.cm=e,Cr(e),jn(e),Zn(e),e.options.lineWrapping||we(e),e.options.mode=t.modeOption,vn(e)}function Zn(e){("rtl"==e.doc.direction?s:Fl)(e.display.lineDiv,"CodeMirror-rtl")}function Qn(e){hn(e,function(){Zn(e),vn(e)})}function Jn(e){this.done=[],this.undone=[],this.undoDepth=1/0,this.lastModTime=this.lastSelTime=0,this.lastOp=this.lastSelOp=null,this.lastOrigin=this.lastSelOrigin=null,this.generation=this.maxGeneration=e||1}function ei(e,t){var r={from:z(t.from),to:Bn(t),text:N(e,t.from,t.to)};return si(e,r,t.from.line,t.to.line+1),$n(e,function(e){return si(e,r,t.from.line,t.to.line+1)},!0),r}function ti(e){for(;e.length&&g(e).ranges;)e.pop()}function ri(e,t){return t?(ti(e.done),g(e.done)):e.done.length&&!g(e.done).ranges?g(e.done):e.done.length>1&&!e.done[e.done.length-2].ranges?(e.done.pop(),g(e.done)):void 0}function ni(e,t,r,n){var i=e.history;i.undone.length=0;var o,l,s=+new Date;if((i.lastOp==n||i.lastOrigin==t.origin&&t.origin&&("+"==t.origin.charAt(0)&&e.cm&&i.lastModTime>s-e.cm.options.historyEventDelay||"*"==t.origin.charAt(0)))&&(o=ri(i,i.lastOp==n)))l=g(o.changes),0==P(t.from,t.to)&&0==P(t.from,l.to)?l.to=Bn(t):o.changes.push(ei(e,t));else{var a=g(i.done);for(a&&a.ranges||li(e.sel,i.done),o={changes:[ei(e,t)],generation:i.generation},i.done.push(o);i.done.length>i.undoDepth;)i.done.shift(),i.done[0].ranges||i.done.shift()}i.done.push(r),i.generation=++i.maxGeneration,i.lastModTime=i.lastSelTime=s,i.lastOp=i.lastSelOp=n,i.lastOrigin=i.lastSelOrigin=t.origin,l||Te(e,"historyAdded")}function ii(e,t,r,n){var i=t.charAt(0);return"*"==i||"+"==i&&r.ranges.length==n.ranges.length&&r.somethingSelected()==n.somethingSelected()&&new Date-e.history.lastSelTime<=(e.cm?e.cm.options.historyEventDelay:500)}function oi(e,t,r,n){var i=e.history,o=n&&n.origin;r==i.lastSelOp||o&&i.lastSelOrigin==o&&(i.lastModTime==i.lastSelTime&&i.lastOrigin==o||ii(e,o,g(i.done),t))?i.done[i.done.length-1]=t:li(t,i.done),i.lastSelTime=+new Date,i.lastSelOrigin=o,i.lastSelOp=r,n&&!1!==n.clearRedo&&ti(i.undone)}function li(e,t){var r=g(t);r&&r.ranges&&r.equals(e)||t.push(e)}function si(e,t,r,n){var i=t["spans_"+e.id],o=0;e.iter(Math.max(e.first,r),Math.min(e.first+e.size,n),function(r){r.markedSpans&&((i||(i=t["spans_"+e.id]={}))[o]=r.markedSpans),++o})}function ai(e){if(!e)return null;for(var t,r=0;r<e.length;++r)e[r].marker.explicitlyCleared?t||(t=e.slice(0,r)):t&&t.push(e[r]);return t?t.length?t:null:e}function ui(e,t){var r=t["spans_"+e.id];if(!r)return null;for(var n=[],i=0;i<t.text.length;++i)n.push(ai(r[i]));return n}function ci(e,t){var r=ui(e,t),n=J(e,t);if(!r)return n;if(!n)return r;for(var i=0;i<r.length;++i){var o=r[i],l=n[i];if(o&&l)e:for(var s=0;s<l.length;++s){for(var a=l[s],u=0;u<o.length;++u)if(o[u].marker==a.marker)continue e;o.push(a)}else l&&(r[i]=l)}return r}function fi(e,t,r){for(var n=[],i=0;i<e.length;++i){var o=e[i];if(o.ranges)n.push(r?ks.prototype.deepCopy.call(o):o);else{var l=o.changes,s=[];n.push({changes:s});for(var a=0;a<l.length;++a){var u=l[a],c=void 0;if(s.push({from:u.from,to:u.to,text:u.text}),t)for(var f in u)(c=f.match(/^spans_(\d+)$/))&&h(t,Number(c[1]))>-1&&(g(s)[f]=u[f],delete u[f])}}}return n}function hi(e,t,r,n){if(n){var i=e.anchor;if(r){var o=P(t,i)<0;o!=P(r,i)<0?(i=t,t=r):o!=P(t,r)<0&&(t=r)}return new Ts(i,t)}return new Ts(r||t,t)}function di(e,t,r,n,i){null==i&&(i=e.cm&&(e.cm.display.shift||e.extend)),bi(e,new ks([hi(e.sel.primary(),t,r,i)],0),n)}function pi(e,t,r){for(var n=[],i=e.cm&&(e.cm.display.shift||e.extend),o=0;o<e.sel.ranges.length;o++)n[o]=hi(e.sel.ranges[o],t[o],null,i);bi(e,zn(n,e.sel.primIndex),r)}function gi(e,t,r,n){var i=e.sel.ranges.slice(0);i[t]=r,bi(e,zn(i,e.sel.primIndex),n)}function vi(e,t,r,n){bi(e,Rn(t,r),n)}function mi(e,t,r){var n={ranges:t.ranges,update:function(t){var r=this;this.ranges=[];for(var n=0;n<t.length;n++)r.ranges[n]=new Ts(U(e,t[n].anchor),U(e,t[n].head))},origin:r&&r.origin};return Te(e,"beforeSelectionChange",e,n),e.cm&&Te(e.cm,"beforeSelectionChange",e.cm,n),n.ranges!=t.ranges?zn(n.ranges,n.ranges.length-1):t}function yi(e,t,r){var n=e.history.done,i=g(n);i&&i.ranges?(n[n.length-1]=t,wi(e,t,r)):bi(e,t,r)}function bi(e,t,r){wi(e,t,r),oi(e,e.sel,e.cm?e.cm.curOp.id:NaN,r)}function wi(e,t,r){(Oe(e,"beforeSelectionChange")||e.cm&&Oe(e.cm,"beforeSelectionChange"))&&(t=mi(e,t,r)),xi(e,Si(e,t,r&&r.bias||(P(t.primary().head,e.sel.primary().head)<0?-1:1),!0)),r&&!1===r.scroll||!e.cm||jr(e.cm)}function xi(e,t){t.equals(e.sel)||(e.sel=t,e.cm&&(e.cm.curOp.updateInput=e.cm.curOp.selectionChanged=!0,Ne(e.cm)),bt(e,"cursorActivity",e))}function Ci(e){xi(e,Si(e,e.sel,null,!1))}function Si(e,t,r,n){for(var i,o=0;o<t.ranges.length;o++){var l=t.ranges[o],s=t.ranges.length==e.sel.ranges.length&&e.sel.ranges[o],a=ki(e,l.anchor,s&&s.anchor,r,n),u=ki(e,l.head,s&&s.head,r,n);(i||a!=l.anchor||u!=l.head)&&(i||(i=t.ranges.slice(0,o)),i[o]=new Ts(a,u))}return i?zn(i,t.primIndex):t}function Li(e,t,r,n,i){var o=M(e,t.line);if(o.markedSpans)for(var l=0;l<o.markedSpans.length;++l){var s=o.markedSpans[l],a=s.marker;if((null==s.from||(a.inclusiveLeft?s.from<=t.ch:s.from<t.ch))&&(null==s.to||(a.inclusiveRight?s.to>=t.ch:s.to>t.ch))){if(i&&(Te(a,"beforeCursorEnter"),a.explicitlyCleared)){if(o.markedSpans){--l;continue}break}if(!a.atomic)continue;if(r){var u=a.find(n<0?1:-1),c=void 0;if((n<0?a.inclusiveRight:a.inclusiveLeft)&&(u=Ti(e,u,-n,u&&u.line==t.line?o:null)),u&&u.line==t.line&&(c=P(u,r))&&(n<0?c<0:c>0))return Li(e,u,t,n,i)}var f=a.find(n<0?-1:1);return(n<0?a.inclusiveLeft:a.inclusiveRight)&&(f=Ti(e,f,n,f.line==t.line?o:null)),f?Li(e,f,t,n,i):null}}return t}function ki(e,t,r,n,i){var o=n||1,l=Li(e,t,r,o,i)||!i&&Li(e,t,r,o,!0)||Li(e,t,r,-o,i)||!i&&Li(e,t,r,-o,!0);return l||(e.cantEdit=!0,E(e.first,0))}function Ti(e,t,r,n){return r<0&&0==t.ch?t.line>e.first?U(e,E(t.line-1)):null:r>0&&t.ch==(n||M(e,t.line)).text.length?t.line<e.first+e.size-1?E(t.line+1,0):null:new E(t.line,t.ch+r)}function Mi(e){e.setSelection(E(e.firstLine(),0),E(e.lastLine()),Gl)}function Ni(e,t,r){var n={canceled:!1,from:t.from,to:t.to,text:t.text,origin:t.origin,cancel:function(){return n.canceled=!0}};return r&&(n.update=function(t,r,i,o){t&&(n.from=U(e,t)),r&&(n.to=U(e,r)),i&&(n.text=i),void 0!==o&&(n.origin=o)}),Te(e,"beforeChange",e,n),e.cm&&Te(e.cm,"beforeChange",e.cm,n),n.canceled?null:{from:n.from,to:n.to,text:n.text,origin:n.origin}}function Oi(e,t,r){if(e.cm){if(!e.cm.curOp)return dn(e.cm,Oi)(e,t,r);if(e.cm.state.suppressEdits)return}if(!(Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"))||(t=Ni(e,t,!0))){var n=Yl&&!r&&te(e,t.from,t.to);if(n)for(var i=n.length-1;i>=0;--i)Ai(e,{from:n[i].from,to:n[i].to,text:i?[""]:t.text,origin:t.origin});else Ai(e,t)}}function Ai(e,t){if(1!=t.text.length||""!=t.text[0]||0!=P(t.from,t.to)){var r=Un(e,t);ni(e,t,r,e.cm?e.cm.curOp.id:NaN),Hi(e,t,r,J(e,t));var n=[];$n(e,function(e,r){r||-1!=h(n,e.history)||(zi(e.history,t),n.push(e.history)),Hi(e,t,null,J(e,t))})}}function Wi(e,t,r){if(!e.cm||!e.cm.state.suppressEdits||r){for(var n,i=e.history,o=e.sel,l="undo"==t?i.done:i.undone,s="undo"==t?i.undone:i.done,a=0;a<l.length&&(n=l[a],r?!n.ranges||n.equals(e.sel):n.ranges);a++);if(a!=l.length){for(i.lastOrigin=i.lastSelOrigin=null;(n=l.pop()).ranges;){if(li(n,s),r&&!n.equals(e.sel))return void bi(e,n,{clearRedo:!1});o=n}var u=[];li(o,s),s.push({changes:u,generation:i.generation}),i.generation=n.generation||++i.maxGeneration;for(var c=Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"),f=n.changes.length-1;f>=0;--f){var d=function(r){var i=n.changes[r];if(i.origin=t,c&&!Ni(e,i,!1))return l.length=0,{};u.push(ei(e,i));var o=r?Un(e,i):g(l);Hi(e,i,o,ci(e,i)),!r&&e.cm&&e.cm.scrollIntoView({from:i.from,to:Bn(i)});var s=[];$n(e,function(e,t){t||-1!=h(s,e.history)||(zi(e.history,i),s.push(e.history)),Hi(e,i,null,ci(e,i))})}(f);if(d)return d.v}}}}function Di(e,t){if(0!=t&&(e.first+=t,e.sel=new ks(v(e.sel.ranges,function(e){return new Ts(E(e.anchor.line+t,e.anchor.ch),E(e.head.line+t,e.head.ch))}),e.sel.primIndex),e.cm)){vn(e.cm,e.first,e.first-t,t);for(var r=e.cm.display,n=r.viewFrom;n<r.viewTo;n++)mn(e.cm,n,"gutter")}}function Hi(e,t,r,n){if(e.cm&&!e.cm.curOp)return dn(e.cm,Hi)(e,t,r,n);if(t.to.line<e.first)Di(e,t.text.length-1-(t.to.line-t.from.line));else if(!(t.from.line>e.lastLine())){if(t.from.line<e.first){var i=t.text.length-1-(e.first-t.from.line);Di(e,i),t={from:E(e.first,0),to:E(t.to.line+i,t.to.ch),text:[g(t.text)],origin:t.origin}}var o=e.lastLine();t.to.line>o&&(t={from:t.from,to:E(o,M(e,o).text.length),text:[t.text[0]],origin:t.origin}),t.removed=N(e,t.from,t.to),r||(r=Un(e,t)),e.cm?Fi(e.cm,t,n):_n(e,t,n),wi(e,r,Gl)}}function Fi(e,t,r){var n=e.doc,i=e.display,o=t.from,l=t.to,s=!1,a=o.line;e.options.lineWrapping||(a=W(fe(M(n,o.line))),n.iter(a,l.line+1,function(e){if(e==i.maxLine)return s=!0,!0})),n.sel.contains(t.from,t.to)>-1&&Ne(e),_n(n,t,r,xr(e)),e.options.lineWrapping||(n.iter(a,o.line+t.text.length,function(e){var t=be(e);t>i.maxLineLength&&(i.maxLine=e,i.maxLineLength=t,i.maxLineChanged=!0,s=!1)}),s&&(e.curOp.updateMaxLine=!0)),nt(n,o.line),Cn(e,400);var u=t.text.length-(l.line-o.line)-1;t.full?vn(e):o.line!=l.line||1!=t.text.length||Yn(e.doc,t)?vn(e,o.line,l.line+1,u):mn(e,o.line,"text");var c=Oe(e,"changes"),f=Oe(e,"change");if(f||c){var h={from:o,to:l,text:t.text,removed:t.removed,origin:t.origin};f&&bt(e,"change",e,h),c&&(e.curOp.changeObjs||(e.curOp.changeObjs=[])).push(h)}e.display.selForContextMenu=null}function Ei(e,t,r,n,i){if(n||(n=r),P(n,r)<0){var o;r=(o=[n,r])[0],n=o[1]}"string"==typeof t&&(t=e.splitLines(t)),Oi(e,{from:r,to:n,text:t,origin:i})}function Pi(e,t,r,n){r<e.line?e.line+=n:t<e.line&&(e.line=t,e.ch=0)}function Ii(e,t,r,n){for(var i=0;i<e.length;++i){var o=e[i],l=!0;if(o.ranges){o.copied||((o=e[i]=o.deepCopy()).copied=!0);for(var s=0;s<o.ranges.length;s++)Pi(o.ranges[s].anchor,t,r,n),Pi(o.ranges[s].head,t,r,n)}else{for(var a=0;a<o.changes.length;++a){var u=o.changes[a];if(r<u.from.line)u.from=E(u.from.line+n,u.from.ch),u.to=E(u.to.line+n,u.to.ch);else if(t<=u.to.line){l=!1;break}}l||(e.splice(0,i+1),i=0)}}}function zi(e,t){var r=t.from.line,n=t.to.line,i=t.text.length-(n-r)-1;Ii(e.done,r,n,i),Ii(e.undone,r,n,i)}function Ri(e,t,r,n){var i=t,o=t;return"number"==typeof t?o=M(e,G(e,t)):i=W(t),null==i?null:(n(o,i)&&e.cm&&mn(e.cm,i,r),o)}function Bi(e){var t=this;this.lines=e,this.parent=null;for(var r=0,n=0;n<e.length;++n)e[n].parent=t,r+=e[n].height;this.height=r}function Gi(e){var t=this;this.children=e;for(var r=0,n=0,i=0;i<e.length;++i){var o=e[i];r+=o.chunkSize(),n+=o.height,o.parent=t}this.size=r,this.height=n,this.parent=null}function Ui(e,t,r){ye(t)<(e.curOp&&e.curOp.scrollTop||e.doc.scrollTop)&&Kr(e,r)}function Vi(e,t,r,n){var i=new Ms(e,r,n),o=e.cm;return o&&i.noHScroll&&(o.display.alignWidgets=!0),Ri(e,t,"widget",function(t){var r=t.widgets||(t.widgets=[]);if(null==i.insertAt?r.push(i):r.splice(Math.min(r.length-1,Math.max(0,i.insertAt)),0,i),i.line=t,o&&!ve(e,t)){var n=ye(t)<e.scrollTop;A(t,t.height+Ht(i)),n&&Kr(o,i.height),o.curOp.forceUpdate=!0}return!0}),bt(o,"lineWidgetAdded",o,i,"number"==typeof t?t:W(t)),i}function Ki(e,t,r,n,o){if(n&&n.shared)return ji(e,t,r,n,o);if(e.cm&&!e.cm.curOp)return dn(e.cm,Ki)(e,t,r,n,o);var l=new Os(e,o),s=P(t,r);if(n&&c(n,l,!1),s>0||0==s&&!1!==l.clearWhenEmpty)return l;if(l.replacedWith&&(l.collapsed=!0,l.widgetNode=i("span",[l.replacedWith],"CodeMirror-widget"),n.handleMouseEvents||l.widgetNode.setAttribute("cm-ignore-events","true"),n.insertLeft&&(l.widgetNode.insertLeft=!0)),l.collapsed){if(ce(e,t.line,t,r,l)||t.line!=r.line&&ce(e,r.line,t,r,l))throw new Error("Inserting collapsed marker partially overlapping an existing one");X()}l.addToHistory&&ni(e,{from:t,to:r,origin:"markText"},e.sel,NaN);var a,u=t.line,f=e.cm;if(e.iter(u,r.line+1,function(e){f&&l.collapsed&&!f.options.lineWrapping&&fe(e)==f.display.maxLine&&(a=!0),l.collapsed&&u!=t.line&&A(e,0),q(e,new Y(l,u==t.line?t.ch:null,u==r.line?r.ch:null)),++u}),l.collapsed&&e.iter(t.line,r.line+1,function(t){ve(e,t)&&A(t,0)}),l.clearOnEnter&&Ql(l,"beforeCursorEnter",function(){return l.clear()}),l.readOnly&&(j(),(e.history.done.length||e.history.undone.length)&&e.clearHistory()),l.collapsed&&(l.id=++Ns,l.atomic=!0),f){if(a&&(f.curOp.updateMaxLine=!0),l.collapsed)vn(f,t.line,r.line+1);else if(l.className||l.title||l.startStyle||l.endStyle||l.css)for(var h=t.line;h<=r.line;h++)mn(f,h,"text");l.atomic&&Ci(f.doc),bt(f,"markerAdded",f,l)}return l}function ji(e,t,r,n,i){(n=c(n)).shared=!1;var o=[Ki(e,t,r,n,i)],l=o[0],s=n.widgetNode;return $n(e,function(e){s&&(n.widgetNode=s.cloneNode(!0)),o.push(Ki(e,U(e,t),U(e,r),n,i));for(var a=0;a<e.linked.length;++a)if(e.linked[a].isParent)return;l=g(o)}),new As(o,l)}function Xi(e){return e.findMarks(E(e.first,0),e.clipPos(E(e.lastLine())),function(e){return e.parent})}function Yi(e,t){for(var r=0;r<t.length;r++){var n=t[r],i=n.find(),o=e.clipPos(i.from),l=e.clipPos(i.to);if(P(o,l)){var s=Ki(e,o,l,n.primary,n.primary.type);n.markers.push(s),s.parent=n}}}function _i(e){for(var t=0;t<e.length;t++)!function(t){var r=e[t],n=[r.primary.doc];$n(r.primary.doc,function(e){return n.push(e)});for(var i=0;i<r.markers.length;i++){var o=r.markers[i];-1==h(n,o.doc)&&(o.parent=null,r.markers.splice(i--,1))}}(t)}function $i(e){var t=this;if(Qi(t),!Me(t,e)&&!Ft(t.display,e)){We(e),gl&&(Hs=+new Date);var r=Sr(t,e,!0),n=e.dataTransfer.files;if(r&&!t.isReadOnly())if(n&&n.length&&window.FileReader&&window.File)for(var i=n.length,o=Array(i),l=0,s=0;s<i;++s)!function(e,n){if(!t.options.allowDropFileTypes||-1!=h(t.options.allowDropFileTypes,e.type)){var s=new FileReader;s.onload=dn(t,function(){var e=s.result;if(/[\x00-\x08\x0e-\x1f]{2}/.test(e)&&(e=""),o[n]=e,++l==i){var a={from:r=U(t.doc,r),to:r,text:t.doc.splitLines(o.join(t.doc.lineSeparator())),origin:"paste"};Oi(t.doc,a),yi(t.doc,Rn(r,Bn(a)))}}),s.readAsText(e)}}(n[s],s);else{if(t.state.draggingText&&t.doc.sel.contains(r)>-1)return t.state.draggingText(e),void setTimeout(function(){return t.display.input.focus()},20);try{var a=e.dataTransfer.getData("Text");if(a){var u;if(t.state.draggingText&&!t.state.draggingText.copy&&(u=t.listSelections()),wi(t.doc,Rn(r,r)),u)for(var c=0;c<u.length;++c)Ei(t.doc,"",u[c].anchor,u[c].head,"drag");t.replaceSelection(a,"around","paste"),t.display.input.focus()}}catch(e){}}}}function qi(e,t){if(gl&&(!e.state.draggingText||+new Date-Hs<100))Fe(t);else if(!Me(e,t)&&!Ft(e.display,t)&&(t.dataTransfer.setData("Text",e.getSelection()),t.dataTransfer.effectAllowed="copyMove",t.dataTransfer.setDragImage&&!xl)){var r=n("img",null,null,"position: fixed; left: 0; top: 0;");r.src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==",wl&&(r.width=r.height=1,e.display.wrapper.appendChild(r),r._top=r.offsetTop),t.dataTransfer.setDragImage(r,0,0),wl&&r.parentNode.removeChild(r)}}function Zi(e,t){var i=Sr(e,t);if(i){var o=document.createDocumentFragment();Mr(e,i,o),e.display.dragCursor||(e.display.dragCursor=n("div",null,"CodeMirror-cursors CodeMirror-dragcursors"),e.display.lineSpace.insertBefore(e.display.dragCursor,e.display.cursorDiv)),r(e.display.dragCursor,o)}}function Qi(e){e.display.dragCursor&&(e.display.lineSpace.removeChild(e.display.dragCursor),e.display.dragCursor=null)}function Ji(e){if(document.getElementsByClassName)for(var t=document.getElementsByClassName("CodeMirror"),r=0;r<t.length;r++){var n=t[r].CodeMirror;n&&e(n)}}function eo(){Fs||(to(),Fs=!0)}function to(){var e;Ql(window,"resize",function(){null==e&&(e=setTimeout(function(){e=null,Ji(ro)},100))}),Ql(window,"blur",function(){return Ji(Fr)})}function ro(e){var t=e.display;t.lastWrapHeight==t.wrapper.clientHeight&&t.lastWrapWidth==t.wrapper.clientWidth||(t.cachedCharWidth=t.cachedTextHeight=t.cachedPaddingH=null,t.scrollbarsClipped=!1,e.setSize())}function no(e){var t=e.split(/-(?!$)/);e=t[t.length-1];for(var r,n,i,o,l=0;l<t.length-1;l++){var s=t[l];if(/^(cmd|meta|m)$/i.test(s))o=!0;else if(/^a(lt)?$/i.test(s))r=!0;else if(/^(c|ctrl|control)$/i.test(s))n=!0;else{if(!/^s(hift)?$/i.test(s))throw new Error("Unrecognized modifier name: "+s);i=!0}}return r&&(e="Alt-"+e),n&&(e="Ctrl-"+e),o&&(e="Cmd-"+e),i&&(e="Shift-"+e),e}function io(e){var t={};for(var r in e)if(e.hasOwnProperty(r)){var n=e[r];if(/^(name|fallthrough|(de|at)tach)$/.test(r))continue;if("..."==n){delete e[r];continue}for(var i=v(r.split(" "),no),o=0;o<i.length;o++){var l=void 0,s=void 0;o==i.length-1?(s=i.join(" "),l=n):(s=i.slice(0,o+1).join(" "),l="...");var a=t[s];if(a){if(a!=l)throw new Error("Inconsistent bindings for "+s)}else t[s]=l}delete e[r]}for(var u in t)e[u]=t[u];return e}function oo(e,t,r,n){var i=(t=uo(t)).call?t.call(e,n):t[e];if(!1===i)return"nothing";if("..."===i)return"multi";if(null!=i&&r(i))return"handled";if(t.fallthrough){if("[object Array]"!=Object.prototype.toString.call(t.fallthrough))return oo(e,t.fallthrough,r,n);for(var o=0;o<t.fallthrough.length;o++){var l=oo(e,t.fallthrough[o],r,n);if(l)return l}}}function lo(e){var t="string"==typeof e?e:Es[e.keyCode];return"Ctrl"==t||"Alt"==t||"Shift"==t||"Mod"==t}function so(e,t,r){var n=e;return t.altKey&&"Alt"!=n&&(e="Alt-"+e),(Dl?t.metaKey:t.ctrlKey)&&"Ctrl"!=n&&(e="Ctrl-"+e),(Dl?t.ctrlKey:t.metaKey)&&"Cmd"!=n&&(e="Cmd-"+e),!r&&t.shiftKey&&"Shift"!=n&&(e="Shift-"+e),e}function ao(e,t){if(wl&&34==e.keyCode&&e.char)return!1;var r=Es[e.keyCode];return null!=r&&!e.altGraphKey&&so(r,e,t)}function uo(e){return"string"==typeof e?Rs[e]:e}function co(e,t){for(var r=e.doc.sel.ranges,n=[],i=0;i<r.length;i++){for(var o=t(r[i]);n.length&&P(o.from,g(n).to)<=0;){var l=n.pop();if(P(l.from,o.from)<0){o.from=l.from;break}}n.push(o)}hn(e,function(){for(var t=n.length-1;t>=0;t--)Ei(e.doc,"",n[t].from,n[t].to,"+delete");jr(e)})}function fo(e,t,r){var n=L(e.text,t+r,r);return n<0||n>e.text.length?null:n}function ho(e,t,r){var n=fo(e,t.ch,r);return null==n?null:new E(t.line,n,r<0?"after":"before")}function po(e,t,r,n,i){if(e){var o=Se(r,t.doc.direction);if(o){var l,s=i<0?g(o):o[0],a=i<0==(1==s.level)?"after":"before";if(s.level>0){var u=Xt(t,r);l=i<0?r.text.length-1:0;var c=Yt(t,u,l).top;l=k(function(e){return Yt(t,u,e).top==c},i<0==(1==s.level)?s.from:s.to-1,l),"before"==a&&(l=fo(r,l,1))}else l=i<0?s.to:s.from;return new E(n,l,a)}}return new E(n,i<0?r.text.length:0,i<0?"before":"after")}function go(e,t,r,n){var i=Se(t,e.doc.direction);if(!i)return ho(t,r,n);r.ch>=t.text.length?(r.ch=t.text.length,r.sticky="before"):r.ch<=0&&(r.ch=0,r.sticky="after");var o=Ce(i,r.ch,r.sticky),l=i[o];if("ltr"==e.doc.direction&&l.level%2==0&&(n>0?l.to>r.ch:l.from<r.ch))return ho(t,r,n);var s,a=function(e,r){return fo(t,e instanceof E?e.ch:e,r)},u=function(r){return e.options.lineWrapping?(s=s||Xt(e,t),hr(e,t,s,r)):{begin:0,end:t.text.length}},c=u("before"==r.sticky?a(r,-1):r.ch);if("rtl"==e.doc.direction||1==l.level){var f=1==l.level==n<0,h=a(r,f?1:-1);if(null!=h&&(f?h<=l.to&&h<=c.end:h>=l.from&&h>=c.begin)){var d=f?"before":"after";return new E(r.line,h,d)}}var p=function(e,t,n){for(var o=function(e,t){return t?new E(r.line,a(e,1),"before"):new E(r.line,e,"after")};e>=0&&e<i.length;e+=t){var l=i[e],s=t>0==(1!=l.level),u=s?n.begin:a(n.end,-1);if(l.from<=u&&u<l.to)return o(u,s);if(u=s?l.from:a(l.to,-1),n.begin<=u&&u<n.end)return o(u,s)}},g=p(o+n,n,c);if(g)return g;var v=n>0?c.end:a(c.begin,-1);return null==v||n>0&&v==t.text.length||!(g=p(n>0?0:i.length-1,n,u(v)))?null:g}function vo(e,t){var r=M(e.doc,t),n=fe(r);return n!=r&&(t=W(n)),po(!0,e,n,t,1)}function mo(e,t){var r=M(e.doc,t),n=he(r);return n!=r&&(t=W(n)),po(!0,e,r,t,-1)}function yo(e,t){var r=vo(e,t.line),n=M(e.doc,r.line),i=Se(n,e.doc.direction);if(!i||0==i[0].level){var o=Math.max(0,n.text.search(/\S/)),l=t.line==r.line&&t.ch<=o&&t.ch;return E(r.line,l?0:o,r.sticky)}return r}function bo(e,t,r){if("string"==typeof t&&!(t=Bs[t]))return!1;e.display.input.ensurePolled();var n=e.display.shift,i=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),r&&(e.display.shift=!1),i=t(e)!=Bl}finally{e.display.shift=n,e.state.suppressEdits=!1}return i}function wo(e,t,r){for(var n=0;n<e.state.keyMaps.length;n++){var i=oo(t,e.state.keyMaps[n],r,e);if(i)return i}return e.options.extraKeys&&oo(t,e.options.extraKeys,r,e)||oo(t,e.options.keyMap,r,e)}function xo(e,t,r,n){var i=e.state.keySeq;if(i){if(lo(t))return"handled";Gs.set(50,function(){e.state.keySeq==i&&(e.state.keySeq=null,e.display.input.reset())}),t=i+" "+t}var o=wo(e,t,n);return"multi"==o&&(e.state.keySeq=t),"handled"==o&&bt(e,"keyHandled",e,t,r),"handled"!=o&&"multi"!=o||(We(r),Ar(e)),i&&!o&&/\'$/.test(t)?(We(r),!0):!!o}function Co(e,t){var r=ao(t,!0);return!!r&&(t.shiftKey&&!e.state.keySeq?xo(e,"Shift-"+r,t,function(t){return bo(e,t,!0)})||xo(e,r,t,function(t){if("string"==typeof t?/^go[A-Z]/.test(t):t.motion)return bo(e,t)}):xo(e,r,t,function(t){return bo(e,t)}))}function So(e,t,r){return xo(e,"'"+r+"'",t,function(t){return bo(e,t,!0)})}function Lo(e){var t=this;if(t.curOp.focus=l(),!Me(t,e)){gl&&vl<11&&27==e.keyCode&&(e.returnValue=!1);var r=e.keyCode;t.display.shift=16==r||e.shiftKey;var n=Co(t,e);wl&&(Us=n?r:null,!n&&88==r&&!rs&&(Ml?e.metaKey:e.ctrlKey)&&t.replaceSelection("",null,"cut")),18!=r||/\bCodeMirror-crosshair\b/.test(t.display.lineDiv.className)||ko(t)}}function ko(e){function t(e){18!=e.keyCode&&e.altKey||(Fl(r,"CodeMirror-crosshair"),ke(document,"keyup",t),ke(document,"mouseover",t))}var r=e.display.lineDiv;s(r,"CodeMirror-crosshair"),Ql(document,"keyup",t),Ql(document,"mouseover",t)}function To(e){16==e.keyCode&&(this.doc.sel.shift=!1),Me(this,e)}function Mo(e){var t=this;if(!(Ft(t.display,e)||Me(t,e)||e.ctrlKey&&!e.altKey||Ml&&e.metaKey)){var r=e.keyCode,n=e.charCode;if(wl&&r==Us)return Us=null,void We(e);if(!wl||e.which&&!(e.which<10)||!Co(t,e)){var i=String.fromCharCode(null==n?r:n);"\b"!=i&&(So(t,e,i)||t.display.input.onKeyPress(e))}}}function No(e,t){var r=+new Date;return js&&js.compare(r,e,t)?(Ks=js=null,"triple"):Ks&&Ks.compare(r,e,t)?(js=new Vs(r,e,t),Ks=null,"double"):(Ks=new Vs(r,e,t),js=null,"single")}function Oo(e){var t=this,r=t.display;if(!(Me(t,e)||r.activeTouch&&r.input.supportsTouch()))if(r.input.ensurePolled(),r.shift=e.shiftKey,Ft(r,e))ml||(r.scroller.draggable=!1,setTimeout(function(){return r.scroller.draggable=!0},100));else if(!zo(t,e)){var n=Sr(t,e),i=Pe(e),o=n?No(n,i):"single";window.focus(),1==i&&t.state.selectingText&&t.state.selectingText(e),n&&Ao(t,i,n,o,e)||(1==i?n?Do(t,n,o,e):Ee(e)==r.scroller&&We(e):2==i?(n&&di(t.doc,n),setTimeout(function(){return r.input.focus()},20)):3==i&&(Hl?Ro(t,e):Dr(t)))}}function Ao(e,t,r,n,i){var o="Click";return"double"==n?o="Double"+o:"triple"==n&&(o="Triple"+o),o=(1==t?"Left":2==t?"Middle":"Right")+o,xo(e,so(o,i),i,function(t){if("string"==typeof t&&(t=Bs[t]),!t)return!1;var n=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),n=t(e,r)!=Bl}finally{e.state.suppressEdits=!1}return n})}function Wo(e,t,r){var n=e.getOption("configureMouse"),i=n?n(e,t,r):{};if(null==i.unit){var o=Nl?r.shiftKey&&r.metaKey:r.altKey;i.unit=o?"rectangle":"single"==t?"char":"double"==t?"word":"line"}return(null==i.extend||e.doc.extend)&&(i.extend=e.doc.extend||r.shiftKey),null==i.addNew&&(i.addNew=Ml?r.metaKey:r.ctrlKey),null==i.moveOnDrag&&(i.moveOnDrag=!(Ml?r.altKey:r.ctrlKey)),i}function Do(e,t,r,n){gl?setTimeout(u(Wr,e),0):e.curOp.focus=l();var i,o=Wo(e,r,n),s=e.doc.sel;e.options.dragDrop&&Jl&&!e.isReadOnly()&&"single"==r&&(i=s.contains(t))>-1&&(P((i=s.ranges[i]).from(),t)<0||t.xRel>0)&&(P(i.to(),t)>0||t.xRel<0)?Ho(e,n,t,o):Eo(e,n,t,o)}function Ho(e,t,r,n){var i=e.display,o=!1,l=dn(e,function(t){ml&&(i.scroller.draggable=!1),e.state.draggingText=!1,ke(document,"mouseup",l),ke(document,"mousemove",s),ke(i.scroller,"dragstart",a),ke(i.scroller,"drop",l),o||(We(t),n.addNew||di(e.doc,r,null,null,n.extend),ml||gl&&9==vl?setTimeout(function(){document.body.focus(),i.input.focus()},20):i.input.focus())}),s=function(e){o=o||Math.abs(t.clientX-e.clientX)+Math.abs(t.clientY-e.clientY)>=10},a=function(){return o=!0};ml&&(i.scroller.draggable=!0),e.state.draggingText=l,l.copy=!n.moveOnDrag,i.scroller.dragDrop&&i.scroller.dragDrop(),Ql(document,"mouseup",l),Ql(document,"mousemove",s),Ql(i.scroller,"dragstart",a),Ql(i.scroller,"drop",l),Dr(e),setTimeout(function(){return i.input.focus()},20)}function Fo(e,t,r){if("char"==r)return new Ts(t,t);if("word"==r)return e.findWordAt(t);if("line"==r)return new Ts(E(t.line,0),U(e.doc,E(t.line+1,0)));var n=r(e,t);return new Ts(n.from,n.to)}function Eo(e,t,r,n){function i(t){if(0!=P(m,t))if(m=t,"rectangle"==n.unit){for(var i=[],o=e.options.tabSize,l=f(M(u,r.line).text,r.ch,o),s=f(M(u,t.line).text,t.ch,o),a=Math.min(l,s),g=Math.max(l,s),v=Math.min(r.line,t.line),y=Math.min(e.lastLine(),Math.max(r.line,t.line));v<=y;v++){var b=M(u,v).text,w=d(b,a,o);a==g?i.push(new Ts(E(v,w),E(v,w))):b.length>w&&i.push(new Ts(E(v,w),E(v,d(b,g,o))))}i.length||i.push(new Ts(r,r)),bi(u,zn(p.ranges.slice(0,h).concat(i),h),{origin:"*mouse",scroll:!1}),e.scrollIntoView(t)}else{var x,C=c,S=Fo(e,t,n.unit),L=C.anchor;P(S.anchor,L)>0?(x=S.head,L=B(C.from(),S.anchor)):(x=S.anchor,L=R(C.to(),S.head));var k=p.ranges.slice(0);k[h]=Po(e,new Ts(U(u,L),x)),bi(u,zn(k,h),Ul)}}function o(t){var r=++b,s=Sr(e,t,!0,"rectangle"==n.unit);if(s)if(0!=P(s,m)){e.curOp.focus=l(),i(s);var c=Ir(a,u);(s.line>=c.to||s.line<c.from)&&setTimeout(dn(e,function(){b==r&&o(t)}),150)}else{var f=t.clientY<y.top?-20:t.clientY>y.bottom?20:0;f&&setTimeout(dn(e,function(){b==r&&(a.scroller.scrollTop+=f,o(t))}),50)}}function s(t){e.state.selectingText=!1,b=1/0,We(t),a.input.focus(),ke(document,"mousemove",w),ke(document,"mouseup",x),u.history.lastSelOrigin=null}var a=e.display,u=e.doc;We(t);var c,h,p=u.sel,g=p.ranges;if(n.addNew&&!n.extend?(h=u.sel.contains(r),c=h>-1?g[h]:new Ts(r,r)):(c=u.sel.primary(),h=u.sel.primIndex),"rectangle"==n.unit)n.addNew||(c=new Ts(r,r)),r=Sr(e,t,!0,!0),h=-1;else{var v=Fo(e,r,n.unit);c=n.extend?hi(c,v.anchor,v.head,n.extend):v}n.addNew?-1==h?(h=g.length,bi(u,zn(g.concat([c]),h),{scroll:!1,origin:"*mouse"})):g.length>1&&g[h].empty()&&"char"==n.unit&&!n.extend?(bi(u,zn(g.slice(0,h).concat(g.slice(h+1)),0),{scroll:!1,origin:"*mouse"}),p=u.sel):gi(u,h,c,Ul):(h=0,bi(u,new ks([c],0),Ul),p=u.sel);var m=r,y=a.wrapper.getBoundingClientRect(),b=0,w=dn(e,function(e){Pe(e)?o(e):s(e)}),x=dn(e,s);e.state.selectingText=x,Ql(document,"mousemove",w),Ql(document,"mouseup",x)}function Po(e,t){var r=t.anchor,n=t.head,i=M(e.doc,r.line);if(0==P(r,n)&&r.sticky==n.sticky)return t;var o=Se(i);if(!o)return t;var l=Ce(o,r.ch,r.sticky),s=o[l];if(s.from!=r.ch&&s.to!=r.ch)return t;var a=l+(s.from==r.ch==(1!=s.level)?0:1);if(0==a||a==o.length)return t;var u;if(n.line!=r.line)u=(n.line-r.line)*("ltr"==e.doc.direction?1:-1)>0;else{var c=Ce(o,n.ch,n.sticky),f=c-l||(n.ch-r.ch)*(1==s.level?-1:1);u=c==a-1||c==a?f<0:f>0}var h=o[a+(u?-1:0)],d=u==(1==h.level),p=d?h.from:h.to,g=d?"after":"before";return r.ch==p&&r.sticky==g?t:new Ts(new E(r.line,p,g),n)}function Io(e,t,r,n){var i,o;if(t.touches)i=t.touches[0].clientX,o=t.touches[0].clientY;else try{i=t.clientX,o=t.clientY}catch(t){return!1}if(i>=Math.floor(e.display.gutters.getBoundingClientRect().right))return!1;n&&We(t);var l=e.display,s=l.lineDiv.getBoundingClientRect();if(o>s.bottom||!Oe(e,r))return He(t);o-=s.top-l.viewOffset;for(var a=0;a<e.options.gutters.length;++a){var u=l.gutters.childNodes[a];if(u&&u.getBoundingClientRect().right>=i)return Te(e,r,e,D(e.doc,o),e.options.gutters[a],t),He(t)}}function zo(e,t){return Io(e,t,"gutterClick",!0)}function Ro(e,t){Ft(e.display,t)||Bo(e,t)||Me(e,t,"contextmenu")||e.display.input.onContextMenu(t)}function Bo(e,t){return!!Oe(e,"gutterContextMenu")&&Io(e,t,"gutterContextMenu",!1)}function Go(e){e.display.wrapper.className=e.display.wrapper.className.replace(/\s*cm-s-\S+/g,"")+e.options.theme.replace(/(^|\s)\s*/g," cm-s-"),er(e)}function Uo(e){Hn(e),vn(e),zr(e)}function Vo(e,t,r){if(!t!=!(r&&r!=Xs)){var n=e.display.dragFunctions,i=t?Ql:ke;i(e.display.scroller,"dragstart",n.start),i(e.display.scroller,"dragenter",n.enter),i(e.display.scroller,"dragover",n.over),i(e.display.scroller,"dragleave",n.leave),i(e.display.scroller,"drop",n.drop)}}function Ko(e){e.options.lineWrapping?(s(e.display.wrapper,"CodeMirror-wrap"),e.display.sizer.style.minWidth="",e.display.sizerWidth=null):(Fl(e.display.wrapper,"CodeMirror-wrap"),we(e)),Cr(e),vn(e),er(e),setTimeout(function(){return en(e)},100)}function jo(e,t){var r=this;if(!(this instanceof jo))return new jo(e,t);this.options=t=t?c(t):{},c(Ys,t,!1),Fn(t);var n=t.value;"string"==typeof n&&(n=new Ds(n,t.mode,null,t.lineSeparator,t.direction)),this.doc=n;var i=new jo.inputStyles[t.inputStyle](this),o=this.display=new T(e,n,i);o.wrapper.CodeMirror=this,Hn(this),Go(this),t.lineWrapping&&(this.display.wrapper.className+=" CodeMirror-wrap"),rn(this),this.state={keyMaps:[],overlays:[],modeGen:0,overwrite:!1,delayingBlurEvent:!1,focused:!1,suppressEdits:!1,pasteIncoming:!1,cutIncoming:!1,selectingText:!1,draggingText:!1,highlight:new Pl,keySeq:null,specialChars:null},t.autofocus&&!Tl&&o.input.focus(),gl&&vl<11&&setTimeout(function(){return r.display.input.reset(!0)},20),Xo(this),eo(),nn(this),this.curOp.forceUpdate=!0,qn(this,n),t.autofocus&&!Tl||this.hasFocus()?setTimeout(u(Hr,this),20):Fr(this);for(var l in _s)_s.hasOwnProperty(l)&&_s[l](r,t[l],Xs);Rr(this),t.finishInit&&t.finishInit(this);for(var s=0;s<$s.length;++s)$s[s](r);on(this),ml&&t.lineWrapping&&"optimizelegibility"==getComputedStyle(o.lineDiv).textRendering&&(o.lineDiv.style.textRendering="auto")}function Xo(e){function t(){i.activeTouch&&(o=setTimeout(function(){return i.activeTouch=null},1e3),(l=i.activeTouch).end=+new Date)}function r(e){if(1!=e.touches.length)return!1;var t=e.touches[0];return t.radiusX<=1&&t.radiusY<=1}function n(e,t){if(null==t.left)return!0;var r=t.left-e.left,n=t.top-e.top;return r*r+n*n>400}var i=e.display;Ql(i.scroller,"mousedown",dn(e,Oo)),gl&&vl<11?Ql(i.scroller,"dblclick",dn(e,function(t){if(!Me(e,t)){var r=Sr(e,t);if(r&&!zo(e,t)&&!Ft(e.display,t)){We(t);var n=e.findWordAt(r);di(e.doc,n.anchor,n.head)}}})):Ql(i.scroller,"dblclick",function(t){return Me(e,t)||We(t)}),Hl||Ql(i.scroller,"contextmenu",function(t){return Ro(e,t)});var o,l={end:0};Ql(i.scroller,"touchstart",function(t){if(!Me(e,t)&&!r(t)&&!zo(e,t)){i.input.ensurePolled(),clearTimeout(o);var n=+new Date;i.activeTouch={start:n,moved:!1,prev:n-l.end<=300?l:null},1==t.touches.length&&(i.activeTouch.left=t.touches[0].pageX,i.activeTouch.top=t.touches[0].pageY)}}),Ql(i.scroller,"touchmove",function(){i.activeTouch&&(i.activeTouch.moved=!0)}),Ql(i.scroller,"touchend",function(r){var o=i.activeTouch;if(o&&!Ft(i,r)&&null!=o.left&&!o.moved&&new Date-o.start<300){var l,s=e.coordsChar(i.activeTouch,"page");l=!o.prev||n(o,o.prev)?new Ts(s,s):!o.prev.prev||n(o,o.prev.prev)?e.findWordAt(s):new Ts(E(s.line,0),U(e.doc,E(s.line+1,0))),e.setSelection(l.anchor,l.head),e.focus(),We(r)}t()}),Ql(i.scroller,"touchcancel",t),Ql(i.scroller,"scroll",function(){i.scroller.clientHeight&&(qr(e,i.scroller.scrollTop),Qr(e,i.scroller.scrollLeft,!0),Te(e,"scroll",e))}),Ql(i.scroller,"mousewheel",function(t){return In(e,t)}),Ql(i.scroller,"DOMMouseScroll",function(t){return In(e,t)}),Ql(i.wrapper,"scroll",function(){return i.wrapper.scrollTop=i.wrapper.scrollLeft=0}),i.dragFunctions={enter:function(t){Me(e,t)||Fe(t)},over:function(t){Me(e,t)||(Zi(e,t),Fe(t))},start:function(t){return qi(e,t)},drop:dn(e,$i),leave:function(t){Me(e,t)||Qi(e)}};var s=i.input.getField();Ql(s,"keyup",function(t){return To.call(e,t)}),Ql(s,"keydown",dn(e,Lo)),Ql(s,"keypress",dn(e,Mo)),Ql(s,"focus",function(t){return Hr(e,t)}),Ql(s,"blur",function(t){return Fr(e,t)})}function Yo(e,t,r,n){var i,o=e.doc;null==r&&(r="add"),"smart"==r&&(o.mode.indent?i=$e(e,t).state:r="prev");var l=e.options.tabSize,s=M(o,t),a=f(s.text,null,l);s.stateAfter&&(s.stateAfter=null);var u,c=s.text.match(/^\s*/)[0];if(n||/\S/.test(s.text)){if("smart"==r&&((u=o.mode.indent(i,s.text.slice(c.length),s.text))==Bl||u>150)){if(!n)return;r="prev"}}else u=0,r="not";"prev"==r?u=t>o.first?f(M(o,t-1).text,null,l):0:"add"==r?u=a+e.options.indentUnit:"subtract"==r?u=a-e.options.indentUnit:"number"==typeof r&&(u=a+r),u=Math.max(0,u);var h="",d=0;if(e.options.indentWithTabs)for(var g=Math.floor(u/l);g;--g)d+=l,h+="\t";if(d<u&&(h+=p(u-d)),h!=c)return Ei(o,h,E(t,0),E(t,c.length),"+input"),s.stateAfter=null,!0;for(var v=0;v<o.sel.ranges.length;v++){var m=o.sel.ranges[v];if(m.head.line==t&&m.head.ch<c.length){var y=E(t,c.length);gi(o,v,new Ts(y,y));break}}}function _o(e){qs=e}function $o(e,t,r,n,i){var o=e.doc;e.display.shift=!1,n||(n=o.sel);var l=e.state.pasteIncoming||"paste"==i,s=es(t),a=null;if(l&&n.ranges.length>1)if(qs&&qs.text.join("\n")==t){if(n.ranges.length%qs.text.length==0){a=[];for(var u=0;u<qs.text.length;u++)a.push(o.splitLines(qs.text[u]))}}else s.length==n.ranges.length&&e.options.pasteLinesPerSelection&&(a=v(s,function(e){return[e]}));for(var c,f=n.ranges.length-1;f>=0;f--){var h=n.ranges[f],d=h.from(),p=h.to();h.empty()&&(r&&r>0?d=E(d.line,d.ch-r):e.state.overwrite&&!l?p=E(p.line,Math.min(M(o,p.line).text.length,p.ch+g(s).length)):qs&&qs.lineWise&&qs.text.join("\n")==t&&(d=p=E(d.line,0))),c=e.curOp.updateInput;var m={from:d,to:p,text:a?a[f%a.length]:s,origin:i||(l?"paste":e.state.cutIncoming?"cut":"+input")};Oi(e.doc,m),bt(e,"inputRead",e,m)}t&&!l&&Zo(e,t),jr(e),e.curOp.updateInput=c,e.curOp.typing=!0,e.state.pasteIncoming=e.state.cutIncoming=!1}function qo(e,t){var r=e.clipboardData&&e.clipboardData.getData("Text");if(r)return e.preventDefault(),t.isReadOnly()||t.options.disableInput||hn(t,function(){return $o(t,r,0,null,"paste")}),!0}function Zo(e,t){if(e.options.electricChars&&e.options.smartIndent)for(var r=e.doc.sel,n=r.ranges.length-1;n>=0;n--){var i=r.ranges[n];if(!(i.head.ch>100||n&&r.ranges[n-1].head.line==i.head.line)){var o=e.getModeAt(i.head),l=!1;if(o.electricChars){for(var s=0;s<o.electricChars.length;s++)if(t.indexOf(o.electricChars.charAt(s))>-1){l=Yo(e,i.head.line,"smart");break}}else o.electricInput&&o.electricInput.test(M(e.doc,i.head.line).text.slice(0,i.head.ch))&&(l=Yo(e,i.head.line,"smart"));l&&bt(e,"electricInput",e,i.head.line)}}}function Qo(e){for(var t=[],r=[],n=0;n<e.doc.sel.ranges.length;n++){var i=e.doc.sel.ranges[n].head.line,o={anchor:E(i,0),head:E(i+1,0)};r.push(o),t.push(e.getRange(o.anchor,o.head))}return{text:t,ranges:r}}function Jo(e,t){e.setAttribute("autocorrect","off"),e.setAttribute("autocapitalize","off"),e.setAttribute("spellcheck",!!t)}function el(){var e=n("textarea",null,null,"position: absolute; bottom: -1em; padding: 0; width: 1px; height: 1em; outline: none"),t=n("div",[e],null,"overflow: hidden; position: relative; width: 3px; height: 0px;");return ml?e.style.width="1000px":e.setAttribute("wrap","off"),Ll&&(e.style.border="1px solid black"),Jo(e),t}function tl(e,t,r,n,i){function o(){var n=t.line+r;return!(n<e.first||n>=e.first+e.size)&&(t=new E(n,t.ch,t.sticky),u=M(e,n))}function l(n){var l;if(null==(l=i?go(e.cm,u,t,r):ho(u,t,r))){if(n||!o())return!1;t=po(i,e.cm,u,t.line,r)}else t=l;return!0}var s=t,a=r,u=M(e,t.line);if("char"==n)l();else if("column"==n)l(!0);else if("word"==n||"group"==n)for(var c=null,f="group"==n,h=e.cm&&e.cm.getHelper(t,"wordChars"),d=!0;!(r<0)||l(!d);d=!1){var p=u.text.charAt(t.ch)||"\n",g=x(p,h)?"w":f&&"\n"==p?"n":!f||/\s/.test(p)?null:"p";if(!f||d||g||(g="s"),c&&c!=g){r<0&&(r=1,l(),t.sticky="after");break}if(g&&(c=g),r>0&&!l(!d))break}var v=ki(e,t,s,a,!0);return I(s,v)&&(v.hitSide=!0),v}function rl(e,t,r,n){var i,o=e.doc,l=t.left;if("page"==n){var s=Math.min(e.display.wrapper.clientHeight,window.innerHeight||document.documentElement.clientHeight),a=Math.max(s-.5*mr(e.display),3);i=(r>0?t.bottom:t.top)+r*a}else"line"==n&&(i=r>0?t.bottom+3:t.top-3);for(var u;(u=cr(e,l,i)).outside;){if(r<0?i<=0:i>=o.height){u.hitSide=!0;break}i+=5*r}return u}function nl(e,t){var r=jt(e,t.line);if(!r||r.hidden)return null;var n=M(e.doc,t.line),i=Ut(r,n,t.line),o=Se(n,e.doc.direction),l="left";o&&(l=Ce(o,t.ch)%2?"right":"left");var s=_t(i.map,t.ch,l);return s.offset="right"==s.collapse?s.end:s.start,s}function il(e){for(var t=e;t;t=t.parentNode)if(/CodeMirror-gutter-wrapper/.test(t.className))return!0;return!1}function ol(e,t){return t&&(e.bad=!0),e}function ll(e,t,r,n,i){function o(e){return function(t){return t.id==e}}function l(){c&&(u+=f,c=!1)}function s(e){e&&(l(),u+=e)}function a(t){if(1==t.nodeType){var r=t.getAttribute("cm-text");if(null!=r)return void s(r||t.textContent.replace(/\u200b/g,""));var u,h=t.getAttribute("cm-marker");if(h){var d=e.findMarks(E(n,0),E(i+1,0),o(+h));return void(d.length&&(u=d[0].find(0))&&s(N(e.doc,u.from,u.to).join(f)))}if("false"==t.getAttribute("contenteditable"))return;var p=/^(pre|div|p)$/i.test(t.nodeName);p&&l();for(var g=0;g<t.childNodes.length;g++)a(t.childNodes[g]);p&&(c=!0)}else 3==t.nodeType&&s(t.nodeValue)}for(var u="",c=!1,f=e.doc.lineSeparator();a(t),t!=r;)t=t.nextSibling;return u}function sl(e,t,r){var n;if(t==e.display.lineDiv){if(!(n=e.display.lineDiv.childNodes[r]))return ol(e.clipPos(E(e.display.viewTo-1)),!0);t=null,r=0}else for(n=t;;n=n.parentNode){if(!n||n==e.display.lineDiv)return null;if(n.parentNode&&n.parentNode==e.display.lineDiv)break}for(var i=0;i<e.display.view.length;i++){var o=e.display.view[i];if(o.node==n)return al(o,t,r)}}function al(e,t,r){function n(t,r,n){for(var i=-1;i<(f?f.length:0);i++)for(var o=i<0?c.map:f[i],l=0;l<o.length;l+=3){var s=o[l+2];if(s==t||s==r){var a=W(i<0?e.line:e.rest[i]),u=o[l]+n;return(n<0||s!=t)&&(u=o[l+(n?1:0)]),E(a,u)}}}var i=e.text.firstChild,l=!1;if(!t||!o(i,t))return ol(E(W(e.line),0),!0);if(t==i&&(l=!0,t=i.childNodes[r],r=0,!t)){var s=e.rest?g(e.rest):e.line;return ol(E(W(s),s.text.length),l)}var a=3==t.nodeType?t:null,u=t;for(a||1!=t.childNodes.length||3!=t.firstChild.nodeType||(a=t.firstChild,r&&(r=a.nodeValue.length));u.parentNode!=i;)u=u.parentNode;var c=e.measure,f=c.maps,h=n(a,u,r);if(h)return ol(h,l);for(var d=u.nextSibling,p=a?a.nodeValue.length-r:0;d;d=d.nextSibling){if(h=n(d,d.firstChild,0))return ol(E(h.line,h.ch-p),l);p+=d.textContent.length}for(var v=u.previousSibling,m=r;v;v=v.previousSibling){if(h=n(v,v.firstChild,-1))return ol(E(h.line,h.ch+m),l);m+=v.textContent.length}}var ul=navigator.userAgent,cl=navigator.platform,fl=/gecko\/\d/i.test(ul),hl=/MSIE \d/.test(ul),dl=/Trident\/(?:[7-9]|\d{2,})\..*rv:(\d+)/.exec(ul),pl=/Edge\/(\d+)/.exec(ul),gl=hl||dl||pl,vl=gl&&(hl?document.documentMode||6:+(pl||dl)[1]),ml=!pl&&/WebKit\//.test(ul),yl=ml&&/Qt\/\d+\.\d+/.test(ul),bl=!pl&&/Chrome\//.test(ul),wl=/Opera\//.test(ul),xl=/Apple Computer/.test(navigator.vendor),Cl=/Mac OS X 1\d\D([8-9]|\d\d)\D/.test(ul),Sl=/PhantomJS/.test(ul),Ll=!pl&&/AppleWebKit/.test(ul)&&/Mobile\/\w+/.test(ul),kl=/Android/.test(ul),Tl=Ll||kl||/webOS|BlackBerry|Opera Mini|Opera Mobi|IEMobile/i.test(ul),Ml=Ll||/Mac/.test(cl),Nl=/\bCrOS\b/.test(ul),Ol=/win/i.test(cl),Al=wl&&ul.match(/Version\/(\d*\.\d*)/);Al&&(Al=Number(Al[1])),Al&&Al>=15&&(wl=!1,ml=!0);var Wl,Dl=Ml&&(yl||wl&&(null==Al||Al<12.11)),Hl=fl||gl&&vl>=9,Fl=function(t,r){var n=t.className,i=e(r).exec(n);if(i){var o=n.slice(i.index+i[0].length);t.className=n.slice(0,i.index)+(o?i[1]+o:"")}};Wl=document.createRange?function(e,t,r,n){var i=document.createRange();return i.setEnd(n||e,r),i.setStart(e,t),i}:function(e,t,r){var n=document.body.createTextRange();try{n.moveToElementText(e.parentNode)}catch(e){return n}return n.collapse(!0),n.moveEnd("character",r),n.moveStart("character",t),n};var El=function(e){e.select()};Ll?El=function(e){e.selectionStart=0,e.selectionEnd=e.value.length}:gl&&(El=function(e){try{e.select()}catch(e){}});var Pl=function(){this.id=null};Pl.prototype.set=function(e,t){clearTimeout(this.id),this.id=setTimeout(t,e)};var Il,zl,Rl=30,Bl={toString:function(){return"CodeMirror.Pass"}},Gl={scroll:!1},Ul={origin:"*mouse"},Vl={origin:"+move"},Kl=[""],jl=/[\u00df\u0587\u0590-\u05f4\u0600-\u06ff\u3040-\u309f\u30a0-\u30ff\u3400-\u4db5\u4e00-\u9fcc\uac00-\ud7af]/,Xl=/[\u0300-\u036f\u0483-\u0489\u0591-\u05bd\u05bf\u05c1\u05c2\u05c4\u05c5\u05c7\u0610-\u061a\u064b-\u065e\u0670\u06d6-\u06dc\u06de-\u06e4\u06e7\u06e8\u06ea-\u06ed\u0711\u0730-\u074a\u07a6-\u07b0\u07eb-\u07f3\u0816-\u0819\u081b-\u0823\u0825-\u0827\u0829-\u082d\u0900-\u0902\u093c\u0941-\u0948\u094d\u0951-\u0955\u0962\u0963\u0981\u09bc\u09be\u09c1-\u09c4\u09cd\u09d7\u09e2\u09e3\u0a01\u0a02\u0a3c\u0a41\u0a42\u0a47\u0a48\u0a4b-\u0a4d\u0a51\u0a70\u0a71\u0a75\u0a81\u0a82\u0abc\u0ac1-\u0ac5\u0ac7\u0ac8\u0acd\u0ae2\u0ae3\u0b01\u0b3c\u0b3e\u0b3f\u0b41-\u0b44\u0b4d\u0b56\u0b57\u0b62\u0b63\u0b82\u0bbe\u0bc0\u0bcd\u0bd7\u0c3e-\u0c40\u0c46-\u0c48\u0c4a-\u0c4d\u0c55\u0c56\u0c62\u0c63\u0cbc\u0cbf\u0cc2\u0cc6\u0ccc\u0ccd\u0cd5\u0cd6\u0ce2\u0ce3\u0d3e\u0d41-\u0d44\u0d4d\u0d57\u0d62\u0d63\u0dca\u0dcf\u0dd2-\u0dd4\u0dd6\u0ddf\u0e31\u0e34-\u0e3a\u0e47-\u0e4e\u0eb1\u0eb4-\u0eb9\u0ebb\u0ebc\u0ec8-\u0ecd\u0f18\u0f19\u0f35\u0f37\u0f39\u0f71-\u0f7e\u0f80-\u0f84\u0f86\u0f87\u0f90-\u0f97\u0f99-\u0fbc\u0fc6\u102d-\u1030\u1032-\u1037\u1039\u103a\u103d\u103e\u1058\u1059\u105e-\u1060\u1071-\u1074\u1082\u1085\u1086\u108d\u109d\u135f\u1712-\u1714\u1732-\u1734\u1752\u1753\u1772\u1773\u17b7-\u17bd\u17c6\u17c9-\u17d3\u17dd\u180b-\u180d\u18a9\u1920-\u1922\u1927\u1928\u1932\u1939-\u193b\u1a17\u1a18\u1a56\u1a58-\u1a5e\u1a60\u1a62\u1a65-\u1a6c\u1a73-\u1a7c\u1a7f\u1b00-\u1b03\u1b34\u1b36-\u1b3a\u1b3c\u1b42\u1b6b-\u1b73\u1b80\u1b81\u1ba2-\u1ba5\u1ba8\u1ba9\u1c2c-\u1c33\u1c36\u1c37\u1cd0-\u1cd2\u1cd4-\u1ce0\u1ce2-\u1ce8\u1ced\u1dc0-\u1de6\u1dfd-\u1dff\u200c\u200d\u20d0-\u20f0\u2cef-\u2cf1\u2de0-\u2dff\u302a-\u302f\u3099\u309a\ua66f-\ua672\ua67c\ua67d\ua6f0\ua6f1\ua802\ua806\ua80b\ua825\ua826\ua8c4\ua8e0-\ua8f1\ua926-\ua92d\ua947-\ua951\ua980-\ua982\ua9b3\ua9b6-\ua9b9\ua9bc\uaa29-\uaa2e\uaa31\uaa32\uaa35\uaa36\uaa43\uaa4c\uaab0\uaab2-\uaab4\uaab7\uaab8\uaabe\uaabf\uaac1\uabe5\uabe8\uabed\udc00-\udfff\ufb1e\ufe00-\ufe0f\ufe20-\ufe26\uff9e\uff9f]/,Yl=!1,_l=!1,$l=null,ql=function(){function e(e){return e<=247?r.charAt(e):1424<=e&&e<=1524?"R":1536<=e&&e<=1785?n.charAt(e-1536):1774<=e&&e<=2220?"r":8192<=e&&e<=8203?"w":8204==e?"b":"L"}function t(e,t,r){this.level=e,this.from=t,this.to=r}var r="bbbbbbbbbtstwsbbbbbbbbbbbbbbssstwNN%%%NNNNNN,N,N1111111111NNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNbbbbbbsbbbbbbbbbbbbbbbbbbbbbbbbbb,N%%%%NNNNLNNNNN%%11NLNNN1LNNNNNLLLLLLLLLLLLLLLLLLLLLLLNLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLN",n="nnnnnnNNr%%r,rNNmmmmmmmmmmmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmmmmmmmmmmmmmmmnnnnnnnnnn%nnrrrmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmnNmmmmmmrrmmNmmmmrr1111111111",i=/[\u0590-\u05f4\u0600-\u06ff\u0700-\u08ac]/,o=/[stwN]/,l=/[LRr]/,s=/[Lb1n]/,a=/[1n]/;return function(r,n){var u="ltr"==n?"L":"R";if(0==r.length||"ltr"==n&&!i.test(r))return!1;for(var c=r.length,f=[],h=0;h<c;++h)f.push(e(r.charCodeAt(h)));for(var d=0,p=u;d<c;++d){var v=f[d];"m"==v?f[d]=p:p=v}for(var m=0,y=u;m<c;++m){var b=f[m];"1"==b&&"r"==y?f[m]="n":l.test(b)&&(y=b,"r"==b&&(f[m]="R"))}for(var w=1,x=f[0];w<c-1;++w){var C=f[w];"+"==C&&"1"==x&&"1"==f[w+1]?f[w]="1":","!=C||x!=f[w+1]||"1"!=x&&"n"!=x||(f[w]=x),x=C}for(var S=0;S<c;++S){var L=f[S];if(","==L)f[S]="N";else if("%"==L){var k=void 0;for(k=S+1;k<c&&"%"==f[k];++k);for(var T=S&&"!"==f[S-1]||k<c&&"1"==f[k]?"1":"N",M=S;M<k;++M)f[M]=T;S=k-1}}for(var N=0,O=u;N<c;++N){var A=f[N];"L"==O&&"1"==A?f[N]="L":l.test(A)&&(O=A)}for(var W=0;W<c;++W)if(o.test(f[W])){var D=void 0;for(D=W+1;D<c&&o.test(f[D]);++D);for(var H="L"==(W?f[W-1]:u),F=H==("L"==(D<c?f[D]:u))?H?"L":"R":u,E=W;E<D;++E)f[E]=F;W=D-1}for(var P,I=[],z=0;z<c;)if(s.test(f[z])){var R=z;for(++z;z<c&&s.test(f[z]);++z);I.push(new t(0,R,z))}else{var B=z,G=I.length;for(++z;z<c&&"L"!=f[z];++z);for(var U=B;U<z;)if(a.test(f[U])){B<U&&I.splice(G,0,new t(1,B,U));var V=U;for(++U;U<z&&a.test(f[U]);++U);I.splice(G,0,new t(2,V,U)),B=U}else++U;B<z&&I.splice(G,0,new t(1,B,z))}return 1==I[0].level&&(P=r.match(/^\s+/))&&(I[0].from=P[0].length,I.unshift(new t(0,0,P[0].length))),1==g(I).level&&(P=r.match(/\s+$/))&&(g(I).to-=P[0].length,I.push(new t(0,c-P[0].length,c))),"rtl"==n?I.reverse():I}}(),Zl=[],Ql=function(e,t,r){if(e.addEventListener)e.addEventListener(t,r,!1);else if(e.attachEvent)e.attachEvent("on"+t,r);else{var n=e._handlers||(e._handlers={});n[t]=(n[t]||Zl).concat(r)}},Jl=function(){if(gl&&vl<9)return!1;var e=n("div");return"draggable"in e||"dragDrop"in e}(),es=3!="\n\nb".split(/\n/).length?function(e){for(var t=0,r=[],n=e.length;t<=n;){var i=e.indexOf("\n",t);-1==i&&(i=e.length);var o=e.slice(t,"\r"==e.charAt(i-1)?i-1:i),l=o.indexOf("\r");-1!=l?(r.push(o.slice(0,l)),t+=l+1):(r.push(o),t=i+1)}return r}:function(e){return e.split(/\r\n?|\n/)},ts=window.getSelection?function(e){try{return e.selectionStart!=e.selectionEnd}catch(e){return!1}}:function(e){var t;try{t=e.ownerDocument.selection.createRange()}catch(e){}return!(!t||t.parentElement()!=e)&&0!=t.compareEndPoints("StartToEnd",t)},rs=function(){var e=n("div");return"oncopy"in e||(e.setAttribute("oncopy","return;"),"function"==typeof e.oncopy)}(),ns=null,is={},os={},ls={},ss=function(e,t,r){this.pos=this.start=0,this.string=e,this.tabSize=t||8,this.lastColumnPos=this.lastColumnValue=0,this.lineStart=0,this.lineOracle=r};ss.prototype.eol=function(){return this.pos>=this.string.length},ss.prototype.sol=function(){return this.pos==this.lineStart},ss.prototype.peek=function(){return this.string.charAt(this.pos)||void 0},ss.prototype.next=function(){if(this.pos<this.string.length)return this.string.charAt(this.pos++)},ss.prototype.eat=function(e){var t=this.string.charAt(this.pos);if("string"==typeof e?t==e:t&&(e.test?e.test(t):e(t)))return++this.pos,t},ss.prototype.eatWhile=function(e){for(var t=this.pos;this.eat(e););return this.pos>t},ss.prototype.eatSpace=function(){for(var e=this,t=this.pos;/[\s\u00a0]/.test(this.string.charAt(this.pos));)++e.pos;return this.pos>t},ss.prototype.skipToEnd=function(){this.pos=this.string.length},ss.prototype.skipTo=function(e){var t=this.string.indexOf(e,this.pos);if(t>-1)return this.pos=t,!0},ss.prototype.backUp=function(e){this.pos-=e},ss.prototype.column=function(){return this.lastColumnPos<this.start&&(this.lastColumnValue=f(this.string,this.start,this.tabSize,this.lastColumnPos,this.lastColumnValue),this.lastColumnPos=this.start),this.lastColumnValue-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.indentation=function(){return f(this.string,null,this.tabSize)-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.match=function(e,t,r){if("string"!=typeof e){var n=this.string.slice(this.pos).match(e);return n&&n.index>0?null:(n&&!1!==t&&(this.pos+=n[0].length),n)}var i=function(e){return r?e.toLowerCase():e};if(i(this.string.substr(this.pos,e.length))==i(e))return!1!==t&&(this.pos+=e.length),!0},ss.prototype.current=function(){return this.string.slice(this.start,this.pos)},ss.prototype.hideFirstChars=function(e,t){this.lineStart+=e;try{return t()}finally{this.lineStart-=e}},ss.prototype.lookAhead=function(e){var t=this.lineOracle;return t&&t.lookAhead(e)};var as=function(e,t){this.state=e,this.lookAhead=t},us=function(e,t,r,n){this.state=t,this.doc=e,this.line=r,this.maxLookAhead=n||0};us.prototype.lookAhead=function(e){var t=this.doc.getLine(this.line+e);return null!=t&&e>this.maxLookAhead&&(this.maxLookAhead=e),t},us.prototype.nextLine=function(){this.line++,this.maxLookAhead>0&&this.maxLookAhead--},us.fromSaved=function(e,t,r){return t instanceof as?new us(e,Ke(e.mode,t.state),r,t.lookAhead):new us(e,Ke(e.mode,t),r)},us.prototype.save=function(e){var t=!1!==e?Ke(this.doc.mode,this.state):this.state;return this.maxLookAhead>0?new as(t,this.maxLookAhead):t};var cs=function(e,t,r){this.start=e.start,this.end=e.pos,this.string=e.current(),this.type=t||null,this.state=r},fs=function(e,t,r){this.text=e,ne(this,t),this.height=r?r(this):1};fs.prototype.lineNo=function(){return W(this)},Ae(fs);var hs,ds={},ps={},gs=null,vs=null,ms={left:0,right:0,top:0,bottom:0},ys=function(e,t,r){this.cm=r;var i=this.vert=n("div",[n("div",null,null,"min-width: 1px")],"CodeMirror-vscrollbar"),o=this.horiz=n("div",[n("div",null,null,"height: 100%; min-height: 1px")],"CodeMirror-hscrollbar");e(i),e(o),Ql(i,"scroll",function(){i.clientHeight&&t(i.scrollTop,"vertical")}),Ql(o,"scroll",function(){o.clientWidth&&t(o.scrollLeft,"horizontal")}),this.checkedZeroWidth=!1,gl&&vl<8&&(this.horiz.style.minHeight=this.vert.style.minWidth="18px")};ys.prototype.update=function(e){var t=e.scrollWidth>e.clientWidth+1,r=e.scrollHeight>e.clientHeight+1,n=e.nativeBarWidth;if(r){this.vert.style.display="block",this.vert.style.bottom=t?n+"px":"0";var i=e.viewHeight-(t?n:0);this.vert.firstChild.style.height=Math.max(0,e.scrollHeight-e.clientHeight+i)+"px"}else this.vert.style.display="",this.vert.firstChild.style.height="0";if(t){this.horiz.style.display="block",this.horiz.style.right=r?n+"px":"0",this.horiz.style.left=e.barLeft+"px";var o=e.viewWidth-e.barLeft-(r?n:0);this.horiz.firstChild.style.width=Math.max(0,e.scrollWidth-e.clientWidth+o)+"px"}else this.horiz.style.display="",this.horiz.firstChild.style.width="0";return!this.checkedZeroWidth&&e.clientHeight>0&&(0==n&&this.zeroWidthHack(),this.checkedZeroWidth=!0),{right:r?n:0,bottom:t?n:0}},ys.prototype.setScrollLeft=function(e){this.horiz.scrollLeft!=e&&(this.horiz.scrollLeft=e),this.disableHoriz&&this.enableZeroWidthBar(this.horiz,this.disableHoriz,"horiz")},ys.prototype.setScrollTop=function(e){this.vert.scrollTop!=e&&(this.vert.scrollTop=e),this.disableVert&&this.enableZeroWidthBar(this.vert,this.disableVert,"vert")},ys.prototype.zeroWidthHack=function(){var e=Ml&&!Cl?"12px":"18px";this.horiz.style.height=this.vert.style.width=e,this.horiz.style.pointerEvents=this.vert.style.pointerEvents="none",this.disableHoriz=new Pl,this.disableVert=new Pl},ys.prototype.enableZeroWidthBar=function(e,t,r){function n(){var i=e.getBoundingClientRect();("vert"==r?document.elementFromPoint(i.right-1,(i.top+i.bottom)/2):document.elementFromPoint((i.right+i.left)/2,i.bottom-1))!=e?e.style.pointerEvents="none":t.set(1e3,n)}e.style.pointerEvents="auto",t.set(1e3,n)},ys.prototype.clear=function(){var e=this.horiz.parentNode;e.removeChild(this.horiz),e.removeChild(this.vert)};var bs=function(){};bs.prototype.update=function(){return{bottom:0,right:0}},bs.prototype.setScrollLeft=function(){},bs.prototype.setScrollTop=function(){},bs.prototype.clear=function(){};var ws={native:ys,null:bs},xs=0,Cs=function(e,t,r){var n=e.display;this.viewport=t,this.visible=Ir(n,e.doc,t),this.editorIsHidden=!n.wrapper.offsetWidth,this.wrapperHeight=n.wrapper.clientHeight,this.wrapperWidth=n.wrapper.clientWidth,this.oldDisplayWidth=Rt(e),this.force=r,this.dims=br(e),this.events=[]};Cs.prototype.signal=function(e,t){Oe(e,t)&&this.events.push(arguments)},Cs.prototype.finish=function(){for(var e=this,t=0;t<this.events.length;t++)Te.apply(null,e.events[t])};var Ss=0,Ls=null;gl?Ls=-.53:fl?Ls=15:bl?Ls=-.7:xl&&(Ls=-1/3);var ks=function(e,t){this.ranges=e,this.primIndex=t};ks.prototype.primary=function(){return this.ranges[this.primIndex]},ks.prototype.equals=function(e){var t=this;if(e==this)return!0;if(e.primIndex!=this.primIndex||e.ranges.length!=this.ranges.length)return!1;for(var r=0;r<this.ranges.length;r++){var n=t.ranges[r],i=e.ranges[r];if(!I(n.anchor,i.anchor)||!I(n.head,i.head))return!1}return!0},ks.prototype.deepCopy=function(){for(var e=this,t=[],r=0;r<this.ranges.length;r++)t[r]=new Ts(z(e.ranges[r].anchor),z(e.ranges[r].head));return new ks(t,this.primIndex)},ks.prototype.somethingSelected=function(){for(var e=this,t=0;t<this.ranges.length;t++)if(!e.ranges[t].empty())return!0;return!1},ks.prototype.contains=function(e,t){var r=this;t||(t=e);for(var n=0;n<this.ranges.length;n++){var i=r.ranges[n];if(P(t,i.from())>=0&&P(e,i.to())<=0)return n}return-1};var Ts=function(e,t){this.anchor=e,this.head=t};Ts.prototype.from=function(){return B(this.anchor,this.head)},Ts.prototype.to=function(){return R(this.anchor,this.head)},Ts.prototype.empty=function(){return this.head.line==this.anchor.line&&this.head.ch==this.anchor.ch},Bi.prototype={chunkSize:function(){return this.lines.length},removeInner:function(e,t){for(var r=this,n=e,i=e+t;n<i;++n){var o=r.lines[n];r.height-=o.height,ot(o),bt(o,"delete")}this.lines.splice(e,t)},collapse:function(e){e.push.apply(e,this.lines)},insertInner:function(e,t,r){var n=this;this.height+=r,this.lines=this.lines.slice(0,e).concat(t).concat(this.lines.slice(e));for(var i=0;i<t.length;++i)t[i].parent=n},iterN:function(e,t,r){for(var n=this,i=e+t;e<i;++e)if(r(n.lines[e]))return!0}},Gi.prototype={chunkSize:function(){return this.size},removeInner:function(e,t){var r=this;this.size-=t;for(var n=0;n<this.children.length;++n){var i=r.children[n],o=i.chunkSize();if(e<o){var l=Math.min(t,o-e),s=i.height;if(i.removeInner(e,l),r.height-=s-i.height,o==l&&(r.children.splice(n--,1),i.parent=null),0==(t-=l))break;e=0}else e-=o}if(this.size-t<25&&(this.children.length>1||!(this.children[0]instanceof Bi))){var a=[];this.collapse(a),this.children=[new Bi(a)],this.children[0].parent=this}},collapse:function(e){for(var t=this,r=0;r<this.children.length;++r)t.children[r].collapse(e)},insertInner:function(e,t,r){var n=this;this.size+=t.length,this.height+=r;for(var i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<=l){if(o.insertInner(e,t,r),o.lines&&o.lines.length>50){for(var s=o.lines.length%25+25,a=s;a<o.lines.length;){var u=new Bi(o.lines.slice(a,a+=25));o.height-=u.height,n.children.splice(++i,0,u),u.parent=n}o.lines=o.lines.slice(0,s),n.maybeSpill()}break}e-=l}},maybeSpill:function(){if(!(this.children.length<=10)){var e=this;do{var t=new Gi(e.children.splice(e.children.length-5,5));if(e.parent){e.size-=t.size,e.height-=t.height;var r=h(e.parent.children,e);e.parent.children.splice(r+1,0,t)}else{var n=new Gi(e.children);n.parent=e,e.children=[n,t],e=n}t.parent=e.parent}while(e.children.length>10);e.parent.maybeSpill()}},iterN:function(e,t,r){for(var n=this,i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<l){var s=Math.min(t,l-e);if(o.iterN(e,s,r))return!0;if(0==(t-=s))break;e=0}else e-=l}}};var Ms=function(e,t,r){var n=this;if(r)for(var i in r)r.hasOwnProperty(i)&&(n[i]=r[i]);this.doc=e,this.node=t};Ms.prototype.clear=function(){var e=this,t=this.doc.cm,r=this.line.widgets,n=this.line,i=W(n);if(null!=i&&r){for(var o=0;o<r.length;++o)r[o]==e&&r.splice(o--,1);r.length||(n.widgets=null);var l=Ht(this);A(n,Math.max(0,n.height-l)),t&&(hn(t,function(){Ui(t,n,-l),mn(t,i,"widget")}),bt(t,"lineWidgetCleared",t,this,i))}},Ms.prototype.changed=function(){var e=this,t=this.height,r=this.doc.cm,n=this.line;this.height=null;var i=Ht(this)-t;i&&(A(n,n.height+i),r&&hn(r,function(){r.curOp.forceUpdate=!0,Ui(r,n,i),bt(r,"lineWidgetChanged",r,e,W(n))}))},Ae(Ms);var Ns=0,Os=function(e,t){this.lines=[],this.type=t,this.doc=e,this.id=++Ns};Os.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){var t=this.doc.cm,r=t&&!t.curOp;if(r&&nn(t),Oe(this,"clear")){var n=this.find();n&&bt(this,"clear",n.from,n.to)}for(var i=null,o=null,l=0;l<this.lines.length;++l){var s=e.lines[l],a=_(s.markedSpans,e);t&&!e.collapsed?mn(t,W(s),"text"):t&&(null!=a.to&&(o=W(s)),null!=a.from&&(i=W(s))),s.markedSpans=$(s.markedSpans,a),null==a.from&&e.collapsed&&!ve(e.doc,s)&&t&&A(s,mr(t.display))}if(t&&this.collapsed&&!t.options.lineWrapping)for(var u=0;u<this.lines.length;++u){var c=fe(e.lines[u]),f=be(c);f>t.display.maxLineLength&&(t.display.maxLine=c,t.display.maxLineLength=f,t.display.maxLineChanged=!0)}null!=i&&t&&this.collapsed&&vn(t,i,o+1),this.lines.length=0,this.explicitlyCleared=!0,this.atomic&&this.doc.cantEdit&&(this.doc.cantEdit=!1,t&&Ci(t.doc)),t&&bt(t,"markerCleared",t,this,i,o),r&&on(t),this.parent&&this.parent.clear()}},Os.prototype.find=function(e,t){var r=this;null==e&&"bookmark"==this.type&&(e=1);for(var n,i,o=0;o<this.lines.length;++o){var l=r.lines[o],s=_(l.markedSpans,r);if(null!=s.from&&(n=E(t?l:W(l),s.from),-1==e))return n;if(null!=s.to&&(i=E(t?l:W(l),s.to),1==e))return i}return n&&{from:n,to:i}},Os.prototype.changed=function(){var e=this,t=this.find(-1,!0),r=this,n=this.doc.cm;t&&n&&hn(n,function(){var i=t.line,o=W(t.line),l=jt(n,o);if(l&&(Qt(l),n.curOp.selectionChanged=n.curOp.forceUpdate=!0),n.curOp.updateMaxLine=!0,!ve(r.doc,i)&&null!=r.height){var s=r.height;r.height=null;var a=Ht(r)-s;a&&A(i,i.height+a)}bt(n,"markerChanged",n,e)})},Os.prototype.attachLine=function(e){if(!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;t.maybeHiddenMarkers&&-1!=h(t.maybeHiddenMarkers,this)||(t.maybeUnhiddenMarkers||(t.maybeUnhiddenMarkers=[])).push(this)}this.lines.push(e)},Os.prototype.detachLine=function(e){if(this.lines.splice(h(this.lines,e),1),!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;(t.maybeHiddenMarkers||(t.maybeHiddenMarkers=[])).push(this)}},Ae(Os);var As=function(e,t){var r=this;this.markers=e,this.primary=t;for(var n=0;n<e.length;++n)e[n].parent=r};As.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){this.explicitlyCleared=!0;for(var t=0;t<this.markers.length;++t)e.markers[t].clear();bt(this,"clear")}},As.prototype.find=function(e,t){return this.primary.find(e,t)},Ae(As);var Ws=0,Ds=function(e,t,r,n,i){if(!(this instanceof Ds))return new Ds(e,t,r,n,i);null==r&&(r=0),Gi.call(this,[new Bi([new fs("",null)])]),this.first=r,this.scrollTop=this.scrollLeft=0,this.cantEdit=!1,this.cleanGeneration=1,this.modeFrontier=this.highlightFrontier=r;var o=E(r,0);this.sel=Rn(o),this.history=new Jn(null),this.id=++Ws,this.modeOption=t,this.lineSep=n,this.direction="rtl"==i?"rtl":"ltr",this.extend=!1,"string"==typeof e&&(e=this.splitLines(e)),_n(this,{from:o,to:o,text:e}),bi(this,Rn(o),Gl)};Ds.prototype=b(Gi.prototype,{constructor:Ds,iter:function(e,t,r){r?this.iterN(e-this.first,t-e,r):this.iterN(this.first,this.first+this.size,e)},insert:function(e,t){for(var r=0,n=0;n<t.length;++n)r+=t[n].height;this.insertInner(e-this.first,t,r)},remove:function(e,t){this.removeInner(e-this.first,t)},getValue:function(e){var t=O(this,this.first,this.first+this.size);return!1===e?t:t.join(e||this.lineSeparator())},setValue:gn(function(e){var t=E(this.first,0),r=this.first+this.size-1;Oi(this,{from:t,to:E(r,M(this,r).text.length),text:this.splitLines(e),origin:"setValue",full:!0},!0),this.cm&&Xr(this.cm,0,0),bi(this,Rn(t),Gl)}),replaceRange:function(e,t,r,n){Ei(this,e,t=U(this,t),r=r?U(this,r):t,n)},getRange:function(e,t,r){var n=N(this,U(this,e),U(this,t));return!1===r?n:n.join(r||this.lineSeparator())},getLine:function(e){var t=this.getLineHandle(e);return t&&t.text},getLineHandle:function(e){if(H(this,e))return M(this,e)},getLineNumber:function(e){return W(e)},getLineHandleVisualStart:function(e){return"number"==typeof e&&(e=M(this,e)),fe(e)},lineCount:function(){return this.size},firstLine:function(){return this.first},lastLine:function(){return this.first+this.size-1},clipPos:function(e){return U(this,e)},getCursor:function(e){var t=this.sel.primary();return null==e||"head"==e?t.head:"anchor"==e?t.anchor:"end"==e||"to"==e||!1===e?t.to():t.from()},listSelections:function(){return this.sel.ranges},somethingSelected:function(){return this.sel.somethingSelected()},setCursor:gn(function(e,t,r){vi(this,U(this,"number"==typeof e?E(e,t||0):e),null,r)}),setSelection:gn(function(e,t,r){vi(this,U(this,e),U(this,t||e),r)}),extendSelection:gn(function(e,t,r){di(this,U(this,e),t&&U(this,t),r)}),extendSelections:gn(function(e,t){pi(this,K(this,e),t)}),extendSelectionsBy:gn(function(e,t){pi(this,K(this,v(this.sel.ranges,e)),t)}),setSelections:gn(function(e,t,r){var n=this;if(e.length){for(var i=[],o=0;o<e.length;o++)i[o]=new Ts(U(n,e[o].anchor),U(n,e[o].head));null==t&&(t=Math.min(e.length-1,this.sel.primIndex)),bi(this,zn(i,t),r)}}),addSelection:gn(function(e,t,r){var n=this.sel.ranges.slice(0);n.push(new Ts(U(this,e),U(this,t||e))),bi(this,zn(n,n.length-1),r)}),getSelection:function(e){for(var t,r=this,n=this.sel.ranges,i=0;i<n.length;i++){var o=N(r,n[i].from(),n[i].to());t=t?t.concat(o):o}return!1===e?t:t.join(e||this.lineSeparator())},getSelections:function(e){for(var t=this,r=[],n=this.sel.ranges,i=0;i<n.length;i++){var o=N(t,n[i].from(),n[i].to());!1!==e&&(o=o.join(e||t.lineSeparator())),r[i]=o}return r},replaceSelection:function(e,t,r){for(var n=[],i=0;i<this.sel.ranges.length;i++)n[i]=e;this.replaceSelections(n,t,r||"+input")},replaceSelections:gn(function(e,t,r){for(var n=this,i=[],o=this.sel,l=0;l<o.ranges.length;l++){var s=o.ranges[l];i[l]={from:s.from(),to:s.to(),text:n.splitLines(e[l]),origin:r}}for(var a=t&&"end"!=t&&Kn(this,i,t),u=i.length-1;u>=0;u--)Oi(n,i[u]);a?yi(this,a):this.cm&&jr(this.cm)}),undo:gn(function(){Wi(this,"undo")}),redo:gn(function(){Wi(this,"redo")}),undoSelection:gn(function(){Wi(this,"undo",!0)}),redoSelection:gn(function(){Wi(this,"redo",!0)}),setExtending:function(e){this.extend=e},getExtending:function(){return this.extend},historySize:function(){for(var e=this.history,t=0,r=0,n=0;n<e.done.length;n++)e.done[n].ranges||++t;for(var i=0;i<e.undone.length;i++)e.undone[i].ranges||++r;return{undo:t,redo:r}},clearHistory:function(){this.history=new Jn(this.history.maxGeneration)},markClean:function(){this.cleanGeneration=this.changeGeneration(!0)},changeGeneration:function(e){return e&&(this.history.lastOp=this.history.lastSelOp=this.history.lastOrigin=null),this.history.generation},isClean:function(e){return this.history.generation==(e||this.cleanGeneration)},getHistory:function(){return{done:fi(this.history.done),undone:fi(this.history.undone)}},setHistory:function(e){var t=this.history=new Jn(this.history.maxGeneration);t.done=fi(e.done.slice(0),null,!0),t.undone=fi(e.undone.slice(0),null,!0)},setGutterMarker:gn(function(e,t,r){return Ri(this,e,"gutter",function(e){var n=e.gutterMarkers||(e.gutterMarkers={});return n[t]=r,!r&&C(n)&&(e.gutterMarkers=null),!0})}),clearGutter:gn(function(e){var t=this;this.iter(function(r){r.gutterMarkers&&r.gutterMarkers[e]&&Ri(t,r,"gutter",function(){return r.gutterMarkers[e]=null,C(r.gutterMarkers)&&(r.gutterMarkers=null),!0})})}),lineInfo:function(e){var t;if("number"==typeof e){if(!H(this,e))return null;if(t=e,!(e=M(this,e)))return null}else if(null==(t=W(e)))return null;return{line:t,handle:e,text:e.text,gutterMarkers:e.gutterMarkers,textClass:e.textClass,bgClass:e.bgClass,wrapClass:e.wrapClass,widgets:e.widgets}},addLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass";if(t[i]){if(e(n).test(t[i]))return!1;t[i]+=" "+n}else t[i]=n;return!0})}),removeLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass",o=t[i];if(!o)return!1;if(null==n)t[i]=null;else{var l=o.match(e(n));if(!l)return!1;var s=l.index+l[0].length;t[i]=o.slice(0,l.index)+(l.index&&s!=o.length?" ":"")+o.slice(s)||null}return!0})}),addLineWidget:gn(function(e,t,r){return Vi(this,e,t,r)}),removeLineWidget:function(e){e.clear()},markText:function(e,t,r){return Ki(this,U(this,e),U(this,t),r,r&&r.type||"range")},setBookmark:function(e,t){var r={replacedWith:t&&(null==t.nodeType?t.widget:t),insertLeft:t&&t.insertLeft,clearWhenEmpty:!1,shared:t&&t.shared,handleMouseEvents:t&&t.handleMouseEvents};return e=U(this,e),Ki(this,e,e,r,"bookmark")},findMarksAt:function(e){var t=[],r=M(this,(e=U(this,e)).line).markedSpans;if(r)for(var n=0;n<r.length;++n){var i=r[n];(null==i.from||i.from<=e.ch)&&(null==i.to||i.to>=e.ch)&&t.push(i.marker.parent||i.marker)}return t},findMarks:function(e,t,r){e=U(this,e),t=U(this,t);var n=[],i=e.line;return this.iter(e.line,t.line+1,function(o){var l=o.markedSpans;if(l)for(var s=0;s<l.length;s++){var a=l[s];null!=a.to&&i==e.line&&e.ch>=a.to||null==a.from&&i!=e.line||null!=a.from&&i==t.line&&a.from>=t.ch||r&&!r(a.marker)||n.push(a.marker.parent||a.marker)}++i}),n},getAllMarks:function(){var e=[];return this.iter(function(t){var r=t.markedSpans;if(r)for(var n=0;n<r.length;++n)null!=r[n].from&&e.push(r[n].marker)}),e},posFromIndex:function(e){var t,r=this.first,n=this.lineSeparator().length;return this.iter(function(i){var o=i.text.length+n;if(o>e)return t=e,!0;e-=o,++r}),U(this,E(r,t))},indexFromPos:function(e){var t=(e=U(this,e)).ch;if(e.line<this.first||e.ch<0)return 0;var r=this.lineSeparator().length;return this.iter(this.first,e.line,function(e){t+=e.text.length+r}),t},copy:function(e){var t=new Ds(O(this,this.first,this.first+this.size),this.modeOption,this.first,this.lineSep,this.direction);return t.scrollTop=this.scrollTop,t.scrollLeft=this.scrollLeft,t.sel=this.sel,t.extend=!1,e&&(t.history.undoDepth=this.history.undoDepth,t.setHistory(this.getHistory())),t},linkedDoc:function(e){e||(e={});var t=this.first,r=this.first+this.size;null!=e.from&&e.from>t&&(t=e.from),null!=e.to&&e.to<r&&(r=e.to);var n=new Ds(O(this,t,r),e.mode||this.modeOption,t,this.lineSep,this.direction);return e.sharedHist&&(n.history=this.history),(this.linked||(this.linked=[])).push({doc:n,sharedHist:e.sharedHist}),n.linked=[{doc:this,isParent:!0,sharedHist:e.sharedHist}],Yi(n,Xi(this)),n},unlinkDoc:function(e){var t=this;if(e instanceof jo&&(e=e.doc),this.linked)for(var r=0;r<this.linked.length;++r)if(t.linked[r].doc==e){t.linked.splice(r,1),e.unlinkDoc(t),_i(Xi(t));break}if(e.history==this.history){var n=[e.id];$n(e,function(e){return n.push(e.id)},!0),e.history=new Jn(null),e.history.done=fi(this.history.done,n),e.history.undone=fi(this.history.undone,n)}},iterLinkedDocs:function(e){$n(this,e)},getMode:function(){return this.mode},getEditor:function(){return this.cm},splitLines:function(e){return this.lineSep?e.split(this.lineSep):es(e)},lineSeparator:function(){return this.lineSep||"\n"},setDirection:gn(function(e){"rtl"!=e&&(e="ltr"),e!=this.direction&&(this.direction=e,this.iter(function(e){return e.order=null}),this.cm&&Qn(this.cm))})}),Ds.prototype.eachLine=Ds.prototype.iter;for(var Hs=0,Fs=!1,Es={3:"Enter",8:"Backspace",9:"Tab",13:"Enter",16:"Shift",17:"Ctrl",18:"Alt",19:"Pause",20:"CapsLock",27:"Esc",32:"Space",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"Left",38:"Up",39:"Right",40:"Down",44:"PrintScrn",45:"Insert",46:"Delete",59:";",61:"=",91:"Mod",92:"Mod",93:"Mod",106:"*",107:"=",109:"-",110:".",111:"/",127:"Delete",173:"-",186:";",187:"=",188:",",189:"-",190:".",191:"/",192:"`",219:"[",220:"\\",221:"]",222:"'",63232:"Up",63233:"Down",63234:"Left",63235:"Right",63272:"Delete",63273:"Home",63275:"End",63276:"PageUp",63277:"PageDown",63302:"Insert"},Ps=0;Ps<10;Ps++)Es[Ps+48]=Es[Ps+96]=String(Ps);for(var Is=65;Is<=90;Is++)Es[Is]=String.fromCharCode(Is);for(var zs=1;zs<=12;zs++)Es[zs+111]=Es[zs+63235]="F"+zs;var Rs={};Rs.basic={Left:"goCharLeft",Right:"goCharRight",Up:"goLineUp",Down:"goLineDown",End:"goLineEnd",Home:"goLineStartSmart",PageUp:"goPageUp",PageDown:"goPageDown",Delete:"delCharAfter",Backspace:"delCharBefore","Shift-Backspace":"delCharBefore",Tab:"defaultTab","Shift-Tab":"indentAuto",Enter:"newlineAndIndent",Insert:"toggleOverwrite",Esc:"singleSelection"},Rs.pcDefault={"Ctrl-A":"selectAll","Ctrl-D":"deleteLine","Ctrl-Z":"undo","Shift-Ctrl-Z":"redo","Ctrl-Y":"redo","Ctrl-Home":"goDocStart","Ctrl-End":"goDocEnd","Ctrl-Up":"goLineUp","Ctrl-Down":"goLineDown","Ctrl-Left":"goGroupLeft","Ctrl-Right":"goGroupRight","Alt-Left":"goLineStart","Alt-Right":"goLineEnd","Ctrl-Backspace":"delGroupBefore","Ctrl-Delete":"delGroupAfter","Ctrl-S":"save","Ctrl-F":"find","Ctrl-G":"findNext","Shift-Ctrl-G":"findPrev","Shift-Ctrl-F":"replace","Shift-Ctrl-R":"replaceAll","Ctrl-[":"indentLess","Ctrl-]":"indentMore","Ctrl-U":"undoSelection","Shift-Ctrl-U":"redoSelection","Alt-U":"redoSelection",fallthrough:"basic"},Rs.emacsy={"Ctrl-F":"goCharRight","Ctrl-B":"goCharLeft","Ctrl-P":"goLineUp","Ctrl-N":"goLineDown","Alt-F":"goWordRight","Alt-B":"goWordLeft","Ctrl-A":"goLineStart","Ctrl-E":"goLineEnd","Ctrl-V":"goPageDown","Shift-Ctrl-V":"goPageUp","Ctrl-D":"delCharAfter","Ctrl-H":"delCharBefore","Alt-D":"delWordAfter","Alt-Backspace":"delWordBefore","Ctrl-K":"killLine","Ctrl-T":"transposeChars","Ctrl-O":"openLine"},Rs.macDefault={"Cmd-A":"selectAll","Cmd-D":"deleteLine","Cmd-Z":"undo","Shift-Cmd-Z":"redo","Cmd-Y":"redo","Cmd-Home":"goDocStart","Cmd-Up":"goDocStart","Cmd-End":"goDocEnd","Cmd-Down":"goDocEnd","Alt-Left":"goGroupLeft","Alt-Right":"goGroupRight","Cmd-Left":"goLineLeft","Cmd-Right":"goLineRight","Alt-Backspace":"delGroupBefore","Ctrl-Alt-Backspace":"delGroupAfter","Alt-Delete":"delGroupAfter","Cmd-S":"save","Cmd-F":"find","Cmd-G":"findNext","Shift-Cmd-G":"findPrev","Cmd-Alt-F":"replace","Shift-Cmd-Alt-F":"replaceAll","Cmd-[":"indentLess","Cmd-]":"indentMore","Cmd-Backspace":"delWrappedLineLeft","Cmd-Delete":"delWrappedLineRight","Cmd-U":"undoSelection","Shift-Cmd-U":"redoSelection","Ctrl-Up":"goDocStart","Ctrl-Down":"goDocEnd",fallthrough:["basic","emacsy"]},Rs.default=Ml?Rs.macDefault:Rs.pcDefault;var Bs={selectAll:Mi,singleSelection:function(e){return e.setSelection(e.getCursor("anchor"),e.getCursor("head"),Gl)},killLine:function(e){return co(e,function(t){if(t.empty()){var r=M(e.doc,t.head.line).text.length;return t.head.ch==r&&t.head.line<e.lastLine()?{from:t.head,to:E(t.head.line+1,0)}:{from:t.head,to:E(t.head.line,r)}}return{from:t.from(),to:t.to()}})},deleteLine:function(e){return co(e,function(t){return{from:E(t.from().line,0),to:U(e.doc,E(t.to().line+1,0))}})},delLineLeft:function(e){return co(e,function(e){return{from:E(e.from().line,0),to:e.from()}})},delWrappedLineLeft:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5;return{from:e.coordsChar({left:0,top:r},"div"),to:t.from()}})},delWrappedLineRight:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5,n=e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div");return{from:t.from(),to:n}})},undo:function(e){return e.undo()},redo:function(e){return e.redo()},undoSelection:function(e){return e.undoSelection()},redoSelection:function(e){return e.redoSelection()},goDocStart:function(e){return e.extendSelection(E(e.firstLine(),0))},goDocEnd:function(e){return e.extendSelection(E(e.lastLine()))},goLineStart:function(e){return e.extendSelectionsBy(function(t){return vo(e,t.head.line)},{origin:"+move",bias:1})},goLineStartSmart:function(e){return e.extendSelectionsBy(function(t){return yo(e,t.head)},{origin:"+move",bias:1})},goLineEnd:function(e){return e.extendSelectionsBy(function(t){return mo(e,t.head.line)},{origin:"+move",bias:-1})},goLineRight:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div")},Vl)},goLineLeft:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:0,top:r},"div")},Vl)},goLineLeftSmart:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5,n=e.coordsChar({left:0,top:r},"div");return n.ch<e.getLine(n.line).search(/\S/)?yo(e,t.head):n},Vl)},goLineUp:function(e){return e.moveV(-1,"line")},goLineDown:function(e){return e.moveV(1,"line")},goPageUp:function(e){return e.moveV(-1,"page")},goPageDown:function(e){return e.moveV(1,"page")},goCharLeft:function(e){return e.moveH(-1,"char")},goCharRight:function(e){return e.moveH(1,"char")},goColumnLeft:function(e){return e.moveH(-1,"column")},goColumnRight:function(e){return e.moveH(1,"column")},goWordLeft:function(e){return e.moveH(-1,"word")},goGroupRight:function(e){return e.moveH(1,"group")},goGroupLeft:function(e){return e.moveH(-1,"group")},goWordRight:function(e){return e.moveH(1,"word")},delCharBefore:function(e){return e.deleteH(-1,"char")},delCharAfter:function(e){return e.deleteH(1,"char")},delWordBefore:function(e){return e.deleteH(-1,"word")},delWordAfter:function(e){return e.deleteH(1,"word")},delGroupBefore:function(e){return e.deleteH(-1,"group")},delGroupAfter:function(e){return e.deleteH(1,"group")},indentAuto:function(e){return e.indentSelection("smart")},indentMore:function(e){return e.indentSelection("add")},indentLess:function(e){return e.indentSelection("subtract")},insertTab:function(e){return e.replaceSelection("\t")},insertSoftTab:function(e){for(var t=[],r=e.listSelections(),n=e.options.tabSize,i=0;i<r.length;i++){var o=r[i].from(),l=f(e.getLine(o.line),o.ch,n);t.push(p(n-l%n))}e.replaceSelections(t)},defaultTab:function(e){e.somethingSelected()?e.indentSelection("add"):e.execCommand("insertTab")},transposeChars:function(e){return hn(e,function(){for(var t=e.listSelections(),r=[],n=0;n<t.length;n++)if(t[n].empty()){var i=t[n].head,o=M(e.doc,i.line).text;if(o)if(i.ch==o.length&&(i=new E(i.line,i.ch-1)),i.ch>0)i=new E(i.line,i.ch+1),e.replaceRange(o.charAt(i.ch-1)+o.charAt(i.ch-2),E(i.line,i.ch-2),i,"+transpose");else if(i.line>e.doc.first){var l=M(e.doc,i.line-1).text;l&&(i=new E(i.line,1),e.replaceRange(o.charAt(0)+e.doc.lineSeparator()+l.charAt(l.length-1),E(i.line-1,l.length-1),i,"+transpose"))}r.push(new Ts(i,i))}e.setSelections(r)})},newlineAndIndent:function(e){return hn(e,function(){for(var t=e.listSelections(),r=t.length-1;r>=0;r--)e.replaceRange(e.doc.lineSeparator(),t[r].anchor,t[r].head,"+input");t=e.listSelections();for(var n=0;n<t.length;n++)e.indentLine(t[n].from().line,null,!0);jr(e)})},openLine:function(e){return e.replaceSelection("\n","start")},toggleOverwrite:function(e){return e.toggleOverwrite()}},Gs=new Pl,Us=null,Vs=function(e,t,r){this.time=e,this.pos=t,this.button=r};Vs.prototype.compare=function(e,t,r){return this.time+400>e&&0==P(t,this.pos)&&r==this.button};var Ks,js,Xs={toString:function(){return"CodeMirror.Init"}},Ys={},_s={};jo.defaults=Ys,jo.optionHandlers=_s;var $s=[];jo.defineInitHook=function(e){return $s.push(e)};var qs=null,Zs=function(e){this.cm=e,this.lastAnchorNode=this.lastAnchorOffset=this.lastFocusNode=this.lastFocusOffset=null,this.polling=new Pl,this.composing=null,this.gracePeriod=!1,this.readDOMTimeout=null};Zs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()}),"cut"==e.type&&i.replaceSelection("",null,"cut");else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type&&i.operation(function(){i.setSelections(t.ranges,0,Gl),i.replaceSelection("",null,"cut")})}if(e.clipboardData){e.clipboardData.clearData();var r=qs.text.join("\n");if(e.clipboardData.setData("Text",r),e.clipboardData.getData("Text")==r)return void e.preventDefault()}var l=el(),s=l.firstChild;i.display.lineSpace.insertBefore(l,i.display.lineSpace.firstChild),s.value=qs.text.join("\n");var a=document.activeElement;El(s),setTimeout(function(){i.display.lineSpace.removeChild(l),a.focus(),a==o&&n.showPrimarySelection()},50)}}var r=this,n=this,i=n.cm,o=n.div=e.lineDiv;Jo(o,i.options.spellcheck),Ql(o,"paste",function(e){Me(i,e)||qo(e,i)||vl<=11&&setTimeout(dn(i,function(){return r.updateFromDOM()}),20)}),Ql(o,"compositionstart",function(e){r.composing={data:e.data,done:!1}}),Ql(o,"compositionupdate",function(e){r.composing||(r.composing={data:e.data,done:!1})}),Ql(o,"compositionend",function(e){r.composing&&(e.data!=r.composing.data&&r.readFromDOMSoon(),r.composing.done=!0)}),Ql(o,"touchstart",function(){return n.forceCompositionEnd()}),Ql(o,"input",function(){r.composing||r.readFromDOMSoon()}),Ql(o,"copy",t),Ql(o,"cut",t)},Zs.prototype.prepareSelection=function(){var e=Tr(this.cm,!1);return e.focus=this.cm.state.focused,e},Zs.prototype.showSelection=function(e,t){e&&this.cm.display.view.length&&((e.focus||t)&&this.showPrimarySelection(),this.showMultipleSelections(e))},Zs.prototype.showPrimarySelection=function(){var e=window.getSelection(),t=this.cm,r=t.doc.sel.primary(),n=r.from(),i=r.to();if(t.display.viewTo==t.display.viewFrom||n.line>=t.display.viewTo||i.line<t.display.viewFrom)e.removeAllRanges();else{var o=sl(t,e.anchorNode,e.anchorOffset),l=sl(t,e.focusNode,e.focusOffset);if(!o||o.bad||!l||l.bad||0!=P(B(o,l),n)||0!=P(R(o,l),i)){var s=t.display.view,a=n.line>=t.display.viewFrom&&nl(t,n)||{node:s[0].measure.map[2],offset:0},u=i.line<t.display.viewTo&&nl(t,i);if(!u){var c=s[s.length-1].measure,f=c.maps?c.maps[c.maps.length-1]:c.map;u={node:f[f.length-1],offset:f[f.length-2]-f[f.length-3]}}if(a&&u){var h,d=e.rangeCount&&e.getRangeAt(0);try{h=Wl(a.node,a.offset,u.offset,u.node)}catch(e){}h&&(!fl&&t.state.focused?(e.collapse(a.node,a.offset),h.collapsed||(e.removeAllRanges(),e.addRange(h))):(e.removeAllRanges(),e.addRange(h)),d&&null==e.anchorNode?e.addRange(d):fl&&this.startGracePeriod()),this.rememberSelection()}else e.removeAllRanges()}}},Zs.prototype.startGracePeriod=function(){var e=this;clearTimeout(this.gracePeriod),this.gracePeriod=setTimeout(function(){e.gracePeriod=!1,e.selectionChanged()&&e.cm.operation(function(){return e.cm.curOp.selectionChanged=!0})},20)},Zs.prototype.showMultipleSelections=function(e){r(this.cm.display.cursorDiv,e.cursors),r(this.cm.display.selectionDiv,e.selection)},Zs.prototype.rememberSelection=function(){var e=window.getSelection();this.lastAnchorNode=e.anchorNode,this.lastAnchorOffset=e.anchorOffset,this.lastFocusNode=e.focusNode,this.lastFocusOffset=e.focusOffset},Zs.prototype.selectionInEditor=function(){var e=window.getSelection();if(!e.rangeCount)return!1;var t=e.getRangeAt(0).commonAncestorContainer;return o(this.div,t)},Zs.prototype.focus=function(){"nocursor"!=this.cm.options.readOnly&&(this.selectionInEditor()||this.showSelection(this.prepareSelection(),!0),this.div.focus())},Zs.prototype.blur=function(){this.div.blur()},Zs.prototype.getField=function(){return this.div},Zs.prototype.supportsTouch=function(){return!0},Zs.prototype.receivedFocus=function(){function e(){t.cm.state.focused&&(t.pollSelection(),t.polling.set(t.cm.options.pollInterval,e))}var t=this;this.selectionInEditor()?this.pollSelection():hn(this.cm,function(){return t.cm.curOp.selectionChanged=!0}),this.polling.set(this.cm.options.pollInterval,e)},Zs.prototype.selectionChanged=function(){var e=window.getSelection();return e.anchorNode!=this.lastAnchorNode||e.anchorOffset!=this.lastAnchorOffset||e.focusNode!=this.lastFocusNode||e.focusOffset!=this.lastFocusOffset},Zs.prototype.pollSelection=function(){if(null==this.readDOMTimeout&&!this.gracePeriod&&this.selectionChanged()){var e=window.getSelection(),t=this.cm;if(kl&&bl&&this.cm.options.gutters.length&&il(e.anchorNode))return this.cm.triggerOnKeyDown({type:"keydown",keyCode:8,preventDefault:Math.abs}),this.blur(),void this.focus();if(!this.composing){this.rememberSelection();var r=sl(t,e.anchorNode,e.anchorOffset),n=sl(t,e.focusNode,e.focusOffset);r&&n&&hn(t,function(){bi(t.doc,Rn(r,n),Gl),(r.bad||n.bad)&&(t.curOp.selectionChanged=!0)})}}},Zs.prototype.pollContent=function(){null!=this.readDOMTimeout&&(clearTimeout(this.readDOMTimeout),this.readDOMTimeout=null);var e=this.cm,t=e.display,r=e.doc.sel.primary(),n=r.from(),i=r.to();if(0==n.ch&&n.line>e.firstLine()&&(n=E(n.line-1,M(e.doc,n.line-1).length)),i.ch==M(e.doc,i.line).text.length&&i.line<e.lastLine()&&(i=E(i.line+1,0)),n.line<t.viewFrom||i.line>t.viewTo-1)return!1;var o,l,s;n.line==t.viewFrom||0==(o=Lr(e,n.line))?(l=W(t.view[0].line),s=t.view[0].node):(l=W(t.view[o].line),s=t.view[o-1].node.nextSibling);var a,u,c=Lr(e,i.line);if(c==t.view.length-1?(a=t.viewTo-1,u=t.lineDiv.lastChild):(a=W(t.view[c+1].line)-1,u=t.view[c+1].node.previousSibling),!s)return!1;for(var f=e.doc.splitLines(ll(e,s,u,l,a)),h=N(e.doc,E(l,0),E(a,M(e.doc,a).text.length));f.length>1&&h.length>1;)if(g(f)==g(h))f.pop(),h.pop(),a--;else{if(f[0]!=h[0])break;f.shift(),h.shift(),l++}for(var d=0,p=0,v=f[0],m=h[0],y=Math.min(v.length,m.length);d<y&&v.charCodeAt(d)==m.charCodeAt(d);)++d;for(var b=g(f),w=g(h),x=Math.min(b.length-(1==f.length?d:0),w.length-(1==h.length?d:0));p<x&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)++p;if(1==f.length&&1==h.length&&l==n.line)for(;d&&d>n.ch&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)d--,p++;f[f.length-1]=b.slice(0,b.length-p).replace(/^\u200b+/,""),f[0]=f[0].slice(d).replace(/\u200b+$/,"");var C=E(l,d),S=E(a,h.length?g(h).length-p:0);return f.length>1||f[0]||P(C,S)?(Ei(e.doc,f,C,S,"+input"),!0):void 0},Zs.prototype.ensurePolled=function(){this.forceCompositionEnd()},Zs.prototype.reset=function(){this.forceCompositionEnd()},Zs.prototype.forceCompositionEnd=function(){this.composing&&(clearTimeout(this.readDOMTimeout),this.composing=null,this.updateFromDOM(),this.div.blur(),this.div.focus())},Zs.prototype.readFromDOMSoon=function(){var e=this;null==this.readDOMTimeout&&(this.readDOMTimeout=setTimeout(function(){if(e.readDOMTimeout=null,e.composing){if(!e.composing.done)return;e.composing=null}e.updateFromDOM()},80))},Zs.prototype.updateFromDOM=function(){var e=this;!this.cm.isReadOnly()&&this.pollContent()||hn(this.cm,function(){return vn(e.cm)})},Zs.prototype.setUneditable=function(e){e.contentEditable="false"},Zs.prototype.onKeyPress=function(e){0!=e.charCode&&(e.preventDefault(),this.cm.isReadOnly()||dn(this.cm,$o)(this.cm,String.fromCharCode(null==e.charCode?e.keyCode:e.charCode),0))},Zs.prototype.readOnlyChanged=function(e){this.div.contentEditable=String("nocursor"!=e)},Zs.prototype.onContextMenu=function(){},Zs.prototype.resetPosition=function(){},Zs.prototype.needsContentAttribute=!0;var Qs=function(e){this.cm=e,this.prevInput="",this.pollingFast=!1,this.polling=new Pl,this.hasSelection=!1,this.composing=null};Qs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()});else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type?i.setSelections(t.ranges,null,Gl):(n.prevInput="",l.value=t.text.join("\n"),El(l))}"cut"==e.type&&(i.state.cutIncoming=!0)}}var r=this,n=this,i=this.cm,o=this.wrapper=el(),l=this.textarea=o.firstChild;e.wrapper.insertBefore(o,e.wrapper.firstChild),Ll&&(l.style.width="0px"),Ql(l,"input",function(){gl&&vl>=9&&r.hasSelection&&(r.hasSelection=null),n.poll()}),Ql(l,"paste",function(e){Me(i,e)||qo(e,i)||(i.state.pasteIncoming=!0,n.fastPoll())}),Ql(l,"cut",t),Ql(l,"copy",t),Ql(e.scroller,"paste",function(t){Ft(e,t)||Me(i,t)||(i.state.pasteIncoming=!0,n.focus())}),Ql(e.lineSpace,"selectstart",function(t){Ft(e,t)||We(t)}),Ql(l,"compositionstart",function(){var e=i.getCursor("from");n.composing&&n.composing.range.clear(),n.composing={start:e,range:i.markText(e,i.getCursor("to"),{className:"CodeMirror-composing"})}}),Ql(l,"compositionend",function(){n.composing&&(n.poll(),n.composing.range.clear(),n.composing=null)})},Qs.prototype.prepareSelection=function(){var e=this.cm,t=e.display,r=e.doc,n=Tr(e);if(e.options.moveInputWithCursor){var i=sr(e,r.sel.primary().head,"div"),o=t.wrapper.getBoundingClientRect(),l=t.lineDiv.getBoundingClientRect();n.teTop=Math.max(0,Math.min(t.wrapper.clientHeight-10,i.top+l.top-o.top)),n.teLeft=Math.max(0,Math.min(t.wrapper.clientWidth-10,i.left+l.left-o.left))}return n},Qs.prototype.showSelection=function(e){var t=this.cm.display;r(t.cursorDiv,e.cursors),r(t.selectionDiv,e.selection),null!=e.teTop&&(this.wrapper.style.top=e.teTop+"px",this.wrapper.style.left=e.teLeft+"px")},Qs.prototype.reset=function(e){if(!this.contextMenuPending&&!this.composing){var t=this.cm;if(t.somethingSelected()){this.prevInput="";var r=t.getSelection();this.textarea.value=r,t.state.focused&&El(this.textarea),gl&&vl>=9&&(this.hasSelection=r)}else e||(this.prevInput=this.textarea.value="",gl&&vl>=9&&(this.hasSelection=null))}},Qs.prototype.getField=function(){return this.textarea},Qs.prototype.supportsTouch=function(){return!1},Qs.prototype.focus=function(){if("nocursor"!=this.cm.options.readOnly&&(!Tl||l()!=this.textarea))try{this.textarea.focus()}catch(e){}},Qs.prototype.blur=function(){this.textarea.blur()},Qs.prototype.resetPosition=function(){this.wrapper.style.top=this.wrapper.style.left=0},Qs.prototype.receivedFocus=function(){this.slowPoll()},Qs.prototype.slowPoll=function(){var e=this;this.pollingFast||this.polling.set(this.cm.options.pollInterval,function(){e.poll(),e.cm.state.focused&&e.slowPoll()})},Qs.prototype.fastPoll=function(){function e(){r.poll()||t?(r.pollingFast=!1,r.slowPoll()):(t=!0,r.polling.set(60,e))}var t=!1,r=this;r.pollingFast=!0,r.polling.set(20,e)},Qs.prototype.poll=function(){var e=this,t=this.cm,r=this.textarea,n=this.prevInput;if(this.contextMenuPending||!t.state.focused||ts(r)&&!n&&!this.composing||t.isReadOnly()||t.options.disableInput||t.state.keySeq)return!1;var i=r.value;if(i==n&&!t.somethingSelected())return!1;if(gl&&vl>=9&&this.hasSelection===i||Ml&&/[\uf700-\uf7ff]/.test(i))return t.display.input.reset(),!1;if(t.doc.sel==t.display.selForContextMenu){var o=i.charCodeAt(0);if(8203!=o||n||(n="​"),8666==o)return this.reset(),this.cm.execCommand("undo")}for(var l=0,s=Math.min(n.length,i.length);l<s&&n.charCodeAt(l)==i.charCodeAt(l);)++l;return hn(t,function(){$o(t,i.slice(l),n.length-l,null,e.composing?"*compose":null),i.length>1e3||i.indexOf("\n")>-1?r.value=e.prevInput="":e.prevInput=i,e.composing&&(e.composing.range.clear(),e.composing.range=t.markText(e.composing.start,t.getCursor("to"),{className:"CodeMirror-composing"}))}),!0},Qs.prototype.ensurePolled=function(){this.pollingFast&&this.poll()&&(this.pollingFast=!1)},Qs.prototype.onKeyPress=function(){gl&&vl>=9&&(this.hasSelection=null),this.fastPoll()},Qs.prototype.onContextMenu=function(e){function t(){if(null!=l.selectionStart){var e=i.somethingSelected(),t="​"+(e?l.value:"");l.value="⇚",l.value=t,n.prevInput=e?"":"​",l.selectionStart=1,l.selectionEnd=t.length,o.selForContextMenu=i.doc.sel}}function r(){if(n.contextMenuPending=!1,n.wrapper.style.cssText=c,l.style.cssText=u,gl&&vl<9&&o.scrollbars.setScrollTop(o.scroller.scrollTop=a),null!=l.selectionStart){(!gl||gl&&vl<9)&&t();var e=0,r=function(){o.selForContextMenu==i.doc.sel&&0==l.selectionStart&&l.selectionEnd>0&&"​"==n.prevInput?dn(i,Mi)(i):e++<10?o.detectingSelectAll=setTimeout(r,500):(o.selForContextMenu=null,o.input.reset())};o.detectingSelectAll=setTimeout(r,200)}}var n=this,i=n.cm,o=i.display,l=n.textarea,s=Sr(i,e),a=o.scroller.scrollTop;if(s&&!wl){i.options.resetSelectionOnContextMenu&&-1==i.doc.sel.contains(s)&&dn(i,bi)(i.doc,Rn(s),Gl);var u=l.style.cssText,c=n.wrapper.style.cssText;n.wrapper.style.cssText="position: absolute";var f=n.wrapper.getBoundingClientRect();l.style.cssText="position: absolute; width: 30px; height: 30px;\n      top: "+(e.clientY-f.top-5)+"px; left: "+(e.clientX-f.left-5)+"px;\n      z-index: 1000; background: "+(gl?"rgba(255, 255, 255, .05)":"transparent")+";\n      outline: none; border-width: 0; outline: none; overflow: hidden; opacity: .05; filter: alpha(opacity=5);";var h;if(ml&&(h=window.scrollY),o.input.focus(),ml&&window.scrollTo(null,h),o.input.reset(),i.somethingSelected()||(l.value=n.prevInput=" "),n.contextMenuPending=!0,o.selForContextMenu=i.doc.sel,clearTimeout(o.detectingSelectAll),gl&&vl>=9&&t(),Hl){Fe(e);var d=function(){ke(window,"mouseup",d),setTimeout(r,20)};Ql(window,"mouseup",d)}else setTimeout(r,50)}},Qs.prototype.readOnlyChanged=function(e){e||this.reset(),this.textarea.disabled="nocursor"==e},Qs.prototype.setUneditable=function(){},Qs.prototype.needsContentAttribute=!1,function(e){function t(t,n,i,o){e.defaults[t]=n,i&&(r[t]=o?function(e,t,r){r!=Xs&&i(e,t,r)}:i)}var r=e.optionHandlers;e.defineOption=t,e.Init=Xs,t("value","",function(e,t){return e.setValue(t)},!0),t("mode",null,function(e,t){e.doc.modeOption=t,jn(e)},!0),t("indentUnit",2,jn,!0),t("indentWithTabs",!1),t("smartIndent",!0),t("tabSize",4,function(e){Xn(e),er(e),vn(e)},!0),t("lineSeparator",null,function(e,t){if(e.doc.lineSep=t,t){var r=[],n=e.doc.first;e.doc.iter(function(e){for(var i=0;;){var o=e.text.indexOf(t,i);if(-1==o)break;i=o+t.length,r.push(E(n,o))}n++});for(var i=r.length-1;i>=0;i--)Ei(e.doc,t,r[i],E(r[i].line,r[i].ch+t.length))}}),t("specialChars",/[\u0000-\u001f\u007f-\u009f\u00ad\u061c\u200b-\u200f\u2028\u2029\ufeff]/g,function(e,t,r){e.state.specialChars=new RegExp(t.source+(t.test("\t")?"":"|\t"),"g"),r!=Xs&&e.refresh()}),t("specialCharPlaceholder",at,function(e){return e.refresh()},!0),t("electricChars",!0),t("inputStyle",Tl?"contenteditable":"textarea",function(){throw new Error("inputStyle can not (yet) be changed in a running editor")},!0),t("spellcheck",!1,function(e,t){return e.getInputField().spellcheck=t},!0),t("rtlMoveVisually",!Ol),t("wholeLineUpdateBefore",!0),t("theme","default",function(e){Go(e),Uo(e)},!0),t("keyMap","default",function(e,t,r){var n=uo(t),i=r!=Xs&&uo(r);i&&i.detach&&i.detach(e,n),n.attach&&n.attach(e,i||null)}),t("extraKeys",null),t("configureMouse",null),t("lineWrapping",!1,Ko,!0),t("gutters",[],function(e){Fn(e.options),Uo(e)},!0),t("fixedGutter",!0,function(e,t){e.display.gutters.style.left=t?wr(e.display)+"px":"0",e.refresh()},!0),t("coverGutterNextToScrollbar",!1,function(e){return en(e)},!0),t("scrollbarStyle","native",function(e){rn(e),en(e),e.display.scrollbars.setScrollTop(e.doc.scrollTop),e.display.scrollbars.setScrollLeft(e.doc.scrollLeft)},!0),t("lineNumbers",!1,function(e){Fn(e.options),Uo(e)},!0),t("firstLineNumber",1,Uo,!0),t("lineNumberFormatter",function(e){return e},Uo,!0),t("showCursorWhenSelecting",!1,kr,!0),t("resetSelectionOnContextMenu",!0),t("lineWiseCopyCut",!0),t("pasteLinesPerSelection",!0),t("readOnly",!1,function(e,t){"nocursor"==t&&(Fr(e),e.display.input.blur()),e.display.input.readOnlyChanged(t)}),t("disableInput",!1,function(e,t){t||e.display.input.reset()},!0),t("dragDrop",!0,Vo),t("allowDropFileTypes",null),t("cursorBlinkRate",530),t("cursorScrollMargin",0),t("cursorHeight",1,kr,!0),t("singleCursorHeightPerLine",!0,kr,!0),t("workTime",100),t("workDelay",100),t("flattenSpans",!0,Xn,!0),t("addModeClass",!1,Xn,!0),t("pollInterval",100),t("undoDepth",200,function(e,t){return e.doc.history.undoDepth=t}),t("historyEventDelay",1250),t("viewportMargin",10,function(e){return e.refresh()},!0),t("maxHighlightLength",1e4,Xn,!0),t("moveInputWithCursor",!0,function(e,t){t||e.display.input.resetPosition()}),t("tabindex",null,function(e,t){return e.display.input.getField().tabIndex=t||""}),t("autofocus",null),t("direction","ltr",function(e,t){return e.doc.setDirection(t)},!0)}(jo),function(e){var t=e.optionHandlers,r=e.helpers={};e.prototype={constructor:e,focus:function(){window.focus(),this.display.input.focus()},setOption:function(e,r){var n=this.options,i=n[e];n[e]==r&&"mode"!=e||(n[e]=r,t.hasOwnProperty(e)&&dn(this,t[e])(this,r,i),Te(this,"optionChange",this,e))},getOption:function(e){return this.options[e]},getDoc:function(){return this.doc},addKeyMap:function(e,t){this.state.keyMaps[t?"push":"unshift"](uo(e))},removeKeyMap:function(e){for(var t=this.state.keyMaps,r=0;r<t.length;++r)if(t[r]==e||t[r].name==e)return t.splice(r,1),!0},addOverlay:pn(function(t,r){var n=t.token?t:e.getMode(this.options,t);if(n.startState)throw new Error("Overlays may not be stateful.");m(this.state.overlays,{mode:n,modeSpec:t,opaque:r&&r.opaque,priority:r&&r.priority||0},function(e){return e.priority}),this.state.modeGen++,vn(this)}),removeOverlay:pn(function(e){for(var t=this,r=this.state.overlays,n=0;n<r.length;++n){var i=r[n].modeSpec;if(i==e||"string"==typeof e&&i.name==e)return r.splice(n,1),t.state.modeGen++,void vn(t)}}),indentLine:pn(function(e,t,r){"string"!=typeof t&&"number"!=typeof t&&(t=null==t?this.options.smartIndent?"smart":"prev":t?"add":"subtract"),H(this.doc,e)&&Yo(this,e,t,r)}),indentSelection:pn(function(e){for(var t=this,r=this.doc.sel.ranges,n=-1,i=0;i<r.length;i++){var o=r[i];if(o.empty())o.head.line>n&&(Yo(t,o.head.line,e,!0),n=o.head.line,i==t.doc.sel.primIndex&&jr(t));else{var l=o.from(),s=o.to(),a=Math.max(n,l.line);n=Math.min(t.lastLine(),s.line-(s.ch?0:1))+1;for(var u=a;u<n;++u)Yo(t,u,e);var c=t.doc.sel.ranges;0==l.ch&&r.length==c.length&&c[i].from().ch>0&&gi(t.doc,i,new Ts(l,c[i].to()),Gl)}}}),getTokenAt:function(e,t){return Je(this,e,t)},getLineTokens:function(e,t){return Je(this,E(e),t,!0)},getTokenTypeAt:function(e){e=U(this.doc,e);var t,r=_e(this,M(this.doc,e.line)),n=0,i=(r.length-1)/2,o=e.ch;if(0==o)t=r[2];else for(;;){var l=n+i>>1;if((l?r[2*l-1]:0)>=o)i=l;else{if(!(r[2*l+1]<o)){t=r[2*l+2];break}n=l+1}}var s=t?t.indexOf("overlay "):-1;return s<0?t:0==s?null:t.slice(0,s-1)},getModeAt:function(t){var r=this.doc.mode;return r.innerMode?e.innerMode(r,this.getTokenAt(t).state).mode:r},getHelper:function(e,t){return this.getHelpers(e,t)[0]},getHelpers:function(e,t){var n=this,i=[];if(!r.hasOwnProperty(t))return i;var o=r[t],l=this.getModeAt(e);if("string"==typeof l[t])o[l[t]]&&i.push(o[l[t]]);else if(l[t])for(var s=0;s<l[t].length;s++){var a=o[l[t][s]];a&&i.push(a)}else l.helperType&&o[l.helperType]?i.push(o[l.helperType]):o[l.name]&&i.push(o[l.name]);for(var u=0;u<o._global.length;u++){var c=o._global[u];c.pred(l,n)&&-1==h(i,c.val)&&i.push(c.val)}return i},getStateAfter:function(e,t){var r=this.doc;return e=G(r,null==e?r.first+r.size-1:e),$e(this,e+1,t).state},cursorCoords:function(e,t){var r,n=this.doc.sel.primary();return r=null==e?n.head:"object"==typeof e?U(this.doc,e):e?n.from():n.to(),sr(this,r,t||"page")},charCoords:function(e,t){return lr(this,U(this.doc,e),t||"page")},coordsChar:function(e,t){return e=or(this,e,t||"page"),cr(this,e.left,e.top)},lineAtHeight:function(e,t){return e=or(this,{top:e,left:0},t||"page").top,D(this.doc,e+this.display.viewOffset)},heightAtLine:function(e,t,r){var n,i=!1;if("number"==typeof e){var o=this.doc.first+this.doc.size-1;e<this.doc.first?e=this.doc.first:e>o&&(e=o,i=!0),n=M(this.doc,e)}else n=e;return ir(this,n,{top:0,left:0},t||"page",r||i).top+(i?this.doc.height-ye(n):0)},defaultTextHeight:function(){return mr(this.display)},defaultCharWidth:function(){return yr(this.display)},getViewport:function(){return{from:this.display.viewFrom,to:this.display.viewTo}},addWidget:function(e,t,r,n,i){var o=this.display,l=(e=sr(this,U(this.doc,e))).bottom,s=e.left;if(t.style.position="absolute",t.setAttribute("cm-ignore-events","true"),this.display.input.setUneditable(t),o.sizer.appendChild(t),"over"==n)l=e.top;else if("above"==n||"near"==n){var a=Math.max(o.wrapper.clientHeight,this.doc.height),u=Math.max(o.sizer.clientWidth,o.lineSpace.clientWidth);("above"==n||e.bottom+t.offsetHeight>a)&&e.top>t.offsetHeight?l=e.top-t.offsetHeight:e.bottom+t.offsetHeight<=a&&(l=e.bottom),s+t.offsetWidth>u&&(s=u-t.offsetWidth)}t.style.top=l+"px",t.style.left=t.style.right="","right"==i?(s=o.sizer.clientWidth-t.offsetWidth,t.style.right="0px"):("left"==i?s=0:"middle"==i&&(s=(o.sizer.clientWidth-t.offsetWidth)/2),t.style.left=s+"px"),r&&Ur(this,{left:s,top:l,right:s+t.offsetWidth,bottom:l+t.offsetHeight})},triggerOnKeyDown:pn(Lo),triggerOnKeyPress:pn(Mo),triggerOnKeyUp:To,triggerOnMouseDown:pn(Oo),execCommand:function(e){if(Bs.hasOwnProperty(e))return Bs[e].call(null,this)},triggerElectric:pn(function(e){Zo(this,e)}),findPosH:function(e,t,r,n){var i=this,o=1;t<0&&(o=-1,t=-t);for(var l=U(this.doc,e),s=0;s<t&&!(l=tl(i.doc,l,o,r,n)).hitSide;++s);return l},moveH:pn(function(e,t){var r=this;this.extendSelectionsBy(function(n){return r.display.shift||r.doc.extend||n.empty()?tl(r.doc,n.head,e,t,r.options.rtlMoveVisually):e<0?n.from():n.to()},Vl)}),deleteH:pn(function(e,t){var r=this.doc.sel,n=this.doc;r.somethingSelected()?n.replaceSelection("",null,"+delete"):co(this,function(r){var i=tl(n,r.head,e,t,!1);return e<0?{from:i,to:r.head}:{from:r.head,to:i}})}),findPosV:function(e,t,r,n){var i=this,o=1,l=n;t<0&&(o=-1,t=-t);for(var s=U(this.doc,e),a=0;a<t;++a){var u=sr(i,s,"div");if(null==l?l=u.left:u.left=l,(s=rl(i,u,o,r)).hitSide)break}return s},moveV:pn(function(e,t){var r=this,n=this.doc,i=[],o=!this.display.shift&&!n.extend&&n.sel.somethingSelected();if(n.extendSelectionsBy(function(l){if(o)return e<0?l.from():l.to();var s=sr(r,l.head,"div");null!=l.goalColumn&&(s.left=l.goalColumn),i.push(s.left);var a=rl(r,s,e,t);return"page"==t&&l==n.sel.primary()&&Kr(r,lr(r,a,"div").top-s.top),a},Vl),i.length)for(var l=0;l<n.sel.ranges.length;l++)n.sel.ranges[l].goalColumn=i[l]}),findWordAt:function(e){var t=M(this.doc,e.line).text,r=e.ch,n=e.ch;if(t){var i=this.getHelper(e,"wordChars");"before"!=e.sticky&&n!=t.length||!r?++n:--r;for(var o=t.charAt(r),l=x(o,i)?function(e){return x(e,i)}:/\s/.test(o)?function(e){return/\s/.test(e)}:function(e){return!/\s/.test(e)&&!x(e)};r>0&&l(t.charAt(r-1));)--r;for(;n<t.length&&l(t.charAt(n));)++n}return new Ts(E(e.line,r),E(e.line,n))},toggleOverwrite:function(e){null!=e&&e==this.state.overwrite||((this.state.overwrite=!this.state.overwrite)?s(this.display.cursorDiv,"CodeMirror-overwrite"):Fl(this.display.cursorDiv,"CodeMirror-overwrite"),Te(this,"overwriteToggle",this,this.state.overwrite))},hasFocus:function(){return this.display.input.getField()==l()},isReadOnly:function(){return!(!this.options.readOnly&&!this.doc.cantEdit)},scrollTo:pn(function(e,t){Xr(this,e,t)}),getScrollInfo:function(){var e=this.display.scroller;return{left:e.scrollLeft,top:e.scrollTop,height:e.scrollHeight-zt(this)-this.display.barHeight,width:e.scrollWidth-zt(this)-this.display.barWidth,clientHeight:Bt(this),clientWidth:Rt(this)}},scrollIntoView:pn(function(e,t){null==e?(e={from:this.doc.sel.primary().head,to:null},null==t&&(t=this.options.cursorScrollMargin)):"number"==typeof e?e={from:E(e,0),to:null}:null==e.from&&(e={from:e,to:null}),e.to||(e.to=e.from),e.margin=t||0,null!=e.from.line?Yr(this,e):$r(this,e.from,e.to,e.margin)}),setSize:pn(function(e,t){var r=this,n=function(e){return"number"==typeof e||/^\d+$/.test(String(e))?e+"px":e};null!=e&&(this.display.wrapper.style.width=n(e)),null!=t&&(this.display.wrapper.style.height=n(t)),this.options.lineWrapping&&Jt(this);var i=this.display.viewFrom;this.doc.iter(i,this.display.viewTo,function(e){if(e.widgets)for(var t=0;t<e.widgets.length;t++)if(e.widgets[t].noHScroll){mn(r,i,"widget");break}++i}),this.curOp.forceUpdate=!0,Te(this,"refresh",this)}),operation:function(e){return hn(this,e)},startOperation:function(){return nn(this)},endOperation:function(){return on(this)},refresh:pn(function(){var e=this.display.cachedTextHeight;vn(this),this.curOp.forceUpdate=!0,er(this),Xr(this,this.doc.scrollLeft,this.doc.scrollTop),Wn(this),(null==e||Math.abs(e-mr(this.display))>.5)&&Cr(this),Te(this,"refresh",this)}),swapDoc:pn(function(e){var t=this.doc;return t.cm=null,qn(this,e),er(this),this.display.input.reset(),Xr(this,e.scrollLeft,e.scrollTop),this.curOp.forceScroll=!0,bt(this,"swapDoc",this,t),t}),getInputField:function(){return this.display.input.getField()},getWrapperElement:function(){return this.display.wrapper},getScrollerElement:function(){return this.display.scroller},getGutterElement:function(){return this.display.gutters}},Ae(e),e.registerHelper=function(t,n,i){r.hasOwnProperty(t)||(r[t]=e[t]={_global:[]}),r[t][n]=i},e.registerGlobalHelper=function(t,n,i,o){e.registerHelper(t,n,o),r[t]._global.push({pred:i,val:o})}}(jo);var Js="iter insert remove copy getEditor constructor".split(" ");for(var ea in Ds.prototype)Ds.prototype.hasOwnProperty(ea)&&h(Js,ea)<0&&(jo.prototype[ea]=function(e){return function(){return e.apply(this.doc,arguments)}}(Ds.prototype[ea]));return Ae(Ds),jo.inputStyles={textarea:Qs,contenteditable:Zs},jo.defineMode=function(e){jo.defaults.mode||"null"==e||(jo.defaults.mode=e),Be.apply(this,arguments)},jo.defineMIME=function(e,t){os[e]=t},jo.defineMode("null",function(){return{token:function(e){return e.skipToEnd()}}}),jo.defineMIME("text/plain","null"),jo.defineExtension=function(e,t){jo.prototype[e]=t},jo.defineDocExtension=function(e,t){Ds.prototype[e]=t},jo.fromTextArea=function(e,t){function r(){e.value=a.getValue()}if(t=t?c(t):{},t.value=e.value,!t.tabindex&&e.tabIndex&&(t.tabindex=e.tabIndex),!t.placeholder&&e.placeholder&&(t.placeholder=e.placeholder),null==t.autofocus){var n=l();t.autofocus=n==e||null!=e.getAttribute("autofocus")&&n==document.body}var i;if(e.form&&(Ql(e.form,"submit",r),!t.leaveSubmitMethodAlone)){var o=e.form;i=o.submit;try{var s=o.submit=function(){r(),o.submit=i,o.submit(),o.submit=s}}catch(e){}}t.finishInit=function(t){t.save=r,t.getTextArea=function(){return e},t.toTextArea=function(){t.toTextArea=isNaN,r(),e.parentNode.removeChild(t.getWrapperElement()),e.style.display="",e.form&&(ke(e.form,"submit",r),"function"==typeof e.form.submit&&(e.form.submit=i))}},e.style.display="none";var a=jo(function(t){return e.parentNode.insertBefore(t,e.nextSibling)},t);return a},function(e){e.off=ke,e.on=Ql,e.wheelEventPixels=Pn,e.Doc=Ds,e.splitLines=es,e.countColumn=f,e.findColumn=d,e.isWordChar=w,e.Pass=Bl,e.signal=Te,e.Line=fs,e.changeEnd=Bn,e.scrollbarModel=ws,e.Pos=E,e.cmpPos=P,e.modes=is,e.mimeModes=os,e.resolveMode=Ge,e.getMode=Ue,e.modeExtensions=ls,e.extendMode=Ve,e.copyState=Ke,e.startState=Xe,e.innerMode=je,e.commands=Bs,e.keyMap=Rs,e.keyName=ao,e.isModifierKey=lo,e.lookupKey=oo,e.normalizeKeyMap=io,e.StringStream=ss,e.SharedTextMarker=As,e.TextMarker=Os,e.LineWidget=Ms,e.e_preventDefault=We,e.e_stopPropagation=De,e.e_stop=Fe,e.addClass=s,e.contains=o,e.rmClass=Fl,e.keyNames=Es}(jo),jo.version="5.30.0",jo});
      !function(e){"object"==typeof exports&&"object"==typeof module?e(require("../../lib/codemirror")):"function"==typeof define&&define.amd?define(["../../lib/codemirror"],e):e(CodeMirror)}(function(e){"use strict";function t(e,t,n,r,o,a){this.indented=e,this.column=t,this.type=n,this.info=r,this.align=o,this.prev=a}function n(e,n,r,o){var a=e.indented;return e.context&&"statement"==e.context.type&&"statement"!=r&&(a=e.context.indented),e.context=new t(a,n,r,o,null,e.context)}function r(e){var t=e.context.type;return")"!=t&&"]"!=t&&"}"!=t||(e.indented=e.context.indented),e.context=e.context.prev}function o(e,t,n){return"variable"==t.prevToken||"type"==t.prevToken||(!!/\S(?:[^- ]>|[*\]])\s*$|\*$/.test(e.string.slice(0,n))||(!(!t.typeAtEndOfLine||e.column()!=e.indentation())||void 0))}function a(e){for(;;){if(!e||"top"==e.type)return!0;if("}"==e.type&&"namespace"!=e.prev.info)return!1;e=e.prev}}function i(e){for(var t={},n=e.split(" "),r=0;r<n.length;++r)t[n[r]]=!0;return t}function l(e,t){return"function"==typeof e?e(t):e.propertyIsEnumerable(t)}function s(e,t){if(!t.startOfLine)return!1;for(var n,r=null;n=e.peek();){if("\\"==n&&e.match(/^.$/)){r=s;break}if("/"==n&&e.match(/^\/[\/\*]/,!1))break;e.next()}return t.tokenize=r,"meta"}function c(e,t){return"type"==t.prevToken&&"type"}function u(e){return e.eatWhile(/[\w\.']/),"number"}function d(e,t){if(e.backUp(1),e.match(/(R|u8R|uR|UR|LR)/)){var n=e.match(/"([^\s\\()]{0,16})\(/);return!!n&&(t.cpp11RawStringDelim=n[1],t.tokenize=m,m(e,t))}return e.match(/(u8|u|U|L)/)?!!e.match(/["']/,!1)&&"string":(e.next(),!1)}function f(e){var t=/(\w+)::~?(\w+)$/.exec(e);return t&&t[1]==t[2]}function p(e,t){for(var n;null!=(n=e.next());)if('"'==n&&!e.eat('"')){t.tokenize=null;break}return"string"}function m(e,t){var n=t.cpp11RawStringDelim.replace(/[^\w\s]/g,"\\$&");return e.match(new RegExp(".*?\\)"+n+'"'))?t.tokenize=null:e.skipToEnd(),"string"}function h(t,n){function r(e){if(e)for(var t in e)e.hasOwnProperty(t)&&o.push(t)}"string"==typeof t&&(t=[t]);var o=[];r(n.keywords),r(n.types),r(n.builtin),r(n.atoms),o.length&&(n.helperType=t[0],e.registerHelper("hintWords",t[0],o));for(var a=0;a<t.length;++a)e.defineMIME(t[a],n)}function g(e,t){for(var n=!1;!e.eol();){if(!n&&e.match('"""')){t.tokenize=null;break}n="\\"==e.next()&&!n}return"string"}function y(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!e&&!o&&t.match('"')){a=!0;break}if(e&&t.match('"""')){a=!0;break}r=t.next(),!o&&"$"==r&&t.match("{")&&t.skipTo("}"),o=!o&&"\\"==r&&!e}return!a&&e||(n.tokenize=null),"string"}}function x(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!o&&t.match('"')&&("single"==e||t.match('""'))){a=!0;break}if(!o&&t.match("``")){w=x(e),a=!0;break}r=t.next(),o="single"==e&&!o&&"\\"==r}return a&&(n.tokenize=null),"string"}}e.defineMode("clike",function(i,s){function c(e,t){var n=e.next();if(S[n]){var r=S[n](e,t);if(!1!==r)return r}if('"'==n||"'"==n)return t.tokenize=u(n),t.tokenize(e,t);if(D.test(n))return p=n,null;if(L.test(n)){if(e.backUp(1),e.match(I))return"number";e.next()}if("/"==n){if(e.eat("*"))return t.tokenize=d,d(e,t);if(e.eat("/"))return e.skipToEnd(),"comment"}if(F.test(n)){for(;!e.match(/^\/[\/*]/,!1)&&e.eat(F););return"operator"}if(e.eatWhile(z),P)for(;e.match(P);)e.eatWhile(z);var o=e.current();return l(x,o)?(l(w,o)&&(p="newstatement"),l(v,o)&&(m=!0),"keyword"):l(b,o)?"type":l(k,o)?(l(w,o)&&(p="newstatement"),"builtin"):l(_,o)?"atom":"variable"}function u(e){return function(t,n){for(var r,o=!1,a=!1;null!=(r=t.next());){if(r==e&&!o){a=!0;break}o=!o&&"\\"==r}return(a||!o&&!C)&&(n.tokenize=null),"string"}}function d(e,t){for(var n,r=!1;n=e.next();){if("/"==n&&r){t.tokenize=null;break}r="*"==n}return"comment"}function f(e,t){s.typeFirstDefinitions&&e.eol()&&a(t.context)&&(t.typeAtEndOfLine=o(e,t,e.pos))}var p,m,h=i.indentUnit,g=s.statementIndentUnit||h,y=s.dontAlignCalls,x=s.keywords||{},b=s.types||{},k=s.builtin||{},w=s.blockKeywords||{},v=s.defKeywords||{},_=s.atoms||{},S=s.hooks||{},C=s.multiLineStrings,T=!1!==s.indentStatements,M=!1!==s.indentSwitch,P=s.namespaceSeparator,D=s.isPunctuationChar||/[\[\]{}\(\),;\:\.]/,L=s.numberStart||/[\d\.]/,I=s.number||/^(?:0x[a-f\d]+|0b[01]+|(?:\d+\.?\d*|\.\d+)(?:e[-+]?\d+)?)(u|ll?|l|f)?/i,F=s.isOperatorChar||/[+\-*&%=<>!?|\/]/,z=s.isIdentifierChar||/[\w\$_\xa1-\uffff]/;return{startState:function(e){return{tokenize:null,context:new t((e||0)-h,0,"top",null,!1),indented:0,startOfLine:!0,prevToken:null}},token:function(e,t){var i=t.context;if(e.sol()&&(null==i.align&&(i.align=!1),t.indented=e.indentation(),t.startOfLine=!0),e.eatSpace())return f(e,t),null;p=m=null;var l=(t.tokenize||c)(e,t);if("comment"==l||"meta"==l)return l;if(null==i.align&&(i.align=!0),";"==p||":"==p||","==p&&e.match(/^\s*(?:\/\/.*)?$/,!1))for(;"statement"==t.context.type;)r(t);else if("{"==p)n(t,e.column(),"}");else if("["==p)n(t,e.column(),"]");else if("("==p)n(t,e.column(),")");else if("}"==p){for(;"statement"==i.type;)i=r(t);for("}"==i.type&&(i=r(t));"statement"==i.type;)i=r(t)}else p==i.type?r(t):T&&(("}"==i.type||"top"==i.type)&&";"!=p||"statement"==i.type&&"newstatement"==p)&&n(t,e.column(),"statement",e.current());if("variable"==l&&("def"==t.prevToken||s.typeFirstDefinitions&&o(e,t,e.start)&&a(t.context)&&e.match(/^\s*\(/,!1))&&(l="def"),S.token){var u=S.token(e,t,l);void 0!==u&&(l=u)}return"def"==l&&!1===s.styleDefs&&(l="variable"),t.startOfLine=!1,t.prevToken=m?"def":l||p,f(e,t),l},indent:function(t,n){if(t.tokenize!=c&&null!=t.tokenize||t.typeAtEndOfLine)return e.Pass;var r=t.context,o=n&&n.charAt(0);if("statement"==r.type&&"}"==o&&(r=r.prev),s.dontIndentStatements)for(;"statement"==r.type&&s.dontIndentStatements.test(r.info);)r=r.prev;if(S.indent){var a=S.indent(t,r,n);if("number"==typeof a)return a}var i=o==r.type,l=r.prev&&"switch"==r.prev.info;if(s.allmanIndentation&&/[{(]/.test(o)){for(;"top"!=r.type&&"}"!=r.type;)r=r.prev;return r.indented}return"statement"==r.type?r.indented+("{"==o?0:g):!r.align||y&&")"==r.type?")"!=r.type||i?r.indented+(i?0:h)+(i||!l||/^(?:case|default)\b/.test(n)?0:h):r.indented+g:r.column+(i?0:1)},electricInput:M?/^\s*(?:case .*?:|default:|\{\}?|\})$/:/^\s*[{}]$/,blockCommentStart:"/*",blockCommentEnd:"*/",lineComment:"//",fold:"brace"}});var b="auto if break case register continue return default do sizeof static else struct switch extern typedef union for goto while enum const volatile",k="int long char short double float unsigned signed void size_t ptrdiff_t";h(["text/x-csrc","text/x-c","text/x-chdr"],{name:"clike",keywords:i(b),types:i(k+" bool _Complex _Bool float_t double_t intptr_t intmax_t int8_t int16_t int32_t int64_t uintptr_t uintmax_t uint8_t uint16_t uint32_t uint64_t"),blockKeywords:i("case do else for if switch while struct"),defKeywords:i("struct"),typeFirstDefinitions:!0,atoms:i("null true false"),hooks:{"#":s,"*":c},modeProps:{fold:["brace","include"]}}),h(["text/x-c++src","text/x-c++hdr"],{name:"clike",keywords:i(b+" asm dynamic_cast namespace reinterpret_cast try explicit new static_cast typeid catch operator template typename class friend private this using const_cast inline public throw virtual delete mutable protected alignas alignof constexpr decltype nullptr noexcept thread_local final static_assert override"),types:i(k+" bool wchar_t"),blockKeywords:i("catch class do else finally for if struct switch try while"),defKeywords:i("class namespace struct enum union"),typeFirstDefinitions:!0,atoms:i("true false null"),dontIndentStatements:/^template$/,isIdentifierChar:/[\w\$_~\xa1-\uffff]/,hooks:{"#":s,"*":c,u:d,U:d,L:d,R:d,0:u,1:u,2:u,3:u,4:u,5:u,6:u,7:u,8:u,9:u,token:function(e,t,n){if("variable"==n&&"("==e.peek()&&(";"==t.prevToken||null==t.prevToken||"}"==t.prevToken)&&f(e.current()))return"def"}},namespaceSeparator:"::",modeProps:{fold:["brace","include"]}}),h("text/x-java",{name:"clike",keywords:i("abstract assert break case catch class const continue default do else enum extends final finally float for goto if implements import instanceof interface native new package private protected public return static strictfp super switch synchronized this throw throws transient try volatile while @interface"),types:i("byte short int long float double boolean char void Boolean Byte Character Double Float Integer Long Number Object Short String StringBuffer StringBuilder Void"),blockKeywords:i("catch class do else finally for if switch try while"),defKeywords:i("class interface package enum @interface"),typeFirstDefinitions:!0,atoms:i("true false null"),number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,hooks:{"@":function(e){return!e.match("interface",!1)&&(e.eatWhile(/[\w\$_]/),"meta")}},modeProps:{fold:["brace","import"]}}),h("text/x-csharp",{name:"clike",keywords:i("abstract as async await base break case catch checked class const continue default delegate do else enum event explicit extern finally fixed for foreach goto if implicit in interface internal is lock namespace new operator out override params private protected public readonly ref return sealed sizeof stackalloc static struct switch this throw try typeof unchecked unsafe using virtual void volatile while add alias ascending descending dynamic from get global group into join let orderby partial remove select set value var yield"),types:i("Action Boolean Byte Char DateTime DateTimeOffset Decimal Double Func Guid Int16 Int32 Int64 Object SByte Single String Task TimeSpan UInt16 UInt32 UInt64 bool byte char decimal double short int long object sbyte float string ushort uint ulong"),blockKeywords:i("catch class do else finally for foreach if struct switch try while"),defKeywords:i("class interface namespace struct var"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"@":function(e,t){return e.eat('"')?(t.tokenize=p,p(e,t)):(e.eatWhile(/[\w\$_]/),"meta")}}}),h("text/x-scala",{name:"clike",keywords:i("abstract case catch class def do else extends final finally for forSome if implicit import lazy match new null object override package private protected return sealed super this throw trait try type val var while with yield _ assert assume require print println printf readLine readBoolean readByte readShort readChar readInt readLong readFloat readDouble"),types:i("AnyVal App Application Array BufferedIterator BigDecimal BigInt Char Console Either Enumeration Equiv Error Exception Fractional Function IndexedSeq Int Integral Iterable Iterator List Map Numeric Nil NotNull Option Ordered Ordering PartialFunction PartialOrdering Product Proxy Range Responder Seq Serializable Set Specializable Stream StringBuilder StringContext Symbol Throwable Traversable TraversableOnce Tuple Unit Vector Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),multiLineStrings:!0,blockKeywords:i("catch class enum do else finally for forSome if match switch try while"),defKeywords:i("class enum def object package trait type val var"),atoms:i("true false null"),indentStatements:!1,indentSwitch:!1,isOperatorChar:/[+\-*&%=<>!?|\/#:@]/,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return!!e.match('""')&&(t.tokenize=g,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},"=":function(e,n){var r=n.context;return!("}"!=r.type||!r.align||!e.eat(">"))&&(n.context=new t(r.indented,r.column,r.type,r.info,null,r.prev),"operator")}},modeProps:{closeBrackets:{triples:'"'}}}),h("text/x-kotlin",{name:"clike",keywords:i("package as typealias class interface this super val var fun for is in This throw return break continue object if else while do try when !in !is as? file import where by get set abstract enum open inner override private public internal protected catch finally out final vararg reified dynamic companion constructor init sealed field property receiver param sparam lateinit data inline noinline tailrec external annotation crossinline const operator infix suspend"),types:i("Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),intendSwitch:!1,indentStatements:!1,multiLineStrings:!0,number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,blockKeywords:i("catch class do else finally for if where try while enum"),defKeywords:i("class val var object package interface fun"),atoms:i("true false null this"),hooks:{'"':function(e,t){return t.tokenize=y(e.match('""')),t.tokenize(e,t)}},modeProps:{closeBrackets:{triples:'"'}}}),h(["x-shader/x-vertex","x-shader/x-fragment"],{name:"clike",keywords:i("sampler1D sampler2D sampler3D samplerCube sampler1DShadow sampler2DShadow const attribute uniform varying break continue discard return for while do if else struct in out inout"),types:i("float int bool void vec2 vec3 vec4 ivec2 ivec3 ivec4 bvec2 bvec3 bvec4 mat2 mat3 mat4"),blockKeywords:i("for while do if else struct"),builtin:i("radians degrees sin cos tan asin acos atan pow exp log exp2 sqrt inversesqrt abs sign floor ceil fract mod min max clamp mix step smoothstep length distance dot cross normalize ftransform faceforward reflect refract matrixCompMult lessThan lessThanEqual greaterThan greaterThanEqual equal notEqual any all not texture1D texture1DProj texture1DLod texture1DProjLod texture2D texture2DProj texture2DLod texture2DProjLod texture3D texture3DProj texture3DLod texture3DProjLod textureCube textureCubeLod shadow1D shadow2D shadow1DProj shadow2DProj shadow1DLod shadow2DLod shadow1DProjLod shadow2DProjLod dFdx dFdy fwidth noise1 noise2 noise3 noise4"),atoms:i("true false gl_FragColor gl_SecondaryColor gl_Normal gl_Vertex gl_MultiTexCoord0 gl_MultiTexCoord1 gl_MultiTexCoord2 gl_MultiTexCoord3 gl_MultiTexCoord4 gl_MultiTexCoord5 gl_MultiTexCoord6 gl_MultiTexCoord7 gl_FogCoord gl_PointCoord gl_Position gl_PointSize gl_ClipVertex gl_FrontColor gl_BackColor gl_FrontSecondaryColor gl_BackSecondaryColor gl_TexCoord gl_FogFragCoord gl_FragCoord gl_FrontFacing gl_FragData gl_FragDepth gl_ModelViewMatrix gl_ProjectionMatrix gl_ModelViewProjectionMatrix gl_TextureMatrix gl_NormalMatrix gl_ModelViewMatrixInverse gl_ProjectionMatrixInverse gl_ModelViewProjectionMatrixInverse gl_TexureMatrixTranspose gl_ModelViewMatrixInverseTranspose gl_ProjectionMatrixInverseTranspose gl_ModelViewProjectionMatrixInverseTranspose gl_TextureMatrixInverseTranspose gl_NormalScale gl_DepthRange gl_ClipPlane gl_Point gl_FrontMaterial gl_BackMaterial gl_LightSource gl_LightModel gl_FrontLightModelProduct gl_BackLightModelProduct gl_TextureColor gl_EyePlaneS gl_EyePlaneT gl_EyePlaneR gl_EyePlaneQ gl_FogParameters gl_MaxLights gl_MaxClipPlanes gl_MaxTextureUnits gl_MaxTextureCoords gl_MaxVertexAttribs gl_MaxVertexUniformComponents gl_MaxVaryingFloats gl_MaxVertexTextureImageUnits gl_MaxTextureImageUnits gl_MaxFragmentUniformComponents gl_MaxCombineTextureImageUnits gl_MaxDrawBuffers"),indentSwitch:!1,hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-nesc",{name:"clike",keywords:i(b+"as atomic async call command component components configuration event generic implementation includes interface module new norace nx_struct nx_union post provides signal task uses abstract extends"),types:i(k),blockKeywords:i("case do else for if switch while struct"),atoms:i("null true false"),hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-objectivec",{name:"clike",keywords:i(b+"inline restrict _Bool _Complex _Imaginary BOOL Class bycopy byref id IMP in inout nil oneway out Protocol SEL self super atomic nonatomic retain copy readwrite readonly"),types:i(k),atoms:i("YES NO NULL NILL ON OFF true false"),hooks:{"@":function(e){return e.eatWhile(/[\w\$]/),"keyword"},"#":s,indent:function(e,t,n){if("statement"==t.type&&/^@\w/.test(n))return t.indented}},modeProps:{fold:"brace"}}),h("text/x-squirrel",{name:"clike",keywords:i("base break clone continue const default delete enum extends function in class foreach local resume return this throw typeof yield constructor instanceof static"),types:i(k),blockKeywords:i("case catch class else for foreach if switch try while"),defKeywords:i("function local class"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"#":s},modeProps:{fold:["brace","include"]}});var w=null;h("text/x-ceylon",{name:"clike",keywords:i("abstracts alias assembly assert assign break case catch class continue dynamic else exists extends finally for function given if import in interface is let module new nonempty object of out outer package return satisfies super switch then this throw try value void while"),types:function(e){var t=e.charAt(0);return t===t.toUpperCase()&&t!==t.toLowerCase()},blockKeywords:i("case catch class dynamic else finally for function if interface module new object switch try while"),defKeywords:i("class dynamic function interface module object package value"),builtin:i("abstract actual aliased annotation by default deprecated doc final formal late license native optional sealed see serializable shared suppressWarnings tagged throws variable"),isPunctuationChar:/[\[\]{}\(\),;\:\.`]/,isOperatorChar:/[+\-*&%=<>!?|^~:\/]/,numberStart:/[\d#$]/,number:/^(?:#[\da-fA-F_]+|\$[01_]+|[\d_]+[kMGTPmunpf]?|[\d_]+\.[\d_]+(?:[eE][-+]?\d+|[kMGTPmunpf]|)|)/i,multiLineStrings:!0,typeFirstDefinitions:!0,atoms:i("true false null larger smaller equal empty finished"),indentSwitch:!1,styleDefs:!1,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return t.tokenize=x(e.match('""')?"triple":"single"),t.tokenize(e,t)},"`":function(e,t){return!(!w||!e.match("`"))&&(t.tokenize=w,w=null,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},token:function(e,t,n){if(("variable"==n||"type"==n)&&"."==t.prevToken)return"variable-2"}},modeProps:{fold:["brace","import"],closeBrackets:{triples:'"'}}})});
      // -------------------------------------------------------------------------
//  Part of the CodeChecker project, under the Apache License v2.0 with
//  LLVM Exceptions. See LICENSE for license information.
//  SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
// -------------------------------------------------------------------------

var BugViewer = {
  _files : [],
  _reports : [],
  _lineWidgets : [],
  _navigationMenuItems : [],
  _sourceFileData : null,
  _currentReport : null,
  _lastBugEvent  : null,

  init : function (files, reports) {
    this._files = files;
    this._reports = reports;

    this.initEscapeChars();
  },

  initEscapeChars : function () {
    this.escapeChars = {
      ' ' : 'nbsp',
      '<' : 'lt',
      '>' : 'gt',
      '"' : 'quot',
      '&' : 'amp'
    };

    var regexString = '[';
    for (var key in this.escapeChars) {
      regexString += key;
    }
    regexString += ']';

    this.escapeRegExp = new RegExp( regexString, 'g');
  },

  escapeHTML : function (str) {
    var that = this;

    return str.replace(this.escapeRegExp, function (m) {
      return '&' + that.escapeChars[m] + ';';
    });
  },

  initByUrl : function () {
    if (!this._reports) return;

    var state = {};
    window.location.hash.substr(1).split('&').forEach(function (s) {
      var parts = s.split('=');
      state[parts[0]] = parts[1];
    });

    for (var key in this._reports) {
      var report = this._reports[key];
      if (report.reportHash === state['reportHash']) {
        this.navigate(report);
        return;
      }
    }

    this.navigate(this._reports[0]);
  },

  create : function () {
    this._content = document.getElementById('editor-wrapper');
    this._filepath = document.getElementById('file-path');
    this._checkerName = document.getElementById('checker-name');
    this._reviewStatusWrapper =
      document.getElementById('review-status-wrapper');
    this._reviewStatus = document.getElementById('review-status');
    this._editor = document.getElementById('editor');

    this._codeMirror = CodeMirror(this._editor, {
      mode: 'text/x-c++src',
      matchBrackets : true,
      lineNumbers : true,
      readOnly : true,
      foldGutter : true,
      extraKeys : {},
      viewportMargin : 100
    });

    this._createNavigationMenu();
  },

  navigate : function (report, item) {
    if (!item) {
      var items = this._navigationMenuItems.filter(function (navItem) {
        return navItem.report.reportHash === report.reportHash;
      });

      if (!items.length) return;

      item = items[0].widget;
    }

    this._selectedReport.classList.remove('active');
    this._selectedReport = item;
    this._selectedReport.classList.add('active');
    this.setReport(report);
  },

  _createNavigationMenu : function () {
    var that = this;

    var nav = document.getElementById('report-nav');
    var list = document.createElement('ul');
    this._reports.forEach(function (report) {
      var events = report['events'];
      var lastBugEvent = events[events.length - 1];
      var item = document.createElement('li');

      var severity = document.createElement('i');
      severity.className = 'severity-' + report.severity.toLowerCase();

      item.appendChild(severity);
      item.appendChild(document.createTextNode(lastBugEvent.message));

      item.addEventListener('click', function () {
        that.navigate(report, item);
      })
      list.appendChild(item);
      that._navigationMenuItems.push({ report : report, widget : item });
    });

    if (!this._selectedReport && list.childNodes.length) {
      this._selectedReport = list.childNodes[0];
      this._selectedReport.classList.add('active');
    }

    nav.appendChild(list);
  },

  setReport : function (report) {
    this._currentReport = report;
    var events = report['events'];
    var lastBugEvent = events[events.length - 1];
    this.setCurrentBugEvent(lastBugEvent, events.length - 1);
    this.setCheckerName(report.checkerName);
    this.setReviewStatus(report.reviewStatus);

    window.location.hash = '#reportHash=' + report.reportHash;
  },

  setCurrentBugEvent : function (event, idx) {
    this._currentBugEvent = event;
    this.setSourceFileData(this._files[event.location.file]);
    this.drawBugPath();

    this.jumpTo(event.location.line, 0);
    this.highlightBugEvent(event, idx);
  },

  highlightBugEvent : function (event, idx) {
    this._lineWidgets.forEach(function (widget) {
      var lineIdx = widget.node.getAttribute('idx');
      if (parseInt(lineIdx) === idx) {
        widget.node.classList.add('current');
      }
    });
  },

  setCheckerName : function (checkerName) {
    this._checkerName.innerHTML = checkerName;
  },

  setReviewStatus : function (status) {
    if (status) {
      var className =
        'review-status-' + status.toLowerCase().split(' ').join('-');
      this._reviewStatus.className = "review-status " + className;

      this._reviewStatus.innerHTML = status;
      this._reviewStatusWrapper.style.display = 'block';
    } else {
      this._reviewStatusWrapper.style.display = 'none';
    }
  },

  setSourceFileData : function (file) {
    if (this._sourceFileData && file.id === this._sourceFileData.id) {
      return;
    }

    this._sourceFileData = file;
    this._filepath.innerHTML = file.path;
    this._codeMirror.doc.setValue(file.content);
    this._refresh();
  },

  _refresh : function () {
    var that = this;
    setTimeout(function () {
      var fullHeight = parseInt(that._content.clientHeight);
      var headerHeight = that._filepath.clientHeight;

      that._codeMirror.setSize('auto', fullHeight - headerHeight);
      that._codeMirror.refresh();
    }, 200);
  },

  clearBubbles : function () {
    this._lineWidgets.forEach(function (widget) { widget.clear(); });
    this._lineWidgets = [];
  },

  getMessage : function (event, kind) {
    if (kind === 'macro') {
      var name = 'macro expansion' + (event.name ? ': ' + event.name : '');

      return '<span class="tag macro">' + name + '</span>'
        + this.escapeHTML(event.expansion).replace(/(?:\r\n|\r|\n)/g, '<br>');
    } else if (kind === 'note') {
      return '<span class="tag note">note</span>'
        +  this.escapeHTML(event.message).replace(/(?:\r\n|\r|\n)/g, '<br>');
    }
  },

  addExtraPathEvents : function (events, kind) {
    var that = this;

    if (!events) {
      return;
    }

    events.forEach(function (event) {
      if (event.location.file !== that._currentBugEvent.location.file) {
        return;
      }

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + kind);

      var msg = document.createElement('span');
      msg.innerHTML = that.getMessage(event, kind);
      element.appendChild(msg);

      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  drawBugPath : function () {
    var that = this;

    this.clearBubbles();

    this.addExtraPathEvents(this._currentReport.macros, 'macro');
    this.addExtraPathEvents(this._currentReport.notes, 'note');

    // Processing bug path events.
    var currentEvents = this._currentReport.events;
    currentEvents.forEach(function (event, step) {
      if (event.location.file !== that._currentBugEvent.location.file)
        return;

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';
      var type = step === currentEvents.length - 1 ? 'error' : 'info';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + type);
      element.setAttribute('idx', step);

      var enumeration = document.createElement('span');
      enumeration.setAttribute('class', 'checker-enum ' + type);
      enumeration.innerHTML = step + 1;

      if (currentEvents.length > 1)
        element.appendChild(enumeration);

      var prevBugEvent = step - 1;
      if (step > 0) {
        var prevBug = document.createElement('span');
        prevBug.setAttribute('class', 'arrow left-arrow');
        prevBug.addEventListener('click', function () {
          var event = currentEvents[prevBugEvent];
          that.setCurrentBugEvent(event, prevBugEvent);
        });
        element.appendChild(prevBug);
      }

      var msg = document.createElement('span');
      msg.innerHTML = that.escapeHTML(event.message)
        .replace(/(?:\r\n|\r|\n)/g, '<br>');

      element.appendChild(msg);

      var nextBugEvent = step + 1;
      if (nextBugEvent < currentEvents.length) {
        var nextBug = document.createElement('span');
        nextBug.setAttribute('class', 'arrow right-arrow');
        nextBug.addEventListener('click', function () {
          var event = currentEvents[nextBugEvent];
          that.setCurrentBugEvent(event, nextBugEvent);
        });
        element.appendChild(nextBug);
      }


      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  jumpTo : function (line, column) {
    var that = this;

    setTimeout(function () {
      var selPosPixel
        = that._codeMirror.charCoords({ line : line, ch : column }, 'local');
      var editorSize = {
        width  : that._editor.clientWidth,
        height : that._editor.clientHeight
      };

      that._codeMirror.scrollIntoView({
        top    : selPosPixel.top - 100,
        bottom : selPosPixel.top + editorSize.height - 150,
        left   : selPosPixel.left < editorSize.width - 100
               ? 0
               : selPosPixel.left - 50,
        right  : selPosPixel.left < editorSize.width - 100
               ? 10
               : selPosPixel.left + editorSize.width - 100
      });
    }, 0);
  }
}


      var data = {"files": {"0": {"id": 0, "path": "/src/arch/x86/kvm/vmx/vmx.c", "content": "// SPDX-License-Identifier: GPL-2.0-only\n/*\n * Kernel-based Virtual Machine driver for Linux\n *\n * This module enables machines with Intel VT-x extensions to run virtual\n * machines without emulation or binary translation.\n *\n * Copyright (C) 2006 Qumranet, Inc.\n * Copyright 2010 Red Hat, Inc. and/or its affiliates.\n *\n * Authors:\n *   Avi Kivity   <avi@qumranet.com>\n *   Yaniv Kamay  <yaniv@qumranet.com>\n */\n\n#include <linux/highmem.h>\n#include <linux/hrtimer.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/module.h>\n#include <linux/moduleparam.h>\n#include <linux/mod_devicetable.h>\n#include <linux/mm.h>\n#include <linux/objtool.h>\n#include <linux/sched.h>\n#include <linux/sched/smt.h>\n#include <linux/slab.h>\n#include <linux/tboot.h>\n#include <linux/trace_events.h>\n#include <linux/entry-kvm.h>\n\n#include <asm/apic.h>\n#include <asm/asm.h>\n#include <asm/cpu.h>\n#include <asm/cpu_device_id.h>\n#include <asm/debugreg.h>\n#include <asm/desc.h>\n#include <asm/fpu/internal.h>\n#include <asm/io.h>\n#include <asm/irq_remapping.h>\n#include <asm/kexec.h>\n#include <asm/perf_event.h>\n#include <asm/mce.h>\n#include <asm/mmu_context.h>\n#include <asm/mshyperv.h>\n#include <asm/mwait.h>\n#include <asm/spec-ctrl.h>\n#include <asm/virtext.h>\n#include <asm/vmx.h>\n\n#include \"capabilities.h\"\n#include \"cpuid.h\"\n#include \"evmcs.h\"\n#include \"irq.h\"\n#include \"kvm_cache_regs.h\"\n#include \"lapic.h\"\n#include \"mmu.h\"\n#include \"nested.h\"\n#include \"pmu.h\"\n#include \"trace.h\"\n#include \"vmcs.h\"\n#include \"vmcs12.h\"\n#include \"vmx.h\"\n#include \"x86.h\"\n\nMODULE_AUTHOR(\"Qumranet\");\nMODULE_LICENSE(\"GPL\");\n\n#ifdef MODULE\nstatic const struct x86_cpu_id vmx_cpu_id[] = {\n\tX86_MATCH_FEATURE(X86_FEATURE_VMX, NULL),\n\t{}\n};\nMODULE_DEVICE_TABLE(x86cpu, vmx_cpu_id);\n#endif\n\nbool __read_mostly enable_vpid = 1;\nmodule_param_named(vpid, enable_vpid, bool, 0444);\n\nstatic bool __read_mostly enable_vnmi = 1;\nmodule_param_named(vnmi, enable_vnmi, bool, S_IRUGO);\n\nbool __read_mostly flexpriority_enabled = 1;\nmodule_param_named(flexpriority, flexpriority_enabled, bool, S_IRUGO);\n\nbool __read_mostly enable_ept = 1;\nmodule_param_named(ept, enable_ept, bool, S_IRUGO);\n\nbool __read_mostly enable_unrestricted_guest = 1;\nmodule_param_named(unrestricted_guest,\n\t\t\tenable_unrestricted_guest, bool, S_IRUGO);\n\nbool __read_mostly enable_ept_ad_bits = 1;\nmodule_param_named(eptad, enable_ept_ad_bits, bool, S_IRUGO);\n\nstatic bool __read_mostly emulate_invalid_guest_state = true;\nmodule_param(emulate_invalid_guest_state, bool, S_IRUGO);\n\nstatic bool __read_mostly fasteoi = 1;\nmodule_param(fasteoi, bool, S_IRUGO);\n\nbool __read_mostly enable_apicv = 1;\nmodule_param(enable_apicv, bool, S_IRUGO);\n\n/*\n * If nested=1, nested virtualization is supported, i.e., guests may use\n * VMX and be a hypervisor for its own guests. If nested=0, guests may not\n * use VMX instructions.\n */\nstatic bool __read_mostly nested = 1;\nmodule_param(nested, bool, S_IRUGO);\n\nbool __read_mostly enable_pml = 1;\nmodule_param_named(pml, enable_pml, bool, S_IRUGO);\n\nstatic bool __read_mostly dump_invalid_vmcs = 0;\nmodule_param(dump_invalid_vmcs, bool, 0644);\n\n#define MSR_BITMAP_MODE_X2APIC\t\t1\n#define MSR_BITMAP_MODE_X2APIC_APICV\t2\n\n#define KVM_VMX_TSC_MULTIPLIER_MAX     0xffffffffffffffffULL\n\n/* Guest_tsc -> host_tsc conversion requires 64-bit division.  */\nstatic int __read_mostly cpu_preemption_timer_multi;\nstatic bool __read_mostly enable_preemption_timer = 1;\n#ifdef CONFIG_X86_64\nmodule_param_named(preemption_timer, enable_preemption_timer, bool, S_IRUGO);\n#endif\n\nextern bool __read_mostly allow_smaller_maxphyaddr;\nmodule_param(allow_smaller_maxphyaddr, bool, S_IRUGO);\n\n#define KVM_VM_CR0_ALWAYS_OFF (X86_CR0_NW | X86_CR0_CD)\n#define KVM_VM_CR0_ALWAYS_ON_UNRESTRICTED_GUEST X86_CR0_NE\n#define KVM_VM_CR0_ALWAYS_ON\t\t\t\t\\\n\t(KVM_VM_CR0_ALWAYS_ON_UNRESTRICTED_GUEST | \t\\\n\t X86_CR0_WP | X86_CR0_PG | X86_CR0_PE)\n\n#define KVM_VM_CR4_ALWAYS_ON_UNRESTRICTED_GUEST X86_CR4_VMXE\n#define KVM_PMODE_VM_CR4_ALWAYS_ON (X86_CR4_PAE | X86_CR4_VMXE)\n#define KVM_RMODE_VM_CR4_ALWAYS_ON (X86_CR4_VME | X86_CR4_PAE | X86_CR4_VMXE)\n\n#define RMODE_GUEST_OWNED_EFLAGS_BITS (~(X86_EFLAGS_IOPL | X86_EFLAGS_VM))\n\n#define MSR_IA32_RTIT_STATUS_MASK (~(RTIT_STATUS_FILTEREN | \\\n\tRTIT_STATUS_CONTEXTEN | RTIT_STATUS_TRIGGEREN | \\\n\tRTIT_STATUS_ERROR | RTIT_STATUS_STOPPED | \\\n\tRTIT_STATUS_BYTECNT))\n\n/*\n * List of MSRs that can be directly passed to the guest.\n * In addition to these x2apic and PT MSRs are handled specially.\n */\nstatic u32 vmx_possible_passthrough_msrs[MAX_POSSIBLE_PASSTHROUGH_MSRS] = {\n\tMSR_IA32_SPEC_CTRL,\n\tMSR_IA32_PRED_CMD,\n\tMSR_IA32_TSC,\n\tMSR_FS_BASE,\n\tMSR_GS_BASE,\n\tMSR_KERNEL_GS_BASE,\n\tMSR_IA32_SYSENTER_CS,\n\tMSR_IA32_SYSENTER_ESP,\n\tMSR_IA32_SYSENTER_EIP,\n\tMSR_CORE_C1_RES,\n\tMSR_CORE_C3_RESIDENCY,\n\tMSR_CORE_C6_RESIDENCY,\n\tMSR_CORE_C7_RESIDENCY,\n};\n\n/*\n * These 2 parameters are used to config the controls for Pause-Loop Exiting:\n * ple_gap:    upper bound on the amount of time between two successive\n *             executions of PAUSE in a loop. Also indicate if ple enabled.\n *             According to test, this time is usually smaller than 128 cycles.\n * ple_window: upper bound on the amount of time a guest is allowed to execute\n *             in a PAUSE loop. Tests indicate that most spinlocks are held for\n *             less than 2^12 cycles\n * Time is measured based on a counter that runs at the same rate as the TSC,\n * refer SDM volume 3b section 21.6.13 & 22.1.3.\n */\nstatic unsigned int ple_gap = KVM_DEFAULT_PLE_GAP;\nmodule_param(ple_gap, uint, 0444);\n\nstatic unsigned int ple_window = KVM_VMX_DEFAULT_PLE_WINDOW;\nmodule_param(ple_window, uint, 0444);\n\n/* Default doubles per-vcpu window every exit. */\nstatic unsigned int ple_window_grow = KVM_DEFAULT_PLE_WINDOW_GROW;\nmodule_param(ple_window_grow, uint, 0444);\n\n/* Default resets per-vcpu window every exit to ple_window. */\nstatic unsigned int ple_window_shrink = KVM_DEFAULT_PLE_WINDOW_SHRINK;\nmodule_param(ple_window_shrink, uint, 0444);\n\n/* Default is to compute the maximum so we can never overflow. */\nstatic unsigned int ple_window_max        = KVM_VMX_DEFAULT_PLE_WINDOW_MAX;\nmodule_param(ple_window_max, uint, 0444);\n\n/* Default is SYSTEM mode, 1 for host-guest mode */\nint __read_mostly pt_mode = PT_MODE_SYSTEM;\nmodule_param(pt_mode, int, S_IRUGO);\n\nstatic DEFINE_STATIC_KEY_FALSE(vmx_l1d_should_flush);\nstatic DEFINE_STATIC_KEY_FALSE(vmx_l1d_flush_cond);\nstatic DEFINE_MUTEX(vmx_l1d_flush_mutex);\n\n/* Storage for pre module init parameter parsing */\nstatic enum vmx_l1d_flush_state __read_mostly vmentry_l1d_flush_param = VMENTER_L1D_FLUSH_AUTO;\n\nstatic const struct {\n\tconst char *option;\n\tbool for_parse;\n} vmentry_l1d_param[] = {\n\t[VMENTER_L1D_FLUSH_AUTO]\t = {\"auto\", true},\n\t[VMENTER_L1D_FLUSH_NEVER]\t = {\"never\", true},\n\t[VMENTER_L1D_FLUSH_COND]\t = {\"cond\", true},\n\t[VMENTER_L1D_FLUSH_ALWAYS]\t = {\"always\", true},\n\t[VMENTER_L1D_FLUSH_EPT_DISABLED] = {\"EPT disabled\", false},\n\t[VMENTER_L1D_FLUSH_NOT_REQUIRED] = {\"not required\", false},\n};\n\n#define L1D_CACHE_ORDER 4\nstatic void *vmx_l1d_flush_pages;\n\nstatic int vmx_setup_l1d_flush(enum vmx_l1d_flush_state l1tf)\n{\n\tstruct page *page;\n\tunsigned int i;\n\n\tif (!boot_cpu_has_bug(X86_BUG_L1TF)) {\n\t\tl1tf_vmx_mitigation = VMENTER_L1D_FLUSH_NOT_REQUIRED;\n\t\treturn 0;\n\t}\n\n\tif (!enable_ept) {\n\t\tl1tf_vmx_mitigation = VMENTER_L1D_FLUSH_EPT_DISABLED;\n\t\treturn 0;\n\t}\n\n\tif (boot_cpu_has(X86_FEATURE_ARCH_CAPABILITIES)) {\n\t\tu64 msr;\n\n\t\trdmsrl(MSR_IA32_ARCH_CAPABILITIES, msr);\n\t\tif (msr & ARCH_CAP_SKIP_VMENTRY_L1DFLUSH) {\n\t\t\tl1tf_vmx_mitigation = VMENTER_L1D_FLUSH_NOT_REQUIRED;\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\t/* If set to auto use the default l1tf mitigation method */\n\tif (l1tf == VMENTER_L1D_FLUSH_AUTO) {\n\t\tswitch (l1tf_mitigation) {\n\t\tcase L1TF_MITIGATION_OFF:\n\t\t\tl1tf = VMENTER_L1D_FLUSH_NEVER;\n\t\t\tbreak;\n\t\tcase L1TF_MITIGATION_FLUSH_NOWARN:\n\t\tcase L1TF_MITIGATION_FLUSH:\n\t\tcase L1TF_MITIGATION_FLUSH_NOSMT:\n\t\t\tl1tf = VMENTER_L1D_FLUSH_COND;\n\t\t\tbreak;\n\t\tcase L1TF_MITIGATION_FULL:\n\t\tcase L1TF_MITIGATION_FULL_FORCE:\n\t\t\tl1tf = VMENTER_L1D_FLUSH_ALWAYS;\n\t\t\tbreak;\n\t\t}\n\t} else if (l1tf_mitigation == L1TF_MITIGATION_FULL_FORCE) {\n\t\tl1tf = VMENTER_L1D_FLUSH_ALWAYS;\n\t}\n\n\tif (l1tf != VMENTER_L1D_FLUSH_NEVER && !vmx_l1d_flush_pages &&\n\t    !boot_cpu_has(X86_FEATURE_FLUSH_L1D)) {\n\t\t/*\n\t\t * This allocation for vmx_l1d_flush_pages is not tied to a VM\n\t\t * lifetime and so should not be charged to a memcg.\n\t\t */\n\t\tpage = alloc_pages(GFP_KERNEL, L1D_CACHE_ORDER);\n\t\tif (!page)\n\t\t\treturn -ENOMEM;\n\t\tvmx_l1d_flush_pages = page_address(page);\n\n\t\t/*\n\t\t * Initialize each page with a different pattern in\n\t\t * order to protect against KSM in the nested\n\t\t * virtualization case.\n\t\t */\n\t\tfor (i = 0; i < 1u << L1D_CACHE_ORDER; ++i) {\n\t\t\tmemset(vmx_l1d_flush_pages + i * PAGE_SIZE, i + 1,\n\t\t\t       PAGE_SIZE);\n\t\t}\n\t}\n\n\tl1tf_vmx_mitigation = l1tf;\n\n\tif (l1tf != VMENTER_L1D_FLUSH_NEVER)\n\t\tstatic_branch_enable(&vmx_l1d_should_flush);\n\telse\n\t\tstatic_branch_disable(&vmx_l1d_should_flush);\n\n\tif (l1tf == VMENTER_L1D_FLUSH_COND)\n\t\tstatic_branch_enable(&vmx_l1d_flush_cond);\n\telse\n\t\tstatic_branch_disable(&vmx_l1d_flush_cond);\n\treturn 0;\n}\n\nstatic int vmentry_l1d_flush_parse(const char *s)\n{\n\tunsigned int i;\n\n\tif (s) {\n\t\tfor (i = 0; i < ARRAY_SIZE(vmentry_l1d_param); i++) {\n\t\t\tif (vmentry_l1d_param[i].for_parse &&\n\t\t\t    sysfs_streq(s, vmentry_l1d_param[i].option))\n\t\t\t\treturn i;\n\t\t}\n\t}\n\treturn -EINVAL;\n}\n\nstatic int vmentry_l1d_flush_set(const char *s, const struct kernel_param *kp)\n{\n\tint l1tf, ret;\n\n\tl1tf = vmentry_l1d_flush_parse(s);\n\tif (l1tf < 0)\n\t\treturn l1tf;\n\n\tif (!boot_cpu_has(X86_BUG_L1TF))\n\t\treturn 0;\n\n\t/*\n\t * Has vmx_init() run already? If not then this is the pre init\n\t * parameter parsing. In that case just store the value and let\n\t * vmx_init() do the proper setup after enable_ept has been\n\t * established.\n\t */\n\tif (l1tf_vmx_mitigation == VMENTER_L1D_FLUSH_AUTO) {\n\t\tvmentry_l1d_flush_param = l1tf;\n\t\treturn 0;\n\t}\n\n\tmutex_lock(&vmx_l1d_flush_mutex);\n\tret = vmx_setup_l1d_flush(l1tf);\n\tmutex_unlock(&vmx_l1d_flush_mutex);\n\treturn ret;\n}\n\nstatic int vmentry_l1d_flush_get(char *s, const struct kernel_param *kp)\n{\n\tif (WARN_ON_ONCE(l1tf_vmx_mitigation >= ARRAY_SIZE(vmentry_l1d_param)))\n\t\treturn sprintf(s, \"???\\n\");\n\n\treturn sprintf(s, \"%s\\n\", vmentry_l1d_param[l1tf_vmx_mitigation].option);\n}\n\nstatic const struct kernel_param_ops vmentry_l1d_flush_ops = {\n\t.set = vmentry_l1d_flush_set,\n\t.get = vmentry_l1d_flush_get,\n};\nmodule_param_cb(vmentry_l1d_flush, &vmentry_l1d_flush_ops, NULL, 0644);\n\nstatic u32 vmx_segment_access_rights(struct kvm_segment *var);\nstatic __always_inline void vmx_disable_intercept_for_msr(struct kvm_vcpu *vcpu,\n\t\t\t\t\t\t\t  u32 msr, int type);\n\nvoid vmx_vmexit(void);\n\n#define vmx_insn_failed(fmt...)\t\t\\\ndo {\t\t\t\t\t\\\n\tWARN_ONCE(1, fmt);\t\t\\\n\tpr_warn_ratelimited(fmt);\t\\\n} while (0)\n\nasmlinkage void vmread_error(unsigned long field, bool fault)\n{\n\tif (fault)\n\t\tkvm_spurious_fault();\n\telse\n\t\tvmx_insn_failed(\"kvm: vmread failed: field=%lx\\n\", field);\n}\n\nnoinline void vmwrite_error(unsigned long field, unsigned long value)\n{\n\tvmx_insn_failed(\"kvm: vmwrite failed: field=%lx val=%lx err=%d\\n\",\n\t\t\tfield, value, vmcs_read32(VM_INSTRUCTION_ERROR));\n}\n\nnoinline void vmclear_error(struct vmcs *vmcs, u64 phys_addr)\n{\n\tvmx_insn_failed(\"kvm: vmclear failed: %p/%llx\\n\", vmcs, phys_addr);\n}\n\nnoinline void vmptrld_error(struct vmcs *vmcs, u64 phys_addr)\n{\n\tvmx_insn_failed(\"kvm: vmptrld failed: %p/%llx\\n\", vmcs, phys_addr);\n}\n\nnoinline void invvpid_error(unsigned long ext, u16 vpid, gva_t gva)\n{\n\tvmx_insn_failed(\"kvm: invvpid failed: ext=0x%lx vpid=%u gva=0x%lx\\n\",\n\t\t\text, vpid, gva);\n}\n\nnoinline void invept_error(unsigned long ext, u64 eptp, gpa_t gpa)\n{\n\tvmx_insn_failed(\"kvm: invept failed: ext=0x%lx eptp=%llx gpa=0x%llx\\n\",\n\t\t\text, eptp, gpa);\n}\n\nstatic DEFINE_PER_CPU(struct vmcs *, vmxarea);\nDEFINE_PER_CPU(struct vmcs *, current_vmcs);\n/*\n * We maintain a per-CPU linked-list of VMCS loaded on that CPU. This is needed\n * when a CPU is brought down, and we need to VMCLEAR all VMCSs loaded on it.\n */\nstatic DEFINE_PER_CPU(struct list_head, loaded_vmcss_on_cpu);\n\nstatic DECLARE_BITMAP(vmx_vpid_bitmap, VMX_NR_VPIDS);\nstatic DEFINE_SPINLOCK(vmx_vpid_lock);\n\nstruct vmcs_config vmcs_config;\nstruct vmx_capability vmx_capability;\n\n#define VMX_SEGMENT_FIELD(seg)\t\t\t\t\t\\\n\t[VCPU_SREG_##seg] = {                                   \\\n\t\t.selector = GUEST_##seg##_SELECTOR,\t\t\\\n\t\t.base = GUEST_##seg##_BASE,\t\t   \t\\\n\t\t.limit = GUEST_##seg##_LIMIT,\t\t   \t\\\n\t\t.ar_bytes = GUEST_##seg##_AR_BYTES,\t   \t\\\n\t}\n\nstatic const struct kvm_vmx_segment_field {\n\tunsigned selector;\n\tunsigned base;\n\tunsigned limit;\n\tunsigned ar_bytes;\n} kvm_vmx_segment_fields[] = {\n\tVMX_SEGMENT_FIELD(CS),\n\tVMX_SEGMENT_FIELD(DS),\n\tVMX_SEGMENT_FIELD(ES),\n\tVMX_SEGMENT_FIELD(FS),\n\tVMX_SEGMENT_FIELD(GS),\n\tVMX_SEGMENT_FIELD(SS),\n\tVMX_SEGMENT_FIELD(TR),\n\tVMX_SEGMENT_FIELD(LDTR),\n};\n\nstatic inline void vmx_segment_cache_clear(struct vcpu_vmx *vmx)\n{\n\tvmx->segment_cache.bitmask = 0;\n}\n\nstatic unsigned long host_idt_base;\n\n/*\n * Though SYSCALL is only supported in 64-bit mode on Intel CPUs, kvm\n * will emulate SYSCALL in legacy mode if the vendor string in guest\n * CPUID.0:{EBX,ECX,EDX} is \"AuthenticAMD\" or \"AMDisbetter!\" To\n * support this emulation, IA32_STAR must always be included in\n * vmx_uret_msrs_list[], even in i386 builds.\n */\nstatic const u32 vmx_uret_msrs_list[] = {\n#ifdef CONFIG_X86_64\n\tMSR_SYSCALL_MASK, MSR_LSTAR, MSR_CSTAR,\n#endif\n\tMSR_EFER, MSR_TSC_AUX, MSR_STAR,\n\tMSR_IA32_TSX_CTRL,\n};\n\n#if IS_ENABLED(CONFIG_HYPERV)\nstatic bool __read_mostly enlightened_vmcs = true;\nmodule_param(enlightened_vmcs, bool, 0444);\n\n/* check_ept_pointer() should be under protection of ept_pointer_lock. */\nstatic void check_ept_pointer_match(struct kvm *kvm)\n{\n\tstruct kvm_vcpu *vcpu;\n\tu64 tmp_eptp = INVALID_PAGE;\n\tint i;\n\n\tkvm_for_each_vcpu(i, vcpu, kvm) {\n\t\tif (!VALID_PAGE(tmp_eptp)) {\n\t\t\ttmp_eptp = to_vmx(vcpu)->ept_pointer;\n\t\t} else if (tmp_eptp != to_vmx(vcpu)->ept_pointer) {\n\t\t\tto_kvm_vmx(kvm)->ept_pointers_match\n\t\t\t\t= EPT_POINTERS_MISMATCH;\n\t\t\treturn;\n\t\t}\n\t}\n\n\tto_kvm_vmx(kvm)->ept_pointers_match = EPT_POINTERS_MATCH;\n}\n\nstatic int kvm_fill_hv_flush_list_func(struct hv_guest_mapping_flush_list *flush,\n\t\tvoid *data)\n{\n\tstruct kvm_tlb_range *range = data;\n\n\treturn hyperv_fill_flush_guest_mapping_list(flush, range->start_gfn,\n\t\t\trange->pages);\n}\n\nstatic inline int __hv_remote_flush_tlb_with_range(struct kvm *kvm,\n\t\tstruct kvm_vcpu *vcpu, struct kvm_tlb_range *range)\n{\n\tu64 ept_pointer = to_vmx(vcpu)->ept_pointer;\n\n\t/*\n\t * FLUSH_GUEST_PHYSICAL_ADDRESS_SPACE hypercall needs address\n\t * of the base of EPT PML4 table, strip off EPT configuration\n\t * information.\n\t */\n\tif (range)\n\t\treturn hyperv_flush_guest_mapping_range(ept_pointer & PAGE_MASK,\n\t\t\t\tkvm_fill_hv_flush_list_func, (void *)range);\n\telse\n\t\treturn hyperv_flush_guest_mapping(ept_pointer & PAGE_MASK);\n}\n\nstatic int hv_remote_flush_tlb_with_range(struct kvm *kvm,\n\t\tstruct kvm_tlb_range *range)\n{\n\tstruct kvm_vcpu *vcpu;\n\tint ret = 0, i;\n\n\tspin_lock(&to_kvm_vmx(kvm)->ept_pointer_lock);\n\n\tif (to_kvm_vmx(kvm)->ept_pointers_match == EPT_POINTERS_CHECK)\n\t\tcheck_ept_pointer_match(kvm);\n\n\tif (to_kvm_vmx(kvm)->ept_pointers_match != EPT_POINTERS_MATCH) {\n\t\tkvm_for_each_vcpu(i, vcpu, kvm) {\n\t\t\t/* If ept_pointer is invalid pointer, bypass flush request. */\n\t\t\tif (VALID_PAGE(to_vmx(vcpu)->ept_pointer))\n\t\t\t\tret |= __hv_remote_flush_tlb_with_range(\n\t\t\t\t\tkvm, vcpu, range);\n\t\t}\n\t} else {\n\t\tret = __hv_remote_flush_tlb_with_range(kvm,\n\t\t\t\tkvm_get_vcpu(kvm, 0), range);\n\t}\n\n\tspin_unlock(&to_kvm_vmx(kvm)->ept_pointer_lock);\n\treturn ret;\n}\nstatic int hv_remote_flush_tlb(struct kvm *kvm)\n{\n\treturn hv_remote_flush_tlb_with_range(kvm, NULL);\n}\n\nstatic int hv_enable_direct_tlbflush(struct kvm_vcpu *vcpu)\n{\n\tstruct hv_enlightened_vmcs *evmcs;\n\tstruct hv_partition_assist_pg **p_hv_pa_pg =\n\t\t\t&vcpu->kvm->arch.hyperv.hv_pa_pg;\n\t/*\n\t * Synthetic VM-Exit is not enabled in current code and so All\n\t * evmcs in singe VM shares same assist page.\n\t */\n\tif (!*p_hv_pa_pg)\n\t\t*p_hv_pa_pg = kzalloc(PAGE_SIZE, GFP_KERNEL);\n\n\tif (!*p_hv_pa_pg)\n\t\treturn -ENOMEM;\n\n\tevmcs = (struct hv_enlightened_vmcs *)to_vmx(vcpu)->loaded_vmcs->vmcs;\n\n\tevmcs->partition_assist_page =\n\t\t__pa(*p_hv_pa_pg);\n\tevmcs->hv_vm_id = (unsigned long)vcpu->kvm;\n\tevmcs->hv_enlightenments_control.nested_flush_hypercall = 1;\n\n\treturn 0;\n}\n\n#endif /* IS_ENABLED(CONFIG_HYPERV) */\n\n/*\n * Comment's format: document - errata name - stepping - processor name.\n * Refer from\n * https://www.virtualbox.org/svn/vbox/trunk/src/VBox/VMM/VMMR0/HMR0.cpp\n */\nstatic u32 vmx_preemption_cpu_tfms[] = {\n/* 323344.pdf - BA86   - D0 - Xeon 7500 Series */\n0x000206E6,\n/* 323056.pdf - AAX65  - C2 - Xeon L3406 */\n/* 322814.pdf - AAT59  - C2 - i7-600, i5-500, i5-400 and i3-300 Mobile */\n/* 322911.pdf - AAU65  - C2 - i5-600, i3-500 Desktop and Pentium G6950 */\n0x00020652,\n/* 322911.pdf - AAU65  - K0 - i5-600, i3-500 Desktop and Pentium G6950 */\n0x00020655,\n/* 322373.pdf - AAO95  - B1 - Xeon 3400 Series */\n/* 322166.pdf - AAN92  - B1 - i7-800 and i5-700 Desktop */\n/*\n * 320767.pdf - AAP86  - B1 -\n * i7-900 Mobile Extreme, i7-800 and i7-700 Mobile\n */\n0x000106E5,\n/* 321333.pdf - AAM126 - C0 - Xeon 3500 */\n0x000106A0,\n/* 321333.pdf - AAM126 - C1 - Xeon 3500 */\n0x000106A1,\n/* 320836.pdf - AAJ124 - C0 - i7-900 Desktop Extreme and i7-900 Desktop */\n0x000106A4,\n /* 321333.pdf - AAM126 - D0 - Xeon 3500 */\n /* 321324.pdf - AAK139 - D0 - Xeon 5500 */\n /* 320836.pdf - AAJ124 - D0 - i7-900 Extreme and i7-900 Desktop */\n0x000106A5,\n /* Xeon E3-1220 V2 */\n0x000306A8,\n};\n\nstatic inline bool cpu_has_broken_vmx_preemption_timer(void)\n{\n\tu32 eax = cpuid_eax(0x00000001), i;\n\n\t/* Clear the reserved bits */\n\teax &= ~(0x3U << 14 | 0xfU << 28);\n\tfor (i = 0; i < ARRAY_SIZE(vmx_preemption_cpu_tfms); i++)\n\t\tif (eax == vmx_preemption_cpu_tfms[i])\n\t\t\treturn true;\n\n\treturn false;\n}\n\nstatic inline bool cpu_need_virtualize_apic_accesses(struct kvm_vcpu *vcpu)\n{\n\treturn flexpriority_enabled && lapic_in_kernel(vcpu);\n}\n\nstatic inline bool report_flexpriority(void)\n{\n\treturn flexpriority_enabled;\n}\n\nstatic int possible_passthrough_msr_slot(u32 msr)\n{\n\tu32 i;\n\n\tfor (i = 0; i < ARRAY_SIZE(vmx_possible_passthrough_msrs); i++)\n\t\tif (vmx_possible_passthrough_msrs[i] == msr)\n\t\t\treturn i;\n\n\treturn -ENOENT;\n}\n\nstatic bool is_valid_passthrough_msr(u32 msr)\n{\n\tbool r;\n\n\tswitch (msr) {\n\tcase 0x800 ... 0x8ff:\n\t\t/* x2APIC MSRs. These are handled in vmx_update_msr_bitmap_x2apic() */\n\t\treturn true;\n\tcase MSR_IA32_RTIT_STATUS:\n\tcase MSR_IA32_RTIT_OUTPUT_BASE:\n\tcase MSR_IA32_RTIT_OUTPUT_MASK:\n\tcase MSR_IA32_RTIT_CR3_MATCH:\n\tcase MSR_IA32_RTIT_ADDR0_A ... MSR_IA32_RTIT_ADDR3_B:\n\t\t/* PT MSRs. These are handled in pt_update_intercept_for_msr() */\n\t\treturn true;\n\t}\n\n\tr = possible_passthrough_msr_slot(msr) != -ENOENT;\n\n\tWARN(!r, \"Invalid MSR %x, please adapt vmx_possible_passthrough_msrs[]\", msr);\n\n\treturn r;\n}\n\nstatic inline int __vmx_find_uret_msr(struct vcpu_vmx *vmx, u32 msr)\n{\n\tint i;\n\n\tfor (i = 0; i < vmx->nr_uret_msrs; ++i)\n\t\tif (vmx_uret_msrs_list[vmx->guest_uret_msrs[i].slot] == msr)\n\t\t\treturn i;\n\treturn -1;\n}\n\nstruct vmx_uret_msr *vmx_find_uret_msr(struct vcpu_vmx *vmx, u32 msr)\n{\n\tint i;\n\n\ti = __vmx_find_uret_msr(vmx, msr);\n\tif (i >= 0)\n\t\treturn &vmx->guest_uret_msrs[i];\n\treturn NULL;\n}\n\nstatic int vmx_set_guest_uret_msr(struct vcpu_vmx *vmx,\n\t\t\t\t  struct vmx_uret_msr *msr, u64 data)\n{\n\tint ret = 0;\n\n\tu64 old_msr_data = msr->data;\n\tmsr->data = data;\n\tif (msr - vmx->guest_uret_msrs < vmx->nr_active_uret_msrs) {\n\t\tpreempt_disable();\n\t\tret = kvm_set_user_return_msr(msr->slot, msr->data, msr->mask);\n\t\tpreempt_enable();\n\t\tif (ret)\n\t\t\tmsr->data = old_msr_data;\n\t}\n\treturn ret;\n}\n\n#ifdef CONFIG_KEXEC_CORE\nstatic void crash_vmclear_local_loaded_vmcss(void)\n{\n\tint cpu = raw_smp_processor_id();\n\tstruct loaded_vmcs *v;\n\n\tlist_for_each_entry(v, &per_cpu(loaded_vmcss_on_cpu, cpu),\n\t\t\t    loaded_vmcss_on_cpu_link)\n\t\tvmcs_clear(v->vmcs);\n}\n#endif /* CONFIG_KEXEC_CORE */\n\nstatic void __loaded_vmcs_clear(void *arg)\n{\n\tstruct loaded_vmcs *loaded_vmcs = arg;\n\tint cpu = raw_smp_processor_id();\n\n\tif (loaded_vmcs->cpu != cpu)\n\t\treturn; /* vcpu migration can race with cpu offline */\n\tif (per_cpu(current_vmcs, cpu) == loaded_vmcs->vmcs)\n\t\tper_cpu(current_vmcs, cpu) = NULL;\n\n\tvmcs_clear(loaded_vmcs->vmcs);\n\tif (loaded_vmcs->shadow_vmcs && loaded_vmcs->launched)\n\t\tvmcs_clear(loaded_vmcs->shadow_vmcs);\n\n\tlist_del(&loaded_vmcs->loaded_vmcss_on_cpu_link);\n\n\t/*\n\t * Ensure all writes to loaded_vmcs, including deleting it from its\n\t * current percpu list, complete before setting loaded_vmcs->vcpu to\n\t * -1, otherwise a different cpu can see vcpu == -1 first and add\n\t * loaded_vmcs to its percpu list before it's deleted from this cpu's\n\t * list. Pairs with the smp_rmb() in vmx_vcpu_load_vmcs().\n\t */\n\tsmp_wmb();\n\n\tloaded_vmcs->cpu = -1;\n\tloaded_vmcs->launched = 0;\n}\n\nvoid loaded_vmcs_clear(struct loaded_vmcs *loaded_vmcs)\n{\n\tint cpu = loaded_vmcs->cpu;\n\n\tif (cpu != -1)\n\t\tsmp_call_function_single(cpu,\n\t\t\t __loaded_vmcs_clear, loaded_vmcs, 1);\n}\n\nstatic bool vmx_segment_cache_test_set(struct vcpu_vmx *vmx, unsigned seg,\n\t\t\t\t       unsigned field)\n{\n\tbool ret;\n\tu32 mask = 1 << (seg * SEG_FIELD_NR + field);\n\n\tif (!kvm_register_is_available(&vmx->vcpu, VCPU_EXREG_SEGMENTS)) {\n\t\tkvm_register_mark_available(&vmx->vcpu, VCPU_EXREG_SEGMENTS);\n\t\tvmx->segment_cache.bitmask = 0;\n\t}\n\tret = vmx->segment_cache.bitmask & mask;\n\tvmx->segment_cache.bitmask |= mask;\n\treturn ret;\n}\n\nstatic u16 vmx_read_guest_seg_selector(struct vcpu_vmx *vmx, unsigned seg)\n{\n\tu16 *p = &vmx->segment_cache.seg[seg].selector;\n\n\tif (!vmx_segment_cache_test_set(vmx, seg, SEG_FIELD_SEL))\n\t\t*p = vmcs_read16(kvm_vmx_segment_fields[seg].selector);\n\treturn *p;\n}\n\nstatic ulong vmx_read_guest_seg_base(struct vcpu_vmx *vmx, unsigned seg)\n{\n\tulong *p = &vmx->segment_cache.seg[seg].base;\n\n\tif (!vmx_segment_cache_test_set(vmx, seg, SEG_FIELD_BASE))\n\t\t*p = vmcs_readl(kvm_vmx_segment_fields[seg].base);\n\treturn *p;\n}\n\nstatic u32 vmx_read_guest_seg_limit(struct vcpu_vmx *vmx, unsigned seg)\n{\n\tu32 *p = &vmx->segment_cache.seg[seg].limit;\n\n\tif (!vmx_segment_cache_test_set(vmx, seg, SEG_FIELD_LIMIT))\n\t\t*p = vmcs_read32(kvm_vmx_segment_fields[seg].limit);\n\treturn *p;\n}\n\nstatic u32 vmx_read_guest_seg_ar(struct vcpu_vmx *vmx, unsigned seg)\n{\n\tu32 *p = &vmx->segment_cache.seg[seg].ar;\n\n\tif (!vmx_segment_cache_test_set(vmx, seg, SEG_FIELD_AR))\n\t\t*p = vmcs_read32(kvm_vmx_segment_fields[seg].ar_bytes);\n\treturn *p;\n}\n\nvoid update_exception_bitmap(struct kvm_vcpu *vcpu)\n{\n\tu32 eb;\n\n\teb = (1u << PF_VECTOR) | (1u << UD_VECTOR) | (1u << MC_VECTOR) |\n\t     (1u << DB_VECTOR) | (1u << AC_VECTOR);\n\t/*\n\t * Guest access to VMware backdoor ports could legitimately\n\t * trigger #GP because of TSS I/O permission bitmap.\n\t * We intercept those #GP and allow access to them anyway\n\t * as VMware does.\n\t */\n\tif (enable_vmware_backdoor)\n\t\teb |= (1u << GP_VECTOR);\n\tif ((vcpu->guest_debug &\n\t     (KVM_GUESTDBG_ENABLE | KVM_GUESTDBG_USE_SW_BP)) ==\n\t    (KVM_GUESTDBG_ENABLE | KVM_GUESTDBG_USE_SW_BP))\n\t\teb |= 1u << BP_VECTOR;\n\tif (to_vmx(vcpu)->rmode.vm86_active)\n\t\teb = ~0;\n\tif (!vmx_need_pf_intercept(vcpu))\n\t\teb &= ~(1u << PF_VECTOR);\n\n\t/* When we are running a nested L2 guest and L1 specified for it a\n\t * certain exception bitmap, we must trap the same exceptions and pass\n\t * them to L1. When running L2, we will only handle the exceptions\n\t * specified above if L1 did not want them.\n\t */\n\tif (is_guest_mode(vcpu))\n\t\teb |= get_vmcs12(vcpu)->exception_bitmap;\n        else {\n\t\t/*\n\t\t * If EPT is enabled, #PF is only trapped if MAXPHYADDR is mismatched\n\t\t * between guest and host.  In that case we only care about present\n\t\t * faults.  For vmcs02, however, PFEC_MASK and PFEC_MATCH are set in\n\t\t * prepare_vmcs02_rare.\n\t\t */\n\t\tbool selective_pf_trap = enable_ept && (eb & (1u << PF_VECTOR));\n\t\tint mask = selective_pf_trap ? PFERR_PRESENT_MASK : 0;\n\t\tvmcs_write32(PAGE_FAULT_ERROR_CODE_MASK, mask);\n\t\tvmcs_write32(PAGE_FAULT_ERROR_CODE_MATCH, mask);\n\t}\n\n\tvmcs_write32(EXCEPTION_BITMAP, eb);\n}\n\n/*\n * Check if MSR is intercepted for currently loaded MSR bitmap.\n */\nstatic bool msr_write_intercepted(struct kvm_vcpu *vcpu, u32 msr)\n{\n\tunsigned long *msr_bitmap;\n\tint f = sizeof(unsigned long);\n\n\tif (!cpu_has_vmx_msr_bitmap())\n\t\treturn true;\n\n\tmsr_bitmap = to_vmx(vcpu)->loaded_vmcs->msr_bitmap;\n\n\tif (msr <= 0x1fff) {\n\t\treturn !!test_bit(msr, msr_bitmap + 0x800 / f);\n\t} else if ((msr >= 0xc0000000) && (msr <= 0xc0001fff)) {\n\t\tmsr &= 0x1fff;\n\t\treturn !!test_bit(msr, msr_bitmap + 0xc00 / f);\n\t}\n\n\treturn true;\n}\n\nstatic void clear_atomic_switch_msr_special(struct vcpu_vmx *vmx,\n\t\tunsigned long entry, unsigned long exit)\n{\n\tvm_entry_controls_clearbit(vmx, entry);\n\tvm_exit_controls_clearbit(vmx, exit);\n}\n\nint vmx_find_loadstore_msr_slot(struct vmx_msrs *m, u32 msr)\n{\n\tunsigned int i;\n\n\tfor (i = 0; i < m->nr; ++i) {\n\t\tif (m->val[i].index == msr)\n\t\t\treturn i;\n\t}\n\treturn -ENOENT;\n}\n\nstatic void clear_atomic_switch_msr(struct vcpu_vmx *vmx, unsigned msr)\n{\n\tint i;\n\tstruct msr_autoload *m = &vmx->msr_autoload;\n\n\tswitch (msr) {\n\tcase MSR_EFER:\n\t\tif (cpu_has_load_ia32_efer()) {\n\t\t\tclear_atomic_switch_msr_special(vmx,\n\t\t\t\t\tVM_ENTRY_LOAD_IA32_EFER,\n\t\t\t\t\tVM_EXIT_LOAD_IA32_EFER);\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\tcase MSR_CORE_PERF_GLOBAL_CTRL:\n\t\tif (cpu_has_load_perf_global_ctrl()) {\n\t\t\tclear_atomic_switch_msr_special(vmx,\n\t\t\t\t\tVM_ENTRY_LOAD_IA32_PERF_GLOBAL_CTRL,\n\t\t\t\t\tVM_EXIT_LOAD_IA32_PERF_GLOBAL_CTRL);\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\t}\n\ti = vmx_find_loadstore_msr_slot(&m->guest, msr);\n\tif (i < 0)\n\t\tgoto skip_guest;\n\t--m->guest.nr;\n\tm->guest.val[i] = m->guest.val[m->guest.nr];\n\tvmcs_write32(VM_ENTRY_MSR_LOAD_COUNT, m->guest.nr);\n\nskip_guest:\n\ti = vmx_find_loadstore_msr_slot(&m->host, msr);\n\tif (i < 0)\n\t\treturn;\n\n\t--m->host.nr;\n\tm->host.val[i] = m->host.val[m->host.nr];\n\tvmcs_write32(VM_EXIT_MSR_LOAD_COUNT, m->host.nr);\n}\n\nstatic void add_atomic_switch_msr_special(struct vcpu_vmx *vmx,\n\t\tunsigned long entry, unsigned long exit,\n\t\tunsigned long guest_val_vmcs, unsigned long host_val_vmcs,\n\t\tu64 guest_val, u64 host_val)\n{\n\tvmcs_write64(guest_val_vmcs, guest_val);\n\tif (host_val_vmcs != HOST_IA32_EFER)\n\t\tvmcs_write64(host_val_vmcs, host_val);\n\tvm_entry_controls_setbit(vmx, entry);\n\tvm_exit_controls_setbit(vmx, exit);\n}\n\nstatic void add_atomic_switch_msr(struct vcpu_vmx *vmx, unsigned msr,\n\t\t\t\t  u64 guest_val, u64 host_val, bool entry_only)\n{\n\tint i, j = 0;\n\tstruct msr_autoload *m = &vmx->msr_autoload;\n\n\tswitch (msr) {\n\tcase MSR_EFER:\n\t\tif (cpu_has_load_ia32_efer()) {\n\t\t\tadd_atomic_switch_msr_special(vmx,\n\t\t\t\t\tVM_ENTRY_LOAD_IA32_EFER,\n\t\t\t\t\tVM_EXIT_LOAD_IA32_EFER,\n\t\t\t\t\tGUEST_IA32_EFER,\n\t\t\t\t\tHOST_IA32_EFER,\n\t\t\t\t\tguest_val, host_val);\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\tcase MSR_CORE_PERF_GLOBAL_CTRL:\n\t\tif (cpu_has_load_perf_global_ctrl()) {\n\t\t\tadd_atomic_switch_msr_special(vmx,\n\t\t\t\t\tVM_ENTRY_LOAD_IA32_PERF_GLOBAL_CTRL,\n\t\t\t\t\tVM_EXIT_LOAD_IA32_PERF_GLOBAL_CTRL,\n\t\t\t\t\tGUEST_IA32_PERF_GLOBAL_CTRL,\n\t\t\t\t\tHOST_IA32_PERF_GLOBAL_CTRL,\n\t\t\t\t\tguest_val, host_val);\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\tcase MSR_IA32_PEBS_ENABLE:\n\t\t/* PEBS needs a quiescent period after being disabled (to write\n\t\t * a record).  Disabling PEBS through VMX MSR swapping doesn't\n\t\t * provide that period, so a CPU could write host's record into\n\t\t * guest's memory.\n\t\t */\n\t\twrmsrl(MSR_IA32_PEBS_ENABLE, 0);\n\t}\n\n\ti = vmx_find_loadstore_msr_slot(&m->guest, msr);\n\tif (!entry_only)\n\t\tj = vmx_find_loadstore_msr_slot(&m->host, msr);\n\n\tif ((i < 0 && m->guest.nr == MAX_NR_LOADSTORE_MSRS) ||\n\t    (j < 0 &&  m->host.nr == MAX_NR_LOADSTORE_MSRS)) {\n\t\tprintk_once(KERN_WARNING \"Not enough msr switch entries. \"\n\t\t\t\t\"Can't add msr %x\\n\", msr);\n\t\treturn;\n\t}\n\tif (i < 0) {\n\t\ti = m->guest.nr++;\n\t\tvmcs_write32(VM_ENTRY_MSR_LOAD_COUNT, m->guest.nr);\n\t}\n\tm->guest.val[i].index = msr;\n\tm->guest.val[i].value = guest_val;\n\n\tif (entry_only)\n\t\treturn;\n\n\tif (j < 0) {\n\t\tj = m->host.nr++;\n\t\tvmcs_write32(VM_EXIT_MSR_LOAD_COUNT, m->host.nr);\n\t}\n\tm->host.val[j].index = msr;\n\tm->host.val[j].value = host_val;\n}\n\nstatic bool update_transition_efer(struct vcpu_vmx *vmx)\n{\n\tu64 guest_efer = vmx->vcpu.arch.efer;\n\tu64 ignore_bits = 0;\n\tint i;\n\n\t/* Shadow paging assumes NX to be available.  */\n\tif (!enable_ept)\n\t\tguest_efer |= EFER_NX;\n\n\t/*\n\t * LMA and LME handled by hardware; SCE meaningless outside long mode.\n\t */\n\tignore_bits |= EFER_SCE;\n#ifdef CONFIG_X86_64\n\tignore_bits |= EFER_LMA | EFER_LME;\n\t/* SCE is meaningful only in long mode on Intel */\n\tif (guest_efer & EFER_LMA)\n\t\tignore_bits &= ~(u64)EFER_SCE;\n#endif\n\n\t/*\n\t * On EPT, we can't emulate NX, so we must switch EFER atomically.\n\t * On CPUs that support \"load IA32_EFER\", always switch EFER\n\t * atomically, since it's faster than switching it manually.\n\t */\n\tif (cpu_has_load_ia32_efer() ||\n\t    (enable_ept && ((vmx->vcpu.arch.efer ^ host_efer) & EFER_NX))) {\n\t\tif (!(guest_efer & EFER_LMA))\n\t\t\tguest_efer &= ~EFER_LME;\n\t\tif (guest_efer != host_efer)\n\t\t\tadd_atomic_switch_msr(vmx, MSR_EFER,\n\t\t\t\t\t      guest_efer, host_efer, false);\n\t\telse\n\t\t\tclear_atomic_switch_msr(vmx, MSR_EFER);\n\t\treturn false;\n\t}\n\n\ti = __vmx_find_uret_msr(vmx, MSR_EFER);\n\tif (i < 0)\n\t\treturn false;\n\n\tclear_atomic_switch_msr(vmx, MSR_EFER);\n\n\tguest_efer &= ~ignore_bits;\n\tguest_efer |= host_efer & ignore_bits;\n\n\tvmx->guest_uret_msrs[i].data = guest_efer;\n\tvmx->guest_uret_msrs[i].mask = ~ignore_bits;\n\n\treturn true;\n}\n\n#ifdef CONFIG_X86_32\n/*\n * On 32-bit kernels, VM exits still load the FS and GS bases from the\n * VMCS rather than the segment table.  KVM uses this helper to figure\n * out the current bases to poke them into the VMCS before entry.\n */\nstatic unsigned long segment_base(u16 selector)\n{\n\tstruct desc_struct *table;\n\tunsigned long v;\n\n\tif (!(selector & ~SEGMENT_RPL_MASK))\n\t\treturn 0;\n\n\ttable = get_current_gdt_ro();\n\n\tif ((selector & SEGMENT_TI_MASK) == SEGMENT_LDT) {\n\t\tu16 ldt_selector = kvm_read_ldt();\n\n\t\tif (!(ldt_selector & ~SEGMENT_RPL_MASK))\n\t\t\treturn 0;\n\n\t\ttable = (struct desc_struct *)segment_base(ldt_selector);\n\t}\n\tv = get_desc_base(&table[selector >> 3]);\n\treturn v;\n}\n#endif\n\nstatic inline bool pt_can_write_msr(struct vcpu_vmx *vmx)\n{\n\treturn vmx_pt_mode_is_host_guest() &&\n\t       !(vmx->pt_desc.guest.ctl & RTIT_CTL_TRACEEN);\n}\n\nstatic inline bool pt_output_base_valid(struct kvm_vcpu *vcpu, u64 base)\n{\n\t/* The base must be 128-byte aligned and a legal physical address. */\n\treturn !kvm_vcpu_is_illegal_gpa(vcpu, base) && !(base & 0x7f);\n}\n\nstatic inline void pt_load_msr(struct pt_ctx *ctx, u32 addr_range)\n{\n\tu32 i;\n\n\twrmsrl(MSR_IA32_RTIT_STATUS, ctx->status);\n\twrmsrl(MSR_IA32_RTIT_OUTPUT_BASE, ctx->output_base);\n\twrmsrl(MSR_IA32_RTIT_OUTPUT_MASK, ctx->output_mask);\n\twrmsrl(MSR_IA32_RTIT_CR3_MATCH, ctx->cr3_match);\n\tfor (i = 0; i < addr_range; i++) {\n\t\twrmsrl(MSR_IA32_RTIT_ADDR0_A + i * 2, ctx->addr_a[i]);\n\t\twrmsrl(MSR_IA32_RTIT_ADDR0_B + i * 2, ctx->addr_b[i]);\n\t}\n}\n\nstatic inline void pt_save_msr(struct pt_ctx *ctx, u32 addr_range)\n{\n\tu32 i;\n\n\trdmsrl(MSR_IA32_RTIT_STATUS, ctx->status);\n\trdmsrl(MSR_IA32_RTIT_OUTPUT_BASE, ctx->output_base);\n\trdmsrl(MSR_IA32_RTIT_OUTPUT_MASK, ctx->output_mask);\n\trdmsrl(MSR_IA32_RTIT_CR3_MATCH, ctx->cr3_match);\n\tfor (i = 0; i < addr_range; i++) {\n\t\trdmsrl(MSR_IA32_RTIT_ADDR0_A + i * 2, ctx->addr_a[i]);\n\t\trdmsrl(MSR_IA32_RTIT_ADDR0_B + i * 2, ctx->addr_b[i]);\n\t}\n}\n\nstatic void pt_guest_enter(struct vcpu_vmx *vmx)\n{\n\tif (vmx_pt_mode_is_system())\n\t\treturn;\n\n\t/*\n\t * GUEST_IA32_RTIT_CTL is already set in the VMCS.\n\t * Save host state before VM entry.\n\t */\n\trdmsrl(MSR_IA32_RTIT_CTL, vmx->pt_desc.host.ctl);\n\tif (vmx->pt_desc.guest.ctl & RTIT_CTL_TRACEEN) {\n\t\twrmsrl(MSR_IA32_RTIT_CTL, 0);\n\t\tpt_save_msr(&vmx->pt_desc.host, vmx->pt_desc.addr_range);\n\t\tpt_load_msr(&vmx->pt_desc.guest, vmx->pt_desc.addr_range);\n\t}\n}\n\nstatic void pt_guest_exit(struct vcpu_vmx *vmx)\n{\n\tif (vmx_pt_mode_is_system())\n\t\treturn;\n\n\tif (vmx->pt_desc.guest.ctl & RTIT_CTL_TRACEEN) {\n\t\tpt_save_msr(&vmx->pt_desc.guest, vmx->pt_desc.addr_range);\n\t\tpt_load_msr(&vmx->pt_desc.host, vmx->pt_desc.addr_range);\n\t}\n\n\t/* Reload host state (IA32_RTIT_CTL will be cleared on VM exit). */\n\twrmsrl(MSR_IA32_RTIT_CTL, vmx->pt_desc.host.ctl);\n}\n\nvoid vmx_set_host_fs_gs(struct vmcs_host_state *host, u16 fs_sel, u16 gs_sel,\n\t\t\tunsigned long fs_base, unsigned long gs_base)\n{\n\tif (unlikely(fs_sel != host->fs_sel)) {\n\t\tif (!(fs_sel & 7))\n\t\t\tvmcs_write16(HOST_FS_SELECTOR, fs_sel);\n\t\telse\n\t\t\tvmcs_write16(HOST_FS_SELECTOR, 0);\n\t\thost->fs_sel = fs_sel;\n\t}\n\tif (unlikely(gs_sel != host->gs_sel)) {\n\t\tif (!(gs_sel & 7))\n\t\t\tvmcs_write16(HOST_GS_SELECTOR, gs_sel);\n\t\telse\n\t\t\tvmcs_write16(HOST_GS_SELECTOR, 0);\n\t\thost->gs_sel = gs_sel;\n\t}\n\tif (unlikely(fs_base != host->fs_base)) {\n\t\tvmcs_writel(HOST_FS_BASE, fs_base);\n\t\thost->fs_base = fs_base;\n\t}\n\tif (unlikely(gs_base != host->gs_base)) {\n\t\tvmcs_writel(HOST_GS_BASE, gs_base);\n\t\thost->gs_base = gs_base;\n\t}\n}\n\nvoid vmx_prepare_switch_to_guest(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tstruct vmcs_host_state *host_state;\n#ifdef CONFIG_X86_64\n\tint cpu = raw_smp_processor_id();\n#endif\n\tunsigned long fs_base, gs_base;\n\tu16 fs_sel, gs_sel;\n\tint i;\n\n\tvmx->req_immediate_exit = false;\n\n\t/*\n\t * Note that guest MSRs to be saved/restored can also be changed\n\t * when guest state is loaded. This happens when guest transitions\n\t * to/from long-mode by setting MSR_EFER.LMA.\n\t */\n\tif (!vmx->guest_uret_msrs_loaded) {\n\t\tvmx->guest_uret_msrs_loaded = true;\n\t\tfor (i = 0; i < vmx->nr_active_uret_msrs; ++i)\n\t\t\tkvm_set_user_return_msr(vmx->guest_uret_msrs[i].slot,\n\t\t\t\t\t\tvmx->guest_uret_msrs[i].data,\n\t\t\t\t\t\tvmx->guest_uret_msrs[i].mask);\n\n\t}\n\n    \tif (vmx->nested.need_vmcs12_to_shadow_sync)\n\t\tnested_sync_vmcs12_to_shadow(vcpu);\n\n\tif (vmx->guest_state_loaded)\n\t\treturn;\n\n\thost_state = &vmx->loaded_vmcs->host_state;\n\n\t/*\n\t * Set host fs and gs selectors.  Unfortunately, 22.2.3 does not\n\t * allow segment selectors with cpl > 0 or ti == 1.\n\t */\n\thost_state->ldt_sel = kvm_read_ldt();\n\n#ifdef CONFIG_X86_64\n\tsavesegment(ds, host_state->ds_sel);\n\tsavesegment(es, host_state->es_sel);\n\n\tgs_base = cpu_kernelmode_gs_base(cpu);\n\tif (likely(is_64bit_mm(current->mm))) {\n\t\tcurrent_save_fsgs();\n\t\tfs_sel = current->thread.fsindex;\n\t\tgs_sel = current->thread.gsindex;\n\t\tfs_base = current->thread.fsbase;\n\t\tvmx->msr_host_kernel_gs_base = current->thread.gsbase;\n\t} else {\n\t\tsavesegment(fs, fs_sel);\n\t\tsavesegment(gs, gs_sel);\n\t\tfs_base = read_msr(MSR_FS_BASE);\n\t\tvmx->msr_host_kernel_gs_base = read_msr(MSR_KERNEL_GS_BASE);\n\t}\n\n\twrmsrl(MSR_KERNEL_GS_BASE, vmx->msr_guest_kernel_gs_base);\n#else\n\tsavesegment(fs, fs_sel);\n\tsavesegment(gs, gs_sel);\n\tfs_base = segment_base(fs_sel);\n\tgs_base = segment_base(gs_sel);\n#endif\n\n\tvmx_set_host_fs_gs(host_state, fs_sel, gs_sel, fs_base, gs_base);\n\tvmx->guest_state_loaded = true;\n}\n\nstatic void vmx_prepare_switch_to_host(struct vcpu_vmx *vmx)\n{\n\tstruct vmcs_host_state *host_state;\n\n\tif (!vmx->guest_state_loaded)\n\t\treturn;\n\n\thost_state = &vmx->loaded_vmcs->host_state;\n\n\t++vmx->vcpu.stat.host_state_reload;\n\n#ifdef CONFIG_X86_64\n\trdmsrl(MSR_KERNEL_GS_BASE, vmx->msr_guest_kernel_gs_base);\n#endif\n\tif (host_state->ldt_sel || (host_state->gs_sel & 7)) {\n\t\tkvm_load_ldt(host_state->ldt_sel);\n#ifdef CONFIG_X86_64\n\t\tload_gs_index(host_state->gs_sel);\n#else\n\t\tloadsegment(gs, host_state->gs_sel);\n#endif\n\t}\n\tif (host_state->fs_sel & 7)\n\t\tloadsegment(fs, host_state->fs_sel);\n#ifdef CONFIG_X86_64\n\tif (unlikely(host_state->ds_sel | host_state->es_sel)) {\n\t\tloadsegment(ds, host_state->ds_sel);\n\t\tloadsegment(es, host_state->es_sel);\n\t}\n#endif\n\tinvalidate_tss_limit();\n#ifdef CONFIG_X86_64\n\twrmsrl(MSR_KERNEL_GS_BASE, vmx->msr_host_kernel_gs_base);\n#endif\n\tload_fixmap_gdt(raw_smp_processor_id());\n\tvmx->guest_state_loaded = false;\n\tvmx->guest_uret_msrs_loaded = false;\n}\n\n#ifdef CONFIG_X86_64\nstatic u64 vmx_read_guest_kernel_gs_base(struct vcpu_vmx *vmx)\n{\n\tpreempt_disable();\n\tif (vmx->guest_state_loaded)\n\t\trdmsrl(MSR_KERNEL_GS_BASE, vmx->msr_guest_kernel_gs_base);\n\tpreempt_enable();\n\treturn vmx->msr_guest_kernel_gs_base;\n}\n\nstatic void vmx_write_guest_kernel_gs_base(struct vcpu_vmx *vmx, u64 data)\n{\n\tpreempt_disable();\n\tif (vmx->guest_state_loaded)\n\t\twrmsrl(MSR_KERNEL_GS_BASE, data);\n\tpreempt_enable();\n\tvmx->msr_guest_kernel_gs_base = data;\n}\n#endif\n\nvoid vmx_vcpu_load_vmcs(struct kvm_vcpu *vcpu, int cpu,\n\t\t\tstruct loaded_vmcs *buddy)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tbool already_loaded = vmx->loaded_vmcs->cpu == cpu;\n\tstruct vmcs *prev;\n\n\tif (!already_loaded) {\n\t\tloaded_vmcs_clear(vmx->loaded_vmcs);\n\t\tlocal_irq_disable();\n\n\t\t/*\n\t\t * Ensure loaded_vmcs->cpu is read before adding loaded_vmcs to\n\t\t * this cpu's percpu list, otherwise it may not yet be deleted\n\t\t * from its previous cpu's percpu list.  Pairs with the\n\t\t * smb_wmb() in __loaded_vmcs_clear().\n\t\t */\n\t\tsmp_rmb();\n\n\t\tlist_add(&vmx->loaded_vmcs->loaded_vmcss_on_cpu_link,\n\t\t\t &per_cpu(loaded_vmcss_on_cpu, cpu));\n\t\tlocal_irq_enable();\n\t}\n\n\tprev = per_cpu(current_vmcs, cpu);\n\tif (prev != vmx->loaded_vmcs->vmcs) {\n\t\tper_cpu(current_vmcs, cpu) = vmx->loaded_vmcs->vmcs;\n\t\tvmcs_load(vmx->loaded_vmcs->vmcs);\n\n\t\t/*\n\t\t * No indirect branch prediction barrier needed when switching\n\t\t * the active VMCS within a guest, e.g. on nested VM-Enter.\n\t\t * The L1 VMM can protect itself with retpolines, IBPB or IBRS.\n\t\t */\n\t\tif (!buddy || WARN_ON_ONCE(buddy->vmcs != prev))\n\t\t\tindirect_branch_prediction_barrier();\n\t}\n\n\tif (!already_loaded) {\n\t\tvoid *gdt = get_current_gdt_ro();\n\t\tunsigned long sysenter_esp;\n\n\t\t/*\n\t\t * Flush all EPTP/VPID contexts, the new pCPU may have stale\n\t\t * TLB entries from its previous association with the vCPU.\n\t\t */\n\t\tkvm_make_request(KVM_REQ_TLB_FLUSH, vcpu);\n\n\t\t/*\n\t\t * Linux uses per-cpu TSS and GDT, so set these when switching\n\t\t * processors.  See 22.2.4.\n\t\t */\n\t\tvmcs_writel(HOST_TR_BASE,\n\t\t\t    (unsigned long)&get_cpu_entry_area(cpu)->tss.x86_tss);\n\t\tvmcs_writel(HOST_GDTR_BASE, (unsigned long)gdt);   /* 22.2.4 */\n\n\t\trdmsrl(MSR_IA32_SYSENTER_ESP, sysenter_esp);\n\t\tvmcs_writel(HOST_IA32_SYSENTER_ESP, sysenter_esp); /* 22.2.3 */\n\n\t\tvmx->loaded_vmcs->cpu = cpu;\n\t}\n\n\t/* Setup TSC multiplier */\n\tif (kvm_has_tsc_control &&\n\t    vmx->current_tsc_ratio != vcpu->arch.tsc_scaling_ratio)\n\t\tdecache_tsc_multiplier(vmx);\n}\n\n/*\n * Switches to specified vcpu, until a matching vcpu_put(), but assumes\n * vcpu mutex is already taken.\n */\nstatic void vmx_vcpu_load(struct kvm_vcpu *vcpu, int cpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\tvmx_vcpu_load_vmcs(vcpu, cpu, NULL);\n\n\tvmx_vcpu_pi_load(vcpu, cpu);\n\n\tvmx->host_debugctlmsr = get_debugctlmsr();\n}\n\nstatic void vmx_vcpu_put(struct kvm_vcpu *vcpu)\n{\n\tvmx_vcpu_pi_put(vcpu);\n\n\tvmx_prepare_switch_to_host(to_vmx(vcpu));\n}\n\nstatic bool emulation_required(struct kvm_vcpu *vcpu)\n{\n\treturn emulate_invalid_guest_state && !vmx_guest_state_valid(vcpu);\n}\n\nunsigned long vmx_get_rflags(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tunsigned long rflags, save_rflags;\n\n\tif (!kvm_register_is_available(vcpu, VCPU_EXREG_RFLAGS)) {\n\t\tkvm_register_mark_available(vcpu, VCPU_EXREG_RFLAGS);\n\t\trflags = vmcs_readl(GUEST_RFLAGS);\n\t\tif (vmx->rmode.vm86_active) {\n\t\t\trflags &= RMODE_GUEST_OWNED_EFLAGS_BITS;\n\t\t\tsave_rflags = vmx->rmode.save_rflags;\n\t\t\trflags |= save_rflags & ~RMODE_GUEST_OWNED_EFLAGS_BITS;\n\t\t}\n\t\tvmx->rflags = rflags;\n\t}\n\treturn vmx->rflags;\n}\n\nvoid vmx_set_rflags(struct kvm_vcpu *vcpu, unsigned long rflags)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tunsigned long old_rflags;\n\n\tif (is_unrestricted_guest(vcpu)) {\n\t\tkvm_register_mark_available(vcpu, VCPU_EXREG_RFLAGS);\n\t\tvmx->rflags = rflags;\n\t\tvmcs_writel(GUEST_RFLAGS, rflags);\n\t\treturn;\n\t}\n\n\told_rflags = vmx_get_rflags(vcpu);\n\tvmx->rflags = rflags;\n\tif (vmx->rmode.vm86_active) {\n\t\tvmx->rmode.save_rflags = rflags;\n\t\trflags |= X86_EFLAGS_IOPL | X86_EFLAGS_VM;\n\t}\n\tvmcs_writel(GUEST_RFLAGS, rflags);\n\n\tif ((old_rflags ^ vmx->rflags) & X86_EFLAGS_VM)\n\t\tvmx->emulation_required = emulation_required(vcpu);\n}\n\nu32 vmx_get_interrupt_shadow(struct kvm_vcpu *vcpu)\n{\n\tu32 interruptibility = vmcs_read32(GUEST_INTERRUPTIBILITY_INFO);\n\tint ret = 0;\n\n\tif (interruptibility & GUEST_INTR_STATE_STI)\n\t\tret |= KVM_X86_SHADOW_INT_STI;\n\tif (interruptibility & GUEST_INTR_STATE_MOV_SS)\n\t\tret |= KVM_X86_SHADOW_INT_MOV_SS;\n\n\treturn ret;\n}\n\nvoid vmx_set_interrupt_shadow(struct kvm_vcpu *vcpu, int mask)\n{\n\tu32 interruptibility_old = vmcs_read32(GUEST_INTERRUPTIBILITY_INFO);\n\tu32 interruptibility = interruptibility_old;\n\n\tinterruptibility &= ~(GUEST_INTR_STATE_STI | GUEST_INTR_STATE_MOV_SS);\n\n\tif (mask & KVM_X86_SHADOW_INT_MOV_SS)\n\t\tinterruptibility |= GUEST_INTR_STATE_MOV_SS;\n\telse if (mask & KVM_X86_SHADOW_INT_STI)\n\t\tinterruptibility |= GUEST_INTR_STATE_STI;\n\n\tif ((interruptibility != interruptibility_old))\n\t\tvmcs_write32(GUEST_INTERRUPTIBILITY_INFO, interruptibility);\n}\n\nstatic int vmx_rtit_ctl_check(struct kvm_vcpu *vcpu, u64 data)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tunsigned long value;\n\n\t/*\n\t * Any MSR write that attempts to change bits marked reserved will\n\t * case a #GP fault.\n\t */\n\tif (data & vmx->pt_desc.ctl_bitmask)\n\t\treturn 1;\n\n\t/*\n\t * Any attempt to modify IA32_RTIT_CTL while TraceEn is set will\n\t * result in a #GP unless the same write also clears TraceEn.\n\t */\n\tif ((vmx->pt_desc.guest.ctl & RTIT_CTL_TRACEEN) &&\n\t\t((vmx->pt_desc.guest.ctl ^ data) & ~RTIT_CTL_TRACEEN))\n\t\treturn 1;\n\n\t/*\n\t * WRMSR to IA32_RTIT_CTL that sets TraceEn but clears this bit\n\t * and FabricEn would cause #GP, if\n\t * CPUID.(EAX=14H, ECX=0):ECX.SNGLRGNOUT[bit 2] = 0\n\t */\n\tif ((data & RTIT_CTL_TRACEEN) && !(data & RTIT_CTL_TOPA) &&\n\t\t!(data & RTIT_CTL_FABRIC_EN) &&\n\t\t!intel_pt_validate_cap(vmx->pt_desc.caps,\n\t\t\t\t\tPT_CAP_single_range_output))\n\t\treturn 1;\n\n\t/*\n\t * MTCFreq, CycThresh and PSBFreq encodings check, any MSR write that\n\t * utilize encodings marked reserved will casue a #GP fault.\n\t */\n\tvalue = intel_pt_validate_cap(vmx->pt_desc.caps, PT_CAP_mtc_periods);\n\tif (intel_pt_validate_cap(vmx->pt_desc.caps, PT_CAP_mtc) &&\n\t\t\t!test_bit((data & RTIT_CTL_MTC_RANGE) >>\n\t\t\tRTIT_CTL_MTC_RANGE_OFFSET, &value))\n\t\treturn 1;\n\tvalue = intel_pt_validate_cap(vmx->pt_desc.caps,\n\t\t\t\t\t\tPT_CAP_cycle_thresholds);\n\tif (intel_pt_validate_cap(vmx->pt_desc.caps, PT_CAP_psb_cyc) &&\n\t\t\t!test_bit((data & RTIT_CTL_CYC_THRESH) >>\n\t\t\tRTIT_CTL_CYC_THRESH_OFFSET, &value))\n\t\treturn 1;\n\tvalue = intel_pt_validate_cap(vmx->pt_desc.caps, PT_CAP_psb_periods);\n\tif (intel_pt_validate_cap(vmx->pt_desc.caps, PT_CAP_psb_cyc) &&\n\t\t\t!test_bit((data & RTIT_CTL_PSB_FREQ) >>\n\t\t\tRTIT_CTL_PSB_FREQ_OFFSET, &value))\n\t\treturn 1;\n\n\t/*\n\t * If ADDRx_CFG is reserved or the encodings is >2 will\n\t * cause a #GP fault.\n\t */\n\tvalue = (data & RTIT_CTL_ADDR0) >> RTIT_CTL_ADDR0_OFFSET;\n\tif ((value && (vmx->pt_desc.addr_range < 1)) || (value > 2))\n\t\treturn 1;\n\tvalue = (data & RTIT_CTL_ADDR1) >> RTIT_CTL_ADDR1_OFFSET;\n\tif ((value && (vmx->pt_desc.addr_range < 2)) || (value > 2))\n\t\treturn 1;\n\tvalue = (data & RTIT_CTL_ADDR2) >> RTIT_CTL_ADDR2_OFFSET;\n\tif ((value && (vmx->pt_desc.addr_range < 3)) || (value > 2))\n\t\treturn 1;\n\tvalue = (data & RTIT_CTL_ADDR3) >> RTIT_CTL_ADDR3_OFFSET;\n\tif ((value && (vmx->pt_desc.addr_range < 4)) || (value > 2))\n\t\treturn 1;\n\n\treturn 0;\n}\n\nstatic bool vmx_can_emulate_instruction(struct kvm_vcpu *vcpu, void *insn, int insn_len)\n{\n\treturn true;\n}\n\nstatic int skip_emulated_instruction(struct kvm_vcpu *vcpu)\n{\n\tunsigned long rip, orig_rip;\n\n\t/*\n\t * Using VMCS.VM_EXIT_INSTRUCTION_LEN on EPT misconfig depends on\n\t * undefined behavior: Intel's SDM doesn't mandate the VMCS field be\n\t * set when EPT misconfig occurs.  In practice, real hardware updates\n\t * VM_EXIT_INSTRUCTION_LEN on EPT misconfig, but other hypervisors\n\t * (namely Hyper-V) don't set it due to it being undefined behavior,\n\t * i.e. we end up advancing IP with some random value.\n\t */\n\tif (!static_cpu_has(X86_FEATURE_HYPERVISOR) ||\n\t    to_vmx(vcpu)->exit_reason != EXIT_REASON_EPT_MISCONFIG) {\n\t\torig_rip = kvm_rip_read(vcpu);\n\t\trip = orig_rip + vmcs_read32(VM_EXIT_INSTRUCTION_LEN);\n#ifdef CONFIG_X86_64\n\t\t/*\n\t\t * We need to mask out the high 32 bits of RIP if not in 64-bit\n\t\t * mode, but just finding out that we are in 64-bit mode is\n\t\t * quite expensive.  Only do it if there was a carry.\n\t\t */\n\t\tif (unlikely(((rip ^ orig_rip) >> 31) == 3) && !is_64_bit_mode(vcpu))\n\t\t\trip = (u32)rip;\n#endif\n\t\tkvm_rip_write(vcpu, rip);\n\t} else {\n\t\tif (!kvm_emulate_instruction(vcpu, EMULTYPE_SKIP))\n\t\t\treturn 0;\n\t}\n\n\t/* skipping an emulated instruction also counts */\n\tvmx_set_interrupt_shadow(vcpu, 0);\n\n\treturn 1;\n}\n\n/*\n * Recognizes a pending MTF VM-exit and records the nested state for later\n * delivery.\n */\nstatic void vmx_update_emulated_instruction(struct kvm_vcpu *vcpu)\n{\n\tstruct vmcs12 *vmcs12 = get_vmcs12(vcpu);\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\tif (!is_guest_mode(vcpu))\n\t\treturn;\n\n\t/*\n\t * Per the SDM, MTF takes priority over debug-trap exceptions besides\n\t * T-bit traps. As instruction emulation is completed (i.e. at the\n\t * instruction boundary), any #DB exception pending delivery must be a\n\t * debug-trap. Record the pending MTF state to be delivered in\n\t * vmx_check_nested_events().\n\t */\n\tif (nested_cpu_has_mtf(vmcs12) &&\n\t    (!vcpu->arch.exception.pending ||\n\t     vcpu->arch.exception.nr == DB_VECTOR))\n\t\tvmx->nested.mtf_pending = true;\n\telse\n\t\tvmx->nested.mtf_pending = false;\n}\n\nstatic int vmx_skip_emulated_instruction(struct kvm_vcpu *vcpu)\n{\n\tvmx_update_emulated_instruction(vcpu);\n\treturn skip_emulated_instruction(vcpu);\n}\n\nstatic void vmx_clear_hlt(struct kvm_vcpu *vcpu)\n{\n\t/*\n\t * Ensure that we clear the HLT state in the VMCS.  We don't need to\n\t * explicitly skip the instruction because if the HLT state is set,\n\t * then the instruction is already executing and RIP has already been\n\t * advanced.\n\t */\n\tif (kvm_hlt_in_guest(vcpu->kvm) &&\n\t\t\tvmcs_read32(GUEST_ACTIVITY_STATE) == GUEST_ACTIVITY_HLT)\n\t\tvmcs_write32(GUEST_ACTIVITY_STATE, GUEST_ACTIVITY_ACTIVE);\n}\n\nstatic void vmx_queue_exception(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tunsigned nr = vcpu->arch.exception.nr;\n\tbool has_error_code = vcpu->arch.exception.has_error_code;\n\tu32 error_code = vcpu->arch.exception.error_code;\n\tu32 intr_info = nr | INTR_INFO_VALID_MASK;\n\n\tkvm_deliver_exception_payload(vcpu);\n\n\tif (has_error_code) {\n\t\tvmcs_write32(VM_ENTRY_EXCEPTION_ERROR_CODE, error_code);\n\t\tintr_info |= INTR_INFO_DELIVER_CODE_MASK;\n\t}\n\n\tif (vmx->rmode.vm86_active) {\n\t\tint inc_eip = 0;\n\t\tif (kvm_exception_is_soft(nr))\n\t\t\tinc_eip = vcpu->arch.event_exit_inst_len;\n\t\tkvm_inject_realmode_interrupt(vcpu, nr, inc_eip);\n\t\treturn;\n\t}\n\n\tWARN_ON_ONCE(vmx->emulation_required);\n\n\tif (kvm_exception_is_soft(nr)) {\n\t\tvmcs_write32(VM_ENTRY_INSTRUCTION_LEN,\n\t\t\t     vmx->vcpu.arch.event_exit_inst_len);\n\t\tintr_info |= INTR_TYPE_SOFT_EXCEPTION;\n\t} else\n\t\tintr_info |= INTR_TYPE_HARD_EXCEPTION;\n\n\tvmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr_info);\n\n\tvmx_clear_hlt(vcpu);\n}\n\nstatic void vmx_setup_uret_msr(struct vcpu_vmx *vmx, unsigned int msr)\n{\n\tstruct vmx_uret_msr tmp;\n\tint from, to;\n\n\tfrom = __vmx_find_uret_msr(vmx, msr);\n\tif (from < 0)\n\t\treturn;\n\tto = vmx->nr_active_uret_msrs++;\n\n\ttmp = vmx->guest_uret_msrs[to];\n\tvmx->guest_uret_msrs[to] = vmx->guest_uret_msrs[from];\n\tvmx->guest_uret_msrs[from] = tmp;\n}\n\n/*\n * Set up the vmcs to automatically save and restore system\n * msrs.  Don't touch the 64-bit msrs if the guest is in legacy\n * mode, as fiddling with msrs is very expensive.\n */\nstatic void setup_msrs(struct vcpu_vmx *vmx)\n{\n\tvmx->guest_uret_msrs_loaded = false;\n\tvmx->nr_active_uret_msrs = 0;\n#ifdef CONFIG_X86_64\n\t/*\n\t * The SYSCALL MSRs are only needed on long mode guests, and only\n\t * when EFER.SCE is set.\n\t */\n\tif (is_long_mode(&vmx->vcpu) && (vmx->vcpu.arch.efer & EFER_SCE)) {\n\t\tvmx_setup_uret_msr(vmx, MSR_STAR);\n\t\tvmx_setup_uret_msr(vmx, MSR_LSTAR);\n\t\tvmx_setup_uret_msr(vmx, MSR_SYSCALL_MASK);\n\t}\n#endif\n\tif (update_transition_efer(vmx))\n\t\tvmx_setup_uret_msr(vmx, MSR_EFER);\n\n\tif (guest_cpuid_has(&vmx->vcpu, X86_FEATURE_RDTSCP))\n\t\tvmx_setup_uret_msr(vmx, MSR_TSC_AUX);\n\n\tvmx_setup_uret_msr(vmx, MSR_IA32_TSX_CTRL);\n\n\tif (cpu_has_vmx_msr_bitmap())\n\t\tvmx_update_msr_bitmap(&vmx->vcpu);\n}\n\nstatic u64 vmx_write_l1_tsc_offset(struct kvm_vcpu *vcpu, u64 offset)\n{\n\tstruct vmcs12 *vmcs12 = get_vmcs12(vcpu);\n\tu64 g_tsc_offset = 0;\n\n\t/*\n\t * We're here if L1 chose not to trap WRMSR to TSC. According\n\t * to the spec, this should set L1's TSC; The offset that L1\n\t * set for L2 remains unchanged, and still needs to be added\n\t * to the newly set TSC to get L2's TSC.\n\t */\n\tif (is_guest_mode(vcpu) &&\n\t    (vmcs12->cpu_based_vm_exec_control & CPU_BASED_USE_TSC_OFFSETTING))\n\t\tg_tsc_offset = vmcs12->tsc_offset;\n\n\ttrace_kvm_write_tsc_offset(vcpu->vcpu_id,\n\t\t\t\t   vcpu->arch.tsc_offset - g_tsc_offset,\n\t\t\t\t   offset);\n\tvmcs_write64(TSC_OFFSET, offset + g_tsc_offset);\n\treturn offset + g_tsc_offset;\n}\n\n/*\n * nested_vmx_allowed() checks whether a guest should be allowed to use VMX\n * instructions and MSRs (i.e., nested VMX). Nested VMX is disabled for\n * all guests if the \"nested\" module option is off, and can also be disabled\n * for a single guest by disabling its VMX cpuid bit.\n */\nbool nested_vmx_allowed(struct kvm_vcpu *vcpu)\n{\n\treturn nested && guest_cpuid_has(vcpu, X86_FEATURE_VMX);\n}\n\nstatic inline bool vmx_feature_control_msr_valid(struct kvm_vcpu *vcpu,\n\t\t\t\t\t\t uint64_t val)\n{\n\tuint64_t valid_bits = to_vmx(vcpu)->msr_ia32_feature_control_valid_bits;\n\n\treturn !(val & ~valid_bits);\n}\n\nstatic int vmx_get_msr_feature(struct kvm_msr_entry *msr)\n{\n\tswitch (msr->index) {\n\tcase MSR_IA32_VMX_BASIC ... MSR_IA32_VMX_VMFUNC:\n\t\tif (!nested)\n\t\t\treturn 1;\n\t\treturn vmx_get_vmx_msr(&vmcs_config.nested, msr->index, &msr->data);\n\tcase MSR_IA32_PERF_CAPABILITIES:\n\t\tmsr->data = vmx_get_perf_capabilities();\n\t\treturn 0;\n\tdefault:\n\t\treturn KVM_MSR_RET_INVALID;\n\t}\n}\n\n/*\n * Reads an msr value (of 'msr_index') into 'pdata'.\n * Returns 0 on success, non-0 otherwise.\n * Assumes vcpu_load() was already called.\n */\nstatic int vmx_get_msr(struct kvm_vcpu *vcpu, struct msr_data *msr_info)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tstruct vmx_uret_msr *msr;\n\tu32 index;\n\n\tswitch (msr_info->index) {\n#ifdef CONFIG_X86_64\n\tcase MSR_FS_BASE:\n\t\tmsr_info->data = vmcs_readl(GUEST_FS_BASE);\n\t\tbreak;\n\tcase MSR_GS_BASE:\n\t\tmsr_info->data = vmcs_readl(GUEST_GS_BASE);\n\t\tbreak;\n\tcase MSR_KERNEL_GS_BASE:\n\t\tmsr_info->data = vmx_read_guest_kernel_gs_base(vmx);\n\t\tbreak;\n#endif\n\tcase MSR_EFER:\n\t\treturn kvm_get_msr_common(vcpu, msr_info);\n\tcase MSR_IA32_TSX_CTRL:\n\t\tif (!msr_info->host_initiated &&\n\t\t    !(vcpu->arch.arch_capabilities & ARCH_CAP_TSX_CTRL_MSR))\n\t\t\treturn 1;\n\t\tgoto find_uret_msr;\n\tcase MSR_IA32_UMWAIT_CONTROL:\n\t\tif (!msr_info->host_initiated && !vmx_has_waitpkg(vmx))\n\t\t\treturn 1;\n\n\t\tmsr_info->data = vmx->msr_ia32_umwait_control;\n\t\tbreak;\n\tcase MSR_IA32_SPEC_CTRL:\n\t\tif (!msr_info->host_initiated &&\n\t\t    !guest_cpuid_has(vcpu, X86_FEATURE_SPEC_CTRL))\n\t\t\treturn 1;\n\n\t\tmsr_info->data = to_vmx(vcpu)->spec_ctrl;\n\t\tbreak;\n\tcase MSR_IA32_SYSENTER_CS:\n\t\tmsr_info->data = vmcs_read32(GUEST_SYSENTER_CS);\n\t\tbreak;\n\tcase MSR_IA32_SYSENTER_EIP:\n\t\tmsr_info->data = vmcs_readl(GUEST_SYSENTER_EIP);\n\t\tbreak;\n\tcase MSR_IA32_SYSENTER_ESP:\n\t\tmsr_info->data = vmcs_readl(GUEST_SYSENTER_ESP);\n\t\tbreak;\n\tcase MSR_IA32_BNDCFGS:\n\t\tif (!kvm_mpx_supported() ||\n\t\t    (!msr_info->host_initiated &&\n\t\t     !guest_cpuid_has(vcpu, X86_FEATURE_MPX)))\n\t\t\treturn 1;\n\t\tmsr_info->data = vmcs_read64(GUEST_BNDCFGS);\n\t\tbreak;\n\tcase MSR_IA32_MCG_EXT_CTL:\n\t\tif (!msr_info->host_initiated &&\n\t\t    !(vmx->msr_ia32_feature_control &\n\t\t      FEAT_CTL_LMCE_ENABLED))\n\t\t\treturn 1;\n\t\tmsr_info->data = vcpu->arch.mcg_ext_ctl;\n\t\tbreak;\n\tcase MSR_IA32_FEAT_CTL:\n\t\tmsr_info->data = vmx->msr_ia32_feature_control;\n\t\tbreak;\n\tcase MSR_IA32_VMX_BASIC ... MSR_IA32_VMX_VMFUNC:\n\t\tif (!nested_vmx_allowed(vcpu))\n\t\t\treturn 1;\n\t\tif (vmx_get_vmx_msr(&vmx->nested.msrs, msr_info->index,\n\t\t\t\t    &msr_info->data))\n\t\t\treturn 1;\n\t\t/*\n\t\t * Enlightened VMCS v1 doesn't have certain fields, but buggy\n\t\t * Hyper-V versions are still trying to use corresponding\n\t\t * features when they are exposed. Filter out the essential\n\t\t * minimum.\n\t\t */\n\t\tif (!msr_info->host_initiated &&\n\t\t    vmx->nested.enlightened_vmcs_enabled)\n\t\t\tnested_evmcs_filter_control_msr(msr_info->index,\n\t\t\t\t\t\t\t&msr_info->data);\n\t\tbreak;\n\tcase MSR_IA32_RTIT_CTL:\n\t\tif (!vmx_pt_mode_is_host_guest())\n\t\t\treturn 1;\n\t\tmsr_info->data = vmx->pt_desc.guest.ctl;\n\t\tbreak;\n\tcase MSR_IA32_RTIT_STATUS:\n\t\tif (!vmx_pt_mode_is_host_guest())\n\t\t\treturn 1;\n\t\tmsr_info->data = vmx->pt_desc.guest.status;\n\t\tbreak;\n\tcase MSR_IA32_RTIT_CR3_MATCH:\n\t\tif (!vmx_pt_mode_is_host_guest() ||\n\t\t\t!intel_pt_validate_cap(vmx->pt_desc.caps,\n\t\t\t\t\t\tPT_CAP_cr3_filtering))\n\t\t\treturn 1;\n\t\tmsr_info->data = vmx->pt_desc.guest.cr3_match;\n\t\tbreak;\n\tcase MSR_IA32_RTIT_OUTPUT_BASE:\n\t\tif (!vmx_pt_mode_is_host_guest() ||\n\t\t\t(!intel_pt_validate_cap(vmx->pt_desc.caps,\n\t\t\t\t\tPT_CAP_topa_output) &&\n\t\t\t !intel_pt_validate_cap(vmx->pt_desc.caps,\n\t\t\t\t\tPT_CAP_single_range_output)))\n\t\t\treturn 1;\n\t\tmsr_info->data = vmx->pt_desc.guest.output_base;\n\t\tbreak;\n\tcase MSR_IA32_RTIT_OUTPUT_MASK:\n\t\tif (!vmx_pt_mode_is_host_guest() ||\n\t\t\t(!intel_pt_validate_cap(vmx->pt_desc.caps,\n\t\t\t\t\tPT_CAP_topa_output) &&\n\t\t\t !intel_pt_validate_cap(vmx->pt_desc.caps,\n\t\t\t\t\tPT_CAP_single_range_output)))\n\t\t\treturn 1;\n\t\tmsr_info->data = vmx->pt_desc.guest.output_mask;\n\t\tbreak;\n\tcase MSR_IA32_RTIT_ADDR0_A ... MSR_IA32_RTIT_ADDR3_B:\n\t\tindex = msr_info->index - MSR_IA32_RTIT_ADDR0_A;\n\t\tif (!vmx_pt_mode_is_host_guest() ||\n\t\t\t(index >= 2 * intel_pt_validate_cap(vmx->pt_desc.caps,\n\t\t\t\t\tPT_CAP_num_address_ranges)))\n\t\t\treturn 1;\n\t\tif (index % 2)\n\t\t\tmsr_info->data = vmx->pt_desc.guest.addr_b[index / 2];\n\t\telse\n\t\t\tmsr_info->data = vmx->pt_desc.guest.addr_a[index / 2];\n\t\tbreak;\n\tcase MSR_TSC_AUX:\n\t\tif (!msr_info->host_initiated &&\n\t\t    !guest_cpuid_has(vcpu, X86_FEATURE_RDTSCP))\n\t\t\treturn 1;\n\t\tgoto find_uret_msr;\n\tdefault:\n\tfind_uret_msr:\n\t\tmsr = vmx_find_uret_msr(vmx, msr_info->index);\n\t\tif (msr) {\n\t\t\tmsr_info->data = msr->data;\n\t\t\tbreak;\n\t\t}\n\t\treturn kvm_get_msr_common(vcpu, msr_info);\n\t}\n\n\treturn 0;\n}\n\nstatic u64 nested_vmx_truncate_sysenter_addr(struct kvm_vcpu *vcpu,\n\t\t\t\t\t\t    u64 data)\n{\n#ifdef CONFIG_X86_64\n\tif (!guest_cpuid_has(vcpu, X86_FEATURE_LM))\n\t\treturn (u32)data;\n#endif\n\treturn (unsigned long)data;\n}\n\n/*\n * Writes msr value into the appropriate \"register\".\n * Returns 0 on success, non-0 otherwise.\n * Assumes vcpu_load() was already called.\n */\nstatic int vmx_set_msr(struct kvm_vcpu *vcpu, struct msr_data *msr_info)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tstruct vmx_uret_msr *msr;\n\tint ret = 0;\n\tu32 msr_index = msr_info->index;\n\tu64 data = msr_info->data;\n\tu32 index;\n\n\tswitch (msr_index) {\n\tcase MSR_EFER:\n\t\tret = kvm_set_msr_common(vcpu, msr_info);\n\t\tbreak;\n#ifdef CONFIG_X86_64\n\tcase MSR_FS_BASE:\n\t\tvmx_segment_cache_clear(vmx);\n\t\tvmcs_writel(GUEST_FS_BASE, data);\n\t\tbreak;\n\tcase MSR_GS_BASE:\n\t\tvmx_segment_cache_clear(vmx);\n\t\tvmcs_writel(GUEST_GS_BASE, data);\n\t\tbreak;\n\tcase MSR_KERNEL_GS_BASE:\n\t\tvmx_write_guest_kernel_gs_base(vmx, data);\n\t\tbreak;\n#endif\n\tcase MSR_IA32_SYSENTER_CS:\n\t\tif (is_guest_mode(vcpu))\n\t\t\tget_vmcs12(vcpu)->guest_sysenter_cs = data;\n\t\tvmcs_write32(GUEST_SYSENTER_CS, data);\n\t\tbreak;\n\tcase MSR_IA32_SYSENTER_EIP:\n\t\tif (is_guest_mode(vcpu)) {\n\t\t\tdata = nested_vmx_truncate_sysenter_addr(vcpu, data);\n\t\t\tget_vmcs12(vcpu)->guest_sysenter_eip = data;\n\t\t}\n\t\tvmcs_writel(GUEST_SYSENTER_EIP, data);\n\t\tbreak;\n\tcase MSR_IA32_SYSENTER_ESP:\n\t\tif (is_guest_mode(vcpu)) {\n\t\t\tdata = nested_vmx_truncate_sysenter_addr(vcpu, data);\n\t\t\tget_vmcs12(vcpu)->guest_sysenter_esp = data;\n\t\t}\n\t\tvmcs_writel(GUEST_SYSENTER_ESP, data);\n\t\tbreak;\n\tcase MSR_IA32_DEBUGCTLMSR:\n\t\tif (is_guest_mode(vcpu) && get_vmcs12(vcpu)->vm_exit_controls &\n\t\t\t\t\t\tVM_EXIT_SAVE_DEBUG_CONTROLS)\n\t\t\tget_vmcs12(vcpu)->guest_ia32_debugctl = data;\n\n\t\tret = kvm_set_msr_common(vcpu, msr_info);\n\t\tbreak;\n\n\tcase MSR_IA32_BNDCFGS:\n\t\tif (!kvm_mpx_supported() ||\n\t\t    (!msr_info->host_initiated &&\n\t\t     !guest_cpuid_has(vcpu, X86_FEATURE_MPX)))\n\t\t\treturn 1;\n\t\tif (is_noncanonical_address(data & PAGE_MASK, vcpu) ||\n\t\t    (data & MSR_IA32_BNDCFGS_RSVD))\n\t\t\treturn 1;\n\t\tvmcs_write64(GUEST_BNDCFGS, data);\n\t\tbreak;\n\tcase MSR_IA32_UMWAIT_CONTROL:\n\t\tif (!msr_info->host_initiated && !vmx_has_waitpkg(vmx))\n\t\t\treturn 1;\n\n\t\t/* The reserved bit 1 and non-32 bit [63:32] should be zero */\n\t\tif (data & (BIT_ULL(1) | GENMASK_ULL(63, 32)))\n\t\t\treturn 1;\n\n\t\tvmx->msr_ia32_umwait_control = data;\n\t\tbreak;\n\tcase MSR_IA32_SPEC_CTRL:\n\t\tif (!msr_info->host_initiated &&\n\t\t    !guest_cpuid_has(vcpu, X86_FEATURE_SPEC_CTRL))\n\t\t\treturn 1;\n\n\t\tif (kvm_spec_ctrl_test_value(data))\n\t\t\treturn 1;\n\n\t\tvmx->spec_ctrl = data;\n\t\tif (!data)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * For non-nested:\n\t\t * When it's written (to non-zero) for the first time, pass\n\t\t * it through.\n\t\t *\n\t\t * For nested:\n\t\t * The handling of the MSR bitmap for L2 guests is done in\n\t\t * nested_vmx_prepare_msr_bitmap. We should not touch the\n\t\t * vmcs02.msr_bitmap here since it gets completely overwritten\n\t\t * in the merging. We update the vmcs01 here for L1 as well\n\t\t * since it will end up touching the MSR anyway now.\n\t\t */\n\t\tvmx_disable_intercept_for_msr(vcpu,\n\t\t\t\t\t      MSR_IA32_SPEC_CTRL,\n\t\t\t\t\t      MSR_TYPE_RW);\n\t\tbreak;\n\tcase MSR_IA32_TSX_CTRL:\n\t\tif (!msr_info->host_initiated &&\n\t\t    !(vcpu->arch.arch_capabilities & ARCH_CAP_TSX_CTRL_MSR))\n\t\t\treturn 1;\n\t\tif (data & ~(TSX_CTRL_RTM_DISABLE | TSX_CTRL_CPUID_CLEAR))\n\t\t\treturn 1;\n\t\tgoto find_uret_msr;\n\tcase MSR_IA32_PRED_CMD:\n\t\tif (!msr_info->host_initiated &&\n\t\t    !guest_cpuid_has(vcpu, X86_FEATURE_SPEC_CTRL))\n\t\t\treturn 1;\n\n\t\tif (data & ~PRED_CMD_IBPB)\n\t\t\treturn 1;\n\t\tif (!boot_cpu_has(X86_FEATURE_SPEC_CTRL))\n\t\t\treturn 1;\n\t\tif (!data)\n\t\t\tbreak;\n\n\t\twrmsrl(MSR_IA32_PRED_CMD, PRED_CMD_IBPB);\n\n\t\t/*\n\t\t * For non-nested:\n\t\t * When it's written (to non-zero) for the first time, pass\n\t\t * it through.\n\t\t *\n\t\t * For nested:\n\t\t * The handling of the MSR bitmap for L2 guests is done in\n\t\t * nested_vmx_prepare_msr_bitmap. We should not touch the\n\t\t * vmcs02.msr_bitmap here since it gets completely overwritten\n\t\t * in the merging.\n\t\t */\n\t\tvmx_disable_intercept_for_msr(vcpu, MSR_IA32_PRED_CMD, MSR_TYPE_W);\n\t\tbreak;\n\tcase MSR_IA32_CR_PAT:\n\t\tif (!kvm_pat_valid(data))\n\t\t\treturn 1;\n\n\t\tif (is_guest_mode(vcpu) &&\n\t\t    get_vmcs12(vcpu)->vm_exit_controls & VM_EXIT_SAVE_IA32_PAT)\n\t\t\tget_vmcs12(vcpu)->guest_ia32_pat = data;\n\n\t\tif (vmcs_config.vmentry_ctrl & VM_ENTRY_LOAD_IA32_PAT) {\n\t\t\tvmcs_write64(GUEST_IA32_PAT, data);\n\t\t\tvcpu->arch.pat = data;\n\t\t\tbreak;\n\t\t}\n\t\tret = kvm_set_msr_common(vcpu, msr_info);\n\t\tbreak;\n\tcase MSR_IA32_TSC_ADJUST:\n\t\tret = kvm_set_msr_common(vcpu, msr_info);\n\t\tbreak;\n\tcase MSR_IA32_MCG_EXT_CTL:\n\t\tif ((!msr_info->host_initiated &&\n\t\t     !(to_vmx(vcpu)->msr_ia32_feature_control &\n\t\t       FEAT_CTL_LMCE_ENABLED)) ||\n\t\t    (data & ~MCG_EXT_CTL_LMCE_EN))\n\t\t\treturn 1;\n\t\tvcpu->arch.mcg_ext_ctl = data;\n\t\tbreak;\n\tcase MSR_IA32_FEAT_CTL:\n\t\tif (!vmx_feature_control_msr_valid(vcpu, data) ||\n\t\t    (to_vmx(vcpu)->msr_ia32_feature_control &\n\t\t     FEAT_CTL_LOCKED && !msr_info->host_initiated))\n\t\t\treturn 1;\n\t\tvmx->msr_ia32_feature_control = data;\n\t\tif (msr_info->host_initiated && data == 0)\n\t\t\tvmx_leave_nested(vcpu);\n\t\tbreak;\n\tcase MSR_IA32_VMX_BASIC ... MSR_IA32_VMX_VMFUNC:\n\t\tif (!msr_info->host_initiated)\n\t\t\treturn 1; /* they are read-only */\n\t\tif (!nested_vmx_allowed(vcpu))\n\t\t\treturn 1;\n\t\treturn vmx_set_vmx_msr(vcpu, msr_index, data);\n\tcase MSR_IA32_RTIT_CTL:\n\t\tif (!vmx_pt_mode_is_host_guest() ||\n\t\t\tvmx_rtit_ctl_check(vcpu, data) ||\n\t\t\tvmx->nested.vmxon)\n\t\t\treturn 1;\n\t\tvmcs_write64(GUEST_IA32_RTIT_CTL, data);\n\t\tvmx->pt_desc.guest.ctl = data;\n\t\tpt_update_intercept_for_msr(vcpu);\n\t\tbreak;\n\tcase MSR_IA32_RTIT_STATUS:\n\t\tif (!pt_can_write_msr(vmx))\n\t\t\treturn 1;\n\t\tif (data & MSR_IA32_RTIT_STATUS_MASK)\n\t\t\treturn 1;\n\t\tvmx->pt_desc.guest.status = data;\n\t\tbreak;\n\tcase MSR_IA32_RTIT_CR3_MATCH:\n\t\tif (!pt_can_write_msr(vmx))\n\t\t\treturn 1;\n\t\tif (!intel_pt_validate_cap(vmx->pt_desc.caps,\n\t\t\t\t\t   PT_CAP_cr3_filtering))\n\t\t\treturn 1;\n\t\tvmx->pt_desc.guest.cr3_match = data;\n\t\tbreak;\n\tcase MSR_IA32_RTIT_OUTPUT_BASE:\n\t\tif (!pt_can_write_msr(vmx))\n\t\t\treturn 1;\n\t\tif (!intel_pt_validate_cap(vmx->pt_desc.caps,\n\t\t\t\t\t   PT_CAP_topa_output) &&\n\t\t    !intel_pt_validate_cap(vmx->pt_desc.caps,\n\t\t\t\t\t   PT_CAP_single_range_output))\n\t\t\treturn 1;\n\t\tif (!pt_output_base_valid(vcpu, data))\n\t\t\treturn 1;\n\t\tvmx->pt_desc.guest.output_base = data;\n\t\tbreak;\n\tcase MSR_IA32_RTIT_OUTPUT_MASK:\n\t\tif (!pt_can_write_msr(vmx))\n\t\t\treturn 1;\n\t\tif (!intel_pt_validate_cap(vmx->pt_desc.caps,\n\t\t\t\t\t   PT_CAP_topa_output) &&\n\t\t    !intel_pt_validate_cap(vmx->pt_desc.caps,\n\t\t\t\t\t   PT_CAP_single_range_output))\n\t\t\treturn 1;\n\t\tvmx->pt_desc.guest.output_mask = data;\n\t\tbreak;\n\tcase MSR_IA32_RTIT_ADDR0_A ... MSR_IA32_RTIT_ADDR3_B:\n\t\tif (!pt_can_write_msr(vmx))\n\t\t\treturn 1;\n\t\tindex = msr_info->index - MSR_IA32_RTIT_ADDR0_A;\n\t\tif (index >= 2 * intel_pt_validate_cap(vmx->pt_desc.caps,\n\t\t\t\t\t\t       PT_CAP_num_address_ranges))\n\t\t\treturn 1;\n\t\tif (is_noncanonical_address(data, vcpu))\n\t\t\treturn 1;\n\t\tif (index % 2)\n\t\t\tvmx->pt_desc.guest.addr_b[index / 2] = data;\n\t\telse\n\t\t\tvmx->pt_desc.guest.addr_a[index / 2] = data;\n\t\tbreak;\n\tcase MSR_TSC_AUX:\n\t\tif (!msr_info->host_initiated &&\n\t\t    !guest_cpuid_has(vcpu, X86_FEATURE_RDTSCP))\n\t\t\treturn 1;\n\t\t/* Check reserved bit, higher 32 bits should be zero */\n\t\tif ((data >> 32) != 0)\n\t\t\treturn 1;\n\t\tgoto find_uret_msr;\n\n\tdefault:\n\tfind_uret_msr:\n\t\tmsr = vmx_find_uret_msr(vmx, msr_index);\n\t\tif (msr)\n\t\t\tret = vmx_set_guest_uret_msr(vmx, msr, data);\n\t\telse\n\t\t\tret = kvm_set_msr_common(vcpu, msr_info);\n\t}\n\n\treturn ret;\n}\n\nstatic void vmx_cache_reg(struct kvm_vcpu *vcpu, enum kvm_reg reg)\n{\n\tunsigned long guest_owned_bits;\n\n\tkvm_register_mark_available(vcpu, reg);\n\n\tswitch (reg) {\n\tcase VCPU_REGS_RSP:\n\t\tvcpu->arch.regs[VCPU_REGS_RSP] = vmcs_readl(GUEST_RSP);\n\t\tbreak;\n\tcase VCPU_REGS_RIP:\n\t\tvcpu->arch.regs[VCPU_REGS_RIP] = vmcs_readl(GUEST_RIP);\n\t\tbreak;\n\tcase VCPU_EXREG_PDPTR:\n\t\tif (enable_ept)\n\t\t\tept_save_pdptrs(vcpu);\n\t\tbreak;\n\tcase VCPU_EXREG_CR0:\n\t\tguest_owned_bits = vcpu->arch.cr0_guest_owned_bits;\n\n\t\tvcpu->arch.cr0 &= ~guest_owned_bits;\n\t\tvcpu->arch.cr0 |= vmcs_readl(GUEST_CR0) & guest_owned_bits;\n\t\tbreak;\n\tcase VCPU_EXREG_CR3:\n\t\tif (is_unrestricted_guest(vcpu) ||\n\t\t    (enable_ept && is_paging(vcpu)))\n\t\t\tvcpu->arch.cr3 = vmcs_readl(GUEST_CR3);\n\t\tbreak;\n\tcase VCPU_EXREG_CR4:\n\t\tguest_owned_bits = vcpu->arch.cr4_guest_owned_bits;\n\n\t\tvcpu->arch.cr4 &= ~guest_owned_bits;\n\t\tvcpu->arch.cr4 |= vmcs_readl(GUEST_CR4) & guest_owned_bits;\n\t\tbreak;\n\tdefault:\n\t\tWARN_ON_ONCE(1);\n\t\tbreak;\n\t}\n}\n\nstatic __init int cpu_has_kvm_support(void)\n{\n\treturn cpu_has_vmx();\n}\n\nstatic __init int vmx_disabled_by_bios(void)\n{\n\treturn !boot_cpu_has(X86_FEATURE_MSR_IA32_FEAT_CTL) ||\n\t       !boot_cpu_has(X86_FEATURE_VMX);\n}\n\nstatic int kvm_cpu_vmxon(u64 vmxon_pointer)\n{\n\tu64 msr;\n\n\tcr4_set_bits(X86_CR4_VMXE);\n\tintel_pt_handle_vmx(1);\n\n\tasm_volatile_goto(\"1: vmxon %[vmxon_pointer]\\n\\t\"\n\t\t\t  _ASM_EXTABLE(1b, %l[fault])\n\t\t\t  : : [vmxon_pointer] \"m\"(vmxon_pointer)\n\t\t\t  : : fault);\n\treturn 0;\n\nfault:\n\tWARN_ONCE(1, \"VMXON faulted, MSR_IA32_FEAT_CTL (0x3a) = 0x%llx\\n\",\n\t\t  rdmsrl_safe(MSR_IA32_FEAT_CTL, &msr) ? 0xdeadbeef : msr);\n\tintel_pt_handle_vmx(0);\n\tcr4_clear_bits(X86_CR4_VMXE);\n\n\treturn -EFAULT;\n}\n\nstatic int hardware_enable(void)\n{\n\tint cpu = raw_smp_processor_id();\n\tu64 phys_addr = __pa(per_cpu(vmxarea, cpu));\n\tint r;\n\n\tif (cr4_read_shadow() & X86_CR4_VMXE)\n\t\treturn -EBUSY;\n\n\t/*\n\t * This can happen if we hot-added a CPU but failed to allocate\n\t * VP assist page for it.\n\t */\n\tif (static_branch_unlikely(&enable_evmcs) &&\n\t    !hv_get_vp_assist_page(cpu))\n\t\treturn -EFAULT;\n\n\tr = kvm_cpu_vmxon(phys_addr);\n\tif (r)\n\t\treturn r;\n\n\tif (enable_ept)\n\t\tept_sync_global();\n\n\treturn 0;\n}\n\nstatic void vmclear_local_loaded_vmcss(void)\n{\n\tint cpu = raw_smp_processor_id();\n\tstruct loaded_vmcs *v, *n;\n\n\tlist_for_each_entry_safe(v, n, &per_cpu(loaded_vmcss_on_cpu, cpu),\n\t\t\t\t loaded_vmcss_on_cpu_link)\n\t\t__loaded_vmcs_clear(v);\n}\n\n\n/* Just like cpu_vmxoff(), but with the __kvm_handle_fault_on_reboot()\n * tricks.\n */\nstatic void kvm_cpu_vmxoff(void)\n{\n\tasm volatile (__ex(\"vmxoff\"));\n\n\tintel_pt_handle_vmx(0);\n\tcr4_clear_bits(X86_CR4_VMXE);\n}\n\nstatic void hardware_disable(void)\n{\n\tvmclear_local_loaded_vmcss();\n\tkvm_cpu_vmxoff();\n}\n\n/*\n * There is no X86_FEATURE for SGX yet, but anyway we need to query CPUID\n * directly instead of going through cpu_has(), to ensure KVM is trapping\n * ENCLS whenever it's supported in hardware.  It does not matter whether\n * the host OS supports or has enabled SGX.\n */\nstatic bool cpu_has_sgx(void)\n{\n\treturn cpuid_eax(0) >= 0x12 && (cpuid_eax(0x12) & BIT(0));\n}\n\nstatic __init int adjust_vmx_controls(u32 ctl_min, u32 ctl_opt,\n\t\t\t\t      u32 msr, u32 *result)\n{\n\tu32 vmx_msr_low, vmx_msr_high;\n\tu32 ctl = ctl_min | ctl_opt;\n\n\trdmsr(msr, vmx_msr_low, vmx_msr_high);\n\n\tctl &= vmx_msr_high; /* bit == 0 in high word ==> must be zero */\n\tctl |= vmx_msr_low;  /* bit == 1 in low word  ==> must be one  */\n\n\t/* Ensure minimum (required) set of control bits are supported. */\n\tif (ctl_min & ~ctl)\n\t\treturn -EIO;\n\n\t*result = ctl;\n\treturn 0;\n}\n\nstatic __init int setup_vmcs_config(struct vmcs_config *vmcs_conf,\n\t\t\t\t    struct vmx_capability *vmx_cap)\n{\n\tu32 vmx_msr_low, vmx_msr_high;\n\tu32 min, opt, min2, opt2;\n\tu32 _pin_based_exec_control = 0;\n\tu32 _cpu_based_exec_control = 0;\n\tu32 _cpu_based_2nd_exec_control = 0;\n\tu32 _vmexit_control = 0;\n\tu32 _vmentry_control = 0;\n\n\tmemset(vmcs_conf, 0, sizeof(*vmcs_conf));\n\tmin = CPU_BASED_HLT_EXITING |\n#ifdef CONFIG_X86_64\n\t      CPU_BASED_CR8_LOAD_EXITING |\n\t      CPU_BASED_CR8_STORE_EXITING |\n#endif\n\t      CPU_BASED_CR3_LOAD_EXITING |\n\t      CPU_BASED_CR3_STORE_EXITING |\n\t      CPU_BASED_UNCOND_IO_EXITING |\n\t      CPU_BASED_MOV_DR_EXITING |\n\t      CPU_BASED_USE_TSC_OFFSETTING |\n\t      CPU_BASED_MWAIT_EXITING |\n\t      CPU_BASED_MONITOR_EXITING |\n\t      CPU_BASED_INVLPG_EXITING |\n\t      CPU_BASED_RDPMC_EXITING;\n\n\topt = CPU_BASED_TPR_SHADOW |\n\t      CPU_BASED_USE_MSR_BITMAPS |\n\t      CPU_BASED_ACTIVATE_SECONDARY_CONTROLS;\n\tif (adjust_vmx_controls(min, opt, MSR_IA32_VMX_PROCBASED_CTLS,\n\t\t\t\t&_cpu_based_exec_control) < 0)\n\t\treturn -EIO;\n#ifdef CONFIG_X86_64\n\tif ((_cpu_based_exec_control & CPU_BASED_TPR_SHADOW))\n\t\t_cpu_based_exec_control &= ~CPU_BASED_CR8_LOAD_EXITING &\n\t\t\t\t\t   ~CPU_BASED_CR8_STORE_EXITING;\n#endif\n\tif (_cpu_based_exec_control & CPU_BASED_ACTIVATE_SECONDARY_CONTROLS) {\n\t\tmin2 = 0;\n\t\topt2 = SECONDARY_EXEC_VIRTUALIZE_APIC_ACCESSES |\n\t\t\tSECONDARY_EXEC_VIRTUALIZE_X2APIC_MODE |\n\t\t\tSECONDARY_EXEC_WBINVD_EXITING |\n\t\t\tSECONDARY_EXEC_ENABLE_VPID |\n\t\t\tSECONDARY_EXEC_ENABLE_EPT |\n\t\t\tSECONDARY_EXEC_UNRESTRICTED_GUEST |\n\t\t\tSECONDARY_EXEC_PAUSE_LOOP_EXITING |\n\t\t\tSECONDARY_EXEC_DESC |\n\t\t\tSECONDARY_EXEC_ENABLE_RDTSCP |\n\t\t\tSECONDARY_EXEC_ENABLE_INVPCID |\n\t\t\tSECONDARY_EXEC_APIC_REGISTER_VIRT |\n\t\t\tSECONDARY_EXEC_VIRTUAL_INTR_DELIVERY |\n\t\t\tSECONDARY_EXEC_SHADOW_VMCS |\n\t\t\tSECONDARY_EXEC_XSAVES |\n\t\t\tSECONDARY_EXEC_RDSEED_EXITING |\n\t\t\tSECONDARY_EXEC_RDRAND_EXITING |\n\t\t\tSECONDARY_EXEC_ENABLE_PML |\n\t\t\tSECONDARY_EXEC_TSC_SCALING |\n\t\t\tSECONDARY_EXEC_ENABLE_USR_WAIT_PAUSE |\n\t\t\tSECONDARY_EXEC_PT_USE_GPA |\n\t\t\tSECONDARY_EXEC_PT_CONCEAL_VMX |\n\t\t\tSECONDARY_EXEC_ENABLE_VMFUNC;\n\t\tif (cpu_has_sgx())\n\t\t\topt2 |= SECONDARY_EXEC_ENCLS_EXITING;\n\t\tif (adjust_vmx_controls(min2, opt2,\n\t\t\t\t\tMSR_IA32_VMX_PROCBASED_CTLS2,\n\t\t\t\t\t&_cpu_based_2nd_exec_control) < 0)\n\t\t\treturn -EIO;\n\t}\n#ifndef CONFIG_X86_64\n\tif (!(_cpu_based_2nd_exec_control &\n\t\t\t\tSECONDARY_EXEC_VIRTUALIZE_APIC_ACCESSES))\n\t\t_cpu_based_exec_control &= ~CPU_BASED_TPR_SHADOW;\n#endif\n\n\tif (!(_cpu_based_exec_control & CPU_BASED_TPR_SHADOW))\n\t\t_cpu_based_2nd_exec_control &= ~(\n\t\t\t\tSECONDARY_EXEC_APIC_REGISTER_VIRT |\n\t\t\t\tSECONDARY_EXEC_VIRTUALIZE_X2APIC_MODE |\n\t\t\t\tSECONDARY_EXEC_VIRTUAL_INTR_DELIVERY);\n\n\trdmsr_safe(MSR_IA32_VMX_EPT_VPID_CAP,\n\t\t&vmx_cap->ept, &vmx_cap->vpid);\n\n\tif (_cpu_based_2nd_exec_control & SECONDARY_EXEC_ENABLE_EPT) {\n\t\t/* CR3 accesses and invlpg don't need to cause VM Exits when EPT\n\t\t   enabled */\n\t\t_cpu_based_exec_control &= ~(CPU_BASED_CR3_LOAD_EXITING |\n\t\t\t\t\t     CPU_BASED_CR3_STORE_EXITING |\n\t\t\t\t\t     CPU_BASED_INVLPG_EXITING);\n\t} else if (vmx_cap->ept) {\n\t\tvmx_cap->ept = 0;\n\t\tpr_warn_once(\"EPT CAP should not exist if not support \"\n\t\t\t\t\"1-setting enable EPT VM-execution control\\n\");\n\t}\n\tif (!(_cpu_based_2nd_exec_control & SECONDARY_EXEC_ENABLE_VPID) &&\n\t\tvmx_cap->vpid) {\n\t\tvmx_cap->vpid = 0;\n\t\tpr_warn_once(\"VPID CAP should not exist if not support \"\n\t\t\t\t\"1-setting enable VPID VM-execution control\\n\");\n\t}\n\n\tmin = VM_EXIT_SAVE_DEBUG_CONTROLS | VM_EXIT_ACK_INTR_ON_EXIT;\n#ifdef CONFIG_X86_64\n\tmin |= VM_EXIT_HOST_ADDR_SPACE_SIZE;\n#endif\n\topt = VM_EXIT_LOAD_IA32_PERF_GLOBAL_CTRL |\n\t      VM_EXIT_LOAD_IA32_PAT |\n\t      VM_EXIT_LOAD_IA32_EFER |\n\t      VM_EXIT_CLEAR_BNDCFGS |\n\t      VM_EXIT_PT_CONCEAL_PIP |\n\t      VM_EXIT_CLEAR_IA32_RTIT_CTL;\n\tif (adjust_vmx_controls(min, opt, MSR_IA32_VMX_EXIT_CTLS,\n\t\t\t\t&_vmexit_control) < 0)\n\t\treturn -EIO;\n\n\tmin = PIN_BASED_EXT_INTR_MASK | PIN_BASED_NMI_EXITING;\n\topt = PIN_BASED_VIRTUAL_NMIS | PIN_BASED_POSTED_INTR |\n\t\t PIN_BASED_VMX_PREEMPTION_TIMER;\n\tif (adjust_vmx_controls(min, opt, MSR_IA32_VMX_PINBASED_CTLS,\n\t\t\t\t&_pin_based_exec_control) < 0)\n\t\treturn -EIO;\n\n\tif (cpu_has_broken_vmx_preemption_timer())\n\t\t_pin_based_exec_control &= ~PIN_BASED_VMX_PREEMPTION_TIMER;\n\tif (!(_cpu_based_2nd_exec_control &\n\t\tSECONDARY_EXEC_VIRTUAL_INTR_DELIVERY))\n\t\t_pin_based_exec_control &= ~PIN_BASED_POSTED_INTR;\n\n\tmin = VM_ENTRY_LOAD_DEBUG_CONTROLS;\n\topt = VM_ENTRY_LOAD_IA32_PERF_GLOBAL_CTRL |\n\t      VM_ENTRY_LOAD_IA32_PAT |\n\t      VM_ENTRY_LOAD_IA32_EFER |\n\t      VM_ENTRY_LOAD_BNDCFGS |\n\t      VM_ENTRY_PT_CONCEAL_PIP |\n\t      VM_ENTRY_LOAD_IA32_RTIT_CTL;\n\tif (adjust_vmx_controls(min, opt, MSR_IA32_VMX_ENTRY_CTLS,\n\t\t\t\t&_vmentry_control) < 0)\n\t\treturn -EIO;\n\n\t/*\n\t * Some cpus support VM_{ENTRY,EXIT}_IA32_PERF_GLOBAL_CTRL but they\n\t * can't be used due to an errata where VM Exit may incorrectly clear\n\t * IA32_PERF_GLOBAL_CTRL[34:32].  Workaround the errata by using the\n\t * MSR load mechanism to switch IA32_PERF_GLOBAL_CTRL.\n\t */\n\tif (boot_cpu_data.x86 == 0x6) {\n\t\tswitch (boot_cpu_data.x86_model) {\n\t\tcase 26: /* AAK155 */\n\t\tcase 30: /* AAP115 */\n\t\tcase 37: /* AAT100 */\n\t\tcase 44: /* BC86,AAY89,BD102 */\n\t\tcase 46: /* BA97 */\n\t\t\t_vmentry_control &= ~VM_ENTRY_LOAD_IA32_PERF_GLOBAL_CTRL;\n\t\t\t_vmexit_control &= ~VM_EXIT_LOAD_IA32_PERF_GLOBAL_CTRL;\n\t\t\tpr_warn_once(\"kvm: VM_EXIT_LOAD_IA32_PERF_GLOBAL_CTRL \"\n\t\t\t\t\t\"does not work properly. Using workaround\\n\");\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n\n\trdmsr(MSR_IA32_VMX_BASIC, vmx_msr_low, vmx_msr_high);\n\n\t/* IA-32 SDM Vol 3B: VMCS size is never greater than 4kB. */\n\tif ((vmx_msr_high & 0x1fff) > PAGE_SIZE)\n\t\treturn -EIO;\n\n#ifdef CONFIG_X86_64\n\t/* IA-32 SDM Vol 3B: 64-bit CPUs always have VMX_BASIC_MSR[48]==0. */\n\tif (vmx_msr_high & (1u<<16))\n\t\treturn -EIO;\n#endif\n\n\t/* Require Write-Back (WB) memory type for VMCS accesses. */\n\tif (((vmx_msr_high >> 18) & 15) != 6)\n\t\treturn -EIO;\n\n\tvmcs_conf->size = vmx_msr_high & 0x1fff;\n\tvmcs_conf->order = get_order(vmcs_conf->size);\n\tvmcs_conf->basic_cap = vmx_msr_high & ~0x1fff;\n\n\tvmcs_conf->revision_id = vmx_msr_low;\n\n\tvmcs_conf->pin_based_exec_ctrl = _pin_based_exec_control;\n\tvmcs_conf->cpu_based_exec_ctrl = _cpu_based_exec_control;\n\tvmcs_conf->cpu_based_2nd_exec_ctrl = _cpu_based_2nd_exec_control;\n\tvmcs_conf->vmexit_ctrl         = _vmexit_control;\n\tvmcs_conf->vmentry_ctrl        = _vmentry_control;\n\n#if IS_ENABLED(CONFIG_HYPERV)\n\tif (enlightened_vmcs)\n\t\tevmcs_sanitize_exec_ctrls(vmcs_conf);\n#endif\n\n\treturn 0;\n}\n\nstruct vmcs *alloc_vmcs_cpu(bool shadow, int cpu, gfp_t flags)\n{\n\tint node = cpu_to_node(cpu);\n\tstruct page *pages;\n\tstruct vmcs *vmcs;\n\n\tpages = __alloc_pages_node(node, flags, vmcs_config.order);\n\tif (!pages)\n\t\treturn NULL;\n\tvmcs = page_address(pages);\n\tmemset(vmcs, 0, vmcs_config.size);\n\n\t/* KVM supports Enlightened VMCS v1 only */\n\tif (static_branch_unlikely(&enable_evmcs))\n\t\tvmcs->hdr.revision_id = KVM_EVMCS_VERSION;\n\telse\n\t\tvmcs->hdr.revision_id = vmcs_config.revision_id;\n\n\tif (shadow)\n\t\tvmcs->hdr.shadow_vmcs = 1;\n\treturn vmcs;\n}\n\nvoid free_vmcs(struct vmcs *vmcs)\n{\n\tfree_pages((unsigned long)vmcs, vmcs_config.order);\n}\n\n/*\n * Free a VMCS, but before that VMCLEAR it on the CPU where it was last loaded\n */\nvoid free_loaded_vmcs(struct loaded_vmcs *loaded_vmcs)\n{\n\tif (!loaded_vmcs->vmcs)\n\t\treturn;\n\tloaded_vmcs_clear(loaded_vmcs);\n\tfree_vmcs(loaded_vmcs->vmcs);\n\tloaded_vmcs->vmcs = NULL;\n\tif (loaded_vmcs->msr_bitmap)\n\t\tfree_page((unsigned long)loaded_vmcs->msr_bitmap);\n\tWARN_ON(loaded_vmcs->shadow_vmcs != NULL);\n}\n\nint alloc_loaded_vmcs(struct loaded_vmcs *loaded_vmcs)\n{\n\tloaded_vmcs->vmcs = alloc_vmcs(false);\n\tif (!loaded_vmcs->vmcs)\n\t\treturn -ENOMEM;\n\n\tvmcs_clear(loaded_vmcs->vmcs);\n\n\tloaded_vmcs->shadow_vmcs = NULL;\n\tloaded_vmcs->hv_timer_soft_disabled = false;\n\tloaded_vmcs->cpu = -1;\n\tloaded_vmcs->launched = 0;\n\n\tif (cpu_has_vmx_msr_bitmap()) {\n\t\tloaded_vmcs->msr_bitmap = (unsigned long *)\n\t\t\t\t__get_free_page(GFP_KERNEL_ACCOUNT);\n\t\tif (!loaded_vmcs->msr_bitmap)\n\t\t\tgoto out_vmcs;\n\t\tmemset(loaded_vmcs->msr_bitmap, 0xff, PAGE_SIZE);\n\n\t\tif (IS_ENABLED(CONFIG_HYPERV) &&\n\t\t    static_branch_unlikely(&enable_evmcs) &&\n\t\t    (ms_hyperv.nested_features & HV_X64_NESTED_MSR_BITMAP)) {\n\t\t\tstruct hv_enlightened_vmcs *evmcs =\n\t\t\t\t(struct hv_enlightened_vmcs *)loaded_vmcs->vmcs;\n\n\t\t\tevmcs->hv_enlightenments_control.msr_bitmap = 1;\n\t\t}\n\t}\n\n\tmemset(&loaded_vmcs->host_state, 0, sizeof(struct vmcs_host_state));\n\tmemset(&loaded_vmcs->controls_shadow, 0,\n\t\tsizeof(struct vmcs_controls_shadow));\n\n\treturn 0;\n\nout_vmcs:\n\tfree_loaded_vmcs(loaded_vmcs);\n\treturn -ENOMEM;\n}\n\nstatic void free_kvm_area(void)\n{\n\tint cpu;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tfree_vmcs(per_cpu(vmxarea, cpu));\n\t\tper_cpu(vmxarea, cpu) = NULL;\n\t}\n}\n\nstatic __init int alloc_kvm_area(void)\n{\n\tint cpu;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tstruct vmcs *vmcs;\n\n\t\tvmcs = alloc_vmcs_cpu(false, cpu, GFP_KERNEL);\n\t\tif (!vmcs) {\n\t\t\tfree_kvm_area();\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\t/*\n\t\t * When eVMCS is enabled, alloc_vmcs_cpu() sets\n\t\t * vmcs->revision_id to KVM_EVMCS_VERSION instead of\n\t\t * revision_id reported by MSR_IA32_VMX_BASIC.\n\t\t *\n\t\t * However, even though not explicitly documented by\n\t\t * TLFS, VMXArea passed as VMXON argument should\n\t\t * still be marked with revision_id reported by\n\t\t * physical CPU.\n\t\t */\n\t\tif (static_branch_unlikely(&enable_evmcs))\n\t\t\tvmcs->hdr.revision_id = vmcs_config.revision_id;\n\n\t\tper_cpu(vmxarea, cpu) = vmcs;\n\t}\n\treturn 0;\n}\n\nstatic void fix_pmode_seg(struct kvm_vcpu *vcpu, int seg,\n\t\tstruct kvm_segment *save)\n{\n\tif (!emulate_invalid_guest_state) {\n\t\t/*\n\t\t * CS and SS RPL should be equal during guest entry according\n\t\t * to VMX spec, but in reality it is not always so. Since vcpu\n\t\t * is in the middle of the transition from real mode to\n\t\t * protected mode it is safe to assume that RPL 0 is a good\n\t\t * default value.\n\t\t */\n\t\tif (seg == VCPU_SREG_CS || seg == VCPU_SREG_SS)\n\t\t\tsave->selector &= ~SEGMENT_RPL_MASK;\n\t\tsave->dpl = save->selector & SEGMENT_RPL_MASK;\n\t\tsave->s = 1;\n\t}\n\tvmx_set_segment(vcpu, save, seg);\n}\n\nstatic void enter_pmode(struct kvm_vcpu *vcpu)\n{\n\tunsigned long flags;\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\t/*\n\t * Update real mode segment cache. It may be not up-to-date if sement\n\t * register was written while vcpu was in a guest mode.\n\t */\n\tvmx_get_segment(vcpu, &vmx->rmode.segs[VCPU_SREG_ES], VCPU_SREG_ES);\n\tvmx_get_segment(vcpu, &vmx->rmode.segs[VCPU_SREG_DS], VCPU_SREG_DS);\n\tvmx_get_segment(vcpu, &vmx->rmode.segs[VCPU_SREG_FS], VCPU_SREG_FS);\n\tvmx_get_segment(vcpu, &vmx->rmode.segs[VCPU_SREG_GS], VCPU_SREG_GS);\n\tvmx_get_segment(vcpu, &vmx->rmode.segs[VCPU_SREG_SS], VCPU_SREG_SS);\n\tvmx_get_segment(vcpu, &vmx->rmode.segs[VCPU_SREG_CS], VCPU_SREG_CS);\n\n\tvmx->rmode.vm86_active = 0;\n\n\tvmx_set_segment(vcpu, &vmx->rmode.segs[VCPU_SREG_TR], VCPU_SREG_TR);\n\n\tflags = vmcs_readl(GUEST_RFLAGS);\n\tflags &= RMODE_GUEST_OWNED_EFLAGS_BITS;\n\tflags |= vmx->rmode.save_rflags & ~RMODE_GUEST_OWNED_EFLAGS_BITS;\n\tvmcs_writel(GUEST_RFLAGS, flags);\n\n\tvmcs_writel(GUEST_CR4, (vmcs_readl(GUEST_CR4) & ~X86_CR4_VME) |\n\t\t\t(vmcs_readl(CR4_READ_SHADOW) & X86_CR4_VME));\n\n\tupdate_exception_bitmap(vcpu);\n\n\tfix_pmode_seg(vcpu, VCPU_SREG_CS, &vmx->rmode.segs[VCPU_SREG_CS]);\n\tfix_pmode_seg(vcpu, VCPU_SREG_SS, &vmx->rmode.segs[VCPU_SREG_SS]);\n\tfix_pmode_seg(vcpu, VCPU_SREG_ES, &vmx->rmode.segs[VCPU_SREG_ES]);\n\tfix_pmode_seg(vcpu, VCPU_SREG_DS, &vmx->rmode.segs[VCPU_SREG_DS]);\n\tfix_pmode_seg(vcpu, VCPU_SREG_FS, &vmx->rmode.segs[VCPU_SREG_FS]);\n\tfix_pmode_seg(vcpu, VCPU_SREG_GS, &vmx->rmode.segs[VCPU_SREG_GS]);\n}\n\nstatic void fix_rmode_seg(int seg, struct kvm_segment *save)\n{\n\tconst struct kvm_vmx_segment_field *sf = &kvm_vmx_segment_fields[seg];\n\tstruct kvm_segment var = *save;\n\n\tvar.dpl = 0x3;\n\tif (seg == VCPU_SREG_CS)\n\t\tvar.type = 0x3;\n\n\tif (!emulate_invalid_guest_state) {\n\t\tvar.selector = var.base >> 4;\n\t\tvar.base = var.base & 0xffff0;\n\t\tvar.limit = 0xffff;\n\t\tvar.g = 0;\n\t\tvar.db = 0;\n\t\tvar.present = 1;\n\t\tvar.s = 1;\n\t\tvar.l = 0;\n\t\tvar.unusable = 0;\n\t\tvar.type = 0x3;\n\t\tvar.avl = 0;\n\t\tif (save->base & 0xf)\n\t\t\tprintk_once(KERN_WARNING \"kvm: segment base is not \"\n\t\t\t\t\t\"paragraph aligned when entering \"\n\t\t\t\t\t\"protected mode (seg=%d)\", seg);\n\t}\n\n\tvmcs_write16(sf->selector, var.selector);\n\tvmcs_writel(sf->base, var.base);\n\tvmcs_write32(sf->limit, var.limit);\n\tvmcs_write32(sf->ar_bytes, vmx_segment_access_rights(&var));\n}\n\nstatic void enter_rmode(struct kvm_vcpu *vcpu)\n{\n\tunsigned long flags;\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tstruct kvm_vmx *kvm_vmx = to_kvm_vmx(vcpu->kvm);\n\n\tvmx_get_segment(vcpu, &vmx->rmode.segs[VCPU_SREG_TR], VCPU_SREG_TR);\n\tvmx_get_segment(vcpu, &vmx->rmode.segs[VCPU_SREG_ES], VCPU_SREG_ES);\n\tvmx_get_segment(vcpu, &vmx->rmode.segs[VCPU_SREG_DS], VCPU_SREG_DS);\n\tvmx_get_segment(vcpu, &vmx->rmode.segs[VCPU_SREG_FS], VCPU_SREG_FS);\n\tvmx_get_segment(vcpu, &vmx->rmode.segs[VCPU_SREG_GS], VCPU_SREG_GS);\n\tvmx_get_segment(vcpu, &vmx->rmode.segs[VCPU_SREG_SS], VCPU_SREG_SS);\n\tvmx_get_segment(vcpu, &vmx->rmode.segs[VCPU_SREG_CS], VCPU_SREG_CS);\n\n\tvmx->rmode.vm86_active = 1;\n\n\t/*\n\t * Very old userspace does not call KVM_SET_TSS_ADDR before entering\n\t * vcpu. Warn the user that an update is overdue.\n\t */\n\tif (!kvm_vmx->tss_addr)\n\t\tprintk_once(KERN_WARNING \"kvm: KVM_SET_TSS_ADDR need to be \"\n\t\t\t     \"called before entering vcpu\\n\");\n\n\tvmx_segment_cache_clear(vmx);\n\n\tvmcs_writel(GUEST_TR_BASE, kvm_vmx->tss_addr);\n\tvmcs_write32(GUEST_TR_LIMIT, RMODE_TSS_SIZE - 1);\n\tvmcs_write32(GUEST_TR_AR_BYTES, 0x008b);\n\n\tflags = vmcs_readl(GUEST_RFLAGS);\n\tvmx->rmode.save_rflags = flags;\n\n\tflags |= X86_EFLAGS_IOPL | X86_EFLAGS_VM;\n\n\tvmcs_writel(GUEST_RFLAGS, flags);\n\tvmcs_writel(GUEST_CR4, vmcs_readl(GUEST_CR4) | X86_CR4_VME);\n\tupdate_exception_bitmap(vcpu);\n\n\tfix_rmode_seg(VCPU_SREG_SS, &vmx->rmode.segs[VCPU_SREG_SS]);\n\tfix_rmode_seg(VCPU_SREG_CS, &vmx->rmode.segs[VCPU_SREG_CS]);\n\tfix_rmode_seg(VCPU_SREG_ES, &vmx->rmode.segs[VCPU_SREG_ES]);\n\tfix_rmode_seg(VCPU_SREG_DS, &vmx->rmode.segs[VCPU_SREG_DS]);\n\tfix_rmode_seg(VCPU_SREG_GS, &vmx->rmode.segs[VCPU_SREG_GS]);\n\tfix_rmode_seg(VCPU_SREG_FS, &vmx->rmode.segs[VCPU_SREG_FS]);\n\n\tkvm_mmu_reset_context(vcpu);\n}\n\nint vmx_set_efer(struct kvm_vcpu *vcpu, u64 efer)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tstruct vmx_uret_msr *msr = vmx_find_uret_msr(vmx, MSR_EFER);\n\n\t/* Nothing to do if hardware doesn't support EFER. */\n\tif (!msr)\n\t\treturn 0;\n\n\tvcpu->arch.efer = efer;\n\tif (efer & EFER_LMA) {\n\t\tvm_entry_controls_setbit(to_vmx(vcpu), VM_ENTRY_IA32E_MODE);\n\t\tmsr->data = efer;\n\t} else {\n\t\tvm_entry_controls_clearbit(to_vmx(vcpu), VM_ENTRY_IA32E_MODE);\n\n\t\tmsr->data = efer & ~EFER_LME;\n\t}\n\tsetup_msrs(vmx);\n\treturn 0;\n}\n\n#ifdef CONFIG_X86_64\n\nstatic void enter_lmode(struct kvm_vcpu *vcpu)\n{\n\tu32 guest_tr_ar;\n\n\tvmx_segment_cache_clear(to_vmx(vcpu));\n\n\tguest_tr_ar = vmcs_read32(GUEST_TR_AR_BYTES);\n\tif ((guest_tr_ar & VMX_AR_TYPE_MASK) != VMX_AR_TYPE_BUSY_64_TSS) {\n\t\tpr_debug_ratelimited(\"%s: tss fixup for long mode. \\n\",\n\t\t\t\t     __func__);\n\t\tvmcs_write32(GUEST_TR_AR_BYTES,\n\t\t\t     (guest_tr_ar & ~VMX_AR_TYPE_MASK)\n\t\t\t     | VMX_AR_TYPE_BUSY_64_TSS);\n\t}\n\tvmx_set_efer(vcpu, vcpu->arch.efer | EFER_LMA);\n}\n\nstatic void exit_lmode(struct kvm_vcpu *vcpu)\n{\n\tvm_entry_controls_clearbit(to_vmx(vcpu), VM_ENTRY_IA32E_MODE);\n\tvmx_set_efer(vcpu, vcpu->arch.efer & ~EFER_LMA);\n}\n\n#endif\n\nstatic void vmx_flush_tlb_all(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\t/*\n\t * INVEPT must be issued when EPT is enabled, irrespective of VPID, as\n\t * the CPU is not required to invalidate guest-physical mappings on\n\t * VM-Entry, even if VPID is disabled.  Guest-physical mappings are\n\t * associated with the root EPT structure and not any particular VPID\n\t * (INVVPID also isn't required to invalidate guest-physical mappings).\n\t */\n\tif (enable_ept) {\n\t\tept_sync_global();\n\t} else if (enable_vpid) {\n\t\tif (cpu_has_vmx_invvpid_global()) {\n\t\t\tvpid_sync_vcpu_global();\n\t\t} else {\n\t\t\tvpid_sync_vcpu_single(vmx->vpid);\n\t\t\tvpid_sync_vcpu_single(vmx->nested.vpid02);\n\t\t}\n\t}\n}\n\nstatic void vmx_flush_tlb_current(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_mmu *mmu = vcpu->arch.mmu;\n\tu64 root_hpa = mmu->root_hpa;\n\n\t/* No flush required if the current context is invalid. */\n\tif (!VALID_PAGE(root_hpa))\n\t\treturn;\n\n\tif (enable_ept)\n\t\tept_sync_context(construct_eptp(vcpu, root_hpa,\n\t\t\t\t\t\tmmu->shadow_root_level));\n\telse if (!is_guest_mode(vcpu))\n\t\tvpid_sync_context(to_vmx(vcpu)->vpid);\n\telse\n\t\tvpid_sync_context(nested_get_vpid02(vcpu));\n}\n\nstatic void vmx_flush_tlb_gva(struct kvm_vcpu *vcpu, gva_t addr)\n{\n\t/*\n\t * vpid_sync_vcpu_addr() is a nop if vmx->vpid==0, see the comment in\n\t * vmx_flush_tlb_guest() for an explanation of why this is ok.\n\t */\n\tvpid_sync_vcpu_addr(to_vmx(vcpu)->vpid, addr);\n}\n\nstatic void vmx_flush_tlb_guest(struct kvm_vcpu *vcpu)\n{\n\t/*\n\t * vpid_sync_context() is a nop if vmx->vpid==0, e.g. if enable_vpid==0\n\t * or a vpid couldn't be allocated for this vCPU.  VM-Enter and VM-Exit\n\t * are required to flush GVA->{G,H}PA mappings from the TLB if vpid is\n\t * disabled (VM-Enter with vpid enabled and vpid==0 is disallowed),\n\t * i.e. no explicit INVVPID is necessary.\n\t */\n\tvpid_sync_context(to_vmx(vcpu)->vpid);\n}\n\nvoid vmx_ept_load_pdptrs(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_mmu *mmu = vcpu->arch.walk_mmu;\n\n\tif (!kvm_register_is_dirty(vcpu, VCPU_EXREG_PDPTR))\n\t\treturn;\n\n\tif (is_pae_paging(vcpu)) {\n\t\tvmcs_write64(GUEST_PDPTR0, mmu->pdptrs[0]);\n\t\tvmcs_write64(GUEST_PDPTR1, mmu->pdptrs[1]);\n\t\tvmcs_write64(GUEST_PDPTR2, mmu->pdptrs[2]);\n\t\tvmcs_write64(GUEST_PDPTR3, mmu->pdptrs[3]);\n\t}\n}\n\nvoid ept_save_pdptrs(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_mmu *mmu = vcpu->arch.walk_mmu;\n\n\tif (WARN_ON_ONCE(!is_pae_paging(vcpu)))\n\t\treturn;\n\n\tmmu->pdptrs[0] = vmcs_read64(GUEST_PDPTR0);\n\tmmu->pdptrs[1] = vmcs_read64(GUEST_PDPTR1);\n\tmmu->pdptrs[2] = vmcs_read64(GUEST_PDPTR2);\n\tmmu->pdptrs[3] = vmcs_read64(GUEST_PDPTR3);\n\n\tkvm_register_mark_dirty(vcpu, VCPU_EXREG_PDPTR);\n}\n\nstatic void ept_update_paging_mode_cr0(unsigned long *hw_cr0,\n\t\t\t\t\tunsigned long cr0,\n\t\t\t\t\tstruct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\tif (!kvm_register_is_available(vcpu, VCPU_EXREG_CR3))\n\t\tvmx_cache_reg(vcpu, VCPU_EXREG_CR3);\n\tif (!(cr0 & X86_CR0_PG)) {\n\t\t/* From paging/starting to nonpaging */\n\t\texec_controls_setbit(vmx, CPU_BASED_CR3_LOAD_EXITING |\n\t\t\t\t\t  CPU_BASED_CR3_STORE_EXITING);\n\t\tvcpu->arch.cr0 = cr0;\n\t\tvmx_set_cr4(vcpu, kvm_read_cr4(vcpu));\n\t} else if (!is_paging(vcpu)) {\n\t\t/* From nonpaging to paging */\n\t\texec_controls_clearbit(vmx, CPU_BASED_CR3_LOAD_EXITING |\n\t\t\t\t\t    CPU_BASED_CR3_STORE_EXITING);\n\t\tvcpu->arch.cr0 = cr0;\n\t\tvmx_set_cr4(vcpu, kvm_read_cr4(vcpu));\n\t}\n\n\tif (!(cr0 & X86_CR0_WP))\n\t\t*hw_cr0 &= ~X86_CR0_WP;\n}\n\nvoid vmx_set_cr0(struct kvm_vcpu *vcpu, unsigned long cr0)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tunsigned long hw_cr0;\n\n\thw_cr0 = (cr0 & ~KVM_VM_CR0_ALWAYS_OFF);\n\tif (is_unrestricted_guest(vcpu))\n\t\thw_cr0 |= KVM_VM_CR0_ALWAYS_ON_UNRESTRICTED_GUEST;\n\telse {\n\t\thw_cr0 |= KVM_VM_CR0_ALWAYS_ON;\n\n\t\tif (vmx->rmode.vm86_active && (cr0 & X86_CR0_PE))\n\t\t\tenter_pmode(vcpu);\n\n\t\tif (!vmx->rmode.vm86_active && !(cr0 & X86_CR0_PE))\n\t\t\tenter_rmode(vcpu);\n\t}\n\n#ifdef CONFIG_X86_64\n\tif (vcpu->arch.efer & EFER_LME) {\n\t\tif (!is_paging(vcpu) && (cr0 & X86_CR0_PG))\n\t\t\tenter_lmode(vcpu);\n\t\tif (is_paging(vcpu) && !(cr0 & X86_CR0_PG))\n\t\t\texit_lmode(vcpu);\n\t}\n#endif\n\n\tif (enable_ept && !is_unrestricted_guest(vcpu))\n\t\tept_update_paging_mode_cr0(&hw_cr0, cr0, vcpu);\n\n\tvmcs_writel(CR0_READ_SHADOW, cr0);\n\tvmcs_writel(GUEST_CR0, hw_cr0);\n\tvcpu->arch.cr0 = cr0;\n\tkvm_register_mark_available(vcpu, VCPU_EXREG_CR0);\n\n\t/* depends on vcpu->arch.cr0 to be set to a new value */\n\tvmx->emulation_required = emulation_required(vcpu);\n}\n\nstatic int vmx_get_max_tdp_level(void)\n{\n\tif (cpu_has_vmx_ept_5levels())\n\t\treturn 5;\n\treturn 4;\n}\n\nu64 construct_eptp(struct kvm_vcpu *vcpu, unsigned long root_hpa,\n\t\t   int root_level)\n{\n\tu64 eptp = VMX_EPTP_MT_WB;\n\n\teptp |= (root_level == 5) ? VMX_EPTP_PWL_5 : VMX_EPTP_PWL_4;\n\n\tif (enable_ept_ad_bits &&\n\t    (!is_guest_mode(vcpu) || nested_ept_ad_enabled(vcpu)))\n\t\teptp |= VMX_EPTP_AD_ENABLE_BIT;\n\teptp |= (root_hpa & PAGE_MASK);\n\n\treturn eptp;\n}\n\nstatic void vmx_load_mmu_pgd(struct kvm_vcpu *vcpu, unsigned long pgd,\n\t\t\t     int pgd_level)\n{\n\tstruct kvm *kvm = vcpu->kvm;\n\tbool update_guest_cr3 = true;\n\tunsigned long guest_cr3;\n\tu64 eptp;\n\n\tif (enable_ept) {\n\t\teptp = construct_eptp(vcpu, pgd, pgd_level);\n\t\tvmcs_write64(EPT_POINTER, eptp);\n\n\t\tif (kvm_x86_ops.tlb_remote_flush) {\n\t\t\tspin_lock(&to_kvm_vmx(kvm)->ept_pointer_lock);\n\t\t\tto_vmx(vcpu)->ept_pointer = eptp;\n\t\t\tto_kvm_vmx(kvm)->ept_pointers_match\n\t\t\t\t= EPT_POINTERS_CHECK;\n\t\t\tspin_unlock(&to_kvm_vmx(kvm)->ept_pointer_lock);\n\t\t}\n\n\t\tif (!enable_unrestricted_guest && !is_paging(vcpu))\n\t\t\tguest_cr3 = to_kvm_vmx(kvm)->ept_identity_map_addr;\n\t\telse if (test_bit(VCPU_EXREG_CR3, (ulong *)&vcpu->arch.regs_avail))\n\t\t\tguest_cr3 = vcpu->arch.cr3;\n\t\telse /* vmcs01.GUEST_CR3 is already up-to-date. */\n\t\t\tupdate_guest_cr3 = false;\n\t\tvmx_ept_load_pdptrs(vcpu);\n\t} else {\n\t\tguest_cr3 = pgd;\n\t}\n\n\tif (update_guest_cr3)\n\t\tvmcs_writel(GUEST_CR3, guest_cr3);\n}\n\nint vmx_set_cr4(struct kvm_vcpu *vcpu, unsigned long cr4)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\t/*\n\t * Pass through host's Machine Check Enable value to hw_cr4, which\n\t * is in force while we are in guest mode.  Do not let guests control\n\t * this bit, even if host CR4.MCE == 0.\n\t */\n\tunsigned long hw_cr4;\n\n\thw_cr4 = (cr4_read_shadow() & X86_CR4_MCE) | (cr4 & ~X86_CR4_MCE);\n\tif (is_unrestricted_guest(vcpu))\n\t\thw_cr4 |= KVM_VM_CR4_ALWAYS_ON_UNRESTRICTED_GUEST;\n\telse if (vmx->rmode.vm86_active)\n\t\thw_cr4 |= KVM_RMODE_VM_CR4_ALWAYS_ON;\n\telse\n\t\thw_cr4 |= KVM_PMODE_VM_CR4_ALWAYS_ON;\n\n\tif (!boot_cpu_has(X86_FEATURE_UMIP) && vmx_umip_emulated()) {\n\t\tif (cr4 & X86_CR4_UMIP) {\n\t\t\tsecondary_exec_controls_setbit(vmx, SECONDARY_EXEC_DESC);\n\t\t\thw_cr4 &= ~X86_CR4_UMIP;\n\t\t} else if (!is_guest_mode(vcpu) ||\n\t\t\t!nested_cpu_has2(get_vmcs12(vcpu), SECONDARY_EXEC_DESC)) {\n\t\t\tsecondary_exec_controls_clearbit(vmx, SECONDARY_EXEC_DESC);\n\t\t}\n\t}\n\n\tif (cr4 & X86_CR4_VMXE) {\n\t\t/*\n\t\t * To use VMXON (and later other VMX instructions), a guest\n\t\t * must first be able to turn on cr4.VMXE (see handle_vmon()).\n\t\t * So basically the check on whether to allow nested VMX\n\t\t * is here.  We operate under the default treatment of SMM,\n\t\t * so VMX cannot be enabled under SMM.\n\t\t */\n\t\tif (!nested_vmx_allowed(vcpu) || is_smm(vcpu))\n\t\t\treturn 1;\n\t}\n\n\tif (vmx->nested.vmxon && !nested_cr4_valid(vcpu, cr4))\n\t\treturn 1;\n\n\tvcpu->arch.cr4 = cr4;\n\tkvm_register_mark_available(vcpu, VCPU_EXREG_CR4);\n\n\tif (!is_unrestricted_guest(vcpu)) {\n\t\tif (enable_ept) {\n\t\t\tif (!is_paging(vcpu)) {\n\t\t\t\thw_cr4 &= ~X86_CR4_PAE;\n\t\t\t\thw_cr4 |= X86_CR4_PSE;\n\t\t\t} else if (!(cr4 & X86_CR4_PAE)) {\n\t\t\t\thw_cr4 &= ~X86_CR4_PAE;\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t * SMEP/SMAP/PKU is disabled if CPU is in non-paging mode in\n\t\t * hardware.  To emulate this behavior, SMEP/SMAP/PKU needs\n\t\t * to be manually disabled when guest switches to non-paging\n\t\t * mode.\n\t\t *\n\t\t * If !enable_unrestricted_guest, the CPU is always running\n\t\t * with CR0.PG=1 and CR4 needs to be modified.\n\t\t * If enable_unrestricted_guest, the CPU automatically\n\t\t * disables SMEP/SMAP/PKU when the guest sets CR0.PG=0.\n\t\t */\n\t\tif (!is_paging(vcpu))\n\t\t\thw_cr4 &= ~(X86_CR4_SMEP | X86_CR4_SMAP | X86_CR4_PKE);\n\t}\n\n\tvmcs_writel(CR4_READ_SHADOW, cr4);\n\tvmcs_writel(GUEST_CR4, hw_cr4);\n\treturn 0;\n}\n\nvoid vmx_get_segment(struct kvm_vcpu *vcpu, struct kvm_segment *var, int seg)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tu32 ar;\n\n\tif (vmx->rmode.vm86_active && seg != VCPU_SREG_LDTR) {\n\t\t*var = vmx->rmode.segs[seg];\n\t\tif (seg == VCPU_SREG_TR\n\t\t    || var->selector == vmx_read_guest_seg_selector(vmx, seg))\n\t\t\treturn;\n\t\tvar->base = vmx_read_guest_seg_base(vmx, seg);\n\t\tvar->selector = vmx_read_guest_seg_selector(vmx, seg);\n\t\treturn;\n\t}\n\tvar->base = vmx_read_guest_seg_base(vmx, seg);\n\tvar->limit = vmx_read_guest_seg_limit(vmx, seg);\n\tvar->selector = vmx_read_guest_seg_selector(vmx, seg);\n\tar = vmx_read_guest_seg_ar(vmx, seg);\n\tvar->unusable = (ar >> 16) & 1;\n\tvar->type = ar & 15;\n\tvar->s = (ar >> 4) & 1;\n\tvar->dpl = (ar >> 5) & 3;\n\t/*\n\t * Some userspaces do not preserve unusable property. Since usable\n\t * segment has to be present according to VMX spec we can use present\n\t * property to amend userspace bug by making unusable segment always\n\t * nonpresent. vmx_segment_access_rights() already marks nonpresent\n\t * segment as unusable.\n\t */\n\tvar->present = !var->unusable;\n\tvar->avl = (ar >> 12) & 1;\n\tvar->l = (ar >> 13) & 1;\n\tvar->db = (ar >> 14) & 1;\n\tvar->g = (ar >> 15) & 1;\n}\n\nstatic u64 vmx_get_segment_base(struct kvm_vcpu *vcpu, int seg)\n{\n\tstruct kvm_segment s;\n\n\tif (to_vmx(vcpu)->rmode.vm86_active) {\n\t\tvmx_get_segment(vcpu, &s, seg);\n\t\treturn s.base;\n\t}\n\treturn vmx_read_guest_seg_base(to_vmx(vcpu), seg);\n}\n\nint vmx_get_cpl(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\tif (unlikely(vmx->rmode.vm86_active))\n\t\treturn 0;\n\telse {\n\t\tint ar = vmx_read_guest_seg_ar(vmx, VCPU_SREG_SS);\n\t\treturn VMX_AR_DPL(ar);\n\t}\n}\n\nstatic u32 vmx_segment_access_rights(struct kvm_segment *var)\n{\n\tu32 ar;\n\n\tif (var->unusable || !var->present)\n\t\tar = 1 << 16;\n\telse {\n\t\tar = var->type & 15;\n\t\tar |= (var->s & 1) << 4;\n\t\tar |= (var->dpl & 3) << 5;\n\t\tar |= (var->present & 1) << 7;\n\t\tar |= (var->avl & 1) << 12;\n\t\tar |= (var->l & 1) << 13;\n\t\tar |= (var->db & 1) << 14;\n\t\tar |= (var->g & 1) << 15;\n\t}\n\n\treturn ar;\n}\n\nvoid vmx_set_segment(struct kvm_vcpu *vcpu, struct kvm_segment *var, int seg)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tconst struct kvm_vmx_segment_field *sf = &kvm_vmx_segment_fields[seg];\n\n\tvmx_segment_cache_clear(vmx);\n\n\tif (vmx->rmode.vm86_active && seg != VCPU_SREG_LDTR) {\n\t\tvmx->rmode.segs[seg] = *var;\n\t\tif (seg == VCPU_SREG_TR)\n\t\t\tvmcs_write16(sf->selector, var->selector);\n\t\telse if (var->s)\n\t\t\tfix_rmode_seg(seg, &vmx->rmode.segs[seg]);\n\t\tgoto out;\n\t}\n\n\tvmcs_writel(sf->base, var->base);\n\tvmcs_write32(sf->limit, var->limit);\n\tvmcs_write16(sf->selector, var->selector);\n\n\t/*\n\t *   Fix the \"Accessed\" bit in AR field of segment registers for older\n\t * qemu binaries.\n\t *   IA32 arch specifies that at the time of processor reset the\n\t * \"Accessed\" bit in the AR field of segment registers is 1. And qemu\n\t * is setting it to 0 in the userland code. This causes invalid guest\n\t * state vmexit when \"unrestricted guest\" mode is turned on.\n\t *    Fix for this setup issue in cpu_reset is being pushed in the qemu\n\t * tree. Newer qemu binaries with that qemu fix would not need this\n\t * kvm hack.\n\t */\n\tif (is_unrestricted_guest(vcpu) && (seg != VCPU_SREG_LDTR))\n\t\tvar->type |= 0x1; /* Accessed */\n\n\tvmcs_write32(sf->ar_bytes, vmx_segment_access_rights(var));\n\nout:\n\tvmx->emulation_required = emulation_required(vcpu);\n}\n\nstatic void vmx_get_cs_db_l_bits(struct kvm_vcpu *vcpu, int *db, int *l)\n{\n\tu32 ar = vmx_read_guest_seg_ar(to_vmx(vcpu), VCPU_SREG_CS);\n\n\t*db = (ar >> 14) & 1;\n\t*l = (ar >> 13) & 1;\n}\n\nstatic void vmx_get_idt(struct kvm_vcpu *vcpu, struct desc_ptr *dt)\n{\n\tdt->size = vmcs_read32(GUEST_IDTR_LIMIT);\n\tdt->address = vmcs_readl(GUEST_IDTR_BASE);\n}\n\nstatic void vmx_set_idt(struct kvm_vcpu *vcpu, struct desc_ptr *dt)\n{\n\tvmcs_write32(GUEST_IDTR_LIMIT, dt->size);\n\tvmcs_writel(GUEST_IDTR_BASE, dt->address);\n}\n\nstatic void vmx_get_gdt(struct kvm_vcpu *vcpu, struct desc_ptr *dt)\n{\n\tdt->size = vmcs_read32(GUEST_GDTR_LIMIT);\n\tdt->address = vmcs_readl(GUEST_GDTR_BASE);\n}\n\nstatic void vmx_set_gdt(struct kvm_vcpu *vcpu, struct desc_ptr *dt)\n{\n\tvmcs_write32(GUEST_GDTR_LIMIT, dt->size);\n\tvmcs_writel(GUEST_GDTR_BASE, dt->address);\n}\n\nstatic bool rmode_segment_valid(struct kvm_vcpu *vcpu, int seg)\n{\n\tstruct kvm_segment var;\n\tu32 ar;\n\n\tvmx_get_segment(vcpu, &var, seg);\n\tvar.dpl = 0x3;\n\tif (seg == VCPU_SREG_CS)\n\t\tvar.type = 0x3;\n\tar = vmx_segment_access_rights(&var);\n\n\tif (var.base != (var.selector << 4))\n\t\treturn false;\n\tif (var.limit != 0xffff)\n\t\treturn false;\n\tif (ar != 0xf3)\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic bool code_segment_valid(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_segment cs;\n\tunsigned int cs_rpl;\n\n\tvmx_get_segment(vcpu, &cs, VCPU_SREG_CS);\n\tcs_rpl = cs.selector & SEGMENT_RPL_MASK;\n\n\tif (cs.unusable)\n\t\treturn false;\n\tif (~cs.type & (VMX_AR_TYPE_CODE_MASK|VMX_AR_TYPE_ACCESSES_MASK))\n\t\treturn false;\n\tif (!cs.s)\n\t\treturn false;\n\tif (cs.type & VMX_AR_TYPE_WRITEABLE_MASK) {\n\t\tif (cs.dpl > cs_rpl)\n\t\t\treturn false;\n\t} else {\n\t\tif (cs.dpl != cs_rpl)\n\t\t\treturn false;\n\t}\n\tif (!cs.present)\n\t\treturn false;\n\n\t/* TODO: Add Reserved field check, this'll require a new member in the kvm_segment_field structure */\n\treturn true;\n}\n\nstatic bool stack_segment_valid(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_segment ss;\n\tunsigned int ss_rpl;\n\n\tvmx_get_segment(vcpu, &ss, VCPU_SREG_SS);\n\tss_rpl = ss.selector & SEGMENT_RPL_MASK;\n\n\tif (ss.unusable)\n\t\treturn true;\n\tif (ss.type != 3 && ss.type != 7)\n\t\treturn false;\n\tif (!ss.s)\n\t\treturn false;\n\tif (ss.dpl != ss_rpl) /* DPL != RPL */\n\t\treturn false;\n\tif (!ss.present)\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic bool data_segment_valid(struct kvm_vcpu *vcpu, int seg)\n{\n\tstruct kvm_segment var;\n\tunsigned int rpl;\n\n\tvmx_get_segment(vcpu, &var, seg);\n\trpl = var.selector & SEGMENT_RPL_MASK;\n\n\tif (var.unusable)\n\t\treturn true;\n\tif (!var.s)\n\t\treturn false;\n\tif (!var.present)\n\t\treturn false;\n\tif (~var.type & (VMX_AR_TYPE_CODE_MASK|VMX_AR_TYPE_WRITEABLE_MASK)) {\n\t\tif (var.dpl < rpl) /* DPL < RPL */\n\t\t\treturn false;\n\t}\n\n\t/* TODO: Add other members to kvm_segment_field to allow checking for other access\n\t * rights flags\n\t */\n\treturn true;\n}\n\nstatic bool tr_valid(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_segment tr;\n\n\tvmx_get_segment(vcpu, &tr, VCPU_SREG_TR);\n\n\tif (tr.unusable)\n\t\treturn false;\n\tif (tr.selector & SEGMENT_TI_MASK)\t/* TI = 1 */\n\t\treturn false;\n\tif (tr.type != 3 && tr.type != 11) /* TODO: Check if guest is in IA32e mode */\n\t\treturn false;\n\tif (!tr.present)\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic bool ldtr_valid(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_segment ldtr;\n\n\tvmx_get_segment(vcpu, &ldtr, VCPU_SREG_LDTR);\n\n\tif (ldtr.unusable)\n\t\treturn true;\n\tif (ldtr.selector & SEGMENT_TI_MASK)\t/* TI = 1 */\n\t\treturn false;\n\tif (ldtr.type != 2)\n\t\treturn false;\n\tif (!ldtr.present)\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic bool cs_ss_rpl_check(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_segment cs, ss;\n\n\tvmx_get_segment(vcpu, &cs, VCPU_SREG_CS);\n\tvmx_get_segment(vcpu, &ss, VCPU_SREG_SS);\n\n\treturn ((cs.selector & SEGMENT_RPL_MASK) ==\n\t\t (ss.selector & SEGMENT_RPL_MASK));\n}\n\n/*\n * Check if guest state is valid. Returns true if valid, false if\n * not.\n * We assume that registers are always usable\n */\nbool __vmx_guest_state_valid(struct kvm_vcpu *vcpu)\n{\n\t/* real mode guest state checks */\n\tif (!is_protmode(vcpu) || (vmx_get_rflags(vcpu) & X86_EFLAGS_VM)) {\n\t\tif (!rmode_segment_valid(vcpu, VCPU_SREG_CS))\n\t\t\treturn false;\n\t\tif (!rmode_segment_valid(vcpu, VCPU_SREG_SS))\n\t\t\treturn false;\n\t\tif (!rmode_segment_valid(vcpu, VCPU_SREG_DS))\n\t\t\treturn false;\n\t\tif (!rmode_segment_valid(vcpu, VCPU_SREG_ES))\n\t\t\treturn false;\n\t\tif (!rmode_segment_valid(vcpu, VCPU_SREG_FS))\n\t\t\treturn false;\n\t\tif (!rmode_segment_valid(vcpu, VCPU_SREG_GS))\n\t\t\treturn false;\n\t} else {\n\t/* protected mode guest state checks */\n\t\tif (!cs_ss_rpl_check(vcpu))\n\t\t\treturn false;\n\t\tif (!code_segment_valid(vcpu))\n\t\t\treturn false;\n\t\tif (!stack_segment_valid(vcpu))\n\t\t\treturn false;\n\t\tif (!data_segment_valid(vcpu, VCPU_SREG_DS))\n\t\t\treturn false;\n\t\tif (!data_segment_valid(vcpu, VCPU_SREG_ES))\n\t\t\treturn false;\n\t\tif (!data_segment_valid(vcpu, VCPU_SREG_FS))\n\t\t\treturn false;\n\t\tif (!data_segment_valid(vcpu, VCPU_SREG_GS))\n\t\t\treturn false;\n\t\tif (!tr_valid(vcpu))\n\t\t\treturn false;\n\t\tif (!ldtr_valid(vcpu))\n\t\t\treturn false;\n\t}\n\t/* TODO:\n\t * - Add checks on RIP\n\t * - Add checks on RFLAGS\n\t */\n\n\treturn true;\n}\n\nstatic int init_rmode_tss(struct kvm *kvm)\n{\n\tgfn_t fn;\n\tu16 data = 0;\n\tint idx, r;\n\n\tidx = srcu_read_lock(&kvm->srcu);\n\tfn = to_kvm_vmx(kvm)->tss_addr >> PAGE_SHIFT;\n\tr = kvm_clear_guest_page(kvm, fn, 0, PAGE_SIZE);\n\tif (r < 0)\n\t\tgoto out;\n\tdata = TSS_BASE_SIZE + TSS_REDIRECTION_SIZE;\n\tr = kvm_write_guest_page(kvm, fn++, &data,\n\t\t\tTSS_IOPB_BASE_OFFSET, sizeof(u16));\n\tif (r < 0)\n\t\tgoto out;\n\tr = kvm_clear_guest_page(kvm, fn++, 0, PAGE_SIZE);\n\tif (r < 0)\n\t\tgoto out;\n\tr = kvm_clear_guest_page(kvm, fn, 0, PAGE_SIZE);\n\tif (r < 0)\n\t\tgoto out;\n\tdata = ~0;\n\tr = kvm_write_guest_page(kvm, fn, &data,\n\t\t\t\t RMODE_TSS_SIZE - 2 * PAGE_SIZE - 1,\n\t\t\t\t sizeof(u8));\nout:\n\tsrcu_read_unlock(&kvm->srcu, idx);\n\treturn r;\n}\n\nstatic int init_rmode_identity_map(struct kvm *kvm)\n{\n\tstruct kvm_vmx *kvm_vmx = to_kvm_vmx(kvm);\n\tint i, r = 0;\n\tkvm_pfn_t identity_map_pfn;\n\tu32 tmp;\n\n\t/* Protect kvm_vmx->ept_identity_pagetable_done. */\n\tmutex_lock(&kvm->slots_lock);\n\n\tif (likely(kvm_vmx->ept_identity_pagetable_done))\n\t\tgoto out;\n\n\tif (!kvm_vmx->ept_identity_map_addr)\n\t\tkvm_vmx->ept_identity_map_addr = VMX_EPT_IDENTITY_PAGETABLE_ADDR;\n\tidentity_map_pfn = kvm_vmx->ept_identity_map_addr >> PAGE_SHIFT;\n\n\tr = __x86_set_memory_region(kvm, IDENTITY_PAGETABLE_PRIVATE_MEMSLOT,\n\t\t\t\t    kvm_vmx->ept_identity_map_addr, PAGE_SIZE);\n\tif (r < 0)\n\t\tgoto out;\n\n\tr = kvm_clear_guest_page(kvm, identity_map_pfn, 0, PAGE_SIZE);\n\tif (r < 0)\n\t\tgoto out;\n\t/* Set up identity-mapping pagetable for EPT in real mode */\n\tfor (i = 0; i < PT32_ENT_PER_PAGE; i++) {\n\t\ttmp = (i << 22) + (_PAGE_PRESENT | _PAGE_RW | _PAGE_USER |\n\t\t\t_PAGE_ACCESSED | _PAGE_DIRTY | _PAGE_PSE);\n\t\tr = kvm_write_guest_page(kvm, identity_map_pfn,\n\t\t\t\t&tmp, i * sizeof(tmp), sizeof(tmp));\n\t\tif (r < 0)\n\t\t\tgoto out;\n\t}\n\tkvm_vmx->ept_identity_pagetable_done = true;\n\nout:\n\tmutex_unlock(&kvm->slots_lock);\n\treturn r;\n}\n\nstatic void seg_setup(int seg)\n{\n\tconst struct kvm_vmx_segment_field *sf = &kvm_vmx_segment_fields[seg];\n\tunsigned int ar;\n\n\tvmcs_write16(sf->selector, 0);\n\tvmcs_writel(sf->base, 0);\n\tvmcs_write32(sf->limit, 0xffff);\n\tar = 0x93;\n\tif (seg == VCPU_SREG_CS)\n\t\tar |= 0x08; /* code segment */\n\n\tvmcs_write32(sf->ar_bytes, ar);\n}\n\nstatic int alloc_apic_access_page(struct kvm *kvm)\n{\n\tstruct page *page;\n\tint r = 0;\n\n\tmutex_lock(&kvm->slots_lock);\n\tif (kvm->arch.apic_access_page_done)\n\t\tgoto out;\n\tr = __x86_set_memory_region(kvm, APIC_ACCESS_PAGE_PRIVATE_MEMSLOT,\n\t\t\t\t    APIC_DEFAULT_PHYS_BASE, PAGE_SIZE);\n\tif (r)\n\t\tgoto out;\n\n\tpage = gfn_to_page(kvm, APIC_DEFAULT_PHYS_BASE >> PAGE_SHIFT);\n\tif (is_error_page(page)) {\n\t\tr = -EFAULT;\n\t\tgoto out;\n\t}\n\n\t/*\n\t * Do not pin the page in memory, so that memory hot-unplug\n\t * is able to migrate it.\n\t */\n\tput_page(page);\n\tkvm->arch.apic_access_page_done = true;\nout:\n\tmutex_unlock(&kvm->slots_lock);\n\treturn r;\n}\n\nint allocate_vpid(void)\n{\n\tint vpid;\n\n\tif (!enable_vpid)\n\t\treturn 0;\n\tspin_lock(&vmx_vpid_lock);\n\tvpid = find_first_zero_bit(vmx_vpid_bitmap, VMX_NR_VPIDS);\n\tif (vpid < VMX_NR_VPIDS)\n\t\t__set_bit(vpid, vmx_vpid_bitmap);\n\telse\n\t\tvpid = 0;\n\tspin_unlock(&vmx_vpid_lock);\n\treturn vpid;\n}\n\nvoid free_vpid(int vpid)\n{\n\tif (!enable_vpid || vpid == 0)\n\t\treturn;\n\tspin_lock(&vmx_vpid_lock);\n\t__clear_bit(vpid, vmx_vpid_bitmap);\n\tspin_unlock(&vmx_vpid_lock);\n}\n\nstatic void vmx_clear_msr_bitmap_read(ulong *msr_bitmap, u32 msr)\n{\n\tint f = sizeof(unsigned long);\n\n\tif (msr <= 0x1fff)\n\t\t__clear_bit(msr, msr_bitmap + 0x000 / f);\n\telse if ((msr >= 0xc0000000) && (msr <= 0xc0001fff))\n\t\t__clear_bit(msr & 0x1fff, msr_bitmap + 0x400 / f);\n}\n\nstatic void vmx_clear_msr_bitmap_write(ulong *msr_bitmap, u32 msr)\n{\n\tint f = sizeof(unsigned long);\n\n\tif (msr <= 0x1fff)\n\t\t__clear_bit(msr, msr_bitmap + 0x800 / f);\n\telse if ((msr >= 0xc0000000) && (msr <= 0xc0001fff))\n\t\t__clear_bit(msr & 0x1fff, msr_bitmap + 0xc00 / f);\n}\n\nstatic void vmx_set_msr_bitmap_read(ulong *msr_bitmap, u32 msr)\n{\n\tint f = sizeof(unsigned long);\n\n\tif (msr <= 0x1fff)\n\t\t__set_bit(msr, msr_bitmap + 0x000 / f);\n\telse if ((msr >= 0xc0000000) && (msr <= 0xc0001fff))\n\t\t__set_bit(msr & 0x1fff, msr_bitmap + 0x400 / f);\n}\n\nstatic void vmx_set_msr_bitmap_write(ulong *msr_bitmap, u32 msr)\n{\n\tint f = sizeof(unsigned long);\n\n\tif (msr <= 0x1fff)\n\t\t__set_bit(msr, msr_bitmap + 0x800 / f);\n\telse if ((msr >= 0xc0000000) && (msr <= 0xc0001fff))\n\t\t__set_bit(msr & 0x1fff, msr_bitmap + 0xc00 / f);\n}\n\nstatic __always_inline void vmx_disable_intercept_for_msr(struct kvm_vcpu *vcpu,\n\t\t\t\t\t\t\t  u32 msr, int type)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tunsigned long *msr_bitmap = vmx->vmcs01.msr_bitmap;\n\n\tif (!cpu_has_vmx_msr_bitmap())\n\t\treturn;\n\n\tif (static_branch_unlikely(&enable_evmcs))\n\t\tevmcs_touch_msr_bitmap();\n\n\t/*\n\t * Mark the desired intercept state in shadow bitmap, this is needed\n\t * for resync when the MSR filters change.\n\t*/\n\tif (is_valid_passthrough_msr(msr)) {\n\t\tint idx = possible_passthrough_msr_slot(msr);\n\n\t\tif (idx != -ENOENT) {\n\t\t\tif (type & MSR_TYPE_R)\n\t\t\t\tclear_bit(idx, vmx->shadow_msr_intercept.read);\n\t\t\tif (type & MSR_TYPE_W)\n\t\t\t\tclear_bit(idx, vmx->shadow_msr_intercept.write);\n\t\t}\n\t}\n\n\tif ((type & MSR_TYPE_R) &&\n\t    !kvm_msr_allowed(vcpu, msr, KVM_MSR_FILTER_READ)) {\n\t\tvmx_set_msr_bitmap_read(msr_bitmap, msr);\n\t\ttype &= ~MSR_TYPE_R;\n\t}\n\n\tif ((type & MSR_TYPE_W) &&\n\t    !kvm_msr_allowed(vcpu, msr, KVM_MSR_FILTER_WRITE)) {\n\t\tvmx_set_msr_bitmap_write(msr_bitmap, msr);\n\t\ttype &= ~MSR_TYPE_W;\n\t}\n\n\tif (type & MSR_TYPE_R)\n\t\tvmx_clear_msr_bitmap_read(msr_bitmap, msr);\n\n\tif (type & MSR_TYPE_W)\n\t\tvmx_clear_msr_bitmap_write(msr_bitmap, msr);\n}\n\nstatic __always_inline void vmx_enable_intercept_for_msr(struct kvm_vcpu *vcpu,\n\t\t\t\t\t\t\t u32 msr, int type)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tunsigned long *msr_bitmap = vmx->vmcs01.msr_bitmap;\n\n\tif (!cpu_has_vmx_msr_bitmap())\n\t\treturn;\n\n\tif (static_branch_unlikely(&enable_evmcs))\n\t\tevmcs_touch_msr_bitmap();\n\n\t/*\n\t * Mark the desired intercept state in shadow bitmap, this is needed\n\t * for resync when the MSR filter changes.\n\t*/\n\tif (is_valid_passthrough_msr(msr)) {\n\t\tint idx = possible_passthrough_msr_slot(msr);\n\n\t\tif (idx != -ENOENT) {\n\t\t\tif (type & MSR_TYPE_R)\n\t\t\t\tset_bit(idx, vmx->shadow_msr_intercept.read);\n\t\t\tif (type & MSR_TYPE_W)\n\t\t\t\tset_bit(idx, vmx->shadow_msr_intercept.write);\n\t\t}\n\t}\n\n\tif (type & MSR_TYPE_R)\n\t\tvmx_set_msr_bitmap_read(msr_bitmap, msr);\n\n\tif (type & MSR_TYPE_W)\n\t\tvmx_set_msr_bitmap_write(msr_bitmap, msr);\n}\n\nstatic __always_inline void vmx_set_intercept_for_msr(struct kvm_vcpu *vcpu,\n\t\t\t\t\t\t      u32 msr, int type, bool value)\n{\n\tif (value)\n\t\tvmx_enable_intercept_for_msr(vcpu, msr, type);\n\telse\n\t\tvmx_disable_intercept_for_msr(vcpu, msr, type);\n}\n\nstatic u8 vmx_msr_bitmap_mode(struct kvm_vcpu *vcpu)\n{\n\tu8 mode = 0;\n\n\tif (cpu_has_secondary_exec_ctrls() &&\n\t    (secondary_exec_controls_get(to_vmx(vcpu)) &\n\t     SECONDARY_EXEC_VIRTUALIZE_X2APIC_MODE)) {\n\t\tmode |= MSR_BITMAP_MODE_X2APIC;\n\t\tif (enable_apicv && kvm_vcpu_apicv_active(vcpu))\n\t\t\tmode |= MSR_BITMAP_MODE_X2APIC_APICV;\n\t}\n\n\treturn mode;\n}\n\nstatic void vmx_reset_x2apic_msrs(struct kvm_vcpu *vcpu, u8 mode)\n{\n\tunsigned long *msr_bitmap = to_vmx(vcpu)->vmcs01.msr_bitmap;\n\tunsigned long read_intercept;\n\tint msr;\n\n\tread_intercept = (mode & MSR_BITMAP_MODE_X2APIC_APICV) ? 0 : ~0;\n\n\tfor (msr = 0x800; msr <= 0x8ff; msr += BITS_PER_LONG) {\n\t\tunsigned int read_idx = msr / BITS_PER_LONG;\n\t\tunsigned int write_idx = read_idx + (0x800 / sizeof(long));\n\n\t\tmsr_bitmap[read_idx] = read_intercept;\n\t\tmsr_bitmap[write_idx] = ~0ul;\n\t}\n}\n\nstatic void vmx_update_msr_bitmap_x2apic(struct kvm_vcpu *vcpu, u8 mode)\n{\n\tif (!cpu_has_vmx_msr_bitmap())\n\t\treturn;\n\n\tvmx_reset_x2apic_msrs(vcpu, mode);\n\n\t/*\n\t * TPR reads and writes can be virtualized even if virtual interrupt\n\t * delivery is not in use.\n\t */\n\tvmx_set_intercept_for_msr(vcpu, X2APIC_MSR(APIC_TASKPRI), MSR_TYPE_RW,\n\t\t\t\t  !(mode & MSR_BITMAP_MODE_X2APIC));\n\n\tif (mode & MSR_BITMAP_MODE_X2APIC_APICV) {\n\t\tvmx_enable_intercept_for_msr(vcpu, X2APIC_MSR(APIC_TMCCT), MSR_TYPE_RW);\n\t\tvmx_disable_intercept_for_msr(vcpu, X2APIC_MSR(APIC_EOI), MSR_TYPE_W);\n\t\tvmx_disable_intercept_for_msr(vcpu, X2APIC_MSR(APIC_SELF_IPI), MSR_TYPE_W);\n\t}\n}\n\nvoid vmx_update_msr_bitmap(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tu8 mode = vmx_msr_bitmap_mode(vcpu);\n\tu8 changed = mode ^ vmx->msr_bitmap_mode;\n\n\tif (!changed)\n\t\treturn;\n\n\tif (changed & (MSR_BITMAP_MODE_X2APIC | MSR_BITMAP_MODE_X2APIC_APICV))\n\t\tvmx_update_msr_bitmap_x2apic(vcpu, mode);\n\n\tvmx->msr_bitmap_mode = mode;\n}\n\nvoid pt_update_intercept_for_msr(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tbool flag = !(vmx->pt_desc.guest.ctl & RTIT_CTL_TRACEEN);\n\tu32 i;\n\n\tvmx_set_intercept_for_msr(vcpu, MSR_IA32_RTIT_STATUS, MSR_TYPE_RW, flag);\n\tvmx_set_intercept_for_msr(vcpu, MSR_IA32_RTIT_OUTPUT_BASE, MSR_TYPE_RW, flag);\n\tvmx_set_intercept_for_msr(vcpu, MSR_IA32_RTIT_OUTPUT_MASK, MSR_TYPE_RW, flag);\n\tvmx_set_intercept_for_msr(vcpu, MSR_IA32_RTIT_CR3_MATCH, MSR_TYPE_RW, flag);\n\tfor (i = 0; i < vmx->pt_desc.addr_range; i++) {\n\t\tvmx_set_intercept_for_msr(vcpu, MSR_IA32_RTIT_ADDR0_A + i * 2, MSR_TYPE_RW, flag);\n\t\tvmx_set_intercept_for_msr(vcpu, MSR_IA32_RTIT_ADDR0_B + i * 2, MSR_TYPE_RW, flag);\n\t}\n}\n\nstatic bool vmx_guest_apic_has_interrupt(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tvoid *vapic_page;\n\tu32 vppr;\n\tint rvi;\n\n\tif (WARN_ON_ONCE(!is_guest_mode(vcpu)) ||\n\t\t!nested_cpu_has_vid(get_vmcs12(vcpu)) ||\n\t\tWARN_ON_ONCE(!vmx->nested.virtual_apic_map.gfn))\n\t\treturn false;\n\n\trvi = vmx_get_rvi();\n\n\tvapic_page = vmx->nested.virtual_apic_map.hva;\n\tvppr = *((u32 *)(vapic_page + APIC_PROCPRI));\n\n\treturn ((rvi & 0xf0) > (vppr & 0xf0));\n}\n\nstatic void vmx_msr_filter_changed(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tu32 i;\n\n\t/*\n\t * Set intercept permissions for all potentially passed through MSRs\n\t * again. They will automatically get filtered through the MSR filter,\n\t * so we are back in sync after this.\n\t */\n\tfor (i = 0; i < ARRAY_SIZE(vmx_possible_passthrough_msrs); i++) {\n\t\tu32 msr = vmx_possible_passthrough_msrs[i];\n\t\tbool read = test_bit(i, vmx->shadow_msr_intercept.read);\n\t\tbool write = test_bit(i, vmx->shadow_msr_intercept.write);\n\n\t\tvmx_set_intercept_for_msr(vcpu, msr, MSR_TYPE_R, read);\n\t\tvmx_set_intercept_for_msr(vcpu, msr, MSR_TYPE_W, write);\n\t}\n\n\tpt_update_intercept_for_msr(vcpu);\n\tvmx_update_msr_bitmap_x2apic(vcpu, vmx_msr_bitmap_mode(vcpu));\n}\n\nstatic inline bool kvm_vcpu_trigger_posted_interrupt(struct kvm_vcpu *vcpu,\n\t\t\t\t\t\t     bool nested)\n{\n#ifdef CONFIG_SMP\n\tint pi_vec = nested ? POSTED_INTR_NESTED_VECTOR : POSTED_INTR_VECTOR;\n\n\tif (vcpu->mode == IN_GUEST_MODE) {\n\t\t/*\n\t\t * The vector of interrupt to be delivered to vcpu had\n\t\t * been set in PIR before this function.\n\t\t *\n\t\t * Following cases will be reached in this block, and\n\t\t * we always send a notification event in all cases as\n\t\t * explained below.\n\t\t *\n\t\t * Case 1: vcpu keeps in non-root mode. Sending a\n\t\t * notification event posts the interrupt to vcpu.\n\t\t *\n\t\t * Case 2: vcpu exits to root mode and is still\n\t\t * runnable. PIR will be synced to vIRR before the\n\t\t * next vcpu entry. Sending a notification event in\n\t\t * this case has no effect, as vcpu is not in root\n\t\t * mode.\n\t\t *\n\t\t * Case 3: vcpu exits to root mode and is blocked.\n\t\t * vcpu_block() has already synced PIR to vIRR and\n\t\t * never blocks vcpu if vIRR is not cleared. Therefore,\n\t\t * a blocked vcpu here does not wait for any requested\n\t\t * interrupts in PIR, and sending a notification event\n\t\t * which has no effect is safe here.\n\t\t */\n\n\t\tapic->send_IPI_mask(get_cpu_mask(vcpu->cpu), pi_vec);\n\t\treturn true;\n\t}\n#endif\n\treturn false;\n}\n\nstatic int vmx_deliver_nested_posted_interrupt(struct kvm_vcpu *vcpu,\n\t\t\t\t\t\tint vector)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\tif (is_guest_mode(vcpu) &&\n\t    vector == vmx->nested.posted_intr_nv) {\n\t\t/*\n\t\t * If a posted intr is not recognized by hardware,\n\t\t * we will accomplish it in the next vmentry.\n\t\t */\n\t\tvmx->nested.pi_pending = true;\n\t\tkvm_make_request(KVM_REQ_EVENT, vcpu);\n\t\t/* the PIR and ON have been set by L1. */\n\t\tif (!kvm_vcpu_trigger_posted_interrupt(vcpu, true))\n\t\t\tkvm_vcpu_kick(vcpu);\n\t\treturn 0;\n\t}\n\treturn -1;\n}\n/*\n * Send interrupt to vcpu via posted interrupt way.\n * 1. If target vcpu is running(non-root mode), send posted interrupt\n * notification to vcpu and hardware will sync PIR to vIRR atomically.\n * 2. If target vcpu isn't running(root mode), kick it to pick up the\n * interrupt from PIR in next vmentry.\n */\nstatic int vmx_deliver_posted_interrupt(struct kvm_vcpu *vcpu, int vector)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tint r;\n\n\tr = vmx_deliver_nested_posted_interrupt(vcpu, vector);\n\tif (!r)\n\t\treturn 0;\n\n\tif (!vcpu->arch.apicv_active)\n\t\treturn -1;\n\n\tif (pi_test_and_set_pir(vector, &vmx->pi_desc))\n\t\treturn 0;\n\n\t/* If a previous notification has sent the IPI, nothing to do.  */\n\tif (pi_test_and_set_on(&vmx->pi_desc))\n\t\treturn 0;\n\n\tif (vcpu != kvm_get_running_vcpu() &&\n\t    !kvm_vcpu_trigger_posted_interrupt(vcpu, false))\n\t\tkvm_vcpu_kick(vcpu);\n\n\treturn 0;\n}\n\n/*\n * Set up the vmcs's constant host-state fields, i.e., host-state fields that\n * will not change in the lifetime of the guest.\n * Note that host-state that does change is set elsewhere. E.g., host-state\n * that is set differently for each CPU is set in vmx_vcpu_load(), not here.\n */\nvoid vmx_set_constant_host_state(struct vcpu_vmx *vmx)\n{\n\tu32 low32, high32;\n\tunsigned long tmpl;\n\tunsigned long cr0, cr3, cr4;\n\n\tcr0 = read_cr0();\n\tWARN_ON(cr0 & X86_CR0_TS);\n\tvmcs_writel(HOST_CR0, cr0);  /* 22.2.3 */\n\n\t/*\n\t * Save the most likely value for this task's CR3 in the VMCS.\n\t * We can't use __get_current_cr3_fast() because we're not atomic.\n\t */\n\tcr3 = __read_cr3();\n\tvmcs_writel(HOST_CR3, cr3);\t\t/* 22.2.3  FIXME: shadow tables */\n\tvmx->loaded_vmcs->host_state.cr3 = cr3;\n\n\t/* Save the most likely value for this task's CR4 in the VMCS. */\n\tcr4 = cr4_read_shadow();\n\tvmcs_writel(HOST_CR4, cr4);\t\t\t/* 22.2.3, 22.2.5 */\n\tvmx->loaded_vmcs->host_state.cr4 = cr4;\n\n\tvmcs_write16(HOST_CS_SELECTOR, __KERNEL_CS);  /* 22.2.4 */\n#ifdef CONFIG_X86_64\n\t/*\n\t * Load null selectors, so we can avoid reloading them in\n\t * vmx_prepare_switch_to_host(), in case userspace uses\n\t * the null selectors too (the expected case).\n\t */\n\tvmcs_write16(HOST_DS_SELECTOR, 0);\n\tvmcs_write16(HOST_ES_SELECTOR, 0);\n#else\n\tvmcs_write16(HOST_DS_SELECTOR, __KERNEL_DS);  /* 22.2.4 */\n\tvmcs_write16(HOST_ES_SELECTOR, __KERNEL_DS);  /* 22.2.4 */\n#endif\n\tvmcs_write16(HOST_SS_SELECTOR, __KERNEL_DS);  /* 22.2.4 */\n\tvmcs_write16(HOST_TR_SELECTOR, GDT_ENTRY_TSS*8);  /* 22.2.4 */\n\n\tvmcs_writel(HOST_IDTR_BASE, host_idt_base);   /* 22.2.4 */\n\n\tvmcs_writel(HOST_RIP, (unsigned long)vmx_vmexit); /* 22.2.5 */\n\n\trdmsr(MSR_IA32_SYSENTER_CS, low32, high32);\n\tvmcs_write32(HOST_IA32_SYSENTER_CS, low32);\n\trdmsrl(MSR_IA32_SYSENTER_EIP, tmpl);\n\tvmcs_writel(HOST_IA32_SYSENTER_EIP, tmpl);   /* 22.2.3 */\n\n\tif (vmcs_config.vmexit_ctrl & VM_EXIT_LOAD_IA32_PAT) {\n\t\trdmsr(MSR_IA32_CR_PAT, low32, high32);\n\t\tvmcs_write64(HOST_IA32_PAT, low32 | ((u64) high32 << 32));\n\t}\n\n\tif (cpu_has_load_ia32_efer())\n\t\tvmcs_write64(HOST_IA32_EFER, host_efer);\n}\n\nvoid set_cr4_guest_host_mask(struct vcpu_vmx *vmx)\n{\n\tstruct kvm_vcpu *vcpu = &vmx->vcpu;\n\n\tvcpu->arch.cr4_guest_owned_bits = KVM_POSSIBLE_CR4_GUEST_BITS &\n\t\t\t\t\t  ~vcpu->arch.cr4_guest_rsvd_bits;\n\tif (!enable_ept)\n\t\tvcpu->arch.cr4_guest_owned_bits &= ~X86_CR4_PGE;\n\tif (is_guest_mode(&vmx->vcpu))\n\t\tvcpu->arch.cr4_guest_owned_bits &=\n\t\t\t~get_vmcs12(vcpu)->cr4_guest_host_mask;\n\tvmcs_writel(CR4_GUEST_HOST_MASK, ~vcpu->arch.cr4_guest_owned_bits);\n}\n\nu32 vmx_pin_based_exec_ctrl(struct vcpu_vmx *vmx)\n{\n\tu32 pin_based_exec_ctrl = vmcs_config.pin_based_exec_ctrl;\n\n\tif (!kvm_vcpu_apicv_active(&vmx->vcpu))\n\t\tpin_based_exec_ctrl &= ~PIN_BASED_POSTED_INTR;\n\n\tif (!enable_vnmi)\n\t\tpin_based_exec_ctrl &= ~PIN_BASED_VIRTUAL_NMIS;\n\n\tif (!enable_preemption_timer)\n\t\tpin_based_exec_ctrl &= ~PIN_BASED_VMX_PREEMPTION_TIMER;\n\n\treturn pin_based_exec_ctrl;\n}\n\nstatic void vmx_refresh_apicv_exec_ctrl(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\tpin_controls_set(vmx, vmx_pin_based_exec_ctrl(vmx));\n\tif (cpu_has_secondary_exec_ctrls()) {\n\t\tif (kvm_vcpu_apicv_active(vcpu))\n\t\t\tsecondary_exec_controls_setbit(vmx,\n\t\t\t\t      SECONDARY_EXEC_APIC_REGISTER_VIRT |\n\t\t\t\t      SECONDARY_EXEC_VIRTUAL_INTR_DELIVERY);\n\t\telse\n\t\t\tsecondary_exec_controls_clearbit(vmx,\n\t\t\t\t\tSECONDARY_EXEC_APIC_REGISTER_VIRT |\n\t\t\t\t\tSECONDARY_EXEC_VIRTUAL_INTR_DELIVERY);\n\t}\n\n\tif (cpu_has_vmx_msr_bitmap())\n\t\tvmx_update_msr_bitmap(vcpu);\n}\n\nu32 vmx_exec_control(struct vcpu_vmx *vmx)\n{\n\tu32 exec_control = vmcs_config.cpu_based_exec_ctrl;\n\n\tif (vmx->vcpu.arch.switch_db_regs & KVM_DEBUGREG_WONT_EXIT)\n\t\texec_control &= ~CPU_BASED_MOV_DR_EXITING;\n\n\tif (!cpu_need_tpr_shadow(&vmx->vcpu)) {\n\t\texec_control &= ~CPU_BASED_TPR_SHADOW;\n#ifdef CONFIG_X86_64\n\t\texec_control |= CPU_BASED_CR8_STORE_EXITING |\n\t\t\t\tCPU_BASED_CR8_LOAD_EXITING;\n#endif\n\t}\n\tif (!enable_ept)\n\t\texec_control |= CPU_BASED_CR3_STORE_EXITING |\n\t\t\t\tCPU_BASED_CR3_LOAD_EXITING  |\n\t\t\t\tCPU_BASED_INVLPG_EXITING;\n\tif (kvm_mwait_in_guest(vmx->vcpu.kvm))\n\t\texec_control &= ~(CPU_BASED_MWAIT_EXITING |\n\t\t\t\tCPU_BASED_MONITOR_EXITING);\n\tif (kvm_hlt_in_guest(vmx->vcpu.kvm))\n\t\texec_control &= ~CPU_BASED_HLT_EXITING;\n\treturn exec_control;\n}\n\n/*\n * Adjust a single secondary execution control bit to intercept/allow an\n * instruction in the guest.  This is usually done based on whether or not a\n * feature has been exposed to the guest in order to correctly emulate faults.\n */\nstatic inline void\nvmx_adjust_secondary_exec_control(struct vcpu_vmx *vmx, u32 *exec_control,\n\t\t\t\t  u32 control, bool enabled, bool exiting)\n{\n\t/*\n\t * If the control is for an opt-in feature, clear the control if the\n\t * feature is not exposed to the guest, i.e. not enabled.  If the\n\t * control is opt-out, i.e. an exiting control, clear the control if\n\t * the feature _is_ exposed to the guest, i.e. exiting/interception is\n\t * disabled for the associated instruction.  Note, the caller is\n\t * responsible presetting exec_control to set all supported bits.\n\t */\n\tif (enabled == exiting)\n\t\t*exec_control &= ~control;\n\n\t/*\n\t * Update the nested MSR settings so that a nested VMM can/can't set\n\t * controls for features that are/aren't exposed to the guest.\n\t */\n\tif (nested) {\n\t\tif (enabled)\n\t\t\tvmx->nested.msrs.secondary_ctls_high |= control;\n\t\telse\n\t\t\tvmx->nested.msrs.secondary_ctls_high &= ~control;\n\t}\n}\n\n/*\n * Wrapper macro for the common case of adjusting a secondary execution control\n * based on a single guest CPUID bit, with a dedicated feature bit.  This also\n * verifies that the control is actually supported by KVM and hardware.\n */\n#define vmx_adjust_sec_exec_control(vmx, exec_control, name, feat_name, ctrl_name, exiting) \\\n({\t\t\t\t\t\t\t\t\t \\\n\tbool __enabled;\t\t\t\t\t\t\t \\\n\t\t\t\t\t\t\t\t\t \\\n\tif (cpu_has_vmx_##name()) {\t\t\t\t\t \\\n\t\t__enabled = guest_cpuid_has(&(vmx)->vcpu,\t\t \\\n\t\t\t\t\t    X86_FEATURE_##feat_name);\t \\\n\t\tvmx_adjust_secondary_exec_control(vmx, exec_control,\t \\\n\t\t\tSECONDARY_EXEC_##ctrl_name, __enabled, exiting); \\\n\t}\t\t\t\t\t\t\t\t \\\n})\n\n/* More macro magic for ENABLE_/opt-in versus _EXITING/opt-out controls. */\n#define vmx_adjust_sec_exec_feature(vmx, exec_control, lname, uname) \\\n\tvmx_adjust_sec_exec_control(vmx, exec_control, lname, uname, ENABLE_##uname, false)\n\n#define vmx_adjust_sec_exec_exiting(vmx, exec_control, lname, uname) \\\n\tvmx_adjust_sec_exec_control(vmx, exec_control, lname, uname, uname##_EXITING, true)\n\nstatic void vmx_compute_secondary_exec_control(struct vcpu_vmx *vmx)\n{\n\tstruct kvm_vcpu *vcpu = &vmx->vcpu;\n\n\tu32 exec_control = vmcs_config.cpu_based_2nd_exec_ctrl;\n\n\tif (vmx_pt_mode_is_system())\n\t\texec_control &= ~(SECONDARY_EXEC_PT_USE_GPA | SECONDARY_EXEC_PT_CONCEAL_VMX);\n\tif (!cpu_need_virtualize_apic_accesses(vcpu))\n\t\texec_control &= ~SECONDARY_EXEC_VIRTUALIZE_APIC_ACCESSES;\n\tif (vmx->vpid == 0)\n\t\texec_control &= ~SECONDARY_EXEC_ENABLE_VPID;\n\tif (!enable_ept) {\n\t\texec_control &= ~SECONDARY_EXEC_ENABLE_EPT;\n\t\tenable_unrestricted_guest = 0;\n\t}\n\tif (!enable_unrestricted_guest)\n\t\texec_control &= ~SECONDARY_EXEC_UNRESTRICTED_GUEST;\n\tif (kvm_pause_in_guest(vmx->vcpu.kvm))\n\t\texec_control &= ~SECONDARY_EXEC_PAUSE_LOOP_EXITING;\n\tif (!kvm_vcpu_apicv_active(vcpu))\n\t\texec_control &= ~(SECONDARY_EXEC_APIC_REGISTER_VIRT |\n\t\t\t\t  SECONDARY_EXEC_VIRTUAL_INTR_DELIVERY);\n\texec_control &= ~SECONDARY_EXEC_VIRTUALIZE_X2APIC_MODE;\n\n\t/* SECONDARY_EXEC_DESC is enabled/disabled on writes to CR4.UMIP,\n\t * in vmx_set_cr4.  */\n\texec_control &= ~SECONDARY_EXEC_DESC;\n\n\t/* SECONDARY_EXEC_SHADOW_VMCS is enabled when L1 executes VMPTRLD\n\t   (handle_vmptrld).\n\t   We can NOT enable shadow_vmcs here because we don't have yet\n\t   a current VMCS12\n\t*/\n\texec_control &= ~SECONDARY_EXEC_SHADOW_VMCS;\n\n\tif (!enable_pml)\n\t\texec_control &= ~SECONDARY_EXEC_ENABLE_PML;\n\n\tif (cpu_has_vmx_xsaves()) {\n\t\t/* Exposing XSAVES only when XSAVE is exposed */\n\t\tbool xsaves_enabled =\n\t\t\tboot_cpu_has(X86_FEATURE_XSAVE) &&\n\t\t\tguest_cpuid_has(vcpu, X86_FEATURE_XSAVE) &&\n\t\t\tguest_cpuid_has(vcpu, X86_FEATURE_XSAVES);\n\n\t\tvcpu->arch.xsaves_enabled = xsaves_enabled;\n\n\t\tvmx_adjust_secondary_exec_control(vmx, &exec_control,\n\t\t\t\t\t\t  SECONDARY_EXEC_XSAVES,\n\t\t\t\t\t\t  xsaves_enabled, false);\n\t}\n\n\tvmx_adjust_sec_exec_feature(vmx, &exec_control, rdtscp, RDTSCP);\n\n\t/*\n\t * Expose INVPCID if and only if PCID is also exposed to the guest.\n\t * INVPCID takes a #UD when it's disabled in the VMCS, but a #GP or #PF\n\t * if CR4.PCIDE=0.  Enumerating CPUID.INVPCID=1 would lead to incorrect\n\t * behavior from the guest perspective (it would expect #GP or #PF).\n\t */\n\tif (!guest_cpuid_has(vcpu, X86_FEATURE_PCID))\n\t\tguest_cpuid_clear(vcpu, X86_FEATURE_INVPCID);\n\tvmx_adjust_sec_exec_feature(vmx, &exec_control, invpcid, INVPCID);\n\n\n\tvmx_adjust_sec_exec_exiting(vmx, &exec_control, rdrand, RDRAND);\n\tvmx_adjust_sec_exec_exiting(vmx, &exec_control, rdseed, RDSEED);\n\n\tvmx_adjust_sec_exec_control(vmx, &exec_control, waitpkg, WAITPKG,\n\t\t\t\t    ENABLE_USR_WAIT_PAUSE, false);\n\n\tvmx->secondary_exec_control = exec_control;\n}\n\nstatic void ept_set_mmio_spte_mask(void)\n{\n\t/*\n\t * EPT Misconfigurations can be generated if the value of bits 2:0\n\t * of an EPT paging-structure entry is 110b (write/execute).\n\t */\n\tkvm_mmu_set_mmio_spte_mask(VMX_EPT_MISCONFIG_WX_VALUE, 0);\n}\n\n#define VMX_XSS_EXIT_BITMAP 0\n\n/*\n * Noting that the initialization of Guest-state Area of VMCS is in\n * vmx_vcpu_reset().\n */\nstatic void init_vmcs(struct vcpu_vmx *vmx)\n{\n\tif (nested)\n\t\tnested_vmx_set_vmcs_shadowing_bitmap();\n\n\tif (cpu_has_vmx_msr_bitmap())\n\t\tvmcs_write64(MSR_BITMAP, __pa(vmx->vmcs01.msr_bitmap));\n\n\tvmcs_write64(VMCS_LINK_POINTER, -1ull); /* 22.3.1.5 */\n\n\t/* Control */\n\tpin_controls_set(vmx, vmx_pin_based_exec_ctrl(vmx));\n\n\texec_controls_set(vmx, vmx_exec_control(vmx));\n\n\tif (cpu_has_secondary_exec_ctrls()) {\n\t\tvmx_compute_secondary_exec_control(vmx);\n\t\tsecondary_exec_controls_set(vmx, vmx->secondary_exec_control);\n\t}\n\n\tif (kvm_vcpu_apicv_active(&vmx->vcpu)) {\n\t\tvmcs_write64(EOI_EXIT_BITMAP0, 0);\n\t\tvmcs_write64(EOI_EXIT_BITMAP1, 0);\n\t\tvmcs_write64(EOI_EXIT_BITMAP2, 0);\n\t\tvmcs_write64(EOI_EXIT_BITMAP3, 0);\n\n\t\tvmcs_write16(GUEST_INTR_STATUS, 0);\n\n\t\tvmcs_write16(POSTED_INTR_NV, POSTED_INTR_VECTOR);\n\t\tvmcs_write64(POSTED_INTR_DESC_ADDR, __pa((&vmx->pi_desc)));\n\t}\n\n\tif (!kvm_pause_in_guest(vmx->vcpu.kvm)) {\n\t\tvmcs_write32(PLE_GAP, ple_gap);\n\t\tvmx->ple_window = ple_window;\n\t\tvmx->ple_window_dirty = true;\n\t}\n\n\tvmcs_write32(PAGE_FAULT_ERROR_CODE_MASK, 0);\n\tvmcs_write32(PAGE_FAULT_ERROR_CODE_MATCH, 0);\n\tvmcs_write32(CR3_TARGET_COUNT, 0);           /* 22.2.1 */\n\n\tvmcs_write16(HOST_FS_SELECTOR, 0);            /* 22.2.4 */\n\tvmcs_write16(HOST_GS_SELECTOR, 0);            /* 22.2.4 */\n\tvmx_set_constant_host_state(vmx);\n\tvmcs_writel(HOST_FS_BASE, 0); /* 22.2.4 */\n\tvmcs_writel(HOST_GS_BASE, 0); /* 22.2.4 */\n\n\tif (cpu_has_vmx_vmfunc())\n\t\tvmcs_write64(VM_FUNCTION_CONTROL, 0);\n\n\tvmcs_write32(VM_EXIT_MSR_STORE_COUNT, 0);\n\tvmcs_write32(VM_EXIT_MSR_LOAD_COUNT, 0);\n\tvmcs_write64(VM_EXIT_MSR_LOAD_ADDR, __pa(vmx->msr_autoload.host.val));\n\tvmcs_write32(VM_ENTRY_MSR_LOAD_COUNT, 0);\n\tvmcs_write64(VM_ENTRY_MSR_LOAD_ADDR, __pa(vmx->msr_autoload.guest.val));\n\n\tif (vmcs_config.vmentry_ctrl & VM_ENTRY_LOAD_IA32_PAT)\n\t\tvmcs_write64(GUEST_IA32_PAT, vmx->vcpu.arch.pat);\n\n\tvm_exit_controls_set(vmx, vmx_vmexit_ctrl());\n\n\t/* 22.2.1, 20.8.1 */\n\tvm_entry_controls_set(vmx, vmx_vmentry_ctrl());\n\n\tvmx->vcpu.arch.cr0_guest_owned_bits = KVM_POSSIBLE_CR0_GUEST_BITS;\n\tvmcs_writel(CR0_GUEST_HOST_MASK, ~vmx->vcpu.arch.cr0_guest_owned_bits);\n\n\tset_cr4_guest_host_mask(vmx);\n\n\tif (vmx->vpid != 0)\n\t\tvmcs_write16(VIRTUAL_PROCESSOR_ID, vmx->vpid);\n\n\tif (cpu_has_vmx_xsaves())\n\t\tvmcs_write64(XSS_EXIT_BITMAP, VMX_XSS_EXIT_BITMAP);\n\n\tif (enable_pml) {\n\t\tvmcs_write64(PML_ADDRESS, page_to_phys(vmx->pml_pg));\n\t\tvmcs_write16(GUEST_PML_INDEX, PML_ENTITY_NUM - 1);\n\t}\n\n\tif (cpu_has_vmx_encls_vmexit())\n\t\tvmcs_write64(ENCLS_EXITING_BITMAP, -1ull);\n\n\tif (vmx_pt_mode_is_host_guest()) {\n\t\tmemset(&vmx->pt_desc, 0, sizeof(vmx->pt_desc));\n\t\t/* Bit[6~0] are forced to 1, writes are ignored. */\n\t\tvmx->pt_desc.guest.output_mask = 0x7F;\n\t\tvmcs_write64(GUEST_IA32_RTIT_CTL, 0);\n\t}\n}\n\nstatic void vmx_vcpu_reset(struct kvm_vcpu *vcpu, bool init_event)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tstruct msr_data apic_base_msr;\n\tu64 cr0;\n\n\tvmx->rmode.vm86_active = 0;\n\tvmx->spec_ctrl = 0;\n\n\tvmx->msr_ia32_umwait_control = 0;\n\n\tvmx->vcpu.arch.regs[VCPU_REGS_RDX] = get_rdx_init_val();\n\tvmx->hv_deadline_tsc = -1;\n\tkvm_set_cr8(vcpu, 0);\n\n\tif (!init_event) {\n\t\tapic_base_msr.data = APIC_DEFAULT_PHYS_BASE |\n\t\t\t\t     MSR_IA32_APICBASE_ENABLE;\n\t\tif (kvm_vcpu_is_reset_bsp(vcpu))\n\t\t\tapic_base_msr.data |= MSR_IA32_APICBASE_BSP;\n\t\tapic_base_msr.host_initiated = true;\n\t\tkvm_set_apic_base(vcpu, &apic_base_msr);\n\t}\n\n\tvmx_segment_cache_clear(vmx);\n\n\tseg_setup(VCPU_SREG_CS);\n\tvmcs_write16(GUEST_CS_SELECTOR, 0xf000);\n\tvmcs_writel(GUEST_CS_BASE, 0xffff0000ul);\n\n\tseg_setup(VCPU_SREG_DS);\n\tseg_setup(VCPU_SREG_ES);\n\tseg_setup(VCPU_SREG_FS);\n\tseg_setup(VCPU_SREG_GS);\n\tseg_setup(VCPU_SREG_SS);\n\n\tvmcs_write16(GUEST_TR_SELECTOR, 0);\n\tvmcs_writel(GUEST_TR_BASE, 0);\n\tvmcs_write32(GUEST_TR_LIMIT, 0xffff);\n\tvmcs_write32(GUEST_TR_AR_BYTES, 0x008b);\n\n\tvmcs_write16(GUEST_LDTR_SELECTOR, 0);\n\tvmcs_writel(GUEST_LDTR_BASE, 0);\n\tvmcs_write32(GUEST_LDTR_LIMIT, 0xffff);\n\tvmcs_write32(GUEST_LDTR_AR_BYTES, 0x00082);\n\n\tif (!init_event) {\n\t\tvmcs_write32(GUEST_SYSENTER_CS, 0);\n\t\tvmcs_writel(GUEST_SYSENTER_ESP, 0);\n\t\tvmcs_writel(GUEST_SYSENTER_EIP, 0);\n\t\tvmcs_write64(GUEST_IA32_DEBUGCTL, 0);\n\t}\n\n\tkvm_set_rflags(vcpu, X86_EFLAGS_FIXED);\n\tkvm_rip_write(vcpu, 0xfff0);\n\n\tvmcs_writel(GUEST_GDTR_BASE, 0);\n\tvmcs_write32(GUEST_GDTR_LIMIT, 0xffff);\n\n\tvmcs_writel(GUEST_IDTR_BASE, 0);\n\tvmcs_write32(GUEST_IDTR_LIMIT, 0xffff);\n\n\tvmcs_write32(GUEST_ACTIVITY_STATE, GUEST_ACTIVITY_ACTIVE);\n\tvmcs_write32(GUEST_INTERRUPTIBILITY_INFO, 0);\n\tvmcs_writel(GUEST_PENDING_DBG_EXCEPTIONS, 0);\n\tif (kvm_mpx_supported())\n\t\tvmcs_write64(GUEST_BNDCFGS, 0);\n\n\tsetup_msrs(vmx);\n\n\tvmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);  /* 22.2.1 */\n\n\tif (cpu_has_vmx_tpr_shadow() && !init_event) {\n\t\tvmcs_write64(VIRTUAL_APIC_PAGE_ADDR, 0);\n\t\tif (cpu_need_tpr_shadow(vcpu))\n\t\t\tvmcs_write64(VIRTUAL_APIC_PAGE_ADDR,\n\t\t\t\t     __pa(vcpu->arch.apic->regs));\n\t\tvmcs_write32(TPR_THRESHOLD, 0);\n\t}\n\n\tkvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);\n\n\tcr0 = X86_CR0_NW | X86_CR0_CD | X86_CR0_ET;\n\tvmx->vcpu.arch.cr0 = cr0;\n\tvmx_set_cr0(vcpu, cr0); /* enter rmode */\n\tvmx_set_cr4(vcpu, 0);\n\tvmx_set_efer(vcpu, 0);\n\n\tupdate_exception_bitmap(vcpu);\n\n\tvpid_sync_context(vmx->vpid);\n\tif (init_event)\n\t\tvmx_clear_hlt(vcpu);\n}\n\nstatic void enable_irq_window(struct kvm_vcpu *vcpu)\n{\n\texec_controls_setbit(to_vmx(vcpu), CPU_BASED_INTR_WINDOW_EXITING);\n}\n\nstatic void enable_nmi_window(struct kvm_vcpu *vcpu)\n{\n\tif (!enable_vnmi ||\n\t    vmcs_read32(GUEST_INTERRUPTIBILITY_INFO) & GUEST_INTR_STATE_STI) {\n\t\tenable_irq_window(vcpu);\n\t\treturn;\n\t}\n\n\texec_controls_setbit(to_vmx(vcpu), CPU_BASED_NMI_WINDOW_EXITING);\n}\n\nstatic void vmx_inject_irq(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tuint32_t intr;\n\tint irq = vcpu->arch.interrupt.nr;\n\n\ttrace_kvm_inj_virq(irq);\n\n\t++vcpu->stat.irq_injections;\n\tif (vmx->rmode.vm86_active) {\n\t\tint inc_eip = 0;\n\t\tif (vcpu->arch.interrupt.soft)\n\t\t\tinc_eip = vcpu->arch.event_exit_inst_len;\n\t\tkvm_inject_realmode_interrupt(vcpu, irq, inc_eip);\n\t\treturn;\n\t}\n\tintr = irq | INTR_INFO_VALID_MASK;\n\tif (vcpu->arch.interrupt.soft) {\n\t\tintr |= INTR_TYPE_SOFT_INTR;\n\t\tvmcs_write32(VM_ENTRY_INSTRUCTION_LEN,\n\t\t\t     vmx->vcpu.arch.event_exit_inst_len);\n\t} else\n\t\tintr |= INTR_TYPE_EXT_INTR;\n\tvmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr);\n\n\tvmx_clear_hlt(vcpu);\n}\n\nstatic void vmx_inject_nmi(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\tif (!enable_vnmi) {\n\t\t/*\n\t\t * Tracking the NMI-blocked state in software is built upon\n\t\t * finding the next open IRQ window. This, in turn, depends on\n\t\t * well-behaving guests: They have to keep IRQs disabled at\n\t\t * least as long as the NMI handler runs. Otherwise we may\n\t\t * cause NMI nesting, maybe breaking the guest. But as this is\n\t\t * highly unlikely, we can live with the residual risk.\n\t\t */\n\t\tvmx->loaded_vmcs->soft_vnmi_blocked = 1;\n\t\tvmx->loaded_vmcs->vnmi_blocked_time = 0;\n\t}\n\n\t++vcpu->stat.nmi_injections;\n\tvmx->loaded_vmcs->nmi_known_unmasked = false;\n\n\tif (vmx->rmode.vm86_active) {\n\t\tkvm_inject_realmode_interrupt(vcpu, NMI_VECTOR, 0);\n\t\treturn;\n\t}\n\n\tvmcs_write32(VM_ENTRY_INTR_INFO_FIELD,\n\t\t\tINTR_TYPE_NMI_INTR | INTR_INFO_VALID_MASK | NMI_VECTOR);\n\n\tvmx_clear_hlt(vcpu);\n}\n\nbool vmx_get_nmi_mask(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tbool masked;\n\n\tif (!enable_vnmi)\n\t\treturn vmx->loaded_vmcs->soft_vnmi_blocked;\n\tif (vmx->loaded_vmcs->nmi_known_unmasked)\n\t\treturn false;\n\tmasked = vmcs_read32(GUEST_INTERRUPTIBILITY_INFO) & GUEST_INTR_STATE_NMI;\n\tvmx->loaded_vmcs->nmi_known_unmasked = !masked;\n\treturn masked;\n}\n\nvoid vmx_set_nmi_mask(struct kvm_vcpu *vcpu, bool masked)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\tif (!enable_vnmi) {\n\t\tif (vmx->loaded_vmcs->soft_vnmi_blocked != masked) {\n\t\t\tvmx->loaded_vmcs->soft_vnmi_blocked = masked;\n\t\t\tvmx->loaded_vmcs->vnmi_blocked_time = 0;\n\t\t}\n\t} else {\n\t\tvmx->loaded_vmcs->nmi_known_unmasked = !masked;\n\t\tif (masked)\n\t\t\tvmcs_set_bits(GUEST_INTERRUPTIBILITY_INFO,\n\t\t\t\t      GUEST_INTR_STATE_NMI);\n\t\telse\n\t\t\tvmcs_clear_bits(GUEST_INTERRUPTIBILITY_INFO,\n\t\t\t\t\tGUEST_INTR_STATE_NMI);\n\t}\n}\n\nbool vmx_nmi_blocked(struct kvm_vcpu *vcpu)\n{\n\tif (is_guest_mode(vcpu) && nested_exit_on_nmi(vcpu))\n\t\treturn false;\n\n\tif (!enable_vnmi && to_vmx(vcpu)->loaded_vmcs->soft_vnmi_blocked)\n\t\treturn true;\n\n\treturn (vmcs_read32(GUEST_INTERRUPTIBILITY_INFO) &\n\t\t(GUEST_INTR_STATE_MOV_SS | GUEST_INTR_STATE_STI |\n\t\t GUEST_INTR_STATE_NMI));\n}\n\nstatic int vmx_nmi_allowed(struct kvm_vcpu *vcpu, bool for_injection)\n{\n\tif (to_vmx(vcpu)->nested.nested_run_pending)\n\t\treturn -EBUSY;\n\n\t/* An NMI must not be injected into L2 if it's supposed to VM-Exit.  */\n\tif (for_injection && is_guest_mode(vcpu) && nested_exit_on_nmi(vcpu))\n\t\treturn -EBUSY;\n\n\treturn !vmx_nmi_blocked(vcpu);\n}\n\nbool vmx_interrupt_blocked(struct kvm_vcpu *vcpu)\n{\n\tif (is_guest_mode(vcpu) && nested_exit_on_intr(vcpu))\n\t\treturn false;\n\n\treturn !(vmx_get_rflags(vcpu) & X86_EFLAGS_IF) ||\n\t       (vmcs_read32(GUEST_INTERRUPTIBILITY_INFO) &\n\t\t(GUEST_INTR_STATE_STI | GUEST_INTR_STATE_MOV_SS));\n}\n\nstatic int vmx_interrupt_allowed(struct kvm_vcpu *vcpu, bool for_injection)\n{\n\tif (to_vmx(vcpu)->nested.nested_run_pending)\n\t\treturn -EBUSY;\n\n       /*\n        * An IRQ must not be injected into L2 if it's supposed to VM-Exit,\n        * e.g. if the IRQ arrived asynchronously after checking nested events.\n        */\n\tif (for_injection && is_guest_mode(vcpu) && nested_exit_on_intr(vcpu))\n\t\treturn -EBUSY;\n\n\treturn !vmx_interrupt_blocked(vcpu);\n}\n\nstatic int vmx_set_tss_addr(struct kvm *kvm, unsigned int addr)\n{\n\tint ret;\n\n\tif (enable_unrestricted_guest)\n\t\treturn 0;\n\n\tmutex_lock(&kvm->slots_lock);\n\tret = __x86_set_memory_region(kvm, TSS_PRIVATE_MEMSLOT, addr,\n\t\t\t\t      PAGE_SIZE * 3);\n\tmutex_unlock(&kvm->slots_lock);\n\n\tif (ret)\n\t\treturn ret;\n\tto_kvm_vmx(kvm)->tss_addr = addr;\n\treturn init_rmode_tss(kvm);\n}\n\nstatic int vmx_set_identity_map_addr(struct kvm *kvm, u64 ident_addr)\n{\n\tto_kvm_vmx(kvm)->ept_identity_map_addr = ident_addr;\n\treturn 0;\n}\n\nstatic bool rmode_exception(struct kvm_vcpu *vcpu, int vec)\n{\n\tswitch (vec) {\n\tcase BP_VECTOR:\n\t\t/*\n\t\t * Update instruction length as we may reinject the exception\n\t\t * from user space while in guest debugging mode.\n\t\t */\n\t\tto_vmx(vcpu)->vcpu.arch.event_exit_inst_len =\n\t\t\tvmcs_read32(VM_EXIT_INSTRUCTION_LEN);\n\t\tif (vcpu->guest_debug & KVM_GUESTDBG_USE_SW_BP)\n\t\t\treturn false;\n\t\tfallthrough;\n\tcase DB_VECTOR:\n\t\treturn !(vcpu->guest_debug &\n\t\t\t(KVM_GUESTDBG_SINGLESTEP | KVM_GUESTDBG_USE_HW_BP));\n\tcase DE_VECTOR:\n\tcase OF_VECTOR:\n\tcase BR_VECTOR:\n\tcase UD_VECTOR:\n\tcase DF_VECTOR:\n\tcase SS_VECTOR:\n\tcase GP_VECTOR:\n\tcase MF_VECTOR:\n\t\treturn true;\n\t}\n\treturn false;\n}\n\nstatic int handle_rmode_exception(struct kvm_vcpu *vcpu,\n\t\t\t\t  int vec, u32 err_code)\n{\n\t/*\n\t * Instruction with address size override prefix opcode 0x67\n\t * Cause the #SS fault with 0 error code in VM86 mode.\n\t */\n\tif (((vec == GP_VECTOR) || (vec == SS_VECTOR)) && err_code == 0) {\n\t\tif (kvm_emulate_instruction(vcpu, 0)) {\n\t\t\tif (vcpu->arch.halt_request) {\n\t\t\t\tvcpu->arch.halt_request = 0;\n\t\t\t\treturn kvm_vcpu_halt(vcpu);\n\t\t\t}\n\t\t\treturn 1;\n\t\t}\n\t\treturn 0;\n\t}\n\n\t/*\n\t * Forward all other exceptions that are valid in real mode.\n\t * FIXME: Breaks guest debugging in real mode, needs to be fixed with\n\t *        the required debugging infrastructure rework.\n\t */\n\tkvm_queue_exception(vcpu, vec);\n\treturn 1;\n}\n\n/*\n * Trigger machine check on the host. We assume all the MSRs are already set up\n * by the CPU and that we still run on the same CPU as the MCE occurred on.\n * We pass a fake environment to the machine check handler because we want\n * the guest to be always treated like user space, no matter what context\n * it used internally.\n */\nstatic void kvm_machine_check(void)\n{\n#if defined(CONFIG_X86_MCE)\n\tstruct pt_regs regs = {\n\t\t.cs = 3, /* Fake ring 3 no matter what the guest ran on */\n\t\t.flags = X86_EFLAGS_IF,\n\t};\n\n\tdo_machine_check(&regs);\n#endif\n}\n\nstatic int handle_machine_check(struct kvm_vcpu *vcpu)\n{\n\t/* handled by vmx_vcpu_run() */\n\treturn 1;\n}\n\n/*\n * If the host has split lock detection disabled, then #AC is\n * unconditionally injected into the guest, which is the pre split lock\n * detection behaviour.\n *\n * If the host has split lock detection enabled then #AC is\n * only injected into the guest when:\n *  - Guest CPL == 3 (user mode)\n *  - Guest has #AC detection enabled in CR0\n *  - Guest EFLAGS has AC bit set\n */\nstatic inline bool guest_inject_ac(struct kvm_vcpu *vcpu)\n{\n\tif (!boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT))\n\t\treturn true;\n\n\treturn vmx_get_cpl(vcpu) == 3 && kvm_read_cr0_bits(vcpu, X86_CR0_AM) &&\n\t       (kvm_get_rflags(vcpu) & X86_EFLAGS_AC);\n}\n\nstatic int handle_exception_nmi(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tstruct kvm_run *kvm_run = vcpu->run;\n\tu32 intr_info, ex_no, error_code;\n\tunsigned long cr2, rip, dr6;\n\tu32 vect_info;\n\n\tvect_info = vmx->idt_vectoring_info;\n\tintr_info = vmx_get_intr_info(vcpu);\n\n\tif (is_machine_check(intr_info) || is_nmi(intr_info))\n\t\treturn 1; /* handled by handle_exception_nmi_irqoff() */\n\n\tif (is_invalid_opcode(intr_info))\n\t\treturn handle_ud(vcpu);\n\n\terror_code = 0;\n\tif (intr_info & INTR_INFO_DELIVER_CODE_MASK)\n\t\terror_code = vmcs_read32(VM_EXIT_INTR_ERROR_CODE);\n\n\tif (!vmx->rmode.vm86_active && is_gp_fault(intr_info)) {\n\t\tWARN_ON_ONCE(!enable_vmware_backdoor);\n\n\t\t/*\n\t\t * VMware backdoor emulation on #GP interception only handles\n\t\t * IN{S}, OUT{S}, and RDPMC, none of which generate a non-zero\n\t\t * error code on #GP.\n\t\t */\n\t\tif (error_code) {\n\t\t\tkvm_queue_exception_e(vcpu, GP_VECTOR, error_code);\n\t\t\treturn 1;\n\t\t}\n\t\treturn kvm_emulate_instruction(vcpu, EMULTYPE_VMWARE_GP);\n\t}\n\n\t/*\n\t * The #PF with PFEC.RSVD = 1 indicates the guest is accessing\n\t * MMIO, it is better to report an internal error.\n\t * See the comments in vmx_handle_exit.\n\t */\n\tif ((vect_info & VECTORING_INFO_VALID_MASK) &&\n\t    !(is_page_fault(intr_info) && !(error_code & PFERR_RSVD_MASK))) {\n\t\tvcpu->run->exit_reason = KVM_EXIT_INTERNAL_ERROR;\n\t\tvcpu->run->internal.suberror = KVM_INTERNAL_ERROR_SIMUL_EX;\n\t\tvcpu->run->internal.ndata = 4;\n\t\tvcpu->run->internal.data[0] = vect_info;\n\t\tvcpu->run->internal.data[1] = intr_info;\n\t\tvcpu->run->internal.data[2] = error_code;\n\t\tvcpu->run->internal.data[3] = vcpu->arch.last_vmentry_cpu;\n\t\treturn 0;\n\t}\n\n\tif (is_page_fault(intr_info)) {\n\t\tcr2 = vmx_get_exit_qual(vcpu);\n\t\tif (enable_ept && !vcpu->arch.apf.host_apf_flags) {\n\t\t\t/*\n\t\t\t * EPT will cause page fault only if we need to\n\t\t\t * detect illegal GPAs.\n\t\t\t */\n\t\t\tWARN_ON_ONCE(!allow_smaller_maxphyaddr);\n\t\t\tkvm_fixup_and_inject_pf_error(vcpu, cr2, error_code);\n\t\t\treturn 1;\n\t\t} else\n\t\t\treturn kvm_handle_page_fault(vcpu, error_code, cr2, NULL, 0);\n\t}\n\n\tex_no = intr_info & INTR_INFO_VECTOR_MASK;\n\n\tif (vmx->rmode.vm86_active && rmode_exception(vcpu, ex_no))\n\t\treturn handle_rmode_exception(vcpu, ex_no, error_code);\n\n\tswitch (ex_no) {\n\tcase DB_VECTOR:\n\t\tdr6 = vmx_get_exit_qual(vcpu);\n\t\tif (!(vcpu->guest_debug &\n\t\t      (KVM_GUESTDBG_SINGLESTEP | KVM_GUESTDBG_USE_HW_BP))) {\n\t\t\tif (is_icebp(intr_info))\n\t\t\t\tWARN_ON(!skip_emulated_instruction(vcpu));\n\n\t\t\tkvm_queue_exception_p(vcpu, DB_VECTOR, dr6);\n\t\t\treturn 1;\n\t\t}\n\t\tkvm_run->debug.arch.dr6 = dr6 | DR6_FIXED_1 | DR6_RTM;\n\t\tkvm_run->debug.arch.dr7 = vmcs_readl(GUEST_DR7);\n\t\tfallthrough;\n\tcase BP_VECTOR:\n\t\t/*\n\t\t * Update instruction length as we may reinject #BP from\n\t\t * user space while in guest debugging mode. Reading it for\n\t\t * #DB as well causes no harm, it is not used in that case.\n\t\t */\n\t\tvmx->vcpu.arch.event_exit_inst_len =\n\t\t\tvmcs_read32(VM_EXIT_INSTRUCTION_LEN);\n\t\tkvm_run->exit_reason = KVM_EXIT_DEBUG;\n\t\trip = kvm_rip_read(vcpu);\n\t\tkvm_run->debug.arch.pc = vmcs_readl(GUEST_CS_BASE) + rip;\n\t\tkvm_run->debug.arch.exception = ex_no;\n\t\tbreak;\n\tcase AC_VECTOR:\n\t\tif (guest_inject_ac(vcpu)) {\n\t\t\tkvm_queue_exception_e(vcpu, AC_VECTOR, error_code);\n\t\t\treturn 1;\n\t\t}\n\n\t\t/*\n\t\t * Handle split lock. Depending on detection mode this will\n\t\t * either warn and disable split lock detection for this\n\t\t * task or force SIGBUS on it.\n\t\t */\n\t\tif (handle_guest_split_lock(kvm_rip_read(vcpu)))\n\t\t\treturn 1;\n\t\tfallthrough;\n\tdefault:\n\t\tkvm_run->exit_reason = KVM_EXIT_EXCEPTION;\n\t\tkvm_run->ex.exception = ex_no;\n\t\tkvm_run->ex.error_code = error_code;\n\t\tbreak;\n\t}\n\treturn 0;\n}\n\nstatic __always_inline int handle_external_interrupt(struct kvm_vcpu *vcpu)\n{\n\t++vcpu->stat.irq_exits;\n\treturn 1;\n}\n\nstatic int handle_triple_fault(struct kvm_vcpu *vcpu)\n{\n\tvcpu->run->exit_reason = KVM_EXIT_SHUTDOWN;\n\tvcpu->mmio_needed = 0;\n\treturn 0;\n}\n\nstatic int handle_io(struct kvm_vcpu *vcpu)\n{\n\tunsigned long exit_qualification;\n\tint size, in, string;\n\tunsigned port;\n\n\texit_qualification = vmx_get_exit_qual(vcpu);\n\tstring = (exit_qualification & 16) != 0;\n\n\t++vcpu->stat.io_exits;\n\n\tif (string)\n\t\treturn kvm_emulate_instruction(vcpu, 0);\n\n\tport = exit_qualification >> 16;\n\tsize = (exit_qualification & 7) + 1;\n\tin = (exit_qualification & 8) != 0;\n\n\treturn kvm_fast_pio(vcpu, size, port, in);\n}\n\nstatic void\nvmx_patch_hypercall(struct kvm_vcpu *vcpu, unsigned char *hypercall)\n{\n\t/*\n\t * Patch in the VMCALL instruction:\n\t */\n\thypercall[0] = 0x0f;\n\thypercall[1] = 0x01;\n\thypercall[2] = 0xc1;\n}\n\n/* called to set cr0 as appropriate for a mov-to-cr0 exit. */\nstatic int handle_set_cr0(struct kvm_vcpu *vcpu, unsigned long val)\n{\n\tif (is_guest_mode(vcpu)) {\n\t\tstruct vmcs12 *vmcs12 = get_vmcs12(vcpu);\n\t\tunsigned long orig_val = val;\n\n\t\t/*\n\t\t * We get here when L2 changed cr0 in a way that did not change\n\t\t * any of L1's shadowed bits (see nested_vmx_exit_handled_cr),\n\t\t * but did change L0 shadowed bits. So we first calculate the\n\t\t * effective cr0 value that L1 would like to write into the\n\t\t * hardware. It consists of the L2-owned bits from the new\n\t\t * value combined with the L1-owned bits from L1's guest_cr0.\n\t\t */\n\t\tval = (val & ~vmcs12->cr0_guest_host_mask) |\n\t\t\t(vmcs12->guest_cr0 & vmcs12->cr0_guest_host_mask);\n\n\t\tif (!nested_guest_cr0_valid(vcpu, val))\n\t\t\treturn 1;\n\n\t\tif (kvm_set_cr0(vcpu, val))\n\t\t\treturn 1;\n\t\tvmcs_writel(CR0_READ_SHADOW, orig_val);\n\t\treturn 0;\n\t} else {\n\t\tif (to_vmx(vcpu)->nested.vmxon &&\n\t\t    !nested_host_cr0_valid(vcpu, val))\n\t\t\treturn 1;\n\n\t\treturn kvm_set_cr0(vcpu, val);\n\t}\n}\n\nstatic int handle_set_cr4(struct kvm_vcpu *vcpu, unsigned long val)\n{\n\tif (is_guest_mode(vcpu)) {\n\t\tstruct vmcs12 *vmcs12 = get_vmcs12(vcpu);\n\t\tunsigned long orig_val = val;\n\n\t\t/* analogously to handle_set_cr0 */\n\t\tval = (val & ~vmcs12->cr4_guest_host_mask) |\n\t\t\t(vmcs12->guest_cr4 & vmcs12->cr4_guest_host_mask);\n\t\tif (kvm_set_cr4(vcpu, val))\n\t\t\treturn 1;\n\t\tvmcs_writel(CR4_READ_SHADOW, orig_val);\n\t\treturn 0;\n\t} else\n\t\treturn kvm_set_cr4(vcpu, val);\n}\n\nstatic int handle_desc(struct kvm_vcpu *vcpu)\n{\n\tWARN_ON(!(vcpu->arch.cr4 & X86_CR4_UMIP));\n\treturn kvm_emulate_instruction(vcpu, 0);\n}\n\nstatic int handle_cr(struct kvm_vcpu *vcpu)\n{\n\tunsigned long exit_qualification, val;\n\tint cr;\n\tint reg;\n\tint err;\n\tint ret;\n\n\texit_qualification = vmx_get_exit_qual(vcpu);\n\tcr = exit_qualification & 15;\n\treg = (exit_qualification >> 8) & 15;\n\tswitch ((exit_qualification >> 4) & 3) {\n\tcase 0: /* mov to cr */\n\t\tval = kvm_register_readl(vcpu, reg);\n\t\ttrace_kvm_cr_write(cr, val);\n\t\tswitch (cr) {\n\t\tcase 0:\n\t\t\terr = handle_set_cr0(vcpu, val);\n\t\t\treturn kvm_complete_insn_gp(vcpu, err);\n\t\tcase 3:\n\t\t\tWARN_ON_ONCE(enable_unrestricted_guest);\n\t\t\terr = kvm_set_cr3(vcpu, val);\n\t\t\treturn kvm_complete_insn_gp(vcpu, err);\n\t\tcase 4:\n\t\t\terr = handle_set_cr4(vcpu, val);\n\t\t\treturn kvm_complete_insn_gp(vcpu, err);\n\t\tcase 8: {\n\t\t\t\tu8 cr8_prev = kvm_get_cr8(vcpu);\n\t\t\t\tu8 cr8 = (u8)val;\n\t\t\t\terr = kvm_set_cr8(vcpu, cr8);\n\t\t\t\tret = kvm_complete_insn_gp(vcpu, err);\n\t\t\t\tif (lapic_in_kernel(vcpu))\n\t\t\t\t\treturn ret;\n\t\t\t\tif (cr8_prev <= cr8)\n\t\t\t\t\treturn ret;\n\t\t\t\t/*\n\t\t\t\t * TODO: we might be squashing a\n\t\t\t\t * KVM_GUESTDBG_SINGLESTEP-triggered\n\t\t\t\t * KVM_EXIT_DEBUG here.\n\t\t\t\t */\n\t\t\t\tvcpu->run->exit_reason = KVM_EXIT_SET_TPR;\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\tcase 2: /* clts */\n\t\tWARN_ONCE(1, \"Guest should always own CR0.TS\");\n\t\tvmx_set_cr0(vcpu, kvm_read_cr0_bits(vcpu, ~X86_CR0_TS));\n\t\ttrace_kvm_cr_write(0, kvm_read_cr0(vcpu));\n\t\treturn kvm_skip_emulated_instruction(vcpu);\n\tcase 1: /*mov from cr*/\n\t\tswitch (cr) {\n\t\tcase 3:\n\t\t\tWARN_ON_ONCE(enable_unrestricted_guest);\n\t\t\tval = kvm_read_cr3(vcpu);\n\t\t\tkvm_register_write(vcpu, reg, val);\n\t\t\ttrace_kvm_cr_read(cr, val);\n\t\t\treturn kvm_skip_emulated_instruction(vcpu);\n\t\tcase 8:\n\t\t\tval = kvm_get_cr8(vcpu);\n\t\t\tkvm_register_write(vcpu, reg, val);\n\t\t\ttrace_kvm_cr_read(cr, val);\n\t\t\treturn kvm_skip_emulated_instruction(vcpu);\n\t\t}\n\t\tbreak;\n\tcase 3: /* lmsw */\n\t\tval = (exit_qualification >> LMSW_SOURCE_DATA_SHIFT) & 0x0f;\n\t\ttrace_kvm_cr_write(0, (kvm_read_cr0(vcpu) & ~0xful) | val);\n\t\tkvm_lmsw(vcpu, val);\n\n\t\treturn kvm_skip_emulated_instruction(vcpu);\n\tdefault:\n\t\tbreak;\n\t}\n\tvcpu->run->exit_reason = 0;\n\tvcpu_unimpl(vcpu, \"unhandled control register: op %d cr %d\\n\",\n\t       (int)(exit_qualification >> 4) & 3, cr);\n\treturn 0;\n}\n\nstatic int handle_dr(struct kvm_vcpu *vcpu)\n{\n\tunsigned long exit_qualification;\n\tint dr, dr7, reg;\n\n\texit_qualification = vmx_get_exit_qual(vcpu);\n\tdr = exit_qualification & DEBUG_REG_ACCESS_NUM;\n\n\t/* First, if DR does not exist, trigger UD */\n\tif (!kvm_require_dr(vcpu, dr))\n\t\treturn 1;\n\n\t/* Do not handle if the CPL > 0, will trigger GP on re-entry */\n\tif (!kvm_require_cpl(vcpu, 0))\n\t\treturn 1;\n\tdr7 = vmcs_readl(GUEST_DR7);\n\tif (dr7 & DR7_GD) {\n\t\t/*\n\t\t * As the vm-exit takes precedence over the debug trap, we\n\t\t * need to emulate the latter, either for the host or the\n\t\t * guest debugging itself.\n\t\t */\n\t\tif (vcpu->guest_debug & KVM_GUESTDBG_USE_HW_BP) {\n\t\t\tvcpu->run->debug.arch.dr6 = DR6_BD | DR6_RTM | DR6_FIXED_1;\n\t\t\tvcpu->run->debug.arch.dr7 = dr7;\n\t\t\tvcpu->run->debug.arch.pc = kvm_get_linear_rip(vcpu);\n\t\t\tvcpu->run->debug.arch.exception = DB_VECTOR;\n\t\t\tvcpu->run->exit_reason = KVM_EXIT_DEBUG;\n\t\t\treturn 0;\n\t\t} else {\n\t\t\tkvm_queue_exception_p(vcpu, DB_VECTOR, DR6_BD);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tif (vcpu->guest_debug == 0) {\n\t\texec_controls_clearbit(to_vmx(vcpu), CPU_BASED_MOV_DR_EXITING);\n\n\t\t/*\n\t\t * No more DR vmexits; force a reload of the debug registers\n\t\t * and reenter on this instruction.  The next vmexit will\n\t\t * retrieve the full state of the debug registers.\n\t\t */\n\t\tvcpu->arch.switch_db_regs |= KVM_DEBUGREG_WONT_EXIT;\n\t\treturn 1;\n\t}\n\n\treg = DEBUG_REG_ACCESS_REG(exit_qualification);\n\tif (exit_qualification & TYPE_MOV_FROM_DR) {\n\t\tunsigned long val;\n\n\t\tif (kvm_get_dr(vcpu, dr, &val))\n\t\t\treturn 1;\n\t\tkvm_register_write(vcpu, reg, val);\n\t} else\n\t\tif (kvm_set_dr(vcpu, dr, kvm_register_readl(vcpu, reg)))\n\t\t\treturn 1;\n\n\treturn kvm_skip_emulated_instruction(vcpu);\n}\n\nstatic void vmx_sync_dirty_debug_regs(struct kvm_vcpu *vcpu)\n{\n\tget_debugreg(vcpu->arch.db[0], 0);\n\tget_debugreg(vcpu->arch.db[1], 1);\n\tget_debugreg(vcpu->arch.db[2], 2);\n\tget_debugreg(vcpu->arch.db[3], 3);\n\tget_debugreg(vcpu->arch.dr6, 6);\n\tvcpu->arch.dr7 = vmcs_readl(GUEST_DR7);\n\n\tvcpu->arch.switch_db_regs &= ~KVM_DEBUGREG_WONT_EXIT;\n\texec_controls_setbit(to_vmx(vcpu), CPU_BASED_MOV_DR_EXITING);\n}\n\nstatic void vmx_set_dr7(struct kvm_vcpu *vcpu, unsigned long val)\n{\n\tvmcs_writel(GUEST_DR7, val);\n}\n\nstatic int handle_tpr_below_threshold(struct kvm_vcpu *vcpu)\n{\n\tkvm_apic_update_ppr(vcpu);\n\treturn 1;\n}\n\nstatic int handle_interrupt_window(struct kvm_vcpu *vcpu)\n{\n\texec_controls_clearbit(to_vmx(vcpu), CPU_BASED_INTR_WINDOW_EXITING);\n\n\tkvm_make_request(KVM_REQ_EVENT, vcpu);\n\n\t++vcpu->stat.irq_window_exits;\n\treturn 1;\n}\n\nstatic int handle_vmcall(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_emulate_hypercall(vcpu);\n}\n\nstatic int handle_invd(struct kvm_vcpu *vcpu)\n{\n\t/* Treat an INVD instruction as a NOP and just skip it. */\n\treturn kvm_skip_emulated_instruction(vcpu);\n}\n\nstatic int handle_invlpg(struct kvm_vcpu *vcpu)\n{\n\tunsigned long exit_qualification = vmx_get_exit_qual(vcpu);\n\n\tkvm_mmu_invlpg(vcpu, exit_qualification);\n\treturn kvm_skip_emulated_instruction(vcpu);\n}\n\nstatic int handle_rdpmc(struct kvm_vcpu *vcpu)\n{\n\tint err;\n\n\terr = kvm_rdpmc(vcpu);\n\treturn kvm_complete_insn_gp(vcpu, err);\n}\n\nstatic int handle_wbinvd(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_emulate_wbinvd(vcpu);\n}\n\nstatic int handle_xsetbv(struct kvm_vcpu *vcpu)\n{\n\tu64 new_bv = kvm_read_edx_eax(vcpu);\n\tu32 index = kvm_rcx_read(vcpu);\n\n\tif (kvm_set_xcr(vcpu, index, new_bv) == 0)\n\t\treturn kvm_skip_emulated_instruction(vcpu);\n\treturn 1;\n}\n\nstatic int handle_apic_access(struct kvm_vcpu *vcpu)\n{\n\tif (likely(fasteoi)) {\n\t\tunsigned long exit_qualification = vmx_get_exit_qual(vcpu);\n\t\tint access_type, offset;\n\n\t\taccess_type = exit_qualification & APIC_ACCESS_TYPE;\n\t\toffset = exit_qualification & APIC_ACCESS_OFFSET;\n\t\t/*\n\t\t * Sane guest uses MOV to write EOI, with written value\n\t\t * not cared. So make a short-circuit here by avoiding\n\t\t * heavy instruction emulation.\n\t\t */\n\t\tif ((access_type == TYPE_LINEAR_APIC_INST_WRITE) &&\n\t\t    (offset == APIC_EOI)) {\n\t\t\tkvm_lapic_set_eoi(vcpu);\n\t\t\treturn kvm_skip_emulated_instruction(vcpu);\n\t\t}\n\t}\n\treturn kvm_emulate_instruction(vcpu, 0);\n}\n\nstatic int handle_apic_eoi_induced(struct kvm_vcpu *vcpu)\n{\n\tunsigned long exit_qualification = vmx_get_exit_qual(vcpu);\n\tint vector = exit_qualification & 0xff;\n\n\t/* EOI-induced VM exit is trap-like and thus no need to adjust IP */\n\tkvm_apic_set_eoi_accelerated(vcpu, vector);\n\treturn 1;\n}\n\nstatic int handle_apic_write(struct kvm_vcpu *vcpu)\n{\n\tunsigned long exit_qualification = vmx_get_exit_qual(vcpu);\n\tu32 offset = exit_qualification & 0xfff;\n\n\t/* APIC-write VM exit is trap-like and thus no need to adjust IP */\n\tkvm_apic_write_nodecode(vcpu, offset);\n\treturn 1;\n}\n\nstatic int handle_task_switch(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tunsigned long exit_qualification;\n\tbool has_error_code = false;\n\tu32 error_code = 0;\n\tu16 tss_selector;\n\tint reason, type, idt_v, idt_index;\n\n\tidt_v = (vmx->idt_vectoring_info & VECTORING_INFO_VALID_MASK);\n\tidt_index = (vmx->idt_vectoring_info & VECTORING_INFO_VECTOR_MASK);\n\ttype = (vmx->idt_vectoring_info & VECTORING_INFO_TYPE_MASK);\n\n\texit_qualification = vmx_get_exit_qual(vcpu);\n\n\treason = (u32)exit_qualification >> 30;\n\tif (reason == TASK_SWITCH_GATE && idt_v) {\n\t\tswitch (type) {\n\t\tcase INTR_TYPE_NMI_INTR:\n\t\t\tvcpu->arch.nmi_injected = false;\n\t\t\tvmx_set_nmi_mask(vcpu, true);\n\t\t\tbreak;\n\t\tcase INTR_TYPE_EXT_INTR:\n\t\tcase INTR_TYPE_SOFT_INTR:\n\t\t\tkvm_clear_interrupt_queue(vcpu);\n\t\t\tbreak;\n\t\tcase INTR_TYPE_HARD_EXCEPTION:\n\t\t\tif (vmx->idt_vectoring_info &\n\t\t\t    VECTORING_INFO_DELIVER_CODE_MASK) {\n\t\t\t\thas_error_code = true;\n\t\t\t\terror_code =\n\t\t\t\t\tvmcs_read32(IDT_VECTORING_ERROR_CODE);\n\t\t\t}\n\t\t\tfallthrough;\n\t\tcase INTR_TYPE_SOFT_EXCEPTION:\n\t\t\tkvm_clear_exception_queue(vcpu);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\ttss_selector = exit_qualification;\n\n\tif (!idt_v || (type != INTR_TYPE_HARD_EXCEPTION &&\n\t\t       type != INTR_TYPE_EXT_INTR &&\n\t\t       type != INTR_TYPE_NMI_INTR))\n\t\tWARN_ON(!skip_emulated_instruction(vcpu));\n\n\t/*\n\t * TODO: What about debug traps on tss switch?\n\t *       Are we supposed to inject them and update dr6?\n\t */\n\treturn kvm_task_switch(vcpu, tss_selector,\n\t\t\t       type == INTR_TYPE_SOFT_INTR ? idt_index : -1,\n\t\t\t       reason, has_error_code, error_code);\n}\n\nstatic int handle_ept_violation(struct kvm_vcpu *vcpu)\n{\n\tunsigned long exit_qualification;\n\tgpa_t gpa;\n\tu64 error_code;\n\n\texit_qualification = vmx_get_exit_qual(vcpu);\n\n\t/*\n\t * EPT violation happened while executing iret from NMI,\n\t * \"blocked by NMI\" bit has to be set before next VM entry.\n\t * There are errata that may cause this bit to not be set:\n\t * AAK134, BY25.\n\t */\n\tif (!(to_vmx(vcpu)->idt_vectoring_info & VECTORING_INFO_VALID_MASK) &&\n\t\t\tenable_vnmi &&\n\t\t\t(exit_qualification & INTR_INFO_UNBLOCK_NMI))\n\t\tvmcs_set_bits(GUEST_INTERRUPTIBILITY_INFO, GUEST_INTR_STATE_NMI);\n\n\tgpa = vmcs_read64(GUEST_PHYSICAL_ADDRESS);\n\ttrace_kvm_page_fault(gpa, exit_qualification);\n\n\t/* Is it a read fault? */\n\terror_code = (exit_qualification & EPT_VIOLATION_ACC_READ)\n\t\t     ? PFERR_USER_MASK : 0;\n\t/* Is it a write fault? */\n\terror_code |= (exit_qualification & EPT_VIOLATION_ACC_WRITE)\n\t\t      ? PFERR_WRITE_MASK : 0;\n\t/* Is it a fetch fault? */\n\terror_code |= (exit_qualification & EPT_VIOLATION_ACC_INSTR)\n\t\t      ? PFERR_FETCH_MASK : 0;\n\t/* ept page table entry is present? */\n\terror_code |= (exit_qualification &\n\t\t       (EPT_VIOLATION_READABLE | EPT_VIOLATION_WRITABLE |\n\t\t\tEPT_VIOLATION_EXECUTABLE))\n\t\t      ? PFERR_PRESENT_MASK : 0;\n\n\terror_code |= (exit_qualification & 0x100) != 0 ?\n\t       PFERR_GUEST_FINAL_MASK : PFERR_GUEST_PAGE_MASK;\n\n\tvcpu->arch.exit_qualification = exit_qualification;\n\n\t/*\n\t * Check that the GPA doesn't exceed physical memory limits, as that is\n\t * a guest page fault.  We have to emulate the instruction here, because\n\t * if the illegal address is that of a paging structure, then\n\t * EPT_VIOLATION_ACC_WRITE bit is set.  Alternatively, if supported we\n\t * would also use advanced VM-exit information for EPT violations to\n\t * reconstruct the page fault error code.\n\t */\n\tif (unlikely(allow_smaller_maxphyaddr && kvm_vcpu_is_illegal_gpa(vcpu, gpa)))\n\t\treturn kvm_emulate_instruction(vcpu, 0);\n\n\treturn kvm_mmu_page_fault(vcpu, gpa, error_code, NULL, 0);\n}\n\nstatic int handle_ept_misconfig(struct kvm_vcpu *vcpu)\n{\n\tgpa_t gpa;\n\n\t/*\n\t * A nested guest cannot optimize MMIO vmexits, because we have an\n\t * nGPA here instead of the required GPA.\n\t */\n\tgpa = vmcs_read64(GUEST_PHYSICAL_ADDRESS);\n\tif (!is_guest_mode(vcpu) &&\n\t    !kvm_io_bus_write(vcpu, KVM_FAST_MMIO_BUS, gpa, 0, NULL)) {\n\t\ttrace_kvm_fast_mmio(gpa);\n\t\treturn kvm_skip_emulated_instruction(vcpu);\n\t}\n\n\treturn kvm_mmu_page_fault(vcpu, gpa, PFERR_RSVD_MASK, NULL, 0);\n}\n\nstatic int handle_nmi_window(struct kvm_vcpu *vcpu)\n{\n\tWARN_ON_ONCE(!enable_vnmi);\n\texec_controls_clearbit(to_vmx(vcpu), CPU_BASED_NMI_WINDOW_EXITING);\n\t++vcpu->stat.nmi_window_exits;\n\tkvm_make_request(KVM_REQ_EVENT, vcpu);\n\n\treturn 1;\n}\n\nstatic int handle_invalid_guest_state(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tbool intr_window_requested;\n\tunsigned count = 130;\n\n\tintr_window_requested = exec_controls_get(vmx) &\n\t\t\t\tCPU_BASED_INTR_WINDOW_EXITING;\n\n\twhile (vmx->emulation_required && count-- != 0) {\n\t\tif (intr_window_requested && !vmx_interrupt_blocked(vcpu))\n\t\t\treturn handle_interrupt_window(&vmx->vcpu);\n\n\t\tif (kvm_test_request(KVM_REQ_EVENT, vcpu))\n\t\t\treturn 1;\n\n\t\tif (!kvm_emulate_instruction(vcpu, 0))\n\t\t\treturn 0;\n\n\t\tif (vmx->emulation_required && !vmx->rmode.vm86_active &&\n\t\t    vcpu->arch.exception.pending) {\n\t\t\tvcpu->run->exit_reason = KVM_EXIT_INTERNAL_ERROR;\n\t\t\tvcpu->run->internal.suberror =\n\t\t\t\t\t\tKVM_INTERNAL_ERROR_EMULATION;\n\t\t\tvcpu->run->internal.ndata = 0;\n\t\t\treturn 0;\n\t\t}\n\n\t\tif (vcpu->arch.halt_request) {\n\t\t\tvcpu->arch.halt_request = 0;\n\t\t\treturn kvm_vcpu_halt(vcpu);\n\t\t}\n\n\t\t/*\n\t\t * Note, return 1 and not 0, vcpu_run() will invoke\n\t\t * xfer_to_guest_mode() which will create a proper return\n\t\t * code.\n\t\t */\n\t\tif (__xfer_to_guest_mode_work_pending())\n\t\t\treturn 1;\n\t}\n\n\treturn 1;\n}\n\nstatic void grow_ple_window(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tunsigned int old = vmx->ple_window;\n\n\tvmx->ple_window = __grow_ple_window(old, ple_window,\n\t\t\t\t\t    ple_window_grow,\n\t\t\t\t\t    ple_window_max);\n\n\tif (vmx->ple_window != old) {\n\t\tvmx->ple_window_dirty = true;\n\t\ttrace_kvm_ple_window_update(vcpu->vcpu_id,\n\t\t\t\t\t    vmx->ple_window, old);\n\t}\n}\n\nstatic void shrink_ple_window(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tunsigned int old = vmx->ple_window;\n\n\tvmx->ple_window = __shrink_ple_window(old, ple_window,\n\t\t\t\t\t      ple_window_shrink,\n\t\t\t\t\t      ple_window);\n\n\tif (vmx->ple_window != old) {\n\t\tvmx->ple_window_dirty = true;\n\t\ttrace_kvm_ple_window_update(vcpu->vcpu_id,\n\t\t\t\t\t    vmx->ple_window, old);\n\t}\n}\n\nstatic void vmx_enable_tdp(void)\n{\n\tkvm_mmu_set_mask_ptes(VMX_EPT_READABLE_MASK,\n\t\tenable_ept_ad_bits ? VMX_EPT_ACCESS_BIT : 0ull,\n\t\tenable_ept_ad_bits ? VMX_EPT_DIRTY_BIT : 0ull,\n\t\t0ull, VMX_EPT_EXECUTABLE_MASK,\n\t\tcpu_has_vmx_ept_execute_only() ? 0ull : VMX_EPT_READABLE_MASK,\n\t\tVMX_EPT_RWX_MASK, 0ull);\n\n\tept_set_mmio_spte_mask();\n}\n\n/*\n * Indicate a busy-waiting vcpu in spinlock. We do not enable the PAUSE\n * exiting, so only get here on cpu with PAUSE-Loop-Exiting.\n */\nstatic int handle_pause(struct kvm_vcpu *vcpu)\n{\n\tif (!kvm_pause_in_guest(vcpu->kvm))\n\t\tgrow_ple_window(vcpu);\n\n\t/*\n\t * Intel sdm vol3 ch-25.1.3 says: The \"PAUSE-loop exiting\"\n\t * VM-execution control is ignored if CPL > 0. OTOH, KVM\n\t * never set PAUSE_EXITING and just set PLE if supported,\n\t * so the vcpu must be CPL=0 if it gets a PAUSE exit.\n\t */\n\tkvm_vcpu_on_spin(vcpu, true);\n\treturn kvm_skip_emulated_instruction(vcpu);\n}\n\nstatic int handle_nop(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_skip_emulated_instruction(vcpu);\n}\n\nstatic int handle_mwait(struct kvm_vcpu *vcpu)\n{\n\tprintk_once(KERN_WARNING \"kvm: MWAIT instruction emulated as NOP!\\n\");\n\treturn handle_nop(vcpu);\n}\n\nstatic int handle_invalid_op(struct kvm_vcpu *vcpu)\n{\n\tkvm_queue_exception(vcpu, UD_VECTOR);\n\treturn 1;\n}\n\nstatic int handle_monitor_trap(struct kvm_vcpu *vcpu)\n{\n\treturn 1;\n}\n\nstatic int handle_monitor(struct kvm_vcpu *vcpu)\n{\n\tprintk_once(KERN_WARNING \"kvm: MONITOR instruction emulated as NOP!\\n\");\n\treturn handle_nop(vcpu);\n}\n\nstatic int handle_invpcid(struct kvm_vcpu *vcpu)\n{\n\tu32 vmx_instruction_info;\n\tunsigned long type;\n\tgva_t gva;\n\tstruct {\n\t\tu64 pcid;\n\t\tu64 gla;\n\t} operand;\n\n\tif (!guest_cpuid_has(vcpu, X86_FEATURE_INVPCID)) {\n\t\tkvm_queue_exception(vcpu, UD_VECTOR);\n\t\treturn 1;\n\t}\n\n\tvmx_instruction_info = vmcs_read32(VMX_INSTRUCTION_INFO);\n\ttype = kvm_register_readl(vcpu, (vmx_instruction_info >> 28) & 0xf);\n\n\tif (type > 3) {\n\t\tkvm_inject_gp(vcpu, 0);\n\t\treturn 1;\n\t}\n\n\t/* According to the Intel instruction reference, the memory operand\n\t * is read even if it isn't needed (e.g., for type==all)\n\t */\n\tif (get_vmx_mem_address(vcpu, vmx_get_exit_qual(vcpu),\n\t\t\t\tvmx_instruction_info, false,\n\t\t\t\tsizeof(operand), &gva))\n\t\treturn 1;\n\n\treturn kvm_handle_invpcid(vcpu, type, gva);\n}\n\nstatic int handle_pml_full(struct kvm_vcpu *vcpu)\n{\n\tunsigned long exit_qualification;\n\n\ttrace_kvm_pml_full(vcpu->vcpu_id);\n\n\texit_qualification = vmx_get_exit_qual(vcpu);\n\n\t/*\n\t * PML buffer FULL happened while executing iret from NMI,\n\t * \"blocked by NMI\" bit has to be set before next VM entry.\n\t */\n\tif (!(to_vmx(vcpu)->idt_vectoring_info & VECTORING_INFO_VALID_MASK) &&\n\t\t\tenable_vnmi &&\n\t\t\t(exit_qualification & INTR_INFO_UNBLOCK_NMI))\n\t\tvmcs_set_bits(GUEST_INTERRUPTIBILITY_INFO,\n\t\t\t\tGUEST_INTR_STATE_NMI);\n\n\t/*\n\t * PML buffer already flushed at beginning of VMEXIT. Nothing to do\n\t * here.., and there's no userspace involvement needed for PML.\n\t */\n\treturn 1;\n}\n\nstatic fastpath_t handle_fastpath_preemption_timer(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\tif (!vmx->req_immediate_exit &&\n\t    !unlikely(vmx->loaded_vmcs->hv_timer_soft_disabled)) {\n\t\tkvm_lapic_expired_hv_timer(vcpu);\n\t\treturn EXIT_FASTPATH_REENTER_GUEST;\n\t}\n\n\treturn EXIT_FASTPATH_NONE;\n}\n\nstatic int handle_preemption_timer(struct kvm_vcpu *vcpu)\n{\n\thandle_fastpath_preemption_timer(vcpu);\n\treturn 1;\n}\n\n/*\n * When nested=0, all VMX instruction VM Exits filter here.  The handlers\n * are overwritten by nested_vmx_setup() when nested=1.\n */\nstatic int handle_vmx_instruction(struct kvm_vcpu *vcpu)\n{\n\tkvm_queue_exception(vcpu, UD_VECTOR);\n\treturn 1;\n}\n\nstatic int handle_encls(struct kvm_vcpu *vcpu)\n{\n\t/*\n\t * SGX virtualization is not yet supported.  There is no software\n\t * enable bit for SGX, so we have to trap ENCLS and inject a #UD\n\t * to prevent the guest from executing ENCLS.\n\t */\n\tkvm_queue_exception(vcpu, UD_VECTOR);\n\treturn 1;\n}\n\n/*\n * The exit handlers return 1 if the exit was handled fully and guest execution\n * may resume.  Otherwise they set the kvm_run parameter to indicate what needs\n * to be done to userspace and return 0.\n */\nstatic int (*kvm_vmx_exit_handlers[])(struct kvm_vcpu *vcpu) = {\n\t[EXIT_REASON_EXCEPTION_NMI]           = handle_exception_nmi,\n\t[EXIT_REASON_EXTERNAL_INTERRUPT]      = handle_external_interrupt,\n\t[EXIT_REASON_TRIPLE_FAULT]            = handle_triple_fault,\n\t[EXIT_REASON_NMI_WINDOW]\t      = handle_nmi_window,\n\t[EXIT_REASON_IO_INSTRUCTION]          = handle_io,\n\t[EXIT_REASON_CR_ACCESS]               = handle_cr,\n\t[EXIT_REASON_DR_ACCESS]               = handle_dr,\n\t[EXIT_REASON_CPUID]                   = kvm_emulate_cpuid,\n\t[EXIT_REASON_MSR_READ]                = kvm_emulate_rdmsr,\n\t[EXIT_REASON_MSR_WRITE]               = kvm_emulate_wrmsr,\n\t[EXIT_REASON_INTERRUPT_WINDOW]        = handle_interrupt_window,\n\t[EXIT_REASON_HLT]                     = kvm_emulate_halt,\n\t[EXIT_REASON_INVD]\t\t      = handle_invd,\n\t[EXIT_REASON_INVLPG]\t\t      = handle_invlpg,\n\t[EXIT_REASON_RDPMC]                   = handle_rdpmc,\n\t[EXIT_REASON_VMCALL]                  = handle_vmcall,\n\t[EXIT_REASON_VMCLEAR]\t\t      = handle_vmx_instruction,\n\t[EXIT_REASON_VMLAUNCH]\t\t      = handle_vmx_instruction,\n\t[EXIT_REASON_VMPTRLD]\t\t      = handle_vmx_instruction,\n\t[EXIT_REASON_VMPTRST]\t\t      = handle_vmx_instruction,\n\t[EXIT_REASON_VMREAD]\t\t      = handle_vmx_instruction,\n\t[EXIT_REASON_VMRESUME]\t\t      = handle_vmx_instruction,\n\t[EXIT_REASON_VMWRITE]\t\t      = handle_vmx_instruction,\n\t[EXIT_REASON_VMOFF]\t\t      = handle_vmx_instruction,\n\t[EXIT_REASON_VMON]\t\t      = handle_vmx_instruction,\n\t[EXIT_REASON_TPR_BELOW_THRESHOLD]     = handle_tpr_below_threshold,\n\t[EXIT_REASON_APIC_ACCESS]             = handle_apic_access,\n\t[EXIT_REASON_APIC_WRITE]              = handle_apic_write,\n\t[EXIT_REASON_EOI_INDUCED]             = handle_apic_eoi_induced,\n\t[EXIT_REASON_WBINVD]                  = handle_wbinvd,\n\t[EXIT_REASON_XSETBV]                  = handle_xsetbv,\n\t[EXIT_REASON_TASK_SWITCH]             = handle_task_switch,\n\t[EXIT_REASON_MCE_DURING_VMENTRY]      = handle_machine_check,\n\t[EXIT_REASON_GDTR_IDTR]\t\t      = handle_desc,\n\t[EXIT_REASON_LDTR_TR]\t\t      = handle_desc,\n\t[EXIT_REASON_EPT_VIOLATION]\t      = handle_ept_violation,\n\t[EXIT_REASON_EPT_MISCONFIG]           = handle_ept_misconfig,\n\t[EXIT_REASON_PAUSE_INSTRUCTION]       = handle_pause,\n\t[EXIT_REASON_MWAIT_INSTRUCTION]\t      = handle_mwait,\n\t[EXIT_REASON_MONITOR_TRAP_FLAG]       = handle_monitor_trap,\n\t[EXIT_REASON_MONITOR_INSTRUCTION]     = handle_monitor,\n\t[EXIT_REASON_INVEPT]                  = handle_vmx_instruction,\n\t[EXIT_REASON_INVVPID]                 = handle_vmx_instruction,\n\t[EXIT_REASON_RDRAND]                  = handle_invalid_op,\n\t[EXIT_REASON_RDSEED]                  = handle_invalid_op,\n\t[EXIT_REASON_PML_FULL]\t\t      = handle_pml_full,\n\t[EXIT_REASON_INVPCID]                 = handle_invpcid,\n\t[EXIT_REASON_VMFUNC]\t\t      = handle_vmx_instruction,\n\t[EXIT_REASON_PREEMPTION_TIMER]\t      = handle_preemption_timer,\n\t[EXIT_REASON_ENCLS]\t\t      = handle_encls,\n};\n\nstatic const int kvm_vmx_max_exit_handlers =\n\tARRAY_SIZE(kvm_vmx_exit_handlers);\n\nstatic void vmx_get_exit_info(struct kvm_vcpu *vcpu, u64 *info1, u64 *info2,\n\t\t\t      u32 *intr_info, u32 *error_code)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\t*info1 = vmx_get_exit_qual(vcpu);\n\tif (!(vmx->exit_reason & VMX_EXIT_REASONS_FAILED_VMENTRY)) {\n\t\t*info2 = vmx->idt_vectoring_info;\n\t\t*intr_info = vmx_get_intr_info(vcpu);\n\t\tif (is_exception_with_error_code(*intr_info))\n\t\t\t*error_code = vmcs_read32(VM_EXIT_INTR_ERROR_CODE);\n\t\telse\n\t\t\t*error_code = 0;\n\t} else {\n\t\t*info2 = 0;\n\t\t*intr_info = 0;\n\t\t*error_code = 0;\n\t}\n}\n\nstatic void vmx_destroy_pml_buffer(struct vcpu_vmx *vmx)\n{\n\tif (vmx->pml_pg) {\n\t\t__free_page(vmx->pml_pg);\n\t\tvmx->pml_pg = NULL;\n\t}\n}\n\nstatic void vmx_flush_pml_buffer(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tu64 *pml_buf;\n\tu16 pml_idx;\n\n\tpml_idx = vmcs_read16(GUEST_PML_INDEX);\n\n\t/* Do nothing if PML buffer is empty */\n\tif (pml_idx == (PML_ENTITY_NUM - 1))\n\t\treturn;\n\n\t/* PML index always points to next available PML buffer entity */\n\tif (pml_idx >= PML_ENTITY_NUM)\n\t\tpml_idx = 0;\n\telse\n\t\tpml_idx++;\n\n\tpml_buf = page_address(vmx->pml_pg);\n\tfor (; pml_idx < PML_ENTITY_NUM; pml_idx++) {\n\t\tu64 gpa;\n\n\t\tgpa = pml_buf[pml_idx];\n\t\tWARN_ON(gpa & (PAGE_SIZE - 1));\n\t\tkvm_vcpu_mark_page_dirty(vcpu, gpa >> PAGE_SHIFT);\n\t}\n\n\t/* reset PML index */\n\tvmcs_write16(GUEST_PML_INDEX, PML_ENTITY_NUM - 1);\n}\n\n/*\n * Flush all vcpus' PML buffer and update logged GPAs to dirty_bitmap.\n * Called before reporting dirty_bitmap to userspace.\n */\nstatic void kvm_flush_pml_buffers(struct kvm *kvm)\n{\n\tint i;\n\tstruct kvm_vcpu *vcpu;\n\t/*\n\t * We only need to kick vcpu out of guest mode here, as PML buffer\n\t * is flushed at beginning of all VMEXITs, and it's obvious that only\n\t * vcpus running in guest are possible to have unflushed GPAs in PML\n\t * buffer.\n\t */\n\tkvm_for_each_vcpu(i, vcpu, kvm)\n\t\tkvm_vcpu_kick(vcpu);\n}\n\nstatic void vmx_dump_sel(char *name, uint32_t sel)\n{\n\tpr_err(\"%s sel=0x%04x, attr=0x%05x, limit=0x%08x, base=0x%016lx\\n\",\n\t       name, vmcs_read16(sel),\n\t       vmcs_read32(sel + GUEST_ES_AR_BYTES - GUEST_ES_SELECTOR),\n\t       vmcs_read32(sel + GUEST_ES_LIMIT - GUEST_ES_SELECTOR),\n\t       vmcs_readl(sel + GUEST_ES_BASE - GUEST_ES_SELECTOR));\n}\n\nstatic void vmx_dump_dtsel(char *name, uint32_t limit)\n{\n\tpr_err(\"%s                           limit=0x%08x, base=0x%016lx\\n\",\n\t       name, vmcs_read32(limit),\n\t       vmcs_readl(limit + GUEST_GDTR_BASE - GUEST_GDTR_LIMIT));\n}\n\nvoid dump_vmcs(void)\n{\n\tu32 vmentry_ctl, vmexit_ctl;\n\tu32 cpu_based_exec_ctrl, pin_based_exec_ctrl, secondary_exec_control;\n\tunsigned long cr4;\n\tu64 efer;\n\n\tif (!dump_invalid_vmcs) {\n\t\tpr_warn_ratelimited(\"set kvm_intel.dump_invalid_vmcs=1 to dump internal KVM state.\\n\");\n\t\treturn;\n\t}\n\n\tvmentry_ctl = vmcs_read32(VM_ENTRY_CONTROLS);\n\tvmexit_ctl = vmcs_read32(VM_EXIT_CONTROLS);\n\tcpu_based_exec_ctrl = vmcs_read32(CPU_BASED_VM_EXEC_CONTROL);\n\tpin_based_exec_ctrl = vmcs_read32(PIN_BASED_VM_EXEC_CONTROL);\n\tcr4 = vmcs_readl(GUEST_CR4);\n\tefer = vmcs_read64(GUEST_IA32_EFER);\n\tsecondary_exec_control = 0;\n\tif (cpu_has_secondary_exec_ctrls())\n\t\tsecondary_exec_control = vmcs_read32(SECONDARY_VM_EXEC_CONTROL);\n\n\tpr_err(\"*** Guest State ***\\n\");\n\tpr_err(\"CR0: actual=0x%016lx, shadow=0x%016lx, gh_mask=%016lx\\n\",\n\t       vmcs_readl(GUEST_CR0), vmcs_readl(CR0_READ_SHADOW),\n\t       vmcs_readl(CR0_GUEST_HOST_MASK));\n\tpr_err(\"CR4: actual=0x%016lx, shadow=0x%016lx, gh_mask=%016lx\\n\",\n\t       cr4, vmcs_readl(CR4_READ_SHADOW), vmcs_readl(CR4_GUEST_HOST_MASK));\n\tpr_err(\"CR3 = 0x%016lx\\n\", vmcs_readl(GUEST_CR3));\n\tif ((secondary_exec_control & SECONDARY_EXEC_ENABLE_EPT) &&\n\t    (cr4 & X86_CR4_PAE) && !(efer & EFER_LMA))\n\t{\n\t\tpr_err(\"PDPTR0 = 0x%016llx  PDPTR1 = 0x%016llx\\n\",\n\t\t       vmcs_read64(GUEST_PDPTR0), vmcs_read64(GUEST_PDPTR1));\n\t\tpr_err(\"PDPTR2 = 0x%016llx  PDPTR3 = 0x%016llx\\n\",\n\t\t       vmcs_read64(GUEST_PDPTR2), vmcs_read64(GUEST_PDPTR3));\n\t}\n\tpr_err(\"RSP = 0x%016lx  RIP = 0x%016lx\\n\",\n\t       vmcs_readl(GUEST_RSP), vmcs_readl(GUEST_RIP));\n\tpr_err(\"RFLAGS=0x%08lx         DR7 = 0x%016lx\\n\",\n\t       vmcs_readl(GUEST_RFLAGS), vmcs_readl(GUEST_DR7));\n\tpr_err(\"Sysenter RSP=%016lx CS:RIP=%04x:%016lx\\n\",\n\t       vmcs_readl(GUEST_SYSENTER_ESP),\n\t       vmcs_read32(GUEST_SYSENTER_CS), vmcs_readl(GUEST_SYSENTER_EIP));\n\tvmx_dump_sel(\"CS:  \", GUEST_CS_SELECTOR);\n\tvmx_dump_sel(\"DS:  \", GUEST_DS_SELECTOR);\n\tvmx_dump_sel(\"SS:  \", GUEST_SS_SELECTOR);\n\tvmx_dump_sel(\"ES:  \", GUEST_ES_SELECTOR);\n\tvmx_dump_sel(\"FS:  \", GUEST_FS_SELECTOR);\n\tvmx_dump_sel(\"GS:  \", GUEST_GS_SELECTOR);\n\tvmx_dump_dtsel(\"GDTR:\", GUEST_GDTR_LIMIT);\n\tvmx_dump_sel(\"LDTR:\", GUEST_LDTR_SELECTOR);\n\tvmx_dump_dtsel(\"IDTR:\", GUEST_IDTR_LIMIT);\n\tvmx_dump_sel(\"TR:  \", GUEST_TR_SELECTOR);\n\tif ((vmexit_ctl & (VM_EXIT_SAVE_IA32_PAT | VM_EXIT_SAVE_IA32_EFER)) ||\n\t    (vmentry_ctl & (VM_ENTRY_LOAD_IA32_PAT | VM_ENTRY_LOAD_IA32_EFER)))\n\t\tpr_err(\"EFER =     0x%016llx  PAT = 0x%016llx\\n\",\n\t\t       efer, vmcs_read64(GUEST_IA32_PAT));\n\tpr_err(\"DebugCtl = 0x%016llx  DebugExceptions = 0x%016lx\\n\",\n\t       vmcs_read64(GUEST_IA32_DEBUGCTL),\n\t       vmcs_readl(GUEST_PENDING_DBG_EXCEPTIONS));\n\tif (cpu_has_load_perf_global_ctrl() &&\n\t    vmentry_ctl & VM_ENTRY_LOAD_IA32_PERF_GLOBAL_CTRL)\n\t\tpr_err(\"PerfGlobCtl = 0x%016llx\\n\",\n\t\t       vmcs_read64(GUEST_IA32_PERF_GLOBAL_CTRL));\n\tif (vmentry_ctl & VM_ENTRY_LOAD_BNDCFGS)\n\t\tpr_err(\"BndCfgS = 0x%016llx\\n\", vmcs_read64(GUEST_BNDCFGS));\n\tpr_err(\"Interruptibility = %08x  ActivityState = %08x\\n\",\n\t       vmcs_read32(GUEST_INTERRUPTIBILITY_INFO),\n\t       vmcs_read32(GUEST_ACTIVITY_STATE));\n\tif (secondary_exec_control & SECONDARY_EXEC_VIRTUAL_INTR_DELIVERY)\n\t\tpr_err(\"InterruptStatus = %04x\\n\",\n\t\t       vmcs_read16(GUEST_INTR_STATUS));\n\n\tpr_err(\"*** Host State ***\\n\");\n\tpr_err(\"RIP = 0x%016lx  RSP = 0x%016lx\\n\",\n\t       vmcs_readl(HOST_RIP), vmcs_readl(HOST_RSP));\n\tpr_err(\"CS=%04x SS=%04x DS=%04x ES=%04x FS=%04x GS=%04x TR=%04x\\n\",\n\t       vmcs_read16(HOST_CS_SELECTOR), vmcs_read16(HOST_SS_SELECTOR),\n\t       vmcs_read16(HOST_DS_SELECTOR), vmcs_read16(HOST_ES_SELECTOR),\n\t       vmcs_read16(HOST_FS_SELECTOR), vmcs_read16(HOST_GS_SELECTOR),\n\t       vmcs_read16(HOST_TR_SELECTOR));\n\tpr_err(\"FSBase=%016lx GSBase=%016lx TRBase=%016lx\\n\",\n\t       vmcs_readl(HOST_FS_BASE), vmcs_readl(HOST_GS_BASE),\n\t       vmcs_readl(HOST_TR_BASE));\n\tpr_err(\"GDTBase=%016lx IDTBase=%016lx\\n\",\n\t       vmcs_readl(HOST_GDTR_BASE), vmcs_readl(HOST_IDTR_BASE));\n\tpr_err(\"CR0=%016lx CR3=%016lx CR4=%016lx\\n\",\n\t       vmcs_readl(HOST_CR0), vmcs_readl(HOST_CR3),\n\t       vmcs_readl(HOST_CR4));\n\tpr_err(\"Sysenter RSP=%016lx CS:RIP=%04x:%016lx\\n\",\n\t       vmcs_readl(HOST_IA32_SYSENTER_ESP),\n\t       vmcs_read32(HOST_IA32_SYSENTER_CS),\n\t       vmcs_readl(HOST_IA32_SYSENTER_EIP));\n\tif (vmexit_ctl & (VM_EXIT_LOAD_IA32_PAT | VM_EXIT_LOAD_IA32_EFER))\n\t\tpr_err(\"EFER = 0x%016llx  PAT = 0x%016llx\\n\",\n\t\t       vmcs_read64(HOST_IA32_EFER),\n\t\t       vmcs_read64(HOST_IA32_PAT));\n\tif (cpu_has_load_perf_global_ctrl() &&\n\t    vmexit_ctl & VM_EXIT_LOAD_IA32_PERF_GLOBAL_CTRL)\n\t\tpr_err(\"PerfGlobCtl = 0x%016llx\\n\",\n\t\t       vmcs_read64(HOST_IA32_PERF_GLOBAL_CTRL));\n\n\tpr_err(\"*** Control State ***\\n\");\n\tpr_err(\"PinBased=%08x CPUBased=%08x SecondaryExec=%08x\\n\",\n\t       pin_based_exec_ctrl, cpu_based_exec_ctrl, secondary_exec_control);\n\tpr_err(\"EntryControls=%08x ExitControls=%08x\\n\", vmentry_ctl, vmexit_ctl);\n\tpr_err(\"ExceptionBitmap=%08x PFECmask=%08x PFECmatch=%08x\\n\",\n\t       vmcs_read32(EXCEPTION_BITMAP),\n\t       vmcs_read32(PAGE_FAULT_ERROR_CODE_MASK),\n\t       vmcs_read32(PAGE_FAULT_ERROR_CODE_MATCH));\n\tpr_err(\"VMEntry: intr_info=%08x errcode=%08x ilen=%08x\\n\",\n\t       vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),\n\t       vmcs_read32(VM_ENTRY_EXCEPTION_ERROR_CODE),\n\t       vmcs_read32(VM_ENTRY_INSTRUCTION_LEN));\n\tpr_err(\"VMExit: intr_info=%08x errcode=%08x ilen=%08x\\n\",\n\t       vmcs_read32(VM_EXIT_INTR_INFO),\n\t       vmcs_read32(VM_EXIT_INTR_ERROR_CODE),\n\t       vmcs_read32(VM_EXIT_INSTRUCTION_LEN));\n\tpr_err(\"        reason=%08x qualification=%016lx\\n\",\n\t       vmcs_read32(VM_EXIT_REASON), vmcs_readl(EXIT_QUALIFICATION));\n\tpr_err(\"IDTVectoring: info=%08x errcode=%08x\\n\",\n\t       vmcs_read32(IDT_VECTORING_INFO_FIELD),\n\t       vmcs_read32(IDT_VECTORING_ERROR_CODE));\n\tpr_err(\"TSC Offset = 0x%016llx\\n\", vmcs_read64(TSC_OFFSET));\n\tif (secondary_exec_control & SECONDARY_EXEC_TSC_SCALING)\n\t\tpr_err(\"TSC Multiplier = 0x%016llx\\n\",\n\t\t       vmcs_read64(TSC_MULTIPLIER));\n\tif (cpu_based_exec_ctrl & CPU_BASED_TPR_SHADOW) {\n\t\tif (secondary_exec_control & SECONDARY_EXEC_VIRTUAL_INTR_DELIVERY) {\n\t\t\tu16 status = vmcs_read16(GUEST_INTR_STATUS);\n\t\t\tpr_err(\"SVI|RVI = %02x|%02x \", status >> 8, status & 0xff);\n\t\t}\n\t\tpr_cont(\"TPR Threshold = 0x%02x\\n\", vmcs_read32(TPR_THRESHOLD));\n\t\tif (secondary_exec_control & SECONDARY_EXEC_VIRTUALIZE_APIC_ACCESSES)\n\t\t\tpr_err(\"APIC-access addr = 0x%016llx \", vmcs_read64(APIC_ACCESS_ADDR));\n\t\tpr_cont(\"virt-APIC addr = 0x%016llx\\n\", vmcs_read64(VIRTUAL_APIC_PAGE_ADDR));\n\t}\n\tif (pin_based_exec_ctrl & PIN_BASED_POSTED_INTR)\n\t\tpr_err(\"PostedIntrVec = 0x%02x\\n\", vmcs_read16(POSTED_INTR_NV));\n\tif ((secondary_exec_control & SECONDARY_EXEC_ENABLE_EPT))\n\t\tpr_err(\"EPT pointer = 0x%016llx\\n\", vmcs_read64(EPT_POINTER));\n\tif (secondary_exec_control & SECONDARY_EXEC_PAUSE_LOOP_EXITING)\n\t\tpr_err(\"PLE Gap=%08x Window=%08x\\n\",\n\t\t       vmcs_read32(PLE_GAP), vmcs_read32(PLE_WINDOW));\n\tif (secondary_exec_control & SECONDARY_EXEC_ENABLE_VPID)\n\t\tpr_err(\"Virtual processor ID = 0x%04x\\n\",\n\t\t       vmcs_read16(VIRTUAL_PROCESSOR_ID));\n}\n\n/*\n * The guest has exited.  See if we can fix it or if we need userspace\n * assistance.\n */\nstatic int vmx_handle_exit(struct kvm_vcpu *vcpu, fastpath_t exit_fastpath)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tu32 exit_reason = vmx->exit_reason;\n\tu32 vectoring_info = vmx->idt_vectoring_info;\n\n\t/*\n\t * Flush logged GPAs PML buffer, this will make dirty_bitmap more\n\t * updated. Another good is, in kvm_vm_ioctl_get_dirty_log, before\n\t * querying dirty_bitmap, we only need to kick all vcpus out of guest\n\t * mode as if vcpus is in root mode, the PML buffer must has been\n\t * flushed already.\n\t */\n\tif (enable_pml)\n\t\tvmx_flush_pml_buffer(vcpu);\n\n\t/*\n\t * We should never reach this point with a pending nested VM-Enter, and\n\t * more specifically emulation of L2 due to invalid guest state (see\n\t * below) should never happen as that means we incorrectly allowed a\n\t * nested VM-Enter with an invalid vmcs12.\n\t */\n\tWARN_ON_ONCE(vmx->nested.nested_run_pending);\n\n\t/* If guest state is invalid, start emulating */\n\tif (vmx->emulation_required)\n\t\treturn handle_invalid_guest_state(vcpu);\n\n\tif (is_guest_mode(vcpu)) {\n\t\t/*\n\t\t * The host physical addresses of some pages of guest memory\n\t\t * are loaded into the vmcs02 (e.g. vmcs12's Virtual APIC\n\t\t * Page). The CPU may write to these pages via their host\n\t\t * physical address while L2 is running, bypassing any\n\t\t * address-translation-based dirty tracking (e.g. EPT write\n\t\t * protection).\n\t\t *\n\t\t * Mark them dirty on every exit from L2 to prevent them from\n\t\t * getting out of sync with dirty tracking.\n\t\t */\n\t\tnested_mark_vmcs12_pages_dirty(vcpu);\n\n\t\tif (nested_vmx_reflect_vmexit(vcpu))\n\t\t\treturn 1;\n\t}\n\n\tif (exit_reason & VMX_EXIT_REASONS_FAILED_VMENTRY) {\n\t\tdump_vmcs();\n\t\tvcpu->run->exit_reason = KVM_EXIT_FAIL_ENTRY;\n\t\tvcpu->run->fail_entry.hardware_entry_failure_reason\n\t\t\t= exit_reason;\n\t\tvcpu->run->fail_entry.cpu = vcpu->arch.last_vmentry_cpu;\n\t\treturn 0;\n\t}\n\n\tif (unlikely(vmx->fail)) {\n\t\tdump_vmcs();\n\t\tvcpu->run->exit_reason = KVM_EXIT_FAIL_ENTRY;\n\t\tvcpu->run->fail_entry.hardware_entry_failure_reason\n\t\t\t= vmcs_read32(VM_INSTRUCTION_ERROR);\n\t\tvcpu->run->fail_entry.cpu = vcpu->arch.last_vmentry_cpu;\n\t\treturn 0;\n\t}\n\n\t/*\n\t * Note:\n\t * Do not try to fix EXIT_REASON_EPT_MISCONFIG if it caused by\n\t * delivery event since it indicates guest is accessing MMIO.\n\t * The vm-exit can be triggered again after return to guest that\n\t * will cause infinite loop.\n\t */\n\tif ((vectoring_info & VECTORING_INFO_VALID_MASK) &&\n\t\t\t(exit_reason != EXIT_REASON_EXCEPTION_NMI &&\n\t\t\texit_reason != EXIT_REASON_EPT_VIOLATION &&\n\t\t\texit_reason != EXIT_REASON_PML_FULL &&\n\t\t\texit_reason != EXIT_REASON_APIC_ACCESS &&\n\t\t\texit_reason != EXIT_REASON_TASK_SWITCH)) {\n\t\tvcpu->run->exit_reason = KVM_EXIT_INTERNAL_ERROR;\n\t\tvcpu->run->internal.suberror = KVM_INTERNAL_ERROR_DELIVERY_EV;\n\t\tvcpu->run->internal.ndata = 3;\n\t\tvcpu->run->internal.data[0] = vectoring_info;\n\t\tvcpu->run->internal.data[1] = exit_reason;\n\t\tvcpu->run->internal.data[2] = vcpu->arch.exit_qualification;\n\t\tif (exit_reason == EXIT_REASON_EPT_MISCONFIG) {\n\t\t\tvcpu->run->internal.ndata++;\n\t\t\tvcpu->run->internal.data[3] =\n\t\t\t\tvmcs_read64(GUEST_PHYSICAL_ADDRESS);\n\t\t}\n\t\tvcpu->run->internal.data[vcpu->run->internal.ndata++] =\n\t\t\tvcpu->arch.last_vmentry_cpu;\n\t\treturn 0;\n\t}\n\n\tif (unlikely(!enable_vnmi &&\n\t\t     vmx->loaded_vmcs->soft_vnmi_blocked)) {\n\t\tif (!vmx_interrupt_blocked(vcpu)) {\n\t\t\tvmx->loaded_vmcs->soft_vnmi_blocked = 0;\n\t\t} else if (vmx->loaded_vmcs->vnmi_blocked_time > 1000000000LL &&\n\t\t\t   vcpu->arch.nmi_pending) {\n\t\t\t/*\n\t\t\t * This CPU don't support us in finding the end of an\n\t\t\t * NMI-blocked window if the guest runs with IRQs\n\t\t\t * disabled. So we pull the trigger after 1 s of\n\t\t\t * futile waiting, but inform the user about this.\n\t\t\t */\n\t\t\tprintk(KERN_WARNING \"%s: Breaking out of NMI-blocked \"\n\t\t\t       \"state on VCPU %d after 1 s timeout\\n\",\n\t\t\t       __func__, vcpu->vcpu_id);\n\t\t\tvmx->loaded_vmcs->soft_vnmi_blocked = 0;\n\t\t}\n\t}\n\n\tif (exit_fastpath != EXIT_FASTPATH_NONE)\n\t\treturn 1;\n\n\tif (exit_reason >= kvm_vmx_max_exit_handlers)\n\t\tgoto unexpected_vmexit;\n#ifdef CONFIG_RETPOLINE\n\tif (exit_reason == EXIT_REASON_MSR_WRITE)\n\t\treturn kvm_emulate_wrmsr(vcpu);\n\telse if (exit_reason == EXIT_REASON_PREEMPTION_TIMER)\n\t\treturn handle_preemption_timer(vcpu);\n\telse if (exit_reason == EXIT_REASON_INTERRUPT_WINDOW)\n\t\treturn handle_interrupt_window(vcpu);\n\telse if (exit_reason == EXIT_REASON_EXTERNAL_INTERRUPT)\n\t\treturn handle_external_interrupt(vcpu);\n\telse if (exit_reason == EXIT_REASON_HLT)\n\t\treturn kvm_emulate_halt(vcpu);\n\telse if (exit_reason == EXIT_REASON_EPT_MISCONFIG)\n\t\treturn handle_ept_misconfig(vcpu);\n#endif\n\n\texit_reason = array_index_nospec(exit_reason,\n\t\t\t\t\t kvm_vmx_max_exit_handlers);\n\tif (!kvm_vmx_exit_handlers[exit_reason])\n\t\tgoto unexpected_vmexit;\n\n\treturn kvm_vmx_exit_handlers[exit_reason](vcpu);\n\nunexpected_vmexit:\n\tvcpu_unimpl(vcpu, \"vmx: unexpected exit reason 0x%x\\n\", exit_reason);\n\tdump_vmcs();\n\tvcpu->run->exit_reason = KVM_EXIT_INTERNAL_ERROR;\n\tvcpu->run->internal.suberror =\n\t\t\tKVM_INTERNAL_ERROR_UNEXPECTED_EXIT_REASON;\n\tvcpu->run->internal.ndata = 2;\n\tvcpu->run->internal.data[0] = exit_reason;\n\tvcpu->run->internal.data[1] = vcpu->arch.last_vmentry_cpu;\n\treturn 0;\n}\n\n/*\n * Software based L1D cache flush which is used when microcode providing\n * the cache control MSR is not loaded.\n *\n * The L1D cache is 32 KiB on Nehalem and later microarchitectures, but to\n * flush it is required to read in 64 KiB because the replacement algorithm\n * is not exactly LRU. This could be sized at runtime via topology\n * information but as all relevant affected CPUs have 32KiB L1D cache size\n * there is no point in doing so.\n */\nstatic noinstr void vmx_l1d_flush(struct kvm_vcpu *vcpu)\n{\n\tint size = PAGE_SIZE << L1D_CACHE_ORDER;\n\n\t/*\n\t * This code is only executed when the the flush mode is 'cond' or\n\t * 'always'\n\t */\n\tif (static_branch_likely(&vmx_l1d_flush_cond)) {\n\t\tbool flush_l1d;\n\n\t\t/*\n\t\t * Clear the per-vcpu flush bit, it gets set again\n\t\t * either from vcpu_run() or from one of the unsafe\n\t\t * VMEXIT handlers.\n\t\t */\n\t\tflush_l1d = vcpu->arch.l1tf_flush_l1d;\n\t\tvcpu->arch.l1tf_flush_l1d = false;\n\n\t\t/*\n\t\t * Clear the per-cpu flush bit, it gets set again from\n\t\t * the interrupt handlers.\n\t\t */\n\t\tflush_l1d |= kvm_get_cpu_l1tf_flush_l1d();\n\t\tkvm_clear_cpu_l1tf_flush_l1d();\n\n\t\tif (!flush_l1d)\n\t\t\treturn;\n\t}\n\n\tvcpu->stat.l1d_flush++;\n\n\tif (static_cpu_has(X86_FEATURE_FLUSH_L1D)) {\n\t\tnative_wrmsrl(MSR_IA32_FLUSH_CMD, L1D_FLUSH);\n\t\treturn;\n\t}\n\n\tasm volatile(\n\t\t/* First ensure the pages are in the TLB */\n\t\t\"xorl\t%%eax, %%eax\\n\"\n\t\t\".Lpopulate_tlb:\\n\\t\"\n\t\t\"movzbl\t(%[flush_pages], %%\" _ASM_AX \"), %%ecx\\n\\t\"\n\t\t\"addl\t$4096, %%eax\\n\\t\"\n\t\t\"cmpl\t%%eax, %[size]\\n\\t\"\n\t\t\"jne\t.Lpopulate_tlb\\n\\t\"\n\t\t\"xorl\t%%eax, %%eax\\n\\t\"\n\t\t\"cpuid\\n\\t\"\n\t\t/* Now fill the cache */\n\t\t\"xorl\t%%eax, %%eax\\n\"\n\t\t\".Lfill_cache:\\n\"\n\t\t\"movzbl\t(%[flush_pages], %%\" _ASM_AX \"), %%ecx\\n\\t\"\n\t\t\"addl\t$64, %%eax\\n\\t\"\n\t\t\"cmpl\t%%eax, %[size]\\n\\t\"\n\t\t\"jne\t.Lfill_cache\\n\\t\"\n\t\t\"lfence\\n\"\n\t\t:: [flush_pages] \"r\" (vmx_l1d_flush_pages),\n\t\t    [size] \"r\" (size)\n\t\t: \"eax\", \"ebx\", \"ecx\", \"edx\");\n}\n\nstatic void update_cr8_intercept(struct kvm_vcpu *vcpu, int tpr, int irr)\n{\n\tstruct vmcs12 *vmcs12 = get_vmcs12(vcpu);\n\tint tpr_threshold;\n\n\tif (is_guest_mode(vcpu) &&\n\t\tnested_cpu_has(vmcs12, CPU_BASED_TPR_SHADOW))\n\t\treturn;\n\n\ttpr_threshold = (irr == -1 || tpr < irr) ? 0 : irr;\n\tif (is_guest_mode(vcpu))\n\t\tto_vmx(vcpu)->nested.l1_tpr_threshold = tpr_threshold;\n\telse\n\t\tvmcs_write32(TPR_THRESHOLD, tpr_threshold);\n}\n\nvoid vmx_set_virtual_apic_mode(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tu32 sec_exec_control;\n\n\tif (!lapic_in_kernel(vcpu))\n\t\treturn;\n\n\tif (!flexpriority_enabled &&\n\t    !cpu_has_vmx_virtualize_x2apic_mode())\n\t\treturn;\n\n\t/* Postpone execution until vmcs01 is the current VMCS. */\n\tif (is_guest_mode(vcpu)) {\n\t\tvmx->nested.change_vmcs01_virtual_apic_mode = true;\n\t\treturn;\n\t}\n\n\tsec_exec_control = secondary_exec_controls_get(vmx);\n\tsec_exec_control &= ~(SECONDARY_EXEC_VIRTUALIZE_APIC_ACCESSES |\n\t\t\t      SECONDARY_EXEC_VIRTUALIZE_X2APIC_MODE);\n\n\tswitch (kvm_get_apic_mode(vcpu)) {\n\tcase LAPIC_MODE_INVALID:\n\t\tWARN_ONCE(true, \"Invalid local APIC state\");\n\tcase LAPIC_MODE_DISABLED:\n\t\tbreak;\n\tcase LAPIC_MODE_XAPIC:\n\t\tif (flexpriority_enabled) {\n\t\t\tsec_exec_control |=\n\t\t\t\tSECONDARY_EXEC_VIRTUALIZE_APIC_ACCESSES;\n\t\t\tkvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);\n\n\t\t\t/*\n\t\t\t * Flush the TLB, reloading the APIC access page will\n\t\t\t * only do so if its physical address has changed, but\n\t\t\t * the guest may have inserted a non-APIC mapping into\n\t\t\t * the TLB while the APIC access page was disabled.\n\t\t\t */\n\t\t\tkvm_make_request(KVM_REQ_TLB_FLUSH_CURRENT, vcpu);\n\t\t}\n\t\tbreak;\n\tcase LAPIC_MODE_X2APIC:\n\t\tif (cpu_has_vmx_virtualize_x2apic_mode())\n\t\t\tsec_exec_control |=\n\t\t\t\tSECONDARY_EXEC_VIRTUALIZE_X2APIC_MODE;\n\t\tbreak;\n\t}\n\tsecondary_exec_controls_set(vmx, sec_exec_control);\n\n\tvmx_update_msr_bitmap(vcpu);\n}\n\nstatic void vmx_set_apic_access_page_addr(struct kvm_vcpu *vcpu)\n{\n\tstruct page *page;\n\n\t/* Defer reload until vmcs01 is the current VMCS. */\n\tif (is_guest_mode(vcpu)) {\n\t\tto_vmx(vcpu)->nested.reload_vmcs01_apic_access_page = true;\n\t\treturn;\n\t}\n\n\tif (!(secondary_exec_controls_get(to_vmx(vcpu)) &\n\t    SECONDARY_EXEC_VIRTUALIZE_APIC_ACCESSES))\n\t\treturn;\n\n\tpage = gfn_to_page(vcpu->kvm, APIC_DEFAULT_PHYS_BASE >> PAGE_SHIFT);\n\tif (is_error_page(page))\n\t\treturn;\n\n\tvmcs_write64(APIC_ACCESS_ADDR, page_to_phys(page));\n\tvmx_flush_tlb_current(vcpu);\n\n\t/*\n\t * Do not pin apic access page in memory, the MMU notifier\n\t * will call us again if it is migrated or swapped out.\n\t */\n\tput_page(page);\n}\n\nstatic void vmx_hwapic_isr_update(struct kvm_vcpu *vcpu, int max_isr)\n{\n\tu16 status;\n\tu8 old;\n\n\tif (max_isr == -1)\n\t\tmax_isr = 0;\n\n\tstatus = vmcs_read16(GUEST_INTR_STATUS);\n\told = status >> 8;\n\tif (max_isr != old) {\n\t\tstatus &= 0xff;\n\t\tstatus |= max_isr << 8;\n\t\tvmcs_write16(GUEST_INTR_STATUS, status);\n\t}\n}\n\nstatic void vmx_set_rvi(int vector)\n{\n\tu16 status;\n\tu8 old;\n\n\tif (vector == -1)\n\t\tvector = 0;\n\n\tstatus = vmcs_read16(GUEST_INTR_STATUS);\n\told = (u8)status & 0xff;\n\tif ((u8)vector != old) {\n\t\tstatus &= ~0xff;\n\t\tstatus |= (u8)vector;\n\t\tvmcs_write16(GUEST_INTR_STATUS, status);\n\t}\n}\n\nstatic void vmx_hwapic_irr_update(struct kvm_vcpu *vcpu, int max_irr)\n{\n\t/*\n\t * When running L2, updating RVI is only relevant when\n\t * vmcs12 virtual-interrupt-delivery enabled.\n\t * However, it can be enabled only when L1 also\n\t * intercepts external-interrupts and in that case\n\t * we should not update vmcs02 RVI but instead intercept\n\t * interrupt. Therefore, do nothing when running L2.\n\t */\n\tif (!is_guest_mode(vcpu))\n\t\tvmx_set_rvi(max_irr);\n}\n\nstatic int vmx_sync_pir_to_irr(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tint max_irr;\n\tbool max_irr_updated;\n\n\tWARN_ON(!vcpu->arch.apicv_active);\n\tif (pi_test_on(&vmx->pi_desc)) {\n\t\tpi_clear_on(&vmx->pi_desc);\n\t\t/*\n\t\t * IOMMU can write to PID.ON, so the barrier matters even on UP.\n\t\t * But on x86 this is just a compiler barrier anyway.\n\t\t */\n\t\tsmp_mb__after_atomic();\n\t\tmax_irr_updated =\n\t\t\tkvm_apic_update_irr(vcpu, vmx->pi_desc.pir, &max_irr);\n\n\t\t/*\n\t\t * If we are running L2 and L1 has a new pending interrupt\n\t\t * which can be injected, we should re-evaluate\n\t\t * what should be done with this new L1 interrupt.\n\t\t * If L1 intercepts external-interrupts, we should\n\t\t * exit from L2 to L1. Otherwise, interrupt should be\n\t\t * delivered directly to L2.\n\t\t */\n\t\tif (is_guest_mode(vcpu) && max_irr_updated) {\n\t\t\tif (nested_exit_on_intr(vcpu))\n\t\t\t\tkvm_vcpu_exiting_guest_mode(vcpu);\n\t\t\telse\n\t\t\t\tkvm_make_request(KVM_REQ_EVENT, vcpu);\n\t\t}\n\t} else {\n\t\tmax_irr = kvm_lapic_find_highest_irr(vcpu);\n\t}\n\tvmx_hwapic_irr_update(vcpu, max_irr);\n\treturn max_irr;\n}\n\nstatic void vmx_load_eoi_exitmap(struct kvm_vcpu *vcpu, u64 *eoi_exit_bitmap)\n{\n\tif (!kvm_vcpu_apicv_active(vcpu))\n\t\treturn;\n\n\tvmcs_write64(EOI_EXIT_BITMAP0, eoi_exit_bitmap[0]);\n\tvmcs_write64(EOI_EXIT_BITMAP1, eoi_exit_bitmap[1]);\n\tvmcs_write64(EOI_EXIT_BITMAP2, eoi_exit_bitmap[2]);\n\tvmcs_write64(EOI_EXIT_BITMAP3, eoi_exit_bitmap[3]);\n}\n\nstatic void vmx_apicv_post_state_restore(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\tpi_clear_on(&vmx->pi_desc);\n\tmemset(vmx->pi_desc.pir, 0, sizeof(vmx->pi_desc.pir));\n}\n\nvoid vmx_do_interrupt_nmi_irqoff(unsigned long entry);\n\nstatic void handle_interrupt_nmi_irqoff(struct kvm_vcpu *vcpu, u32 intr_info)\n{\n\tunsigned int vector = intr_info & INTR_INFO_VECTOR_MASK;\n\tgate_desc *desc = (gate_desc *)host_idt_base + vector;\n\n\tkvm_before_interrupt(vcpu);\n\tvmx_do_interrupt_nmi_irqoff(gate_offset(desc));\n\tkvm_after_interrupt(vcpu);\n}\n\nstatic void handle_exception_nmi_irqoff(struct vcpu_vmx *vmx)\n{\n\tu32 intr_info = vmx_get_intr_info(&vmx->vcpu);\n\n\t/* if exit due to PF check for async PF */\n\tif (is_page_fault(intr_info))\n\t\tvmx->vcpu.arch.apf.host_apf_flags = kvm_read_and_reset_apf_flags();\n\t/* Handle machine checks before interrupts are enabled */\n\telse if (is_machine_check(intr_info))\n\t\tkvm_machine_check();\n\t/* We need to handle NMIs before interrupts are enabled */\n\telse if (is_nmi(intr_info))\n\t\thandle_interrupt_nmi_irqoff(&vmx->vcpu, intr_info);\n}\n\nstatic void handle_external_interrupt_irqoff(struct kvm_vcpu *vcpu)\n{\n\tu32 intr_info = vmx_get_intr_info(vcpu);\n\n\tif (WARN_ONCE(!is_external_intr(intr_info),\n\t    \"KVM: unexpected VM-Exit interrupt info: 0x%x\", intr_info))\n\t\treturn;\n\n\thandle_interrupt_nmi_irqoff(vcpu, intr_info);\n}\n\nstatic void vmx_handle_exit_irqoff(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\tif (vmx->exit_reason == EXIT_REASON_EXTERNAL_INTERRUPT)\n\t\thandle_external_interrupt_irqoff(vcpu);\n\telse if (vmx->exit_reason == EXIT_REASON_EXCEPTION_NMI)\n\t\thandle_exception_nmi_irqoff(vmx);\n}\n\nstatic bool vmx_has_emulated_msr(u32 index)\n{\n\tswitch (index) {\n\tcase MSR_IA32_SMBASE:\n\t\t/*\n\t\t * We cannot do SMM unless we can run the guest in big\n\t\t * real mode.\n\t\t */\n\t\treturn enable_unrestricted_guest || emulate_invalid_guest_state;\n\tcase MSR_IA32_VMX_BASIC ... MSR_IA32_VMX_VMFUNC:\n\t\treturn nested;\n\tcase MSR_AMD64_VIRT_SPEC_CTRL:\n\t\t/* This is AMD only.  */\n\t\treturn false;\n\tdefault:\n\t\treturn true;\n\t}\n}\n\nstatic void vmx_recover_nmi_blocking(struct vcpu_vmx *vmx)\n{\n\tu32 exit_intr_info;\n\tbool unblock_nmi;\n\tu8 vector;\n\tbool idtv_info_valid;\n\n\tidtv_info_valid = vmx->idt_vectoring_info & VECTORING_INFO_VALID_MASK;\n\n\tif (enable_vnmi) {\n\t\tif (vmx->loaded_vmcs->nmi_known_unmasked)\n\t\t\treturn;\n\n\t\texit_intr_info = vmx_get_intr_info(&vmx->vcpu);\n\t\tunblock_nmi = (exit_intr_info & INTR_INFO_UNBLOCK_NMI) != 0;\n\t\tvector = exit_intr_info & INTR_INFO_VECTOR_MASK;\n\t\t/*\n\t\t * SDM 3: 27.7.1.2 (September 2008)\n\t\t * Re-set bit \"block by NMI\" before VM entry if vmexit caused by\n\t\t * a guest IRET fault.\n\t\t * SDM 3: 23.2.2 (September 2008)\n\t\t * Bit 12 is undefined in any of the following cases:\n\t\t *  If the VM exit sets the valid bit in the IDT-vectoring\n\t\t *   information field.\n\t\t *  If the VM exit is due to a double fault.\n\t\t */\n\t\tif ((exit_intr_info & INTR_INFO_VALID_MASK) && unblock_nmi &&\n\t\t    vector != DF_VECTOR && !idtv_info_valid)\n\t\t\tvmcs_set_bits(GUEST_INTERRUPTIBILITY_INFO,\n\t\t\t\t      GUEST_INTR_STATE_NMI);\n\t\telse\n\t\t\tvmx->loaded_vmcs->nmi_known_unmasked =\n\t\t\t\t!(vmcs_read32(GUEST_INTERRUPTIBILITY_INFO)\n\t\t\t\t  & GUEST_INTR_STATE_NMI);\n\t} else if (unlikely(vmx->loaded_vmcs->soft_vnmi_blocked))\n\t\tvmx->loaded_vmcs->vnmi_blocked_time +=\n\t\t\tktime_to_ns(ktime_sub(ktime_get(),\n\t\t\t\t\t      vmx->loaded_vmcs->entry_time));\n}\n\nstatic void __vmx_complete_interrupts(struct kvm_vcpu *vcpu,\n\t\t\t\t      u32 idt_vectoring_info,\n\t\t\t\t      int instr_len_field,\n\t\t\t\t      int error_code_field)\n{\n\tu8 vector;\n\tint type;\n\tbool idtv_info_valid;\n\n\tidtv_info_valid = idt_vectoring_info & VECTORING_INFO_VALID_MASK;\n\n\tvcpu->arch.nmi_injected = false;\n\tkvm_clear_exception_queue(vcpu);\n\tkvm_clear_interrupt_queue(vcpu);\n\n\tif (!idtv_info_valid)\n\t\treturn;\n\n\tkvm_make_request(KVM_REQ_EVENT, vcpu);\n\n\tvector = idt_vectoring_info & VECTORING_INFO_VECTOR_MASK;\n\ttype = idt_vectoring_info & VECTORING_INFO_TYPE_MASK;\n\n\tswitch (type) {\n\tcase INTR_TYPE_NMI_INTR:\n\t\tvcpu->arch.nmi_injected = true;\n\t\t/*\n\t\t * SDM 3: 27.7.1.2 (September 2008)\n\t\t * Clear bit \"block by NMI\" before VM entry if a NMI\n\t\t * delivery faulted.\n\t\t */\n\t\tvmx_set_nmi_mask(vcpu, false);\n\t\tbreak;\n\tcase INTR_TYPE_SOFT_EXCEPTION:\n\t\tvcpu->arch.event_exit_inst_len = vmcs_read32(instr_len_field);\n\t\tfallthrough;\n\tcase INTR_TYPE_HARD_EXCEPTION:\n\t\tif (idt_vectoring_info & VECTORING_INFO_DELIVER_CODE_MASK) {\n\t\t\tu32 err = vmcs_read32(error_code_field);\n\t\t\tkvm_requeue_exception_e(vcpu, vector, err);\n\t\t} else\n\t\t\tkvm_requeue_exception(vcpu, vector);\n\t\tbreak;\n\tcase INTR_TYPE_SOFT_INTR:\n\t\tvcpu->arch.event_exit_inst_len = vmcs_read32(instr_len_field);\n\t\tfallthrough;\n\tcase INTR_TYPE_EXT_INTR:\n\t\tkvm_queue_interrupt(vcpu, vector, type == INTR_TYPE_SOFT_INTR);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n}\n\nstatic void vmx_complete_interrupts(struct vcpu_vmx *vmx)\n{\n\t__vmx_complete_interrupts(&vmx->vcpu, vmx->idt_vectoring_info,\n\t\t\t\t  VM_EXIT_INSTRUCTION_LEN,\n\t\t\t\t  IDT_VECTORING_ERROR_CODE);\n}\n\nstatic void vmx_cancel_injection(struct kvm_vcpu *vcpu)\n{\n\t__vmx_complete_interrupts(vcpu,\n\t\t\t\t  vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),\n\t\t\t\t  VM_ENTRY_INSTRUCTION_LEN,\n\t\t\t\t  VM_ENTRY_EXCEPTION_ERROR_CODE);\n\n\tvmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);\n}\n\nstatic void atomic_switch_perf_msrs(struct vcpu_vmx *vmx)\n{\n\tint i, nr_msrs;\n\tstruct perf_guest_switch_msr *msrs;\n\n\tmsrs = perf_guest_get_msrs(&nr_msrs);\n\n\tif (!msrs)\n\t\treturn;\n\n\tfor (i = 0; i < nr_msrs; i++)\n\t\tif (msrs[i].host == msrs[i].guest)\n\t\t\tclear_atomic_switch_msr(vmx, msrs[i].msr);\n\t\telse\n\t\t\tadd_atomic_switch_msr(vmx, msrs[i].msr, msrs[i].guest,\n\t\t\t\t\tmsrs[i].host, false);\n}\n\nstatic void vmx_update_hv_timer(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tu64 tscl;\n\tu32 delta_tsc;\n\n\tif (vmx->req_immediate_exit) {\n\t\tvmcs_write32(VMX_PREEMPTION_TIMER_VALUE, 0);\n\t\tvmx->loaded_vmcs->hv_timer_soft_disabled = false;\n\t} else if (vmx->hv_deadline_tsc != -1) {\n\t\ttscl = rdtsc();\n\t\tif (vmx->hv_deadline_tsc > tscl)\n\t\t\t/* set_hv_timer ensures the delta fits in 32-bits */\n\t\t\tdelta_tsc = (u32)((vmx->hv_deadline_tsc - tscl) >>\n\t\t\t\tcpu_preemption_timer_multi);\n\t\telse\n\t\t\tdelta_tsc = 0;\n\n\t\tvmcs_write32(VMX_PREEMPTION_TIMER_VALUE, delta_tsc);\n\t\tvmx->loaded_vmcs->hv_timer_soft_disabled = false;\n\t} else if (!vmx->loaded_vmcs->hv_timer_soft_disabled) {\n\t\tvmcs_write32(VMX_PREEMPTION_TIMER_VALUE, -1);\n\t\tvmx->loaded_vmcs->hv_timer_soft_disabled = true;\n\t}\n}\n\nvoid noinstr vmx_update_host_rsp(struct vcpu_vmx *vmx, unsigned long host_rsp)\n{\n\tif (unlikely(host_rsp != vmx->loaded_vmcs->host_state.rsp)) {\n\t\tvmx->loaded_vmcs->host_state.rsp = host_rsp;\n\t\tvmcs_writel(HOST_RSP, host_rsp);\n\t}\n}\n\nstatic fastpath_t vmx_exit_handlers_fastpath(struct kvm_vcpu *vcpu)\n{\n\tswitch (to_vmx(vcpu)->exit_reason) {\n\tcase EXIT_REASON_MSR_WRITE:\n\t\treturn handle_fastpath_set_msr_irqoff(vcpu);\n\tcase EXIT_REASON_PREEMPTION_TIMER:\n\t\treturn handle_fastpath_preemption_timer(vcpu);\n\tdefault:\n\t\treturn EXIT_FASTPATH_NONE;\n\t}\n}\n\nbool __vmx_vcpu_run(struct vcpu_vmx *vmx, unsigned long *regs, bool launched);\n\nstatic noinstr void vmx_vcpu_enter_exit(struct kvm_vcpu *vcpu,\n\t\t\t\t\tstruct vcpu_vmx *vmx)\n{\n\t/*\n\t * VMENTER enables interrupts (host state), but the kernel state is\n\t * interrupts disabled when this is invoked. Also tell RCU about\n\t * it. This is the same logic as for exit_to_user_mode().\n\t *\n\t * This ensures that e.g. latency analysis on the host observes\n\t * guest mode as interrupt enabled.\n\t *\n\t * guest_enter_irqoff() informs context tracking about the\n\t * transition to guest mode and if enabled adjusts RCU state\n\t * accordingly.\n\t */\n\tinstrumentation_begin();\n\ttrace_hardirqs_on_prepare();\n\tlockdep_hardirqs_on_prepare(CALLER_ADDR0);\n\tinstrumentation_end();\n\n\tguest_enter_irqoff();\n\tlockdep_hardirqs_on(CALLER_ADDR0);\n\n\t/* L1D Flush includes CPU buffer clear to mitigate MDS */\n\tif (static_branch_unlikely(&vmx_l1d_should_flush))\n\t\tvmx_l1d_flush(vcpu);\n\telse if (static_branch_unlikely(&mds_user_clear))\n\t\tmds_clear_cpu_buffers();\n\n\tif (vcpu->arch.cr2 != native_read_cr2())\n\t\tnative_write_cr2(vcpu->arch.cr2);\n\n\tvmx->fail = __vmx_vcpu_run(vmx, (unsigned long *)&vcpu->arch.regs,\n\t\t\t\t   vmx->loaded_vmcs->launched);\n\n\tvcpu->arch.cr2 = native_read_cr2();\n\n\t/*\n\t * VMEXIT disables interrupts (host state), but tracing and lockdep\n\t * have them in state 'on' as recorded before entering guest mode.\n\t * Same as enter_from_user_mode().\n\t *\n\t * guest_exit_irqoff() restores host context and reinstates RCU if\n\t * enabled and required.\n\t *\n\t * This needs to be done before the below as native_read_msr()\n\t * contains a tracepoint and x86_spec_ctrl_restore_host() calls\n\t * into world and some more.\n\t */\n\tlockdep_hardirqs_off(CALLER_ADDR0);\n\tguest_exit_irqoff();\n\n\tinstrumentation_begin();\n\ttrace_hardirqs_off_finish();\n\tinstrumentation_end();\n}\n\nstatic fastpath_t vmx_vcpu_run(struct kvm_vcpu *vcpu)\n{\n\tfastpath_t exit_fastpath;\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tunsigned long cr3, cr4;\n\nreenter_guest:\n\t/* Record the guest's net vcpu time for enforced NMI injections. */\n\tif (unlikely(!enable_vnmi &&\n\t\t     vmx->loaded_vmcs->soft_vnmi_blocked))\n\t\tvmx->loaded_vmcs->entry_time = ktime_get();\n\n\t/* Don't enter VMX if guest state is invalid, let the exit handler\n\t   start emulation until we arrive back to a valid state */\n\tif (vmx->emulation_required)\n\t\treturn EXIT_FASTPATH_NONE;\n\n\tif (vmx->ple_window_dirty) {\n\t\tvmx->ple_window_dirty = false;\n\t\tvmcs_write32(PLE_WINDOW, vmx->ple_window);\n\t}\n\n\t/*\n\t * We did this in prepare_switch_to_guest, because it needs to\n\t * be within srcu_read_lock.\n\t */\n\tWARN_ON_ONCE(vmx->nested.need_vmcs12_to_shadow_sync);\n\n\tif (kvm_register_is_dirty(vcpu, VCPU_REGS_RSP))\n\t\tvmcs_writel(GUEST_RSP, vcpu->arch.regs[VCPU_REGS_RSP]);\n\tif (kvm_register_is_dirty(vcpu, VCPU_REGS_RIP))\n\t\tvmcs_writel(GUEST_RIP, vcpu->arch.regs[VCPU_REGS_RIP]);\n\n\tcr3 = __get_current_cr3_fast();\n\tif (unlikely(cr3 != vmx->loaded_vmcs->host_state.cr3)) {\n\t\tvmcs_writel(HOST_CR3, cr3);\n\t\tvmx->loaded_vmcs->host_state.cr3 = cr3;\n\t}\n\n\tcr4 = cr4_read_shadow();\n\tif (unlikely(cr4 != vmx->loaded_vmcs->host_state.cr4)) {\n\t\tvmcs_writel(HOST_CR4, cr4);\n\t\tvmx->loaded_vmcs->host_state.cr4 = cr4;\n\t}\n\n\t/* When single-stepping over STI and MOV SS, we must clear the\n\t * corresponding interruptibility bits in the guest state. Otherwise\n\t * vmentry fails as it then expects bit 14 (BS) in pending debug\n\t * exceptions being set, but that's not correct for the guest debugging\n\t * case. */\n\tif (vcpu->guest_debug & KVM_GUESTDBG_SINGLESTEP)\n\t\tvmx_set_interrupt_shadow(vcpu, 0);\n\n\tkvm_load_guest_xsave_state(vcpu);\n\n\tpt_guest_enter(vmx);\n\n\tatomic_switch_perf_msrs(vmx);\n\n\tif (enable_preemption_timer)\n\t\tvmx_update_hv_timer(vcpu);\n\n\tkvm_wait_lapic_expire(vcpu);\n\n\t/*\n\t * If this vCPU has touched SPEC_CTRL, restore the guest's value if\n\t * it's non-zero. Since vmentry is serialising on affected CPUs, there\n\t * is no need to worry about the conditional branch over the wrmsr\n\t * being speculatively taken.\n\t */\n\tx86_spec_ctrl_set_guest(vmx->spec_ctrl, 0);\n\n\t/* The actual VMENTER/EXIT is in the .noinstr.text section. */\n\tvmx_vcpu_enter_exit(vcpu, vmx);\n\n\t/*\n\t * We do not use IBRS in the kernel. If this vCPU has used the\n\t * SPEC_CTRL MSR it may have left it on; save the value and\n\t * turn it off. This is much more efficient than blindly adding\n\t * it to the atomic save/restore list. Especially as the former\n\t * (Saving guest MSRs on vmexit) doesn't even exist in KVM.\n\t *\n\t * For non-nested case:\n\t * If the L01 MSR bitmap does not intercept the MSR, then we need to\n\t * save it.\n\t *\n\t * For nested case:\n\t * If the L02 MSR bitmap does not intercept the MSR, then we need to\n\t * save it.\n\t */\n\tif (unlikely(!msr_write_intercepted(vcpu, MSR_IA32_SPEC_CTRL)))\n\t\tvmx->spec_ctrl = native_read_msr(MSR_IA32_SPEC_CTRL);\n\n\tx86_spec_ctrl_restore_host(vmx->spec_ctrl, 0);\n\n\t/* All fields are clean at this point */\n\tif (static_branch_unlikely(&enable_evmcs))\n\t\tcurrent_evmcs->hv_clean_fields |=\n\t\t\tHV_VMX_ENLIGHTENED_CLEAN_FIELD_ALL;\n\n\tif (static_branch_unlikely(&enable_evmcs))\n\t\tcurrent_evmcs->hv_vp_id = vcpu->arch.hyperv.vp_index;\n\n\t/* MSR_IA32_DEBUGCTLMSR is zeroed on vmexit. Restore it if needed */\n\tif (vmx->host_debugctlmsr)\n\t\tupdate_debugctlmsr(vmx->host_debugctlmsr);\n\n#ifndef CONFIG_X86_64\n\t/*\n\t * The sysexit path does not restore ds/es, so we must set them to\n\t * a reasonable value ourselves.\n\t *\n\t * We can't defer this to vmx_prepare_switch_to_host() since that\n\t * function may be executed in interrupt context, which saves and\n\t * restore segments around it, nullifying its effect.\n\t */\n\tloadsegment(ds, __USER_DS);\n\tloadsegment(es, __USER_DS);\n#endif\n\n\tvmx_register_cache_reset(vcpu);\n\n\tpt_guest_exit(vmx);\n\n\tkvm_load_host_xsave_state(vcpu);\n\n\tvmx->nested.nested_run_pending = 0;\n\tvmx->idt_vectoring_info = 0;\n\n\tif (unlikely(vmx->fail)) {\n\t\tvmx->exit_reason = 0xdead;\n\t\treturn EXIT_FASTPATH_NONE;\n\t}\n\n\tvmx->exit_reason = vmcs_read32(VM_EXIT_REASON);\n\tif (unlikely((u16)vmx->exit_reason == EXIT_REASON_MCE_DURING_VMENTRY))\n\t\tkvm_machine_check();\n\n\ttrace_kvm_exit(vmx->exit_reason, vcpu, KVM_ISA_VMX);\n\n\tif (unlikely(vmx->exit_reason & VMX_EXIT_REASONS_FAILED_VMENTRY))\n\t\treturn EXIT_FASTPATH_NONE;\n\n\tvmx->loaded_vmcs->launched = 1;\n\tvmx->idt_vectoring_info = vmcs_read32(IDT_VECTORING_INFO_FIELD);\n\n\tvmx_recover_nmi_blocking(vmx);\n\tvmx_complete_interrupts(vmx);\n\n\tif (is_guest_mode(vcpu))\n\t\treturn EXIT_FASTPATH_NONE;\n\n\texit_fastpath = vmx_exit_handlers_fastpath(vcpu);\n\tif (exit_fastpath == EXIT_FASTPATH_REENTER_GUEST) {\n\t\tif (!kvm_vcpu_exit_request(vcpu)) {\n\t\t\t/*\n\t\t\t * FIXME: this goto should be a loop in vcpu_enter_guest,\n\t\t\t * but it would incur the cost of a retpoline for now.\n\t\t\t * Revisit once static calls are available.\n\t\t\t */\n\t\t\tif (vcpu->arch.apicv_active)\n\t\t\t\tvmx_sync_pir_to_irr(vcpu);\n\t\t\tgoto reenter_guest;\n\t\t}\n\t\texit_fastpath = EXIT_FASTPATH_EXIT_HANDLED;\n\t}\n\n\treturn exit_fastpath;\n}\n\nstatic void vmx_free_vcpu(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\tif (enable_pml)\n\t\tvmx_destroy_pml_buffer(vmx);\n\tfree_vpid(vmx->vpid);\n\tnested_vmx_free_vcpu(vcpu);\n\tfree_loaded_vmcs(vmx->loaded_vmcs);\n}\n\nstatic int vmx_create_vcpu(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx;\n\tint i, cpu, err;\n\n\tBUILD_BUG_ON(offsetof(struct vcpu_vmx, vcpu) != 0);\n\tvmx = to_vmx(vcpu);\n\n\terr = -ENOMEM;\n\n\tvmx->vpid = allocate_vpid();\n\n\t/*\n\t * If PML is turned on, failure on enabling PML just results in failure\n\t * of creating the vcpu, therefore we can simplify PML logic (by\n\t * avoiding dealing with cases, such as enabling PML partially on vcpus\n\t * for the guest), etc.\n\t */\n\tif (enable_pml) {\n\t\tvmx->pml_pg = alloc_page(GFP_KERNEL_ACCOUNT | __GFP_ZERO);\n\t\tif (!vmx->pml_pg)\n\t\t\tgoto free_vpid;\n\t}\n\n\tBUILD_BUG_ON(ARRAY_SIZE(vmx_uret_msrs_list) != MAX_NR_USER_RETURN_MSRS);\n\n\tfor (i = 0; i < ARRAY_SIZE(vmx_uret_msrs_list); ++i) {\n\t\tu32 index = vmx_uret_msrs_list[i];\n\t\tu32 data_low, data_high;\n\t\tint j = vmx->nr_uret_msrs;\n\n\t\tif (rdmsr_safe(index, &data_low, &data_high) < 0)\n\t\t\tcontinue;\n\t\tif (wrmsr_safe(index, data_low, data_high) < 0)\n\t\t\tcontinue;\n\n\t\tvmx->guest_uret_msrs[j].slot = i;\n\t\tvmx->guest_uret_msrs[j].data = 0;\n\t\tswitch (index) {\n\t\tcase MSR_IA32_TSX_CTRL:\n\t\t\t/*\n\t\t\t * No need to pass TSX_CTRL_CPUID_CLEAR through, so\n\t\t\t * let's avoid changing CPUID bits under the host\n\t\t\t * kernel's feet.\n\t\t\t */\n\t\t\tvmx->guest_uret_msrs[j].mask = ~(u64)TSX_CTRL_CPUID_CLEAR;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tvmx->guest_uret_msrs[j].mask = -1ull;\n\t\t\tbreak;\n\t\t}\n\t\t++vmx->nr_uret_msrs;\n\t}\n\n\terr = alloc_loaded_vmcs(&vmx->vmcs01);\n\tif (err < 0)\n\t\tgoto free_pml;\n\n\t/* The MSR bitmap starts with all ones */\n\tbitmap_fill(vmx->shadow_msr_intercept.read, MAX_POSSIBLE_PASSTHROUGH_MSRS);\n\tbitmap_fill(vmx->shadow_msr_intercept.write, MAX_POSSIBLE_PASSTHROUGH_MSRS);\n\n\tvmx_disable_intercept_for_msr(vcpu, MSR_IA32_TSC, MSR_TYPE_R);\n\tvmx_disable_intercept_for_msr(vcpu, MSR_FS_BASE, MSR_TYPE_RW);\n\tvmx_disable_intercept_for_msr(vcpu, MSR_GS_BASE, MSR_TYPE_RW);\n\tvmx_disable_intercept_for_msr(vcpu, MSR_KERNEL_GS_BASE, MSR_TYPE_RW);\n\tvmx_disable_intercept_for_msr(vcpu, MSR_IA32_SYSENTER_CS, MSR_TYPE_RW);\n\tvmx_disable_intercept_for_msr(vcpu, MSR_IA32_SYSENTER_ESP, MSR_TYPE_RW);\n\tvmx_disable_intercept_for_msr(vcpu, MSR_IA32_SYSENTER_EIP, MSR_TYPE_RW);\n\tif (kvm_cstate_in_guest(vcpu->kvm)) {\n\t\tvmx_disable_intercept_for_msr(vcpu, MSR_CORE_C1_RES, MSR_TYPE_R);\n\t\tvmx_disable_intercept_for_msr(vcpu, MSR_CORE_C3_RESIDENCY, MSR_TYPE_R);\n\t\tvmx_disable_intercept_for_msr(vcpu, MSR_CORE_C6_RESIDENCY, MSR_TYPE_R);\n\t\tvmx_disable_intercept_for_msr(vcpu, MSR_CORE_C7_RESIDENCY, MSR_TYPE_R);\n\t}\n\tvmx->msr_bitmap_mode = 0;\n\n\tvmx->loaded_vmcs = &vmx->vmcs01;\n\tcpu = get_cpu();\n\tvmx_vcpu_load(vcpu, cpu);\n\tvcpu->cpu = cpu;\n\tinit_vmcs(vmx);\n\tvmx_vcpu_put(vcpu);\n\tput_cpu();\n\tif (cpu_need_virtualize_apic_accesses(vcpu)) {\n\t\terr = alloc_apic_access_page(vcpu->kvm);\n\t\tif (err)\n\t\t\tgoto free_vmcs;\n\t}\n\n\tif (enable_ept && !enable_unrestricted_guest) {\n\t\terr = init_rmode_identity_map(vcpu->kvm);\n\t\tif (err)\n\t\t\tgoto free_vmcs;\n\t}\n\n\tif (nested)\n\t\tmemcpy(&vmx->nested.msrs, &vmcs_config.nested, sizeof(vmx->nested.msrs));\n\telse\n\t\tmemset(&vmx->nested.msrs, 0, sizeof(vmx->nested.msrs));\n\n\tvmx->nested.posted_intr_nv = -1;\n\tvmx->nested.current_vmptr = -1ull;\n\n\tvcpu->arch.microcode_version = 0x100000000ULL;\n\tvmx->msr_ia32_feature_control_valid_bits = FEAT_CTL_LOCKED;\n\n\t/*\n\t * Enforce invariant: pi_desc.nv is always either POSTED_INTR_VECTOR\n\t * or POSTED_INTR_WAKEUP_VECTOR.\n\t */\n\tvmx->pi_desc.nv = POSTED_INTR_VECTOR;\n\tvmx->pi_desc.sn = 1;\n\n\tvmx->ept_pointer = INVALID_PAGE;\n\n\treturn 0;\n\nfree_vmcs:\n\tfree_loaded_vmcs(vmx->loaded_vmcs);\nfree_pml:\n\tvmx_destroy_pml_buffer(vmx);\nfree_vpid:\n\tfree_vpid(vmx->vpid);\n\treturn err;\n}\n\n#define L1TF_MSG_SMT \"L1TF CPU bug present and SMT on, data leak possible. See CVE-2018-3646 and https://www.kernel.org/doc/html/latest/admin-guide/hw-vuln/l1tf.html for details.\\n\"\n#define L1TF_MSG_L1D \"L1TF CPU bug present and virtualization mitigation disabled, data leak possible. See CVE-2018-3646 and https://www.kernel.org/doc/html/latest/admin-guide/hw-vuln/l1tf.html for details.\\n\"\n\nstatic int vmx_vm_init(struct kvm *kvm)\n{\n\tspin_lock_init(&to_kvm_vmx(kvm)->ept_pointer_lock);\n\n\tif (!ple_gap)\n\t\tkvm->arch.pause_in_guest = true;\n\n\tif (boot_cpu_has(X86_BUG_L1TF) && enable_ept) {\n\t\tswitch (l1tf_mitigation) {\n\t\tcase L1TF_MITIGATION_OFF:\n\t\tcase L1TF_MITIGATION_FLUSH_NOWARN:\n\t\t\t/* 'I explicitly don't care' is set */\n\t\t\tbreak;\n\t\tcase L1TF_MITIGATION_FLUSH:\n\t\tcase L1TF_MITIGATION_FLUSH_NOSMT:\n\t\tcase L1TF_MITIGATION_FULL:\n\t\t\t/*\n\t\t\t * Warn upon starting the first VM in a potentially\n\t\t\t * insecure environment.\n\t\t\t */\n\t\t\tif (sched_smt_active())\n\t\t\t\tpr_warn_once(L1TF_MSG_SMT);\n\t\t\tif (l1tf_vmx_mitigation == VMENTER_L1D_FLUSH_NEVER)\n\t\t\t\tpr_warn_once(L1TF_MSG_L1D);\n\t\t\tbreak;\n\t\tcase L1TF_MITIGATION_FULL_FORCE:\n\t\t\t/* Flush is enforced */\n\t\t\tbreak;\n\t\t}\n\t}\n\tkvm_apicv_init(kvm, enable_apicv);\n\treturn 0;\n}\n\nstatic int __init vmx_check_processor_compat(void)\n{\n\tstruct vmcs_config vmcs_conf;\n\tstruct vmx_capability vmx_cap;\n\n\tif (!this_cpu_has(X86_FEATURE_MSR_IA32_FEAT_CTL) ||\n\t    !this_cpu_has(X86_FEATURE_VMX)) {\n\t\tpr_err(\"kvm: VMX is disabled on CPU %d\\n\", smp_processor_id());\n\t\treturn -EIO;\n\t}\n\n\tif (setup_vmcs_config(&vmcs_conf, &vmx_cap) < 0)\n\t\treturn -EIO;\n\tif (nested)\n\t\tnested_vmx_setup_ctls_msrs(&vmcs_conf.nested, vmx_cap.ept);\n\tif (memcmp(&vmcs_config, &vmcs_conf, sizeof(struct vmcs_config)) != 0) {\n\t\tprintk(KERN_ERR \"kvm: CPU %d feature inconsistency!\\n\",\n\t\t\t\tsmp_processor_id());\n\t\treturn -EIO;\n\t}\n\treturn 0;\n}\n\nstatic u64 vmx_get_mt_mask(struct kvm_vcpu *vcpu, gfn_t gfn, bool is_mmio)\n{\n\tu8 cache;\n\tu64 ipat = 0;\n\n\t/* We wanted to honor guest CD/MTRR/PAT, but doing so could result in\n\t * memory aliases with conflicting memory types and sometimes MCEs.\n\t * We have to be careful as to what are honored and when.\n\t *\n\t * For MMIO, guest CD/MTRR are ignored.  The EPT memory type is set to\n\t * UC.  The effective memory type is UC or WC depending on guest PAT.\n\t * This was historically the source of MCEs and we want to be\n\t * conservative.\n\t *\n\t * When there is no need to deal with noncoherent DMA (e.g., no VT-d\n\t * or VT-d has snoop control), guest CD/MTRR/PAT are all ignored.  The\n\t * EPT memory type is set to WB.  The effective memory type is forced\n\t * WB.\n\t *\n\t * Otherwise, we trust guest.  Guest CD/MTRR/PAT are all honored.  The\n\t * EPT memory type is used to emulate guest CD/MTRR.\n\t */\n\n\tif (is_mmio) {\n\t\tcache = MTRR_TYPE_UNCACHABLE;\n\t\tgoto exit;\n\t}\n\n\tif (!kvm_arch_has_noncoherent_dma(vcpu->kvm)) {\n\t\tipat = VMX_EPT_IPAT_BIT;\n\t\tcache = MTRR_TYPE_WRBACK;\n\t\tgoto exit;\n\t}\n\n\tif (kvm_read_cr0(vcpu) & X86_CR0_CD) {\n\t\tipat = VMX_EPT_IPAT_BIT;\n\t\tif (kvm_check_has_quirk(vcpu->kvm, KVM_X86_QUIRK_CD_NW_CLEARED))\n\t\t\tcache = MTRR_TYPE_WRBACK;\n\t\telse\n\t\t\tcache = MTRR_TYPE_UNCACHABLE;\n\t\tgoto exit;\n\t}\n\n\tcache = kvm_mtrr_get_guest_memory_type(vcpu, gfn);\n\nexit:\n\treturn (cache << VMX_EPT_MT_EPTE_SHIFT) | ipat;\n}\n\nstatic void vmcs_set_secondary_exec_control(struct vcpu_vmx *vmx)\n{\n\t/*\n\t * These bits in the secondary execution controls field\n\t * are dynamic, the others are mostly based on the hypervisor\n\t * architecture and the guest's CPUID.  Do not touch the\n\t * dynamic bits.\n\t */\n\tu32 mask =\n\t\tSECONDARY_EXEC_SHADOW_VMCS |\n\t\tSECONDARY_EXEC_VIRTUALIZE_X2APIC_MODE |\n\t\tSECONDARY_EXEC_VIRTUALIZE_APIC_ACCESSES |\n\t\tSECONDARY_EXEC_DESC;\n\n\tu32 new_ctl = vmx->secondary_exec_control;\n\tu32 cur_ctl = secondary_exec_controls_get(vmx);\n\n\tsecondary_exec_controls_set(vmx, (new_ctl & ~mask) | (cur_ctl & mask));\n}\n\n/*\n * Generate MSR_IA32_VMX_CR{0,4}_FIXED1 according to CPUID. Only set bits\n * (indicating \"allowed-1\") if they are supported in the guest's CPUID.\n */\nstatic void nested_vmx_cr_fixed1_bits_update(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tstruct kvm_cpuid_entry2 *entry;\n\n\tvmx->nested.msrs.cr0_fixed1 = 0xffffffff;\n\tvmx->nested.msrs.cr4_fixed1 = X86_CR4_PCE;\n\n#define cr4_fixed1_update(_cr4_mask, _reg, _cpuid_mask) do {\t\t\\\n\tif (entry && (entry->_reg & (_cpuid_mask)))\t\t\t\\\n\t\tvmx->nested.msrs.cr4_fixed1 |= (_cr4_mask);\t\\\n} while (0)\n\n\tentry = kvm_find_cpuid_entry(vcpu, 0x1, 0);\n\tcr4_fixed1_update(X86_CR4_VME,        edx, feature_bit(VME));\n\tcr4_fixed1_update(X86_CR4_PVI,        edx, feature_bit(VME));\n\tcr4_fixed1_update(X86_CR4_TSD,        edx, feature_bit(TSC));\n\tcr4_fixed1_update(X86_CR4_DE,         edx, feature_bit(DE));\n\tcr4_fixed1_update(X86_CR4_PSE,        edx, feature_bit(PSE));\n\tcr4_fixed1_update(X86_CR4_PAE,        edx, feature_bit(PAE));\n\tcr4_fixed1_update(X86_CR4_MCE,        edx, feature_bit(MCE));\n\tcr4_fixed1_update(X86_CR4_PGE,        edx, feature_bit(PGE));\n\tcr4_fixed1_update(X86_CR4_OSFXSR,     edx, feature_bit(FXSR));\n\tcr4_fixed1_update(X86_CR4_OSXMMEXCPT, edx, feature_bit(XMM));\n\tcr4_fixed1_update(X86_CR4_VMXE,       ecx, feature_bit(VMX));\n\tcr4_fixed1_update(X86_CR4_SMXE,       ecx, feature_bit(SMX));\n\tcr4_fixed1_update(X86_CR4_PCIDE,      ecx, feature_bit(PCID));\n\tcr4_fixed1_update(X86_CR4_OSXSAVE,    ecx, feature_bit(XSAVE));\n\n\tentry = kvm_find_cpuid_entry(vcpu, 0x7, 0);\n\tcr4_fixed1_update(X86_CR4_FSGSBASE,   ebx, feature_bit(FSGSBASE));\n\tcr4_fixed1_update(X86_CR4_SMEP,       ebx, feature_bit(SMEP));\n\tcr4_fixed1_update(X86_CR4_SMAP,       ebx, feature_bit(SMAP));\n\tcr4_fixed1_update(X86_CR4_PKE,        ecx, feature_bit(PKU));\n\tcr4_fixed1_update(X86_CR4_UMIP,       ecx, feature_bit(UMIP));\n\tcr4_fixed1_update(X86_CR4_LA57,       ecx, feature_bit(LA57));\n\n#undef cr4_fixed1_update\n}\n\nstatic void nested_vmx_entry_exit_ctls_update(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\tif (kvm_mpx_supported()) {\n\t\tbool mpx_enabled = guest_cpuid_has(vcpu, X86_FEATURE_MPX);\n\n\t\tif (mpx_enabled) {\n\t\t\tvmx->nested.msrs.entry_ctls_high |= VM_ENTRY_LOAD_BNDCFGS;\n\t\t\tvmx->nested.msrs.exit_ctls_high |= VM_EXIT_CLEAR_BNDCFGS;\n\t\t} else {\n\t\t\tvmx->nested.msrs.entry_ctls_high &= ~VM_ENTRY_LOAD_BNDCFGS;\n\t\t\tvmx->nested.msrs.exit_ctls_high &= ~VM_EXIT_CLEAR_BNDCFGS;\n\t\t}\n\t}\n}\n\nstatic void update_intel_pt_cfg(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tstruct kvm_cpuid_entry2 *best = NULL;\n\tint i;\n\n\tfor (i = 0; i < PT_CPUID_LEAVES; i++) {\n\t\tbest = kvm_find_cpuid_entry(vcpu, 0x14, i);\n\t\tif (!best)\n\t\t\treturn;\n\t\tvmx->pt_desc.caps[CPUID_EAX + i*PT_CPUID_REGS_NUM] = best->eax;\n\t\tvmx->pt_desc.caps[CPUID_EBX + i*PT_CPUID_REGS_NUM] = best->ebx;\n\t\tvmx->pt_desc.caps[CPUID_ECX + i*PT_CPUID_REGS_NUM] = best->ecx;\n\t\tvmx->pt_desc.caps[CPUID_EDX + i*PT_CPUID_REGS_NUM] = best->edx;\n\t}\n\n\t/* Get the number of configurable Address Ranges for filtering */\n\tvmx->pt_desc.addr_range = intel_pt_validate_cap(vmx->pt_desc.caps,\n\t\t\t\t\t\tPT_CAP_num_address_ranges);\n\n\t/* Initialize and clear the no dependency bits */\n\tvmx->pt_desc.ctl_bitmask = ~(RTIT_CTL_TRACEEN | RTIT_CTL_OS |\n\t\t\tRTIT_CTL_USR | RTIT_CTL_TSC_EN | RTIT_CTL_DISRETC);\n\n\t/*\n\t * If CPUID.(EAX=14H,ECX=0):EBX[0]=1 CR3Filter can be set otherwise\n\t * will inject an #GP\n\t */\n\tif (intel_pt_validate_cap(vmx->pt_desc.caps, PT_CAP_cr3_filtering))\n\t\tvmx->pt_desc.ctl_bitmask &= ~RTIT_CTL_CR3EN;\n\n\t/*\n\t * If CPUID.(EAX=14H,ECX=0):EBX[1]=1 CYCEn, CycThresh and\n\t * PSBFreq can be set\n\t */\n\tif (intel_pt_validate_cap(vmx->pt_desc.caps, PT_CAP_psb_cyc))\n\t\tvmx->pt_desc.ctl_bitmask &= ~(RTIT_CTL_CYCLEACC |\n\t\t\t\tRTIT_CTL_CYC_THRESH | RTIT_CTL_PSB_FREQ);\n\n\t/*\n\t * If CPUID.(EAX=14H,ECX=0):EBX[3]=1 MTCEn BranchEn and\n\t * MTCFreq can be set\n\t */\n\tif (intel_pt_validate_cap(vmx->pt_desc.caps, PT_CAP_mtc))\n\t\tvmx->pt_desc.ctl_bitmask &= ~(RTIT_CTL_MTC_EN |\n\t\t\t\tRTIT_CTL_BRANCH_EN | RTIT_CTL_MTC_RANGE);\n\n\t/* If CPUID.(EAX=14H,ECX=0):EBX[4]=1 FUPonPTW and PTWEn can be set */\n\tif (intel_pt_validate_cap(vmx->pt_desc.caps, PT_CAP_ptwrite))\n\t\tvmx->pt_desc.ctl_bitmask &= ~(RTIT_CTL_FUP_ON_PTW |\n\t\t\t\t\t\t\tRTIT_CTL_PTW_EN);\n\n\t/* If CPUID.(EAX=14H,ECX=0):EBX[5]=1 PwrEvEn can be set */\n\tif (intel_pt_validate_cap(vmx->pt_desc.caps, PT_CAP_power_event_trace))\n\t\tvmx->pt_desc.ctl_bitmask &= ~RTIT_CTL_PWR_EVT_EN;\n\n\t/* If CPUID.(EAX=14H,ECX=0):ECX[0]=1 ToPA can be set */\n\tif (intel_pt_validate_cap(vmx->pt_desc.caps, PT_CAP_topa_output))\n\t\tvmx->pt_desc.ctl_bitmask &= ~RTIT_CTL_TOPA;\n\n\t/* If CPUID.(EAX=14H,ECX=0):ECX[3]=1 FabircEn can be set */\n\tif (intel_pt_validate_cap(vmx->pt_desc.caps, PT_CAP_output_subsys))\n\t\tvmx->pt_desc.ctl_bitmask &= ~RTIT_CTL_FABRIC_EN;\n\n\t/* unmask address range configure area */\n\tfor (i = 0; i < vmx->pt_desc.addr_range; i++)\n\t\tvmx->pt_desc.ctl_bitmask &= ~(0xfULL << (32 + i * 4));\n}\n\nstatic void vmx_vcpu_after_set_cpuid(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\t/* xsaves_enabled is recomputed in vmx_compute_secondary_exec_control(). */\n\tvcpu->arch.xsaves_enabled = false;\n\n\tif (cpu_has_secondary_exec_ctrls()) {\n\t\tvmx_compute_secondary_exec_control(vmx);\n\t\tvmcs_set_secondary_exec_control(vmx);\n\t}\n\n\tif (nested_vmx_allowed(vcpu))\n\t\tto_vmx(vcpu)->msr_ia32_feature_control_valid_bits |=\n\t\t\tFEAT_CTL_VMX_ENABLED_INSIDE_SMX |\n\t\t\tFEAT_CTL_VMX_ENABLED_OUTSIDE_SMX;\n\telse\n\t\tto_vmx(vcpu)->msr_ia32_feature_control_valid_bits &=\n\t\t\t~(FEAT_CTL_VMX_ENABLED_INSIDE_SMX |\n\t\t\t  FEAT_CTL_VMX_ENABLED_OUTSIDE_SMX);\n\n\tif (nested_vmx_allowed(vcpu)) {\n\t\tnested_vmx_cr_fixed1_bits_update(vcpu);\n\t\tnested_vmx_entry_exit_ctls_update(vcpu);\n\t}\n\n\tif (boot_cpu_has(X86_FEATURE_INTEL_PT) &&\n\t\t\tguest_cpuid_has(vcpu, X86_FEATURE_INTEL_PT))\n\t\tupdate_intel_pt_cfg(vcpu);\n\n\tif (boot_cpu_has(X86_FEATURE_RTM)) {\n\t\tstruct vmx_uret_msr *msr;\n\t\tmsr = vmx_find_uret_msr(vmx, MSR_IA32_TSX_CTRL);\n\t\tif (msr) {\n\t\t\tbool enabled = guest_cpuid_has(vcpu, X86_FEATURE_RTM);\n\t\t\tvmx_set_guest_uret_msr(vmx, msr, enabled ? 0 : TSX_CTRL_RTM_DISABLE);\n\t\t}\n\t}\n\n\tset_cr4_guest_host_mask(vmx);\n\n\t/* Refresh #PF interception to account for MAXPHYADDR changes. */\n\tupdate_exception_bitmap(vcpu);\n}\n\nstatic __init void vmx_set_cpu_caps(void)\n{\n\tkvm_set_cpu_caps();\n\n\t/* CPUID 0x1 */\n\tif (nested)\n\t\tkvm_cpu_cap_set(X86_FEATURE_VMX);\n\n\t/* CPUID 0x7 */\n\tif (kvm_mpx_supported())\n\t\tkvm_cpu_cap_check_and_set(X86_FEATURE_MPX);\n\tif (cpu_has_vmx_invpcid())\n\t\tkvm_cpu_cap_check_and_set(X86_FEATURE_INVPCID);\n\tif (vmx_pt_mode_is_host_guest())\n\t\tkvm_cpu_cap_check_and_set(X86_FEATURE_INTEL_PT);\n\n\tif (vmx_umip_emulated())\n\t\tkvm_cpu_cap_set(X86_FEATURE_UMIP);\n\n\t/* CPUID 0xD.1 */\n\tsupported_xss = 0;\n\tif (!cpu_has_vmx_xsaves())\n\t\tkvm_cpu_cap_clear(X86_FEATURE_XSAVES);\n\n\t/* CPUID 0x80000001 */\n\tif (!cpu_has_vmx_rdtscp())\n\t\tkvm_cpu_cap_clear(X86_FEATURE_RDTSCP);\n\n\tif (cpu_has_vmx_waitpkg())\n\t\tkvm_cpu_cap_check_and_set(X86_FEATURE_WAITPKG);\n}\n\nstatic void vmx_request_immediate_exit(struct kvm_vcpu *vcpu)\n{\n\tto_vmx(vcpu)->req_immediate_exit = true;\n}\n\nstatic int vmx_check_intercept_io(struct kvm_vcpu *vcpu,\n\t\t\t\t  struct x86_instruction_info *info)\n{\n\tstruct vmcs12 *vmcs12 = get_vmcs12(vcpu);\n\tunsigned short port;\n\tbool intercept;\n\tint size;\n\n\tif (info->intercept == x86_intercept_in ||\n\t    info->intercept == x86_intercept_ins) {\n\t\tport = info->src_val;\n\t\tsize = info->dst_bytes;\n\t} else {\n\t\tport = info->dst_val;\n\t\tsize = info->src_bytes;\n\t}\n\n\t/*\n\t * If the 'use IO bitmaps' VM-execution control is 0, IO instruction\n\t * VM-exits depend on the 'unconditional IO exiting' VM-execution\n\t * control.\n\t *\n\t * Otherwise, IO instruction VM-exits are controlled by the IO bitmaps.\n\t */\n\tif (!nested_cpu_has(vmcs12, CPU_BASED_USE_IO_BITMAPS))\n\t\tintercept = nested_cpu_has(vmcs12,\n\t\t\t\t\t   CPU_BASED_UNCOND_IO_EXITING);\n\telse\n\t\tintercept = nested_vmx_check_io_bitmaps(vcpu, port, size);\n\n\t/* FIXME: produce nested vmexit and return X86EMUL_INTERCEPTED.  */\n\treturn intercept ? X86EMUL_UNHANDLEABLE : X86EMUL_CONTINUE;\n}\n\nstatic int vmx_check_intercept(struct kvm_vcpu *vcpu,\n\t\t\t       struct x86_instruction_info *info,\n\t\t\t       enum x86_intercept_stage stage,\n\t\t\t       struct x86_exception *exception)\n{\n\tstruct vmcs12 *vmcs12 = get_vmcs12(vcpu);\n\n\tswitch (info->intercept) {\n\t/*\n\t * RDPID causes #UD if disabled through secondary execution controls.\n\t * Because it is marked as EmulateOnUD, we need to intercept it here.\n\t */\n\tcase x86_intercept_rdtscp:\n\t\tif (!nested_cpu_has2(vmcs12, SECONDARY_EXEC_ENABLE_RDTSCP)) {\n\t\t\texception->vector = UD_VECTOR;\n\t\t\texception->error_code_valid = false;\n\t\t\treturn X86EMUL_PROPAGATE_FAULT;\n\t\t}\n\t\tbreak;\n\n\tcase x86_intercept_in:\n\tcase x86_intercept_ins:\n\tcase x86_intercept_out:\n\tcase x86_intercept_outs:\n\t\treturn vmx_check_intercept_io(vcpu, info);\n\n\tcase x86_intercept_lgdt:\n\tcase x86_intercept_lidt:\n\tcase x86_intercept_lldt:\n\tcase x86_intercept_ltr:\n\tcase x86_intercept_sgdt:\n\tcase x86_intercept_sidt:\n\tcase x86_intercept_sldt:\n\tcase x86_intercept_str:\n\t\tif (!nested_cpu_has2(vmcs12, SECONDARY_EXEC_DESC))\n\t\t\treturn X86EMUL_CONTINUE;\n\n\t\t/* FIXME: produce nested vmexit and return X86EMUL_INTERCEPTED.  */\n\t\tbreak;\n\n\t/* TODO: check more intercepts... */\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn X86EMUL_UNHANDLEABLE;\n}\n\n#ifdef CONFIG_X86_64\n/* (a << shift) / divisor, return 1 if overflow otherwise 0 */\nstatic inline int u64_shl_div_u64(u64 a, unsigned int shift,\n\t\t\t\t  u64 divisor, u64 *result)\n{\n\tu64 low = a << shift, high = a >> (64 - shift);\n\n\t/* To avoid the overflow on divq */\n\tif (high >= divisor)\n\t\treturn 1;\n\n\t/* Low hold the result, high hold rem which is discarded */\n\tasm(\"divq %2\\n\\t\" : \"=a\" (low), \"=d\" (high) :\n\t    \"rm\" (divisor), \"0\" (low), \"1\" (high));\n\t*result = low;\n\n\treturn 0;\n}\n\nstatic int vmx_set_hv_timer(struct kvm_vcpu *vcpu, u64 guest_deadline_tsc,\n\t\t\t    bool *expired)\n{\n\tstruct vcpu_vmx *vmx;\n\tu64 tscl, guest_tscl, delta_tsc, lapic_timer_advance_cycles;\n\tstruct kvm_timer *ktimer = &vcpu->arch.apic->lapic_timer;\n\n\tvmx = to_vmx(vcpu);\n\ttscl = rdtsc();\n\tguest_tscl = kvm_read_l1_tsc(vcpu, tscl);\n\tdelta_tsc = max(guest_deadline_tsc, guest_tscl) - guest_tscl;\n\tlapic_timer_advance_cycles = nsec_to_cycles(vcpu,\n\t\t\t\t\t\t    ktimer->timer_advance_ns);\n\n\tif (delta_tsc > lapic_timer_advance_cycles)\n\t\tdelta_tsc -= lapic_timer_advance_cycles;\n\telse\n\t\tdelta_tsc = 0;\n\n\t/* Convert to host delta tsc if tsc scaling is enabled */\n\tif (vcpu->arch.tsc_scaling_ratio != kvm_default_tsc_scaling_ratio &&\n\t    delta_tsc && u64_shl_div_u64(delta_tsc,\n\t\t\t\tkvm_tsc_scaling_ratio_frac_bits,\n\t\t\t\tvcpu->arch.tsc_scaling_ratio, &delta_tsc))\n\t\treturn -ERANGE;\n\n\t/*\n\t * If the delta tsc can't fit in the 32 bit after the multi shift,\n\t * we can't use the preemption timer.\n\t * It's possible that it fits on later vmentries, but checking\n\t * on every vmentry is costly so we just use an hrtimer.\n\t */\n\tif (delta_tsc >> (cpu_preemption_timer_multi + 32))\n\t\treturn -ERANGE;\n\n\tvmx->hv_deadline_tsc = tscl + delta_tsc;\n\t*expired = !delta_tsc;\n\treturn 0;\n}\n\nstatic void vmx_cancel_hv_timer(struct kvm_vcpu *vcpu)\n{\n\tto_vmx(vcpu)->hv_deadline_tsc = -1;\n}\n#endif\n\nstatic void vmx_sched_in(struct kvm_vcpu *vcpu, int cpu)\n{\n\tif (!kvm_pause_in_guest(vcpu->kvm))\n\t\tshrink_ple_window(vcpu);\n}\n\nstatic void vmx_slot_enable_log_dirty(struct kvm *kvm,\n\t\t\t\t     struct kvm_memory_slot *slot)\n{\n\tif (!kvm_dirty_log_manual_protect_and_init_set(kvm))\n\t\tkvm_mmu_slot_leaf_clear_dirty(kvm, slot);\n\tkvm_mmu_slot_largepage_remove_write_access(kvm, slot);\n}\n\nstatic void vmx_slot_disable_log_dirty(struct kvm *kvm,\n\t\t\t\t       struct kvm_memory_slot *slot)\n{\n\tkvm_mmu_slot_set_dirty(kvm, slot);\n}\n\nstatic void vmx_flush_log_dirty(struct kvm *kvm)\n{\n\tkvm_flush_pml_buffers(kvm);\n}\n\nstatic void vmx_enable_log_dirty_pt_masked(struct kvm *kvm,\n\t\t\t\t\t   struct kvm_memory_slot *memslot,\n\t\t\t\t\t   gfn_t offset, unsigned long mask)\n{\n\tkvm_mmu_clear_dirty_pt_masked(kvm, memslot, offset, mask);\n}\n\nstatic int vmx_pre_block(struct kvm_vcpu *vcpu)\n{\n\tif (pi_pre_block(vcpu))\n\t\treturn 1;\n\n\tif (kvm_lapic_hv_timer_in_use(vcpu))\n\t\tkvm_lapic_switch_to_sw_timer(vcpu);\n\n\treturn 0;\n}\n\nstatic void vmx_post_block(struct kvm_vcpu *vcpu)\n{\n\tif (kvm_x86_ops.set_hv_timer)\n\t\tkvm_lapic_switch_to_hv_timer(vcpu);\n\n\tpi_post_block(vcpu);\n}\n\nstatic void vmx_setup_mce(struct kvm_vcpu *vcpu)\n{\n\tif (vcpu->arch.mcg_cap & MCG_LMCE_P)\n\t\tto_vmx(vcpu)->msr_ia32_feature_control_valid_bits |=\n\t\t\tFEAT_CTL_LMCE_ENABLED;\n\telse\n\t\tto_vmx(vcpu)->msr_ia32_feature_control_valid_bits &=\n\t\t\t~FEAT_CTL_LMCE_ENABLED;\n}\n\nstatic int vmx_smi_allowed(struct kvm_vcpu *vcpu, bool for_injection)\n{\n\t/* we need a nested vmexit to enter SMM, postpone if run is pending */\n\tif (to_vmx(vcpu)->nested.nested_run_pending)\n\t\treturn -EBUSY;\n\treturn !is_smm(vcpu);\n}\n\nstatic int vmx_pre_enter_smm(struct kvm_vcpu *vcpu, char *smstate)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\tvmx->nested.smm.guest_mode = is_guest_mode(vcpu);\n\tif (vmx->nested.smm.guest_mode)\n\t\tnested_vmx_vmexit(vcpu, -1, 0, 0);\n\n\tvmx->nested.smm.vmxon = vmx->nested.vmxon;\n\tvmx->nested.vmxon = false;\n\tvmx_clear_hlt(vcpu);\n\treturn 0;\n}\n\nstatic int vmx_pre_leave_smm(struct kvm_vcpu *vcpu, const char *smstate)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tint ret;\n\n\tif (vmx->nested.smm.vmxon) {\n\t\tvmx->nested.vmxon = true;\n\t\tvmx->nested.smm.vmxon = false;\n\t}\n\n\tif (vmx->nested.smm.guest_mode) {\n\t\tret = nested_vmx_enter_non_root_mode(vcpu, false);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tvmx->nested.smm.guest_mode = false;\n\t}\n\treturn 0;\n}\n\nstatic void enable_smi_window(struct kvm_vcpu *vcpu)\n{\n\t/* RSM will cause a vmexit anyway.  */\n}\n\nstatic bool vmx_apic_init_signal_blocked(struct kvm_vcpu *vcpu)\n{\n\treturn to_vmx(vcpu)->nested.vmxon;\n}\n\nstatic void vmx_migrate_timers(struct kvm_vcpu *vcpu)\n{\n\tif (is_guest_mode(vcpu)) {\n\t\tstruct hrtimer *timer = &to_vmx(vcpu)->nested.preemption_timer;\n\n\t\tif (hrtimer_try_to_cancel(timer) == 1)\n\t\t\thrtimer_start_expires(timer, HRTIMER_MODE_ABS_PINNED);\n\t}\n}\n\nstatic void hardware_unsetup(void)\n{\n\tif (nested)\n\t\tnested_vmx_hardware_unsetup();\n\n\tfree_kvm_area();\n}\n\nstatic bool vmx_check_apicv_inhibit_reasons(ulong bit)\n{\n\tulong supported = BIT(APICV_INHIBIT_REASON_DISABLE) |\n\t\t\t  BIT(APICV_INHIBIT_REASON_HYPERV);\n\n\treturn supported & BIT(bit);\n}\n\nstatic struct kvm_x86_ops vmx_x86_ops __initdata = {\n\t.hardware_unsetup = hardware_unsetup,\n\n\t.hardware_enable = hardware_enable,\n\t.hardware_disable = hardware_disable,\n\t.cpu_has_accelerated_tpr = report_flexpriority,\n\t.has_emulated_msr = vmx_has_emulated_msr,\n\n\t.vm_size = sizeof(struct kvm_vmx),\n\t.vm_init = vmx_vm_init,\n\n\t.vcpu_create = vmx_create_vcpu,\n\t.vcpu_free = vmx_free_vcpu,\n\t.vcpu_reset = vmx_vcpu_reset,\n\n\t.prepare_guest_switch = vmx_prepare_switch_to_guest,\n\t.vcpu_load = vmx_vcpu_load,\n\t.vcpu_put = vmx_vcpu_put,\n\n\t.update_exception_bitmap = update_exception_bitmap,\n\t.get_msr_feature = vmx_get_msr_feature,\n\t.get_msr = vmx_get_msr,\n\t.set_msr = vmx_set_msr,\n\t.get_segment_base = vmx_get_segment_base,\n\t.get_segment = vmx_get_segment,\n\t.set_segment = vmx_set_segment,\n\t.get_cpl = vmx_get_cpl,\n\t.get_cs_db_l_bits = vmx_get_cs_db_l_bits,\n\t.set_cr0 = vmx_set_cr0,\n\t.set_cr4 = vmx_set_cr4,\n\t.set_efer = vmx_set_efer,\n\t.get_idt = vmx_get_idt,\n\t.set_idt = vmx_set_idt,\n\t.get_gdt = vmx_get_gdt,\n\t.set_gdt = vmx_set_gdt,\n\t.set_dr7 = vmx_set_dr7,\n\t.sync_dirty_debug_regs = vmx_sync_dirty_debug_regs,\n\t.cache_reg = vmx_cache_reg,\n\t.get_rflags = vmx_get_rflags,\n\t.set_rflags = vmx_set_rflags,\n\n\t.tlb_flush_all = vmx_flush_tlb_all,\n\t.tlb_flush_current = vmx_flush_tlb_current,\n\t.tlb_flush_gva = vmx_flush_tlb_gva,\n\t.tlb_flush_guest = vmx_flush_tlb_guest,\n\n\t.run = vmx_vcpu_run,\n\t.handle_exit = vmx_handle_exit,\n\t.skip_emulated_instruction = vmx_skip_emulated_instruction,\n\t.update_emulated_instruction = vmx_update_emulated_instruction,\n\t.set_interrupt_shadow = vmx_set_interrupt_shadow,\n\t.get_interrupt_shadow = vmx_get_interrupt_shadow,\n\t.patch_hypercall = vmx_patch_hypercall,\n\t.set_irq = vmx_inject_irq,\n\t.set_nmi = vmx_inject_nmi,\n\t.queue_exception = vmx_queue_exception,\n\t.cancel_injection = vmx_cancel_injection,\n\t.interrupt_allowed = vmx_interrupt_allowed,\n\t.nmi_allowed = vmx_nmi_allowed,\n\t.get_nmi_mask = vmx_get_nmi_mask,\n\t.set_nmi_mask = vmx_set_nmi_mask,\n\t.enable_nmi_window = enable_nmi_window,\n\t.enable_irq_window = enable_irq_window,\n\t.update_cr8_intercept = update_cr8_intercept,\n\t.set_virtual_apic_mode = vmx_set_virtual_apic_mode,\n\t.set_apic_access_page_addr = vmx_set_apic_access_page_addr,\n\t.refresh_apicv_exec_ctrl = vmx_refresh_apicv_exec_ctrl,\n\t.load_eoi_exitmap = vmx_load_eoi_exitmap,\n\t.apicv_post_state_restore = vmx_apicv_post_state_restore,\n\t.check_apicv_inhibit_reasons = vmx_check_apicv_inhibit_reasons,\n\t.hwapic_irr_update = vmx_hwapic_irr_update,\n\t.hwapic_isr_update = vmx_hwapic_isr_update,\n\t.guest_apic_has_interrupt = vmx_guest_apic_has_interrupt,\n\t.sync_pir_to_irr = vmx_sync_pir_to_irr,\n\t.deliver_posted_interrupt = vmx_deliver_posted_interrupt,\n\t.dy_apicv_has_pending_interrupt = pi_has_pending_interrupt,\n\n\t.set_tss_addr = vmx_set_tss_addr,\n\t.set_identity_map_addr = vmx_set_identity_map_addr,\n\t.get_mt_mask = vmx_get_mt_mask,\n\n\t.get_exit_info = vmx_get_exit_info,\n\n\t.vcpu_after_set_cpuid = vmx_vcpu_after_set_cpuid,\n\n\t.has_wbinvd_exit = cpu_has_vmx_wbinvd_exit,\n\n\t.write_l1_tsc_offset = vmx_write_l1_tsc_offset,\n\n\t.load_mmu_pgd = vmx_load_mmu_pgd,\n\n\t.check_intercept = vmx_check_intercept,\n\t.handle_exit_irqoff = vmx_handle_exit_irqoff,\n\n\t.request_immediate_exit = vmx_request_immediate_exit,\n\n\t.sched_in = vmx_sched_in,\n\n\t.slot_enable_log_dirty = vmx_slot_enable_log_dirty,\n\t.slot_disable_log_dirty = vmx_slot_disable_log_dirty,\n\t.flush_log_dirty = vmx_flush_log_dirty,\n\t.enable_log_dirty_pt_masked = vmx_enable_log_dirty_pt_masked,\n\n\t.pre_block = vmx_pre_block,\n\t.post_block = vmx_post_block,\n\n\t.pmu_ops = &intel_pmu_ops,\n\t.nested_ops = &vmx_nested_ops,\n\n\t.update_pi_irte = pi_update_irte,\n\n#ifdef CONFIG_X86_64\n\t.set_hv_timer = vmx_set_hv_timer,\n\t.cancel_hv_timer = vmx_cancel_hv_timer,\n#endif\n\n\t.setup_mce = vmx_setup_mce,\n\n\t.smi_allowed = vmx_smi_allowed,\n\t.pre_enter_smm = vmx_pre_enter_smm,\n\t.pre_leave_smm = vmx_pre_leave_smm,\n\t.enable_smi_window = enable_smi_window,\n\n\t.can_emulate_instruction = vmx_can_emulate_instruction,\n\t.apic_init_signal_blocked = vmx_apic_init_signal_blocked,\n\t.migrate_timers = vmx_migrate_timers,\n\n\t.msr_filter_changed = vmx_msr_filter_changed,\n};\n\nstatic __init int hardware_setup(void)\n{\n\tunsigned long host_bndcfgs;\n\tstruct desc_ptr dt;\n\tint r, i, ept_lpage_level;\n\n\tstore_idt(&dt);\n\thost_idt_base = dt.address;\n\n\tfor (i = 0; i < ARRAY_SIZE(vmx_uret_msrs_list); ++i)\n\t\tkvm_define_user_return_msr(i, vmx_uret_msrs_list[i]);\n\n\tif (setup_vmcs_config(&vmcs_config, &vmx_capability) < 0)\n\t\treturn -EIO;\n\n\tif (boot_cpu_has(X86_FEATURE_NX))\n\t\tkvm_enable_efer_bits(EFER_NX);\n\n\tif (boot_cpu_has(X86_FEATURE_MPX)) {\n\t\trdmsrl(MSR_IA32_BNDCFGS, host_bndcfgs);\n\t\tWARN_ONCE(host_bndcfgs, \"KVM: BNDCFGS in host will be lost\");\n\t}\n\n\tif (!cpu_has_vmx_mpx())\n\t\tsupported_xcr0 &= ~(XFEATURE_MASK_BNDREGS |\n\t\t\t\t    XFEATURE_MASK_BNDCSR);\n\n\tif (!cpu_has_vmx_vpid() || !cpu_has_vmx_invvpid() ||\n\t    !(cpu_has_vmx_invvpid_single() || cpu_has_vmx_invvpid_global()))\n\t\tenable_vpid = 0;\n\n\tif (!cpu_has_vmx_ept() ||\n\t    !cpu_has_vmx_ept_4levels() ||\n\t    !cpu_has_vmx_ept_mt_wb() ||\n\t    !cpu_has_vmx_invept_global())\n\t\tenable_ept = 0;\n\n\tif (!cpu_has_vmx_ept_ad_bits() || !enable_ept)\n\t\tenable_ept_ad_bits = 0;\n\n\tif (!cpu_has_vmx_unrestricted_guest() || !enable_ept)\n\t\tenable_unrestricted_guest = 0;\n\n\tif (!cpu_has_vmx_flexpriority())\n\t\tflexpriority_enabled = 0;\n\n\tif (!cpu_has_virtual_nmis())\n\t\tenable_vnmi = 0;\n\n\t/*\n\t * set_apic_access_page_addr() is used to reload apic access\n\t * page upon invalidation.  No need to do anything if not\n\t * using the APIC_ACCESS_ADDR VMCS field.\n\t */\n\tif (!flexpriority_enabled)\n\t\tvmx_x86_ops.set_apic_access_page_addr = NULL;\n\n\tif (!cpu_has_vmx_tpr_shadow())\n\t\tvmx_x86_ops.update_cr8_intercept = NULL;\n\n#if IS_ENABLED(CONFIG_HYPERV)\n\tif (ms_hyperv.nested_features & HV_X64_NESTED_GUEST_MAPPING_FLUSH\n\t    && enable_ept) {\n\t\tvmx_x86_ops.tlb_remote_flush = hv_remote_flush_tlb;\n\t\tvmx_x86_ops.tlb_remote_flush_with_range =\n\t\t\t\thv_remote_flush_tlb_with_range;\n\t}\n#endif\n\n\tif (!cpu_has_vmx_ple()) {\n\t\tple_gap = 0;\n\t\tple_window = 0;\n\t\tple_window_grow = 0;\n\t\tple_window_max = 0;\n\t\tple_window_shrink = 0;\n\t}\n\n\tif (!cpu_has_vmx_apicv()) {\n\t\tenable_apicv = 0;\n\t\tvmx_x86_ops.sync_pir_to_irr = NULL;\n\t}\n\n\tif (cpu_has_vmx_tsc_scaling()) {\n\t\tkvm_has_tsc_control = true;\n\t\tkvm_max_tsc_scaling_ratio = KVM_VMX_TSC_MULTIPLIER_MAX;\n\t\tkvm_tsc_scaling_ratio_frac_bits = 48;\n\t}\n\n\tset_bit(0, vmx_vpid_bitmap); /* 0 is reserved for host */\n\n\tif (enable_ept)\n\t\tvmx_enable_tdp();\n\n\tif (!enable_ept)\n\t\tept_lpage_level = 0;\n\telse if (cpu_has_vmx_ept_1g_page())\n\t\tept_lpage_level = PG_LEVEL_1G;\n\telse if (cpu_has_vmx_ept_2m_page())\n\t\tept_lpage_level = PG_LEVEL_2M;\n\telse\n\t\tept_lpage_level = PG_LEVEL_4K;\n\tkvm_configure_mmu(enable_ept, vmx_get_max_tdp_level(), ept_lpage_level);\n\n\t/*\n\t * Only enable PML when hardware supports PML feature, and both EPT\n\t * and EPT A/D bit features are enabled -- PML depends on them to work.\n\t */\n\tif (!enable_ept || !enable_ept_ad_bits || !cpu_has_vmx_pml())\n\t\tenable_pml = 0;\n\n\tif (!enable_pml) {\n\t\tvmx_x86_ops.slot_enable_log_dirty = NULL;\n\t\tvmx_x86_ops.slot_disable_log_dirty = NULL;\n\t\tvmx_x86_ops.flush_log_dirty = NULL;\n\t\tvmx_x86_ops.enable_log_dirty_pt_masked = NULL;\n\t}\n\n\tif (!cpu_has_vmx_preemption_timer())\n\t\tenable_preemption_timer = false;\n\n\tif (enable_preemption_timer) {\n\t\tu64 use_timer_freq = 5000ULL * 1000 * 1000;\n\t\tu64 vmx_msr;\n\n\t\trdmsrl(MSR_IA32_VMX_MISC, vmx_msr);\n\t\tcpu_preemption_timer_multi =\n\t\t\tvmx_msr & VMX_MISC_PREEMPTION_TIMER_RATE_MASK;\n\n\t\tif (tsc_khz)\n\t\t\tuse_timer_freq = (u64)tsc_khz * 1000;\n\t\tuse_timer_freq >>= cpu_preemption_timer_multi;\n\n\t\t/*\n\t\t * KVM \"disables\" the preemption timer by setting it to its max\n\t\t * value.  Don't use the timer if it might cause spurious exits\n\t\t * at a rate faster than 0.1 Hz (of uninterrupted guest time).\n\t\t */\n\t\tif (use_timer_freq > 0xffffffffu / 10)\n\t\t\tenable_preemption_timer = false;\n\t}\n\n\tif (!enable_preemption_timer) {\n\t\tvmx_x86_ops.set_hv_timer = NULL;\n\t\tvmx_x86_ops.cancel_hv_timer = NULL;\n\t\tvmx_x86_ops.request_immediate_exit = __kvm_request_immediate_exit;\n\t}\n\n\tkvm_set_posted_intr_wakeup_handler(pi_wakeup_handler);\n\n\tkvm_mce_cap_supported |= MCG_LMCE_P;\n\n\tif (pt_mode != PT_MODE_SYSTEM && pt_mode != PT_MODE_HOST_GUEST)\n\t\treturn -EINVAL;\n\tif (!enable_ept || !cpu_has_vmx_intel_pt())\n\t\tpt_mode = PT_MODE_SYSTEM;\n\n\tif (nested) {\n\t\tnested_vmx_setup_ctls_msrs(&vmcs_config.nested,\n\t\t\t\t\t   vmx_capability.ept);\n\n\t\tr = nested_vmx_hardware_setup(kvm_vmx_exit_handlers);\n\t\tif (r)\n\t\t\treturn r;\n\t}\n\n\tvmx_set_cpu_caps();\n\n\tr = alloc_kvm_area();\n\tif (r)\n\t\tnested_vmx_hardware_unsetup();\n\treturn r;\n}\n\nstatic struct kvm_x86_init_ops vmx_init_ops __initdata = {\n\t.cpu_has_kvm_support = cpu_has_kvm_support,\n\t.disabled_by_bios = vmx_disabled_by_bios,\n\t.check_processor_compatibility = vmx_check_processor_compat,\n\t.hardware_setup = hardware_setup,\n\n\t.runtime_ops = &vmx_x86_ops,\n};\n\nstatic void vmx_cleanup_l1d_flush(void)\n{\n\tif (vmx_l1d_flush_pages) {\n\t\tfree_pages((unsigned long)vmx_l1d_flush_pages, L1D_CACHE_ORDER);\n\t\tvmx_l1d_flush_pages = NULL;\n\t}\n\t/* Restore state so sysfs ignores VMX */\n\tl1tf_vmx_mitigation = VMENTER_L1D_FLUSH_AUTO;\n}\n\nstatic void vmx_exit(void)\n{\n#ifdef CONFIG_KEXEC_CORE\n\tRCU_INIT_POINTER(crash_vmclear_loaded_vmcss, NULL);\n\tsynchronize_rcu();\n#endif\n\n\tkvm_exit();\n\n#if IS_ENABLED(CONFIG_HYPERV)\n\tif (static_branch_unlikely(&enable_evmcs)) {\n\t\tint cpu;\n\t\tstruct hv_vp_assist_page *vp_ap;\n\t\t/*\n\t\t * Reset everything to support using non-enlightened VMCS\n\t\t * access later (e.g. when we reload the module with\n\t\t * enlightened_vmcs=0)\n\t\t */\n\t\tfor_each_online_cpu(cpu) {\n\t\t\tvp_ap =\thv_get_vp_assist_page(cpu);\n\n\t\t\tif (!vp_ap)\n\t\t\t\tcontinue;\n\n\t\t\tvp_ap->nested_control.features.directhypercall = 0;\n\t\t\tvp_ap->current_nested_vmcs = 0;\n\t\t\tvp_ap->enlighten_vmentry = 0;\n\t\t}\n\n\t\tstatic_branch_disable(&enable_evmcs);\n\t}\n#endif\n\tvmx_cleanup_l1d_flush();\n}\nmodule_exit(vmx_exit);\n\nstatic int __init vmx_init(void)\n{\n\tint r, cpu;\n\n#if IS_ENABLED(CONFIG_HYPERV)\n\t/*\n\t * Enlightened VMCS usage should be recommended and the host needs\n\t * to support eVMCS v1 or above. We can also disable eVMCS support\n\t * with module parameter.\n\t */\n\tif (enlightened_vmcs &&\n\t    ms_hyperv.hints & HV_X64_ENLIGHTENED_VMCS_RECOMMENDED &&\n\t    (ms_hyperv.nested_features & HV_X64_ENLIGHTENED_VMCS_VERSION) >=\n\t    KVM_EVMCS_VERSION) {\n\t\tint cpu;\n\n\t\t/* Check that we have assist pages on all online CPUs */\n\t\tfor_each_online_cpu(cpu) {\n\t\t\tif (!hv_get_vp_assist_page(cpu)) {\n\t\t\t\tenlightened_vmcs = false;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (enlightened_vmcs) {\n\t\t\tpr_info(\"KVM: vmx: using Hyper-V Enlightened VMCS\\n\");\n\t\t\tstatic_branch_enable(&enable_evmcs);\n\t\t}\n\n\t\tif (ms_hyperv.nested_features & HV_X64_NESTED_DIRECT_FLUSH)\n\t\t\tvmx_x86_ops.enable_direct_tlbflush\n\t\t\t\t= hv_enable_direct_tlbflush;\n\n\t} else {\n\t\tenlightened_vmcs = false;\n\t}\n#endif\n\n\tr = kvm_init(&vmx_init_ops, sizeof(struct vcpu_vmx),\n\t\t     __alignof__(struct vcpu_vmx), THIS_MODULE);\n\tif (r)\n\t\treturn r;\n\n\t/*\n\t * Must be called after kvm_init() so enable_ept is properly set\n\t * up. Hand the parameter mitigation value in which was stored in\n\t * the pre module init parser. If no parameter was given, it will\n\t * contain 'auto' which will be turned into the default 'cond'\n\t * mitigation mode.\n\t */\n\tr = vmx_setup_l1d_flush(vmentry_l1d_flush_param);\n\tif (r) {\n\t\tvmx_exit();\n\t\treturn r;\n\t}\n\n\tfor_each_possible_cpu(cpu) {\n\t\tINIT_LIST_HEAD(&per_cpu(loaded_vmcss_on_cpu, cpu));\n\n\t\tpi_init_cpu(cpu);\n\t}\n\n#ifdef CONFIG_KEXEC_CORE\n\trcu_assign_pointer(crash_vmclear_loaded_vmcss,\n\t\t\t   crash_vmclear_local_loaded_vmcss);\n#endif\n\tvmx_check_vmcs12_offsets();\n\n\t/*\n\t * Shadow paging doesn't have a (further) performance penalty\n\t * from GUEST_MAXPHYADDR < HOST_MAXPHYADDR so enable it\n\t * by default\n\t */\n\tif (!enable_ept)\n\t\tallow_smaller_maxphyaddr = true;\n\n\treturn 0;\n}\nmodule_init(vmx_init);\n"}}, "reports": [{"events": [{"location": {"col": 1, "file": 0, "line": 747}, "message": "WARNING: Assignment of 0/1 to bool variable"}], "macros": [], "notes": [], "path": "/src/arch/x86/kvm/vmx/vmx.c", "reportHash": "e4b4fc93515a47e4ce7b77ea3bb399e2", "checkerName": "coccinelle", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 1, "file": 0, "line": 2625}, "message": "WARNING: Assignment of 0/1 to bool variable"}], "macros": [], "notes": [], "path": "/src/arch/x86/kvm/vmx/vmx.c", "reportHash": "e4b4fc93515a47e4ce7b77ea3bb399e2", "checkerName": "coccinelle", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 26, "file": 0, "line": 116}, "message": "WARNING: Assignment of 0/1 to bool variable"}], "macros": [], "notes": [], "path": "/src/arch/x86/kvm/vmx/vmx.c", "reportHash": "a93312f829eed22592edac5e2db0a896", "checkerName": "coccinelle", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 19, "file": 0, "line": 102}, "message": "WARNING: Assignment of 0/1 to bool variable"}], "macros": [], "notes": [], "path": "/src/arch/x86/kvm/vmx/vmx.c", "reportHash": "71a020f6c3859b92c70eec9705af25d4", "checkerName": "coccinelle", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 19, "file": 0, "line": 86}, "message": "WARNING: Assignment of 0/1 to bool variable"}], "macros": [], "notes": [], "path": "/src/arch/x86/kvm/vmx/vmx.c", "reportHash": "b781337f4131cdf846b048c38fbac1e9", "checkerName": "coccinelle", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 19, "file": 0, "line": 93}, "message": "WARNING: Assignment of 0/1 to bool variable"}], "macros": [], "notes": [], "path": "/src/arch/x86/kvm/vmx/vmx.c", "reportHash": "d101b90ae1cfe682183cb739b8736f00", "checkerName": "coccinelle", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 19, "file": 0, "line": 113}, "message": "WARNING: Assignment of 0/1 to bool variable"}], "macros": [], "notes": [], "path": "/src/arch/x86/kvm/vmx/vmx.c", "reportHash": "3c4c6ea9517510fb31d776ca0c88f8a7", "checkerName": "coccinelle", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 26, "file": 0, "line": 126}, "message": "WARNING: Assignment of 0/1 to bool variable"}], "macros": [], "notes": [], "path": "/src/arch/x86/kvm/vmx/vmx.c", "reportHash": "93a75167821297caff414026ef0d7476", "checkerName": "coccinelle", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 19, "file": 0, "line": 89}, "message": "WARNING: Assignment of 0/1 to bool variable"}], "macros": [], "notes": [], "path": "/src/arch/x86/kvm/vmx/vmx.c", "reportHash": "4328cf3fa9f196016626e69340261e43", "checkerName": "coccinelle", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 26, "file": 0, "line": 80}, "message": "WARNING: Assignment of 0/1 to bool variable"}], "macros": [], "notes": [], "path": "/src/arch/x86/kvm/vmx/vmx.c", "reportHash": "43fbfa58dd14dd1e89301d63089856a6", "checkerName": "coccinelle", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 19, "file": 0, "line": 77}, "message": "WARNING: Assignment of 0/1 to bool variable"}], "macros": [], "notes": [], "path": "/src/arch/x86/kvm/vmx/vmx.c", "reportHash": "353cbbe9a8f17ae7abf6b5579735f0be", "checkerName": "coccinelle", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 26, "file": 0, "line": 99}, "message": "WARNING: Assignment of 0/1 to bool variable"}], "macros": [], "notes": [], "path": "/src/arch/x86/kvm/vmx/vmx.c", "reportHash": "c8665713801aeadd7ce086b0e5e7abb0", "checkerName": "coccinelle", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 19, "file": 0, "line": 83}, "message": "WARNING: Assignment of 0/1 to bool variable"}], "macros": [], "notes": [], "path": "/src/arch/x86/kvm/vmx/vmx.c", "reportHash": "110bf8148ad184517f3272af6ac89982", "checkerName": "coccinelle", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 2, "file": 0, "line": 7749}, "message": "WARNING: Assignment of 0/1 to bool variable"}], "macros": [], "notes": [], "path": "/src/arch/x86/kvm/vmx/vmx.c", "reportHash": "b585a55c227eb2202be37960e709523e", "checkerName": "coccinelle", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 2, "file": 0, "line": 7755}, "message": "WARNING: Assignment of 0/1 to bool variable"}], "macros": [], "notes": [], "path": "/src/arch/x86/kvm/vmx/vmx.c", "reportHash": "020729df876e4176f10ccdc9b6e504da", "checkerName": "coccinelle", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 2, "file": 0, "line": 7758}, "message": "WARNING: Assignment of 0/1 to bool variable"}], "macros": [], "notes": [], "path": "/src/arch/x86/kvm/vmx/vmx.c", "reportHash": "f85b46016401f839ad12039c5e87f102", "checkerName": "coccinelle", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 2, "file": 0, "line": 7761}, "message": "WARNING: Assignment of 0/1 to bool variable"}], "macros": [], "notes": [], "path": "/src/arch/x86/kvm/vmx/vmx.c", "reportHash": "19497d0db0c92db2829d8fceace1d5af", "checkerName": "coccinelle", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 2, "file": 0, "line": 7764}, "message": "WARNING: Assignment of 0/1 to bool variable"}], "macros": [], "notes": [], "path": "/src/arch/x86/kvm/vmx/vmx.c", "reportHash": "b7a27b00b88933c4f791784a608795b4", "checkerName": "coccinelle", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 2, "file": 0, "line": 7767}, "message": "WARNING: Assignment of 0/1 to bool variable"}], "macros": [], "notes": [], "path": "/src/arch/x86/kvm/vmx/vmx.c", "reportHash": "755cfaeb566c4830b4c5be4129cd5ec0", "checkerName": "coccinelle", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 2, "file": 0, "line": 7798}, "message": "WARNING: Assignment of 0/1 to bool variable"}], "macros": [], "notes": [], "path": "/src/arch/x86/kvm/vmx/vmx.c", "reportHash": "e21bdb830910d9e1c12c10f9e11c0985", "checkerName": "coccinelle", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 2, "file": 0, "line": 7828}, "message": "WARNING: Assignment of 0/1 to bool variable"}], "macros": [], "notes": [], "path": "/src/arch/x86/kvm/vmx/vmx.c", "reportHash": "d6e4cf134711140a96ec87b7b754e438", "checkerName": "coccinelle", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 26, "file": 0, "line": 110}, "message": "WARNING: Assignment of 0/1 to bool variable"}], "macros": [], "notes": [], "path": "/src/arch/x86/kvm/vmx/vmx.c", "reportHash": "9a2da70078d71047933452605e16c18f", "checkerName": "coccinelle", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 2, "file": 0, "line": 4217}, "message": "WARNING: Assignment of 0/1 to bool variable"}], "macros": [], "notes": [], "path": "/src/arch/x86/kvm/vmx/vmx.c", "reportHash": "19497d0db0c92db2829d8fceace1d5af", "checkerName": "coccinelle", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 1, "file": 0, "line": 6781}, "message": "WARNING: Assignment of 0/1 to bool variable"}], "macros": [], "notes": [], "path": "/src/arch/x86/kvm/vmx/vmx.c", "reportHash": "4810815a8443836e49f85cc1ce3435d8", "checkerName": "coccinelle", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 1, "file": 0, "line": 6798}, "message": "WARNING: Assignment of 0/1 to bool variable"}], "macros": [], "notes": [], "path": "/src/arch/x86/kvm/vmx/vmx.c", "reportHash": "8ff7a45e0a7ae4e1b55c66bbb230db4b", "checkerName": "coccinelle", "reviewStatus": null, "severity": "UNSPECIFIED"}]};
      window.onload = function() {
        if (!browserCompatible) {
          setNonCompatibleBrowserMessage();
        } else {
          BugViewer.init(data.files, data.reports);
          BugViewer.create();
          BugViewer.initByUrl();
        }
      };
    </script>
  </head>
  <body>
  <div class="container">
    <div id="content">
      <div id="side-bar">
        <div class="header">
          <a href="index.html" class="button">&#8249; Return to List</a>
        </div>
        <div id="report-nav">
          <div class="header">Reports</div>
        </div>
      </div>
      <div id="editor-wrapper">
        <div class="header">
          <div id="file">
            <span class="label">File:</span>
            <span id="file-path"></span>
          </div>
          <div id="checker">
            <span class="label">Checker name:</span>
            <span id="checker-name"></span>
          </div>
          <div id="review-status-wrapper">
            <span class="label">Review status:</span>
            <span id="review-status"></span>
          </div>
        </div>
        <div id="editor"></div>
      </div>
    </div>
  </div>
  </body>
</html>
