<!DOCTYPE html>
<html>
  <head>
    <title>Plist HTML Viewer</title>

    <meta charset="UTF-8">

    <style type="text/css">
      .CodeMirror{font-family:monospace;height:300px;color:#000;direction:ltr}.CodeMirror-lines{padding:4px 0}.CodeMirror pre{padding:0 4px}.CodeMirror-gutter-filler,.CodeMirror-scrollbar-filler{background-color:#fff}.CodeMirror-gutters{border-right:1px solid #ddd;background-color:#f7f7f7;white-space:nowrap}.CodeMirror-linenumber{padding:0 3px 0 5px;min-width:20px;text-align:right;color:#999;white-space:nowrap}.CodeMirror-guttermarker{color:#000}.CodeMirror-guttermarker-subtle{color:#999}.CodeMirror-cursor{border-left:1px solid #000;border-right:none;width:0}.CodeMirror div.CodeMirror-secondarycursor{border-left:1px solid silver}.cm-fat-cursor .CodeMirror-cursor{width:auto;border:0!important;background:#7e7}.cm-fat-cursor div.CodeMirror-cursors{z-index:1}.cm-animate-fat-cursor{width:auto;border:0;-webkit-animation:blink 1.06s steps(1) infinite;-moz-animation:blink 1.06s steps(1) infinite;animation:blink 1.06s steps(1) infinite;background-color:#7e7}@-moz-keyframes blink{50%{background-color:transparent}}@-webkit-keyframes blink{50%{background-color:transparent}}@keyframes blink{50%{background-color:transparent}}.cm-tab{display:inline-block;text-decoration:inherit}.CodeMirror-rulers{position:absolute;left:0;right:0;top:-50px;bottom:-20px;overflow:hidden}.CodeMirror-ruler{border-left:1px solid #ccc;top:0;bottom:0;position:absolute}.cm-s-default .cm-header{color:#00f}.cm-s-default .cm-quote{color:#090}.cm-negative{color:#d44}.cm-positive{color:#292}.cm-header,.cm-strong{font-weight:700}.cm-em{font-style:italic}.cm-link{text-decoration:underline}.cm-strikethrough{text-decoration:line-through}.cm-s-default .cm-keyword{color:#708}.cm-s-default .cm-atom{color:#219}.cm-s-default .cm-number{color:#164}.cm-s-default .cm-def{color:#00f}.cm-s-default .cm-variable-2{color:#05a}.cm-s-default .cm-type,.cm-s-default .cm-variable-3{color:#085}.cm-s-default .cm-comment{color:#a50}.cm-s-default .cm-string{color:#a11}.cm-s-default .cm-string-2{color:#f50}.cm-s-default .cm-meta{color:#555}.cm-s-default .cm-qualifier{color:#555}.cm-s-default .cm-builtin{color:#30a}.cm-s-default .cm-bracket{color:#997}.cm-s-default .cm-tag{color:#170}.cm-s-default .cm-attribute{color:#00c}.cm-s-default .cm-hr{color:#999}.cm-s-default .cm-link{color:#00c}.cm-s-default .cm-error{color:red}.cm-invalidchar{color:red}.CodeMirror-composing{border-bottom:2px solid}div.CodeMirror span.CodeMirror-matchingbracket{color:#0f0}div.CodeMirror span.CodeMirror-nonmatchingbracket{color:#f22}.CodeMirror-matchingtag{background:rgba(255,150,0,.3)}.CodeMirror-activeline-background{background:#e8f2ff}.CodeMirror{position:relative;overflow:hidden;background:#fff}.CodeMirror-scroll{overflow:scroll!important;margin-bottom:-30px;margin-right:-30px;padding-bottom:30px;height:100%;outline:0;position:relative}.CodeMirror-sizer{position:relative;border-right:30px solid transparent}.CodeMirror-gutter-filler,.CodeMirror-hscrollbar,.CodeMirror-scrollbar-filler,.CodeMirror-vscrollbar{position:absolute;z-index:6;display:none}.CodeMirror-vscrollbar{right:0;top:0;overflow-x:hidden;overflow-y:scroll}.CodeMirror-hscrollbar{bottom:0;left:0;overflow-y:hidden;overflow-x:scroll}.CodeMirror-scrollbar-filler{right:0;bottom:0}.CodeMirror-gutter-filler{left:0;bottom:0}.CodeMirror-gutters{position:absolute;left:0;top:0;min-height:100%;z-index:3}.CodeMirror-gutter{white-space:normal;height:100%;display:inline-block;vertical-align:top;margin-bottom:-30px}.CodeMirror-gutter-wrapper{position:absolute;z-index:4;background:0 0!important;border:none!important}.CodeMirror-gutter-background{position:absolute;top:0;bottom:0;z-index:4}.CodeMirror-gutter-elt{position:absolute;cursor:default;z-index:4}.CodeMirror-gutter-wrapper ::selection{background-color:transparent}.CodeMirror-gutter-wrapper ::-moz-selection{background-color:transparent}.CodeMirror-lines{cursor:text;min-height:1px}.CodeMirror pre{-moz-border-radius:0;-webkit-border-radius:0;border-radius:0;border-width:0;background:0 0;font-family:inherit;font-size:inherit;margin:0;white-space:pre;word-wrap:normal;line-height:inherit;color:inherit;z-index:2;position:relative;overflow:visible;-webkit-tap-highlight-color:transparent;-webkit-font-variant-ligatures:contextual;font-variant-ligatures:contextual}.CodeMirror-wrap pre{word-wrap:break-word;white-space:pre-wrap;word-break:normal}.CodeMirror-linebackground{position:absolute;left:0;right:0;top:0;bottom:0;z-index:0}.CodeMirror-linewidget{position:relative;z-index:2;overflow:auto}.CodeMirror-rtl pre{direction:rtl}.CodeMirror-code{outline:0}.CodeMirror-gutter,.CodeMirror-gutters,.CodeMirror-linenumber,.CodeMirror-scroll,.CodeMirror-sizer{-moz-box-sizing:content-box;box-sizing:content-box}.CodeMirror-measure{position:absolute;width:100%;height:0;overflow:hidden;visibility:hidden}.CodeMirror-cursor{position:absolute;pointer-events:none}.CodeMirror-measure pre{position:static}div.CodeMirror-cursors{visibility:hidden;position:relative;z-index:3}div.CodeMirror-dragcursors{visibility:visible}.CodeMirror-focused div.CodeMirror-cursors{visibility:visible}.CodeMirror-selected{background:#d9d9d9}.CodeMirror-focused .CodeMirror-selected{background:#d7d4f0}.CodeMirror-crosshair{cursor:crosshair}.CodeMirror-line::selection,.CodeMirror-line>span::selection,.CodeMirror-line>span>span::selection{background:#d7d4f0}.CodeMirror-line::-moz-selection,.CodeMirror-line>span::-moz-selection,.CodeMirror-line>span>span::-moz-selection{background:#d7d4f0}.cm-searching{background-color:#ffa;background-color:rgba(255,255,0,.4)}.cm-force-border{padding-right:.1px}@media print{.CodeMirror div.CodeMirror-cursors{visibility:hidden}}.cm-tab-wrap-hack:after{content:''}span.CodeMirror-selectedtext{background:0 0}
/*# sourceMappingURL=codemirror.min.css.map */

      .severity-low {
  background-color: #669603;
}

.severity-low:after {
  content : 'L';
}

.severity-unspecified {
  background-color: #666666;
}

.severity-unspecified:after {
  content : 'U';
}

.severity-style {
  background-color: #9932cc;
}

.severity-style:after {
  content : 'S';
}

.severity-medium {
  background-color: #a9d323;
  color: black;
}

.severity-medium:after {
  content : 'M';
}

.severity-high {
  background-color: #ffa800;
}

.severity-high:after {
  content : 'H';
}

.severity-critical {
  background-color: #e92625;
}

.severity-critical:after {
  content : 'C';
}

i[class*="severity-"] {
  line-height: normal;
  text-transform: capitalize;
  font-size: 0.8em;
  font-weight: bold;
  color: white;
  display: inline-block;
  width: 16px;
  height: 16px;
  text-align: center;
  font-family: sans-serif;
}

      html, body {
  width: 100%;
  height: 100%;
  padding: 0px;
  margin: 0px;
}

div.container {
  padding: 10px;
}

#content {
  height: 100%;
  display: block;
  overflow: hidden;
}

#content > div {
  margin: 10px;
  overflow: hidden;
  border: 1px solid #ddd;
  border-radius: 3px;
  overflow: hidden;
  height: 97%;
}

.button {
  background-color: #f1f1f1;
  text-decoration: none;
  display: inline-block;
  padding: 8px 16px;
  color: black;
  cursor: pointer;
}

.button:hover {
  background-color: #ddd;
  color: black;
}

.review-status {
  color: white;
  text-align: center;
}

.review-status-confirmed {
  background-color: #e92625;
}

.review-status-false-positive {
  background-color: grey;
}

.review-status-intentional {
  background-color: #669603;
}

      div.container {
  width: 100%;
  height: 100%;
  padding: 0px;
}

#editor-wrapper {
  margin: 10px;
}

#side-bar {
  float: left;
  width: 260px;
  margin: 0px;
}

#report-nav ul {
  list-style-type: none;
  padding: 0;
  margin: 0;
  overflow-y: auto;
  height: 100%;
}

#report-nav ul > li {
  padding: .4em;
  background-color: #fff;
  border-bottom: 1px solid rgba(0,0,0,.125);
  text-align: left;
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

#report-nav ul > li.active {
  background-color: #427ea9;
  color: white;
}

#report-nav ul > li:hover {
  background-color: #427ea9;
  color: white;
  cursor: pointer;
}

#report-nav ul a {
  text-decoration: none;
}

#report-nav i[class*="severity-"] {
  margin-right: 5px;
}

.header {
  border-bottom: 1px solid lightgrey;
  font-family: monospace;
  padding: 10px;
  background-color: #fafbfc;
  border-bottom: 1px solid #e1e4e8;
  border-top-left-radius: 2px;
  border-top-right-radius: 2px;
}

#report-nav .header {
  font-weight: bold;
}

#editor-wrapper .header > div {
  padding-top: 2px;
}

#file-path,
#checker-name {
  color: #195ea2;
}

#review-status {
  padding: 0px 5px;
}

#file-path {
  font-family: monospace;
}

.check-msg {
  display: inline-block;
  padding: 3px 6px;
  margin: 1px;
  -webkit-border-radius: 5px;
  -moz-border-radius: 5px;
  border-radius: 5px;
}

.check-msg.info {
  color: #00546f;
  background-color: #bfdfe9;
  border: 1px solid #87a8b3;
}

.check-msg.error {
  background-color: #f2dede;
  color: #a94442;
  border: 1px solid #ebcccc;
}

.check-msg.macro {
  background-color: #d7dac2;
  color: #4f5c6d;
  border: 1px solid #d7dac2;
}

.check-msg.note {
  background-color: #d7d7d7;
  color: #4f5c6d;
  border: 1px solid #bfbfbf;
}

.check-msg.current {
  border: 2px dashed #3692ff;
}

.check-msg .tag {
  padding: 1px 5px;
  text-align: center;
  border-radius: 2px;
  margin-right: 5px;
  text-decoration: inherit;
}

.check-msg .tag.macro {
  background-color: #83876a;
  color: white;
  text-transform: capitalize;
}

.check-msg .tag.note {
  background-color: #9299a1;
  color: white;
  text-transform: capitalize;
}

.checker-enum {
  color: white;
  padding: 1px 5px;
  text-align: center;
  border-radius: 25px;
  margin-right: 5px;
  text-decoration: inherit;
}

.checker-enum.info {
  background-color: #427ea9;
}

.checker-enum.error {
  background-color: #a94442;
}

.arrow {
  border: solid black;
  border-width: 0 3px 3px 0;
  display: inline-block;
  padding: 3px;
  cursor: pointer;
  margin: 0px 5px;
}

.arrow:hover {
  border: solid #437ea8;
  border-width: 0 3px 3px 0;
}

.left-arrow {
  transform: rotate(135deg);
  -webkit-transform: rotate(135deg);
}

.right-arrow {
  transform: rotate(-45deg);
  -webkit-transform: rotate(-45deg);
}

    </style>

    <script type="text/javascript">
      function setNonCompatibleBrowserMessage() {
  document.body.innerHTML =
    '<h2 style="margin-left: 20px;">Your browser is not compatible with CodeChecker Viewer!</h2> \
     <p style="margin-left: 20px;">The version required for the following browsers are:</p> \
     <ul style="margin-left: 20px;"> \
     <li>Internet Explorer: version 9 or newer</li> \
     <li>Firefox: version 22.0 or newer</li> \
     </ul>';
}

// http://stackoverflow.com/questions/5916900/how-can-you-detect-the-version-of-a-browser
var browserVersion = (function(){
  var ua = navigator.userAgent, tem,
    M = ua.match(/(opera|chrome|safari|firefox|msie|trident(?=\/))\/?\s*(\d+)/i) || [];

  if (/trident/i.test(M[1])) {
    tem = /\brv[ :]+(\d+)/g.exec(ua) || [];
    return 'IE ' + (tem[1] || '');
  }

  if (M[1] === 'Chrome') {
    tem = ua.match(/\b(OPR|Edge)\/(\d+)/);
    if (tem != null) return tem.slice(1).join(' ').replace('OPR', 'Opera');
  }

  M = M[2] ? [M[1], M[2]] : [navigator.appName, navigator.appVersion, '-?'];
  if ((tem = ua.match(/version\/(\d+)/i)) != null) M.splice(1, 1, tem[1]);
    return M.join(' ');
})();

var pos = browserVersion.indexOf(' ');
var browser = browserVersion.substr(0, pos);
var version = parseInt(browserVersion.substr(pos + 1));

var browserCompatible
  = browser === 'Firefox'
  ? version >= 22
  : browser === 'IE'
  ? version >= 9
  : true;


      /* MIT License

Copyright (C) 2017 by Marijn Haverbeke <marijnh@gmail.com> and others

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
 */
      !function(e,t){"object"==typeof exports&&"undefined"!=typeof module?module.exports=t():"function"==typeof define&&define.amd?define(t):e.CodeMirror=t()}(this,function(){"use strict";function e(e){return new RegExp("(^|\\s)"+e+"(?:$|\\s)\\s*")}function t(e){for(var t=e.childNodes.length;t>0;--t)e.removeChild(e.firstChild);return e}function r(e,r){return t(e).appendChild(r)}function n(e,t,r,n){var i=document.createElement(e);if(r&&(i.className=r),n&&(i.style.cssText=n),"string"==typeof t)i.appendChild(document.createTextNode(t));else if(t)for(var o=0;o<t.length;++o)i.appendChild(t[o]);return i}function i(e,t,r,i){var o=n(e,t,r,i);return o.setAttribute("role","presentation"),o}function o(e,t){if(3==t.nodeType&&(t=t.parentNode),e.contains)return e.contains(t);do{if(11==t.nodeType&&(t=t.host),t==e)return!0}while(t=t.parentNode)}function l(){var e;try{e=document.activeElement}catch(t){e=document.body||null}for(;e&&e.shadowRoot&&e.shadowRoot.activeElement;)e=e.shadowRoot.activeElement;return e}function s(t,r){var n=t.className;e(r).test(n)||(t.className+=(n?" ":"")+r)}function a(t,r){for(var n=t.split(" "),i=0;i<n.length;i++)n[i]&&!e(n[i]).test(r)&&(r+=" "+n[i]);return r}function u(e){var t=Array.prototype.slice.call(arguments,1);return function(){return e.apply(null,t)}}function c(e,t,r){t||(t={});for(var n in e)!e.hasOwnProperty(n)||!1===r&&t.hasOwnProperty(n)||(t[n]=e[n]);return t}function f(e,t,r,n,i){null==t&&-1==(t=e.search(/[^\s\u00a0]/))&&(t=e.length);for(var o=n||0,l=i||0;;){var s=e.indexOf("\t",o);if(s<0||s>=t)return l+(t-o);l+=s-o,l+=r-l%r,o=s+1}}function h(e,t){for(var r=0;r<e.length;++r)if(e[r]==t)return r;return-1}function d(e,t,r){for(var n=0,i=0;;){var o=e.indexOf("\t",n);-1==o&&(o=e.length);var l=o-n;if(o==e.length||i+l>=t)return n+Math.min(l,t-i);if(i+=o-n,i+=r-i%r,n=o+1,i>=t)return n}}function p(e){for(;Kl.length<=e;)Kl.push(g(Kl)+" ");return Kl[e]}function g(e){return e[e.length-1]}function v(e,t){for(var r=[],n=0;n<e.length;n++)r[n]=t(e[n],n);return r}function m(e,t,r){for(var n=0,i=r(t);n<e.length&&r(e[n])<=i;)n++;e.splice(n,0,t)}function y(){}function b(e,t){var r;return Object.create?r=Object.create(e):(y.prototype=e,r=new y),t&&c(t,r),r}function w(e){return/\w/.test(e)||e>""&&(e.toUpperCase()!=e.toLowerCase()||jl.test(e))}function x(e,t){return t?!!(t.source.indexOf("\\w")>-1&&w(e))||t.test(e):w(e)}function C(e){for(var t in e)if(e.hasOwnProperty(t)&&e[t])return!1;return!0}function S(e){return e.charCodeAt(0)>=768&&Xl.test(e)}function L(e,t,r){for(;(r<0?t>0:t<e.length)&&S(e.charAt(t));)t+=r;return t}function k(e,t,r){for(var n=t>r?-1:1;;){if(t==r)return t;var i=(t+r)/2,o=n<0?Math.ceil(i):Math.floor(i);if(o==t)return e(o)?t:r;e(o)?r=o:t=o+n}}function T(e,t,r){var o=this;this.input=r,o.scrollbarFiller=n("div",null,"CodeMirror-scrollbar-filler"),o.scrollbarFiller.setAttribute("cm-not-content","true"),o.gutterFiller=n("div",null,"CodeMirror-gutter-filler"),o.gutterFiller.setAttribute("cm-not-content","true"),o.lineDiv=i("div",null,"CodeMirror-code"),o.selectionDiv=n("div",null,null,"position: relative; z-index: 1"),o.cursorDiv=n("div",null,"CodeMirror-cursors"),o.measure=n("div",null,"CodeMirror-measure"),o.lineMeasure=n("div",null,"CodeMirror-measure"),o.lineSpace=i("div",[o.measure,o.lineMeasure,o.selectionDiv,o.cursorDiv,o.lineDiv],null,"position: relative; outline: none");var l=i("div",[o.lineSpace],"CodeMirror-lines");o.mover=n("div",[l],null,"position: relative"),o.sizer=n("div",[o.mover],"CodeMirror-sizer"),o.sizerWidth=null,o.heightForcer=n("div",null,null,"position: absolute; height: "+Rl+"px; width: 1px;"),o.gutters=n("div",null,"CodeMirror-gutters"),o.lineGutter=null,o.scroller=n("div",[o.sizer,o.heightForcer,o.gutters],"CodeMirror-scroll"),o.scroller.setAttribute("tabIndex","-1"),o.wrapper=n("div",[o.scrollbarFiller,o.gutterFiller,o.scroller],"CodeMirror"),gl&&vl<8&&(o.gutters.style.zIndex=-1,o.scroller.style.paddingRight=0),ml||fl&&Tl||(o.scroller.draggable=!0),e&&(e.appendChild?e.appendChild(o.wrapper):e(o.wrapper)),o.viewFrom=o.viewTo=t.first,o.reportedViewFrom=o.reportedViewTo=t.first,o.view=[],o.renderedView=null,o.externalMeasured=null,o.viewOffset=0,o.lastWrapHeight=o.lastWrapWidth=0,o.updateLineNumbers=null,o.nativeBarWidth=o.barHeight=o.barWidth=0,o.scrollbarsClipped=!1,o.lineNumWidth=o.lineNumInnerWidth=o.lineNumChars=null,o.alignWidgets=!1,o.cachedCharWidth=o.cachedTextHeight=o.cachedPaddingH=null,o.maxLine=null,o.maxLineLength=0,o.maxLineChanged=!1,o.wheelDX=o.wheelDY=o.wheelStartX=o.wheelStartY=null,o.shift=!1,o.selForContextMenu=null,o.activeTouch=null,r.init(o)}function M(e,t){if((t-=e.first)<0||t>=e.size)throw new Error("There is no line "+(t+e.first)+" in the document.");for(var r=e;!r.lines;)for(var n=0;;++n){var i=r.children[n],o=i.chunkSize();if(t<o){r=i;break}t-=o}return r.lines[t]}function N(e,t,r){var n=[],i=t.line;return e.iter(t.line,r.line+1,function(e){var o=e.text;i==r.line&&(o=o.slice(0,r.ch)),i==t.line&&(o=o.slice(t.ch)),n.push(o),++i}),n}function O(e,t,r){var n=[];return e.iter(t,r,function(e){n.push(e.text)}),n}function A(e,t){var r=t-e.height;if(r)for(var n=e;n;n=n.parent)n.height+=r}function W(e){if(null==e.parent)return null;for(var t=e.parent,r=h(t.lines,e),n=t.parent;n;t=n,n=n.parent)for(var i=0;n.children[i]!=t;++i)r+=n.children[i].chunkSize();return r+t.first}function D(e,t){var r=e.first;e:do{for(var n=0;n<e.children.length;++n){var i=e.children[n],o=i.height;if(t<o){e=i;continue e}t-=o,r+=i.chunkSize()}return r}while(!e.lines);for(var l=0;l<e.lines.length;++l){var s=e.lines[l].height;if(t<s)break;t-=s}return r+l}function H(e,t){return t>=e.first&&t<e.first+e.size}function F(e,t){return String(e.lineNumberFormatter(t+e.firstLineNumber))}function E(e,t,r){if(void 0===r&&(r=null),!(this instanceof E))return new E(e,t,r);this.line=e,this.ch=t,this.sticky=r}function P(e,t){return e.line-t.line||e.ch-t.ch}function I(e,t){return e.sticky==t.sticky&&0==P(e,t)}function z(e){return E(e.line,e.ch)}function R(e,t){return P(e,t)<0?t:e}function B(e,t){return P(e,t)<0?e:t}function G(e,t){return Math.max(e.first,Math.min(t,e.first+e.size-1))}function U(e,t){if(t.line<e.first)return E(e.first,0);var r=e.first+e.size-1;return t.line>r?E(r,M(e,r).text.length):V(t,M(e,t.line).text.length)}function V(e,t){var r=e.ch;return null==r||r>t?E(e.line,t):r<0?E(e.line,0):e}function K(e,t){for(var r=[],n=0;n<t.length;n++)r[n]=U(e,t[n]);return r}function j(){Yl=!0}function X(){_l=!0}function Y(e,t,r){this.marker=e,this.from=t,this.to=r}function _(e,t){if(e)for(var r=0;r<e.length;++r){var n=e[r];if(n.marker==t)return n}}function $(e,t){for(var r,n=0;n<e.length;++n)e[n]!=t&&(r||(r=[])).push(e[n]);return r}function q(e,t){e.markedSpans=e.markedSpans?e.markedSpans.concat([t]):[t],t.marker.attachLine(e)}function Z(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t)||o.from==t&&"bookmark"==l.type&&(!r||!o.marker.insertLeft)){var s=null==o.to||(l.inclusiveRight?o.to>=t:o.to>t);(n||(n=[])).push(new Y(l,o.from,s?null:o.to))}}return n}function Q(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.to||(l.inclusiveRight?o.to>=t:o.to>t)||o.from==t&&"bookmark"==l.type&&(!r||o.marker.insertLeft)){var s=null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t);(n||(n=[])).push(new Y(l,s?null:o.from-t,null==o.to?null:o.to-t))}}return n}function J(e,t){if(t.full)return null;var r=H(e,t.from.line)&&M(e,t.from.line).markedSpans,n=H(e,t.to.line)&&M(e,t.to.line).markedSpans;if(!r&&!n)return null;var i=t.from.ch,o=t.to.ch,l=0==P(t.from,t.to),s=Z(r,i,l),a=Q(n,o,l),u=1==t.text.length,c=g(t.text).length+(u?i:0);if(s)for(var f=0;f<s.length;++f){var h=s[f];if(null==h.to){var d=_(a,h.marker);d?u&&(h.to=null==d.to?null:d.to+c):h.to=i}}if(a)for(var p=0;p<a.length;++p){var v=a[p];null!=v.to&&(v.to+=c),null==v.from?_(s,v.marker)||(v.from=c,u&&(s||(s=[])).push(v)):(v.from+=c,u&&(s||(s=[])).push(v))}s&&(s=ee(s)),a&&a!=s&&(a=ee(a));var m=[s];if(!u){var y,b=t.text.length-2;if(b>0&&s)for(var w=0;w<s.length;++w)null==s[w].to&&(y||(y=[])).push(new Y(s[w].marker,null,null));for(var x=0;x<b;++x)m.push(y);m.push(a)}return m}function ee(e){for(var t=0;t<e.length;++t){var r=e[t];null!=r.from&&r.from==r.to&&!1!==r.marker.clearWhenEmpty&&e.splice(t--,1)}return e.length?e:null}function te(e,t,r){var n=null;if(e.iter(t.line,r.line+1,function(e){if(e.markedSpans)for(var t=0;t<e.markedSpans.length;++t){var r=e.markedSpans[t].marker;!r.readOnly||n&&-1!=h(n,r)||(n||(n=[])).push(r)}}),!n)return null;for(var i=[{from:t,to:r}],o=0;o<n.length;++o)for(var l=n[o],s=l.find(0),a=0;a<i.length;++a){var u=i[a];if(!(P(u.to,s.from)<0||P(u.from,s.to)>0)){var c=[a,1],f=P(u.from,s.from),d=P(u.to,s.to);(f<0||!l.inclusiveLeft&&!f)&&c.push({from:u.from,to:s.from}),(d>0||!l.inclusiveRight&&!d)&&c.push({from:s.to,to:u.to}),i.splice.apply(i,c),a+=c.length-3}}return i}function re(e){var t=e.markedSpans;if(t){for(var r=0;r<t.length;++r)t[r].marker.detachLine(e);e.markedSpans=null}}function ne(e,t){if(t){for(var r=0;r<t.length;++r)t[r].marker.attachLine(e);e.markedSpans=t}}function ie(e){return e.inclusiveLeft?-1:0}function oe(e){return e.inclusiveRight?1:0}function le(e,t){var r=e.lines.length-t.lines.length;if(0!=r)return r;var n=e.find(),i=t.find(),o=P(n.from,i.from)||ie(e)-ie(t);if(o)return-o;var l=P(n.to,i.to)||oe(e)-oe(t);return l||t.id-e.id}function se(e,t){var r,n=_l&&e.markedSpans;if(n)for(var i=void 0,o=0;o<n.length;++o)(i=n[o]).marker.collapsed&&null==(t?i.from:i.to)&&(!r||le(r,i.marker)<0)&&(r=i.marker);return r}function ae(e){return se(e,!0)}function ue(e){return se(e,!1)}function ce(e,t,r,n,i){var o=M(e,t),l=_l&&o.markedSpans;if(l)for(var s=0;s<l.length;++s){var a=l[s];if(a.marker.collapsed){var u=a.marker.find(0),c=P(u.from,r)||ie(a.marker)-ie(i),f=P(u.to,n)||oe(a.marker)-oe(i);if(!(c>=0&&f<=0||c<=0&&f>=0)&&(c<=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.to,r)>=0:P(u.to,r)>0)||c>=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.from,n)<=0:P(u.from,n)<0)))return!0}}}function fe(e){for(var t;t=ae(e);)e=t.find(-1,!0).line;return e}function he(e){for(var t;t=ue(e);)e=t.find(1,!0).line;return e}function de(e){for(var t,r;t=ue(e);)e=t.find(1,!0).line,(r||(r=[])).push(e);return r}function pe(e,t){var r=M(e,t),n=fe(r);return r==n?t:W(n)}function ge(e,t){if(t>e.lastLine())return t;var r,n=M(e,t);if(!ve(e,n))return t;for(;r=ue(n);)n=r.find(1,!0).line;return W(n)+1}function ve(e,t){var r=_l&&t.markedSpans;if(r)for(var n=void 0,i=0;i<r.length;++i)if((n=r[i]).marker.collapsed){if(null==n.from)return!0;if(!n.marker.widgetNode&&0==n.from&&n.marker.inclusiveLeft&&me(e,t,n))return!0}}function me(e,t,r){if(null==r.to){var n=r.marker.find(1,!0);return me(e,n.line,_(n.line.markedSpans,r.marker))}if(r.marker.inclusiveRight&&r.to==t.text.length)return!0;for(var i=void 0,o=0;o<t.markedSpans.length;++o)if((i=t.markedSpans[o]).marker.collapsed&&!i.marker.widgetNode&&i.from==r.to&&(null==i.to||i.to!=r.from)&&(i.marker.inclusiveLeft||r.marker.inclusiveRight)&&me(e,t,i))return!0}function ye(e){for(var t=0,r=(e=fe(e)).parent,n=0;n<r.lines.length;++n){var i=r.lines[n];if(i==e)break;t+=i.height}for(var o=r.parent;o;r=o,o=r.parent)for(var l=0;l<o.children.length;++l){var s=o.children[l];if(s==r)break;t+=s.height}return t}function be(e){if(0==e.height)return 0;for(var t,r=e.text.length,n=e;t=ae(n);){var i=t.find(0,!0);n=i.from.line,r+=i.from.ch-i.to.ch}for(n=e;t=ue(n);){var o=t.find(0,!0);r-=n.text.length-o.from.ch,r+=(n=o.to.line).text.length-o.to.ch}return r}function we(e){var t=e.display,r=e.doc;t.maxLine=M(r,r.first),t.maxLineLength=be(t.maxLine),t.maxLineChanged=!0,r.iter(function(e){var r=be(e);r>t.maxLineLength&&(t.maxLineLength=r,t.maxLine=e)})}function xe(e,t,r,n){if(!e)return n(t,r,"ltr",0);for(var i=!1,o=0;o<e.length;++o){var l=e[o];(l.from<r&&l.to>t||t==r&&l.to==t)&&(n(Math.max(l.from,t),Math.min(l.to,r),1==l.level?"rtl":"ltr",o),i=!0)}i||n(t,r,"ltr")}function Ce(e,t,r){var n;$l=null;for(var i=0;i<e.length;++i){var o=e[i];if(o.from<t&&o.to>t)return i;o.to==t&&(o.from!=o.to&&"before"==r?n=i:$l=i),o.from==t&&(o.from!=o.to&&"before"!=r?n=i:$l=i)}return null!=n?n:$l}function Se(e,t){var r=e.order;return null==r&&(r=e.order=ql(e.text,t)),r}function Le(e,t){return e._handlers&&e._handlers[t]||Zl}function ke(e,t,r){if(e.removeEventListener)e.removeEventListener(t,r,!1);else if(e.detachEvent)e.detachEvent("on"+t,r);else{var n=e._handlers,i=n&&n[t];if(i){var o=h(i,r);o>-1&&(n[t]=i.slice(0,o).concat(i.slice(o+1)))}}}function Te(e,t){var r=Le(e,t);if(r.length)for(var n=Array.prototype.slice.call(arguments,2),i=0;i<r.length;++i)r[i].apply(null,n)}function Me(e,t,r){return"string"==typeof t&&(t={type:t,preventDefault:function(){this.defaultPrevented=!0}}),Te(e,r||t.type,e,t),He(t)||t.codemirrorIgnore}function Ne(e){var t=e._handlers&&e._handlers.cursorActivity;if(t)for(var r=e.curOp.cursorActivityHandlers||(e.curOp.cursorActivityHandlers=[]),n=0;n<t.length;++n)-1==h(r,t[n])&&r.push(t[n])}function Oe(e,t){return Le(e,t).length>0}function Ae(e){e.prototype.on=function(e,t){Ql(this,e,t)},e.prototype.off=function(e,t){ke(this,e,t)}}function We(e){e.preventDefault?e.preventDefault():e.returnValue=!1}function De(e){e.stopPropagation?e.stopPropagation():e.cancelBubble=!0}function He(e){return null!=e.defaultPrevented?e.defaultPrevented:0==e.returnValue}function Fe(e){We(e),De(e)}function Ee(e){return e.target||e.srcElement}function Pe(e){var t=e.which;return null==t&&(1&e.button?t=1:2&e.button?t=3:4&e.button&&(t=2)),Ml&&e.ctrlKey&&1==t&&(t=3),t}function Ie(e){if(null==Il){var t=n("span","​");r(e,n("span",[t,document.createTextNode("x")])),0!=e.firstChild.offsetHeight&&(Il=t.offsetWidth<=1&&t.offsetHeight>2&&!(gl&&vl<8))}var i=Il?n("span","​"):n("span"," ",null,"display: inline-block; width: 1px; margin-right: -1px");return i.setAttribute("cm-text",""),i}function ze(e){if(null!=zl)return zl;var n=r(e,document.createTextNode("AخA")),i=Wl(n,0,1).getBoundingClientRect(),o=Wl(n,1,2).getBoundingClientRect();return t(e),!(!i||i.left==i.right)&&(zl=o.right-i.right<3)}function Re(e){if(null!=ns)return ns;var t=r(e,n("span","x")),i=t.getBoundingClientRect(),o=Wl(t,0,1).getBoundingClientRect();return ns=Math.abs(i.left-o.left)>1}function Be(e,t){arguments.length>2&&(t.dependencies=Array.prototype.slice.call(arguments,2)),is[e]=t}function Ge(e){if("string"==typeof e&&os.hasOwnProperty(e))e=os[e];else if(e&&"string"==typeof e.name&&os.hasOwnProperty(e.name)){var t=os[e.name];"string"==typeof t&&(t={name:t}),(e=b(t,e)).name=t.name}else{if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+xml$/.test(e))return Ge("application/xml");if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+json$/.test(e))return Ge("application/json")}return"string"==typeof e?{name:e}:e||{name:"null"}}function Ue(e,t){t=Ge(t);var r=is[t.name];if(!r)return Ue(e,"text/plain");var n=r(e,t);if(ls.hasOwnProperty(t.name)){var i=ls[t.name];for(var o in i)i.hasOwnProperty(o)&&(n.hasOwnProperty(o)&&(n["_"+o]=n[o]),n[o]=i[o])}if(n.name=t.name,t.helperType&&(n.helperType=t.helperType),t.modeProps)for(var l in t.modeProps)n[l]=t.modeProps[l];return n}function Ve(e,t){c(t,ls.hasOwnProperty(e)?ls[e]:ls[e]={})}function Ke(e,t){if(!0===t)return t;if(e.copyState)return e.copyState(t);var r={};for(var n in t){var i=t[n];i instanceof Array&&(i=i.concat([])),r[n]=i}return r}function je(e,t){for(var r;e.innerMode&&(r=e.innerMode(t))&&r.mode!=e;)t=r.state,e=r.mode;return r||{mode:e,state:t}}function Xe(e,t,r){return!e.startState||e.startState(t,r)}function Ye(e,t,r,n){var i=[e.state.modeGen],o={};tt(e,t.text,e.doc.mode,r,function(e,t){return i.push(e,t)},o,n);for(var l=r.state,s=0;s<e.state.overlays.length;++s)!function(n){var l=e.state.overlays[n],s=1,a=0;r.state=!0,tt(e,t.text,l.mode,r,function(e,t){for(var r=s;a<e;){var n=i[s];n>e&&i.splice(s,1,e,i[s+1],n),s+=2,a=Math.min(e,n)}if(t)if(l.opaque)i.splice(r,s-r,e,"overlay "+t),s=r+2;else for(;r<s;r+=2){var o=i[r+1];i[r+1]=(o?o+" ":"")+"overlay "+t}},o)}(s);return r.state=l,{styles:i,classes:o.bgClass||o.textClass?o:null}}function _e(e,t,r){if(!t.styles||t.styles[0]!=e.state.modeGen){var n=$e(e,W(t)),i=t.text.length>e.options.maxHighlightLength&&Ke(e.doc.mode,n.state),o=Ye(e,t,n);i&&(n.state=i),t.stateAfter=n.save(!i),t.styles=o.styles,o.classes?t.styleClasses=o.classes:t.styleClasses&&(t.styleClasses=null),r===e.doc.highlightFrontier&&(e.doc.modeFrontier=Math.max(e.doc.modeFrontier,++e.doc.highlightFrontier))}return t.styles}function $e(e,t,r){var n=e.doc,i=e.display;if(!n.mode.startState)return new us(n,!0,t);var o=rt(e,t,r),l=o>n.first&&M(n,o-1).stateAfter,s=l?us.fromSaved(n,l,o):new us(n,Xe(n.mode),o);return n.iter(o,t,function(r){qe(e,r.text,s);var n=s.line;r.stateAfter=n==t-1||n%5==0||n>=i.viewFrom&&n<i.viewTo?s.save():null,s.nextLine()}),r&&(n.modeFrontier=s.line),s}function qe(e,t,r,n){var i=e.doc.mode,o=new ss(t,e.options.tabSize,r);for(o.start=o.pos=n||0,""==t&&Ze(i,r.state);!o.eol();)Qe(i,o,r.state),o.start=o.pos}function Ze(e,t){if(e.blankLine)return e.blankLine(t);if(e.innerMode){var r=je(e,t);return r.mode.blankLine?r.mode.blankLine(r.state):void 0}}function Qe(e,t,r,n){for(var i=0;i<10;i++){n&&(n[0]=je(e,r).mode);var o=e.token(t,r);if(t.pos>t.start)return o}throw new Error("Mode "+e.name+" failed to advance stream.")}function Je(e,t,r,n){var i,o,l=e.doc,s=l.mode,a=M(l,(t=U(l,t)).line),u=$e(e,t.line,r),c=new ss(a.text,e.options.tabSize,u);for(n&&(o=[]);(n||c.pos<t.ch)&&!c.eol();)c.start=c.pos,i=Qe(s,c,u.state),n&&o.push(new cs(c,i,Ke(l.mode,u.state)));return n?o:new cs(c,i,u.state)}function et(e,t){if(e)for(;;){var r=e.match(/(?:^|\s+)line-(background-)?(\S+)/);if(!r)break;e=e.slice(0,r.index)+e.slice(r.index+r[0].length);var n=r[1]?"bgClass":"textClass";null==t[n]?t[n]=r[2]:new RegExp("(?:^|s)"+r[2]+"(?:$|s)").test(t[n])||(t[n]+=" "+r[2])}return e}function tt(e,t,r,n,i,o,l){var s=r.flattenSpans;null==s&&(s=e.options.flattenSpans);var a,u=0,c=null,f=new ss(t,e.options.tabSize,n),h=e.options.addModeClass&&[null];for(""==t&&et(Ze(r,n.state),o);!f.eol();){if(f.pos>e.options.maxHighlightLength?(s=!1,l&&qe(e,t,n,f.pos),f.pos=t.length,a=null):a=et(Qe(r,f,n.state,h),o),h){var d=h[0].name;d&&(a="m-"+(a?d+" "+a:d))}if(!s||c!=a){for(;u<f.start;)i(u=Math.min(f.start,u+5e3),c);c=a}f.start=f.pos}for(;u<f.pos;){var p=Math.min(f.pos,u+5e3);i(p,c),u=p}}function rt(e,t,r){for(var n,i,o=e.doc,l=r?-1:t-(e.doc.mode.innerMode?1e3:100),s=t;s>l;--s){if(s<=o.first)return o.first;var a=M(o,s-1),u=a.stateAfter;if(u&&(!r||s+(u instanceof as?u.lookAhead:0)<=o.modeFrontier))return s;var c=f(a.text,null,e.options.tabSize);(null==i||n>c)&&(i=s-1,n=c)}return i}function nt(e,t){if(e.modeFrontier=Math.min(e.modeFrontier,t),!(e.highlightFrontier<t-10)){for(var r=e.first,n=t-1;n>r;n--){var i=M(e,n).stateAfter;if(i&&(!(i instanceof as)||n+i.lookAhead<t)){r=n+1;break}}e.highlightFrontier=Math.min(e.highlightFrontier,r)}}function it(e,t,r,n){e.text=t,e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null),null!=e.order&&(e.order=null),re(e),ne(e,r);var i=n?n(e):1;i!=e.height&&A(e,i)}function ot(e){e.parent=null,re(e)}function lt(e,t){if(!e||/^\s*$/.test(e))return null;var r=t.addModeClass?ps:ds;return r[e]||(r[e]=e.replace(/\S+/g,"cm-$&"))}function st(e,t){var r=i("span",null,null,ml?"padding-right: .1px":null),n={pre:i("pre",[r],"CodeMirror-line"),content:r,col:0,pos:0,cm:e,trailingSpace:!1,splitSpaces:(gl||ml)&&e.getOption("lineWrapping")};t.measure={};for(var o=0;o<=(t.rest?t.rest.length:0);o++){var l=o?t.rest[o-1]:t.line,s=void 0;n.pos=0,n.addToken=ut,ze(e.display.measure)&&(s=Se(l,e.doc.direction))&&(n.addToken=ft(n.addToken,s)),n.map=[],dt(l,n,_e(e,l,t!=e.display.externalMeasured&&W(l))),l.styleClasses&&(l.styleClasses.bgClass&&(n.bgClass=a(l.styleClasses.bgClass,n.bgClass||"")),l.styleClasses.textClass&&(n.textClass=a(l.styleClasses.textClass,n.textClass||""))),0==n.map.length&&n.map.push(0,0,n.content.appendChild(Ie(e.display.measure))),0==o?(t.measure.map=n.map,t.measure.cache={}):((t.measure.maps||(t.measure.maps=[])).push(n.map),(t.measure.caches||(t.measure.caches=[])).push({}))}if(ml){var u=n.content.lastChild;(/\bcm-tab\b/.test(u.className)||u.querySelector&&u.querySelector(".cm-tab"))&&(n.content.className="cm-tab-wrap-hack")}return Te(e,"renderLine",e,t.line,n.pre),n.pre.className&&(n.textClass=a(n.pre.className,n.textClass||"")),n}function at(e){var t=n("span","•","cm-invalidchar");return t.title="\\u"+e.charCodeAt(0).toString(16),t.setAttribute("aria-label",t.title),t}function ut(e,t,r,i,o,l,s){if(t){var a,u=e.splitSpaces?ct(t,e.trailingSpace):t,c=e.cm.state.specialChars,f=!1;if(c.test(t)){a=document.createDocumentFragment();for(var h=0;;){c.lastIndex=h;var d=c.exec(t),g=d?d.index-h:t.length-h;if(g){var v=document.createTextNode(u.slice(h,h+g));gl&&vl<9?a.appendChild(n("span",[v])):a.appendChild(v),e.map.push(e.pos,e.pos+g,v),e.col+=g,e.pos+=g}if(!d)break;h+=g+1;var m=void 0;if("\t"==d[0]){var y=e.cm.options.tabSize,b=y-e.col%y;(m=a.appendChild(n("span",p(b),"cm-tab"))).setAttribute("role","presentation"),m.setAttribute("cm-text","\t"),e.col+=b}else"\r"==d[0]||"\n"==d[0]?((m=a.appendChild(n("span","\r"==d[0]?"␍":"␤","cm-invalidchar"))).setAttribute("cm-text",d[0]),e.col+=1):((m=e.cm.options.specialCharPlaceholder(d[0])).setAttribute("cm-text",d[0]),gl&&vl<9?a.appendChild(n("span",[m])):a.appendChild(m),e.col+=1);e.map.push(e.pos,e.pos+1,m),e.pos++}}else e.col+=t.length,a=document.createTextNode(u),e.map.push(e.pos,e.pos+t.length,a),gl&&vl<9&&(f=!0),e.pos+=t.length;if(e.trailingSpace=32==u.charCodeAt(t.length-1),r||i||o||f||s){var w=r||"";i&&(w+=i),o&&(w+=o);var x=n("span",[a],w,s);return l&&(x.title=l),e.content.appendChild(x)}e.content.appendChild(a)}}function ct(e,t){if(e.length>1&&!/  /.test(e))return e;for(var r=t,n="",i=0;i<e.length;i++){var o=e.charAt(i);" "!=o||!r||i!=e.length-1&&32!=e.charCodeAt(i+1)||(o=" "),n+=o,r=" "==o}return n}function ft(e,t){return function(r,n,i,o,l,s,a){i=i?i+" cm-force-border":"cm-force-border";for(var u=r.pos,c=u+n.length;;){for(var f=void 0,h=0;h<t.length&&!((f=t[h]).to>u&&f.from<=u);h++);if(f.to>=c)return e(r,n,i,o,l,s,a);e(r,n.slice(0,f.to-u),i,o,null,s,a),o=null,n=n.slice(f.to-u),u=f.to}}}function ht(e,t,r,n){var i=!n&&r.widgetNode;i&&e.map.push(e.pos,e.pos+t,i),!n&&e.cm.display.input.needsContentAttribute&&(i||(i=e.content.appendChild(document.createElement("span"))),i.setAttribute("cm-marker",r.id)),i&&(e.cm.display.input.setUneditable(i),e.content.appendChild(i)),e.pos+=t,e.trailingSpace=!1}function dt(e,t,r){var n=e.markedSpans,i=e.text,o=0;if(n)for(var l,s,a,u,c,f,h,d=i.length,p=0,g=1,v="",m=0;;){if(m==p){a=u=c=f=s="",h=null,m=1/0;for(var y=[],b=void 0,w=0;w<n.length;++w){var x=n[w],C=x.marker;"bookmark"==C.type&&x.from==p&&C.widgetNode?y.push(C):x.from<=p&&(null==x.to||x.to>p||C.collapsed&&x.to==p&&x.from==p)?(null!=x.to&&x.to!=p&&m>x.to&&(m=x.to,u=""),C.className&&(a+=" "+C.className),C.css&&(s=(s?s+";":"")+C.css),C.startStyle&&x.from==p&&(c+=" "+C.startStyle),C.endStyle&&x.to==m&&(b||(b=[])).push(C.endStyle,x.to),C.title&&!f&&(f=C.title),C.collapsed&&(!h||le(h.marker,C)<0)&&(h=x)):x.from>p&&m>x.from&&(m=x.from)}if(b)for(var S=0;S<b.length;S+=2)b[S+1]==m&&(u+=" "+b[S]);if(!h||h.from==p)for(var L=0;L<y.length;++L)ht(t,0,y[L]);if(h&&(h.from||0)==p){if(ht(t,(null==h.to?d+1:h.to)-p,h.marker,null==h.from),null==h.to)return;h.to==p&&(h=!1)}}if(p>=d)break;for(var k=Math.min(d,m);;){if(v){var T=p+v.length;if(!h){var M=T>k?v.slice(0,k-p):v;t.addToken(t,M,l?l+a:a,c,p+M.length==m?u:"",f,s)}if(T>=k){v=v.slice(k-p),p=k;break}p=T,c=""}v=i.slice(o,o=r[g++]),l=lt(r[g++],t.cm.options)}}else for(var N=1;N<r.length;N+=2)t.addToken(t,i.slice(o,o=r[N]),lt(r[N+1],t.cm.options))}function pt(e,t,r){this.line=t,this.rest=de(t),this.size=this.rest?W(g(this.rest))-r+1:1,this.node=this.text=null,this.hidden=ve(e,t)}function gt(e,t,r){for(var n,i=[],o=t;o<r;o=n){var l=new pt(e.doc,M(e.doc,o),o);n=o+l.size,i.push(l)}return i}function vt(e){gs?gs.ops.push(e):e.ownsGroup=gs={ops:[e],delayedCallbacks:[]}}function mt(e){var t=e.delayedCallbacks,r=0;do{for(;r<t.length;r++)t[r].call(null);for(var n=0;n<e.ops.length;n++){var i=e.ops[n];if(i.cursorActivityHandlers)for(;i.cursorActivityCalled<i.cursorActivityHandlers.length;)i.cursorActivityHandlers[i.cursorActivityCalled++].call(null,i.cm)}}while(r<t.length)}function yt(e,t){var r=e.ownsGroup;if(r)try{mt(r)}finally{gs=null,t(r)}}function bt(e,t){var r=Le(e,t);if(r.length){var n,i=Array.prototype.slice.call(arguments,2);gs?n=gs.delayedCallbacks:vs?n=vs:(n=vs=[],setTimeout(wt,0));for(var o=0;o<r.length;++o)!function(e){n.push(function(){return r[e].apply(null,i)})}(o)}}function wt(){var e=vs;vs=null;for(var t=0;t<e.length;++t)e[t]()}function xt(e,t,r,n){for(var i=0;i<t.changes.length;i++){var o=t.changes[i];"text"==o?kt(e,t):"gutter"==o?Mt(e,t,r,n):"class"==o?Tt(e,t):"widget"==o&&Nt(e,t,n)}t.changes=null}function Ct(e){return e.node==e.text&&(e.node=n("div",null,null,"position: relative"),e.text.parentNode&&e.text.parentNode.replaceChild(e.node,e.text),e.node.appendChild(e.text),gl&&vl<8&&(e.node.style.zIndex=2)),e.node}function St(e,t){var r=t.bgClass?t.bgClass+" "+(t.line.bgClass||""):t.line.bgClass;if(r&&(r+=" CodeMirror-linebackground"),t.background)r?t.background.className=r:(t.background.parentNode.removeChild(t.background),t.background=null);else if(r){var i=Ct(t);t.background=i.insertBefore(n("div",null,r),i.firstChild),e.display.input.setUneditable(t.background)}}function Lt(e,t){var r=e.display.externalMeasured;return r&&r.line==t.line?(e.display.externalMeasured=null,t.measure=r.measure,r.built):st(e,t)}function kt(e,t){var r=t.text.className,n=Lt(e,t);t.text==t.node&&(t.node=n.pre),t.text.parentNode.replaceChild(n.pre,t.text),t.text=n.pre,n.bgClass!=t.bgClass||n.textClass!=t.textClass?(t.bgClass=n.bgClass,t.textClass=n.textClass,Tt(e,t)):r&&(t.text.className=r)}function Tt(e,t){St(e,t),t.line.wrapClass?Ct(t).className=t.line.wrapClass:t.node!=t.text&&(t.node.className="");var r=t.textClass?t.textClass+" "+(t.line.textClass||""):t.line.textClass;t.text.className=r||""}function Mt(e,t,r,i){if(t.gutter&&(t.node.removeChild(t.gutter),t.gutter=null),t.gutterBackground&&(t.node.removeChild(t.gutterBackground),t.gutterBackground=null),t.line.gutterClass){var o=Ct(t);t.gutterBackground=n("div",null,"CodeMirror-gutter-background "+t.line.gutterClass,"left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px; width: "+i.gutterTotalWidth+"px"),e.display.input.setUneditable(t.gutterBackground),o.insertBefore(t.gutterBackground,t.text)}var l=t.line.gutterMarkers;if(e.options.lineNumbers||l){var s=Ct(t),a=t.gutter=n("div",null,"CodeMirror-gutter-wrapper","left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px");if(e.display.input.setUneditable(a),s.insertBefore(a,t.text),t.line.gutterClass&&(a.className+=" "+t.line.gutterClass),!e.options.lineNumbers||l&&l["CodeMirror-linenumbers"]||(t.lineNumber=a.appendChild(n("div",F(e.options,r),"CodeMirror-linenumber CodeMirror-gutter-elt","left: "+i.gutterLeft["CodeMirror-linenumbers"]+"px; width: "+e.display.lineNumInnerWidth+"px"))),l)for(var u=0;u<e.options.gutters.length;++u){var c=e.options.gutters[u],f=l.hasOwnProperty(c)&&l[c];f&&a.appendChild(n("div",[f],"CodeMirror-gutter-elt","left: "+i.gutterLeft[c]+"px; width: "+i.gutterWidth[c]+"px"))}}}function Nt(e,t,r){t.alignable&&(t.alignable=null);for(var n=t.node.firstChild,i=void 0;n;n=i)i=n.nextSibling,"CodeMirror-linewidget"==n.className&&t.node.removeChild(n);At(e,t,r)}function Ot(e,t,r,n){var i=Lt(e,t);return t.text=t.node=i.pre,i.bgClass&&(t.bgClass=i.bgClass),i.textClass&&(t.textClass=i.textClass),Tt(e,t),Mt(e,t,r,n),At(e,t,n),t.node}function At(e,t,r){if(Wt(e,t.line,t,r,!0),t.rest)for(var n=0;n<t.rest.length;n++)Wt(e,t.rest[n],t,r,!1)}function Wt(e,t,r,i,o){if(t.widgets)for(var l=Ct(r),s=0,a=t.widgets;s<a.length;++s){var u=a[s],c=n("div",[u.node],"CodeMirror-linewidget");u.handleMouseEvents||c.setAttribute("cm-ignore-events","true"),Dt(u,c,r,i),e.display.input.setUneditable(c),o&&u.above?l.insertBefore(c,r.gutter||r.text):l.appendChild(c),bt(u,"redraw")}}function Dt(e,t,r,n){if(e.noHScroll){(r.alignable||(r.alignable=[])).push(t);var i=n.wrapperWidth;t.style.left=n.fixedPos+"px",e.coverGutter||(i-=n.gutterTotalWidth,t.style.paddingLeft=n.gutterTotalWidth+"px"),t.style.width=i+"px"}e.coverGutter&&(t.style.zIndex=5,t.style.position="relative",e.noHScroll||(t.style.marginLeft=-n.gutterTotalWidth+"px"))}function Ht(e){if(null!=e.height)return e.height;var t=e.doc.cm;if(!t)return 0;if(!o(document.body,e.node)){var i="position: relative;";e.coverGutter&&(i+="margin-left: -"+t.display.gutters.offsetWidth+"px;"),e.noHScroll&&(i+="width: "+t.display.wrapper.clientWidth+"px;"),r(t.display.measure,n("div",[e.node],null,i))}return e.height=e.node.parentNode.offsetHeight}function Ft(e,t){for(var r=Ee(t);r!=e.wrapper;r=r.parentNode)if(!r||1==r.nodeType&&"true"==r.getAttribute("cm-ignore-events")||r.parentNode==e.sizer&&r!=e.mover)return!0}function Et(e){return e.lineSpace.offsetTop}function Pt(e){return e.mover.offsetHeight-e.lineSpace.offsetHeight}function It(e){if(e.cachedPaddingH)return e.cachedPaddingH;var t=r(e.measure,n("pre","x")),i=window.getComputedStyle?window.getComputedStyle(t):t.currentStyle,o={left:parseInt(i.paddingLeft),right:parseInt(i.paddingRight)};return isNaN(o.left)||isNaN(o.right)||(e.cachedPaddingH=o),o}function zt(e){return Rl-e.display.nativeBarWidth}function Rt(e){return e.display.scroller.clientWidth-zt(e)-e.display.barWidth}function Bt(e){return e.display.scroller.clientHeight-zt(e)-e.display.barHeight}function Gt(e,t,r){var n=e.options.lineWrapping,i=n&&Rt(e);if(!t.measure.heights||n&&t.measure.width!=i){var o=t.measure.heights=[];if(n){t.measure.width=i;for(var l=t.text.firstChild.getClientRects(),s=0;s<l.length-1;s++){var a=l[s],u=l[s+1];Math.abs(a.bottom-u.bottom)>2&&o.push((a.bottom+u.top)/2-r.top)}}o.push(r.bottom-r.top)}}function Ut(e,t,r){if(e.line==t)return{map:e.measure.map,cache:e.measure.cache};for(var n=0;n<e.rest.length;n++)if(e.rest[n]==t)return{map:e.measure.maps[n],cache:e.measure.caches[n]};for(var i=0;i<e.rest.length;i++)if(W(e.rest[i])>r)return{map:e.measure.maps[i],cache:e.measure.caches[i],before:!0}}function Vt(e,t){var n=W(t=fe(t)),i=e.display.externalMeasured=new pt(e.doc,t,n);i.lineN=n;var o=i.built=st(e,i);return i.text=o.pre,r(e.display.lineMeasure,o.pre),i}function Kt(e,t,r,n){return Yt(e,Xt(e,t),r,n)}function jt(e,t){if(t>=e.display.viewFrom&&t<e.display.viewTo)return e.display.view[Lr(e,t)];var r=e.display.externalMeasured;return r&&t>=r.lineN&&t<r.lineN+r.size?r:void 0}function Xt(e,t){var r=W(t),n=jt(e,r);n&&!n.text?n=null:n&&n.changes&&(xt(e,n,r,br(e)),e.curOp.forceUpdate=!0),n||(n=Vt(e,t));var i=Ut(n,t,r);return{line:t,view:n,rect:null,map:i.map,cache:i.cache,before:i.before,hasHeights:!1}}function Yt(e,t,r,n,i){t.before&&(r=-1);var o,l=r+(n||"");return t.cache.hasOwnProperty(l)?o=t.cache[l]:(t.rect||(t.rect=t.view.text.getBoundingClientRect()),t.hasHeights||(Gt(e,t.view,t.rect),t.hasHeights=!0),(o=qt(e,t,r,n)).bogus||(t.cache[l]=o)),{left:o.left,right:o.right,top:i?o.rtop:o.top,bottom:i?o.rbottom:o.bottom}}function _t(e,t,r){for(var n,i,o,l,s,a,u=0;u<e.length;u+=3)if(s=e[u],a=e[u+1],t<s?(i=0,o=1,l="left"):t<a?o=(i=t-s)+1:(u==e.length-3||t==a&&e[u+3]>t)&&(i=(o=a-s)-1,t>=a&&(l="right")),null!=i){if(n=e[u+2],s==a&&r==(n.insertLeft?"left":"right")&&(l=r),"left"==r&&0==i)for(;u&&e[u-2]==e[u-3]&&e[u-1].insertLeft;)n=e[2+(u-=3)],l="left";if("right"==r&&i==a-s)for(;u<e.length-3&&e[u+3]==e[u+4]&&!e[u+5].insertLeft;)n=e[(u+=3)+2],l="right";break}return{node:n,start:i,end:o,collapse:l,coverStart:s,coverEnd:a}}function $t(e,t){var r=ms;if("left"==t)for(var n=0;n<e.length&&(r=e[n]).left==r.right;n++);else for(var i=e.length-1;i>=0&&(r=e[i]).left==r.right;i--);return r}function qt(e,t,r,n){var i,o=_t(t.map,r,n),l=o.node,s=o.start,a=o.end,u=o.collapse;if(3==l.nodeType){for(var c=0;c<4;c++){for(;s&&S(t.line.text.charAt(o.coverStart+s));)--s;for(;o.coverStart+a<o.coverEnd&&S(t.line.text.charAt(o.coverStart+a));)++a;if((i=gl&&vl<9&&0==s&&a==o.coverEnd-o.coverStart?l.parentNode.getBoundingClientRect():$t(Wl(l,s,a).getClientRects(),n)).left||i.right||0==s)break;a=s,s-=1,u="right"}gl&&vl<11&&(i=Zt(e.display.measure,i))}else{s>0&&(u=n="right");var f;i=e.options.lineWrapping&&(f=l.getClientRects()).length>1?f["right"==n?f.length-1:0]:l.getBoundingClientRect()}if(gl&&vl<9&&!s&&(!i||!i.left&&!i.right)){var h=l.parentNode.getClientRects()[0];i=h?{left:h.left,right:h.left+yr(e.display),top:h.top,bottom:h.bottom}:ms}for(var d=i.top-t.rect.top,p=i.bottom-t.rect.top,g=(d+p)/2,v=t.view.measure.heights,m=0;m<v.length-1&&!(g<v[m]);m++);var y=m?v[m-1]:0,b=v[m],w={left:("right"==u?i.right:i.left)-t.rect.left,right:("left"==u?i.left:i.right)-t.rect.left,top:y,bottom:b};return i.left||i.right||(w.bogus=!0),e.options.singleCursorHeightPerLine||(w.rtop=d,w.rbottom=p),w}function Zt(e,t){if(!window.screen||null==screen.logicalXDPI||screen.logicalXDPI==screen.deviceXDPI||!Re(e))return t;var r=screen.logicalXDPI/screen.deviceXDPI,n=screen.logicalYDPI/screen.deviceYDPI;return{left:t.left*r,right:t.right*r,top:t.top*n,bottom:t.bottom*n}}function Qt(e){if(e.measure&&(e.measure.cache={},e.measure.heights=null,e.rest))for(var t=0;t<e.rest.length;t++)e.measure.caches[t]={}}function Jt(e){e.display.externalMeasure=null,t(e.display.lineMeasure);for(var r=0;r<e.display.view.length;r++)Qt(e.display.view[r])}function er(e){Jt(e),e.display.cachedCharWidth=e.display.cachedTextHeight=e.display.cachedPaddingH=null,e.options.lineWrapping||(e.display.maxLineChanged=!0),e.display.lineNumChars=null}function tr(){return bl&&kl?-(document.body.getBoundingClientRect().left-parseInt(getComputedStyle(document.body).marginLeft)):window.pageXOffset||(document.documentElement||document.body).scrollLeft}function rr(){return bl&&kl?-(document.body.getBoundingClientRect().top-parseInt(getComputedStyle(document.body).marginTop)):window.pageYOffset||(document.documentElement||document.body).scrollTop}function nr(e){var t=0;if(e.widgets)for(var r=0;r<e.widgets.length;++r)e.widgets[r].above&&(t+=Ht(e.widgets[r]));return t}function ir(e,t,r,n,i){if(!i){var o=nr(t);r.top+=o,r.bottom+=o}if("line"==n)return r;n||(n="local");var l=ye(t);if("local"==n?l+=Et(e.display):l-=e.display.viewOffset,"page"==n||"window"==n){var s=e.display.lineSpace.getBoundingClientRect();l+=s.top+("window"==n?0:rr());var a=s.left+("window"==n?0:tr());r.left+=a,r.right+=a}return r.top+=l,r.bottom+=l,r}function or(e,t,r){if("div"==r)return t;var n=t.left,i=t.top;if("page"==r)n-=tr(),i-=rr();else if("local"==r||!r){var o=e.display.sizer.getBoundingClientRect();n+=o.left,i+=o.top}var l=e.display.lineSpace.getBoundingClientRect();return{left:n-l.left,top:i-l.top}}function lr(e,t,r,n,i){return n||(n=M(e.doc,t.line)),ir(e,n,Kt(e,n,t.ch,i),r)}function sr(e,t,r,n,i,o){function l(t,l){var s=Yt(e,i,t,l?"right":"left",o);return l?s.left=s.right:s.right=s.left,ir(e,n,s,r)}function s(e,t,r){var n=1==a[t].level;return l(r?e-1:e,n!=r)}n=n||M(e.doc,t.line),i||(i=Xt(e,n));var a=Se(n,e.doc.direction),u=t.ch,c=t.sticky;if(u>=n.text.length?(u=n.text.length,c="before"):u<=0&&(u=0,c="after"),!a)return l("before"==c?u-1:u,"before"==c);var f=Ce(a,u,c),h=$l,d=s(u,f,"before"==c);return null!=h&&(d.other=s(u,h,"before"!=c)),d}function ar(e,t){var r=0;t=U(e.doc,t),e.options.lineWrapping||(r=yr(e.display)*t.ch);var n=M(e.doc,t.line),i=ye(n)+Et(e.display);return{left:r,right:r,top:i,bottom:i+n.height}}function ur(e,t,r,n,i){var o=E(e,t,r);return o.xRel=i,n&&(o.outside=!0),o}function cr(e,t,r){var n=e.doc;if((r+=e.display.viewOffset)<0)return ur(n.first,0,null,!0,-1);var i=D(n,r),o=n.first+n.size-1;if(i>o)return ur(n.first+n.size-1,M(n,o).text.length,null,!0,1);t<0&&(t=0);for(var l=M(n,i);;){var s=pr(e,l,i,t,r),a=ue(l),u=a&&a.find(0,!0);if(!a||!(s.ch>u.from.ch||s.ch==u.from.ch&&s.xRel>0))return s;i=W(l=u.to.line)}}function fr(e,t,r,n){n-=nr(t);var i=t.text.length,o=k(function(t){return Yt(e,r,t-1).bottom<=n},i,0);return i=k(function(t){return Yt(e,r,t).top>n},o,i),{begin:o,end:i}}function hr(e,t,r,n){return r||(r=Xt(e,t)),fr(e,t,r,ir(e,t,Yt(e,r,n),"line").top)}function dr(e,t,r,n){return!(e.bottom<=r)&&(e.top>r||(n?e.left:e.right)>t)}function pr(e,t,r,n,i){i-=ye(t);var o=Xt(e,t),l=nr(t),s=0,a=t.text.length,u=!0,c=Se(t,e.doc.direction);if(c){var f=(e.options.lineWrapping?vr:gr)(e,t,r,o,c,n,i);s=(u=1!=f.level)?f.from:f.to-1,a=u?f.to:f.from-1}var h,d,p=null,g=null,v=k(function(t){var r=Yt(e,o,t);return r.top+=l,r.bottom+=l,!!dr(r,n,i,!1)&&(r.top<=i&&r.left<=n&&(p=t,g=r),!0)},s,a),m=!1;if(g){var y=n-g.left<g.right-n,b=y==u;v=p+(b?0:1),d=b?"after":"before",h=y?g.left:g.right}else{u||v!=a&&v!=s||v++,d=0==v?"after":v==t.text.length?"before":Yt(e,o,v-(u?1:0)).bottom+l<=i==u?"after":"before";var w=sr(e,E(r,v,d),"line",t,o);h=w.left,m=i<w.top||i>=w.bottom}return v=L(t.text,v,1),ur(r,v,d,m,n-h)}function gr(e,t,r,n,i,o,l){var s=k(function(s){var a=i[s],u=1!=a.level;return dr(sr(e,E(r,u?a.to:a.from,u?"before":"after"),"line",t,n),o,l,!0)},0,i.length-1),a=i[s];if(s>0){var u=1!=a.level,c=sr(e,E(r,u?a.from:a.to,u?"after":"before"),"line",t,n);dr(c,o,l,!0)&&c.top>l&&(a=i[s-1])}return a}function vr(e,t,r,n,i,o,l){for(var s=fr(e,t,n,l),a=s.begin,u=s.end,c=null,f=null,h=0;h<i.length;h++){var d=i[h];if(!(d.from>=u||d.to<=a)){var p=Yt(e,n,1!=d.level?Math.min(u,d.to)-1:Math.max(a,d.from)).right,g=p<o?o-p+1e9:p-o;(!c||f>g)&&(c=d,f=g)}}return c||(c=i[i.length-1]),c.from<a&&(c={from:a,to:c.to,level:c.level}),c.to>u&&(c={from:c.from,to:u,level:c.level}),c}function mr(e){if(null!=e.cachedTextHeight)return e.cachedTextHeight;if(null==hs){hs=n("pre");for(var i=0;i<49;++i)hs.appendChild(document.createTextNode("x")),hs.appendChild(n("br"));hs.appendChild(document.createTextNode("x"))}r(e.measure,hs);var o=hs.offsetHeight/50;return o>3&&(e.cachedTextHeight=o),t(e.measure),o||1}function yr(e){if(null!=e.cachedCharWidth)return e.cachedCharWidth;var t=n("span","xxxxxxxxxx"),i=n("pre",[t]);r(e.measure,i);var o=t.getBoundingClientRect(),l=(o.right-o.left)/10;return l>2&&(e.cachedCharWidth=l),l||10}function br(e){for(var t=e.display,r={},n={},i=t.gutters.clientLeft,o=t.gutters.firstChild,l=0;o;o=o.nextSibling,++l)r[e.options.gutters[l]]=o.offsetLeft+o.clientLeft+i,n[e.options.gutters[l]]=o.clientWidth;return{fixedPos:wr(t),gutterTotalWidth:t.gutters.offsetWidth,gutterLeft:r,gutterWidth:n,wrapperWidth:t.wrapper.clientWidth}}function wr(e){return e.scroller.getBoundingClientRect().left-e.sizer.getBoundingClientRect().left}function xr(e){var t=mr(e.display),r=e.options.lineWrapping,n=r&&Math.max(5,e.display.scroller.clientWidth/yr(e.display)-3);return function(i){if(ve(e.doc,i))return 0;var o=0;if(i.widgets)for(var l=0;l<i.widgets.length;l++)i.widgets[l].height&&(o+=i.widgets[l].height);return r?o+(Math.ceil(i.text.length/n)||1)*t:o+t}}function Cr(e){var t=e.doc,r=xr(e);t.iter(function(e){var t=r(e);t!=e.height&&A(e,t)})}function Sr(e,t,r,n){var i=e.display;if(!r&&"true"==Ee(t).getAttribute("cm-not-content"))return null;var o,l,s=i.lineSpace.getBoundingClientRect();try{o=t.clientX-s.left,l=t.clientY-s.top}catch(t){return null}var a,u=cr(e,o,l);if(n&&1==u.xRel&&(a=M(e.doc,u.line).text).length==u.ch){var c=f(a,a.length,e.options.tabSize)-a.length;u=E(u.line,Math.max(0,Math.round((o-It(e.display).left)/yr(e.display))-c))}return u}function Lr(e,t){if(t>=e.display.viewTo)return null;if((t-=e.display.viewFrom)<0)return null;for(var r=e.display.view,n=0;n<r.length;n++)if((t-=r[n].size)<0)return n}function kr(e){e.display.input.showSelection(e.display.input.prepareSelection())}function Tr(e,t){void 0===t&&(t=!0);for(var r=e.doc,n={},i=n.cursors=document.createDocumentFragment(),o=n.selection=document.createDocumentFragment(),l=0;l<r.sel.ranges.length;l++)if(t||l!=r.sel.primIndex){var s=r.sel.ranges[l];if(!(s.from().line>=e.display.viewTo||s.to().line<e.display.viewFrom)){var a=s.empty();(a||e.options.showCursorWhenSelecting)&&Mr(e,s.head,i),a||Or(e,s,o)}}return n}function Mr(e,t,r){var i=sr(e,t,"div",null,null,!e.options.singleCursorHeightPerLine),o=r.appendChild(n("div"," ","CodeMirror-cursor"));if(o.style.left=i.left+"px",o.style.top=i.top+"px",o.style.height=Math.max(0,i.bottom-i.top)*e.options.cursorHeight+"px",i.other){var l=r.appendChild(n("div"," ","CodeMirror-cursor CodeMirror-secondarycursor"));l.style.display="",l.style.left=i.other.left+"px",l.style.top=i.other.top+"px",l.style.height=.85*(i.other.bottom-i.other.top)+"px"}}function Nr(e,t){return e.top-t.top||e.left-t.left}function Or(e,t,r){function i(e,t,r,i){t<0&&(t=0),t=Math.round(t),i=Math.round(i),a.appendChild(n("div",null,"CodeMirror-selected","position: absolute; left: "+e+"px;\n                             top: "+t+"px; width: "+(null==r?f-e:r)+"px;\n                             height: "+(i-t)+"px"))}function o(t,r,n){function o(r,n){return lr(e,E(t,r),"div",u,n)}var l,a,u=M(s,t),h=u.text.length,d=Se(u,s.direction);return xe(d,r||0,null==n?h:n,function(t,s,p,g){var v=o(t,"ltr"==p?"left":"right"),m=o(s-1,"ltr"==p?"right":"left");if("ltr"==p){var y=null==r&&0==t?c:v.left,b=null==n&&s==h?f:m.right;m.top-v.top<=3?i(y,m.top,b-y,m.bottom):(i(y,v.top,null,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top),i(c,m.top,m.right,m.bottom))}else if(t<s){var w=null==r&&0==t?f:v.right,x=null==n&&s==h?c:m.left;if(m.top-v.top<=3)i(x,m.top,w-x,m.bottom);else{var C=c;if(g){var S=hr(e,u,null,t).end;C=o(S-(/\s/.test(u.text.charAt(S-1))?2:1),"left").left}i(C,v.top,w-C,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top);var L=null;d.length,L=o(hr(e,u,null,s).begin,"right").right-x,i(x,m.top,L,m.bottom)}}(!l||Nr(v,l)<0)&&(l=v),Nr(m,l)<0&&(l=m),(!a||Nr(v,a)<0)&&(a=v),Nr(m,a)<0&&(a=m)}),{start:l,end:a}}var l=e.display,s=e.doc,a=document.createDocumentFragment(),u=It(e.display),c=u.left,f=Math.max(l.sizerWidth,Rt(e)-l.sizer.offsetLeft)-u.right,h=t.from(),d=t.to();if(h.line==d.line)o(h.line,h.ch,d.ch);else{var p=M(s,h.line),g=M(s,d.line),v=fe(p)==fe(g),m=o(h.line,h.ch,v?p.text.length+1:null).end,y=o(d.line,v?0:null,d.ch).start;v&&(m.top<y.top-2?(i(m.right,m.top,null,m.bottom),i(c,y.top,y.left,y.bottom)):i(m.right,m.top,y.left-m.right,m.bottom)),m.bottom<y.top&&i(c,m.bottom,null,y.top)}r.appendChild(a)}function Ar(e){if(e.state.focused){var t=e.display;clearInterval(t.blinker);var r=!0;t.cursorDiv.style.visibility="",e.options.cursorBlinkRate>0?t.blinker=setInterval(function(){return t.cursorDiv.style.visibility=(r=!r)?"":"hidden"},e.options.cursorBlinkRate):e.options.cursorBlinkRate<0&&(t.cursorDiv.style.visibility="hidden")}}function Wr(e){e.state.focused||(e.display.input.focus(),Hr(e))}function Dr(e){e.state.delayingBlurEvent=!0,setTimeout(function(){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1,Fr(e))},100)}function Hr(e,t){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1),"nocursor"!=e.options.readOnly&&(e.state.focused||(Te(e,"focus",e,t),e.state.focused=!0,s(e.display.wrapper,"CodeMirror-focused"),e.curOp||e.display.selForContextMenu==e.doc.sel||(e.display.input.reset(),ml&&setTimeout(function(){return e.display.input.reset(!0)},20)),e.display.input.receivedFocus()),Ar(e))}function Fr(e,t){e.state.delayingBlurEvent||(e.state.focused&&(Te(e,"blur",e,t),e.state.focused=!1,Fl(e.display.wrapper,"CodeMirror-focused")),clearInterval(e.display.blinker),setTimeout(function(){e.state.focused||(e.display.shift=!1)},150))}function Er(e){for(var t=e.display,r=t.lineDiv.offsetTop,n=0;n<t.view.length;n++){var i=t.view[n],o=void 0;if(!i.hidden){if(gl&&vl<8){var l=i.node.offsetTop+i.node.offsetHeight;o=l-r,r=l}else{var s=i.node.getBoundingClientRect();o=s.bottom-s.top}var a=i.line.height-o;if(o<2&&(o=mr(t)),(a>.005||a<-.005)&&(A(i.line,o),Pr(i.line),i.rest))for(var u=0;u<i.rest.length;u++)Pr(i.rest[u])}}}function Pr(e){if(e.widgets)for(var t=0;t<e.widgets.length;++t)e.widgets[t].height=e.widgets[t].node.parentNode.offsetHeight}function Ir(e,t,r){var n=r&&null!=r.top?Math.max(0,r.top):e.scroller.scrollTop;n=Math.floor(n-Et(e));var i=r&&null!=r.bottom?r.bottom:n+e.wrapper.clientHeight,o=D(t,n),l=D(t,i);if(r&&r.ensure){var s=r.ensure.from.line,a=r.ensure.to.line;s<o?(o=s,l=D(t,ye(M(t,s))+e.wrapper.clientHeight)):Math.min(a,t.lastLine())>=l&&(o=D(t,ye(M(t,a))-e.wrapper.clientHeight),l=a)}return{from:o,to:Math.max(l,o+1)}}function zr(e){var t=e.display,r=t.view;if(t.alignWidgets||t.gutters.firstChild&&e.options.fixedGutter){for(var n=wr(t)-t.scroller.scrollLeft+e.doc.scrollLeft,i=t.gutters.offsetWidth,o=n+"px",l=0;l<r.length;l++)if(!r[l].hidden){e.options.fixedGutter&&(r[l].gutter&&(r[l].gutter.style.left=o),r[l].gutterBackground&&(r[l].gutterBackground.style.left=o));var s=r[l].alignable;if(s)for(var a=0;a<s.length;a++)s[a].style.left=o}e.options.fixedGutter&&(t.gutters.style.left=n+i+"px")}}function Rr(e){if(!e.options.lineNumbers)return!1;var t=e.doc,r=F(e.options,t.first+t.size-1),i=e.display;if(r.length!=i.lineNumChars){var o=i.measure.appendChild(n("div",[n("div",r)],"CodeMirror-linenumber CodeMirror-gutter-elt")),l=o.firstChild.offsetWidth,s=o.offsetWidth-l;return i.lineGutter.style.width="",i.lineNumInnerWidth=Math.max(l,i.lineGutter.offsetWidth-s)+1,i.lineNumWidth=i.lineNumInnerWidth+s,i.lineNumChars=i.lineNumInnerWidth?r.length:-1,i.lineGutter.style.width=i.lineNumWidth+"px",Wn(e),!0}return!1}function Br(e,t){if(!Me(e,"scrollCursorIntoView")){var r=e.display,i=r.sizer.getBoundingClientRect(),o=null;if(t.top+i.top<0?o=!0:t.bottom+i.top>(window.innerHeight||document.documentElement.clientHeight)&&(o=!1),null!=o&&!Sl){var l=n("div","​",null,"position: absolute;\n                         top: "+(t.top-r.viewOffset-Et(e.display))+"px;\n                         height: "+(t.bottom-t.top+zt(e)+r.barHeight)+"px;\n                         left: "+t.left+"px; width: "+Math.max(2,t.right-t.left)+"px;");e.display.lineSpace.appendChild(l),l.scrollIntoView(o),e.display.lineSpace.removeChild(l)}}}function Gr(e,t,r,n){null==n&&(n=0);var i;e.options.lineWrapping||t!=r||(r="before"==(t=t.ch?E(t.line,"before"==t.sticky?t.ch-1:t.ch,"after"):t).sticky?E(t.line,t.ch+1,"before"):t);for(var o=0;o<5;o++){var l=!1,s=sr(e,t),a=r&&r!=t?sr(e,r):s,u=Vr(e,i={left:Math.min(s.left,a.left),top:Math.min(s.top,a.top)-n,right:Math.max(s.left,a.left),bottom:Math.max(s.bottom,a.bottom)+n}),c=e.doc.scrollTop,f=e.doc.scrollLeft;if(null!=u.scrollTop&&(qr(e,u.scrollTop),Math.abs(e.doc.scrollTop-c)>1&&(l=!0)),null!=u.scrollLeft&&(Qr(e,u.scrollLeft),Math.abs(e.doc.scrollLeft-f)>1&&(l=!0)),!l)break}return i}function Ur(e,t){var r=Vr(e,t);null!=r.scrollTop&&qr(e,r.scrollTop),null!=r.scrollLeft&&Qr(e,r.scrollLeft)}function Vr(e,t){var r=e.display,n=mr(e.display);t.top<0&&(t.top=0);var i=e.curOp&&null!=e.curOp.scrollTop?e.curOp.scrollTop:r.scroller.scrollTop,o=Bt(e),l={};t.bottom-t.top>o&&(t.bottom=t.top+o);var s=e.doc.height+Pt(r),a=t.top<n,u=t.bottom>s-n;if(t.top<i)l.scrollTop=a?0:t.top;else if(t.bottom>i+o){var c=Math.min(t.top,(u?s:t.bottom)-o);c!=i&&(l.scrollTop=c)}var f=e.curOp&&null!=e.curOp.scrollLeft?e.curOp.scrollLeft:r.scroller.scrollLeft,h=Rt(e)-(e.options.fixedGutter?r.gutters.offsetWidth:0),d=t.right-t.left>h;return d&&(t.right=t.left+h),t.left<10?l.scrollLeft=0:t.left<f?l.scrollLeft=Math.max(0,t.left-(d?0:10)):t.right>h+f-3&&(l.scrollLeft=t.right+(d?0:10)-h),l}function Kr(e,t){null!=t&&(_r(e),e.curOp.scrollTop=(null==e.curOp.scrollTop?e.doc.scrollTop:e.curOp.scrollTop)+t)}function jr(e){_r(e);var t=e.getCursor();e.curOp.scrollToPos={from:t,to:t,margin:e.options.cursorScrollMargin}}function Xr(e,t,r){null==t&&null==r||_r(e),null!=t&&(e.curOp.scrollLeft=t),null!=r&&(e.curOp.scrollTop=r)}function Yr(e,t){_r(e),e.curOp.scrollToPos=t}function _r(e){var t=e.curOp.scrollToPos;t&&(e.curOp.scrollToPos=null,$r(e,ar(e,t.from),ar(e,t.to),t.margin))}function $r(e,t,r,n){var i=Vr(e,{left:Math.min(t.left,r.left),top:Math.min(t.top,r.top)-n,right:Math.max(t.right,r.right),bottom:Math.max(t.bottom,r.bottom)+n});Xr(e,i.scrollLeft,i.scrollTop)}function qr(e,t){Math.abs(e.doc.scrollTop-t)<2||(fl||On(e,{top:t}),Zr(e,t,!0),fl&&On(e),Cn(e,100))}function Zr(e,t,r){t=Math.min(e.display.scroller.scrollHeight-e.display.scroller.clientHeight,t),(e.display.scroller.scrollTop!=t||r)&&(e.doc.scrollTop=t,e.display.scrollbars.setScrollTop(t),e.display.scroller.scrollTop!=t&&(e.display.scroller.scrollTop=t))}function Qr(e,t,r,n){t=Math.min(t,e.display.scroller.scrollWidth-e.display.scroller.clientWidth),(r?t==e.doc.scrollLeft:Math.abs(e.doc.scrollLeft-t)<2)&&!n||(e.doc.scrollLeft=t,zr(e),e.display.scroller.scrollLeft!=t&&(e.display.scroller.scrollLeft=t),e.display.scrollbars.setScrollLeft(t))}function Jr(e){var t=e.display,r=t.gutters.offsetWidth,n=Math.round(e.doc.height+Pt(e.display));return{clientHeight:t.scroller.clientHeight,viewHeight:t.wrapper.clientHeight,scrollWidth:t.scroller.scrollWidth,clientWidth:t.scroller.clientWidth,viewWidth:t.wrapper.clientWidth,barLeft:e.options.fixedGutter?r:0,docHeight:n,scrollHeight:n+zt(e)+t.barHeight,nativeBarWidth:t.nativeBarWidth,gutterWidth:r}}function en(e,t){t||(t=Jr(e));var r=e.display.barWidth,n=e.display.barHeight;tn(e,t);for(var i=0;i<4&&r!=e.display.barWidth||n!=e.display.barHeight;i++)r!=e.display.barWidth&&e.options.lineWrapping&&Er(e),tn(e,Jr(e)),r=e.display.barWidth,n=e.display.barHeight}function tn(e,t){var r=e.display,n=r.scrollbars.update(t);r.sizer.style.paddingRight=(r.barWidth=n.right)+"px",r.sizer.style.paddingBottom=(r.barHeight=n.bottom)+"px",r.heightForcer.style.borderBottom=n.bottom+"px solid transparent",n.right&&n.bottom?(r.scrollbarFiller.style.display="block",r.scrollbarFiller.style.height=n.bottom+"px",r.scrollbarFiller.style.width=n.right+"px"):r.scrollbarFiller.style.display="",n.bottom&&e.options.coverGutterNextToScrollbar&&e.options.fixedGutter?(r.gutterFiller.style.display="block",r.gutterFiller.style.height=n.bottom+"px",r.gutterFiller.style.width=t.gutterWidth+"px"):r.gutterFiller.style.display=""}function rn(e){e.display.scrollbars&&(e.display.scrollbars.clear(),e.display.scrollbars.addClass&&Fl(e.display.wrapper,e.display.scrollbars.addClass)),e.display.scrollbars=new ws[e.options.scrollbarStyle](function(t){e.display.wrapper.insertBefore(t,e.display.scrollbarFiller),Ql(t,"mousedown",function(){e.state.focused&&setTimeout(function(){return e.display.input.focus()},0)}),t.setAttribute("cm-not-content","true")},function(t,r){"horizontal"==r?Qr(e,t):qr(e,t)},e),e.display.scrollbars.addClass&&s(e.display.wrapper,e.display.scrollbars.addClass)}function nn(e){e.curOp={cm:e,viewChanged:!1,startHeight:e.doc.height,forceUpdate:!1,updateInput:null,typing:!1,changeObjs:null,cursorActivityHandlers:null,cursorActivityCalled:0,selectionChanged:!1,updateMaxLine:!1,scrollLeft:null,scrollTop:null,scrollToPos:null,focus:!1,id:++xs},vt(e.curOp)}function on(e){yt(e.curOp,function(e){for(var t=0;t<e.ops.length;t++)e.ops[t].cm.curOp=null;ln(e)})}function ln(e){for(var t=e.ops,r=0;r<t.length;r++)sn(t[r]);for(var n=0;n<t.length;n++)an(t[n]);for(var i=0;i<t.length;i++)un(t[i]);for(var o=0;o<t.length;o++)cn(t[o]);for(var l=0;l<t.length;l++)fn(t[l])}function sn(e){var t=e.cm,r=t.display;Ln(t),e.updateMaxLine&&we(t),e.mustUpdate=e.viewChanged||e.forceUpdate||null!=e.scrollTop||e.scrollToPos&&(e.scrollToPos.from.line<r.viewFrom||e.scrollToPos.to.line>=r.viewTo)||r.maxLineChanged&&t.options.lineWrapping,e.update=e.mustUpdate&&new Cs(t,e.mustUpdate&&{top:e.scrollTop,ensure:e.scrollToPos},e.forceUpdate)}function an(e){e.updatedDisplay=e.mustUpdate&&Mn(e.cm,e.update)}function un(e){var t=e.cm,r=t.display;e.updatedDisplay&&Er(t),e.barMeasure=Jr(t),r.maxLineChanged&&!t.options.lineWrapping&&(e.adjustWidthTo=Kt(t,r.maxLine,r.maxLine.text.length).left+3,t.display.sizerWidth=e.adjustWidthTo,e.barMeasure.scrollWidth=Math.max(r.scroller.clientWidth,r.sizer.offsetLeft+e.adjustWidthTo+zt(t)+t.display.barWidth),e.maxScrollLeft=Math.max(0,r.sizer.offsetLeft+e.adjustWidthTo-Rt(t))),(e.updatedDisplay||e.selectionChanged)&&(e.preparedSelection=r.input.prepareSelection())}function cn(e){var t=e.cm;null!=e.adjustWidthTo&&(t.display.sizer.style.minWidth=e.adjustWidthTo+"px",e.maxScrollLeft<t.doc.scrollLeft&&Qr(t,Math.min(t.display.scroller.scrollLeft,e.maxScrollLeft),!0),t.display.maxLineChanged=!1);var r=e.focus&&e.focus==l();e.preparedSelection&&t.display.input.showSelection(e.preparedSelection,r),(e.updatedDisplay||e.startHeight!=t.doc.height)&&en(t,e.barMeasure),e.updatedDisplay&&Dn(t,e.barMeasure),e.selectionChanged&&Ar(t),t.state.focused&&e.updateInput&&t.display.input.reset(e.typing),r&&Wr(e.cm)}function fn(e){var t=e.cm,r=t.display,n=t.doc;e.updatedDisplay&&Nn(t,e.update),null==r.wheelStartX||null==e.scrollTop&&null==e.scrollLeft&&!e.scrollToPos||(r.wheelStartX=r.wheelStartY=null),null!=e.scrollTop&&Zr(t,e.scrollTop,e.forceScroll),null!=e.scrollLeft&&Qr(t,e.scrollLeft,!0,!0),e.scrollToPos&&Br(t,Gr(t,U(n,e.scrollToPos.from),U(n,e.scrollToPos.to),e.scrollToPos.margin));var i=e.maybeHiddenMarkers,o=e.maybeUnhiddenMarkers;if(i)for(var l=0;l<i.length;++l)i[l].lines.length||Te(i[l],"hide");if(o)for(var s=0;s<o.length;++s)o[s].lines.length&&Te(o[s],"unhide");r.wrapper.offsetHeight&&(n.scrollTop=t.display.scroller.scrollTop),e.changeObjs&&Te(t,"changes",t,e.changeObjs),e.update&&e.update.finish()}function hn(e,t){if(e.curOp)return t();nn(e);try{return t()}finally{on(e)}}function dn(e,t){return function(){if(e.curOp)return t.apply(e,arguments);nn(e);try{return t.apply(e,arguments)}finally{on(e)}}}function pn(e){return function(){if(this.curOp)return e.apply(this,arguments);nn(this);try{return e.apply(this,arguments)}finally{on(this)}}}function gn(e){return function(){var t=this.cm;if(!t||t.curOp)return e.apply(this,arguments);nn(t);try{return e.apply(this,arguments)}finally{on(t)}}}function vn(e,t,r,n){null==t&&(t=e.doc.first),null==r&&(r=e.doc.first+e.doc.size),n||(n=0);var i=e.display;if(n&&r<i.viewTo&&(null==i.updateLineNumbers||i.updateLineNumbers>t)&&(i.updateLineNumbers=t),e.curOp.viewChanged=!0,t>=i.viewTo)_l&&pe(e.doc,t)<i.viewTo&&yn(e);else if(r<=i.viewFrom)_l&&ge(e.doc,r+n)>i.viewFrom?yn(e):(i.viewFrom+=n,i.viewTo+=n);else if(t<=i.viewFrom&&r>=i.viewTo)yn(e);else if(t<=i.viewFrom){var o=bn(e,r,r+n,1);o?(i.view=i.view.slice(o.index),i.viewFrom=o.lineN,i.viewTo+=n):yn(e)}else if(r>=i.viewTo){var l=bn(e,t,t,-1);l?(i.view=i.view.slice(0,l.index),i.viewTo=l.lineN):yn(e)}else{var s=bn(e,t,t,-1),a=bn(e,r,r+n,1);s&&a?(i.view=i.view.slice(0,s.index).concat(gt(e,s.lineN,a.lineN)).concat(i.view.slice(a.index)),i.viewTo+=n):yn(e)}var u=i.externalMeasured;u&&(r<u.lineN?u.lineN+=n:t<u.lineN+u.size&&(i.externalMeasured=null))}function mn(e,t,r){e.curOp.viewChanged=!0;var n=e.display,i=e.display.externalMeasured;if(i&&t>=i.lineN&&t<i.lineN+i.size&&(n.externalMeasured=null),!(t<n.viewFrom||t>=n.viewTo)){var o=n.view[Lr(e,t)];if(null!=o.node){var l=o.changes||(o.changes=[]);-1==h(l,r)&&l.push(r)}}}function yn(e){e.display.viewFrom=e.display.viewTo=e.doc.first,e.display.view=[],e.display.viewOffset=0}function bn(e,t,r,n){var i,o=Lr(e,t),l=e.display.view;if(!_l||r==e.doc.first+e.doc.size)return{index:o,lineN:r};for(var s=e.display.viewFrom,a=0;a<o;a++)s+=l[a].size;if(s!=t){if(n>0){if(o==l.length-1)return null;i=s+l[o].size-t,o++}else i=s-t;t+=i,r+=i}for(;pe(e.doc,r)!=r;){if(o==(n<0?0:l.length-1))return null;r+=n*l[o-(n<0?1:0)].size,o+=n}return{index:o,lineN:r}}function wn(e,t,r){var n=e.display;0==n.view.length||t>=n.viewTo||r<=n.viewFrom?(n.view=gt(e,t,r),n.viewFrom=t):(n.viewFrom>t?n.view=gt(e,t,n.viewFrom).concat(n.view):n.viewFrom<t&&(n.view=n.view.slice(Lr(e,t))),n.viewFrom=t,n.viewTo<r?n.view=n.view.concat(gt(e,n.viewTo,r)):n.viewTo>r&&(n.view=n.view.slice(0,Lr(e,r)))),n.viewTo=r}function xn(e){for(var t=e.display.view,r=0,n=0;n<t.length;n++){var i=t[n];i.hidden||i.node&&!i.changes||++r}return r}function Cn(e,t){e.doc.highlightFrontier<e.display.viewTo&&e.state.highlight.set(t,u(Sn,e))}function Sn(e){var t=e.doc;if(!(t.highlightFrontier>=e.display.viewTo)){var r=+new Date+e.options.workTime,n=$e(e,t.highlightFrontier),i=[];t.iter(n.line,Math.min(t.first+t.size,e.display.viewTo+500),function(o){if(n.line>=e.display.viewFrom){var l=o.styles,s=o.text.length>e.options.maxHighlightLength?Ke(t.mode,n.state):null,a=Ye(e,o,n,!0);s&&(n.state=s),o.styles=a.styles;var u=o.styleClasses,c=a.classes;c?o.styleClasses=c:u&&(o.styleClasses=null);for(var f=!l||l.length!=o.styles.length||u!=c&&(!u||!c||u.bgClass!=c.bgClass||u.textClass!=c.textClass),h=0;!f&&h<l.length;++h)f=l[h]!=o.styles[h];f&&i.push(n.line),o.stateAfter=n.save(),n.nextLine()}else o.text.length<=e.options.maxHighlightLength&&qe(e,o.text,n),o.stateAfter=n.line%5==0?n.save():null,n.nextLine();if(+new Date>r)return Cn(e,e.options.workDelay),!0}),t.highlightFrontier=n.line,t.modeFrontier=Math.max(t.modeFrontier,n.line),i.length&&hn(e,function(){for(var t=0;t<i.length;t++)mn(e,i[t],"text")})}}function Ln(e){var t=e.display;!t.scrollbarsClipped&&t.scroller.offsetWidth&&(t.nativeBarWidth=t.scroller.offsetWidth-t.scroller.clientWidth,t.heightForcer.style.height=zt(e)+"px",t.sizer.style.marginBottom=-t.nativeBarWidth+"px",t.sizer.style.borderRightWidth=zt(e)+"px",t.scrollbarsClipped=!0)}function kn(e){if(e.hasFocus())return null;var t=l();if(!t||!o(e.display.lineDiv,t))return null;var r={activeElt:t};if(window.getSelection){var n=window.getSelection();n.anchorNode&&n.extend&&o(e.display.lineDiv,n.anchorNode)&&(r.anchorNode=n.anchorNode,r.anchorOffset=n.anchorOffset,r.focusNode=n.focusNode,r.focusOffset=n.focusOffset)}return r}function Tn(e){if(e&&e.activeElt&&e.activeElt!=l()&&(e.activeElt.focus(),e.anchorNode&&o(document.body,e.anchorNode)&&o(document.body,e.focusNode))){var t=window.getSelection(),r=document.createRange();r.setEnd(e.anchorNode,e.anchorOffset),r.collapse(!1),t.removeAllRanges(),t.addRange(r),t.extend(e.focusNode,e.focusOffset)}}function Mn(e,r){var n=e.display,i=e.doc;if(r.editorIsHidden)return yn(e),!1;if(!r.force&&r.visible.from>=n.viewFrom&&r.visible.to<=n.viewTo&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo)&&n.renderedView==n.view&&0==xn(e))return!1;Rr(e)&&(yn(e),r.dims=br(e));var o=i.first+i.size,l=Math.max(r.visible.from-e.options.viewportMargin,i.first),s=Math.min(o,r.visible.to+e.options.viewportMargin);n.viewFrom<l&&l-n.viewFrom<20&&(l=Math.max(i.first,n.viewFrom)),n.viewTo>s&&n.viewTo-s<20&&(s=Math.min(o,n.viewTo)),_l&&(l=pe(e.doc,l),s=ge(e.doc,s));var a=l!=n.viewFrom||s!=n.viewTo||n.lastWrapHeight!=r.wrapperHeight||n.lastWrapWidth!=r.wrapperWidth;wn(e,l,s),n.viewOffset=ye(M(e.doc,n.viewFrom)),e.display.mover.style.top=n.viewOffset+"px";var u=xn(e);if(!a&&0==u&&!r.force&&n.renderedView==n.view&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo))return!1;var c=kn(e);return u>4&&(n.lineDiv.style.display="none"),An(e,n.updateLineNumbers,r.dims),u>4&&(n.lineDiv.style.display=""),n.renderedView=n.view,Tn(c),t(n.cursorDiv),t(n.selectionDiv),n.gutters.style.height=n.sizer.style.minHeight=0,a&&(n.lastWrapHeight=r.wrapperHeight,n.lastWrapWidth=r.wrapperWidth,Cn(e,400)),n.updateLineNumbers=null,!0}function Nn(e,t){for(var r=t.viewport,n=!0;(n&&e.options.lineWrapping&&t.oldDisplayWidth!=Rt(e)||(r&&null!=r.top&&(r={top:Math.min(e.doc.height+Pt(e.display)-Bt(e),r.top)}),t.visible=Ir(e.display,e.doc,r),!(t.visible.from>=e.display.viewFrom&&t.visible.to<=e.display.viewTo)))&&Mn(e,t);n=!1){Er(e);var i=Jr(e);kr(e),en(e,i),Dn(e,i),t.force=!1}t.signal(e,"update",e),e.display.viewFrom==e.display.reportedViewFrom&&e.display.viewTo==e.display.reportedViewTo||(t.signal(e,"viewportChange",e,e.display.viewFrom,e.display.viewTo),e.display.reportedViewFrom=e.display.viewFrom,e.display.reportedViewTo=e.display.viewTo)}function On(e,t){var r=new Cs(e,t);if(Mn(e,r)){Er(e),Nn(e,r);var n=Jr(e);kr(e),en(e,n),Dn(e,n),r.finish()}}function An(e,r,n){function i(t){var r=t.nextSibling;return ml&&Ml&&e.display.currentWheelTarget==t?t.style.display="none":t.parentNode.removeChild(t),r}for(var o=e.display,l=e.options.lineNumbers,s=o.lineDiv,a=s.firstChild,u=o.view,c=o.viewFrom,f=0;f<u.length;f++){var d=u[f];if(d.hidden);else if(d.node&&d.node.parentNode==s){for(;a!=d.node;)a=i(a);var p=l&&null!=r&&r<=c&&d.lineNumber;d.changes&&(h(d.changes,"gutter")>-1&&(p=!1),xt(e,d,c,n)),p&&(t(d.lineNumber),d.lineNumber.appendChild(document.createTextNode(F(e.options,c)))),a=d.node.nextSibling}else{var g=Ot(e,d,c,n);s.insertBefore(g,a)}c+=d.size}for(;a;)a=i(a)}function Wn(e){var t=e.display.gutters.offsetWidth;e.display.sizer.style.marginLeft=t+"px"}function Dn(e,t){e.display.sizer.style.minHeight=t.docHeight+"px",e.display.heightForcer.style.top=t.docHeight+"px",e.display.gutters.style.height=t.docHeight+e.display.barHeight+zt(e)+"px"}function Hn(e){var r=e.display.gutters,i=e.options.gutters;t(r);for(var o=0;o<i.length;++o){var l=i[o],s=r.appendChild(n("div",null,"CodeMirror-gutter "+l));"CodeMirror-linenumbers"==l&&(e.display.lineGutter=s,s.style.width=(e.display.lineNumWidth||1)+"px")}r.style.display=o?"":"none",Wn(e)}function Fn(e){var t=h(e.gutters,"CodeMirror-linenumbers");-1==t&&e.lineNumbers?e.gutters=e.gutters.concat(["CodeMirror-linenumbers"]):t>-1&&!e.lineNumbers&&(e.gutters=e.gutters.slice(0),e.gutters.splice(t,1))}function En(e){var t=e.wheelDeltaX,r=e.wheelDeltaY;return null==t&&e.detail&&e.axis==e.HORIZONTAL_AXIS&&(t=e.detail),null==r&&e.detail&&e.axis==e.VERTICAL_AXIS?r=e.detail:null==r&&(r=e.wheelDelta),{x:t,y:r}}function Pn(e){var t=En(e);return t.x*=Ls,t.y*=Ls,t}function In(e,t){var r=En(t),n=r.x,i=r.y,o=e.display,l=o.scroller,s=l.scrollWidth>l.clientWidth,a=l.scrollHeight>l.clientHeight;if(n&&s||i&&a){if(i&&Ml&&ml)e:for(var u=t.target,c=o.view;u!=l;u=u.parentNode)for(var f=0;f<c.length;f++)if(c[f].node==u){e.display.currentWheelTarget=u;break e}if(n&&!fl&&!wl&&null!=Ls)return i&&a&&qr(e,Math.max(0,l.scrollTop+i*Ls)),Qr(e,Math.max(0,l.scrollLeft+n*Ls)),(!i||i&&a)&&We(t),void(o.wheelStartX=null);if(i&&null!=Ls){var h=i*Ls,d=e.doc.scrollTop,p=d+o.wrapper.clientHeight;h<0?d=Math.max(0,d+h-50):p=Math.min(e.doc.height,p+h+50),On(e,{top:d,bottom:p})}Ss<20&&(null==o.wheelStartX?(o.wheelStartX=l.scrollLeft,o.wheelStartY=l.scrollTop,o.wheelDX=n,o.wheelDY=i,setTimeout(function(){if(null!=o.wheelStartX){var e=l.scrollLeft-o.wheelStartX,t=l.scrollTop-o.wheelStartY,r=t&&o.wheelDY&&t/o.wheelDY||e&&o.wheelDX&&e/o.wheelDX;o.wheelStartX=o.wheelStartY=null,r&&(Ls=(Ls*Ss+r)/(Ss+1),++Ss)}},200)):(o.wheelDX+=n,o.wheelDY+=i))}}function zn(e,t){var r=e[t];e.sort(function(e,t){return P(e.from(),t.from())}),t=h(e,r);for(var n=1;n<e.length;n++){var i=e[n],o=e[n-1];if(P(o.to(),i.from())>=0){var l=B(o.from(),i.from()),s=R(o.to(),i.to()),a=o.empty()?i.from()==i.head:o.from()==o.head;n<=t&&--t,e.splice(--n,2,new Ts(a?s:l,a?l:s))}}return new ks(e,t)}function Rn(e,t){return new ks([new Ts(e,t||e)],0)}function Bn(e){return e.text?E(e.from.line+e.text.length-1,g(e.text).length+(1==e.text.length?e.from.ch:0)):e.to}function Gn(e,t){if(P(e,t.from)<0)return e;if(P(e,t.to)<=0)return Bn(t);var r=e.line+t.text.length-(t.to.line-t.from.line)-1,n=e.ch;return e.line==t.to.line&&(n+=Bn(t).ch-t.to.ch),E(r,n)}function Un(e,t){for(var r=[],n=0;n<e.sel.ranges.length;n++){var i=e.sel.ranges[n];r.push(new Ts(Gn(i.anchor,t),Gn(i.head,t)))}return zn(r,e.sel.primIndex)}function Vn(e,t,r){return e.line==t.line?E(r.line,e.ch-t.ch+r.ch):E(r.line+(e.line-t.line),e.ch)}function Kn(e,t,r){for(var n=[],i=E(e.first,0),o=i,l=0;l<t.length;l++){var s=t[l],a=Vn(s.from,i,o),u=Vn(Bn(s),i,o);if(i=s.to,o=u,"around"==r){var c=e.sel.ranges[l],f=P(c.head,c.anchor)<0;n[l]=new Ts(f?u:a,f?a:u)}else n[l]=new Ts(a,a)}return new ks(n,e.sel.primIndex)}function jn(e){e.doc.mode=Ue(e.options,e.doc.modeOption),Xn(e)}function Xn(e){e.doc.iter(function(e){e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null)}),e.doc.modeFrontier=e.doc.highlightFrontier=e.doc.first,Cn(e,100),e.state.modeGen++,e.curOp&&vn(e)}function Yn(e,t){return 0==t.from.ch&&0==t.to.ch&&""==g(t.text)&&(!e.cm||e.cm.options.wholeLineUpdateBefore)}function _n(e,t,r,n){function i(e){return r?r[e]:null}function o(e,r,i){it(e,r,i,n),bt(e,"change",e,t)}function l(e,t){for(var r=[],o=e;o<t;++o)r.push(new fs(u[o],i(o),n));return r}var s=t.from,a=t.to,u=t.text,c=M(e,s.line),f=M(e,a.line),h=g(u),d=i(u.length-1),p=a.line-s.line;if(t.full)e.insert(0,l(0,u.length)),e.remove(u.length,e.size-u.length);else if(Yn(e,t)){var v=l(0,u.length-1);o(f,f.text,d),p&&e.remove(s.line,p),v.length&&e.insert(s.line,v)}else if(c==f)if(1==u.length)o(c,c.text.slice(0,s.ch)+h+c.text.slice(a.ch),d);else{var m=l(1,u.length-1);m.push(new fs(h+c.text.slice(a.ch),d,n)),o(c,c.text.slice(0,s.ch)+u[0],i(0)),e.insert(s.line+1,m)}else if(1==u.length)o(c,c.text.slice(0,s.ch)+u[0]+f.text.slice(a.ch),i(0)),e.remove(s.line+1,p);else{o(c,c.text.slice(0,s.ch)+u[0],i(0)),o(f,h+f.text.slice(a.ch),d);var y=l(1,u.length-1);p>1&&e.remove(s.line+1,p-1),e.insert(s.line+1,y)}bt(e,"change",e,t)}function $n(e,t,r){function n(e,i,o){if(e.linked)for(var l=0;l<e.linked.length;++l){var s=e.linked[l];if(s.doc!=i){var a=o&&s.sharedHist;r&&!a||(t(s.doc,a),n(s.doc,e,a))}}}n(e,null,!0)}function qn(e,t){if(t.cm)throw new Error("This document is already in use.");e.doc=t,t.cm=e,Cr(e),jn(e),Zn(e),e.options.lineWrapping||we(e),e.options.mode=t.modeOption,vn(e)}function Zn(e){("rtl"==e.doc.direction?s:Fl)(e.display.lineDiv,"CodeMirror-rtl")}function Qn(e){hn(e,function(){Zn(e),vn(e)})}function Jn(e){this.done=[],this.undone=[],this.undoDepth=1/0,this.lastModTime=this.lastSelTime=0,this.lastOp=this.lastSelOp=null,this.lastOrigin=this.lastSelOrigin=null,this.generation=this.maxGeneration=e||1}function ei(e,t){var r={from:z(t.from),to:Bn(t),text:N(e,t.from,t.to)};return si(e,r,t.from.line,t.to.line+1),$n(e,function(e){return si(e,r,t.from.line,t.to.line+1)},!0),r}function ti(e){for(;e.length&&g(e).ranges;)e.pop()}function ri(e,t){return t?(ti(e.done),g(e.done)):e.done.length&&!g(e.done).ranges?g(e.done):e.done.length>1&&!e.done[e.done.length-2].ranges?(e.done.pop(),g(e.done)):void 0}function ni(e,t,r,n){var i=e.history;i.undone.length=0;var o,l,s=+new Date;if((i.lastOp==n||i.lastOrigin==t.origin&&t.origin&&("+"==t.origin.charAt(0)&&e.cm&&i.lastModTime>s-e.cm.options.historyEventDelay||"*"==t.origin.charAt(0)))&&(o=ri(i,i.lastOp==n)))l=g(o.changes),0==P(t.from,t.to)&&0==P(t.from,l.to)?l.to=Bn(t):o.changes.push(ei(e,t));else{var a=g(i.done);for(a&&a.ranges||li(e.sel,i.done),o={changes:[ei(e,t)],generation:i.generation},i.done.push(o);i.done.length>i.undoDepth;)i.done.shift(),i.done[0].ranges||i.done.shift()}i.done.push(r),i.generation=++i.maxGeneration,i.lastModTime=i.lastSelTime=s,i.lastOp=i.lastSelOp=n,i.lastOrigin=i.lastSelOrigin=t.origin,l||Te(e,"historyAdded")}function ii(e,t,r,n){var i=t.charAt(0);return"*"==i||"+"==i&&r.ranges.length==n.ranges.length&&r.somethingSelected()==n.somethingSelected()&&new Date-e.history.lastSelTime<=(e.cm?e.cm.options.historyEventDelay:500)}function oi(e,t,r,n){var i=e.history,o=n&&n.origin;r==i.lastSelOp||o&&i.lastSelOrigin==o&&(i.lastModTime==i.lastSelTime&&i.lastOrigin==o||ii(e,o,g(i.done),t))?i.done[i.done.length-1]=t:li(t,i.done),i.lastSelTime=+new Date,i.lastSelOrigin=o,i.lastSelOp=r,n&&!1!==n.clearRedo&&ti(i.undone)}function li(e,t){var r=g(t);r&&r.ranges&&r.equals(e)||t.push(e)}function si(e,t,r,n){var i=t["spans_"+e.id],o=0;e.iter(Math.max(e.first,r),Math.min(e.first+e.size,n),function(r){r.markedSpans&&((i||(i=t["spans_"+e.id]={}))[o]=r.markedSpans),++o})}function ai(e){if(!e)return null;for(var t,r=0;r<e.length;++r)e[r].marker.explicitlyCleared?t||(t=e.slice(0,r)):t&&t.push(e[r]);return t?t.length?t:null:e}function ui(e,t){var r=t["spans_"+e.id];if(!r)return null;for(var n=[],i=0;i<t.text.length;++i)n.push(ai(r[i]));return n}function ci(e,t){var r=ui(e,t),n=J(e,t);if(!r)return n;if(!n)return r;for(var i=0;i<r.length;++i){var o=r[i],l=n[i];if(o&&l)e:for(var s=0;s<l.length;++s){for(var a=l[s],u=0;u<o.length;++u)if(o[u].marker==a.marker)continue e;o.push(a)}else l&&(r[i]=l)}return r}function fi(e,t,r){for(var n=[],i=0;i<e.length;++i){var o=e[i];if(o.ranges)n.push(r?ks.prototype.deepCopy.call(o):o);else{var l=o.changes,s=[];n.push({changes:s});for(var a=0;a<l.length;++a){var u=l[a],c=void 0;if(s.push({from:u.from,to:u.to,text:u.text}),t)for(var f in u)(c=f.match(/^spans_(\d+)$/))&&h(t,Number(c[1]))>-1&&(g(s)[f]=u[f],delete u[f])}}}return n}function hi(e,t,r,n){if(n){var i=e.anchor;if(r){var o=P(t,i)<0;o!=P(r,i)<0?(i=t,t=r):o!=P(t,r)<0&&(t=r)}return new Ts(i,t)}return new Ts(r||t,t)}function di(e,t,r,n,i){null==i&&(i=e.cm&&(e.cm.display.shift||e.extend)),bi(e,new ks([hi(e.sel.primary(),t,r,i)],0),n)}function pi(e,t,r){for(var n=[],i=e.cm&&(e.cm.display.shift||e.extend),o=0;o<e.sel.ranges.length;o++)n[o]=hi(e.sel.ranges[o],t[o],null,i);bi(e,zn(n,e.sel.primIndex),r)}function gi(e,t,r,n){var i=e.sel.ranges.slice(0);i[t]=r,bi(e,zn(i,e.sel.primIndex),n)}function vi(e,t,r,n){bi(e,Rn(t,r),n)}function mi(e,t,r){var n={ranges:t.ranges,update:function(t){var r=this;this.ranges=[];for(var n=0;n<t.length;n++)r.ranges[n]=new Ts(U(e,t[n].anchor),U(e,t[n].head))},origin:r&&r.origin};return Te(e,"beforeSelectionChange",e,n),e.cm&&Te(e.cm,"beforeSelectionChange",e.cm,n),n.ranges!=t.ranges?zn(n.ranges,n.ranges.length-1):t}function yi(e,t,r){var n=e.history.done,i=g(n);i&&i.ranges?(n[n.length-1]=t,wi(e,t,r)):bi(e,t,r)}function bi(e,t,r){wi(e,t,r),oi(e,e.sel,e.cm?e.cm.curOp.id:NaN,r)}function wi(e,t,r){(Oe(e,"beforeSelectionChange")||e.cm&&Oe(e.cm,"beforeSelectionChange"))&&(t=mi(e,t,r)),xi(e,Si(e,t,r&&r.bias||(P(t.primary().head,e.sel.primary().head)<0?-1:1),!0)),r&&!1===r.scroll||!e.cm||jr(e.cm)}function xi(e,t){t.equals(e.sel)||(e.sel=t,e.cm&&(e.cm.curOp.updateInput=e.cm.curOp.selectionChanged=!0,Ne(e.cm)),bt(e,"cursorActivity",e))}function Ci(e){xi(e,Si(e,e.sel,null,!1))}function Si(e,t,r,n){for(var i,o=0;o<t.ranges.length;o++){var l=t.ranges[o],s=t.ranges.length==e.sel.ranges.length&&e.sel.ranges[o],a=ki(e,l.anchor,s&&s.anchor,r,n),u=ki(e,l.head,s&&s.head,r,n);(i||a!=l.anchor||u!=l.head)&&(i||(i=t.ranges.slice(0,o)),i[o]=new Ts(a,u))}return i?zn(i,t.primIndex):t}function Li(e,t,r,n,i){var o=M(e,t.line);if(o.markedSpans)for(var l=0;l<o.markedSpans.length;++l){var s=o.markedSpans[l],a=s.marker;if((null==s.from||(a.inclusiveLeft?s.from<=t.ch:s.from<t.ch))&&(null==s.to||(a.inclusiveRight?s.to>=t.ch:s.to>t.ch))){if(i&&(Te(a,"beforeCursorEnter"),a.explicitlyCleared)){if(o.markedSpans){--l;continue}break}if(!a.atomic)continue;if(r){var u=a.find(n<0?1:-1),c=void 0;if((n<0?a.inclusiveRight:a.inclusiveLeft)&&(u=Ti(e,u,-n,u&&u.line==t.line?o:null)),u&&u.line==t.line&&(c=P(u,r))&&(n<0?c<0:c>0))return Li(e,u,t,n,i)}var f=a.find(n<0?-1:1);return(n<0?a.inclusiveLeft:a.inclusiveRight)&&(f=Ti(e,f,n,f.line==t.line?o:null)),f?Li(e,f,t,n,i):null}}return t}function ki(e,t,r,n,i){var o=n||1,l=Li(e,t,r,o,i)||!i&&Li(e,t,r,o,!0)||Li(e,t,r,-o,i)||!i&&Li(e,t,r,-o,!0);return l||(e.cantEdit=!0,E(e.first,0))}function Ti(e,t,r,n){return r<0&&0==t.ch?t.line>e.first?U(e,E(t.line-1)):null:r>0&&t.ch==(n||M(e,t.line)).text.length?t.line<e.first+e.size-1?E(t.line+1,0):null:new E(t.line,t.ch+r)}function Mi(e){e.setSelection(E(e.firstLine(),0),E(e.lastLine()),Gl)}function Ni(e,t,r){var n={canceled:!1,from:t.from,to:t.to,text:t.text,origin:t.origin,cancel:function(){return n.canceled=!0}};return r&&(n.update=function(t,r,i,o){t&&(n.from=U(e,t)),r&&(n.to=U(e,r)),i&&(n.text=i),void 0!==o&&(n.origin=o)}),Te(e,"beforeChange",e,n),e.cm&&Te(e.cm,"beforeChange",e.cm,n),n.canceled?null:{from:n.from,to:n.to,text:n.text,origin:n.origin}}function Oi(e,t,r){if(e.cm){if(!e.cm.curOp)return dn(e.cm,Oi)(e,t,r);if(e.cm.state.suppressEdits)return}if(!(Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"))||(t=Ni(e,t,!0))){var n=Yl&&!r&&te(e,t.from,t.to);if(n)for(var i=n.length-1;i>=0;--i)Ai(e,{from:n[i].from,to:n[i].to,text:i?[""]:t.text,origin:t.origin});else Ai(e,t)}}function Ai(e,t){if(1!=t.text.length||""!=t.text[0]||0!=P(t.from,t.to)){var r=Un(e,t);ni(e,t,r,e.cm?e.cm.curOp.id:NaN),Hi(e,t,r,J(e,t));var n=[];$n(e,function(e,r){r||-1!=h(n,e.history)||(zi(e.history,t),n.push(e.history)),Hi(e,t,null,J(e,t))})}}function Wi(e,t,r){if(!e.cm||!e.cm.state.suppressEdits||r){for(var n,i=e.history,o=e.sel,l="undo"==t?i.done:i.undone,s="undo"==t?i.undone:i.done,a=0;a<l.length&&(n=l[a],r?!n.ranges||n.equals(e.sel):n.ranges);a++);if(a!=l.length){for(i.lastOrigin=i.lastSelOrigin=null;(n=l.pop()).ranges;){if(li(n,s),r&&!n.equals(e.sel))return void bi(e,n,{clearRedo:!1});o=n}var u=[];li(o,s),s.push({changes:u,generation:i.generation}),i.generation=n.generation||++i.maxGeneration;for(var c=Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"),f=n.changes.length-1;f>=0;--f){var d=function(r){var i=n.changes[r];if(i.origin=t,c&&!Ni(e,i,!1))return l.length=0,{};u.push(ei(e,i));var o=r?Un(e,i):g(l);Hi(e,i,o,ci(e,i)),!r&&e.cm&&e.cm.scrollIntoView({from:i.from,to:Bn(i)});var s=[];$n(e,function(e,t){t||-1!=h(s,e.history)||(zi(e.history,i),s.push(e.history)),Hi(e,i,null,ci(e,i))})}(f);if(d)return d.v}}}}function Di(e,t){if(0!=t&&(e.first+=t,e.sel=new ks(v(e.sel.ranges,function(e){return new Ts(E(e.anchor.line+t,e.anchor.ch),E(e.head.line+t,e.head.ch))}),e.sel.primIndex),e.cm)){vn(e.cm,e.first,e.first-t,t);for(var r=e.cm.display,n=r.viewFrom;n<r.viewTo;n++)mn(e.cm,n,"gutter")}}function Hi(e,t,r,n){if(e.cm&&!e.cm.curOp)return dn(e.cm,Hi)(e,t,r,n);if(t.to.line<e.first)Di(e,t.text.length-1-(t.to.line-t.from.line));else if(!(t.from.line>e.lastLine())){if(t.from.line<e.first){var i=t.text.length-1-(e.first-t.from.line);Di(e,i),t={from:E(e.first,0),to:E(t.to.line+i,t.to.ch),text:[g(t.text)],origin:t.origin}}var o=e.lastLine();t.to.line>o&&(t={from:t.from,to:E(o,M(e,o).text.length),text:[t.text[0]],origin:t.origin}),t.removed=N(e,t.from,t.to),r||(r=Un(e,t)),e.cm?Fi(e.cm,t,n):_n(e,t,n),wi(e,r,Gl)}}function Fi(e,t,r){var n=e.doc,i=e.display,o=t.from,l=t.to,s=!1,a=o.line;e.options.lineWrapping||(a=W(fe(M(n,o.line))),n.iter(a,l.line+1,function(e){if(e==i.maxLine)return s=!0,!0})),n.sel.contains(t.from,t.to)>-1&&Ne(e),_n(n,t,r,xr(e)),e.options.lineWrapping||(n.iter(a,o.line+t.text.length,function(e){var t=be(e);t>i.maxLineLength&&(i.maxLine=e,i.maxLineLength=t,i.maxLineChanged=!0,s=!1)}),s&&(e.curOp.updateMaxLine=!0)),nt(n,o.line),Cn(e,400);var u=t.text.length-(l.line-o.line)-1;t.full?vn(e):o.line!=l.line||1!=t.text.length||Yn(e.doc,t)?vn(e,o.line,l.line+1,u):mn(e,o.line,"text");var c=Oe(e,"changes"),f=Oe(e,"change");if(f||c){var h={from:o,to:l,text:t.text,removed:t.removed,origin:t.origin};f&&bt(e,"change",e,h),c&&(e.curOp.changeObjs||(e.curOp.changeObjs=[])).push(h)}e.display.selForContextMenu=null}function Ei(e,t,r,n,i){if(n||(n=r),P(n,r)<0){var o;r=(o=[n,r])[0],n=o[1]}"string"==typeof t&&(t=e.splitLines(t)),Oi(e,{from:r,to:n,text:t,origin:i})}function Pi(e,t,r,n){r<e.line?e.line+=n:t<e.line&&(e.line=t,e.ch=0)}function Ii(e,t,r,n){for(var i=0;i<e.length;++i){var o=e[i],l=!0;if(o.ranges){o.copied||((o=e[i]=o.deepCopy()).copied=!0);for(var s=0;s<o.ranges.length;s++)Pi(o.ranges[s].anchor,t,r,n),Pi(o.ranges[s].head,t,r,n)}else{for(var a=0;a<o.changes.length;++a){var u=o.changes[a];if(r<u.from.line)u.from=E(u.from.line+n,u.from.ch),u.to=E(u.to.line+n,u.to.ch);else if(t<=u.to.line){l=!1;break}}l||(e.splice(0,i+1),i=0)}}}function zi(e,t){var r=t.from.line,n=t.to.line,i=t.text.length-(n-r)-1;Ii(e.done,r,n,i),Ii(e.undone,r,n,i)}function Ri(e,t,r,n){var i=t,o=t;return"number"==typeof t?o=M(e,G(e,t)):i=W(t),null==i?null:(n(o,i)&&e.cm&&mn(e.cm,i,r),o)}function Bi(e){var t=this;this.lines=e,this.parent=null;for(var r=0,n=0;n<e.length;++n)e[n].parent=t,r+=e[n].height;this.height=r}function Gi(e){var t=this;this.children=e;for(var r=0,n=0,i=0;i<e.length;++i){var o=e[i];r+=o.chunkSize(),n+=o.height,o.parent=t}this.size=r,this.height=n,this.parent=null}function Ui(e,t,r){ye(t)<(e.curOp&&e.curOp.scrollTop||e.doc.scrollTop)&&Kr(e,r)}function Vi(e,t,r,n){var i=new Ms(e,r,n),o=e.cm;return o&&i.noHScroll&&(o.display.alignWidgets=!0),Ri(e,t,"widget",function(t){var r=t.widgets||(t.widgets=[]);if(null==i.insertAt?r.push(i):r.splice(Math.min(r.length-1,Math.max(0,i.insertAt)),0,i),i.line=t,o&&!ve(e,t)){var n=ye(t)<e.scrollTop;A(t,t.height+Ht(i)),n&&Kr(o,i.height),o.curOp.forceUpdate=!0}return!0}),bt(o,"lineWidgetAdded",o,i,"number"==typeof t?t:W(t)),i}function Ki(e,t,r,n,o){if(n&&n.shared)return ji(e,t,r,n,o);if(e.cm&&!e.cm.curOp)return dn(e.cm,Ki)(e,t,r,n,o);var l=new Os(e,o),s=P(t,r);if(n&&c(n,l,!1),s>0||0==s&&!1!==l.clearWhenEmpty)return l;if(l.replacedWith&&(l.collapsed=!0,l.widgetNode=i("span",[l.replacedWith],"CodeMirror-widget"),n.handleMouseEvents||l.widgetNode.setAttribute("cm-ignore-events","true"),n.insertLeft&&(l.widgetNode.insertLeft=!0)),l.collapsed){if(ce(e,t.line,t,r,l)||t.line!=r.line&&ce(e,r.line,t,r,l))throw new Error("Inserting collapsed marker partially overlapping an existing one");X()}l.addToHistory&&ni(e,{from:t,to:r,origin:"markText"},e.sel,NaN);var a,u=t.line,f=e.cm;if(e.iter(u,r.line+1,function(e){f&&l.collapsed&&!f.options.lineWrapping&&fe(e)==f.display.maxLine&&(a=!0),l.collapsed&&u!=t.line&&A(e,0),q(e,new Y(l,u==t.line?t.ch:null,u==r.line?r.ch:null)),++u}),l.collapsed&&e.iter(t.line,r.line+1,function(t){ve(e,t)&&A(t,0)}),l.clearOnEnter&&Ql(l,"beforeCursorEnter",function(){return l.clear()}),l.readOnly&&(j(),(e.history.done.length||e.history.undone.length)&&e.clearHistory()),l.collapsed&&(l.id=++Ns,l.atomic=!0),f){if(a&&(f.curOp.updateMaxLine=!0),l.collapsed)vn(f,t.line,r.line+1);else if(l.className||l.title||l.startStyle||l.endStyle||l.css)for(var h=t.line;h<=r.line;h++)mn(f,h,"text");l.atomic&&Ci(f.doc),bt(f,"markerAdded",f,l)}return l}function ji(e,t,r,n,i){(n=c(n)).shared=!1;var o=[Ki(e,t,r,n,i)],l=o[0],s=n.widgetNode;return $n(e,function(e){s&&(n.widgetNode=s.cloneNode(!0)),o.push(Ki(e,U(e,t),U(e,r),n,i));for(var a=0;a<e.linked.length;++a)if(e.linked[a].isParent)return;l=g(o)}),new As(o,l)}function Xi(e){return e.findMarks(E(e.first,0),e.clipPos(E(e.lastLine())),function(e){return e.parent})}function Yi(e,t){for(var r=0;r<t.length;r++){var n=t[r],i=n.find(),o=e.clipPos(i.from),l=e.clipPos(i.to);if(P(o,l)){var s=Ki(e,o,l,n.primary,n.primary.type);n.markers.push(s),s.parent=n}}}function _i(e){for(var t=0;t<e.length;t++)!function(t){var r=e[t],n=[r.primary.doc];$n(r.primary.doc,function(e){return n.push(e)});for(var i=0;i<r.markers.length;i++){var o=r.markers[i];-1==h(n,o.doc)&&(o.parent=null,r.markers.splice(i--,1))}}(t)}function $i(e){var t=this;if(Qi(t),!Me(t,e)&&!Ft(t.display,e)){We(e),gl&&(Hs=+new Date);var r=Sr(t,e,!0),n=e.dataTransfer.files;if(r&&!t.isReadOnly())if(n&&n.length&&window.FileReader&&window.File)for(var i=n.length,o=Array(i),l=0,s=0;s<i;++s)!function(e,n){if(!t.options.allowDropFileTypes||-1!=h(t.options.allowDropFileTypes,e.type)){var s=new FileReader;s.onload=dn(t,function(){var e=s.result;if(/[\x00-\x08\x0e-\x1f]{2}/.test(e)&&(e=""),o[n]=e,++l==i){var a={from:r=U(t.doc,r),to:r,text:t.doc.splitLines(o.join(t.doc.lineSeparator())),origin:"paste"};Oi(t.doc,a),yi(t.doc,Rn(r,Bn(a)))}}),s.readAsText(e)}}(n[s],s);else{if(t.state.draggingText&&t.doc.sel.contains(r)>-1)return t.state.draggingText(e),void setTimeout(function(){return t.display.input.focus()},20);try{var a=e.dataTransfer.getData("Text");if(a){var u;if(t.state.draggingText&&!t.state.draggingText.copy&&(u=t.listSelections()),wi(t.doc,Rn(r,r)),u)for(var c=0;c<u.length;++c)Ei(t.doc,"",u[c].anchor,u[c].head,"drag");t.replaceSelection(a,"around","paste"),t.display.input.focus()}}catch(e){}}}}function qi(e,t){if(gl&&(!e.state.draggingText||+new Date-Hs<100))Fe(t);else if(!Me(e,t)&&!Ft(e.display,t)&&(t.dataTransfer.setData("Text",e.getSelection()),t.dataTransfer.effectAllowed="copyMove",t.dataTransfer.setDragImage&&!xl)){var r=n("img",null,null,"position: fixed; left: 0; top: 0;");r.src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==",wl&&(r.width=r.height=1,e.display.wrapper.appendChild(r),r._top=r.offsetTop),t.dataTransfer.setDragImage(r,0,0),wl&&r.parentNode.removeChild(r)}}function Zi(e,t){var i=Sr(e,t);if(i){var o=document.createDocumentFragment();Mr(e,i,o),e.display.dragCursor||(e.display.dragCursor=n("div",null,"CodeMirror-cursors CodeMirror-dragcursors"),e.display.lineSpace.insertBefore(e.display.dragCursor,e.display.cursorDiv)),r(e.display.dragCursor,o)}}function Qi(e){e.display.dragCursor&&(e.display.lineSpace.removeChild(e.display.dragCursor),e.display.dragCursor=null)}function Ji(e){if(document.getElementsByClassName)for(var t=document.getElementsByClassName("CodeMirror"),r=0;r<t.length;r++){var n=t[r].CodeMirror;n&&e(n)}}function eo(){Fs||(to(),Fs=!0)}function to(){var e;Ql(window,"resize",function(){null==e&&(e=setTimeout(function(){e=null,Ji(ro)},100))}),Ql(window,"blur",function(){return Ji(Fr)})}function ro(e){var t=e.display;t.lastWrapHeight==t.wrapper.clientHeight&&t.lastWrapWidth==t.wrapper.clientWidth||(t.cachedCharWidth=t.cachedTextHeight=t.cachedPaddingH=null,t.scrollbarsClipped=!1,e.setSize())}function no(e){var t=e.split(/-(?!$)/);e=t[t.length-1];for(var r,n,i,o,l=0;l<t.length-1;l++){var s=t[l];if(/^(cmd|meta|m)$/i.test(s))o=!0;else if(/^a(lt)?$/i.test(s))r=!0;else if(/^(c|ctrl|control)$/i.test(s))n=!0;else{if(!/^s(hift)?$/i.test(s))throw new Error("Unrecognized modifier name: "+s);i=!0}}return r&&(e="Alt-"+e),n&&(e="Ctrl-"+e),o&&(e="Cmd-"+e),i&&(e="Shift-"+e),e}function io(e){var t={};for(var r in e)if(e.hasOwnProperty(r)){var n=e[r];if(/^(name|fallthrough|(de|at)tach)$/.test(r))continue;if("..."==n){delete e[r];continue}for(var i=v(r.split(" "),no),o=0;o<i.length;o++){var l=void 0,s=void 0;o==i.length-1?(s=i.join(" "),l=n):(s=i.slice(0,o+1).join(" "),l="...");var a=t[s];if(a){if(a!=l)throw new Error("Inconsistent bindings for "+s)}else t[s]=l}delete e[r]}for(var u in t)e[u]=t[u];return e}function oo(e,t,r,n){var i=(t=uo(t)).call?t.call(e,n):t[e];if(!1===i)return"nothing";if("..."===i)return"multi";if(null!=i&&r(i))return"handled";if(t.fallthrough){if("[object Array]"!=Object.prototype.toString.call(t.fallthrough))return oo(e,t.fallthrough,r,n);for(var o=0;o<t.fallthrough.length;o++){var l=oo(e,t.fallthrough[o],r,n);if(l)return l}}}function lo(e){var t="string"==typeof e?e:Es[e.keyCode];return"Ctrl"==t||"Alt"==t||"Shift"==t||"Mod"==t}function so(e,t,r){var n=e;return t.altKey&&"Alt"!=n&&(e="Alt-"+e),(Dl?t.metaKey:t.ctrlKey)&&"Ctrl"!=n&&(e="Ctrl-"+e),(Dl?t.ctrlKey:t.metaKey)&&"Cmd"!=n&&(e="Cmd-"+e),!r&&t.shiftKey&&"Shift"!=n&&(e="Shift-"+e),e}function ao(e,t){if(wl&&34==e.keyCode&&e.char)return!1;var r=Es[e.keyCode];return null!=r&&!e.altGraphKey&&so(r,e,t)}function uo(e){return"string"==typeof e?Rs[e]:e}function co(e,t){for(var r=e.doc.sel.ranges,n=[],i=0;i<r.length;i++){for(var o=t(r[i]);n.length&&P(o.from,g(n).to)<=0;){var l=n.pop();if(P(l.from,o.from)<0){o.from=l.from;break}}n.push(o)}hn(e,function(){for(var t=n.length-1;t>=0;t--)Ei(e.doc,"",n[t].from,n[t].to,"+delete");jr(e)})}function fo(e,t,r){var n=L(e.text,t+r,r);return n<0||n>e.text.length?null:n}function ho(e,t,r){var n=fo(e,t.ch,r);return null==n?null:new E(t.line,n,r<0?"after":"before")}function po(e,t,r,n,i){if(e){var o=Se(r,t.doc.direction);if(o){var l,s=i<0?g(o):o[0],a=i<0==(1==s.level)?"after":"before";if(s.level>0){var u=Xt(t,r);l=i<0?r.text.length-1:0;var c=Yt(t,u,l).top;l=k(function(e){return Yt(t,u,e).top==c},i<0==(1==s.level)?s.from:s.to-1,l),"before"==a&&(l=fo(r,l,1))}else l=i<0?s.to:s.from;return new E(n,l,a)}}return new E(n,i<0?r.text.length:0,i<0?"before":"after")}function go(e,t,r,n){var i=Se(t,e.doc.direction);if(!i)return ho(t,r,n);r.ch>=t.text.length?(r.ch=t.text.length,r.sticky="before"):r.ch<=0&&(r.ch=0,r.sticky="after");var o=Ce(i,r.ch,r.sticky),l=i[o];if("ltr"==e.doc.direction&&l.level%2==0&&(n>0?l.to>r.ch:l.from<r.ch))return ho(t,r,n);var s,a=function(e,r){return fo(t,e instanceof E?e.ch:e,r)},u=function(r){return e.options.lineWrapping?(s=s||Xt(e,t),hr(e,t,s,r)):{begin:0,end:t.text.length}},c=u("before"==r.sticky?a(r,-1):r.ch);if("rtl"==e.doc.direction||1==l.level){var f=1==l.level==n<0,h=a(r,f?1:-1);if(null!=h&&(f?h<=l.to&&h<=c.end:h>=l.from&&h>=c.begin)){var d=f?"before":"after";return new E(r.line,h,d)}}var p=function(e,t,n){for(var o=function(e,t){return t?new E(r.line,a(e,1),"before"):new E(r.line,e,"after")};e>=0&&e<i.length;e+=t){var l=i[e],s=t>0==(1!=l.level),u=s?n.begin:a(n.end,-1);if(l.from<=u&&u<l.to)return o(u,s);if(u=s?l.from:a(l.to,-1),n.begin<=u&&u<n.end)return o(u,s)}},g=p(o+n,n,c);if(g)return g;var v=n>0?c.end:a(c.begin,-1);return null==v||n>0&&v==t.text.length||!(g=p(n>0?0:i.length-1,n,u(v)))?null:g}function vo(e,t){var r=M(e.doc,t),n=fe(r);return n!=r&&(t=W(n)),po(!0,e,n,t,1)}function mo(e,t){var r=M(e.doc,t),n=he(r);return n!=r&&(t=W(n)),po(!0,e,r,t,-1)}function yo(e,t){var r=vo(e,t.line),n=M(e.doc,r.line),i=Se(n,e.doc.direction);if(!i||0==i[0].level){var o=Math.max(0,n.text.search(/\S/)),l=t.line==r.line&&t.ch<=o&&t.ch;return E(r.line,l?0:o,r.sticky)}return r}function bo(e,t,r){if("string"==typeof t&&!(t=Bs[t]))return!1;e.display.input.ensurePolled();var n=e.display.shift,i=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),r&&(e.display.shift=!1),i=t(e)!=Bl}finally{e.display.shift=n,e.state.suppressEdits=!1}return i}function wo(e,t,r){for(var n=0;n<e.state.keyMaps.length;n++){var i=oo(t,e.state.keyMaps[n],r,e);if(i)return i}return e.options.extraKeys&&oo(t,e.options.extraKeys,r,e)||oo(t,e.options.keyMap,r,e)}function xo(e,t,r,n){var i=e.state.keySeq;if(i){if(lo(t))return"handled";Gs.set(50,function(){e.state.keySeq==i&&(e.state.keySeq=null,e.display.input.reset())}),t=i+" "+t}var o=wo(e,t,n);return"multi"==o&&(e.state.keySeq=t),"handled"==o&&bt(e,"keyHandled",e,t,r),"handled"!=o&&"multi"!=o||(We(r),Ar(e)),i&&!o&&/\'$/.test(t)?(We(r),!0):!!o}function Co(e,t){var r=ao(t,!0);return!!r&&(t.shiftKey&&!e.state.keySeq?xo(e,"Shift-"+r,t,function(t){return bo(e,t,!0)})||xo(e,r,t,function(t){if("string"==typeof t?/^go[A-Z]/.test(t):t.motion)return bo(e,t)}):xo(e,r,t,function(t){return bo(e,t)}))}function So(e,t,r){return xo(e,"'"+r+"'",t,function(t){return bo(e,t,!0)})}function Lo(e){var t=this;if(t.curOp.focus=l(),!Me(t,e)){gl&&vl<11&&27==e.keyCode&&(e.returnValue=!1);var r=e.keyCode;t.display.shift=16==r||e.shiftKey;var n=Co(t,e);wl&&(Us=n?r:null,!n&&88==r&&!rs&&(Ml?e.metaKey:e.ctrlKey)&&t.replaceSelection("",null,"cut")),18!=r||/\bCodeMirror-crosshair\b/.test(t.display.lineDiv.className)||ko(t)}}function ko(e){function t(e){18!=e.keyCode&&e.altKey||(Fl(r,"CodeMirror-crosshair"),ke(document,"keyup",t),ke(document,"mouseover",t))}var r=e.display.lineDiv;s(r,"CodeMirror-crosshair"),Ql(document,"keyup",t),Ql(document,"mouseover",t)}function To(e){16==e.keyCode&&(this.doc.sel.shift=!1),Me(this,e)}function Mo(e){var t=this;if(!(Ft(t.display,e)||Me(t,e)||e.ctrlKey&&!e.altKey||Ml&&e.metaKey)){var r=e.keyCode,n=e.charCode;if(wl&&r==Us)return Us=null,void We(e);if(!wl||e.which&&!(e.which<10)||!Co(t,e)){var i=String.fromCharCode(null==n?r:n);"\b"!=i&&(So(t,e,i)||t.display.input.onKeyPress(e))}}}function No(e,t){var r=+new Date;return js&&js.compare(r,e,t)?(Ks=js=null,"triple"):Ks&&Ks.compare(r,e,t)?(js=new Vs(r,e,t),Ks=null,"double"):(Ks=new Vs(r,e,t),js=null,"single")}function Oo(e){var t=this,r=t.display;if(!(Me(t,e)||r.activeTouch&&r.input.supportsTouch()))if(r.input.ensurePolled(),r.shift=e.shiftKey,Ft(r,e))ml||(r.scroller.draggable=!1,setTimeout(function(){return r.scroller.draggable=!0},100));else if(!zo(t,e)){var n=Sr(t,e),i=Pe(e),o=n?No(n,i):"single";window.focus(),1==i&&t.state.selectingText&&t.state.selectingText(e),n&&Ao(t,i,n,o,e)||(1==i?n?Do(t,n,o,e):Ee(e)==r.scroller&&We(e):2==i?(n&&di(t.doc,n),setTimeout(function(){return r.input.focus()},20)):3==i&&(Hl?Ro(t,e):Dr(t)))}}function Ao(e,t,r,n,i){var o="Click";return"double"==n?o="Double"+o:"triple"==n&&(o="Triple"+o),o=(1==t?"Left":2==t?"Middle":"Right")+o,xo(e,so(o,i),i,function(t){if("string"==typeof t&&(t=Bs[t]),!t)return!1;var n=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),n=t(e,r)!=Bl}finally{e.state.suppressEdits=!1}return n})}function Wo(e,t,r){var n=e.getOption("configureMouse"),i=n?n(e,t,r):{};if(null==i.unit){var o=Nl?r.shiftKey&&r.metaKey:r.altKey;i.unit=o?"rectangle":"single"==t?"char":"double"==t?"word":"line"}return(null==i.extend||e.doc.extend)&&(i.extend=e.doc.extend||r.shiftKey),null==i.addNew&&(i.addNew=Ml?r.metaKey:r.ctrlKey),null==i.moveOnDrag&&(i.moveOnDrag=!(Ml?r.altKey:r.ctrlKey)),i}function Do(e,t,r,n){gl?setTimeout(u(Wr,e),0):e.curOp.focus=l();var i,o=Wo(e,r,n),s=e.doc.sel;e.options.dragDrop&&Jl&&!e.isReadOnly()&&"single"==r&&(i=s.contains(t))>-1&&(P((i=s.ranges[i]).from(),t)<0||t.xRel>0)&&(P(i.to(),t)>0||t.xRel<0)?Ho(e,n,t,o):Eo(e,n,t,o)}function Ho(e,t,r,n){var i=e.display,o=!1,l=dn(e,function(t){ml&&(i.scroller.draggable=!1),e.state.draggingText=!1,ke(document,"mouseup",l),ke(document,"mousemove",s),ke(i.scroller,"dragstart",a),ke(i.scroller,"drop",l),o||(We(t),n.addNew||di(e.doc,r,null,null,n.extend),ml||gl&&9==vl?setTimeout(function(){document.body.focus(),i.input.focus()},20):i.input.focus())}),s=function(e){o=o||Math.abs(t.clientX-e.clientX)+Math.abs(t.clientY-e.clientY)>=10},a=function(){return o=!0};ml&&(i.scroller.draggable=!0),e.state.draggingText=l,l.copy=!n.moveOnDrag,i.scroller.dragDrop&&i.scroller.dragDrop(),Ql(document,"mouseup",l),Ql(document,"mousemove",s),Ql(i.scroller,"dragstart",a),Ql(i.scroller,"drop",l),Dr(e),setTimeout(function(){return i.input.focus()},20)}function Fo(e,t,r){if("char"==r)return new Ts(t,t);if("word"==r)return e.findWordAt(t);if("line"==r)return new Ts(E(t.line,0),U(e.doc,E(t.line+1,0)));var n=r(e,t);return new Ts(n.from,n.to)}function Eo(e,t,r,n){function i(t){if(0!=P(m,t))if(m=t,"rectangle"==n.unit){for(var i=[],o=e.options.tabSize,l=f(M(u,r.line).text,r.ch,o),s=f(M(u,t.line).text,t.ch,o),a=Math.min(l,s),g=Math.max(l,s),v=Math.min(r.line,t.line),y=Math.min(e.lastLine(),Math.max(r.line,t.line));v<=y;v++){var b=M(u,v).text,w=d(b,a,o);a==g?i.push(new Ts(E(v,w),E(v,w))):b.length>w&&i.push(new Ts(E(v,w),E(v,d(b,g,o))))}i.length||i.push(new Ts(r,r)),bi(u,zn(p.ranges.slice(0,h).concat(i),h),{origin:"*mouse",scroll:!1}),e.scrollIntoView(t)}else{var x,C=c,S=Fo(e,t,n.unit),L=C.anchor;P(S.anchor,L)>0?(x=S.head,L=B(C.from(),S.anchor)):(x=S.anchor,L=R(C.to(),S.head));var k=p.ranges.slice(0);k[h]=Po(e,new Ts(U(u,L),x)),bi(u,zn(k,h),Ul)}}function o(t){var r=++b,s=Sr(e,t,!0,"rectangle"==n.unit);if(s)if(0!=P(s,m)){e.curOp.focus=l(),i(s);var c=Ir(a,u);(s.line>=c.to||s.line<c.from)&&setTimeout(dn(e,function(){b==r&&o(t)}),150)}else{var f=t.clientY<y.top?-20:t.clientY>y.bottom?20:0;f&&setTimeout(dn(e,function(){b==r&&(a.scroller.scrollTop+=f,o(t))}),50)}}function s(t){e.state.selectingText=!1,b=1/0,We(t),a.input.focus(),ke(document,"mousemove",w),ke(document,"mouseup",x),u.history.lastSelOrigin=null}var a=e.display,u=e.doc;We(t);var c,h,p=u.sel,g=p.ranges;if(n.addNew&&!n.extend?(h=u.sel.contains(r),c=h>-1?g[h]:new Ts(r,r)):(c=u.sel.primary(),h=u.sel.primIndex),"rectangle"==n.unit)n.addNew||(c=new Ts(r,r)),r=Sr(e,t,!0,!0),h=-1;else{var v=Fo(e,r,n.unit);c=n.extend?hi(c,v.anchor,v.head,n.extend):v}n.addNew?-1==h?(h=g.length,bi(u,zn(g.concat([c]),h),{scroll:!1,origin:"*mouse"})):g.length>1&&g[h].empty()&&"char"==n.unit&&!n.extend?(bi(u,zn(g.slice(0,h).concat(g.slice(h+1)),0),{scroll:!1,origin:"*mouse"}),p=u.sel):gi(u,h,c,Ul):(h=0,bi(u,new ks([c],0),Ul),p=u.sel);var m=r,y=a.wrapper.getBoundingClientRect(),b=0,w=dn(e,function(e){Pe(e)?o(e):s(e)}),x=dn(e,s);e.state.selectingText=x,Ql(document,"mousemove",w),Ql(document,"mouseup",x)}function Po(e,t){var r=t.anchor,n=t.head,i=M(e.doc,r.line);if(0==P(r,n)&&r.sticky==n.sticky)return t;var o=Se(i);if(!o)return t;var l=Ce(o,r.ch,r.sticky),s=o[l];if(s.from!=r.ch&&s.to!=r.ch)return t;var a=l+(s.from==r.ch==(1!=s.level)?0:1);if(0==a||a==o.length)return t;var u;if(n.line!=r.line)u=(n.line-r.line)*("ltr"==e.doc.direction?1:-1)>0;else{var c=Ce(o,n.ch,n.sticky),f=c-l||(n.ch-r.ch)*(1==s.level?-1:1);u=c==a-1||c==a?f<0:f>0}var h=o[a+(u?-1:0)],d=u==(1==h.level),p=d?h.from:h.to,g=d?"after":"before";return r.ch==p&&r.sticky==g?t:new Ts(new E(r.line,p,g),n)}function Io(e,t,r,n){var i,o;if(t.touches)i=t.touches[0].clientX,o=t.touches[0].clientY;else try{i=t.clientX,o=t.clientY}catch(t){return!1}if(i>=Math.floor(e.display.gutters.getBoundingClientRect().right))return!1;n&&We(t);var l=e.display,s=l.lineDiv.getBoundingClientRect();if(o>s.bottom||!Oe(e,r))return He(t);o-=s.top-l.viewOffset;for(var a=0;a<e.options.gutters.length;++a){var u=l.gutters.childNodes[a];if(u&&u.getBoundingClientRect().right>=i)return Te(e,r,e,D(e.doc,o),e.options.gutters[a],t),He(t)}}function zo(e,t){return Io(e,t,"gutterClick",!0)}function Ro(e,t){Ft(e.display,t)||Bo(e,t)||Me(e,t,"contextmenu")||e.display.input.onContextMenu(t)}function Bo(e,t){return!!Oe(e,"gutterContextMenu")&&Io(e,t,"gutterContextMenu",!1)}function Go(e){e.display.wrapper.className=e.display.wrapper.className.replace(/\s*cm-s-\S+/g,"")+e.options.theme.replace(/(^|\s)\s*/g," cm-s-"),er(e)}function Uo(e){Hn(e),vn(e),zr(e)}function Vo(e,t,r){if(!t!=!(r&&r!=Xs)){var n=e.display.dragFunctions,i=t?Ql:ke;i(e.display.scroller,"dragstart",n.start),i(e.display.scroller,"dragenter",n.enter),i(e.display.scroller,"dragover",n.over),i(e.display.scroller,"dragleave",n.leave),i(e.display.scroller,"drop",n.drop)}}function Ko(e){e.options.lineWrapping?(s(e.display.wrapper,"CodeMirror-wrap"),e.display.sizer.style.minWidth="",e.display.sizerWidth=null):(Fl(e.display.wrapper,"CodeMirror-wrap"),we(e)),Cr(e),vn(e),er(e),setTimeout(function(){return en(e)},100)}function jo(e,t){var r=this;if(!(this instanceof jo))return new jo(e,t);this.options=t=t?c(t):{},c(Ys,t,!1),Fn(t);var n=t.value;"string"==typeof n&&(n=new Ds(n,t.mode,null,t.lineSeparator,t.direction)),this.doc=n;var i=new jo.inputStyles[t.inputStyle](this),o=this.display=new T(e,n,i);o.wrapper.CodeMirror=this,Hn(this),Go(this),t.lineWrapping&&(this.display.wrapper.className+=" CodeMirror-wrap"),rn(this),this.state={keyMaps:[],overlays:[],modeGen:0,overwrite:!1,delayingBlurEvent:!1,focused:!1,suppressEdits:!1,pasteIncoming:!1,cutIncoming:!1,selectingText:!1,draggingText:!1,highlight:new Pl,keySeq:null,specialChars:null},t.autofocus&&!Tl&&o.input.focus(),gl&&vl<11&&setTimeout(function(){return r.display.input.reset(!0)},20),Xo(this),eo(),nn(this),this.curOp.forceUpdate=!0,qn(this,n),t.autofocus&&!Tl||this.hasFocus()?setTimeout(u(Hr,this),20):Fr(this);for(var l in _s)_s.hasOwnProperty(l)&&_s[l](r,t[l],Xs);Rr(this),t.finishInit&&t.finishInit(this);for(var s=0;s<$s.length;++s)$s[s](r);on(this),ml&&t.lineWrapping&&"optimizelegibility"==getComputedStyle(o.lineDiv).textRendering&&(o.lineDiv.style.textRendering="auto")}function Xo(e){function t(){i.activeTouch&&(o=setTimeout(function(){return i.activeTouch=null},1e3),(l=i.activeTouch).end=+new Date)}function r(e){if(1!=e.touches.length)return!1;var t=e.touches[0];return t.radiusX<=1&&t.radiusY<=1}function n(e,t){if(null==t.left)return!0;var r=t.left-e.left,n=t.top-e.top;return r*r+n*n>400}var i=e.display;Ql(i.scroller,"mousedown",dn(e,Oo)),gl&&vl<11?Ql(i.scroller,"dblclick",dn(e,function(t){if(!Me(e,t)){var r=Sr(e,t);if(r&&!zo(e,t)&&!Ft(e.display,t)){We(t);var n=e.findWordAt(r);di(e.doc,n.anchor,n.head)}}})):Ql(i.scroller,"dblclick",function(t){return Me(e,t)||We(t)}),Hl||Ql(i.scroller,"contextmenu",function(t){return Ro(e,t)});var o,l={end:0};Ql(i.scroller,"touchstart",function(t){if(!Me(e,t)&&!r(t)&&!zo(e,t)){i.input.ensurePolled(),clearTimeout(o);var n=+new Date;i.activeTouch={start:n,moved:!1,prev:n-l.end<=300?l:null},1==t.touches.length&&(i.activeTouch.left=t.touches[0].pageX,i.activeTouch.top=t.touches[0].pageY)}}),Ql(i.scroller,"touchmove",function(){i.activeTouch&&(i.activeTouch.moved=!0)}),Ql(i.scroller,"touchend",function(r){var o=i.activeTouch;if(o&&!Ft(i,r)&&null!=o.left&&!o.moved&&new Date-o.start<300){var l,s=e.coordsChar(i.activeTouch,"page");l=!o.prev||n(o,o.prev)?new Ts(s,s):!o.prev.prev||n(o,o.prev.prev)?e.findWordAt(s):new Ts(E(s.line,0),U(e.doc,E(s.line+1,0))),e.setSelection(l.anchor,l.head),e.focus(),We(r)}t()}),Ql(i.scroller,"touchcancel",t),Ql(i.scroller,"scroll",function(){i.scroller.clientHeight&&(qr(e,i.scroller.scrollTop),Qr(e,i.scroller.scrollLeft,!0),Te(e,"scroll",e))}),Ql(i.scroller,"mousewheel",function(t){return In(e,t)}),Ql(i.scroller,"DOMMouseScroll",function(t){return In(e,t)}),Ql(i.wrapper,"scroll",function(){return i.wrapper.scrollTop=i.wrapper.scrollLeft=0}),i.dragFunctions={enter:function(t){Me(e,t)||Fe(t)},over:function(t){Me(e,t)||(Zi(e,t),Fe(t))},start:function(t){return qi(e,t)},drop:dn(e,$i),leave:function(t){Me(e,t)||Qi(e)}};var s=i.input.getField();Ql(s,"keyup",function(t){return To.call(e,t)}),Ql(s,"keydown",dn(e,Lo)),Ql(s,"keypress",dn(e,Mo)),Ql(s,"focus",function(t){return Hr(e,t)}),Ql(s,"blur",function(t){return Fr(e,t)})}function Yo(e,t,r,n){var i,o=e.doc;null==r&&(r="add"),"smart"==r&&(o.mode.indent?i=$e(e,t).state:r="prev");var l=e.options.tabSize,s=M(o,t),a=f(s.text,null,l);s.stateAfter&&(s.stateAfter=null);var u,c=s.text.match(/^\s*/)[0];if(n||/\S/.test(s.text)){if("smart"==r&&((u=o.mode.indent(i,s.text.slice(c.length),s.text))==Bl||u>150)){if(!n)return;r="prev"}}else u=0,r="not";"prev"==r?u=t>o.first?f(M(o,t-1).text,null,l):0:"add"==r?u=a+e.options.indentUnit:"subtract"==r?u=a-e.options.indentUnit:"number"==typeof r&&(u=a+r),u=Math.max(0,u);var h="",d=0;if(e.options.indentWithTabs)for(var g=Math.floor(u/l);g;--g)d+=l,h+="\t";if(d<u&&(h+=p(u-d)),h!=c)return Ei(o,h,E(t,0),E(t,c.length),"+input"),s.stateAfter=null,!0;for(var v=0;v<o.sel.ranges.length;v++){var m=o.sel.ranges[v];if(m.head.line==t&&m.head.ch<c.length){var y=E(t,c.length);gi(o,v,new Ts(y,y));break}}}function _o(e){qs=e}function $o(e,t,r,n,i){var o=e.doc;e.display.shift=!1,n||(n=o.sel);var l=e.state.pasteIncoming||"paste"==i,s=es(t),a=null;if(l&&n.ranges.length>1)if(qs&&qs.text.join("\n")==t){if(n.ranges.length%qs.text.length==0){a=[];for(var u=0;u<qs.text.length;u++)a.push(o.splitLines(qs.text[u]))}}else s.length==n.ranges.length&&e.options.pasteLinesPerSelection&&(a=v(s,function(e){return[e]}));for(var c,f=n.ranges.length-1;f>=0;f--){var h=n.ranges[f],d=h.from(),p=h.to();h.empty()&&(r&&r>0?d=E(d.line,d.ch-r):e.state.overwrite&&!l?p=E(p.line,Math.min(M(o,p.line).text.length,p.ch+g(s).length)):qs&&qs.lineWise&&qs.text.join("\n")==t&&(d=p=E(d.line,0))),c=e.curOp.updateInput;var m={from:d,to:p,text:a?a[f%a.length]:s,origin:i||(l?"paste":e.state.cutIncoming?"cut":"+input")};Oi(e.doc,m),bt(e,"inputRead",e,m)}t&&!l&&Zo(e,t),jr(e),e.curOp.updateInput=c,e.curOp.typing=!0,e.state.pasteIncoming=e.state.cutIncoming=!1}function qo(e,t){var r=e.clipboardData&&e.clipboardData.getData("Text");if(r)return e.preventDefault(),t.isReadOnly()||t.options.disableInput||hn(t,function(){return $o(t,r,0,null,"paste")}),!0}function Zo(e,t){if(e.options.electricChars&&e.options.smartIndent)for(var r=e.doc.sel,n=r.ranges.length-1;n>=0;n--){var i=r.ranges[n];if(!(i.head.ch>100||n&&r.ranges[n-1].head.line==i.head.line)){var o=e.getModeAt(i.head),l=!1;if(o.electricChars){for(var s=0;s<o.electricChars.length;s++)if(t.indexOf(o.electricChars.charAt(s))>-1){l=Yo(e,i.head.line,"smart");break}}else o.electricInput&&o.electricInput.test(M(e.doc,i.head.line).text.slice(0,i.head.ch))&&(l=Yo(e,i.head.line,"smart"));l&&bt(e,"electricInput",e,i.head.line)}}}function Qo(e){for(var t=[],r=[],n=0;n<e.doc.sel.ranges.length;n++){var i=e.doc.sel.ranges[n].head.line,o={anchor:E(i,0),head:E(i+1,0)};r.push(o),t.push(e.getRange(o.anchor,o.head))}return{text:t,ranges:r}}function Jo(e,t){e.setAttribute("autocorrect","off"),e.setAttribute("autocapitalize","off"),e.setAttribute("spellcheck",!!t)}function el(){var e=n("textarea",null,null,"position: absolute; bottom: -1em; padding: 0; width: 1px; height: 1em; outline: none"),t=n("div",[e],null,"overflow: hidden; position: relative; width: 3px; height: 0px;");return ml?e.style.width="1000px":e.setAttribute("wrap","off"),Ll&&(e.style.border="1px solid black"),Jo(e),t}function tl(e,t,r,n,i){function o(){var n=t.line+r;return!(n<e.first||n>=e.first+e.size)&&(t=new E(n,t.ch,t.sticky),u=M(e,n))}function l(n){var l;if(null==(l=i?go(e.cm,u,t,r):ho(u,t,r))){if(n||!o())return!1;t=po(i,e.cm,u,t.line,r)}else t=l;return!0}var s=t,a=r,u=M(e,t.line);if("char"==n)l();else if("column"==n)l(!0);else if("word"==n||"group"==n)for(var c=null,f="group"==n,h=e.cm&&e.cm.getHelper(t,"wordChars"),d=!0;!(r<0)||l(!d);d=!1){var p=u.text.charAt(t.ch)||"\n",g=x(p,h)?"w":f&&"\n"==p?"n":!f||/\s/.test(p)?null:"p";if(!f||d||g||(g="s"),c&&c!=g){r<0&&(r=1,l(),t.sticky="after");break}if(g&&(c=g),r>0&&!l(!d))break}var v=ki(e,t,s,a,!0);return I(s,v)&&(v.hitSide=!0),v}function rl(e,t,r,n){var i,o=e.doc,l=t.left;if("page"==n){var s=Math.min(e.display.wrapper.clientHeight,window.innerHeight||document.documentElement.clientHeight),a=Math.max(s-.5*mr(e.display),3);i=(r>0?t.bottom:t.top)+r*a}else"line"==n&&(i=r>0?t.bottom+3:t.top-3);for(var u;(u=cr(e,l,i)).outside;){if(r<0?i<=0:i>=o.height){u.hitSide=!0;break}i+=5*r}return u}function nl(e,t){var r=jt(e,t.line);if(!r||r.hidden)return null;var n=M(e.doc,t.line),i=Ut(r,n,t.line),o=Se(n,e.doc.direction),l="left";o&&(l=Ce(o,t.ch)%2?"right":"left");var s=_t(i.map,t.ch,l);return s.offset="right"==s.collapse?s.end:s.start,s}function il(e){for(var t=e;t;t=t.parentNode)if(/CodeMirror-gutter-wrapper/.test(t.className))return!0;return!1}function ol(e,t){return t&&(e.bad=!0),e}function ll(e,t,r,n,i){function o(e){return function(t){return t.id==e}}function l(){c&&(u+=f,c=!1)}function s(e){e&&(l(),u+=e)}function a(t){if(1==t.nodeType){var r=t.getAttribute("cm-text");if(null!=r)return void s(r||t.textContent.replace(/\u200b/g,""));var u,h=t.getAttribute("cm-marker");if(h){var d=e.findMarks(E(n,0),E(i+1,0),o(+h));return void(d.length&&(u=d[0].find(0))&&s(N(e.doc,u.from,u.to).join(f)))}if("false"==t.getAttribute("contenteditable"))return;var p=/^(pre|div|p)$/i.test(t.nodeName);p&&l();for(var g=0;g<t.childNodes.length;g++)a(t.childNodes[g]);p&&(c=!0)}else 3==t.nodeType&&s(t.nodeValue)}for(var u="",c=!1,f=e.doc.lineSeparator();a(t),t!=r;)t=t.nextSibling;return u}function sl(e,t,r){var n;if(t==e.display.lineDiv){if(!(n=e.display.lineDiv.childNodes[r]))return ol(e.clipPos(E(e.display.viewTo-1)),!0);t=null,r=0}else for(n=t;;n=n.parentNode){if(!n||n==e.display.lineDiv)return null;if(n.parentNode&&n.parentNode==e.display.lineDiv)break}for(var i=0;i<e.display.view.length;i++){var o=e.display.view[i];if(o.node==n)return al(o,t,r)}}function al(e,t,r){function n(t,r,n){for(var i=-1;i<(f?f.length:0);i++)for(var o=i<0?c.map:f[i],l=0;l<o.length;l+=3){var s=o[l+2];if(s==t||s==r){var a=W(i<0?e.line:e.rest[i]),u=o[l]+n;return(n<0||s!=t)&&(u=o[l+(n?1:0)]),E(a,u)}}}var i=e.text.firstChild,l=!1;if(!t||!o(i,t))return ol(E(W(e.line),0),!0);if(t==i&&(l=!0,t=i.childNodes[r],r=0,!t)){var s=e.rest?g(e.rest):e.line;return ol(E(W(s),s.text.length),l)}var a=3==t.nodeType?t:null,u=t;for(a||1!=t.childNodes.length||3!=t.firstChild.nodeType||(a=t.firstChild,r&&(r=a.nodeValue.length));u.parentNode!=i;)u=u.parentNode;var c=e.measure,f=c.maps,h=n(a,u,r);if(h)return ol(h,l);for(var d=u.nextSibling,p=a?a.nodeValue.length-r:0;d;d=d.nextSibling){if(h=n(d,d.firstChild,0))return ol(E(h.line,h.ch-p),l);p+=d.textContent.length}for(var v=u.previousSibling,m=r;v;v=v.previousSibling){if(h=n(v,v.firstChild,-1))return ol(E(h.line,h.ch+m),l);m+=v.textContent.length}}var ul=navigator.userAgent,cl=navigator.platform,fl=/gecko\/\d/i.test(ul),hl=/MSIE \d/.test(ul),dl=/Trident\/(?:[7-9]|\d{2,})\..*rv:(\d+)/.exec(ul),pl=/Edge\/(\d+)/.exec(ul),gl=hl||dl||pl,vl=gl&&(hl?document.documentMode||6:+(pl||dl)[1]),ml=!pl&&/WebKit\//.test(ul),yl=ml&&/Qt\/\d+\.\d+/.test(ul),bl=!pl&&/Chrome\//.test(ul),wl=/Opera\//.test(ul),xl=/Apple Computer/.test(navigator.vendor),Cl=/Mac OS X 1\d\D([8-9]|\d\d)\D/.test(ul),Sl=/PhantomJS/.test(ul),Ll=!pl&&/AppleWebKit/.test(ul)&&/Mobile\/\w+/.test(ul),kl=/Android/.test(ul),Tl=Ll||kl||/webOS|BlackBerry|Opera Mini|Opera Mobi|IEMobile/i.test(ul),Ml=Ll||/Mac/.test(cl),Nl=/\bCrOS\b/.test(ul),Ol=/win/i.test(cl),Al=wl&&ul.match(/Version\/(\d*\.\d*)/);Al&&(Al=Number(Al[1])),Al&&Al>=15&&(wl=!1,ml=!0);var Wl,Dl=Ml&&(yl||wl&&(null==Al||Al<12.11)),Hl=fl||gl&&vl>=9,Fl=function(t,r){var n=t.className,i=e(r).exec(n);if(i){var o=n.slice(i.index+i[0].length);t.className=n.slice(0,i.index)+(o?i[1]+o:"")}};Wl=document.createRange?function(e,t,r,n){var i=document.createRange();return i.setEnd(n||e,r),i.setStart(e,t),i}:function(e,t,r){var n=document.body.createTextRange();try{n.moveToElementText(e.parentNode)}catch(e){return n}return n.collapse(!0),n.moveEnd("character",r),n.moveStart("character",t),n};var El=function(e){e.select()};Ll?El=function(e){e.selectionStart=0,e.selectionEnd=e.value.length}:gl&&(El=function(e){try{e.select()}catch(e){}});var Pl=function(){this.id=null};Pl.prototype.set=function(e,t){clearTimeout(this.id),this.id=setTimeout(t,e)};var Il,zl,Rl=30,Bl={toString:function(){return"CodeMirror.Pass"}},Gl={scroll:!1},Ul={origin:"*mouse"},Vl={origin:"+move"},Kl=[""],jl=/[\u00df\u0587\u0590-\u05f4\u0600-\u06ff\u3040-\u309f\u30a0-\u30ff\u3400-\u4db5\u4e00-\u9fcc\uac00-\ud7af]/,Xl=/[\u0300-\u036f\u0483-\u0489\u0591-\u05bd\u05bf\u05c1\u05c2\u05c4\u05c5\u05c7\u0610-\u061a\u064b-\u065e\u0670\u06d6-\u06dc\u06de-\u06e4\u06e7\u06e8\u06ea-\u06ed\u0711\u0730-\u074a\u07a6-\u07b0\u07eb-\u07f3\u0816-\u0819\u081b-\u0823\u0825-\u0827\u0829-\u082d\u0900-\u0902\u093c\u0941-\u0948\u094d\u0951-\u0955\u0962\u0963\u0981\u09bc\u09be\u09c1-\u09c4\u09cd\u09d7\u09e2\u09e3\u0a01\u0a02\u0a3c\u0a41\u0a42\u0a47\u0a48\u0a4b-\u0a4d\u0a51\u0a70\u0a71\u0a75\u0a81\u0a82\u0abc\u0ac1-\u0ac5\u0ac7\u0ac8\u0acd\u0ae2\u0ae3\u0b01\u0b3c\u0b3e\u0b3f\u0b41-\u0b44\u0b4d\u0b56\u0b57\u0b62\u0b63\u0b82\u0bbe\u0bc0\u0bcd\u0bd7\u0c3e-\u0c40\u0c46-\u0c48\u0c4a-\u0c4d\u0c55\u0c56\u0c62\u0c63\u0cbc\u0cbf\u0cc2\u0cc6\u0ccc\u0ccd\u0cd5\u0cd6\u0ce2\u0ce3\u0d3e\u0d41-\u0d44\u0d4d\u0d57\u0d62\u0d63\u0dca\u0dcf\u0dd2-\u0dd4\u0dd6\u0ddf\u0e31\u0e34-\u0e3a\u0e47-\u0e4e\u0eb1\u0eb4-\u0eb9\u0ebb\u0ebc\u0ec8-\u0ecd\u0f18\u0f19\u0f35\u0f37\u0f39\u0f71-\u0f7e\u0f80-\u0f84\u0f86\u0f87\u0f90-\u0f97\u0f99-\u0fbc\u0fc6\u102d-\u1030\u1032-\u1037\u1039\u103a\u103d\u103e\u1058\u1059\u105e-\u1060\u1071-\u1074\u1082\u1085\u1086\u108d\u109d\u135f\u1712-\u1714\u1732-\u1734\u1752\u1753\u1772\u1773\u17b7-\u17bd\u17c6\u17c9-\u17d3\u17dd\u180b-\u180d\u18a9\u1920-\u1922\u1927\u1928\u1932\u1939-\u193b\u1a17\u1a18\u1a56\u1a58-\u1a5e\u1a60\u1a62\u1a65-\u1a6c\u1a73-\u1a7c\u1a7f\u1b00-\u1b03\u1b34\u1b36-\u1b3a\u1b3c\u1b42\u1b6b-\u1b73\u1b80\u1b81\u1ba2-\u1ba5\u1ba8\u1ba9\u1c2c-\u1c33\u1c36\u1c37\u1cd0-\u1cd2\u1cd4-\u1ce0\u1ce2-\u1ce8\u1ced\u1dc0-\u1de6\u1dfd-\u1dff\u200c\u200d\u20d0-\u20f0\u2cef-\u2cf1\u2de0-\u2dff\u302a-\u302f\u3099\u309a\ua66f-\ua672\ua67c\ua67d\ua6f0\ua6f1\ua802\ua806\ua80b\ua825\ua826\ua8c4\ua8e0-\ua8f1\ua926-\ua92d\ua947-\ua951\ua980-\ua982\ua9b3\ua9b6-\ua9b9\ua9bc\uaa29-\uaa2e\uaa31\uaa32\uaa35\uaa36\uaa43\uaa4c\uaab0\uaab2-\uaab4\uaab7\uaab8\uaabe\uaabf\uaac1\uabe5\uabe8\uabed\udc00-\udfff\ufb1e\ufe00-\ufe0f\ufe20-\ufe26\uff9e\uff9f]/,Yl=!1,_l=!1,$l=null,ql=function(){function e(e){return e<=247?r.charAt(e):1424<=e&&e<=1524?"R":1536<=e&&e<=1785?n.charAt(e-1536):1774<=e&&e<=2220?"r":8192<=e&&e<=8203?"w":8204==e?"b":"L"}function t(e,t,r){this.level=e,this.from=t,this.to=r}var r="bbbbbbbbbtstwsbbbbbbbbbbbbbbssstwNN%%%NNNNNN,N,N1111111111NNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNbbbbbbsbbbbbbbbbbbbbbbbbbbbbbbbbb,N%%%%NNNNLNNNNN%%11NLNNN1LNNNNNLLLLLLLLLLLLLLLLLLLLLLLNLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLN",n="nnnnnnNNr%%r,rNNmmmmmmmmmmmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmmmmmmmmmmmmmmmnnnnnnnnnn%nnrrrmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmnNmmmmmmrrmmNmmmmrr1111111111",i=/[\u0590-\u05f4\u0600-\u06ff\u0700-\u08ac]/,o=/[stwN]/,l=/[LRr]/,s=/[Lb1n]/,a=/[1n]/;return function(r,n){var u="ltr"==n?"L":"R";if(0==r.length||"ltr"==n&&!i.test(r))return!1;for(var c=r.length,f=[],h=0;h<c;++h)f.push(e(r.charCodeAt(h)));for(var d=0,p=u;d<c;++d){var v=f[d];"m"==v?f[d]=p:p=v}for(var m=0,y=u;m<c;++m){var b=f[m];"1"==b&&"r"==y?f[m]="n":l.test(b)&&(y=b,"r"==b&&(f[m]="R"))}for(var w=1,x=f[0];w<c-1;++w){var C=f[w];"+"==C&&"1"==x&&"1"==f[w+1]?f[w]="1":","!=C||x!=f[w+1]||"1"!=x&&"n"!=x||(f[w]=x),x=C}for(var S=0;S<c;++S){var L=f[S];if(","==L)f[S]="N";else if("%"==L){var k=void 0;for(k=S+1;k<c&&"%"==f[k];++k);for(var T=S&&"!"==f[S-1]||k<c&&"1"==f[k]?"1":"N",M=S;M<k;++M)f[M]=T;S=k-1}}for(var N=0,O=u;N<c;++N){var A=f[N];"L"==O&&"1"==A?f[N]="L":l.test(A)&&(O=A)}for(var W=0;W<c;++W)if(o.test(f[W])){var D=void 0;for(D=W+1;D<c&&o.test(f[D]);++D);for(var H="L"==(W?f[W-1]:u),F=H==("L"==(D<c?f[D]:u))?H?"L":"R":u,E=W;E<D;++E)f[E]=F;W=D-1}for(var P,I=[],z=0;z<c;)if(s.test(f[z])){var R=z;for(++z;z<c&&s.test(f[z]);++z);I.push(new t(0,R,z))}else{var B=z,G=I.length;for(++z;z<c&&"L"!=f[z];++z);for(var U=B;U<z;)if(a.test(f[U])){B<U&&I.splice(G,0,new t(1,B,U));var V=U;for(++U;U<z&&a.test(f[U]);++U);I.splice(G,0,new t(2,V,U)),B=U}else++U;B<z&&I.splice(G,0,new t(1,B,z))}return 1==I[0].level&&(P=r.match(/^\s+/))&&(I[0].from=P[0].length,I.unshift(new t(0,0,P[0].length))),1==g(I).level&&(P=r.match(/\s+$/))&&(g(I).to-=P[0].length,I.push(new t(0,c-P[0].length,c))),"rtl"==n?I.reverse():I}}(),Zl=[],Ql=function(e,t,r){if(e.addEventListener)e.addEventListener(t,r,!1);else if(e.attachEvent)e.attachEvent("on"+t,r);else{var n=e._handlers||(e._handlers={});n[t]=(n[t]||Zl).concat(r)}},Jl=function(){if(gl&&vl<9)return!1;var e=n("div");return"draggable"in e||"dragDrop"in e}(),es=3!="\n\nb".split(/\n/).length?function(e){for(var t=0,r=[],n=e.length;t<=n;){var i=e.indexOf("\n",t);-1==i&&(i=e.length);var o=e.slice(t,"\r"==e.charAt(i-1)?i-1:i),l=o.indexOf("\r");-1!=l?(r.push(o.slice(0,l)),t+=l+1):(r.push(o),t=i+1)}return r}:function(e){return e.split(/\r\n?|\n/)},ts=window.getSelection?function(e){try{return e.selectionStart!=e.selectionEnd}catch(e){return!1}}:function(e){var t;try{t=e.ownerDocument.selection.createRange()}catch(e){}return!(!t||t.parentElement()!=e)&&0!=t.compareEndPoints("StartToEnd",t)},rs=function(){var e=n("div");return"oncopy"in e||(e.setAttribute("oncopy","return;"),"function"==typeof e.oncopy)}(),ns=null,is={},os={},ls={},ss=function(e,t,r){this.pos=this.start=0,this.string=e,this.tabSize=t||8,this.lastColumnPos=this.lastColumnValue=0,this.lineStart=0,this.lineOracle=r};ss.prototype.eol=function(){return this.pos>=this.string.length},ss.prototype.sol=function(){return this.pos==this.lineStart},ss.prototype.peek=function(){return this.string.charAt(this.pos)||void 0},ss.prototype.next=function(){if(this.pos<this.string.length)return this.string.charAt(this.pos++)},ss.prototype.eat=function(e){var t=this.string.charAt(this.pos);if("string"==typeof e?t==e:t&&(e.test?e.test(t):e(t)))return++this.pos,t},ss.prototype.eatWhile=function(e){for(var t=this.pos;this.eat(e););return this.pos>t},ss.prototype.eatSpace=function(){for(var e=this,t=this.pos;/[\s\u00a0]/.test(this.string.charAt(this.pos));)++e.pos;return this.pos>t},ss.prototype.skipToEnd=function(){this.pos=this.string.length},ss.prototype.skipTo=function(e){var t=this.string.indexOf(e,this.pos);if(t>-1)return this.pos=t,!0},ss.prototype.backUp=function(e){this.pos-=e},ss.prototype.column=function(){return this.lastColumnPos<this.start&&(this.lastColumnValue=f(this.string,this.start,this.tabSize,this.lastColumnPos,this.lastColumnValue),this.lastColumnPos=this.start),this.lastColumnValue-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.indentation=function(){return f(this.string,null,this.tabSize)-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.match=function(e,t,r){if("string"!=typeof e){var n=this.string.slice(this.pos).match(e);return n&&n.index>0?null:(n&&!1!==t&&(this.pos+=n[0].length),n)}var i=function(e){return r?e.toLowerCase():e};if(i(this.string.substr(this.pos,e.length))==i(e))return!1!==t&&(this.pos+=e.length),!0},ss.prototype.current=function(){return this.string.slice(this.start,this.pos)},ss.prototype.hideFirstChars=function(e,t){this.lineStart+=e;try{return t()}finally{this.lineStart-=e}},ss.prototype.lookAhead=function(e){var t=this.lineOracle;return t&&t.lookAhead(e)};var as=function(e,t){this.state=e,this.lookAhead=t},us=function(e,t,r,n){this.state=t,this.doc=e,this.line=r,this.maxLookAhead=n||0};us.prototype.lookAhead=function(e){var t=this.doc.getLine(this.line+e);return null!=t&&e>this.maxLookAhead&&(this.maxLookAhead=e),t},us.prototype.nextLine=function(){this.line++,this.maxLookAhead>0&&this.maxLookAhead--},us.fromSaved=function(e,t,r){return t instanceof as?new us(e,Ke(e.mode,t.state),r,t.lookAhead):new us(e,Ke(e.mode,t),r)},us.prototype.save=function(e){var t=!1!==e?Ke(this.doc.mode,this.state):this.state;return this.maxLookAhead>0?new as(t,this.maxLookAhead):t};var cs=function(e,t,r){this.start=e.start,this.end=e.pos,this.string=e.current(),this.type=t||null,this.state=r},fs=function(e,t,r){this.text=e,ne(this,t),this.height=r?r(this):1};fs.prototype.lineNo=function(){return W(this)},Ae(fs);var hs,ds={},ps={},gs=null,vs=null,ms={left:0,right:0,top:0,bottom:0},ys=function(e,t,r){this.cm=r;var i=this.vert=n("div",[n("div",null,null,"min-width: 1px")],"CodeMirror-vscrollbar"),o=this.horiz=n("div",[n("div",null,null,"height: 100%; min-height: 1px")],"CodeMirror-hscrollbar");e(i),e(o),Ql(i,"scroll",function(){i.clientHeight&&t(i.scrollTop,"vertical")}),Ql(o,"scroll",function(){o.clientWidth&&t(o.scrollLeft,"horizontal")}),this.checkedZeroWidth=!1,gl&&vl<8&&(this.horiz.style.minHeight=this.vert.style.minWidth="18px")};ys.prototype.update=function(e){var t=e.scrollWidth>e.clientWidth+1,r=e.scrollHeight>e.clientHeight+1,n=e.nativeBarWidth;if(r){this.vert.style.display="block",this.vert.style.bottom=t?n+"px":"0";var i=e.viewHeight-(t?n:0);this.vert.firstChild.style.height=Math.max(0,e.scrollHeight-e.clientHeight+i)+"px"}else this.vert.style.display="",this.vert.firstChild.style.height="0";if(t){this.horiz.style.display="block",this.horiz.style.right=r?n+"px":"0",this.horiz.style.left=e.barLeft+"px";var o=e.viewWidth-e.barLeft-(r?n:0);this.horiz.firstChild.style.width=Math.max(0,e.scrollWidth-e.clientWidth+o)+"px"}else this.horiz.style.display="",this.horiz.firstChild.style.width="0";return!this.checkedZeroWidth&&e.clientHeight>0&&(0==n&&this.zeroWidthHack(),this.checkedZeroWidth=!0),{right:r?n:0,bottom:t?n:0}},ys.prototype.setScrollLeft=function(e){this.horiz.scrollLeft!=e&&(this.horiz.scrollLeft=e),this.disableHoriz&&this.enableZeroWidthBar(this.horiz,this.disableHoriz,"horiz")},ys.prototype.setScrollTop=function(e){this.vert.scrollTop!=e&&(this.vert.scrollTop=e),this.disableVert&&this.enableZeroWidthBar(this.vert,this.disableVert,"vert")},ys.prototype.zeroWidthHack=function(){var e=Ml&&!Cl?"12px":"18px";this.horiz.style.height=this.vert.style.width=e,this.horiz.style.pointerEvents=this.vert.style.pointerEvents="none",this.disableHoriz=new Pl,this.disableVert=new Pl},ys.prototype.enableZeroWidthBar=function(e,t,r){function n(){var i=e.getBoundingClientRect();("vert"==r?document.elementFromPoint(i.right-1,(i.top+i.bottom)/2):document.elementFromPoint((i.right+i.left)/2,i.bottom-1))!=e?e.style.pointerEvents="none":t.set(1e3,n)}e.style.pointerEvents="auto",t.set(1e3,n)},ys.prototype.clear=function(){var e=this.horiz.parentNode;e.removeChild(this.horiz),e.removeChild(this.vert)};var bs=function(){};bs.prototype.update=function(){return{bottom:0,right:0}},bs.prototype.setScrollLeft=function(){},bs.prototype.setScrollTop=function(){},bs.prototype.clear=function(){};var ws={native:ys,null:bs},xs=0,Cs=function(e,t,r){var n=e.display;this.viewport=t,this.visible=Ir(n,e.doc,t),this.editorIsHidden=!n.wrapper.offsetWidth,this.wrapperHeight=n.wrapper.clientHeight,this.wrapperWidth=n.wrapper.clientWidth,this.oldDisplayWidth=Rt(e),this.force=r,this.dims=br(e),this.events=[]};Cs.prototype.signal=function(e,t){Oe(e,t)&&this.events.push(arguments)},Cs.prototype.finish=function(){for(var e=this,t=0;t<this.events.length;t++)Te.apply(null,e.events[t])};var Ss=0,Ls=null;gl?Ls=-.53:fl?Ls=15:bl?Ls=-.7:xl&&(Ls=-1/3);var ks=function(e,t){this.ranges=e,this.primIndex=t};ks.prototype.primary=function(){return this.ranges[this.primIndex]},ks.prototype.equals=function(e){var t=this;if(e==this)return!0;if(e.primIndex!=this.primIndex||e.ranges.length!=this.ranges.length)return!1;for(var r=0;r<this.ranges.length;r++){var n=t.ranges[r],i=e.ranges[r];if(!I(n.anchor,i.anchor)||!I(n.head,i.head))return!1}return!0},ks.prototype.deepCopy=function(){for(var e=this,t=[],r=0;r<this.ranges.length;r++)t[r]=new Ts(z(e.ranges[r].anchor),z(e.ranges[r].head));return new ks(t,this.primIndex)},ks.prototype.somethingSelected=function(){for(var e=this,t=0;t<this.ranges.length;t++)if(!e.ranges[t].empty())return!0;return!1},ks.prototype.contains=function(e,t){var r=this;t||(t=e);for(var n=0;n<this.ranges.length;n++){var i=r.ranges[n];if(P(t,i.from())>=0&&P(e,i.to())<=0)return n}return-1};var Ts=function(e,t){this.anchor=e,this.head=t};Ts.prototype.from=function(){return B(this.anchor,this.head)},Ts.prototype.to=function(){return R(this.anchor,this.head)},Ts.prototype.empty=function(){return this.head.line==this.anchor.line&&this.head.ch==this.anchor.ch},Bi.prototype={chunkSize:function(){return this.lines.length},removeInner:function(e,t){for(var r=this,n=e,i=e+t;n<i;++n){var o=r.lines[n];r.height-=o.height,ot(o),bt(o,"delete")}this.lines.splice(e,t)},collapse:function(e){e.push.apply(e,this.lines)},insertInner:function(e,t,r){var n=this;this.height+=r,this.lines=this.lines.slice(0,e).concat(t).concat(this.lines.slice(e));for(var i=0;i<t.length;++i)t[i].parent=n},iterN:function(e,t,r){for(var n=this,i=e+t;e<i;++e)if(r(n.lines[e]))return!0}},Gi.prototype={chunkSize:function(){return this.size},removeInner:function(e,t){var r=this;this.size-=t;for(var n=0;n<this.children.length;++n){var i=r.children[n],o=i.chunkSize();if(e<o){var l=Math.min(t,o-e),s=i.height;if(i.removeInner(e,l),r.height-=s-i.height,o==l&&(r.children.splice(n--,1),i.parent=null),0==(t-=l))break;e=0}else e-=o}if(this.size-t<25&&(this.children.length>1||!(this.children[0]instanceof Bi))){var a=[];this.collapse(a),this.children=[new Bi(a)],this.children[0].parent=this}},collapse:function(e){for(var t=this,r=0;r<this.children.length;++r)t.children[r].collapse(e)},insertInner:function(e,t,r){var n=this;this.size+=t.length,this.height+=r;for(var i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<=l){if(o.insertInner(e,t,r),o.lines&&o.lines.length>50){for(var s=o.lines.length%25+25,a=s;a<o.lines.length;){var u=new Bi(o.lines.slice(a,a+=25));o.height-=u.height,n.children.splice(++i,0,u),u.parent=n}o.lines=o.lines.slice(0,s),n.maybeSpill()}break}e-=l}},maybeSpill:function(){if(!(this.children.length<=10)){var e=this;do{var t=new Gi(e.children.splice(e.children.length-5,5));if(e.parent){e.size-=t.size,e.height-=t.height;var r=h(e.parent.children,e);e.parent.children.splice(r+1,0,t)}else{var n=new Gi(e.children);n.parent=e,e.children=[n,t],e=n}t.parent=e.parent}while(e.children.length>10);e.parent.maybeSpill()}},iterN:function(e,t,r){for(var n=this,i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<l){var s=Math.min(t,l-e);if(o.iterN(e,s,r))return!0;if(0==(t-=s))break;e=0}else e-=l}}};var Ms=function(e,t,r){var n=this;if(r)for(var i in r)r.hasOwnProperty(i)&&(n[i]=r[i]);this.doc=e,this.node=t};Ms.prototype.clear=function(){var e=this,t=this.doc.cm,r=this.line.widgets,n=this.line,i=W(n);if(null!=i&&r){for(var o=0;o<r.length;++o)r[o]==e&&r.splice(o--,1);r.length||(n.widgets=null);var l=Ht(this);A(n,Math.max(0,n.height-l)),t&&(hn(t,function(){Ui(t,n,-l),mn(t,i,"widget")}),bt(t,"lineWidgetCleared",t,this,i))}},Ms.prototype.changed=function(){var e=this,t=this.height,r=this.doc.cm,n=this.line;this.height=null;var i=Ht(this)-t;i&&(A(n,n.height+i),r&&hn(r,function(){r.curOp.forceUpdate=!0,Ui(r,n,i),bt(r,"lineWidgetChanged",r,e,W(n))}))},Ae(Ms);var Ns=0,Os=function(e,t){this.lines=[],this.type=t,this.doc=e,this.id=++Ns};Os.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){var t=this.doc.cm,r=t&&!t.curOp;if(r&&nn(t),Oe(this,"clear")){var n=this.find();n&&bt(this,"clear",n.from,n.to)}for(var i=null,o=null,l=0;l<this.lines.length;++l){var s=e.lines[l],a=_(s.markedSpans,e);t&&!e.collapsed?mn(t,W(s),"text"):t&&(null!=a.to&&(o=W(s)),null!=a.from&&(i=W(s))),s.markedSpans=$(s.markedSpans,a),null==a.from&&e.collapsed&&!ve(e.doc,s)&&t&&A(s,mr(t.display))}if(t&&this.collapsed&&!t.options.lineWrapping)for(var u=0;u<this.lines.length;++u){var c=fe(e.lines[u]),f=be(c);f>t.display.maxLineLength&&(t.display.maxLine=c,t.display.maxLineLength=f,t.display.maxLineChanged=!0)}null!=i&&t&&this.collapsed&&vn(t,i,o+1),this.lines.length=0,this.explicitlyCleared=!0,this.atomic&&this.doc.cantEdit&&(this.doc.cantEdit=!1,t&&Ci(t.doc)),t&&bt(t,"markerCleared",t,this,i,o),r&&on(t),this.parent&&this.parent.clear()}},Os.prototype.find=function(e,t){var r=this;null==e&&"bookmark"==this.type&&(e=1);for(var n,i,o=0;o<this.lines.length;++o){var l=r.lines[o],s=_(l.markedSpans,r);if(null!=s.from&&(n=E(t?l:W(l),s.from),-1==e))return n;if(null!=s.to&&(i=E(t?l:W(l),s.to),1==e))return i}return n&&{from:n,to:i}},Os.prototype.changed=function(){var e=this,t=this.find(-1,!0),r=this,n=this.doc.cm;t&&n&&hn(n,function(){var i=t.line,o=W(t.line),l=jt(n,o);if(l&&(Qt(l),n.curOp.selectionChanged=n.curOp.forceUpdate=!0),n.curOp.updateMaxLine=!0,!ve(r.doc,i)&&null!=r.height){var s=r.height;r.height=null;var a=Ht(r)-s;a&&A(i,i.height+a)}bt(n,"markerChanged",n,e)})},Os.prototype.attachLine=function(e){if(!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;t.maybeHiddenMarkers&&-1!=h(t.maybeHiddenMarkers,this)||(t.maybeUnhiddenMarkers||(t.maybeUnhiddenMarkers=[])).push(this)}this.lines.push(e)},Os.prototype.detachLine=function(e){if(this.lines.splice(h(this.lines,e),1),!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;(t.maybeHiddenMarkers||(t.maybeHiddenMarkers=[])).push(this)}},Ae(Os);var As=function(e,t){var r=this;this.markers=e,this.primary=t;for(var n=0;n<e.length;++n)e[n].parent=r};As.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){this.explicitlyCleared=!0;for(var t=0;t<this.markers.length;++t)e.markers[t].clear();bt(this,"clear")}},As.prototype.find=function(e,t){return this.primary.find(e,t)},Ae(As);var Ws=0,Ds=function(e,t,r,n,i){if(!(this instanceof Ds))return new Ds(e,t,r,n,i);null==r&&(r=0),Gi.call(this,[new Bi([new fs("",null)])]),this.first=r,this.scrollTop=this.scrollLeft=0,this.cantEdit=!1,this.cleanGeneration=1,this.modeFrontier=this.highlightFrontier=r;var o=E(r,0);this.sel=Rn(o),this.history=new Jn(null),this.id=++Ws,this.modeOption=t,this.lineSep=n,this.direction="rtl"==i?"rtl":"ltr",this.extend=!1,"string"==typeof e&&(e=this.splitLines(e)),_n(this,{from:o,to:o,text:e}),bi(this,Rn(o),Gl)};Ds.prototype=b(Gi.prototype,{constructor:Ds,iter:function(e,t,r){r?this.iterN(e-this.first,t-e,r):this.iterN(this.first,this.first+this.size,e)},insert:function(e,t){for(var r=0,n=0;n<t.length;++n)r+=t[n].height;this.insertInner(e-this.first,t,r)},remove:function(e,t){this.removeInner(e-this.first,t)},getValue:function(e){var t=O(this,this.first,this.first+this.size);return!1===e?t:t.join(e||this.lineSeparator())},setValue:gn(function(e){var t=E(this.first,0),r=this.first+this.size-1;Oi(this,{from:t,to:E(r,M(this,r).text.length),text:this.splitLines(e),origin:"setValue",full:!0},!0),this.cm&&Xr(this.cm,0,0),bi(this,Rn(t),Gl)}),replaceRange:function(e,t,r,n){Ei(this,e,t=U(this,t),r=r?U(this,r):t,n)},getRange:function(e,t,r){var n=N(this,U(this,e),U(this,t));return!1===r?n:n.join(r||this.lineSeparator())},getLine:function(e){var t=this.getLineHandle(e);return t&&t.text},getLineHandle:function(e){if(H(this,e))return M(this,e)},getLineNumber:function(e){return W(e)},getLineHandleVisualStart:function(e){return"number"==typeof e&&(e=M(this,e)),fe(e)},lineCount:function(){return this.size},firstLine:function(){return this.first},lastLine:function(){return this.first+this.size-1},clipPos:function(e){return U(this,e)},getCursor:function(e){var t=this.sel.primary();return null==e||"head"==e?t.head:"anchor"==e?t.anchor:"end"==e||"to"==e||!1===e?t.to():t.from()},listSelections:function(){return this.sel.ranges},somethingSelected:function(){return this.sel.somethingSelected()},setCursor:gn(function(e,t,r){vi(this,U(this,"number"==typeof e?E(e,t||0):e),null,r)}),setSelection:gn(function(e,t,r){vi(this,U(this,e),U(this,t||e),r)}),extendSelection:gn(function(e,t,r){di(this,U(this,e),t&&U(this,t),r)}),extendSelections:gn(function(e,t){pi(this,K(this,e),t)}),extendSelectionsBy:gn(function(e,t){pi(this,K(this,v(this.sel.ranges,e)),t)}),setSelections:gn(function(e,t,r){var n=this;if(e.length){for(var i=[],o=0;o<e.length;o++)i[o]=new Ts(U(n,e[o].anchor),U(n,e[o].head));null==t&&(t=Math.min(e.length-1,this.sel.primIndex)),bi(this,zn(i,t),r)}}),addSelection:gn(function(e,t,r){var n=this.sel.ranges.slice(0);n.push(new Ts(U(this,e),U(this,t||e))),bi(this,zn(n,n.length-1),r)}),getSelection:function(e){for(var t,r=this,n=this.sel.ranges,i=0;i<n.length;i++){var o=N(r,n[i].from(),n[i].to());t=t?t.concat(o):o}return!1===e?t:t.join(e||this.lineSeparator())},getSelections:function(e){for(var t=this,r=[],n=this.sel.ranges,i=0;i<n.length;i++){var o=N(t,n[i].from(),n[i].to());!1!==e&&(o=o.join(e||t.lineSeparator())),r[i]=o}return r},replaceSelection:function(e,t,r){for(var n=[],i=0;i<this.sel.ranges.length;i++)n[i]=e;this.replaceSelections(n,t,r||"+input")},replaceSelections:gn(function(e,t,r){for(var n=this,i=[],o=this.sel,l=0;l<o.ranges.length;l++){var s=o.ranges[l];i[l]={from:s.from(),to:s.to(),text:n.splitLines(e[l]),origin:r}}for(var a=t&&"end"!=t&&Kn(this,i,t),u=i.length-1;u>=0;u--)Oi(n,i[u]);a?yi(this,a):this.cm&&jr(this.cm)}),undo:gn(function(){Wi(this,"undo")}),redo:gn(function(){Wi(this,"redo")}),undoSelection:gn(function(){Wi(this,"undo",!0)}),redoSelection:gn(function(){Wi(this,"redo",!0)}),setExtending:function(e){this.extend=e},getExtending:function(){return this.extend},historySize:function(){for(var e=this.history,t=0,r=0,n=0;n<e.done.length;n++)e.done[n].ranges||++t;for(var i=0;i<e.undone.length;i++)e.undone[i].ranges||++r;return{undo:t,redo:r}},clearHistory:function(){this.history=new Jn(this.history.maxGeneration)},markClean:function(){this.cleanGeneration=this.changeGeneration(!0)},changeGeneration:function(e){return e&&(this.history.lastOp=this.history.lastSelOp=this.history.lastOrigin=null),this.history.generation},isClean:function(e){return this.history.generation==(e||this.cleanGeneration)},getHistory:function(){return{done:fi(this.history.done),undone:fi(this.history.undone)}},setHistory:function(e){var t=this.history=new Jn(this.history.maxGeneration);t.done=fi(e.done.slice(0),null,!0),t.undone=fi(e.undone.slice(0),null,!0)},setGutterMarker:gn(function(e,t,r){return Ri(this,e,"gutter",function(e){var n=e.gutterMarkers||(e.gutterMarkers={});return n[t]=r,!r&&C(n)&&(e.gutterMarkers=null),!0})}),clearGutter:gn(function(e){var t=this;this.iter(function(r){r.gutterMarkers&&r.gutterMarkers[e]&&Ri(t,r,"gutter",function(){return r.gutterMarkers[e]=null,C(r.gutterMarkers)&&(r.gutterMarkers=null),!0})})}),lineInfo:function(e){var t;if("number"==typeof e){if(!H(this,e))return null;if(t=e,!(e=M(this,e)))return null}else if(null==(t=W(e)))return null;return{line:t,handle:e,text:e.text,gutterMarkers:e.gutterMarkers,textClass:e.textClass,bgClass:e.bgClass,wrapClass:e.wrapClass,widgets:e.widgets}},addLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass";if(t[i]){if(e(n).test(t[i]))return!1;t[i]+=" "+n}else t[i]=n;return!0})}),removeLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass",o=t[i];if(!o)return!1;if(null==n)t[i]=null;else{var l=o.match(e(n));if(!l)return!1;var s=l.index+l[0].length;t[i]=o.slice(0,l.index)+(l.index&&s!=o.length?" ":"")+o.slice(s)||null}return!0})}),addLineWidget:gn(function(e,t,r){return Vi(this,e,t,r)}),removeLineWidget:function(e){e.clear()},markText:function(e,t,r){return Ki(this,U(this,e),U(this,t),r,r&&r.type||"range")},setBookmark:function(e,t){var r={replacedWith:t&&(null==t.nodeType?t.widget:t),insertLeft:t&&t.insertLeft,clearWhenEmpty:!1,shared:t&&t.shared,handleMouseEvents:t&&t.handleMouseEvents};return e=U(this,e),Ki(this,e,e,r,"bookmark")},findMarksAt:function(e){var t=[],r=M(this,(e=U(this,e)).line).markedSpans;if(r)for(var n=0;n<r.length;++n){var i=r[n];(null==i.from||i.from<=e.ch)&&(null==i.to||i.to>=e.ch)&&t.push(i.marker.parent||i.marker)}return t},findMarks:function(e,t,r){e=U(this,e),t=U(this,t);var n=[],i=e.line;return this.iter(e.line,t.line+1,function(o){var l=o.markedSpans;if(l)for(var s=0;s<l.length;s++){var a=l[s];null!=a.to&&i==e.line&&e.ch>=a.to||null==a.from&&i!=e.line||null!=a.from&&i==t.line&&a.from>=t.ch||r&&!r(a.marker)||n.push(a.marker.parent||a.marker)}++i}),n},getAllMarks:function(){var e=[];return this.iter(function(t){var r=t.markedSpans;if(r)for(var n=0;n<r.length;++n)null!=r[n].from&&e.push(r[n].marker)}),e},posFromIndex:function(e){var t,r=this.first,n=this.lineSeparator().length;return this.iter(function(i){var o=i.text.length+n;if(o>e)return t=e,!0;e-=o,++r}),U(this,E(r,t))},indexFromPos:function(e){var t=(e=U(this,e)).ch;if(e.line<this.first||e.ch<0)return 0;var r=this.lineSeparator().length;return this.iter(this.first,e.line,function(e){t+=e.text.length+r}),t},copy:function(e){var t=new Ds(O(this,this.first,this.first+this.size),this.modeOption,this.first,this.lineSep,this.direction);return t.scrollTop=this.scrollTop,t.scrollLeft=this.scrollLeft,t.sel=this.sel,t.extend=!1,e&&(t.history.undoDepth=this.history.undoDepth,t.setHistory(this.getHistory())),t},linkedDoc:function(e){e||(e={});var t=this.first,r=this.first+this.size;null!=e.from&&e.from>t&&(t=e.from),null!=e.to&&e.to<r&&(r=e.to);var n=new Ds(O(this,t,r),e.mode||this.modeOption,t,this.lineSep,this.direction);return e.sharedHist&&(n.history=this.history),(this.linked||(this.linked=[])).push({doc:n,sharedHist:e.sharedHist}),n.linked=[{doc:this,isParent:!0,sharedHist:e.sharedHist}],Yi(n,Xi(this)),n},unlinkDoc:function(e){var t=this;if(e instanceof jo&&(e=e.doc),this.linked)for(var r=0;r<this.linked.length;++r)if(t.linked[r].doc==e){t.linked.splice(r,1),e.unlinkDoc(t),_i(Xi(t));break}if(e.history==this.history){var n=[e.id];$n(e,function(e){return n.push(e.id)},!0),e.history=new Jn(null),e.history.done=fi(this.history.done,n),e.history.undone=fi(this.history.undone,n)}},iterLinkedDocs:function(e){$n(this,e)},getMode:function(){return this.mode},getEditor:function(){return this.cm},splitLines:function(e){return this.lineSep?e.split(this.lineSep):es(e)},lineSeparator:function(){return this.lineSep||"\n"},setDirection:gn(function(e){"rtl"!=e&&(e="ltr"),e!=this.direction&&(this.direction=e,this.iter(function(e){return e.order=null}),this.cm&&Qn(this.cm))})}),Ds.prototype.eachLine=Ds.prototype.iter;for(var Hs=0,Fs=!1,Es={3:"Enter",8:"Backspace",9:"Tab",13:"Enter",16:"Shift",17:"Ctrl",18:"Alt",19:"Pause",20:"CapsLock",27:"Esc",32:"Space",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"Left",38:"Up",39:"Right",40:"Down",44:"PrintScrn",45:"Insert",46:"Delete",59:";",61:"=",91:"Mod",92:"Mod",93:"Mod",106:"*",107:"=",109:"-",110:".",111:"/",127:"Delete",173:"-",186:";",187:"=",188:",",189:"-",190:".",191:"/",192:"`",219:"[",220:"\\",221:"]",222:"'",63232:"Up",63233:"Down",63234:"Left",63235:"Right",63272:"Delete",63273:"Home",63275:"End",63276:"PageUp",63277:"PageDown",63302:"Insert"},Ps=0;Ps<10;Ps++)Es[Ps+48]=Es[Ps+96]=String(Ps);for(var Is=65;Is<=90;Is++)Es[Is]=String.fromCharCode(Is);for(var zs=1;zs<=12;zs++)Es[zs+111]=Es[zs+63235]="F"+zs;var Rs={};Rs.basic={Left:"goCharLeft",Right:"goCharRight",Up:"goLineUp",Down:"goLineDown",End:"goLineEnd",Home:"goLineStartSmart",PageUp:"goPageUp",PageDown:"goPageDown",Delete:"delCharAfter",Backspace:"delCharBefore","Shift-Backspace":"delCharBefore",Tab:"defaultTab","Shift-Tab":"indentAuto",Enter:"newlineAndIndent",Insert:"toggleOverwrite",Esc:"singleSelection"},Rs.pcDefault={"Ctrl-A":"selectAll","Ctrl-D":"deleteLine","Ctrl-Z":"undo","Shift-Ctrl-Z":"redo","Ctrl-Y":"redo","Ctrl-Home":"goDocStart","Ctrl-End":"goDocEnd","Ctrl-Up":"goLineUp","Ctrl-Down":"goLineDown","Ctrl-Left":"goGroupLeft","Ctrl-Right":"goGroupRight","Alt-Left":"goLineStart","Alt-Right":"goLineEnd","Ctrl-Backspace":"delGroupBefore","Ctrl-Delete":"delGroupAfter","Ctrl-S":"save","Ctrl-F":"find","Ctrl-G":"findNext","Shift-Ctrl-G":"findPrev","Shift-Ctrl-F":"replace","Shift-Ctrl-R":"replaceAll","Ctrl-[":"indentLess","Ctrl-]":"indentMore","Ctrl-U":"undoSelection","Shift-Ctrl-U":"redoSelection","Alt-U":"redoSelection",fallthrough:"basic"},Rs.emacsy={"Ctrl-F":"goCharRight","Ctrl-B":"goCharLeft","Ctrl-P":"goLineUp","Ctrl-N":"goLineDown","Alt-F":"goWordRight","Alt-B":"goWordLeft","Ctrl-A":"goLineStart","Ctrl-E":"goLineEnd","Ctrl-V":"goPageDown","Shift-Ctrl-V":"goPageUp","Ctrl-D":"delCharAfter","Ctrl-H":"delCharBefore","Alt-D":"delWordAfter","Alt-Backspace":"delWordBefore","Ctrl-K":"killLine","Ctrl-T":"transposeChars","Ctrl-O":"openLine"},Rs.macDefault={"Cmd-A":"selectAll","Cmd-D":"deleteLine","Cmd-Z":"undo","Shift-Cmd-Z":"redo","Cmd-Y":"redo","Cmd-Home":"goDocStart","Cmd-Up":"goDocStart","Cmd-End":"goDocEnd","Cmd-Down":"goDocEnd","Alt-Left":"goGroupLeft","Alt-Right":"goGroupRight","Cmd-Left":"goLineLeft","Cmd-Right":"goLineRight","Alt-Backspace":"delGroupBefore","Ctrl-Alt-Backspace":"delGroupAfter","Alt-Delete":"delGroupAfter","Cmd-S":"save","Cmd-F":"find","Cmd-G":"findNext","Shift-Cmd-G":"findPrev","Cmd-Alt-F":"replace","Shift-Cmd-Alt-F":"replaceAll","Cmd-[":"indentLess","Cmd-]":"indentMore","Cmd-Backspace":"delWrappedLineLeft","Cmd-Delete":"delWrappedLineRight","Cmd-U":"undoSelection","Shift-Cmd-U":"redoSelection","Ctrl-Up":"goDocStart","Ctrl-Down":"goDocEnd",fallthrough:["basic","emacsy"]},Rs.default=Ml?Rs.macDefault:Rs.pcDefault;var Bs={selectAll:Mi,singleSelection:function(e){return e.setSelection(e.getCursor("anchor"),e.getCursor("head"),Gl)},killLine:function(e){return co(e,function(t){if(t.empty()){var r=M(e.doc,t.head.line).text.length;return t.head.ch==r&&t.head.line<e.lastLine()?{from:t.head,to:E(t.head.line+1,0)}:{from:t.head,to:E(t.head.line,r)}}return{from:t.from(),to:t.to()}})},deleteLine:function(e){return co(e,function(t){return{from:E(t.from().line,0),to:U(e.doc,E(t.to().line+1,0))}})},delLineLeft:function(e){return co(e,function(e){return{from:E(e.from().line,0),to:e.from()}})},delWrappedLineLeft:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5;return{from:e.coordsChar({left:0,top:r},"div"),to:t.from()}})},delWrappedLineRight:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5,n=e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div");return{from:t.from(),to:n}})},undo:function(e){return e.undo()},redo:function(e){return e.redo()},undoSelection:function(e){return e.undoSelection()},redoSelection:function(e){return e.redoSelection()},goDocStart:function(e){return e.extendSelection(E(e.firstLine(),0))},goDocEnd:function(e){return e.extendSelection(E(e.lastLine()))},goLineStart:function(e){return e.extendSelectionsBy(function(t){return vo(e,t.head.line)},{origin:"+move",bias:1})},goLineStartSmart:function(e){return e.extendSelectionsBy(function(t){return yo(e,t.head)},{origin:"+move",bias:1})},goLineEnd:function(e){return e.extendSelectionsBy(function(t){return mo(e,t.head.line)},{origin:"+move",bias:-1})},goLineRight:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div")},Vl)},goLineLeft:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:0,top:r},"div")},Vl)},goLineLeftSmart:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5,n=e.coordsChar({left:0,top:r},"div");return n.ch<e.getLine(n.line).search(/\S/)?yo(e,t.head):n},Vl)},goLineUp:function(e){return e.moveV(-1,"line")},goLineDown:function(e){return e.moveV(1,"line")},goPageUp:function(e){return e.moveV(-1,"page")},goPageDown:function(e){return e.moveV(1,"page")},goCharLeft:function(e){return e.moveH(-1,"char")},goCharRight:function(e){return e.moveH(1,"char")},goColumnLeft:function(e){return e.moveH(-1,"column")},goColumnRight:function(e){return e.moveH(1,"column")},goWordLeft:function(e){return e.moveH(-1,"word")},goGroupRight:function(e){return e.moveH(1,"group")},goGroupLeft:function(e){return e.moveH(-1,"group")},goWordRight:function(e){return e.moveH(1,"word")},delCharBefore:function(e){return e.deleteH(-1,"char")},delCharAfter:function(e){return e.deleteH(1,"char")},delWordBefore:function(e){return e.deleteH(-1,"word")},delWordAfter:function(e){return e.deleteH(1,"word")},delGroupBefore:function(e){return e.deleteH(-1,"group")},delGroupAfter:function(e){return e.deleteH(1,"group")},indentAuto:function(e){return e.indentSelection("smart")},indentMore:function(e){return e.indentSelection("add")},indentLess:function(e){return e.indentSelection("subtract")},insertTab:function(e){return e.replaceSelection("\t")},insertSoftTab:function(e){for(var t=[],r=e.listSelections(),n=e.options.tabSize,i=0;i<r.length;i++){var o=r[i].from(),l=f(e.getLine(o.line),o.ch,n);t.push(p(n-l%n))}e.replaceSelections(t)},defaultTab:function(e){e.somethingSelected()?e.indentSelection("add"):e.execCommand("insertTab")},transposeChars:function(e){return hn(e,function(){for(var t=e.listSelections(),r=[],n=0;n<t.length;n++)if(t[n].empty()){var i=t[n].head,o=M(e.doc,i.line).text;if(o)if(i.ch==o.length&&(i=new E(i.line,i.ch-1)),i.ch>0)i=new E(i.line,i.ch+1),e.replaceRange(o.charAt(i.ch-1)+o.charAt(i.ch-2),E(i.line,i.ch-2),i,"+transpose");else if(i.line>e.doc.first){var l=M(e.doc,i.line-1).text;l&&(i=new E(i.line,1),e.replaceRange(o.charAt(0)+e.doc.lineSeparator()+l.charAt(l.length-1),E(i.line-1,l.length-1),i,"+transpose"))}r.push(new Ts(i,i))}e.setSelections(r)})},newlineAndIndent:function(e){return hn(e,function(){for(var t=e.listSelections(),r=t.length-1;r>=0;r--)e.replaceRange(e.doc.lineSeparator(),t[r].anchor,t[r].head,"+input");t=e.listSelections();for(var n=0;n<t.length;n++)e.indentLine(t[n].from().line,null,!0);jr(e)})},openLine:function(e){return e.replaceSelection("\n","start")},toggleOverwrite:function(e){return e.toggleOverwrite()}},Gs=new Pl,Us=null,Vs=function(e,t,r){this.time=e,this.pos=t,this.button=r};Vs.prototype.compare=function(e,t,r){return this.time+400>e&&0==P(t,this.pos)&&r==this.button};var Ks,js,Xs={toString:function(){return"CodeMirror.Init"}},Ys={},_s={};jo.defaults=Ys,jo.optionHandlers=_s;var $s=[];jo.defineInitHook=function(e){return $s.push(e)};var qs=null,Zs=function(e){this.cm=e,this.lastAnchorNode=this.lastAnchorOffset=this.lastFocusNode=this.lastFocusOffset=null,this.polling=new Pl,this.composing=null,this.gracePeriod=!1,this.readDOMTimeout=null};Zs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()}),"cut"==e.type&&i.replaceSelection("",null,"cut");else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type&&i.operation(function(){i.setSelections(t.ranges,0,Gl),i.replaceSelection("",null,"cut")})}if(e.clipboardData){e.clipboardData.clearData();var r=qs.text.join("\n");if(e.clipboardData.setData("Text",r),e.clipboardData.getData("Text")==r)return void e.preventDefault()}var l=el(),s=l.firstChild;i.display.lineSpace.insertBefore(l,i.display.lineSpace.firstChild),s.value=qs.text.join("\n");var a=document.activeElement;El(s),setTimeout(function(){i.display.lineSpace.removeChild(l),a.focus(),a==o&&n.showPrimarySelection()},50)}}var r=this,n=this,i=n.cm,o=n.div=e.lineDiv;Jo(o,i.options.spellcheck),Ql(o,"paste",function(e){Me(i,e)||qo(e,i)||vl<=11&&setTimeout(dn(i,function(){return r.updateFromDOM()}),20)}),Ql(o,"compositionstart",function(e){r.composing={data:e.data,done:!1}}),Ql(o,"compositionupdate",function(e){r.composing||(r.composing={data:e.data,done:!1})}),Ql(o,"compositionend",function(e){r.composing&&(e.data!=r.composing.data&&r.readFromDOMSoon(),r.composing.done=!0)}),Ql(o,"touchstart",function(){return n.forceCompositionEnd()}),Ql(o,"input",function(){r.composing||r.readFromDOMSoon()}),Ql(o,"copy",t),Ql(o,"cut",t)},Zs.prototype.prepareSelection=function(){var e=Tr(this.cm,!1);return e.focus=this.cm.state.focused,e},Zs.prototype.showSelection=function(e,t){e&&this.cm.display.view.length&&((e.focus||t)&&this.showPrimarySelection(),this.showMultipleSelections(e))},Zs.prototype.showPrimarySelection=function(){var e=window.getSelection(),t=this.cm,r=t.doc.sel.primary(),n=r.from(),i=r.to();if(t.display.viewTo==t.display.viewFrom||n.line>=t.display.viewTo||i.line<t.display.viewFrom)e.removeAllRanges();else{var o=sl(t,e.anchorNode,e.anchorOffset),l=sl(t,e.focusNode,e.focusOffset);if(!o||o.bad||!l||l.bad||0!=P(B(o,l),n)||0!=P(R(o,l),i)){var s=t.display.view,a=n.line>=t.display.viewFrom&&nl(t,n)||{node:s[0].measure.map[2],offset:0},u=i.line<t.display.viewTo&&nl(t,i);if(!u){var c=s[s.length-1].measure,f=c.maps?c.maps[c.maps.length-1]:c.map;u={node:f[f.length-1],offset:f[f.length-2]-f[f.length-3]}}if(a&&u){var h,d=e.rangeCount&&e.getRangeAt(0);try{h=Wl(a.node,a.offset,u.offset,u.node)}catch(e){}h&&(!fl&&t.state.focused?(e.collapse(a.node,a.offset),h.collapsed||(e.removeAllRanges(),e.addRange(h))):(e.removeAllRanges(),e.addRange(h)),d&&null==e.anchorNode?e.addRange(d):fl&&this.startGracePeriod()),this.rememberSelection()}else e.removeAllRanges()}}},Zs.prototype.startGracePeriod=function(){var e=this;clearTimeout(this.gracePeriod),this.gracePeriod=setTimeout(function(){e.gracePeriod=!1,e.selectionChanged()&&e.cm.operation(function(){return e.cm.curOp.selectionChanged=!0})},20)},Zs.prototype.showMultipleSelections=function(e){r(this.cm.display.cursorDiv,e.cursors),r(this.cm.display.selectionDiv,e.selection)},Zs.prototype.rememberSelection=function(){var e=window.getSelection();this.lastAnchorNode=e.anchorNode,this.lastAnchorOffset=e.anchorOffset,this.lastFocusNode=e.focusNode,this.lastFocusOffset=e.focusOffset},Zs.prototype.selectionInEditor=function(){var e=window.getSelection();if(!e.rangeCount)return!1;var t=e.getRangeAt(0).commonAncestorContainer;return o(this.div,t)},Zs.prototype.focus=function(){"nocursor"!=this.cm.options.readOnly&&(this.selectionInEditor()||this.showSelection(this.prepareSelection(),!0),this.div.focus())},Zs.prototype.blur=function(){this.div.blur()},Zs.prototype.getField=function(){return this.div},Zs.prototype.supportsTouch=function(){return!0},Zs.prototype.receivedFocus=function(){function e(){t.cm.state.focused&&(t.pollSelection(),t.polling.set(t.cm.options.pollInterval,e))}var t=this;this.selectionInEditor()?this.pollSelection():hn(this.cm,function(){return t.cm.curOp.selectionChanged=!0}),this.polling.set(this.cm.options.pollInterval,e)},Zs.prototype.selectionChanged=function(){var e=window.getSelection();return e.anchorNode!=this.lastAnchorNode||e.anchorOffset!=this.lastAnchorOffset||e.focusNode!=this.lastFocusNode||e.focusOffset!=this.lastFocusOffset},Zs.prototype.pollSelection=function(){if(null==this.readDOMTimeout&&!this.gracePeriod&&this.selectionChanged()){var e=window.getSelection(),t=this.cm;if(kl&&bl&&this.cm.options.gutters.length&&il(e.anchorNode))return this.cm.triggerOnKeyDown({type:"keydown",keyCode:8,preventDefault:Math.abs}),this.blur(),void this.focus();if(!this.composing){this.rememberSelection();var r=sl(t,e.anchorNode,e.anchorOffset),n=sl(t,e.focusNode,e.focusOffset);r&&n&&hn(t,function(){bi(t.doc,Rn(r,n),Gl),(r.bad||n.bad)&&(t.curOp.selectionChanged=!0)})}}},Zs.prototype.pollContent=function(){null!=this.readDOMTimeout&&(clearTimeout(this.readDOMTimeout),this.readDOMTimeout=null);var e=this.cm,t=e.display,r=e.doc.sel.primary(),n=r.from(),i=r.to();if(0==n.ch&&n.line>e.firstLine()&&(n=E(n.line-1,M(e.doc,n.line-1).length)),i.ch==M(e.doc,i.line).text.length&&i.line<e.lastLine()&&(i=E(i.line+1,0)),n.line<t.viewFrom||i.line>t.viewTo-1)return!1;var o,l,s;n.line==t.viewFrom||0==(o=Lr(e,n.line))?(l=W(t.view[0].line),s=t.view[0].node):(l=W(t.view[o].line),s=t.view[o-1].node.nextSibling);var a,u,c=Lr(e,i.line);if(c==t.view.length-1?(a=t.viewTo-1,u=t.lineDiv.lastChild):(a=W(t.view[c+1].line)-1,u=t.view[c+1].node.previousSibling),!s)return!1;for(var f=e.doc.splitLines(ll(e,s,u,l,a)),h=N(e.doc,E(l,0),E(a,M(e.doc,a).text.length));f.length>1&&h.length>1;)if(g(f)==g(h))f.pop(),h.pop(),a--;else{if(f[0]!=h[0])break;f.shift(),h.shift(),l++}for(var d=0,p=0,v=f[0],m=h[0],y=Math.min(v.length,m.length);d<y&&v.charCodeAt(d)==m.charCodeAt(d);)++d;for(var b=g(f),w=g(h),x=Math.min(b.length-(1==f.length?d:0),w.length-(1==h.length?d:0));p<x&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)++p;if(1==f.length&&1==h.length&&l==n.line)for(;d&&d>n.ch&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)d--,p++;f[f.length-1]=b.slice(0,b.length-p).replace(/^\u200b+/,""),f[0]=f[0].slice(d).replace(/\u200b+$/,"");var C=E(l,d),S=E(a,h.length?g(h).length-p:0);return f.length>1||f[0]||P(C,S)?(Ei(e.doc,f,C,S,"+input"),!0):void 0},Zs.prototype.ensurePolled=function(){this.forceCompositionEnd()},Zs.prototype.reset=function(){this.forceCompositionEnd()},Zs.prototype.forceCompositionEnd=function(){this.composing&&(clearTimeout(this.readDOMTimeout),this.composing=null,this.updateFromDOM(),this.div.blur(),this.div.focus())},Zs.prototype.readFromDOMSoon=function(){var e=this;null==this.readDOMTimeout&&(this.readDOMTimeout=setTimeout(function(){if(e.readDOMTimeout=null,e.composing){if(!e.composing.done)return;e.composing=null}e.updateFromDOM()},80))},Zs.prototype.updateFromDOM=function(){var e=this;!this.cm.isReadOnly()&&this.pollContent()||hn(this.cm,function(){return vn(e.cm)})},Zs.prototype.setUneditable=function(e){e.contentEditable="false"},Zs.prototype.onKeyPress=function(e){0!=e.charCode&&(e.preventDefault(),this.cm.isReadOnly()||dn(this.cm,$o)(this.cm,String.fromCharCode(null==e.charCode?e.keyCode:e.charCode),0))},Zs.prototype.readOnlyChanged=function(e){this.div.contentEditable=String("nocursor"!=e)},Zs.prototype.onContextMenu=function(){},Zs.prototype.resetPosition=function(){},Zs.prototype.needsContentAttribute=!0;var Qs=function(e){this.cm=e,this.prevInput="",this.pollingFast=!1,this.polling=new Pl,this.hasSelection=!1,this.composing=null};Qs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()});else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type?i.setSelections(t.ranges,null,Gl):(n.prevInput="",l.value=t.text.join("\n"),El(l))}"cut"==e.type&&(i.state.cutIncoming=!0)}}var r=this,n=this,i=this.cm,o=this.wrapper=el(),l=this.textarea=o.firstChild;e.wrapper.insertBefore(o,e.wrapper.firstChild),Ll&&(l.style.width="0px"),Ql(l,"input",function(){gl&&vl>=9&&r.hasSelection&&(r.hasSelection=null),n.poll()}),Ql(l,"paste",function(e){Me(i,e)||qo(e,i)||(i.state.pasteIncoming=!0,n.fastPoll())}),Ql(l,"cut",t),Ql(l,"copy",t),Ql(e.scroller,"paste",function(t){Ft(e,t)||Me(i,t)||(i.state.pasteIncoming=!0,n.focus())}),Ql(e.lineSpace,"selectstart",function(t){Ft(e,t)||We(t)}),Ql(l,"compositionstart",function(){var e=i.getCursor("from");n.composing&&n.composing.range.clear(),n.composing={start:e,range:i.markText(e,i.getCursor("to"),{className:"CodeMirror-composing"})}}),Ql(l,"compositionend",function(){n.composing&&(n.poll(),n.composing.range.clear(),n.composing=null)})},Qs.prototype.prepareSelection=function(){var e=this.cm,t=e.display,r=e.doc,n=Tr(e);if(e.options.moveInputWithCursor){var i=sr(e,r.sel.primary().head,"div"),o=t.wrapper.getBoundingClientRect(),l=t.lineDiv.getBoundingClientRect();n.teTop=Math.max(0,Math.min(t.wrapper.clientHeight-10,i.top+l.top-o.top)),n.teLeft=Math.max(0,Math.min(t.wrapper.clientWidth-10,i.left+l.left-o.left))}return n},Qs.prototype.showSelection=function(e){var t=this.cm.display;r(t.cursorDiv,e.cursors),r(t.selectionDiv,e.selection),null!=e.teTop&&(this.wrapper.style.top=e.teTop+"px",this.wrapper.style.left=e.teLeft+"px")},Qs.prototype.reset=function(e){if(!this.contextMenuPending&&!this.composing){var t=this.cm;if(t.somethingSelected()){this.prevInput="";var r=t.getSelection();this.textarea.value=r,t.state.focused&&El(this.textarea),gl&&vl>=9&&(this.hasSelection=r)}else e||(this.prevInput=this.textarea.value="",gl&&vl>=9&&(this.hasSelection=null))}},Qs.prototype.getField=function(){return this.textarea},Qs.prototype.supportsTouch=function(){return!1},Qs.prototype.focus=function(){if("nocursor"!=this.cm.options.readOnly&&(!Tl||l()!=this.textarea))try{this.textarea.focus()}catch(e){}},Qs.prototype.blur=function(){this.textarea.blur()},Qs.prototype.resetPosition=function(){this.wrapper.style.top=this.wrapper.style.left=0},Qs.prototype.receivedFocus=function(){this.slowPoll()},Qs.prototype.slowPoll=function(){var e=this;this.pollingFast||this.polling.set(this.cm.options.pollInterval,function(){e.poll(),e.cm.state.focused&&e.slowPoll()})},Qs.prototype.fastPoll=function(){function e(){r.poll()||t?(r.pollingFast=!1,r.slowPoll()):(t=!0,r.polling.set(60,e))}var t=!1,r=this;r.pollingFast=!0,r.polling.set(20,e)},Qs.prototype.poll=function(){var e=this,t=this.cm,r=this.textarea,n=this.prevInput;if(this.contextMenuPending||!t.state.focused||ts(r)&&!n&&!this.composing||t.isReadOnly()||t.options.disableInput||t.state.keySeq)return!1;var i=r.value;if(i==n&&!t.somethingSelected())return!1;if(gl&&vl>=9&&this.hasSelection===i||Ml&&/[\uf700-\uf7ff]/.test(i))return t.display.input.reset(),!1;if(t.doc.sel==t.display.selForContextMenu){var o=i.charCodeAt(0);if(8203!=o||n||(n="​"),8666==o)return this.reset(),this.cm.execCommand("undo")}for(var l=0,s=Math.min(n.length,i.length);l<s&&n.charCodeAt(l)==i.charCodeAt(l);)++l;return hn(t,function(){$o(t,i.slice(l),n.length-l,null,e.composing?"*compose":null),i.length>1e3||i.indexOf("\n")>-1?r.value=e.prevInput="":e.prevInput=i,e.composing&&(e.composing.range.clear(),e.composing.range=t.markText(e.composing.start,t.getCursor("to"),{className:"CodeMirror-composing"}))}),!0},Qs.prototype.ensurePolled=function(){this.pollingFast&&this.poll()&&(this.pollingFast=!1)},Qs.prototype.onKeyPress=function(){gl&&vl>=9&&(this.hasSelection=null),this.fastPoll()},Qs.prototype.onContextMenu=function(e){function t(){if(null!=l.selectionStart){var e=i.somethingSelected(),t="​"+(e?l.value:"");l.value="⇚",l.value=t,n.prevInput=e?"":"​",l.selectionStart=1,l.selectionEnd=t.length,o.selForContextMenu=i.doc.sel}}function r(){if(n.contextMenuPending=!1,n.wrapper.style.cssText=c,l.style.cssText=u,gl&&vl<9&&o.scrollbars.setScrollTop(o.scroller.scrollTop=a),null!=l.selectionStart){(!gl||gl&&vl<9)&&t();var e=0,r=function(){o.selForContextMenu==i.doc.sel&&0==l.selectionStart&&l.selectionEnd>0&&"​"==n.prevInput?dn(i,Mi)(i):e++<10?o.detectingSelectAll=setTimeout(r,500):(o.selForContextMenu=null,o.input.reset())};o.detectingSelectAll=setTimeout(r,200)}}var n=this,i=n.cm,o=i.display,l=n.textarea,s=Sr(i,e),a=o.scroller.scrollTop;if(s&&!wl){i.options.resetSelectionOnContextMenu&&-1==i.doc.sel.contains(s)&&dn(i,bi)(i.doc,Rn(s),Gl);var u=l.style.cssText,c=n.wrapper.style.cssText;n.wrapper.style.cssText="position: absolute";var f=n.wrapper.getBoundingClientRect();l.style.cssText="position: absolute; width: 30px; height: 30px;\n      top: "+(e.clientY-f.top-5)+"px; left: "+(e.clientX-f.left-5)+"px;\n      z-index: 1000; background: "+(gl?"rgba(255, 255, 255, .05)":"transparent")+";\n      outline: none; border-width: 0; outline: none; overflow: hidden; opacity: .05; filter: alpha(opacity=5);";var h;if(ml&&(h=window.scrollY),o.input.focus(),ml&&window.scrollTo(null,h),o.input.reset(),i.somethingSelected()||(l.value=n.prevInput=" "),n.contextMenuPending=!0,o.selForContextMenu=i.doc.sel,clearTimeout(o.detectingSelectAll),gl&&vl>=9&&t(),Hl){Fe(e);var d=function(){ke(window,"mouseup",d),setTimeout(r,20)};Ql(window,"mouseup",d)}else setTimeout(r,50)}},Qs.prototype.readOnlyChanged=function(e){e||this.reset(),this.textarea.disabled="nocursor"==e},Qs.prototype.setUneditable=function(){},Qs.prototype.needsContentAttribute=!1,function(e){function t(t,n,i,o){e.defaults[t]=n,i&&(r[t]=o?function(e,t,r){r!=Xs&&i(e,t,r)}:i)}var r=e.optionHandlers;e.defineOption=t,e.Init=Xs,t("value","",function(e,t){return e.setValue(t)},!0),t("mode",null,function(e,t){e.doc.modeOption=t,jn(e)},!0),t("indentUnit",2,jn,!0),t("indentWithTabs",!1),t("smartIndent",!0),t("tabSize",4,function(e){Xn(e),er(e),vn(e)},!0),t("lineSeparator",null,function(e,t){if(e.doc.lineSep=t,t){var r=[],n=e.doc.first;e.doc.iter(function(e){for(var i=0;;){var o=e.text.indexOf(t,i);if(-1==o)break;i=o+t.length,r.push(E(n,o))}n++});for(var i=r.length-1;i>=0;i--)Ei(e.doc,t,r[i],E(r[i].line,r[i].ch+t.length))}}),t("specialChars",/[\u0000-\u001f\u007f-\u009f\u00ad\u061c\u200b-\u200f\u2028\u2029\ufeff]/g,function(e,t,r){e.state.specialChars=new RegExp(t.source+(t.test("\t")?"":"|\t"),"g"),r!=Xs&&e.refresh()}),t("specialCharPlaceholder",at,function(e){return e.refresh()},!0),t("electricChars",!0),t("inputStyle",Tl?"contenteditable":"textarea",function(){throw new Error("inputStyle can not (yet) be changed in a running editor")},!0),t("spellcheck",!1,function(e,t){return e.getInputField().spellcheck=t},!0),t("rtlMoveVisually",!Ol),t("wholeLineUpdateBefore",!0),t("theme","default",function(e){Go(e),Uo(e)},!0),t("keyMap","default",function(e,t,r){var n=uo(t),i=r!=Xs&&uo(r);i&&i.detach&&i.detach(e,n),n.attach&&n.attach(e,i||null)}),t("extraKeys",null),t("configureMouse",null),t("lineWrapping",!1,Ko,!0),t("gutters",[],function(e){Fn(e.options),Uo(e)},!0),t("fixedGutter",!0,function(e,t){e.display.gutters.style.left=t?wr(e.display)+"px":"0",e.refresh()},!0),t("coverGutterNextToScrollbar",!1,function(e){return en(e)},!0),t("scrollbarStyle","native",function(e){rn(e),en(e),e.display.scrollbars.setScrollTop(e.doc.scrollTop),e.display.scrollbars.setScrollLeft(e.doc.scrollLeft)},!0),t("lineNumbers",!1,function(e){Fn(e.options),Uo(e)},!0),t("firstLineNumber",1,Uo,!0),t("lineNumberFormatter",function(e){return e},Uo,!0),t("showCursorWhenSelecting",!1,kr,!0),t("resetSelectionOnContextMenu",!0),t("lineWiseCopyCut",!0),t("pasteLinesPerSelection",!0),t("readOnly",!1,function(e,t){"nocursor"==t&&(Fr(e),e.display.input.blur()),e.display.input.readOnlyChanged(t)}),t("disableInput",!1,function(e,t){t||e.display.input.reset()},!0),t("dragDrop",!0,Vo),t("allowDropFileTypes",null),t("cursorBlinkRate",530),t("cursorScrollMargin",0),t("cursorHeight",1,kr,!0),t("singleCursorHeightPerLine",!0,kr,!0),t("workTime",100),t("workDelay",100),t("flattenSpans",!0,Xn,!0),t("addModeClass",!1,Xn,!0),t("pollInterval",100),t("undoDepth",200,function(e,t){return e.doc.history.undoDepth=t}),t("historyEventDelay",1250),t("viewportMargin",10,function(e){return e.refresh()},!0),t("maxHighlightLength",1e4,Xn,!0),t("moveInputWithCursor",!0,function(e,t){t||e.display.input.resetPosition()}),t("tabindex",null,function(e,t){return e.display.input.getField().tabIndex=t||""}),t("autofocus",null),t("direction","ltr",function(e,t){return e.doc.setDirection(t)},!0)}(jo),function(e){var t=e.optionHandlers,r=e.helpers={};e.prototype={constructor:e,focus:function(){window.focus(),this.display.input.focus()},setOption:function(e,r){var n=this.options,i=n[e];n[e]==r&&"mode"!=e||(n[e]=r,t.hasOwnProperty(e)&&dn(this,t[e])(this,r,i),Te(this,"optionChange",this,e))},getOption:function(e){return this.options[e]},getDoc:function(){return this.doc},addKeyMap:function(e,t){this.state.keyMaps[t?"push":"unshift"](uo(e))},removeKeyMap:function(e){for(var t=this.state.keyMaps,r=0;r<t.length;++r)if(t[r]==e||t[r].name==e)return t.splice(r,1),!0},addOverlay:pn(function(t,r){var n=t.token?t:e.getMode(this.options,t);if(n.startState)throw new Error("Overlays may not be stateful.");m(this.state.overlays,{mode:n,modeSpec:t,opaque:r&&r.opaque,priority:r&&r.priority||0},function(e){return e.priority}),this.state.modeGen++,vn(this)}),removeOverlay:pn(function(e){for(var t=this,r=this.state.overlays,n=0;n<r.length;++n){var i=r[n].modeSpec;if(i==e||"string"==typeof e&&i.name==e)return r.splice(n,1),t.state.modeGen++,void vn(t)}}),indentLine:pn(function(e,t,r){"string"!=typeof t&&"number"!=typeof t&&(t=null==t?this.options.smartIndent?"smart":"prev":t?"add":"subtract"),H(this.doc,e)&&Yo(this,e,t,r)}),indentSelection:pn(function(e){for(var t=this,r=this.doc.sel.ranges,n=-1,i=0;i<r.length;i++){var o=r[i];if(o.empty())o.head.line>n&&(Yo(t,o.head.line,e,!0),n=o.head.line,i==t.doc.sel.primIndex&&jr(t));else{var l=o.from(),s=o.to(),a=Math.max(n,l.line);n=Math.min(t.lastLine(),s.line-(s.ch?0:1))+1;for(var u=a;u<n;++u)Yo(t,u,e);var c=t.doc.sel.ranges;0==l.ch&&r.length==c.length&&c[i].from().ch>0&&gi(t.doc,i,new Ts(l,c[i].to()),Gl)}}}),getTokenAt:function(e,t){return Je(this,e,t)},getLineTokens:function(e,t){return Je(this,E(e),t,!0)},getTokenTypeAt:function(e){e=U(this.doc,e);var t,r=_e(this,M(this.doc,e.line)),n=0,i=(r.length-1)/2,o=e.ch;if(0==o)t=r[2];else for(;;){var l=n+i>>1;if((l?r[2*l-1]:0)>=o)i=l;else{if(!(r[2*l+1]<o)){t=r[2*l+2];break}n=l+1}}var s=t?t.indexOf("overlay "):-1;return s<0?t:0==s?null:t.slice(0,s-1)},getModeAt:function(t){var r=this.doc.mode;return r.innerMode?e.innerMode(r,this.getTokenAt(t).state).mode:r},getHelper:function(e,t){return this.getHelpers(e,t)[0]},getHelpers:function(e,t){var n=this,i=[];if(!r.hasOwnProperty(t))return i;var o=r[t],l=this.getModeAt(e);if("string"==typeof l[t])o[l[t]]&&i.push(o[l[t]]);else if(l[t])for(var s=0;s<l[t].length;s++){var a=o[l[t][s]];a&&i.push(a)}else l.helperType&&o[l.helperType]?i.push(o[l.helperType]):o[l.name]&&i.push(o[l.name]);for(var u=0;u<o._global.length;u++){var c=o._global[u];c.pred(l,n)&&-1==h(i,c.val)&&i.push(c.val)}return i},getStateAfter:function(e,t){var r=this.doc;return e=G(r,null==e?r.first+r.size-1:e),$e(this,e+1,t).state},cursorCoords:function(e,t){var r,n=this.doc.sel.primary();return r=null==e?n.head:"object"==typeof e?U(this.doc,e):e?n.from():n.to(),sr(this,r,t||"page")},charCoords:function(e,t){return lr(this,U(this.doc,e),t||"page")},coordsChar:function(e,t){return e=or(this,e,t||"page"),cr(this,e.left,e.top)},lineAtHeight:function(e,t){return e=or(this,{top:e,left:0},t||"page").top,D(this.doc,e+this.display.viewOffset)},heightAtLine:function(e,t,r){var n,i=!1;if("number"==typeof e){var o=this.doc.first+this.doc.size-1;e<this.doc.first?e=this.doc.first:e>o&&(e=o,i=!0),n=M(this.doc,e)}else n=e;return ir(this,n,{top:0,left:0},t||"page",r||i).top+(i?this.doc.height-ye(n):0)},defaultTextHeight:function(){return mr(this.display)},defaultCharWidth:function(){return yr(this.display)},getViewport:function(){return{from:this.display.viewFrom,to:this.display.viewTo}},addWidget:function(e,t,r,n,i){var o=this.display,l=(e=sr(this,U(this.doc,e))).bottom,s=e.left;if(t.style.position="absolute",t.setAttribute("cm-ignore-events","true"),this.display.input.setUneditable(t),o.sizer.appendChild(t),"over"==n)l=e.top;else if("above"==n||"near"==n){var a=Math.max(o.wrapper.clientHeight,this.doc.height),u=Math.max(o.sizer.clientWidth,o.lineSpace.clientWidth);("above"==n||e.bottom+t.offsetHeight>a)&&e.top>t.offsetHeight?l=e.top-t.offsetHeight:e.bottom+t.offsetHeight<=a&&(l=e.bottom),s+t.offsetWidth>u&&(s=u-t.offsetWidth)}t.style.top=l+"px",t.style.left=t.style.right="","right"==i?(s=o.sizer.clientWidth-t.offsetWidth,t.style.right="0px"):("left"==i?s=0:"middle"==i&&(s=(o.sizer.clientWidth-t.offsetWidth)/2),t.style.left=s+"px"),r&&Ur(this,{left:s,top:l,right:s+t.offsetWidth,bottom:l+t.offsetHeight})},triggerOnKeyDown:pn(Lo),triggerOnKeyPress:pn(Mo),triggerOnKeyUp:To,triggerOnMouseDown:pn(Oo),execCommand:function(e){if(Bs.hasOwnProperty(e))return Bs[e].call(null,this)},triggerElectric:pn(function(e){Zo(this,e)}),findPosH:function(e,t,r,n){var i=this,o=1;t<0&&(o=-1,t=-t);for(var l=U(this.doc,e),s=0;s<t&&!(l=tl(i.doc,l,o,r,n)).hitSide;++s);return l},moveH:pn(function(e,t){var r=this;this.extendSelectionsBy(function(n){return r.display.shift||r.doc.extend||n.empty()?tl(r.doc,n.head,e,t,r.options.rtlMoveVisually):e<0?n.from():n.to()},Vl)}),deleteH:pn(function(e,t){var r=this.doc.sel,n=this.doc;r.somethingSelected()?n.replaceSelection("",null,"+delete"):co(this,function(r){var i=tl(n,r.head,e,t,!1);return e<0?{from:i,to:r.head}:{from:r.head,to:i}})}),findPosV:function(e,t,r,n){var i=this,o=1,l=n;t<0&&(o=-1,t=-t);for(var s=U(this.doc,e),a=0;a<t;++a){var u=sr(i,s,"div");if(null==l?l=u.left:u.left=l,(s=rl(i,u,o,r)).hitSide)break}return s},moveV:pn(function(e,t){var r=this,n=this.doc,i=[],o=!this.display.shift&&!n.extend&&n.sel.somethingSelected();if(n.extendSelectionsBy(function(l){if(o)return e<0?l.from():l.to();var s=sr(r,l.head,"div");null!=l.goalColumn&&(s.left=l.goalColumn),i.push(s.left);var a=rl(r,s,e,t);return"page"==t&&l==n.sel.primary()&&Kr(r,lr(r,a,"div").top-s.top),a},Vl),i.length)for(var l=0;l<n.sel.ranges.length;l++)n.sel.ranges[l].goalColumn=i[l]}),findWordAt:function(e){var t=M(this.doc,e.line).text,r=e.ch,n=e.ch;if(t){var i=this.getHelper(e,"wordChars");"before"!=e.sticky&&n!=t.length||!r?++n:--r;for(var o=t.charAt(r),l=x(o,i)?function(e){return x(e,i)}:/\s/.test(o)?function(e){return/\s/.test(e)}:function(e){return!/\s/.test(e)&&!x(e)};r>0&&l(t.charAt(r-1));)--r;for(;n<t.length&&l(t.charAt(n));)++n}return new Ts(E(e.line,r),E(e.line,n))},toggleOverwrite:function(e){null!=e&&e==this.state.overwrite||((this.state.overwrite=!this.state.overwrite)?s(this.display.cursorDiv,"CodeMirror-overwrite"):Fl(this.display.cursorDiv,"CodeMirror-overwrite"),Te(this,"overwriteToggle",this,this.state.overwrite))},hasFocus:function(){return this.display.input.getField()==l()},isReadOnly:function(){return!(!this.options.readOnly&&!this.doc.cantEdit)},scrollTo:pn(function(e,t){Xr(this,e,t)}),getScrollInfo:function(){var e=this.display.scroller;return{left:e.scrollLeft,top:e.scrollTop,height:e.scrollHeight-zt(this)-this.display.barHeight,width:e.scrollWidth-zt(this)-this.display.barWidth,clientHeight:Bt(this),clientWidth:Rt(this)}},scrollIntoView:pn(function(e,t){null==e?(e={from:this.doc.sel.primary().head,to:null},null==t&&(t=this.options.cursorScrollMargin)):"number"==typeof e?e={from:E(e,0),to:null}:null==e.from&&(e={from:e,to:null}),e.to||(e.to=e.from),e.margin=t||0,null!=e.from.line?Yr(this,e):$r(this,e.from,e.to,e.margin)}),setSize:pn(function(e,t){var r=this,n=function(e){return"number"==typeof e||/^\d+$/.test(String(e))?e+"px":e};null!=e&&(this.display.wrapper.style.width=n(e)),null!=t&&(this.display.wrapper.style.height=n(t)),this.options.lineWrapping&&Jt(this);var i=this.display.viewFrom;this.doc.iter(i,this.display.viewTo,function(e){if(e.widgets)for(var t=0;t<e.widgets.length;t++)if(e.widgets[t].noHScroll){mn(r,i,"widget");break}++i}),this.curOp.forceUpdate=!0,Te(this,"refresh",this)}),operation:function(e){return hn(this,e)},startOperation:function(){return nn(this)},endOperation:function(){return on(this)},refresh:pn(function(){var e=this.display.cachedTextHeight;vn(this),this.curOp.forceUpdate=!0,er(this),Xr(this,this.doc.scrollLeft,this.doc.scrollTop),Wn(this),(null==e||Math.abs(e-mr(this.display))>.5)&&Cr(this),Te(this,"refresh",this)}),swapDoc:pn(function(e){var t=this.doc;return t.cm=null,qn(this,e),er(this),this.display.input.reset(),Xr(this,e.scrollLeft,e.scrollTop),this.curOp.forceScroll=!0,bt(this,"swapDoc",this,t),t}),getInputField:function(){return this.display.input.getField()},getWrapperElement:function(){return this.display.wrapper},getScrollerElement:function(){return this.display.scroller},getGutterElement:function(){return this.display.gutters}},Ae(e),e.registerHelper=function(t,n,i){r.hasOwnProperty(t)||(r[t]=e[t]={_global:[]}),r[t][n]=i},e.registerGlobalHelper=function(t,n,i,o){e.registerHelper(t,n,o),r[t]._global.push({pred:i,val:o})}}(jo);var Js="iter insert remove copy getEditor constructor".split(" ");for(var ea in Ds.prototype)Ds.prototype.hasOwnProperty(ea)&&h(Js,ea)<0&&(jo.prototype[ea]=function(e){return function(){return e.apply(this.doc,arguments)}}(Ds.prototype[ea]));return Ae(Ds),jo.inputStyles={textarea:Qs,contenteditable:Zs},jo.defineMode=function(e){jo.defaults.mode||"null"==e||(jo.defaults.mode=e),Be.apply(this,arguments)},jo.defineMIME=function(e,t){os[e]=t},jo.defineMode("null",function(){return{token:function(e){return e.skipToEnd()}}}),jo.defineMIME("text/plain","null"),jo.defineExtension=function(e,t){jo.prototype[e]=t},jo.defineDocExtension=function(e,t){Ds.prototype[e]=t},jo.fromTextArea=function(e,t){function r(){e.value=a.getValue()}if(t=t?c(t):{},t.value=e.value,!t.tabindex&&e.tabIndex&&(t.tabindex=e.tabIndex),!t.placeholder&&e.placeholder&&(t.placeholder=e.placeholder),null==t.autofocus){var n=l();t.autofocus=n==e||null!=e.getAttribute("autofocus")&&n==document.body}var i;if(e.form&&(Ql(e.form,"submit",r),!t.leaveSubmitMethodAlone)){var o=e.form;i=o.submit;try{var s=o.submit=function(){r(),o.submit=i,o.submit(),o.submit=s}}catch(e){}}t.finishInit=function(t){t.save=r,t.getTextArea=function(){return e},t.toTextArea=function(){t.toTextArea=isNaN,r(),e.parentNode.removeChild(t.getWrapperElement()),e.style.display="",e.form&&(ke(e.form,"submit",r),"function"==typeof e.form.submit&&(e.form.submit=i))}},e.style.display="none";var a=jo(function(t){return e.parentNode.insertBefore(t,e.nextSibling)},t);return a},function(e){e.off=ke,e.on=Ql,e.wheelEventPixels=Pn,e.Doc=Ds,e.splitLines=es,e.countColumn=f,e.findColumn=d,e.isWordChar=w,e.Pass=Bl,e.signal=Te,e.Line=fs,e.changeEnd=Bn,e.scrollbarModel=ws,e.Pos=E,e.cmpPos=P,e.modes=is,e.mimeModes=os,e.resolveMode=Ge,e.getMode=Ue,e.modeExtensions=ls,e.extendMode=Ve,e.copyState=Ke,e.startState=Xe,e.innerMode=je,e.commands=Bs,e.keyMap=Rs,e.keyName=ao,e.isModifierKey=lo,e.lookupKey=oo,e.normalizeKeyMap=io,e.StringStream=ss,e.SharedTextMarker=As,e.TextMarker=Os,e.LineWidget=Ms,e.e_preventDefault=We,e.e_stopPropagation=De,e.e_stop=Fe,e.addClass=s,e.contains=o,e.rmClass=Fl,e.keyNames=Es}(jo),jo.version="5.30.0",jo});
      !function(e){"object"==typeof exports&&"object"==typeof module?e(require("../../lib/codemirror")):"function"==typeof define&&define.amd?define(["../../lib/codemirror"],e):e(CodeMirror)}(function(e){"use strict";function t(e,t,n,r,o,a){this.indented=e,this.column=t,this.type=n,this.info=r,this.align=o,this.prev=a}function n(e,n,r,o){var a=e.indented;return e.context&&"statement"==e.context.type&&"statement"!=r&&(a=e.context.indented),e.context=new t(a,n,r,o,null,e.context)}function r(e){var t=e.context.type;return")"!=t&&"]"!=t&&"}"!=t||(e.indented=e.context.indented),e.context=e.context.prev}function o(e,t,n){return"variable"==t.prevToken||"type"==t.prevToken||(!!/\S(?:[^- ]>|[*\]])\s*$|\*$/.test(e.string.slice(0,n))||(!(!t.typeAtEndOfLine||e.column()!=e.indentation())||void 0))}function a(e){for(;;){if(!e||"top"==e.type)return!0;if("}"==e.type&&"namespace"!=e.prev.info)return!1;e=e.prev}}function i(e){for(var t={},n=e.split(" "),r=0;r<n.length;++r)t[n[r]]=!0;return t}function l(e,t){return"function"==typeof e?e(t):e.propertyIsEnumerable(t)}function s(e,t){if(!t.startOfLine)return!1;for(var n,r=null;n=e.peek();){if("\\"==n&&e.match(/^.$/)){r=s;break}if("/"==n&&e.match(/^\/[\/\*]/,!1))break;e.next()}return t.tokenize=r,"meta"}function c(e,t){return"type"==t.prevToken&&"type"}function u(e){return e.eatWhile(/[\w\.']/),"number"}function d(e,t){if(e.backUp(1),e.match(/(R|u8R|uR|UR|LR)/)){var n=e.match(/"([^\s\\()]{0,16})\(/);return!!n&&(t.cpp11RawStringDelim=n[1],t.tokenize=m,m(e,t))}return e.match(/(u8|u|U|L)/)?!!e.match(/["']/,!1)&&"string":(e.next(),!1)}function f(e){var t=/(\w+)::~?(\w+)$/.exec(e);return t&&t[1]==t[2]}function p(e,t){for(var n;null!=(n=e.next());)if('"'==n&&!e.eat('"')){t.tokenize=null;break}return"string"}function m(e,t){var n=t.cpp11RawStringDelim.replace(/[^\w\s]/g,"\\$&");return e.match(new RegExp(".*?\\)"+n+'"'))?t.tokenize=null:e.skipToEnd(),"string"}function h(t,n){function r(e){if(e)for(var t in e)e.hasOwnProperty(t)&&o.push(t)}"string"==typeof t&&(t=[t]);var o=[];r(n.keywords),r(n.types),r(n.builtin),r(n.atoms),o.length&&(n.helperType=t[0],e.registerHelper("hintWords",t[0],o));for(var a=0;a<t.length;++a)e.defineMIME(t[a],n)}function g(e,t){for(var n=!1;!e.eol();){if(!n&&e.match('"""')){t.tokenize=null;break}n="\\"==e.next()&&!n}return"string"}function y(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!e&&!o&&t.match('"')){a=!0;break}if(e&&t.match('"""')){a=!0;break}r=t.next(),!o&&"$"==r&&t.match("{")&&t.skipTo("}"),o=!o&&"\\"==r&&!e}return!a&&e||(n.tokenize=null),"string"}}function x(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!o&&t.match('"')&&("single"==e||t.match('""'))){a=!0;break}if(!o&&t.match("``")){w=x(e),a=!0;break}r=t.next(),o="single"==e&&!o&&"\\"==r}return a&&(n.tokenize=null),"string"}}e.defineMode("clike",function(i,s){function c(e,t){var n=e.next();if(S[n]){var r=S[n](e,t);if(!1!==r)return r}if('"'==n||"'"==n)return t.tokenize=u(n),t.tokenize(e,t);if(D.test(n))return p=n,null;if(L.test(n)){if(e.backUp(1),e.match(I))return"number";e.next()}if("/"==n){if(e.eat("*"))return t.tokenize=d,d(e,t);if(e.eat("/"))return e.skipToEnd(),"comment"}if(F.test(n)){for(;!e.match(/^\/[\/*]/,!1)&&e.eat(F););return"operator"}if(e.eatWhile(z),P)for(;e.match(P);)e.eatWhile(z);var o=e.current();return l(x,o)?(l(w,o)&&(p="newstatement"),l(v,o)&&(m=!0),"keyword"):l(b,o)?"type":l(k,o)?(l(w,o)&&(p="newstatement"),"builtin"):l(_,o)?"atom":"variable"}function u(e){return function(t,n){for(var r,o=!1,a=!1;null!=(r=t.next());){if(r==e&&!o){a=!0;break}o=!o&&"\\"==r}return(a||!o&&!C)&&(n.tokenize=null),"string"}}function d(e,t){for(var n,r=!1;n=e.next();){if("/"==n&&r){t.tokenize=null;break}r="*"==n}return"comment"}function f(e,t){s.typeFirstDefinitions&&e.eol()&&a(t.context)&&(t.typeAtEndOfLine=o(e,t,e.pos))}var p,m,h=i.indentUnit,g=s.statementIndentUnit||h,y=s.dontAlignCalls,x=s.keywords||{},b=s.types||{},k=s.builtin||{},w=s.blockKeywords||{},v=s.defKeywords||{},_=s.atoms||{},S=s.hooks||{},C=s.multiLineStrings,T=!1!==s.indentStatements,M=!1!==s.indentSwitch,P=s.namespaceSeparator,D=s.isPunctuationChar||/[\[\]{}\(\),;\:\.]/,L=s.numberStart||/[\d\.]/,I=s.number||/^(?:0x[a-f\d]+|0b[01]+|(?:\d+\.?\d*|\.\d+)(?:e[-+]?\d+)?)(u|ll?|l|f)?/i,F=s.isOperatorChar||/[+\-*&%=<>!?|\/]/,z=s.isIdentifierChar||/[\w\$_\xa1-\uffff]/;return{startState:function(e){return{tokenize:null,context:new t((e||0)-h,0,"top",null,!1),indented:0,startOfLine:!0,prevToken:null}},token:function(e,t){var i=t.context;if(e.sol()&&(null==i.align&&(i.align=!1),t.indented=e.indentation(),t.startOfLine=!0),e.eatSpace())return f(e,t),null;p=m=null;var l=(t.tokenize||c)(e,t);if("comment"==l||"meta"==l)return l;if(null==i.align&&(i.align=!0),";"==p||":"==p||","==p&&e.match(/^\s*(?:\/\/.*)?$/,!1))for(;"statement"==t.context.type;)r(t);else if("{"==p)n(t,e.column(),"}");else if("["==p)n(t,e.column(),"]");else if("("==p)n(t,e.column(),")");else if("}"==p){for(;"statement"==i.type;)i=r(t);for("}"==i.type&&(i=r(t));"statement"==i.type;)i=r(t)}else p==i.type?r(t):T&&(("}"==i.type||"top"==i.type)&&";"!=p||"statement"==i.type&&"newstatement"==p)&&n(t,e.column(),"statement",e.current());if("variable"==l&&("def"==t.prevToken||s.typeFirstDefinitions&&o(e,t,e.start)&&a(t.context)&&e.match(/^\s*\(/,!1))&&(l="def"),S.token){var u=S.token(e,t,l);void 0!==u&&(l=u)}return"def"==l&&!1===s.styleDefs&&(l="variable"),t.startOfLine=!1,t.prevToken=m?"def":l||p,f(e,t),l},indent:function(t,n){if(t.tokenize!=c&&null!=t.tokenize||t.typeAtEndOfLine)return e.Pass;var r=t.context,o=n&&n.charAt(0);if("statement"==r.type&&"}"==o&&(r=r.prev),s.dontIndentStatements)for(;"statement"==r.type&&s.dontIndentStatements.test(r.info);)r=r.prev;if(S.indent){var a=S.indent(t,r,n);if("number"==typeof a)return a}var i=o==r.type,l=r.prev&&"switch"==r.prev.info;if(s.allmanIndentation&&/[{(]/.test(o)){for(;"top"!=r.type&&"}"!=r.type;)r=r.prev;return r.indented}return"statement"==r.type?r.indented+("{"==o?0:g):!r.align||y&&")"==r.type?")"!=r.type||i?r.indented+(i?0:h)+(i||!l||/^(?:case|default)\b/.test(n)?0:h):r.indented+g:r.column+(i?0:1)},electricInput:M?/^\s*(?:case .*?:|default:|\{\}?|\})$/:/^\s*[{}]$/,blockCommentStart:"/*",blockCommentEnd:"*/",lineComment:"//",fold:"brace"}});var b="auto if break case register continue return default do sizeof static else struct switch extern typedef union for goto while enum const volatile",k="int long char short double float unsigned signed void size_t ptrdiff_t";h(["text/x-csrc","text/x-c","text/x-chdr"],{name:"clike",keywords:i(b),types:i(k+" bool _Complex _Bool float_t double_t intptr_t intmax_t int8_t int16_t int32_t int64_t uintptr_t uintmax_t uint8_t uint16_t uint32_t uint64_t"),blockKeywords:i("case do else for if switch while struct"),defKeywords:i("struct"),typeFirstDefinitions:!0,atoms:i("null true false"),hooks:{"#":s,"*":c},modeProps:{fold:["brace","include"]}}),h(["text/x-c++src","text/x-c++hdr"],{name:"clike",keywords:i(b+" asm dynamic_cast namespace reinterpret_cast try explicit new static_cast typeid catch operator template typename class friend private this using const_cast inline public throw virtual delete mutable protected alignas alignof constexpr decltype nullptr noexcept thread_local final static_assert override"),types:i(k+" bool wchar_t"),blockKeywords:i("catch class do else finally for if struct switch try while"),defKeywords:i("class namespace struct enum union"),typeFirstDefinitions:!0,atoms:i("true false null"),dontIndentStatements:/^template$/,isIdentifierChar:/[\w\$_~\xa1-\uffff]/,hooks:{"#":s,"*":c,u:d,U:d,L:d,R:d,0:u,1:u,2:u,3:u,4:u,5:u,6:u,7:u,8:u,9:u,token:function(e,t,n){if("variable"==n&&"("==e.peek()&&(";"==t.prevToken||null==t.prevToken||"}"==t.prevToken)&&f(e.current()))return"def"}},namespaceSeparator:"::",modeProps:{fold:["brace","include"]}}),h("text/x-java",{name:"clike",keywords:i("abstract assert break case catch class const continue default do else enum extends final finally float for goto if implements import instanceof interface native new package private protected public return static strictfp super switch synchronized this throw throws transient try volatile while @interface"),types:i("byte short int long float double boolean char void Boolean Byte Character Double Float Integer Long Number Object Short String StringBuffer StringBuilder Void"),blockKeywords:i("catch class do else finally for if switch try while"),defKeywords:i("class interface package enum @interface"),typeFirstDefinitions:!0,atoms:i("true false null"),number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,hooks:{"@":function(e){return!e.match("interface",!1)&&(e.eatWhile(/[\w\$_]/),"meta")}},modeProps:{fold:["brace","import"]}}),h("text/x-csharp",{name:"clike",keywords:i("abstract as async await base break case catch checked class const continue default delegate do else enum event explicit extern finally fixed for foreach goto if implicit in interface internal is lock namespace new operator out override params private protected public readonly ref return sealed sizeof stackalloc static struct switch this throw try typeof unchecked unsafe using virtual void volatile while add alias ascending descending dynamic from get global group into join let orderby partial remove select set value var yield"),types:i("Action Boolean Byte Char DateTime DateTimeOffset Decimal Double Func Guid Int16 Int32 Int64 Object SByte Single String Task TimeSpan UInt16 UInt32 UInt64 bool byte char decimal double short int long object sbyte float string ushort uint ulong"),blockKeywords:i("catch class do else finally for foreach if struct switch try while"),defKeywords:i("class interface namespace struct var"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"@":function(e,t){return e.eat('"')?(t.tokenize=p,p(e,t)):(e.eatWhile(/[\w\$_]/),"meta")}}}),h("text/x-scala",{name:"clike",keywords:i("abstract case catch class def do else extends final finally for forSome if implicit import lazy match new null object override package private protected return sealed super this throw trait try type val var while with yield _ assert assume require print println printf readLine readBoolean readByte readShort readChar readInt readLong readFloat readDouble"),types:i("AnyVal App Application Array BufferedIterator BigDecimal BigInt Char Console Either Enumeration Equiv Error Exception Fractional Function IndexedSeq Int Integral Iterable Iterator List Map Numeric Nil NotNull Option Ordered Ordering PartialFunction PartialOrdering Product Proxy Range Responder Seq Serializable Set Specializable Stream StringBuilder StringContext Symbol Throwable Traversable TraversableOnce Tuple Unit Vector Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),multiLineStrings:!0,blockKeywords:i("catch class enum do else finally for forSome if match switch try while"),defKeywords:i("class enum def object package trait type val var"),atoms:i("true false null"),indentStatements:!1,indentSwitch:!1,isOperatorChar:/[+\-*&%=<>!?|\/#:@]/,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return!!e.match('""')&&(t.tokenize=g,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},"=":function(e,n){var r=n.context;return!("}"!=r.type||!r.align||!e.eat(">"))&&(n.context=new t(r.indented,r.column,r.type,r.info,null,r.prev),"operator")}},modeProps:{closeBrackets:{triples:'"'}}}),h("text/x-kotlin",{name:"clike",keywords:i("package as typealias class interface this super val var fun for is in This throw return break continue object if else while do try when !in !is as? file import where by get set abstract enum open inner override private public internal protected catch finally out final vararg reified dynamic companion constructor init sealed field property receiver param sparam lateinit data inline noinline tailrec external annotation crossinline const operator infix suspend"),types:i("Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),intendSwitch:!1,indentStatements:!1,multiLineStrings:!0,number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,blockKeywords:i("catch class do else finally for if where try while enum"),defKeywords:i("class val var object package interface fun"),atoms:i("true false null this"),hooks:{'"':function(e,t){return t.tokenize=y(e.match('""')),t.tokenize(e,t)}},modeProps:{closeBrackets:{triples:'"'}}}),h(["x-shader/x-vertex","x-shader/x-fragment"],{name:"clike",keywords:i("sampler1D sampler2D sampler3D samplerCube sampler1DShadow sampler2DShadow const attribute uniform varying break continue discard return for while do if else struct in out inout"),types:i("float int bool void vec2 vec3 vec4 ivec2 ivec3 ivec4 bvec2 bvec3 bvec4 mat2 mat3 mat4"),blockKeywords:i("for while do if else struct"),builtin:i("radians degrees sin cos tan asin acos atan pow exp log exp2 sqrt inversesqrt abs sign floor ceil fract mod min max clamp mix step smoothstep length distance dot cross normalize ftransform faceforward reflect refract matrixCompMult lessThan lessThanEqual greaterThan greaterThanEqual equal notEqual any all not texture1D texture1DProj texture1DLod texture1DProjLod texture2D texture2DProj texture2DLod texture2DProjLod texture3D texture3DProj texture3DLod texture3DProjLod textureCube textureCubeLod shadow1D shadow2D shadow1DProj shadow2DProj shadow1DLod shadow2DLod shadow1DProjLod shadow2DProjLod dFdx dFdy fwidth noise1 noise2 noise3 noise4"),atoms:i("true false gl_FragColor gl_SecondaryColor gl_Normal gl_Vertex gl_MultiTexCoord0 gl_MultiTexCoord1 gl_MultiTexCoord2 gl_MultiTexCoord3 gl_MultiTexCoord4 gl_MultiTexCoord5 gl_MultiTexCoord6 gl_MultiTexCoord7 gl_FogCoord gl_PointCoord gl_Position gl_PointSize gl_ClipVertex gl_FrontColor gl_BackColor gl_FrontSecondaryColor gl_BackSecondaryColor gl_TexCoord gl_FogFragCoord gl_FragCoord gl_FrontFacing gl_FragData gl_FragDepth gl_ModelViewMatrix gl_ProjectionMatrix gl_ModelViewProjectionMatrix gl_TextureMatrix gl_NormalMatrix gl_ModelViewMatrixInverse gl_ProjectionMatrixInverse gl_ModelViewProjectionMatrixInverse gl_TexureMatrixTranspose gl_ModelViewMatrixInverseTranspose gl_ProjectionMatrixInverseTranspose gl_ModelViewProjectionMatrixInverseTranspose gl_TextureMatrixInverseTranspose gl_NormalScale gl_DepthRange gl_ClipPlane gl_Point gl_FrontMaterial gl_BackMaterial gl_LightSource gl_LightModel gl_FrontLightModelProduct gl_BackLightModelProduct gl_TextureColor gl_EyePlaneS gl_EyePlaneT gl_EyePlaneR gl_EyePlaneQ gl_FogParameters gl_MaxLights gl_MaxClipPlanes gl_MaxTextureUnits gl_MaxTextureCoords gl_MaxVertexAttribs gl_MaxVertexUniformComponents gl_MaxVaryingFloats gl_MaxVertexTextureImageUnits gl_MaxTextureImageUnits gl_MaxFragmentUniformComponents gl_MaxCombineTextureImageUnits gl_MaxDrawBuffers"),indentSwitch:!1,hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-nesc",{name:"clike",keywords:i(b+"as atomic async call command component components configuration event generic implementation includes interface module new norace nx_struct nx_union post provides signal task uses abstract extends"),types:i(k),blockKeywords:i("case do else for if switch while struct"),atoms:i("null true false"),hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-objectivec",{name:"clike",keywords:i(b+"inline restrict _Bool _Complex _Imaginary BOOL Class bycopy byref id IMP in inout nil oneway out Protocol SEL self super atomic nonatomic retain copy readwrite readonly"),types:i(k),atoms:i("YES NO NULL NILL ON OFF true false"),hooks:{"@":function(e){return e.eatWhile(/[\w\$]/),"keyword"},"#":s,indent:function(e,t,n){if("statement"==t.type&&/^@\w/.test(n))return t.indented}},modeProps:{fold:"brace"}}),h("text/x-squirrel",{name:"clike",keywords:i("base break clone continue const default delete enum extends function in class foreach local resume return this throw typeof yield constructor instanceof static"),types:i(k),blockKeywords:i("case catch class else for foreach if switch try while"),defKeywords:i("function local class"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"#":s},modeProps:{fold:["brace","include"]}});var w=null;h("text/x-ceylon",{name:"clike",keywords:i("abstracts alias assembly assert assign break case catch class continue dynamic else exists extends finally for function given if import in interface is let module new nonempty object of out outer package return satisfies super switch then this throw try value void while"),types:function(e){var t=e.charAt(0);return t===t.toUpperCase()&&t!==t.toLowerCase()},blockKeywords:i("case catch class dynamic else finally for function if interface module new object switch try while"),defKeywords:i("class dynamic function interface module object package value"),builtin:i("abstract actual aliased annotation by default deprecated doc final formal late license native optional sealed see serializable shared suppressWarnings tagged throws variable"),isPunctuationChar:/[\[\]{}\(\),;\:\.`]/,isOperatorChar:/[+\-*&%=<>!?|^~:\/]/,numberStart:/[\d#$]/,number:/^(?:#[\da-fA-F_]+|\$[01_]+|[\d_]+[kMGTPmunpf]?|[\d_]+\.[\d_]+(?:[eE][-+]?\d+|[kMGTPmunpf]|)|)/i,multiLineStrings:!0,typeFirstDefinitions:!0,atoms:i("true false null larger smaller equal empty finished"),indentSwitch:!1,styleDefs:!1,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return t.tokenize=x(e.match('""')?"triple":"single"),t.tokenize(e,t)},"`":function(e,t){return!(!w||!e.match("`"))&&(t.tokenize=w,w=null,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},token:function(e,t,n){if(("variable"==n||"type"==n)&&"."==t.prevToken)return"variable-2"}},modeProps:{fold:["brace","import"],closeBrackets:{triples:'"'}}})});
      // -------------------------------------------------------------------------
//  Part of the CodeChecker project, under the Apache License v2.0 with
//  LLVM Exceptions. See LICENSE for license information.
//  SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
// -------------------------------------------------------------------------

var BugViewer = {
  _files : [],
  _reports : [],
  _lineWidgets : [],
  _navigationMenuItems : [],
  _sourceFileData : null,
  _currentReport : null,
  _lastBugEvent  : null,

  init : function (files, reports) {
    this._files = files;
    this._reports = reports;

    this.initEscapeChars();
  },

  initEscapeChars : function () {
    this.escapeChars = {
      ' ' : 'nbsp',
      '<' : 'lt',
      '>' : 'gt',
      '"' : 'quot',
      '&' : 'amp'
    };

    var regexString = '[';
    for (var key in this.escapeChars) {
      regexString += key;
    }
    regexString += ']';

    this.escapeRegExp = new RegExp( regexString, 'g');
  },

  escapeHTML : function (str) {
    var that = this;

    return str.replace(this.escapeRegExp, function (m) {
      return '&' + that.escapeChars[m] + ';';
    });
  },

  initByUrl : function () {
    if (!this._reports) return;

    var state = {};
    window.location.hash.substr(1).split('&').forEach(function (s) {
      var parts = s.split('=');
      state[parts[0]] = parts[1];
    });

    for (var key in this._reports) {
      var report = this._reports[key];
      if (report.reportHash === state['reportHash']) {
        this.navigate(report);
        return;
      }
    }

    this.navigate(this._reports[0]);
  },

  create : function () {
    this._content = document.getElementById('editor-wrapper');
    this._filepath = document.getElementById('file-path');
    this._checkerName = document.getElementById('checker-name');
    this._reviewStatusWrapper =
      document.getElementById('review-status-wrapper');
    this._reviewStatus = document.getElementById('review-status');
    this._editor = document.getElementById('editor');

    this._codeMirror = CodeMirror(this._editor, {
      mode: 'text/x-c++src',
      matchBrackets : true,
      lineNumbers : true,
      readOnly : true,
      foldGutter : true,
      extraKeys : {},
      viewportMargin : 100
    });

    this._createNavigationMenu();
  },

  navigate : function (report, item) {
    if (!item) {
      var items = this._navigationMenuItems.filter(function (navItem) {
        return navItem.report.reportHash === report.reportHash;
      });

      if (!items.length) return;

      item = items[0].widget;
    }

    this._selectedReport.classList.remove('active');
    this._selectedReport = item;
    this._selectedReport.classList.add('active');
    this.setReport(report);
  },

  _createNavigationMenu : function () {
    var that = this;

    var nav = document.getElementById('report-nav');
    var list = document.createElement('ul');
    this._reports.forEach(function (report) {
      var events = report['events'];
      var lastBugEvent = events[events.length - 1];
      var item = document.createElement('li');

      var severity = document.createElement('i');
      severity.className = 'severity-' + report.severity.toLowerCase();

      item.appendChild(severity);
      item.appendChild(document.createTextNode(lastBugEvent.message));

      item.addEventListener('click', function () {
        that.navigate(report, item);
      })
      list.appendChild(item);
      that._navigationMenuItems.push({ report : report, widget : item });
    });

    if (!this._selectedReport && list.childNodes.length) {
      this._selectedReport = list.childNodes[0];
      this._selectedReport.classList.add('active');
    }

    nav.appendChild(list);
  },

  setReport : function (report) {
    this._currentReport = report;
    var events = report['events'];
    var lastBugEvent = events[events.length - 1];
    this.setCurrentBugEvent(lastBugEvent, events.length - 1);
    this.setCheckerName(report.checkerName);
    this.setReviewStatus(report.reviewStatus);

    window.location.hash = '#reportHash=' + report.reportHash;
  },

  setCurrentBugEvent : function (event, idx) {
    this._currentBugEvent = event;
    this.setSourceFileData(this._files[event.location.file]);
    this.drawBugPath();

    this.jumpTo(event.location.line, 0);
    this.highlightBugEvent(event, idx);
  },

  highlightBugEvent : function (event, idx) {
    this._lineWidgets.forEach(function (widget) {
      var lineIdx = widget.node.getAttribute('idx');
      if (parseInt(lineIdx) === idx) {
        widget.node.classList.add('current');
      }
    });
  },

  setCheckerName : function (checkerName) {
    this._checkerName.innerHTML = checkerName;
  },

  setReviewStatus : function (status) {
    if (status) {
      var className =
        'review-status-' + status.toLowerCase().split(' ').join('-');
      this._reviewStatus.className = "review-status " + className;

      this._reviewStatus.innerHTML = status;
      this._reviewStatusWrapper.style.display = 'block';
    } else {
      this._reviewStatusWrapper.style.display = 'none';
    }
  },

  setSourceFileData : function (file) {
    if (this._sourceFileData && file.id === this._sourceFileData.id) {
      return;
    }

    this._sourceFileData = file;
    this._filepath.innerHTML = file.path;
    this._codeMirror.doc.setValue(file.content);
    this._refresh();
  },

  _refresh : function () {
    var that = this;
    setTimeout(function () {
      var fullHeight = parseInt(that._content.clientHeight);
      var headerHeight = that._filepath.clientHeight;

      that._codeMirror.setSize('auto', fullHeight - headerHeight);
      that._codeMirror.refresh();
    }, 200);
  },

  clearBubbles : function () {
    this._lineWidgets.forEach(function (widget) { widget.clear(); });
    this._lineWidgets = [];
  },

  getMessage : function (event, kind) {
    if (kind === 'macro') {
      var name = 'macro expansion' + (event.name ? ': ' + event.name : '');

      return '<span class="tag macro">' + name + '</span>'
        + this.escapeHTML(event.expansion).replace(/(?:\r\n|\r|\n)/g, '<br>');
    } else if (kind === 'note') {
      return '<span class="tag note">note</span>'
        +  this.escapeHTML(event.message).replace(/(?:\r\n|\r|\n)/g, '<br>');
    }
  },

  addExtraPathEvents : function (events, kind) {
    var that = this;

    if (!events) {
      return;
    }

    events.forEach(function (event) {
      if (event.location.file !== that._currentBugEvent.location.file) {
        return;
      }

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + kind);

      var msg = document.createElement('span');
      msg.innerHTML = that.getMessage(event, kind);
      element.appendChild(msg);

      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  drawBugPath : function () {
    var that = this;

    this.clearBubbles();

    this.addExtraPathEvents(this._currentReport.macros, 'macro');
    this.addExtraPathEvents(this._currentReport.notes, 'note');

    // Processing bug path events.
    var currentEvents = this._currentReport.events;
    currentEvents.forEach(function (event, step) {
      if (event.location.file !== that._currentBugEvent.location.file)
        return;

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';
      var type = step === currentEvents.length - 1 ? 'error' : 'info';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + type);
      element.setAttribute('idx', step);

      var enumeration = document.createElement('span');
      enumeration.setAttribute('class', 'checker-enum ' + type);
      enumeration.innerHTML = step + 1;

      if (currentEvents.length > 1)
        element.appendChild(enumeration);

      var prevBugEvent = step - 1;
      if (step > 0) {
        var prevBug = document.createElement('span');
        prevBug.setAttribute('class', 'arrow left-arrow');
        prevBug.addEventListener('click', function () {
          var event = currentEvents[prevBugEvent];
          that.setCurrentBugEvent(event, prevBugEvent);
        });
        element.appendChild(prevBug);
      }

      var msg = document.createElement('span');
      msg.innerHTML = that.escapeHTML(event.message)
        .replace(/(?:\r\n|\r|\n)/g, '<br>');

      element.appendChild(msg);

      var nextBugEvent = step + 1;
      if (nextBugEvent < currentEvents.length) {
        var nextBug = document.createElement('span');
        nextBug.setAttribute('class', 'arrow right-arrow');
        nextBug.addEventListener('click', function () {
          var event = currentEvents[nextBugEvent];
          that.setCurrentBugEvent(event, nextBugEvent);
        });
        element.appendChild(nextBug);
      }


      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  jumpTo : function (line, column) {
    var that = this;

    setTimeout(function () {
      var selPosPixel
        = that._codeMirror.charCoords({ line : line, ch : column }, 'local');
      var editorSize = {
        width  : that._editor.clientWidth,
        height : that._editor.clientHeight
      };

      that._codeMirror.scrollIntoView({
        top    : selPosPixel.top - 100,
        bottom : selPosPixel.top + editorSize.height - 150,
        left   : selPosPixel.left < editorSize.width - 100
               ? 0
               : selPosPixel.left - 50,
        right  : selPosPixel.left < editorSize.width - 100
               ? 10
               : selPosPixel.left + editorSize.width - 100
      });
    }, 0);
  }
}


      var data = {"files": {"0": {"id": 0, "path": "/src/drivers/net/ethernet/broadcom/bnxt/bnxt.c", "content": "/* Broadcom NetXtreme-C/E network driver.\n *\n * Copyright (c) 2014-2016 Broadcom Corporation\n * Copyright (c) 2016-2019 Broadcom Limited\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation.\n */\n\n#include <linux/module.h>\n\n#include <linux/stringify.h>\n#include <linux/kernel.h>\n#include <linux/timer.h>\n#include <linux/errno.h>\n#include <linux/ioport.h>\n#include <linux/slab.h>\n#include <linux/vmalloc.h>\n#include <linux/interrupt.h>\n#include <linux/pci.h>\n#include <linux/netdevice.h>\n#include <linux/etherdevice.h>\n#include <linux/skbuff.h>\n#include <linux/dma-mapping.h>\n#include <linux/bitops.h>\n#include <linux/io.h>\n#include <linux/irq.h>\n#include <linux/delay.h>\n#include <asm/byteorder.h>\n#include <asm/page.h>\n#include <linux/time.h>\n#include <linux/mii.h>\n#include <linux/mdio.h>\n#include <linux/if.h>\n#include <linux/if_vlan.h>\n#include <linux/if_bridge.h>\n#include <linux/rtc.h>\n#include <linux/bpf.h>\n#include <net/ip.h>\n#include <net/tcp.h>\n#include <net/udp.h>\n#include <net/checksum.h>\n#include <net/ip6_checksum.h>\n#include <net/udp_tunnel.h>\n#include <linux/workqueue.h>\n#include <linux/prefetch.h>\n#include <linux/cache.h>\n#include <linux/log2.h>\n#include <linux/aer.h>\n#include <linux/bitmap.h>\n#include <linux/cpu_rmap.h>\n#include <linux/cpumask.h>\n#include <net/pkt_cls.h>\n#include <linux/hwmon.h>\n#include <linux/hwmon-sysfs.h>\n#include <net/page_pool.h>\n\n#include \"bnxt_hsi.h\"\n#include \"bnxt.h\"\n#include \"bnxt_ulp.h\"\n#include \"bnxt_sriov.h\"\n#include \"bnxt_ethtool.h\"\n#include \"bnxt_dcb.h\"\n#include \"bnxt_xdp.h\"\n#include \"bnxt_vfr.h\"\n#include \"bnxt_tc.h\"\n#include \"bnxt_devlink.h\"\n#include \"bnxt_debugfs.h\"\n\n#define BNXT_TX_TIMEOUT\t\t(5 * HZ)\n#define BNXT_DEF_MSG_ENABLE\t(NETIF_MSG_DRV | NETIF_MSG_HW)\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Broadcom BCM573xx network driver\");\n\n#define BNXT_RX_OFFSET (NET_SKB_PAD + NET_IP_ALIGN)\n#define BNXT_RX_DMA_OFFSET NET_SKB_PAD\n#define BNXT_RX_COPY_THRESH 256\n\n#define BNXT_TX_PUSH_THRESH 164\n\nenum board_idx {\n\tBCM57301,\n\tBCM57302,\n\tBCM57304,\n\tBCM57417_NPAR,\n\tBCM58700,\n\tBCM57311,\n\tBCM57312,\n\tBCM57402,\n\tBCM57404,\n\tBCM57406,\n\tBCM57402_NPAR,\n\tBCM57407,\n\tBCM57412,\n\tBCM57414,\n\tBCM57416,\n\tBCM57417,\n\tBCM57412_NPAR,\n\tBCM57314,\n\tBCM57417_SFP,\n\tBCM57416_SFP,\n\tBCM57404_NPAR,\n\tBCM57406_NPAR,\n\tBCM57407_SFP,\n\tBCM57407_NPAR,\n\tBCM57414_NPAR,\n\tBCM57416_NPAR,\n\tBCM57452,\n\tBCM57454,\n\tBCM5745x_NPAR,\n\tBCM57508,\n\tBCM57504,\n\tBCM57502,\n\tBCM57508_NPAR,\n\tBCM57504_NPAR,\n\tBCM57502_NPAR,\n\tBCM58802,\n\tBCM58804,\n\tBCM58808,\n\tNETXTREME_E_VF,\n\tNETXTREME_C_VF,\n\tNETXTREME_S_VF,\n\tNETXTREME_E_P5_VF,\n};\n\n/* indexed by enum above */\nstatic const struct {\n\tchar *name;\n} board_info[] = {\n\t[BCM57301] = { \"Broadcom BCM57301 NetXtreme-C 10Gb Ethernet\" },\n\t[BCM57302] = { \"Broadcom BCM57302 NetXtreme-C 10Gb/25Gb Ethernet\" },\n\t[BCM57304] = { \"Broadcom BCM57304 NetXtreme-C 10Gb/25Gb/40Gb/50Gb Ethernet\" },\n\t[BCM57417_NPAR] = { \"Broadcom BCM57417 NetXtreme-E Ethernet Partition\" },\n\t[BCM58700] = { \"Broadcom BCM58700 Nitro 1Gb/2.5Gb/10Gb Ethernet\" },\n\t[BCM57311] = { \"Broadcom BCM57311 NetXtreme-C 10Gb Ethernet\" },\n\t[BCM57312] = { \"Broadcom BCM57312 NetXtreme-C 10Gb/25Gb Ethernet\" },\n\t[BCM57402] = { \"Broadcom BCM57402 NetXtreme-E 10Gb Ethernet\" },\n\t[BCM57404] = { \"Broadcom BCM57404 NetXtreme-E 10Gb/25Gb Ethernet\" },\n\t[BCM57406] = { \"Broadcom BCM57406 NetXtreme-E 10GBase-T Ethernet\" },\n\t[BCM57402_NPAR] = { \"Broadcom BCM57402 NetXtreme-E Ethernet Partition\" },\n\t[BCM57407] = { \"Broadcom BCM57407 NetXtreme-E 10GBase-T Ethernet\" },\n\t[BCM57412] = { \"Broadcom BCM57412 NetXtreme-E 10Gb Ethernet\" },\n\t[BCM57414] = { \"Broadcom BCM57414 NetXtreme-E 10Gb/25Gb Ethernet\" },\n\t[BCM57416] = { \"Broadcom BCM57416 NetXtreme-E 10GBase-T Ethernet\" },\n\t[BCM57417] = { \"Broadcom BCM57417 NetXtreme-E 10GBase-T Ethernet\" },\n\t[BCM57412_NPAR] = { \"Broadcom BCM57412 NetXtreme-E Ethernet Partition\" },\n\t[BCM57314] = { \"Broadcom BCM57314 NetXtreme-C 10Gb/25Gb/40Gb/50Gb Ethernet\" },\n\t[BCM57417_SFP] = { \"Broadcom BCM57417 NetXtreme-E 10Gb/25Gb Ethernet\" },\n\t[BCM57416_SFP] = { \"Broadcom BCM57416 NetXtreme-E 10Gb Ethernet\" },\n\t[BCM57404_NPAR] = { \"Broadcom BCM57404 NetXtreme-E Ethernet Partition\" },\n\t[BCM57406_NPAR] = { \"Broadcom BCM57406 NetXtreme-E Ethernet Partition\" },\n\t[BCM57407_SFP] = { \"Broadcom BCM57407 NetXtreme-E 25Gb Ethernet\" },\n\t[BCM57407_NPAR] = { \"Broadcom BCM57407 NetXtreme-E Ethernet Partition\" },\n\t[BCM57414_NPAR] = { \"Broadcom BCM57414 NetXtreme-E Ethernet Partition\" },\n\t[BCM57416_NPAR] = { \"Broadcom BCM57416 NetXtreme-E Ethernet Partition\" },\n\t[BCM57452] = { \"Broadcom BCM57452 NetXtreme-E 10Gb/25Gb/40Gb/50Gb Ethernet\" },\n\t[BCM57454] = { \"Broadcom BCM57454 NetXtreme-E 10Gb/25Gb/40Gb/50Gb/100Gb Ethernet\" },\n\t[BCM5745x_NPAR] = { \"Broadcom BCM5745x NetXtreme-E Ethernet Partition\" },\n\t[BCM57508] = { \"Broadcom BCM57508 NetXtreme-E 10Gb/25Gb/50Gb/100Gb/200Gb Ethernet\" },\n\t[BCM57504] = { \"Broadcom BCM57504 NetXtreme-E 10Gb/25Gb/50Gb/100Gb/200Gb Ethernet\" },\n\t[BCM57502] = { \"Broadcom BCM57502 NetXtreme-E 10Gb/25Gb/50Gb Ethernet\" },\n\t[BCM57508_NPAR] = { \"Broadcom BCM57508 NetXtreme-E Ethernet Partition\" },\n\t[BCM57504_NPAR] = { \"Broadcom BCM57504 NetXtreme-E Ethernet Partition\" },\n\t[BCM57502_NPAR] = { \"Broadcom BCM57502 NetXtreme-E Ethernet Partition\" },\n\t[BCM58802] = { \"Broadcom BCM58802 NetXtreme-S 10Gb/25Gb/40Gb/50Gb Ethernet\" },\n\t[BCM58804] = { \"Broadcom BCM58804 NetXtreme-S 10Gb/25Gb/40Gb/50Gb/100Gb Ethernet\" },\n\t[BCM58808] = { \"Broadcom BCM58808 NetXtreme-S 10Gb/25Gb/40Gb/50Gb/100Gb Ethernet\" },\n\t[NETXTREME_E_VF] = { \"Broadcom NetXtreme-E Ethernet Virtual Function\" },\n\t[NETXTREME_C_VF] = { \"Broadcom NetXtreme-C Ethernet Virtual Function\" },\n\t[NETXTREME_S_VF] = { \"Broadcom NetXtreme-S Ethernet Virtual Function\" },\n\t[NETXTREME_E_P5_VF] = { \"Broadcom BCM5750X NetXtreme-E Ethernet Virtual Function\" },\n};\n\nstatic const struct pci_device_id bnxt_pci_tbl[] = {\n\t{ PCI_VDEVICE(BROADCOM, 0x1604), .driver_data = BCM5745x_NPAR },\n\t{ PCI_VDEVICE(BROADCOM, 0x1605), .driver_data = BCM5745x_NPAR },\n\t{ PCI_VDEVICE(BROADCOM, 0x1614), .driver_data = BCM57454 },\n\t{ PCI_VDEVICE(BROADCOM, 0x16c0), .driver_data = BCM57417_NPAR },\n\t{ PCI_VDEVICE(BROADCOM, 0x16c8), .driver_data = BCM57301 },\n\t{ PCI_VDEVICE(BROADCOM, 0x16c9), .driver_data = BCM57302 },\n\t{ PCI_VDEVICE(BROADCOM, 0x16ca), .driver_data = BCM57304 },\n\t{ PCI_VDEVICE(BROADCOM, 0x16cc), .driver_data = BCM57417_NPAR },\n\t{ PCI_VDEVICE(BROADCOM, 0x16cd), .driver_data = BCM58700 },\n\t{ PCI_VDEVICE(BROADCOM, 0x16ce), .driver_data = BCM57311 },\n\t{ PCI_VDEVICE(BROADCOM, 0x16cf), .driver_data = BCM57312 },\n\t{ PCI_VDEVICE(BROADCOM, 0x16d0), .driver_data = BCM57402 },\n\t{ PCI_VDEVICE(BROADCOM, 0x16d1), .driver_data = BCM57404 },\n\t{ PCI_VDEVICE(BROADCOM, 0x16d2), .driver_data = BCM57406 },\n\t{ PCI_VDEVICE(BROADCOM, 0x16d4), .driver_data = BCM57402_NPAR },\n\t{ PCI_VDEVICE(BROADCOM, 0x16d5), .driver_data = BCM57407 },\n\t{ PCI_VDEVICE(BROADCOM, 0x16d6), .driver_data = BCM57412 },\n\t{ PCI_VDEVICE(BROADCOM, 0x16d7), .driver_data = BCM57414 },\n\t{ PCI_VDEVICE(BROADCOM, 0x16d8), .driver_data = BCM57416 },\n\t{ PCI_VDEVICE(BROADCOM, 0x16d9), .driver_data = BCM57417 },\n\t{ PCI_VDEVICE(BROADCOM, 0x16de), .driver_data = BCM57412_NPAR },\n\t{ PCI_VDEVICE(BROADCOM, 0x16df), .driver_data = BCM57314 },\n\t{ PCI_VDEVICE(BROADCOM, 0x16e2), .driver_data = BCM57417_SFP },\n\t{ PCI_VDEVICE(BROADCOM, 0x16e3), .driver_data = BCM57416_SFP },\n\t{ PCI_VDEVICE(BROADCOM, 0x16e7), .driver_data = BCM57404_NPAR },\n\t{ PCI_VDEVICE(BROADCOM, 0x16e8), .driver_data = BCM57406_NPAR },\n\t{ PCI_VDEVICE(BROADCOM, 0x16e9), .driver_data = BCM57407_SFP },\n\t{ PCI_VDEVICE(BROADCOM, 0x16ea), .driver_data = BCM57407_NPAR },\n\t{ PCI_VDEVICE(BROADCOM, 0x16eb), .driver_data = BCM57412_NPAR },\n\t{ PCI_VDEVICE(BROADCOM, 0x16ec), .driver_data = BCM57414_NPAR },\n\t{ PCI_VDEVICE(BROADCOM, 0x16ed), .driver_data = BCM57414_NPAR },\n\t{ PCI_VDEVICE(BROADCOM, 0x16ee), .driver_data = BCM57416_NPAR },\n\t{ PCI_VDEVICE(BROADCOM, 0x16ef), .driver_data = BCM57416_NPAR },\n\t{ PCI_VDEVICE(BROADCOM, 0x16f0), .driver_data = BCM58808 },\n\t{ PCI_VDEVICE(BROADCOM, 0x16f1), .driver_data = BCM57452 },\n\t{ PCI_VDEVICE(BROADCOM, 0x1750), .driver_data = BCM57508 },\n\t{ PCI_VDEVICE(BROADCOM, 0x1751), .driver_data = BCM57504 },\n\t{ PCI_VDEVICE(BROADCOM, 0x1752), .driver_data = BCM57502 },\n\t{ PCI_VDEVICE(BROADCOM, 0x1800), .driver_data = BCM57508_NPAR },\n\t{ PCI_VDEVICE(BROADCOM, 0x1801), .driver_data = BCM57504_NPAR },\n\t{ PCI_VDEVICE(BROADCOM, 0x1802), .driver_data = BCM57502_NPAR },\n\t{ PCI_VDEVICE(BROADCOM, 0x1803), .driver_data = BCM57508_NPAR },\n\t{ PCI_VDEVICE(BROADCOM, 0x1804), .driver_data = BCM57504_NPAR },\n\t{ PCI_VDEVICE(BROADCOM, 0x1805), .driver_data = BCM57502_NPAR },\n\t{ PCI_VDEVICE(BROADCOM, 0xd802), .driver_data = BCM58802 },\n\t{ PCI_VDEVICE(BROADCOM, 0xd804), .driver_data = BCM58804 },\n#ifdef CONFIG_BNXT_SRIOV\n\t{ PCI_VDEVICE(BROADCOM, 0x1606), .driver_data = NETXTREME_E_VF },\n\t{ PCI_VDEVICE(BROADCOM, 0x1609), .driver_data = NETXTREME_E_VF },\n\t{ PCI_VDEVICE(BROADCOM, 0x16c1), .driver_data = NETXTREME_E_VF },\n\t{ PCI_VDEVICE(BROADCOM, 0x16cb), .driver_data = NETXTREME_C_VF },\n\t{ PCI_VDEVICE(BROADCOM, 0x16d3), .driver_data = NETXTREME_E_VF },\n\t{ PCI_VDEVICE(BROADCOM, 0x16dc), .driver_data = NETXTREME_E_VF },\n\t{ PCI_VDEVICE(BROADCOM, 0x16e1), .driver_data = NETXTREME_C_VF },\n\t{ PCI_VDEVICE(BROADCOM, 0x16e5), .driver_data = NETXTREME_C_VF },\n\t{ PCI_VDEVICE(BROADCOM, 0x1806), .driver_data = NETXTREME_E_P5_VF },\n\t{ PCI_VDEVICE(BROADCOM, 0x1807), .driver_data = NETXTREME_E_P5_VF },\n\t{ PCI_VDEVICE(BROADCOM, 0xd800), .driver_data = NETXTREME_S_VF },\n#endif\n\t{ 0 }\n};\n\nMODULE_DEVICE_TABLE(pci, bnxt_pci_tbl);\n\nstatic const u16 bnxt_vf_req_snif[] = {\n\tHWRM_FUNC_CFG,\n\tHWRM_FUNC_VF_CFG,\n\tHWRM_PORT_PHY_QCFG,\n\tHWRM_CFA_L2_FILTER_ALLOC,\n};\n\nstatic const u16 bnxt_async_events_arr[] = {\n\tASYNC_EVENT_CMPL_EVENT_ID_LINK_STATUS_CHANGE,\n\tASYNC_EVENT_CMPL_EVENT_ID_LINK_SPEED_CHANGE,\n\tASYNC_EVENT_CMPL_EVENT_ID_PF_DRVR_UNLOAD,\n\tASYNC_EVENT_CMPL_EVENT_ID_PORT_CONN_NOT_ALLOWED,\n\tASYNC_EVENT_CMPL_EVENT_ID_VF_CFG_CHANGE,\n\tASYNC_EVENT_CMPL_EVENT_ID_LINK_SPEED_CFG_CHANGE,\n\tASYNC_EVENT_CMPL_EVENT_ID_PORT_PHY_CFG_CHANGE,\n\tASYNC_EVENT_CMPL_EVENT_ID_RESET_NOTIFY,\n\tASYNC_EVENT_CMPL_EVENT_ID_ERROR_RECOVERY,\n\tASYNC_EVENT_CMPL_EVENT_ID_DEBUG_NOTIFICATION,\n\tASYNC_EVENT_CMPL_EVENT_ID_RING_MONITOR_MSG,\n\tASYNC_EVENT_CMPL_EVENT_ID_ECHO_REQUEST,\n};\n\nstatic struct workqueue_struct *bnxt_pf_wq;\n\nstatic bool bnxt_vf_pciid(enum board_idx idx)\n{\n\treturn (idx == NETXTREME_C_VF || idx == NETXTREME_E_VF ||\n\t\tidx == NETXTREME_S_VF || idx == NETXTREME_E_P5_VF);\n}\n\n#define DB_CP_REARM_FLAGS\t(DB_KEY_CP | DB_IDX_VALID)\n#define DB_CP_FLAGS\t\t(DB_KEY_CP | DB_IDX_VALID | DB_IRQ_DIS)\n#define DB_CP_IRQ_DIS_FLAGS\t(DB_KEY_CP | DB_IRQ_DIS)\n\n#define BNXT_CP_DB_IRQ_DIS(db)\t\t\t\t\t\t\\\n\t\twritel(DB_CP_IRQ_DIS_FLAGS, db)\n\n#define BNXT_DB_CQ(db, idx)\t\t\t\t\t\t\\\n\twritel(DB_CP_FLAGS | RING_CMP(idx), (db)->doorbell)\n\n#define BNXT_DB_NQ_P5(db, idx)\t\t\t\t\t\t\\\n\twriteq((db)->db_key64 | DBR_TYPE_NQ | RING_CMP(idx), (db)->doorbell)\n\n#define BNXT_DB_CQ_ARM(db, idx)\t\t\t\t\t\t\\\n\twritel(DB_CP_REARM_FLAGS | RING_CMP(idx), (db)->doorbell)\n\n#define BNXT_DB_NQ_ARM_P5(db, idx)\t\t\t\t\t\\\n\twriteq((db)->db_key64 | DBR_TYPE_NQ_ARM | RING_CMP(idx), (db)->doorbell)\n\nstatic void bnxt_db_nq(struct bnxt *bp, struct bnxt_db_info *db, u32 idx)\n{\n\tif (bp->flags & BNXT_FLAG_CHIP_P5)\n\t\tBNXT_DB_NQ_P5(db, idx);\n\telse\n\t\tBNXT_DB_CQ(db, idx);\n}\n\nstatic void bnxt_db_nq_arm(struct bnxt *bp, struct bnxt_db_info *db, u32 idx)\n{\n\tif (bp->flags & BNXT_FLAG_CHIP_P5)\n\t\tBNXT_DB_NQ_ARM_P5(db, idx);\n\telse\n\t\tBNXT_DB_CQ_ARM(db, idx);\n}\n\nstatic void bnxt_db_cq(struct bnxt *bp, struct bnxt_db_info *db, u32 idx)\n{\n\tif (bp->flags & BNXT_FLAG_CHIP_P5)\n\t\twriteq(db->db_key64 | DBR_TYPE_CQ_ARMALL | RING_CMP(idx),\n\t\t       db->doorbell);\n\telse\n\t\tBNXT_DB_CQ(db, idx);\n}\n\nconst u16 bnxt_lhint_arr[] = {\n\tTX_BD_FLAGS_LHINT_512_AND_SMALLER,\n\tTX_BD_FLAGS_LHINT_512_TO_1023,\n\tTX_BD_FLAGS_LHINT_1024_TO_2047,\n\tTX_BD_FLAGS_LHINT_1024_TO_2047,\n\tTX_BD_FLAGS_LHINT_2048_AND_LARGER,\n\tTX_BD_FLAGS_LHINT_2048_AND_LARGER,\n\tTX_BD_FLAGS_LHINT_2048_AND_LARGER,\n\tTX_BD_FLAGS_LHINT_2048_AND_LARGER,\n\tTX_BD_FLAGS_LHINT_2048_AND_LARGER,\n\tTX_BD_FLAGS_LHINT_2048_AND_LARGER,\n\tTX_BD_FLAGS_LHINT_2048_AND_LARGER,\n\tTX_BD_FLAGS_LHINT_2048_AND_LARGER,\n\tTX_BD_FLAGS_LHINT_2048_AND_LARGER,\n\tTX_BD_FLAGS_LHINT_2048_AND_LARGER,\n\tTX_BD_FLAGS_LHINT_2048_AND_LARGER,\n\tTX_BD_FLAGS_LHINT_2048_AND_LARGER,\n\tTX_BD_FLAGS_LHINT_2048_AND_LARGER,\n\tTX_BD_FLAGS_LHINT_2048_AND_LARGER,\n\tTX_BD_FLAGS_LHINT_2048_AND_LARGER,\n};\n\nstatic u16 bnxt_xmit_get_cfa_action(struct sk_buff *skb)\n{\n\tstruct metadata_dst *md_dst = skb_metadata_dst(skb);\n\n\tif (!md_dst || md_dst->type != METADATA_HW_PORT_MUX)\n\t\treturn 0;\n\n\treturn md_dst->u.port_info.port_id;\n}\n\nstatic netdev_tx_t bnxt_start_xmit(struct sk_buff *skb, struct net_device *dev)\n{\n\tstruct bnxt *bp = netdev_priv(dev);\n\tstruct tx_bd *txbd;\n\tstruct tx_bd_ext *txbd1;\n\tstruct netdev_queue *txq;\n\tint i;\n\tdma_addr_t mapping;\n\tunsigned int length, pad = 0;\n\tu32 len, free_size, vlan_tag_flags, cfa_action, flags;\n\tu16 prod, last_frag;\n\tstruct pci_dev *pdev = bp->pdev;\n\tstruct bnxt_tx_ring_info *txr;\n\tstruct bnxt_sw_tx_bd *tx_buf;\n\n\ti = skb_get_queue_mapping(skb);\n\tif (unlikely(i >= bp->tx_nr_rings)) {\n\t\tdev_kfree_skb_any(skb);\n\t\treturn NETDEV_TX_OK;\n\t}\n\n\ttxq = netdev_get_tx_queue(dev, i);\n\ttxr = &bp->tx_ring[bp->tx_ring_map[i]];\n\tprod = txr->tx_prod;\n\n\tfree_size = bnxt_tx_avail(bp, txr);\n\tif (unlikely(free_size < skb_shinfo(skb)->nr_frags + 2)) {\n\t\tnetif_tx_stop_queue(txq);\n\t\treturn NETDEV_TX_BUSY;\n\t}\n\n\tlength = skb->len;\n\tlen = skb_headlen(skb);\n\tlast_frag = skb_shinfo(skb)->nr_frags;\n\n\ttxbd = &txr->tx_desc_ring[TX_RING(prod)][TX_IDX(prod)];\n\n\ttxbd->tx_bd_opaque = prod;\n\n\ttx_buf = &txr->tx_buf_ring[prod];\n\ttx_buf->skb = skb;\n\ttx_buf->nr_frags = last_frag;\n\n\tvlan_tag_flags = 0;\n\tcfa_action = bnxt_xmit_get_cfa_action(skb);\n\tif (skb_vlan_tag_present(skb)) {\n\t\tvlan_tag_flags = TX_BD_CFA_META_KEY_VLAN |\n\t\t\t\t skb_vlan_tag_get(skb);\n\t\t/* Currently supports 8021Q, 8021AD vlan offloads\n\t\t * QINQ1, QINQ2, QINQ3 vlan headers are deprecated\n\t\t */\n\t\tif (skb->vlan_proto == htons(ETH_P_8021Q))\n\t\t\tvlan_tag_flags |= 1 << TX_BD_CFA_META_TPID_SHIFT;\n\t}\n\n\tif (free_size == bp->tx_ring_size && length <= bp->tx_push_thresh) {\n\t\tstruct tx_push_buffer *tx_push_buf = txr->tx_push;\n\t\tstruct tx_push_bd *tx_push = &tx_push_buf->push_bd;\n\t\tstruct tx_bd_ext *tx_push1 = &tx_push->txbd2;\n\t\tvoid __iomem *db = txr->tx_db.doorbell;\n\t\tvoid *pdata = tx_push_buf->data;\n\t\tu64 *end;\n\t\tint j, push_len;\n\n\t\t/* Set COAL_NOW to be ready quickly for the next push */\n\t\ttx_push->tx_bd_len_flags_type =\n\t\t\tcpu_to_le32((length << TX_BD_LEN_SHIFT) |\n\t\t\t\t\tTX_BD_TYPE_LONG_TX_BD |\n\t\t\t\t\tTX_BD_FLAGS_LHINT_512_AND_SMALLER |\n\t\t\t\t\tTX_BD_FLAGS_COAL_NOW |\n\t\t\t\t\tTX_BD_FLAGS_PACKET_END |\n\t\t\t\t\t(2 << TX_BD_FLAGS_BD_CNT_SHIFT));\n\n\t\tif (skb->ip_summed == CHECKSUM_PARTIAL)\n\t\t\ttx_push1->tx_bd_hsize_lflags =\n\t\t\t\t\tcpu_to_le32(TX_BD_FLAGS_TCP_UDP_CHKSUM);\n\t\telse\n\t\t\ttx_push1->tx_bd_hsize_lflags = 0;\n\n\t\ttx_push1->tx_bd_cfa_meta = cpu_to_le32(vlan_tag_flags);\n\t\ttx_push1->tx_bd_cfa_action =\n\t\t\tcpu_to_le32(cfa_action << TX_BD_CFA_ACTION_SHIFT);\n\n\t\tend = pdata + length;\n\t\tend = PTR_ALIGN(end, 8) - 1;\n\t\t*end = 0;\n\n\t\tskb_copy_from_linear_data(skb, pdata, len);\n\t\tpdata += len;\n\t\tfor (j = 0; j < last_frag; j++) {\n\t\t\tskb_frag_t *frag = &skb_shinfo(skb)->frags[j];\n\t\t\tvoid *fptr;\n\n\t\t\tfptr = skb_frag_address_safe(frag);\n\t\t\tif (!fptr)\n\t\t\t\tgoto normal_tx;\n\n\t\t\tmemcpy(pdata, fptr, skb_frag_size(frag));\n\t\t\tpdata += skb_frag_size(frag);\n\t\t}\n\n\t\ttxbd->tx_bd_len_flags_type = tx_push->tx_bd_len_flags_type;\n\t\ttxbd->tx_bd_haddr = txr->data_mapping;\n\t\tprod = NEXT_TX(prod);\n\t\ttxbd = &txr->tx_desc_ring[TX_RING(prod)][TX_IDX(prod)];\n\t\tmemcpy(txbd, tx_push1, sizeof(*txbd));\n\t\tprod = NEXT_TX(prod);\n\t\ttx_push->doorbell =\n\t\t\tcpu_to_le32(DB_KEY_TX_PUSH | DB_LONG_TX_PUSH | prod);\n\t\ttxr->tx_prod = prod;\n\n\t\ttx_buf->is_push = 1;\n\t\tnetdev_tx_sent_queue(txq, skb->len);\n\t\twmb();\t/* Sync is_push and byte queue before pushing data */\n\n\t\tpush_len = (length + sizeof(*tx_push) + 7) / 8;\n\t\tif (push_len > 16) {\n\t\t\t__iowrite64_copy(db, tx_push_buf, 16);\n\t\t\t__iowrite32_copy(db + 4, tx_push_buf + 1,\n\t\t\t\t\t (push_len - 16) << 1);\n\t\t} else {\n\t\t\t__iowrite64_copy(db, tx_push_buf, push_len);\n\t\t}\n\n\t\tgoto tx_done;\n\t}\n\nnormal_tx:\n\tif (length < BNXT_MIN_PKT_SIZE) {\n\t\tpad = BNXT_MIN_PKT_SIZE - length;\n\t\tif (skb_pad(skb, pad)) {\n\t\t\t/* SKB already freed. */\n\t\t\ttx_buf->skb = NULL;\n\t\t\treturn NETDEV_TX_OK;\n\t\t}\n\t\tlength = BNXT_MIN_PKT_SIZE;\n\t}\n\n\tmapping = dma_map_single(&pdev->dev, skb->data, len, DMA_TO_DEVICE);\n\n\tif (unlikely(dma_mapping_error(&pdev->dev, mapping))) {\n\t\tdev_kfree_skb_any(skb);\n\t\ttx_buf->skb = NULL;\n\t\treturn NETDEV_TX_OK;\n\t}\n\n\tdma_unmap_addr_set(tx_buf, mapping, mapping);\n\tflags = (len << TX_BD_LEN_SHIFT) | TX_BD_TYPE_LONG_TX_BD |\n\t\t((last_frag + 2) << TX_BD_FLAGS_BD_CNT_SHIFT);\n\n\ttxbd->tx_bd_haddr = cpu_to_le64(mapping);\n\n\tprod = NEXT_TX(prod);\n\ttxbd1 = (struct tx_bd_ext *)\n\t\t&txr->tx_desc_ring[TX_RING(prod)][TX_IDX(prod)];\n\n\ttxbd1->tx_bd_hsize_lflags = 0;\n\tif (skb_is_gso(skb)) {\n\t\tu32 hdr_len;\n\n\t\tif (skb->encapsulation)\n\t\t\thdr_len = skb_inner_network_offset(skb) +\n\t\t\t\tskb_inner_network_header_len(skb) +\n\t\t\t\tinner_tcp_hdrlen(skb);\n\t\telse\n\t\t\thdr_len = skb_transport_offset(skb) +\n\t\t\t\ttcp_hdrlen(skb);\n\n\t\ttxbd1->tx_bd_hsize_lflags = cpu_to_le32(TX_BD_FLAGS_LSO |\n\t\t\t\t\tTX_BD_FLAGS_T_IPID |\n\t\t\t\t\t(hdr_len << (TX_BD_HSIZE_SHIFT - 1)));\n\t\tlength = skb_shinfo(skb)->gso_size;\n\t\ttxbd1->tx_bd_mss = cpu_to_le32(length);\n\t\tlength += hdr_len;\n\t} else if (skb->ip_summed == CHECKSUM_PARTIAL) {\n\t\ttxbd1->tx_bd_hsize_lflags =\n\t\t\tcpu_to_le32(TX_BD_FLAGS_TCP_UDP_CHKSUM);\n\t\ttxbd1->tx_bd_mss = 0;\n\t}\n\n\tlength >>= 9;\n\tif (unlikely(length >= ARRAY_SIZE(bnxt_lhint_arr))) {\n\t\tdev_warn_ratelimited(&pdev->dev, \"Dropped oversize %d bytes TX packet.\\n\",\n\t\t\t\t     skb->len);\n\t\ti = 0;\n\t\tgoto tx_dma_error;\n\t}\n\tflags |= bnxt_lhint_arr[length];\n\ttxbd->tx_bd_len_flags_type = cpu_to_le32(flags);\n\n\ttxbd1->tx_bd_cfa_meta = cpu_to_le32(vlan_tag_flags);\n\ttxbd1->tx_bd_cfa_action =\n\t\t\tcpu_to_le32(cfa_action << TX_BD_CFA_ACTION_SHIFT);\n\tfor (i = 0; i < last_frag; i++) {\n\t\tskb_frag_t *frag = &skb_shinfo(skb)->frags[i];\n\n\t\tprod = NEXT_TX(prod);\n\t\ttxbd = &txr->tx_desc_ring[TX_RING(prod)][TX_IDX(prod)];\n\n\t\tlen = skb_frag_size(frag);\n\t\tmapping = skb_frag_dma_map(&pdev->dev, frag, 0, len,\n\t\t\t\t\t   DMA_TO_DEVICE);\n\n\t\tif (unlikely(dma_mapping_error(&pdev->dev, mapping)))\n\t\t\tgoto tx_dma_error;\n\n\t\ttx_buf = &txr->tx_buf_ring[prod];\n\t\tdma_unmap_addr_set(tx_buf, mapping, mapping);\n\n\t\ttxbd->tx_bd_haddr = cpu_to_le64(mapping);\n\n\t\tflags = len << TX_BD_LEN_SHIFT;\n\t\ttxbd->tx_bd_len_flags_type = cpu_to_le32(flags);\n\t}\n\n\tflags &= ~TX_BD_LEN;\n\ttxbd->tx_bd_len_flags_type =\n\t\tcpu_to_le32(((len + pad) << TX_BD_LEN_SHIFT) | flags |\n\t\t\t    TX_BD_FLAGS_PACKET_END);\n\n\tnetdev_tx_sent_queue(txq, skb->len);\n\n\t/* Sync BD data before updating doorbell */\n\twmb();\n\n\tprod = NEXT_TX(prod);\n\ttxr->tx_prod = prod;\n\n\tif (!netdev_xmit_more() || netif_xmit_stopped(txq))\n\t\tbnxt_db_write(bp, &txr->tx_db, prod);\n\ntx_done:\n\n\tif (unlikely(bnxt_tx_avail(bp, txr) <= MAX_SKB_FRAGS + 1)) {\n\t\tif (netdev_xmit_more() && !tx_buf->is_push)\n\t\t\tbnxt_db_write(bp, &txr->tx_db, prod);\n\n\t\tnetif_tx_stop_queue(txq);\n\n\t\t/* netif_tx_stop_queue() must be done before checking\n\t\t * tx index in bnxt_tx_avail() below, because in\n\t\t * bnxt_tx_int(), we update tx index before checking for\n\t\t * netif_tx_queue_stopped().\n\t\t */\n\t\tsmp_mb();\n\t\tif (bnxt_tx_avail(bp, txr) > bp->tx_wake_thresh)\n\t\t\tnetif_tx_wake_queue(txq);\n\t}\n\treturn NETDEV_TX_OK;\n\ntx_dma_error:\n\tlast_frag = i;\n\n\t/* start back at beginning and unmap skb */\n\tprod = txr->tx_prod;\n\ttx_buf = &txr->tx_buf_ring[prod];\n\ttx_buf->skb = NULL;\n\tdma_unmap_single(&pdev->dev, dma_unmap_addr(tx_buf, mapping),\n\t\t\t skb_headlen(skb), PCI_DMA_TODEVICE);\n\tprod = NEXT_TX(prod);\n\n\t/* unmap remaining mapped pages */\n\tfor (i = 0; i < last_frag; i++) {\n\t\tprod = NEXT_TX(prod);\n\t\ttx_buf = &txr->tx_buf_ring[prod];\n\t\tdma_unmap_page(&pdev->dev, dma_unmap_addr(tx_buf, mapping),\n\t\t\t       skb_frag_size(&skb_shinfo(skb)->frags[i]),\n\t\t\t       PCI_DMA_TODEVICE);\n\t}\n\n\tdev_kfree_skb_any(skb);\n\treturn NETDEV_TX_OK;\n}\n\nstatic void bnxt_tx_int(struct bnxt *bp, struct bnxt_napi *bnapi, int nr_pkts)\n{\n\tstruct bnxt_tx_ring_info *txr = bnapi->tx_ring;\n\tstruct netdev_queue *txq = netdev_get_tx_queue(bp->dev, txr->txq_index);\n\tu16 cons = txr->tx_cons;\n\tstruct pci_dev *pdev = bp->pdev;\n\tint i;\n\tunsigned int tx_bytes = 0;\n\n\tfor (i = 0; i < nr_pkts; i++) {\n\t\tstruct bnxt_sw_tx_bd *tx_buf;\n\t\tstruct sk_buff *skb;\n\t\tint j, last;\n\n\t\ttx_buf = &txr->tx_buf_ring[cons];\n\t\tcons = NEXT_TX(cons);\n\t\tskb = tx_buf->skb;\n\t\ttx_buf->skb = NULL;\n\n\t\tif (tx_buf->is_push) {\n\t\t\ttx_buf->is_push = 0;\n\t\t\tgoto next_tx_int;\n\t\t}\n\n\t\tdma_unmap_single(&pdev->dev, dma_unmap_addr(tx_buf, mapping),\n\t\t\t\t skb_headlen(skb), PCI_DMA_TODEVICE);\n\t\tlast = tx_buf->nr_frags;\n\n\t\tfor (j = 0; j < last; j++) {\n\t\t\tcons = NEXT_TX(cons);\n\t\t\ttx_buf = &txr->tx_buf_ring[cons];\n\t\t\tdma_unmap_page(\n\t\t\t\t&pdev->dev,\n\t\t\t\tdma_unmap_addr(tx_buf, mapping),\n\t\t\t\tskb_frag_size(&skb_shinfo(skb)->frags[j]),\n\t\t\t\tPCI_DMA_TODEVICE);\n\t\t}\n\nnext_tx_int:\n\t\tcons = NEXT_TX(cons);\n\n\t\ttx_bytes += skb->len;\n\t\tdev_kfree_skb_any(skb);\n\t}\n\n\tnetdev_tx_completed_queue(txq, nr_pkts, tx_bytes);\n\ttxr->tx_cons = cons;\n\n\t/* Need to make the tx_cons update visible to bnxt_start_xmit()\n\t * before checking for netif_tx_queue_stopped().  Without the\n\t * memory barrier, there is a small possibility that bnxt_start_xmit()\n\t * will miss it and cause the queue to be stopped forever.\n\t */\n\tsmp_mb();\n\n\tif (unlikely(netif_tx_queue_stopped(txq)) &&\n\t    (bnxt_tx_avail(bp, txr) > bp->tx_wake_thresh)) {\n\t\t__netif_tx_lock(txq, smp_processor_id());\n\t\tif (netif_tx_queue_stopped(txq) &&\n\t\t    bnxt_tx_avail(bp, txr) > bp->tx_wake_thresh &&\n\t\t    txr->dev_state != BNXT_DEV_STATE_CLOSING)\n\t\t\tnetif_tx_wake_queue(txq);\n\t\t__netif_tx_unlock(txq);\n\t}\n}\n\nstatic struct page *__bnxt_alloc_rx_page(struct bnxt *bp, dma_addr_t *mapping,\n\t\t\t\t\t struct bnxt_rx_ring_info *rxr,\n\t\t\t\t\t gfp_t gfp)\n{\n\tstruct device *dev = &bp->pdev->dev;\n\tstruct page *page;\n\n\tpage = page_pool_dev_alloc_pages(rxr->page_pool);\n\tif (!page)\n\t\treturn NULL;\n\n\t*mapping = dma_map_page_attrs(dev, page, 0, PAGE_SIZE, bp->rx_dir,\n\t\t\t\t      DMA_ATTR_WEAK_ORDERING);\n\tif (dma_mapping_error(dev, *mapping)) {\n\t\tpage_pool_recycle_direct(rxr->page_pool, page);\n\t\treturn NULL;\n\t}\n\t*mapping += bp->rx_dma_offset;\n\treturn page;\n}\n\nstatic inline u8 *__bnxt_alloc_rx_data(struct bnxt *bp, dma_addr_t *mapping,\n\t\t\t\t       gfp_t gfp)\n{\n\tu8 *data;\n\tstruct pci_dev *pdev = bp->pdev;\n\n\tdata = kmalloc(bp->rx_buf_size, gfp);\n\tif (!data)\n\t\treturn NULL;\n\n\t*mapping = dma_map_single_attrs(&pdev->dev, data + bp->rx_dma_offset,\n\t\t\t\t\tbp->rx_buf_use_size, bp->rx_dir,\n\t\t\t\t\tDMA_ATTR_WEAK_ORDERING);\n\n\tif (dma_mapping_error(&pdev->dev, *mapping)) {\n\t\tkfree(data);\n\t\tdata = NULL;\n\t}\n\treturn data;\n}\n\nint bnxt_alloc_rx_data(struct bnxt *bp, struct bnxt_rx_ring_info *rxr,\n\t\t       u16 prod, gfp_t gfp)\n{\n\tstruct rx_bd *rxbd = &rxr->rx_desc_ring[RX_RING(prod)][RX_IDX(prod)];\n\tstruct bnxt_sw_rx_bd *rx_buf = &rxr->rx_buf_ring[prod];\n\tdma_addr_t mapping;\n\n\tif (BNXT_RX_PAGE_MODE(bp)) {\n\t\tstruct page *page =\n\t\t\t__bnxt_alloc_rx_page(bp, &mapping, rxr, gfp);\n\n\t\tif (!page)\n\t\t\treturn -ENOMEM;\n\n\t\trx_buf->data = page;\n\t\trx_buf->data_ptr = page_address(page) + bp->rx_offset;\n\t} else {\n\t\tu8 *data = __bnxt_alloc_rx_data(bp, &mapping, gfp);\n\n\t\tif (!data)\n\t\t\treturn -ENOMEM;\n\n\t\trx_buf->data = data;\n\t\trx_buf->data_ptr = data + bp->rx_offset;\n\t}\n\trx_buf->mapping = mapping;\n\n\trxbd->rx_bd_haddr = cpu_to_le64(mapping);\n\treturn 0;\n}\n\nvoid bnxt_reuse_rx_data(struct bnxt_rx_ring_info *rxr, u16 cons, void *data)\n{\n\tu16 prod = rxr->rx_prod;\n\tstruct bnxt_sw_rx_bd *cons_rx_buf, *prod_rx_buf;\n\tstruct rx_bd *cons_bd, *prod_bd;\n\n\tprod_rx_buf = &rxr->rx_buf_ring[prod];\n\tcons_rx_buf = &rxr->rx_buf_ring[cons];\n\n\tprod_rx_buf->data = data;\n\tprod_rx_buf->data_ptr = cons_rx_buf->data_ptr;\n\n\tprod_rx_buf->mapping = cons_rx_buf->mapping;\n\n\tprod_bd = &rxr->rx_desc_ring[RX_RING(prod)][RX_IDX(prod)];\n\tcons_bd = &rxr->rx_desc_ring[RX_RING(cons)][RX_IDX(cons)];\n\n\tprod_bd->rx_bd_haddr = cons_bd->rx_bd_haddr;\n}\n\nstatic inline u16 bnxt_find_next_agg_idx(struct bnxt_rx_ring_info *rxr, u16 idx)\n{\n\tu16 next, max = rxr->rx_agg_bmap_size;\n\n\tnext = find_next_zero_bit(rxr->rx_agg_bmap, max, idx);\n\tif (next >= max)\n\t\tnext = find_first_zero_bit(rxr->rx_agg_bmap, max);\n\treturn next;\n}\n\nstatic inline int bnxt_alloc_rx_page(struct bnxt *bp,\n\t\t\t\t     struct bnxt_rx_ring_info *rxr,\n\t\t\t\t     u16 prod, gfp_t gfp)\n{\n\tstruct rx_bd *rxbd =\n\t\t&rxr->rx_agg_desc_ring[RX_RING(prod)][RX_IDX(prod)];\n\tstruct bnxt_sw_rx_agg_bd *rx_agg_buf;\n\tstruct pci_dev *pdev = bp->pdev;\n\tstruct page *page;\n\tdma_addr_t mapping;\n\tu16 sw_prod = rxr->rx_sw_agg_prod;\n\tunsigned int offset = 0;\n\n\tif (PAGE_SIZE > BNXT_RX_PAGE_SIZE) {\n\t\tpage = rxr->rx_page;\n\t\tif (!page) {\n\t\t\tpage = alloc_page(gfp);\n\t\t\tif (!page)\n\t\t\t\treturn -ENOMEM;\n\t\t\trxr->rx_page = page;\n\t\t\trxr->rx_page_offset = 0;\n\t\t}\n\t\toffset = rxr->rx_page_offset;\n\t\trxr->rx_page_offset += BNXT_RX_PAGE_SIZE;\n\t\tif (rxr->rx_page_offset == PAGE_SIZE)\n\t\t\trxr->rx_page = NULL;\n\t\telse\n\t\t\tget_page(page);\n\t} else {\n\t\tpage = alloc_page(gfp);\n\t\tif (!page)\n\t\t\treturn -ENOMEM;\n\t}\n\n\tmapping = dma_map_page_attrs(&pdev->dev, page, offset,\n\t\t\t\t     BNXT_RX_PAGE_SIZE, PCI_DMA_FROMDEVICE,\n\t\t\t\t     DMA_ATTR_WEAK_ORDERING);\n\tif (dma_mapping_error(&pdev->dev, mapping)) {\n\t\t__free_page(page);\n\t\treturn -EIO;\n\t}\n\n\tif (unlikely(test_bit(sw_prod, rxr->rx_agg_bmap)))\n\t\tsw_prod = bnxt_find_next_agg_idx(rxr, sw_prod);\n\n\t__set_bit(sw_prod, rxr->rx_agg_bmap);\n\trx_agg_buf = &rxr->rx_agg_ring[sw_prod];\n\trxr->rx_sw_agg_prod = NEXT_RX_AGG(sw_prod);\n\n\trx_agg_buf->page = page;\n\trx_agg_buf->offset = offset;\n\trx_agg_buf->mapping = mapping;\n\trxbd->rx_bd_haddr = cpu_to_le64(mapping);\n\trxbd->rx_bd_opaque = sw_prod;\n\treturn 0;\n}\n\nstatic struct rx_agg_cmp *bnxt_get_agg(struct bnxt *bp,\n\t\t\t\t       struct bnxt_cp_ring_info *cpr,\n\t\t\t\t       u16 cp_cons, u16 curr)\n{\n\tstruct rx_agg_cmp *agg;\n\n\tcp_cons = RING_CMP(ADV_RAW_CMP(cp_cons, curr));\n\tagg = (struct rx_agg_cmp *)\n\t\t&cpr->cp_desc_ring[CP_RING(cp_cons)][CP_IDX(cp_cons)];\n\treturn agg;\n}\n\nstatic struct rx_agg_cmp *bnxt_get_tpa_agg_p5(struct bnxt *bp,\n\t\t\t\t\t      struct bnxt_rx_ring_info *rxr,\n\t\t\t\t\t      u16 agg_id, u16 curr)\n{\n\tstruct bnxt_tpa_info *tpa_info = &rxr->rx_tpa[agg_id];\n\n\treturn &tpa_info->agg_arr[curr];\n}\n\nstatic void bnxt_reuse_rx_agg_bufs(struct bnxt_cp_ring_info *cpr, u16 idx,\n\t\t\t\t   u16 start, u32 agg_bufs, bool tpa)\n{\n\tstruct bnxt_napi *bnapi = cpr->bnapi;\n\tstruct bnxt *bp = bnapi->bp;\n\tstruct bnxt_rx_ring_info *rxr = bnapi->rx_ring;\n\tu16 prod = rxr->rx_agg_prod;\n\tu16 sw_prod = rxr->rx_sw_agg_prod;\n\tbool p5_tpa = false;\n\tu32 i;\n\n\tif ((bp->flags & BNXT_FLAG_CHIP_P5) && tpa)\n\t\tp5_tpa = true;\n\n\tfor (i = 0; i < agg_bufs; i++) {\n\t\tu16 cons;\n\t\tstruct rx_agg_cmp *agg;\n\t\tstruct bnxt_sw_rx_agg_bd *cons_rx_buf, *prod_rx_buf;\n\t\tstruct rx_bd *prod_bd;\n\t\tstruct page *page;\n\n\t\tif (p5_tpa)\n\t\t\tagg = bnxt_get_tpa_agg_p5(bp, rxr, idx, start + i);\n\t\telse\n\t\t\tagg = bnxt_get_agg(bp, cpr, idx, start + i);\n\t\tcons = agg->rx_agg_cmp_opaque;\n\t\t__clear_bit(cons, rxr->rx_agg_bmap);\n\n\t\tif (unlikely(test_bit(sw_prod, rxr->rx_agg_bmap)))\n\t\t\tsw_prod = bnxt_find_next_agg_idx(rxr, sw_prod);\n\n\t\t__set_bit(sw_prod, rxr->rx_agg_bmap);\n\t\tprod_rx_buf = &rxr->rx_agg_ring[sw_prod];\n\t\tcons_rx_buf = &rxr->rx_agg_ring[cons];\n\n\t\t/* It is possible for sw_prod to be equal to cons, so\n\t\t * set cons_rx_buf->page to NULL first.\n\t\t */\n\t\tpage = cons_rx_buf->page;\n\t\tcons_rx_buf->page = NULL;\n\t\tprod_rx_buf->page = page;\n\t\tprod_rx_buf->offset = cons_rx_buf->offset;\n\n\t\tprod_rx_buf->mapping = cons_rx_buf->mapping;\n\n\t\tprod_bd = &rxr->rx_agg_desc_ring[RX_RING(prod)][RX_IDX(prod)];\n\n\t\tprod_bd->rx_bd_haddr = cpu_to_le64(cons_rx_buf->mapping);\n\t\tprod_bd->rx_bd_opaque = sw_prod;\n\n\t\tprod = NEXT_RX_AGG(prod);\n\t\tsw_prod = NEXT_RX_AGG(sw_prod);\n\t}\n\trxr->rx_agg_prod = prod;\n\trxr->rx_sw_agg_prod = sw_prod;\n}\n\nstatic struct sk_buff *bnxt_rx_page_skb(struct bnxt *bp,\n\t\t\t\t\tstruct bnxt_rx_ring_info *rxr,\n\t\t\t\t\tu16 cons, void *data, u8 *data_ptr,\n\t\t\t\t\tdma_addr_t dma_addr,\n\t\t\t\t\tunsigned int offset_and_len)\n{\n\tunsigned int payload = offset_and_len >> 16;\n\tunsigned int len = offset_and_len & 0xffff;\n\tskb_frag_t *frag;\n\tstruct page *page = data;\n\tu16 prod = rxr->rx_prod;\n\tstruct sk_buff *skb;\n\tint off, err;\n\n\terr = bnxt_alloc_rx_data(bp, rxr, prod, GFP_ATOMIC);\n\tif (unlikely(err)) {\n\t\tbnxt_reuse_rx_data(rxr, cons, data);\n\t\treturn NULL;\n\t}\n\tdma_addr -= bp->rx_dma_offset;\n\tdma_unmap_page_attrs(&bp->pdev->dev, dma_addr, PAGE_SIZE, bp->rx_dir,\n\t\t\t     DMA_ATTR_WEAK_ORDERING);\n\tpage_pool_release_page(rxr->page_pool, page);\n\n\tif (unlikely(!payload))\n\t\tpayload = eth_get_headlen(bp->dev, data_ptr, len);\n\n\tskb = napi_alloc_skb(&rxr->bnapi->napi, payload);\n\tif (!skb) {\n\t\t__free_page(page);\n\t\treturn NULL;\n\t}\n\n\toff = (void *)data_ptr - page_address(page);\n\tskb_add_rx_frag(skb, 0, page, off, len, PAGE_SIZE);\n\tmemcpy(skb->data - NET_IP_ALIGN, data_ptr - NET_IP_ALIGN,\n\t       payload + NET_IP_ALIGN);\n\n\tfrag = &skb_shinfo(skb)->frags[0];\n\tskb_frag_size_sub(frag, payload);\n\tskb_frag_off_add(frag, payload);\n\tskb->data_len -= payload;\n\tskb->tail += payload;\n\n\treturn skb;\n}\n\nstatic struct sk_buff *bnxt_rx_skb(struct bnxt *bp,\n\t\t\t\t   struct bnxt_rx_ring_info *rxr, u16 cons,\n\t\t\t\t   void *data, u8 *data_ptr,\n\t\t\t\t   dma_addr_t dma_addr,\n\t\t\t\t   unsigned int offset_and_len)\n{\n\tu16 prod = rxr->rx_prod;\n\tstruct sk_buff *skb;\n\tint err;\n\n\terr = bnxt_alloc_rx_data(bp, rxr, prod, GFP_ATOMIC);\n\tif (unlikely(err)) {\n\t\tbnxt_reuse_rx_data(rxr, cons, data);\n\t\treturn NULL;\n\t}\n\n\tskb = build_skb(data, 0);\n\tdma_unmap_single_attrs(&bp->pdev->dev, dma_addr, bp->rx_buf_use_size,\n\t\t\t       bp->rx_dir, DMA_ATTR_WEAK_ORDERING);\n\tif (!skb) {\n\t\tkfree(data);\n\t\treturn NULL;\n\t}\n\n\tskb_reserve(skb, bp->rx_offset);\n\tskb_put(skb, offset_and_len & 0xffff);\n\treturn skb;\n}\n\nstatic struct sk_buff *bnxt_rx_pages(struct bnxt *bp,\n\t\t\t\t     struct bnxt_cp_ring_info *cpr,\n\t\t\t\t     struct sk_buff *skb, u16 idx,\n\t\t\t\t     u32 agg_bufs, bool tpa)\n{\n\tstruct bnxt_napi *bnapi = cpr->bnapi;\n\tstruct pci_dev *pdev = bp->pdev;\n\tstruct bnxt_rx_ring_info *rxr = bnapi->rx_ring;\n\tu16 prod = rxr->rx_agg_prod;\n\tbool p5_tpa = false;\n\tu32 i;\n\n\tif ((bp->flags & BNXT_FLAG_CHIP_P5) && tpa)\n\t\tp5_tpa = true;\n\n\tfor (i = 0; i < agg_bufs; i++) {\n\t\tu16 cons, frag_len;\n\t\tstruct rx_agg_cmp *agg;\n\t\tstruct bnxt_sw_rx_agg_bd *cons_rx_buf;\n\t\tstruct page *page;\n\t\tdma_addr_t mapping;\n\n\t\tif (p5_tpa)\n\t\t\tagg = bnxt_get_tpa_agg_p5(bp, rxr, idx, i);\n\t\telse\n\t\t\tagg = bnxt_get_agg(bp, cpr, idx, i);\n\t\tcons = agg->rx_agg_cmp_opaque;\n\t\tfrag_len = (le32_to_cpu(agg->rx_agg_cmp_len_flags_type) &\n\t\t\t    RX_AGG_CMP_LEN) >> RX_AGG_CMP_LEN_SHIFT;\n\n\t\tcons_rx_buf = &rxr->rx_agg_ring[cons];\n\t\tskb_fill_page_desc(skb, i, cons_rx_buf->page,\n\t\t\t\t   cons_rx_buf->offset, frag_len);\n\t\t__clear_bit(cons, rxr->rx_agg_bmap);\n\n\t\t/* It is possible for bnxt_alloc_rx_page() to allocate\n\t\t * a sw_prod index that equals the cons index, so we\n\t\t * need to clear the cons entry now.\n\t\t */\n\t\tmapping = cons_rx_buf->mapping;\n\t\tpage = cons_rx_buf->page;\n\t\tcons_rx_buf->page = NULL;\n\n\t\tif (bnxt_alloc_rx_page(bp, rxr, prod, GFP_ATOMIC) != 0) {\n\t\t\tstruct skb_shared_info *shinfo;\n\t\t\tunsigned int nr_frags;\n\n\t\t\tshinfo = skb_shinfo(skb);\n\t\t\tnr_frags = --shinfo->nr_frags;\n\t\t\t__skb_frag_set_page(&shinfo->frags[nr_frags], NULL);\n\n\t\t\tdev_kfree_skb(skb);\n\n\t\t\tcons_rx_buf->page = page;\n\n\t\t\t/* Update prod since possibly some pages have been\n\t\t\t * allocated already.\n\t\t\t */\n\t\t\trxr->rx_agg_prod = prod;\n\t\t\tbnxt_reuse_rx_agg_bufs(cpr, idx, i, agg_bufs - i, tpa);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tdma_unmap_page_attrs(&pdev->dev, mapping, BNXT_RX_PAGE_SIZE,\n\t\t\t\t     PCI_DMA_FROMDEVICE,\n\t\t\t\t     DMA_ATTR_WEAK_ORDERING);\n\n\t\tskb->data_len += frag_len;\n\t\tskb->len += frag_len;\n\t\tskb->truesize += PAGE_SIZE;\n\n\t\tprod = NEXT_RX_AGG(prod);\n\t}\n\trxr->rx_agg_prod = prod;\n\treturn skb;\n}\n\nstatic int bnxt_agg_bufs_valid(struct bnxt *bp, struct bnxt_cp_ring_info *cpr,\n\t\t\t       u8 agg_bufs, u32 *raw_cons)\n{\n\tu16 last;\n\tstruct rx_agg_cmp *agg;\n\n\t*raw_cons = ADV_RAW_CMP(*raw_cons, agg_bufs);\n\tlast = RING_CMP(*raw_cons);\n\tagg = (struct rx_agg_cmp *)\n\t\t&cpr->cp_desc_ring[CP_RING(last)][CP_IDX(last)];\n\treturn RX_AGG_CMP_VALID(agg, *raw_cons);\n}\n\nstatic inline struct sk_buff *bnxt_copy_skb(struct bnxt_napi *bnapi, u8 *data,\n\t\t\t\t\t    unsigned int len,\n\t\t\t\t\t    dma_addr_t mapping)\n{\n\tstruct bnxt *bp = bnapi->bp;\n\tstruct pci_dev *pdev = bp->pdev;\n\tstruct sk_buff *skb;\n\n\tskb = napi_alloc_skb(&bnapi->napi, len);\n\tif (!skb)\n\t\treturn NULL;\n\n\tdma_sync_single_for_cpu(&pdev->dev, mapping, bp->rx_copy_thresh,\n\t\t\t\tbp->rx_dir);\n\n\tmemcpy(skb->data - NET_IP_ALIGN, data - NET_IP_ALIGN,\n\t       len + NET_IP_ALIGN);\n\n\tdma_sync_single_for_device(&pdev->dev, mapping, bp->rx_copy_thresh,\n\t\t\t\t   bp->rx_dir);\n\n\tskb_put(skb, len);\n\treturn skb;\n}\n\nstatic int bnxt_discard_rx(struct bnxt *bp, struct bnxt_cp_ring_info *cpr,\n\t\t\t   u32 *raw_cons, void *cmp)\n{\n\tstruct rx_cmp *rxcmp = cmp;\n\tu32 tmp_raw_cons = *raw_cons;\n\tu8 cmp_type, agg_bufs = 0;\n\n\tcmp_type = RX_CMP_TYPE(rxcmp);\n\n\tif (cmp_type == CMP_TYPE_RX_L2_CMP) {\n\t\tagg_bufs = (le32_to_cpu(rxcmp->rx_cmp_misc_v1) &\n\t\t\t    RX_CMP_AGG_BUFS) >>\n\t\t\t   RX_CMP_AGG_BUFS_SHIFT;\n\t} else if (cmp_type == CMP_TYPE_RX_L2_TPA_END_CMP) {\n\t\tstruct rx_tpa_end_cmp *tpa_end = cmp;\n\n\t\tif (bp->flags & BNXT_FLAG_CHIP_P5)\n\t\t\treturn 0;\n\n\t\tagg_bufs = TPA_END_AGG_BUFS(tpa_end);\n\t}\n\n\tif (agg_bufs) {\n\t\tif (!bnxt_agg_bufs_valid(bp, cpr, agg_bufs, &tmp_raw_cons))\n\t\t\treturn -EBUSY;\n\t}\n\t*raw_cons = tmp_raw_cons;\n\treturn 0;\n}\n\nstatic void bnxt_queue_fw_reset_work(struct bnxt *bp, unsigned long delay)\n{\n\tif (!(test_bit(BNXT_STATE_IN_FW_RESET, &bp->state)))\n\t\treturn;\n\n\tif (BNXT_PF(bp))\n\t\tqueue_delayed_work(bnxt_pf_wq, &bp->fw_reset_task, delay);\n\telse\n\t\tschedule_delayed_work(&bp->fw_reset_task, delay);\n}\n\nstatic void bnxt_queue_sp_work(struct bnxt *bp)\n{\n\tif (BNXT_PF(bp))\n\t\tqueue_work(bnxt_pf_wq, &bp->sp_task);\n\telse\n\t\tschedule_work(&bp->sp_task);\n}\n\nstatic void bnxt_sched_reset(struct bnxt *bp, struct bnxt_rx_ring_info *rxr)\n{\n\tif (!rxr->bnapi->in_reset) {\n\t\trxr->bnapi->in_reset = true;\n\t\tif (bp->flags & BNXT_FLAG_CHIP_P5)\n\t\t\tset_bit(BNXT_RESET_TASK_SP_EVENT, &bp->sp_event);\n\t\telse\n\t\t\tset_bit(BNXT_RST_RING_SP_EVENT, &bp->sp_event);\n\t\tbnxt_queue_sp_work(bp);\n\t}\n\trxr->rx_next_cons = 0xffff;\n}\n\nstatic u16 bnxt_alloc_agg_idx(struct bnxt_rx_ring_info *rxr, u16 agg_id)\n{\n\tstruct bnxt_tpa_idx_map *map = rxr->rx_tpa_idx_map;\n\tu16 idx = agg_id & MAX_TPA_P5_MASK;\n\n\tif (test_bit(idx, map->agg_idx_bmap))\n\t\tidx = find_first_zero_bit(map->agg_idx_bmap,\n\t\t\t\t\t  BNXT_AGG_IDX_BMAP_SIZE);\n\t__set_bit(idx, map->agg_idx_bmap);\n\tmap->agg_id_tbl[agg_id] = idx;\n\treturn idx;\n}\n\nstatic void bnxt_free_agg_idx(struct bnxt_rx_ring_info *rxr, u16 idx)\n{\n\tstruct bnxt_tpa_idx_map *map = rxr->rx_tpa_idx_map;\n\n\t__clear_bit(idx, map->agg_idx_bmap);\n}\n\nstatic u16 bnxt_lookup_agg_idx(struct bnxt_rx_ring_info *rxr, u16 agg_id)\n{\n\tstruct bnxt_tpa_idx_map *map = rxr->rx_tpa_idx_map;\n\n\treturn map->agg_id_tbl[agg_id];\n}\n\nstatic void bnxt_tpa_start(struct bnxt *bp, struct bnxt_rx_ring_info *rxr,\n\t\t\t   struct rx_tpa_start_cmp *tpa_start,\n\t\t\t   struct rx_tpa_start_cmp_ext *tpa_start1)\n{\n\tstruct bnxt_sw_rx_bd *cons_rx_buf, *prod_rx_buf;\n\tstruct bnxt_tpa_info *tpa_info;\n\tu16 cons, prod, agg_id;\n\tstruct rx_bd *prod_bd;\n\tdma_addr_t mapping;\n\n\tif (bp->flags & BNXT_FLAG_CHIP_P5) {\n\t\tagg_id = TPA_START_AGG_ID_P5(tpa_start);\n\t\tagg_id = bnxt_alloc_agg_idx(rxr, agg_id);\n\t} else {\n\t\tagg_id = TPA_START_AGG_ID(tpa_start);\n\t}\n\tcons = tpa_start->rx_tpa_start_cmp_opaque;\n\tprod = rxr->rx_prod;\n\tcons_rx_buf = &rxr->rx_buf_ring[cons];\n\tprod_rx_buf = &rxr->rx_buf_ring[prod];\n\ttpa_info = &rxr->rx_tpa[agg_id];\n\n\tif (unlikely(cons != rxr->rx_next_cons ||\n\t\t     TPA_START_ERROR(tpa_start))) {\n\t\tnetdev_warn(bp->dev, \"TPA cons %x, expected cons %x, error code %x\\n\",\n\t\t\t    cons, rxr->rx_next_cons,\n\t\t\t    TPA_START_ERROR_CODE(tpa_start1));\n\t\tbnxt_sched_reset(bp, rxr);\n\t\treturn;\n\t}\n\t/* Store cfa_code in tpa_info to use in tpa_end\n\t * completion processing.\n\t */\n\ttpa_info->cfa_code = TPA_START_CFA_CODE(tpa_start1);\n\tprod_rx_buf->data = tpa_info->data;\n\tprod_rx_buf->data_ptr = tpa_info->data_ptr;\n\n\tmapping = tpa_info->mapping;\n\tprod_rx_buf->mapping = mapping;\n\n\tprod_bd = &rxr->rx_desc_ring[RX_RING(prod)][RX_IDX(prod)];\n\n\tprod_bd->rx_bd_haddr = cpu_to_le64(mapping);\n\n\ttpa_info->data = cons_rx_buf->data;\n\ttpa_info->data_ptr = cons_rx_buf->data_ptr;\n\tcons_rx_buf->data = NULL;\n\ttpa_info->mapping = cons_rx_buf->mapping;\n\n\ttpa_info->len =\n\t\tle32_to_cpu(tpa_start->rx_tpa_start_cmp_len_flags_type) >>\n\t\t\t\tRX_TPA_START_CMP_LEN_SHIFT;\n\tif (likely(TPA_START_HASH_VALID(tpa_start))) {\n\t\tu32 hash_type = TPA_START_HASH_TYPE(tpa_start);\n\n\t\ttpa_info->hash_type = PKT_HASH_TYPE_L4;\n\t\ttpa_info->gso_type = SKB_GSO_TCPV4;\n\t\t/* RSS profiles 1 and 3 with extract code 0 for inner 4-tuple */\n\t\tif (hash_type == 3 || TPA_START_IS_IPV6(tpa_start1))\n\t\t\ttpa_info->gso_type = SKB_GSO_TCPV6;\n\t\ttpa_info->rss_hash =\n\t\t\tle32_to_cpu(tpa_start->rx_tpa_start_cmp_rss_hash);\n\t} else {\n\t\ttpa_info->hash_type = PKT_HASH_TYPE_NONE;\n\t\ttpa_info->gso_type = 0;\n\t\tnetif_warn(bp, rx_err, bp->dev, \"TPA packet without valid hash\\n\");\n\t}\n\ttpa_info->flags2 = le32_to_cpu(tpa_start1->rx_tpa_start_cmp_flags2);\n\ttpa_info->metadata = le32_to_cpu(tpa_start1->rx_tpa_start_cmp_metadata);\n\ttpa_info->hdr_info = le32_to_cpu(tpa_start1->rx_tpa_start_cmp_hdr_info);\n\ttpa_info->agg_count = 0;\n\n\trxr->rx_prod = NEXT_RX(prod);\n\tcons = NEXT_RX(cons);\n\trxr->rx_next_cons = NEXT_RX(cons);\n\tcons_rx_buf = &rxr->rx_buf_ring[cons];\n\n\tbnxt_reuse_rx_data(rxr, cons, cons_rx_buf->data);\n\trxr->rx_prod = NEXT_RX(rxr->rx_prod);\n\tcons_rx_buf->data = NULL;\n}\n\nstatic void bnxt_abort_tpa(struct bnxt_cp_ring_info *cpr, u16 idx, u32 agg_bufs)\n{\n\tif (agg_bufs)\n\t\tbnxt_reuse_rx_agg_bufs(cpr, idx, 0, agg_bufs, true);\n}\n\n#ifdef CONFIG_INET\nstatic void bnxt_gro_tunnel(struct sk_buff *skb, __be16 ip_proto)\n{\n\tstruct udphdr *uh = NULL;\n\n\tif (ip_proto == htons(ETH_P_IP)) {\n\t\tstruct iphdr *iph = (struct iphdr *)skb->data;\n\n\t\tif (iph->protocol == IPPROTO_UDP)\n\t\t\tuh = (struct udphdr *)(iph + 1);\n\t} else {\n\t\tstruct ipv6hdr *iph = (struct ipv6hdr *)skb->data;\n\n\t\tif (iph->nexthdr == IPPROTO_UDP)\n\t\t\tuh = (struct udphdr *)(iph + 1);\n\t}\n\tif (uh) {\n\t\tif (uh->check)\n\t\t\tskb_shinfo(skb)->gso_type |= SKB_GSO_UDP_TUNNEL_CSUM;\n\t\telse\n\t\t\tskb_shinfo(skb)->gso_type |= SKB_GSO_UDP_TUNNEL;\n\t}\n}\n#endif\n\nstatic struct sk_buff *bnxt_gro_func_5731x(struct bnxt_tpa_info *tpa_info,\n\t\t\t\t\t   int payload_off, int tcp_ts,\n\t\t\t\t\t   struct sk_buff *skb)\n{\n#ifdef CONFIG_INET\n\tstruct tcphdr *th;\n\tint len, nw_off;\n\tu16 outer_ip_off, inner_ip_off, inner_mac_off;\n\tu32 hdr_info = tpa_info->hdr_info;\n\tbool loopback = false;\n\n\tinner_ip_off = BNXT_TPA_INNER_L3_OFF(hdr_info);\n\tinner_mac_off = BNXT_TPA_INNER_L2_OFF(hdr_info);\n\touter_ip_off = BNXT_TPA_OUTER_L3_OFF(hdr_info);\n\n\t/* If the packet is an internal loopback packet, the offsets will\n\t * have an extra 4 bytes.\n\t */\n\tif (inner_mac_off == 4) {\n\t\tloopback = true;\n\t} else if (inner_mac_off > 4) {\n\t\t__be16 proto = *((__be16 *)(skb->data + inner_ip_off -\n\t\t\t\t\t    ETH_HLEN - 2));\n\n\t\t/* We only support inner iPv4/ipv6.  If we don't see the\n\t\t * correct protocol ID, it must be a loopback packet where\n\t\t * the offsets are off by 4.\n\t\t */\n\t\tif (proto != htons(ETH_P_IP) && proto != htons(ETH_P_IPV6))\n\t\t\tloopback = true;\n\t}\n\tif (loopback) {\n\t\t/* internal loopback packet, subtract all offsets by 4 */\n\t\tinner_ip_off -= 4;\n\t\tinner_mac_off -= 4;\n\t\touter_ip_off -= 4;\n\t}\n\n\tnw_off = inner_ip_off - ETH_HLEN;\n\tskb_set_network_header(skb, nw_off);\n\tif (tpa_info->flags2 & RX_TPA_START_CMP_FLAGS2_IP_TYPE) {\n\t\tstruct ipv6hdr *iph = ipv6_hdr(skb);\n\n\t\tskb_set_transport_header(skb, nw_off + sizeof(struct ipv6hdr));\n\t\tlen = skb->len - skb_transport_offset(skb);\n\t\tth = tcp_hdr(skb);\n\t\tth->check = ~tcp_v6_check(len, &iph->saddr, &iph->daddr, 0);\n\t} else {\n\t\tstruct iphdr *iph = ip_hdr(skb);\n\n\t\tskb_set_transport_header(skb, nw_off + sizeof(struct iphdr));\n\t\tlen = skb->len - skb_transport_offset(skb);\n\t\tth = tcp_hdr(skb);\n\t\tth->check = ~tcp_v4_check(len, iph->saddr, iph->daddr, 0);\n\t}\n\n\tif (inner_mac_off) { /* tunnel */\n\t\t__be16 proto = *((__be16 *)(skb->data + outer_ip_off -\n\t\t\t\t\t    ETH_HLEN - 2));\n\n\t\tbnxt_gro_tunnel(skb, proto);\n\t}\n#endif\n\treturn skb;\n}\n\nstatic struct sk_buff *bnxt_gro_func_5750x(struct bnxt_tpa_info *tpa_info,\n\t\t\t\t\t   int payload_off, int tcp_ts,\n\t\t\t\t\t   struct sk_buff *skb)\n{\n#ifdef CONFIG_INET\n\tu16 outer_ip_off, inner_ip_off, inner_mac_off;\n\tu32 hdr_info = tpa_info->hdr_info;\n\tint iphdr_len, nw_off;\n\n\tinner_ip_off = BNXT_TPA_INNER_L3_OFF(hdr_info);\n\tinner_mac_off = BNXT_TPA_INNER_L2_OFF(hdr_info);\n\touter_ip_off = BNXT_TPA_OUTER_L3_OFF(hdr_info);\n\n\tnw_off = inner_ip_off - ETH_HLEN;\n\tskb_set_network_header(skb, nw_off);\n\tiphdr_len = (tpa_info->flags2 & RX_TPA_START_CMP_FLAGS2_IP_TYPE) ?\n\t\t     sizeof(struct ipv6hdr) : sizeof(struct iphdr);\n\tskb_set_transport_header(skb, nw_off + iphdr_len);\n\n\tif (inner_mac_off) { /* tunnel */\n\t\t__be16 proto = *((__be16 *)(skb->data + outer_ip_off -\n\t\t\t\t\t    ETH_HLEN - 2));\n\n\t\tbnxt_gro_tunnel(skb, proto);\n\t}\n#endif\n\treturn skb;\n}\n\n#define BNXT_IPV4_HDR_SIZE\t(sizeof(struct iphdr) + sizeof(struct tcphdr))\n#define BNXT_IPV6_HDR_SIZE\t(sizeof(struct ipv6hdr) + sizeof(struct tcphdr))\n\nstatic struct sk_buff *bnxt_gro_func_5730x(struct bnxt_tpa_info *tpa_info,\n\t\t\t\t\t   int payload_off, int tcp_ts,\n\t\t\t\t\t   struct sk_buff *skb)\n{\n#ifdef CONFIG_INET\n\tstruct tcphdr *th;\n\tint len, nw_off, tcp_opt_len = 0;\n\n\tif (tcp_ts)\n\t\ttcp_opt_len = 12;\n\n\tif (tpa_info->gso_type == SKB_GSO_TCPV4) {\n\t\tstruct iphdr *iph;\n\n\t\tnw_off = payload_off - BNXT_IPV4_HDR_SIZE - tcp_opt_len -\n\t\t\t ETH_HLEN;\n\t\tskb_set_network_header(skb, nw_off);\n\t\tiph = ip_hdr(skb);\n\t\tskb_set_transport_header(skb, nw_off + sizeof(struct iphdr));\n\t\tlen = skb->len - skb_transport_offset(skb);\n\t\tth = tcp_hdr(skb);\n\t\tth->check = ~tcp_v4_check(len, iph->saddr, iph->daddr, 0);\n\t} else if (tpa_info->gso_type == SKB_GSO_TCPV6) {\n\t\tstruct ipv6hdr *iph;\n\n\t\tnw_off = payload_off - BNXT_IPV6_HDR_SIZE - tcp_opt_len -\n\t\t\t ETH_HLEN;\n\t\tskb_set_network_header(skb, nw_off);\n\t\tiph = ipv6_hdr(skb);\n\t\tskb_set_transport_header(skb, nw_off + sizeof(struct ipv6hdr));\n\t\tlen = skb->len - skb_transport_offset(skb);\n\t\tth = tcp_hdr(skb);\n\t\tth->check = ~tcp_v6_check(len, &iph->saddr, &iph->daddr, 0);\n\t} else {\n\t\tdev_kfree_skb_any(skb);\n\t\treturn NULL;\n\t}\n\n\tif (nw_off) /* tunnel */\n\t\tbnxt_gro_tunnel(skb, skb->protocol);\n#endif\n\treturn skb;\n}\n\nstatic inline struct sk_buff *bnxt_gro_skb(struct bnxt *bp,\n\t\t\t\t\t   struct bnxt_tpa_info *tpa_info,\n\t\t\t\t\t   struct rx_tpa_end_cmp *tpa_end,\n\t\t\t\t\t   struct rx_tpa_end_cmp_ext *tpa_end1,\n\t\t\t\t\t   struct sk_buff *skb)\n{\n#ifdef CONFIG_INET\n\tint payload_off;\n\tu16 segs;\n\n\tsegs = TPA_END_TPA_SEGS(tpa_end);\n\tif (segs == 1)\n\t\treturn skb;\n\n\tNAPI_GRO_CB(skb)->count = segs;\n\tskb_shinfo(skb)->gso_size =\n\t\tle32_to_cpu(tpa_end1->rx_tpa_end_cmp_seg_len);\n\tskb_shinfo(skb)->gso_type = tpa_info->gso_type;\n\tif (bp->flags & BNXT_FLAG_CHIP_P5)\n\t\tpayload_off = TPA_END_PAYLOAD_OFF_P5(tpa_end1);\n\telse\n\t\tpayload_off = TPA_END_PAYLOAD_OFF(tpa_end);\n\tskb = bp->gro_func(tpa_info, payload_off, TPA_END_GRO_TS(tpa_end), skb);\n\tif (likely(skb))\n\t\ttcp_gro_complete(skb);\n#endif\n\treturn skb;\n}\n\n/* Given the cfa_code of a received packet determine which\n * netdev (vf-rep or PF) the packet is destined to.\n */\nstatic struct net_device *bnxt_get_pkt_dev(struct bnxt *bp, u16 cfa_code)\n{\n\tstruct net_device *dev = bnxt_get_vf_rep(bp, cfa_code);\n\n\t/* if vf-rep dev is NULL, the must belongs to the PF */\n\treturn dev ? dev : bp->dev;\n}\n\nstatic inline struct sk_buff *bnxt_tpa_end(struct bnxt *bp,\n\t\t\t\t\t   struct bnxt_cp_ring_info *cpr,\n\t\t\t\t\t   u32 *raw_cons,\n\t\t\t\t\t   struct rx_tpa_end_cmp *tpa_end,\n\t\t\t\t\t   struct rx_tpa_end_cmp_ext *tpa_end1,\n\t\t\t\t\t   u8 *event)\n{\n\tstruct bnxt_napi *bnapi = cpr->bnapi;\n\tstruct bnxt_rx_ring_info *rxr = bnapi->rx_ring;\n\tu8 *data_ptr, agg_bufs;\n\tunsigned int len;\n\tstruct bnxt_tpa_info *tpa_info;\n\tdma_addr_t mapping;\n\tstruct sk_buff *skb;\n\tu16 idx = 0, agg_id;\n\tvoid *data;\n\tbool gro;\n\n\tif (unlikely(bnapi->in_reset)) {\n\t\tint rc = bnxt_discard_rx(bp, cpr, raw_cons, tpa_end);\n\n\t\tif (rc < 0)\n\t\t\treturn ERR_PTR(-EBUSY);\n\t\treturn NULL;\n\t}\n\n\tif (bp->flags & BNXT_FLAG_CHIP_P5) {\n\t\tagg_id = TPA_END_AGG_ID_P5(tpa_end);\n\t\tagg_id = bnxt_lookup_agg_idx(rxr, agg_id);\n\t\tagg_bufs = TPA_END_AGG_BUFS_P5(tpa_end1);\n\t\ttpa_info = &rxr->rx_tpa[agg_id];\n\t\tif (unlikely(agg_bufs != tpa_info->agg_count)) {\n\t\t\tnetdev_warn(bp->dev, \"TPA end agg_buf %d != expected agg_bufs %d\\n\",\n\t\t\t\t    agg_bufs, tpa_info->agg_count);\n\t\t\tagg_bufs = tpa_info->agg_count;\n\t\t}\n\t\ttpa_info->agg_count = 0;\n\t\t*event |= BNXT_AGG_EVENT;\n\t\tbnxt_free_agg_idx(rxr, agg_id);\n\t\tidx = agg_id;\n\t\tgro = !!(bp->flags & BNXT_FLAG_GRO);\n\t} else {\n\t\tagg_id = TPA_END_AGG_ID(tpa_end);\n\t\tagg_bufs = TPA_END_AGG_BUFS(tpa_end);\n\t\ttpa_info = &rxr->rx_tpa[agg_id];\n\t\tidx = RING_CMP(*raw_cons);\n\t\tif (agg_bufs) {\n\t\t\tif (!bnxt_agg_bufs_valid(bp, cpr, agg_bufs, raw_cons))\n\t\t\t\treturn ERR_PTR(-EBUSY);\n\n\t\t\t*event |= BNXT_AGG_EVENT;\n\t\t\tidx = NEXT_CMP(idx);\n\t\t}\n\t\tgro = !!TPA_END_GRO(tpa_end);\n\t}\n\tdata = tpa_info->data;\n\tdata_ptr = tpa_info->data_ptr;\n\tprefetch(data_ptr);\n\tlen = tpa_info->len;\n\tmapping = tpa_info->mapping;\n\n\tif (unlikely(agg_bufs > MAX_SKB_FRAGS || TPA_END_ERRORS(tpa_end1))) {\n\t\tbnxt_abort_tpa(cpr, idx, agg_bufs);\n\t\tif (agg_bufs > MAX_SKB_FRAGS)\n\t\t\tnetdev_warn(bp->dev, \"TPA frags %d exceeded MAX_SKB_FRAGS %d\\n\",\n\t\t\t\t    agg_bufs, (int)MAX_SKB_FRAGS);\n\t\treturn NULL;\n\t}\n\n\tif (len <= bp->rx_copy_thresh) {\n\t\tskb = bnxt_copy_skb(bnapi, data_ptr, len, mapping);\n\t\tif (!skb) {\n\t\t\tbnxt_abort_tpa(cpr, idx, agg_bufs);\n\t\t\treturn NULL;\n\t\t}\n\t} else {\n\t\tu8 *new_data;\n\t\tdma_addr_t new_mapping;\n\n\t\tnew_data = __bnxt_alloc_rx_data(bp, &new_mapping, GFP_ATOMIC);\n\t\tif (!new_data) {\n\t\t\tbnxt_abort_tpa(cpr, idx, agg_bufs);\n\t\t\treturn NULL;\n\t\t}\n\n\t\ttpa_info->data = new_data;\n\t\ttpa_info->data_ptr = new_data + bp->rx_offset;\n\t\ttpa_info->mapping = new_mapping;\n\n\t\tskb = build_skb(data, 0);\n\t\tdma_unmap_single_attrs(&bp->pdev->dev, mapping,\n\t\t\t\t       bp->rx_buf_use_size, bp->rx_dir,\n\t\t\t\t       DMA_ATTR_WEAK_ORDERING);\n\n\t\tif (!skb) {\n\t\t\tkfree(data);\n\t\t\tbnxt_abort_tpa(cpr, idx, agg_bufs);\n\t\t\treturn NULL;\n\t\t}\n\t\tskb_reserve(skb, bp->rx_offset);\n\t\tskb_put(skb, len);\n\t}\n\n\tif (agg_bufs) {\n\t\tskb = bnxt_rx_pages(bp, cpr, skb, idx, agg_bufs, true);\n\t\tif (!skb) {\n\t\t\t/* Page reuse already handled by bnxt_rx_pages(). */\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\tskb->protocol =\n\t\teth_type_trans(skb, bnxt_get_pkt_dev(bp, tpa_info->cfa_code));\n\n\tif (tpa_info->hash_type != PKT_HASH_TYPE_NONE)\n\t\tskb_set_hash(skb, tpa_info->rss_hash, tpa_info->hash_type);\n\n\tif ((tpa_info->flags2 & RX_CMP_FLAGS2_META_FORMAT_VLAN) &&\n\t    (skb->dev->features & BNXT_HW_FEATURE_VLAN_ALL_RX)) {\n\t\tu16 vlan_proto = tpa_info->metadata >>\n\t\t\tRX_CMP_FLAGS2_METADATA_TPID_SFT;\n\t\tu16 vtag = tpa_info->metadata & RX_CMP_FLAGS2_METADATA_TCI_MASK;\n\n\t\t__vlan_hwaccel_put_tag(skb, htons(vlan_proto), vtag);\n\t}\n\n\tskb_checksum_none_assert(skb);\n\tif (likely(tpa_info->flags2 & RX_TPA_START_CMP_FLAGS2_L4_CS_CALC)) {\n\t\tskb->ip_summed = CHECKSUM_UNNECESSARY;\n\t\tskb->csum_level =\n\t\t\t(tpa_info->flags2 & RX_CMP_FLAGS2_T_L4_CS_CALC) >> 3;\n\t}\n\n\tif (gro)\n\t\tskb = bnxt_gro_skb(bp, tpa_info, tpa_end, tpa_end1, skb);\n\n\treturn skb;\n}\n\nstatic void bnxt_tpa_agg(struct bnxt *bp, struct bnxt_rx_ring_info *rxr,\n\t\t\t struct rx_agg_cmp *rx_agg)\n{\n\tu16 agg_id = TPA_AGG_AGG_ID(rx_agg);\n\tstruct bnxt_tpa_info *tpa_info;\n\n\tagg_id = bnxt_lookup_agg_idx(rxr, agg_id);\n\ttpa_info = &rxr->rx_tpa[agg_id];\n\tBUG_ON(tpa_info->agg_count >= MAX_SKB_FRAGS);\n\ttpa_info->agg_arr[tpa_info->agg_count++] = *rx_agg;\n}\n\nstatic void bnxt_deliver_skb(struct bnxt *bp, struct bnxt_napi *bnapi,\n\t\t\t     struct sk_buff *skb)\n{\n\tif (skb->dev != bp->dev) {\n\t\t/* this packet belongs to a vf-rep */\n\t\tbnxt_vf_rep_rx(bp, skb);\n\t\treturn;\n\t}\n\tskb_record_rx_queue(skb, bnapi->index);\n\tnapi_gro_receive(&bnapi->napi, skb);\n}\n\n/* returns the following:\n * 1       - 1 packet successfully received\n * 0       - successful TPA_START, packet not completed yet\n * -EBUSY  - completion ring does not have all the agg buffers yet\n * -ENOMEM - packet aborted due to out of memory\n * -EIO    - packet aborted due to hw error indicated in BD\n */\nstatic int bnxt_rx_pkt(struct bnxt *bp, struct bnxt_cp_ring_info *cpr,\n\t\t       u32 *raw_cons, u8 *event)\n{\n\tstruct bnxt_napi *bnapi = cpr->bnapi;\n\tstruct bnxt_rx_ring_info *rxr = bnapi->rx_ring;\n\tstruct net_device *dev = bp->dev;\n\tstruct rx_cmp *rxcmp;\n\tstruct rx_cmp_ext *rxcmp1;\n\tu32 tmp_raw_cons = *raw_cons;\n\tu16 cfa_code, cons, prod, cp_cons = RING_CMP(tmp_raw_cons);\n\tstruct bnxt_sw_rx_bd *rx_buf;\n\tunsigned int len;\n\tu8 *data_ptr, agg_bufs, cmp_type;\n\tdma_addr_t dma_addr;\n\tstruct sk_buff *skb;\n\tvoid *data;\n\tint rc = 0;\n\tu32 misc;\n\n\trxcmp = (struct rx_cmp *)\n\t\t\t&cpr->cp_desc_ring[CP_RING(cp_cons)][CP_IDX(cp_cons)];\n\n\tcmp_type = RX_CMP_TYPE(rxcmp);\n\n\tif (cmp_type == CMP_TYPE_RX_TPA_AGG_CMP) {\n\t\tbnxt_tpa_agg(bp, rxr, (struct rx_agg_cmp *)rxcmp);\n\t\tgoto next_rx_no_prod_no_len;\n\t}\n\n\ttmp_raw_cons = NEXT_RAW_CMP(tmp_raw_cons);\n\tcp_cons = RING_CMP(tmp_raw_cons);\n\trxcmp1 = (struct rx_cmp_ext *)\n\t\t\t&cpr->cp_desc_ring[CP_RING(cp_cons)][CP_IDX(cp_cons)];\n\n\tif (!RX_CMP_VALID(rxcmp1, tmp_raw_cons))\n\t\treturn -EBUSY;\n\n\tprod = rxr->rx_prod;\n\n\tif (cmp_type == CMP_TYPE_RX_L2_TPA_START_CMP) {\n\t\tbnxt_tpa_start(bp, rxr, (struct rx_tpa_start_cmp *)rxcmp,\n\t\t\t       (struct rx_tpa_start_cmp_ext *)rxcmp1);\n\n\t\t*event |= BNXT_RX_EVENT;\n\t\tgoto next_rx_no_prod_no_len;\n\n\t} else if (cmp_type == CMP_TYPE_RX_L2_TPA_END_CMP) {\n\t\tskb = bnxt_tpa_end(bp, cpr, &tmp_raw_cons,\n\t\t\t\t   (struct rx_tpa_end_cmp *)rxcmp,\n\t\t\t\t   (struct rx_tpa_end_cmp_ext *)rxcmp1, event);\n\n\t\tif (IS_ERR(skb))\n\t\t\treturn -EBUSY;\n\n\t\trc = -ENOMEM;\n\t\tif (likely(skb)) {\n\t\t\tbnxt_deliver_skb(bp, bnapi, skb);\n\t\t\trc = 1;\n\t\t}\n\t\t*event |= BNXT_RX_EVENT;\n\t\tgoto next_rx_no_prod_no_len;\n\t}\n\n\tcons = rxcmp->rx_cmp_opaque;\n\tif (unlikely(cons != rxr->rx_next_cons)) {\n\t\tint rc1 = bnxt_discard_rx(bp, cpr, raw_cons, rxcmp);\n\n\t\t/* 0xffff is forced error, don't print it */\n\t\tif (rxr->rx_next_cons != 0xffff)\n\t\t\tnetdev_warn(bp->dev, \"RX cons %x != expected cons %x\\n\",\n\t\t\t\t    cons, rxr->rx_next_cons);\n\t\tbnxt_sched_reset(bp, rxr);\n\t\treturn rc1;\n\t}\n\trx_buf = &rxr->rx_buf_ring[cons];\n\tdata = rx_buf->data;\n\tdata_ptr = rx_buf->data_ptr;\n\tprefetch(data_ptr);\n\n\tmisc = le32_to_cpu(rxcmp->rx_cmp_misc_v1);\n\tagg_bufs = (misc & RX_CMP_AGG_BUFS) >> RX_CMP_AGG_BUFS_SHIFT;\n\n\tif (agg_bufs) {\n\t\tif (!bnxt_agg_bufs_valid(bp, cpr, agg_bufs, &tmp_raw_cons))\n\t\t\treturn -EBUSY;\n\n\t\tcp_cons = NEXT_CMP(cp_cons);\n\t\t*event |= BNXT_AGG_EVENT;\n\t}\n\t*event |= BNXT_RX_EVENT;\n\n\trx_buf->data = NULL;\n\tif (rxcmp1->rx_cmp_cfa_code_errors_v2 & RX_CMP_L2_ERRORS) {\n\t\tu32 rx_err = le32_to_cpu(rxcmp1->rx_cmp_cfa_code_errors_v2);\n\n\t\tbnxt_reuse_rx_data(rxr, cons, data);\n\t\tif (agg_bufs)\n\t\t\tbnxt_reuse_rx_agg_bufs(cpr, cp_cons, 0, agg_bufs,\n\t\t\t\t\t       false);\n\n\t\trc = -EIO;\n\t\tif (rx_err & RX_CMPL_ERRORS_BUFFER_ERROR_MASK) {\n\t\t\tbnapi->cp_ring.sw_stats.rx.rx_buf_errors++;\n\t\t\tif (!(bp->flags & BNXT_FLAG_CHIP_P5) &&\n\t\t\t    !(bp->fw_cap & BNXT_FW_CAP_RING_MONITOR)) {\n\t\t\t\tnetdev_warn_once(bp->dev, \"RX buffer error %x\\n\",\n\t\t\t\t\t\t rx_err);\n\t\t\t\tbnxt_sched_reset(bp, rxr);\n\t\t\t}\n\t\t}\n\t\tgoto next_rx_no_len;\n\t}\n\n\tlen = le32_to_cpu(rxcmp->rx_cmp_len_flags_type) >> RX_CMP_LEN_SHIFT;\n\tdma_addr = rx_buf->mapping;\n\n\tif (bnxt_rx_xdp(bp, rxr, cons, data, &data_ptr, &len, event)) {\n\t\trc = 1;\n\t\tgoto next_rx;\n\t}\n\n\tif (len <= bp->rx_copy_thresh) {\n\t\tskb = bnxt_copy_skb(bnapi, data_ptr, len, dma_addr);\n\t\tbnxt_reuse_rx_data(rxr, cons, data);\n\t\tif (!skb) {\n\t\t\tif (agg_bufs)\n\t\t\t\tbnxt_reuse_rx_agg_bufs(cpr, cp_cons, 0,\n\t\t\t\t\t\t       agg_bufs, false);\n\t\t\trc = -ENOMEM;\n\t\t\tgoto next_rx;\n\t\t}\n\t} else {\n\t\tu32 payload;\n\n\t\tif (rx_buf->data_ptr == data_ptr)\n\t\t\tpayload = misc & RX_CMP_PAYLOAD_OFFSET;\n\t\telse\n\t\t\tpayload = 0;\n\t\tskb = bp->rx_skb_func(bp, rxr, cons, data, data_ptr, dma_addr,\n\t\t\t\t      payload | len);\n\t\tif (!skb) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto next_rx;\n\t\t}\n\t}\n\n\tif (agg_bufs) {\n\t\tskb = bnxt_rx_pages(bp, cpr, skb, cp_cons, agg_bufs, false);\n\t\tif (!skb) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto next_rx;\n\t\t}\n\t}\n\n\tif (RX_CMP_HASH_VALID(rxcmp)) {\n\t\tu32 hash_type = RX_CMP_HASH_TYPE(rxcmp);\n\t\tenum pkt_hash_types type = PKT_HASH_TYPE_L4;\n\n\t\t/* RSS profiles 1 and 3 with extract code 0 for inner 4-tuple */\n\t\tif (hash_type != 1 && hash_type != 3)\n\t\t\ttype = PKT_HASH_TYPE_L3;\n\t\tskb_set_hash(skb, le32_to_cpu(rxcmp->rx_cmp_rss_hash), type);\n\t}\n\n\tcfa_code = RX_CMP_CFA_CODE(rxcmp1);\n\tskb->protocol = eth_type_trans(skb, bnxt_get_pkt_dev(bp, cfa_code));\n\n\tif ((rxcmp1->rx_cmp_flags2 &\n\t     cpu_to_le32(RX_CMP_FLAGS2_META_FORMAT_VLAN)) &&\n\t    (skb->dev->features & BNXT_HW_FEATURE_VLAN_ALL_RX)) {\n\t\tu32 meta_data = le32_to_cpu(rxcmp1->rx_cmp_meta_data);\n\t\tu16 vtag = meta_data & RX_CMP_FLAGS2_METADATA_TCI_MASK;\n\t\tu16 vlan_proto = meta_data >> RX_CMP_FLAGS2_METADATA_TPID_SFT;\n\n\t\t__vlan_hwaccel_put_tag(skb, htons(vlan_proto), vtag);\n\t}\n\n\tskb_checksum_none_assert(skb);\n\tif (RX_CMP_L4_CS_OK(rxcmp1)) {\n\t\tif (dev->features & NETIF_F_RXCSUM) {\n\t\t\tskb->ip_summed = CHECKSUM_UNNECESSARY;\n\t\t\tskb->csum_level = RX_CMP_ENCAP(rxcmp1);\n\t\t}\n\t} else {\n\t\tif (rxcmp1->rx_cmp_cfa_code_errors_v2 & RX_CMP_L4_CS_ERR_BITS) {\n\t\t\tif (dev->features & NETIF_F_RXCSUM)\n\t\t\t\tbnapi->cp_ring.sw_stats.rx.rx_l4_csum_errors++;\n\t\t}\n\t}\n\n\tbnxt_deliver_skb(bp, bnapi, skb);\n\trc = 1;\n\nnext_rx:\n\tcpr->rx_packets += 1;\n\tcpr->rx_bytes += len;\n\nnext_rx_no_len:\n\trxr->rx_prod = NEXT_RX(prod);\n\trxr->rx_next_cons = NEXT_RX(cons);\n\nnext_rx_no_prod_no_len:\n\t*raw_cons = tmp_raw_cons;\n\n\treturn rc;\n}\n\n/* In netpoll mode, if we are using a combined completion ring, we need to\n * discard the rx packets and recycle the buffers.\n */\nstatic int bnxt_force_rx_discard(struct bnxt *bp,\n\t\t\t\t struct bnxt_cp_ring_info *cpr,\n\t\t\t\t u32 *raw_cons, u8 *event)\n{\n\tu32 tmp_raw_cons = *raw_cons;\n\tstruct rx_cmp_ext *rxcmp1;\n\tstruct rx_cmp *rxcmp;\n\tu16 cp_cons;\n\tu8 cmp_type;\n\n\tcp_cons = RING_CMP(tmp_raw_cons);\n\trxcmp = (struct rx_cmp *)\n\t\t\t&cpr->cp_desc_ring[CP_RING(cp_cons)][CP_IDX(cp_cons)];\n\n\ttmp_raw_cons = NEXT_RAW_CMP(tmp_raw_cons);\n\tcp_cons = RING_CMP(tmp_raw_cons);\n\trxcmp1 = (struct rx_cmp_ext *)\n\t\t\t&cpr->cp_desc_ring[CP_RING(cp_cons)][CP_IDX(cp_cons)];\n\n\tif (!RX_CMP_VALID(rxcmp1, tmp_raw_cons))\n\t\treturn -EBUSY;\n\n\tcmp_type = RX_CMP_TYPE(rxcmp);\n\tif (cmp_type == CMP_TYPE_RX_L2_CMP) {\n\t\trxcmp1->rx_cmp_cfa_code_errors_v2 |=\n\t\t\tcpu_to_le32(RX_CMPL_ERRORS_CRC_ERROR);\n\t} else if (cmp_type == CMP_TYPE_RX_L2_TPA_END_CMP) {\n\t\tstruct rx_tpa_end_cmp_ext *tpa_end1;\n\n\t\ttpa_end1 = (struct rx_tpa_end_cmp_ext *)rxcmp1;\n\t\ttpa_end1->rx_tpa_end_cmp_errors_v2 |=\n\t\t\tcpu_to_le32(RX_TPA_END_CMP_ERRORS);\n\t}\n\treturn bnxt_rx_pkt(bp, cpr, raw_cons, event);\n}\n\nu32 bnxt_fw_health_readl(struct bnxt *bp, int reg_idx)\n{\n\tstruct bnxt_fw_health *fw_health = bp->fw_health;\n\tu32 reg = fw_health->regs[reg_idx];\n\tu32 reg_type, reg_off, val = 0;\n\n\treg_type = BNXT_FW_HEALTH_REG_TYPE(reg);\n\treg_off = BNXT_FW_HEALTH_REG_OFF(reg);\n\tswitch (reg_type) {\n\tcase BNXT_FW_HEALTH_REG_TYPE_CFG:\n\t\tpci_read_config_dword(bp->pdev, reg_off, &val);\n\t\tbreak;\n\tcase BNXT_FW_HEALTH_REG_TYPE_GRC:\n\t\treg_off = fw_health->mapped_regs[reg_idx];\n\t\tfallthrough;\n\tcase BNXT_FW_HEALTH_REG_TYPE_BAR0:\n\t\tval = readl(bp->bar0 + reg_off);\n\t\tbreak;\n\tcase BNXT_FW_HEALTH_REG_TYPE_BAR1:\n\t\tval = readl(bp->bar1 + reg_off);\n\t\tbreak;\n\t}\n\tif (reg_idx == BNXT_FW_RESET_INPROG_REG)\n\t\tval &= fw_health->fw_reset_inprog_reg_mask;\n\treturn val;\n}\n\nstatic u16 bnxt_agg_ring_id_to_grp_idx(struct bnxt *bp, u16 ring_id)\n{\n\tint i;\n\n\tfor (i = 0; i < bp->rx_nr_rings; i++) {\n\t\tu16 grp_idx = bp->rx_ring[i].bnapi->index;\n\t\tstruct bnxt_ring_grp_info *grp_info;\n\n\t\tgrp_info = &bp->grp_info[grp_idx];\n\t\tif (grp_info->agg_fw_ring_id == ring_id)\n\t\t\treturn grp_idx;\n\t}\n\treturn INVALID_HW_RING_ID;\n}\n\n#define BNXT_GET_EVENT_PORT(data)\t\\\n\t((data) &\t\t\t\\\n\t ASYNC_EVENT_CMPL_PORT_CONN_NOT_ALLOWED_EVENT_DATA1_PORT_ID_MASK)\n\n#define BNXT_EVENT_RING_TYPE(data2)\t\\\n\t((data2) &\t\t\t\\\n\t ASYNC_EVENT_CMPL_RING_MONITOR_MSG_EVENT_DATA2_DISABLE_RING_TYPE_MASK)\n\n#define BNXT_EVENT_RING_TYPE_RX(data2)\t\\\n\t(BNXT_EVENT_RING_TYPE(data2) ==\t\\\n\t ASYNC_EVENT_CMPL_RING_MONITOR_MSG_EVENT_DATA2_DISABLE_RING_TYPE_RX)\n\nstatic int bnxt_async_event_process(struct bnxt *bp,\n\t\t\t\t    struct hwrm_async_event_cmpl *cmpl)\n{\n\tu16 event_id = le16_to_cpu(cmpl->event_id);\n\tu32 data1 = le32_to_cpu(cmpl->event_data1);\n\tu32 data2 = le32_to_cpu(cmpl->event_data2);\n\n\t/* TODO CHIMP_FW: Define event id's for link change, error etc */\n\tswitch (event_id) {\n\tcase ASYNC_EVENT_CMPL_EVENT_ID_LINK_SPEED_CFG_CHANGE: {\n\t\tstruct bnxt_link_info *link_info = &bp->link_info;\n\n\t\tif (BNXT_VF(bp))\n\t\t\tgoto async_event_process_exit;\n\n\t\t/* print unsupported speed warning in forced speed mode only */\n\t\tif (!(link_info->autoneg & BNXT_AUTONEG_SPEED) &&\n\t\t    (data1 & 0x20000)) {\n\t\t\tu16 fw_speed = link_info->force_link_speed;\n\t\t\tu32 speed = bnxt_fw_to_ethtool_speed(fw_speed);\n\n\t\t\tif (speed != SPEED_UNKNOWN)\n\t\t\t\tnetdev_warn(bp->dev, \"Link speed %d no longer supported\\n\",\n\t\t\t\t\t    speed);\n\t\t}\n\t\tset_bit(BNXT_LINK_SPEED_CHNG_SP_EVENT, &bp->sp_event);\n\t}\n\t\tfallthrough;\n\tcase ASYNC_EVENT_CMPL_EVENT_ID_LINK_SPEED_CHANGE:\n\tcase ASYNC_EVENT_CMPL_EVENT_ID_PORT_PHY_CFG_CHANGE:\n\t\tset_bit(BNXT_LINK_CFG_CHANGE_SP_EVENT, &bp->sp_event);\n\t\tfallthrough;\n\tcase ASYNC_EVENT_CMPL_EVENT_ID_LINK_STATUS_CHANGE:\n\t\tset_bit(BNXT_LINK_CHNG_SP_EVENT, &bp->sp_event);\n\t\tbreak;\n\tcase ASYNC_EVENT_CMPL_EVENT_ID_PF_DRVR_UNLOAD:\n\t\tset_bit(BNXT_HWRM_PF_UNLOAD_SP_EVENT, &bp->sp_event);\n\t\tbreak;\n\tcase ASYNC_EVENT_CMPL_EVENT_ID_PORT_CONN_NOT_ALLOWED: {\n\t\tu16 port_id = BNXT_GET_EVENT_PORT(data1);\n\n\t\tif (BNXT_VF(bp))\n\t\t\tbreak;\n\n\t\tif (bp->pf.port_id != port_id)\n\t\t\tbreak;\n\n\t\tset_bit(BNXT_HWRM_PORT_MODULE_SP_EVENT, &bp->sp_event);\n\t\tbreak;\n\t}\n\tcase ASYNC_EVENT_CMPL_EVENT_ID_VF_CFG_CHANGE:\n\t\tif (BNXT_PF(bp))\n\t\t\tgoto async_event_process_exit;\n\t\tset_bit(BNXT_RESET_TASK_SILENT_SP_EVENT, &bp->sp_event);\n\t\tbreak;\n\tcase ASYNC_EVENT_CMPL_EVENT_ID_RESET_NOTIFY: {\n\t\tchar *fatal_str = \"non-fatal\";\n\n\t\tif (!bp->fw_health)\n\t\t\tgoto async_event_process_exit;\n\n\t\tbp->fw_reset_timestamp = jiffies;\n\t\tbp->fw_reset_min_dsecs = cmpl->timestamp_lo;\n\t\tif (!bp->fw_reset_min_dsecs)\n\t\t\tbp->fw_reset_min_dsecs = BNXT_DFLT_FW_RST_MIN_DSECS;\n\t\tbp->fw_reset_max_dsecs = le16_to_cpu(cmpl->timestamp_hi);\n\t\tif (!bp->fw_reset_max_dsecs)\n\t\t\tbp->fw_reset_max_dsecs = BNXT_DFLT_FW_RST_MAX_DSECS;\n\t\tif (EVENT_DATA1_RESET_NOTIFY_FATAL(data1)) {\n\t\t\tfatal_str = \"fatal\";\n\t\t\tset_bit(BNXT_STATE_FW_FATAL_COND, &bp->state);\n\t\t}\n\t\tnetif_warn(bp, hw, bp->dev,\n\t\t\t   \"Firmware %s reset event, data1: 0x%x, data2: 0x%x, min wait %u ms, max wait %u ms\\n\",\n\t\t\t   fatal_str, data1, data2,\n\t\t\t   bp->fw_reset_min_dsecs * 100,\n\t\t\t   bp->fw_reset_max_dsecs * 100);\n\t\tset_bit(BNXT_FW_RESET_NOTIFY_SP_EVENT, &bp->sp_event);\n\t\tbreak;\n\t}\n\tcase ASYNC_EVENT_CMPL_EVENT_ID_ERROR_RECOVERY: {\n\t\tstruct bnxt_fw_health *fw_health = bp->fw_health;\n\n\t\tif (!fw_health)\n\t\t\tgoto async_event_process_exit;\n\n\t\tfw_health->enabled = EVENT_DATA1_RECOVERY_ENABLED(data1);\n\t\tfw_health->master = EVENT_DATA1_RECOVERY_MASTER_FUNC(data1);\n\t\tif (!fw_health->enabled) {\n\t\t\tnetif_info(bp, drv, bp->dev,\n\t\t\t\t   \"Error recovery info: error recovery[0]\\n\");\n\t\t\tbreak;\n\t\t}\n\t\tfw_health->tmr_multiplier =\n\t\t\tDIV_ROUND_UP(fw_health->polling_dsecs * HZ,\n\t\t\t\t     bp->current_interval * 10);\n\t\tfw_health->tmr_counter = fw_health->tmr_multiplier;\n\t\tfw_health->last_fw_heartbeat =\n\t\t\tbnxt_fw_health_readl(bp, BNXT_FW_HEARTBEAT_REG);\n\t\tfw_health->last_fw_reset_cnt =\n\t\t\tbnxt_fw_health_readl(bp, BNXT_FW_RESET_CNT_REG);\n\t\tnetif_info(bp, drv, bp->dev,\n\t\t\t   \"Error recovery info: error recovery[1], master[%d], reset count[%u], health status: 0x%x\\n\",\n\t\t\t   fw_health->master, fw_health->last_fw_reset_cnt,\n\t\t\t   bnxt_fw_health_readl(bp, BNXT_FW_HEALTH_REG));\n\t\tgoto async_event_process_exit;\n\t}\n\tcase ASYNC_EVENT_CMPL_EVENT_ID_DEBUG_NOTIFICATION:\n\t\tnetif_notice(bp, hw, bp->dev,\n\t\t\t     \"Received firmware debug notification, data1: 0x%x, data2: 0x%x\\n\",\n\t\t\t     data1, data2);\n\t\tgoto async_event_process_exit;\n\tcase ASYNC_EVENT_CMPL_EVENT_ID_RING_MONITOR_MSG: {\n\t\tstruct bnxt_rx_ring_info *rxr;\n\t\tu16 grp_idx;\n\n\t\tif (bp->flags & BNXT_FLAG_CHIP_P5)\n\t\t\tgoto async_event_process_exit;\n\n\t\tnetdev_warn(bp->dev, \"Ring monitor event, ring type %lu id 0x%x\\n\",\n\t\t\t    BNXT_EVENT_RING_TYPE(data2), data1);\n\t\tif (!BNXT_EVENT_RING_TYPE_RX(data2))\n\t\t\tgoto async_event_process_exit;\n\n\t\tgrp_idx = bnxt_agg_ring_id_to_grp_idx(bp, data1);\n\t\tif (grp_idx == INVALID_HW_RING_ID) {\n\t\t\tnetdev_warn(bp->dev, \"Unknown RX agg ring id 0x%x\\n\",\n\t\t\t\t    data1);\n\t\t\tgoto async_event_process_exit;\n\t\t}\n\t\trxr = bp->bnapi[grp_idx]->rx_ring;\n\t\tbnxt_sched_reset(bp, rxr);\n\t\tgoto async_event_process_exit;\n\t}\n\tcase ASYNC_EVENT_CMPL_EVENT_ID_ECHO_REQUEST: {\n\t\tstruct bnxt_fw_health *fw_health = bp->fw_health;\n\n\t\tnetif_notice(bp, hw, bp->dev,\n\t\t\t     \"Received firmware echo request, data1: 0x%x, data2: 0x%x\\n\",\n\t\t\t     data1, data2);\n\t\tif (fw_health) {\n\t\t\tfw_health->echo_req_data1 = data1;\n\t\t\tfw_health->echo_req_data2 = data2;\n\t\t\tset_bit(BNXT_FW_ECHO_REQUEST_SP_EVENT, &bp->sp_event);\n\t\t\tbreak;\n\t\t}\n\t\tgoto async_event_process_exit;\n\t}\n\tdefault:\n\t\tgoto async_event_process_exit;\n\t}\n\tbnxt_queue_sp_work(bp);\nasync_event_process_exit:\n\tbnxt_ulp_async_events(bp, cmpl);\n\treturn 0;\n}\n\nstatic int bnxt_hwrm_handler(struct bnxt *bp, struct tx_cmp *txcmp)\n{\n\tu16 cmpl_type = TX_CMP_TYPE(txcmp), vf_id, seq_id;\n\tstruct hwrm_cmpl *h_cmpl = (struct hwrm_cmpl *)txcmp;\n\tstruct hwrm_fwd_req_cmpl *fwd_req_cmpl =\n\t\t\t\t(struct hwrm_fwd_req_cmpl *)txcmp;\n\n\tswitch (cmpl_type) {\n\tcase CMPL_BASE_TYPE_HWRM_DONE:\n\t\tseq_id = le16_to_cpu(h_cmpl->sequence_id);\n\t\tif (seq_id == bp->hwrm_intr_seq_id)\n\t\t\tbp->hwrm_intr_seq_id = (u16)~bp->hwrm_intr_seq_id;\n\t\telse\n\t\t\tnetdev_err(bp->dev, \"Invalid hwrm seq id %d\\n\", seq_id);\n\t\tbreak;\n\n\tcase CMPL_BASE_TYPE_HWRM_FWD_REQ:\n\t\tvf_id = le16_to_cpu(fwd_req_cmpl->source_id);\n\n\t\tif ((vf_id < bp->pf.first_vf_id) ||\n\t\t    (vf_id >= bp->pf.first_vf_id + bp->pf.active_vfs)) {\n\t\t\tnetdev_err(bp->dev, \"Msg contains invalid VF id %x\\n\",\n\t\t\t\t   vf_id);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tset_bit(vf_id - bp->pf.first_vf_id, bp->pf.vf_event_bmap);\n\t\tset_bit(BNXT_HWRM_EXEC_FWD_REQ_SP_EVENT, &bp->sp_event);\n\t\tbnxt_queue_sp_work(bp);\n\t\tbreak;\n\n\tcase CMPL_BASE_TYPE_HWRM_ASYNC_EVENT:\n\t\tbnxt_async_event_process(bp,\n\t\t\t\t\t (struct hwrm_async_event_cmpl *)txcmp);\n\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nstatic irqreturn_t bnxt_msix(int irq, void *dev_instance)\n{\n\tstruct bnxt_napi *bnapi = dev_instance;\n\tstruct bnxt *bp = bnapi->bp;\n\tstruct bnxt_cp_ring_info *cpr = &bnapi->cp_ring;\n\tu32 cons = RING_CMP(cpr->cp_raw_cons);\n\n\tcpr->event_ctr++;\n\tprefetch(&cpr->cp_desc_ring[CP_RING(cons)][CP_IDX(cons)]);\n\tnapi_schedule(&bnapi->napi);\n\treturn IRQ_HANDLED;\n}\n\nstatic inline int bnxt_has_work(struct bnxt *bp, struct bnxt_cp_ring_info *cpr)\n{\n\tu32 raw_cons = cpr->cp_raw_cons;\n\tu16 cons = RING_CMP(raw_cons);\n\tstruct tx_cmp *txcmp;\n\n\ttxcmp = &cpr->cp_desc_ring[CP_RING(cons)][CP_IDX(cons)];\n\n\treturn TX_CMP_VALID(txcmp, raw_cons);\n}\n\nstatic irqreturn_t bnxt_inta(int irq, void *dev_instance)\n{\n\tstruct bnxt_napi *bnapi = dev_instance;\n\tstruct bnxt *bp = bnapi->bp;\n\tstruct bnxt_cp_ring_info *cpr = &bnapi->cp_ring;\n\tu32 cons = RING_CMP(cpr->cp_raw_cons);\n\tu32 int_status;\n\n\tprefetch(&cpr->cp_desc_ring[CP_RING(cons)][CP_IDX(cons)]);\n\n\tif (!bnxt_has_work(bp, cpr)) {\n\t\tint_status = readl(bp->bar0 + BNXT_CAG_REG_LEGACY_INT_STATUS);\n\t\t/* return if erroneous interrupt */\n\t\tif (!(int_status & (0x10000 << cpr->cp_ring_struct.fw_ring_id)))\n\t\t\treturn IRQ_NONE;\n\t}\n\n\t/* disable ring IRQ */\n\tBNXT_CP_DB_IRQ_DIS(cpr->cp_db.doorbell);\n\n\t/* Return here if interrupt is shared and is disabled. */\n\tif (unlikely(atomic_read(&bp->intr_sem) != 0))\n\t\treturn IRQ_HANDLED;\n\n\tnapi_schedule(&bnapi->napi);\n\treturn IRQ_HANDLED;\n}\n\nstatic int __bnxt_poll_work(struct bnxt *bp, struct bnxt_cp_ring_info *cpr,\n\t\t\t    int budget)\n{\n\tstruct bnxt_napi *bnapi = cpr->bnapi;\n\tu32 raw_cons = cpr->cp_raw_cons;\n\tu32 cons;\n\tint tx_pkts = 0;\n\tint rx_pkts = 0;\n\tu8 event = 0;\n\tstruct tx_cmp *txcmp;\n\n\tcpr->has_more_work = 0;\n\tcpr->had_work_done = 1;\n\twhile (1) {\n\t\tint rc;\n\n\t\tcons = RING_CMP(raw_cons);\n\t\ttxcmp = &cpr->cp_desc_ring[CP_RING(cons)][CP_IDX(cons)];\n\n\t\tif (!TX_CMP_VALID(txcmp, raw_cons))\n\t\t\tbreak;\n\n\t\t/* The valid test of the entry must be done first before\n\t\t * reading any further.\n\t\t */\n\t\tdma_rmb();\n\t\tif (TX_CMP_TYPE(txcmp) == CMP_TYPE_TX_L2_CMP) {\n\t\t\ttx_pkts++;\n\t\t\t/* return full budget so NAPI will complete. */\n\t\t\tif (unlikely(tx_pkts > bp->tx_wake_thresh)) {\n\t\t\t\trx_pkts = budget;\n\t\t\t\traw_cons = NEXT_RAW_CMP(raw_cons);\n\t\t\t\tif (budget)\n\t\t\t\t\tcpr->has_more_work = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else if ((TX_CMP_TYPE(txcmp) & 0x30) == 0x10) {\n\t\t\tif (likely(budget))\n\t\t\t\trc = bnxt_rx_pkt(bp, cpr, &raw_cons, &event);\n\t\t\telse\n\t\t\t\trc = bnxt_force_rx_discard(bp, cpr, &raw_cons,\n\t\t\t\t\t\t\t   &event);\n\t\t\tif (likely(rc >= 0))\n\t\t\t\trx_pkts += rc;\n\t\t\t/* Increment rx_pkts when rc is -ENOMEM to count towards\n\t\t\t * the NAPI budget.  Otherwise, we may potentially loop\n\t\t\t * here forever if we consistently cannot allocate\n\t\t\t * buffers.\n\t\t\t */\n\t\t\telse if (rc == -ENOMEM && budget)\n\t\t\t\trx_pkts++;\n\t\t\telse if (rc == -EBUSY)\t/* partial completion */\n\t\t\t\tbreak;\n\t\t} else if (unlikely((TX_CMP_TYPE(txcmp) ==\n\t\t\t\t     CMPL_BASE_TYPE_HWRM_DONE) ||\n\t\t\t\t    (TX_CMP_TYPE(txcmp) ==\n\t\t\t\t     CMPL_BASE_TYPE_HWRM_FWD_REQ) ||\n\t\t\t\t    (TX_CMP_TYPE(txcmp) ==\n\t\t\t\t     CMPL_BASE_TYPE_HWRM_ASYNC_EVENT))) {\n\t\t\tbnxt_hwrm_handler(bp, txcmp);\n\t\t}\n\t\traw_cons = NEXT_RAW_CMP(raw_cons);\n\n\t\tif (rx_pkts && rx_pkts == budget) {\n\t\t\tcpr->has_more_work = 1;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (event & BNXT_REDIRECT_EVENT)\n\t\txdp_do_flush_map();\n\n\tif (event & BNXT_TX_EVENT) {\n\t\tstruct bnxt_tx_ring_info *txr = bnapi->tx_ring;\n\t\tu16 prod = txr->tx_prod;\n\n\t\t/* Sync BD data before updating doorbell */\n\t\twmb();\n\n\t\tbnxt_db_write_relaxed(bp, &txr->tx_db, prod);\n\t}\n\n\tcpr->cp_raw_cons = raw_cons;\n\tbnapi->tx_pkts += tx_pkts;\n\tbnapi->events |= event;\n\treturn rx_pkts;\n}\n\nstatic void __bnxt_poll_work_done(struct bnxt *bp, struct bnxt_napi *bnapi)\n{\n\tif (bnapi->tx_pkts) {\n\t\tbnapi->tx_int(bp, bnapi, bnapi->tx_pkts);\n\t\tbnapi->tx_pkts = 0;\n\t}\n\n\tif ((bnapi->events & BNXT_RX_EVENT) && !(bnapi->in_reset)) {\n\t\tstruct bnxt_rx_ring_info *rxr = bnapi->rx_ring;\n\n\t\tif (bnapi->events & BNXT_AGG_EVENT)\n\t\t\tbnxt_db_write(bp, &rxr->rx_agg_db, rxr->rx_agg_prod);\n\t\tbnxt_db_write(bp, &rxr->rx_db, rxr->rx_prod);\n\t}\n\tbnapi->events = 0;\n}\n\nstatic int bnxt_poll_work(struct bnxt *bp, struct bnxt_cp_ring_info *cpr,\n\t\t\t  int budget)\n{\n\tstruct bnxt_napi *bnapi = cpr->bnapi;\n\tint rx_pkts;\n\n\trx_pkts = __bnxt_poll_work(bp, cpr, budget);\n\n\t/* ACK completion ring before freeing tx ring and producing new\n\t * buffers in rx/agg rings to prevent overflowing the completion\n\t * ring.\n\t */\n\tbnxt_db_cq(bp, &cpr->cp_db, cpr->cp_raw_cons);\n\n\t__bnxt_poll_work_done(bp, bnapi);\n\treturn rx_pkts;\n}\n\nstatic int bnxt_poll_nitroa0(struct napi_struct *napi, int budget)\n{\n\tstruct bnxt_napi *bnapi = container_of(napi, struct bnxt_napi, napi);\n\tstruct bnxt *bp = bnapi->bp;\n\tstruct bnxt_cp_ring_info *cpr = &bnapi->cp_ring;\n\tstruct bnxt_rx_ring_info *rxr = bnapi->rx_ring;\n\tstruct tx_cmp *txcmp;\n\tstruct rx_cmp_ext *rxcmp1;\n\tu32 cp_cons, tmp_raw_cons;\n\tu32 raw_cons = cpr->cp_raw_cons;\n\tu32 rx_pkts = 0;\n\tu8 event = 0;\n\n\twhile (1) {\n\t\tint rc;\n\n\t\tcp_cons = RING_CMP(raw_cons);\n\t\ttxcmp = &cpr->cp_desc_ring[CP_RING(cp_cons)][CP_IDX(cp_cons)];\n\n\t\tif (!TX_CMP_VALID(txcmp, raw_cons))\n\t\t\tbreak;\n\n\t\tif ((TX_CMP_TYPE(txcmp) & 0x30) == 0x10) {\n\t\t\ttmp_raw_cons = NEXT_RAW_CMP(raw_cons);\n\t\t\tcp_cons = RING_CMP(tmp_raw_cons);\n\t\t\trxcmp1 = (struct rx_cmp_ext *)\n\t\t\t  &cpr->cp_desc_ring[CP_RING(cp_cons)][CP_IDX(cp_cons)];\n\n\t\t\tif (!RX_CMP_VALID(rxcmp1, tmp_raw_cons))\n\t\t\t\tbreak;\n\n\t\t\t/* force an error to recycle the buffer */\n\t\t\trxcmp1->rx_cmp_cfa_code_errors_v2 |=\n\t\t\t\tcpu_to_le32(RX_CMPL_ERRORS_CRC_ERROR);\n\n\t\t\trc = bnxt_rx_pkt(bp, cpr, &raw_cons, &event);\n\t\t\tif (likely(rc == -EIO) && budget)\n\t\t\t\trx_pkts++;\n\t\t\telse if (rc == -EBUSY)\t/* partial completion */\n\t\t\t\tbreak;\n\t\t} else if (unlikely(TX_CMP_TYPE(txcmp) ==\n\t\t\t\t    CMPL_BASE_TYPE_HWRM_DONE)) {\n\t\t\tbnxt_hwrm_handler(bp, txcmp);\n\t\t} else {\n\t\t\tnetdev_err(bp->dev,\n\t\t\t\t   \"Invalid completion received on special ring\\n\");\n\t\t}\n\t\traw_cons = NEXT_RAW_CMP(raw_cons);\n\n\t\tif (rx_pkts == budget)\n\t\t\tbreak;\n\t}\n\n\tcpr->cp_raw_cons = raw_cons;\n\tBNXT_DB_CQ(&cpr->cp_db, cpr->cp_raw_cons);\n\tbnxt_db_write(bp, &rxr->rx_db, rxr->rx_prod);\n\n\tif (event & BNXT_AGG_EVENT)\n\t\tbnxt_db_write(bp, &rxr->rx_agg_db, rxr->rx_agg_prod);\n\n\tif (!bnxt_has_work(bp, cpr) && rx_pkts < budget) {\n\t\tnapi_complete_done(napi, rx_pkts);\n\t\tBNXT_DB_CQ_ARM(&cpr->cp_db, cpr->cp_raw_cons);\n\t}\n\treturn rx_pkts;\n}\n\nstatic int bnxt_poll(struct napi_struct *napi, int budget)\n{\n\tstruct bnxt_napi *bnapi = container_of(napi, struct bnxt_napi, napi);\n\tstruct bnxt *bp = bnapi->bp;\n\tstruct bnxt_cp_ring_info *cpr = &bnapi->cp_ring;\n\tint work_done = 0;\n\n\tif (unlikely(test_bit(BNXT_STATE_FW_FATAL_COND, &bp->state))) {\n\t\tnapi_complete(napi);\n\t\treturn 0;\n\t}\n\twhile (1) {\n\t\twork_done += bnxt_poll_work(bp, cpr, budget - work_done);\n\n\t\tif (work_done >= budget) {\n\t\t\tif (!budget)\n\t\t\t\tBNXT_DB_CQ_ARM(&cpr->cp_db, cpr->cp_raw_cons);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!bnxt_has_work(bp, cpr)) {\n\t\t\tif (napi_complete_done(napi, work_done))\n\t\t\t\tBNXT_DB_CQ_ARM(&cpr->cp_db, cpr->cp_raw_cons);\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (bp->flags & BNXT_FLAG_DIM) {\n\t\tstruct dim_sample dim_sample = {};\n\n\t\tdim_update_sample(cpr->event_ctr,\n\t\t\t\t  cpr->rx_packets,\n\t\t\t\t  cpr->rx_bytes,\n\t\t\t\t  &dim_sample);\n\t\tnet_dim(&cpr->dim, dim_sample);\n\t}\n\treturn work_done;\n}\n\nstatic int __bnxt_poll_cqs(struct bnxt *bp, struct bnxt_napi *bnapi, int budget)\n{\n\tstruct bnxt_cp_ring_info *cpr = &bnapi->cp_ring;\n\tint i, work_done = 0;\n\n\tfor (i = 0; i < 2; i++) {\n\t\tstruct bnxt_cp_ring_info *cpr2 = cpr->cp_ring_arr[i];\n\n\t\tif (cpr2) {\n\t\t\twork_done += __bnxt_poll_work(bp, cpr2,\n\t\t\t\t\t\t      budget - work_done);\n\t\t\tcpr->has_more_work |= cpr2->has_more_work;\n\t\t}\n\t}\n\treturn work_done;\n}\n\nstatic void __bnxt_poll_cqs_done(struct bnxt *bp, struct bnxt_napi *bnapi,\n\t\t\t\t u64 dbr_type)\n{\n\tstruct bnxt_cp_ring_info *cpr = &bnapi->cp_ring;\n\tint i;\n\n\tfor (i = 0; i < 2; i++) {\n\t\tstruct bnxt_cp_ring_info *cpr2 = cpr->cp_ring_arr[i];\n\t\tstruct bnxt_db_info *db;\n\n\t\tif (cpr2 && cpr2->had_work_done) {\n\t\t\tdb = &cpr2->cp_db;\n\t\t\twriteq(db->db_key64 | dbr_type |\n\t\t\t       RING_CMP(cpr2->cp_raw_cons), db->doorbell);\n\t\t\tcpr2->had_work_done = 0;\n\t\t}\n\t}\n\t__bnxt_poll_work_done(bp, bnapi);\n}\n\nstatic int bnxt_poll_p5(struct napi_struct *napi, int budget)\n{\n\tstruct bnxt_napi *bnapi = container_of(napi, struct bnxt_napi, napi);\n\tstruct bnxt_cp_ring_info *cpr = &bnapi->cp_ring;\n\tu32 raw_cons = cpr->cp_raw_cons;\n\tstruct bnxt *bp = bnapi->bp;\n\tstruct nqe_cn *nqcmp;\n\tint work_done = 0;\n\tu32 cons;\n\n\tif (unlikely(test_bit(BNXT_STATE_FW_FATAL_COND, &bp->state))) {\n\t\tnapi_complete(napi);\n\t\treturn 0;\n\t}\n\tif (cpr->has_more_work) {\n\t\tcpr->has_more_work = 0;\n\t\twork_done = __bnxt_poll_cqs(bp, bnapi, budget);\n\t}\n\twhile (1) {\n\t\tcons = RING_CMP(raw_cons);\n\t\tnqcmp = &cpr->nq_desc_ring[CP_RING(cons)][CP_IDX(cons)];\n\n\t\tif (!NQ_CMP_VALID(nqcmp, raw_cons)) {\n\t\t\tif (cpr->has_more_work)\n\t\t\t\tbreak;\n\n\t\t\t__bnxt_poll_cqs_done(bp, bnapi, DBR_TYPE_CQ_ARMALL);\n\t\t\tcpr->cp_raw_cons = raw_cons;\n\t\t\tif (napi_complete_done(napi, work_done))\n\t\t\t\tBNXT_DB_NQ_ARM_P5(&cpr->cp_db,\n\t\t\t\t\t\t  cpr->cp_raw_cons);\n\t\t\treturn work_done;\n\t\t}\n\n\t\t/* The valid test of the entry must be done first before\n\t\t * reading any further.\n\t\t */\n\t\tdma_rmb();\n\n\t\tif (nqcmp->type == cpu_to_le16(NQ_CN_TYPE_CQ_NOTIFICATION)) {\n\t\t\tu32 idx = le32_to_cpu(nqcmp->cq_handle_low);\n\t\t\tstruct bnxt_cp_ring_info *cpr2;\n\n\t\t\tcpr2 = cpr->cp_ring_arr[idx];\n\t\t\twork_done += __bnxt_poll_work(bp, cpr2,\n\t\t\t\t\t\t      budget - work_done);\n\t\t\tcpr->has_more_work |= cpr2->has_more_work;\n\t\t} else {\n\t\t\tbnxt_hwrm_handler(bp, (struct tx_cmp *)nqcmp);\n\t\t}\n\t\traw_cons = NEXT_RAW_CMP(raw_cons);\n\t}\n\t__bnxt_poll_cqs_done(bp, bnapi, DBR_TYPE_CQ);\n\tif (raw_cons != cpr->cp_raw_cons) {\n\t\tcpr->cp_raw_cons = raw_cons;\n\t\tBNXT_DB_NQ_P5(&cpr->cp_db, raw_cons);\n\t}\n\treturn work_done;\n}\n\nstatic void bnxt_free_tx_skbs(struct bnxt *bp)\n{\n\tint i, max_idx;\n\tstruct pci_dev *pdev = bp->pdev;\n\n\tif (!bp->tx_ring)\n\t\treturn;\n\n\tmax_idx = bp->tx_nr_pages * TX_DESC_CNT;\n\tfor (i = 0; i < bp->tx_nr_rings; i++) {\n\t\tstruct bnxt_tx_ring_info *txr = &bp->tx_ring[i];\n\t\tint j;\n\n\t\tfor (j = 0; j < max_idx;) {\n\t\t\tstruct bnxt_sw_tx_bd *tx_buf = &txr->tx_buf_ring[j];\n\t\t\tstruct sk_buff *skb;\n\t\t\tint k, last;\n\n\t\t\tif (i < bp->tx_nr_rings_xdp &&\n\t\t\t    tx_buf->action == XDP_REDIRECT) {\n\t\t\t\tdma_unmap_single(&pdev->dev,\n\t\t\t\t\tdma_unmap_addr(tx_buf, mapping),\n\t\t\t\t\tdma_unmap_len(tx_buf, len),\n\t\t\t\t\tPCI_DMA_TODEVICE);\n\t\t\t\txdp_return_frame(tx_buf->xdpf);\n\t\t\t\ttx_buf->action = 0;\n\t\t\t\ttx_buf->xdpf = NULL;\n\t\t\t\tj++;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tskb = tx_buf->skb;\n\t\t\tif (!skb) {\n\t\t\t\tj++;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\ttx_buf->skb = NULL;\n\n\t\t\tif (tx_buf->is_push) {\n\t\t\t\tdev_kfree_skb(skb);\n\t\t\t\tj += 2;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tdma_unmap_single(&pdev->dev,\n\t\t\t\t\t dma_unmap_addr(tx_buf, mapping),\n\t\t\t\t\t skb_headlen(skb),\n\t\t\t\t\t PCI_DMA_TODEVICE);\n\n\t\t\tlast = tx_buf->nr_frags;\n\t\t\tj += 2;\n\t\t\tfor (k = 0; k < last; k++, j++) {\n\t\t\t\tint ring_idx = j & bp->tx_ring_mask;\n\t\t\t\tskb_frag_t *frag = &skb_shinfo(skb)->frags[k];\n\n\t\t\t\ttx_buf = &txr->tx_buf_ring[ring_idx];\n\t\t\t\tdma_unmap_page(\n\t\t\t\t\t&pdev->dev,\n\t\t\t\t\tdma_unmap_addr(tx_buf, mapping),\n\t\t\t\t\tskb_frag_size(frag), PCI_DMA_TODEVICE);\n\t\t\t}\n\t\t\tdev_kfree_skb(skb);\n\t\t}\n\t\tnetdev_tx_reset_queue(netdev_get_tx_queue(bp->dev, i));\n\t}\n}\n\nstatic void bnxt_free_one_rx_ring_skbs(struct bnxt *bp, int ring_nr)\n{\n\tstruct bnxt_rx_ring_info *rxr = &bp->rx_ring[ring_nr];\n\tstruct pci_dev *pdev = bp->pdev;\n\tstruct bnxt_tpa_idx_map *map;\n\tint i, max_idx, max_agg_idx;\n\n\tmax_idx = bp->rx_nr_pages * RX_DESC_CNT;\n\tmax_agg_idx = bp->rx_agg_nr_pages * RX_DESC_CNT;\n\tif (!rxr->rx_tpa)\n\t\tgoto skip_rx_tpa_free;\n\n\tfor (i = 0; i < bp->max_tpa; i++) {\n\t\tstruct bnxt_tpa_info *tpa_info = &rxr->rx_tpa[i];\n\t\tu8 *data = tpa_info->data;\n\n\t\tif (!data)\n\t\t\tcontinue;\n\n\t\tdma_unmap_single_attrs(&pdev->dev, tpa_info->mapping,\n\t\t\t\t       bp->rx_buf_use_size, bp->rx_dir,\n\t\t\t\t       DMA_ATTR_WEAK_ORDERING);\n\n\t\ttpa_info->data = NULL;\n\n\t\tkfree(data);\n\t}\n\nskip_rx_tpa_free:\n\tfor (i = 0; i < max_idx; i++) {\n\t\tstruct bnxt_sw_rx_bd *rx_buf = &rxr->rx_buf_ring[i];\n\t\tdma_addr_t mapping = rx_buf->mapping;\n\t\tvoid *data = rx_buf->data;\n\n\t\tif (!data)\n\t\t\tcontinue;\n\n\t\trx_buf->data = NULL;\n\t\tif (BNXT_RX_PAGE_MODE(bp)) {\n\t\t\tmapping -= bp->rx_dma_offset;\n\t\t\tdma_unmap_page_attrs(&pdev->dev, mapping, PAGE_SIZE,\n\t\t\t\t\t     bp->rx_dir,\n\t\t\t\t\t     DMA_ATTR_WEAK_ORDERING);\n\t\t\tpage_pool_recycle_direct(rxr->page_pool, data);\n\t\t} else {\n\t\t\tdma_unmap_single_attrs(&pdev->dev, mapping,\n\t\t\t\t\t       bp->rx_buf_use_size, bp->rx_dir,\n\t\t\t\t\t       DMA_ATTR_WEAK_ORDERING);\n\t\t\tkfree(data);\n\t\t}\n\t}\n\tfor (i = 0; i < max_agg_idx; i++) {\n\t\tstruct bnxt_sw_rx_agg_bd *rx_agg_buf = &rxr->rx_agg_ring[i];\n\t\tstruct page *page = rx_agg_buf->page;\n\n\t\tif (!page)\n\t\t\tcontinue;\n\n\t\tdma_unmap_page_attrs(&pdev->dev, rx_agg_buf->mapping,\n\t\t\t\t     BNXT_RX_PAGE_SIZE, PCI_DMA_FROMDEVICE,\n\t\t\t\t     DMA_ATTR_WEAK_ORDERING);\n\n\t\trx_agg_buf->page = NULL;\n\t\t__clear_bit(i, rxr->rx_agg_bmap);\n\n\t\t__free_page(page);\n\t}\n\tif (rxr->rx_page) {\n\t\t__free_page(rxr->rx_page);\n\t\trxr->rx_page = NULL;\n\t}\n\tmap = rxr->rx_tpa_idx_map;\n\tif (map)\n\t\tmemset(map->agg_idx_bmap, 0, sizeof(map->agg_idx_bmap));\n}\n\nstatic void bnxt_free_rx_skbs(struct bnxt *bp)\n{\n\tint i;\n\n\tif (!bp->rx_ring)\n\t\treturn;\n\n\tfor (i = 0; i < bp->rx_nr_rings; i++)\n\t\tbnxt_free_one_rx_ring_skbs(bp, i);\n}\n\nstatic void bnxt_free_skbs(struct bnxt *bp)\n{\n\tbnxt_free_tx_skbs(bp);\n\tbnxt_free_rx_skbs(bp);\n}\n\nstatic void bnxt_init_ctx_mem(struct bnxt_mem_init *mem_init, void *p, int len)\n{\n\tu8 init_val = mem_init->init_val;\n\tu16 offset = mem_init->offset;\n\tu8 *p2 = p;\n\tint i;\n\n\tif (!init_val)\n\t\treturn;\n\tif (offset == BNXT_MEM_INVALID_OFFSET) {\n\t\tmemset(p, init_val, len);\n\t\treturn;\n\t}\n\tfor (i = 0; i < len; i += mem_init->size)\n\t\t*(p2 + i + offset) = init_val;\n}\n\nstatic void bnxt_free_ring(struct bnxt *bp, struct bnxt_ring_mem_info *rmem)\n{\n\tstruct pci_dev *pdev = bp->pdev;\n\tint i;\n\n\tfor (i = 0; i < rmem->nr_pages; i++) {\n\t\tif (!rmem->pg_arr[i])\n\t\t\tcontinue;\n\n\t\tdma_free_coherent(&pdev->dev, rmem->page_size,\n\t\t\t\t  rmem->pg_arr[i], rmem->dma_arr[i]);\n\n\t\trmem->pg_arr[i] = NULL;\n\t}\n\tif (rmem->pg_tbl) {\n\t\tsize_t pg_tbl_size = rmem->nr_pages * 8;\n\n\t\tif (rmem->flags & BNXT_RMEM_USE_FULL_PAGE_FLAG)\n\t\t\tpg_tbl_size = rmem->page_size;\n\t\tdma_free_coherent(&pdev->dev, pg_tbl_size,\n\t\t\t\t  rmem->pg_tbl, rmem->pg_tbl_map);\n\t\trmem->pg_tbl = NULL;\n\t}\n\tif (rmem->vmem_size && *rmem->vmem) {\n\t\tvfree(*rmem->vmem);\n\t\t*rmem->vmem = NULL;\n\t}\n}\n\nstatic int bnxt_alloc_ring(struct bnxt *bp, struct bnxt_ring_mem_info *rmem)\n{\n\tstruct pci_dev *pdev = bp->pdev;\n\tu64 valid_bit = 0;\n\tint i;\n\n\tif (rmem->flags & (BNXT_RMEM_VALID_PTE_FLAG | BNXT_RMEM_RING_PTE_FLAG))\n\t\tvalid_bit = PTU_PTE_VALID;\n\tif ((rmem->nr_pages > 1 || rmem->depth > 0) && !rmem->pg_tbl) {\n\t\tsize_t pg_tbl_size = rmem->nr_pages * 8;\n\n\t\tif (rmem->flags & BNXT_RMEM_USE_FULL_PAGE_FLAG)\n\t\t\tpg_tbl_size = rmem->page_size;\n\t\trmem->pg_tbl = dma_alloc_coherent(&pdev->dev, pg_tbl_size,\n\t\t\t\t\t\t  &rmem->pg_tbl_map,\n\t\t\t\t\t\t  GFP_KERNEL);\n\t\tif (!rmem->pg_tbl)\n\t\t\treturn -ENOMEM;\n\t}\n\n\tfor (i = 0; i < rmem->nr_pages; i++) {\n\t\tu64 extra_bits = valid_bit;\n\n\t\trmem->pg_arr[i] = dma_alloc_coherent(&pdev->dev,\n\t\t\t\t\t\t     rmem->page_size,\n\t\t\t\t\t\t     &rmem->dma_arr[i],\n\t\t\t\t\t\t     GFP_KERNEL);\n\t\tif (!rmem->pg_arr[i])\n\t\t\treturn -ENOMEM;\n\n\t\tif (rmem->mem_init)\n\t\t\tbnxt_init_ctx_mem(rmem->mem_init, rmem->pg_arr[i],\n\t\t\t\t\t  rmem->page_size);\n\t\tif (rmem->nr_pages > 1 || rmem->depth > 0) {\n\t\t\tif (i == rmem->nr_pages - 2 &&\n\t\t\t    (rmem->flags & BNXT_RMEM_RING_PTE_FLAG))\n\t\t\t\textra_bits |= PTU_PTE_NEXT_TO_LAST;\n\t\t\telse if (i == rmem->nr_pages - 1 &&\n\t\t\t\t (rmem->flags & BNXT_RMEM_RING_PTE_FLAG))\n\t\t\t\textra_bits |= PTU_PTE_LAST;\n\t\t\trmem->pg_tbl[i] =\n\t\t\t\tcpu_to_le64(rmem->dma_arr[i] | extra_bits);\n\t\t}\n\t}\n\n\tif (rmem->vmem_size) {\n\t\t*rmem->vmem = vzalloc(rmem->vmem_size);\n\t\tif (!(*rmem->vmem))\n\t\t\treturn -ENOMEM;\n\t}\n\treturn 0;\n}\n\nstatic void bnxt_free_tpa_info(struct bnxt *bp)\n{\n\tint i;\n\n\tfor (i = 0; i < bp->rx_nr_rings; i++) {\n\t\tstruct bnxt_rx_ring_info *rxr = &bp->rx_ring[i];\n\n\t\tkfree(rxr->rx_tpa_idx_map);\n\t\trxr->rx_tpa_idx_map = NULL;\n\t\tif (rxr->rx_tpa) {\n\t\t\tkfree(rxr->rx_tpa[0].agg_arr);\n\t\t\trxr->rx_tpa[0].agg_arr = NULL;\n\t\t}\n\t\tkfree(rxr->rx_tpa);\n\t\trxr->rx_tpa = NULL;\n\t}\n}\n\nstatic int bnxt_alloc_tpa_info(struct bnxt *bp)\n{\n\tint i, j, total_aggs = 0;\n\n\tbp->max_tpa = MAX_TPA;\n\tif (bp->flags & BNXT_FLAG_CHIP_P5) {\n\t\tif (!bp->max_tpa_v2)\n\t\t\treturn 0;\n\t\tbp->max_tpa = max_t(u16, bp->max_tpa_v2, MAX_TPA_P5);\n\t\ttotal_aggs = bp->max_tpa * MAX_SKB_FRAGS;\n\t}\n\n\tfor (i = 0; i < bp->rx_nr_rings; i++) {\n\t\tstruct bnxt_rx_ring_info *rxr = &bp->rx_ring[i];\n\t\tstruct rx_agg_cmp *agg;\n\n\t\trxr->rx_tpa = kcalloc(bp->max_tpa, sizeof(struct bnxt_tpa_info),\n\t\t\t\t      GFP_KERNEL);\n\t\tif (!rxr->rx_tpa)\n\t\t\treturn -ENOMEM;\n\n\t\tif (!(bp->flags & BNXT_FLAG_CHIP_P5))\n\t\t\tcontinue;\n\t\tagg = kcalloc(total_aggs, sizeof(*agg), GFP_KERNEL);\n\t\trxr->rx_tpa[0].agg_arr = agg;\n\t\tif (!agg)\n\t\t\treturn -ENOMEM;\n\t\tfor (j = 1; j < bp->max_tpa; j++)\n\t\t\trxr->rx_tpa[j].agg_arr = agg + j * MAX_SKB_FRAGS;\n\t\trxr->rx_tpa_idx_map = kzalloc(sizeof(*rxr->rx_tpa_idx_map),\n\t\t\t\t\t      GFP_KERNEL);\n\t\tif (!rxr->rx_tpa_idx_map)\n\t\t\treturn -ENOMEM;\n\t}\n\treturn 0;\n}\n\nstatic void bnxt_free_rx_rings(struct bnxt *bp)\n{\n\tint i;\n\n\tif (!bp->rx_ring)\n\t\treturn;\n\n\tbnxt_free_tpa_info(bp);\n\tfor (i = 0; i < bp->rx_nr_rings; i++) {\n\t\tstruct bnxt_rx_ring_info *rxr = &bp->rx_ring[i];\n\t\tstruct bnxt_ring_struct *ring;\n\n\t\tif (rxr->xdp_prog)\n\t\t\tbpf_prog_put(rxr->xdp_prog);\n\n\t\tif (xdp_rxq_info_is_reg(&rxr->xdp_rxq))\n\t\t\txdp_rxq_info_unreg(&rxr->xdp_rxq);\n\n\t\tpage_pool_destroy(rxr->page_pool);\n\t\trxr->page_pool = NULL;\n\n\t\tkfree(rxr->rx_agg_bmap);\n\t\trxr->rx_agg_bmap = NULL;\n\n\t\tring = &rxr->rx_ring_struct;\n\t\tbnxt_free_ring(bp, &ring->ring_mem);\n\n\t\tring = &rxr->rx_agg_ring_struct;\n\t\tbnxt_free_ring(bp, &ring->ring_mem);\n\t}\n}\n\nstatic int bnxt_alloc_rx_page_pool(struct bnxt *bp,\n\t\t\t\t   struct bnxt_rx_ring_info *rxr)\n{\n\tstruct page_pool_params pp = { 0 };\n\n\tpp.pool_size = bp->rx_ring_size;\n\tpp.nid = dev_to_node(&bp->pdev->dev);\n\tpp.dev = &bp->pdev->dev;\n\tpp.dma_dir = DMA_BIDIRECTIONAL;\n\n\trxr->page_pool = page_pool_create(&pp);\n\tif (IS_ERR(rxr->page_pool)) {\n\t\tint err = PTR_ERR(rxr->page_pool);\n\n\t\trxr->page_pool = NULL;\n\t\treturn err;\n\t}\n\treturn 0;\n}\n\nstatic int bnxt_alloc_rx_rings(struct bnxt *bp)\n{\n\tint i, rc = 0, agg_rings = 0;\n\n\tif (!bp->rx_ring)\n\t\treturn -ENOMEM;\n\n\tif (bp->flags & BNXT_FLAG_AGG_RINGS)\n\t\tagg_rings = 1;\n\n\tfor (i = 0; i < bp->rx_nr_rings; i++) {\n\t\tstruct bnxt_rx_ring_info *rxr = &bp->rx_ring[i];\n\t\tstruct bnxt_ring_struct *ring;\n\n\t\tring = &rxr->rx_ring_struct;\n\n\t\trc = bnxt_alloc_rx_page_pool(bp, rxr);\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\trc = xdp_rxq_info_reg(&rxr->xdp_rxq, bp->dev, i, 0);\n\t\tif (rc < 0)\n\t\t\treturn rc;\n\n\t\trc = xdp_rxq_info_reg_mem_model(&rxr->xdp_rxq,\n\t\t\t\t\t\tMEM_TYPE_PAGE_POOL,\n\t\t\t\t\t\trxr->page_pool);\n\t\tif (rc) {\n\t\t\txdp_rxq_info_unreg(&rxr->xdp_rxq);\n\t\t\treturn rc;\n\t\t}\n\n\t\trc = bnxt_alloc_ring(bp, &ring->ring_mem);\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\tring->grp_idx = i;\n\t\tif (agg_rings) {\n\t\t\tu16 mem_size;\n\n\t\t\tring = &rxr->rx_agg_ring_struct;\n\t\t\trc = bnxt_alloc_ring(bp, &ring->ring_mem);\n\t\t\tif (rc)\n\t\t\t\treturn rc;\n\n\t\t\tring->grp_idx = i;\n\t\t\trxr->rx_agg_bmap_size = bp->rx_agg_ring_mask + 1;\n\t\t\tmem_size = rxr->rx_agg_bmap_size / 8;\n\t\t\trxr->rx_agg_bmap = kzalloc(mem_size, GFP_KERNEL);\n\t\t\tif (!rxr->rx_agg_bmap)\n\t\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\tif (bp->flags & BNXT_FLAG_TPA)\n\t\trc = bnxt_alloc_tpa_info(bp);\n\treturn rc;\n}\n\nstatic void bnxt_free_tx_rings(struct bnxt *bp)\n{\n\tint i;\n\tstruct pci_dev *pdev = bp->pdev;\n\n\tif (!bp->tx_ring)\n\t\treturn;\n\n\tfor (i = 0; i < bp->tx_nr_rings; i++) {\n\t\tstruct bnxt_tx_ring_info *txr = &bp->tx_ring[i];\n\t\tstruct bnxt_ring_struct *ring;\n\n\t\tif (txr->tx_push) {\n\t\t\tdma_free_coherent(&pdev->dev, bp->tx_push_size,\n\t\t\t\t\t  txr->tx_push, txr->tx_push_mapping);\n\t\t\ttxr->tx_push = NULL;\n\t\t}\n\n\t\tring = &txr->tx_ring_struct;\n\n\t\tbnxt_free_ring(bp, &ring->ring_mem);\n\t}\n}\n\nstatic int bnxt_alloc_tx_rings(struct bnxt *bp)\n{\n\tint i, j, rc;\n\tstruct pci_dev *pdev = bp->pdev;\n\n\tbp->tx_push_size = 0;\n\tif (bp->tx_push_thresh) {\n\t\tint push_size;\n\n\t\tpush_size  = L1_CACHE_ALIGN(sizeof(struct tx_push_bd) +\n\t\t\t\t\tbp->tx_push_thresh);\n\n\t\tif (push_size > 256) {\n\t\t\tpush_size = 0;\n\t\t\tbp->tx_push_thresh = 0;\n\t\t}\n\n\t\tbp->tx_push_size = push_size;\n\t}\n\n\tfor (i = 0, j = 0; i < bp->tx_nr_rings; i++) {\n\t\tstruct bnxt_tx_ring_info *txr = &bp->tx_ring[i];\n\t\tstruct bnxt_ring_struct *ring;\n\t\tu8 qidx;\n\n\t\tring = &txr->tx_ring_struct;\n\n\t\trc = bnxt_alloc_ring(bp, &ring->ring_mem);\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\tring->grp_idx = txr->bnapi->index;\n\t\tif (bp->tx_push_size) {\n\t\t\tdma_addr_t mapping;\n\n\t\t\t/* One pre-allocated DMA buffer to backup\n\t\t\t * TX push operation\n\t\t\t */\n\t\t\ttxr->tx_push = dma_alloc_coherent(&pdev->dev,\n\t\t\t\t\t\tbp->tx_push_size,\n\t\t\t\t\t\t&txr->tx_push_mapping,\n\t\t\t\t\t\tGFP_KERNEL);\n\n\t\t\tif (!txr->tx_push)\n\t\t\t\treturn -ENOMEM;\n\n\t\t\tmapping = txr->tx_push_mapping +\n\t\t\t\tsizeof(struct tx_push_bd);\n\t\t\ttxr->data_mapping = cpu_to_le64(mapping);\n\t\t}\n\t\tqidx = bp->tc_to_qidx[j];\n\t\tring->queue_id = bp->q_info[qidx].queue_id;\n\t\tif (i < bp->tx_nr_rings_xdp)\n\t\t\tcontinue;\n\t\tif (i % bp->tx_nr_rings_per_tc == (bp->tx_nr_rings_per_tc - 1))\n\t\t\tj++;\n\t}\n\treturn 0;\n}\n\nstatic void bnxt_free_cp_rings(struct bnxt *bp)\n{\n\tint i;\n\n\tif (!bp->bnapi)\n\t\treturn;\n\n\tfor (i = 0; i < bp->cp_nr_rings; i++) {\n\t\tstruct bnxt_napi *bnapi = bp->bnapi[i];\n\t\tstruct bnxt_cp_ring_info *cpr;\n\t\tstruct bnxt_ring_struct *ring;\n\t\tint j;\n\n\t\tif (!bnapi)\n\t\t\tcontinue;\n\n\t\tcpr = &bnapi->cp_ring;\n\t\tring = &cpr->cp_ring_struct;\n\n\t\tbnxt_free_ring(bp, &ring->ring_mem);\n\n\t\tfor (j = 0; j < 2; j++) {\n\t\t\tstruct bnxt_cp_ring_info *cpr2 = cpr->cp_ring_arr[j];\n\n\t\t\tif (cpr2) {\n\t\t\t\tring = &cpr2->cp_ring_struct;\n\t\t\t\tbnxt_free_ring(bp, &ring->ring_mem);\n\t\t\t\tkfree(cpr2);\n\t\t\t\tcpr->cp_ring_arr[j] = NULL;\n\t\t\t}\n\t\t}\n\t}\n}\n\nstatic struct bnxt_cp_ring_info *bnxt_alloc_cp_sub_ring(struct bnxt *bp)\n{\n\tstruct bnxt_ring_mem_info *rmem;\n\tstruct bnxt_ring_struct *ring;\n\tstruct bnxt_cp_ring_info *cpr;\n\tint rc;\n\n\tcpr = kzalloc(sizeof(*cpr), GFP_KERNEL);\n\tif (!cpr)\n\t\treturn NULL;\n\n\tring = &cpr->cp_ring_struct;\n\trmem = &ring->ring_mem;\n\trmem->nr_pages = bp->cp_nr_pages;\n\trmem->page_size = HW_CMPD_RING_SIZE;\n\trmem->pg_arr = (void **)cpr->cp_desc_ring;\n\trmem->dma_arr = cpr->cp_desc_mapping;\n\trmem->flags = BNXT_RMEM_RING_PTE_FLAG;\n\trc = bnxt_alloc_ring(bp, rmem);\n\tif (rc) {\n\t\tbnxt_free_ring(bp, rmem);\n\t\tkfree(cpr);\n\t\tcpr = NULL;\n\t}\n\treturn cpr;\n}\n\nstatic int bnxt_alloc_cp_rings(struct bnxt *bp)\n{\n\tbool sh = !!(bp->flags & BNXT_FLAG_SHARED_RINGS);\n\tint i, rc, ulp_base_vec, ulp_msix;\n\n\tulp_msix = bnxt_get_ulp_msix_num(bp);\n\tulp_base_vec = bnxt_get_ulp_msix_base(bp);\n\tfor (i = 0; i < bp->cp_nr_rings; i++) {\n\t\tstruct bnxt_napi *bnapi = bp->bnapi[i];\n\t\tstruct bnxt_cp_ring_info *cpr;\n\t\tstruct bnxt_ring_struct *ring;\n\n\t\tif (!bnapi)\n\t\t\tcontinue;\n\n\t\tcpr = &bnapi->cp_ring;\n\t\tcpr->bnapi = bnapi;\n\t\tring = &cpr->cp_ring_struct;\n\n\t\trc = bnxt_alloc_ring(bp, &ring->ring_mem);\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\tif (ulp_msix && i >= ulp_base_vec)\n\t\t\tring->map_idx = i + ulp_msix;\n\t\telse\n\t\t\tring->map_idx = i;\n\n\t\tif (!(bp->flags & BNXT_FLAG_CHIP_P5))\n\t\t\tcontinue;\n\n\t\tif (i < bp->rx_nr_rings) {\n\t\t\tstruct bnxt_cp_ring_info *cpr2 =\n\t\t\t\tbnxt_alloc_cp_sub_ring(bp);\n\n\t\t\tcpr->cp_ring_arr[BNXT_RX_HDL] = cpr2;\n\t\t\tif (!cpr2)\n\t\t\t\treturn -ENOMEM;\n\t\t\tcpr2->bnapi = bnapi;\n\t\t}\n\t\tif ((sh && i < bp->tx_nr_rings) ||\n\t\t    (!sh && i >= bp->rx_nr_rings)) {\n\t\t\tstruct bnxt_cp_ring_info *cpr2 =\n\t\t\t\tbnxt_alloc_cp_sub_ring(bp);\n\n\t\t\tcpr->cp_ring_arr[BNXT_TX_HDL] = cpr2;\n\t\t\tif (!cpr2)\n\t\t\t\treturn -ENOMEM;\n\t\t\tcpr2->bnapi = bnapi;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic void bnxt_init_ring_struct(struct bnxt *bp)\n{\n\tint i;\n\n\tfor (i = 0; i < bp->cp_nr_rings; i++) {\n\t\tstruct bnxt_napi *bnapi = bp->bnapi[i];\n\t\tstruct bnxt_ring_mem_info *rmem;\n\t\tstruct bnxt_cp_ring_info *cpr;\n\t\tstruct bnxt_rx_ring_info *rxr;\n\t\tstruct bnxt_tx_ring_info *txr;\n\t\tstruct bnxt_ring_struct *ring;\n\n\t\tif (!bnapi)\n\t\t\tcontinue;\n\n\t\tcpr = &bnapi->cp_ring;\n\t\tring = &cpr->cp_ring_struct;\n\t\trmem = &ring->ring_mem;\n\t\trmem->nr_pages = bp->cp_nr_pages;\n\t\trmem->page_size = HW_CMPD_RING_SIZE;\n\t\trmem->pg_arr = (void **)cpr->cp_desc_ring;\n\t\trmem->dma_arr = cpr->cp_desc_mapping;\n\t\trmem->vmem_size = 0;\n\n\t\trxr = bnapi->rx_ring;\n\t\tif (!rxr)\n\t\t\tgoto skip_rx;\n\n\t\tring = &rxr->rx_ring_struct;\n\t\trmem = &ring->ring_mem;\n\t\trmem->nr_pages = bp->rx_nr_pages;\n\t\trmem->page_size = HW_RXBD_RING_SIZE;\n\t\trmem->pg_arr = (void **)rxr->rx_desc_ring;\n\t\trmem->dma_arr = rxr->rx_desc_mapping;\n\t\trmem->vmem_size = SW_RXBD_RING_SIZE * bp->rx_nr_pages;\n\t\trmem->vmem = (void **)&rxr->rx_buf_ring;\n\n\t\tring = &rxr->rx_agg_ring_struct;\n\t\trmem = &ring->ring_mem;\n\t\trmem->nr_pages = bp->rx_agg_nr_pages;\n\t\trmem->page_size = HW_RXBD_RING_SIZE;\n\t\trmem->pg_arr = (void **)rxr->rx_agg_desc_ring;\n\t\trmem->dma_arr = rxr->rx_agg_desc_mapping;\n\t\trmem->vmem_size = SW_RXBD_AGG_RING_SIZE * bp->rx_agg_nr_pages;\n\t\trmem->vmem = (void **)&rxr->rx_agg_ring;\n\nskip_rx:\n\t\ttxr = bnapi->tx_ring;\n\t\tif (!txr)\n\t\t\tcontinue;\n\n\t\tring = &txr->tx_ring_struct;\n\t\trmem = &ring->ring_mem;\n\t\trmem->nr_pages = bp->tx_nr_pages;\n\t\trmem->page_size = HW_RXBD_RING_SIZE;\n\t\trmem->pg_arr = (void **)txr->tx_desc_ring;\n\t\trmem->dma_arr = txr->tx_desc_mapping;\n\t\trmem->vmem_size = SW_TXBD_RING_SIZE * bp->tx_nr_pages;\n\t\trmem->vmem = (void **)&txr->tx_buf_ring;\n\t}\n}\n\nstatic void bnxt_init_rxbd_pages(struct bnxt_ring_struct *ring, u32 type)\n{\n\tint i;\n\tu32 prod;\n\tstruct rx_bd **rx_buf_ring;\n\n\trx_buf_ring = (struct rx_bd **)ring->ring_mem.pg_arr;\n\tfor (i = 0, prod = 0; i < ring->ring_mem.nr_pages; i++) {\n\t\tint j;\n\t\tstruct rx_bd *rxbd;\n\n\t\trxbd = rx_buf_ring[i];\n\t\tif (!rxbd)\n\t\t\tcontinue;\n\n\t\tfor (j = 0; j < RX_DESC_CNT; j++, rxbd++, prod++) {\n\t\t\trxbd->rx_bd_len_flags_type = cpu_to_le32(type);\n\t\t\trxbd->rx_bd_opaque = prod;\n\t\t}\n\t}\n}\n\nstatic int bnxt_alloc_one_rx_ring(struct bnxt *bp, int ring_nr)\n{\n\tstruct bnxt_rx_ring_info *rxr = &bp->rx_ring[ring_nr];\n\tstruct net_device *dev = bp->dev;\n\tu32 prod;\n\tint i;\n\n\tprod = rxr->rx_prod;\n\tfor (i = 0; i < bp->rx_ring_size; i++) {\n\t\tif (bnxt_alloc_rx_data(bp, rxr, prod, GFP_KERNEL)) {\n\t\t\tnetdev_warn(dev, \"init'ed rx ring %d with %d/%d skbs only\\n\",\n\t\t\t\t    ring_nr, i, bp->rx_ring_size);\n\t\t\tbreak;\n\t\t}\n\t\tprod = NEXT_RX(prod);\n\t}\n\trxr->rx_prod = prod;\n\n\tif (!(bp->flags & BNXT_FLAG_AGG_RINGS))\n\t\treturn 0;\n\n\tprod = rxr->rx_agg_prod;\n\tfor (i = 0; i < bp->rx_agg_ring_size; i++) {\n\t\tif (bnxt_alloc_rx_page(bp, rxr, prod, GFP_KERNEL)) {\n\t\t\tnetdev_warn(dev, \"init'ed rx ring %d with %d/%d pages only\\n\",\n\t\t\t\t    ring_nr, i, bp->rx_ring_size);\n\t\t\tbreak;\n\t\t}\n\t\tprod = NEXT_RX_AGG(prod);\n\t}\n\trxr->rx_agg_prod = prod;\n\n\tif (rxr->rx_tpa) {\n\t\tdma_addr_t mapping;\n\t\tu8 *data;\n\n\t\tfor (i = 0; i < bp->max_tpa; i++) {\n\t\t\tdata = __bnxt_alloc_rx_data(bp, &mapping, GFP_KERNEL);\n\t\t\tif (!data)\n\t\t\t\treturn -ENOMEM;\n\n\t\t\trxr->rx_tpa[i].data = data;\n\t\t\trxr->rx_tpa[i].data_ptr = data + bp->rx_offset;\n\t\t\trxr->rx_tpa[i].mapping = mapping;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic int bnxt_init_one_rx_ring(struct bnxt *bp, int ring_nr)\n{\n\tstruct bnxt_rx_ring_info *rxr;\n\tstruct bnxt_ring_struct *ring;\n\tu32 type;\n\n\ttype = (bp->rx_buf_use_size << RX_BD_LEN_SHIFT) |\n\t\tRX_BD_TYPE_RX_PACKET_BD | RX_BD_FLAGS_EOP;\n\n\tif (NET_IP_ALIGN == 2)\n\t\ttype |= RX_BD_FLAGS_SOP;\n\n\trxr = &bp->rx_ring[ring_nr];\n\tring = &rxr->rx_ring_struct;\n\tbnxt_init_rxbd_pages(ring, type);\n\n\tif (BNXT_RX_PAGE_MODE(bp) && bp->xdp_prog) {\n\t\tbpf_prog_add(bp->xdp_prog, 1);\n\t\trxr->xdp_prog = bp->xdp_prog;\n\t}\n\tring->fw_ring_id = INVALID_HW_RING_ID;\n\n\tring = &rxr->rx_agg_ring_struct;\n\tring->fw_ring_id = INVALID_HW_RING_ID;\n\n\tif ((bp->flags & BNXT_FLAG_AGG_RINGS)) {\n\t\ttype = ((u32)BNXT_RX_PAGE_SIZE << RX_BD_LEN_SHIFT) |\n\t\t\tRX_BD_TYPE_RX_AGG_BD | RX_BD_FLAGS_SOP;\n\n\t\tbnxt_init_rxbd_pages(ring, type);\n\t}\n\n\treturn bnxt_alloc_one_rx_ring(bp, ring_nr);\n}\n\nstatic void bnxt_init_cp_rings(struct bnxt *bp)\n{\n\tint i, j;\n\n\tfor (i = 0; i < bp->cp_nr_rings; i++) {\n\t\tstruct bnxt_cp_ring_info *cpr = &bp->bnapi[i]->cp_ring;\n\t\tstruct bnxt_ring_struct *ring = &cpr->cp_ring_struct;\n\n\t\tring->fw_ring_id = INVALID_HW_RING_ID;\n\t\tcpr->rx_ring_coal.coal_ticks = bp->rx_coal.coal_ticks;\n\t\tcpr->rx_ring_coal.coal_bufs = bp->rx_coal.coal_bufs;\n\t\tfor (j = 0; j < 2; j++) {\n\t\t\tstruct bnxt_cp_ring_info *cpr2 = cpr->cp_ring_arr[j];\n\n\t\t\tif (!cpr2)\n\t\t\t\tcontinue;\n\n\t\t\tring = &cpr2->cp_ring_struct;\n\t\t\tring->fw_ring_id = INVALID_HW_RING_ID;\n\t\t\tcpr2->rx_ring_coal.coal_ticks = bp->rx_coal.coal_ticks;\n\t\t\tcpr2->rx_ring_coal.coal_bufs = bp->rx_coal.coal_bufs;\n\t\t}\n\t}\n}\n\nstatic int bnxt_init_rx_rings(struct bnxt *bp)\n{\n\tint i, rc = 0;\n\n\tif (BNXT_RX_PAGE_MODE(bp)) {\n\t\tbp->rx_offset = NET_IP_ALIGN + XDP_PACKET_HEADROOM;\n\t\tbp->rx_dma_offset = XDP_PACKET_HEADROOM;\n\t} else {\n\t\tbp->rx_offset = BNXT_RX_OFFSET;\n\t\tbp->rx_dma_offset = BNXT_RX_DMA_OFFSET;\n\t}\n\n\tfor (i = 0; i < bp->rx_nr_rings; i++) {\n\t\trc = bnxt_init_one_rx_ring(bp, i);\n\t\tif (rc)\n\t\t\tbreak;\n\t}\n\n\treturn rc;\n}\n\nstatic int bnxt_init_tx_rings(struct bnxt *bp)\n{\n\tu16 i;\n\n\tbp->tx_wake_thresh = max_t(int, bp->tx_ring_size / 2,\n\t\t\t\t   MAX_SKB_FRAGS + 1);\n\n\tfor (i = 0; i < bp->tx_nr_rings; i++) {\n\t\tstruct bnxt_tx_ring_info *txr = &bp->tx_ring[i];\n\t\tstruct bnxt_ring_struct *ring = &txr->tx_ring_struct;\n\n\t\tring->fw_ring_id = INVALID_HW_RING_ID;\n\t}\n\n\treturn 0;\n}\n\nstatic void bnxt_free_ring_grps(struct bnxt *bp)\n{\n\tkfree(bp->grp_info);\n\tbp->grp_info = NULL;\n}\n\nstatic int bnxt_init_ring_grps(struct bnxt *bp, bool irq_re_init)\n{\n\tint i;\n\n\tif (irq_re_init) {\n\t\tbp->grp_info = kcalloc(bp->cp_nr_rings,\n\t\t\t\t       sizeof(struct bnxt_ring_grp_info),\n\t\t\t\t       GFP_KERNEL);\n\t\tif (!bp->grp_info)\n\t\t\treturn -ENOMEM;\n\t}\n\tfor (i = 0; i < bp->cp_nr_rings; i++) {\n\t\tif (irq_re_init)\n\t\t\tbp->grp_info[i].fw_stats_ctx = INVALID_HW_RING_ID;\n\t\tbp->grp_info[i].fw_grp_id = INVALID_HW_RING_ID;\n\t\tbp->grp_info[i].rx_fw_ring_id = INVALID_HW_RING_ID;\n\t\tbp->grp_info[i].agg_fw_ring_id = INVALID_HW_RING_ID;\n\t\tbp->grp_info[i].cp_fw_ring_id = INVALID_HW_RING_ID;\n\t}\n\treturn 0;\n}\n\nstatic void bnxt_free_vnics(struct bnxt *bp)\n{\n\tkfree(bp->vnic_info);\n\tbp->vnic_info = NULL;\n\tbp->nr_vnics = 0;\n}\n\nstatic int bnxt_alloc_vnics(struct bnxt *bp)\n{\n\tint num_vnics = 1;\n\n#ifdef CONFIG_RFS_ACCEL\n\tif ((bp->flags & (BNXT_FLAG_RFS | BNXT_FLAG_CHIP_P5)) == BNXT_FLAG_RFS)\n\t\tnum_vnics += bp->rx_nr_rings;\n#endif\n\n\tif (BNXT_CHIP_TYPE_NITRO_A0(bp))\n\t\tnum_vnics++;\n\n\tbp->vnic_info = kcalloc(num_vnics, sizeof(struct bnxt_vnic_info),\n\t\t\t\tGFP_KERNEL);\n\tif (!bp->vnic_info)\n\t\treturn -ENOMEM;\n\n\tbp->nr_vnics = num_vnics;\n\treturn 0;\n}\n\nstatic void bnxt_init_vnics(struct bnxt *bp)\n{\n\tint i;\n\n\tfor (i = 0; i < bp->nr_vnics; i++) {\n\t\tstruct bnxt_vnic_info *vnic = &bp->vnic_info[i];\n\t\tint j;\n\n\t\tvnic->fw_vnic_id = INVALID_HW_RING_ID;\n\t\tfor (j = 0; j < BNXT_MAX_CTX_PER_VNIC; j++)\n\t\t\tvnic->fw_rss_cos_lb_ctx[j] = INVALID_HW_RING_ID;\n\n\t\tvnic->fw_l2_ctx_id = INVALID_HW_RING_ID;\n\n\t\tif (bp->vnic_info[i].rss_hash_key) {\n\t\t\tif (i == 0)\n\t\t\t\tprandom_bytes(vnic->rss_hash_key,\n\t\t\t\t\t      HW_HASH_KEY_SIZE);\n\t\t\telse\n\t\t\t\tmemcpy(vnic->rss_hash_key,\n\t\t\t\t       bp->vnic_info[0].rss_hash_key,\n\t\t\t\t       HW_HASH_KEY_SIZE);\n\t\t}\n\t}\n}\n\nstatic int bnxt_calc_nr_ring_pages(u32 ring_size, int desc_per_pg)\n{\n\tint pages;\n\n\tpages = ring_size / desc_per_pg;\n\n\tif (!pages)\n\t\treturn 1;\n\n\tpages++;\n\n\twhile (pages & (pages - 1))\n\t\tpages++;\n\n\treturn pages;\n}\n\nvoid bnxt_set_tpa_flags(struct bnxt *bp)\n{\n\tbp->flags &= ~BNXT_FLAG_TPA;\n\tif (bp->flags & BNXT_FLAG_NO_AGG_RINGS)\n\t\treturn;\n\tif (bp->dev->features & NETIF_F_LRO)\n\t\tbp->flags |= BNXT_FLAG_LRO;\n\telse if (bp->dev->features & NETIF_F_GRO_HW)\n\t\tbp->flags |= BNXT_FLAG_GRO;\n}\n\n/* bp->rx_ring_size, bp->tx_ring_size, dev->mtu, BNXT_FLAG_{G|L}RO flags must\n * be set on entry.\n */\nvoid bnxt_set_ring_params(struct bnxt *bp)\n{\n\tu32 ring_size, rx_size, rx_space, max_rx_cmpl;\n\tu32 agg_factor = 0, agg_ring_size = 0;\n\n\t/* 8 for CRC and VLAN */\n\trx_size = SKB_DATA_ALIGN(bp->dev->mtu + ETH_HLEN + NET_IP_ALIGN + 8);\n\n\trx_space = rx_size + NET_SKB_PAD +\n\t\tSKB_DATA_ALIGN(sizeof(struct skb_shared_info));\n\n\tbp->rx_copy_thresh = BNXT_RX_COPY_THRESH;\n\tring_size = bp->rx_ring_size;\n\tbp->rx_agg_ring_size = 0;\n\tbp->rx_agg_nr_pages = 0;\n\n\tif (bp->flags & BNXT_FLAG_TPA)\n\t\tagg_factor = min_t(u32, 4, 65536 / BNXT_RX_PAGE_SIZE);\n\n\tbp->flags &= ~BNXT_FLAG_JUMBO;\n\tif (rx_space > PAGE_SIZE && !(bp->flags & BNXT_FLAG_NO_AGG_RINGS)) {\n\t\tu32 jumbo_factor;\n\n\t\tbp->flags |= BNXT_FLAG_JUMBO;\n\t\tjumbo_factor = PAGE_ALIGN(bp->dev->mtu - 40) >> PAGE_SHIFT;\n\t\tif (jumbo_factor > agg_factor)\n\t\t\tagg_factor = jumbo_factor;\n\t}\n\tagg_ring_size = ring_size * agg_factor;\n\n\tif (agg_ring_size) {\n\t\tbp->rx_agg_nr_pages = bnxt_calc_nr_ring_pages(agg_ring_size,\n\t\t\t\t\t\t\tRX_DESC_CNT);\n\t\tif (bp->rx_agg_nr_pages > MAX_RX_AGG_PAGES) {\n\t\t\tu32 tmp = agg_ring_size;\n\n\t\t\tbp->rx_agg_nr_pages = MAX_RX_AGG_PAGES;\n\t\t\tagg_ring_size = MAX_RX_AGG_PAGES * RX_DESC_CNT - 1;\n\t\t\tnetdev_warn(bp->dev, \"rx agg ring size %d reduced to %d.\\n\",\n\t\t\t\t    tmp, agg_ring_size);\n\t\t}\n\t\tbp->rx_agg_ring_size = agg_ring_size;\n\t\tbp->rx_agg_ring_mask = (bp->rx_agg_nr_pages * RX_DESC_CNT) - 1;\n\t\trx_size = SKB_DATA_ALIGN(BNXT_RX_COPY_THRESH + NET_IP_ALIGN);\n\t\trx_space = rx_size + NET_SKB_PAD +\n\t\t\tSKB_DATA_ALIGN(sizeof(struct skb_shared_info));\n\t}\n\n\tbp->rx_buf_use_size = rx_size;\n\tbp->rx_buf_size = rx_space;\n\n\tbp->rx_nr_pages = bnxt_calc_nr_ring_pages(ring_size, RX_DESC_CNT);\n\tbp->rx_ring_mask = (bp->rx_nr_pages * RX_DESC_CNT) - 1;\n\n\tring_size = bp->tx_ring_size;\n\tbp->tx_nr_pages = bnxt_calc_nr_ring_pages(ring_size, TX_DESC_CNT);\n\tbp->tx_ring_mask = (bp->tx_nr_pages * TX_DESC_CNT) - 1;\n\n\tmax_rx_cmpl = bp->rx_ring_size;\n\t/* MAX TPA needs to be added because TPA_START completions are\n\t * immediately recycled, so the TPA completions are not bound by\n\t * the RX ring size.\n\t */\n\tif (bp->flags & BNXT_FLAG_TPA)\n\t\tmax_rx_cmpl += bp->max_tpa;\n\t/* RX and TPA completions are 32-byte, all others are 16-byte */\n\tring_size = max_rx_cmpl * 2 + agg_ring_size + bp->tx_ring_size;\n\tbp->cp_ring_size = ring_size;\n\n\tbp->cp_nr_pages = bnxt_calc_nr_ring_pages(ring_size, CP_DESC_CNT);\n\tif (bp->cp_nr_pages > MAX_CP_PAGES) {\n\t\tbp->cp_nr_pages = MAX_CP_PAGES;\n\t\tbp->cp_ring_size = MAX_CP_PAGES * CP_DESC_CNT - 1;\n\t\tnetdev_warn(bp->dev, \"completion ring size %d reduced to %d.\\n\",\n\t\t\t    ring_size, bp->cp_ring_size);\n\t}\n\tbp->cp_bit = bp->cp_nr_pages * CP_DESC_CNT;\n\tbp->cp_ring_mask = bp->cp_bit - 1;\n}\n\n/* Changing allocation mode of RX rings.\n * TODO: Update when extending xdp_rxq_info to support allocation modes.\n */\nint bnxt_set_rx_skb_mode(struct bnxt *bp, bool page_mode)\n{\n\tif (page_mode) {\n\t\tif (bp->dev->mtu > BNXT_MAX_PAGE_MODE_MTU)\n\t\t\treturn -EOPNOTSUPP;\n\t\tbp->dev->max_mtu =\n\t\t\tmin_t(u16, bp->max_mtu, BNXT_MAX_PAGE_MODE_MTU);\n\t\tbp->flags &= ~BNXT_FLAG_AGG_RINGS;\n\t\tbp->flags |= BNXT_FLAG_NO_AGG_RINGS | BNXT_FLAG_RX_PAGE_MODE;\n\t\tbp->rx_dir = DMA_BIDIRECTIONAL;\n\t\tbp->rx_skb_func = bnxt_rx_page_skb;\n\t\t/* Disable LRO or GRO_HW */\n\t\tnetdev_update_features(bp->dev);\n\t} else {\n\t\tbp->dev->max_mtu = bp->max_mtu;\n\t\tbp->flags &= ~BNXT_FLAG_RX_PAGE_MODE;\n\t\tbp->rx_dir = DMA_FROM_DEVICE;\n\t\tbp->rx_skb_func = bnxt_rx_skb;\n\t}\n\treturn 0;\n}\n\nstatic void bnxt_free_vnic_attributes(struct bnxt *bp)\n{\n\tint i;\n\tstruct bnxt_vnic_info *vnic;\n\tstruct pci_dev *pdev = bp->pdev;\n\n\tif (!bp->vnic_info)\n\t\treturn;\n\n\tfor (i = 0; i < bp->nr_vnics; i++) {\n\t\tvnic = &bp->vnic_info[i];\n\n\t\tkfree(vnic->fw_grp_ids);\n\t\tvnic->fw_grp_ids = NULL;\n\n\t\tkfree(vnic->uc_list);\n\t\tvnic->uc_list = NULL;\n\n\t\tif (vnic->mc_list) {\n\t\t\tdma_free_coherent(&pdev->dev, vnic->mc_list_size,\n\t\t\t\t\t  vnic->mc_list, vnic->mc_list_mapping);\n\t\t\tvnic->mc_list = NULL;\n\t\t}\n\n\t\tif (vnic->rss_table) {\n\t\t\tdma_free_coherent(&pdev->dev, vnic->rss_table_size,\n\t\t\t\t\t  vnic->rss_table,\n\t\t\t\t\t  vnic->rss_table_dma_addr);\n\t\t\tvnic->rss_table = NULL;\n\t\t}\n\n\t\tvnic->rss_hash_key = NULL;\n\t\tvnic->flags = 0;\n\t}\n}\n\nstatic int bnxt_alloc_vnic_attributes(struct bnxt *bp)\n{\n\tint i, rc = 0, size;\n\tstruct bnxt_vnic_info *vnic;\n\tstruct pci_dev *pdev = bp->pdev;\n\tint max_rings;\n\n\tfor (i = 0; i < bp->nr_vnics; i++) {\n\t\tvnic = &bp->vnic_info[i];\n\n\t\tif (vnic->flags & BNXT_VNIC_UCAST_FLAG) {\n\t\t\tint mem_size = (BNXT_MAX_UC_ADDRS - 1) * ETH_ALEN;\n\n\t\t\tif (mem_size > 0) {\n\t\t\t\tvnic->uc_list = kmalloc(mem_size, GFP_KERNEL);\n\t\t\t\tif (!vnic->uc_list) {\n\t\t\t\t\trc = -ENOMEM;\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (vnic->flags & BNXT_VNIC_MCAST_FLAG) {\n\t\t\tvnic->mc_list_size = BNXT_MAX_MC_ADDRS * ETH_ALEN;\n\t\t\tvnic->mc_list =\n\t\t\t\tdma_alloc_coherent(&pdev->dev,\n\t\t\t\t\t\t   vnic->mc_list_size,\n\t\t\t\t\t\t   &vnic->mc_list_mapping,\n\t\t\t\t\t\t   GFP_KERNEL);\n\t\t\tif (!vnic->mc_list) {\n\t\t\t\trc = -ENOMEM;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\n\t\tif (bp->flags & BNXT_FLAG_CHIP_P5)\n\t\t\tgoto vnic_skip_grps;\n\n\t\tif (vnic->flags & BNXT_VNIC_RSS_FLAG)\n\t\t\tmax_rings = bp->rx_nr_rings;\n\t\telse\n\t\t\tmax_rings = 1;\n\n\t\tvnic->fw_grp_ids = kcalloc(max_rings, sizeof(u16), GFP_KERNEL);\n\t\tif (!vnic->fw_grp_ids) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\nvnic_skip_grps:\n\t\tif ((bp->flags & BNXT_FLAG_NEW_RSS_CAP) &&\n\t\t    !(vnic->flags & BNXT_VNIC_RSS_FLAG))\n\t\t\tcontinue;\n\n\t\t/* Allocate rss table and hash key */\n\t\tsize = L1_CACHE_ALIGN(HW_HASH_INDEX_SIZE * sizeof(u16));\n\t\tif (bp->flags & BNXT_FLAG_CHIP_P5)\n\t\t\tsize = L1_CACHE_ALIGN(BNXT_MAX_RSS_TABLE_SIZE_P5);\n\n\t\tvnic->rss_table_size = size + HW_HASH_KEY_SIZE;\n\t\tvnic->rss_table = dma_alloc_coherent(&pdev->dev,\n\t\t\t\t\t\t     vnic->rss_table_size,\n\t\t\t\t\t\t     &vnic->rss_table_dma_addr,\n\t\t\t\t\t\t     GFP_KERNEL);\n\t\tif (!vnic->rss_table) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\n\t\tvnic->rss_hash_key = ((void *)vnic->rss_table) + size;\n\t\tvnic->rss_hash_key_dma_addr = vnic->rss_table_dma_addr + size;\n\t}\n\treturn 0;\n\nout:\n\treturn rc;\n}\n\nstatic void bnxt_free_hwrm_resources(struct bnxt *bp)\n{\n\tstruct pci_dev *pdev = bp->pdev;\n\n\tif (bp->hwrm_cmd_resp_addr) {\n\t\tdma_free_coherent(&pdev->dev, PAGE_SIZE, bp->hwrm_cmd_resp_addr,\n\t\t\t\t  bp->hwrm_cmd_resp_dma_addr);\n\t\tbp->hwrm_cmd_resp_addr = NULL;\n\t}\n\n\tif (bp->hwrm_cmd_kong_resp_addr) {\n\t\tdma_free_coherent(&pdev->dev, PAGE_SIZE,\n\t\t\t\t  bp->hwrm_cmd_kong_resp_addr,\n\t\t\t\t  bp->hwrm_cmd_kong_resp_dma_addr);\n\t\tbp->hwrm_cmd_kong_resp_addr = NULL;\n\t}\n}\n\nstatic int bnxt_alloc_kong_hwrm_resources(struct bnxt *bp)\n{\n\tstruct pci_dev *pdev = bp->pdev;\n\n\tif (bp->hwrm_cmd_kong_resp_addr)\n\t\treturn 0;\n\n\tbp->hwrm_cmd_kong_resp_addr =\n\t\tdma_alloc_coherent(&pdev->dev, PAGE_SIZE,\n\t\t\t\t   &bp->hwrm_cmd_kong_resp_dma_addr,\n\t\t\t\t   GFP_KERNEL);\n\tif (!bp->hwrm_cmd_kong_resp_addr)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\nstatic int bnxt_alloc_hwrm_resources(struct bnxt *bp)\n{\n\tstruct pci_dev *pdev = bp->pdev;\n\n\tbp->hwrm_cmd_resp_addr = dma_alloc_coherent(&pdev->dev, PAGE_SIZE,\n\t\t\t\t\t\t   &bp->hwrm_cmd_resp_dma_addr,\n\t\t\t\t\t\t   GFP_KERNEL);\n\tif (!bp->hwrm_cmd_resp_addr)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\nstatic void bnxt_free_hwrm_short_cmd_req(struct bnxt *bp)\n{\n\tif (bp->hwrm_short_cmd_req_addr) {\n\t\tstruct pci_dev *pdev = bp->pdev;\n\n\t\tdma_free_coherent(&pdev->dev, bp->hwrm_max_ext_req_len,\n\t\t\t\t  bp->hwrm_short_cmd_req_addr,\n\t\t\t\t  bp->hwrm_short_cmd_req_dma_addr);\n\t\tbp->hwrm_short_cmd_req_addr = NULL;\n\t}\n}\n\nstatic int bnxt_alloc_hwrm_short_cmd_req(struct bnxt *bp)\n{\n\tstruct pci_dev *pdev = bp->pdev;\n\n\tif (bp->hwrm_short_cmd_req_addr)\n\t\treturn 0;\n\n\tbp->hwrm_short_cmd_req_addr =\n\t\tdma_alloc_coherent(&pdev->dev, bp->hwrm_max_ext_req_len,\n\t\t\t\t   &bp->hwrm_short_cmd_req_dma_addr,\n\t\t\t\t   GFP_KERNEL);\n\tif (!bp->hwrm_short_cmd_req_addr)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\nstatic void bnxt_free_stats_mem(struct bnxt *bp, struct bnxt_stats_mem *stats)\n{\n\tkfree(stats->hw_masks);\n\tstats->hw_masks = NULL;\n\tkfree(stats->sw_stats);\n\tstats->sw_stats = NULL;\n\tif (stats->hw_stats) {\n\t\tdma_free_coherent(&bp->pdev->dev, stats->len, stats->hw_stats,\n\t\t\t\t  stats->hw_stats_map);\n\t\tstats->hw_stats = NULL;\n\t}\n}\n\nstatic int bnxt_alloc_stats_mem(struct bnxt *bp, struct bnxt_stats_mem *stats,\n\t\t\t\tbool alloc_masks)\n{\n\tstats->hw_stats = dma_alloc_coherent(&bp->pdev->dev, stats->len,\n\t\t\t\t\t     &stats->hw_stats_map, GFP_KERNEL);\n\tif (!stats->hw_stats)\n\t\treturn -ENOMEM;\n\n\tstats->sw_stats = kzalloc(stats->len, GFP_KERNEL);\n\tif (!stats->sw_stats)\n\t\tgoto stats_mem_err;\n\n\tif (alloc_masks) {\n\t\tstats->hw_masks = kzalloc(stats->len, GFP_KERNEL);\n\t\tif (!stats->hw_masks)\n\t\t\tgoto stats_mem_err;\n\t}\n\treturn 0;\n\nstats_mem_err:\n\tbnxt_free_stats_mem(bp, stats);\n\treturn -ENOMEM;\n}\n\nstatic void bnxt_fill_masks(u64 *mask_arr, u64 mask, int count)\n{\n\tint i;\n\n\tfor (i = 0; i < count; i++)\n\t\tmask_arr[i] = mask;\n}\n\nstatic void bnxt_copy_hw_masks(u64 *mask_arr, __le64 *hw_mask_arr, int count)\n{\n\tint i;\n\n\tfor (i = 0; i < count; i++)\n\t\tmask_arr[i] = le64_to_cpu(hw_mask_arr[i]);\n}\n\nstatic int bnxt_hwrm_func_qstat_ext(struct bnxt *bp,\n\t\t\t\t    struct bnxt_stats_mem *stats)\n{\n\tstruct hwrm_func_qstats_ext_output *resp = bp->hwrm_cmd_resp_addr;\n\tstruct hwrm_func_qstats_ext_input req = {0};\n\t__le64 *hw_masks;\n\tint rc;\n\n\tif (!(bp->fw_cap & BNXT_FW_CAP_EXT_HW_STATS_SUPPORTED) ||\n\t    !(bp->flags & BNXT_FLAG_CHIP_P5))\n\t\treturn -EOPNOTSUPP;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_FUNC_QSTATS_EXT, -1, -1);\n\treq.fid = cpu_to_le16(0xffff);\n\treq.flags = FUNC_QSTATS_EXT_REQ_FLAGS_COUNTER_MASK;\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (rc)\n\t\tgoto qstat_exit;\n\n\thw_masks = &resp->rx_ucast_pkts;\n\tbnxt_copy_hw_masks(stats->hw_masks, hw_masks, stats->len / 8);\n\nqstat_exit:\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\treturn rc;\n}\n\nstatic int bnxt_hwrm_port_qstats(struct bnxt *bp, u8 flags);\nstatic int bnxt_hwrm_port_qstats_ext(struct bnxt *bp, u8 flags);\n\nstatic void bnxt_init_stats(struct bnxt *bp)\n{\n\tstruct bnxt_napi *bnapi = bp->bnapi[0];\n\tstruct bnxt_cp_ring_info *cpr;\n\tstruct bnxt_stats_mem *stats;\n\t__le64 *rx_stats, *tx_stats;\n\tint rc, rx_count, tx_count;\n\tu64 *rx_masks, *tx_masks;\n\tu64 mask;\n\tu8 flags;\n\n\tcpr = &bnapi->cp_ring;\n\tstats = &cpr->stats;\n\trc = bnxt_hwrm_func_qstat_ext(bp, stats);\n\tif (rc) {\n\t\tif (bp->flags & BNXT_FLAG_CHIP_P5)\n\t\t\tmask = (1ULL << 48) - 1;\n\t\telse\n\t\t\tmask = -1ULL;\n\t\tbnxt_fill_masks(stats->hw_masks, mask, stats->len / 8);\n\t}\n\tif (bp->flags & BNXT_FLAG_PORT_STATS) {\n\t\tstats = &bp->port_stats;\n\t\trx_stats = stats->hw_stats;\n\t\trx_masks = stats->hw_masks;\n\t\trx_count = sizeof(struct rx_port_stats) / 8;\n\t\ttx_stats = rx_stats + BNXT_TX_PORT_STATS_BYTE_OFFSET / 8;\n\t\ttx_masks = rx_masks + BNXT_TX_PORT_STATS_BYTE_OFFSET / 8;\n\t\ttx_count = sizeof(struct tx_port_stats) / 8;\n\n\t\tflags = PORT_QSTATS_REQ_FLAGS_COUNTER_MASK;\n\t\trc = bnxt_hwrm_port_qstats(bp, flags);\n\t\tif (rc) {\n\t\t\tmask = (1ULL << 40) - 1;\n\n\t\t\tbnxt_fill_masks(rx_masks, mask, rx_count);\n\t\t\tbnxt_fill_masks(tx_masks, mask, tx_count);\n\t\t} else {\n\t\t\tbnxt_copy_hw_masks(rx_masks, rx_stats, rx_count);\n\t\t\tbnxt_copy_hw_masks(tx_masks, tx_stats, tx_count);\n\t\t\tbnxt_hwrm_port_qstats(bp, 0);\n\t\t}\n\t}\n\tif (bp->flags & BNXT_FLAG_PORT_STATS_EXT) {\n\t\tstats = &bp->rx_port_stats_ext;\n\t\trx_stats = stats->hw_stats;\n\t\trx_masks = stats->hw_masks;\n\t\trx_count = sizeof(struct rx_port_stats_ext) / 8;\n\t\tstats = &bp->tx_port_stats_ext;\n\t\ttx_stats = stats->hw_stats;\n\t\ttx_masks = stats->hw_masks;\n\t\ttx_count = sizeof(struct tx_port_stats_ext) / 8;\n\n\t\tflags = PORT_QSTATS_EXT_REQ_FLAGS_COUNTER_MASK;\n\t\trc = bnxt_hwrm_port_qstats_ext(bp, flags);\n\t\tif (rc) {\n\t\t\tmask = (1ULL << 40) - 1;\n\n\t\t\tbnxt_fill_masks(rx_masks, mask, rx_count);\n\t\t\tif (tx_stats)\n\t\t\t\tbnxt_fill_masks(tx_masks, mask, tx_count);\n\t\t} else {\n\t\t\tbnxt_copy_hw_masks(rx_masks, rx_stats, rx_count);\n\t\t\tif (tx_stats)\n\t\t\t\tbnxt_copy_hw_masks(tx_masks, tx_stats,\n\t\t\t\t\t\t   tx_count);\n\t\t\tbnxt_hwrm_port_qstats_ext(bp, 0);\n\t\t}\n\t}\n}\n\nstatic void bnxt_free_port_stats(struct bnxt *bp)\n{\n\tbp->flags &= ~BNXT_FLAG_PORT_STATS;\n\tbp->flags &= ~BNXT_FLAG_PORT_STATS_EXT;\n\n\tbnxt_free_stats_mem(bp, &bp->port_stats);\n\tbnxt_free_stats_mem(bp, &bp->rx_port_stats_ext);\n\tbnxt_free_stats_mem(bp, &bp->tx_port_stats_ext);\n}\n\nstatic void bnxt_free_ring_stats(struct bnxt *bp)\n{\n\tint i;\n\n\tif (!bp->bnapi)\n\t\treturn;\n\n\tfor (i = 0; i < bp->cp_nr_rings; i++) {\n\t\tstruct bnxt_napi *bnapi = bp->bnapi[i];\n\t\tstruct bnxt_cp_ring_info *cpr = &bnapi->cp_ring;\n\n\t\tbnxt_free_stats_mem(bp, &cpr->stats);\n\t}\n}\n\nstatic int bnxt_alloc_stats(struct bnxt *bp)\n{\n\tu32 size, i;\n\tint rc;\n\n\tsize = bp->hw_ring_stats_size;\n\n\tfor (i = 0; i < bp->cp_nr_rings; i++) {\n\t\tstruct bnxt_napi *bnapi = bp->bnapi[i];\n\t\tstruct bnxt_cp_ring_info *cpr = &bnapi->cp_ring;\n\n\t\tcpr->stats.len = size;\n\t\trc = bnxt_alloc_stats_mem(bp, &cpr->stats, !i);\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\tcpr->hw_stats_ctx_id = INVALID_STATS_CTX_ID;\n\t}\n\n\tif (BNXT_VF(bp) || bp->chip_num == CHIP_NUM_58700)\n\t\treturn 0;\n\n\tif (bp->port_stats.hw_stats)\n\t\tgoto alloc_ext_stats;\n\n\tbp->port_stats.len = BNXT_PORT_STATS_SIZE;\n\trc = bnxt_alloc_stats_mem(bp, &bp->port_stats, true);\n\tif (rc)\n\t\treturn rc;\n\n\tbp->flags |= BNXT_FLAG_PORT_STATS;\n\nalloc_ext_stats:\n\t/* Display extended statistics only if FW supports it */\n\tif (bp->hwrm_spec_code < 0x10804 || bp->hwrm_spec_code == 0x10900)\n\t\tif (!(bp->fw_cap & BNXT_FW_CAP_EXT_STATS_SUPPORTED))\n\t\t\treturn 0;\n\n\tif (bp->rx_port_stats_ext.hw_stats)\n\t\tgoto alloc_tx_ext_stats;\n\n\tbp->rx_port_stats_ext.len = sizeof(struct rx_port_stats_ext);\n\trc = bnxt_alloc_stats_mem(bp, &bp->rx_port_stats_ext, true);\n\t/* Extended stats are optional */\n\tif (rc)\n\t\treturn 0;\n\nalloc_tx_ext_stats:\n\tif (bp->tx_port_stats_ext.hw_stats)\n\t\treturn 0;\n\n\tif (bp->hwrm_spec_code >= 0x10902 ||\n\t    (bp->fw_cap & BNXT_FW_CAP_EXT_STATS_SUPPORTED)) {\n\t\tbp->tx_port_stats_ext.len = sizeof(struct tx_port_stats_ext);\n\t\trc = bnxt_alloc_stats_mem(bp, &bp->tx_port_stats_ext, true);\n\t\t/* Extended stats are optional */\n\t\tif (rc)\n\t\t\treturn 0;\n\t}\n\tbp->flags |= BNXT_FLAG_PORT_STATS_EXT;\n\treturn 0;\n}\n\nstatic void bnxt_clear_ring_indices(struct bnxt *bp)\n{\n\tint i;\n\n\tif (!bp->bnapi)\n\t\treturn;\n\n\tfor (i = 0; i < bp->cp_nr_rings; i++) {\n\t\tstruct bnxt_napi *bnapi = bp->bnapi[i];\n\t\tstruct bnxt_cp_ring_info *cpr;\n\t\tstruct bnxt_rx_ring_info *rxr;\n\t\tstruct bnxt_tx_ring_info *txr;\n\n\t\tif (!bnapi)\n\t\t\tcontinue;\n\n\t\tcpr = &bnapi->cp_ring;\n\t\tcpr->cp_raw_cons = 0;\n\n\t\ttxr = bnapi->tx_ring;\n\t\tif (txr) {\n\t\t\ttxr->tx_prod = 0;\n\t\t\ttxr->tx_cons = 0;\n\t\t}\n\n\t\trxr = bnapi->rx_ring;\n\t\tif (rxr) {\n\t\t\trxr->rx_prod = 0;\n\t\t\trxr->rx_agg_prod = 0;\n\t\t\trxr->rx_sw_agg_prod = 0;\n\t\t\trxr->rx_next_cons = 0;\n\t\t}\n\t}\n}\n\nstatic void bnxt_free_ntp_fltrs(struct bnxt *bp, bool irq_reinit)\n{\n#ifdef CONFIG_RFS_ACCEL\n\tint i;\n\n\t/* Under rtnl_lock and all our NAPIs have been disabled.  It's\n\t * safe to delete the hash table.\n\t */\n\tfor (i = 0; i < BNXT_NTP_FLTR_HASH_SIZE; i++) {\n\t\tstruct hlist_head *head;\n\t\tstruct hlist_node *tmp;\n\t\tstruct bnxt_ntuple_filter *fltr;\n\n\t\thead = &bp->ntp_fltr_hash_tbl[i];\n\t\thlist_for_each_entry_safe(fltr, tmp, head, hash) {\n\t\t\thlist_del(&fltr->hash);\n\t\t\tkfree(fltr);\n\t\t}\n\t}\n\tif (irq_reinit) {\n\t\tkfree(bp->ntp_fltr_bmap);\n\t\tbp->ntp_fltr_bmap = NULL;\n\t}\n\tbp->ntp_fltr_count = 0;\n#endif\n}\n\nstatic int bnxt_alloc_ntp_fltrs(struct bnxt *bp)\n{\n#ifdef CONFIG_RFS_ACCEL\n\tint i, rc = 0;\n\n\tif (!(bp->flags & BNXT_FLAG_RFS))\n\t\treturn 0;\n\n\tfor (i = 0; i < BNXT_NTP_FLTR_HASH_SIZE; i++)\n\t\tINIT_HLIST_HEAD(&bp->ntp_fltr_hash_tbl[i]);\n\n\tbp->ntp_fltr_count = 0;\n\tbp->ntp_fltr_bmap = kcalloc(BITS_TO_LONGS(BNXT_NTP_FLTR_MAX_FLTR),\n\t\t\t\t    sizeof(long),\n\t\t\t\t    GFP_KERNEL);\n\n\tif (!bp->ntp_fltr_bmap)\n\t\trc = -ENOMEM;\n\n\treturn rc;\n#else\n\treturn 0;\n#endif\n}\n\nstatic void bnxt_free_mem(struct bnxt *bp, bool irq_re_init)\n{\n\tbnxt_free_vnic_attributes(bp);\n\tbnxt_free_tx_rings(bp);\n\tbnxt_free_rx_rings(bp);\n\tbnxt_free_cp_rings(bp);\n\tbnxt_free_ntp_fltrs(bp, irq_re_init);\n\tif (irq_re_init) {\n\t\tbnxt_free_ring_stats(bp);\n\t\tif (!(bp->fw_cap & BNXT_FW_CAP_PORT_STATS_NO_RESET) ||\n\t\t    test_bit(BNXT_STATE_IN_FW_RESET, &bp->state))\n\t\t\tbnxt_free_port_stats(bp);\n\t\tbnxt_free_ring_grps(bp);\n\t\tbnxt_free_vnics(bp);\n\t\tkfree(bp->tx_ring_map);\n\t\tbp->tx_ring_map = NULL;\n\t\tkfree(bp->tx_ring);\n\t\tbp->tx_ring = NULL;\n\t\tkfree(bp->rx_ring);\n\t\tbp->rx_ring = NULL;\n\t\tkfree(bp->bnapi);\n\t\tbp->bnapi = NULL;\n\t} else {\n\t\tbnxt_clear_ring_indices(bp);\n\t}\n}\n\nstatic int bnxt_alloc_mem(struct bnxt *bp, bool irq_re_init)\n{\n\tint i, j, rc, size, arr_size;\n\tvoid *bnapi;\n\n\tif (irq_re_init) {\n\t\t/* Allocate bnapi mem pointer array and mem block for\n\t\t * all queues\n\t\t */\n\t\tarr_size = L1_CACHE_ALIGN(sizeof(struct bnxt_napi *) *\n\t\t\t\tbp->cp_nr_rings);\n\t\tsize = L1_CACHE_ALIGN(sizeof(struct bnxt_napi));\n\t\tbnapi = kzalloc(arr_size + size * bp->cp_nr_rings, GFP_KERNEL);\n\t\tif (!bnapi)\n\t\t\treturn -ENOMEM;\n\n\t\tbp->bnapi = bnapi;\n\t\tbnapi += arr_size;\n\t\tfor (i = 0; i < bp->cp_nr_rings; i++, bnapi += size) {\n\t\t\tbp->bnapi[i] = bnapi;\n\t\t\tbp->bnapi[i]->index = i;\n\t\t\tbp->bnapi[i]->bp = bp;\n\t\t\tif (bp->flags & BNXT_FLAG_CHIP_P5) {\n\t\t\t\tstruct bnxt_cp_ring_info *cpr =\n\t\t\t\t\t&bp->bnapi[i]->cp_ring;\n\n\t\t\t\tcpr->cp_ring_struct.ring_mem.flags =\n\t\t\t\t\tBNXT_RMEM_RING_PTE_FLAG;\n\t\t\t}\n\t\t}\n\n\t\tbp->rx_ring = kcalloc(bp->rx_nr_rings,\n\t\t\t\t      sizeof(struct bnxt_rx_ring_info),\n\t\t\t\t      GFP_KERNEL);\n\t\tif (!bp->rx_ring)\n\t\t\treturn -ENOMEM;\n\n\t\tfor (i = 0; i < bp->rx_nr_rings; i++) {\n\t\t\tstruct bnxt_rx_ring_info *rxr = &bp->rx_ring[i];\n\n\t\t\tif (bp->flags & BNXT_FLAG_CHIP_P5) {\n\t\t\t\trxr->rx_ring_struct.ring_mem.flags =\n\t\t\t\t\tBNXT_RMEM_RING_PTE_FLAG;\n\t\t\t\trxr->rx_agg_ring_struct.ring_mem.flags =\n\t\t\t\t\tBNXT_RMEM_RING_PTE_FLAG;\n\t\t\t}\n\t\t\trxr->bnapi = bp->bnapi[i];\n\t\t\tbp->bnapi[i]->rx_ring = &bp->rx_ring[i];\n\t\t}\n\n\t\tbp->tx_ring = kcalloc(bp->tx_nr_rings,\n\t\t\t\t      sizeof(struct bnxt_tx_ring_info),\n\t\t\t\t      GFP_KERNEL);\n\t\tif (!bp->tx_ring)\n\t\t\treturn -ENOMEM;\n\n\t\tbp->tx_ring_map = kcalloc(bp->tx_nr_rings, sizeof(u16),\n\t\t\t\t\t  GFP_KERNEL);\n\n\t\tif (!bp->tx_ring_map)\n\t\t\treturn -ENOMEM;\n\n\t\tif (bp->flags & BNXT_FLAG_SHARED_RINGS)\n\t\t\tj = 0;\n\t\telse\n\t\t\tj = bp->rx_nr_rings;\n\n\t\tfor (i = 0; i < bp->tx_nr_rings; i++, j++) {\n\t\t\tstruct bnxt_tx_ring_info *txr = &bp->tx_ring[i];\n\n\t\t\tif (bp->flags & BNXT_FLAG_CHIP_P5)\n\t\t\t\ttxr->tx_ring_struct.ring_mem.flags =\n\t\t\t\t\tBNXT_RMEM_RING_PTE_FLAG;\n\t\t\ttxr->bnapi = bp->bnapi[j];\n\t\t\tbp->bnapi[j]->tx_ring = txr;\n\t\t\tbp->tx_ring_map[i] = bp->tx_nr_rings_xdp + i;\n\t\t\tif (i >= bp->tx_nr_rings_xdp) {\n\t\t\t\ttxr->txq_index = i - bp->tx_nr_rings_xdp;\n\t\t\t\tbp->bnapi[j]->tx_int = bnxt_tx_int;\n\t\t\t} else {\n\t\t\t\tbp->bnapi[j]->flags |= BNXT_NAPI_FLAG_XDP;\n\t\t\t\tbp->bnapi[j]->tx_int = bnxt_tx_int_xdp;\n\t\t\t}\n\t\t}\n\n\t\trc = bnxt_alloc_stats(bp);\n\t\tif (rc)\n\t\t\tgoto alloc_mem_err;\n\t\tbnxt_init_stats(bp);\n\n\t\trc = bnxt_alloc_ntp_fltrs(bp);\n\t\tif (rc)\n\t\t\tgoto alloc_mem_err;\n\n\t\trc = bnxt_alloc_vnics(bp);\n\t\tif (rc)\n\t\t\tgoto alloc_mem_err;\n\t}\n\n\tbnxt_init_ring_struct(bp);\n\n\trc = bnxt_alloc_rx_rings(bp);\n\tif (rc)\n\t\tgoto alloc_mem_err;\n\n\trc = bnxt_alloc_tx_rings(bp);\n\tif (rc)\n\t\tgoto alloc_mem_err;\n\n\trc = bnxt_alloc_cp_rings(bp);\n\tif (rc)\n\t\tgoto alloc_mem_err;\n\n\tbp->vnic_info[0].flags |= BNXT_VNIC_RSS_FLAG | BNXT_VNIC_MCAST_FLAG |\n\t\t\t\t  BNXT_VNIC_UCAST_FLAG;\n\trc = bnxt_alloc_vnic_attributes(bp);\n\tif (rc)\n\t\tgoto alloc_mem_err;\n\treturn 0;\n\nalloc_mem_err:\n\tbnxt_free_mem(bp, true);\n\treturn rc;\n}\n\nstatic void bnxt_disable_int(struct bnxt *bp)\n{\n\tint i;\n\n\tif (!bp->bnapi)\n\t\treturn;\n\n\tfor (i = 0; i < bp->cp_nr_rings; i++) {\n\t\tstruct bnxt_napi *bnapi = bp->bnapi[i];\n\t\tstruct bnxt_cp_ring_info *cpr = &bnapi->cp_ring;\n\t\tstruct bnxt_ring_struct *ring = &cpr->cp_ring_struct;\n\n\t\tif (ring->fw_ring_id != INVALID_HW_RING_ID)\n\t\t\tbnxt_db_nq(bp, &cpr->cp_db, cpr->cp_raw_cons);\n\t}\n}\n\nstatic int bnxt_cp_num_to_irq_num(struct bnxt *bp, int n)\n{\n\tstruct bnxt_napi *bnapi = bp->bnapi[n];\n\tstruct bnxt_cp_ring_info *cpr;\n\n\tcpr = &bnapi->cp_ring;\n\treturn cpr->cp_ring_struct.map_idx;\n}\n\nstatic void bnxt_disable_int_sync(struct bnxt *bp)\n{\n\tint i;\n\n\tif (!bp->irq_tbl)\n\t\treturn;\n\n\tatomic_inc(&bp->intr_sem);\n\n\tbnxt_disable_int(bp);\n\tfor (i = 0; i < bp->cp_nr_rings; i++) {\n\t\tint map_idx = bnxt_cp_num_to_irq_num(bp, i);\n\n\t\tsynchronize_irq(bp->irq_tbl[map_idx].vector);\n\t}\n}\n\nstatic void bnxt_enable_int(struct bnxt *bp)\n{\n\tint i;\n\n\tatomic_set(&bp->intr_sem, 0);\n\tfor (i = 0; i < bp->cp_nr_rings; i++) {\n\t\tstruct bnxt_napi *bnapi = bp->bnapi[i];\n\t\tstruct bnxt_cp_ring_info *cpr = &bnapi->cp_ring;\n\n\t\tbnxt_db_nq_arm(bp, &cpr->cp_db, cpr->cp_raw_cons);\n\t}\n}\n\nvoid bnxt_hwrm_cmd_hdr_init(struct bnxt *bp, void *request, u16 req_type,\n\t\t\t    u16 cmpl_ring, u16 target_id)\n{\n\tstruct input *req = request;\n\n\treq->req_type = cpu_to_le16(req_type);\n\treq->cmpl_ring = cpu_to_le16(cmpl_ring);\n\treq->target_id = cpu_to_le16(target_id);\n\tif (bnxt_kong_hwrm_message(bp, req))\n\t\treq->resp_addr = cpu_to_le64(bp->hwrm_cmd_kong_resp_dma_addr);\n\telse\n\t\treq->resp_addr = cpu_to_le64(bp->hwrm_cmd_resp_dma_addr);\n}\n\nstatic int bnxt_hwrm_to_stderr(u32 hwrm_err)\n{\n\tswitch (hwrm_err) {\n\tcase HWRM_ERR_CODE_SUCCESS:\n\t\treturn 0;\n\tcase HWRM_ERR_CODE_RESOURCE_LOCKED:\n\t\treturn -EROFS;\n\tcase HWRM_ERR_CODE_RESOURCE_ACCESS_DENIED:\n\t\treturn -EACCES;\n\tcase HWRM_ERR_CODE_RESOURCE_ALLOC_ERROR:\n\t\treturn -ENOSPC;\n\tcase HWRM_ERR_CODE_INVALID_PARAMS:\n\tcase HWRM_ERR_CODE_INVALID_FLAGS:\n\tcase HWRM_ERR_CODE_INVALID_ENABLES:\n\tcase HWRM_ERR_CODE_UNSUPPORTED_TLV:\n\tcase HWRM_ERR_CODE_UNSUPPORTED_OPTION_ERR:\n\t\treturn -EINVAL;\n\tcase HWRM_ERR_CODE_NO_BUFFER:\n\t\treturn -ENOMEM;\n\tcase HWRM_ERR_CODE_HOT_RESET_PROGRESS:\n\tcase HWRM_ERR_CODE_BUSY:\n\t\treturn -EAGAIN;\n\tcase HWRM_ERR_CODE_CMD_NOT_SUPPORTED:\n\t\treturn -EOPNOTSUPP;\n\tdefault:\n\t\treturn -EIO;\n\t}\n}\n\nstatic int bnxt_hwrm_do_send_msg(struct bnxt *bp, void *msg, u32 msg_len,\n\t\t\t\t int timeout, bool silent)\n{\n\tint i, intr_process, rc, tmo_count;\n\tstruct input *req = msg;\n\tu32 *data = msg;\n\tu8 *valid;\n\tu16 cp_ring_id, len = 0;\n\tstruct hwrm_err_output *resp = bp->hwrm_cmd_resp_addr;\n\tu16 max_req_len = BNXT_HWRM_MAX_REQ_LEN;\n\tstruct hwrm_short_input short_input = {0};\n\tu32 doorbell_offset = BNXT_GRCPF_REG_CHIMP_COMM_TRIGGER;\n\tu32 bar_offset = BNXT_GRCPF_REG_CHIMP_COMM;\n\tu16 dst = BNXT_HWRM_CHNL_CHIMP;\n\n\tif (BNXT_NO_FW_ACCESS(bp) &&\n\t    le16_to_cpu(req->req_type) != HWRM_FUNC_RESET)\n\t\treturn -EBUSY;\n\n\tif (msg_len > BNXT_HWRM_MAX_REQ_LEN) {\n\t\tif (msg_len > bp->hwrm_max_ext_req_len ||\n\t\t    !bp->hwrm_short_cmd_req_addr)\n\t\t\treturn -EINVAL;\n\t}\n\n\tif (bnxt_hwrm_kong_chnl(bp, req)) {\n\t\tdst = BNXT_HWRM_CHNL_KONG;\n\t\tbar_offset = BNXT_GRCPF_REG_KONG_COMM;\n\t\tdoorbell_offset = BNXT_GRCPF_REG_KONG_COMM_TRIGGER;\n\t\tresp = bp->hwrm_cmd_kong_resp_addr;\n\t}\n\n\tmemset(resp, 0, PAGE_SIZE);\n\tcp_ring_id = le16_to_cpu(req->cmpl_ring);\n\tintr_process = (cp_ring_id == INVALID_HW_RING_ID) ? 0 : 1;\n\n\treq->seq_id = cpu_to_le16(bnxt_get_hwrm_seq_id(bp, dst));\n\t/* currently supports only one outstanding message */\n\tif (intr_process)\n\t\tbp->hwrm_intr_seq_id = le16_to_cpu(req->seq_id);\n\n\tif ((bp->fw_cap & BNXT_FW_CAP_SHORT_CMD) ||\n\t    msg_len > BNXT_HWRM_MAX_REQ_LEN) {\n\t\tvoid *short_cmd_req = bp->hwrm_short_cmd_req_addr;\n\t\tu16 max_msg_len;\n\n\t\t/* Set boundary for maximum extended request length for short\n\t\t * cmd format. If passed up from device use the max supported\n\t\t * internal req length.\n\t\t */\n\t\tmax_msg_len = bp->hwrm_max_ext_req_len;\n\n\t\tmemcpy(short_cmd_req, req, msg_len);\n\t\tif (msg_len < max_msg_len)\n\t\t\tmemset(short_cmd_req + msg_len, 0,\n\t\t\t       max_msg_len - msg_len);\n\n\t\tshort_input.req_type = req->req_type;\n\t\tshort_input.signature =\n\t\t\t\tcpu_to_le16(SHORT_REQ_SIGNATURE_SHORT_CMD);\n\t\tshort_input.size = cpu_to_le16(msg_len);\n\t\tshort_input.req_addr =\n\t\t\tcpu_to_le64(bp->hwrm_short_cmd_req_dma_addr);\n\n\t\tdata = (u32 *)&short_input;\n\t\tmsg_len = sizeof(short_input);\n\n\t\t/* Sync memory write before updating doorbell */\n\t\twmb();\n\n\t\tmax_req_len = BNXT_HWRM_SHORT_REQ_LEN;\n\t}\n\n\t/* Write request msg to hwrm channel */\n\t__iowrite32_copy(bp->bar0 + bar_offset, data, msg_len / 4);\n\n\tfor (i = msg_len; i < max_req_len; i += 4)\n\t\twritel(0, bp->bar0 + bar_offset + i);\n\n\t/* Ring channel doorbell */\n\twritel(1, bp->bar0 + doorbell_offset);\n\n\tif (!pci_is_enabled(bp->pdev))\n\t\treturn -ENODEV;\n\n\tif (!timeout)\n\t\ttimeout = DFLT_HWRM_CMD_TIMEOUT;\n\t/* Limit timeout to an upper limit */\n\ttimeout = min(timeout, HWRM_CMD_MAX_TIMEOUT);\n\t/* convert timeout to usec */\n\ttimeout *= 1000;\n\n\ti = 0;\n\t/* Short timeout for the first few iterations:\n\t * number of loops = number of loops for short timeout +\n\t * number of loops for standard timeout.\n\t */\n\ttmo_count = HWRM_SHORT_TIMEOUT_COUNTER;\n\ttimeout = timeout - HWRM_SHORT_MIN_TIMEOUT * HWRM_SHORT_TIMEOUT_COUNTER;\n\ttmo_count += DIV_ROUND_UP(timeout, HWRM_MIN_TIMEOUT);\n\n\tif (intr_process) {\n\t\tu16 seq_id = bp->hwrm_intr_seq_id;\n\n\t\t/* Wait until hwrm response cmpl interrupt is processed */\n\t\twhile (bp->hwrm_intr_seq_id != (u16)~seq_id &&\n\t\t       i++ < tmo_count) {\n\t\t\t/* Abort the wait for completion if the FW health\n\t\t\t * check has failed.\n\t\t\t */\n\t\t\tif (test_bit(BNXT_STATE_FW_FATAL_COND, &bp->state))\n\t\t\t\treturn -EBUSY;\n\t\t\t/* on first few passes, just barely sleep */\n\t\t\tif (i < HWRM_SHORT_TIMEOUT_COUNTER) {\n\t\t\t\tusleep_range(HWRM_SHORT_MIN_TIMEOUT,\n\t\t\t\t\t     HWRM_SHORT_MAX_TIMEOUT);\n\t\t\t} else {\n\t\t\t\tif (HWRM_WAIT_MUST_ABORT(bp, req))\n\t\t\t\t\tbreak;\n\t\t\t\tusleep_range(HWRM_MIN_TIMEOUT,\n\t\t\t\t\t     HWRM_MAX_TIMEOUT);\n\t\t\t}\n\t\t}\n\n\t\tif (bp->hwrm_intr_seq_id != (u16)~seq_id) {\n\t\t\tif (!silent)\n\t\t\t\tnetdev_err(bp->dev, \"Resp cmpl intr err msg: 0x%x\\n\",\n\t\t\t\t\t   le16_to_cpu(req->req_type));\n\t\t\treturn -EBUSY;\n\t\t}\n\t\tlen = le16_to_cpu(resp->resp_len);\n\t\tvalid = ((u8 *)resp) + len - 1;\n\t} else {\n\t\tint j;\n\n\t\t/* Check if response len is updated */\n\t\tfor (i = 0; i < tmo_count; i++) {\n\t\t\t/* Abort the wait for completion if the FW health\n\t\t\t * check has failed.\n\t\t\t */\n\t\t\tif (test_bit(BNXT_STATE_FW_FATAL_COND, &bp->state))\n\t\t\t\treturn -EBUSY;\n\t\t\tlen = le16_to_cpu(resp->resp_len);\n\t\t\tif (len)\n\t\t\t\tbreak;\n\t\t\t/* on first few passes, just barely sleep */\n\t\t\tif (i < HWRM_SHORT_TIMEOUT_COUNTER) {\n\t\t\t\tusleep_range(HWRM_SHORT_MIN_TIMEOUT,\n\t\t\t\t\t     HWRM_SHORT_MAX_TIMEOUT);\n\t\t\t} else {\n\t\t\t\tif (HWRM_WAIT_MUST_ABORT(bp, req))\n\t\t\t\t\tgoto timeout_abort;\n\t\t\t\tusleep_range(HWRM_MIN_TIMEOUT,\n\t\t\t\t\t     HWRM_MAX_TIMEOUT);\n\t\t\t}\n\t\t}\n\n\t\tif (i >= tmo_count) {\ntimeout_abort:\n\t\t\tif (!silent)\n\t\t\t\tnetdev_err(bp->dev, \"Error (timeout: %d) msg {0x%x 0x%x} len:%d\\n\",\n\t\t\t\t\t   HWRM_TOTAL_TIMEOUT(i),\n\t\t\t\t\t   le16_to_cpu(req->req_type),\n\t\t\t\t\t   le16_to_cpu(req->seq_id), len);\n\t\t\treturn -EBUSY;\n\t\t}\n\n\t\t/* Last byte of resp contains valid bit */\n\t\tvalid = ((u8 *)resp) + len - 1;\n\t\tfor (j = 0; j < HWRM_VALID_BIT_DELAY_USEC; j++) {\n\t\t\t/* make sure we read from updated DMA memory */\n\t\t\tdma_rmb();\n\t\t\tif (*valid)\n\t\t\t\tbreak;\n\t\t\tusleep_range(1, 5);\n\t\t}\n\n\t\tif (j >= HWRM_VALID_BIT_DELAY_USEC) {\n\t\t\tif (!silent)\n\t\t\t\tnetdev_err(bp->dev, \"Error (timeout: %d) msg {0x%x 0x%x} len:%d v:%d\\n\",\n\t\t\t\t\t   HWRM_TOTAL_TIMEOUT(i),\n\t\t\t\t\t   le16_to_cpu(req->req_type),\n\t\t\t\t\t   le16_to_cpu(req->seq_id), len,\n\t\t\t\t\t   *valid);\n\t\t\treturn -EBUSY;\n\t\t}\n\t}\n\n\t/* Zero valid bit for compatibility.  Valid bit in an older spec\n\t * may become a new field in a newer spec.  We must make sure that\n\t * a new field not implemented by old spec will read zero.\n\t */\n\t*valid = 0;\n\trc = le16_to_cpu(resp->error_code);\n\tif (rc && !silent)\n\t\tnetdev_err(bp->dev, \"hwrm req_type 0x%x seq id 0x%x error 0x%x\\n\",\n\t\t\t   le16_to_cpu(resp->req_type),\n\t\t\t   le16_to_cpu(resp->seq_id), rc);\n\treturn bnxt_hwrm_to_stderr(rc);\n}\n\nint _hwrm_send_message(struct bnxt *bp, void *msg, u32 msg_len, int timeout)\n{\n\treturn bnxt_hwrm_do_send_msg(bp, msg, msg_len, timeout, false);\n}\n\nint _hwrm_send_message_silent(struct bnxt *bp, void *msg, u32 msg_len,\n\t\t\t      int timeout)\n{\n\treturn bnxt_hwrm_do_send_msg(bp, msg, msg_len, timeout, true);\n}\n\nint hwrm_send_message(struct bnxt *bp, void *msg, u32 msg_len, int timeout)\n{\n\tint rc;\n\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message(bp, msg, msg_len, timeout);\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\treturn rc;\n}\n\nint hwrm_send_message_silent(struct bnxt *bp, void *msg, u32 msg_len,\n\t\t\t     int timeout)\n{\n\tint rc;\n\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = bnxt_hwrm_do_send_msg(bp, msg, msg_len, timeout, true);\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\treturn rc;\n}\n\nint bnxt_hwrm_func_drv_rgtr(struct bnxt *bp, unsigned long *bmap, int bmap_size,\n\t\t\t    bool async_only)\n{\n\tstruct hwrm_func_drv_rgtr_output *resp = bp->hwrm_cmd_resp_addr;\n\tstruct hwrm_func_drv_rgtr_input req = {0};\n\tDECLARE_BITMAP(async_events_bmap, 256);\n\tu32 *events = (u32 *)async_events_bmap;\n\tu32 flags;\n\tint rc, i;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_FUNC_DRV_RGTR, -1, -1);\n\n\treq.enables =\n\t\tcpu_to_le32(FUNC_DRV_RGTR_REQ_ENABLES_OS_TYPE |\n\t\t\t    FUNC_DRV_RGTR_REQ_ENABLES_VER |\n\t\t\t    FUNC_DRV_RGTR_REQ_ENABLES_ASYNC_EVENT_FWD);\n\n\treq.os_type = cpu_to_le16(FUNC_DRV_RGTR_REQ_OS_TYPE_LINUX);\n\tflags = FUNC_DRV_RGTR_REQ_FLAGS_16BIT_VER_MODE;\n\tif (bp->fw_cap & BNXT_FW_CAP_HOT_RESET)\n\t\tflags |= FUNC_DRV_RGTR_REQ_FLAGS_HOT_RESET_SUPPORT;\n\tif (bp->fw_cap & BNXT_FW_CAP_ERROR_RECOVERY)\n\t\tflags |= FUNC_DRV_RGTR_REQ_FLAGS_ERROR_RECOVERY_SUPPORT |\n\t\t\t FUNC_DRV_RGTR_REQ_FLAGS_MASTER_SUPPORT;\n\treq.flags = cpu_to_le32(flags);\n\treq.ver_maj_8b = DRV_VER_MAJ;\n\treq.ver_min_8b = DRV_VER_MIN;\n\treq.ver_upd_8b = DRV_VER_UPD;\n\treq.ver_maj = cpu_to_le16(DRV_VER_MAJ);\n\treq.ver_min = cpu_to_le16(DRV_VER_MIN);\n\treq.ver_upd = cpu_to_le16(DRV_VER_UPD);\n\n\tif (BNXT_PF(bp)) {\n\t\tu32 data[8];\n\t\tint i;\n\n\t\tmemset(data, 0, sizeof(data));\n\t\tfor (i = 0; i < ARRAY_SIZE(bnxt_vf_req_snif); i++) {\n\t\t\tu16 cmd = bnxt_vf_req_snif[i];\n\t\t\tunsigned int bit, idx;\n\n\t\t\tidx = cmd / 32;\n\t\t\tbit = cmd % 32;\n\t\t\tdata[idx] |= 1 << bit;\n\t\t}\n\n\t\tfor (i = 0; i < 8; i++)\n\t\t\treq.vf_req_fwd[i] = cpu_to_le32(data[i]);\n\n\t\treq.enables |=\n\t\t\tcpu_to_le32(FUNC_DRV_RGTR_REQ_ENABLES_VF_REQ_FWD);\n\t}\n\n\tif (bp->fw_cap & BNXT_FW_CAP_OVS_64BIT_HANDLE)\n\t\treq.flags |= cpu_to_le32(\n\t\t\tFUNC_DRV_RGTR_REQ_FLAGS_FLOW_HANDLE_64BIT_MODE);\n\n\tmemset(async_events_bmap, 0, sizeof(async_events_bmap));\n\tfor (i = 0; i < ARRAY_SIZE(bnxt_async_events_arr); i++) {\n\t\tu16 event_id = bnxt_async_events_arr[i];\n\n\t\tif (event_id == ASYNC_EVENT_CMPL_EVENT_ID_ERROR_RECOVERY &&\n\t\t    !(bp->fw_cap & BNXT_FW_CAP_ERROR_RECOVERY))\n\t\t\tcontinue;\n\t\t__set_bit(bnxt_async_events_arr[i], async_events_bmap);\n\t}\n\tif (bmap && bmap_size) {\n\t\tfor (i = 0; i < bmap_size; i++) {\n\t\t\tif (test_bit(i, bmap))\n\t\t\t\t__set_bit(i, async_events_bmap);\n\t\t}\n\t}\n\tfor (i = 0; i < 8; i++)\n\t\treq.async_event_fwd[i] |= cpu_to_le32(events[i]);\n\n\tif (async_only)\n\t\treq.enables =\n\t\t\tcpu_to_le32(FUNC_DRV_RGTR_REQ_ENABLES_ASYNC_EVENT_FWD);\n\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (!rc) {\n\t\tset_bit(BNXT_STATE_DRV_REGISTERED, &bp->state);\n\t\tif (resp->flags &\n\t\t    cpu_to_le32(FUNC_DRV_RGTR_RESP_FLAGS_IF_CHANGE_SUPPORTED))\n\t\t\tbp->fw_cap |= BNXT_FW_CAP_IF_CHANGE;\n\t}\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\treturn rc;\n}\n\nstatic int bnxt_hwrm_func_drv_unrgtr(struct bnxt *bp)\n{\n\tstruct hwrm_func_drv_unrgtr_input req = {0};\n\n\tif (!test_and_clear_bit(BNXT_STATE_DRV_REGISTERED, &bp->state))\n\t\treturn 0;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_FUNC_DRV_UNRGTR, -1, -1);\n\treturn hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n}\n\nstatic int bnxt_hwrm_tunnel_dst_port_free(struct bnxt *bp, u8 tunnel_type)\n{\n\tu32 rc = 0;\n\tstruct hwrm_tunnel_dst_port_free_input req = {0};\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_TUNNEL_DST_PORT_FREE, -1, -1);\n\treq.tunnel_type = tunnel_type;\n\n\tswitch (tunnel_type) {\n\tcase TUNNEL_DST_PORT_FREE_REQ_TUNNEL_TYPE_VXLAN:\n\t\treq.tunnel_dst_port_id = cpu_to_le16(bp->vxlan_fw_dst_port_id);\n\t\tbp->vxlan_fw_dst_port_id = INVALID_HW_RING_ID;\n\t\tbreak;\n\tcase TUNNEL_DST_PORT_FREE_REQ_TUNNEL_TYPE_GENEVE:\n\t\treq.tunnel_dst_port_id = cpu_to_le16(bp->nge_fw_dst_port_id);\n\t\tbp->nge_fw_dst_port_id = INVALID_HW_RING_ID;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\trc = hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (rc)\n\t\tnetdev_err(bp->dev, \"hwrm_tunnel_dst_port_free failed. rc:%d\\n\",\n\t\t\t   rc);\n\treturn rc;\n}\n\nstatic int bnxt_hwrm_tunnel_dst_port_alloc(struct bnxt *bp, __be16 port,\n\t\t\t\t\t   u8 tunnel_type)\n{\n\tu32 rc = 0;\n\tstruct hwrm_tunnel_dst_port_alloc_input req = {0};\n\tstruct hwrm_tunnel_dst_port_alloc_output *resp = bp->hwrm_cmd_resp_addr;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_TUNNEL_DST_PORT_ALLOC, -1, -1);\n\n\treq.tunnel_type = tunnel_type;\n\treq.tunnel_dst_port_val = port;\n\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"hwrm_tunnel_dst_port_alloc failed. rc:%d\\n\",\n\t\t\t   rc);\n\t\tgoto err_out;\n\t}\n\n\tswitch (tunnel_type) {\n\tcase TUNNEL_DST_PORT_ALLOC_REQ_TUNNEL_TYPE_VXLAN:\n\t\tbp->vxlan_fw_dst_port_id =\n\t\t\tle16_to_cpu(resp->tunnel_dst_port_id);\n\t\tbreak;\n\tcase TUNNEL_DST_PORT_ALLOC_REQ_TUNNEL_TYPE_GENEVE:\n\t\tbp->nge_fw_dst_port_id = le16_to_cpu(resp->tunnel_dst_port_id);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\nerr_out:\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\treturn rc;\n}\n\nstatic int bnxt_hwrm_cfa_l2_set_rx_mask(struct bnxt *bp, u16 vnic_id)\n{\n\tstruct hwrm_cfa_l2_set_rx_mask_input req = {0};\n\tstruct bnxt_vnic_info *vnic = &bp->vnic_info[vnic_id];\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_CFA_L2_SET_RX_MASK, -1, -1);\n\treq.vnic_id = cpu_to_le32(vnic->fw_vnic_id);\n\n\treq.num_mc_entries = cpu_to_le32(vnic->mc_list_count);\n\treq.mc_tbl_addr = cpu_to_le64(vnic->mc_list_mapping);\n\treq.mask = cpu_to_le32(vnic->rx_mask);\n\treturn hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n}\n\n#ifdef CONFIG_RFS_ACCEL\nstatic int bnxt_hwrm_cfa_ntuple_filter_free(struct bnxt *bp,\n\t\t\t\t\t    struct bnxt_ntuple_filter *fltr)\n{\n\tstruct hwrm_cfa_ntuple_filter_free_input req = {0};\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_CFA_NTUPLE_FILTER_FREE, -1, -1);\n\treq.ntuple_filter_id = fltr->filter_id;\n\treturn hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n}\n\n#define BNXT_NTP_FLTR_FLAGS\t\t\t\t\t\\\n\t(CFA_NTUPLE_FILTER_ALLOC_REQ_ENABLES_L2_FILTER_ID |\t\\\n\t CFA_NTUPLE_FILTER_ALLOC_REQ_ENABLES_ETHERTYPE |\t\\\n\t CFA_NTUPLE_FILTER_ALLOC_REQ_ENABLES_SRC_MACADDR |\t\\\n\t CFA_NTUPLE_FILTER_ALLOC_REQ_ENABLES_IPADDR_TYPE |\t\\\n\t CFA_NTUPLE_FILTER_ALLOC_REQ_ENABLES_SRC_IPADDR |\t\\\n\t CFA_NTUPLE_FILTER_ALLOC_REQ_ENABLES_SRC_IPADDR_MASK |\t\\\n\t CFA_NTUPLE_FILTER_ALLOC_REQ_ENABLES_DST_IPADDR |\t\\\n\t CFA_NTUPLE_FILTER_ALLOC_REQ_ENABLES_DST_IPADDR_MASK |\t\\\n\t CFA_NTUPLE_FILTER_ALLOC_REQ_ENABLES_IP_PROTOCOL |\t\\\n\t CFA_NTUPLE_FILTER_ALLOC_REQ_ENABLES_SRC_PORT |\t\t\\\n\t CFA_NTUPLE_FILTER_ALLOC_REQ_ENABLES_SRC_PORT_MASK |\t\\\n\t CFA_NTUPLE_FILTER_ALLOC_REQ_ENABLES_DST_PORT |\t\t\\\n\t CFA_NTUPLE_FILTER_ALLOC_REQ_ENABLES_DST_PORT_MASK |\t\\\n\t CFA_NTUPLE_FILTER_ALLOC_REQ_ENABLES_DST_ID)\n\n#define BNXT_NTP_TUNNEL_FLTR_FLAG\t\t\t\t\\\n\t\tCFA_NTUPLE_FILTER_ALLOC_REQ_ENABLES_TUNNEL_TYPE\n\nstatic int bnxt_hwrm_cfa_ntuple_filter_alloc(struct bnxt *bp,\n\t\t\t\t\t     struct bnxt_ntuple_filter *fltr)\n{\n\tstruct hwrm_cfa_ntuple_filter_alloc_input req = {0};\n\tstruct hwrm_cfa_ntuple_filter_alloc_output *resp;\n\tstruct flow_keys *keys = &fltr->fkeys;\n\tstruct bnxt_vnic_info *vnic;\n\tu32 flags = 0;\n\tint rc = 0;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_CFA_NTUPLE_FILTER_ALLOC, -1, -1);\n\treq.l2_filter_id = bp->vnic_info[0].fw_l2_filter_id[fltr->l2_fltr_idx];\n\n\tif (bp->fw_cap & BNXT_FW_CAP_CFA_RFS_RING_TBL_IDX_V2) {\n\t\tflags = CFA_NTUPLE_FILTER_ALLOC_REQ_FLAGS_DEST_RFS_RING_IDX;\n\t\treq.dst_id = cpu_to_le16(fltr->rxq);\n\t} else {\n\t\tvnic = &bp->vnic_info[fltr->rxq + 1];\n\t\treq.dst_id = cpu_to_le16(vnic->fw_vnic_id);\n\t}\n\treq.flags = cpu_to_le32(flags);\n\treq.enables = cpu_to_le32(BNXT_NTP_FLTR_FLAGS);\n\n\treq.ethertype = htons(ETH_P_IP);\n\tmemcpy(req.src_macaddr, fltr->src_mac_addr, ETH_ALEN);\n\treq.ip_addr_type = CFA_NTUPLE_FILTER_ALLOC_REQ_IP_ADDR_TYPE_IPV4;\n\treq.ip_protocol = keys->basic.ip_proto;\n\n\tif (keys->basic.n_proto == htons(ETH_P_IPV6)) {\n\t\tint i;\n\n\t\treq.ethertype = htons(ETH_P_IPV6);\n\t\treq.ip_addr_type =\n\t\t\tCFA_NTUPLE_FILTER_ALLOC_REQ_IP_ADDR_TYPE_IPV6;\n\t\t*(struct in6_addr *)&req.src_ipaddr[0] =\n\t\t\tkeys->addrs.v6addrs.src;\n\t\t*(struct in6_addr *)&req.dst_ipaddr[0] =\n\t\t\tkeys->addrs.v6addrs.dst;\n\t\tfor (i = 0; i < 4; i++) {\n\t\t\treq.src_ipaddr_mask[i] = cpu_to_be32(0xffffffff);\n\t\t\treq.dst_ipaddr_mask[i] = cpu_to_be32(0xffffffff);\n\t\t}\n\t} else {\n\t\treq.src_ipaddr[0] = keys->addrs.v4addrs.src;\n\t\treq.src_ipaddr_mask[0] = cpu_to_be32(0xffffffff);\n\t\treq.dst_ipaddr[0] = keys->addrs.v4addrs.dst;\n\t\treq.dst_ipaddr_mask[0] = cpu_to_be32(0xffffffff);\n\t}\n\tif (keys->control.flags & FLOW_DIS_ENCAPSULATION) {\n\t\treq.enables |= cpu_to_le32(BNXT_NTP_TUNNEL_FLTR_FLAG);\n\t\treq.tunnel_type =\n\t\t\tCFA_NTUPLE_FILTER_ALLOC_REQ_TUNNEL_TYPE_ANYTUNNEL;\n\t}\n\n\treq.src_port = keys->ports.src;\n\treq.src_port_mask = cpu_to_be16(0xffff);\n\treq.dst_port = keys->ports.dst;\n\treq.dst_port_mask = cpu_to_be16(0xffff);\n\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (!rc) {\n\t\tresp = bnxt_get_hwrm_resp_addr(bp, &req);\n\t\tfltr->filter_id = resp->ntuple_filter_id;\n\t}\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\treturn rc;\n}\n#endif\n\nstatic int bnxt_hwrm_set_vnic_filter(struct bnxt *bp, u16 vnic_id, u16 idx,\n\t\t\t\t     u8 *mac_addr)\n{\n\tu32 rc = 0;\n\tstruct hwrm_cfa_l2_filter_alloc_input req = {0};\n\tstruct hwrm_cfa_l2_filter_alloc_output *resp = bp->hwrm_cmd_resp_addr;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_CFA_L2_FILTER_ALLOC, -1, -1);\n\treq.flags = cpu_to_le32(CFA_L2_FILTER_ALLOC_REQ_FLAGS_PATH_RX);\n\tif (!BNXT_CHIP_TYPE_NITRO_A0(bp))\n\t\treq.flags |=\n\t\t\tcpu_to_le32(CFA_L2_FILTER_ALLOC_REQ_FLAGS_OUTERMOST);\n\treq.dst_id = cpu_to_le16(bp->vnic_info[vnic_id].fw_vnic_id);\n\treq.enables =\n\t\tcpu_to_le32(CFA_L2_FILTER_ALLOC_REQ_ENABLES_L2_ADDR |\n\t\t\t    CFA_L2_FILTER_ALLOC_REQ_ENABLES_DST_ID |\n\t\t\t    CFA_L2_FILTER_ALLOC_REQ_ENABLES_L2_ADDR_MASK);\n\tmemcpy(req.l2_addr, mac_addr, ETH_ALEN);\n\treq.l2_addr_mask[0] = 0xff;\n\treq.l2_addr_mask[1] = 0xff;\n\treq.l2_addr_mask[2] = 0xff;\n\treq.l2_addr_mask[3] = 0xff;\n\treq.l2_addr_mask[4] = 0xff;\n\treq.l2_addr_mask[5] = 0xff;\n\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (!rc)\n\t\tbp->vnic_info[vnic_id].fw_l2_filter_id[idx] =\n\t\t\t\t\t\t\tresp->l2_filter_id;\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\treturn rc;\n}\n\nstatic int bnxt_hwrm_clear_vnic_filter(struct bnxt *bp)\n{\n\tu16 i, j, num_of_vnics = 1; /* only vnic 0 supported */\n\tint rc = 0;\n\n\t/* Any associated ntuple filters will also be cleared by firmware. */\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\tfor (i = 0; i < num_of_vnics; i++) {\n\t\tstruct bnxt_vnic_info *vnic = &bp->vnic_info[i];\n\n\t\tfor (j = 0; j < vnic->uc_filter_count; j++) {\n\t\t\tstruct hwrm_cfa_l2_filter_free_input req = {0};\n\n\t\t\tbnxt_hwrm_cmd_hdr_init(bp, &req,\n\t\t\t\t\t       HWRM_CFA_L2_FILTER_FREE, -1, -1);\n\n\t\t\treq.l2_filter_id = vnic->fw_l2_filter_id[j];\n\n\t\t\trc = _hwrm_send_message(bp, &req, sizeof(req),\n\t\t\t\t\t\tHWRM_CMD_TIMEOUT);\n\t\t}\n\t\tvnic->uc_filter_count = 0;\n\t}\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\n\treturn rc;\n}\n\nstatic int bnxt_hwrm_vnic_set_tpa(struct bnxt *bp, u16 vnic_id, u32 tpa_flags)\n{\n\tstruct bnxt_vnic_info *vnic = &bp->vnic_info[vnic_id];\n\tu16 max_aggs = VNIC_TPA_CFG_REQ_MAX_AGGS_MAX;\n\tstruct hwrm_vnic_tpa_cfg_input req = {0};\n\n\tif (vnic->fw_vnic_id == INVALID_HW_RING_ID)\n\t\treturn 0;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_VNIC_TPA_CFG, -1, -1);\n\n\tif (tpa_flags) {\n\t\tu16 mss = bp->dev->mtu - 40;\n\t\tu32 nsegs, n, segs = 0, flags;\n\n\t\tflags = VNIC_TPA_CFG_REQ_FLAGS_TPA |\n\t\t\tVNIC_TPA_CFG_REQ_FLAGS_ENCAP_TPA |\n\t\t\tVNIC_TPA_CFG_REQ_FLAGS_RSC_WND_UPDATE |\n\t\t\tVNIC_TPA_CFG_REQ_FLAGS_AGG_WITH_ECN |\n\t\t\tVNIC_TPA_CFG_REQ_FLAGS_AGG_WITH_SAME_GRE_SEQ;\n\t\tif (tpa_flags & BNXT_FLAG_GRO)\n\t\t\tflags |= VNIC_TPA_CFG_REQ_FLAGS_GRO;\n\n\t\treq.flags = cpu_to_le32(flags);\n\n\t\treq.enables =\n\t\t\tcpu_to_le32(VNIC_TPA_CFG_REQ_ENABLES_MAX_AGG_SEGS |\n\t\t\t\t    VNIC_TPA_CFG_REQ_ENABLES_MAX_AGGS |\n\t\t\t\t    VNIC_TPA_CFG_REQ_ENABLES_MIN_AGG_LEN);\n\n\t\t/* Number of segs are log2 units, and first packet is not\n\t\t * included as part of this units.\n\t\t */\n\t\tif (mss <= BNXT_RX_PAGE_SIZE) {\n\t\t\tn = BNXT_RX_PAGE_SIZE / mss;\n\t\t\tnsegs = (MAX_SKB_FRAGS - 1) * n;\n\t\t} else {\n\t\t\tn = mss / BNXT_RX_PAGE_SIZE;\n\t\t\tif (mss & (BNXT_RX_PAGE_SIZE - 1))\n\t\t\t\tn++;\n\t\t\tnsegs = (MAX_SKB_FRAGS - n) / n;\n\t\t}\n\n\t\tif (bp->flags & BNXT_FLAG_CHIP_P5) {\n\t\t\tsegs = MAX_TPA_SEGS_P5;\n\t\t\tmax_aggs = bp->max_tpa;\n\t\t} else {\n\t\t\tsegs = ilog2(nsegs);\n\t\t}\n\t\treq.max_agg_segs = cpu_to_le16(segs);\n\t\treq.max_aggs = cpu_to_le16(max_aggs);\n\n\t\treq.min_agg_len = cpu_to_le32(512);\n\t}\n\treq.vnic_id = cpu_to_le16(vnic->fw_vnic_id);\n\n\treturn hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n}\n\nstatic u16 bnxt_cp_ring_from_grp(struct bnxt *bp, struct bnxt_ring_struct *ring)\n{\n\tstruct bnxt_ring_grp_info *grp_info;\n\n\tgrp_info = &bp->grp_info[ring->grp_idx];\n\treturn grp_info->cp_fw_ring_id;\n}\n\nstatic u16 bnxt_cp_ring_for_rx(struct bnxt *bp, struct bnxt_rx_ring_info *rxr)\n{\n\tif (bp->flags & BNXT_FLAG_CHIP_P5) {\n\t\tstruct bnxt_napi *bnapi = rxr->bnapi;\n\t\tstruct bnxt_cp_ring_info *cpr;\n\n\t\tcpr = bnapi->cp_ring.cp_ring_arr[BNXT_RX_HDL];\n\t\treturn cpr->cp_ring_struct.fw_ring_id;\n\t} else {\n\t\treturn bnxt_cp_ring_from_grp(bp, &rxr->rx_ring_struct);\n\t}\n}\n\nstatic u16 bnxt_cp_ring_for_tx(struct bnxt *bp, struct bnxt_tx_ring_info *txr)\n{\n\tif (bp->flags & BNXT_FLAG_CHIP_P5) {\n\t\tstruct bnxt_napi *bnapi = txr->bnapi;\n\t\tstruct bnxt_cp_ring_info *cpr;\n\n\t\tcpr = bnapi->cp_ring.cp_ring_arr[BNXT_TX_HDL];\n\t\treturn cpr->cp_ring_struct.fw_ring_id;\n\t} else {\n\t\treturn bnxt_cp_ring_from_grp(bp, &txr->tx_ring_struct);\n\t}\n}\n\nstatic int bnxt_alloc_rss_indir_tbl(struct bnxt *bp)\n{\n\tint entries;\n\n\tif (bp->flags & BNXT_FLAG_CHIP_P5)\n\t\tentries = BNXT_MAX_RSS_TABLE_ENTRIES_P5;\n\telse\n\t\tentries = HW_HASH_INDEX_SIZE;\n\n\tbp->rss_indir_tbl_entries = entries;\n\tbp->rss_indir_tbl = kmalloc_array(entries, sizeof(*bp->rss_indir_tbl),\n\t\t\t\t\t  GFP_KERNEL);\n\tif (!bp->rss_indir_tbl)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\nstatic void bnxt_set_dflt_rss_indir_tbl(struct bnxt *bp)\n{\n\tu16 max_rings, max_entries, pad, i;\n\n\tif (!bp->rx_nr_rings)\n\t\treturn;\n\n\tif (BNXT_CHIP_TYPE_NITRO_A0(bp))\n\t\tmax_rings = bp->rx_nr_rings - 1;\n\telse\n\t\tmax_rings = bp->rx_nr_rings;\n\n\tmax_entries = bnxt_get_rxfh_indir_size(bp->dev);\n\n\tfor (i = 0; i < max_entries; i++)\n\t\tbp->rss_indir_tbl[i] = ethtool_rxfh_indir_default(i, max_rings);\n\n\tpad = bp->rss_indir_tbl_entries - max_entries;\n\tif (pad)\n\t\tmemset(&bp->rss_indir_tbl[i], 0, pad * sizeof(u16));\n}\n\nstatic u16 bnxt_get_max_rss_ring(struct bnxt *bp)\n{\n\tu16 i, tbl_size, max_ring = 0;\n\n\tif (!bp->rss_indir_tbl)\n\t\treturn 0;\n\n\ttbl_size = bnxt_get_rxfh_indir_size(bp->dev);\n\tfor (i = 0; i < tbl_size; i++)\n\t\tmax_ring = max(max_ring, bp->rss_indir_tbl[i]);\n\treturn max_ring;\n}\n\nint bnxt_get_nr_rss_ctxs(struct bnxt *bp, int rx_rings)\n{\n\tif (bp->flags & BNXT_FLAG_CHIP_P5)\n\t\treturn DIV_ROUND_UP(rx_rings, BNXT_RSS_TABLE_ENTRIES_P5);\n\tif (BNXT_CHIP_TYPE_NITRO_A0(bp))\n\t\treturn 2;\n\treturn 1;\n}\n\nstatic void __bnxt_fill_hw_rss_tbl(struct bnxt *bp, struct bnxt_vnic_info *vnic)\n{\n\tbool no_rss = !(vnic->flags & BNXT_VNIC_RSS_FLAG);\n\tu16 i, j;\n\n\t/* Fill the RSS indirection table with ring group ids */\n\tfor (i = 0, j = 0; i < HW_HASH_INDEX_SIZE; i++) {\n\t\tif (!no_rss)\n\t\t\tj = bp->rss_indir_tbl[i];\n\t\tvnic->rss_table[i] = cpu_to_le16(vnic->fw_grp_ids[j]);\n\t}\n}\n\nstatic void __bnxt_fill_hw_rss_tbl_p5(struct bnxt *bp,\n\t\t\t\t      struct bnxt_vnic_info *vnic)\n{\n\t__le16 *ring_tbl = vnic->rss_table;\n\tstruct bnxt_rx_ring_info *rxr;\n\tu16 tbl_size, i;\n\n\ttbl_size = bnxt_get_rxfh_indir_size(bp->dev);\n\n\tfor (i = 0; i < tbl_size; i++) {\n\t\tu16 ring_id, j;\n\n\t\tj = bp->rss_indir_tbl[i];\n\t\trxr = &bp->rx_ring[j];\n\n\t\tring_id = rxr->rx_ring_struct.fw_ring_id;\n\t\t*ring_tbl++ = cpu_to_le16(ring_id);\n\t\tring_id = bnxt_cp_ring_for_rx(bp, rxr);\n\t\t*ring_tbl++ = cpu_to_le16(ring_id);\n\t}\n}\n\nstatic void bnxt_fill_hw_rss_tbl(struct bnxt *bp, struct bnxt_vnic_info *vnic)\n{\n\tif (bp->flags & BNXT_FLAG_CHIP_P5)\n\t\t__bnxt_fill_hw_rss_tbl_p5(bp, vnic);\n\telse\n\t\t__bnxt_fill_hw_rss_tbl(bp, vnic);\n}\n\nstatic int bnxt_hwrm_vnic_set_rss(struct bnxt *bp, u16 vnic_id, bool set_rss)\n{\n\tstruct bnxt_vnic_info *vnic = &bp->vnic_info[vnic_id];\n\tstruct hwrm_vnic_rss_cfg_input req = {0};\n\n\tif ((bp->flags & BNXT_FLAG_CHIP_P5) ||\n\t    vnic->fw_rss_cos_lb_ctx[0] == INVALID_HW_RING_ID)\n\t\treturn 0;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_VNIC_RSS_CFG, -1, -1);\n\tif (set_rss) {\n\t\tbnxt_fill_hw_rss_tbl(bp, vnic);\n\t\treq.hash_type = cpu_to_le32(bp->rss_hash_cfg);\n\t\treq.hash_mode_flags = VNIC_RSS_CFG_REQ_HASH_MODE_FLAGS_DEFAULT;\n\t\treq.ring_grp_tbl_addr = cpu_to_le64(vnic->rss_table_dma_addr);\n\t\treq.hash_key_tbl_addr =\n\t\t\tcpu_to_le64(vnic->rss_hash_key_dma_addr);\n\t}\n\treq.rss_ctx_idx = cpu_to_le16(vnic->fw_rss_cos_lb_ctx[0]);\n\treturn hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n}\n\nstatic int bnxt_hwrm_vnic_set_rss_p5(struct bnxt *bp, u16 vnic_id, bool set_rss)\n{\n\tstruct bnxt_vnic_info *vnic = &bp->vnic_info[vnic_id];\n\tstruct hwrm_vnic_rss_cfg_input req = {0};\n\tdma_addr_t ring_tbl_map;\n\tu32 i, nr_ctxs;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_VNIC_RSS_CFG, -1, -1);\n\treq.vnic_id = cpu_to_le16(vnic->fw_vnic_id);\n\tif (!set_rss) {\n\t\thwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\t\treturn 0;\n\t}\n\tbnxt_fill_hw_rss_tbl(bp, vnic);\n\treq.hash_type = cpu_to_le32(bp->rss_hash_cfg);\n\treq.hash_mode_flags = VNIC_RSS_CFG_REQ_HASH_MODE_FLAGS_DEFAULT;\n\treq.hash_key_tbl_addr = cpu_to_le64(vnic->rss_hash_key_dma_addr);\n\tring_tbl_map = vnic->rss_table_dma_addr;\n\tnr_ctxs = bnxt_get_nr_rss_ctxs(bp, bp->rx_nr_rings);\n\tfor (i = 0; i < nr_ctxs; ring_tbl_map += BNXT_RSS_TABLE_SIZE_P5, i++) {\n\t\tint rc;\n\n\t\treq.ring_grp_tbl_addr = cpu_to_le64(ring_tbl_map);\n\t\treq.ring_table_pair_index = i;\n\t\treq.rss_ctx_idx = cpu_to_le16(vnic->fw_rss_cos_lb_ctx[i]);\n\t\trc = hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\treturn 0;\n}\n\nstatic int bnxt_hwrm_vnic_set_hds(struct bnxt *bp, u16 vnic_id)\n{\n\tstruct bnxt_vnic_info *vnic = &bp->vnic_info[vnic_id];\n\tstruct hwrm_vnic_plcmodes_cfg_input req = {0};\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_VNIC_PLCMODES_CFG, -1, -1);\n\treq.flags = cpu_to_le32(VNIC_PLCMODES_CFG_REQ_FLAGS_JUMBO_PLACEMENT |\n\t\t\t\tVNIC_PLCMODES_CFG_REQ_FLAGS_HDS_IPV4 |\n\t\t\t\tVNIC_PLCMODES_CFG_REQ_FLAGS_HDS_IPV6);\n\treq.enables =\n\t\tcpu_to_le32(VNIC_PLCMODES_CFG_REQ_ENABLES_JUMBO_THRESH_VALID |\n\t\t\t    VNIC_PLCMODES_CFG_REQ_ENABLES_HDS_THRESHOLD_VALID);\n\t/* thresholds not implemented in firmware yet */\n\treq.jumbo_thresh = cpu_to_le16(bp->rx_copy_thresh);\n\treq.hds_threshold = cpu_to_le16(bp->rx_copy_thresh);\n\treq.vnic_id = cpu_to_le32(vnic->fw_vnic_id);\n\treturn hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n}\n\nstatic void bnxt_hwrm_vnic_ctx_free_one(struct bnxt *bp, u16 vnic_id,\n\t\t\t\t\tu16 ctx_idx)\n{\n\tstruct hwrm_vnic_rss_cos_lb_ctx_free_input req = {0};\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_VNIC_RSS_COS_LB_CTX_FREE, -1, -1);\n\treq.rss_cos_lb_ctx_id =\n\t\tcpu_to_le16(bp->vnic_info[vnic_id].fw_rss_cos_lb_ctx[ctx_idx]);\n\n\thwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tbp->vnic_info[vnic_id].fw_rss_cos_lb_ctx[ctx_idx] = INVALID_HW_RING_ID;\n}\n\nstatic void bnxt_hwrm_vnic_ctx_free(struct bnxt *bp)\n{\n\tint i, j;\n\n\tfor (i = 0; i < bp->nr_vnics; i++) {\n\t\tstruct bnxt_vnic_info *vnic = &bp->vnic_info[i];\n\n\t\tfor (j = 0; j < BNXT_MAX_CTX_PER_VNIC; j++) {\n\t\t\tif (vnic->fw_rss_cos_lb_ctx[j] != INVALID_HW_RING_ID)\n\t\t\t\tbnxt_hwrm_vnic_ctx_free_one(bp, i, j);\n\t\t}\n\t}\n\tbp->rsscos_nr_ctxs = 0;\n}\n\nstatic int bnxt_hwrm_vnic_ctx_alloc(struct bnxt *bp, u16 vnic_id, u16 ctx_idx)\n{\n\tint rc;\n\tstruct hwrm_vnic_rss_cos_lb_ctx_alloc_input req = {0};\n\tstruct hwrm_vnic_rss_cos_lb_ctx_alloc_output *resp =\n\t\t\t\t\t\tbp->hwrm_cmd_resp_addr;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_VNIC_RSS_COS_LB_CTX_ALLOC, -1,\n\t\t\t       -1);\n\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (!rc)\n\t\tbp->vnic_info[vnic_id].fw_rss_cos_lb_ctx[ctx_idx] =\n\t\t\tle16_to_cpu(resp->rss_cos_lb_ctx_id);\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\n\treturn rc;\n}\n\nstatic u32 bnxt_get_roce_vnic_mode(struct bnxt *bp)\n{\n\tif (bp->flags & BNXT_FLAG_ROCE_MIRROR_CAP)\n\t\treturn VNIC_CFG_REQ_FLAGS_ROCE_MIRRORING_CAPABLE_VNIC_MODE;\n\treturn VNIC_CFG_REQ_FLAGS_ROCE_DUAL_VNIC_MODE;\n}\n\nint bnxt_hwrm_vnic_cfg(struct bnxt *bp, u16 vnic_id)\n{\n\tunsigned int ring = 0, grp_idx;\n\tstruct bnxt_vnic_info *vnic = &bp->vnic_info[vnic_id];\n\tstruct hwrm_vnic_cfg_input req = {0};\n\tu16 def_vlan = 0;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_VNIC_CFG, -1, -1);\n\n\tif (bp->flags & BNXT_FLAG_CHIP_P5) {\n\t\tstruct bnxt_rx_ring_info *rxr = &bp->rx_ring[0];\n\n\t\treq.default_rx_ring_id =\n\t\t\tcpu_to_le16(rxr->rx_ring_struct.fw_ring_id);\n\t\treq.default_cmpl_ring_id =\n\t\t\tcpu_to_le16(bnxt_cp_ring_for_rx(bp, rxr));\n\t\treq.enables =\n\t\t\tcpu_to_le32(VNIC_CFG_REQ_ENABLES_DEFAULT_RX_RING_ID |\n\t\t\t\t    VNIC_CFG_REQ_ENABLES_DEFAULT_CMPL_RING_ID);\n\t\tgoto vnic_mru;\n\t}\n\treq.enables = cpu_to_le32(VNIC_CFG_REQ_ENABLES_DFLT_RING_GRP);\n\t/* Only RSS support for now TBD: COS & LB */\n\tif (vnic->fw_rss_cos_lb_ctx[0] != INVALID_HW_RING_ID) {\n\t\treq.rss_rule = cpu_to_le16(vnic->fw_rss_cos_lb_ctx[0]);\n\t\treq.enables |= cpu_to_le32(VNIC_CFG_REQ_ENABLES_RSS_RULE |\n\t\t\t\t\t   VNIC_CFG_REQ_ENABLES_MRU);\n\t} else if (vnic->flags & BNXT_VNIC_RFS_NEW_RSS_FLAG) {\n\t\treq.rss_rule =\n\t\t\tcpu_to_le16(bp->vnic_info[0].fw_rss_cos_lb_ctx[0]);\n\t\treq.enables |= cpu_to_le32(VNIC_CFG_REQ_ENABLES_RSS_RULE |\n\t\t\t\t\t   VNIC_CFG_REQ_ENABLES_MRU);\n\t\treq.flags |= cpu_to_le32(VNIC_CFG_REQ_FLAGS_RSS_DFLT_CR_MODE);\n\t} else {\n\t\treq.rss_rule = cpu_to_le16(0xffff);\n\t}\n\n\tif (BNXT_CHIP_TYPE_NITRO_A0(bp) &&\n\t    (vnic->fw_rss_cos_lb_ctx[0] != INVALID_HW_RING_ID)) {\n\t\treq.cos_rule = cpu_to_le16(vnic->fw_rss_cos_lb_ctx[1]);\n\t\treq.enables |= cpu_to_le32(VNIC_CFG_REQ_ENABLES_COS_RULE);\n\t} else {\n\t\treq.cos_rule = cpu_to_le16(0xffff);\n\t}\n\n\tif (vnic->flags & BNXT_VNIC_RSS_FLAG)\n\t\tring = 0;\n\telse if (vnic->flags & BNXT_VNIC_RFS_FLAG)\n\t\tring = vnic_id - 1;\n\telse if ((vnic_id == 1) && BNXT_CHIP_TYPE_NITRO_A0(bp))\n\t\tring = bp->rx_nr_rings - 1;\n\n\tgrp_idx = bp->rx_ring[ring].bnapi->index;\n\treq.dflt_ring_grp = cpu_to_le16(bp->grp_info[grp_idx].fw_grp_id);\n\treq.lb_rule = cpu_to_le16(0xffff);\nvnic_mru:\n\treq.mru = cpu_to_le16(bp->dev->mtu + ETH_HLEN + VLAN_HLEN);\n\n\treq.vnic_id = cpu_to_le16(vnic->fw_vnic_id);\n#ifdef CONFIG_BNXT_SRIOV\n\tif (BNXT_VF(bp))\n\t\tdef_vlan = bp->vf.vlan;\n#endif\n\tif ((bp->flags & BNXT_FLAG_STRIP_VLAN) || def_vlan)\n\t\treq.flags |= cpu_to_le32(VNIC_CFG_REQ_FLAGS_VLAN_STRIP_MODE);\n\tif (!vnic_id && bnxt_ulp_registered(bp->edev, BNXT_ROCE_ULP))\n\t\treq.flags |= cpu_to_le32(bnxt_get_roce_vnic_mode(bp));\n\n\treturn hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n}\n\nstatic void bnxt_hwrm_vnic_free_one(struct bnxt *bp, u16 vnic_id)\n{\n\tif (bp->vnic_info[vnic_id].fw_vnic_id != INVALID_HW_RING_ID) {\n\t\tstruct hwrm_vnic_free_input req = {0};\n\n\t\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_VNIC_FREE, -1, -1);\n\t\treq.vnic_id =\n\t\t\tcpu_to_le32(bp->vnic_info[vnic_id].fw_vnic_id);\n\n\t\thwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\t\tbp->vnic_info[vnic_id].fw_vnic_id = INVALID_HW_RING_ID;\n\t}\n}\n\nstatic void bnxt_hwrm_vnic_free(struct bnxt *bp)\n{\n\tu16 i;\n\n\tfor (i = 0; i < bp->nr_vnics; i++)\n\t\tbnxt_hwrm_vnic_free_one(bp, i);\n}\n\nstatic int bnxt_hwrm_vnic_alloc(struct bnxt *bp, u16 vnic_id,\n\t\t\t\tunsigned int start_rx_ring_idx,\n\t\t\t\tunsigned int nr_rings)\n{\n\tint rc = 0;\n\tunsigned int i, j, grp_idx, end_idx = start_rx_ring_idx + nr_rings;\n\tstruct hwrm_vnic_alloc_input req = {0};\n\tstruct hwrm_vnic_alloc_output *resp = bp->hwrm_cmd_resp_addr;\n\tstruct bnxt_vnic_info *vnic = &bp->vnic_info[vnic_id];\n\n\tif (bp->flags & BNXT_FLAG_CHIP_P5)\n\t\tgoto vnic_no_ring_grps;\n\n\t/* map ring groups to this vnic */\n\tfor (i = start_rx_ring_idx, j = 0; i < end_idx; i++, j++) {\n\t\tgrp_idx = bp->rx_ring[i].bnapi->index;\n\t\tif (bp->grp_info[grp_idx].fw_grp_id == INVALID_HW_RING_ID) {\n\t\t\tnetdev_err(bp->dev, \"Not enough ring groups avail:%x req:%x\\n\",\n\t\t\t\t   j, nr_rings);\n\t\t\tbreak;\n\t\t}\n\t\tvnic->fw_grp_ids[j] = bp->grp_info[grp_idx].fw_grp_id;\n\t}\n\nvnic_no_ring_grps:\n\tfor (i = 0; i < BNXT_MAX_CTX_PER_VNIC; i++)\n\t\tvnic->fw_rss_cos_lb_ctx[i] = INVALID_HW_RING_ID;\n\tif (vnic_id == 0)\n\t\treq.flags = cpu_to_le32(VNIC_ALLOC_REQ_FLAGS_DEFAULT);\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_VNIC_ALLOC, -1, -1);\n\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (!rc)\n\t\tvnic->fw_vnic_id = le32_to_cpu(resp->vnic_id);\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\treturn rc;\n}\n\nstatic int bnxt_hwrm_vnic_qcaps(struct bnxt *bp)\n{\n\tstruct hwrm_vnic_qcaps_output *resp = bp->hwrm_cmd_resp_addr;\n\tstruct hwrm_vnic_qcaps_input req = {0};\n\tint rc;\n\n\tbp->hw_ring_stats_size = sizeof(struct ctx_hw_stats);\n\tbp->flags &= ~(BNXT_FLAG_NEW_RSS_CAP | BNXT_FLAG_ROCE_MIRROR_CAP);\n\tif (bp->hwrm_spec_code < 0x10600)\n\t\treturn 0;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_VNIC_QCAPS, -1, -1);\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (!rc) {\n\t\tu32 flags = le32_to_cpu(resp->flags);\n\n\t\tif (!(bp->flags & BNXT_FLAG_CHIP_P5) &&\n\t\t    (flags & VNIC_QCAPS_RESP_FLAGS_RSS_DFLT_CR_CAP))\n\t\t\tbp->flags |= BNXT_FLAG_NEW_RSS_CAP;\n\t\tif (flags &\n\t\t    VNIC_QCAPS_RESP_FLAGS_ROCE_MIRRORING_CAPABLE_VNIC_CAP)\n\t\t\tbp->flags |= BNXT_FLAG_ROCE_MIRROR_CAP;\n\n\t\t/* Older P5 fw before EXT_HW_STATS support did not set\n\t\t * VLAN_STRIP_CAP properly.\n\t\t */\n\t\tif ((flags & VNIC_QCAPS_RESP_FLAGS_VLAN_STRIP_CAP) ||\n\t\t    (BNXT_CHIP_P5_THOR(bp) &&\n\t\t     !(bp->fw_cap & BNXT_FW_CAP_EXT_HW_STATS_SUPPORTED)))\n\t\t\tbp->fw_cap |= BNXT_FW_CAP_VLAN_RX_STRIP;\n\t\tbp->max_tpa_v2 = le16_to_cpu(resp->max_aggs_supported);\n\t\tif (bp->max_tpa_v2) {\n\t\t\tif (BNXT_CHIP_P5_THOR(bp))\n\t\t\t\tbp->hw_ring_stats_size = BNXT_RING_STATS_SIZE_P5;\n\t\t\telse\n\t\t\t\tbp->hw_ring_stats_size = BNXT_RING_STATS_SIZE_P5_SR2;\n\t\t}\n\t}\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\treturn rc;\n}\n\nstatic int bnxt_hwrm_ring_grp_alloc(struct bnxt *bp)\n{\n\tu16 i;\n\tu32 rc = 0;\n\n\tif (bp->flags & BNXT_FLAG_CHIP_P5)\n\t\treturn 0;\n\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\tfor (i = 0; i < bp->rx_nr_rings; i++) {\n\t\tstruct hwrm_ring_grp_alloc_input req = {0};\n\t\tstruct hwrm_ring_grp_alloc_output *resp =\n\t\t\t\t\tbp->hwrm_cmd_resp_addr;\n\t\tunsigned int grp_idx = bp->rx_ring[i].bnapi->index;\n\n\t\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_RING_GRP_ALLOC, -1, -1);\n\n\t\treq.cr = cpu_to_le16(bp->grp_info[grp_idx].cp_fw_ring_id);\n\t\treq.rr = cpu_to_le16(bp->grp_info[grp_idx].rx_fw_ring_id);\n\t\treq.ar = cpu_to_le16(bp->grp_info[grp_idx].agg_fw_ring_id);\n\t\treq.sc = cpu_to_le16(bp->grp_info[grp_idx].fw_stats_ctx);\n\n\t\trc = _hwrm_send_message(bp, &req, sizeof(req),\n\t\t\t\t\tHWRM_CMD_TIMEOUT);\n\t\tif (rc)\n\t\t\tbreak;\n\n\t\tbp->grp_info[grp_idx].fw_grp_id =\n\t\t\tle32_to_cpu(resp->ring_group_id);\n\t}\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\treturn rc;\n}\n\nstatic void bnxt_hwrm_ring_grp_free(struct bnxt *bp)\n{\n\tu16 i;\n\tstruct hwrm_ring_grp_free_input req = {0};\n\n\tif (!bp->grp_info || (bp->flags & BNXT_FLAG_CHIP_P5))\n\t\treturn;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_RING_GRP_FREE, -1, -1);\n\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\tfor (i = 0; i < bp->cp_nr_rings; i++) {\n\t\tif (bp->grp_info[i].fw_grp_id == INVALID_HW_RING_ID)\n\t\t\tcontinue;\n\t\treq.ring_group_id =\n\t\t\tcpu_to_le32(bp->grp_info[i].fw_grp_id);\n\n\t\t_hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\t\tbp->grp_info[i].fw_grp_id = INVALID_HW_RING_ID;\n\t}\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n}\n\nstatic int hwrm_ring_alloc_send_msg(struct bnxt *bp,\n\t\t\t\t    struct bnxt_ring_struct *ring,\n\t\t\t\t    u32 ring_type, u32 map_index)\n{\n\tint rc = 0, err = 0;\n\tstruct hwrm_ring_alloc_input req = {0};\n\tstruct hwrm_ring_alloc_output *resp = bp->hwrm_cmd_resp_addr;\n\tstruct bnxt_ring_mem_info *rmem = &ring->ring_mem;\n\tstruct bnxt_ring_grp_info *grp_info;\n\tu16 ring_id;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_RING_ALLOC, -1, -1);\n\n\treq.enables = 0;\n\tif (rmem->nr_pages > 1) {\n\t\treq.page_tbl_addr = cpu_to_le64(rmem->pg_tbl_map);\n\t\t/* Page size is in log2 units */\n\t\treq.page_size = BNXT_PAGE_SHIFT;\n\t\treq.page_tbl_depth = 1;\n\t} else {\n\t\treq.page_tbl_addr =  cpu_to_le64(rmem->dma_arr[0]);\n\t}\n\treq.fbo = 0;\n\t/* Association of ring index with doorbell index and MSIX number */\n\treq.logical_id = cpu_to_le16(map_index);\n\n\tswitch (ring_type) {\n\tcase HWRM_RING_ALLOC_TX: {\n\t\tstruct bnxt_tx_ring_info *txr;\n\n\t\ttxr = container_of(ring, struct bnxt_tx_ring_info,\n\t\t\t\t   tx_ring_struct);\n\t\treq.ring_type = RING_ALLOC_REQ_RING_TYPE_TX;\n\t\t/* Association of transmit ring with completion ring */\n\t\tgrp_info = &bp->grp_info[ring->grp_idx];\n\t\treq.cmpl_ring_id = cpu_to_le16(bnxt_cp_ring_for_tx(bp, txr));\n\t\treq.length = cpu_to_le32(bp->tx_ring_mask + 1);\n\t\treq.stat_ctx_id = cpu_to_le32(grp_info->fw_stats_ctx);\n\t\treq.queue_id = cpu_to_le16(ring->queue_id);\n\t\tbreak;\n\t}\n\tcase HWRM_RING_ALLOC_RX:\n\t\treq.ring_type = RING_ALLOC_REQ_RING_TYPE_RX;\n\t\treq.length = cpu_to_le32(bp->rx_ring_mask + 1);\n\t\tif (bp->flags & BNXT_FLAG_CHIP_P5) {\n\t\t\tu16 flags = 0;\n\n\t\t\t/* Association of rx ring with stats context */\n\t\t\tgrp_info = &bp->grp_info[ring->grp_idx];\n\t\t\treq.rx_buf_size = cpu_to_le16(bp->rx_buf_use_size);\n\t\t\treq.stat_ctx_id = cpu_to_le32(grp_info->fw_stats_ctx);\n\t\t\treq.enables |= cpu_to_le32(\n\t\t\t\tRING_ALLOC_REQ_ENABLES_RX_BUF_SIZE_VALID);\n\t\t\tif (NET_IP_ALIGN == 2)\n\t\t\t\tflags = RING_ALLOC_REQ_FLAGS_RX_SOP_PAD;\n\t\t\treq.flags = cpu_to_le16(flags);\n\t\t}\n\t\tbreak;\n\tcase HWRM_RING_ALLOC_AGG:\n\t\tif (bp->flags & BNXT_FLAG_CHIP_P5) {\n\t\t\treq.ring_type = RING_ALLOC_REQ_RING_TYPE_RX_AGG;\n\t\t\t/* Association of agg ring with rx ring */\n\t\t\tgrp_info = &bp->grp_info[ring->grp_idx];\n\t\t\treq.rx_ring_id = cpu_to_le16(grp_info->rx_fw_ring_id);\n\t\t\treq.rx_buf_size = cpu_to_le16(BNXT_RX_PAGE_SIZE);\n\t\t\treq.stat_ctx_id = cpu_to_le32(grp_info->fw_stats_ctx);\n\t\t\treq.enables |= cpu_to_le32(\n\t\t\t\tRING_ALLOC_REQ_ENABLES_RX_RING_ID_VALID |\n\t\t\t\tRING_ALLOC_REQ_ENABLES_RX_BUF_SIZE_VALID);\n\t\t} else {\n\t\t\treq.ring_type = RING_ALLOC_REQ_RING_TYPE_RX;\n\t\t}\n\t\treq.length = cpu_to_le32(bp->rx_agg_ring_mask + 1);\n\t\tbreak;\n\tcase HWRM_RING_ALLOC_CMPL:\n\t\treq.ring_type = RING_ALLOC_REQ_RING_TYPE_L2_CMPL;\n\t\treq.length = cpu_to_le32(bp->cp_ring_mask + 1);\n\t\tif (bp->flags & BNXT_FLAG_CHIP_P5) {\n\t\t\t/* Association of cp ring with nq */\n\t\t\tgrp_info = &bp->grp_info[map_index];\n\t\t\treq.nq_ring_id = cpu_to_le16(grp_info->cp_fw_ring_id);\n\t\t\treq.cq_handle = cpu_to_le64(ring->handle);\n\t\t\treq.enables |= cpu_to_le32(\n\t\t\t\tRING_ALLOC_REQ_ENABLES_NQ_RING_ID_VALID);\n\t\t} else if (bp->flags & BNXT_FLAG_USING_MSIX) {\n\t\t\treq.int_mode = RING_ALLOC_REQ_INT_MODE_MSIX;\n\t\t}\n\t\tbreak;\n\tcase HWRM_RING_ALLOC_NQ:\n\t\treq.ring_type = RING_ALLOC_REQ_RING_TYPE_NQ;\n\t\treq.length = cpu_to_le32(bp->cp_ring_mask + 1);\n\t\tif (bp->flags & BNXT_FLAG_USING_MSIX)\n\t\t\treq.int_mode = RING_ALLOC_REQ_INT_MODE_MSIX;\n\t\tbreak;\n\tdefault:\n\t\tnetdev_err(bp->dev, \"hwrm alloc invalid ring type %d\\n\",\n\t\t\t   ring_type);\n\t\treturn -1;\n\t}\n\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\terr = le16_to_cpu(resp->error_code);\n\tring_id = le16_to_cpu(resp->ring_id);\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\n\tif (rc || err) {\n\t\tnetdev_err(bp->dev, \"hwrm_ring_alloc type %d failed. rc:%x err:%x\\n\",\n\t\t\t   ring_type, rc, err);\n\t\treturn -EIO;\n\t}\n\tring->fw_ring_id = ring_id;\n\treturn rc;\n}\n\nstatic int bnxt_hwrm_set_async_event_cr(struct bnxt *bp, int idx)\n{\n\tint rc;\n\n\tif (BNXT_PF(bp)) {\n\t\tstruct hwrm_func_cfg_input req = {0};\n\n\t\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_FUNC_CFG, -1, -1);\n\t\treq.fid = cpu_to_le16(0xffff);\n\t\treq.enables = cpu_to_le32(FUNC_CFG_REQ_ENABLES_ASYNC_EVENT_CR);\n\t\treq.async_event_cr = cpu_to_le16(idx);\n\t\trc = hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\t} else {\n\t\tstruct hwrm_func_vf_cfg_input req = {0};\n\n\t\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_FUNC_VF_CFG, -1, -1);\n\t\treq.enables =\n\t\t\tcpu_to_le32(FUNC_VF_CFG_REQ_ENABLES_ASYNC_EVENT_CR);\n\t\treq.async_event_cr = cpu_to_le16(idx);\n\t\trc = hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\t}\n\treturn rc;\n}\n\nstatic void bnxt_set_db(struct bnxt *bp, struct bnxt_db_info *db, u32 ring_type,\n\t\t\tu32 map_idx, u32 xid)\n{\n\tif (bp->flags & BNXT_FLAG_CHIP_P5) {\n\t\tif (BNXT_PF(bp))\n\t\t\tdb->doorbell = bp->bar1 + DB_PF_OFFSET_P5;\n\t\telse\n\t\t\tdb->doorbell = bp->bar1 + DB_VF_OFFSET_P5;\n\t\tswitch (ring_type) {\n\t\tcase HWRM_RING_ALLOC_TX:\n\t\t\tdb->db_key64 = DBR_PATH_L2 | DBR_TYPE_SQ;\n\t\t\tbreak;\n\t\tcase HWRM_RING_ALLOC_RX:\n\t\tcase HWRM_RING_ALLOC_AGG:\n\t\t\tdb->db_key64 = DBR_PATH_L2 | DBR_TYPE_SRQ;\n\t\t\tbreak;\n\t\tcase HWRM_RING_ALLOC_CMPL:\n\t\t\tdb->db_key64 = DBR_PATH_L2;\n\t\t\tbreak;\n\t\tcase HWRM_RING_ALLOC_NQ:\n\t\t\tdb->db_key64 = DBR_PATH_L2;\n\t\t\tbreak;\n\t\t}\n\t\tdb->db_key64 |= (u64)xid << DBR_XID_SFT;\n\t} else {\n\t\tdb->doorbell = bp->bar1 + map_idx * 0x80;\n\t\tswitch (ring_type) {\n\t\tcase HWRM_RING_ALLOC_TX:\n\t\t\tdb->db_key32 = DB_KEY_TX;\n\t\t\tbreak;\n\t\tcase HWRM_RING_ALLOC_RX:\n\t\tcase HWRM_RING_ALLOC_AGG:\n\t\t\tdb->db_key32 = DB_KEY_RX;\n\t\t\tbreak;\n\t\tcase HWRM_RING_ALLOC_CMPL:\n\t\t\tdb->db_key32 = DB_KEY_CP;\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nstatic int bnxt_hwrm_ring_alloc(struct bnxt *bp)\n{\n\tbool agg_rings = !!(bp->flags & BNXT_FLAG_AGG_RINGS);\n\tint i, rc = 0;\n\tu32 type;\n\n\tif (bp->flags & BNXT_FLAG_CHIP_P5)\n\t\ttype = HWRM_RING_ALLOC_NQ;\n\telse\n\t\ttype = HWRM_RING_ALLOC_CMPL;\n\tfor (i = 0; i < bp->cp_nr_rings; i++) {\n\t\tstruct bnxt_napi *bnapi = bp->bnapi[i];\n\t\tstruct bnxt_cp_ring_info *cpr = &bnapi->cp_ring;\n\t\tstruct bnxt_ring_struct *ring = &cpr->cp_ring_struct;\n\t\tu32 map_idx = ring->map_idx;\n\t\tunsigned int vector;\n\n\t\tvector = bp->irq_tbl[map_idx].vector;\n\t\tdisable_irq_nosync(vector);\n\t\trc = hwrm_ring_alloc_send_msg(bp, ring, type, map_idx);\n\t\tif (rc) {\n\t\t\tenable_irq(vector);\n\t\t\tgoto err_out;\n\t\t}\n\t\tbnxt_set_db(bp, &cpr->cp_db, type, map_idx, ring->fw_ring_id);\n\t\tbnxt_db_nq(bp, &cpr->cp_db, cpr->cp_raw_cons);\n\t\tenable_irq(vector);\n\t\tbp->grp_info[i].cp_fw_ring_id = ring->fw_ring_id;\n\n\t\tif (!i) {\n\t\t\trc = bnxt_hwrm_set_async_event_cr(bp, ring->fw_ring_id);\n\t\t\tif (rc)\n\t\t\t\tnetdev_warn(bp->dev, \"Failed to set async event completion ring.\\n\");\n\t\t}\n\t}\n\n\ttype = HWRM_RING_ALLOC_TX;\n\tfor (i = 0; i < bp->tx_nr_rings; i++) {\n\t\tstruct bnxt_tx_ring_info *txr = &bp->tx_ring[i];\n\t\tstruct bnxt_ring_struct *ring;\n\t\tu32 map_idx;\n\n\t\tif (bp->flags & BNXT_FLAG_CHIP_P5) {\n\t\t\tstruct bnxt_napi *bnapi = txr->bnapi;\n\t\t\tstruct bnxt_cp_ring_info *cpr, *cpr2;\n\t\t\tu32 type2 = HWRM_RING_ALLOC_CMPL;\n\n\t\t\tcpr = &bnapi->cp_ring;\n\t\t\tcpr2 = cpr->cp_ring_arr[BNXT_TX_HDL];\n\t\t\tring = &cpr2->cp_ring_struct;\n\t\t\tring->handle = BNXT_TX_HDL;\n\t\t\tmap_idx = bnapi->index;\n\t\t\trc = hwrm_ring_alloc_send_msg(bp, ring, type2, map_idx);\n\t\t\tif (rc)\n\t\t\t\tgoto err_out;\n\t\t\tbnxt_set_db(bp, &cpr2->cp_db, type2, map_idx,\n\t\t\t\t    ring->fw_ring_id);\n\t\t\tbnxt_db_cq(bp, &cpr2->cp_db, cpr2->cp_raw_cons);\n\t\t}\n\t\tring = &txr->tx_ring_struct;\n\t\tmap_idx = i;\n\t\trc = hwrm_ring_alloc_send_msg(bp, ring, type, map_idx);\n\t\tif (rc)\n\t\t\tgoto err_out;\n\t\tbnxt_set_db(bp, &txr->tx_db, type, map_idx, ring->fw_ring_id);\n\t}\n\n\ttype = HWRM_RING_ALLOC_RX;\n\tfor (i = 0; i < bp->rx_nr_rings; i++) {\n\t\tstruct bnxt_rx_ring_info *rxr = &bp->rx_ring[i];\n\t\tstruct bnxt_ring_struct *ring = &rxr->rx_ring_struct;\n\t\tstruct bnxt_napi *bnapi = rxr->bnapi;\n\t\tu32 map_idx = bnapi->index;\n\n\t\trc = hwrm_ring_alloc_send_msg(bp, ring, type, map_idx);\n\t\tif (rc)\n\t\t\tgoto err_out;\n\t\tbnxt_set_db(bp, &rxr->rx_db, type, map_idx, ring->fw_ring_id);\n\t\t/* If we have agg rings, post agg buffers first. */\n\t\tif (!agg_rings)\n\t\t\tbnxt_db_write(bp, &rxr->rx_db, rxr->rx_prod);\n\t\tbp->grp_info[map_idx].rx_fw_ring_id = ring->fw_ring_id;\n\t\tif (bp->flags & BNXT_FLAG_CHIP_P5) {\n\t\t\tstruct bnxt_cp_ring_info *cpr = &bnapi->cp_ring;\n\t\t\tu32 type2 = HWRM_RING_ALLOC_CMPL;\n\t\t\tstruct bnxt_cp_ring_info *cpr2;\n\n\t\t\tcpr2 = cpr->cp_ring_arr[BNXT_RX_HDL];\n\t\t\tring = &cpr2->cp_ring_struct;\n\t\t\tring->handle = BNXT_RX_HDL;\n\t\t\trc = hwrm_ring_alloc_send_msg(bp, ring, type2, map_idx);\n\t\t\tif (rc)\n\t\t\t\tgoto err_out;\n\t\t\tbnxt_set_db(bp, &cpr2->cp_db, type2, map_idx,\n\t\t\t\t    ring->fw_ring_id);\n\t\t\tbnxt_db_cq(bp, &cpr2->cp_db, cpr2->cp_raw_cons);\n\t\t}\n\t}\n\n\tif (agg_rings) {\n\t\ttype = HWRM_RING_ALLOC_AGG;\n\t\tfor (i = 0; i < bp->rx_nr_rings; i++) {\n\t\t\tstruct bnxt_rx_ring_info *rxr = &bp->rx_ring[i];\n\t\t\tstruct bnxt_ring_struct *ring =\n\t\t\t\t\t\t&rxr->rx_agg_ring_struct;\n\t\t\tu32 grp_idx = ring->grp_idx;\n\t\t\tu32 map_idx = grp_idx + bp->rx_nr_rings;\n\n\t\t\trc = hwrm_ring_alloc_send_msg(bp, ring, type, map_idx);\n\t\t\tif (rc)\n\t\t\t\tgoto err_out;\n\n\t\t\tbnxt_set_db(bp, &rxr->rx_agg_db, type, map_idx,\n\t\t\t\t    ring->fw_ring_id);\n\t\t\tbnxt_db_write(bp, &rxr->rx_agg_db, rxr->rx_agg_prod);\n\t\t\tbnxt_db_write(bp, &rxr->rx_db, rxr->rx_prod);\n\t\t\tbp->grp_info[grp_idx].agg_fw_ring_id = ring->fw_ring_id;\n\t\t}\n\t}\nerr_out:\n\treturn rc;\n}\n\nstatic int hwrm_ring_free_send_msg(struct bnxt *bp,\n\t\t\t\t   struct bnxt_ring_struct *ring,\n\t\t\t\t   u32 ring_type, int cmpl_ring_id)\n{\n\tint rc;\n\tstruct hwrm_ring_free_input req = {0};\n\tstruct hwrm_ring_free_output *resp = bp->hwrm_cmd_resp_addr;\n\tu16 error_code;\n\n\tif (BNXT_NO_FW_ACCESS(bp))\n\t\treturn 0;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_RING_FREE, cmpl_ring_id, -1);\n\treq.ring_type = ring_type;\n\treq.ring_id = cpu_to_le16(ring->fw_ring_id);\n\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\terror_code = le16_to_cpu(resp->error_code);\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\n\tif (rc || error_code) {\n\t\tnetdev_err(bp->dev, \"hwrm_ring_free type %d failed. rc:%x err:%x\\n\",\n\t\t\t   ring_type, rc, error_code);\n\t\treturn -EIO;\n\t}\n\treturn 0;\n}\n\nstatic void bnxt_hwrm_ring_free(struct bnxt *bp, bool close_path)\n{\n\tu32 type;\n\tint i;\n\n\tif (!bp->bnapi)\n\t\treturn;\n\n\tfor (i = 0; i < bp->tx_nr_rings; i++) {\n\t\tstruct bnxt_tx_ring_info *txr = &bp->tx_ring[i];\n\t\tstruct bnxt_ring_struct *ring = &txr->tx_ring_struct;\n\n\t\tif (ring->fw_ring_id != INVALID_HW_RING_ID) {\n\t\t\tu32 cmpl_ring_id = bnxt_cp_ring_for_tx(bp, txr);\n\n\t\t\thwrm_ring_free_send_msg(bp, ring,\n\t\t\t\t\t\tRING_FREE_REQ_RING_TYPE_TX,\n\t\t\t\t\t\tclose_path ? cmpl_ring_id :\n\t\t\t\t\t\tINVALID_HW_RING_ID);\n\t\t\tring->fw_ring_id = INVALID_HW_RING_ID;\n\t\t}\n\t}\n\n\tfor (i = 0; i < bp->rx_nr_rings; i++) {\n\t\tstruct bnxt_rx_ring_info *rxr = &bp->rx_ring[i];\n\t\tstruct bnxt_ring_struct *ring = &rxr->rx_ring_struct;\n\t\tu32 grp_idx = rxr->bnapi->index;\n\n\t\tif (ring->fw_ring_id != INVALID_HW_RING_ID) {\n\t\t\tu32 cmpl_ring_id = bnxt_cp_ring_for_rx(bp, rxr);\n\n\t\t\thwrm_ring_free_send_msg(bp, ring,\n\t\t\t\t\t\tRING_FREE_REQ_RING_TYPE_RX,\n\t\t\t\t\t\tclose_path ? cmpl_ring_id :\n\t\t\t\t\t\tINVALID_HW_RING_ID);\n\t\t\tring->fw_ring_id = INVALID_HW_RING_ID;\n\t\t\tbp->grp_info[grp_idx].rx_fw_ring_id =\n\t\t\t\tINVALID_HW_RING_ID;\n\t\t}\n\t}\n\n\tif (bp->flags & BNXT_FLAG_CHIP_P5)\n\t\ttype = RING_FREE_REQ_RING_TYPE_RX_AGG;\n\telse\n\t\ttype = RING_FREE_REQ_RING_TYPE_RX;\n\tfor (i = 0; i < bp->rx_nr_rings; i++) {\n\t\tstruct bnxt_rx_ring_info *rxr = &bp->rx_ring[i];\n\t\tstruct bnxt_ring_struct *ring = &rxr->rx_agg_ring_struct;\n\t\tu32 grp_idx = rxr->bnapi->index;\n\n\t\tif (ring->fw_ring_id != INVALID_HW_RING_ID) {\n\t\t\tu32 cmpl_ring_id = bnxt_cp_ring_for_rx(bp, rxr);\n\n\t\t\thwrm_ring_free_send_msg(bp, ring, type,\n\t\t\t\t\t\tclose_path ? cmpl_ring_id :\n\t\t\t\t\t\tINVALID_HW_RING_ID);\n\t\t\tring->fw_ring_id = INVALID_HW_RING_ID;\n\t\t\tbp->grp_info[grp_idx].agg_fw_ring_id =\n\t\t\t\tINVALID_HW_RING_ID;\n\t\t}\n\t}\n\n\t/* The completion rings are about to be freed.  After that the\n\t * IRQ doorbell will not work anymore.  So we need to disable\n\t * IRQ here.\n\t */\n\tbnxt_disable_int_sync(bp);\n\n\tif (bp->flags & BNXT_FLAG_CHIP_P5)\n\t\ttype = RING_FREE_REQ_RING_TYPE_NQ;\n\telse\n\t\ttype = RING_FREE_REQ_RING_TYPE_L2_CMPL;\n\tfor (i = 0; i < bp->cp_nr_rings; i++) {\n\t\tstruct bnxt_napi *bnapi = bp->bnapi[i];\n\t\tstruct bnxt_cp_ring_info *cpr = &bnapi->cp_ring;\n\t\tstruct bnxt_ring_struct *ring;\n\t\tint j;\n\n\t\tfor (j = 0; j < 2; j++) {\n\t\t\tstruct bnxt_cp_ring_info *cpr2 = cpr->cp_ring_arr[j];\n\n\t\t\tif (cpr2) {\n\t\t\t\tring = &cpr2->cp_ring_struct;\n\t\t\t\tif (ring->fw_ring_id == INVALID_HW_RING_ID)\n\t\t\t\t\tcontinue;\n\t\t\t\thwrm_ring_free_send_msg(bp, ring,\n\t\t\t\t\tRING_FREE_REQ_RING_TYPE_L2_CMPL,\n\t\t\t\t\tINVALID_HW_RING_ID);\n\t\t\t\tring->fw_ring_id = INVALID_HW_RING_ID;\n\t\t\t}\n\t\t}\n\t\tring = &cpr->cp_ring_struct;\n\t\tif (ring->fw_ring_id != INVALID_HW_RING_ID) {\n\t\t\thwrm_ring_free_send_msg(bp, ring, type,\n\t\t\t\t\t\tINVALID_HW_RING_ID);\n\t\t\tring->fw_ring_id = INVALID_HW_RING_ID;\n\t\t\tbp->grp_info[i].cp_fw_ring_id = INVALID_HW_RING_ID;\n\t\t}\n\t}\n}\n\nstatic int bnxt_trim_rings(struct bnxt *bp, int *rx, int *tx, int max,\n\t\t\t   bool shared);\n\nstatic int bnxt_hwrm_get_rings(struct bnxt *bp)\n{\n\tstruct hwrm_func_qcfg_output *resp = bp->hwrm_cmd_resp_addr;\n\tstruct bnxt_hw_resc *hw_resc = &bp->hw_resc;\n\tstruct hwrm_func_qcfg_input req = {0};\n\tint rc;\n\n\tif (bp->hwrm_spec_code < 0x10601)\n\t\treturn 0;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_FUNC_QCFG, -1, -1);\n\treq.fid = cpu_to_le16(0xffff);\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (rc) {\n\t\tmutex_unlock(&bp->hwrm_cmd_lock);\n\t\treturn rc;\n\t}\n\n\thw_resc->resv_tx_rings = le16_to_cpu(resp->alloc_tx_rings);\n\tif (BNXT_NEW_RM(bp)) {\n\t\tu16 cp, stats;\n\n\t\thw_resc->resv_rx_rings = le16_to_cpu(resp->alloc_rx_rings);\n\t\thw_resc->resv_hw_ring_grps =\n\t\t\tle32_to_cpu(resp->alloc_hw_ring_grps);\n\t\thw_resc->resv_vnics = le16_to_cpu(resp->alloc_vnics);\n\t\tcp = le16_to_cpu(resp->alloc_cmpl_rings);\n\t\tstats = le16_to_cpu(resp->alloc_stat_ctx);\n\t\thw_resc->resv_irqs = cp;\n\t\tif (bp->flags & BNXT_FLAG_CHIP_P5) {\n\t\t\tint rx = hw_resc->resv_rx_rings;\n\t\t\tint tx = hw_resc->resv_tx_rings;\n\n\t\t\tif (bp->flags & BNXT_FLAG_AGG_RINGS)\n\t\t\t\trx >>= 1;\n\t\t\tif (cp < (rx + tx)) {\n\t\t\t\tbnxt_trim_rings(bp, &rx, &tx, cp, false);\n\t\t\t\tif (bp->flags & BNXT_FLAG_AGG_RINGS)\n\t\t\t\t\trx <<= 1;\n\t\t\t\thw_resc->resv_rx_rings = rx;\n\t\t\t\thw_resc->resv_tx_rings = tx;\n\t\t\t}\n\t\t\thw_resc->resv_irqs = le16_to_cpu(resp->alloc_msix);\n\t\t\thw_resc->resv_hw_ring_grps = rx;\n\t\t}\n\t\thw_resc->resv_cp_rings = cp;\n\t\thw_resc->resv_stat_ctxs = stats;\n\t}\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\treturn 0;\n}\n\n/* Caller must hold bp->hwrm_cmd_lock */\nint __bnxt_hwrm_get_tx_rings(struct bnxt *bp, u16 fid, int *tx_rings)\n{\n\tstruct hwrm_func_qcfg_output *resp = bp->hwrm_cmd_resp_addr;\n\tstruct hwrm_func_qcfg_input req = {0};\n\tint rc;\n\n\tif (bp->hwrm_spec_code < 0x10601)\n\t\treturn 0;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_FUNC_QCFG, -1, -1);\n\treq.fid = cpu_to_le16(fid);\n\trc = _hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (!rc)\n\t\t*tx_rings = le16_to_cpu(resp->alloc_tx_rings);\n\n\treturn rc;\n}\n\nstatic bool bnxt_rfs_supported(struct bnxt *bp);\n\nstatic void\n__bnxt_hwrm_reserve_pf_rings(struct bnxt *bp, struct hwrm_func_cfg_input *req,\n\t\t\t     int tx_rings, int rx_rings, int ring_grps,\n\t\t\t     int cp_rings, int stats, int vnics)\n{\n\tu32 enables = 0;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, req, HWRM_FUNC_CFG, -1, -1);\n\treq->fid = cpu_to_le16(0xffff);\n\tenables |= tx_rings ? FUNC_CFG_REQ_ENABLES_NUM_TX_RINGS : 0;\n\treq->num_tx_rings = cpu_to_le16(tx_rings);\n\tif (BNXT_NEW_RM(bp)) {\n\t\tenables |= rx_rings ? FUNC_CFG_REQ_ENABLES_NUM_RX_RINGS : 0;\n\t\tenables |= stats ? FUNC_CFG_REQ_ENABLES_NUM_STAT_CTXS : 0;\n\t\tif (bp->flags & BNXT_FLAG_CHIP_P5) {\n\t\t\tenables |= cp_rings ? FUNC_CFG_REQ_ENABLES_NUM_MSIX : 0;\n\t\t\tenables |= tx_rings + ring_grps ?\n\t\t\t\t   FUNC_CFG_REQ_ENABLES_NUM_CMPL_RINGS : 0;\n\t\t\tenables |= rx_rings ?\n\t\t\t\tFUNC_CFG_REQ_ENABLES_NUM_RSSCOS_CTXS : 0;\n\t\t} else {\n\t\t\tenables |= cp_rings ?\n\t\t\t\t   FUNC_CFG_REQ_ENABLES_NUM_CMPL_RINGS : 0;\n\t\t\tenables |= ring_grps ?\n\t\t\t\t   FUNC_CFG_REQ_ENABLES_NUM_HW_RING_GRPS |\n\t\t\t\t   FUNC_CFG_REQ_ENABLES_NUM_RSSCOS_CTXS : 0;\n\t\t}\n\t\tenables |= vnics ? FUNC_CFG_REQ_ENABLES_NUM_VNICS : 0;\n\n\t\treq->num_rx_rings = cpu_to_le16(rx_rings);\n\t\tif (bp->flags & BNXT_FLAG_CHIP_P5) {\n\t\t\treq->num_cmpl_rings = cpu_to_le16(tx_rings + ring_grps);\n\t\t\treq->num_msix = cpu_to_le16(cp_rings);\n\t\t\treq->num_rsscos_ctxs =\n\t\t\t\tcpu_to_le16(DIV_ROUND_UP(ring_grps, 64));\n\t\t} else {\n\t\t\treq->num_cmpl_rings = cpu_to_le16(cp_rings);\n\t\t\treq->num_hw_ring_grps = cpu_to_le16(ring_grps);\n\t\t\treq->num_rsscos_ctxs = cpu_to_le16(1);\n\t\t\tif (!(bp->flags & BNXT_FLAG_NEW_RSS_CAP) &&\n\t\t\t    bnxt_rfs_supported(bp))\n\t\t\t\treq->num_rsscos_ctxs =\n\t\t\t\t\tcpu_to_le16(ring_grps + 1);\n\t\t}\n\t\treq->num_stat_ctxs = cpu_to_le16(stats);\n\t\treq->num_vnics = cpu_to_le16(vnics);\n\t}\n\treq->enables = cpu_to_le32(enables);\n}\n\nstatic void\n__bnxt_hwrm_reserve_vf_rings(struct bnxt *bp,\n\t\t\t     struct hwrm_func_vf_cfg_input *req, int tx_rings,\n\t\t\t     int rx_rings, int ring_grps, int cp_rings,\n\t\t\t     int stats, int vnics)\n{\n\tu32 enables = 0;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, req, HWRM_FUNC_VF_CFG, -1, -1);\n\tenables |= tx_rings ? FUNC_VF_CFG_REQ_ENABLES_NUM_TX_RINGS : 0;\n\tenables |= rx_rings ? FUNC_VF_CFG_REQ_ENABLES_NUM_RX_RINGS |\n\t\t\t      FUNC_VF_CFG_REQ_ENABLES_NUM_RSSCOS_CTXS : 0;\n\tenables |= stats ? FUNC_VF_CFG_REQ_ENABLES_NUM_STAT_CTXS : 0;\n\tif (bp->flags & BNXT_FLAG_CHIP_P5) {\n\t\tenables |= tx_rings + ring_grps ?\n\t\t\t   FUNC_VF_CFG_REQ_ENABLES_NUM_CMPL_RINGS : 0;\n\t} else {\n\t\tenables |= cp_rings ?\n\t\t\t   FUNC_VF_CFG_REQ_ENABLES_NUM_CMPL_RINGS : 0;\n\t\tenables |= ring_grps ?\n\t\t\t   FUNC_VF_CFG_REQ_ENABLES_NUM_HW_RING_GRPS : 0;\n\t}\n\tenables |= vnics ? FUNC_VF_CFG_REQ_ENABLES_NUM_VNICS : 0;\n\tenables |= FUNC_VF_CFG_REQ_ENABLES_NUM_L2_CTXS;\n\n\treq->num_l2_ctxs = cpu_to_le16(BNXT_VF_MAX_L2_CTX);\n\treq->num_tx_rings = cpu_to_le16(tx_rings);\n\treq->num_rx_rings = cpu_to_le16(rx_rings);\n\tif (bp->flags & BNXT_FLAG_CHIP_P5) {\n\t\treq->num_cmpl_rings = cpu_to_le16(tx_rings + ring_grps);\n\t\treq->num_rsscos_ctxs = cpu_to_le16(DIV_ROUND_UP(ring_grps, 64));\n\t} else {\n\t\treq->num_cmpl_rings = cpu_to_le16(cp_rings);\n\t\treq->num_hw_ring_grps = cpu_to_le16(ring_grps);\n\t\treq->num_rsscos_ctxs = cpu_to_le16(BNXT_VF_MAX_RSS_CTX);\n\t}\n\treq->num_stat_ctxs = cpu_to_le16(stats);\n\treq->num_vnics = cpu_to_le16(vnics);\n\n\treq->enables = cpu_to_le32(enables);\n}\n\nstatic int\nbnxt_hwrm_reserve_pf_rings(struct bnxt *bp, int tx_rings, int rx_rings,\n\t\t\t   int ring_grps, int cp_rings, int stats, int vnics)\n{\n\tstruct hwrm_func_cfg_input req = {0};\n\tint rc;\n\n\t__bnxt_hwrm_reserve_pf_rings(bp, &req, tx_rings, rx_rings, ring_grps,\n\t\t\t\t     cp_rings, stats, vnics);\n\tif (!req.enables)\n\t\treturn 0;\n\n\trc = hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (rc)\n\t\treturn rc;\n\n\tif (bp->hwrm_spec_code < 0x10601)\n\t\tbp->hw_resc.resv_tx_rings = tx_rings;\n\n\treturn bnxt_hwrm_get_rings(bp);\n}\n\nstatic int\nbnxt_hwrm_reserve_vf_rings(struct bnxt *bp, int tx_rings, int rx_rings,\n\t\t\t   int ring_grps, int cp_rings, int stats, int vnics)\n{\n\tstruct hwrm_func_vf_cfg_input req = {0};\n\tint rc;\n\n\tif (!BNXT_NEW_RM(bp)) {\n\t\tbp->hw_resc.resv_tx_rings = tx_rings;\n\t\treturn 0;\n\t}\n\n\t__bnxt_hwrm_reserve_vf_rings(bp, &req, tx_rings, rx_rings, ring_grps,\n\t\t\t\t     cp_rings, stats, vnics);\n\trc = hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (rc)\n\t\treturn rc;\n\n\treturn bnxt_hwrm_get_rings(bp);\n}\n\nstatic int bnxt_hwrm_reserve_rings(struct bnxt *bp, int tx, int rx, int grp,\n\t\t\t\t   int cp, int stat, int vnic)\n{\n\tif (BNXT_PF(bp))\n\t\treturn bnxt_hwrm_reserve_pf_rings(bp, tx, rx, grp, cp, stat,\n\t\t\t\t\t\t  vnic);\n\telse\n\t\treturn bnxt_hwrm_reserve_vf_rings(bp, tx, rx, grp, cp, stat,\n\t\t\t\t\t\t  vnic);\n}\n\nint bnxt_nq_rings_in_use(struct bnxt *bp)\n{\n\tint cp = bp->cp_nr_rings;\n\tint ulp_msix, ulp_base;\n\n\tulp_msix = bnxt_get_ulp_msix_num(bp);\n\tif (ulp_msix) {\n\t\tulp_base = bnxt_get_ulp_msix_base(bp);\n\t\tcp += ulp_msix;\n\t\tif ((ulp_base + ulp_msix) > cp)\n\t\t\tcp = ulp_base + ulp_msix;\n\t}\n\treturn cp;\n}\n\nstatic int bnxt_cp_rings_in_use(struct bnxt *bp)\n{\n\tint cp;\n\n\tif (!(bp->flags & BNXT_FLAG_CHIP_P5))\n\t\treturn bnxt_nq_rings_in_use(bp);\n\n\tcp = bp->tx_nr_rings + bp->rx_nr_rings;\n\treturn cp;\n}\n\nstatic int bnxt_get_func_stat_ctxs(struct bnxt *bp)\n{\n\tint ulp_stat = bnxt_get_ulp_stat_ctxs(bp);\n\tint cp = bp->cp_nr_rings;\n\n\tif (!ulp_stat)\n\t\treturn cp;\n\n\tif (bnxt_nq_rings_in_use(bp) > cp + bnxt_get_ulp_msix_num(bp))\n\t\treturn bnxt_get_ulp_msix_base(bp) + ulp_stat;\n\n\treturn cp + ulp_stat;\n}\n\n/* Check if a default RSS map needs to be setup.  This function is only\n * used on older firmware that does not require reserving RX rings.\n */\nstatic void bnxt_check_rss_tbl_no_rmgr(struct bnxt *bp)\n{\n\tstruct bnxt_hw_resc *hw_resc = &bp->hw_resc;\n\n\t/* The RSS map is valid for RX rings set to resv_rx_rings */\n\tif (hw_resc->resv_rx_rings != bp->rx_nr_rings) {\n\t\thw_resc->resv_rx_rings = bp->rx_nr_rings;\n\t\tif (!netif_is_rxfh_configured(bp->dev))\n\t\t\tbnxt_set_dflt_rss_indir_tbl(bp);\n\t}\n}\n\nstatic bool bnxt_need_reserve_rings(struct bnxt *bp)\n{\n\tstruct bnxt_hw_resc *hw_resc = &bp->hw_resc;\n\tint cp = bnxt_cp_rings_in_use(bp);\n\tint nq = bnxt_nq_rings_in_use(bp);\n\tint rx = bp->rx_nr_rings, stat;\n\tint vnic = 1, grp = rx;\n\n\tif (hw_resc->resv_tx_rings != bp->tx_nr_rings &&\n\t    bp->hwrm_spec_code >= 0x10601)\n\t\treturn true;\n\n\t/* Old firmware does not need RX ring reservations but we still\n\t * need to setup a default RSS map when needed.  With new firmware\n\t * we go through RX ring reservations first and then set up the\n\t * RSS map for the successfully reserved RX rings when needed.\n\t */\n\tif (!BNXT_NEW_RM(bp)) {\n\t\tbnxt_check_rss_tbl_no_rmgr(bp);\n\t\treturn false;\n\t}\n\tif ((bp->flags & BNXT_FLAG_RFS) && !(bp->flags & BNXT_FLAG_CHIP_P5))\n\t\tvnic = rx + 1;\n\tif (bp->flags & BNXT_FLAG_AGG_RINGS)\n\t\trx <<= 1;\n\tstat = bnxt_get_func_stat_ctxs(bp);\n\tif (hw_resc->resv_rx_rings != rx || hw_resc->resv_cp_rings != cp ||\n\t    hw_resc->resv_vnics != vnic || hw_resc->resv_stat_ctxs != stat ||\n\t    (hw_resc->resv_hw_ring_grps != grp &&\n\t     !(bp->flags & BNXT_FLAG_CHIP_P5)))\n\t\treturn true;\n\tif ((bp->flags & BNXT_FLAG_CHIP_P5) && BNXT_PF(bp) &&\n\t    hw_resc->resv_irqs != nq)\n\t\treturn true;\n\treturn false;\n}\n\nstatic int __bnxt_reserve_rings(struct bnxt *bp)\n{\n\tstruct bnxt_hw_resc *hw_resc = &bp->hw_resc;\n\tint cp = bnxt_nq_rings_in_use(bp);\n\tint tx = bp->tx_nr_rings;\n\tint rx = bp->rx_nr_rings;\n\tint grp, rx_rings, rc;\n\tint vnic = 1, stat;\n\tbool sh = false;\n\n\tif (!bnxt_need_reserve_rings(bp))\n\t\treturn 0;\n\n\tif (bp->flags & BNXT_FLAG_SHARED_RINGS)\n\t\tsh = true;\n\tif ((bp->flags & BNXT_FLAG_RFS) && !(bp->flags & BNXT_FLAG_CHIP_P5))\n\t\tvnic = rx + 1;\n\tif (bp->flags & BNXT_FLAG_AGG_RINGS)\n\t\trx <<= 1;\n\tgrp = bp->rx_nr_rings;\n\tstat = bnxt_get_func_stat_ctxs(bp);\n\n\trc = bnxt_hwrm_reserve_rings(bp, tx, rx, grp, cp, stat, vnic);\n\tif (rc)\n\t\treturn rc;\n\n\ttx = hw_resc->resv_tx_rings;\n\tif (BNXT_NEW_RM(bp)) {\n\t\trx = hw_resc->resv_rx_rings;\n\t\tcp = hw_resc->resv_irqs;\n\t\tgrp = hw_resc->resv_hw_ring_grps;\n\t\tvnic = hw_resc->resv_vnics;\n\t\tstat = hw_resc->resv_stat_ctxs;\n\t}\n\n\trx_rings = rx;\n\tif (bp->flags & BNXT_FLAG_AGG_RINGS) {\n\t\tif (rx >= 2) {\n\t\t\trx_rings = rx >> 1;\n\t\t} else {\n\t\t\tif (netif_running(bp->dev))\n\t\t\t\treturn -ENOMEM;\n\n\t\t\tbp->flags &= ~BNXT_FLAG_AGG_RINGS;\n\t\t\tbp->flags |= BNXT_FLAG_NO_AGG_RINGS;\n\t\t\tbp->dev->hw_features &= ~NETIF_F_LRO;\n\t\t\tbp->dev->features &= ~NETIF_F_LRO;\n\t\t\tbnxt_set_ring_params(bp);\n\t\t}\n\t}\n\trx_rings = min_t(int, rx_rings, grp);\n\tcp = min_t(int, cp, bp->cp_nr_rings);\n\tif (stat > bnxt_get_ulp_stat_ctxs(bp))\n\t\tstat -= bnxt_get_ulp_stat_ctxs(bp);\n\tcp = min_t(int, cp, stat);\n\trc = bnxt_trim_rings(bp, &rx_rings, &tx, cp, sh);\n\tif (bp->flags & BNXT_FLAG_AGG_RINGS)\n\t\trx = rx_rings << 1;\n\tcp = sh ? max_t(int, tx, rx_rings) : tx + rx_rings;\n\tbp->tx_nr_rings = tx;\n\n\t/* If we cannot reserve all the RX rings, reset the RSS map only\n\t * if absolutely necessary\n\t */\n\tif (rx_rings != bp->rx_nr_rings) {\n\t\tnetdev_warn(bp->dev, \"Able to reserve only %d out of %d requested RX rings\\n\",\n\t\t\t    rx_rings, bp->rx_nr_rings);\n\t\tif ((bp->dev->priv_flags & IFF_RXFH_CONFIGURED) &&\n\t\t    (bnxt_get_nr_rss_ctxs(bp, bp->rx_nr_rings) !=\n\t\t     bnxt_get_nr_rss_ctxs(bp, rx_rings) ||\n\t\t     bnxt_get_max_rss_ring(bp) >= rx_rings)) {\n\t\t\tnetdev_warn(bp->dev, \"RSS table entries reverting to default\\n\");\n\t\t\tbp->dev->priv_flags &= ~IFF_RXFH_CONFIGURED;\n\t\t}\n\t}\n\tbp->rx_nr_rings = rx_rings;\n\tbp->cp_nr_rings = cp;\n\n\tif (!tx || !rx || !cp || !grp || !vnic || !stat)\n\t\treturn -ENOMEM;\n\n\tif (!netif_is_rxfh_configured(bp->dev))\n\t\tbnxt_set_dflt_rss_indir_tbl(bp);\n\n\treturn rc;\n}\n\nstatic int bnxt_hwrm_check_vf_rings(struct bnxt *bp, int tx_rings, int rx_rings,\n\t\t\t\t    int ring_grps, int cp_rings, int stats,\n\t\t\t\t    int vnics)\n{\n\tstruct hwrm_func_vf_cfg_input req = {0};\n\tu32 flags;\n\n\tif (!BNXT_NEW_RM(bp))\n\t\treturn 0;\n\n\t__bnxt_hwrm_reserve_vf_rings(bp, &req, tx_rings, rx_rings, ring_grps,\n\t\t\t\t     cp_rings, stats, vnics);\n\tflags = FUNC_VF_CFG_REQ_FLAGS_TX_ASSETS_TEST |\n\t\tFUNC_VF_CFG_REQ_FLAGS_RX_ASSETS_TEST |\n\t\tFUNC_VF_CFG_REQ_FLAGS_CMPL_ASSETS_TEST |\n\t\tFUNC_VF_CFG_REQ_FLAGS_STAT_CTX_ASSETS_TEST |\n\t\tFUNC_VF_CFG_REQ_FLAGS_VNIC_ASSETS_TEST |\n\t\tFUNC_VF_CFG_REQ_FLAGS_RSSCOS_CTX_ASSETS_TEST;\n\tif (!(bp->flags & BNXT_FLAG_CHIP_P5))\n\t\tflags |= FUNC_VF_CFG_REQ_FLAGS_RING_GRP_ASSETS_TEST;\n\n\treq.flags = cpu_to_le32(flags);\n\treturn hwrm_send_message_silent(bp, &req, sizeof(req),\n\t\t\t\t\tHWRM_CMD_TIMEOUT);\n}\n\nstatic int bnxt_hwrm_check_pf_rings(struct bnxt *bp, int tx_rings, int rx_rings,\n\t\t\t\t    int ring_grps, int cp_rings, int stats,\n\t\t\t\t    int vnics)\n{\n\tstruct hwrm_func_cfg_input req = {0};\n\tu32 flags;\n\n\t__bnxt_hwrm_reserve_pf_rings(bp, &req, tx_rings, rx_rings, ring_grps,\n\t\t\t\t     cp_rings, stats, vnics);\n\tflags = FUNC_CFG_REQ_FLAGS_TX_ASSETS_TEST;\n\tif (BNXT_NEW_RM(bp)) {\n\t\tflags |= FUNC_CFG_REQ_FLAGS_RX_ASSETS_TEST |\n\t\t\t FUNC_CFG_REQ_FLAGS_CMPL_ASSETS_TEST |\n\t\t\t FUNC_CFG_REQ_FLAGS_STAT_CTX_ASSETS_TEST |\n\t\t\t FUNC_CFG_REQ_FLAGS_VNIC_ASSETS_TEST;\n\t\tif (bp->flags & BNXT_FLAG_CHIP_P5)\n\t\t\tflags |= FUNC_CFG_REQ_FLAGS_RSSCOS_CTX_ASSETS_TEST |\n\t\t\t\t FUNC_CFG_REQ_FLAGS_NQ_ASSETS_TEST;\n\t\telse\n\t\t\tflags |= FUNC_CFG_REQ_FLAGS_RING_GRP_ASSETS_TEST;\n\t}\n\n\treq.flags = cpu_to_le32(flags);\n\treturn hwrm_send_message_silent(bp, &req, sizeof(req),\n\t\t\t\t\tHWRM_CMD_TIMEOUT);\n}\n\nstatic int bnxt_hwrm_check_rings(struct bnxt *bp, int tx_rings, int rx_rings,\n\t\t\t\t int ring_grps, int cp_rings, int stats,\n\t\t\t\t int vnics)\n{\n\tif (bp->hwrm_spec_code < 0x10801)\n\t\treturn 0;\n\n\tif (BNXT_PF(bp))\n\t\treturn bnxt_hwrm_check_pf_rings(bp, tx_rings, rx_rings,\n\t\t\t\t\t\tring_grps, cp_rings, stats,\n\t\t\t\t\t\tvnics);\n\n\treturn bnxt_hwrm_check_vf_rings(bp, tx_rings, rx_rings, ring_grps,\n\t\t\t\t\tcp_rings, stats, vnics);\n}\n\nstatic void bnxt_hwrm_coal_params_qcaps(struct bnxt *bp)\n{\n\tstruct hwrm_ring_aggint_qcaps_output *resp = bp->hwrm_cmd_resp_addr;\n\tstruct bnxt_coal_cap *coal_cap = &bp->coal_cap;\n\tstruct hwrm_ring_aggint_qcaps_input req = {0};\n\tint rc;\n\n\tcoal_cap->cmpl_params = BNXT_LEGACY_COAL_CMPL_PARAMS;\n\tcoal_cap->num_cmpl_dma_aggr_max = 63;\n\tcoal_cap->num_cmpl_dma_aggr_during_int_max = 63;\n\tcoal_cap->cmpl_aggr_dma_tmr_max = 65535;\n\tcoal_cap->cmpl_aggr_dma_tmr_during_int_max = 65535;\n\tcoal_cap->int_lat_tmr_min_max = 65535;\n\tcoal_cap->int_lat_tmr_max_max = 65535;\n\tcoal_cap->num_cmpl_aggr_int_max = 65535;\n\tcoal_cap->timer_units = 80;\n\n\tif (bp->hwrm_spec_code < 0x10902)\n\t\treturn;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_RING_AGGINT_QCAPS, -1, -1);\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message_silent(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (!rc) {\n\t\tcoal_cap->cmpl_params = le32_to_cpu(resp->cmpl_params);\n\t\tcoal_cap->nq_params = le32_to_cpu(resp->nq_params);\n\t\tcoal_cap->num_cmpl_dma_aggr_max =\n\t\t\tle16_to_cpu(resp->num_cmpl_dma_aggr_max);\n\t\tcoal_cap->num_cmpl_dma_aggr_during_int_max =\n\t\t\tle16_to_cpu(resp->num_cmpl_dma_aggr_during_int_max);\n\t\tcoal_cap->cmpl_aggr_dma_tmr_max =\n\t\t\tle16_to_cpu(resp->cmpl_aggr_dma_tmr_max);\n\t\tcoal_cap->cmpl_aggr_dma_tmr_during_int_max =\n\t\t\tle16_to_cpu(resp->cmpl_aggr_dma_tmr_during_int_max);\n\t\tcoal_cap->int_lat_tmr_min_max =\n\t\t\tle16_to_cpu(resp->int_lat_tmr_min_max);\n\t\tcoal_cap->int_lat_tmr_max_max =\n\t\t\tle16_to_cpu(resp->int_lat_tmr_max_max);\n\t\tcoal_cap->num_cmpl_aggr_int_max =\n\t\t\tle16_to_cpu(resp->num_cmpl_aggr_int_max);\n\t\tcoal_cap->timer_units = le16_to_cpu(resp->timer_units);\n\t}\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n}\n\nstatic u16 bnxt_usec_to_coal_tmr(struct bnxt *bp, u16 usec)\n{\n\tstruct bnxt_coal_cap *coal_cap = &bp->coal_cap;\n\n\treturn usec * 1000 / coal_cap->timer_units;\n}\n\nstatic void bnxt_hwrm_set_coal_params(struct bnxt *bp,\n\tstruct bnxt_coal *hw_coal,\n\tstruct hwrm_ring_cmpl_ring_cfg_aggint_params_input *req)\n{\n\tstruct bnxt_coal_cap *coal_cap = &bp->coal_cap;\n\tu32 cmpl_params = coal_cap->cmpl_params;\n\tu16 val, tmr, max, flags = 0;\n\n\tmax = hw_coal->bufs_per_record * 128;\n\tif (hw_coal->budget)\n\t\tmax = hw_coal->bufs_per_record * hw_coal->budget;\n\tmax = min_t(u16, max, coal_cap->num_cmpl_aggr_int_max);\n\n\tval = clamp_t(u16, hw_coal->coal_bufs, 1, max);\n\treq->num_cmpl_aggr_int = cpu_to_le16(val);\n\n\tval = min_t(u16, val, coal_cap->num_cmpl_dma_aggr_max);\n\treq->num_cmpl_dma_aggr = cpu_to_le16(val);\n\n\tval = clamp_t(u16, hw_coal->coal_bufs_irq, 1,\n\t\t      coal_cap->num_cmpl_dma_aggr_during_int_max);\n\treq->num_cmpl_dma_aggr_during_int = cpu_to_le16(val);\n\n\ttmr = bnxt_usec_to_coal_tmr(bp, hw_coal->coal_ticks);\n\ttmr = clamp_t(u16, tmr, 1, coal_cap->int_lat_tmr_max_max);\n\treq->int_lat_tmr_max = cpu_to_le16(tmr);\n\n\t/* min timer set to 1/2 of interrupt timer */\n\tif (cmpl_params & RING_AGGINT_QCAPS_RESP_CMPL_PARAMS_INT_LAT_TMR_MIN) {\n\t\tval = tmr / 2;\n\t\tval = clamp_t(u16, val, 1, coal_cap->int_lat_tmr_min_max);\n\t\treq->int_lat_tmr_min = cpu_to_le16(val);\n\t\treq->enables |= cpu_to_le16(BNXT_COAL_CMPL_MIN_TMR_ENABLE);\n\t}\n\n\t/* buf timer set to 1/4 of interrupt timer */\n\tval = clamp_t(u16, tmr / 4, 1, coal_cap->cmpl_aggr_dma_tmr_max);\n\treq->cmpl_aggr_dma_tmr = cpu_to_le16(val);\n\n\tif (cmpl_params &\n\t    RING_AGGINT_QCAPS_RESP_CMPL_PARAMS_NUM_CMPL_DMA_AGGR_DURING_INT) {\n\t\ttmr = bnxt_usec_to_coal_tmr(bp, hw_coal->coal_ticks_irq);\n\t\tval = clamp_t(u16, tmr, 1,\n\t\t\t      coal_cap->cmpl_aggr_dma_tmr_during_int_max);\n\t\treq->cmpl_aggr_dma_tmr_during_int = cpu_to_le16(val);\n\t\treq->enables |=\n\t\t\tcpu_to_le16(BNXT_COAL_CMPL_AGGR_TMR_DURING_INT_ENABLE);\n\t}\n\n\tif (cmpl_params & RING_AGGINT_QCAPS_RESP_CMPL_PARAMS_TIMER_RESET)\n\t\tflags |= RING_CMPL_RING_CFG_AGGINT_PARAMS_REQ_FLAGS_TIMER_RESET;\n\tif ((cmpl_params & RING_AGGINT_QCAPS_RESP_CMPL_PARAMS_RING_IDLE) &&\n\t    hw_coal->idle_thresh && hw_coal->coal_ticks < hw_coal->idle_thresh)\n\t\tflags |= RING_CMPL_RING_CFG_AGGINT_PARAMS_REQ_FLAGS_RING_IDLE;\n\treq->flags = cpu_to_le16(flags);\n\treq->enables |= cpu_to_le16(BNXT_COAL_CMPL_ENABLES);\n}\n\n/* Caller holds bp->hwrm_cmd_lock */\nstatic int __bnxt_hwrm_set_coal_nq(struct bnxt *bp, struct bnxt_napi *bnapi,\n\t\t\t\t   struct bnxt_coal *hw_coal)\n{\n\tstruct hwrm_ring_cmpl_ring_cfg_aggint_params_input req = {0};\n\tstruct bnxt_cp_ring_info *cpr = &bnapi->cp_ring;\n\tstruct bnxt_coal_cap *coal_cap = &bp->coal_cap;\n\tu32 nq_params = coal_cap->nq_params;\n\tu16 tmr;\n\n\tif (!(nq_params & RING_AGGINT_QCAPS_RESP_NQ_PARAMS_INT_LAT_TMR_MIN))\n\t\treturn 0;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_RING_CMPL_RING_CFG_AGGINT_PARAMS,\n\t\t\t       -1, -1);\n\treq.ring_id = cpu_to_le16(cpr->cp_ring_struct.fw_ring_id);\n\treq.flags =\n\t\tcpu_to_le16(RING_CMPL_RING_CFG_AGGINT_PARAMS_REQ_FLAGS_IS_NQ);\n\n\ttmr = bnxt_usec_to_coal_tmr(bp, hw_coal->coal_ticks) / 2;\n\ttmr = clamp_t(u16, tmr, 1, coal_cap->int_lat_tmr_min_max);\n\treq.int_lat_tmr_min = cpu_to_le16(tmr);\n\treq.enables |= cpu_to_le16(BNXT_COAL_CMPL_MIN_TMR_ENABLE);\n\treturn _hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n}\n\nint bnxt_hwrm_set_ring_coal(struct bnxt *bp, struct bnxt_napi *bnapi)\n{\n\tstruct hwrm_ring_cmpl_ring_cfg_aggint_params_input req_rx = {0};\n\tstruct bnxt_cp_ring_info *cpr = &bnapi->cp_ring;\n\tstruct bnxt_coal coal;\n\n\t/* Tick values in micro seconds.\n\t * 1 coal_buf x bufs_per_record = 1 completion record.\n\t */\n\tmemcpy(&coal, &bp->rx_coal, sizeof(struct bnxt_coal));\n\n\tcoal.coal_ticks = cpr->rx_ring_coal.coal_ticks;\n\tcoal.coal_bufs = cpr->rx_ring_coal.coal_bufs;\n\n\tif (!bnapi->rx_ring)\n\t\treturn -ENODEV;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req_rx,\n\t\t\t       HWRM_RING_CMPL_RING_CFG_AGGINT_PARAMS, -1, -1);\n\n\tbnxt_hwrm_set_coal_params(bp, &coal, &req_rx);\n\n\treq_rx.ring_id = cpu_to_le16(bnxt_cp_ring_for_rx(bp, bnapi->rx_ring));\n\n\treturn hwrm_send_message(bp, &req_rx, sizeof(req_rx),\n\t\t\t\t HWRM_CMD_TIMEOUT);\n}\n\nint bnxt_hwrm_set_coal(struct bnxt *bp)\n{\n\tint i, rc = 0;\n\tstruct hwrm_ring_cmpl_ring_cfg_aggint_params_input req_rx = {0},\n\t\t\t\t\t\t\t   req_tx = {0}, *req;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req_rx,\n\t\t\t       HWRM_RING_CMPL_RING_CFG_AGGINT_PARAMS, -1, -1);\n\tbnxt_hwrm_cmd_hdr_init(bp, &req_tx,\n\t\t\t       HWRM_RING_CMPL_RING_CFG_AGGINT_PARAMS, -1, -1);\n\n\tbnxt_hwrm_set_coal_params(bp, &bp->rx_coal, &req_rx);\n\tbnxt_hwrm_set_coal_params(bp, &bp->tx_coal, &req_tx);\n\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\tfor (i = 0; i < bp->cp_nr_rings; i++) {\n\t\tstruct bnxt_napi *bnapi = bp->bnapi[i];\n\t\tstruct bnxt_coal *hw_coal;\n\t\tu16 ring_id;\n\n\t\treq = &req_rx;\n\t\tif (!bnapi->rx_ring) {\n\t\t\tring_id = bnxt_cp_ring_for_tx(bp, bnapi->tx_ring);\n\t\t\treq = &req_tx;\n\t\t} else {\n\t\t\tring_id = bnxt_cp_ring_for_rx(bp, bnapi->rx_ring);\n\t\t}\n\t\treq->ring_id = cpu_to_le16(ring_id);\n\n\t\trc = _hwrm_send_message(bp, req, sizeof(*req),\n\t\t\t\t\tHWRM_CMD_TIMEOUT);\n\t\tif (rc)\n\t\t\tbreak;\n\n\t\tif (!(bp->flags & BNXT_FLAG_CHIP_P5))\n\t\t\tcontinue;\n\n\t\tif (bnapi->rx_ring && bnapi->tx_ring) {\n\t\t\treq = &req_tx;\n\t\t\tring_id = bnxt_cp_ring_for_tx(bp, bnapi->tx_ring);\n\t\t\treq->ring_id = cpu_to_le16(ring_id);\n\t\t\trc = _hwrm_send_message(bp, req, sizeof(*req),\n\t\t\t\t\t\tHWRM_CMD_TIMEOUT);\n\t\t\tif (rc)\n\t\t\t\tbreak;\n\t\t}\n\t\tif (bnapi->rx_ring)\n\t\t\thw_coal = &bp->rx_coal;\n\t\telse\n\t\t\thw_coal = &bp->tx_coal;\n\t\t__bnxt_hwrm_set_coal_nq(bp, bnapi, hw_coal);\n\t}\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\treturn rc;\n}\n\nstatic void bnxt_hwrm_stat_ctx_free(struct bnxt *bp)\n{\n\tstruct hwrm_stat_ctx_clr_stats_input req0 = {0};\n\tstruct hwrm_stat_ctx_free_input req = {0};\n\tint i;\n\n\tif (!bp->bnapi)\n\t\treturn;\n\n\tif (BNXT_CHIP_TYPE_NITRO_A0(bp))\n\t\treturn;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req0, HWRM_STAT_CTX_CLR_STATS, -1, -1);\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_STAT_CTX_FREE, -1, -1);\n\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\tfor (i = 0; i < bp->cp_nr_rings; i++) {\n\t\tstruct bnxt_napi *bnapi = bp->bnapi[i];\n\t\tstruct bnxt_cp_ring_info *cpr = &bnapi->cp_ring;\n\n\t\tif (cpr->hw_stats_ctx_id != INVALID_STATS_CTX_ID) {\n\t\t\treq.stat_ctx_id = cpu_to_le32(cpr->hw_stats_ctx_id);\n\t\t\tif (BNXT_FW_MAJ(bp) <= 20) {\n\t\t\t\treq0.stat_ctx_id = req.stat_ctx_id;\n\t\t\t\t_hwrm_send_message(bp, &req0, sizeof(req0),\n\t\t\t\t\t\t   HWRM_CMD_TIMEOUT);\n\t\t\t}\n\t\t\t_hwrm_send_message(bp, &req, sizeof(req),\n\t\t\t\t\t   HWRM_CMD_TIMEOUT);\n\n\t\t\tcpr->hw_stats_ctx_id = INVALID_STATS_CTX_ID;\n\t\t}\n\t}\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n}\n\nstatic int bnxt_hwrm_stat_ctx_alloc(struct bnxt *bp)\n{\n\tint rc = 0, i;\n\tstruct hwrm_stat_ctx_alloc_input req = {0};\n\tstruct hwrm_stat_ctx_alloc_output *resp = bp->hwrm_cmd_resp_addr;\n\n\tif (BNXT_CHIP_TYPE_NITRO_A0(bp))\n\t\treturn 0;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_STAT_CTX_ALLOC, -1, -1);\n\n\treq.stats_dma_length = cpu_to_le16(bp->hw_ring_stats_size);\n\treq.update_period_ms = cpu_to_le32(bp->stats_coal_ticks / 1000);\n\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\tfor (i = 0; i < bp->cp_nr_rings; i++) {\n\t\tstruct bnxt_napi *bnapi = bp->bnapi[i];\n\t\tstruct bnxt_cp_ring_info *cpr = &bnapi->cp_ring;\n\n\t\treq.stats_dma_addr = cpu_to_le64(cpr->stats.hw_stats_map);\n\n\t\trc = _hwrm_send_message(bp, &req, sizeof(req),\n\t\t\t\t\tHWRM_CMD_TIMEOUT);\n\t\tif (rc)\n\t\t\tbreak;\n\n\t\tcpr->hw_stats_ctx_id = le32_to_cpu(resp->stat_ctx_id);\n\n\t\tbp->grp_info[i].fw_stats_ctx = cpr->hw_stats_ctx_id;\n\t}\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\treturn rc;\n}\n\nstatic int bnxt_hwrm_func_qcfg(struct bnxt *bp)\n{\n\tstruct hwrm_func_qcfg_input req = {0};\n\tstruct hwrm_func_qcfg_output *resp = bp->hwrm_cmd_resp_addr;\n\tu32 min_db_offset = 0;\n\tu16 flags;\n\tint rc;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_FUNC_QCFG, -1, -1);\n\treq.fid = cpu_to_le16(0xffff);\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (rc)\n\t\tgoto func_qcfg_exit;\n\n#ifdef CONFIG_BNXT_SRIOV\n\tif (BNXT_VF(bp)) {\n\t\tstruct bnxt_vf_info *vf = &bp->vf;\n\n\t\tvf->vlan = le16_to_cpu(resp->vlan) & VLAN_VID_MASK;\n\t} else {\n\t\tbp->pf.registered_vfs = le16_to_cpu(resp->registered_vfs);\n\t}\n#endif\n\tflags = le16_to_cpu(resp->flags);\n\tif (flags & (FUNC_QCFG_RESP_FLAGS_FW_DCBX_AGENT_ENABLED |\n\t\t     FUNC_QCFG_RESP_FLAGS_FW_LLDP_AGENT_ENABLED)) {\n\t\tbp->fw_cap |= BNXT_FW_CAP_LLDP_AGENT;\n\t\tif (flags & FUNC_QCFG_RESP_FLAGS_FW_DCBX_AGENT_ENABLED)\n\t\t\tbp->fw_cap |= BNXT_FW_CAP_DCBX_AGENT;\n\t}\n\tif (BNXT_PF(bp) && (flags & FUNC_QCFG_RESP_FLAGS_MULTI_HOST))\n\t\tbp->flags |= BNXT_FLAG_MULTI_HOST;\n\tif (flags & FUNC_QCFG_RESP_FLAGS_RING_MONITOR_ENABLED)\n\t\tbp->fw_cap |= BNXT_FW_CAP_RING_MONITOR;\n\n\tswitch (resp->port_partition_type) {\n\tcase FUNC_QCFG_RESP_PORT_PARTITION_TYPE_NPAR1_0:\n\tcase FUNC_QCFG_RESP_PORT_PARTITION_TYPE_NPAR1_5:\n\tcase FUNC_QCFG_RESP_PORT_PARTITION_TYPE_NPAR2_0:\n\t\tbp->port_partition_type = resp->port_partition_type;\n\t\tbreak;\n\t}\n\tif (bp->hwrm_spec_code < 0x10707 ||\n\t    resp->evb_mode == FUNC_QCFG_RESP_EVB_MODE_VEB)\n\t\tbp->br_mode = BRIDGE_MODE_VEB;\n\telse if (resp->evb_mode == FUNC_QCFG_RESP_EVB_MODE_VEPA)\n\t\tbp->br_mode = BRIDGE_MODE_VEPA;\n\telse\n\t\tbp->br_mode = BRIDGE_MODE_UNDEF;\n\n\tbp->max_mtu = le16_to_cpu(resp->max_mtu_configured);\n\tif (!bp->max_mtu)\n\t\tbp->max_mtu = BNXT_MAX_MTU;\n\n\tif (bp->db_size)\n\t\tgoto func_qcfg_exit;\n\n\tif (bp->flags & BNXT_FLAG_CHIP_P5) {\n\t\tif (BNXT_PF(bp))\n\t\t\tmin_db_offset = DB_PF_OFFSET_P5;\n\t\telse\n\t\t\tmin_db_offset = DB_VF_OFFSET_P5;\n\t}\n\tbp->db_size = PAGE_ALIGN(le16_to_cpu(resp->l2_doorbell_bar_size_kb) *\n\t\t\t\t 1024);\n\tif (!bp->db_size || bp->db_size > pci_resource_len(bp->pdev, 2) ||\n\t    bp->db_size <= min_db_offset)\n\t\tbp->db_size = pci_resource_len(bp->pdev, 2);\n\nfunc_qcfg_exit:\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\treturn rc;\n}\n\nstatic void bnxt_init_ctx_initializer(struct bnxt_ctx_mem_info *ctx,\n\t\t\tstruct hwrm_func_backing_store_qcaps_output *resp)\n{\n\tstruct bnxt_mem_init *mem_init;\n\tu16 init_mask;\n\tu8 init_val;\n\tu8 *offset;\n\tint i;\n\n\tinit_val = resp->ctx_kind_initializer;\n\tinit_mask = le16_to_cpu(resp->ctx_init_mask);\n\toffset = &resp->qp_init_offset;\n\tmem_init = &ctx->mem_init[BNXT_CTX_MEM_INIT_QP];\n\tfor (i = 0; i < BNXT_CTX_MEM_INIT_MAX; i++, mem_init++, offset++) {\n\t\tmem_init->init_val = init_val;\n\t\tmem_init->offset = BNXT_MEM_INVALID_OFFSET;\n\t\tif (!init_mask)\n\t\t\tcontinue;\n\t\tif (i == BNXT_CTX_MEM_INIT_STAT)\n\t\t\toffset = &resp->stat_init_offset;\n\t\tif (init_mask & (1 << i))\n\t\t\tmem_init->offset = *offset * 4;\n\t\telse\n\t\t\tmem_init->init_val = 0;\n\t}\n\tctx->mem_init[BNXT_CTX_MEM_INIT_QP].size = ctx->qp_entry_size;\n\tctx->mem_init[BNXT_CTX_MEM_INIT_SRQ].size = ctx->srq_entry_size;\n\tctx->mem_init[BNXT_CTX_MEM_INIT_CQ].size = ctx->cq_entry_size;\n\tctx->mem_init[BNXT_CTX_MEM_INIT_VNIC].size = ctx->vnic_entry_size;\n\tctx->mem_init[BNXT_CTX_MEM_INIT_STAT].size = ctx->stat_entry_size;\n\tctx->mem_init[BNXT_CTX_MEM_INIT_MRAV].size = ctx->mrav_entry_size;\n}\n\nstatic int bnxt_hwrm_func_backing_store_qcaps(struct bnxt *bp)\n{\n\tstruct hwrm_func_backing_store_qcaps_input req = {0};\n\tstruct hwrm_func_backing_store_qcaps_output *resp =\n\t\tbp->hwrm_cmd_resp_addr;\n\tint rc;\n\n\tif (bp->hwrm_spec_code < 0x10902 || BNXT_VF(bp) || bp->ctx)\n\t\treturn 0;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_FUNC_BACKING_STORE_QCAPS, -1, -1);\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message_silent(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (!rc) {\n\t\tstruct bnxt_ctx_pg_info *ctx_pg;\n\t\tstruct bnxt_ctx_mem_info *ctx;\n\t\tint i, tqm_rings;\n\n\t\tctx = kzalloc(sizeof(*ctx), GFP_KERNEL);\n\t\tif (!ctx) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto ctx_err;\n\t\t}\n\t\tctx->qp_max_entries = le32_to_cpu(resp->qp_max_entries);\n\t\tctx->qp_min_qp1_entries = le16_to_cpu(resp->qp_min_qp1_entries);\n\t\tctx->qp_max_l2_entries = le16_to_cpu(resp->qp_max_l2_entries);\n\t\tctx->qp_entry_size = le16_to_cpu(resp->qp_entry_size);\n\t\tctx->srq_max_l2_entries = le16_to_cpu(resp->srq_max_l2_entries);\n\t\tctx->srq_max_entries = le32_to_cpu(resp->srq_max_entries);\n\t\tctx->srq_entry_size = le16_to_cpu(resp->srq_entry_size);\n\t\tctx->cq_max_l2_entries = le16_to_cpu(resp->cq_max_l2_entries);\n\t\tctx->cq_max_entries = le32_to_cpu(resp->cq_max_entries);\n\t\tctx->cq_entry_size = le16_to_cpu(resp->cq_entry_size);\n\t\tctx->vnic_max_vnic_entries =\n\t\t\tle16_to_cpu(resp->vnic_max_vnic_entries);\n\t\tctx->vnic_max_ring_table_entries =\n\t\t\tle16_to_cpu(resp->vnic_max_ring_table_entries);\n\t\tctx->vnic_entry_size = le16_to_cpu(resp->vnic_entry_size);\n\t\tctx->stat_max_entries = le32_to_cpu(resp->stat_max_entries);\n\t\tctx->stat_entry_size = le16_to_cpu(resp->stat_entry_size);\n\t\tctx->tqm_entry_size = le16_to_cpu(resp->tqm_entry_size);\n\t\tctx->tqm_min_entries_per_ring =\n\t\t\tle32_to_cpu(resp->tqm_min_entries_per_ring);\n\t\tctx->tqm_max_entries_per_ring =\n\t\t\tle32_to_cpu(resp->tqm_max_entries_per_ring);\n\t\tctx->tqm_entries_multiple = resp->tqm_entries_multiple;\n\t\tif (!ctx->tqm_entries_multiple)\n\t\t\tctx->tqm_entries_multiple = 1;\n\t\tctx->mrav_max_entries = le32_to_cpu(resp->mrav_max_entries);\n\t\tctx->mrav_entry_size = le16_to_cpu(resp->mrav_entry_size);\n\t\tctx->mrav_num_entries_units =\n\t\t\tle16_to_cpu(resp->mrav_num_entries_units);\n\t\tctx->tim_entry_size = le16_to_cpu(resp->tim_entry_size);\n\t\tctx->tim_max_entries = le32_to_cpu(resp->tim_max_entries);\n\n\t\tbnxt_init_ctx_initializer(ctx, resp);\n\n\t\tctx->tqm_fp_rings_count = resp->tqm_fp_rings_count;\n\t\tif (!ctx->tqm_fp_rings_count)\n\t\t\tctx->tqm_fp_rings_count = bp->max_q;\n\t\telse if (ctx->tqm_fp_rings_count > BNXT_MAX_TQM_FP_RINGS)\n\t\t\tctx->tqm_fp_rings_count = BNXT_MAX_TQM_FP_RINGS;\n\n\t\ttqm_rings = ctx->tqm_fp_rings_count + BNXT_MAX_TQM_SP_RINGS;\n\t\tctx_pg = kcalloc(tqm_rings, sizeof(*ctx_pg), GFP_KERNEL);\n\t\tif (!ctx_pg) {\n\t\t\tkfree(ctx);\n\t\t\trc = -ENOMEM;\n\t\t\tgoto ctx_err;\n\t\t}\n\t\tfor (i = 0; i < tqm_rings; i++, ctx_pg++)\n\t\t\tctx->tqm_mem[i] = ctx_pg;\n\t\tbp->ctx = ctx;\n\t} else {\n\t\trc = 0;\n\t}\nctx_err:\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\treturn rc;\n}\n\nstatic void bnxt_hwrm_set_pg_attr(struct bnxt_ring_mem_info *rmem, u8 *pg_attr,\n\t\t\t\t  __le64 *pg_dir)\n{\n\tu8 pg_size = 0;\n\n\tif (!rmem->nr_pages)\n\t\treturn;\n\n\tif (BNXT_PAGE_SHIFT == 13)\n\t\tpg_size = 1 << 4;\n\telse if (BNXT_PAGE_SIZE == 16)\n\t\tpg_size = 2 << 4;\n\n\t*pg_attr = pg_size;\n\tif (rmem->depth >= 1) {\n\t\tif (rmem->depth == 2)\n\t\t\t*pg_attr |= 2;\n\t\telse\n\t\t\t*pg_attr |= 1;\n\t\t*pg_dir = cpu_to_le64(rmem->pg_tbl_map);\n\t} else {\n\t\t*pg_dir = cpu_to_le64(rmem->dma_arr[0]);\n\t}\n}\n\n#define FUNC_BACKING_STORE_CFG_REQ_DFLT_ENABLES\t\t\t\\\n\t(FUNC_BACKING_STORE_CFG_REQ_ENABLES_QP |\t\t\\\n\t FUNC_BACKING_STORE_CFG_REQ_ENABLES_SRQ |\t\t\\\n\t FUNC_BACKING_STORE_CFG_REQ_ENABLES_CQ |\t\t\\\n\t FUNC_BACKING_STORE_CFG_REQ_ENABLES_VNIC |\t\t\\\n\t FUNC_BACKING_STORE_CFG_REQ_ENABLES_STAT)\n\nstatic int bnxt_hwrm_func_backing_store_cfg(struct bnxt *bp, u32 enables)\n{\n\tstruct hwrm_func_backing_store_cfg_input req = {0};\n\tstruct bnxt_ctx_mem_info *ctx = bp->ctx;\n\tstruct bnxt_ctx_pg_info *ctx_pg;\n\tu32 req_len = sizeof(req);\n\t__le32 *num_entries;\n\t__le64 *pg_dir;\n\tu32 flags = 0;\n\tu8 *pg_attr;\n\tu32 ena;\n\tint i;\n\n\tif (!ctx)\n\t\treturn 0;\n\n\tif (req_len > bp->hwrm_max_ext_req_len)\n\t\treq_len = BNXT_BACKING_STORE_CFG_LEGACY_LEN;\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_FUNC_BACKING_STORE_CFG, -1, -1);\n\treq.enables = cpu_to_le32(enables);\n\n\tif (enables & FUNC_BACKING_STORE_CFG_REQ_ENABLES_QP) {\n\t\tctx_pg = &ctx->qp_mem;\n\t\treq.qp_num_entries = cpu_to_le32(ctx_pg->entries);\n\t\treq.qp_num_qp1_entries = cpu_to_le16(ctx->qp_min_qp1_entries);\n\t\treq.qp_num_l2_entries = cpu_to_le16(ctx->qp_max_l2_entries);\n\t\treq.qp_entry_size = cpu_to_le16(ctx->qp_entry_size);\n\t\tbnxt_hwrm_set_pg_attr(&ctx_pg->ring_mem,\n\t\t\t\t      &req.qpc_pg_size_qpc_lvl,\n\t\t\t\t      &req.qpc_page_dir);\n\t}\n\tif (enables & FUNC_BACKING_STORE_CFG_REQ_ENABLES_SRQ) {\n\t\tctx_pg = &ctx->srq_mem;\n\t\treq.srq_num_entries = cpu_to_le32(ctx_pg->entries);\n\t\treq.srq_num_l2_entries = cpu_to_le16(ctx->srq_max_l2_entries);\n\t\treq.srq_entry_size = cpu_to_le16(ctx->srq_entry_size);\n\t\tbnxt_hwrm_set_pg_attr(&ctx_pg->ring_mem,\n\t\t\t\t      &req.srq_pg_size_srq_lvl,\n\t\t\t\t      &req.srq_page_dir);\n\t}\n\tif (enables & FUNC_BACKING_STORE_CFG_REQ_ENABLES_CQ) {\n\t\tctx_pg = &ctx->cq_mem;\n\t\treq.cq_num_entries = cpu_to_le32(ctx_pg->entries);\n\t\treq.cq_num_l2_entries = cpu_to_le16(ctx->cq_max_l2_entries);\n\t\treq.cq_entry_size = cpu_to_le16(ctx->cq_entry_size);\n\t\tbnxt_hwrm_set_pg_attr(&ctx_pg->ring_mem, &req.cq_pg_size_cq_lvl,\n\t\t\t\t      &req.cq_page_dir);\n\t}\n\tif (enables & FUNC_BACKING_STORE_CFG_REQ_ENABLES_VNIC) {\n\t\tctx_pg = &ctx->vnic_mem;\n\t\treq.vnic_num_vnic_entries =\n\t\t\tcpu_to_le16(ctx->vnic_max_vnic_entries);\n\t\treq.vnic_num_ring_table_entries =\n\t\t\tcpu_to_le16(ctx->vnic_max_ring_table_entries);\n\t\treq.vnic_entry_size = cpu_to_le16(ctx->vnic_entry_size);\n\t\tbnxt_hwrm_set_pg_attr(&ctx_pg->ring_mem,\n\t\t\t\t      &req.vnic_pg_size_vnic_lvl,\n\t\t\t\t      &req.vnic_page_dir);\n\t}\n\tif (enables & FUNC_BACKING_STORE_CFG_REQ_ENABLES_STAT) {\n\t\tctx_pg = &ctx->stat_mem;\n\t\treq.stat_num_entries = cpu_to_le32(ctx->stat_max_entries);\n\t\treq.stat_entry_size = cpu_to_le16(ctx->stat_entry_size);\n\t\tbnxt_hwrm_set_pg_attr(&ctx_pg->ring_mem,\n\t\t\t\t      &req.stat_pg_size_stat_lvl,\n\t\t\t\t      &req.stat_page_dir);\n\t}\n\tif (enables & FUNC_BACKING_STORE_CFG_REQ_ENABLES_MRAV) {\n\t\tctx_pg = &ctx->mrav_mem;\n\t\treq.mrav_num_entries = cpu_to_le32(ctx_pg->entries);\n\t\tif (ctx->mrav_num_entries_units)\n\t\t\tflags |=\n\t\t\tFUNC_BACKING_STORE_CFG_REQ_FLAGS_MRAV_RESERVATION_SPLIT;\n\t\treq.mrav_entry_size = cpu_to_le16(ctx->mrav_entry_size);\n\t\tbnxt_hwrm_set_pg_attr(&ctx_pg->ring_mem,\n\t\t\t\t      &req.mrav_pg_size_mrav_lvl,\n\t\t\t\t      &req.mrav_page_dir);\n\t}\n\tif (enables & FUNC_BACKING_STORE_CFG_REQ_ENABLES_TIM) {\n\t\tctx_pg = &ctx->tim_mem;\n\t\treq.tim_num_entries = cpu_to_le32(ctx_pg->entries);\n\t\treq.tim_entry_size = cpu_to_le16(ctx->tim_entry_size);\n\t\tbnxt_hwrm_set_pg_attr(&ctx_pg->ring_mem,\n\t\t\t\t      &req.tim_pg_size_tim_lvl,\n\t\t\t\t      &req.tim_page_dir);\n\t}\n\tfor (i = 0, num_entries = &req.tqm_sp_num_entries,\n\t     pg_attr = &req.tqm_sp_pg_size_tqm_sp_lvl,\n\t     pg_dir = &req.tqm_sp_page_dir,\n\t     ena = FUNC_BACKING_STORE_CFG_REQ_ENABLES_TQM_SP;\n\t     i < BNXT_MAX_TQM_RINGS;\n\t     i++, num_entries++, pg_attr++, pg_dir++, ena <<= 1) {\n\t\tif (!(enables & ena))\n\t\t\tcontinue;\n\n\t\treq.tqm_entry_size = cpu_to_le16(ctx->tqm_entry_size);\n\t\tctx_pg = ctx->tqm_mem[i];\n\t\t*num_entries = cpu_to_le32(ctx_pg->entries);\n\t\tbnxt_hwrm_set_pg_attr(&ctx_pg->ring_mem, pg_attr, pg_dir);\n\t}\n\treq.flags = cpu_to_le32(flags);\n\treturn hwrm_send_message(bp, &req, req_len, HWRM_CMD_TIMEOUT);\n}\n\nstatic int bnxt_alloc_ctx_mem_blk(struct bnxt *bp,\n\t\t\t\t  struct bnxt_ctx_pg_info *ctx_pg)\n{\n\tstruct bnxt_ring_mem_info *rmem = &ctx_pg->ring_mem;\n\n\trmem->page_size = BNXT_PAGE_SIZE;\n\trmem->pg_arr = ctx_pg->ctx_pg_arr;\n\trmem->dma_arr = ctx_pg->ctx_dma_arr;\n\trmem->flags = BNXT_RMEM_VALID_PTE_FLAG;\n\tif (rmem->depth >= 1)\n\t\trmem->flags |= BNXT_RMEM_USE_FULL_PAGE_FLAG;\n\treturn bnxt_alloc_ring(bp, rmem);\n}\n\nstatic int bnxt_alloc_ctx_pg_tbls(struct bnxt *bp,\n\t\t\t\t  struct bnxt_ctx_pg_info *ctx_pg, u32 mem_size,\n\t\t\t\t  u8 depth, struct bnxt_mem_init *mem_init)\n{\n\tstruct bnxt_ring_mem_info *rmem = &ctx_pg->ring_mem;\n\tint rc;\n\n\tif (!mem_size)\n\t\treturn -EINVAL;\n\n\tctx_pg->nr_pages = DIV_ROUND_UP(mem_size, BNXT_PAGE_SIZE);\n\tif (ctx_pg->nr_pages > MAX_CTX_TOTAL_PAGES) {\n\t\tctx_pg->nr_pages = 0;\n\t\treturn -EINVAL;\n\t}\n\tif (ctx_pg->nr_pages > MAX_CTX_PAGES || depth > 1) {\n\t\tint nr_tbls, i;\n\n\t\trmem->depth = 2;\n\t\tctx_pg->ctx_pg_tbl = kcalloc(MAX_CTX_PAGES, sizeof(ctx_pg),\n\t\t\t\t\t     GFP_KERNEL);\n\t\tif (!ctx_pg->ctx_pg_tbl)\n\t\t\treturn -ENOMEM;\n\t\tnr_tbls = DIV_ROUND_UP(ctx_pg->nr_pages, MAX_CTX_PAGES);\n\t\trmem->nr_pages = nr_tbls;\n\t\trc = bnxt_alloc_ctx_mem_blk(bp, ctx_pg);\n\t\tif (rc)\n\t\t\treturn rc;\n\t\tfor (i = 0; i < nr_tbls; i++) {\n\t\t\tstruct bnxt_ctx_pg_info *pg_tbl;\n\n\t\t\tpg_tbl = kzalloc(sizeof(*pg_tbl), GFP_KERNEL);\n\t\t\tif (!pg_tbl)\n\t\t\t\treturn -ENOMEM;\n\t\t\tctx_pg->ctx_pg_tbl[i] = pg_tbl;\n\t\t\trmem = &pg_tbl->ring_mem;\n\t\t\trmem->pg_tbl = ctx_pg->ctx_pg_arr[i];\n\t\t\trmem->pg_tbl_map = ctx_pg->ctx_dma_arr[i];\n\t\t\trmem->depth = 1;\n\t\t\trmem->nr_pages = MAX_CTX_PAGES;\n\t\t\trmem->mem_init = mem_init;\n\t\t\tif (i == (nr_tbls - 1)) {\n\t\t\t\tint rem = ctx_pg->nr_pages % MAX_CTX_PAGES;\n\n\t\t\t\tif (rem)\n\t\t\t\t\trmem->nr_pages = rem;\n\t\t\t}\n\t\t\trc = bnxt_alloc_ctx_mem_blk(bp, pg_tbl);\n\t\t\tif (rc)\n\t\t\t\tbreak;\n\t\t}\n\t} else {\n\t\trmem->nr_pages = DIV_ROUND_UP(mem_size, BNXT_PAGE_SIZE);\n\t\tif (rmem->nr_pages > 1 || depth)\n\t\t\trmem->depth = 1;\n\t\trmem->mem_init = mem_init;\n\t\trc = bnxt_alloc_ctx_mem_blk(bp, ctx_pg);\n\t}\n\treturn rc;\n}\n\nstatic void bnxt_free_ctx_pg_tbls(struct bnxt *bp,\n\t\t\t\t  struct bnxt_ctx_pg_info *ctx_pg)\n{\n\tstruct bnxt_ring_mem_info *rmem = &ctx_pg->ring_mem;\n\n\tif (rmem->depth > 1 || ctx_pg->nr_pages > MAX_CTX_PAGES ||\n\t    ctx_pg->ctx_pg_tbl) {\n\t\tint i, nr_tbls = rmem->nr_pages;\n\n\t\tfor (i = 0; i < nr_tbls; i++) {\n\t\t\tstruct bnxt_ctx_pg_info *pg_tbl;\n\t\t\tstruct bnxt_ring_mem_info *rmem2;\n\n\t\t\tpg_tbl = ctx_pg->ctx_pg_tbl[i];\n\t\t\tif (!pg_tbl)\n\t\t\t\tcontinue;\n\t\t\trmem2 = &pg_tbl->ring_mem;\n\t\t\tbnxt_free_ring(bp, rmem2);\n\t\t\tctx_pg->ctx_pg_arr[i] = NULL;\n\t\t\tkfree(pg_tbl);\n\t\t\tctx_pg->ctx_pg_tbl[i] = NULL;\n\t\t}\n\t\tkfree(ctx_pg->ctx_pg_tbl);\n\t\tctx_pg->ctx_pg_tbl = NULL;\n\t}\n\tbnxt_free_ring(bp, rmem);\n\tctx_pg->nr_pages = 0;\n}\n\nstatic void bnxt_free_ctx_mem(struct bnxt *bp)\n{\n\tstruct bnxt_ctx_mem_info *ctx = bp->ctx;\n\tint i;\n\n\tif (!ctx)\n\t\treturn;\n\n\tif (ctx->tqm_mem[0]) {\n\t\tfor (i = 0; i < ctx->tqm_fp_rings_count + 1; i++)\n\t\t\tbnxt_free_ctx_pg_tbls(bp, ctx->tqm_mem[i]);\n\t\tkfree(ctx->tqm_mem[0]);\n\t\tctx->tqm_mem[0] = NULL;\n\t}\n\n\tbnxt_free_ctx_pg_tbls(bp, &ctx->tim_mem);\n\tbnxt_free_ctx_pg_tbls(bp, &ctx->mrav_mem);\n\tbnxt_free_ctx_pg_tbls(bp, &ctx->stat_mem);\n\tbnxt_free_ctx_pg_tbls(bp, &ctx->vnic_mem);\n\tbnxt_free_ctx_pg_tbls(bp, &ctx->cq_mem);\n\tbnxt_free_ctx_pg_tbls(bp, &ctx->srq_mem);\n\tbnxt_free_ctx_pg_tbls(bp, &ctx->qp_mem);\n\tctx->flags &= ~BNXT_CTX_FLAG_INITED;\n}\n\nstatic int bnxt_alloc_ctx_mem(struct bnxt *bp)\n{\n\tstruct bnxt_ctx_pg_info *ctx_pg;\n\tstruct bnxt_ctx_mem_info *ctx;\n\tstruct bnxt_mem_init *init;\n\tu32 mem_size, ena, entries;\n\tu32 entries_sp, min;\n\tu32 num_mr, num_ah;\n\tu32 extra_srqs = 0;\n\tu32 extra_qps = 0;\n\tu8 pg_lvl = 1;\n\tint i, rc;\n\n\trc = bnxt_hwrm_func_backing_store_qcaps(bp);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"Failed querying context mem capability, rc = %d.\\n\",\n\t\t\t   rc);\n\t\treturn rc;\n\t}\n\tctx = bp->ctx;\n\tif (!ctx || (ctx->flags & BNXT_CTX_FLAG_INITED))\n\t\treturn 0;\n\n\tif ((bp->flags & BNXT_FLAG_ROCE_CAP) && !is_kdump_kernel()) {\n\t\tpg_lvl = 2;\n\t\textra_qps = 65536;\n\t\textra_srqs = 8192;\n\t}\n\n\tctx_pg = &ctx->qp_mem;\n\tctx_pg->entries = ctx->qp_min_qp1_entries + ctx->qp_max_l2_entries +\n\t\t\t  extra_qps;\n\tif (ctx->qp_entry_size) {\n\t\tmem_size = ctx->qp_entry_size * ctx_pg->entries;\n\t\tinit = &ctx->mem_init[BNXT_CTX_MEM_INIT_QP];\n\t\trc = bnxt_alloc_ctx_pg_tbls(bp, ctx_pg, mem_size, pg_lvl, init);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\tctx_pg = &ctx->srq_mem;\n\tctx_pg->entries = ctx->srq_max_l2_entries + extra_srqs;\n\tif (ctx->srq_entry_size) {\n\t\tmem_size = ctx->srq_entry_size * ctx_pg->entries;\n\t\tinit = &ctx->mem_init[BNXT_CTX_MEM_INIT_SRQ];\n\t\trc = bnxt_alloc_ctx_pg_tbls(bp, ctx_pg, mem_size, pg_lvl, init);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\tctx_pg = &ctx->cq_mem;\n\tctx_pg->entries = ctx->cq_max_l2_entries + extra_qps * 2;\n\tif (ctx->cq_entry_size) {\n\t\tmem_size = ctx->cq_entry_size * ctx_pg->entries;\n\t\tinit = &ctx->mem_init[BNXT_CTX_MEM_INIT_CQ];\n\t\trc = bnxt_alloc_ctx_pg_tbls(bp, ctx_pg, mem_size, pg_lvl, init);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\tctx_pg = &ctx->vnic_mem;\n\tctx_pg->entries = ctx->vnic_max_vnic_entries +\n\t\t\t  ctx->vnic_max_ring_table_entries;\n\tif (ctx->vnic_entry_size) {\n\t\tmem_size = ctx->vnic_entry_size * ctx_pg->entries;\n\t\tinit = &ctx->mem_init[BNXT_CTX_MEM_INIT_VNIC];\n\t\trc = bnxt_alloc_ctx_pg_tbls(bp, ctx_pg, mem_size, 1, init);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\tctx_pg = &ctx->stat_mem;\n\tctx_pg->entries = ctx->stat_max_entries;\n\tif (ctx->stat_entry_size) {\n\t\tmem_size = ctx->stat_entry_size * ctx_pg->entries;\n\t\tinit = &ctx->mem_init[BNXT_CTX_MEM_INIT_STAT];\n\t\trc = bnxt_alloc_ctx_pg_tbls(bp, ctx_pg, mem_size, 1, init);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\tena = 0;\n\tif (!(bp->flags & BNXT_FLAG_ROCE_CAP))\n\t\tgoto skip_rdma;\n\n\tctx_pg = &ctx->mrav_mem;\n\t/* 128K extra is needed to accommodate static AH context\n\t * allocation by f/w.\n\t */\n\tnum_mr = 1024 * 256;\n\tnum_ah = 1024 * 128;\n\tctx_pg->entries = num_mr + num_ah;\n\tif (ctx->mrav_entry_size) {\n\t\tmem_size = ctx->mrav_entry_size * ctx_pg->entries;\n\t\tinit = &ctx->mem_init[BNXT_CTX_MEM_INIT_MRAV];\n\t\trc = bnxt_alloc_ctx_pg_tbls(bp, ctx_pg, mem_size, 2, init);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\tena = FUNC_BACKING_STORE_CFG_REQ_ENABLES_MRAV;\n\tif (ctx->mrav_num_entries_units)\n\t\tctx_pg->entries =\n\t\t\t((num_mr / ctx->mrav_num_entries_units) << 16) |\n\t\t\t (num_ah / ctx->mrav_num_entries_units);\n\n\tctx_pg = &ctx->tim_mem;\n\tctx_pg->entries = ctx->qp_mem.entries;\n\tif (ctx->tim_entry_size) {\n\t\tmem_size = ctx->tim_entry_size * ctx_pg->entries;\n\t\trc = bnxt_alloc_ctx_pg_tbls(bp, ctx_pg, mem_size, 1, NULL);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\tena |= FUNC_BACKING_STORE_CFG_REQ_ENABLES_TIM;\n\nskip_rdma:\n\tmin = ctx->tqm_min_entries_per_ring;\n\tentries_sp = ctx->vnic_max_vnic_entries + ctx->qp_max_l2_entries +\n\t\t     2 * (extra_qps + ctx->qp_min_qp1_entries) + min;\n\tentries_sp = roundup(entries_sp, ctx->tqm_entries_multiple);\n\tentries = ctx->qp_max_l2_entries + extra_qps + ctx->qp_min_qp1_entries;\n\tentries = roundup(entries, ctx->tqm_entries_multiple);\n\tentries = clamp_t(u32, entries, min, ctx->tqm_max_entries_per_ring);\n\tfor (i = 0; i < ctx->tqm_fp_rings_count + 1; i++) {\n\t\tctx_pg = ctx->tqm_mem[i];\n\t\tctx_pg->entries = i ? entries : entries_sp;\n\t\tif (ctx->tqm_entry_size) {\n\t\t\tmem_size = ctx->tqm_entry_size * ctx_pg->entries;\n\t\t\trc = bnxt_alloc_ctx_pg_tbls(bp, ctx_pg, mem_size, 1,\n\t\t\t\t\t\t    NULL);\n\t\t\tif (rc)\n\t\t\t\treturn rc;\n\t\t}\n\t\tena |= FUNC_BACKING_STORE_CFG_REQ_ENABLES_TQM_SP << i;\n\t}\n\tena |= FUNC_BACKING_STORE_CFG_REQ_DFLT_ENABLES;\n\trc = bnxt_hwrm_func_backing_store_cfg(bp, ena);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"Failed configuring context mem, rc = %d.\\n\",\n\t\t\t   rc);\n\t\treturn rc;\n\t}\n\tctx->flags |= BNXT_CTX_FLAG_INITED;\n\treturn 0;\n}\n\nint bnxt_hwrm_func_resc_qcaps(struct bnxt *bp, bool all)\n{\n\tstruct hwrm_func_resource_qcaps_output *resp = bp->hwrm_cmd_resp_addr;\n\tstruct hwrm_func_resource_qcaps_input req = {0};\n\tstruct bnxt_hw_resc *hw_resc = &bp->hw_resc;\n\tint rc;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_FUNC_RESOURCE_QCAPS, -1, -1);\n\treq.fid = cpu_to_le16(0xffff);\n\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message_silent(bp, &req, sizeof(req),\n\t\t\t\t       HWRM_CMD_TIMEOUT);\n\tif (rc)\n\t\tgoto hwrm_func_resc_qcaps_exit;\n\n\thw_resc->max_tx_sch_inputs = le16_to_cpu(resp->max_tx_scheduler_inputs);\n\tif (!all)\n\t\tgoto hwrm_func_resc_qcaps_exit;\n\n\thw_resc->min_rsscos_ctxs = le16_to_cpu(resp->min_rsscos_ctx);\n\thw_resc->max_rsscos_ctxs = le16_to_cpu(resp->max_rsscos_ctx);\n\thw_resc->min_cp_rings = le16_to_cpu(resp->min_cmpl_rings);\n\thw_resc->max_cp_rings = le16_to_cpu(resp->max_cmpl_rings);\n\thw_resc->min_tx_rings = le16_to_cpu(resp->min_tx_rings);\n\thw_resc->max_tx_rings = le16_to_cpu(resp->max_tx_rings);\n\thw_resc->min_rx_rings = le16_to_cpu(resp->min_rx_rings);\n\thw_resc->max_rx_rings = le16_to_cpu(resp->max_rx_rings);\n\thw_resc->min_hw_ring_grps = le16_to_cpu(resp->min_hw_ring_grps);\n\thw_resc->max_hw_ring_grps = le16_to_cpu(resp->max_hw_ring_grps);\n\thw_resc->min_l2_ctxs = le16_to_cpu(resp->min_l2_ctxs);\n\thw_resc->max_l2_ctxs = le16_to_cpu(resp->max_l2_ctxs);\n\thw_resc->min_vnics = le16_to_cpu(resp->min_vnics);\n\thw_resc->max_vnics = le16_to_cpu(resp->max_vnics);\n\thw_resc->min_stat_ctxs = le16_to_cpu(resp->min_stat_ctx);\n\thw_resc->max_stat_ctxs = le16_to_cpu(resp->max_stat_ctx);\n\n\tif (bp->flags & BNXT_FLAG_CHIP_P5) {\n\t\tu16 max_msix = le16_to_cpu(resp->max_msix);\n\n\t\thw_resc->max_nqs = max_msix;\n\t\thw_resc->max_hw_ring_grps = hw_resc->max_rx_rings;\n\t}\n\n\tif (BNXT_PF(bp)) {\n\t\tstruct bnxt_pf_info *pf = &bp->pf;\n\n\t\tpf->vf_resv_strategy =\n\t\t\tle16_to_cpu(resp->vf_reservation_strategy);\n\t\tif (pf->vf_resv_strategy > BNXT_VF_RESV_STRATEGY_MINIMAL_STATIC)\n\t\t\tpf->vf_resv_strategy = BNXT_VF_RESV_STRATEGY_MAXIMAL;\n\t}\nhwrm_func_resc_qcaps_exit:\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\treturn rc;\n}\n\nstatic int __bnxt_hwrm_func_qcaps(struct bnxt *bp)\n{\n\tint rc = 0;\n\tstruct hwrm_func_qcaps_input req = {0};\n\tstruct hwrm_func_qcaps_output *resp = bp->hwrm_cmd_resp_addr;\n\tstruct bnxt_hw_resc *hw_resc = &bp->hw_resc;\n\tu32 flags, flags_ext;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_FUNC_QCAPS, -1, -1);\n\treq.fid = cpu_to_le16(0xffff);\n\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (rc)\n\t\tgoto hwrm_func_qcaps_exit;\n\n\tflags = le32_to_cpu(resp->flags);\n\tif (flags & FUNC_QCAPS_RESP_FLAGS_ROCE_V1_SUPPORTED)\n\t\tbp->flags |= BNXT_FLAG_ROCEV1_CAP;\n\tif (flags & FUNC_QCAPS_RESP_FLAGS_ROCE_V2_SUPPORTED)\n\t\tbp->flags |= BNXT_FLAG_ROCEV2_CAP;\n\tif (flags & FUNC_QCAPS_RESP_FLAGS_PCIE_STATS_SUPPORTED)\n\t\tbp->fw_cap |= BNXT_FW_CAP_PCIE_STATS_SUPPORTED;\n\tif (flags & FUNC_QCAPS_RESP_FLAGS_HOT_RESET_CAPABLE)\n\t\tbp->fw_cap |= BNXT_FW_CAP_HOT_RESET;\n\tif (flags & FUNC_QCAPS_RESP_FLAGS_EXT_STATS_SUPPORTED)\n\t\tbp->fw_cap |= BNXT_FW_CAP_EXT_STATS_SUPPORTED;\n\tif (flags &  FUNC_QCAPS_RESP_FLAGS_ERROR_RECOVERY_CAPABLE)\n\t\tbp->fw_cap |= BNXT_FW_CAP_ERROR_RECOVERY;\n\tif (flags & FUNC_QCAPS_RESP_FLAGS_ERR_RECOVER_RELOAD)\n\t\tbp->fw_cap |= BNXT_FW_CAP_ERR_RECOVER_RELOAD;\n\tif (!(flags & FUNC_QCAPS_RESP_FLAGS_VLAN_ACCELERATION_TX_DISABLED))\n\t\tbp->fw_cap |= BNXT_FW_CAP_VLAN_TX_INSERT;\n\n\tflags_ext = le32_to_cpu(resp->flags_ext);\n\tif (flags_ext & FUNC_QCAPS_RESP_FLAGS_EXT_EXT_HW_STATS_SUPPORTED)\n\t\tbp->fw_cap |= BNXT_FW_CAP_EXT_HW_STATS_SUPPORTED;\n\n\tbp->tx_push_thresh = 0;\n\tif ((flags & FUNC_QCAPS_RESP_FLAGS_PUSH_MODE_SUPPORTED) &&\n\t    BNXT_FW_MAJ(bp) > 217)\n\t\tbp->tx_push_thresh = BNXT_TX_PUSH_THRESH;\n\n\thw_resc->max_rsscos_ctxs = le16_to_cpu(resp->max_rsscos_ctx);\n\thw_resc->max_cp_rings = le16_to_cpu(resp->max_cmpl_rings);\n\thw_resc->max_tx_rings = le16_to_cpu(resp->max_tx_rings);\n\thw_resc->max_rx_rings = le16_to_cpu(resp->max_rx_rings);\n\thw_resc->max_hw_ring_grps = le32_to_cpu(resp->max_hw_ring_grps);\n\tif (!hw_resc->max_hw_ring_grps)\n\t\thw_resc->max_hw_ring_grps = hw_resc->max_tx_rings;\n\thw_resc->max_l2_ctxs = le16_to_cpu(resp->max_l2_ctxs);\n\thw_resc->max_vnics = le16_to_cpu(resp->max_vnics);\n\thw_resc->max_stat_ctxs = le16_to_cpu(resp->max_stat_ctx);\n\n\tif (BNXT_PF(bp)) {\n\t\tstruct bnxt_pf_info *pf = &bp->pf;\n\n\t\tpf->fw_fid = le16_to_cpu(resp->fid);\n\t\tpf->port_id = le16_to_cpu(resp->port_id);\n\t\tmemcpy(pf->mac_addr, resp->mac_address, ETH_ALEN);\n\t\tpf->first_vf_id = le16_to_cpu(resp->first_vf_id);\n\t\tpf->max_vfs = le16_to_cpu(resp->max_vfs);\n\t\tpf->max_encap_records = le32_to_cpu(resp->max_encap_records);\n\t\tpf->max_decap_records = le32_to_cpu(resp->max_decap_records);\n\t\tpf->max_tx_em_flows = le32_to_cpu(resp->max_tx_em_flows);\n\t\tpf->max_tx_wm_flows = le32_to_cpu(resp->max_tx_wm_flows);\n\t\tpf->max_rx_em_flows = le32_to_cpu(resp->max_rx_em_flows);\n\t\tpf->max_rx_wm_flows = le32_to_cpu(resp->max_rx_wm_flows);\n\t\tbp->flags &= ~BNXT_FLAG_WOL_CAP;\n\t\tif (flags & FUNC_QCAPS_RESP_FLAGS_WOL_MAGICPKT_SUPPORTED)\n\t\t\tbp->flags |= BNXT_FLAG_WOL_CAP;\n\t} else {\n#ifdef CONFIG_BNXT_SRIOV\n\t\tstruct bnxt_vf_info *vf = &bp->vf;\n\n\t\tvf->fw_fid = le16_to_cpu(resp->fid);\n\t\tmemcpy(vf->mac_addr, resp->mac_address, ETH_ALEN);\n#endif\n\t}\n\nhwrm_func_qcaps_exit:\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\treturn rc;\n}\n\nstatic int bnxt_hwrm_queue_qportcfg(struct bnxt *bp);\n\nstatic int bnxt_hwrm_func_qcaps(struct bnxt *bp)\n{\n\tint rc;\n\n\trc = __bnxt_hwrm_func_qcaps(bp);\n\tif (rc)\n\t\treturn rc;\n\trc = bnxt_hwrm_queue_qportcfg(bp);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"hwrm query qportcfg failure rc: %d\\n\", rc);\n\t\treturn rc;\n\t}\n\tif (bp->hwrm_spec_code >= 0x10803) {\n\t\trc = bnxt_alloc_ctx_mem(bp);\n\t\tif (rc)\n\t\t\treturn rc;\n\t\trc = bnxt_hwrm_func_resc_qcaps(bp, true);\n\t\tif (!rc)\n\t\t\tbp->fw_cap |= BNXT_FW_CAP_NEW_RM;\n\t}\n\treturn 0;\n}\n\nstatic int bnxt_hwrm_cfa_adv_flow_mgnt_qcaps(struct bnxt *bp)\n{\n\tstruct hwrm_cfa_adv_flow_mgnt_qcaps_input req = {0};\n\tstruct hwrm_cfa_adv_flow_mgnt_qcaps_output *resp;\n\tint rc = 0;\n\tu32 flags;\n\n\tif (!(bp->fw_cap & BNXT_FW_CAP_CFA_ADV_FLOW))\n\t\treturn 0;\n\n\tresp = bp->hwrm_cmd_resp_addr;\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_CFA_ADV_FLOW_MGNT_QCAPS, -1, -1);\n\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (rc)\n\t\tgoto hwrm_cfa_adv_qcaps_exit;\n\n\tflags = le32_to_cpu(resp->flags);\n\tif (flags &\n\t    CFA_ADV_FLOW_MGNT_QCAPS_RESP_FLAGS_RFS_RING_TBL_IDX_V2_SUPPORTED)\n\t\tbp->fw_cap |= BNXT_FW_CAP_CFA_RFS_RING_TBL_IDX_V2;\n\nhwrm_cfa_adv_qcaps_exit:\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\treturn rc;\n}\n\nstatic int __bnxt_alloc_fw_health(struct bnxt *bp)\n{\n\tif (bp->fw_health)\n\t\treturn 0;\n\n\tbp->fw_health = kzalloc(sizeof(*bp->fw_health), GFP_KERNEL);\n\tif (!bp->fw_health)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\nstatic int bnxt_alloc_fw_health(struct bnxt *bp)\n{\n\tint rc;\n\n\tif (!(bp->fw_cap & BNXT_FW_CAP_HOT_RESET) &&\n\t    !(bp->fw_cap & BNXT_FW_CAP_ERROR_RECOVERY))\n\t\treturn 0;\n\n\trc = __bnxt_alloc_fw_health(bp);\n\tif (rc) {\n\t\tbp->fw_cap &= ~BNXT_FW_CAP_HOT_RESET;\n\t\tbp->fw_cap &= ~BNXT_FW_CAP_ERROR_RECOVERY;\n\t\treturn rc;\n\t}\n\n\treturn 0;\n}\n\nstatic void __bnxt_map_fw_health_reg(struct bnxt *bp, u32 reg)\n{\n\twritel(reg & BNXT_GRC_BASE_MASK, bp->bar0 +\n\t\t\t\t\t BNXT_GRCPF_REG_WINDOW_BASE_OUT +\n\t\t\t\t\t BNXT_FW_HEALTH_WIN_MAP_OFF);\n}\n\nbool bnxt_is_fw_healthy(struct bnxt *bp)\n{\n\tif (bp->fw_health && bp->fw_health->status_reliable) {\n\t\tu32 fw_status;\n\n\t\tfw_status = bnxt_fw_health_readl(bp, BNXT_FW_HEALTH_REG);\n\t\tif (fw_status && !BNXT_FW_IS_HEALTHY(fw_status))\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic void bnxt_inv_fw_health_reg(struct bnxt *bp)\n{\n\tstruct bnxt_fw_health *fw_health = bp->fw_health;\n\tu32 reg_type;\n\n\tif (!fw_health || !fw_health->status_reliable)\n\t\treturn;\n\n\treg_type = BNXT_FW_HEALTH_REG_TYPE(fw_health->regs[BNXT_FW_HEALTH_REG]);\n\tif (reg_type == BNXT_FW_HEALTH_REG_TYPE_GRC)\n\t\tfw_health->status_reliable = false;\n}\n\nstatic void bnxt_try_map_fw_health_reg(struct bnxt *bp)\n{\n\tvoid __iomem *hs;\n\tu32 status_loc;\n\tu32 reg_type;\n\tu32 sig;\n\n\tif (bp->fw_health)\n\t\tbp->fw_health->status_reliable = false;\n\n\t__bnxt_map_fw_health_reg(bp, HCOMM_STATUS_STRUCT_LOC);\n\ths = bp->bar0 + BNXT_FW_HEALTH_WIN_OFF(HCOMM_STATUS_STRUCT_LOC);\n\n\tsig = readl(hs + offsetof(struct hcomm_status, sig_ver));\n\tif ((sig & HCOMM_STATUS_SIGNATURE_MASK) != HCOMM_STATUS_SIGNATURE_VAL) {\n\t\tif (!bp->chip_num) {\n\t\t\t__bnxt_map_fw_health_reg(bp, BNXT_GRC_REG_BASE);\n\t\t\tbp->chip_num = readl(bp->bar0 +\n\t\t\t\t\t     BNXT_FW_HEALTH_WIN_BASE +\n\t\t\t\t\t     BNXT_GRC_REG_CHIP_NUM);\n\t\t}\n\t\tif (!BNXT_CHIP_P5(bp))\n\t\t\treturn;\n\n\t\tstatus_loc = BNXT_GRC_REG_STATUS_P5 |\n\t\t\t     BNXT_FW_HEALTH_REG_TYPE_BAR0;\n\t} else {\n\t\tstatus_loc = readl(hs + offsetof(struct hcomm_status,\n\t\t\t\t\t\t fw_status_loc));\n\t}\n\n\tif (__bnxt_alloc_fw_health(bp)) {\n\t\tnetdev_warn(bp->dev, \"no memory for firmware status checks\\n\");\n\t\treturn;\n\t}\n\n\tbp->fw_health->regs[BNXT_FW_HEALTH_REG] = status_loc;\n\treg_type = BNXT_FW_HEALTH_REG_TYPE(status_loc);\n\tif (reg_type == BNXT_FW_HEALTH_REG_TYPE_GRC) {\n\t\t__bnxt_map_fw_health_reg(bp, status_loc);\n\t\tbp->fw_health->mapped_regs[BNXT_FW_HEALTH_REG] =\n\t\t\tBNXT_FW_HEALTH_WIN_OFF(status_loc);\n\t}\n\n\tbp->fw_health->status_reliable = true;\n}\n\nstatic int bnxt_map_fw_health_regs(struct bnxt *bp)\n{\n\tstruct bnxt_fw_health *fw_health = bp->fw_health;\n\tu32 reg_base = 0xffffffff;\n\tint i;\n\n\tbp->fw_health->status_reliable = false;\n\t/* Only pre-map the monitoring GRC registers using window 3 */\n\tfor (i = 0; i < 4; i++) {\n\t\tu32 reg = fw_health->regs[i];\n\n\t\tif (BNXT_FW_HEALTH_REG_TYPE(reg) != BNXT_FW_HEALTH_REG_TYPE_GRC)\n\t\t\tcontinue;\n\t\tif (reg_base == 0xffffffff)\n\t\t\treg_base = reg & BNXT_GRC_BASE_MASK;\n\t\tif ((reg & BNXT_GRC_BASE_MASK) != reg_base)\n\t\t\treturn -ERANGE;\n\t\tfw_health->mapped_regs[i] = BNXT_FW_HEALTH_WIN_OFF(reg);\n\t}\n\tbp->fw_health->status_reliable = true;\n\tif (reg_base == 0xffffffff)\n\t\treturn 0;\n\n\t__bnxt_map_fw_health_reg(bp, reg_base);\n\treturn 0;\n}\n\nstatic int bnxt_hwrm_error_recovery_qcfg(struct bnxt *bp)\n{\n\tstruct hwrm_error_recovery_qcfg_output *resp = bp->hwrm_cmd_resp_addr;\n\tstruct bnxt_fw_health *fw_health = bp->fw_health;\n\tstruct hwrm_error_recovery_qcfg_input req = {0};\n\tint rc, i;\n\n\tif (!(bp->fw_cap & BNXT_FW_CAP_ERROR_RECOVERY))\n\t\treturn 0;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_ERROR_RECOVERY_QCFG, -1, -1);\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (rc)\n\t\tgoto err_recovery_out;\n\tfw_health->flags = le32_to_cpu(resp->flags);\n\tif ((fw_health->flags & ERROR_RECOVERY_QCFG_RESP_FLAGS_CO_CPU) &&\n\t    !(bp->fw_cap & BNXT_FW_CAP_KONG_MB_CHNL)) {\n\t\trc = -EINVAL;\n\t\tgoto err_recovery_out;\n\t}\n\tfw_health->polling_dsecs = le32_to_cpu(resp->driver_polling_freq);\n\tfw_health->master_func_wait_dsecs =\n\t\tle32_to_cpu(resp->master_func_wait_period);\n\tfw_health->normal_func_wait_dsecs =\n\t\tle32_to_cpu(resp->normal_func_wait_period);\n\tfw_health->post_reset_wait_dsecs =\n\t\tle32_to_cpu(resp->master_func_wait_period_after_reset);\n\tfw_health->post_reset_max_wait_dsecs =\n\t\tle32_to_cpu(resp->max_bailout_time_after_reset);\n\tfw_health->regs[BNXT_FW_HEALTH_REG] =\n\t\tle32_to_cpu(resp->fw_health_status_reg);\n\tfw_health->regs[BNXT_FW_HEARTBEAT_REG] =\n\t\tle32_to_cpu(resp->fw_heartbeat_reg);\n\tfw_health->regs[BNXT_FW_RESET_CNT_REG] =\n\t\tle32_to_cpu(resp->fw_reset_cnt_reg);\n\tfw_health->regs[BNXT_FW_RESET_INPROG_REG] =\n\t\tle32_to_cpu(resp->reset_inprogress_reg);\n\tfw_health->fw_reset_inprog_reg_mask =\n\t\tle32_to_cpu(resp->reset_inprogress_reg_mask);\n\tfw_health->fw_reset_seq_cnt = resp->reg_array_cnt;\n\tif (fw_health->fw_reset_seq_cnt >= 16) {\n\t\trc = -EINVAL;\n\t\tgoto err_recovery_out;\n\t}\n\tfor (i = 0; i < fw_health->fw_reset_seq_cnt; i++) {\n\t\tfw_health->fw_reset_seq_regs[i] =\n\t\t\tle32_to_cpu(resp->reset_reg[i]);\n\t\tfw_health->fw_reset_seq_vals[i] =\n\t\t\tle32_to_cpu(resp->reset_reg_val[i]);\n\t\tfw_health->fw_reset_seq_delay_msec[i] =\n\t\t\tresp->delay_after_reset[i];\n\t}\nerr_recovery_out:\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\tif (!rc)\n\t\trc = bnxt_map_fw_health_regs(bp);\n\tif (rc)\n\t\tbp->fw_cap &= ~BNXT_FW_CAP_ERROR_RECOVERY;\n\treturn rc;\n}\n\nstatic int bnxt_hwrm_func_reset(struct bnxt *bp)\n{\n\tstruct hwrm_func_reset_input req = {0};\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_FUNC_RESET, -1, -1);\n\treq.enables = 0;\n\n\treturn hwrm_send_message(bp, &req, sizeof(req), HWRM_RESET_TIMEOUT);\n}\n\nstatic void bnxt_nvm_cfg_ver_get(struct bnxt *bp)\n{\n\tstruct hwrm_nvm_get_dev_info_output nvm_info;\n\n\tif (!bnxt_hwrm_nvm_get_dev_info(bp, &nvm_info))\n\t\tsnprintf(bp->nvm_cfg_ver, FW_VER_STR_LEN, \"%d.%d.%d\",\n\t\t\t nvm_info.nvm_cfg_ver_maj, nvm_info.nvm_cfg_ver_min,\n\t\t\t nvm_info.nvm_cfg_ver_upd);\n}\n\nstatic int bnxt_hwrm_queue_qportcfg(struct bnxt *bp)\n{\n\tint rc = 0;\n\tstruct hwrm_queue_qportcfg_input req = {0};\n\tstruct hwrm_queue_qportcfg_output *resp = bp->hwrm_cmd_resp_addr;\n\tu8 i, j, *qptr;\n\tbool no_rdma;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_QUEUE_QPORTCFG, -1, -1);\n\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (rc)\n\t\tgoto qportcfg_exit;\n\n\tif (!resp->max_configurable_queues) {\n\t\trc = -EINVAL;\n\t\tgoto qportcfg_exit;\n\t}\n\tbp->max_tc = resp->max_configurable_queues;\n\tbp->max_lltc = resp->max_configurable_lossless_queues;\n\tif (bp->max_tc > BNXT_MAX_QUEUE)\n\t\tbp->max_tc = BNXT_MAX_QUEUE;\n\n\tno_rdma = !(bp->flags & BNXT_FLAG_ROCE_CAP);\n\tqptr = &resp->queue_id0;\n\tfor (i = 0, j = 0; i < bp->max_tc; i++) {\n\t\tbp->q_info[j].queue_id = *qptr;\n\t\tbp->q_ids[i] = *qptr++;\n\t\tbp->q_info[j].queue_profile = *qptr++;\n\t\tbp->tc_to_qidx[j] = j;\n\t\tif (!BNXT_CNPQ(bp->q_info[j].queue_profile) ||\n\t\t    (no_rdma && BNXT_PF(bp)))\n\t\t\tj++;\n\t}\n\tbp->max_q = bp->max_tc;\n\tbp->max_tc = max_t(u8, j, 1);\n\n\tif (resp->queue_cfg_info & QUEUE_QPORTCFG_RESP_QUEUE_CFG_INFO_ASYM_CFG)\n\t\tbp->max_tc = 1;\n\n\tif (bp->max_lltc > bp->max_tc)\n\t\tbp->max_lltc = bp->max_tc;\n\nqportcfg_exit:\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\treturn rc;\n}\n\nstatic int __bnxt_hwrm_ver_get(struct bnxt *bp, bool silent)\n{\n\tstruct hwrm_ver_get_input req = {0};\n\tint rc;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_VER_GET, -1, -1);\n\treq.hwrm_intf_maj = HWRM_VERSION_MAJOR;\n\treq.hwrm_intf_min = HWRM_VERSION_MINOR;\n\treq.hwrm_intf_upd = HWRM_VERSION_UPDATE;\n\n\trc = bnxt_hwrm_do_send_msg(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT,\n\t\t\t\t   silent);\n\treturn rc;\n}\n\nstatic int bnxt_hwrm_ver_get(struct bnxt *bp)\n{\n\tstruct hwrm_ver_get_output *resp = bp->hwrm_cmd_resp_addr;\n\tu16 fw_maj, fw_min, fw_bld, fw_rsv;\n\tu32 dev_caps_cfg, hwrm_ver;\n\tint rc, len;\n\n\tbp->hwrm_max_req_len = HWRM_MAX_REQ_LEN;\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = __bnxt_hwrm_ver_get(bp, false);\n\tif (rc)\n\t\tgoto hwrm_ver_get_exit;\n\n\tmemcpy(&bp->ver_resp, resp, sizeof(struct hwrm_ver_get_output));\n\n\tbp->hwrm_spec_code = resp->hwrm_intf_maj_8b << 16 |\n\t\t\t     resp->hwrm_intf_min_8b << 8 |\n\t\t\t     resp->hwrm_intf_upd_8b;\n\tif (resp->hwrm_intf_maj_8b < 1) {\n\t\tnetdev_warn(bp->dev, \"HWRM interface %d.%d.%d is older than 1.0.0.\\n\",\n\t\t\t    resp->hwrm_intf_maj_8b, resp->hwrm_intf_min_8b,\n\t\t\t    resp->hwrm_intf_upd_8b);\n\t\tnetdev_warn(bp->dev, \"Please update firmware with HWRM interface 1.0.0 or newer.\\n\");\n\t}\n\n\thwrm_ver = HWRM_VERSION_MAJOR << 16 | HWRM_VERSION_MINOR << 8 |\n\t\t\tHWRM_VERSION_UPDATE;\n\n\tif (bp->hwrm_spec_code > hwrm_ver)\n\t\tsnprintf(bp->hwrm_ver_supp, FW_VER_STR_LEN, \"%d.%d.%d\",\n\t\t\t HWRM_VERSION_MAJOR, HWRM_VERSION_MINOR,\n\t\t\t HWRM_VERSION_UPDATE);\n\telse\n\t\tsnprintf(bp->hwrm_ver_supp, FW_VER_STR_LEN, \"%d.%d.%d\",\n\t\t\t resp->hwrm_intf_maj_8b, resp->hwrm_intf_min_8b,\n\t\t\t resp->hwrm_intf_upd_8b);\n\n\tfw_maj = le16_to_cpu(resp->hwrm_fw_major);\n\tif (bp->hwrm_spec_code > 0x10803 && fw_maj) {\n\t\tfw_min = le16_to_cpu(resp->hwrm_fw_minor);\n\t\tfw_bld = le16_to_cpu(resp->hwrm_fw_build);\n\t\tfw_rsv = le16_to_cpu(resp->hwrm_fw_patch);\n\t\tlen = FW_VER_STR_LEN;\n\t} else {\n\t\tfw_maj = resp->hwrm_fw_maj_8b;\n\t\tfw_min = resp->hwrm_fw_min_8b;\n\t\tfw_bld = resp->hwrm_fw_bld_8b;\n\t\tfw_rsv = resp->hwrm_fw_rsvd_8b;\n\t\tlen = BC_HWRM_STR_LEN;\n\t}\n\tbp->fw_ver_code = BNXT_FW_VER_CODE(fw_maj, fw_min, fw_bld, fw_rsv);\n\tsnprintf(bp->fw_ver_str, len, \"%d.%d.%d.%d\", fw_maj, fw_min, fw_bld,\n\t\t fw_rsv);\n\n\tif (strlen(resp->active_pkg_name)) {\n\t\tint fw_ver_len = strlen(bp->fw_ver_str);\n\n\t\tsnprintf(bp->fw_ver_str + fw_ver_len,\n\t\t\t FW_VER_STR_LEN - fw_ver_len - 1, \"/pkg %s\",\n\t\t\t resp->active_pkg_name);\n\t\tbp->fw_cap |= BNXT_FW_CAP_PKG_VER;\n\t}\n\n\tbp->hwrm_cmd_timeout = le16_to_cpu(resp->def_req_timeout);\n\tif (!bp->hwrm_cmd_timeout)\n\t\tbp->hwrm_cmd_timeout = DFLT_HWRM_CMD_TIMEOUT;\n\n\tif (resp->hwrm_intf_maj_8b >= 1) {\n\t\tbp->hwrm_max_req_len = le16_to_cpu(resp->max_req_win_len);\n\t\tbp->hwrm_max_ext_req_len = le16_to_cpu(resp->max_ext_req_len);\n\t}\n\tif (bp->hwrm_max_ext_req_len < HWRM_MAX_REQ_LEN)\n\t\tbp->hwrm_max_ext_req_len = HWRM_MAX_REQ_LEN;\n\n\tbp->chip_num = le16_to_cpu(resp->chip_num);\n\tbp->chip_rev = resp->chip_rev;\n\tif (bp->chip_num == CHIP_NUM_58700 && !resp->chip_rev &&\n\t    !resp->chip_metal)\n\t\tbp->flags |= BNXT_FLAG_CHIP_NITRO_A0;\n\n\tdev_caps_cfg = le32_to_cpu(resp->dev_caps_cfg);\n\tif ((dev_caps_cfg & VER_GET_RESP_DEV_CAPS_CFG_SHORT_CMD_SUPPORTED) &&\n\t    (dev_caps_cfg & VER_GET_RESP_DEV_CAPS_CFG_SHORT_CMD_REQUIRED))\n\t\tbp->fw_cap |= BNXT_FW_CAP_SHORT_CMD;\n\n\tif (dev_caps_cfg & VER_GET_RESP_DEV_CAPS_CFG_KONG_MB_CHNL_SUPPORTED)\n\t\tbp->fw_cap |= BNXT_FW_CAP_KONG_MB_CHNL;\n\n\tif (dev_caps_cfg &\n\t    VER_GET_RESP_DEV_CAPS_CFG_FLOW_HANDLE_64BIT_SUPPORTED)\n\t\tbp->fw_cap |= BNXT_FW_CAP_OVS_64BIT_HANDLE;\n\n\tif (dev_caps_cfg &\n\t    VER_GET_RESP_DEV_CAPS_CFG_TRUSTED_VF_SUPPORTED)\n\t\tbp->fw_cap |= BNXT_FW_CAP_TRUSTED_VF;\n\n\tif (dev_caps_cfg &\n\t    VER_GET_RESP_DEV_CAPS_CFG_CFA_ADV_FLOW_MGNT_SUPPORTED)\n\t\tbp->fw_cap |= BNXT_FW_CAP_CFA_ADV_FLOW;\n\nhwrm_ver_get_exit:\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\treturn rc;\n}\n\nint bnxt_hwrm_fw_set_time(struct bnxt *bp)\n{\n\tstruct hwrm_fw_set_time_input req = {0};\n\tstruct tm tm;\n\ttime64_t now = ktime_get_real_seconds();\n\n\tif ((BNXT_VF(bp) && bp->hwrm_spec_code < 0x10901) ||\n\t    bp->hwrm_spec_code < 0x10400)\n\t\treturn -EOPNOTSUPP;\n\n\ttime64_to_tm(now, 0, &tm);\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_FW_SET_TIME, -1, -1);\n\treq.year = cpu_to_le16(1900 + tm.tm_year);\n\treq.month = 1 + tm.tm_mon;\n\treq.day = tm.tm_mday;\n\treq.hour = tm.tm_hour;\n\treq.minute = tm.tm_min;\n\treq.second = tm.tm_sec;\n\treturn hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n}\n\nstatic void bnxt_add_one_ctr(u64 hw, u64 *sw, u64 mask)\n{\n\tu64 sw_tmp;\n\n\thw &= mask;\n\tsw_tmp = (*sw & ~mask) | hw;\n\tif (hw < (*sw & mask))\n\t\tsw_tmp += mask + 1;\n\tWRITE_ONCE(*sw, sw_tmp);\n}\n\nstatic void __bnxt_accumulate_stats(__le64 *hw_stats, u64 *sw_stats, u64 *masks,\n\t\t\t\t    int count, bool ignore_zero)\n{\n\tint i;\n\n\tfor (i = 0; i < count; i++) {\n\t\tu64 hw = le64_to_cpu(READ_ONCE(hw_stats[i]));\n\n\t\tif (ignore_zero && !hw)\n\t\t\tcontinue;\n\n\t\tif (masks[i] == -1ULL)\n\t\t\tsw_stats[i] = hw;\n\t\telse\n\t\t\tbnxt_add_one_ctr(hw, &sw_stats[i], masks[i]);\n\t}\n}\n\nstatic void bnxt_accumulate_stats(struct bnxt_stats_mem *stats)\n{\n\tif (!stats->hw_stats)\n\t\treturn;\n\n\t__bnxt_accumulate_stats(stats->hw_stats, stats->sw_stats,\n\t\t\t\tstats->hw_masks, stats->len / 8, false);\n}\n\nstatic void bnxt_accumulate_all_stats(struct bnxt *bp)\n{\n\tstruct bnxt_stats_mem *ring0_stats;\n\tbool ignore_zero = false;\n\tint i;\n\n\t/* Chip bug.  Counter intermittently becomes 0. */\n\tif (bp->flags & BNXT_FLAG_CHIP_P5)\n\t\tignore_zero = true;\n\n\tfor (i = 0; i < bp->cp_nr_rings; i++) {\n\t\tstruct bnxt_napi *bnapi = bp->bnapi[i];\n\t\tstruct bnxt_cp_ring_info *cpr;\n\t\tstruct bnxt_stats_mem *stats;\n\n\t\tcpr = &bnapi->cp_ring;\n\t\tstats = &cpr->stats;\n\t\tif (!i)\n\t\t\tring0_stats = stats;\n\t\t__bnxt_accumulate_stats(stats->hw_stats, stats->sw_stats,\n\t\t\t\t\tring0_stats->hw_masks,\n\t\t\t\t\tring0_stats->len / 8, ignore_zero);\n\t}\n\tif (bp->flags & BNXT_FLAG_PORT_STATS) {\n\t\tstruct bnxt_stats_mem *stats = &bp->port_stats;\n\t\t__le64 *hw_stats = stats->hw_stats;\n\t\tu64 *sw_stats = stats->sw_stats;\n\t\tu64 *masks = stats->hw_masks;\n\t\tint cnt;\n\n\t\tcnt = sizeof(struct rx_port_stats) / 8;\n\t\t__bnxt_accumulate_stats(hw_stats, sw_stats, masks, cnt, false);\n\n\t\thw_stats += BNXT_TX_PORT_STATS_BYTE_OFFSET / 8;\n\t\tsw_stats += BNXT_TX_PORT_STATS_BYTE_OFFSET / 8;\n\t\tmasks += BNXT_TX_PORT_STATS_BYTE_OFFSET / 8;\n\t\tcnt = sizeof(struct tx_port_stats) / 8;\n\t\t__bnxt_accumulate_stats(hw_stats, sw_stats, masks, cnt, false);\n\t}\n\tif (bp->flags & BNXT_FLAG_PORT_STATS_EXT) {\n\t\tbnxt_accumulate_stats(&bp->rx_port_stats_ext);\n\t\tbnxt_accumulate_stats(&bp->tx_port_stats_ext);\n\t}\n}\n\nstatic int bnxt_hwrm_port_qstats(struct bnxt *bp, u8 flags)\n{\n\tstruct bnxt_pf_info *pf = &bp->pf;\n\tstruct hwrm_port_qstats_input req = {0};\n\n\tif (!(bp->flags & BNXT_FLAG_PORT_STATS))\n\t\treturn 0;\n\n\tif (flags && !(bp->fw_cap & BNXT_FW_CAP_EXT_HW_STATS_SUPPORTED))\n\t\treturn -EOPNOTSUPP;\n\n\treq.flags = flags;\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_PORT_QSTATS, -1, -1);\n\treq.port_id = cpu_to_le16(pf->port_id);\n\treq.tx_stat_host_addr = cpu_to_le64(bp->port_stats.hw_stats_map +\n\t\t\t\t\t    BNXT_TX_PORT_STATS_BYTE_OFFSET);\n\treq.rx_stat_host_addr = cpu_to_le64(bp->port_stats.hw_stats_map);\n\treturn hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n}\n\nstatic int bnxt_hwrm_port_qstats_ext(struct bnxt *bp, u8 flags)\n{\n\tstruct hwrm_port_qstats_ext_output *resp = bp->hwrm_cmd_resp_addr;\n\tstruct hwrm_queue_pri2cos_qcfg_input req2 = {0};\n\tstruct hwrm_port_qstats_ext_input req = {0};\n\tstruct bnxt_pf_info *pf = &bp->pf;\n\tu32 tx_stat_size;\n\tint rc;\n\n\tif (!(bp->flags & BNXT_FLAG_PORT_STATS_EXT))\n\t\treturn 0;\n\n\tif (flags && !(bp->fw_cap & BNXT_FW_CAP_EXT_HW_STATS_SUPPORTED))\n\t\treturn -EOPNOTSUPP;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_PORT_QSTATS_EXT, -1, -1);\n\treq.flags = flags;\n\treq.port_id = cpu_to_le16(pf->port_id);\n\treq.rx_stat_size = cpu_to_le16(sizeof(struct rx_port_stats_ext));\n\treq.rx_stat_host_addr = cpu_to_le64(bp->rx_port_stats_ext.hw_stats_map);\n\ttx_stat_size = bp->tx_port_stats_ext.hw_stats ?\n\t\t       sizeof(struct tx_port_stats_ext) : 0;\n\treq.tx_stat_size = cpu_to_le16(tx_stat_size);\n\treq.tx_stat_host_addr = cpu_to_le64(bp->tx_port_stats_ext.hw_stats_map);\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (!rc) {\n\t\tbp->fw_rx_stats_ext_size = le16_to_cpu(resp->rx_stat_size) / 8;\n\t\tbp->fw_tx_stats_ext_size = tx_stat_size ?\n\t\t\tle16_to_cpu(resp->tx_stat_size) / 8 : 0;\n\t} else {\n\t\tbp->fw_rx_stats_ext_size = 0;\n\t\tbp->fw_tx_stats_ext_size = 0;\n\t}\n\tif (flags)\n\t\tgoto qstats_done;\n\n\tif (bp->fw_tx_stats_ext_size <=\n\t    offsetof(struct tx_port_stats_ext, pfc_pri0_tx_duration_us) / 8) {\n\t\tmutex_unlock(&bp->hwrm_cmd_lock);\n\t\tbp->pri2cos_valid = 0;\n\t\treturn rc;\n\t}\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req2, HWRM_QUEUE_PRI2COS_QCFG, -1, -1);\n\treq2.flags = cpu_to_le32(QUEUE_PRI2COS_QCFG_REQ_FLAGS_IVLAN);\n\n\trc = _hwrm_send_message(bp, &req2, sizeof(req2), HWRM_CMD_TIMEOUT);\n\tif (!rc) {\n\t\tstruct hwrm_queue_pri2cos_qcfg_output *resp2;\n\t\tu8 *pri2cos;\n\t\tint i, j;\n\n\t\tresp2 = bp->hwrm_cmd_resp_addr;\n\t\tpri2cos = &resp2->pri0_cos_queue_id;\n\t\tfor (i = 0; i < 8; i++) {\n\t\t\tu8 queue_id = pri2cos[i];\n\t\t\tu8 queue_idx;\n\n\t\t\t/* Per port queue IDs start from 0, 10, 20, etc */\n\t\t\tqueue_idx = queue_id % 10;\n\t\t\tif (queue_idx > BNXT_MAX_QUEUE) {\n\t\t\t\tbp->pri2cos_valid = false;\n\t\t\t\tgoto qstats_done;\n\t\t\t}\n\t\t\tfor (j = 0; j < bp->max_q; j++) {\n\t\t\t\tif (bp->q_ids[j] == queue_id)\n\t\t\t\t\tbp->pri2cos_idx[i] = queue_idx;\n\t\t\t}\n\t\t}\n\t\tbp->pri2cos_valid = 1;\n\t}\nqstats_done:\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\treturn rc;\n}\n\nstatic void bnxt_hwrm_free_tunnel_ports(struct bnxt *bp)\n{\n\tif (bp->vxlan_fw_dst_port_id != INVALID_HW_RING_ID)\n\t\tbnxt_hwrm_tunnel_dst_port_free(\n\t\t\tbp, TUNNEL_DST_PORT_FREE_REQ_TUNNEL_TYPE_VXLAN);\n\tif (bp->nge_fw_dst_port_id != INVALID_HW_RING_ID)\n\t\tbnxt_hwrm_tunnel_dst_port_free(\n\t\t\tbp, TUNNEL_DST_PORT_FREE_REQ_TUNNEL_TYPE_GENEVE);\n}\n\nstatic int bnxt_set_tpa(struct bnxt *bp, bool set_tpa)\n{\n\tint rc, i;\n\tu32 tpa_flags = 0;\n\n\tif (set_tpa)\n\t\ttpa_flags = bp->flags & BNXT_FLAG_TPA;\n\telse if (BNXT_NO_FW_ACCESS(bp))\n\t\treturn 0;\n\tfor (i = 0; i < bp->nr_vnics; i++) {\n\t\trc = bnxt_hwrm_vnic_set_tpa(bp, i, tpa_flags);\n\t\tif (rc) {\n\t\t\tnetdev_err(bp->dev, \"hwrm vnic set tpa failure rc for vnic %d: %x\\n\",\n\t\t\t\t   i, rc);\n\t\t\treturn rc;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic void bnxt_hwrm_clear_vnic_rss(struct bnxt *bp)\n{\n\tint i;\n\n\tfor (i = 0; i < bp->nr_vnics; i++)\n\t\tbnxt_hwrm_vnic_set_rss(bp, i, false);\n}\n\nstatic void bnxt_clear_vnic(struct bnxt *bp)\n{\n\tif (!bp->vnic_info)\n\t\treturn;\n\n\tbnxt_hwrm_clear_vnic_filter(bp);\n\tif (!(bp->flags & BNXT_FLAG_CHIP_P5)) {\n\t\t/* clear all RSS setting before free vnic ctx */\n\t\tbnxt_hwrm_clear_vnic_rss(bp);\n\t\tbnxt_hwrm_vnic_ctx_free(bp);\n\t}\n\t/* before free the vnic, undo the vnic tpa settings */\n\tif (bp->flags & BNXT_FLAG_TPA)\n\t\tbnxt_set_tpa(bp, false);\n\tbnxt_hwrm_vnic_free(bp);\n\tif (bp->flags & BNXT_FLAG_CHIP_P5)\n\t\tbnxt_hwrm_vnic_ctx_free(bp);\n}\n\nstatic void bnxt_hwrm_resource_free(struct bnxt *bp, bool close_path,\n\t\t\t\t    bool irq_re_init)\n{\n\tbnxt_clear_vnic(bp);\n\tbnxt_hwrm_ring_free(bp, close_path);\n\tbnxt_hwrm_ring_grp_free(bp);\n\tif (irq_re_init) {\n\t\tbnxt_hwrm_stat_ctx_free(bp);\n\t\tbnxt_hwrm_free_tunnel_ports(bp);\n\t}\n}\n\nstatic int bnxt_hwrm_set_br_mode(struct bnxt *bp, u16 br_mode)\n{\n\tstruct hwrm_func_cfg_input req = {0};\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_FUNC_CFG, -1, -1);\n\treq.fid = cpu_to_le16(0xffff);\n\treq.enables = cpu_to_le32(FUNC_CFG_REQ_ENABLES_EVB_MODE);\n\tif (br_mode == BRIDGE_MODE_VEB)\n\t\treq.evb_mode = FUNC_CFG_REQ_EVB_MODE_VEB;\n\telse if (br_mode == BRIDGE_MODE_VEPA)\n\t\treq.evb_mode = FUNC_CFG_REQ_EVB_MODE_VEPA;\n\telse\n\t\treturn -EINVAL;\n\treturn hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n}\n\nstatic int bnxt_hwrm_set_cache_line_size(struct bnxt *bp, int size)\n{\n\tstruct hwrm_func_cfg_input req = {0};\n\n\tif (BNXT_VF(bp) || bp->hwrm_spec_code < 0x10803)\n\t\treturn 0;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_FUNC_CFG, -1, -1);\n\treq.fid = cpu_to_le16(0xffff);\n\treq.enables = cpu_to_le32(FUNC_CFG_REQ_ENABLES_CACHE_LINESIZE);\n\treq.options = FUNC_CFG_REQ_OPTIONS_CACHE_LINESIZE_SIZE_64;\n\tif (size == 128)\n\t\treq.options = FUNC_CFG_REQ_OPTIONS_CACHE_LINESIZE_SIZE_128;\n\n\treturn hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n}\n\nstatic int __bnxt_setup_vnic(struct bnxt *bp, u16 vnic_id)\n{\n\tstruct bnxt_vnic_info *vnic = &bp->vnic_info[vnic_id];\n\tint rc;\n\n\tif (vnic->flags & BNXT_VNIC_RFS_NEW_RSS_FLAG)\n\t\tgoto skip_rss_ctx;\n\n\t/* allocate context for vnic */\n\trc = bnxt_hwrm_vnic_ctx_alloc(bp, vnic_id, 0);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"hwrm vnic %d alloc failure rc: %x\\n\",\n\t\t\t   vnic_id, rc);\n\t\tgoto vnic_setup_err;\n\t}\n\tbp->rsscos_nr_ctxs++;\n\n\tif (BNXT_CHIP_TYPE_NITRO_A0(bp)) {\n\t\trc = bnxt_hwrm_vnic_ctx_alloc(bp, vnic_id, 1);\n\t\tif (rc) {\n\t\t\tnetdev_err(bp->dev, \"hwrm vnic %d cos ctx alloc failure rc: %x\\n\",\n\t\t\t\t   vnic_id, rc);\n\t\t\tgoto vnic_setup_err;\n\t\t}\n\t\tbp->rsscos_nr_ctxs++;\n\t}\n\nskip_rss_ctx:\n\t/* configure default vnic, ring grp */\n\trc = bnxt_hwrm_vnic_cfg(bp, vnic_id);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"hwrm vnic %d cfg failure rc: %x\\n\",\n\t\t\t   vnic_id, rc);\n\t\tgoto vnic_setup_err;\n\t}\n\n\t/* Enable RSS hashing on vnic */\n\trc = bnxt_hwrm_vnic_set_rss(bp, vnic_id, true);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"hwrm vnic %d set rss failure rc: %x\\n\",\n\t\t\t   vnic_id, rc);\n\t\tgoto vnic_setup_err;\n\t}\n\n\tif (bp->flags & BNXT_FLAG_AGG_RINGS) {\n\t\trc = bnxt_hwrm_vnic_set_hds(bp, vnic_id);\n\t\tif (rc) {\n\t\t\tnetdev_err(bp->dev, \"hwrm vnic %d set hds failure rc: %x\\n\",\n\t\t\t\t   vnic_id, rc);\n\t\t}\n\t}\n\nvnic_setup_err:\n\treturn rc;\n}\n\nstatic int __bnxt_setup_vnic_p5(struct bnxt *bp, u16 vnic_id)\n{\n\tint rc, i, nr_ctxs;\n\n\tnr_ctxs = bnxt_get_nr_rss_ctxs(bp, bp->rx_nr_rings);\n\tfor (i = 0; i < nr_ctxs; i++) {\n\t\trc = bnxt_hwrm_vnic_ctx_alloc(bp, vnic_id, i);\n\t\tif (rc) {\n\t\t\tnetdev_err(bp->dev, \"hwrm vnic %d ctx %d alloc failure rc: %x\\n\",\n\t\t\t\t   vnic_id, i, rc);\n\t\t\tbreak;\n\t\t}\n\t\tbp->rsscos_nr_ctxs++;\n\t}\n\tif (i < nr_ctxs)\n\t\treturn -ENOMEM;\n\n\trc = bnxt_hwrm_vnic_set_rss_p5(bp, vnic_id, true);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"hwrm vnic %d set rss failure rc: %d\\n\",\n\t\t\t   vnic_id, rc);\n\t\treturn rc;\n\t}\n\trc = bnxt_hwrm_vnic_cfg(bp, vnic_id);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"hwrm vnic %d cfg failure rc: %x\\n\",\n\t\t\t   vnic_id, rc);\n\t\treturn rc;\n\t}\n\tif (bp->flags & BNXT_FLAG_AGG_RINGS) {\n\t\trc = bnxt_hwrm_vnic_set_hds(bp, vnic_id);\n\t\tif (rc) {\n\t\t\tnetdev_err(bp->dev, \"hwrm vnic %d set hds failure rc: %x\\n\",\n\t\t\t\t   vnic_id, rc);\n\t\t}\n\t}\n\treturn rc;\n}\n\nstatic int bnxt_setup_vnic(struct bnxt *bp, u16 vnic_id)\n{\n\tif (bp->flags & BNXT_FLAG_CHIP_P5)\n\t\treturn __bnxt_setup_vnic_p5(bp, vnic_id);\n\telse\n\t\treturn __bnxt_setup_vnic(bp, vnic_id);\n}\n\nstatic int bnxt_alloc_rfs_vnics(struct bnxt *bp)\n{\n#ifdef CONFIG_RFS_ACCEL\n\tint i, rc = 0;\n\n\tif (bp->flags & BNXT_FLAG_CHIP_P5)\n\t\treturn 0;\n\n\tfor (i = 0; i < bp->rx_nr_rings; i++) {\n\t\tstruct bnxt_vnic_info *vnic;\n\t\tu16 vnic_id = i + 1;\n\t\tu16 ring_id = i;\n\n\t\tif (vnic_id >= bp->nr_vnics)\n\t\t\tbreak;\n\n\t\tvnic = &bp->vnic_info[vnic_id];\n\t\tvnic->flags |= BNXT_VNIC_RFS_FLAG;\n\t\tif (bp->flags & BNXT_FLAG_NEW_RSS_CAP)\n\t\t\tvnic->flags |= BNXT_VNIC_RFS_NEW_RSS_FLAG;\n\t\trc = bnxt_hwrm_vnic_alloc(bp, vnic_id, ring_id, 1);\n\t\tif (rc) {\n\t\t\tnetdev_err(bp->dev, \"hwrm vnic %d alloc failure rc: %x\\n\",\n\t\t\t\t   vnic_id, rc);\n\t\t\tbreak;\n\t\t}\n\t\trc = bnxt_setup_vnic(bp, vnic_id);\n\t\tif (rc)\n\t\t\tbreak;\n\t}\n\treturn rc;\n#else\n\treturn 0;\n#endif\n}\n\n/* Allow PF and VF with default VLAN to be in promiscuous mode */\nstatic bool bnxt_promisc_ok(struct bnxt *bp)\n{\n#ifdef CONFIG_BNXT_SRIOV\n\tif (BNXT_VF(bp) && !bp->vf.vlan)\n\t\treturn false;\n#endif\n\treturn true;\n}\n\nstatic int bnxt_setup_nitroa0_vnic(struct bnxt *bp)\n{\n\tunsigned int rc = 0;\n\n\trc = bnxt_hwrm_vnic_alloc(bp, 1, bp->rx_nr_rings - 1, 1);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"Cannot allocate special vnic for NS2 A0: %x\\n\",\n\t\t\t   rc);\n\t\treturn rc;\n\t}\n\n\trc = bnxt_hwrm_vnic_cfg(bp, 1);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"Cannot allocate special vnic for NS2 A0: %x\\n\",\n\t\t\t   rc);\n\t\treturn rc;\n\t}\n\treturn rc;\n}\n\nstatic int bnxt_cfg_rx_mode(struct bnxt *);\nstatic bool bnxt_mc_list_updated(struct bnxt *, u32 *);\n\nstatic int bnxt_init_chip(struct bnxt *bp, bool irq_re_init)\n{\n\tstruct bnxt_vnic_info *vnic = &bp->vnic_info[0];\n\tint rc = 0;\n\tunsigned int rx_nr_rings = bp->rx_nr_rings;\n\n\tif (irq_re_init) {\n\t\trc = bnxt_hwrm_stat_ctx_alloc(bp);\n\t\tif (rc) {\n\t\t\tnetdev_err(bp->dev, \"hwrm stat ctx alloc failure rc: %x\\n\",\n\t\t\t\t   rc);\n\t\t\tgoto err_out;\n\t\t}\n\t}\n\n\trc = bnxt_hwrm_ring_alloc(bp);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"hwrm ring alloc failure rc: %x\\n\", rc);\n\t\tgoto err_out;\n\t}\n\n\trc = bnxt_hwrm_ring_grp_alloc(bp);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"hwrm_ring_grp alloc failure: %x\\n\", rc);\n\t\tgoto err_out;\n\t}\n\n\tif (BNXT_CHIP_TYPE_NITRO_A0(bp))\n\t\trx_nr_rings--;\n\n\t/* default vnic 0 */\n\trc = bnxt_hwrm_vnic_alloc(bp, 0, 0, rx_nr_rings);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"hwrm vnic alloc failure rc: %x\\n\", rc);\n\t\tgoto err_out;\n\t}\n\n\trc = bnxt_setup_vnic(bp, 0);\n\tif (rc)\n\t\tgoto err_out;\n\n\tif (bp->flags & BNXT_FLAG_RFS) {\n\t\trc = bnxt_alloc_rfs_vnics(bp);\n\t\tif (rc)\n\t\t\tgoto err_out;\n\t}\n\n\tif (bp->flags & BNXT_FLAG_TPA) {\n\t\trc = bnxt_set_tpa(bp, true);\n\t\tif (rc)\n\t\t\tgoto err_out;\n\t}\n\n\tif (BNXT_VF(bp))\n\t\tbnxt_update_vf_mac(bp);\n\n\t/* Filter for default vnic 0 */\n\trc = bnxt_hwrm_set_vnic_filter(bp, 0, 0, bp->dev->dev_addr);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"HWRM vnic filter failure rc: %x\\n\", rc);\n\t\tgoto err_out;\n\t}\n\tvnic->uc_filter_count = 1;\n\n\tvnic->rx_mask = 0;\n\tif (bp->dev->flags & IFF_BROADCAST)\n\t\tvnic->rx_mask |= CFA_L2_SET_RX_MASK_REQ_MASK_BCAST;\n\n\tif ((bp->dev->flags & IFF_PROMISC) && bnxt_promisc_ok(bp))\n\t\tvnic->rx_mask |= CFA_L2_SET_RX_MASK_REQ_MASK_PROMISCUOUS;\n\n\tif (bp->dev->flags & IFF_ALLMULTI) {\n\t\tvnic->rx_mask |= CFA_L2_SET_RX_MASK_REQ_MASK_ALL_MCAST;\n\t\tvnic->mc_list_count = 0;\n\t} else {\n\t\tu32 mask = 0;\n\n\t\tbnxt_mc_list_updated(bp, &mask);\n\t\tvnic->rx_mask |= mask;\n\t}\n\n\trc = bnxt_cfg_rx_mode(bp);\n\tif (rc)\n\t\tgoto err_out;\n\n\trc = bnxt_hwrm_set_coal(bp);\n\tif (rc)\n\t\tnetdev_warn(bp->dev, \"HWRM set coalescing failure rc: %x\\n\",\n\t\t\t\trc);\n\n\tif (BNXT_CHIP_TYPE_NITRO_A0(bp)) {\n\t\trc = bnxt_setup_nitroa0_vnic(bp);\n\t\tif (rc)\n\t\t\tnetdev_err(bp->dev, \"Special vnic setup failure for NS2 A0 rc: %x\\n\",\n\t\t\t\t   rc);\n\t}\n\n\tif (BNXT_VF(bp)) {\n\t\tbnxt_hwrm_func_qcfg(bp);\n\t\tnetdev_update_features(bp->dev);\n\t}\n\n\treturn 0;\n\nerr_out:\n\tbnxt_hwrm_resource_free(bp, 0, true);\n\n\treturn rc;\n}\n\nstatic int bnxt_shutdown_nic(struct bnxt *bp, bool irq_re_init)\n{\n\tbnxt_hwrm_resource_free(bp, 1, irq_re_init);\n\treturn 0;\n}\n\nstatic int bnxt_init_nic(struct bnxt *bp, bool irq_re_init)\n{\n\tbnxt_init_cp_rings(bp);\n\tbnxt_init_rx_rings(bp);\n\tbnxt_init_tx_rings(bp);\n\tbnxt_init_ring_grps(bp, irq_re_init);\n\tbnxt_init_vnics(bp);\n\n\treturn bnxt_init_chip(bp, irq_re_init);\n}\n\nstatic int bnxt_set_real_num_queues(struct bnxt *bp)\n{\n\tint rc;\n\tstruct net_device *dev = bp->dev;\n\n\trc = netif_set_real_num_tx_queues(dev, bp->tx_nr_rings -\n\t\t\t\t\t  bp->tx_nr_rings_xdp);\n\tif (rc)\n\t\treturn rc;\n\n\trc = netif_set_real_num_rx_queues(dev, bp->rx_nr_rings);\n\tif (rc)\n\t\treturn rc;\n\n#ifdef CONFIG_RFS_ACCEL\n\tif (bp->flags & BNXT_FLAG_RFS)\n\t\tdev->rx_cpu_rmap = alloc_irq_cpu_rmap(bp->rx_nr_rings);\n#endif\n\n\treturn rc;\n}\n\nstatic int bnxt_trim_rings(struct bnxt *bp, int *rx, int *tx, int max,\n\t\t\t   bool shared)\n{\n\tint _rx = *rx, _tx = *tx;\n\n\tif (shared) {\n\t\t*rx = min_t(int, _rx, max);\n\t\t*tx = min_t(int, _tx, max);\n\t} else {\n\t\tif (max < 2)\n\t\t\treturn -ENOMEM;\n\n\t\twhile (_rx + _tx > max) {\n\t\t\tif (_rx > _tx && _rx > 1)\n\t\t\t\t_rx--;\n\t\t\telse if (_tx > 1)\n\t\t\t\t_tx--;\n\t\t}\n\t\t*rx = _rx;\n\t\t*tx = _tx;\n\t}\n\treturn 0;\n}\n\nstatic void bnxt_setup_msix(struct bnxt *bp)\n{\n\tconst int len = sizeof(bp->irq_tbl[0].name);\n\tstruct net_device *dev = bp->dev;\n\tint tcs, i;\n\n\ttcs = netdev_get_num_tc(dev);\n\tif (tcs) {\n\t\tint i, off, count;\n\n\t\tfor (i = 0; i < tcs; i++) {\n\t\t\tcount = bp->tx_nr_rings_per_tc;\n\t\t\toff = i * count;\n\t\t\tnetdev_set_tc_queue(dev, i, count, off);\n\t\t}\n\t}\n\n\tfor (i = 0; i < bp->cp_nr_rings; i++) {\n\t\tint map_idx = bnxt_cp_num_to_irq_num(bp, i);\n\t\tchar *attr;\n\n\t\tif (bp->flags & BNXT_FLAG_SHARED_RINGS)\n\t\t\tattr = \"TxRx\";\n\t\telse if (i < bp->rx_nr_rings)\n\t\t\tattr = \"rx\";\n\t\telse\n\t\t\tattr = \"tx\";\n\n\t\tsnprintf(bp->irq_tbl[map_idx].name, len, \"%s-%s-%d\", dev->name,\n\t\t\t attr, i);\n\t\tbp->irq_tbl[map_idx].handler = bnxt_msix;\n\t}\n}\n\nstatic void bnxt_setup_inta(struct bnxt *bp)\n{\n\tconst int len = sizeof(bp->irq_tbl[0].name);\n\n\tif (netdev_get_num_tc(bp->dev))\n\t\tnetdev_reset_tc(bp->dev);\n\n\tsnprintf(bp->irq_tbl[0].name, len, \"%s-%s-%d\", bp->dev->name, \"TxRx\",\n\t\t 0);\n\tbp->irq_tbl[0].handler = bnxt_inta;\n}\n\nstatic int bnxt_init_int_mode(struct bnxt *bp);\n\nstatic int bnxt_setup_int_mode(struct bnxt *bp)\n{\n\tint rc;\n\n\tif (!bp->irq_tbl) {\n\t\trc = bnxt_init_int_mode(bp);\n\t\tif (rc || !bp->irq_tbl)\n\t\t\treturn rc ?: -ENODEV;\n\t}\n\n\tif (bp->flags & BNXT_FLAG_USING_MSIX)\n\t\tbnxt_setup_msix(bp);\n\telse\n\t\tbnxt_setup_inta(bp);\n\n\trc = bnxt_set_real_num_queues(bp);\n\treturn rc;\n}\n\n#ifdef CONFIG_RFS_ACCEL\nstatic unsigned int bnxt_get_max_func_rss_ctxs(struct bnxt *bp)\n{\n\treturn bp->hw_resc.max_rsscos_ctxs;\n}\n\nstatic unsigned int bnxt_get_max_func_vnics(struct bnxt *bp)\n{\n\treturn bp->hw_resc.max_vnics;\n}\n#endif\n\nunsigned int bnxt_get_max_func_stat_ctxs(struct bnxt *bp)\n{\n\treturn bp->hw_resc.max_stat_ctxs;\n}\n\nunsigned int bnxt_get_max_func_cp_rings(struct bnxt *bp)\n{\n\treturn bp->hw_resc.max_cp_rings;\n}\n\nstatic unsigned int bnxt_get_max_func_cp_rings_for_en(struct bnxt *bp)\n{\n\tunsigned int cp = bp->hw_resc.max_cp_rings;\n\n\tif (!(bp->flags & BNXT_FLAG_CHIP_P5))\n\t\tcp -= bnxt_get_ulp_msix_num(bp);\n\n\treturn cp;\n}\n\nstatic unsigned int bnxt_get_max_func_irqs(struct bnxt *bp)\n{\n\tstruct bnxt_hw_resc *hw_resc = &bp->hw_resc;\n\n\tif (bp->flags & BNXT_FLAG_CHIP_P5)\n\t\treturn min_t(unsigned int, hw_resc->max_irqs, hw_resc->max_nqs);\n\n\treturn min_t(unsigned int, hw_resc->max_irqs, hw_resc->max_cp_rings);\n}\n\nstatic void bnxt_set_max_func_irqs(struct bnxt *bp, unsigned int max_irqs)\n{\n\tbp->hw_resc.max_irqs = max_irqs;\n}\n\nunsigned int bnxt_get_avail_cp_rings_for_en(struct bnxt *bp)\n{\n\tunsigned int cp;\n\n\tcp = bnxt_get_max_func_cp_rings_for_en(bp);\n\tif (bp->flags & BNXT_FLAG_CHIP_P5)\n\t\treturn cp - bp->rx_nr_rings - bp->tx_nr_rings;\n\telse\n\t\treturn cp - bp->cp_nr_rings;\n}\n\nunsigned int bnxt_get_avail_stat_ctxs_for_en(struct bnxt *bp)\n{\n\treturn bnxt_get_max_func_stat_ctxs(bp) - bnxt_get_func_stat_ctxs(bp);\n}\n\nint bnxt_get_avail_msix(struct bnxt *bp, int num)\n{\n\tint max_cp = bnxt_get_max_func_cp_rings(bp);\n\tint max_irq = bnxt_get_max_func_irqs(bp);\n\tint total_req = bp->cp_nr_rings + num;\n\tint max_idx, avail_msix;\n\n\tmax_idx = bp->total_irqs;\n\tif (!(bp->flags & BNXT_FLAG_CHIP_P5))\n\t\tmax_idx = min_t(int, bp->total_irqs, max_cp);\n\tavail_msix = max_idx - bp->cp_nr_rings;\n\tif (!BNXT_NEW_RM(bp) || avail_msix >= num)\n\t\treturn avail_msix;\n\n\tif (max_irq < total_req) {\n\t\tnum = max_irq - bp->cp_nr_rings;\n\t\tif (num <= 0)\n\t\t\treturn 0;\n\t}\n\treturn num;\n}\n\nstatic int bnxt_get_num_msix(struct bnxt *bp)\n{\n\tif (!BNXT_NEW_RM(bp))\n\t\treturn bnxt_get_max_func_irqs(bp);\n\n\treturn bnxt_nq_rings_in_use(bp);\n}\n\nstatic int bnxt_init_msix(struct bnxt *bp)\n{\n\tint i, total_vecs, max, rc = 0, min = 1, ulp_msix;\n\tstruct msix_entry *msix_ent;\n\n\ttotal_vecs = bnxt_get_num_msix(bp);\n\tmax = bnxt_get_max_func_irqs(bp);\n\tif (total_vecs > max)\n\t\ttotal_vecs = max;\n\n\tif (!total_vecs)\n\t\treturn 0;\n\n\tmsix_ent = kcalloc(total_vecs, sizeof(struct msix_entry), GFP_KERNEL);\n\tif (!msix_ent)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < total_vecs; i++) {\n\t\tmsix_ent[i].entry = i;\n\t\tmsix_ent[i].vector = 0;\n\t}\n\n\tif (!(bp->flags & BNXT_FLAG_SHARED_RINGS))\n\t\tmin = 2;\n\n\ttotal_vecs = pci_enable_msix_range(bp->pdev, msix_ent, min, total_vecs);\n\tulp_msix = bnxt_get_ulp_msix_num(bp);\n\tif (total_vecs < 0 || total_vecs < ulp_msix) {\n\t\trc = -ENODEV;\n\t\tgoto msix_setup_exit;\n\t}\n\n\tbp->irq_tbl = kcalloc(total_vecs, sizeof(struct bnxt_irq), GFP_KERNEL);\n\tif (bp->irq_tbl) {\n\t\tfor (i = 0; i < total_vecs; i++)\n\t\t\tbp->irq_tbl[i].vector = msix_ent[i].vector;\n\n\t\tbp->total_irqs = total_vecs;\n\t\t/* Trim rings based upon num of vectors allocated */\n\t\trc = bnxt_trim_rings(bp, &bp->rx_nr_rings, &bp->tx_nr_rings,\n\t\t\t\t     total_vecs - ulp_msix, min == 1);\n\t\tif (rc)\n\t\t\tgoto msix_setup_exit;\n\n\t\tbp->cp_nr_rings = (min == 1) ?\n\t\t\t\t  max_t(int, bp->tx_nr_rings, bp->rx_nr_rings) :\n\t\t\t\t  bp->tx_nr_rings + bp->rx_nr_rings;\n\n\t} else {\n\t\trc = -ENOMEM;\n\t\tgoto msix_setup_exit;\n\t}\n\tbp->flags |= BNXT_FLAG_USING_MSIX;\n\tkfree(msix_ent);\n\treturn 0;\n\nmsix_setup_exit:\n\tnetdev_err(bp->dev, \"bnxt_init_msix err: %x\\n\", rc);\n\tkfree(bp->irq_tbl);\n\tbp->irq_tbl = NULL;\n\tpci_disable_msix(bp->pdev);\n\tkfree(msix_ent);\n\treturn rc;\n}\n\nstatic int bnxt_init_inta(struct bnxt *bp)\n{\n\tbp->irq_tbl = kzalloc(sizeof(struct bnxt_irq), GFP_KERNEL);\n\tif (!bp->irq_tbl)\n\t\treturn -ENOMEM;\n\n\tbp->total_irqs = 1;\n\tbp->rx_nr_rings = 1;\n\tbp->tx_nr_rings = 1;\n\tbp->cp_nr_rings = 1;\n\tbp->flags |= BNXT_FLAG_SHARED_RINGS;\n\tbp->irq_tbl[0].vector = bp->pdev->irq;\n\treturn 0;\n}\n\nstatic int bnxt_init_int_mode(struct bnxt *bp)\n{\n\tint rc = -ENODEV;\n\n\tif (bp->flags & BNXT_FLAG_MSIX_CAP)\n\t\trc = bnxt_init_msix(bp);\n\n\tif (!(bp->flags & BNXT_FLAG_USING_MSIX) && BNXT_PF(bp)) {\n\t\t/* fallback to INTA */\n\t\trc = bnxt_init_inta(bp);\n\t}\n\treturn rc;\n}\n\nstatic void bnxt_clear_int_mode(struct bnxt *bp)\n{\n\tif (bp->flags & BNXT_FLAG_USING_MSIX)\n\t\tpci_disable_msix(bp->pdev);\n\n\tkfree(bp->irq_tbl);\n\tbp->irq_tbl = NULL;\n\tbp->flags &= ~BNXT_FLAG_USING_MSIX;\n}\n\nint bnxt_reserve_rings(struct bnxt *bp, bool irq_re_init)\n{\n\tint tcs = netdev_get_num_tc(bp->dev);\n\tbool irq_cleared = false;\n\tint rc;\n\n\tif (!bnxt_need_reserve_rings(bp))\n\t\treturn 0;\n\n\tif (irq_re_init && BNXT_NEW_RM(bp) &&\n\t    bnxt_get_num_msix(bp) != bp->total_irqs) {\n\t\tbnxt_ulp_irq_stop(bp);\n\t\tbnxt_clear_int_mode(bp);\n\t\tirq_cleared = true;\n\t}\n\trc = __bnxt_reserve_rings(bp);\n\tif (irq_cleared) {\n\t\tif (!rc)\n\t\t\trc = bnxt_init_int_mode(bp);\n\t\tbnxt_ulp_irq_restart(bp, rc);\n\t}\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"ring reservation/IRQ init failure rc: %d\\n\", rc);\n\t\treturn rc;\n\t}\n\tif (tcs && (bp->tx_nr_rings_per_tc * tcs != bp->tx_nr_rings)) {\n\t\tnetdev_err(bp->dev, \"tx ring reservation failure\\n\");\n\t\tnetdev_reset_tc(bp->dev);\n\t\tbp->tx_nr_rings_per_tc = bp->tx_nr_rings;\n\t\treturn -ENOMEM;\n\t}\n\treturn 0;\n}\n\nstatic void bnxt_free_irq(struct bnxt *bp)\n{\n\tstruct bnxt_irq *irq;\n\tint i;\n\n#ifdef CONFIG_RFS_ACCEL\n\tfree_irq_cpu_rmap(bp->dev->rx_cpu_rmap);\n\tbp->dev->rx_cpu_rmap = NULL;\n#endif\n\tif (!bp->irq_tbl || !bp->bnapi)\n\t\treturn;\n\n\tfor (i = 0; i < bp->cp_nr_rings; i++) {\n\t\tint map_idx = bnxt_cp_num_to_irq_num(bp, i);\n\n\t\tirq = &bp->irq_tbl[map_idx];\n\t\tif (irq->requested) {\n\t\t\tif (irq->have_cpumask) {\n\t\t\t\tirq_set_affinity_hint(irq->vector, NULL);\n\t\t\t\tfree_cpumask_var(irq->cpu_mask);\n\t\t\t\tirq->have_cpumask = 0;\n\t\t\t}\n\t\t\tfree_irq(irq->vector, bp->bnapi[i]);\n\t\t}\n\n\t\tirq->requested = 0;\n\t}\n}\n\nstatic int bnxt_request_irq(struct bnxt *bp)\n{\n\tint i, j, rc = 0;\n\tunsigned long flags = 0;\n#ifdef CONFIG_RFS_ACCEL\n\tstruct cpu_rmap *rmap;\n#endif\n\n\trc = bnxt_setup_int_mode(bp);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"bnxt_setup_int_mode err: %x\\n\",\n\t\t\t   rc);\n\t\treturn rc;\n\t}\n#ifdef CONFIG_RFS_ACCEL\n\trmap = bp->dev->rx_cpu_rmap;\n#endif\n\tif (!(bp->flags & BNXT_FLAG_USING_MSIX))\n\t\tflags = IRQF_SHARED;\n\n\tfor (i = 0, j = 0; i < bp->cp_nr_rings; i++) {\n\t\tint map_idx = bnxt_cp_num_to_irq_num(bp, i);\n\t\tstruct bnxt_irq *irq = &bp->irq_tbl[map_idx];\n\n#ifdef CONFIG_RFS_ACCEL\n\t\tif (rmap && bp->bnapi[i]->rx_ring) {\n\t\t\trc = irq_cpu_rmap_add(rmap, irq->vector);\n\t\t\tif (rc)\n\t\t\t\tnetdev_warn(bp->dev, \"failed adding irq rmap for ring %d\\n\",\n\t\t\t\t\t    j);\n\t\t\tj++;\n\t\t}\n#endif\n\t\trc = request_irq(irq->vector, irq->handler, flags, irq->name,\n\t\t\t\t bp->bnapi[i]);\n\t\tif (rc)\n\t\t\tbreak;\n\n\t\tirq->requested = 1;\n\n\t\tif (zalloc_cpumask_var(&irq->cpu_mask, GFP_KERNEL)) {\n\t\t\tint numa_node = dev_to_node(&bp->pdev->dev);\n\n\t\t\tirq->have_cpumask = 1;\n\t\t\tcpumask_set_cpu(cpumask_local_spread(i, numa_node),\n\t\t\t\t\tirq->cpu_mask);\n\t\t\trc = irq_set_affinity_hint(irq->vector, irq->cpu_mask);\n\t\t\tif (rc) {\n\t\t\t\tnetdev_warn(bp->dev,\n\t\t\t\t\t    \"Set affinity failed, IRQ = %d\\n\",\n\t\t\t\t\t    irq->vector);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\treturn rc;\n}\n\nstatic void bnxt_del_napi(struct bnxt *bp)\n{\n\tint i;\n\n\tif (!bp->bnapi)\n\t\treturn;\n\n\tfor (i = 0; i < bp->cp_nr_rings; i++) {\n\t\tstruct bnxt_napi *bnapi = bp->bnapi[i];\n\n\t\t__netif_napi_del(&bnapi->napi);\n\t}\n\t/* We called __netif_napi_del(), we need\n\t * to respect an RCU grace period before freeing napi structures.\n\t */\n\tsynchronize_net();\n}\n\nstatic void bnxt_init_napi(struct bnxt *bp)\n{\n\tint i;\n\tunsigned int cp_nr_rings = bp->cp_nr_rings;\n\tstruct bnxt_napi *bnapi;\n\n\tif (bp->flags & BNXT_FLAG_USING_MSIX) {\n\t\tint (*poll_fn)(struct napi_struct *, int) = bnxt_poll;\n\n\t\tif (bp->flags & BNXT_FLAG_CHIP_P5)\n\t\t\tpoll_fn = bnxt_poll_p5;\n\t\telse if (BNXT_CHIP_TYPE_NITRO_A0(bp))\n\t\t\tcp_nr_rings--;\n\t\tfor (i = 0; i < cp_nr_rings; i++) {\n\t\t\tbnapi = bp->bnapi[i];\n\t\t\tnetif_napi_add(bp->dev, &bnapi->napi, poll_fn, 64);\n\t\t}\n\t\tif (BNXT_CHIP_TYPE_NITRO_A0(bp)) {\n\t\t\tbnapi = bp->bnapi[cp_nr_rings];\n\t\t\tnetif_napi_add(bp->dev, &bnapi->napi,\n\t\t\t\t       bnxt_poll_nitroa0, 64);\n\t\t}\n\t} else {\n\t\tbnapi = bp->bnapi[0];\n\t\tnetif_napi_add(bp->dev, &bnapi->napi, bnxt_poll, 64);\n\t}\n}\n\nstatic void bnxt_disable_napi(struct bnxt *bp)\n{\n\tint i;\n\n\tif (!bp->bnapi ||\n\t    test_and_set_bit(BNXT_STATE_NAPI_DISABLED, &bp->state))\n\t\treturn;\n\n\tfor (i = 0; i < bp->cp_nr_rings; i++) {\n\t\tstruct bnxt_cp_ring_info *cpr = &bp->bnapi[i]->cp_ring;\n\n\t\tif (bp->bnapi[i]->rx_ring)\n\t\t\tcancel_work_sync(&cpr->dim.work);\n\n\t\tnapi_disable(&bp->bnapi[i]->napi);\n\t}\n}\n\nstatic void bnxt_enable_napi(struct bnxt *bp)\n{\n\tint i;\n\n\tclear_bit(BNXT_STATE_NAPI_DISABLED, &bp->state);\n\tfor (i = 0; i < bp->cp_nr_rings; i++) {\n\t\tstruct bnxt_napi *bnapi = bp->bnapi[i];\n\t\tstruct bnxt_cp_ring_info *cpr;\n\n\t\tcpr = &bnapi->cp_ring;\n\t\tif (bnapi->in_reset)\n\t\t\tcpr->sw_stats.rx.rx_resets++;\n\t\tbnapi->in_reset = false;\n\n\t\tif (bnapi->rx_ring) {\n\t\t\tINIT_WORK(&cpr->dim.work, bnxt_dim_work);\n\t\t\tcpr->dim.mode = DIM_CQ_PERIOD_MODE_START_FROM_EQE;\n\t\t}\n\t\tnapi_enable(&bnapi->napi);\n\t}\n}\n\nvoid bnxt_tx_disable(struct bnxt *bp)\n{\n\tint i;\n\tstruct bnxt_tx_ring_info *txr;\n\n\tif (bp->tx_ring) {\n\t\tfor (i = 0; i < bp->tx_nr_rings; i++) {\n\t\t\ttxr = &bp->tx_ring[i];\n\t\t\ttxr->dev_state = BNXT_DEV_STATE_CLOSING;\n\t\t}\n\t}\n\t/* Drop carrier first to prevent TX timeout */\n\tnetif_carrier_off(bp->dev);\n\t/* Stop all TX queues */\n\tnetif_tx_disable(bp->dev);\n}\n\nvoid bnxt_tx_enable(struct bnxt *bp)\n{\n\tint i;\n\tstruct bnxt_tx_ring_info *txr;\n\n\tfor (i = 0; i < bp->tx_nr_rings; i++) {\n\t\ttxr = &bp->tx_ring[i];\n\t\ttxr->dev_state = 0;\n\t}\n\tnetif_tx_wake_all_queues(bp->dev);\n\tif (bp->link_info.link_up)\n\t\tnetif_carrier_on(bp->dev);\n}\n\nstatic char *bnxt_report_fec(struct bnxt_link_info *link_info)\n{\n\tu8 active_fec = link_info->active_fec_sig_mode &\n\t\t\tPORT_PHY_QCFG_RESP_ACTIVE_FEC_MASK;\n\n\tswitch (active_fec) {\n\tdefault:\n\tcase PORT_PHY_QCFG_RESP_ACTIVE_FEC_FEC_NONE_ACTIVE:\n\t\treturn \"None\";\n\tcase PORT_PHY_QCFG_RESP_ACTIVE_FEC_FEC_CLAUSE74_ACTIVE:\n\t\treturn \"Clause 74 BaseR\";\n\tcase PORT_PHY_QCFG_RESP_ACTIVE_FEC_FEC_CLAUSE91_ACTIVE:\n\t\treturn \"Clause 91 RS(528,514)\";\n\tcase PORT_PHY_QCFG_RESP_ACTIVE_FEC_FEC_RS544_1XN_ACTIVE:\n\t\treturn \"Clause 91 RS544_1XN\";\n\tcase PORT_PHY_QCFG_RESP_ACTIVE_FEC_FEC_RS544_IEEE_ACTIVE:\n\t\treturn \"Clause 91 RS(544,514)\";\n\tcase PORT_PHY_QCFG_RESP_ACTIVE_FEC_FEC_RS272_1XN_ACTIVE:\n\t\treturn \"Clause 91 RS272_1XN\";\n\tcase PORT_PHY_QCFG_RESP_ACTIVE_FEC_FEC_RS272_IEEE_ACTIVE:\n\t\treturn \"Clause 91 RS(272,257)\";\n\t}\n}\n\nstatic void bnxt_report_link(struct bnxt *bp)\n{\n\tif (bp->link_info.link_up) {\n\t\tconst char *duplex;\n\t\tconst char *flow_ctrl;\n\t\tu32 speed;\n\t\tu16 fec;\n\n\t\tnetif_carrier_on(bp->dev);\n\t\tspeed = bnxt_fw_to_ethtool_speed(bp->link_info.link_speed);\n\t\tif (speed == SPEED_UNKNOWN) {\n\t\t\tnetdev_info(bp->dev, \"NIC Link is Up, speed unknown\\n\");\n\t\t\treturn;\n\t\t}\n\t\tif (bp->link_info.duplex == BNXT_LINK_DUPLEX_FULL)\n\t\t\tduplex = \"full\";\n\t\telse\n\t\t\tduplex = \"half\";\n\t\tif (bp->link_info.pause == BNXT_LINK_PAUSE_BOTH)\n\t\t\tflow_ctrl = \"ON - receive & transmit\";\n\t\telse if (bp->link_info.pause == BNXT_LINK_PAUSE_TX)\n\t\t\tflow_ctrl = \"ON - transmit\";\n\t\telse if (bp->link_info.pause == BNXT_LINK_PAUSE_RX)\n\t\t\tflow_ctrl = \"ON - receive\";\n\t\telse\n\t\t\tflow_ctrl = \"none\";\n\t\tnetdev_info(bp->dev, \"NIC Link is Up, %u Mbps %s duplex, Flow control: %s\\n\",\n\t\t\t    speed, duplex, flow_ctrl);\n\t\tif (bp->flags & BNXT_FLAG_EEE_CAP)\n\t\t\tnetdev_info(bp->dev, \"EEE is %s\\n\",\n\t\t\t\t    bp->eee.eee_active ? \"active\" :\n\t\t\t\t\t\t\t \"not active\");\n\t\tfec = bp->link_info.fec_cfg;\n\t\tif (!(fec & PORT_PHY_QCFG_RESP_FEC_CFG_FEC_NONE_SUPPORTED))\n\t\t\tnetdev_info(bp->dev, \"FEC autoneg %s encoding: %s\\n\",\n\t\t\t\t    (fec & BNXT_FEC_AUTONEG) ? \"on\" : \"off\",\n\t\t\t\t    bnxt_report_fec(&bp->link_info));\n\t} else {\n\t\tnetif_carrier_off(bp->dev);\n\t\tnetdev_err(bp->dev, \"NIC Link is Down\\n\");\n\t}\n}\n\nstatic bool bnxt_phy_qcaps_no_speed(struct hwrm_port_phy_qcaps_output *resp)\n{\n\tif (!resp->supported_speeds_auto_mode &&\n\t    !resp->supported_speeds_force_mode &&\n\t    !resp->supported_pam4_speeds_auto_mode &&\n\t    !resp->supported_pam4_speeds_force_mode)\n\t\treturn true;\n\treturn false;\n}\n\nstatic int bnxt_hwrm_phy_qcaps(struct bnxt *bp)\n{\n\tint rc = 0;\n\tstruct hwrm_port_phy_qcaps_input req = {0};\n\tstruct hwrm_port_phy_qcaps_output *resp = bp->hwrm_cmd_resp_addr;\n\tstruct bnxt_link_info *link_info = &bp->link_info;\n\n\tbp->flags &= ~BNXT_FLAG_EEE_CAP;\n\tif (bp->test_info)\n\t\tbp->test_info->flags &= ~(BNXT_TEST_FL_EXT_LPBK |\n\t\t\t\t\t  BNXT_TEST_FL_AN_PHY_LPBK);\n\tif (bp->hwrm_spec_code < 0x10201)\n\t\treturn 0;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_PORT_PHY_QCAPS, -1, -1);\n\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (rc)\n\t\tgoto hwrm_phy_qcaps_exit;\n\n\tif (resp->flags & PORT_PHY_QCAPS_RESP_FLAGS_EEE_SUPPORTED) {\n\t\tstruct ethtool_eee *eee = &bp->eee;\n\t\tu16 fw_speeds = le16_to_cpu(resp->supported_speeds_eee_mode);\n\n\t\tbp->flags |= BNXT_FLAG_EEE_CAP;\n\t\teee->supported = _bnxt_fw_to_ethtool_adv_spds(fw_speeds, 0);\n\t\tbp->lpi_tmr_lo = le32_to_cpu(resp->tx_lpi_timer_low) &\n\t\t\t\t PORT_PHY_QCAPS_RESP_TX_LPI_TIMER_LOW_MASK;\n\t\tbp->lpi_tmr_hi = le32_to_cpu(resp->valid_tx_lpi_timer_high) &\n\t\t\t\t PORT_PHY_QCAPS_RESP_TX_LPI_TIMER_HIGH_MASK;\n\t}\n\tif (resp->flags & PORT_PHY_QCAPS_RESP_FLAGS_EXTERNAL_LPBK_SUPPORTED) {\n\t\tif (bp->test_info)\n\t\t\tbp->test_info->flags |= BNXT_TEST_FL_EXT_LPBK;\n\t}\n\tif (resp->flags & PORT_PHY_QCAPS_RESP_FLAGS_AUTONEG_LPBK_SUPPORTED) {\n\t\tif (bp->test_info)\n\t\t\tbp->test_info->flags |= BNXT_TEST_FL_AN_PHY_LPBK;\n\t}\n\tif (resp->flags & PORT_PHY_QCAPS_RESP_FLAGS_SHARED_PHY_CFG_SUPPORTED) {\n\t\tif (BNXT_PF(bp))\n\t\t\tbp->fw_cap |= BNXT_FW_CAP_SHARED_PORT_CFG;\n\t}\n\tif (resp->flags & PORT_PHY_QCAPS_RESP_FLAGS_CUMULATIVE_COUNTERS_ON_RESET)\n\t\tbp->fw_cap |= BNXT_FW_CAP_PORT_STATS_NO_RESET;\n\n\tif (bp->hwrm_spec_code >= 0x10a01) {\n\t\tif (bnxt_phy_qcaps_no_speed(resp)) {\n\t\t\tlink_info->phy_state = BNXT_PHY_STATE_DISABLED;\n\t\t\tnetdev_warn(bp->dev, \"Ethernet link disabled\\n\");\n\t\t} else if (link_info->phy_state == BNXT_PHY_STATE_DISABLED) {\n\t\t\tlink_info->phy_state = BNXT_PHY_STATE_ENABLED;\n\t\t\tnetdev_info(bp->dev, \"Ethernet link enabled\\n\");\n\t\t\t/* Phy re-enabled, reprobe the speeds */\n\t\t\tlink_info->support_auto_speeds = 0;\n\t\t\tlink_info->support_pam4_auto_speeds = 0;\n\t\t}\n\t}\n\tif (resp->supported_speeds_auto_mode)\n\t\tlink_info->support_auto_speeds =\n\t\t\tle16_to_cpu(resp->supported_speeds_auto_mode);\n\tif (resp->supported_pam4_speeds_auto_mode)\n\t\tlink_info->support_pam4_auto_speeds =\n\t\t\tle16_to_cpu(resp->supported_pam4_speeds_auto_mode);\n\n\tbp->port_count = resp->port_cnt;\n\nhwrm_phy_qcaps_exit:\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\treturn rc;\n}\n\nstatic bool bnxt_support_dropped(u16 advertising, u16 supported)\n{\n\tu16 diff = advertising ^ supported;\n\n\treturn ((supported | diff) != supported);\n}\n\nint bnxt_update_link(struct bnxt *bp, bool chng_link_state)\n{\n\tint rc = 0;\n\tstruct bnxt_link_info *link_info = &bp->link_info;\n\tstruct hwrm_port_phy_qcfg_input req = {0};\n\tstruct hwrm_port_phy_qcfg_output *resp = bp->hwrm_cmd_resp_addr;\n\tu8 link_up = link_info->link_up;\n\tbool support_changed = false;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_PORT_PHY_QCFG, -1, -1);\n\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (rc) {\n\t\tmutex_unlock(&bp->hwrm_cmd_lock);\n\t\treturn rc;\n\t}\n\n\tmemcpy(&link_info->phy_qcfg_resp, resp, sizeof(*resp));\n\tlink_info->phy_link_status = resp->link;\n\tlink_info->duplex = resp->duplex_cfg;\n\tif (bp->hwrm_spec_code >= 0x10800)\n\t\tlink_info->duplex = resp->duplex_state;\n\tlink_info->pause = resp->pause;\n\tlink_info->auto_mode = resp->auto_mode;\n\tlink_info->auto_pause_setting = resp->auto_pause;\n\tlink_info->lp_pause = resp->link_partner_adv_pause;\n\tlink_info->force_pause_setting = resp->force_pause;\n\tlink_info->duplex_setting = resp->duplex_cfg;\n\tif (link_info->phy_link_status == BNXT_LINK_LINK)\n\t\tlink_info->link_speed = le16_to_cpu(resp->link_speed);\n\telse\n\t\tlink_info->link_speed = 0;\n\tlink_info->force_link_speed = le16_to_cpu(resp->force_link_speed);\n\tlink_info->force_pam4_link_speed =\n\t\tle16_to_cpu(resp->force_pam4_link_speed);\n\tlink_info->support_speeds = le16_to_cpu(resp->support_speeds);\n\tlink_info->support_pam4_speeds = le16_to_cpu(resp->support_pam4_speeds);\n\tlink_info->auto_link_speeds = le16_to_cpu(resp->auto_link_speed_mask);\n\tlink_info->auto_pam4_link_speeds =\n\t\tle16_to_cpu(resp->auto_pam4_link_speed_mask);\n\tlink_info->lp_auto_link_speeds =\n\t\tle16_to_cpu(resp->link_partner_adv_speeds);\n\tlink_info->lp_auto_pam4_link_speeds =\n\t\tresp->link_partner_pam4_adv_speeds;\n\tlink_info->preemphasis = le32_to_cpu(resp->preemphasis);\n\tlink_info->phy_ver[0] = resp->phy_maj;\n\tlink_info->phy_ver[1] = resp->phy_min;\n\tlink_info->phy_ver[2] = resp->phy_bld;\n\tlink_info->media_type = resp->media_type;\n\tlink_info->phy_type = resp->phy_type;\n\tlink_info->transceiver = resp->xcvr_pkg_type;\n\tlink_info->phy_addr = resp->eee_config_phy_addr &\n\t\t\t      PORT_PHY_QCFG_RESP_PHY_ADDR_MASK;\n\tlink_info->module_status = resp->module_status;\n\n\tif (bp->flags & BNXT_FLAG_EEE_CAP) {\n\t\tstruct ethtool_eee *eee = &bp->eee;\n\t\tu16 fw_speeds;\n\n\t\teee->eee_active = 0;\n\t\tif (resp->eee_config_phy_addr &\n\t\t    PORT_PHY_QCFG_RESP_EEE_CONFIG_EEE_ACTIVE) {\n\t\t\teee->eee_active = 1;\n\t\t\tfw_speeds = le16_to_cpu(\n\t\t\t\tresp->link_partner_adv_eee_link_speed_mask);\n\t\t\teee->lp_advertised =\n\t\t\t\t_bnxt_fw_to_ethtool_adv_spds(fw_speeds, 0);\n\t\t}\n\n\t\t/* Pull initial EEE config */\n\t\tif (!chng_link_state) {\n\t\t\tif (resp->eee_config_phy_addr &\n\t\t\t    PORT_PHY_QCFG_RESP_EEE_CONFIG_EEE_ENABLED)\n\t\t\t\teee->eee_enabled = 1;\n\n\t\t\tfw_speeds = le16_to_cpu(resp->adv_eee_link_speed_mask);\n\t\t\teee->advertised =\n\t\t\t\t_bnxt_fw_to_ethtool_adv_spds(fw_speeds, 0);\n\n\t\t\tif (resp->eee_config_phy_addr &\n\t\t\t    PORT_PHY_QCFG_RESP_EEE_CONFIG_EEE_TX_LPI) {\n\t\t\t\t__le32 tmr;\n\n\t\t\t\teee->tx_lpi_enabled = 1;\n\t\t\t\ttmr = resp->xcvr_identifier_type_tx_lpi_timer;\n\t\t\t\teee->tx_lpi_timer = le32_to_cpu(tmr) &\n\t\t\t\t\tPORT_PHY_QCFG_RESP_TX_LPI_TIMER_MASK;\n\t\t\t}\n\t\t}\n\t}\n\n\tlink_info->fec_cfg = PORT_PHY_QCFG_RESP_FEC_CFG_FEC_NONE_SUPPORTED;\n\tif (bp->hwrm_spec_code >= 0x10504) {\n\t\tlink_info->fec_cfg = le16_to_cpu(resp->fec_cfg);\n\t\tlink_info->active_fec_sig_mode = resp->active_fec_signal_mode;\n\t}\n\t/* TODO: need to add more logic to report VF link */\n\tif (chng_link_state) {\n\t\tif (link_info->phy_link_status == BNXT_LINK_LINK)\n\t\t\tlink_info->link_up = 1;\n\t\telse\n\t\t\tlink_info->link_up = 0;\n\t\tif (link_up != link_info->link_up)\n\t\t\tbnxt_report_link(bp);\n\t} else {\n\t\t/* alwasy link down if not require to update link state */\n\t\tlink_info->link_up = 0;\n\t}\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\n\tif (!BNXT_PHY_CFG_ABLE(bp))\n\t\treturn 0;\n\n\t/* Check if any advertised speeds are no longer supported. The caller\n\t * holds the link_lock mutex, so we can modify link_info settings.\n\t */\n\tif (bnxt_support_dropped(link_info->advertising,\n\t\t\t\t link_info->support_auto_speeds)) {\n\t\tlink_info->advertising = link_info->support_auto_speeds;\n\t\tsupport_changed = true;\n\t}\n\tif (bnxt_support_dropped(link_info->advertising_pam4,\n\t\t\t\t link_info->support_pam4_auto_speeds)) {\n\t\tlink_info->advertising_pam4 = link_info->support_pam4_auto_speeds;\n\t\tsupport_changed = true;\n\t}\n\tif (support_changed && (link_info->autoneg & BNXT_AUTONEG_SPEED))\n\t\tbnxt_hwrm_set_link_setting(bp, true, false);\n\treturn 0;\n}\n\nstatic void bnxt_get_port_module_status(struct bnxt *bp)\n{\n\tstruct bnxt_link_info *link_info = &bp->link_info;\n\tstruct hwrm_port_phy_qcfg_output *resp = &link_info->phy_qcfg_resp;\n\tu8 module_status;\n\n\tif (bnxt_update_link(bp, true))\n\t\treturn;\n\n\tmodule_status = link_info->module_status;\n\tswitch (module_status) {\n\tcase PORT_PHY_QCFG_RESP_MODULE_STATUS_DISABLETX:\n\tcase PORT_PHY_QCFG_RESP_MODULE_STATUS_PWRDOWN:\n\tcase PORT_PHY_QCFG_RESP_MODULE_STATUS_WARNINGMSG:\n\t\tnetdev_warn(bp->dev, \"Unqualified SFP+ module detected on port %d\\n\",\n\t\t\t    bp->pf.port_id);\n\t\tif (bp->hwrm_spec_code >= 0x10201) {\n\t\t\tnetdev_warn(bp->dev, \"Module part number %s\\n\",\n\t\t\t\t    resp->phy_vendor_partnumber);\n\t\t}\n\t\tif (module_status == PORT_PHY_QCFG_RESP_MODULE_STATUS_DISABLETX)\n\t\t\tnetdev_warn(bp->dev, \"TX is disabled\\n\");\n\t\tif (module_status == PORT_PHY_QCFG_RESP_MODULE_STATUS_PWRDOWN)\n\t\t\tnetdev_warn(bp->dev, \"SFP+ module is shutdown\\n\");\n\t}\n}\n\nstatic void\nbnxt_hwrm_set_pause_common(struct bnxt *bp, struct hwrm_port_phy_cfg_input *req)\n{\n\tif (bp->link_info.autoneg & BNXT_AUTONEG_FLOW_CTRL) {\n\t\tif (bp->hwrm_spec_code >= 0x10201)\n\t\t\treq->auto_pause =\n\t\t\t\tPORT_PHY_CFG_REQ_AUTO_PAUSE_AUTONEG_PAUSE;\n\t\tif (bp->link_info.req_flow_ctrl & BNXT_LINK_PAUSE_RX)\n\t\t\treq->auto_pause |= PORT_PHY_CFG_REQ_AUTO_PAUSE_RX;\n\t\tif (bp->link_info.req_flow_ctrl & BNXT_LINK_PAUSE_TX)\n\t\t\treq->auto_pause |= PORT_PHY_CFG_REQ_AUTO_PAUSE_TX;\n\t\treq->enables |=\n\t\t\tcpu_to_le32(PORT_PHY_CFG_REQ_ENABLES_AUTO_PAUSE);\n\t} else {\n\t\tif (bp->link_info.req_flow_ctrl & BNXT_LINK_PAUSE_RX)\n\t\t\treq->force_pause |= PORT_PHY_CFG_REQ_FORCE_PAUSE_RX;\n\t\tif (bp->link_info.req_flow_ctrl & BNXT_LINK_PAUSE_TX)\n\t\t\treq->force_pause |= PORT_PHY_CFG_REQ_FORCE_PAUSE_TX;\n\t\treq->enables |=\n\t\t\tcpu_to_le32(PORT_PHY_CFG_REQ_ENABLES_FORCE_PAUSE);\n\t\tif (bp->hwrm_spec_code >= 0x10201) {\n\t\t\treq->auto_pause = req->force_pause;\n\t\t\treq->enables |= cpu_to_le32(\n\t\t\t\tPORT_PHY_CFG_REQ_ENABLES_AUTO_PAUSE);\n\t\t}\n\t}\n}\n\nstatic void bnxt_hwrm_set_link_common(struct bnxt *bp, struct hwrm_port_phy_cfg_input *req)\n{\n\tif (bp->link_info.autoneg & BNXT_AUTONEG_SPEED) {\n\t\treq->auto_mode |= PORT_PHY_CFG_REQ_AUTO_MODE_SPEED_MASK;\n\t\tif (bp->link_info.advertising) {\n\t\t\treq->enables |= cpu_to_le32(PORT_PHY_CFG_REQ_ENABLES_AUTO_LINK_SPEED_MASK);\n\t\t\treq->auto_link_speed_mask = cpu_to_le16(bp->link_info.advertising);\n\t\t}\n\t\tif (bp->link_info.advertising_pam4) {\n\t\t\treq->enables |=\n\t\t\t\tcpu_to_le32(PORT_PHY_CFG_REQ_ENABLES_AUTO_PAM4_LINK_SPEED_MASK);\n\t\t\treq->auto_link_pam4_speed_mask =\n\t\t\t\tcpu_to_le16(bp->link_info.advertising_pam4);\n\t\t}\n\t\treq->enables |= cpu_to_le32(PORT_PHY_CFG_REQ_ENABLES_AUTO_MODE);\n\t\treq->flags |= cpu_to_le32(PORT_PHY_CFG_REQ_FLAGS_RESTART_AUTONEG);\n\t} else {\n\t\treq->flags |= cpu_to_le32(PORT_PHY_CFG_REQ_FLAGS_FORCE);\n\t\tif (bp->link_info.req_signal_mode == BNXT_SIG_MODE_PAM4) {\n\t\t\treq->force_pam4_link_speed = cpu_to_le16(bp->link_info.req_link_speed);\n\t\t\treq->enables |= cpu_to_le32(PORT_PHY_CFG_REQ_ENABLES_FORCE_PAM4_LINK_SPEED);\n\t\t} else {\n\t\t\treq->force_link_speed = cpu_to_le16(bp->link_info.req_link_speed);\n\t\t}\n\t}\n\n\t/* tell chimp that the setting takes effect immediately */\n\treq->flags |= cpu_to_le32(PORT_PHY_CFG_REQ_FLAGS_RESET_PHY);\n}\n\nint bnxt_hwrm_set_pause(struct bnxt *bp)\n{\n\tstruct hwrm_port_phy_cfg_input req = {0};\n\tint rc;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_PORT_PHY_CFG, -1, -1);\n\tbnxt_hwrm_set_pause_common(bp, &req);\n\n\tif ((bp->link_info.autoneg & BNXT_AUTONEG_FLOW_CTRL) ||\n\t    bp->link_info.force_link_chng)\n\t\tbnxt_hwrm_set_link_common(bp, &req);\n\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (!rc && !(bp->link_info.autoneg & BNXT_AUTONEG_FLOW_CTRL)) {\n\t\t/* since changing of pause setting doesn't trigger any link\n\t\t * change event, the driver needs to update the current pause\n\t\t * result upon successfully return of the phy_cfg command\n\t\t */\n\t\tbp->link_info.pause =\n\t\tbp->link_info.force_pause_setting = bp->link_info.req_flow_ctrl;\n\t\tbp->link_info.auto_pause_setting = 0;\n\t\tif (!bp->link_info.force_link_chng)\n\t\t\tbnxt_report_link(bp);\n\t}\n\tbp->link_info.force_link_chng = false;\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\treturn rc;\n}\n\nstatic void bnxt_hwrm_set_eee(struct bnxt *bp,\n\t\t\t      struct hwrm_port_phy_cfg_input *req)\n{\n\tstruct ethtool_eee *eee = &bp->eee;\n\n\tif (eee->eee_enabled) {\n\t\tu16 eee_speeds;\n\t\tu32 flags = PORT_PHY_CFG_REQ_FLAGS_EEE_ENABLE;\n\n\t\tif (eee->tx_lpi_enabled)\n\t\t\tflags |= PORT_PHY_CFG_REQ_FLAGS_EEE_TX_LPI_ENABLE;\n\t\telse\n\t\t\tflags |= PORT_PHY_CFG_REQ_FLAGS_EEE_TX_LPI_DISABLE;\n\n\t\treq->flags |= cpu_to_le32(flags);\n\t\teee_speeds = bnxt_get_fw_auto_link_speeds(eee->advertised);\n\t\treq->eee_link_speed_mask = cpu_to_le16(eee_speeds);\n\t\treq->tx_lpi_timer = cpu_to_le32(eee->tx_lpi_timer);\n\t} else {\n\t\treq->flags |= cpu_to_le32(PORT_PHY_CFG_REQ_FLAGS_EEE_DISABLE);\n\t}\n}\n\nint bnxt_hwrm_set_link_setting(struct bnxt *bp, bool set_pause, bool set_eee)\n{\n\tstruct hwrm_port_phy_cfg_input req = {0};\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_PORT_PHY_CFG, -1, -1);\n\tif (set_pause)\n\t\tbnxt_hwrm_set_pause_common(bp, &req);\n\n\tbnxt_hwrm_set_link_common(bp, &req);\n\n\tif (set_eee)\n\t\tbnxt_hwrm_set_eee(bp, &req);\n\treturn hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n}\n\nstatic int bnxt_hwrm_shutdown_link(struct bnxt *bp)\n{\n\tstruct hwrm_port_phy_cfg_input req = {0};\n\n\tif (!BNXT_SINGLE_PF(bp))\n\t\treturn 0;\n\n\tif (pci_num_vf(bp->pdev))\n\t\treturn 0;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_PORT_PHY_CFG, -1, -1);\n\treq.flags = cpu_to_le32(PORT_PHY_CFG_REQ_FLAGS_FORCE_LINK_DWN);\n\treturn hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n}\n\nstatic int bnxt_fw_init_one(struct bnxt *bp);\n\nstatic int bnxt_fw_reset_via_optee(struct bnxt *bp)\n{\n#ifdef CONFIG_TEE_BNXT_FW\n\tint rc = tee_bnxt_fw_load();\n\n\tif (rc)\n\t\tnetdev_err(bp->dev, \"Failed FW reset via OP-TEE, rc=%d\\n\", rc);\n\n\treturn rc;\n#else\n\tnetdev_err(bp->dev, \"OP-TEE not supported\\n\");\n\treturn -ENODEV;\n#endif\n}\n\nstatic int bnxt_try_recover_fw(struct bnxt *bp)\n{\n\tif (bp->fw_health && bp->fw_health->status_reliable) {\n\t\tint retry = 0, rc;\n\t\tu32 sts;\n\n\t\tmutex_lock(&bp->hwrm_cmd_lock);\n\t\tdo {\n\t\t\tsts = bnxt_fw_health_readl(bp, BNXT_FW_HEALTH_REG);\n\t\t\trc = __bnxt_hwrm_ver_get(bp, true);\n\t\t\tif (!sts || (!BNXT_FW_IS_BOOTING(sts) &&\n\t\t\t\t     !BNXT_FW_IS_RECOVERING(sts)))\n\t\t\t\tbreak;\n\t\t\tretry++;\n\t\t} while (rc == -EBUSY && retry < BNXT_FW_RETRY);\n\t\tmutex_unlock(&bp->hwrm_cmd_lock);\n\n\t\tif (!BNXT_FW_IS_HEALTHY(sts)) {\n\t\t\tnetdev_err(bp->dev,\n\t\t\t\t   \"Firmware not responding, status: 0x%x\\n\",\n\t\t\t\t   sts);\n\t\t\trc = -ENODEV;\n\t\t}\n\t\tif (sts & FW_STATUS_REG_CRASHED_NO_MASTER) {\n\t\t\tnetdev_warn(bp->dev, \"Firmware recover via OP-TEE requested\\n\");\n\t\t\treturn bnxt_fw_reset_via_optee(bp);\n\t\t}\n\t\treturn rc;\n\t}\n\n\treturn -ENODEV;\n}\n\nstatic int bnxt_hwrm_if_change(struct bnxt *bp, bool up)\n{\n\tstruct hwrm_func_drv_if_change_output *resp = bp->hwrm_cmd_resp_addr;\n\tstruct hwrm_func_drv_if_change_input req = {0};\n\tbool fw_reset = !bp->irq_tbl;\n\tbool resc_reinit = false;\n\tint rc, retry = 0;\n\tu32 flags = 0;\n\n\tif (!(bp->fw_cap & BNXT_FW_CAP_IF_CHANGE))\n\t\treturn 0;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_FUNC_DRV_IF_CHANGE, -1, -1);\n\tif (up)\n\t\treq.flags = cpu_to_le32(FUNC_DRV_IF_CHANGE_REQ_FLAGS_UP);\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\twhile (retry < BNXT_FW_IF_RETRY) {\n\t\trc = _hwrm_send_message(bp, &req, sizeof(req),\n\t\t\t\t\tHWRM_CMD_TIMEOUT);\n\t\tif (rc != -EAGAIN)\n\t\t\tbreak;\n\n\t\tmsleep(50);\n\t\tretry++;\n\t}\n\tif (!rc)\n\t\tflags = le32_to_cpu(resp->flags);\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\n\tif (rc == -EAGAIN)\n\t\treturn rc;\n\tif (rc && up) {\n\t\trc = bnxt_try_recover_fw(bp);\n\t\tfw_reset = true;\n\t}\n\tif (rc)\n\t\treturn rc;\n\n\tif (!up) {\n\t\tbnxt_inv_fw_health_reg(bp);\n\t\treturn 0;\n\t}\n\n\tif (flags & FUNC_DRV_IF_CHANGE_RESP_FLAGS_RESC_CHANGE)\n\t\tresc_reinit = true;\n\tif (flags & FUNC_DRV_IF_CHANGE_RESP_FLAGS_HOT_FW_RESET_DONE)\n\t\tfw_reset = true;\n\telse if (bp->fw_health && !bp->fw_health->status_reliable)\n\t\tbnxt_try_map_fw_health_reg(bp);\n\n\tif (test_bit(BNXT_STATE_IN_FW_RESET, &bp->state) && !fw_reset) {\n\t\tnetdev_err(bp->dev, \"RESET_DONE not set during FW reset.\\n\");\n\t\tset_bit(BNXT_STATE_ABORT_ERR, &bp->state);\n\t\treturn -ENODEV;\n\t}\n\tif (resc_reinit || fw_reset) {\n\t\tif (fw_reset) {\n\t\t\tset_bit(BNXT_STATE_FW_RESET_DET, &bp->state);\n\t\t\tif (!test_bit(BNXT_STATE_IN_FW_RESET, &bp->state))\n\t\t\t\tbnxt_ulp_stop(bp);\n\t\t\tbnxt_free_ctx_mem(bp);\n\t\t\tkfree(bp->ctx);\n\t\t\tbp->ctx = NULL;\n\t\t\tbnxt_dcb_free(bp);\n\t\t\trc = bnxt_fw_init_one(bp);\n\t\t\tif (rc) {\n\t\t\t\tclear_bit(BNXT_STATE_FW_RESET_DET, &bp->state);\n\t\t\t\tset_bit(BNXT_STATE_ABORT_ERR, &bp->state);\n\t\t\t\treturn rc;\n\t\t\t}\n\t\t\tbnxt_clear_int_mode(bp);\n\t\t\trc = bnxt_init_int_mode(bp);\n\t\t\tif (rc) {\n\t\t\t\tclear_bit(BNXT_STATE_FW_RESET_DET, &bp->state);\n\t\t\t\tnetdev_err(bp->dev, \"init int mode failed\\n\");\n\t\t\t\treturn rc;\n\t\t\t}\n\t\t}\n\t\tif (BNXT_NEW_RM(bp)) {\n\t\t\tstruct bnxt_hw_resc *hw_resc = &bp->hw_resc;\n\n\t\t\trc = bnxt_hwrm_func_resc_qcaps(bp, true);\n\t\t\tif (rc)\n\t\t\t\tnetdev_err(bp->dev, \"resc_qcaps failed\\n\");\n\n\t\t\thw_resc->resv_cp_rings = 0;\n\t\t\thw_resc->resv_stat_ctxs = 0;\n\t\t\thw_resc->resv_irqs = 0;\n\t\t\thw_resc->resv_tx_rings = 0;\n\t\t\thw_resc->resv_rx_rings = 0;\n\t\t\thw_resc->resv_hw_ring_grps = 0;\n\t\t\thw_resc->resv_vnics = 0;\n\t\t\tif (!fw_reset) {\n\t\t\t\tbp->tx_nr_rings = 0;\n\t\t\t\tbp->rx_nr_rings = 0;\n\t\t\t}\n\t\t}\n\t}\n\treturn rc;\n}\n\nstatic int bnxt_hwrm_port_led_qcaps(struct bnxt *bp)\n{\n\tstruct hwrm_port_led_qcaps_output *resp = bp->hwrm_cmd_resp_addr;\n\tstruct hwrm_port_led_qcaps_input req = {0};\n\tstruct bnxt_pf_info *pf = &bp->pf;\n\tint rc;\n\n\tbp->num_leds = 0;\n\tif (BNXT_VF(bp) || bp->hwrm_spec_code < 0x10601)\n\t\treturn 0;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_PORT_LED_QCAPS, -1, -1);\n\treq.port_id = cpu_to_le16(pf->port_id);\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (rc) {\n\t\tmutex_unlock(&bp->hwrm_cmd_lock);\n\t\treturn rc;\n\t}\n\tif (resp->num_leds > 0 && resp->num_leds < BNXT_MAX_LED) {\n\t\tint i;\n\n\t\tbp->num_leds = resp->num_leds;\n\t\tmemcpy(bp->leds, &resp->led0_id, sizeof(bp->leds[0]) *\n\t\t\t\t\t\t bp->num_leds);\n\t\tfor (i = 0; i < bp->num_leds; i++) {\n\t\t\tstruct bnxt_led_info *led = &bp->leds[i];\n\t\t\t__le16 caps = led->led_state_caps;\n\n\t\t\tif (!led->led_group_id ||\n\t\t\t    !BNXT_LED_ALT_BLINK_CAP(caps)) {\n\t\t\t\tbp->num_leds = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\treturn 0;\n}\n\nint bnxt_hwrm_alloc_wol_fltr(struct bnxt *bp)\n{\n\tstruct hwrm_wol_filter_alloc_input req = {0};\n\tstruct hwrm_wol_filter_alloc_output *resp = bp->hwrm_cmd_resp_addr;\n\tint rc;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_WOL_FILTER_ALLOC, -1, -1);\n\treq.port_id = cpu_to_le16(bp->pf.port_id);\n\treq.wol_type = WOL_FILTER_ALLOC_REQ_WOL_TYPE_MAGICPKT;\n\treq.enables = cpu_to_le32(WOL_FILTER_ALLOC_REQ_ENABLES_MAC_ADDRESS);\n\tmemcpy(req.mac_address, bp->dev->dev_addr, ETH_ALEN);\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (!rc)\n\t\tbp->wol_filter_id = resp->wol_filter_id;\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\treturn rc;\n}\n\nint bnxt_hwrm_free_wol_fltr(struct bnxt *bp)\n{\n\tstruct hwrm_wol_filter_free_input req = {0};\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_WOL_FILTER_FREE, -1, -1);\n\treq.port_id = cpu_to_le16(bp->pf.port_id);\n\treq.enables = cpu_to_le32(WOL_FILTER_FREE_REQ_ENABLES_WOL_FILTER_ID);\n\treq.wol_filter_id = bp->wol_filter_id;\n\treturn hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n}\n\nstatic u16 bnxt_hwrm_get_wol_fltrs(struct bnxt *bp, u16 handle)\n{\n\tstruct hwrm_wol_filter_qcfg_input req = {0};\n\tstruct hwrm_wol_filter_qcfg_output *resp = bp->hwrm_cmd_resp_addr;\n\tu16 next_handle = 0;\n\tint rc;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_WOL_FILTER_QCFG, -1, -1);\n\treq.port_id = cpu_to_le16(bp->pf.port_id);\n\treq.handle = cpu_to_le16(handle);\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (!rc) {\n\t\tnext_handle = le16_to_cpu(resp->next_handle);\n\t\tif (next_handle != 0) {\n\t\t\tif (resp->wol_type ==\n\t\t\t    WOL_FILTER_ALLOC_REQ_WOL_TYPE_MAGICPKT) {\n\t\t\t\tbp->wol = 1;\n\t\t\t\tbp->wol_filter_id = resp->wol_filter_id;\n\t\t\t}\n\t\t}\n\t}\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\treturn next_handle;\n}\n\nstatic void bnxt_get_wol_settings(struct bnxt *bp)\n{\n\tu16 handle = 0;\n\n\tbp->wol = 0;\n\tif (!BNXT_PF(bp) || !(bp->flags & BNXT_FLAG_WOL_CAP))\n\t\treturn;\n\n\tdo {\n\t\thandle = bnxt_hwrm_get_wol_fltrs(bp, handle);\n\t} while (handle && handle != 0xffff);\n}\n\n#ifdef CONFIG_BNXT_HWMON\nstatic ssize_t bnxt_show_temp(struct device *dev,\n\t\t\t      struct device_attribute *devattr, char *buf)\n{\n\tstruct hwrm_temp_monitor_query_input req = {0};\n\tstruct hwrm_temp_monitor_query_output *resp;\n\tstruct bnxt *bp = dev_get_drvdata(dev);\n\tu32 len = 0;\n\tint rc;\n\n\tresp = bp->hwrm_cmd_resp_addr;\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_TEMP_MONITOR_QUERY, -1, -1);\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (!rc)\n\t\tlen = sprintf(buf, \"%u\\n\", resp->temp * 1000); /* display millidegree */\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\treturn rc ?: len;\n}\nstatic SENSOR_DEVICE_ATTR(temp1_input, 0444, bnxt_show_temp, NULL, 0);\n\nstatic struct attribute *bnxt_attrs[] = {\n\t&sensor_dev_attr_temp1_input.dev_attr.attr,\n\tNULL\n};\nATTRIBUTE_GROUPS(bnxt);\n\nstatic void bnxt_hwmon_close(struct bnxt *bp)\n{\n\tif (bp->hwmon_dev) {\n\t\thwmon_device_unregister(bp->hwmon_dev);\n\t\tbp->hwmon_dev = NULL;\n\t}\n}\n\nstatic void bnxt_hwmon_open(struct bnxt *bp)\n{\n\tstruct hwrm_temp_monitor_query_input req = {0};\n\tstruct pci_dev *pdev = bp->pdev;\n\tint rc;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_TEMP_MONITOR_QUERY, -1, -1);\n\trc = hwrm_send_message_silent(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (rc == -EACCES || rc == -EOPNOTSUPP) {\n\t\tbnxt_hwmon_close(bp);\n\t\treturn;\n\t}\n\n\tif (bp->hwmon_dev)\n\t\treturn;\n\n\tbp->hwmon_dev = hwmon_device_register_with_groups(&pdev->dev,\n\t\t\t\t\t\t\t  DRV_MODULE_NAME, bp,\n\t\t\t\t\t\t\t  bnxt_groups);\n\tif (IS_ERR(bp->hwmon_dev)) {\n\t\tbp->hwmon_dev = NULL;\n\t\tdev_warn(&pdev->dev, \"Cannot register hwmon device\\n\");\n\t}\n}\n#else\nstatic void bnxt_hwmon_close(struct bnxt *bp)\n{\n}\n\nstatic void bnxt_hwmon_open(struct bnxt *bp)\n{\n}\n#endif\n\nstatic bool bnxt_eee_config_ok(struct bnxt *bp)\n{\n\tstruct ethtool_eee *eee = &bp->eee;\n\tstruct bnxt_link_info *link_info = &bp->link_info;\n\n\tif (!(bp->flags & BNXT_FLAG_EEE_CAP))\n\t\treturn true;\n\n\tif (eee->eee_enabled) {\n\t\tu32 advertising =\n\t\t\t_bnxt_fw_to_ethtool_adv_spds(link_info->advertising, 0);\n\n\t\tif (!(link_info->autoneg & BNXT_AUTONEG_SPEED)) {\n\t\t\teee->eee_enabled = 0;\n\t\t\treturn false;\n\t\t}\n\t\tif (eee->advertised & ~advertising) {\n\t\t\teee->advertised = advertising & eee->supported;\n\t\t\treturn false;\n\t\t}\n\t}\n\treturn true;\n}\n\nstatic int bnxt_update_phy_setting(struct bnxt *bp)\n{\n\tint rc;\n\tbool update_link = false;\n\tbool update_pause = false;\n\tbool update_eee = false;\n\tstruct bnxt_link_info *link_info = &bp->link_info;\n\n\trc = bnxt_update_link(bp, true);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"failed to update link (rc: %x)\\n\",\n\t\t\t   rc);\n\t\treturn rc;\n\t}\n\tif (!BNXT_SINGLE_PF(bp))\n\t\treturn 0;\n\n\tif ((link_info->autoneg & BNXT_AUTONEG_FLOW_CTRL) &&\n\t    (link_info->auto_pause_setting & BNXT_LINK_PAUSE_BOTH) !=\n\t    link_info->req_flow_ctrl)\n\t\tupdate_pause = true;\n\tif (!(link_info->autoneg & BNXT_AUTONEG_FLOW_CTRL) &&\n\t    link_info->force_pause_setting != link_info->req_flow_ctrl)\n\t\tupdate_pause = true;\n\tif (!(link_info->autoneg & BNXT_AUTONEG_SPEED)) {\n\t\tif (BNXT_AUTO_MODE(link_info->auto_mode))\n\t\t\tupdate_link = true;\n\t\tif (link_info->req_signal_mode == BNXT_SIG_MODE_NRZ &&\n\t\t    link_info->req_link_speed != link_info->force_link_speed)\n\t\t\tupdate_link = true;\n\t\telse if (link_info->req_signal_mode == BNXT_SIG_MODE_PAM4 &&\n\t\t\t link_info->req_link_speed != link_info->force_pam4_link_speed)\n\t\t\tupdate_link = true;\n\t\tif (link_info->req_duplex != link_info->duplex_setting)\n\t\t\tupdate_link = true;\n\t} else {\n\t\tif (link_info->auto_mode == BNXT_LINK_AUTO_NONE)\n\t\t\tupdate_link = true;\n\t\tif (link_info->advertising != link_info->auto_link_speeds ||\n\t\t    link_info->advertising_pam4 != link_info->auto_pam4_link_speeds)\n\t\t\tupdate_link = true;\n\t}\n\n\t/* The last close may have shutdown the link, so need to call\n\t * PHY_CFG to bring it back up.\n\t */\n\tif (!bp->link_info.link_up)\n\t\tupdate_link = true;\n\n\tif (!bnxt_eee_config_ok(bp))\n\t\tupdate_eee = true;\n\n\tif (update_link)\n\t\trc = bnxt_hwrm_set_link_setting(bp, update_pause, update_eee);\n\telse if (update_pause)\n\t\trc = bnxt_hwrm_set_pause(bp);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"failed to update phy setting (rc: %x)\\n\",\n\t\t\t   rc);\n\t\treturn rc;\n\t}\n\n\treturn rc;\n}\n\n/* Common routine to pre-map certain register block to different GRC window.\n * A PF has 16 4K windows and a VF has 4 4K windows. However, only 15 windows\n * in PF and 3 windows in VF that can be customized to map in different\n * register blocks.\n */\nstatic void bnxt_preset_reg_win(struct bnxt *bp)\n{\n\tif (BNXT_PF(bp)) {\n\t\t/* CAG registers map to GRC window #4 */\n\t\twritel(BNXT_CAG_REG_BASE,\n\t\t       bp->bar0 + BNXT_GRCPF_REG_WINDOW_BASE_OUT + 12);\n\t}\n}\n\nstatic int bnxt_init_dflt_ring_mode(struct bnxt *bp);\n\nstatic int bnxt_reinit_after_abort(struct bnxt *bp)\n{\n\tint rc;\n\n\tif (test_bit(BNXT_STATE_IN_FW_RESET, &bp->state))\n\t\treturn -EBUSY;\n\n\tif (bp->dev->reg_state == NETREG_UNREGISTERED)\n\t\treturn -ENODEV;\n\n\trc = bnxt_fw_init_one(bp);\n\tif (!rc) {\n\t\tbnxt_clear_int_mode(bp);\n\t\trc = bnxt_init_int_mode(bp);\n\t\tif (!rc) {\n\t\t\tclear_bit(BNXT_STATE_ABORT_ERR, &bp->state);\n\t\t\tset_bit(BNXT_STATE_FW_RESET_DET, &bp->state);\n\t\t}\n\t}\n\treturn rc;\n}\n\nstatic int __bnxt_open_nic(struct bnxt *bp, bool irq_re_init, bool link_re_init)\n{\n\tint rc = 0;\n\n\tbnxt_preset_reg_win(bp);\n\tnetif_carrier_off(bp->dev);\n\tif (irq_re_init) {\n\t\t/* Reserve rings now if none were reserved at driver probe. */\n\t\trc = bnxt_init_dflt_ring_mode(bp);\n\t\tif (rc) {\n\t\t\tnetdev_err(bp->dev, \"Failed to reserve default rings at open\\n\");\n\t\t\treturn rc;\n\t\t}\n\t}\n\trc = bnxt_reserve_rings(bp, irq_re_init);\n\tif (rc)\n\t\treturn rc;\n\tif ((bp->flags & BNXT_FLAG_RFS) &&\n\t    !(bp->flags & BNXT_FLAG_USING_MSIX)) {\n\t\t/* disable RFS if falling back to INTA */\n\t\tbp->dev->hw_features &= ~NETIF_F_NTUPLE;\n\t\tbp->flags &= ~BNXT_FLAG_RFS;\n\t}\n\n\trc = bnxt_alloc_mem(bp, irq_re_init);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"bnxt_alloc_mem err: %x\\n\", rc);\n\t\tgoto open_err_free_mem;\n\t}\n\n\tif (irq_re_init) {\n\t\tbnxt_init_napi(bp);\n\t\trc = bnxt_request_irq(bp);\n\t\tif (rc) {\n\t\t\tnetdev_err(bp->dev, \"bnxt_request_irq err: %x\\n\", rc);\n\t\t\tgoto open_err_irq;\n\t\t}\n\t}\n\n\trc = bnxt_init_nic(bp, irq_re_init);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"bnxt_init_nic err: %x\\n\", rc);\n\t\tgoto open_err_irq;\n\t}\n\n\tbnxt_enable_napi(bp);\n\tbnxt_debug_dev_init(bp);\n\n\tif (link_re_init) {\n\t\tmutex_lock(&bp->link_lock);\n\t\trc = bnxt_update_phy_setting(bp);\n\t\tmutex_unlock(&bp->link_lock);\n\t\tif (rc) {\n\t\t\tnetdev_warn(bp->dev, \"failed to update phy settings\\n\");\n\t\t\tif (BNXT_SINGLE_PF(bp)) {\n\t\t\t\tbp->link_info.phy_retry = true;\n\t\t\t\tbp->link_info.phy_retry_expires =\n\t\t\t\t\tjiffies + 5 * HZ;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (irq_re_init)\n\t\tudp_tunnel_nic_reset_ntf(bp->dev);\n\n\tset_bit(BNXT_STATE_OPEN, &bp->state);\n\tbnxt_enable_int(bp);\n\t/* Enable TX queues */\n\tbnxt_tx_enable(bp);\n\tmod_timer(&bp->timer, jiffies + bp->current_interval);\n\t/* Poll link status and check for SFP+ module status */\n\tbnxt_get_port_module_status(bp);\n\n\t/* VF-reps may need to be re-opened after the PF is re-opened */\n\tif (BNXT_PF(bp))\n\t\tbnxt_vf_reps_open(bp);\n\treturn 0;\n\nopen_err_irq:\n\tbnxt_del_napi(bp);\n\nopen_err_free_mem:\n\tbnxt_free_skbs(bp);\n\tbnxt_free_irq(bp);\n\tbnxt_free_mem(bp, true);\n\treturn rc;\n}\n\n/* rtnl_lock held */\nint bnxt_open_nic(struct bnxt *bp, bool irq_re_init, bool link_re_init)\n{\n\tint rc = 0;\n\n\tif (test_bit(BNXT_STATE_ABORT_ERR, &bp->state))\n\t\trc = -EIO;\n\tif (!rc)\n\t\trc = __bnxt_open_nic(bp, irq_re_init, link_re_init);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"nic open fail (rc: %x)\\n\", rc);\n\t\tdev_close(bp->dev);\n\t}\n\treturn rc;\n}\n\n/* rtnl_lock held, open the NIC half way by allocating all resources, but\n * NAPI, IRQ, and TX are not enabled.  This is mainly used for offline\n * self tests.\n */\nint bnxt_half_open_nic(struct bnxt *bp)\n{\n\tint rc = 0;\n\n\trc = bnxt_alloc_mem(bp, false);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"bnxt_alloc_mem err: %x\\n\", rc);\n\t\tgoto half_open_err;\n\t}\n\trc = bnxt_init_nic(bp, false);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"bnxt_init_nic err: %x\\n\", rc);\n\t\tgoto half_open_err;\n\t}\n\treturn 0;\n\nhalf_open_err:\n\tbnxt_free_skbs(bp);\n\tbnxt_free_mem(bp, false);\n\tdev_close(bp->dev);\n\treturn rc;\n}\n\n/* rtnl_lock held, this call can only be made after a previous successful\n * call to bnxt_half_open_nic().\n */\nvoid bnxt_half_close_nic(struct bnxt *bp)\n{\n\tbnxt_hwrm_resource_free(bp, false, false);\n\tbnxt_free_skbs(bp);\n\tbnxt_free_mem(bp, false);\n}\n\nstatic void bnxt_reenable_sriov(struct bnxt *bp)\n{\n\tif (BNXT_PF(bp)) {\n\t\tstruct bnxt_pf_info *pf = &bp->pf;\n\t\tint n = pf->active_vfs;\n\n\t\tif (n)\n\t\t\tbnxt_cfg_hw_sriov(bp, &n, true);\n\t}\n}\n\nstatic int bnxt_open(struct net_device *dev)\n{\n\tstruct bnxt *bp = netdev_priv(dev);\n\tint rc;\n\n\tif (test_bit(BNXT_STATE_ABORT_ERR, &bp->state)) {\n\t\trc = bnxt_reinit_after_abort(bp);\n\t\tif (rc) {\n\t\t\tif (rc == -EBUSY)\n\t\t\t\tnetdev_err(bp->dev, \"A previous firmware reset has not completed, aborting\\n\");\n\t\t\telse\n\t\t\t\tnetdev_err(bp->dev, \"Failed to reinitialize after aborted firmware reset\\n\");\n\t\t\treturn -ENODEV;\n\t\t}\n\t}\n\n\trc = bnxt_hwrm_if_change(bp, true);\n\tif (rc)\n\t\treturn rc;\n\trc = __bnxt_open_nic(bp, true, true);\n\tif (rc) {\n\t\tbnxt_hwrm_if_change(bp, false);\n\t} else {\n\t\tif (test_and_clear_bit(BNXT_STATE_FW_RESET_DET, &bp->state)) {\n\t\t\tif (!test_bit(BNXT_STATE_IN_FW_RESET, &bp->state)) {\n\t\t\t\tbnxt_ulp_start(bp, 0);\n\t\t\t\tbnxt_reenable_sriov(bp);\n\t\t\t}\n\t\t}\n\t\tbnxt_hwmon_open(bp);\n\t}\n\n\treturn rc;\n}\n\nstatic bool bnxt_drv_busy(struct bnxt *bp)\n{\n\treturn (test_bit(BNXT_STATE_IN_SP_TASK, &bp->state) ||\n\t\ttest_bit(BNXT_STATE_READ_STATS, &bp->state));\n}\n\nstatic void bnxt_get_ring_stats(struct bnxt *bp,\n\t\t\t\tstruct rtnl_link_stats64 *stats);\n\nstatic void __bnxt_close_nic(struct bnxt *bp, bool irq_re_init,\n\t\t\t     bool link_re_init)\n{\n\t/* Close the VF-reps before closing PF */\n\tif (BNXT_PF(bp))\n\t\tbnxt_vf_reps_close(bp);\n\n\t/* Change device state to avoid TX queue wake up's */\n\tbnxt_tx_disable(bp);\n\n\tclear_bit(BNXT_STATE_OPEN, &bp->state);\n\tsmp_mb__after_atomic();\n\twhile (bnxt_drv_busy(bp))\n\t\tmsleep(20);\n\n\t/* Flush rings and and disable interrupts */\n\tbnxt_shutdown_nic(bp, irq_re_init);\n\n\t/* TODO CHIMP_FW: Link/PHY related cleanup if (link_re_init) */\n\n\tbnxt_debug_dev_exit(bp);\n\tbnxt_disable_napi(bp);\n\tdel_timer_sync(&bp->timer);\n\tbnxt_free_skbs(bp);\n\n\t/* Save ring stats before shutdown */\n\tif (bp->bnapi && irq_re_init)\n\t\tbnxt_get_ring_stats(bp, &bp->net_stats_prev);\n\tif (irq_re_init) {\n\t\tbnxt_free_irq(bp);\n\t\tbnxt_del_napi(bp);\n\t}\n\tbnxt_free_mem(bp, irq_re_init);\n}\n\nint bnxt_close_nic(struct bnxt *bp, bool irq_re_init, bool link_re_init)\n{\n\tint rc = 0;\n\n\tif (test_bit(BNXT_STATE_IN_FW_RESET, &bp->state)) {\n\t\t/* If we get here, it means firmware reset is in progress\n\t\t * while we are trying to close.  We can safely proceed with\n\t\t * the close because we are holding rtnl_lock().  Some firmware\n\t\t * messages may fail as we proceed to close.  We set the\n\t\t * ABORT_ERR flag here so that the FW reset thread will later\n\t\t * abort when it gets the rtnl_lock() and sees the flag.\n\t\t */\n\t\tnetdev_warn(bp->dev, \"FW reset in progress during close, FW reset will be aborted\\n\");\n\t\tset_bit(BNXT_STATE_ABORT_ERR, &bp->state);\n\t}\n\n#ifdef CONFIG_BNXT_SRIOV\n\tif (bp->sriov_cfg) {\n\t\trc = wait_event_interruptible_timeout(bp->sriov_cfg_wait,\n\t\t\t\t\t\t      !bp->sriov_cfg,\n\t\t\t\t\t\t      BNXT_SRIOV_CFG_WAIT_TMO);\n\t\tif (rc)\n\t\t\tnetdev_warn(bp->dev, \"timeout waiting for SRIOV config operation to complete!\\n\");\n\t}\n#endif\n\t__bnxt_close_nic(bp, irq_re_init, link_re_init);\n\treturn rc;\n}\n\nstatic int bnxt_close(struct net_device *dev)\n{\n\tstruct bnxt *bp = netdev_priv(dev);\n\n\tbnxt_hwmon_close(bp);\n\tbnxt_close_nic(bp, true, true);\n\tbnxt_hwrm_shutdown_link(bp);\n\tbnxt_hwrm_if_change(bp, false);\n\treturn 0;\n}\n\nstatic int bnxt_hwrm_port_phy_read(struct bnxt *bp, u16 phy_addr, u16 reg,\n\t\t\t\t   u16 *val)\n{\n\tstruct hwrm_port_phy_mdio_read_output *resp = bp->hwrm_cmd_resp_addr;\n\tstruct hwrm_port_phy_mdio_read_input req = {0};\n\tint rc;\n\n\tif (bp->hwrm_spec_code < 0x10a00)\n\t\treturn -EOPNOTSUPP;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_PORT_PHY_MDIO_READ, -1, -1);\n\treq.port_id = cpu_to_le16(bp->pf.port_id);\n\treq.phy_addr = phy_addr;\n\treq.reg_addr = cpu_to_le16(reg & 0x1f);\n\tif (mdio_phy_id_is_c45(phy_addr)) {\n\t\treq.cl45_mdio = 1;\n\t\treq.phy_addr = mdio_phy_id_prtad(phy_addr);\n\t\treq.dev_addr = mdio_phy_id_devad(phy_addr);\n\t\treq.reg_addr = cpu_to_le16(reg);\n\t}\n\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (!rc)\n\t\t*val = le16_to_cpu(resp->reg_data);\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\treturn rc;\n}\n\nstatic int bnxt_hwrm_port_phy_write(struct bnxt *bp, u16 phy_addr, u16 reg,\n\t\t\t\t    u16 val)\n{\n\tstruct hwrm_port_phy_mdio_write_input req = {0};\n\n\tif (bp->hwrm_spec_code < 0x10a00)\n\t\treturn -EOPNOTSUPP;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_PORT_PHY_MDIO_WRITE, -1, -1);\n\treq.port_id = cpu_to_le16(bp->pf.port_id);\n\treq.phy_addr = phy_addr;\n\treq.reg_addr = cpu_to_le16(reg & 0x1f);\n\tif (mdio_phy_id_is_c45(phy_addr)) {\n\t\treq.cl45_mdio = 1;\n\t\treq.phy_addr = mdio_phy_id_prtad(phy_addr);\n\t\treq.dev_addr = mdio_phy_id_devad(phy_addr);\n\t\treq.reg_addr = cpu_to_le16(reg);\n\t}\n\treq.reg_data = cpu_to_le16(val);\n\n\treturn hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n}\n\n/* rtnl_lock held */\nstatic int bnxt_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)\n{\n\tstruct mii_ioctl_data *mdio = if_mii(ifr);\n\tstruct bnxt *bp = netdev_priv(dev);\n\tint rc;\n\n\tswitch (cmd) {\n\tcase SIOCGMIIPHY:\n\t\tmdio->phy_id = bp->link_info.phy_addr;\n\n\t\tfallthrough;\n\tcase SIOCGMIIREG: {\n\t\tu16 mii_regval = 0;\n\n\t\tif (!netif_running(dev))\n\t\t\treturn -EAGAIN;\n\n\t\trc = bnxt_hwrm_port_phy_read(bp, mdio->phy_id, mdio->reg_num,\n\t\t\t\t\t     &mii_regval);\n\t\tmdio->val_out = mii_regval;\n\t\treturn rc;\n\t}\n\n\tcase SIOCSMIIREG:\n\t\tif (!netif_running(dev))\n\t\t\treturn -EAGAIN;\n\n\t\treturn bnxt_hwrm_port_phy_write(bp, mdio->phy_id, mdio->reg_num,\n\t\t\t\t\t\tmdio->val_in);\n\n\tdefault:\n\t\t/* do nothing */\n\t\tbreak;\n\t}\n\treturn -EOPNOTSUPP;\n}\n\nstatic void bnxt_get_ring_stats(struct bnxt *bp,\n\t\t\t\tstruct rtnl_link_stats64 *stats)\n{\n\tint i;\n\n\tfor (i = 0; i < bp->cp_nr_rings; i++) {\n\t\tstruct bnxt_napi *bnapi = bp->bnapi[i];\n\t\tstruct bnxt_cp_ring_info *cpr = &bnapi->cp_ring;\n\t\tu64 *sw = cpr->stats.sw_stats;\n\n\t\tstats->rx_packets += BNXT_GET_RING_STATS64(sw, rx_ucast_pkts);\n\t\tstats->rx_packets += BNXT_GET_RING_STATS64(sw, rx_mcast_pkts);\n\t\tstats->rx_packets += BNXT_GET_RING_STATS64(sw, rx_bcast_pkts);\n\n\t\tstats->tx_packets += BNXT_GET_RING_STATS64(sw, tx_ucast_pkts);\n\t\tstats->tx_packets += BNXT_GET_RING_STATS64(sw, tx_mcast_pkts);\n\t\tstats->tx_packets += BNXT_GET_RING_STATS64(sw, tx_bcast_pkts);\n\n\t\tstats->rx_bytes += BNXT_GET_RING_STATS64(sw, rx_ucast_bytes);\n\t\tstats->rx_bytes += BNXT_GET_RING_STATS64(sw, rx_mcast_bytes);\n\t\tstats->rx_bytes += BNXT_GET_RING_STATS64(sw, rx_bcast_bytes);\n\n\t\tstats->tx_bytes += BNXT_GET_RING_STATS64(sw, tx_ucast_bytes);\n\t\tstats->tx_bytes += BNXT_GET_RING_STATS64(sw, tx_mcast_bytes);\n\t\tstats->tx_bytes += BNXT_GET_RING_STATS64(sw, tx_bcast_bytes);\n\n\t\tstats->rx_missed_errors +=\n\t\t\tBNXT_GET_RING_STATS64(sw, rx_discard_pkts);\n\n\t\tstats->multicast += BNXT_GET_RING_STATS64(sw, rx_mcast_pkts);\n\n\t\tstats->tx_dropped += BNXT_GET_RING_STATS64(sw, tx_error_pkts);\n\t}\n}\n\nstatic void bnxt_add_prev_stats(struct bnxt *bp,\n\t\t\t\tstruct rtnl_link_stats64 *stats)\n{\n\tstruct rtnl_link_stats64 *prev_stats = &bp->net_stats_prev;\n\n\tstats->rx_packets += prev_stats->rx_packets;\n\tstats->tx_packets += prev_stats->tx_packets;\n\tstats->rx_bytes += prev_stats->rx_bytes;\n\tstats->tx_bytes += prev_stats->tx_bytes;\n\tstats->rx_missed_errors += prev_stats->rx_missed_errors;\n\tstats->multicast += prev_stats->multicast;\n\tstats->tx_dropped += prev_stats->tx_dropped;\n}\n\nstatic void\nbnxt_get_stats64(struct net_device *dev, struct rtnl_link_stats64 *stats)\n{\n\tstruct bnxt *bp = netdev_priv(dev);\n\n\tset_bit(BNXT_STATE_READ_STATS, &bp->state);\n\t/* Make sure bnxt_close_nic() sees that we are reading stats before\n\t * we check the BNXT_STATE_OPEN flag.\n\t */\n\tsmp_mb__after_atomic();\n\tif (!test_bit(BNXT_STATE_OPEN, &bp->state)) {\n\t\tclear_bit(BNXT_STATE_READ_STATS, &bp->state);\n\t\t*stats = bp->net_stats_prev;\n\t\treturn;\n\t}\n\n\tbnxt_get_ring_stats(bp, stats);\n\tbnxt_add_prev_stats(bp, stats);\n\n\tif (bp->flags & BNXT_FLAG_PORT_STATS) {\n\t\tu64 *rx = bp->port_stats.sw_stats;\n\t\tu64 *tx = bp->port_stats.sw_stats +\n\t\t\t  BNXT_TX_PORT_STATS_BYTE_OFFSET / 8;\n\n\t\tstats->rx_crc_errors =\n\t\t\tBNXT_GET_RX_PORT_STATS64(rx, rx_fcs_err_frames);\n\t\tstats->rx_frame_errors =\n\t\t\tBNXT_GET_RX_PORT_STATS64(rx, rx_align_err_frames);\n\t\tstats->rx_length_errors =\n\t\t\tBNXT_GET_RX_PORT_STATS64(rx, rx_undrsz_frames) +\n\t\t\tBNXT_GET_RX_PORT_STATS64(rx, rx_ovrsz_frames) +\n\t\t\tBNXT_GET_RX_PORT_STATS64(rx, rx_runt_frames);\n\t\tstats->rx_errors =\n\t\t\tBNXT_GET_RX_PORT_STATS64(rx, rx_false_carrier_frames) +\n\t\t\tBNXT_GET_RX_PORT_STATS64(rx, rx_jbr_frames);\n\t\tstats->collisions =\n\t\t\tBNXT_GET_TX_PORT_STATS64(tx, tx_total_collisions);\n\t\tstats->tx_fifo_errors =\n\t\t\tBNXT_GET_TX_PORT_STATS64(tx, tx_fifo_underruns);\n\t\tstats->tx_errors = BNXT_GET_TX_PORT_STATS64(tx, tx_err);\n\t}\n\tclear_bit(BNXT_STATE_READ_STATS, &bp->state);\n}\n\nstatic bool bnxt_mc_list_updated(struct bnxt *bp, u32 *rx_mask)\n{\n\tstruct net_device *dev = bp->dev;\n\tstruct bnxt_vnic_info *vnic = &bp->vnic_info[0];\n\tstruct netdev_hw_addr *ha;\n\tu8 *haddr;\n\tint mc_count = 0;\n\tbool update = false;\n\tint off = 0;\n\n\tnetdev_for_each_mc_addr(ha, dev) {\n\t\tif (mc_count >= BNXT_MAX_MC_ADDRS) {\n\t\t\t*rx_mask |= CFA_L2_SET_RX_MASK_REQ_MASK_ALL_MCAST;\n\t\t\tvnic->mc_list_count = 0;\n\t\t\treturn false;\n\t\t}\n\t\thaddr = ha->addr;\n\t\tif (!ether_addr_equal(haddr, vnic->mc_list + off)) {\n\t\t\tmemcpy(vnic->mc_list + off, haddr, ETH_ALEN);\n\t\t\tupdate = true;\n\t\t}\n\t\toff += ETH_ALEN;\n\t\tmc_count++;\n\t}\n\tif (mc_count)\n\t\t*rx_mask |= CFA_L2_SET_RX_MASK_REQ_MASK_MCAST;\n\n\tif (mc_count != vnic->mc_list_count) {\n\t\tvnic->mc_list_count = mc_count;\n\t\tupdate = true;\n\t}\n\treturn update;\n}\n\nstatic bool bnxt_uc_list_updated(struct bnxt *bp)\n{\n\tstruct net_device *dev = bp->dev;\n\tstruct bnxt_vnic_info *vnic = &bp->vnic_info[0];\n\tstruct netdev_hw_addr *ha;\n\tint off = 0;\n\n\tif (netdev_uc_count(dev) != (vnic->uc_filter_count - 1))\n\t\treturn true;\n\n\tnetdev_for_each_uc_addr(ha, dev) {\n\t\tif (!ether_addr_equal(ha->addr, vnic->uc_list + off))\n\t\t\treturn true;\n\n\t\toff += ETH_ALEN;\n\t}\n\treturn false;\n}\n\nstatic void bnxt_set_rx_mode(struct net_device *dev)\n{\n\tstruct bnxt *bp = netdev_priv(dev);\n\tstruct bnxt_vnic_info *vnic;\n\tbool mc_update = false;\n\tbool uc_update;\n\tu32 mask;\n\n\tif (!test_bit(BNXT_STATE_OPEN, &bp->state))\n\t\treturn;\n\n\tvnic = &bp->vnic_info[0];\n\tmask = vnic->rx_mask;\n\tmask &= ~(CFA_L2_SET_RX_MASK_REQ_MASK_PROMISCUOUS |\n\t\t  CFA_L2_SET_RX_MASK_REQ_MASK_MCAST |\n\t\t  CFA_L2_SET_RX_MASK_REQ_MASK_ALL_MCAST |\n\t\t  CFA_L2_SET_RX_MASK_REQ_MASK_BCAST);\n\n\tif ((dev->flags & IFF_PROMISC) && bnxt_promisc_ok(bp))\n\t\tmask |= CFA_L2_SET_RX_MASK_REQ_MASK_PROMISCUOUS;\n\n\tuc_update = bnxt_uc_list_updated(bp);\n\n\tif (dev->flags & IFF_BROADCAST)\n\t\tmask |= CFA_L2_SET_RX_MASK_REQ_MASK_BCAST;\n\tif (dev->flags & IFF_ALLMULTI) {\n\t\tmask |= CFA_L2_SET_RX_MASK_REQ_MASK_ALL_MCAST;\n\t\tvnic->mc_list_count = 0;\n\t} else {\n\t\tmc_update = bnxt_mc_list_updated(bp, &mask);\n\t}\n\n\tif (mask != vnic->rx_mask || uc_update || mc_update) {\n\t\tvnic->rx_mask = mask;\n\n\t\tset_bit(BNXT_RX_MASK_SP_EVENT, &bp->sp_event);\n\t\tbnxt_queue_sp_work(bp);\n\t}\n}\n\nstatic int bnxt_cfg_rx_mode(struct bnxt *bp)\n{\n\tstruct net_device *dev = bp->dev;\n\tstruct bnxt_vnic_info *vnic = &bp->vnic_info[0];\n\tstruct netdev_hw_addr *ha;\n\tint i, off = 0, rc;\n\tbool uc_update;\n\n\tnetif_addr_lock_bh(dev);\n\tuc_update = bnxt_uc_list_updated(bp);\n\tnetif_addr_unlock_bh(dev);\n\n\tif (!uc_update)\n\t\tgoto skip_uc;\n\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\tfor (i = 1; i < vnic->uc_filter_count; i++) {\n\t\tstruct hwrm_cfa_l2_filter_free_input req = {0};\n\n\t\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_CFA_L2_FILTER_FREE, -1,\n\t\t\t\t       -1);\n\n\t\treq.l2_filter_id = vnic->fw_l2_filter_id[i];\n\n\t\trc = _hwrm_send_message(bp, &req, sizeof(req),\n\t\t\t\t\tHWRM_CMD_TIMEOUT);\n\t}\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\n\tvnic->uc_filter_count = 1;\n\n\tnetif_addr_lock_bh(dev);\n\tif (netdev_uc_count(dev) > (BNXT_MAX_UC_ADDRS - 1)) {\n\t\tvnic->rx_mask |= CFA_L2_SET_RX_MASK_REQ_MASK_PROMISCUOUS;\n\t} else {\n\t\tnetdev_for_each_uc_addr(ha, dev) {\n\t\t\tmemcpy(vnic->uc_list + off, ha->addr, ETH_ALEN);\n\t\t\toff += ETH_ALEN;\n\t\t\tvnic->uc_filter_count++;\n\t\t}\n\t}\n\tnetif_addr_unlock_bh(dev);\n\n\tfor (i = 1, off = 0; i < vnic->uc_filter_count; i++, off += ETH_ALEN) {\n\t\trc = bnxt_hwrm_set_vnic_filter(bp, 0, i, vnic->uc_list + off);\n\t\tif (rc) {\n\t\t\tnetdev_err(bp->dev, \"HWRM vnic filter failure rc: %x\\n\",\n\t\t\t\t   rc);\n\t\t\tvnic->uc_filter_count = i;\n\t\t\treturn rc;\n\t\t}\n\t}\n\nskip_uc:\n\trc = bnxt_hwrm_cfa_l2_set_rx_mask(bp, 0);\n\tif (rc && vnic->mc_list_count) {\n\t\tnetdev_info(bp->dev, \"Failed setting MC filters rc: %d, turning on ALL_MCAST mode\\n\",\n\t\t\t    rc);\n\t\tvnic->rx_mask |= CFA_L2_SET_RX_MASK_REQ_MASK_ALL_MCAST;\n\t\tvnic->mc_list_count = 0;\n\t\trc = bnxt_hwrm_cfa_l2_set_rx_mask(bp, 0);\n\t}\n\tif (rc)\n\t\tnetdev_err(bp->dev, \"HWRM cfa l2 rx mask failure rc: %d\\n\",\n\t\t\t   rc);\n\n\treturn rc;\n}\n\nstatic bool bnxt_can_reserve_rings(struct bnxt *bp)\n{\n#ifdef CONFIG_BNXT_SRIOV\n\tif (BNXT_NEW_RM(bp) && BNXT_VF(bp)) {\n\t\tstruct bnxt_hw_resc *hw_resc = &bp->hw_resc;\n\n\t\t/* No minimum rings were provisioned by the PF.  Don't\n\t\t * reserve rings by default when device is down.\n\t\t */\n\t\tif (hw_resc->min_tx_rings || hw_resc->resv_tx_rings)\n\t\t\treturn true;\n\n\t\tif (!netif_running(bp->dev))\n\t\t\treturn false;\n\t}\n#endif\n\treturn true;\n}\n\n/* If the chip and firmware supports RFS */\nstatic bool bnxt_rfs_supported(struct bnxt *bp)\n{\n\tif (bp->flags & BNXT_FLAG_CHIP_P5) {\n\t\tif (bp->fw_cap & BNXT_FW_CAP_CFA_RFS_RING_TBL_IDX_V2)\n\t\t\treturn true;\n\t\treturn false;\n\t}\n\tif (BNXT_PF(bp) && !BNXT_CHIP_TYPE_NITRO_A0(bp))\n\t\treturn true;\n\tif (bp->flags & BNXT_FLAG_NEW_RSS_CAP)\n\t\treturn true;\n\treturn false;\n}\n\n/* If runtime conditions support RFS */\nstatic bool bnxt_rfs_capable(struct bnxt *bp)\n{\n#ifdef CONFIG_RFS_ACCEL\n\tint vnics, max_vnics, max_rss_ctxs;\n\n\tif (bp->flags & BNXT_FLAG_CHIP_P5)\n\t\treturn bnxt_rfs_supported(bp);\n\tif (!(bp->flags & BNXT_FLAG_MSIX_CAP) || !bnxt_can_reserve_rings(bp))\n\t\treturn false;\n\n\tvnics = 1 + bp->rx_nr_rings;\n\tmax_vnics = bnxt_get_max_func_vnics(bp);\n\tmax_rss_ctxs = bnxt_get_max_func_rss_ctxs(bp);\n\n\t/* RSS contexts not a limiting factor */\n\tif (bp->flags & BNXT_FLAG_NEW_RSS_CAP)\n\t\tmax_rss_ctxs = max_vnics;\n\tif (vnics > max_vnics || vnics > max_rss_ctxs) {\n\t\tif (bp->rx_nr_rings > 1)\n\t\t\tnetdev_warn(bp->dev,\n\t\t\t\t    \"Not enough resources to support NTUPLE filters, enough resources for up to %d rx rings\\n\",\n\t\t\t\t    min(max_rss_ctxs - 1, max_vnics - 1));\n\t\treturn false;\n\t}\n\n\tif (!BNXT_NEW_RM(bp))\n\t\treturn true;\n\n\tif (vnics == bp->hw_resc.resv_vnics)\n\t\treturn true;\n\n\tbnxt_hwrm_reserve_rings(bp, 0, 0, 0, 0, 0, vnics);\n\tif (vnics <= bp->hw_resc.resv_vnics)\n\t\treturn true;\n\n\tnetdev_warn(bp->dev, \"Unable to reserve resources to support NTUPLE filters.\\n\");\n\tbnxt_hwrm_reserve_rings(bp, 0, 0, 0, 0, 0, 1);\n\treturn false;\n#else\n\treturn false;\n#endif\n}\n\nstatic netdev_features_t bnxt_fix_features(struct net_device *dev,\n\t\t\t\t\t   netdev_features_t features)\n{\n\tstruct bnxt *bp = netdev_priv(dev);\n\tnetdev_features_t vlan_features;\n\n\tif ((features & NETIF_F_NTUPLE) && !bnxt_rfs_capable(bp))\n\t\tfeatures &= ~NETIF_F_NTUPLE;\n\n\tif (bp->flags & BNXT_FLAG_NO_AGG_RINGS)\n\t\tfeatures &= ~(NETIF_F_LRO | NETIF_F_GRO_HW);\n\n\tif (!(features & NETIF_F_GRO))\n\t\tfeatures &= ~NETIF_F_GRO_HW;\n\n\tif (features & NETIF_F_GRO_HW)\n\t\tfeatures &= ~NETIF_F_LRO;\n\n\t/* Both CTAG and STAG VLAN accelaration on the RX side have to be\n\t * turned on or off together.\n\t */\n\tvlan_features = features & BNXT_HW_FEATURE_VLAN_ALL_RX;\n\tif (vlan_features != BNXT_HW_FEATURE_VLAN_ALL_RX) {\n\t\tif (dev->features & BNXT_HW_FEATURE_VLAN_ALL_RX)\n\t\t\tfeatures &= ~BNXT_HW_FEATURE_VLAN_ALL_RX;\n\t\telse if (vlan_features)\n\t\t\tfeatures |= BNXT_HW_FEATURE_VLAN_ALL_RX;\n\t}\n#ifdef CONFIG_BNXT_SRIOV\n\tif (BNXT_VF(bp) && bp->vf.vlan)\n\t\tfeatures &= ~BNXT_HW_FEATURE_VLAN_ALL_RX;\n#endif\n\treturn features;\n}\n\nstatic int bnxt_set_features(struct net_device *dev, netdev_features_t features)\n{\n\tstruct bnxt *bp = netdev_priv(dev);\n\tu32 flags = bp->flags;\n\tu32 changes;\n\tint rc = 0;\n\tbool re_init = false;\n\tbool update_tpa = false;\n\n\tflags &= ~BNXT_FLAG_ALL_CONFIG_FEATS;\n\tif (features & NETIF_F_GRO_HW)\n\t\tflags |= BNXT_FLAG_GRO;\n\telse if (features & NETIF_F_LRO)\n\t\tflags |= BNXT_FLAG_LRO;\n\n\tif (bp->flags & BNXT_FLAG_NO_AGG_RINGS)\n\t\tflags &= ~BNXT_FLAG_TPA;\n\n\tif (features & BNXT_HW_FEATURE_VLAN_ALL_RX)\n\t\tflags |= BNXT_FLAG_STRIP_VLAN;\n\n\tif (features & NETIF_F_NTUPLE)\n\t\tflags |= BNXT_FLAG_RFS;\n\n\tchanges = flags ^ bp->flags;\n\tif (changes & BNXT_FLAG_TPA) {\n\t\tupdate_tpa = true;\n\t\tif ((bp->flags & BNXT_FLAG_TPA) == 0 ||\n\t\t    (flags & BNXT_FLAG_TPA) == 0 ||\n\t\t    (bp->flags & BNXT_FLAG_CHIP_P5))\n\t\t\tre_init = true;\n\t}\n\n\tif (changes & ~BNXT_FLAG_TPA)\n\t\tre_init = true;\n\n\tif (flags != bp->flags) {\n\t\tu32 old_flags = bp->flags;\n\n\t\tif (!test_bit(BNXT_STATE_OPEN, &bp->state)) {\n\t\t\tbp->flags = flags;\n\t\t\tif (update_tpa)\n\t\t\t\tbnxt_set_ring_params(bp);\n\t\t\treturn rc;\n\t\t}\n\n\t\tif (re_init) {\n\t\t\tbnxt_close_nic(bp, false, false);\n\t\t\tbp->flags = flags;\n\t\t\tif (update_tpa)\n\t\t\t\tbnxt_set_ring_params(bp);\n\n\t\t\treturn bnxt_open_nic(bp, false, false);\n\t\t}\n\t\tif (update_tpa) {\n\t\t\tbp->flags = flags;\n\t\t\trc = bnxt_set_tpa(bp,\n\t\t\t\t\t  (flags & BNXT_FLAG_TPA) ?\n\t\t\t\t\t  true : false);\n\t\t\tif (rc)\n\t\t\t\tbp->flags = old_flags;\n\t\t}\n\t}\n\treturn rc;\n}\n\nint bnxt_dbg_hwrm_rd_reg(struct bnxt *bp, u32 reg_off, u16 num_words,\n\t\t\t u32 *reg_buf)\n{\n\tstruct hwrm_dbg_read_direct_output *resp = bp->hwrm_cmd_resp_addr;\n\tstruct hwrm_dbg_read_direct_input req = {0};\n\t__le32 *dbg_reg_buf;\n\tdma_addr_t mapping;\n\tint rc, i;\n\n\tdbg_reg_buf = dma_alloc_coherent(&bp->pdev->dev, num_words * 4,\n\t\t\t\t\t &mapping, GFP_KERNEL);\n\tif (!dbg_reg_buf)\n\t\treturn -ENOMEM;\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_DBG_READ_DIRECT, -1, -1);\n\treq.host_dest_addr = cpu_to_le64(mapping);\n\treq.read_addr = cpu_to_le32(reg_off + CHIMP_REG_VIEW_ADDR);\n\treq.read_len32 = cpu_to_le32(num_words);\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (rc || resp->error_code) {\n\t\trc = -EIO;\n\t\tgoto dbg_rd_reg_exit;\n\t}\n\tfor (i = 0; i < num_words; i++)\n\t\treg_buf[i] = le32_to_cpu(dbg_reg_buf[i]);\n\ndbg_rd_reg_exit:\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\tdma_free_coherent(&bp->pdev->dev, num_words * 4, dbg_reg_buf, mapping);\n\treturn rc;\n}\n\nstatic int bnxt_dbg_hwrm_ring_info_get(struct bnxt *bp, u8 ring_type,\n\t\t\t\t       u32 ring_id, u32 *prod, u32 *cons)\n{\n\tstruct hwrm_dbg_ring_info_get_output *resp = bp->hwrm_cmd_resp_addr;\n\tstruct hwrm_dbg_ring_info_get_input req = {0};\n\tint rc;\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_DBG_RING_INFO_GET, -1, -1);\n\treq.ring_type = ring_type;\n\treq.fw_ring_id = cpu_to_le32(ring_id);\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\trc = _hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\tif (!rc) {\n\t\t*prod = le32_to_cpu(resp->producer_index);\n\t\t*cons = le32_to_cpu(resp->consumer_index);\n\t}\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n\treturn rc;\n}\n\nstatic void bnxt_dump_tx_sw_state(struct bnxt_napi *bnapi)\n{\n\tstruct bnxt_tx_ring_info *txr = bnapi->tx_ring;\n\tint i = bnapi->index;\n\n\tif (!txr)\n\t\treturn;\n\n\tnetdev_info(bnapi->bp->dev, \"[%d]: tx{fw_ring: %d prod: %x cons: %x}\\n\",\n\t\t    i, txr->tx_ring_struct.fw_ring_id, txr->tx_prod,\n\t\t    txr->tx_cons);\n}\n\nstatic void bnxt_dump_rx_sw_state(struct bnxt_napi *bnapi)\n{\n\tstruct bnxt_rx_ring_info *rxr = bnapi->rx_ring;\n\tint i = bnapi->index;\n\n\tif (!rxr)\n\t\treturn;\n\n\tnetdev_info(bnapi->bp->dev, \"[%d]: rx{fw_ring: %d prod: %x} rx_agg{fw_ring: %d agg_prod: %x sw_agg_prod: %x}\\n\",\n\t\t    i, rxr->rx_ring_struct.fw_ring_id, rxr->rx_prod,\n\t\t    rxr->rx_agg_ring_struct.fw_ring_id, rxr->rx_agg_prod,\n\t\t    rxr->rx_sw_agg_prod);\n}\n\nstatic void bnxt_dump_cp_sw_state(struct bnxt_napi *bnapi)\n{\n\tstruct bnxt_cp_ring_info *cpr = &bnapi->cp_ring;\n\tint i = bnapi->index;\n\n\tnetdev_info(bnapi->bp->dev, \"[%d]: cp{fw_ring: %d raw_cons: %x}\\n\",\n\t\t    i, cpr->cp_ring_struct.fw_ring_id, cpr->cp_raw_cons);\n}\n\nstatic void bnxt_dbg_dump_states(struct bnxt *bp)\n{\n\tint i;\n\tstruct bnxt_napi *bnapi;\n\n\tfor (i = 0; i < bp->cp_nr_rings; i++) {\n\t\tbnapi = bp->bnapi[i];\n\t\tif (netif_msg_drv(bp)) {\n\t\t\tbnxt_dump_tx_sw_state(bnapi);\n\t\t\tbnxt_dump_rx_sw_state(bnapi);\n\t\t\tbnxt_dump_cp_sw_state(bnapi);\n\t\t}\n\t}\n}\n\nstatic int bnxt_hwrm_rx_ring_reset(struct bnxt *bp, int ring_nr)\n{\n\tstruct bnxt_rx_ring_info *rxr = &bp->rx_ring[ring_nr];\n\tstruct hwrm_ring_reset_input req = {0};\n\tstruct bnxt_napi *bnapi = rxr->bnapi;\n\tstruct bnxt_cp_ring_info *cpr;\n\tu16 cp_ring_id;\n\n\tcpr = &bnapi->cp_ring;\n\tcp_ring_id = cpr->cp_ring_struct.fw_ring_id;\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_RING_RESET, cp_ring_id, -1);\n\treq.ring_type = RING_RESET_REQ_RING_TYPE_RX_RING_GRP;\n\treq.ring_id = cpu_to_le16(bp->grp_info[bnapi->index].fw_grp_id);\n\treturn hwrm_send_message_silent(bp, &req, sizeof(req),\n\t\t\t\t\tHWRM_CMD_TIMEOUT);\n}\n\nstatic void bnxt_reset_task(struct bnxt *bp, bool silent)\n{\n\tif (!silent)\n\t\tbnxt_dbg_dump_states(bp);\n\tif (netif_running(bp->dev)) {\n\t\tint rc;\n\n\t\tif (silent) {\n\t\t\tbnxt_close_nic(bp, false, false);\n\t\t\tbnxt_open_nic(bp, false, false);\n\t\t} else {\n\t\t\tbnxt_ulp_stop(bp);\n\t\t\tbnxt_close_nic(bp, true, false);\n\t\t\trc = bnxt_open_nic(bp, true, false);\n\t\t\tbnxt_ulp_start(bp, rc);\n\t\t}\n\t}\n}\n\nstatic void bnxt_tx_timeout(struct net_device *dev, unsigned int txqueue)\n{\n\tstruct bnxt *bp = netdev_priv(dev);\n\n\tnetdev_err(bp->dev,  \"TX timeout detected, starting reset task!\\n\");\n\tset_bit(BNXT_RESET_TASK_SP_EVENT, &bp->sp_event);\n\tbnxt_queue_sp_work(bp);\n}\n\nstatic void bnxt_fw_health_check(struct bnxt *bp)\n{\n\tstruct bnxt_fw_health *fw_health = bp->fw_health;\n\tu32 val;\n\n\tif (!fw_health->enabled || test_bit(BNXT_STATE_IN_FW_RESET, &bp->state))\n\t\treturn;\n\n\tif (fw_health->tmr_counter) {\n\t\tfw_health->tmr_counter--;\n\t\treturn;\n\t}\n\n\tval = bnxt_fw_health_readl(bp, BNXT_FW_HEARTBEAT_REG);\n\tif (val == fw_health->last_fw_heartbeat)\n\t\tgoto fw_reset;\n\n\tfw_health->last_fw_heartbeat = val;\n\n\tval = bnxt_fw_health_readl(bp, BNXT_FW_RESET_CNT_REG);\n\tif (val != fw_health->last_fw_reset_cnt)\n\t\tgoto fw_reset;\n\n\tfw_health->tmr_counter = fw_health->tmr_multiplier;\n\treturn;\n\nfw_reset:\n\tset_bit(BNXT_FW_EXCEPTION_SP_EVENT, &bp->sp_event);\n\tbnxt_queue_sp_work(bp);\n}\n\nstatic void bnxt_timer(struct timer_list *t)\n{\n\tstruct bnxt *bp = from_timer(bp, t, timer);\n\tstruct net_device *dev = bp->dev;\n\n\tif (!netif_running(dev) || !test_bit(BNXT_STATE_OPEN, &bp->state))\n\t\treturn;\n\n\tif (atomic_read(&bp->intr_sem) != 0)\n\t\tgoto bnxt_restart_timer;\n\n\tif (bp->fw_cap & BNXT_FW_CAP_ERROR_RECOVERY)\n\t\tbnxt_fw_health_check(bp);\n\n\tif (bp->link_info.link_up && bp->stats_coal_ticks) {\n\t\tset_bit(BNXT_PERIODIC_STATS_SP_EVENT, &bp->sp_event);\n\t\tbnxt_queue_sp_work(bp);\n\t}\n\n\tif (bnxt_tc_flower_enabled(bp)) {\n\t\tset_bit(BNXT_FLOW_STATS_SP_EVENT, &bp->sp_event);\n\t\tbnxt_queue_sp_work(bp);\n\t}\n\n#ifdef CONFIG_RFS_ACCEL\n\tif ((bp->flags & BNXT_FLAG_RFS) && bp->ntp_fltr_count) {\n\t\tset_bit(BNXT_RX_NTP_FLTR_SP_EVENT, &bp->sp_event);\n\t\tbnxt_queue_sp_work(bp);\n\t}\n#endif /*CONFIG_RFS_ACCEL*/\n\n\tif (bp->link_info.phy_retry) {\n\t\tif (time_after(jiffies, bp->link_info.phy_retry_expires)) {\n\t\t\tbp->link_info.phy_retry = false;\n\t\t\tnetdev_warn(bp->dev, \"failed to update phy settings after maximum retries.\\n\");\n\t\t} else {\n\t\t\tset_bit(BNXT_UPDATE_PHY_SP_EVENT, &bp->sp_event);\n\t\t\tbnxt_queue_sp_work(bp);\n\t\t}\n\t}\n\n\tif ((bp->flags & BNXT_FLAG_CHIP_P5) && !bp->chip_rev &&\n\t    netif_carrier_ok(dev)) {\n\t\tset_bit(BNXT_RING_COAL_NOW_SP_EVENT, &bp->sp_event);\n\t\tbnxt_queue_sp_work(bp);\n\t}\nbnxt_restart_timer:\n\tmod_timer(&bp->timer, jiffies + bp->current_interval);\n}\n\nstatic void bnxt_rtnl_lock_sp(struct bnxt *bp)\n{\n\t/* We are called from bnxt_sp_task which has BNXT_STATE_IN_SP_TASK\n\t * set.  If the device is being closed, bnxt_close() may be holding\n\t * rtnl() and waiting for BNXT_STATE_IN_SP_TASK to clear.  So we\n\t * must clear BNXT_STATE_IN_SP_TASK before holding rtnl().\n\t */\n\tclear_bit(BNXT_STATE_IN_SP_TASK, &bp->state);\n\trtnl_lock();\n}\n\nstatic void bnxt_rtnl_unlock_sp(struct bnxt *bp)\n{\n\tset_bit(BNXT_STATE_IN_SP_TASK, &bp->state);\n\trtnl_unlock();\n}\n\n/* Only called from bnxt_sp_task() */\nstatic void bnxt_reset(struct bnxt *bp, bool silent)\n{\n\tbnxt_rtnl_lock_sp(bp);\n\tif (test_bit(BNXT_STATE_OPEN, &bp->state))\n\t\tbnxt_reset_task(bp, silent);\n\tbnxt_rtnl_unlock_sp(bp);\n}\n\n/* Only called from bnxt_sp_task() */\nstatic void bnxt_rx_ring_reset(struct bnxt *bp)\n{\n\tint i;\n\n\tbnxt_rtnl_lock_sp(bp);\n\tif (!test_bit(BNXT_STATE_OPEN, &bp->state)) {\n\t\tbnxt_rtnl_unlock_sp(bp);\n\t\treturn;\n\t}\n\t/* Disable and flush TPA before resetting the RX ring */\n\tif (bp->flags & BNXT_FLAG_TPA)\n\t\tbnxt_set_tpa(bp, false);\n\tfor (i = 0; i < bp->rx_nr_rings; i++) {\n\t\tstruct bnxt_rx_ring_info *rxr = &bp->rx_ring[i];\n\t\tstruct bnxt_cp_ring_info *cpr;\n\t\tint rc;\n\n\t\tif (!rxr->bnapi->in_reset)\n\t\t\tcontinue;\n\n\t\trc = bnxt_hwrm_rx_ring_reset(bp, i);\n\t\tif (rc) {\n\t\t\tif (rc == -EINVAL || rc == -EOPNOTSUPP)\n\t\t\t\tnetdev_info_once(bp->dev, \"RX ring reset not supported by firmware, falling back to global reset\\n\");\n\t\t\telse\n\t\t\t\tnetdev_warn(bp->dev, \"RX ring reset failed, rc = %d, falling back to global reset\\n\",\n\t\t\t\t\t    rc);\n\t\t\tbnxt_reset_task(bp, true);\n\t\t\tbreak;\n\t\t}\n\t\tbnxt_free_one_rx_ring_skbs(bp, i);\n\t\trxr->rx_prod = 0;\n\t\trxr->rx_agg_prod = 0;\n\t\trxr->rx_sw_agg_prod = 0;\n\t\trxr->rx_next_cons = 0;\n\t\trxr->bnapi->in_reset = false;\n\t\tbnxt_alloc_one_rx_ring(bp, i);\n\t\tcpr = &rxr->bnapi->cp_ring;\n\t\tcpr->sw_stats.rx.rx_resets++;\n\t\tif (bp->flags & BNXT_FLAG_AGG_RINGS)\n\t\t\tbnxt_db_write(bp, &rxr->rx_agg_db, rxr->rx_agg_prod);\n\t\tbnxt_db_write(bp, &rxr->rx_db, rxr->rx_prod);\n\t}\n\tif (bp->flags & BNXT_FLAG_TPA)\n\t\tbnxt_set_tpa(bp, true);\n\tbnxt_rtnl_unlock_sp(bp);\n}\n\nstatic void bnxt_fw_reset_close(struct bnxt *bp)\n{\n\tbnxt_ulp_stop(bp);\n\t/* When firmware is in fatal state, quiesce device and disable\n\t * bus master to prevent any potential bad DMAs before freeing\n\t * kernel memory.\n\t */\n\tif (test_bit(BNXT_STATE_FW_FATAL_COND, &bp->state)) {\n\t\tu16 val = 0;\n\n\t\tpci_read_config_word(bp->pdev, PCI_SUBSYSTEM_ID, &val);\n\t\tif (val == 0xffff)\n\t\t\tbp->fw_reset_min_dsecs = 0;\n\t\tbnxt_tx_disable(bp);\n\t\tbnxt_disable_napi(bp);\n\t\tbnxt_disable_int_sync(bp);\n\t\tbnxt_free_irq(bp);\n\t\tbnxt_clear_int_mode(bp);\n\t\tpci_disable_device(bp->pdev);\n\t}\n\t__bnxt_close_nic(bp, true, false);\n\tbnxt_clear_int_mode(bp);\n\tbnxt_hwrm_func_drv_unrgtr(bp);\n\tif (pci_is_enabled(bp->pdev))\n\t\tpci_disable_device(bp->pdev);\n\tbnxt_free_ctx_mem(bp);\n\tkfree(bp->ctx);\n\tbp->ctx = NULL;\n}\n\nstatic bool is_bnxt_fw_ok(struct bnxt *bp)\n{\n\tstruct bnxt_fw_health *fw_health = bp->fw_health;\n\tbool no_heartbeat = false, has_reset = false;\n\tu32 val;\n\n\tval = bnxt_fw_health_readl(bp, BNXT_FW_HEARTBEAT_REG);\n\tif (val == fw_health->last_fw_heartbeat)\n\t\tno_heartbeat = true;\n\n\tval = bnxt_fw_health_readl(bp, BNXT_FW_RESET_CNT_REG);\n\tif (val != fw_health->last_fw_reset_cnt)\n\t\thas_reset = true;\n\n\tif (!no_heartbeat && has_reset)\n\t\treturn true;\n\n\treturn false;\n}\n\n/* rtnl_lock is acquired before calling this function */\nstatic void bnxt_force_fw_reset(struct bnxt *bp)\n{\n\tstruct bnxt_fw_health *fw_health = bp->fw_health;\n\tu32 wait_dsecs;\n\n\tif (!test_bit(BNXT_STATE_OPEN, &bp->state) ||\n\t    test_bit(BNXT_STATE_IN_FW_RESET, &bp->state))\n\t\treturn;\n\n\tset_bit(BNXT_STATE_IN_FW_RESET, &bp->state);\n\tbnxt_fw_reset_close(bp);\n\twait_dsecs = fw_health->master_func_wait_dsecs;\n\tif (fw_health->master) {\n\t\tif (fw_health->flags & ERROR_RECOVERY_QCFG_RESP_FLAGS_CO_CPU)\n\t\t\twait_dsecs = 0;\n\t\tbp->fw_reset_state = BNXT_FW_RESET_STATE_RESET_FW;\n\t} else {\n\t\tbp->fw_reset_timestamp = jiffies + wait_dsecs * HZ / 10;\n\t\twait_dsecs = fw_health->normal_func_wait_dsecs;\n\t\tbp->fw_reset_state = BNXT_FW_RESET_STATE_ENABLE_DEV;\n\t}\n\n\tbp->fw_reset_min_dsecs = fw_health->post_reset_wait_dsecs;\n\tbp->fw_reset_max_dsecs = fw_health->post_reset_max_wait_dsecs;\n\tbnxt_queue_fw_reset_work(bp, wait_dsecs * HZ / 10);\n}\n\nvoid bnxt_fw_exception(struct bnxt *bp)\n{\n\tnetdev_warn(bp->dev, \"Detected firmware fatal condition, initiating reset\\n\");\n\tset_bit(BNXT_STATE_FW_FATAL_COND, &bp->state);\n\tbnxt_rtnl_lock_sp(bp);\n\tbnxt_force_fw_reset(bp);\n\tbnxt_rtnl_unlock_sp(bp);\n}\n\n/* Returns the number of registered VFs, or 1 if VF configuration is pending, or\n * < 0 on error.\n */\nstatic int bnxt_get_registered_vfs(struct bnxt *bp)\n{\n#ifdef CONFIG_BNXT_SRIOV\n\tint rc;\n\n\tif (!BNXT_PF(bp))\n\t\treturn 0;\n\n\trc = bnxt_hwrm_func_qcfg(bp);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"func_qcfg cmd failed, rc = %d\\n\", rc);\n\t\treturn rc;\n\t}\n\tif (bp->pf.registered_vfs)\n\t\treturn bp->pf.registered_vfs;\n\tif (bp->sriov_cfg)\n\t\treturn 1;\n#endif\n\treturn 0;\n}\n\nvoid bnxt_fw_reset(struct bnxt *bp)\n{\n\tbnxt_rtnl_lock_sp(bp);\n\tif (test_bit(BNXT_STATE_OPEN, &bp->state) &&\n\t    !test_bit(BNXT_STATE_IN_FW_RESET, &bp->state)) {\n\t\tint n = 0, tmo;\n\n\t\tset_bit(BNXT_STATE_IN_FW_RESET, &bp->state);\n\t\tif (bp->pf.active_vfs &&\n\t\t    !test_bit(BNXT_STATE_FW_FATAL_COND, &bp->state))\n\t\t\tn = bnxt_get_registered_vfs(bp);\n\t\tif (n < 0) {\n\t\t\tnetdev_err(bp->dev, \"Firmware reset aborted, rc = %d\\n\",\n\t\t\t\t   n);\n\t\t\tclear_bit(BNXT_STATE_IN_FW_RESET, &bp->state);\n\t\t\tdev_close(bp->dev);\n\t\t\tgoto fw_reset_exit;\n\t\t} else if (n > 0) {\n\t\t\tu16 vf_tmo_dsecs = n * 10;\n\n\t\t\tif (bp->fw_reset_max_dsecs < vf_tmo_dsecs)\n\t\t\t\tbp->fw_reset_max_dsecs = vf_tmo_dsecs;\n\t\t\tbp->fw_reset_state =\n\t\t\t\tBNXT_FW_RESET_STATE_POLL_VF;\n\t\t\tbnxt_queue_fw_reset_work(bp, HZ / 10);\n\t\t\tgoto fw_reset_exit;\n\t\t}\n\t\tbnxt_fw_reset_close(bp);\n\t\tif (bp->fw_cap & BNXT_FW_CAP_ERR_RECOVER_RELOAD) {\n\t\t\tbp->fw_reset_state = BNXT_FW_RESET_STATE_POLL_FW_DOWN;\n\t\t\ttmo = HZ / 10;\n\t\t} else {\n\t\t\tbp->fw_reset_state = BNXT_FW_RESET_STATE_ENABLE_DEV;\n\t\t\ttmo = bp->fw_reset_min_dsecs * HZ / 10;\n\t\t}\n\t\tbnxt_queue_fw_reset_work(bp, tmo);\n\t}\nfw_reset_exit:\n\tbnxt_rtnl_unlock_sp(bp);\n}\n\nstatic void bnxt_chk_missed_irq(struct bnxt *bp)\n{\n\tint i;\n\n\tif (!(bp->flags & BNXT_FLAG_CHIP_P5))\n\t\treturn;\n\n\tfor (i = 0; i < bp->cp_nr_rings; i++) {\n\t\tstruct bnxt_napi *bnapi = bp->bnapi[i];\n\t\tstruct bnxt_cp_ring_info *cpr;\n\t\tu32 fw_ring_id;\n\t\tint j;\n\n\t\tif (!bnapi)\n\t\t\tcontinue;\n\n\t\tcpr = &bnapi->cp_ring;\n\t\tfor (j = 0; j < 2; j++) {\n\t\t\tstruct bnxt_cp_ring_info *cpr2 = cpr->cp_ring_arr[j];\n\t\t\tu32 val[2];\n\n\t\t\tif (!cpr2 || cpr2->has_more_work ||\n\t\t\t    !bnxt_has_work(bp, cpr2))\n\t\t\t\tcontinue;\n\n\t\t\tif (cpr2->cp_raw_cons != cpr2->last_cp_raw_cons) {\n\t\t\t\tcpr2->last_cp_raw_cons = cpr2->cp_raw_cons;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tfw_ring_id = cpr2->cp_ring_struct.fw_ring_id;\n\t\t\tbnxt_dbg_hwrm_ring_info_get(bp,\n\t\t\t\tDBG_RING_INFO_GET_REQ_RING_TYPE_L2_CMPL,\n\t\t\t\tfw_ring_id, &val[0], &val[1]);\n\t\t\tcpr->sw_stats.cmn.missed_irqs++;\n\t\t}\n\t}\n}\n\nstatic void bnxt_cfg_ntp_filters(struct bnxt *);\n\nstatic void bnxt_init_ethtool_link_settings(struct bnxt *bp)\n{\n\tstruct bnxt_link_info *link_info = &bp->link_info;\n\n\tif (BNXT_AUTO_MODE(link_info->auto_mode)) {\n\t\tlink_info->autoneg = BNXT_AUTONEG_SPEED;\n\t\tif (bp->hwrm_spec_code >= 0x10201) {\n\t\t\tif (link_info->auto_pause_setting &\n\t\t\t    PORT_PHY_CFG_REQ_AUTO_PAUSE_AUTONEG_PAUSE)\n\t\t\t\tlink_info->autoneg |= BNXT_AUTONEG_FLOW_CTRL;\n\t\t} else {\n\t\t\tlink_info->autoneg |= BNXT_AUTONEG_FLOW_CTRL;\n\t\t}\n\t\tlink_info->advertising = link_info->auto_link_speeds;\n\t\tlink_info->advertising_pam4 = link_info->auto_pam4_link_speeds;\n\t} else {\n\t\tlink_info->req_link_speed = link_info->force_link_speed;\n\t\tlink_info->req_signal_mode = BNXT_SIG_MODE_NRZ;\n\t\tif (link_info->force_pam4_link_speed) {\n\t\t\tlink_info->req_link_speed =\n\t\t\t\tlink_info->force_pam4_link_speed;\n\t\t\tlink_info->req_signal_mode = BNXT_SIG_MODE_PAM4;\n\t\t}\n\t\tlink_info->req_duplex = link_info->duplex_setting;\n\t}\n\tif (link_info->autoneg & BNXT_AUTONEG_FLOW_CTRL)\n\t\tlink_info->req_flow_ctrl =\n\t\t\tlink_info->auto_pause_setting & BNXT_LINK_PAUSE_BOTH;\n\telse\n\t\tlink_info->req_flow_ctrl = link_info->force_pause_setting;\n}\n\nstatic void bnxt_fw_echo_reply(struct bnxt *bp)\n{\n\tstruct bnxt_fw_health *fw_health = bp->fw_health;\n\tstruct hwrm_func_echo_response_input req = {0};\n\n\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_FUNC_ECHO_RESPONSE, -1, -1);\n\treq.event_data1 = cpu_to_le32(fw_health->echo_req_data1);\n\treq.event_data2 = cpu_to_le32(fw_health->echo_req_data2);\n\thwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n}\n\nstatic void bnxt_sp_task(struct work_struct *work)\n{\n\tstruct bnxt *bp = container_of(work, struct bnxt, sp_task);\n\n\tset_bit(BNXT_STATE_IN_SP_TASK, &bp->state);\n\tsmp_mb__after_atomic();\n\tif (!test_bit(BNXT_STATE_OPEN, &bp->state)) {\n\t\tclear_bit(BNXT_STATE_IN_SP_TASK, &bp->state);\n\t\treturn;\n\t}\n\n\tif (test_and_clear_bit(BNXT_RX_MASK_SP_EVENT, &bp->sp_event))\n\t\tbnxt_cfg_rx_mode(bp);\n\n\tif (test_and_clear_bit(BNXT_RX_NTP_FLTR_SP_EVENT, &bp->sp_event))\n\t\tbnxt_cfg_ntp_filters(bp);\n\tif (test_and_clear_bit(BNXT_HWRM_EXEC_FWD_REQ_SP_EVENT, &bp->sp_event))\n\t\tbnxt_hwrm_exec_fwd_req(bp);\n\tif (test_and_clear_bit(BNXT_PERIODIC_STATS_SP_EVENT, &bp->sp_event)) {\n\t\tbnxt_hwrm_port_qstats(bp, 0);\n\t\tbnxt_hwrm_port_qstats_ext(bp, 0);\n\t\tbnxt_accumulate_all_stats(bp);\n\t}\n\n\tif (test_and_clear_bit(BNXT_LINK_CHNG_SP_EVENT, &bp->sp_event)) {\n\t\tint rc;\n\n\t\tmutex_lock(&bp->link_lock);\n\t\tif (test_and_clear_bit(BNXT_LINK_SPEED_CHNG_SP_EVENT,\n\t\t\t\t       &bp->sp_event))\n\t\t\tbnxt_hwrm_phy_qcaps(bp);\n\n\t\trc = bnxt_update_link(bp, true);\n\t\tif (rc)\n\t\t\tnetdev_err(bp->dev, \"SP task can't update link (rc: %x)\\n\",\n\t\t\t\t   rc);\n\n\t\tif (test_and_clear_bit(BNXT_LINK_CFG_CHANGE_SP_EVENT,\n\t\t\t\t       &bp->sp_event))\n\t\t\tbnxt_init_ethtool_link_settings(bp);\n\t\tmutex_unlock(&bp->link_lock);\n\t}\n\tif (test_and_clear_bit(BNXT_UPDATE_PHY_SP_EVENT, &bp->sp_event)) {\n\t\tint rc;\n\n\t\tmutex_lock(&bp->link_lock);\n\t\trc = bnxt_update_phy_setting(bp);\n\t\tmutex_unlock(&bp->link_lock);\n\t\tif (rc) {\n\t\t\tnetdev_warn(bp->dev, \"update phy settings retry failed\\n\");\n\t\t} else {\n\t\t\tbp->link_info.phy_retry = false;\n\t\t\tnetdev_info(bp->dev, \"update phy settings retry succeeded\\n\");\n\t\t}\n\t}\n\tif (test_and_clear_bit(BNXT_HWRM_PORT_MODULE_SP_EVENT, &bp->sp_event)) {\n\t\tmutex_lock(&bp->link_lock);\n\t\tbnxt_get_port_module_status(bp);\n\t\tmutex_unlock(&bp->link_lock);\n\t}\n\n\tif (test_and_clear_bit(BNXT_FLOW_STATS_SP_EVENT, &bp->sp_event))\n\t\tbnxt_tc_flow_stats_work(bp);\n\n\tif (test_and_clear_bit(BNXT_RING_COAL_NOW_SP_EVENT, &bp->sp_event))\n\t\tbnxt_chk_missed_irq(bp);\n\n\tif (test_and_clear_bit(BNXT_FW_ECHO_REQUEST_SP_EVENT, &bp->sp_event))\n\t\tbnxt_fw_echo_reply(bp);\n\n\t/* These functions below will clear BNXT_STATE_IN_SP_TASK.  They\n\t * must be the last functions to be called before exiting.\n\t */\n\tif (test_and_clear_bit(BNXT_RESET_TASK_SP_EVENT, &bp->sp_event))\n\t\tbnxt_reset(bp, false);\n\n\tif (test_and_clear_bit(BNXT_RESET_TASK_SILENT_SP_EVENT, &bp->sp_event))\n\t\tbnxt_reset(bp, true);\n\n\tif (test_and_clear_bit(BNXT_RST_RING_SP_EVENT, &bp->sp_event))\n\t\tbnxt_rx_ring_reset(bp);\n\n\tif (test_and_clear_bit(BNXT_FW_RESET_NOTIFY_SP_EVENT, &bp->sp_event))\n\t\tbnxt_devlink_health_report(bp, BNXT_FW_RESET_NOTIFY_SP_EVENT);\n\n\tif (test_and_clear_bit(BNXT_FW_EXCEPTION_SP_EVENT, &bp->sp_event)) {\n\t\tif (!is_bnxt_fw_ok(bp))\n\t\t\tbnxt_devlink_health_report(bp,\n\t\t\t\t\t\t   BNXT_FW_EXCEPTION_SP_EVENT);\n\t}\n\n\tsmp_mb__before_atomic();\n\tclear_bit(BNXT_STATE_IN_SP_TASK, &bp->state);\n}\n\n/* Under rtnl_lock */\nint bnxt_check_rings(struct bnxt *bp, int tx, int rx, bool sh, int tcs,\n\t\t     int tx_xdp)\n{\n\tint max_rx, max_tx, tx_sets = 1;\n\tint tx_rings_needed, stats;\n\tint rx_rings = rx;\n\tint cp, vnics, rc;\n\n\tif (tcs)\n\t\ttx_sets = tcs;\n\n\trc = bnxt_get_max_rings(bp, &max_rx, &max_tx, sh);\n\tif (rc)\n\t\treturn rc;\n\n\tif (max_rx < rx)\n\t\treturn -ENOMEM;\n\n\ttx_rings_needed = tx * tx_sets + tx_xdp;\n\tif (max_tx < tx_rings_needed)\n\t\treturn -ENOMEM;\n\n\tvnics = 1;\n\tif ((bp->flags & (BNXT_FLAG_RFS | BNXT_FLAG_CHIP_P5)) == BNXT_FLAG_RFS)\n\t\tvnics += rx_rings;\n\n\tif (bp->flags & BNXT_FLAG_AGG_RINGS)\n\t\trx_rings <<= 1;\n\tcp = sh ? max_t(int, tx_rings_needed, rx) : tx_rings_needed + rx;\n\tstats = cp;\n\tif (BNXT_NEW_RM(bp)) {\n\t\tcp += bnxt_get_ulp_msix_num(bp);\n\t\tstats += bnxt_get_ulp_stat_ctxs(bp);\n\t}\n\treturn bnxt_hwrm_check_rings(bp, tx_rings_needed, rx_rings, rx, cp,\n\t\t\t\t     stats, vnics);\n}\n\nstatic void bnxt_unmap_bars(struct bnxt *bp, struct pci_dev *pdev)\n{\n\tif (bp->bar2) {\n\t\tpci_iounmap(pdev, bp->bar2);\n\t\tbp->bar2 = NULL;\n\t}\n\n\tif (bp->bar1) {\n\t\tpci_iounmap(pdev, bp->bar1);\n\t\tbp->bar1 = NULL;\n\t}\n\n\tif (bp->bar0) {\n\t\tpci_iounmap(pdev, bp->bar0);\n\t\tbp->bar0 = NULL;\n\t}\n}\n\nstatic void bnxt_cleanup_pci(struct bnxt *bp)\n{\n\tbnxt_unmap_bars(bp, bp->pdev);\n\tpci_release_regions(bp->pdev);\n\tif (pci_is_enabled(bp->pdev))\n\t\tpci_disable_device(bp->pdev);\n}\n\nstatic void bnxt_init_dflt_coal(struct bnxt *bp)\n{\n\tstruct bnxt_coal *coal;\n\n\t/* Tick values in micro seconds.\n\t * 1 coal_buf x bufs_per_record = 1 completion record.\n\t */\n\tcoal = &bp->rx_coal;\n\tcoal->coal_ticks = 10;\n\tcoal->coal_bufs = 30;\n\tcoal->coal_ticks_irq = 1;\n\tcoal->coal_bufs_irq = 2;\n\tcoal->idle_thresh = 50;\n\tcoal->bufs_per_record = 2;\n\tcoal->budget = 64;\t\t/* NAPI budget */\n\n\tcoal = &bp->tx_coal;\n\tcoal->coal_ticks = 28;\n\tcoal->coal_bufs = 30;\n\tcoal->coal_ticks_irq = 2;\n\tcoal->coal_bufs_irq = 2;\n\tcoal->bufs_per_record = 1;\n\n\tbp->stats_coal_ticks = BNXT_DEF_STATS_COAL_TICKS;\n}\n\nstatic int bnxt_fw_init_one_p1(struct bnxt *bp)\n{\n\tint rc;\n\n\tbp->fw_cap = 0;\n\trc = bnxt_hwrm_ver_get(bp);\n\tbnxt_try_map_fw_health_reg(bp);\n\tif (rc) {\n\t\trc = bnxt_try_recover_fw(bp);\n\t\tif (rc)\n\t\t\treturn rc;\n\t\trc = bnxt_hwrm_ver_get(bp);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\tif (bp->fw_cap & BNXT_FW_CAP_KONG_MB_CHNL) {\n\t\trc = bnxt_alloc_kong_hwrm_resources(bp);\n\t\tif (rc)\n\t\t\tbp->fw_cap &= ~BNXT_FW_CAP_KONG_MB_CHNL;\n\t}\n\n\tif ((bp->fw_cap & BNXT_FW_CAP_SHORT_CMD) ||\n\t    bp->hwrm_max_ext_req_len > BNXT_HWRM_MAX_REQ_LEN) {\n\t\trc = bnxt_alloc_hwrm_short_cmd_req(bp);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\tbnxt_nvm_cfg_ver_get(bp);\n\n\trc = bnxt_hwrm_func_reset(bp);\n\tif (rc)\n\t\treturn -ENODEV;\n\n\tbnxt_hwrm_fw_set_time(bp);\n\treturn 0;\n}\n\nstatic int bnxt_fw_init_one_p2(struct bnxt *bp)\n{\n\tint rc;\n\n\t/* Get the MAX capabilities for this function */\n\trc = bnxt_hwrm_func_qcaps(bp);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"hwrm query capability failure rc: %x\\n\",\n\t\t\t   rc);\n\t\treturn -ENODEV;\n\t}\n\n\trc = bnxt_hwrm_cfa_adv_flow_mgnt_qcaps(bp);\n\tif (rc)\n\t\tnetdev_warn(bp->dev, \"hwrm query adv flow mgnt failure rc: %d\\n\",\n\t\t\t    rc);\n\n\tif (bnxt_alloc_fw_health(bp)) {\n\t\tnetdev_warn(bp->dev, \"no memory for firmware error recovery\\n\");\n\t} else {\n\t\trc = bnxt_hwrm_error_recovery_qcfg(bp);\n\t\tif (rc)\n\t\t\tnetdev_warn(bp->dev, \"hwrm query error recovery failure rc: %d\\n\",\n\t\t\t\t    rc);\n\t}\n\n\trc = bnxt_hwrm_func_drv_rgtr(bp, NULL, 0, false);\n\tif (rc)\n\t\treturn -ENODEV;\n\n\tbnxt_hwrm_func_qcfg(bp);\n\tbnxt_hwrm_vnic_qcaps(bp);\n\tbnxt_hwrm_port_led_qcaps(bp);\n\tbnxt_ethtool_init(bp);\n\tbnxt_dcb_init(bp);\n\treturn 0;\n}\n\nstatic void bnxt_set_dflt_rss_hash_type(struct bnxt *bp)\n{\n\tbp->flags &= ~BNXT_FLAG_UDP_RSS_CAP;\n\tbp->rss_hash_cfg = VNIC_RSS_CFG_REQ_HASH_TYPE_IPV4 |\n\t\t\t   VNIC_RSS_CFG_REQ_HASH_TYPE_TCP_IPV4 |\n\t\t\t   VNIC_RSS_CFG_REQ_HASH_TYPE_IPV6 |\n\t\t\t   VNIC_RSS_CFG_REQ_HASH_TYPE_TCP_IPV6;\n\tif (BNXT_CHIP_P4_PLUS(bp) && bp->hwrm_spec_code >= 0x10501) {\n\t\tbp->flags |= BNXT_FLAG_UDP_RSS_CAP;\n\t\tbp->rss_hash_cfg |= VNIC_RSS_CFG_REQ_HASH_TYPE_UDP_IPV4 |\n\t\t\t\t    VNIC_RSS_CFG_REQ_HASH_TYPE_UDP_IPV6;\n\t}\n}\n\nstatic void bnxt_set_dflt_rfs(struct bnxt *bp)\n{\n\tstruct net_device *dev = bp->dev;\n\n\tdev->hw_features &= ~NETIF_F_NTUPLE;\n\tdev->features &= ~NETIF_F_NTUPLE;\n\tbp->flags &= ~BNXT_FLAG_RFS;\n\tif (bnxt_rfs_supported(bp)) {\n\t\tdev->hw_features |= NETIF_F_NTUPLE;\n\t\tif (bnxt_rfs_capable(bp)) {\n\t\t\tbp->flags |= BNXT_FLAG_RFS;\n\t\t\tdev->features |= NETIF_F_NTUPLE;\n\t\t}\n\t}\n}\n\nstatic void bnxt_fw_init_one_p3(struct bnxt *bp)\n{\n\tstruct pci_dev *pdev = bp->pdev;\n\n\tbnxt_set_dflt_rss_hash_type(bp);\n\tbnxt_set_dflt_rfs(bp);\n\n\tbnxt_get_wol_settings(bp);\n\tif (bp->flags & BNXT_FLAG_WOL_CAP)\n\t\tdevice_set_wakeup_enable(&pdev->dev, bp->wol);\n\telse\n\t\tdevice_set_wakeup_capable(&pdev->dev, false);\n\n\tbnxt_hwrm_set_cache_line_size(bp, cache_line_size());\n\tbnxt_hwrm_coal_params_qcaps(bp);\n}\n\nstatic int bnxt_fw_init_one(struct bnxt *bp)\n{\n\tint rc;\n\n\trc = bnxt_fw_init_one_p1(bp);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"Firmware init phase 1 failed\\n\");\n\t\treturn rc;\n\t}\n\trc = bnxt_fw_init_one_p2(bp);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"Firmware init phase 2 failed\\n\");\n\t\treturn rc;\n\t}\n\trc = bnxt_approve_mac(bp, bp->dev->dev_addr, false);\n\tif (rc)\n\t\treturn rc;\n\n\t/* In case fw capabilities have changed, destroy the unneeded\n\t * reporters and create newly capable ones.\n\t */\n\tbnxt_dl_fw_reporters_destroy(bp, false);\n\tbnxt_dl_fw_reporters_create(bp);\n\tbnxt_fw_init_one_p3(bp);\n\treturn 0;\n}\n\nstatic void bnxt_fw_reset_writel(struct bnxt *bp, int reg_idx)\n{\n\tstruct bnxt_fw_health *fw_health = bp->fw_health;\n\tu32 reg = fw_health->fw_reset_seq_regs[reg_idx];\n\tu32 val = fw_health->fw_reset_seq_vals[reg_idx];\n\tu32 reg_type, reg_off, delay_msecs;\n\n\tdelay_msecs = fw_health->fw_reset_seq_delay_msec[reg_idx];\n\treg_type = BNXT_FW_HEALTH_REG_TYPE(reg);\n\treg_off = BNXT_FW_HEALTH_REG_OFF(reg);\n\tswitch (reg_type) {\n\tcase BNXT_FW_HEALTH_REG_TYPE_CFG:\n\t\tpci_write_config_dword(bp->pdev, reg_off, val);\n\t\tbreak;\n\tcase BNXT_FW_HEALTH_REG_TYPE_GRC:\n\t\twritel(reg_off & BNXT_GRC_BASE_MASK,\n\t\t       bp->bar0 + BNXT_GRCPF_REG_WINDOW_BASE_OUT + 4);\n\t\treg_off = (reg_off & BNXT_GRC_OFFSET_MASK) + 0x2000;\n\t\tfallthrough;\n\tcase BNXT_FW_HEALTH_REG_TYPE_BAR0:\n\t\twritel(val, bp->bar0 + reg_off);\n\t\tbreak;\n\tcase BNXT_FW_HEALTH_REG_TYPE_BAR1:\n\t\twritel(val, bp->bar1 + reg_off);\n\t\tbreak;\n\t}\n\tif (delay_msecs) {\n\t\tpci_read_config_dword(bp->pdev, 0, &val);\n\t\tmsleep(delay_msecs);\n\t}\n}\n\nstatic void bnxt_reset_all(struct bnxt *bp)\n{\n\tstruct bnxt_fw_health *fw_health = bp->fw_health;\n\tint i, rc;\n\n\tif (bp->fw_cap & BNXT_FW_CAP_ERR_RECOVER_RELOAD) {\n\t\tbnxt_fw_reset_via_optee(bp);\n\t\tbp->fw_reset_timestamp = jiffies;\n\t\treturn;\n\t}\n\n\tif (fw_health->flags & ERROR_RECOVERY_QCFG_RESP_FLAGS_HOST) {\n\t\tfor (i = 0; i < fw_health->fw_reset_seq_cnt; i++)\n\t\t\tbnxt_fw_reset_writel(bp, i);\n\t} else if (fw_health->flags & ERROR_RECOVERY_QCFG_RESP_FLAGS_CO_CPU) {\n\t\tstruct hwrm_fw_reset_input req = {0};\n\n\t\tbnxt_hwrm_cmd_hdr_init(bp, &req, HWRM_FW_RESET, -1, -1);\n\t\treq.resp_addr = cpu_to_le64(bp->hwrm_cmd_kong_resp_dma_addr);\n\t\treq.embedded_proc_type = FW_RESET_REQ_EMBEDDED_PROC_TYPE_CHIP;\n\t\treq.selfrst_status = FW_RESET_REQ_SELFRST_STATUS_SELFRSTASAP;\n\t\treq.flags = FW_RESET_REQ_FLAGS_RESET_GRACEFUL;\n\t\trc = hwrm_send_message(bp, &req, sizeof(req), HWRM_CMD_TIMEOUT);\n\t\tif (rc != -ENODEV)\n\t\t\tnetdev_warn(bp->dev, \"Unable to reset FW rc=%d\\n\", rc);\n\t}\n\tbp->fw_reset_timestamp = jiffies;\n}\n\nstatic bool bnxt_fw_reset_timeout(struct bnxt *bp)\n{\n\treturn time_after(jiffies, bp->fw_reset_timestamp +\n\t\t\t  (bp->fw_reset_max_dsecs * HZ / 10));\n}\n\nstatic void bnxt_fw_reset_task(struct work_struct *work)\n{\n\tstruct bnxt *bp = container_of(work, struct bnxt, fw_reset_task.work);\n\tint rc;\n\n\tif (!test_bit(BNXT_STATE_IN_FW_RESET, &bp->state)) {\n\t\tnetdev_err(bp->dev, \"bnxt_fw_reset_task() called when not in fw reset mode!\\n\");\n\t\treturn;\n\t}\n\n\tswitch (bp->fw_reset_state) {\n\tcase BNXT_FW_RESET_STATE_POLL_VF: {\n\t\tint n = bnxt_get_registered_vfs(bp);\n\t\tint tmo;\n\n\t\tif (n < 0) {\n\t\t\tnetdev_err(bp->dev, \"Firmware reset aborted, subsequent func_qcfg cmd failed, rc = %d, %d msecs since reset timestamp\\n\",\n\t\t\t\t   n, jiffies_to_msecs(jiffies -\n\t\t\t\t   bp->fw_reset_timestamp));\n\t\t\tgoto fw_reset_abort;\n\t\t} else if (n > 0) {\n\t\t\tif (bnxt_fw_reset_timeout(bp)) {\n\t\t\t\tclear_bit(BNXT_STATE_IN_FW_RESET, &bp->state);\n\t\t\t\tbp->fw_reset_state = 0;\n\t\t\t\tnetdev_err(bp->dev, \"Firmware reset aborted, bnxt_get_registered_vfs() returns %d\\n\",\n\t\t\t\t\t   n);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tbnxt_queue_fw_reset_work(bp, HZ / 10);\n\t\t\treturn;\n\t\t}\n\t\tbp->fw_reset_timestamp = jiffies;\n\t\trtnl_lock();\n\t\tbnxt_fw_reset_close(bp);\n\t\tif (bp->fw_cap & BNXT_FW_CAP_ERR_RECOVER_RELOAD) {\n\t\t\tbp->fw_reset_state = BNXT_FW_RESET_STATE_POLL_FW_DOWN;\n\t\t\ttmo = HZ / 10;\n\t\t} else {\n\t\t\tbp->fw_reset_state = BNXT_FW_RESET_STATE_ENABLE_DEV;\n\t\t\ttmo = bp->fw_reset_min_dsecs * HZ / 10;\n\t\t}\n\t\trtnl_unlock();\n\t\tbnxt_queue_fw_reset_work(bp, tmo);\n\t\treturn;\n\t}\n\tcase BNXT_FW_RESET_STATE_POLL_FW_DOWN: {\n\t\tu32 val;\n\n\t\tval = bnxt_fw_health_readl(bp, BNXT_FW_HEALTH_REG);\n\t\tif (!(val & BNXT_FW_STATUS_SHUTDOWN) &&\n\t\t    !bnxt_fw_reset_timeout(bp)) {\n\t\t\tbnxt_queue_fw_reset_work(bp, HZ / 5);\n\t\t\treturn;\n\t\t}\n\n\t\tif (!bp->fw_health->master) {\n\t\t\tu32 wait_dsecs = bp->fw_health->normal_func_wait_dsecs;\n\n\t\t\tbp->fw_reset_state = BNXT_FW_RESET_STATE_ENABLE_DEV;\n\t\t\tbnxt_queue_fw_reset_work(bp, wait_dsecs * HZ / 10);\n\t\t\treturn;\n\t\t}\n\t\tbp->fw_reset_state = BNXT_FW_RESET_STATE_RESET_FW;\n\t}\n\t\tfallthrough;\n\tcase BNXT_FW_RESET_STATE_RESET_FW:\n\t\tbnxt_reset_all(bp);\n\t\tbp->fw_reset_state = BNXT_FW_RESET_STATE_ENABLE_DEV;\n\t\tbnxt_queue_fw_reset_work(bp, bp->fw_reset_min_dsecs * HZ / 10);\n\t\treturn;\n\tcase BNXT_FW_RESET_STATE_ENABLE_DEV:\n\t\tbnxt_inv_fw_health_reg(bp);\n\t\tif (test_bit(BNXT_STATE_FW_FATAL_COND, &bp->state) &&\n\t\t    !bp->fw_reset_min_dsecs) {\n\t\t\tu16 val;\n\n\t\t\tpci_read_config_word(bp->pdev, PCI_SUBSYSTEM_ID, &val);\n\t\t\tif (val == 0xffff) {\n\t\t\t\tif (bnxt_fw_reset_timeout(bp)) {\n\t\t\t\t\tnetdev_err(bp->dev, \"Firmware reset aborted, PCI config space invalid\\n\");\n\t\t\t\t\tgoto fw_reset_abort;\n\t\t\t\t}\n\t\t\t\tbnxt_queue_fw_reset_work(bp, HZ / 1000);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t\tclear_bit(BNXT_STATE_FW_FATAL_COND, &bp->state);\n\t\tif (pci_enable_device(bp->pdev)) {\n\t\t\tnetdev_err(bp->dev, \"Cannot re-enable PCI device\\n\");\n\t\t\tgoto fw_reset_abort;\n\t\t}\n\t\tpci_set_master(bp->pdev);\n\t\tbp->fw_reset_state = BNXT_FW_RESET_STATE_POLL_FW;\n\t\tfallthrough;\n\tcase BNXT_FW_RESET_STATE_POLL_FW:\n\t\tbp->hwrm_cmd_timeout = SHORT_HWRM_CMD_TIMEOUT;\n\t\trc = __bnxt_hwrm_ver_get(bp, true);\n\t\tif (rc) {\n\t\t\tif (bnxt_fw_reset_timeout(bp)) {\n\t\t\t\tnetdev_err(bp->dev, \"Firmware reset aborted\\n\");\n\t\t\t\tgoto fw_reset_abort_status;\n\t\t\t}\n\t\t\tbnxt_queue_fw_reset_work(bp, HZ / 5);\n\t\t\treturn;\n\t\t}\n\t\tbp->hwrm_cmd_timeout = DFLT_HWRM_CMD_TIMEOUT;\n\t\tbp->fw_reset_state = BNXT_FW_RESET_STATE_OPENING;\n\t\tfallthrough;\n\tcase BNXT_FW_RESET_STATE_OPENING:\n\t\twhile (!rtnl_trylock()) {\n\t\t\tbnxt_queue_fw_reset_work(bp, HZ / 10);\n\t\t\treturn;\n\t\t}\n\t\trc = bnxt_open(bp->dev);\n\t\tif (rc) {\n\t\t\tnetdev_err(bp->dev, \"bnxt_open_nic() failed\\n\");\n\t\t\tclear_bit(BNXT_STATE_IN_FW_RESET, &bp->state);\n\t\t\tdev_close(bp->dev);\n\t\t}\n\n\t\tbp->fw_reset_state = 0;\n\t\t/* Make sure fw_reset_state is 0 before clearing the flag */\n\t\tsmp_mb__before_atomic();\n\t\tclear_bit(BNXT_STATE_IN_FW_RESET, &bp->state);\n\t\tbnxt_ulp_start(bp, rc);\n\t\tif (!rc)\n\t\t\tbnxt_reenable_sriov(bp);\n\t\tbnxt_dl_health_recovery_done(bp);\n\t\tbnxt_dl_health_status_update(bp, true);\n\t\trtnl_unlock();\n\t\tbreak;\n\t}\n\treturn;\n\nfw_reset_abort_status:\n\tif (bp->fw_health->status_reliable ||\n\t    (bp->fw_cap & BNXT_FW_CAP_ERROR_RECOVERY)) {\n\t\tu32 sts = bnxt_fw_health_readl(bp, BNXT_FW_HEALTH_REG);\n\n\t\tnetdev_err(bp->dev, \"fw_health_status 0x%x\\n\", sts);\n\t}\nfw_reset_abort:\n\tclear_bit(BNXT_STATE_IN_FW_RESET, &bp->state);\n\tif (bp->fw_reset_state != BNXT_FW_RESET_STATE_POLL_VF)\n\t\tbnxt_dl_health_status_update(bp, false);\n\tbp->fw_reset_state = 0;\n\trtnl_lock();\n\tdev_close(bp->dev);\n\trtnl_unlock();\n}\n\nstatic int bnxt_init_board(struct pci_dev *pdev, struct net_device *dev)\n{\n\tint rc;\n\tstruct bnxt *bp = netdev_priv(dev);\n\n\tSET_NETDEV_DEV(dev, &pdev->dev);\n\n\t/* enable device (incl. PCI PM wakeup), and bus-mastering */\n\trc = pci_enable_device(pdev);\n\tif (rc) {\n\t\tdev_err(&pdev->dev, \"Cannot enable PCI device, aborting\\n\");\n\t\tgoto init_err;\n\t}\n\n\tif (!(pci_resource_flags(pdev, 0) & IORESOURCE_MEM)) {\n\t\tdev_err(&pdev->dev,\n\t\t\t\"Cannot find PCI device base address, aborting\\n\");\n\t\trc = -ENODEV;\n\t\tgoto init_err_disable;\n\t}\n\n\trc = pci_request_regions(pdev, DRV_MODULE_NAME);\n\tif (rc) {\n\t\tdev_err(&pdev->dev, \"Cannot obtain PCI resources, aborting\\n\");\n\t\tgoto init_err_disable;\n\t}\n\n\tif (dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64)) != 0 &&\n\t    dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(32)) != 0) {\n\t\tdev_err(&pdev->dev, \"System does not support DMA, aborting\\n\");\n\t\trc = -EIO;\n\t\tgoto init_err_release;\n\t}\n\n\tpci_set_master(pdev);\n\n\tbp->dev = dev;\n\tbp->pdev = pdev;\n\n\t/* Doorbell BAR bp->bar1 is mapped after bnxt_fw_init_one_p2()\n\t * determines the BAR size.\n\t */\n\tbp->bar0 = pci_ioremap_bar(pdev, 0);\n\tif (!bp->bar0) {\n\t\tdev_err(&pdev->dev, \"Cannot map device registers, aborting\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto init_err_release;\n\t}\n\n\tbp->bar2 = pci_ioremap_bar(pdev, 4);\n\tif (!bp->bar2) {\n\t\tdev_err(&pdev->dev, \"Cannot map bar4 registers, aborting\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto init_err_release;\n\t}\n\n\tpci_enable_pcie_error_reporting(pdev);\n\n\tINIT_WORK(&bp->sp_task, bnxt_sp_task);\n\tINIT_DELAYED_WORK(&bp->fw_reset_task, bnxt_fw_reset_task);\n\n\tspin_lock_init(&bp->ntp_fltr_lock);\n#if BITS_PER_LONG == 32\n\tspin_lock_init(&bp->db_lock);\n#endif\n\n\tbp->rx_ring_size = BNXT_DEFAULT_RX_RING_SIZE;\n\tbp->tx_ring_size = BNXT_DEFAULT_TX_RING_SIZE;\n\n\tbnxt_init_dflt_coal(bp);\n\n\ttimer_setup(&bp->timer, bnxt_timer, 0);\n\tbp->current_interval = BNXT_TIMER_INTERVAL;\n\n\tbp->vxlan_fw_dst_port_id = INVALID_HW_RING_ID;\n\tbp->nge_fw_dst_port_id = INVALID_HW_RING_ID;\n\n\tclear_bit(BNXT_STATE_OPEN, &bp->state);\n\treturn 0;\n\ninit_err_release:\n\tbnxt_unmap_bars(bp, pdev);\n\tpci_release_regions(pdev);\n\ninit_err_disable:\n\tpci_disable_device(pdev);\n\ninit_err:\n\treturn rc;\n}\n\n/* rtnl_lock held */\nstatic int bnxt_change_mac_addr(struct net_device *dev, void *p)\n{\n\tstruct sockaddr *addr = p;\n\tstruct bnxt *bp = netdev_priv(dev);\n\tint rc = 0;\n\n\tif (!is_valid_ether_addr(addr->sa_data))\n\t\treturn -EADDRNOTAVAIL;\n\n\tif (ether_addr_equal(addr->sa_data, dev->dev_addr))\n\t\treturn 0;\n\n\trc = bnxt_approve_mac(bp, addr->sa_data, true);\n\tif (rc)\n\t\treturn rc;\n\n\tmemcpy(dev->dev_addr, addr->sa_data, dev->addr_len);\n\tif (netif_running(dev)) {\n\t\tbnxt_close_nic(bp, false, false);\n\t\trc = bnxt_open_nic(bp, false, false);\n\t}\n\n\treturn rc;\n}\n\n/* rtnl_lock held */\nstatic int bnxt_change_mtu(struct net_device *dev, int new_mtu)\n{\n\tstruct bnxt *bp = netdev_priv(dev);\n\n\tif (netif_running(dev))\n\t\tbnxt_close_nic(bp, true, false);\n\n\tdev->mtu = new_mtu;\n\tbnxt_set_ring_params(bp);\n\n\tif (netif_running(dev))\n\t\treturn bnxt_open_nic(bp, true, false);\n\n\treturn 0;\n}\n\nint bnxt_setup_mq_tc(struct net_device *dev, u8 tc)\n{\n\tstruct bnxt *bp = netdev_priv(dev);\n\tbool sh = false;\n\tint rc;\n\n\tif (tc > bp->max_tc) {\n\t\tnetdev_err(dev, \"Too many traffic classes requested: %d. Max supported is %d.\\n\",\n\t\t\t   tc, bp->max_tc);\n\t\treturn -EINVAL;\n\t}\n\n\tif (netdev_get_num_tc(dev) == tc)\n\t\treturn 0;\n\n\tif (bp->flags & BNXT_FLAG_SHARED_RINGS)\n\t\tsh = true;\n\n\trc = bnxt_check_rings(bp, bp->tx_nr_rings_per_tc, bp->rx_nr_rings,\n\t\t\t      sh, tc, bp->tx_nr_rings_xdp);\n\tif (rc)\n\t\treturn rc;\n\n\t/* Needs to close the device and do hw resource re-allocations */\n\tif (netif_running(bp->dev))\n\t\tbnxt_close_nic(bp, true, false);\n\n\tif (tc) {\n\t\tbp->tx_nr_rings = bp->tx_nr_rings_per_tc * tc;\n\t\tnetdev_set_num_tc(dev, tc);\n\t} else {\n\t\tbp->tx_nr_rings = bp->tx_nr_rings_per_tc;\n\t\tnetdev_reset_tc(dev);\n\t}\n\tbp->tx_nr_rings += bp->tx_nr_rings_xdp;\n\tbp->cp_nr_rings = sh ? max_t(int, bp->tx_nr_rings, bp->rx_nr_rings) :\n\t\t\t       bp->tx_nr_rings + bp->rx_nr_rings;\n\n\tif (netif_running(bp->dev))\n\t\treturn bnxt_open_nic(bp, true, false);\n\n\treturn 0;\n}\n\nstatic int bnxt_setup_tc_block_cb(enum tc_setup_type type, void *type_data,\n\t\t\t\t  void *cb_priv)\n{\n\tstruct bnxt *bp = cb_priv;\n\n\tif (!bnxt_tc_flower_enabled(bp) ||\n\t    !tc_cls_can_offload_and_chain0(bp->dev, type_data))\n\t\treturn -EOPNOTSUPP;\n\n\tswitch (type) {\n\tcase TC_SETUP_CLSFLOWER:\n\t\treturn bnxt_tc_setup_flower(bp, bp->pf.fw_fid, type_data);\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nLIST_HEAD(bnxt_block_cb_list);\n\nstatic int bnxt_setup_tc(struct net_device *dev, enum tc_setup_type type,\n\t\t\t void *type_data)\n{\n\tstruct bnxt *bp = netdev_priv(dev);\n\n\tswitch (type) {\n\tcase TC_SETUP_BLOCK:\n\t\treturn flow_block_cb_setup_simple(type_data,\n\t\t\t\t\t\t  &bnxt_block_cb_list,\n\t\t\t\t\t\t  bnxt_setup_tc_block_cb,\n\t\t\t\t\t\t  bp, bp, true);\n\tcase TC_SETUP_QDISC_MQPRIO: {\n\t\tstruct tc_mqprio_qopt *mqprio = type_data;\n\n\t\tmqprio->hw = TC_MQPRIO_HW_OFFLOAD_TCS;\n\n\t\treturn bnxt_setup_mq_tc(dev, mqprio->num_tc);\n\t}\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\n#ifdef CONFIG_RFS_ACCEL\nstatic bool bnxt_fltr_match(struct bnxt_ntuple_filter *f1,\n\t\t\t    struct bnxt_ntuple_filter *f2)\n{\n\tstruct flow_keys *keys1 = &f1->fkeys;\n\tstruct flow_keys *keys2 = &f2->fkeys;\n\n\tif (keys1->basic.n_proto != keys2->basic.n_proto ||\n\t    keys1->basic.ip_proto != keys2->basic.ip_proto)\n\t\treturn false;\n\n\tif (keys1->basic.n_proto == htons(ETH_P_IP)) {\n\t\tif (keys1->addrs.v4addrs.src != keys2->addrs.v4addrs.src ||\n\t\t    keys1->addrs.v4addrs.dst != keys2->addrs.v4addrs.dst)\n\t\t\treturn false;\n\t} else {\n\t\tif (memcmp(&keys1->addrs.v6addrs.src, &keys2->addrs.v6addrs.src,\n\t\t\t   sizeof(keys1->addrs.v6addrs.src)) ||\n\t\t    memcmp(&keys1->addrs.v6addrs.dst, &keys2->addrs.v6addrs.dst,\n\t\t\t   sizeof(keys1->addrs.v6addrs.dst)))\n\t\t\treturn false;\n\t}\n\n\tif (keys1->ports.ports == keys2->ports.ports &&\n\t    keys1->control.flags == keys2->control.flags &&\n\t    ether_addr_equal(f1->src_mac_addr, f2->src_mac_addr) &&\n\t    ether_addr_equal(f1->dst_mac_addr, f2->dst_mac_addr))\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic int bnxt_rx_flow_steer(struct net_device *dev, const struct sk_buff *skb,\n\t\t\t      u16 rxq_index, u32 flow_id)\n{\n\tstruct bnxt *bp = netdev_priv(dev);\n\tstruct bnxt_ntuple_filter *fltr, *new_fltr;\n\tstruct flow_keys *fkeys;\n\tstruct ethhdr *eth = (struct ethhdr *)skb_mac_header(skb);\n\tint rc = 0, idx, bit_id, l2_idx = 0;\n\tstruct hlist_head *head;\n\tu32 flags;\n\n\tif (!ether_addr_equal(dev->dev_addr, eth->h_dest)) {\n\t\tstruct bnxt_vnic_info *vnic = &bp->vnic_info[0];\n\t\tint off = 0, j;\n\n\t\tnetif_addr_lock_bh(dev);\n\t\tfor (j = 0; j < vnic->uc_filter_count; j++, off += ETH_ALEN) {\n\t\t\tif (ether_addr_equal(eth->h_dest,\n\t\t\t\t\t     vnic->uc_list + off)) {\n\t\t\t\tl2_idx = j + 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tnetif_addr_unlock_bh(dev);\n\t\tif (!l2_idx)\n\t\t\treturn -EINVAL;\n\t}\n\tnew_fltr = kzalloc(sizeof(*new_fltr), GFP_ATOMIC);\n\tif (!new_fltr)\n\t\treturn -ENOMEM;\n\n\tfkeys = &new_fltr->fkeys;\n\tif (!skb_flow_dissect_flow_keys(skb, fkeys, 0)) {\n\t\trc = -EPROTONOSUPPORT;\n\t\tgoto err_free;\n\t}\n\n\tif ((fkeys->basic.n_proto != htons(ETH_P_IP) &&\n\t     fkeys->basic.n_proto != htons(ETH_P_IPV6)) ||\n\t    ((fkeys->basic.ip_proto != IPPROTO_TCP) &&\n\t     (fkeys->basic.ip_proto != IPPROTO_UDP))) {\n\t\trc = -EPROTONOSUPPORT;\n\t\tgoto err_free;\n\t}\n\tif (fkeys->basic.n_proto == htons(ETH_P_IPV6) &&\n\t    bp->hwrm_spec_code < 0x10601) {\n\t\trc = -EPROTONOSUPPORT;\n\t\tgoto err_free;\n\t}\n\tflags = fkeys->control.flags;\n\tif (((flags & FLOW_DIS_ENCAPSULATION) &&\n\t     bp->hwrm_spec_code < 0x10601) || (flags & FLOW_DIS_IS_FRAGMENT)) {\n\t\trc = -EPROTONOSUPPORT;\n\t\tgoto err_free;\n\t}\n\n\tmemcpy(new_fltr->dst_mac_addr, eth->h_dest, ETH_ALEN);\n\tmemcpy(new_fltr->src_mac_addr, eth->h_source, ETH_ALEN);\n\n\tidx = skb_get_hash_raw(skb) & BNXT_NTP_FLTR_HASH_MASK;\n\thead = &bp->ntp_fltr_hash_tbl[idx];\n\trcu_read_lock();\n\thlist_for_each_entry_rcu(fltr, head, hash) {\n\t\tif (bnxt_fltr_match(fltr, new_fltr)) {\n\t\t\trcu_read_unlock();\n\t\t\trc = 0;\n\t\t\tgoto err_free;\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\tspin_lock_bh(&bp->ntp_fltr_lock);\n\tbit_id = bitmap_find_free_region(bp->ntp_fltr_bmap,\n\t\t\t\t\t BNXT_NTP_FLTR_MAX_FLTR, 0);\n\tif (bit_id < 0) {\n\t\tspin_unlock_bh(&bp->ntp_fltr_lock);\n\t\trc = -ENOMEM;\n\t\tgoto err_free;\n\t}\n\n\tnew_fltr->sw_id = (u16)bit_id;\n\tnew_fltr->flow_id = flow_id;\n\tnew_fltr->l2_fltr_idx = l2_idx;\n\tnew_fltr->rxq = rxq_index;\n\thlist_add_head_rcu(&new_fltr->hash, head);\n\tbp->ntp_fltr_count++;\n\tspin_unlock_bh(&bp->ntp_fltr_lock);\n\n\tset_bit(BNXT_RX_NTP_FLTR_SP_EVENT, &bp->sp_event);\n\tbnxt_queue_sp_work(bp);\n\n\treturn new_fltr->sw_id;\n\nerr_free:\n\tkfree(new_fltr);\n\treturn rc;\n}\n\nstatic void bnxt_cfg_ntp_filters(struct bnxt *bp)\n{\n\tint i;\n\n\tfor (i = 0; i < BNXT_NTP_FLTR_HASH_SIZE; i++) {\n\t\tstruct hlist_head *head;\n\t\tstruct hlist_node *tmp;\n\t\tstruct bnxt_ntuple_filter *fltr;\n\t\tint rc;\n\n\t\thead = &bp->ntp_fltr_hash_tbl[i];\n\t\thlist_for_each_entry_safe(fltr, tmp, head, hash) {\n\t\t\tbool del = false;\n\n\t\t\tif (test_bit(BNXT_FLTR_VALID, &fltr->state)) {\n\t\t\t\tif (rps_may_expire_flow(bp->dev, fltr->rxq,\n\t\t\t\t\t\t\tfltr->flow_id,\n\t\t\t\t\t\t\tfltr->sw_id)) {\n\t\t\t\t\tbnxt_hwrm_cfa_ntuple_filter_free(bp,\n\t\t\t\t\t\t\t\t\t fltr);\n\t\t\t\t\tdel = true;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\trc = bnxt_hwrm_cfa_ntuple_filter_alloc(bp,\n\t\t\t\t\t\t\t\t       fltr);\n\t\t\t\tif (rc)\n\t\t\t\t\tdel = true;\n\t\t\t\telse\n\t\t\t\t\tset_bit(BNXT_FLTR_VALID, &fltr->state);\n\t\t\t}\n\n\t\t\tif (del) {\n\t\t\t\tspin_lock_bh(&bp->ntp_fltr_lock);\n\t\t\t\thlist_del_rcu(&fltr->hash);\n\t\t\t\tbp->ntp_fltr_count--;\n\t\t\t\tspin_unlock_bh(&bp->ntp_fltr_lock);\n\t\t\t\tsynchronize_rcu();\n\t\t\t\tclear_bit(fltr->sw_id, bp->ntp_fltr_bmap);\n\t\t\t\tkfree(fltr);\n\t\t\t}\n\t\t}\n\t}\n\tif (test_and_clear_bit(BNXT_HWRM_PF_UNLOAD_SP_EVENT, &bp->sp_event))\n\t\tnetdev_info(bp->dev, \"Receive PF driver unload event!\\n\");\n}\n\n#else\n\nstatic void bnxt_cfg_ntp_filters(struct bnxt *bp)\n{\n}\n\n#endif /* CONFIG_RFS_ACCEL */\n\nstatic int bnxt_udp_tunnel_sync(struct net_device *netdev, unsigned int table)\n{\n\tstruct bnxt *bp = netdev_priv(netdev);\n\tstruct udp_tunnel_info ti;\n\tunsigned int cmd;\n\n\tudp_tunnel_nic_get_port(netdev, table, 0, &ti);\n\tif (ti.type == UDP_TUNNEL_TYPE_VXLAN)\n\t\tcmd = TUNNEL_DST_PORT_FREE_REQ_TUNNEL_TYPE_VXLAN;\n\telse\n\t\tcmd = TUNNEL_DST_PORT_FREE_REQ_TUNNEL_TYPE_GENEVE;\n\n\tif (ti.port)\n\t\treturn bnxt_hwrm_tunnel_dst_port_alloc(bp, ti.port, cmd);\n\n\treturn bnxt_hwrm_tunnel_dst_port_free(bp, cmd);\n}\n\nstatic const struct udp_tunnel_nic_info bnxt_udp_tunnels = {\n\t.sync_table\t= bnxt_udp_tunnel_sync,\n\t.flags\t\t= UDP_TUNNEL_NIC_INFO_MAY_SLEEP |\n\t\t\t  UDP_TUNNEL_NIC_INFO_OPEN_ONLY,\n\t.tables\t\t= {\n\t\t{ .n_entries = 1, .tunnel_types = UDP_TUNNEL_TYPE_VXLAN,  },\n\t\t{ .n_entries = 1, .tunnel_types = UDP_TUNNEL_TYPE_GENEVE, },\n\t},\n};\n\nstatic int bnxt_bridge_getlink(struct sk_buff *skb, u32 pid, u32 seq,\n\t\t\t       struct net_device *dev, u32 filter_mask,\n\t\t\t       int nlflags)\n{\n\tstruct bnxt *bp = netdev_priv(dev);\n\n\treturn ndo_dflt_bridge_getlink(skb, pid, seq, dev, bp->br_mode, 0, 0,\n\t\t\t\t       nlflags, filter_mask, NULL);\n}\n\nstatic int bnxt_bridge_setlink(struct net_device *dev, struct nlmsghdr *nlh,\n\t\t\t       u16 flags, struct netlink_ext_ack *extack)\n{\n\tstruct bnxt *bp = netdev_priv(dev);\n\tstruct nlattr *attr, *br_spec;\n\tint rem, rc = 0;\n\n\tif (bp->hwrm_spec_code < 0x10708 || !BNXT_SINGLE_PF(bp))\n\t\treturn -EOPNOTSUPP;\n\n\tbr_spec = nlmsg_find_attr(nlh, sizeof(struct ifinfomsg), IFLA_AF_SPEC);\n\tif (!br_spec)\n\t\treturn -EINVAL;\n\n\tnla_for_each_nested(attr, br_spec, rem) {\n\t\tu16 mode;\n\n\t\tif (nla_type(attr) != IFLA_BRIDGE_MODE)\n\t\t\tcontinue;\n\n\t\tif (nla_len(attr) < sizeof(mode))\n\t\t\treturn -EINVAL;\n\n\t\tmode = nla_get_u16(attr);\n\t\tif (mode == bp->br_mode)\n\t\t\tbreak;\n\n\t\trc = bnxt_hwrm_set_br_mode(bp, mode);\n\t\tif (!rc)\n\t\t\tbp->br_mode = mode;\n\t\tbreak;\n\t}\n\treturn rc;\n}\n\nint bnxt_get_port_parent_id(struct net_device *dev,\n\t\t\t    struct netdev_phys_item_id *ppid)\n{\n\tstruct bnxt *bp = netdev_priv(dev);\n\n\tif (bp->eswitch_mode != DEVLINK_ESWITCH_MODE_SWITCHDEV)\n\t\treturn -EOPNOTSUPP;\n\n\t/* The PF and it's VF-reps only support the switchdev framework */\n\tif (!BNXT_PF(bp) || !(bp->flags & BNXT_FLAG_DSN_VALID))\n\t\treturn -EOPNOTSUPP;\n\n\tppid->id_len = sizeof(bp->dsn);\n\tmemcpy(ppid->id, bp->dsn, ppid->id_len);\n\n\treturn 0;\n}\n\nstatic struct devlink_port *bnxt_get_devlink_port(struct net_device *dev)\n{\n\tstruct bnxt *bp = netdev_priv(dev);\n\n\treturn &bp->dl_port;\n}\n\nstatic const struct net_device_ops bnxt_netdev_ops = {\n\t.ndo_open\t\t= bnxt_open,\n\t.ndo_start_xmit\t\t= bnxt_start_xmit,\n\t.ndo_stop\t\t= bnxt_close,\n\t.ndo_get_stats64\t= bnxt_get_stats64,\n\t.ndo_set_rx_mode\t= bnxt_set_rx_mode,\n\t.ndo_do_ioctl\t\t= bnxt_ioctl,\n\t.ndo_validate_addr\t= eth_validate_addr,\n\t.ndo_set_mac_address\t= bnxt_change_mac_addr,\n\t.ndo_change_mtu\t\t= bnxt_change_mtu,\n\t.ndo_fix_features\t= bnxt_fix_features,\n\t.ndo_set_features\t= bnxt_set_features,\n\t.ndo_tx_timeout\t\t= bnxt_tx_timeout,\n#ifdef CONFIG_BNXT_SRIOV\n\t.ndo_get_vf_config\t= bnxt_get_vf_config,\n\t.ndo_set_vf_mac\t\t= bnxt_set_vf_mac,\n\t.ndo_set_vf_vlan\t= bnxt_set_vf_vlan,\n\t.ndo_set_vf_rate\t= bnxt_set_vf_bw,\n\t.ndo_set_vf_link_state\t= bnxt_set_vf_link_state,\n\t.ndo_set_vf_spoofchk\t= bnxt_set_vf_spoofchk,\n\t.ndo_set_vf_trust\t= bnxt_set_vf_trust,\n#endif\n\t.ndo_setup_tc           = bnxt_setup_tc,\n#ifdef CONFIG_RFS_ACCEL\n\t.ndo_rx_flow_steer\t= bnxt_rx_flow_steer,\n#endif\n\t.ndo_bpf\t\t= bnxt_xdp,\n\t.ndo_xdp_xmit\t\t= bnxt_xdp_xmit,\n\t.ndo_bridge_getlink\t= bnxt_bridge_getlink,\n\t.ndo_bridge_setlink\t= bnxt_bridge_setlink,\n\t.ndo_get_devlink_port\t= bnxt_get_devlink_port,\n};\n\nstatic void bnxt_remove_one(struct pci_dev *pdev)\n{\n\tstruct net_device *dev = pci_get_drvdata(pdev);\n\tstruct bnxt *bp = netdev_priv(dev);\n\n\tif (BNXT_PF(bp))\n\t\tbnxt_sriov_disable(bp);\n\n\tif (BNXT_PF(bp))\n\t\tdevlink_port_type_clear(&bp->dl_port);\n\tpci_disable_pcie_error_reporting(pdev);\n\tunregister_netdev(dev);\n\tclear_bit(BNXT_STATE_IN_FW_RESET, &bp->state);\n\t/* Flush any pending tasks */\n\tcancel_work_sync(&bp->sp_task);\n\tcancel_delayed_work_sync(&bp->fw_reset_task);\n\tbp->sp_event = 0;\n\n\tbnxt_dl_fw_reporters_destroy(bp, true);\n\tbnxt_dl_unregister(bp);\n\tbnxt_shutdown_tc(bp);\n\n\tbnxt_clear_int_mode(bp);\n\tbnxt_hwrm_func_drv_unrgtr(bp);\n\tbnxt_free_hwrm_resources(bp);\n\tbnxt_free_hwrm_short_cmd_req(bp);\n\tbnxt_ethtool_free(bp);\n\tbnxt_dcb_free(bp);\n\tkfree(bp->edev);\n\tbp->edev = NULL;\n\tkfree(bp->fw_health);\n\tbp->fw_health = NULL;\n\tbnxt_cleanup_pci(bp);\n\tbnxt_free_ctx_mem(bp);\n\tkfree(bp->ctx);\n\tbp->ctx = NULL;\n\tkfree(bp->rss_indir_tbl);\n\tbp->rss_indir_tbl = NULL;\n\tbnxt_free_port_stats(bp);\n\tfree_netdev(dev);\n}\n\nstatic int bnxt_probe_phy(struct bnxt *bp, bool fw_dflt)\n{\n\tint rc = 0;\n\tstruct bnxt_link_info *link_info = &bp->link_info;\n\n\trc = bnxt_hwrm_phy_qcaps(bp);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"Probe phy can't get phy capabilities (rc: %x)\\n\",\n\t\t\t   rc);\n\t\treturn rc;\n\t}\n\tif (!fw_dflt)\n\t\treturn 0;\n\n\trc = bnxt_update_link(bp, false);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"Probe phy can't update link (rc: %x)\\n\",\n\t\t\t   rc);\n\t\treturn rc;\n\t}\n\n\t/* Older firmware does not have supported_auto_speeds, so assume\n\t * that all supported speeds can be autonegotiated.\n\t */\n\tif (link_info->auto_link_speeds && !link_info->support_auto_speeds)\n\t\tlink_info->support_auto_speeds = link_info->support_speeds;\n\n\tbnxt_init_ethtool_link_settings(bp);\n\treturn 0;\n}\n\nstatic int bnxt_get_max_irq(struct pci_dev *pdev)\n{\n\tu16 ctrl;\n\n\tif (!pdev->msix_cap)\n\t\treturn 1;\n\n\tpci_read_config_word(pdev, pdev->msix_cap + PCI_MSIX_FLAGS, &ctrl);\n\treturn (ctrl & PCI_MSIX_FLAGS_QSIZE) + 1;\n}\n\nstatic void _bnxt_get_max_rings(struct bnxt *bp, int *max_rx, int *max_tx,\n\t\t\t\tint *max_cp)\n{\n\tstruct bnxt_hw_resc *hw_resc = &bp->hw_resc;\n\tint max_ring_grps = 0, max_irq;\n\n\t*max_tx = hw_resc->max_tx_rings;\n\t*max_rx = hw_resc->max_rx_rings;\n\t*max_cp = bnxt_get_max_func_cp_rings_for_en(bp);\n\tmax_irq = min_t(int, bnxt_get_max_func_irqs(bp) -\n\t\t\tbnxt_get_ulp_msix_num(bp),\n\t\t\thw_resc->max_stat_ctxs - bnxt_get_ulp_stat_ctxs(bp));\n\tif (!(bp->flags & BNXT_FLAG_CHIP_P5))\n\t\t*max_cp = min_t(int, *max_cp, max_irq);\n\tmax_ring_grps = hw_resc->max_hw_ring_grps;\n\tif (BNXT_CHIP_TYPE_NITRO_A0(bp) && BNXT_PF(bp)) {\n\t\t*max_cp -= 1;\n\t\t*max_rx -= 2;\n\t}\n\tif (bp->flags & BNXT_FLAG_AGG_RINGS)\n\t\t*max_rx >>= 1;\n\tif (bp->flags & BNXT_FLAG_CHIP_P5) {\n\t\tbnxt_trim_rings(bp, max_rx, max_tx, *max_cp, false);\n\t\t/* On P5 chips, max_cp output param should be available NQs */\n\t\t*max_cp = max_irq;\n\t}\n\t*max_rx = min_t(int, *max_rx, max_ring_grps);\n}\n\nint bnxt_get_max_rings(struct bnxt *bp, int *max_rx, int *max_tx, bool shared)\n{\n\tint rx, tx, cp;\n\n\t_bnxt_get_max_rings(bp, &rx, &tx, &cp);\n\t*max_rx = rx;\n\t*max_tx = tx;\n\tif (!rx || !tx || !cp)\n\t\treturn -ENOMEM;\n\n\treturn bnxt_trim_rings(bp, max_rx, max_tx, cp, shared);\n}\n\nstatic int bnxt_get_dflt_rings(struct bnxt *bp, int *max_rx, int *max_tx,\n\t\t\t       bool shared)\n{\n\tint rc;\n\n\trc = bnxt_get_max_rings(bp, max_rx, max_tx, shared);\n\tif (rc && (bp->flags & BNXT_FLAG_AGG_RINGS)) {\n\t\t/* Not enough rings, try disabling agg rings. */\n\t\tbp->flags &= ~BNXT_FLAG_AGG_RINGS;\n\t\trc = bnxt_get_max_rings(bp, max_rx, max_tx, shared);\n\t\tif (rc) {\n\t\t\t/* set BNXT_FLAG_AGG_RINGS back for consistency */\n\t\t\tbp->flags |= BNXT_FLAG_AGG_RINGS;\n\t\t\treturn rc;\n\t\t}\n\t\tbp->flags |= BNXT_FLAG_NO_AGG_RINGS;\n\t\tbp->dev->hw_features &= ~(NETIF_F_LRO | NETIF_F_GRO_HW);\n\t\tbp->dev->features &= ~(NETIF_F_LRO | NETIF_F_GRO_HW);\n\t\tbnxt_set_ring_params(bp);\n\t}\n\n\tif (bp->flags & BNXT_FLAG_ROCE_CAP) {\n\t\tint max_cp, max_stat, max_irq;\n\n\t\t/* Reserve minimum resources for RoCE */\n\t\tmax_cp = bnxt_get_max_func_cp_rings(bp);\n\t\tmax_stat = bnxt_get_max_func_stat_ctxs(bp);\n\t\tmax_irq = bnxt_get_max_func_irqs(bp);\n\t\tif (max_cp <= BNXT_MIN_ROCE_CP_RINGS ||\n\t\t    max_irq <= BNXT_MIN_ROCE_CP_RINGS ||\n\t\t    max_stat <= BNXT_MIN_ROCE_STAT_CTXS)\n\t\t\treturn 0;\n\n\t\tmax_cp -= BNXT_MIN_ROCE_CP_RINGS;\n\t\tmax_irq -= BNXT_MIN_ROCE_CP_RINGS;\n\t\tmax_stat -= BNXT_MIN_ROCE_STAT_CTXS;\n\t\tmax_cp = min_t(int, max_cp, max_irq);\n\t\tmax_cp = min_t(int, max_cp, max_stat);\n\t\trc = bnxt_trim_rings(bp, max_rx, max_tx, max_cp, shared);\n\t\tif (rc)\n\t\t\trc = 0;\n\t}\n\treturn rc;\n}\n\n/* In initial default shared ring setting, each shared ring must have a\n * RX/TX ring pair.\n */\nstatic void bnxt_trim_dflt_sh_rings(struct bnxt *bp)\n{\n\tbp->cp_nr_rings = min_t(int, bp->tx_nr_rings_per_tc, bp->rx_nr_rings);\n\tbp->rx_nr_rings = bp->cp_nr_rings;\n\tbp->tx_nr_rings_per_tc = bp->cp_nr_rings;\n\tbp->tx_nr_rings = bp->tx_nr_rings_per_tc;\n}\n\nstatic int bnxt_set_dflt_rings(struct bnxt *bp, bool sh)\n{\n\tint dflt_rings, max_rx_rings, max_tx_rings, rc;\n\n\tif (!bnxt_can_reserve_rings(bp))\n\t\treturn 0;\n\n\tif (sh)\n\t\tbp->flags |= BNXT_FLAG_SHARED_RINGS;\n\tdflt_rings = is_kdump_kernel() ? 1 : netif_get_num_default_rss_queues();\n\t/* Reduce default rings on multi-port cards so that total default\n\t * rings do not exceed CPU count.\n\t */\n\tif (bp->port_count > 1) {\n\t\tint max_rings =\n\t\t\tmax_t(int, num_online_cpus() / bp->port_count, 1);\n\n\t\tdflt_rings = min_t(int, dflt_rings, max_rings);\n\t}\n\trc = bnxt_get_dflt_rings(bp, &max_rx_rings, &max_tx_rings, sh);\n\tif (rc)\n\t\treturn rc;\n\tbp->rx_nr_rings = min_t(int, dflt_rings, max_rx_rings);\n\tbp->tx_nr_rings_per_tc = min_t(int, dflt_rings, max_tx_rings);\n\tif (sh)\n\t\tbnxt_trim_dflt_sh_rings(bp);\n\telse\n\t\tbp->cp_nr_rings = bp->tx_nr_rings_per_tc + bp->rx_nr_rings;\n\tbp->tx_nr_rings = bp->tx_nr_rings_per_tc;\n\n\trc = __bnxt_reserve_rings(bp);\n\tif (rc)\n\t\tnetdev_warn(bp->dev, \"Unable to reserve tx rings\\n\");\n\tbp->tx_nr_rings_per_tc = bp->tx_nr_rings;\n\tif (sh)\n\t\tbnxt_trim_dflt_sh_rings(bp);\n\n\t/* Rings may have been trimmed, re-reserve the trimmed rings. */\n\tif (bnxt_need_reserve_rings(bp)) {\n\t\trc = __bnxt_reserve_rings(bp);\n\t\tif (rc)\n\t\t\tnetdev_warn(bp->dev, \"2nd rings reservation failed.\\n\");\n\t\tbp->tx_nr_rings_per_tc = bp->tx_nr_rings;\n\t}\n\tif (BNXT_CHIP_TYPE_NITRO_A0(bp)) {\n\t\tbp->rx_nr_rings++;\n\t\tbp->cp_nr_rings++;\n\t}\n\tif (rc) {\n\t\tbp->tx_nr_rings = 0;\n\t\tbp->rx_nr_rings = 0;\n\t}\n\treturn rc;\n}\n\nstatic int bnxt_init_dflt_ring_mode(struct bnxt *bp)\n{\n\tint rc;\n\n\tif (bp->tx_nr_rings)\n\t\treturn 0;\n\n\tbnxt_ulp_irq_stop(bp);\n\tbnxt_clear_int_mode(bp);\n\trc = bnxt_set_dflt_rings(bp, true);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"Not enough rings available.\\n\");\n\t\tgoto init_dflt_ring_err;\n\t}\n\trc = bnxt_init_int_mode(bp);\n\tif (rc)\n\t\tgoto init_dflt_ring_err;\n\n\tbp->tx_nr_rings_per_tc = bp->tx_nr_rings;\n\tif (bnxt_rfs_supported(bp) && bnxt_rfs_capable(bp)) {\n\t\tbp->flags |= BNXT_FLAG_RFS;\n\t\tbp->dev->features |= NETIF_F_NTUPLE;\n\t}\ninit_dflt_ring_err:\n\tbnxt_ulp_irq_restart(bp, rc);\n\treturn rc;\n}\n\nint bnxt_restore_pf_fw_resources(struct bnxt *bp)\n{\n\tint rc;\n\n\tASSERT_RTNL();\n\tbnxt_hwrm_func_qcaps(bp);\n\n\tif (netif_running(bp->dev))\n\t\t__bnxt_close_nic(bp, true, false);\n\n\tbnxt_ulp_irq_stop(bp);\n\tbnxt_clear_int_mode(bp);\n\trc = bnxt_init_int_mode(bp);\n\tbnxt_ulp_irq_restart(bp, rc);\n\n\tif (netif_running(bp->dev)) {\n\t\tif (rc)\n\t\t\tdev_close(bp->dev);\n\t\telse\n\t\t\trc = bnxt_open_nic(bp, true, false);\n\t}\n\n\treturn rc;\n}\n\nstatic int bnxt_init_mac_addr(struct bnxt *bp)\n{\n\tint rc = 0;\n\n\tif (BNXT_PF(bp)) {\n\t\tmemcpy(bp->dev->dev_addr, bp->pf.mac_addr, ETH_ALEN);\n\t} else {\n#ifdef CONFIG_BNXT_SRIOV\n\t\tstruct bnxt_vf_info *vf = &bp->vf;\n\t\tbool strict_approval = true;\n\n\t\tif (is_valid_ether_addr(vf->mac_addr)) {\n\t\t\t/* overwrite netdev dev_addr with admin VF MAC */\n\t\t\tmemcpy(bp->dev->dev_addr, vf->mac_addr, ETH_ALEN);\n\t\t\t/* Older PF driver or firmware may not approve this\n\t\t\t * correctly.\n\t\t\t */\n\t\t\tstrict_approval = false;\n\t\t} else {\n\t\t\teth_hw_addr_random(bp->dev);\n\t\t}\n\t\trc = bnxt_approve_mac(bp, bp->dev->dev_addr, strict_approval);\n#endif\n\t}\n\treturn rc;\n}\n\n#define BNXT_VPD_LEN\t512\nstatic void bnxt_vpd_read_info(struct bnxt *bp)\n{\n\tstruct pci_dev *pdev = bp->pdev;\n\tint i, len, pos, ro_size, size;\n\tssize_t vpd_size;\n\tu8 *vpd_data;\n\n\tvpd_data = kmalloc(BNXT_VPD_LEN, GFP_KERNEL);\n\tif (!vpd_data)\n\t\treturn;\n\n\tvpd_size = pci_read_vpd(pdev, 0, BNXT_VPD_LEN, vpd_data);\n\tif (vpd_size <= 0) {\n\t\tnetdev_err(bp->dev, \"Unable to read VPD\\n\");\n\t\tgoto exit;\n\t}\n\n\ti = pci_vpd_find_tag(vpd_data, 0, vpd_size, PCI_VPD_LRDT_RO_DATA);\n\tif (i < 0) {\n\t\tnetdev_err(bp->dev, \"VPD READ-Only not found\\n\");\n\t\tgoto exit;\n\t}\n\n\tro_size = pci_vpd_lrdt_size(&vpd_data[i]);\n\ti += PCI_VPD_LRDT_TAG_SIZE;\n\tif (i + ro_size > vpd_size)\n\t\tgoto exit;\n\n\tpos = pci_vpd_find_info_keyword(vpd_data, i, ro_size,\n\t\t\t\t\tPCI_VPD_RO_KEYWORD_PARTNO);\n\tif (pos < 0)\n\t\tgoto read_sn;\n\n\tlen = pci_vpd_info_field_size(&vpd_data[pos]);\n\tpos += PCI_VPD_INFO_FLD_HDR_SIZE;\n\tif (len + pos > vpd_size)\n\t\tgoto read_sn;\n\n\tsize = min(len, BNXT_VPD_FLD_LEN - 1);\n\tmemcpy(bp->board_partno, &vpd_data[pos], size);\n\nread_sn:\n\tpos = pci_vpd_find_info_keyword(vpd_data, i, ro_size,\n\t\t\t\t\tPCI_VPD_RO_KEYWORD_SERIALNO);\n\tif (pos < 0)\n\t\tgoto exit;\n\n\tlen = pci_vpd_info_field_size(&vpd_data[pos]);\n\tpos += PCI_VPD_INFO_FLD_HDR_SIZE;\n\tif (len + pos > vpd_size)\n\t\tgoto exit;\n\n\tsize = min(len, BNXT_VPD_FLD_LEN - 1);\n\tmemcpy(bp->board_serialno, &vpd_data[pos], size);\nexit:\n\tkfree(vpd_data);\n}\n\nstatic int bnxt_pcie_dsn_get(struct bnxt *bp, u8 dsn[])\n{\n\tstruct pci_dev *pdev = bp->pdev;\n\tu64 qword;\n\n\tqword = pci_get_dsn(pdev);\n\tif (!qword) {\n\t\tnetdev_info(bp->dev, \"Unable to read adapter's DSN\\n\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tput_unaligned_le64(qword, dsn);\n\n\tbp->flags |= BNXT_FLAG_DSN_VALID;\n\treturn 0;\n}\n\nstatic int bnxt_map_db_bar(struct bnxt *bp)\n{\n\tif (!bp->db_size)\n\t\treturn -ENODEV;\n\tbp->bar1 = pci_iomap(bp->pdev, 2, bp->db_size);\n\tif (!bp->bar1)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\nstatic int bnxt_init_one(struct pci_dev *pdev, const struct pci_device_id *ent)\n{\n\tstruct net_device *dev;\n\tstruct bnxt *bp;\n\tint rc, max_irqs;\n\n\tif (pci_is_bridge(pdev))\n\t\treturn -ENODEV;\n\n\t/* Clear any pending DMA transactions from crash kernel\n\t * while loading driver in capture kernel.\n\t */\n\tif (is_kdump_kernel()) {\n\t\tpci_clear_master(pdev);\n\t\tpcie_flr(pdev);\n\t}\n\n\tmax_irqs = bnxt_get_max_irq(pdev);\n\tdev = alloc_etherdev_mq(sizeof(*bp), max_irqs);\n\tif (!dev)\n\t\treturn -ENOMEM;\n\n\tbp = netdev_priv(dev);\n\tbp->msg_enable = BNXT_DEF_MSG_ENABLE;\n\tbnxt_set_max_func_irqs(bp, max_irqs);\n\n\tif (bnxt_vf_pciid(ent->driver_data))\n\t\tbp->flags |= BNXT_FLAG_VF;\n\n\tif (pdev->msix_cap)\n\t\tbp->flags |= BNXT_FLAG_MSIX_CAP;\n\n\trc = bnxt_init_board(pdev, dev);\n\tif (rc < 0)\n\t\tgoto init_err_free;\n\n\tdev->netdev_ops = &bnxt_netdev_ops;\n\tdev->watchdog_timeo = BNXT_TX_TIMEOUT;\n\tdev->ethtool_ops = &bnxt_ethtool_ops;\n\tpci_set_drvdata(pdev, dev);\n\n\trc = bnxt_alloc_hwrm_resources(bp);\n\tif (rc)\n\t\tgoto init_err_pci_clean;\n\n\tmutex_init(&bp->hwrm_cmd_lock);\n\tmutex_init(&bp->link_lock);\n\n\trc = bnxt_fw_init_one_p1(bp);\n\tif (rc)\n\t\tgoto init_err_pci_clean;\n\n\tif (BNXT_PF(bp))\n\t\tbnxt_vpd_read_info(bp);\n\n\tif (BNXT_CHIP_P5(bp)) {\n\t\tbp->flags |= BNXT_FLAG_CHIP_P5;\n\t\tif (BNXT_CHIP_SR2(bp))\n\t\t\tbp->flags |= BNXT_FLAG_CHIP_SR2;\n\t}\n\n\trc = bnxt_alloc_rss_indir_tbl(bp);\n\tif (rc)\n\t\tgoto init_err_pci_clean;\n\n\trc = bnxt_fw_init_one_p2(bp);\n\tif (rc)\n\t\tgoto init_err_pci_clean;\n\n\trc = bnxt_map_db_bar(bp);\n\tif (rc) {\n\t\tdev_err(&pdev->dev, \"Cannot map doorbell BAR rc = %d, aborting\\n\",\n\t\t\trc);\n\t\tgoto init_err_pci_clean;\n\t}\n\n\tdev->hw_features = NETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM | NETIF_F_SG |\n\t\t\t   NETIF_F_TSO | NETIF_F_TSO6 |\n\t\t\t   NETIF_F_GSO_UDP_TUNNEL | NETIF_F_GSO_GRE |\n\t\t\t   NETIF_F_GSO_IPXIP4 |\n\t\t\t   NETIF_F_GSO_UDP_TUNNEL_CSUM | NETIF_F_GSO_GRE_CSUM |\n\t\t\t   NETIF_F_GSO_PARTIAL | NETIF_F_RXHASH |\n\t\t\t   NETIF_F_RXCSUM | NETIF_F_GRO;\n\n\tif (BNXT_SUPPORTS_TPA(bp))\n\t\tdev->hw_features |= NETIF_F_LRO;\n\n\tdev->hw_enc_features =\n\t\t\tNETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM | NETIF_F_SG |\n\t\t\tNETIF_F_TSO | NETIF_F_TSO6 |\n\t\t\tNETIF_F_GSO_UDP_TUNNEL | NETIF_F_GSO_GRE |\n\t\t\tNETIF_F_GSO_UDP_TUNNEL_CSUM | NETIF_F_GSO_GRE_CSUM |\n\t\t\tNETIF_F_GSO_IPXIP4 | NETIF_F_GSO_PARTIAL;\n\tdev->udp_tunnel_nic_info = &bnxt_udp_tunnels;\n\n\tdev->gso_partial_features = NETIF_F_GSO_UDP_TUNNEL_CSUM |\n\t\t\t\t    NETIF_F_GSO_GRE_CSUM;\n\tdev->vlan_features = dev->hw_features | NETIF_F_HIGHDMA;\n\tif (bp->fw_cap & BNXT_FW_CAP_VLAN_RX_STRIP)\n\t\tdev->hw_features |= BNXT_HW_FEATURE_VLAN_ALL_RX;\n\tif (bp->fw_cap & BNXT_FW_CAP_VLAN_TX_INSERT)\n\t\tdev->hw_features |= BNXT_HW_FEATURE_VLAN_ALL_TX;\n\tif (BNXT_SUPPORTS_TPA(bp))\n\t\tdev->hw_features |= NETIF_F_GRO_HW;\n\tdev->features |= dev->hw_features | NETIF_F_HIGHDMA;\n\tif (dev->features & NETIF_F_GRO_HW)\n\t\tdev->features &= ~NETIF_F_LRO;\n\tdev->priv_flags |= IFF_UNICAST_FLT;\n\n#ifdef CONFIG_BNXT_SRIOV\n\tinit_waitqueue_head(&bp->sriov_cfg_wait);\n\tmutex_init(&bp->sriov_lock);\n#endif\n\tif (BNXT_SUPPORTS_TPA(bp)) {\n\t\tbp->gro_func = bnxt_gro_func_5730x;\n\t\tif (BNXT_CHIP_P4(bp))\n\t\t\tbp->gro_func = bnxt_gro_func_5731x;\n\t\telse if (BNXT_CHIP_P5(bp))\n\t\t\tbp->gro_func = bnxt_gro_func_5750x;\n\t}\n\tif (!BNXT_CHIP_P4_PLUS(bp))\n\t\tbp->flags |= BNXT_FLAG_DOUBLE_DB;\n\n\tbp->ulp_probe = bnxt_ulp_probe;\n\n\trc = bnxt_init_mac_addr(bp);\n\tif (rc) {\n\t\tdev_err(&pdev->dev, \"Unable to initialize mac address.\\n\");\n\t\trc = -EADDRNOTAVAIL;\n\t\tgoto init_err_pci_clean;\n\t}\n\n\tif (BNXT_PF(bp)) {\n\t\t/* Read the adapter's DSN to use as the eswitch switch_id */\n\t\trc = bnxt_pcie_dsn_get(bp, bp->dsn);\n\t}\n\n\t/* MTU range: 60 - FW defined max */\n\tdev->min_mtu = ETH_ZLEN;\n\tdev->max_mtu = bp->max_mtu;\n\n\trc = bnxt_probe_phy(bp, true);\n\tif (rc)\n\t\tgoto init_err_pci_clean;\n\n\tbnxt_set_rx_skb_mode(bp, false);\n\tbnxt_set_tpa_flags(bp);\n\tbnxt_set_ring_params(bp);\n\trc = bnxt_set_dflt_rings(bp, true);\n\tif (rc) {\n\t\tnetdev_err(bp->dev, \"Not enough rings available.\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto init_err_pci_clean;\n\t}\n\n\tbnxt_fw_init_one_p3(bp);\n\n\tif (dev->hw_features & BNXT_HW_FEATURE_VLAN_ALL_RX)\n\t\tbp->flags |= BNXT_FLAG_STRIP_VLAN;\n\n\trc = bnxt_init_int_mode(bp);\n\tif (rc)\n\t\tgoto init_err_pci_clean;\n\n\t/* No TC has been set yet and rings may have been trimmed due to\n\t * limited MSIX, so we re-initialize the TX rings per TC.\n\t */\n\tbp->tx_nr_rings_per_tc = bp->tx_nr_rings;\n\n\tif (BNXT_PF(bp)) {\n\t\tif (!bnxt_pf_wq) {\n\t\t\tbnxt_pf_wq =\n\t\t\t\tcreate_singlethread_workqueue(\"bnxt_pf_wq\");\n\t\t\tif (!bnxt_pf_wq) {\n\t\t\t\tdev_err(&pdev->dev, \"Unable to create workqueue.\\n\");\n\t\t\t\trc = -ENOMEM;\n\t\t\t\tgoto init_err_pci_clean;\n\t\t\t}\n\t\t}\n\t\trc = bnxt_init_tc(bp);\n\t\tif (rc)\n\t\t\tnetdev_err(dev, \"Failed to initialize TC flower offload, err = %d.\\n\",\n\t\t\t\t   rc);\n\t}\n\n\tbnxt_dl_register(bp);\n\n\trc = register_netdev(dev);\n\tif (rc)\n\t\tgoto init_err_cleanup;\n\n\tif (BNXT_PF(bp))\n\t\tdevlink_port_type_eth_set(&bp->dl_port, bp->dev);\n\tbnxt_dl_fw_reporters_create(bp);\n\n\tnetdev_info(dev, \"%s found at mem %lx, node addr %pM\\n\",\n\t\t    board_info[ent->driver_data].name,\n\t\t    (long)pci_resource_start(pdev, 0), dev->dev_addr);\n\tpcie_print_link_status(pdev);\n\n\tpci_save_state(pdev);\n\treturn 0;\n\ninit_err_cleanup:\n\tbnxt_dl_unregister(bp);\n\tbnxt_shutdown_tc(bp);\n\tbnxt_clear_int_mode(bp);\n\ninit_err_pci_clean:\n\tbnxt_hwrm_func_drv_unrgtr(bp);\n\tbnxt_free_hwrm_short_cmd_req(bp);\n\tbnxt_free_hwrm_resources(bp);\n\tkfree(bp->fw_health);\n\tbp->fw_health = NULL;\n\tbnxt_cleanup_pci(bp);\n\tbnxt_free_ctx_mem(bp);\n\tkfree(bp->ctx);\n\tbp->ctx = NULL;\n\tkfree(bp->rss_indir_tbl);\n\tbp->rss_indir_tbl = NULL;\n\ninit_err_free:\n\tfree_netdev(dev);\n\treturn rc;\n}\n\nstatic void bnxt_shutdown(struct pci_dev *pdev)\n{\n\tstruct net_device *dev = pci_get_drvdata(pdev);\n\tstruct bnxt *bp;\n\n\tif (!dev)\n\t\treturn;\n\n\trtnl_lock();\n\tbp = netdev_priv(dev);\n\tif (!bp)\n\t\tgoto shutdown_exit;\n\n\tif (netif_running(dev))\n\t\tdev_close(dev);\n\n\tbnxt_ulp_shutdown(bp);\n\tbnxt_clear_int_mode(bp);\n\tpci_disable_device(pdev);\n\n\tif (system_state == SYSTEM_POWER_OFF) {\n\t\tpci_wake_from_d3(pdev, bp->wol);\n\t\tpci_set_power_state(pdev, PCI_D3hot);\n\t}\n\nshutdown_exit:\n\trtnl_unlock();\n}\n\n#ifdef CONFIG_PM_SLEEP\nstatic int bnxt_suspend(struct device *device)\n{\n\tstruct net_device *dev = dev_get_drvdata(device);\n\tstruct bnxt *bp = netdev_priv(dev);\n\tint rc = 0;\n\n\trtnl_lock();\n\tbnxt_ulp_stop(bp);\n\tif (netif_running(dev)) {\n\t\tnetif_device_detach(dev);\n\t\trc = bnxt_close(dev);\n\t}\n\tbnxt_hwrm_func_drv_unrgtr(bp);\n\tpci_disable_device(bp->pdev);\n\tbnxt_free_ctx_mem(bp);\n\tkfree(bp->ctx);\n\tbp->ctx = NULL;\n\trtnl_unlock();\n\treturn rc;\n}\n\nstatic int bnxt_resume(struct device *device)\n{\n\tstruct net_device *dev = dev_get_drvdata(device);\n\tstruct bnxt *bp = netdev_priv(dev);\n\tint rc = 0;\n\n\trtnl_lock();\n\trc = pci_enable_device(bp->pdev);\n\tif (rc) {\n\t\tnetdev_err(dev, \"Cannot re-enable PCI device during resume, err = %d\\n\",\n\t\t\t   rc);\n\t\tgoto resume_exit;\n\t}\n\tpci_set_master(bp->pdev);\n\tif (bnxt_hwrm_ver_get(bp)) {\n\t\trc = -ENODEV;\n\t\tgoto resume_exit;\n\t}\n\trc = bnxt_hwrm_func_reset(bp);\n\tif (rc) {\n\t\trc = -EBUSY;\n\t\tgoto resume_exit;\n\t}\n\n\trc = bnxt_hwrm_func_qcaps(bp);\n\tif (rc)\n\t\tgoto resume_exit;\n\n\tif (bnxt_hwrm_func_drv_rgtr(bp, NULL, 0, false)) {\n\t\trc = -ENODEV;\n\t\tgoto resume_exit;\n\t}\n\n\tbnxt_get_wol_settings(bp);\n\tif (netif_running(dev)) {\n\t\trc = bnxt_open(dev);\n\t\tif (!rc)\n\t\t\tnetif_device_attach(dev);\n\t}\n\nresume_exit:\n\tbnxt_ulp_start(bp, rc);\n\tif (!rc)\n\t\tbnxt_reenable_sriov(bp);\n\trtnl_unlock();\n\treturn rc;\n}\n\nstatic SIMPLE_DEV_PM_OPS(bnxt_pm_ops, bnxt_suspend, bnxt_resume);\n#define BNXT_PM_OPS (&bnxt_pm_ops)\n\n#else\n\n#define BNXT_PM_OPS NULL\n\n#endif /* CONFIG_PM_SLEEP */\n\n/**\n * bnxt_io_error_detected - called when PCI error is detected\n * @pdev: Pointer to PCI device\n * @state: The current pci connection state\n *\n * This function is called after a PCI bus error affecting\n * this device has been detected.\n */\nstatic pci_ers_result_t bnxt_io_error_detected(struct pci_dev *pdev,\n\t\t\t\t\t       pci_channel_state_t state)\n{\n\tstruct net_device *netdev = pci_get_drvdata(pdev);\n\tstruct bnxt *bp = netdev_priv(netdev);\n\n\tnetdev_info(netdev, \"PCI I/O error detected\\n\");\n\n\trtnl_lock();\n\tnetif_device_detach(netdev);\n\n\tbnxt_ulp_stop(bp);\n\n\tif (state == pci_channel_io_perm_failure) {\n\t\trtnl_unlock();\n\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\t}\n\n\tif (state == pci_channel_io_frozen)\n\t\tset_bit(BNXT_STATE_PCI_CHANNEL_IO_FROZEN, &bp->state);\n\n\tif (netif_running(netdev))\n\t\tbnxt_close(netdev);\n\n\tpci_disable_device(pdev);\n\tbnxt_free_ctx_mem(bp);\n\tkfree(bp->ctx);\n\tbp->ctx = NULL;\n\trtnl_unlock();\n\n\t/* Request a slot slot reset. */\n\treturn PCI_ERS_RESULT_NEED_RESET;\n}\n\n/**\n * bnxt_io_slot_reset - called after the pci bus has been reset.\n * @pdev: Pointer to PCI device\n *\n * Restart the card from scratch, as if from a cold-boot.\n * At this point, the card has exprienced a hard reset,\n * followed by fixups by BIOS, and has its config space\n * set up identically to what it was at cold boot.\n */\nstatic pci_ers_result_t bnxt_io_slot_reset(struct pci_dev *pdev)\n{\n\tpci_ers_result_t result = PCI_ERS_RESULT_DISCONNECT;\n\tstruct net_device *netdev = pci_get_drvdata(pdev);\n\tstruct bnxt *bp = netdev_priv(netdev);\n\tint err = 0, off;\n\n\tnetdev_info(bp->dev, \"PCI Slot Reset\\n\");\n\n\trtnl_lock();\n\n\tif (pci_enable_device(pdev)) {\n\t\tdev_err(&pdev->dev,\n\t\t\t\"Cannot re-enable PCI device after reset.\\n\");\n\t} else {\n\t\tpci_set_master(pdev);\n\t\t/* Upon fatal error, our device internal logic that latches to\n\t\t * BAR value is getting reset and will restore only upon\n\t\t * rewritting the BARs.\n\t\t *\n\t\t * As pci_restore_state() does not re-write the BARs if the\n\t\t * value is same as saved value earlier, driver needs to\n\t\t * write the BARs to 0 to force restore, in case of fatal error.\n\t\t */\n\t\tif (test_and_clear_bit(BNXT_STATE_PCI_CHANNEL_IO_FROZEN,\n\t\t\t\t       &bp->state)) {\n\t\t\tfor (off = PCI_BASE_ADDRESS_0;\n\t\t\t     off <= PCI_BASE_ADDRESS_5; off += 4)\n\t\t\t\tpci_write_config_dword(bp->pdev, off, 0);\n\t\t}\n\t\tpci_restore_state(pdev);\n\t\tpci_save_state(pdev);\n\n\t\terr = bnxt_hwrm_func_reset(bp);\n\t\tif (!err)\n\t\t\tresult = PCI_ERS_RESULT_RECOVERED;\n\t}\n\n\trtnl_unlock();\n\n\treturn result;\n}\n\n/**\n * bnxt_io_resume - called when traffic can start flowing again.\n * @pdev: Pointer to PCI device\n *\n * This callback is called when the error recovery driver tells\n * us that its OK to resume normal operation.\n */\nstatic void bnxt_io_resume(struct pci_dev *pdev)\n{\n\tstruct net_device *netdev = pci_get_drvdata(pdev);\n\tstruct bnxt *bp = netdev_priv(netdev);\n\tint err;\n\n\tnetdev_info(bp->dev, \"PCI Slot Resume\\n\");\n\trtnl_lock();\n\n\terr = bnxt_hwrm_func_qcaps(bp);\n\tif (!err && netif_running(netdev))\n\t\terr = bnxt_open(netdev);\n\n\tbnxt_ulp_start(bp, err);\n\tif (!err) {\n\t\tbnxt_reenable_sriov(bp);\n\t\tnetif_device_attach(netdev);\n\t}\n\n\trtnl_unlock();\n}\n\nstatic const struct pci_error_handlers bnxt_err_handler = {\n\t.error_detected\t= bnxt_io_error_detected,\n\t.slot_reset\t= bnxt_io_slot_reset,\n\t.resume\t\t= bnxt_io_resume\n};\n\nstatic struct pci_driver bnxt_pci_driver = {\n\t.name\t\t= DRV_MODULE_NAME,\n\t.id_table\t= bnxt_pci_tbl,\n\t.probe\t\t= bnxt_init_one,\n\t.remove\t\t= bnxt_remove_one,\n\t.shutdown\t= bnxt_shutdown,\n\t.driver.pm\t= BNXT_PM_OPS,\n\t.err_handler\t= &bnxt_err_handler,\n#if defined(CONFIG_BNXT_SRIOV)\n\t.sriov_configure = bnxt_sriov_configure,\n#endif\n};\n\nstatic int __init bnxt_init(void)\n{\n\tbnxt_debug_init();\n\treturn pci_register_driver(&bnxt_pci_driver);\n}\n\nstatic void __exit bnxt_exit(void)\n{\n\tpci_unregister_driver(&bnxt_pci_driver);\n\tif (bnxt_pf_wq)\n\t\tdestroy_workqueue(bnxt_pf_wq);\n\tbnxt_debug_exit();\n}\n\nmodule_init(bnxt_init);\nmodule_exit(bnxt_exit);\n"}}, "reports": [{"events": [{"location": {"col": 0, "file": 0, "line": 7612}, "message": "error: we previously assumed 'bp->fw_health' could be null (see line 7583)"}], "macros": [], "notes": [], "path": "/src/drivers/net/ethernet/broadcom/bnxt/bnxt.c", "reportHash": "4b43ae769a4c9947820fc5a8b6be64e4", "checkerName": "smatch.check_check_deref", "reviewStatus": null, "severity": "UNSPECIFIED"}]};
      window.onload = function() {
        if (!browserCompatible) {
          setNonCompatibleBrowserMessage();
        } else {
          BugViewer.init(data.files, data.reports);
          BugViewer.create();
          BugViewer.initByUrl();
        }
      };
    </script>
  </head>
  <body>
  <div class="container">
    <div id="content">
      <div id="side-bar">
        <div class="header">
          <a href="index.html" class="button">&#8249; Return to List</a>
        </div>
        <div id="report-nav">
          <div class="header">Reports</div>
        </div>
      </div>
      <div id="editor-wrapper">
        <div class="header">
          <div id="file">
            <span class="label">File:</span>
            <span id="file-path"></span>
          </div>
          <div id="checker">
            <span class="label">Checker name:</span>
            <span id="checker-name"></span>
          </div>
          <div id="review-status-wrapper">
            <span class="label">Review status:</span>
            <span id="review-status"></span>
          </div>
        </div>
        <div id="editor"></div>
      </div>
    </div>
  </div>
  </body>
</html>
