<!DOCTYPE html>
<html>
  <head>
    <title>Plist HTML Viewer</title>

    <meta charset="UTF-8">

    <style type="text/css">
      .CodeMirror{font-family:monospace;height:300px;color:#000;direction:ltr}.CodeMirror-lines{padding:4px 0}.CodeMirror pre{padding:0 4px}.CodeMirror-gutter-filler,.CodeMirror-scrollbar-filler{background-color:#fff}.CodeMirror-gutters{border-right:1px solid #ddd;background-color:#f7f7f7;white-space:nowrap}.CodeMirror-linenumber{padding:0 3px 0 5px;min-width:20px;text-align:right;color:#999;white-space:nowrap}.CodeMirror-guttermarker{color:#000}.CodeMirror-guttermarker-subtle{color:#999}.CodeMirror-cursor{border-left:1px solid #000;border-right:none;width:0}.CodeMirror div.CodeMirror-secondarycursor{border-left:1px solid silver}.cm-fat-cursor .CodeMirror-cursor{width:auto;border:0!important;background:#7e7}.cm-fat-cursor div.CodeMirror-cursors{z-index:1}.cm-animate-fat-cursor{width:auto;border:0;-webkit-animation:blink 1.06s steps(1) infinite;-moz-animation:blink 1.06s steps(1) infinite;animation:blink 1.06s steps(1) infinite;background-color:#7e7}@-moz-keyframes blink{50%{background-color:transparent}}@-webkit-keyframes blink{50%{background-color:transparent}}@keyframes blink{50%{background-color:transparent}}.cm-tab{display:inline-block;text-decoration:inherit}.CodeMirror-rulers{position:absolute;left:0;right:0;top:-50px;bottom:-20px;overflow:hidden}.CodeMirror-ruler{border-left:1px solid #ccc;top:0;bottom:0;position:absolute}.cm-s-default .cm-header{color:#00f}.cm-s-default .cm-quote{color:#090}.cm-negative{color:#d44}.cm-positive{color:#292}.cm-header,.cm-strong{font-weight:700}.cm-em{font-style:italic}.cm-link{text-decoration:underline}.cm-strikethrough{text-decoration:line-through}.cm-s-default .cm-keyword{color:#708}.cm-s-default .cm-atom{color:#219}.cm-s-default .cm-number{color:#164}.cm-s-default .cm-def{color:#00f}.cm-s-default .cm-variable-2{color:#05a}.cm-s-default .cm-type,.cm-s-default .cm-variable-3{color:#085}.cm-s-default .cm-comment{color:#a50}.cm-s-default .cm-string{color:#a11}.cm-s-default .cm-string-2{color:#f50}.cm-s-default .cm-meta{color:#555}.cm-s-default .cm-qualifier{color:#555}.cm-s-default .cm-builtin{color:#30a}.cm-s-default .cm-bracket{color:#997}.cm-s-default .cm-tag{color:#170}.cm-s-default .cm-attribute{color:#00c}.cm-s-default .cm-hr{color:#999}.cm-s-default .cm-link{color:#00c}.cm-s-default .cm-error{color:red}.cm-invalidchar{color:red}.CodeMirror-composing{border-bottom:2px solid}div.CodeMirror span.CodeMirror-matchingbracket{color:#0f0}div.CodeMirror span.CodeMirror-nonmatchingbracket{color:#f22}.CodeMirror-matchingtag{background:rgba(255,150,0,.3)}.CodeMirror-activeline-background{background:#e8f2ff}.CodeMirror{position:relative;overflow:hidden;background:#fff}.CodeMirror-scroll{overflow:scroll!important;margin-bottom:-30px;margin-right:-30px;padding-bottom:30px;height:100%;outline:0;position:relative}.CodeMirror-sizer{position:relative;border-right:30px solid transparent}.CodeMirror-gutter-filler,.CodeMirror-hscrollbar,.CodeMirror-scrollbar-filler,.CodeMirror-vscrollbar{position:absolute;z-index:6;display:none}.CodeMirror-vscrollbar{right:0;top:0;overflow-x:hidden;overflow-y:scroll}.CodeMirror-hscrollbar{bottom:0;left:0;overflow-y:hidden;overflow-x:scroll}.CodeMirror-scrollbar-filler{right:0;bottom:0}.CodeMirror-gutter-filler{left:0;bottom:0}.CodeMirror-gutters{position:absolute;left:0;top:0;min-height:100%;z-index:3}.CodeMirror-gutter{white-space:normal;height:100%;display:inline-block;vertical-align:top;margin-bottom:-30px}.CodeMirror-gutter-wrapper{position:absolute;z-index:4;background:0 0!important;border:none!important}.CodeMirror-gutter-background{position:absolute;top:0;bottom:0;z-index:4}.CodeMirror-gutter-elt{position:absolute;cursor:default;z-index:4}.CodeMirror-gutter-wrapper ::selection{background-color:transparent}.CodeMirror-gutter-wrapper ::-moz-selection{background-color:transparent}.CodeMirror-lines{cursor:text;min-height:1px}.CodeMirror pre{-moz-border-radius:0;-webkit-border-radius:0;border-radius:0;border-width:0;background:0 0;font-family:inherit;font-size:inherit;margin:0;white-space:pre;word-wrap:normal;line-height:inherit;color:inherit;z-index:2;position:relative;overflow:visible;-webkit-tap-highlight-color:transparent;-webkit-font-variant-ligatures:contextual;font-variant-ligatures:contextual}.CodeMirror-wrap pre{word-wrap:break-word;white-space:pre-wrap;word-break:normal}.CodeMirror-linebackground{position:absolute;left:0;right:0;top:0;bottom:0;z-index:0}.CodeMirror-linewidget{position:relative;z-index:2;overflow:auto}.CodeMirror-rtl pre{direction:rtl}.CodeMirror-code{outline:0}.CodeMirror-gutter,.CodeMirror-gutters,.CodeMirror-linenumber,.CodeMirror-scroll,.CodeMirror-sizer{-moz-box-sizing:content-box;box-sizing:content-box}.CodeMirror-measure{position:absolute;width:100%;height:0;overflow:hidden;visibility:hidden}.CodeMirror-cursor{position:absolute;pointer-events:none}.CodeMirror-measure pre{position:static}div.CodeMirror-cursors{visibility:hidden;position:relative;z-index:3}div.CodeMirror-dragcursors{visibility:visible}.CodeMirror-focused div.CodeMirror-cursors{visibility:visible}.CodeMirror-selected{background:#d9d9d9}.CodeMirror-focused .CodeMirror-selected{background:#d7d4f0}.CodeMirror-crosshair{cursor:crosshair}.CodeMirror-line::selection,.CodeMirror-line>span::selection,.CodeMirror-line>span>span::selection{background:#d7d4f0}.CodeMirror-line::-moz-selection,.CodeMirror-line>span::-moz-selection,.CodeMirror-line>span>span::-moz-selection{background:#d7d4f0}.cm-searching{background-color:#ffa;background-color:rgba(255,255,0,.4)}.cm-force-border{padding-right:.1px}@media print{.CodeMirror div.CodeMirror-cursors{visibility:hidden}}.cm-tab-wrap-hack:after{content:''}span.CodeMirror-selectedtext{background:0 0}
/*# sourceMappingURL=codemirror.min.css.map */

      .severity-low {
  background-color: #669603;
}

.severity-low:after {
  content : 'L';
}

.severity-unspecified {
  background-color: #666666;
}

.severity-unspecified:after {
  content : 'U';
}

.severity-style {
  background-color: #9932cc;
}

.severity-style:after {
  content : 'S';
}

.severity-medium {
  background-color: #a9d323;
  color: black;
}

.severity-medium:after {
  content : 'M';
}

.severity-high {
  background-color: #ffa800;
}

.severity-high:after {
  content : 'H';
}

.severity-critical {
  background-color: #e92625;
}

.severity-critical:after {
  content : 'C';
}

i[class*="severity-"] {
  line-height: normal;
  text-transform: capitalize;
  font-size: 0.8em;
  font-weight: bold;
  color: white;
  display: inline-block;
  width: 16px;
  height: 16px;
  text-align: center;
  font-family: sans-serif;
}

      html, body {
  width: 100%;
  height: 100%;
  padding: 0px;
  margin: 0px;
}

div.container {
  padding: 10px;
}

#content {
  height: 100%;
  display: block;
  overflow: hidden;
}

#content > div {
  margin: 10px;
  overflow: hidden;
  border: 1px solid #ddd;
  border-radius: 3px;
  overflow: hidden;
  height: 97%;
}

.button {
  background-color: #f1f1f1;
  text-decoration: none;
  display: inline-block;
  padding: 8px 16px;
  color: black;
  cursor: pointer;
}

.button:hover {
  background-color: #ddd;
  color: black;
}

.review-status {
  color: white;
  text-align: center;
}

.review-status-confirmed {
  background-color: #e92625;
}

.review-status-false-positive {
  background-color: grey;
}

.review-status-intentional {
  background-color: #669603;
}

      div.container {
  width: 100%;
  height: 100%;
  padding: 0px;
}

#editor-wrapper {
  margin: 10px;
}

#side-bar {
  float: left;
  width: 260px;
  margin: 0px;
}

#report-nav ul {
  list-style-type: none;
  padding: 0;
  margin: 0;
  overflow-y: auto;
  height: 100%;
}

#report-nav ul > li {
  padding: .4em;
  background-color: #fff;
  border-bottom: 1px solid rgba(0,0,0,.125);
  text-align: left;
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

#report-nav ul > li.active {
  background-color: #427ea9;
  color: white;
}

#report-nav ul > li:hover {
  background-color: #427ea9;
  color: white;
  cursor: pointer;
}

#report-nav ul a {
  text-decoration: none;
}

#report-nav i[class*="severity-"] {
  margin-right: 5px;
}

.header {
  border-bottom: 1px solid lightgrey;
  font-family: monospace;
  padding: 10px;
  background-color: #fafbfc;
  border-bottom: 1px solid #e1e4e8;
  border-top-left-radius: 2px;
  border-top-right-radius: 2px;
}

#report-nav .header {
  font-weight: bold;
}

#editor-wrapper .header > div {
  padding-top: 2px;
}

#file-path,
#checker-name {
  color: #195ea2;
}

#review-status {
  padding: 0px 5px;
}

#file-path {
  font-family: monospace;
}

.check-msg {
  display: inline-block;
  padding: 3px 6px;
  margin: 1px;
  -webkit-border-radius: 5px;
  -moz-border-radius: 5px;
  border-radius: 5px;
}

.check-msg.info {
  color: #00546f;
  background-color: #bfdfe9;
  border: 1px solid #87a8b3;
}

.check-msg.error {
  background-color: #f2dede;
  color: #a94442;
  border: 1px solid #ebcccc;
}

.check-msg.macro {
  background-color: #d7dac2;
  color: #4f5c6d;
  border: 1px solid #d7dac2;
}

.check-msg.note {
  background-color: #d7d7d7;
  color: #4f5c6d;
  border: 1px solid #bfbfbf;
}

.check-msg.current {
  border: 2px dashed #3692ff;
}

.check-msg .tag {
  padding: 1px 5px;
  text-align: center;
  border-radius: 2px;
  margin-right: 5px;
  text-decoration: inherit;
}

.check-msg .tag.macro {
  background-color: #83876a;
  color: white;
  text-transform: capitalize;
}

.check-msg .tag.note {
  background-color: #9299a1;
  color: white;
  text-transform: capitalize;
}

.checker-enum {
  color: white;
  padding: 1px 5px;
  text-align: center;
  border-radius: 25px;
  margin-right: 5px;
  text-decoration: inherit;
}

.checker-enum.info {
  background-color: #427ea9;
}

.checker-enum.error {
  background-color: #a94442;
}

.arrow {
  border: solid black;
  border-width: 0 3px 3px 0;
  display: inline-block;
  padding: 3px;
  cursor: pointer;
  margin: 0px 5px;
}

.arrow:hover {
  border: solid #437ea8;
  border-width: 0 3px 3px 0;
}

.left-arrow {
  transform: rotate(135deg);
  -webkit-transform: rotate(135deg);
}

.right-arrow {
  transform: rotate(-45deg);
  -webkit-transform: rotate(-45deg);
}

    </style>

    <script type="text/javascript">
      function setNonCompatibleBrowserMessage() {
  document.body.innerHTML =
    '<h2 style="margin-left: 20px;">Your browser is not compatible with CodeChecker Viewer!</h2> \
     <p style="margin-left: 20px;">The version required for the following browsers are:</p> \
     <ul style="margin-left: 20px;"> \
     <li>Internet Explorer: version 9 or newer</li> \
     <li>Firefox: version 22.0 or newer</li> \
     </ul>';
}

// http://stackoverflow.com/questions/5916900/how-can-you-detect-the-version-of-a-browser
var browserVersion = (function(){
  var ua = navigator.userAgent, tem,
    M = ua.match(/(opera|chrome|safari|firefox|msie|trident(?=\/))\/?\s*(\d+)/i) || [];

  if (/trident/i.test(M[1])) {
    tem = /\brv[ :]+(\d+)/g.exec(ua) || [];
    return 'IE ' + (tem[1] || '');
  }

  if (M[1] === 'Chrome') {
    tem = ua.match(/\b(OPR|Edge)\/(\d+)/);
    if (tem != null) return tem.slice(1).join(' ').replace('OPR', 'Opera');
  }

  M = M[2] ? [M[1], M[2]] : [navigator.appName, navigator.appVersion, '-?'];
  if ((tem = ua.match(/version\/(\d+)/i)) != null) M.splice(1, 1, tem[1]);
    return M.join(' ');
})();

var pos = browserVersion.indexOf(' ');
var browser = browserVersion.substr(0, pos);
var version = parseInt(browserVersion.substr(pos + 1));

var browserCompatible
  = browser === 'Firefox'
  ? version >= 22
  : browser === 'IE'
  ? version >= 9
  : true;


      /* MIT License

Copyright (C) 2017 by Marijn Haverbeke <marijnh@gmail.com> and others

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
 */
      !function(e,t){"object"==typeof exports&&"undefined"!=typeof module?module.exports=t():"function"==typeof define&&define.amd?define(t):e.CodeMirror=t()}(this,function(){"use strict";function e(e){return new RegExp("(^|\\s)"+e+"(?:$|\\s)\\s*")}function t(e){for(var t=e.childNodes.length;t>0;--t)e.removeChild(e.firstChild);return e}function r(e,r){return t(e).appendChild(r)}function n(e,t,r,n){var i=document.createElement(e);if(r&&(i.className=r),n&&(i.style.cssText=n),"string"==typeof t)i.appendChild(document.createTextNode(t));else if(t)for(var o=0;o<t.length;++o)i.appendChild(t[o]);return i}function i(e,t,r,i){var o=n(e,t,r,i);return o.setAttribute("role","presentation"),o}function o(e,t){if(3==t.nodeType&&(t=t.parentNode),e.contains)return e.contains(t);do{if(11==t.nodeType&&(t=t.host),t==e)return!0}while(t=t.parentNode)}function l(){var e;try{e=document.activeElement}catch(t){e=document.body||null}for(;e&&e.shadowRoot&&e.shadowRoot.activeElement;)e=e.shadowRoot.activeElement;return e}function s(t,r){var n=t.className;e(r).test(n)||(t.className+=(n?" ":"")+r)}function a(t,r){for(var n=t.split(" "),i=0;i<n.length;i++)n[i]&&!e(n[i]).test(r)&&(r+=" "+n[i]);return r}function u(e){var t=Array.prototype.slice.call(arguments,1);return function(){return e.apply(null,t)}}function c(e,t,r){t||(t={});for(var n in e)!e.hasOwnProperty(n)||!1===r&&t.hasOwnProperty(n)||(t[n]=e[n]);return t}function f(e,t,r,n,i){null==t&&-1==(t=e.search(/[^\s\u00a0]/))&&(t=e.length);for(var o=n||0,l=i||0;;){var s=e.indexOf("\t",o);if(s<0||s>=t)return l+(t-o);l+=s-o,l+=r-l%r,o=s+1}}function h(e,t){for(var r=0;r<e.length;++r)if(e[r]==t)return r;return-1}function d(e,t,r){for(var n=0,i=0;;){var o=e.indexOf("\t",n);-1==o&&(o=e.length);var l=o-n;if(o==e.length||i+l>=t)return n+Math.min(l,t-i);if(i+=o-n,i+=r-i%r,n=o+1,i>=t)return n}}function p(e){for(;Kl.length<=e;)Kl.push(g(Kl)+" ");return Kl[e]}function g(e){return e[e.length-1]}function v(e,t){for(var r=[],n=0;n<e.length;n++)r[n]=t(e[n],n);return r}function m(e,t,r){for(var n=0,i=r(t);n<e.length&&r(e[n])<=i;)n++;e.splice(n,0,t)}function y(){}function b(e,t){var r;return Object.create?r=Object.create(e):(y.prototype=e,r=new y),t&&c(t,r),r}function w(e){return/\w/.test(e)||e>""&&(e.toUpperCase()!=e.toLowerCase()||jl.test(e))}function x(e,t){return t?!!(t.source.indexOf("\\w")>-1&&w(e))||t.test(e):w(e)}function C(e){for(var t in e)if(e.hasOwnProperty(t)&&e[t])return!1;return!0}function S(e){return e.charCodeAt(0)>=768&&Xl.test(e)}function L(e,t,r){for(;(r<0?t>0:t<e.length)&&S(e.charAt(t));)t+=r;return t}function k(e,t,r){for(var n=t>r?-1:1;;){if(t==r)return t;var i=(t+r)/2,o=n<0?Math.ceil(i):Math.floor(i);if(o==t)return e(o)?t:r;e(o)?r=o:t=o+n}}function T(e,t,r){var o=this;this.input=r,o.scrollbarFiller=n("div",null,"CodeMirror-scrollbar-filler"),o.scrollbarFiller.setAttribute("cm-not-content","true"),o.gutterFiller=n("div",null,"CodeMirror-gutter-filler"),o.gutterFiller.setAttribute("cm-not-content","true"),o.lineDiv=i("div",null,"CodeMirror-code"),o.selectionDiv=n("div",null,null,"position: relative; z-index: 1"),o.cursorDiv=n("div",null,"CodeMirror-cursors"),o.measure=n("div",null,"CodeMirror-measure"),o.lineMeasure=n("div",null,"CodeMirror-measure"),o.lineSpace=i("div",[o.measure,o.lineMeasure,o.selectionDiv,o.cursorDiv,o.lineDiv],null,"position: relative; outline: none");var l=i("div",[o.lineSpace],"CodeMirror-lines");o.mover=n("div",[l],null,"position: relative"),o.sizer=n("div",[o.mover],"CodeMirror-sizer"),o.sizerWidth=null,o.heightForcer=n("div",null,null,"position: absolute; height: "+Rl+"px; width: 1px;"),o.gutters=n("div",null,"CodeMirror-gutters"),o.lineGutter=null,o.scroller=n("div",[o.sizer,o.heightForcer,o.gutters],"CodeMirror-scroll"),o.scroller.setAttribute("tabIndex","-1"),o.wrapper=n("div",[o.scrollbarFiller,o.gutterFiller,o.scroller],"CodeMirror"),gl&&vl<8&&(o.gutters.style.zIndex=-1,o.scroller.style.paddingRight=0),ml||fl&&Tl||(o.scroller.draggable=!0),e&&(e.appendChild?e.appendChild(o.wrapper):e(o.wrapper)),o.viewFrom=o.viewTo=t.first,o.reportedViewFrom=o.reportedViewTo=t.first,o.view=[],o.renderedView=null,o.externalMeasured=null,o.viewOffset=0,o.lastWrapHeight=o.lastWrapWidth=0,o.updateLineNumbers=null,o.nativeBarWidth=o.barHeight=o.barWidth=0,o.scrollbarsClipped=!1,o.lineNumWidth=o.lineNumInnerWidth=o.lineNumChars=null,o.alignWidgets=!1,o.cachedCharWidth=o.cachedTextHeight=o.cachedPaddingH=null,o.maxLine=null,o.maxLineLength=0,o.maxLineChanged=!1,o.wheelDX=o.wheelDY=o.wheelStartX=o.wheelStartY=null,o.shift=!1,o.selForContextMenu=null,o.activeTouch=null,r.init(o)}function M(e,t){if((t-=e.first)<0||t>=e.size)throw new Error("There is no line "+(t+e.first)+" in the document.");for(var r=e;!r.lines;)for(var n=0;;++n){var i=r.children[n],o=i.chunkSize();if(t<o){r=i;break}t-=o}return r.lines[t]}function N(e,t,r){var n=[],i=t.line;return e.iter(t.line,r.line+1,function(e){var o=e.text;i==r.line&&(o=o.slice(0,r.ch)),i==t.line&&(o=o.slice(t.ch)),n.push(o),++i}),n}function O(e,t,r){var n=[];return e.iter(t,r,function(e){n.push(e.text)}),n}function A(e,t){var r=t-e.height;if(r)for(var n=e;n;n=n.parent)n.height+=r}function W(e){if(null==e.parent)return null;for(var t=e.parent,r=h(t.lines,e),n=t.parent;n;t=n,n=n.parent)for(var i=0;n.children[i]!=t;++i)r+=n.children[i].chunkSize();return r+t.first}function D(e,t){var r=e.first;e:do{for(var n=0;n<e.children.length;++n){var i=e.children[n],o=i.height;if(t<o){e=i;continue e}t-=o,r+=i.chunkSize()}return r}while(!e.lines);for(var l=0;l<e.lines.length;++l){var s=e.lines[l].height;if(t<s)break;t-=s}return r+l}function H(e,t){return t>=e.first&&t<e.first+e.size}function F(e,t){return String(e.lineNumberFormatter(t+e.firstLineNumber))}function E(e,t,r){if(void 0===r&&(r=null),!(this instanceof E))return new E(e,t,r);this.line=e,this.ch=t,this.sticky=r}function P(e,t){return e.line-t.line||e.ch-t.ch}function I(e,t){return e.sticky==t.sticky&&0==P(e,t)}function z(e){return E(e.line,e.ch)}function R(e,t){return P(e,t)<0?t:e}function B(e,t){return P(e,t)<0?e:t}function G(e,t){return Math.max(e.first,Math.min(t,e.first+e.size-1))}function U(e,t){if(t.line<e.first)return E(e.first,0);var r=e.first+e.size-1;return t.line>r?E(r,M(e,r).text.length):V(t,M(e,t.line).text.length)}function V(e,t){var r=e.ch;return null==r||r>t?E(e.line,t):r<0?E(e.line,0):e}function K(e,t){for(var r=[],n=0;n<t.length;n++)r[n]=U(e,t[n]);return r}function j(){Yl=!0}function X(){_l=!0}function Y(e,t,r){this.marker=e,this.from=t,this.to=r}function _(e,t){if(e)for(var r=0;r<e.length;++r){var n=e[r];if(n.marker==t)return n}}function $(e,t){for(var r,n=0;n<e.length;++n)e[n]!=t&&(r||(r=[])).push(e[n]);return r}function q(e,t){e.markedSpans=e.markedSpans?e.markedSpans.concat([t]):[t],t.marker.attachLine(e)}function Z(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t)||o.from==t&&"bookmark"==l.type&&(!r||!o.marker.insertLeft)){var s=null==o.to||(l.inclusiveRight?o.to>=t:o.to>t);(n||(n=[])).push(new Y(l,o.from,s?null:o.to))}}return n}function Q(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.to||(l.inclusiveRight?o.to>=t:o.to>t)||o.from==t&&"bookmark"==l.type&&(!r||o.marker.insertLeft)){var s=null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t);(n||(n=[])).push(new Y(l,s?null:o.from-t,null==o.to?null:o.to-t))}}return n}function J(e,t){if(t.full)return null;var r=H(e,t.from.line)&&M(e,t.from.line).markedSpans,n=H(e,t.to.line)&&M(e,t.to.line).markedSpans;if(!r&&!n)return null;var i=t.from.ch,o=t.to.ch,l=0==P(t.from,t.to),s=Z(r,i,l),a=Q(n,o,l),u=1==t.text.length,c=g(t.text).length+(u?i:0);if(s)for(var f=0;f<s.length;++f){var h=s[f];if(null==h.to){var d=_(a,h.marker);d?u&&(h.to=null==d.to?null:d.to+c):h.to=i}}if(a)for(var p=0;p<a.length;++p){var v=a[p];null!=v.to&&(v.to+=c),null==v.from?_(s,v.marker)||(v.from=c,u&&(s||(s=[])).push(v)):(v.from+=c,u&&(s||(s=[])).push(v))}s&&(s=ee(s)),a&&a!=s&&(a=ee(a));var m=[s];if(!u){var y,b=t.text.length-2;if(b>0&&s)for(var w=0;w<s.length;++w)null==s[w].to&&(y||(y=[])).push(new Y(s[w].marker,null,null));for(var x=0;x<b;++x)m.push(y);m.push(a)}return m}function ee(e){for(var t=0;t<e.length;++t){var r=e[t];null!=r.from&&r.from==r.to&&!1!==r.marker.clearWhenEmpty&&e.splice(t--,1)}return e.length?e:null}function te(e,t,r){var n=null;if(e.iter(t.line,r.line+1,function(e){if(e.markedSpans)for(var t=0;t<e.markedSpans.length;++t){var r=e.markedSpans[t].marker;!r.readOnly||n&&-1!=h(n,r)||(n||(n=[])).push(r)}}),!n)return null;for(var i=[{from:t,to:r}],o=0;o<n.length;++o)for(var l=n[o],s=l.find(0),a=0;a<i.length;++a){var u=i[a];if(!(P(u.to,s.from)<0||P(u.from,s.to)>0)){var c=[a,1],f=P(u.from,s.from),d=P(u.to,s.to);(f<0||!l.inclusiveLeft&&!f)&&c.push({from:u.from,to:s.from}),(d>0||!l.inclusiveRight&&!d)&&c.push({from:s.to,to:u.to}),i.splice.apply(i,c),a+=c.length-3}}return i}function re(e){var t=e.markedSpans;if(t){for(var r=0;r<t.length;++r)t[r].marker.detachLine(e);e.markedSpans=null}}function ne(e,t){if(t){for(var r=0;r<t.length;++r)t[r].marker.attachLine(e);e.markedSpans=t}}function ie(e){return e.inclusiveLeft?-1:0}function oe(e){return e.inclusiveRight?1:0}function le(e,t){var r=e.lines.length-t.lines.length;if(0!=r)return r;var n=e.find(),i=t.find(),o=P(n.from,i.from)||ie(e)-ie(t);if(o)return-o;var l=P(n.to,i.to)||oe(e)-oe(t);return l||t.id-e.id}function se(e,t){var r,n=_l&&e.markedSpans;if(n)for(var i=void 0,o=0;o<n.length;++o)(i=n[o]).marker.collapsed&&null==(t?i.from:i.to)&&(!r||le(r,i.marker)<0)&&(r=i.marker);return r}function ae(e){return se(e,!0)}function ue(e){return se(e,!1)}function ce(e,t,r,n,i){var o=M(e,t),l=_l&&o.markedSpans;if(l)for(var s=0;s<l.length;++s){var a=l[s];if(a.marker.collapsed){var u=a.marker.find(0),c=P(u.from,r)||ie(a.marker)-ie(i),f=P(u.to,n)||oe(a.marker)-oe(i);if(!(c>=0&&f<=0||c<=0&&f>=0)&&(c<=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.to,r)>=0:P(u.to,r)>0)||c>=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.from,n)<=0:P(u.from,n)<0)))return!0}}}function fe(e){for(var t;t=ae(e);)e=t.find(-1,!0).line;return e}function he(e){for(var t;t=ue(e);)e=t.find(1,!0).line;return e}function de(e){for(var t,r;t=ue(e);)e=t.find(1,!0).line,(r||(r=[])).push(e);return r}function pe(e,t){var r=M(e,t),n=fe(r);return r==n?t:W(n)}function ge(e,t){if(t>e.lastLine())return t;var r,n=M(e,t);if(!ve(e,n))return t;for(;r=ue(n);)n=r.find(1,!0).line;return W(n)+1}function ve(e,t){var r=_l&&t.markedSpans;if(r)for(var n=void 0,i=0;i<r.length;++i)if((n=r[i]).marker.collapsed){if(null==n.from)return!0;if(!n.marker.widgetNode&&0==n.from&&n.marker.inclusiveLeft&&me(e,t,n))return!0}}function me(e,t,r){if(null==r.to){var n=r.marker.find(1,!0);return me(e,n.line,_(n.line.markedSpans,r.marker))}if(r.marker.inclusiveRight&&r.to==t.text.length)return!0;for(var i=void 0,o=0;o<t.markedSpans.length;++o)if((i=t.markedSpans[o]).marker.collapsed&&!i.marker.widgetNode&&i.from==r.to&&(null==i.to||i.to!=r.from)&&(i.marker.inclusiveLeft||r.marker.inclusiveRight)&&me(e,t,i))return!0}function ye(e){for(var t=0,r=(e=fe(e)).parent,n=0;n<r.lines.length;++n){var i=r.lines[n];if(i==e)break;t+=i.height}for(var o=r.parent;o;r=o,o=r.parent)for(var l=0;l<o.children.length;++l){var s=o.children[l];if(s==r)break;t+=s.height}return t}function be(e){if(0==e.height)return 0;for(var t,r=e.text.length,n=e;t=ae(n);){var i=t.find(0,!0);n=i.from.line,r+=i.from.ch-i.to.ch}for(n=e;t=ue(n);){var o=t.find(0,!0);r-=n.text.length-o.from.ch,r+=(n=o.to.line).text.length-o.to.ch}return r}function we(e){var t=e.display,r=e.doc;t.maxLine=M(r,r.first),t.maxLineLength=be(t.maxLine),t.maxLineChanged=!0,r.iter(function(e){var r=be(e);r>t.maxLineLength&&(t.maxLineLength=r,t.maxLine=e)})}function xe(e,t,r,n){if(!e)return n(t,r,"ltr",0);for(var i=!1,o=0;o<e.length;++o){var l=e[o];(l.from<r&&l.to>t||t==r&&l.to==t)&&(n(Math.max(l.from,t),Math.min(l.to,r),1==l.level?"rtl":"ltr",o),i=!0)}i||n(t,r,"ltr")}function Ce(e,t,r){var n;$l=null;for(var i=0;i<e.length;++i){var o=e[i];if(o.from<t&&o.to>t)return i;o.to==t&&(o.from!=o.to&&"before"==r?n=i:$l=i),o.from==t&&(o.from!=o.to&&"before"!=r?n=i:$l=i)}return null!=n?n:$l}function Se(e,t){var r=e.order;return null==r&&(r=e.order=ql(e.text,t)),r}function Le(e,t){return e._handlers&&e._handlers[t]||Zl}function ke(e,t,r){if(e.removeEventListener)e.removeEventListener(t,r,!1);else if(e.detachEvent)e.detachEvent("on"+t,r);else{var n=e._handlers,i=n&&n[t];if(i){var o=h(i,r);o>-1&&(n[t]=i.slice(0,o).concat(i.slice(o+1)))}}}function Te(e,t){var r=Le(e,t);if(r.length)for(var n=Array.prototype.slice.call(arguments,2),i=0;i<r.length;++i)r[i].apply(null,n)}function Me(e,t,r){return"string"==typeof t&&(t={type:t,preventDefault:function(){this.defaultPrevented=!0}}),Te(e,r||t.type,e,t),He(t)||t.codemirrorIgnore}function Ne(e){var t=e._handlers&&e._handlers.cursorActivity;if(t)for(var r=e.curOp.cursorActivityHandlers||(e.curOp.cursorActivityHandlers=[]),n=0;n<t.length;++n)-1==h(r,t[n])&&r.push(t[n])}function Oe(e,t){return Le(e,t).length>0}function Ae(e){e.prototype.on=function(e,t){Ql(this,e,t)},e.prototype.off=function(e,t){ke(this,e,t)}}function We(e){e.preventDefault?e.preventDefault():e.returnValue=!1}function De(e){e.stopPropagation?e.stopPropagation():e.cancelBubble=!0}function He(e){return null!=e.defaultPrevented?e.defaultPrevented:0==e.returnValue}function Fe(e){We(e),De(e)}function Ee(e){return e.target||e.srcElement}function Pe(e){var t=e.which;return null==t&&(1&e.button?t=1:2&e.button?t=3:4&e.button&&(t=2)),Ml&&e.ctrlKey&&1==t&&(t=3),t}function Ie(e){if(null==Il){var t=n("span","​");r(e,n("span",[t,document.createTextNode("x")])),0!=e.firstChild.offsetHeight&&(Il=t.offsetWidth<=1&&t.offsetHeight>2&&!(gl&&vl<8))}var i=Il?n("span","​"):n("span"," ",null,"display: inline-block; width: 1px; margin-right: -1px");return i.setAttribute("cm-text",""),i}function ze(e){if(null!=zl)return zl;var n=r(e,document.createTextNode("AخA")),i=Wl(n,0,1).getBoundingClientRect(),o=Wl(n,1,2).getBoundingClientRect();return t(e),!(!i||i.left==i.right)&&(zl=o.right-i.right<3)}function Re(e){if(null!=ns)return ns;var t=r(e,n("span","x")),i=t.getBoundingClientRect(),o=Wl(t,0,1).getBoundingClientRect();return ns=Math.abs(i.left-o.left)>1}function Be(e,t){arguments.length>2&&(t.dependencies=Array.prototype.slice.call(arguments,2)),is[e]=t}function Ge(e){if("string"==typeof e&&os.hasOwnProperty(e))e=os[e];else if(e&&"string"==typeof e.name&&os.hasOwnProperty(e.name)){var t=os[e.name];"string"==typeof t&&(t={name:t}),(e=b(t,e)).name=t.name}else{if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+xml$/.test(e))return Ge("application/xml");if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+json$/.test(e))return Ge("application/json")}return"string"==typeof e?{name:e}:e||{name:"null"}}function Ue(e,t){t=Ge(t);var r=is[t.name];if(!r)return Ue(e,"text/plain");var n=r(e,t);if(ls.hasOwnProperty(t.name)){var i=ls[t.name];for(var o in i)i.hasOwnProperty(o)&&(n.hasOwnProperty(o)&&(n["_"+o]=n[o]),n[o]=i[o])}if(n.name=t.name,t.helperType&&(n.helperType=t.helperType),t.modeProps)for(var l in t.modeProps)n[l]=t.modeProps[l];return n}function Ve(e,t){c(t,ls.hasOwnProperty(e)?ls[e]:ls[e]={})}function Ke(e,t){if(!0===t)return t;if(e.copyState)return e.copyState(t);var r={};for(var n in t){var i=t[n];i instanceof Array&&(i=i.concat([])),r[n]=i}return r}function je(e,t){for(var r;e.innerMode&&(r=e.innerMode(t))&&r.mode!=e;)t=r.state,e=r.mode;return r||{mode:e,state:t}}function Xe(e,t,r){return!e.startState||e.startState(t,r)}function Ye(e,t,r,n){var i=[e.state.modeGen],o={};tt(e,t.text,e.doc.mode,r,function(e,t){return i.push(e,t)},o,n);for(var l=r.state,s=0;s<e.state.overlays.length;++s)!function(n){var l=e.state.overlays[n],s=1,a=0;r.state=!0,tt(e,t.text,l.mode,r,function(e,t){for(var r=s;a<e;){var n=i[s];n>e&&i.splice(s,1,e,i[s+1],n),s+=2,a=Math.min(e,n)}if(t)if(l.opaque)i.splice(r,s-r,e,"overlay "+t),s=r+2;else for(;r<s;r+=2){var o=i[r+1];i[r+1]=(o?o+" ":"")+"overlay "+t}},o)}(s);return r.state=l,{styles:i,classes:o.bgClass||o.textClass?o:null}}function _e(e,t,r){if(!t.styles||t.styles[0]!=e.state.modeGen){var n=$e(e,W(t)),i=t.text.length>e.options.maxHighlightLength&&Ke(e.doc.mode,n.state),o=Ye(e,t,n);i&&(n.state=i),t.stateAfter=n.save(!i),t.styles=o.styles,o.classes?t.styleClasses=o.classes:t.styleClasses&&(t.styleClasses=null),r===e.doc.highlightFrontier&&(e.doc.modeFrontier=Math.max(e.doc.modeFrontier,++e.doc.highlightFrontier))}return t.styles}function $e(e,t,r){var n=e.doc,i=e.display;if(!n.mode.startState)return new us(n,!0,t);var o=rt(e,t,r),l=o>n.first&&M(n,o-1).stateAfter,s=l?us.fromSaved(n,l,o):new us(n,Xe(n.mode),o);return n.iter(o,t,function(r){qe(e,r.text,s);var n=s.line;r.stateAfter=n==t-1||n%5==0||n>=i.viewFrom&&n<i.viewTo?s.save():null,s.nextLine()}),r&&(n.modeFrontier=s.line),s}function qe(e,t,r,n){var i=e.doc.mode,o=new ss(t,e.options.tabSize,r);for(o.start=o.pos=n||0,""==t&&Ze(i,r.state);!o.eol();)Qe(i,o,r.state),o.start=o.pos}function Ze(e,t){if(e.blankLine)return e.blankLine(t);if(e.innerMode){var r=je(e,t);return r.mode.blankLine?r.mode.blankLine(r.state):void 0}}function Qe(e,t,r,n){for(var i=0;i<10;i++){n&&(n[0]=je(e,r).mode);var o=e.token(t,r);if(t.pos>t.start)return o}throw new Error("Mode "+e.name+" failed to advance stream.")}function Je(e,t,r,n){var i,o,l=e.doc,s=l.mode,a=M(l,(t=U(l,t)).line),u=$e(e,t.line,r),c=new ss(a.text,e.options.tabSize,u);for(n&&(o=[]);(n||c.pos<t.ch)&&!c.eol();)c.start=c.pos,i=Qe(s,c,u.state),n&&o.push(new cs(c,i,Ke(l.mode,u.state)));return n?o:new cs(c,i,u.state)}function et(e,t){if(e)for(;;){var r=e.match(/(?:^|\s+)line-(background-)?(\S+)/);if(!r)break;e=e.slice(0,r.index)+e.slice(r.index+r[0].length);var n=r[1]?"bgClass":"textClass";null==t[n]?t[n]=r[2]:new RegExp("(?:^|s)"+r[2]+"(?:$|s)").test(t[n])||(t[n]+=" "+r[2])}return e}function tt(e,t,r,n,i,o,l){var s=r.flattenSpans;null==s&&(s=e.options.flattenSpans);var a,u=0,c=null,f=new ss(t,e.options.tabSize,n),h=e.options.addModeClass&&[null];for(""==t&&et(Ze(r,n.state),o);!f.eol();){if(f.pos>e.options.maxHighlightLength?(s=!1,l&&qe(e,t,n,f.pos),f.pos=t.length,a=null):a=et(Qe(r,f,n.state,h),o),h){var d=h[0].name;d&&(a="m-"+(a?d+" "+a:d))}if(!s||c!=a){for(;u<f.start;)i(u=Math.min(f.start,u+5e3),c);c=a}f.start=f.pos}for(;u<f.pos;){var p=Math.min(f.pos,u+5e3);i(p,c),u=p}}function rt(e,t,r){for(var n,i,o=e.doc,l=r?-1:t-(e.doc.mode.innerMode?1e3:100),s=t;s>l;--s){if(s<=o.first)return o.first;var a=M(o,s-1),u=a.stateAfter;if(u&&(!r||s+(u instanceof as?u.lookAhead:0)<=o.modeFrontier))return s;var c=f(a.text,null,e.options.tabSize);(null==i||n>c)&&(i=s-1,n=c)}return i}function nt(e,t){if(e.modeFrontier=Math.min(e.modeFrontier,t),!(e.highlightFrontier<t-10)){for(var r=e.first,n=t-1;n>r;n--){var i=M(e,n).stateAfter;if(i&&(!(i instanceof as)||n+i.lookAhead<t)){r=n+1;break}}e.highlightFrontier=Math.min(e.highlightFrontier,r)}}function it(e,t,r,n){e.text=t,e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null),null!=e.order&&(e.order=null),re(e),ne(e,r);var i=n?n(e):1;i!=e.height&&A(e,i)}function ot(e){e.parent=null,re(e)}function lt(e,t){if(!e||/^\s*$/.test(e))return null;var r=t.addModeClass?ps:ds;return r[e]||(r[e]=e.replace(/\S+/g,"cm-$&"))}function st(e,t){var r=i("span",null,null,ml?"padding-right: .1px":null),n={pre:i("pre",[r],"CodeMirror-line"),content:r,col:0,pos:0,cm:e,trailingSpace:!1,splitSpaces:(gl||ml)&&e.getOption("lineWrapping")};t.measure={};for(var o=0;o<=(t.rest?t.rest.length:0);o++){var l=o?t.rest[o-1]:t.line,s=void 0;n.pos=0,n.addToken=ut,ze(e.display.measure)&&(s=Se(l,e.doc.direction))&&(n.addToken=ft(n.addToken,s)),n.map=[],dt(l,n,_e(e,l,t!=e.display.externalMeasured&&W(l))),l.styleClasses&&(l.styleClasses.bgClass&&(n.bgClass=a(l.styleClasses.bgClass,n.bgClass||"")),l.styleClasses.textClass&&(n.textClass=a(l.styleClasses.textClass,n.textClass||""))),0==n.map.length&&n.map.push(0,0,n.content.appendChild(Ie(e.display.measure))),0==o?(t.measure.map=n.map,t.measure.cache={}):((t.measure.maps||(t.measure.maps=[])).push(n.map),(t.measure.caches||(t.measure.caches=[])).push({}))}if(ml){var u=n.content.lastChild;(/\bcm-tab\b/.test(u.className)||u.querySelector&&u.querySelector(".cm-tab"))&&(n.content.className="cm-tab-wrap-hack")}return Te(e,"renderLine",e,t.line,n.pre),n.pre.className&&(n.textClass=a(n.pre.className,n.textClass||"")),n}function at(e){var t=n("span","•","cm-invalidchar");return t.title="\\u"+e.charCodeAt(0).toString(16),t.setAttribute("aria-label",t.title),t}function ut(e,t,r,i,o,l,s){if(t){var a,u=e.splitSpaces?ct(t,e.trailingSpace):t,c=e.cm.state.specialChars,f=!1;if(c.test(t)){a=document.createDocumentFragment();for(var h=0;;){c.lastIndex=h;var d=c.exec(t),g=d?d.index-h:t.length-h;if(g){var v=document.createTextNode(u.slice(h,h+g));gl&&vl<9?a.appendChild(n("span",[v])):a.appendChild(v),e.map.push(e.pos,e.pos+g,v),e.col+=g,e.pos+=g}if(!d)break;h+=g+1;var m=void 0;if("\t"==d[0]){var y=e.cm.options.tabSize,b=y-e.col%y;(m=a.appendChild(n("span",p(b),"cm-tab"))).setAttribute("role","presentation"),m.setAttribute("cm-text","\t"),e.col+=b}else"\r"==d[0]||"\n"==d[0]?((m=a.appendChild(n("span","\r"==d[0]?"␍":"␤","cm-invalidchar"))).setAttribute("cm-text",d[0]),e.col+=1):((m=e.cm.options.specialCharPlaceholder(d[0])).setAttribute("cm-text",d[0]),gl&&vl<9?a.appendChild(n("span",[m])):a.appendChild(m),e.col+=1);e.map.push(e.pos,e.pos+1,m),e.pos++}}else e.col+=t.length,a=document.createTextNode(u),e.map.push(e.pos,e.pos+t.length,a),gl&&vl<9&&(f=!0),e.pos+=t.length;if(e.trailingSpace=32==u.charCodeAt(t.length-1),r||i||o||f||s){var w=r||"";i&&(w+=i),o&&(w+=o);var x=n("span",[a],w,s);return l&&(x.title=l),e.content.appendChild(x)}e.content.appendChild(a)}}function ct(e,t){if(e.length>1&&!/  /.test(e))return e;for(var r=t,n="",i=0;i<e.length;i++){var o=e.charAt(i);" "!=o||!r||i!=e.length-1&&32!=e.charCodeAt(i+1)||(o=" "),n+=o,r=" "==o}return n}function ft(e,t){return function(r,n,i,o,l,s,a){i=i?i+" cm-force-border":"cm-force-border";for(var u=r.pos,c=u+n.length;;){for(var f=void 0,h=0;h<t.length&&!((f=t[h]).to>u&&f.from<=u);h++);if(f.to>=c)return e(r,n,i,o,l,s,a);e(r,n.slice(0,f.to-u),i,o,null,s,a),o=null,n=n.slice(f.to-u),u=f.to}}}function ht(e,t,r,n){var i=!n&&r.widgetNode;i&&e.map.push(e.pos,e.pos+t,i),!n&&e.cm.display.input.needsContentAttribute&&(i||(i=e.content.appendChild(document.createElement("span"))),i.setAttribute("cm-marker",r.id)),i&&(e.cm.display.input.setUneditable(i),e.content.appendChild(i)),e.pos+=t,e.trailingSpace=!1}function dt(e,t,r){var n=e.markedSpans,i=e.text,o=0;if(n)for(var l,s,a,u,c,f,h,d=i.length,p=0,g=1,v="",m=0;;){if(m==p){a=u=c=f=s="",h=null,m=1/0;for(var y=[],b=void 0,w=0;w<n.length;++w){var x=n[w],C=x.marker;"bookmark"==C.type&&x.from==p&&C.widgetNode?y.push(C):x.from<=p&&(null==x.to||x.to>p||C.collapsed&&x.to==p&&x.from==p)?(null!=x.to&&x.to!=p&&m>x.to&&(m=x.to,u=""),C.className&&(a+=" "+C.className),C.css&&(s=(s?s+";":"")+C.css),C.startStyle&&x.from==p&&(c+=" "+C.startStyle),C.endStyle&&x.to==m&&(b||(b=[])).push(C.endStyle,x.to),C.title&&!f&&(f=C.title),C.collapsed&&(!h||le(h.marker,C)<0)&&(h=x)):x.from>p&&m>x.from&&(m=x.from)}if(b)for(var S=0;S<b.length;S+=2)b[S+1]==m&&(u+=" "+b[S]);if(!h||h.from==p)for(var L=0;L<y.length;++L)ht(t,0,y[L]);if(h&&(h.from||0)==p){if(ht(t,(null==h.to?d+1:h.to)-p,h.marker,null==h.from),null==h.to)return;h.to==p&&(h=!1)}}if(p>=d)break;for(var k=Math.min(d,m);;){if(v){var T=p+v.length;if(!h){var M=T>k?v.slice(0,k-p):v;t.addToken(t,M,l?l+a:a,c,p+M.length==m?u:"",f,s)}if(T>=k){v=v.slice(k-p),p=k;break}p=T,c=""}v=i.slice(o,o=r[g++]),l=lt(r[g++],t.cm.options)}}else for(var N=1;N<r.length;N+=2)t.addToken(t,i.slice(o,o=r[N]),lt(r[N+1],t.cm.options))}function pt(e,t,r){this.line=t,this.rest=de(t),this.size=this.rest?W(g(this.rest))-r+1:1,this.node=this.text=null,this.hidden=ve(e,t)}function gt(e,t,r){for(var n,i=[],o=t;o<r;o=n){var l=new pt(e.doc,M(e.doc,o),o);n=o+l.size,i.push(l)}return i}function vt(e){gs?gs.ops.push(e):e.ownsGroup=gs={ops:[e],delayedCallbacks:[]}}function mt(e){var t=e.delayedCallbacks,r=0;do{for(;r<t.length;r++)t[r].call(null);for(var n=0;n<e.ops.length;n++){var i=e.ops[n];if(i.cursorActivityHandlers)for(;i.cursorActivityCalled<i.cursorActivityHandlers.length;)i.cursorActivityHandlers[i.cursorActivityCalled++].call(null,i.cm)}}while(r<t.length)}function yt(e,t){var r=e.ownsGroup;if(r)try{mt(r)}finally{gs=null,t(r)}}function bt(e,t){var r=Le(e,t);if(r.length){var n,i=Array.prototype.slice.call(arguments,2);gs?n=gs.delayedCallbacks:vs?n=vs:(n=vs=[],setTimeout(wt,0));for(var o=0;o<r.length;++o)!function(e){n.push(function(){return r[e].apply(null,i)})}(o)}}function wt(){var e=vs;vs=null;for(var t=0;t<e.length;++t)e[t]()}function xt(e,t,r,n){for(var i=0;i<t.changes.length;i++){var o=t.changes[i];"text"==o?kt(e,t):"gutter"==o?Mt(e,t,r,n):"class"==o?Tt(e,t):"widget"==o&&Nt(e,t,n)}t.changes=null}function Ct(e){return e.node==e.text&&(e.node=n("div",null,null,"position: relative"),e.text.parentNode&&e.text.parentNode.replaceChild(e.node,e.text),e.node.appendChild(e.text),gl&&vl<8&&(e.node.style.zIndex=2)),e.node}function St(e,t){var r=t.bgClass?t.bgClass+" "+(t.line.bgClass||""):t.line.bgClass;if(r&&(r+=" CodeMirror-linebackground"),t.background)r?t.background.className=r:(t.background.parentNode.removeChild(t.background),t.background=null);else if(r){var i=Ct(t);t.background=i.insertBefore(n("div",null,r),i.firstChild),e.display.input.setUneditable(t.background)}}function Lt(e,t){var r=e.display.externalMeasured;return r&&r.line==t.line?(e.display.externalMeasured=null,t.measure=r.measure,r.built):st(e,t)}function kt(e,t){var r=t.text.className,n=Lt(e,t);t.text==t.node&&(t.node=n.pre),t.text.parentNode.replaceChild(n.pre,t.text),t.text=n.pre,n.bgClass!=t.bgClass||n.textClass!=t.textClass?(t.bgClass=n.bgClass,t.textClass=n.textClass,Tt(e,t)):r&&(t.text.className=r)}function Tt(e,t){St(e,t),t.line.wrapClass?Ct(t).className=t.line.wrapClass:t.node!=t.text&&(t.node.className="");var r=t.textClass?t.textClass+" "+(t.line.textClass||""):t.line.textClass;t.text.className=r||""}function Mt(e,t,r,i){if(t.gutter&&(t.node.removeChild(t.gutter),t.gutter=null),t.gutterBackground&&(t.node.removeChild(t.gutterBackground),t.gutterBackground=null),t.line.gutterClass){var o=Ct(t);t.gutterBackground=n("div",null,"CodeMirror-gutter-background "+t.line.gutterClass,"left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px; width: "+i.gutterTotalWidth+"px"),e.display.input.setUneditable(t.gutterBackground),o.insertBefore(t.gutterBackground,t.text)}var l=t.line.gutterMarkers;if(e.options.lineNumbers||l){var s=Ct(t),a=t.gutter=n("div",null,"CodeMirror-gutter-wrapper","left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px");if(e.display.input.setUneditable(a),s.insertBefore(a,t.text),t.line.gutterClass&&(a.className+=" "+t.line.gutterClass),!e.options.lineNumbers||l&&l["CodeMirror-linenumbers"]||(t.lineNumber=a.appendChild(n("div",F(e.options,r),"CodeMirror-linenumber CodeMirror-gutter-elt","left: "+i.gutterLeft["CodeMirror-linenumbers"]+"px; width: "+e.display.lineNumInnerWidth+"px"))),l)for(var u=0;u<e.options.gutters.length;++u){var c=e.options.gutters[u],f=l.hasOwnProperty(c)&&l[c];f&&a.appendChild(n("div",[f],"CodeMirror-gutter-elt","left: "+i.gutterLeft[c]+"px; width: "+i.gutterWidth[c]+"px"))}}}function Nt(e,t,r){t.alignable&&(t.alignable=null);for(var n=t.node.firstChild,i=void 0;n;n=i)i=n.nextSibling,"CodeMirror-linewidget"==n.className&&t.node.removeChild(n);At(e,t,r)}function Ot(e,t,r,n){var i=Lt(e,t);return t.text=t.node=i.pre,i.bgClass&&(t.bgClass=i.bgClass),i.textClass&&(t.textClass=i.textClass),Tt(e,t),Mt(e,t,r,n),At(e,t,n),t.node}function At(e,t,r){if(Wt(e,t.line,t,r,!0),t.rest)for(var n=0;n<t.rest.length;n++)Wt(e,t.rest[n],t,r,!1)}function Wt(e,t,r,i,o){if(t.widgets)for(var l=Ct(r),s=0,a=t.widgets;s<a.length;++s){var u=a[s],c=n("div",[u.node],"CodeMirror-linewidget");u.handleMouseEvents||c.setAttribute("cm-ignore-events","true"),Dt(u,c,r,i),e.display.input.setUneditable(c),o&&u.above?l.insertBefore(c,r.gutter||r.text):l.appendChild(c),bt(u,"redraw")}}function Dt(e,t,r,n){if(e.noHScroll){(r.alignable||(r.alignable=[])).push(t);var i=n.wrapperWidth;t.style.left=n.fixedPos+"px",e.coverGutter||(i-=n.gutterTotalWidth,t.style.paddingLeft=n.gutterTotalWidth+"px"),t.style.width=i+"px"}e.coverGutter&&(t.style.zIndex=5,t.style.position="relative",e.noHScroll||(t.style.marginLeft=-n.gutterTotalWidth+"px"))}function Ht(e){if(null!=e.height)return e.height;var t=e.doc.cm;if(!t)return 0;if(!o(document.body,e.node)){var i="position: relative;";e.coverGutter&&(i+="margin-left: -"+t.display.gutters.offsetWidth+"px;"),e.noHScroll&&(i+="width: "+t.display.wrapper.clientWidth+"px;"),r(t.display.measure,n("div",[e.node],null,i))}return e.height=e.node.parentNode.offsetHeight}function Ft(e,t){for(var r=Ee(t);r!=e.wrapper;r=r.parentNode)if(!r||1==r.nodeType&&"true"==r.getAttribute("cm-ignore-events")||r.parentNode==e.sizer&&r!=e.mover)return!0}function Et(e){return e.lineSpace.offsetTop}function Pt(e){return e.mover.offsetHeight-e.lineSpace.offsetHeight}function It(e){if(e.cachedPaddingH)return e.cachedPaddingH;var t=r(e.measure,n("pre","x")),i=window.getComputedStyle?window.getComputedStyle(t):t.currentStyle,o={left:parseInt(i.paddingLeft),right:parseInt(i.paddingRight)};return isNaN(o.left)||isNaN(o.right)||(e.cachedPaddingH=o),o}function zt(e){return Rl-e.display.nativeBarWidth}function Rt(e){return e.display.scroller.clientWidth-zt(e)-e.display.barWidth}function Bt(e){return e.display.scroller.clientHeight-zt(e)-e.display.barHeight}function Gt(e,t,r){var n=e.options.lineWrapping,i=n&&Rt(e);if(!t.measure.heights||n&&t.measure.width!=i){var o=t.measure.heights=[];if(n){t.measure.width=i;for(var l=t.text.firstChild.getClientRects(),s=0;s<l.length-1;s++){var a=l[s],u=l[s+1];Math.abs(a.bottom-u.bottom)>2&&o.push((a.bottom+u.top)/2-r.top)}}o.push(r.bottom-r.top)}}function Ut(e,t,r){if(e.line==t)return{map:e.measure.map,cache:e.measure.cache};for(var n=0;n<e.rest.length;n++)if(e.rest[n]==t)return{map:e.measure.maps[n],cache:e.measure.caches[n]};for(var i=0;i<e.rest.length;i++)if(W(e.rest[i])>r)return{map:e.measure.maps[i],cache:e.measure.caches[i],before:!0}}function Vt(e,t){var n=W(t=fe(t)),i=e.display.externalMeasured=new pt(e.doc,t,n);i.lineN=n;var o=i.built=st(e,i);return i.text=o.pre,r(e.display.lineMeasure,o.pre),i}function Kt(e,t,r,n){return Yt(e,Xt(e,t),r,n)}function jt(e,t){if(t>=e.display.viewFrom&&t<e.display.viewTo)return e.display.view[Lr(e,t)];var r=e.display.externalMeasured;return r&&t>=r.lineN&&t<r.lineN+r.size?r:void 0}function Xt(e,t){var r=W(t),n=jt(e,r);n&&!n.text?n=null:n&&n.changes&&(xt(e,n,r,br(e)),e.curOp.forceUpdate=!0),n||(n=Vt(e,t));var i=Ut(n,t,r);return{line:t,view:n,rect:null,map:i.map,cache:i.cache,before:i.before,hasHeights:!1}}function Yt(e,t,r,n,i){t.before&&(r=-1);var o,l=r+(n||"");return t.cache.hasOwnProperty(l)?o=t.cache[l]:(t.rect||(t.rect=t.view.text.getBoundingClientRect()),t.hasHeights||(Gt(e,t.view,t.rect),t.hasHeights=!0),(o=qt(e,t,r,n)).bogus||(t.cache[l]=o)),{left:o.left,right:o.right,top:i?o.rtop:o.top,bottom:i?o.rbottom:o.bottom}}function _t(e,t,r){for(var n,i,o,l,s,a,u=0;u<e.length;u+=3)if(s=e[u],a=e[u+1],t<s?(i=0,o=1,l="left"):t<a?o=(i=t-s)+1:(u==e.length-3||t==a&&e[u+3]>t)&&(i=(o=a-s)-1,t>=a&&(l="right")),null!=i){if(n=e[u+2],s==a&&r==(n.insertLeft?"left":"right")&&(l=r),"left"==r&&0==i)for(;u&&e[u-2]==e[u-3]&&e[u-1].insertLeft;)n=e[2+(u-=3)],l="left";if("right"==r&&i==a-s)for(;u<e.length-3&&e[u+3]==e[u+4]&&!e[u+5].insertLeft;)n=e[(u+=3)+2],l="right";break}return{node:n,start:i,end:o,collapse:l,coverStart:s,coverEnd:a}}function $t(e,t){var r=ms;if("left"==t)for(var n=0;n<e.length&&(r=e[n]).left==r.right;n++);else for(var i=e.length-1;i>=0&&(r=e[i]).left==r.right;i--);return r}function qt(e,t,r,n){var i,o=_t(t.map,r,n),l=o.node,s=o.start,a=o.end,u=o.collapse;if(3==l.nodeType){for(var c=0;c<4;c++){for(;s&&S(t.line.text.charAt(o.coverStart+s));)--s;for(;o.coverStart+a<o.coverEnd&&S(t.line.text.charAt(o.coverStart+a));)++a;if((i=gl&&vl<9&&0==s&&a==o.coverEnd-o.coverStart?l.parentNode.getBoundingClientRect():$t(Wl(l,s,a).getClientRects(),n)).left||i.right||0==s)break;a=s,s-=1,u="right"}gl&&vl<11&&(i=Zt(e.display.measure,i))}else{s>0&&(u=n="right");var f;i=e.options.lineWrapping&&(f=l.getClientRects()).length>1?f["right"==n?f.length-1:0]:l.getBoundingClientRect()}if(gl&&vl<9&&!s&&(!i||!i.left&&!i.right)){var h=l.parentNode.getClientRects()[0];i=h?{left:h.left,right:h.left+yr(e.display),top:h.top,bottom:h.bottom}:ms}for(var d=i.top-t.rect.top,p=i.bottom-t.rect.top,g=(d+p)/2,v=t.view.measure.heights,m=0;m<v.length-1&&!(g<v[m]);m++);var y=m?v[m-1]:0,b=v[m],w={left:("right"==u?i.right:i.left)-t.rect.left,right:("left"==u?i.left:i.right)-t.rect.left,top:y,bottom:b};return i.left||i.right||(w.bogus=!0),e.options.singleCursorHeightPerLine||(w.rtop=d,w.rbottom=p),w}function Zt(e,t){if(!window.screen||null==screen.logicalXDPI||screen.logicalXDPI==screen.deviceXDPI||!Re(e))return t;var r=screen.logicalXDPI/screen.deviceXDPI,n=screen.logicalYDPI/screen.deviceYDPI;return{left:t.left*r,right:t.right*r,top:t.top*n,bottom:t.bottom*n}}function Qt(e){if(e.measure&&(e.measure.cache={},e.measure.heights=null,e.rest))for(var t=0;t<e.rest.length;t++)e.measure.caches[t]={}}function Jt(e){e.display.externalMeasure=null,t(e.display.lineMeasure);for(var r=0;r<e.display.view.length;r++)Qt(e.display.view[r])}function er(e){Jt(e),e.display.cachedCharWidth=e.display.cachedTextHeight=e.display.cachedPaddingH=null,e.options.lineWrapping||(e.display.maxLineChanged=!0),e.display.lineNumChars=null}function tr(){return bl&&kl?-(document.body.getBoundingClientRect().left-parseInt(getComputedStyle(document.body).marginLeft)):window.pageXOffset||(document.documentElement||document.body).scrollLeft}function rr(){return bl&&kl?-(document.body.getBoundingClientRect().top-parseInt(getComputedStyle(document.body).marginTop)):window.pageYOffset||(document.documentElement||document.body).scrollTop}function nr(e){var t=0;if(e.widgets)for(var r=0;r<e.widgets.length;++r)e.widgets[r].above&&(t+=Ht(e.widgets[r]));return t}function ir(e,t,r,n,i){if(!i){var o=nr(t);r.top+=o,r.bottom+=o}if("line"==n)return r;n||(n="local");var l=ye(t);if("local"==n?l+=Et(e.display):l-=e.display.viewOffset,"page"==n||"window"==n){var s=e.display.lineSpace.getBoundingClientRect();l+=s.top+("window"==n?0:rr());var a=s.left+("window"==n?0:tr());r.left+=a,r.right+=a}return r.top+=l,r.bottom+=l,r}function or(e,t,r){if("div"==r)return t;var n=t.left,i=t.top;if("page"==r)n-=tr(),i-=rr();else if("local"==r||!r){var o=e.display.sizer.getBoundingClientRect();n+=o.left,i+=o.top}var l=e.display.lineSpace.getBoundingClientRect();return{left:n-l.left,top:i-l.top}}function lr(e,t,r,n,i){return n||(n=M(e.doc,t.line)),ir(e,n,Kt(e,n,t.ch,i),r)}function sr(e,t,r,n,i,o){function l(t,l){var s=Yt(e,i,t,l?"right":"left",o);return l?s.left=s.right:s.right=s.left,ir(e,n,s,r)}function s(e,t,r){var n=1==a[t].level;return l(r?e-1:e,n!=r)}n=n||M(e.doc,t.line),i||(i=Xt(e,n));var a=Se(n,e.doc.direction),u=t.ch,c=t.sticky;if(u>=n.text.length?(u=n.text.length,c="before"):u<=0&&(u=0,c="after"),!a)return l("before"==c?u-1:u,"before"==c);var f=Ce(a,u,c),h=$l,d=s(u,f,"before"==c);return null!=h&&(d.other=s(u,h,"before"!=c)),d}function ar(e,t){var r=0;t=U(e.doc,t),e.options.lineWrapping||(r=yr(e.display)*t.ch);var n=M(e.doc,t.line),i=ye(n)+Et(e.display);return{left:r,right:r,top:i,bottom:i+n.height}}function ur(e,t,r,n,i){var o=E(e,t,r);return o.xRel=i,n&&(o.outside=!0),o}function cr(e,t,r){var n=e.doc;if((r+=e.display.viewOffset)<0)return ur(n.first,0,null,!0,-1);var i=D(n,r),o=n.first+n.size-1;if(i>o)return ur(n.first+n.size-1,M(n,o).text.length,null,!0,1);t<0&&(t=0);for(var l=M(n,i);;){var s=pr(e,l,i,t,r),a=ue(l),u=a&&a.find(0,!0);if(!a||!(s.ch>u.from.ch||s.ch==u.from.ch&&s.xRel>0))return s;i=W(l=u.to.line)}}function fr(e,t,r,n){n-=nr(t);var i=t.text.length,o=k(function(t){return Yt(e,r,t-1).bottom<=n},i,0);return i=k(function(t){return Yt(e,r,t).top>n},o,i),{begin:o,end:i}}function hr(e,t,r,n){return r||(r=Xt(e,t)),fr(e,t,r,ir(e,t,Yt(e,r,n),"line").top)}function dr(e,t,r,n){return!(e.bottom<=r)&&(e.top>r||(n?e.left:e.right)>t)}function pr(e,t,r,n,i){i-=ye(t);var o=Xt(e,t),l=nr(t),s=0,a=t.text.length,u=!0,c=Se(t,e.doc.direction);if(c){var f=(e.options.lineWrapping?vr:gr)(e,t,r,o,c,n,i);s=(u=1!=f.level)?f.from:f.to-1,a=u?f.to:f.from-1}var h,d,p=null,g=null,v=k(function(t){var r=Yt(e,o,t);return r.top+=l,r.bottom+=l,!!dr(r,n,i,!1)&&(r.top<=i&&r.left<=n&&(p=t,g=r),!0)},s,a),m=!1;if(g){var y=n-g.left<g.right-n,b=y==u;v=p+(b?0:1),d=b?"after":"before",h=y?g.left:g.right}else{u||v!=a&&v!=s||v++,d=0==v?"after":v==t.text.length?"before":Yt(e,o,v-(u?1:0)).bottom+l<=i==u?"after":"before";var w=sr(e,E(r,v,d),"line",t,o);h=w.left,m=i<w.top||i>=w.bottom}return v=L(t.text,v,1),ur(r,v,d,m,n-h)}function gr(e,t,r,n,i,o,l){var s=k(function(s){var a=i[s],u=1!=a.level;return dr(sr(e,E(r,u?a.to:a.from,u?"before":"after"),"line",t,n),o,l,!0)},0,i.length-1),a=i[s];if(s>0){var u=1!=a.level,c=sr(e,E(r,u?a.from:a.to,u?"after":"before"),"line",t,n);dr(c,o,l,!0)&&c.top>l&&(a=i[s-1])}return a}function vr(e,t,r,n,i,o,l){for(var s=fr(e,t,n,l),a=s.begin,u=s.end,c=null,f=null,h=0;h<i.length;h++){var d=i[h];if(!(d.from>=u||d.to<=a)){var p=Yt(e,n,1!=d.level?Math.min(u,d.to)-1:Math.max(a,d.from)).right,g=p<o?o-p+1e9:p-o;(!c||f>g)&&(c=d,f=g)}}return c||(c=i[i.length-1]),c.from<a&&(c={from:a,to:c.to,level:c.level}),c.to>u&&(c={from:c.from,to:u,level:c.level}),c}function mr(e){if(null!=e.cachedTextHeight)return e.cachedTextHeight;if(null==hs){hs=n("pre");for(var i=0;i<49;++i)hs.appendChild(document.createTextNode("x")),hs.appendChild(n("br"));hs.appendChild(document.createTextNode("x"))}r(e.measure,hs);var o=hs.offsetHeight/50;return o>3&&(e.cachedTextHeight=o),t(e.measure),o||1}function yr(e){if(null!=e.cachedCharWidth)return e.cachedCharWidth;var t=n("span","xxxxxxxxxx"),i=n("pre",[t]);r(e.measure,i);var o=t.getBoundingClientRect(),l=(o.right-o.left)/10;return l>2&&(e.cachedCharWidth=l),l||10}function br(e){for(var t=e.display,r={},n={},i=t.gutters.clientLeft,o=t.gutters.firstChild,l=0;o;o=o.nextSibling,++l)r[e.options.gutters[l]]=o.offsetLeft+o.clientLeft+i,n[e.options.gutters[l]]=o.clientWidth;return{fixedPos:wr(t),gutterTotalWidth:t.gutters.offsetWidth,gutterLeft:r,gutterWidth:n,wrapperWidth:t.wrapper.clientWidth}}function wr(e){return e.scroller.getBoundingClientRect().left-e.sizer.getBoundingClientRect().left}function xr(e){var t=mr(e.display),r=e.options.lineWrapping,n=r&&Math.max(5,e.display.scroller.clientWidth/yr(e.display)-3);return function(i){if(ve(e.doc,i))return 0;var o=0;if(i.widgets)for(var l=0;l<i.widgets.length;l++)i.widgets[l].height&&(o+=i.widgets[l].height);return r?o+(Math.ceil(i.text.length/n)||1)*t:o+t}}function Cr(e){var t=e.doc,r=xr(e);t.iter(function(e){var t=r(e);t!=e.height&&A(e,t)})}function Sr(e,t,r,n){var i=e.display;if(!r&&"true"==Ee(t).getAttribute("cm-not-content"))return null;var o,l,s=i.lineSpace.getBoundingClientRect();try{o=t.clientX-s.left,l=t.clientY-s.top}catch(t){return null}var a,u=cr(e,o,l);if(n&&1==u.xRel&&(a=M(e.doc,u.line).text).length==u.ch){var c=f(a,a.length,e.options.tabSize)-a.length;u=E(u.line,Math.max(0,Math.round((o-It(e.display).left)/yr(e.display))-c))}return u}function Lr(e,t){if(t>=e.display.viewTo)return null;if((t-=e.display.viewFrom)<0)return null;for(var r=e.display.view,n=0;n<r.length;n++)if((t-=r[n].size)<0)return n}function kr(e){e.display.input.showSelection(e.display.input.prepareSelection())}function Tr(e,t){void 0===t&&(t=!0);for(var r=e.doc,n={},i=n.cursors=document.createDocumentFragment(),o=n.selection=document.createDocumentFragment(),l=0;l<r.sel.ranges.length;l++)if(t||l!=r.sel.primIndex){var s=r.sel.ranges[l];if(!(s.from().line>=e.display.viewTo||s.to().line<e.display.viewFrom)){var a=s.empty();(a||e.options.showCursorWhenSelecting)&&Mr(e,s.head,i),a||Or(e,s,o)}}return n}function Mr(e,t,r){var i=sr(e,t,"div",null,null,!e.options.singleCursorHeightPerLine),o=r.appendChild(n("div"," ","CodeMirror-cursor"));if(o.style.left=i.left+"px",o.style.top=i.top+"px",o.style.height=Math.max(0,i.bottom-i.top)*e.options.cursorHeight+"px",i.other){var l=r.appendChild(n("div"," ","CodeMirror-cursor CodeMirror-secondarycursor"));l.style.display="",l.style.left=i.other.left+"px",l.style.top=i.other.top+"px",l.style.height=.85*(i.other.bottom-i.other.top)+"px"}}function Nr(e,t){return e.top-t.top||e.left-t.left}function Or(e,t,r){function i(e,t,r,i){t<0&&(t=0),t=Math.round(t),i=Math.round(i),a.appendChild(n("div",null,"CodeMirror-selected","position: absolute; left: "+e+"px;\n                             top: "+t+"px; width: "+(null==r?f-e:r)+"px;\n                             height: "+(i-t)+"px"))}function o(t,r,n){function o(r,n){return lr(e,E(t,r),"div",u,n)}var l,a,u=M(s,t),h=u.text.length,d=Se(u,s.direction);return xe(d,r||0,null==n?h:n,function(t,s,p,g){var v=o(t,"ltr"==p?"left":"right"),m=o(s-1,"ltr"==p?"right":"left");if("ltr"==p){var y=null==r&&0==t?c:v.left,b=null==n&&s==h?f:m.right;m.top-v.top<=3?i(y,m.top,b-y,m.bottom):(i(y,v.top,null,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top),i(c,m.top,m.right,m.bottom))}else if(t<s){var w=null==r&&0==t?f:v.right,x=null==n&&s==h?c:m.left;if(m.top-v.top<=3)i(x,m.top,w-x,m.bottom);else{var C=c;if(g){var S=hr(e,u,null,t).end;C=o(S-(/\s/.test(u.text.charAt(S-1))?2:1),"left").left}i(C,v.top,w-C,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top);var L=null;d.length,L=o(hr(e,u,null,s).begin,"right").right-x,i(x,m.top,L,m.bottom)}}(!l||Nr(v,l)<0)&&(l=v),Nr(m,l)<0&&(l=m),(!a||Nr(v,a)<0)&&(a=v),Nr(m,a)<0&&(a=m)}),{start:l,end:a}}var l=e.display,s=e.doc,a=document.createDocumentFragment(),u=It(e.display),c=u.left,f=Math.max(l.sizerWidth,Rt(e)-l.sizer.offsetLeft)-u.right,h=t.from(),d=t.to();if(h.line==d.line)o(h.line,h.ch,d.ch);else{var p=M(s,h.line),g=M(s,d.line),v=fe(p)==fe(g),m=o(h.line,h.ch,v?p.text.length+1:null).end,y=o(d.line,v?0:null,d.ch).start;v&&(m.top<y.top-2?(i(m.right,m.top,null,m.bottom),i(c,y.top,y.left,y.bottom)):i(m.right,m.top,y.left-m.right,m.bottom)),m.bottom<y.top&&i(c,m.bottom,null,y.top)}r.appendChild(a)}function Ar(e){if(e.state.focused){var t=e.display;clearInterval(t.blinker);var r=!0;t.cursorDiv.style.visibility="",e.options.cursorBlinkRate>0?t.blinker=setInterval(function(){return t.cursorDiv.style.visibility=(r=!r)?"":"hidden"},e.options.cursorBlinkRate):e.options.cursorBlinkRate<0&&(t.cursorDiv.style.visibility="hidden")}}function Wr(e){e.state.focused||(e.display.input.focus(),Hr(e))}function Dr(e){e.state.delayingBlurEvent=!0,setTimeout(function(){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1,Fr(e))},100)}function Hr(e,t){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1),"nocursor"!=e.options.readOnly&&(e.state.focused||(Te(e,"focus",e,t),e.state.focused=!0,s(e.display.wrapper,"CodeMirror-focused"),e.curOp||e.display.selForContextMenu==e.doc.sel||(e.display.input.reset(),ml&&setTimeout(function(){return e.display.input.reset(!0)},20)),e.display.input.receivedFocus()),Ar(e))}function Fr(e,t){e.state.delayingBlurEvent||(e.state.focused&&(Te(e,"blur",e,t),e.state.focused=!1,Fl(e.display.wrapper,"CodeMirror-focused")),clearInterval(e.display.blinker),setTimeout(function(){e.state.focused||(e.display.shift=!1)},150))}function Er(e){for(var t=e.display,r=t.lineDiv.offsetTop,n=0;n<t.view.length;n++){var i=t.view[n],o=void 0;if(!i.hidden){if(gl&&vl<8){var l=i.node.offsetTop+i.node.offsetHeight;o=l-r,r=l}else{var s=i.node.getBoundingClientRect();o=s.bottom-s.top}var a=i.line.height-o;if(o<2&&(o=mr(t)),(a>.005||a<-.005)&&(A(i.line,o),Pr(i.line),i.rest))for(var u=0;u<i.rest.length;u++)Pr(i.rest[u])}}}function Pr(e){if(e.widgets)for(var t=0;t<e.widgets.length;++t)e.widgets[t].height=e.widgets[t].node.parentNode.offsetHeight}function Ir(e,t,r){var n=r&&null!=r.top?Math.max(0,r.top):e.scroller.scrollTop;n=Math.floor(n-Et(e));var i=r&&null!=r.bottom?r.bottom:n+e.wrapper.clientHeight,o=D(t,n),l=D(t,i);if(r&&r.ensure){var s=r.ensure.from.line,a=r.ensure.to.line;s<o?(o=s,l=D(t,ye(M(t,s))+e.wrapper.clientHeight)):Math.min(a,t.lastLine())>=l&&(o=D(t,ye(M(t,a))-e.wrapper.clientHeight),l=a)}return{from:o,to:Math.max(l,o+1)}}function zr(e){var t=e.display,r=t.view;if(t.alignWidgets||t.gutters.firstChild&&e.options.fixedGutter){for(var n=wr(t)-t.scroller.scrollLeft+e.doc.scrollLeft,i=t.gutters.offsetWidth,o=n+"px",l=0;l<r.length;l++)if(!r[l].hidden){e.options.fixedGutter&&(r[l].gutter&&(r[l].gutter.style.left=o),r[l].gutterBackground&&(r[l].gutterBackground.style.left=o));var s=r[l].alignable;if(s)for(var a=0;a<s.length;a++)s[a].style.left=o}e.options.fixedGutter&&(t.gutters.style.left=n+i+"px")}}function Rr(e){if(!e.options.lineNumbers)return!1;var t=e.doc,r=F(e.options,t.first+t.size-1),i=e.display;if(r.length!=i.lineNumChars){var o=i.measure.appendChild(n("div",[n("div",r)],"CodeMirror-linenumber CodeMirror-gutter-elt")),l=o.firstChild.offsetWidth,s=o.offsetWidth-l;return i.lineGutter.style.width="",i.lineNumInnerWidth=Math.max(l,i.lineGutter.offsetWidth-s)+1,i.lineNumWidth=i.lineNumInnerWidth+s,i.lineNumChars=i.lineNumInnerWidth?r.length:-1,i.lineGutter.style.width=i.lineNumWidth+"px",Wn(e),!0}return!1}function Br(e,t){if(!Me(e,"scrollCursorIntoView")){var r=e.display,i=r.sizer.getBoundingClientRect(),o=null;if(t.top+i.top<0?o=!0:t.bottom+i.top>(window.innerHeight||document.documentElement.clientHeight)&&(o=!1),null!=o&&!Sl){var l=n("div","​",null,"position: absolute;\n                         top: "+(t.top-r.viewOffset-Et(e.display))+"px;\n                         height: "+(t.bottom-t.top+zt(e)+r.barHeight)+"px;\n                         left: "+t.left+"px; width: "+Math.max(2,t.right-t.left)+"px;");e.display.lineSpace.appendChild(l),l.scrollIntoView(o),e.display.lineSpace.removeChild(l)}}}function Gr(e,t,r,n){null==n&&(n=0);var i;e.options.lineWrapping||t!=r||(r="before"==(t=t.ch?E(t.line,"before"==t.sticky?t.ch-1:t.ch,"after"):t).sticky?E(t.line,t.ch+1,"before"):t);for(var o=0;o<5;o++){var l=!1,s=sr(e,t),a=r&&r!=t?sr(e,r):s,u=Vr(e,i={left:Math.min(s.left,a.left),top:Math.min(s.top,a.top)-n,right:Math.max(s.left,a.left),bottom:Math.max(s.bottom,a.bottom)+n}),c=e.doc.scrollTop,f=e.doc.scrollLeft;if(null!=u.scrollTop&&(qr(e,u.scrollTop),Math.abs(e.doc.scrollTop-c)>1&&(l=!0)),null!=u.scrollLeft&&(Qr(e,u.scrollLeft),Math.abs(e.doc.scrollLeft-f)>1&&(l=!0)),!l)break}return i}function Ur(e,t){var r=Vr(e,t);null!=r.scrollTop&&qr(e,r.scrollTop),null!=r.scrollLeft&&Qr(e,r.scrollLeft)}function Vr(e,t){var r=e.display,n=mr(e.display);t.top<0&&(t.top=0);var i=e.curOp&&null!=e.curOp.scrollTop?e.curOp.scrollTop:r.scroller.scrollTop,o=Bt(e),l={};t.bottom-t.top>o&&(t.bottom=t.top+o);var s=e.doc.height+Pt(r),a=t.top<n,u=t.bottom>s-n;if(t.top<i)l.scrollTop=a?0:t.top;else if(t.bottom>i+o){var c=Math.min(t.top,(u?s:t.bottom)-o);c!=i&&(l.scrollTop=c)}var f=e.curOp&&null!=e.curOp.scrollLeft?e.curOp.scrollLeft:r.scroller.scrollLeft,h=Rt(e)-(e.options.fixedGutter?r.gutters.offsetWidth:0),d=t.right-t.left>h;return d&&(t.right=t.left+h),t.left<10?l.scrollLeft=0:t.left<f?l.scrollLeft=Math.max(0,t.left-(d?0:10)):t.right>h+f-3&&(l.scrollLeft=t.right+(d?0:10)-h),l}function Kr(e,t){null!=t&&(_r(e),e.curOp.scrollTop=(null==e.curOp.scrollTop?e.doc.scrollTop:e.curOp.scrollTop)+t)}function jr(e){_r(e);var t=e.getCursor();e.curOp.scrollToPos={from:t,to:t,margin:e.options.cursorScrollMargin}}function Xr(e,t,r){null==t&&null==r||_r(e),null!=t&&(e.curOp.scrollLeft=t),null!=r&&(e.curOp.scrollTop=r)}function Yr(e,t){_r(e),e.curOp.scrollToPos=t}function _r(e){var t=e.curOp.scrollToPos;t&&(e.curOp.scrollToPos=null,$r(e,ar(e,t.from),ar(e,t.to),t.margin))}function $r(e,t,r,n){var i=Vr(e,{left:Math.min(t.left,r.left),top:Math.min(t.top,r.top)-n,right:Math.max(t.right,r.right),bottom:Math.max(t.bottom,r.bottom)+n});Xr(e,i.scrollLeft,i.scrollTop)}function qr(e,t){Math.abs(e.doc.scrollTop-t)<2||(fl||On(e,{top:t}),Zr(e,t,!0),fl&&On(e),Cn(e,100))}function Zr(e,t,r){t=Math.min(e.display.scroller.scrollHeight-e.display.scroller.clientHeight,t),(e.display.scroller.scrollTop!=t||r)&&(e.doc.scrollTop=t,e.display.scrollbars.setScrollTop(t),e.display.scroller.scrollTop!=t&&(e.display.scroller.scrollTop=t))}function Qr(e,t,r,n){t=Math.min(t,e.display.scroller.scrollWidth-e.display.scroller.clientWidth),(r?t==e.doc.scrollLeft:Math.abs(e.doc.scrollLeft-t)<2)&&!n||(e.doc.scrollLeft=t,zr(e),e.display.scroller.scrollLeft!=t&&(e.display.scroller.scrollLeft=t),e.display.scrollbars.setScrollLeft(t))}function Jr(e){var t=e.display,r=t.gutters.offsetWidth,n=Math.round(e.doc.height+Pt(e.display));return{clientHeight:t.scroller.clientHeight,viewHeight:t.wrapper.clientHeight,scrollWidth:t.scroller.scrollWidth,clientWidth:t.scroller.clientWidth,viewWidth:t.wrapper.clientWidth,barLeft:e.options.fixedGutter?r:0,docHeight:n,scrollHeight:n+zt(e)+t.barHeight,nativeBarWidth:t.nativeBarWidth,gutterWidth:r}}function en(e,t){t||(t=Jr(e));var r=e.display.barWidth,n=e.display.barHeight;tn(e,t);for(var i=0;i<4&&r!=e.display.barWidth||n!=e.display.barHeight;i++)r!=e.display.barWidth&&e.options.lineWrapping&&Er(e),tn(e,Jr(e)),r=e.display.barWidth,n=e.display.barHeight}function tn(e,t){var r=e.display,n=r.scrollbars.update(t);r.sizer.style.paddingRight=(r.barWidth=n.right)+"px",r.sizer.style.paddingBottom=(r.barHeight=n.bottom)+"px",r.heightForcer.style.borderBottom=n.bottom+"px solid transparent",n.right&&n.bottom?(r.scrollbarFiller.style.display="block",r.scrollbarFiller.style.height=n.bottom+"px",r.scrollbarFiller.style.width=n.right+"px"):r.scrollbarFiller.style.display="",n.bottom&&e.options.coverGutterNextToScrollbar&&e.options.fixedGutter?(r.gutterFiller.style.display="block",r.gutterFiller.style.height=n.bottom+"px",r.gutterFiller.style.width=t.gutterWidth+"px"):r.gutterFiller.style.display=""}function rn(e){e.display.scrollbars&&(e.display.scrollbars.clear(),e.display.scrollbars.addClass&&Fl(e.display.wrapper,e.display.scrollbars.addClass)),e.display.scrollbars=new ws[e.options.scrollbarStyle](function(t){e.display.wrapper.insertBefore(t,e.display.scrollbarFiller),Ql(t,"mousedown",function(){e.state.focused&&setTimeout(function(){return e.display.input.focus()},0)}),t.setAttribute("cm-not-content","true")},function(t,r){"horizontal"==r?Qr(e,t):qr(e,t)},e),e.display.scrollbars.addClass&&s(e.display.wrapper,e.display.scrollbars.addClass)}function nn(e){e.curOp={cm:e,viewChanged:!1,startHeight:e.doc.height,forceUpdate:!1,updateInput:null,typing:!1,changeObjs:null,cursorActivityHandlers:null,cursorActivityCalled:0,selectionChanged:!1,updateMaxLine:!1,scrollLeft:null,scrollTop:null,scrollToPos:null,focus:!1,id:++xs},vt(e.curOp)}function on(e){yt(e.curOp,function(e){for(var t=0;t<e.ops.length;t++)e.ops[t].cm.curOp=null;ln(e)})}function ln(e){for(var t=e.ops,r=0;r<t.length;r++)sn(t[r]);for(var n=0;n<t.length;n++)an(t[n]);for(var i=0;i<t.length;i++)un(t[i]);for(var o=0;o<t.length;o++)cn(t[o]);for(var l=0;l<t.length;l++)fn(t[l])}function sn(e){var t=e.cm,r=t.display;Ln(t),e.updateMaxLine&&we(t),e.mustUpdate=e.viewChanged||e.forceUpdate||null!=e.scrollTop||e.scrollToPos&&(e.scrollToPos.from.line<r.viewFrom||e.scrollToPos.to.line>=r.viewTo)||r.maxLineChanged&&t.options.lineWrapping,e.update=e.mustUpdate&&new Cs(t,e.mustUpdate&&{top:e.scrollTop,ensure:e.scrollToPos},e.forceUpdate)}function an(e){e.updatedDisplay=e.mustUpdate&&Mn(e.cm,e.update)}function un(e){var t=e.cm,r=t.display;e.updatedDisplay&&Er(t),e.barMeasure=Jr(t),r.maxLineChanged&&!t.options.lineWrapping&&(e.adjustWidthTo=Kt(t,r.maxLine,r.maxLine.text.length).left+3,t.display.sizerWidth=e.adjustWidthTo,e.barMeasure.scrollWidth=Math.max(r.scroller.clientWidth,r.sizer.offsetLeft+e.adjustWidthTo+zt(t)+t.display.barWidth),e.maxScrollLeft=Math.max(0,r.sizer.offsetLeft+e.adjustWidthTo-Rt(t))),(e.updatedDisplay||e.selectionChanged)&&(e.preparedSelection=r.input.prepareSelection())}function cn(e){var t=e.cm;null!=e.adjustWidthTo&&(t.display.sizer.style.minWidth=e.adjustWidthTo+"px",e.maxScrollLeft<t.doc.scrollLeft&&Qr(t,Math.min(t.display.scroller.scrollLeft,e.maxScrollLeft),!0),t.display.maxLineChanged=!1);var r=e.focus&&e.focus==l();e.preparedSelection&&t.display.input.showSelection(e.preparedSelection,r),(e.updatedDisplay||e.startHeight!=t.doc.height)&&en(t,e.barMeasure),e.updatedDisplay&&Dn(t,e.barMeasure),e.selectionChanged&&Ar(t),t.state.focused&&e.updateInput&&t.display.input.reset(e.typing),r&&Wr(e.cm)}function fn(e){var t=e.cm,r=t.display,n=t.doc;e.updatedDisplay&&Nn(t,e.update),null==r.wheelStartX||null==e.scrollTop&&null==e.scrollLeft&&!e.scrollToPos||(r.wheelStartX=r.wheelStartY=null),null!=e.scrollTop&&Zr(t,e.scrollTop,e.forceScroll),null!=e.scrollLeft&&Qr(t,e.scrollLeft,!0,!0),e.scrollToPos&&Br(t,Gr(t,U(n,e.scrollToPos.from),U(n,e.scrollToPos.to),e.scrollToPos.margin));var i=e.maybeHiddenMarkers,o=e.maybeUnhiddenMarkers;if(i)for(var l=0;l<i.length;++l)i[l].lines.length||Te(i[l],"hide");if(o)for(var s=0;s<o.length;++s)o[s].lines.length&&Te(o[s],"unhide");r.wrapper.offsetHeight&&(n.scrollTop=t.display.scroller.scrollTop),e.changeObjs&&Te(t,"changes",t,e.changeObjs),e.update&&e.update.finish()}function hn(e,t){if(e.curOp)return t();nn(e);try{return t()}finally{on(e)}}function dn(e,t){return function(){if(e.curOp)return t.apply(e,arguments);nn(e);try{return t.apply(e,arguments)}finally{on(e)}}}function pn(e){return function(){if(this.curOp)return e.apply(this,arguments);nn(this);try{return e.apply(this,arguments)}finally{on(this)}}}function gn(e){return function(){var t=this.cm;if(!t||t.curOp)return e.apply(this,arguments);nn(t);try{return e.apply(this,arguments)}finally{on(t)}}}function vn(e,t,r,n){null==t&&(t=e.doc.first),null==r&&(r=e.doc.first+e.doc.size),n||(n=0);var i=e.display;if(n&&r<i.viewTo&&(null==i.updateLineNumbers||i.updateLineNumbers>t)&&(i.updateLineNumbers=t),e.curOp.viewChanged=!0,t>=i.viewTo)_l&&pe(e.doc,t)<i.viewTo&&yn(e);else if(r<=i.viewFrom)_l&&ge(e.doc,r+n)>i.viewFrom?yn(e):(i.viewFrom+=n,i.viewTo+=n);else if(t<=i.viewFrom&&r>=i.viewTo)yn(e);else if(t<=i.viewFrom){var o=bn(e,r,r+n,1);o?(i.view=i.view.slice(o.index),i.viewFrom=o.lineN,i.viewTo+=n):yn(e)}else if(r>=i.viewTo){var l=bn(e,t,t,-1);l?(i.view=i.view.slice(0,l.index),i.viewTo=l.lineN):yn(e)}else{var s=bn(e,t,t,-1),a=bn(e,r,r+n,1);s&&a?(i.view=i.view.slice(0,s.index).concat(gt(e,s.lineN,a.lineN)).concat(i.view.slice(a.index)),i.viewTo+=n):yn(e)}var u=i.externalMeasured;u&&(r<u.lineN?u.lineN+=n:t<u.lineN+u.size&&(i.externalMeasured=null))}function mn(e,t,r){e.curOp.viewChanged=!0;var n=e.display,i=e.display.externalMeasured;if(i&&t>=i.lineN&&t<i.lineN+i.size&&(n.externalMeasured=null),!(t<n.viewFrom||t>=n.viewTo)){var o=n.view[Lr(e,t)];if(null!=o.node){var l=o.changes||(o.changes=[]);-1==h(l,r)&&l.push(r)}}}function yn(e){e.display.viewFrom=e.display.viewTo=e.doc.first,e.display.view=[],e.display.viewOffset=0}function bn(e,t,r,n){var i,o=Lr(e,t),l=e.display.view;if(!_l||r==e.doc.first+e.doc.size)return{index:o,lineN:r};for(var s=e.display.viewFrom,a=0;a<o;a++)s+=l[a].size;if(s!=t){if(n>0){if(o==l.length-1)return null;i=s+l[o].size-t,o++}else i=s-t;t+=i,r+=i}for(;pe(e.doc,r)!=r;){if(o==(n<0?0:l.length-1))return null;r+=n*l[o-(n<0?1:0)].size,o+=n}return{index:o,lineN:r}}function wn(e,t,r){var n=e.display;0==n.view.length||t>=n.viewTo||r<=n.viewFrom?(n.view=gt(e,t,r),n.viewFrom=t):(n.viewFrom>t?n.view=gt(e,t,n.viewFrom).concat(n.view):n.viewFrom<t&&(n.view=n.view.slice(Lr(e,t))),n.viewFrom=t,n.viewTo<r?n.view=n.view.concat(gt(e,n.viewTo,r)):n.viewTo>r&&(n.view=n.view.slice(0,Lr(e,r)))),n.viewTo=r}function xn(e){for(var t=e.display.view,r=0,n=0;n<t.length;n++){var i=t[n];i.hidden||i.node&&!i.changes||++r}return r}function Cn(e,t){e.doc.highlightFrontier<e.display.viewTo&&e.state.highlight.set(t,u(Sn,e))}function Sn(e){var t=e.doc;if(!(t.highlightFrontier>=e.display.viewTo)){var r=+new Date+e.options.workTime,n=$e(e,t.highlightFrontier),i=[];t.iter(n.line,Math.min(t.first+t.size,e.display.viewTo+500),function(o){if(n.line>=e.display.viewFrom){var l=o.styles,s=o.text.length>e.options.maxHighlightLength?Ke(t.mode,n.state):null,a=Ye(e,o,n,!0);s&&(n.state=s),o.styles=a.styles;var u=o.styleClasses,c=a.classes;c?o.styleClasses=c:u&&(o.styleClasses=null);for(var f=!l||l.length!=o.styles.length||u!=c&&(!u||!c||u.bgClass!=c.bgClass||u.textClass!=c.textClass),h=0;!f&&h<l.length;++h)f=l[h]!=o.styles[h];f&&i.push(n.line),o.stateAfter=n.save(),n.nextLine()}else o.text.length<=e.options.maxHighlightLength&&qe(e,o.text,n),o.stateAfter=n.line%5==0?n.save():null,n.nextLine();if(+new Date>r)return Cn(e,e.options.workDelay),!0}),t.highlightFrontier=n.line,t.modeFrontier=Math.max(t.modeFrontier,n.line),i.length&&hn(e,function(){for(var t=0;t<i.length;t++)mn(e,i[t],"text")})}}function Ln(e){var t=e.display;!t.scrollbarsClipped&&t.scroller.offsetWidth&&(t.nativeBarWidth=t.scroller.offsetWidth-t.scroller.clientWidth,t.heightForcer.style.height=zt(e)+"px",t.sizer.style.marginBottom=-t.nativeBarWidth+"px",t.sizer.style.borderRightWidth=zt(e)+"px",t.scrollbarsClipped=!0)}function kn(e){if(e.hasFocus())return null;var t=l();if(!t||!o(e.display.lineDiv,t))return null;var r={activeElt:t};if(window.getSelection){var n=window.getSelection();n.anchorNode&&n.extend&&o(e.display.lineDiv,n.anchorNode)&&(r.anchorNode=n.anchorNode,r.anchorOffset=n.anchorOffset,r.focusNode=n.focusNode,r.focusOffset=n.focusOffset)}return r}function Tn(e){if(e&&e.activeElt&&e.activeElt!=l()&&(e.activeElt.focus(),e.anchorNode&&o(document.body,e.anchorNode)&&o(document.body,e.focusNode))){var t=window.getSelection(),r=document.createRange();r.setEnd(e.anchorNode,e.anchorOffset),r.collapse(!1),t.removeAllRanges(),t.addRange(r),t.extend(e.focusNode,e.focusOffset)}}function Mn(e,r){var n=e.display,i=e.doc;if(r.editorIsHidden)return yn(e),!1;if(!r.force&&r.visible.from>=n.viewFrom&&r.visible.to<=n.viewTo&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo)&&n.renderedView==n.view&&0==xn(e))return!1;Rr(e)&&(yn(e),r.dims=br(e));var o=i.first+i.size,l=Math.max(r.visible.from-e.options.viewportMargin,i.first),s=Math.min(o,r.visible.to+e.options.viewportMargin);n.viewFrom<l&&l-n.viewFrom<20&&(l=Math.max(i.first,n.viewFrom)),n.viewTo>s&&n.viewTo-s<20&&(s=Math.min(o,n.viewTo)),_l&&(l=pe(e.doc,l),s=ge(e.doc,s));var a=l!=n.viewFrom||s!=n.viewTo||n.lastWrapHeight!=r.wrapperHeight||n.lastWrapWidth!=r.wrapperWidth;wn(e,l,s),n.viewOffset=ye(M(e.doc,n.viewFrom)),e.display.mover.style.top=n.viewOffset+"px";var u=xn(e);if(!a&&0==u&&!r.force&&n.renderedView==n.view&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo))return!1;var c=kn(e);return u>4&&(n.lineDiv.style.display="none"),An(e,n.updateLineNumbers,r.dims),u>4&&(n.lineDiv.style.display=""),n.renderedView=n.view,Tn(c),t(n.cursorDiv),t(n.selectionDiv),n.gutters.style.height=n.sizer.style.minHeight=0,a&&(n.lastWrapHeight=r.wrapperHeight,n.lastWrapWidth=r.wrapperWidth,Cn(e,400)),n.updateLineNumbers=null,!0}function Nn(e,t){for(var r=t.viewport,n=!0;(n&&e.options.lineWrapping&&t.oldDisplayWidth!=Rt(e)||(r&&null!=r.top&&(r={top:Math.min(e.doc.height+Pt(e.display)-Bt(e),r.top)}),t.visible=Ir(e.display,e.doc,r),!(t.visible.from>=e.display.viewFrom&&t.visible.to<=e.display.viewTo)))&&Mn(e,t);n=!1){Er(e);var i=Jr(e);kr(e),en(e,i),Dn(e,i),t.force=!1}t.signal(e,"update",e),e.display.viewFrom==e.display.reportedViewFrom&&e.display.viewTo==e.display.reportedViewTo||(t.signal(e,"viewportChange",e,e.display.viewFrom,e.display.viewTo),e.display.reportedViewFrom=e.display.viewFrom,e.display.reportedViewTo=e.display.viewTo)}function On(e,t){var r=new Cs(e,t);if(Mn(e,r)){Er(e),Nn(e,r);var n=Jr(e);kr(e),en(e,n),Dn(e,n),r.finish()}}function An(e,r,n){function i(t){var r=t.nextSibling;return ml&&Ml&&e.display.currentWheelTarget==t?t.style.display="none":t.parentNode.removeChild(t),r}for(var o=e.display,l=e.options.lineNumbers,s=o.lineDiv,a=s.firstChild,u=o.view,c=o.viewFrom,f=0;f<u.length;f++){var d=u[f];if(d.hidden);else if(d.node&&d.node.parentNode==s){for(;a!=d.node;)a=i(a);var p=l&&null!=r&&r<=c&&d.lineNumber;d.changes&&(h(d.changes,"gutter")>-1&&(p=!1),xt(e,d,c,n)),p&&(t(d.lineNumber),d.lineNumber.appendChild(document.createTextNode(F(e.options,c)))),a=d.node.nextSibling}else{var g=Ot(e,d,c,n);s.insertBefore(g,a)}c+=d.size}for(;a;)a=i(a)}function Wn(e){var t=e.display.gutters.offsetWidth;e.display.sizer.style.marginLeft=t+"px"}function Dn(e,t){e.display.sizer.style.minHeight=t.docHeight+"px",e.display.heightForcer.style.top=t.docHeight+"px",e.display.gutters.style.height=t.docHeight+e.display.barHeight+zt(e)+"px"}function Hn(e){var r=e.display.gutters,i=e.options.gutters;t(r);for(var o=0;o<i.length;++o){var l=i[o],s=r.appendChild(n("div",null,"CodeMirror-gutter "+l));"CodeMirror-linenumbers"==l&&(e.display.lineGutter=s,s.style.width=(e.display.lineNumWidth||1)+"px")}r.style.display=o?"":"none",Wn(e)}function Fn(e){var t=h(e.gutters,"CodeMirror-linenumbers");-1==t&&e.lineNumbers?e.gutters=e.gutters.concat(["CodeMirror-linenumbers"]):t>-1&&!e.lineNumbers&&(e.gutters=e.gutters.slice(0),e.gutters.splice(t,1))}function En(e){var t=e.wheelDeltaX,r=e.wheelDeltaY;return null==t&&e.detail&&e.axis==e.HORIZONTAL_AXIS&&(t=e.detail),null==r&&e.detail&&e.axis==e.VERTICAL_AXIS?r=e.detail:null==r&&(r=e.wheelDelta),{x:t,y:r}}function Pn(e){var t=En(e);return t.x*=Ls,t.y*=Ls,t}function In(e,t){var r=En(t),n=r.x,i=r.y,o=e.display,l=o.scroller,s=l.scrollWidth>l.clientWidth,a=l.scrollHeight>l.clientHeight;if(n&&s||i&&a){if(i&&Ml&&ml)e:for(var u=t.target,c=o.view;u!=l;u=u.parentNode)for(var f=0;f<c.length;f++)if(c[f].node==u){e.display.currentWheelTarget=u;break e}if(n&&!fl&&!wl&&null!=Ls)return i&&a&&qr(e,Math.max(0,l.scrollTop+i*Ls)),Qr(e,Math.max(0,l.scrollLeft+n*Ls)),(!i||i&&a)&&We(t),void(o.wheelStartX=null);if(i&&null!=Ls){var h=i*Ls,d=e.doc.scrollTop,p=d+o.wrapper.clientHeight;h<0?d=Math.max(0,d+h-50):p=Math.min(e.doc.height,p+h+50),On(e,{top:d,bottom:p})}Ss<20&&(null==o.wheelStartX?(o.wheelStartX=l.scrollLeft,o.wheelStartY=l.scrollTop,o.wheelDX=n,o.wheelDY=i,setTimeout(function(){if(null!=o.wheelStartX){var e=l.scrollLeft-o.wheelStartX,t=l.scrollTop-o.wheelStartY,r=t&&o.wheelDY&&t/o.wheelDY||e&&o.wheelDX&&e/o.wheelDX;o.wheelStartX=o.wheelStartY=null,r&&(Ls=(Ls*Ss+r)/(Ss+1),++Ss)}},200)):(o.wheelDX+=n,o.wheelDY+=i))}}function zn(e,t){var r=e[t];e.sort(function(e,t){return P(e.from(),t.from())}),t=h(e,r);for(var n=1;n<e.length;n++){var i=e[n],o=e[n-1];if(P(o.to(),i.from())>=0){var l=B(o.from(),i.from()),s=R(o.to(),i.to()),a=o.empty()?i.from()==i.head:o.from()==o.head;n<=t&&--t,e.splice(--n,2,new Ts(a?s:l,a?l:s))}}return new ks(e,t)}function Rn(e,t){return new ks([new Ts(e,t||e)],0)}function Bn(e){return e.text?E(e.from.line+e.text.length-1,g(e.text).length+(1==e.text.length?e.from.ch:0)):e.to}function Gn(e,t){if(P(e,t.from)<0)return e;if(P(e,t.to)<=0)return Bn(t);var r=e.line+t.text.length-(t.to.line-t.from.line)-1,n=e.ch;return e.line==t.to.line&&(n+=Bn(t).ch-t.to.ch),E(r,n)}function Un(e,t){for(var r=[],n=0;n<e.sel.ranges.length;n++){var i=e.sel.ranges[n];r.push(new Ts(Gn(i.anchor,t),Gn(i.head,t)))}return zn(r,e.sel.primIndex)}function Vn(e,t,r){return e.line==t.line?E(r.line,e.ch-t.ch+r.ch):E(r.line+(e.line-t.line),e.ch)}function Kn(e,t,r){for(var n=[],i=E(e.first,0),o=i,l=0;l<t.length;l++){var s=t[l],a=Vn(s.from,i,o),u=Vn(Bn(s),i,o);if(i=s.to,o=u,"around"==r){var c=e.sel.ranges[l],f=P(c.head,c.anchor)<0;n[l]=new Ts(f?u:a,f?a:u)}else n[l]=new Ts(a,a)}return new ks(n,e.sel.primIndex)}function jn(e){e.doc.mode=Ue(e.options,e.doc.modeOption),Xn(e)}function Xn(e){e.doc.iter(function(e){e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null)}),e.doc.modeFrontier=e.doc.highlightFrontier=e.doc.first,Cn(e,100),e.state.modeGen++,e.curOp&&vn(e)}function Yn(e,t){return 0==t.from.ch&&0==t.to.ch&&""==g(t.text)&&(!e.cm||e.cm.options.wholeLineUpdateBefore)}function _n(e,t,r,n){function i(e){return r?r[e]:null}function o(e,r,i){it(e,r,i,n),bt(e,"change",e,t)}function l(e,t){for(var r=[],o=e;o<t;++o)r.push(new fs(u[o],i(o),n));return r}var s=t.from,a=t.to,u=t.text,c=M(e,s.line),f=M(e,a.line),h=g(u),d=i(u.length-1),p=a.line-s.line;if(t.full)e.insert(0,l(0,u.length)),e.remove(u.length,e.size-u.length);else if(Yn(e,t)){var v=l(0,u.length-1);o(f,f.text,d),p&&e.remove(s.line,p),v.length&&e.insert(s.line,v)}else if(c==f)if(1==u.length)o(c,c.text.slice(0,s.ch)+h+c.text.slice(a.ch),d);else{var m=l(1,u.length-1);m.push(new fs(h+c.text.slice(a.ch),d,n)),o(c,c.text.slice(0,s.ch)+u[0],i(0)),e.insert(s.line+1,m)}else if(1==u.length)o(c,c.text.slice(0,s.ch)+u[0]+f.text.slice(a.ch),i(0)),e.remove(s.line+1,p);else{o(c,c.text.slice(0,s.ch)+u[0],i(0)),o(f,h+f.text.slice(a.ch),d);var y=l(1,u.length-1);p>1&&e.remove(s.line+1,p-1),e.insert(s.line+1,y)}bt(e,"change",e,t)}function $n(e,t,r){function n(e,i,o){if(e.linked)for(var l=0;l<e.linked.length;++l){var s=e.linked[l];if(s.doc!=i){var a=o&&s.sharedHist;r&&!a||(t(s.doc,a),n(s.doc,e,a))}}}n(e,null,!0)}function qn(e,t){if(t.cm)throw new Error("This document is already in use.");e.doc=t,t.cm=e,Cr(e),jn(e),Zn(e),e.options.lineWrapping||we(e),e.options.mode=t.modeOption,vn(e)}function Zn(e){("rtl"==e.doc.direction?s:Fl)(e.display.lineDiv,"CodeMirror-rtl")}function Qn(e){hn(e,function(){Zn(e),vn(e)})}function Jn(e){this.done=[],this.undone=[],this.undoDepth=1/0,this.lastModTime=this.lastSelTime=0,this.lastOp=this.lastSelOp=null,this.lastOrigin=this.lastSelOrigin=null,this.generation=this.maxGeneration=e||1}function ei(e,t){var r={from:z(t.from),to:Bn(t),text:N(e,t.from,t.to)};return si(e,r,t.from.line,t.to.line+1),$n(e,function(e){return si(e,r,t.from.line,t.to.line+1)},!0),r}function ti(e){for(;e.length&&g(e).ranges;)e.pop()}function ri(e,t){return t?(ti(e.done),g(e.done)):e.done.length&&!g(e.done).ranges?g(e.done):e.done.length>1&&!e.done[e.done.length-2].ranges?(e.done.pop(),g(e.done)):void 0}function ni(e,t,r,n){var i=e.history;i.undone.length=0;var o,l,s=+new Date;if((i.lastOp==n||i.lastOrigin==t.origin&&t.origin&&("+"==t.origin.charAt(0)&&e.cm&&i.lastModTime>s-e.cm.options.historyEventDelay||"*"==t.origin.charAt(0)))&&(o=ri(i,i.lastOp==n)))l=g(o.changes),0==P(t.from,t.to)&&0==P(t.from,l.to)?l.to=Bn(t):o.changes.push(ei(e,t));else{var a=g(i.done);for(a&&a.ranges||li(e.sel,i.done),o={changes:[ei(e,t)],generation:i.generation},i.done.push(o);i.done.length>i.undoDepth;)i.done.shift(),i.done[0].ranges||i.done.shift()}i.done.push(r),i.generation=++i.maxGeneration,i.lastModTime=i.lastSelTime=s,i.lastOp=i.lastSelOp=n,i.lastOrigin=i.lastSelOrigin=t.origin,l||Te(e,"historyAdded")}function ii(e,t,r,n){var i=t.charAt(0);return"*"==i||"+"==i&&r.ranges.length==n.ranges.length&&r.somethingSelected()==n.somethingSelected()&&new Date-e.history.lastSelTime<=(e.cm?e.cm.options.historyEventDelay:500)}function oi(e,t,r,n){var i=e.history,o=n&&n.origin;r==i.lastSelOp||o&&i.lastSelOrigin==o&&(i.lastModTime==i.lastSelTime&&i.lastOrigin==o||ii(e,o,g(i.done),t))?i.done[i.done.length-1]=t:li(t,i.done),i.lastSelTime=+new Date,i.lastSelOrigin=o,i.lastSelOp=r,n&&!1!==n.clearRedo&&ti(i.undone)}function li(e,t){var r=g(t);r&&r.ranges&&r.equals(e)||t.push(e)}function si(e,t,r,n){var i=t["spans_"+e.id],o=0;e.iter(Math.max(e.first,r),Math.min(e.first+e.size,n),function(r){r.markedSpans&&((i||(i=t["spans_"+e.id]={}))[o]=r.markedSpans),++o})}function ai(e){if(!e)return null;for(var t,r=0;r<e.length;++r)e[r].marker.explicitlyCleared?t||(t=e.slice(0,r)):t&&t.push(e[r]);return t?t.length?t:null:e}function ui(e,t){var r=t["spans_"+e.id];if(!r)return null;for(var n=[],i=0;i<t.text.length;++i)n.push(ai(r[i]));return n}function ci(e,t){var r=ui(e,t),n=J(e,t);if(!r)return n;if(!n)return r;for(var i=0;i<r.length;++i){var o=r[i],l=n[i];if(o&&l)e:for(var s=0;s<l.length;++s){for(var a=l[s],u=0;u<o.length;++u)if(o[u].marker==a.marker)continue e;o.push(a)}else l&&(r[i]=l)}return r}function fi(e,t,r){for(var n=[],i=0;i<e.length;++i){var o=e[i];if(o.ranges)n.push(r?ks.prototype.deepCopy.call(o):o);else{var l=o.changes,s=[];n.push({changes:s});for(var a=0;a<l.length;++a){var u=l[a],c=void 0;if(s.push({from:u.from,to:u.to,text:u.text}),t)for(var f in u)(c=f.match(/^spans_(\d+)$/))&&h(t,Number(c[1]))>-1&&(g(s)[f]=u[f],delete u[f])}}}return n}function hi(e,t,r,n){if(n){var i=e.anchor;if(r){var o=P(t,i)<0;o!=P(r,i)<0?(i=t,t=r):o!=P(t,r)<0&&(t=r)}return new Ts(i,t)}return new Ts(r||t,t)}function di(e,t,r,n,i){null==i&&(i=e.cm&&(e.cm.display.shift||e.extend)),bi(e,new ks([hi(e.sel.primary(),t,r,i)],0),n)}function pi(e,t,r){for(var n=[],i=e.cm&&(e.cm.display.shift||e.extend),o=0;o<e.sel.ranges.length;o++)n[o]=hi(e.sel.ranges[o],t[o],null,i);bi(e,zn(n,e.sel.primIndex),r)}function gi(e,t,r,n){var i=e.sel.ranges.slice(0);i[t]=r,bi(e,zn(i,e.sel.primIndex),n)}function vi(e,t,r,n){bi(e,Rn(t,r),n)}function mi(e,t,r){var n={ranges:t.ranges,update:function(t){var r=this;this.ranges=[];for(var n=0;n<t.length;n++)r.ranges[n]=new Ts(U(e,t[n].anchor),U(e,t[n].head))},origin:r&&r.origin};return Te(e,"beforeSelectionChange",e,n),e.cm&&Te(e.cm,"beforeSelectionChange",e.cm,n),n.ranges!=t.ranges?zn(n.ranges,n.ranges.length-1):t}function yi(e,t,r){var n=e.history.done,i=g(n);i&&i.ranges?(n[n.length-1]=t,wi(e,t,r)):bi(e,t,r)}function bi(e,t,r){wi(e,t,r),oi(e,e.sel,e.cm?e.cm.curOp.id:NaN,r)}function wi(e,t,r){(Oe(e,"beforeSelectionChange")||e.cm&&Oe(e.cm,"beforeSelectionChange"))&&(t=mi(e,t,r)),xi(e,Si(e,t,r&&r.bias||(P(t.primary().head,e.sel.primary().head)<0?-1:1),!0)),r&&!1===r.scroll||!e.cm||jr(e.cm)}function xi(e,t){t.equals(e.sel)||(e.sel=t,e.cm&&(e.cm.curOp.updateInput=e.cm.curOp.selectionChanged=!0,Ne(e.cm)),bt(e,"cursorActivity",e))}function Ci(e){xi(e,Si(e,e.sel,null,!1))}function Si(e,t,r,n){for(var i,o=0;o<t.ranges.length;o++){var l=t.ranges[o],s=t.ranges.length==e.sel.ranges.length&&e.sel.ranges[o],a=ki(e,l.anchor,s&&s.anchor,r,n),u=ki(e,l.head,s&&s.head,r,n);(i||a!=l.anchor||u!=l.head)&&(i||(i=t.ranges.slice(0,o)),i[o]=new Ts(a,u))}return i?zn(i,t.primIndex):t}function Li(e,t,r,n,i){var o=M(e,t.line);if(o.markedSpans)for(var l=0;l<o.markedSpans.length;++l){var s=o.markedSpans[l],a=s.marker;if((null==s.from||(a.inclusiveLeft?s.from<=t.ch:s.from<t.ch))&&(null==s.to||(a.inclusiveRight?s.to>=t.ch:s.to>t.ch))){if(i&&(Te(a,"beforeCursorEnter"),a.explicitlyCleared)){if(o.markedSpans){--l;continue}break}if(!a.atomic)continue;if(r){var u=a.find(n<0?1:-1),c=void 0;if((n<0?a.inclusiveRight:a.inclusiveLeft)&&(u=Ti(e,u,-n,u&&u.line==t.line?o:null)),u&&u.line==t.line&&(c=P(u,r))&&(n<0?c<0:c>0))return Li(e,u,t,n,i)}var f=a.find(n<0?-1:1);return(n<0?a.inclusiveLeft:a.inclusiveRight)&&(f=Ti(e,f,n,f.line==t.line?o:null)),f?Li(e,f,t,n,i):null}}return t}function ki(e,t,r,n,i){var o=n||1,l=Li(e,t,r,o,i)||!i&&Li(e,t,r,o,!0)||Li(e,t,r,-o,i)||!i&&Li(e,t,r,-o,!0);return l||(e.cantEdit=!0,E(e.first,0))}function Ti(e,t,r,n){return r<0&&0==t.ch?t.line>e.first?U(e,E(t.line-1)):null:r>0&&t.ch==(n||M(e,t.line)).text.length?t.line<e.first+e.size-1?E(t.line+1,0):null:new E(t.line,t.ch+r)}function Mi(e){e.setSelection(E(e.firstLine(),0),E(e.lastLine()),Gl)}function Ni(e,t,r){var n={canceled:!1,from:t.from,to:t.to,text:t.text,origin:t.origin,cancel:function(){return n.canceled=!0}};return r&&(n.update=function(t,r,i,o){t&&(n.from=U(e,t)),r&&(n.to=U(e,r)),i&&(n.text=i),void 0!==o&&(n.origin=o)}),Te(e,"beforeChange",e,n),e.cm&&Te(e.cm,"beforeChange",e.cm,n),n.canceled?null:{from:n.from,to:n.to,text:n.text,origin:n.origin}}function Oi(e,t,r){if(e.cm){if(!e.cm.curOp)return dn(e.cm,Oi)(e,t,r);if(e.cm.state.suppressEdits)return}if(!(Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"))||(t=Ni(e,t,!0))){var n=Yl&&!r&&te(e,t.from,t.to);if(n)for(var i=n.length-1;i>=0;--i)Ai(e,{from:n[i].from,to:n[i].to,text:i?[""]:t.text,origin:t.origin});else Ai(e,t)}}function Ai(e,t){if(1!=t.text.length||""!=t.text[0]||0!=P(t.from,t.to)){var r=Un(e,t);ni(e,t,r,e.cm?e.cm.curOp.id:NaN),Hi(e,t,r,J(e,t));var n=[];$n(e,function(e,r){r||-1!=h(n,e.history)||(zi(e.history,t),n.push(e.history)),Hi(e,t,null,J(e,t))})}}function Wi(e,t,r){if(!e.cm||!e.cm.state.suppressEdits||r){for(var n,i=e.history,o=e.sel,l="undo"==t?i.done:i.undone,s="undo"==t?i.undone:i.done,a=0;a<l.length&&(n=l[a],r?!n.ranges||n.equals(e.sel):n.ranges);a++);if(a!=l.length){for(i.lastOrigin=i.lastSelOrigin=null;(n=l.pop()).ranges;){if(li(n,s),r&&!n.equals(e.sel))return void bi(e,n,{clearRedo:!1});o=n}var u=[];li(o,s),s.push({changes:u,generation:i.generation}),i.generation=n.generation||++i.maxGeneration;for(var c=Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"),f=n.changes.length-1;f>=0;--f){var d=function(r){var i=n.changes[r];if(i.origin=t,c&&!Ni(e,i,!1))return l.length=0,{};u.push(ei(e,i));var o=r?Un(e,i):g(l);Hi(e,i,o,ci(e,i)),!r&&e.cm&&e.cm.scrollIntoView({from:i.from,to:Bn(i)});var s=[];$n(e,function(e,t){t||-1!=h(s,e.history)||(zi(e.history,i),s.push(e.history)),Hi(e,i,null,ci(e,i))})}(f);if(d)return d.v}}}}function Di(e,t){if(0!=t&&(e.first+=t,e.sel=new ks(v(e.sel.ranges,function(e){return new Ts(E(e.anchor.line+t,e.anchor.ch),E(e.head.line+t,e.head.ch))}),e.sel.primIndex),e.cm)){vn(e.cm,e.first,e.first-t,t);for(var r=e.cm.display,n=r.viewFrom;n<r.viewTo;n++)mn(e.cm,n,"gutter")}}function Hi(e,t,r,n){if(e.cm&&!e.cm.curOp)return dn(e.cm,Hi)(e,t,r,n);if(t.to.line<e.first)Di(e,t.text.length-1-(t.to.line-t.from.line));else if(!(t.from.line>e.lastLine())){if(t.from.line<e.first){var i=t.text.length-1-(e.first-t.from.line);Di(e,i),t={from:E(e.first,0),to:E(t.to.line+i,t.to.ch),text:[g(t.text)],origin:t.origin}}var o=e.lastLine();t.to.line>o&&(t={from:t.from,to:E(o,M(e,o).text.length),text:[t.text[0]],origin:t.origin}),t.removed=N(e,t.from,t.to),r||(r=Un(e,t)),e.cm?Fi(e.cm,t,n):_n(e,t,n),wi(e,r,Gl)}}function Fi(e,t,r){var n=e.doc,i=e.display,o=t.from,l=t.to,s=!1,a=o.line;e.options.lineWrapping||(a=W(fe(M(n,o.line))),n.iter(a,l.line+1,function(e){if(e==i.maxLine)return s=!0,!0})),n.sel.contains(t.from,t.to)>-1&&Ne(e),_n(n,t,r,xr(e)),e.options.lineWrapping||(n.iter(a,o.line+t.text.length,function(e){var t=be(e);t>i.maxLineLength&&(i.maxLine=e,i.maxLineLength=t,i.maxLineChanged=!0,s=!1)}),s&&(e.curOp.updateMaxLine=!0)),nt(n,o.line),Cn(e,400);var u=t.text.length-(l.line-o.line)-1;t.full?vn(e):o.line!=l.line||1!=t.text.length||Yn(e.doc,t)?vn(e,o.line,l.line+1,u):mn(e,o.line,"text");var c=Oe(e,"changes"),f=Oe(e,"change");if(f||c){var h={from:o,to:l,text:t.text,removed:t.removed,origin:t.origin};f&&bt(e,"change",e,h),c&&(e.curOp.changeObjs||(e.curOp.changeObjs=[])).push(h)}e.display.selForContextMenu=null}function Ei(e,t,r,n,i){if(n||(n=r),P(n,r)<0){var o;r=(o=[n,r])[0],n=o[1]}"string"==typeof t&&(t=e.splitLines(t)),Oi(e,{from:r,to:n,text:t,origin:i})}function Pi(e,t,r,n){r<e.line?e.line+=n:t<e.line&&(e.line=t,e.ch=0)}function Ii(e,t,r,n){for(var i=0;i<e.length;++i){var o=e[i],l=!0;if(o.ranges){o.copied||((o=e[i]=o.deepCopy()).copied=!0);for(var s=0;s<o.ranges.length;s++)Pi(o.ranges[s].anchor,t,r,n),Pi(o.ranges[s].head,t,r,n)}else{for(var a=0;a<o.changes.length;++a){var u=o.changes[a];if(r<u.from.line)u.from=E(u.from.line+n,u.from.ch),u.to=E(u.to.line+n,u.to.ch);else if(t<=u.to.line){l=!1;break}}l||(e.splice(0,i+1),i=0)}}}function zi(e,t){var r=t.from.line,n=t.to.line,i=t.text.length-(n-r)-1;Ii(e.done,r,n,i),Ii(e.undone,r,n,i)}function Ri(e,t,r,n){var i=t,o=t;return"number"==typeof t?o=M(e,G(e,t)):i=W(t),null==i?null:(n(o,i)&&e.cm&&mn(e.cm,i,r),o)}function Bi(e){var t=this;this.lines=e,this.parent=null;for(var r=0,n=0;n<e.length;++n)e[n].parent=t,r+=e[n].height;this.height=r}function Gi(e){var t=this;this.children=e;for(var r=0,n=0,i=0;i<e.length;++i){var o=e[i];r+=o.chunkSize(),n+=o.height,o.parent=t}this.size=r,this.height=n,this.parent=null}function Ui(e,t,r){ye(t)<(e.curOp&&e.curOp.scrollTop||e.doc.scrollTop)&&Kr(e,r)}function Vi(e,t,r,n){var i=new Ms(e,r,n),o=e.cm;return o&&i.noHScroll&&(o.display.alignWidgets=!0),Ri(e,t,"widget",function(t){var r=t.widgets||(t.widgets=[]);if(null==i.insertAt?r.push(i):r.splice(Math.min(r.length-1,Math.max(0,i.insertAt)),0,i),i.line=t,o&&!ve(e,t)){var n=ye(t)<e.scrollTop;A(t,t.height+Ht(i)),n&&Kr(o,i.height),o.curOp.forceUpdate=!0}return!0}),bt(o,"lineWidgetAdded",o,i,"number"==typeof t?t:W(t)),i}function Ki(e,t,r,n,o){if(n&&n.shared)return ji(e,t,r,n,o);if(e.cm&&!e.cm.curOp)return dn(e.cm,Ki)(e,t,r,n,o);var l=new Os(e,o),s=P(t,r);if(n&&c(n,l,!1),s>0||0==s&&!1!==l.clearWhenEmpty)return l;if(l.replacedWith&&(l.collapsed=!0,l.widgetNode=i("span",[l.replacedWith],"CodeMirror-widget"),n.handleMouseEvents||l.widgetNode.setAttribute("cm-ignore-events","true"),n.insertLeft&&(l.widgetNode.insertLeft=!0)),l.collapsed){if(ce(e,t.line,t,r,l)||t.line!=r.line&&ce(e,r.line,t,r,l))throw new Error("Inserting collapsed marker partially overlapping an existing one");X()}l.addToHistory&&ni(e,{from:t,to:r,origin:"markText"},e.sel,NaN);var a,u=t.line,f=e.cm;if(e.iter(u,r.line+1,function(e){f&&l.collapsed&&!f.options.lineWrapping&&fe(e)==f.display.maxLine&&(a=!0),l.collapsed&&u!=t.line&&A(e,0),q(e,new Y(l,u==t.line?t.ch:null,u==r.line?r.ch:null)),++u}),l.collapsed&&e.iter(t.line,r.line+1,function(t){ve(e,t)&&A(t,0)}),l.clearOnEnter&&Ql(l,"beforeCursorEnter",function(){return l.clear()}),l.readOnly&&(j(),(e.history.done.length||e.history.undone.length)&&e.clearHistory()),l.collapsed&&(l.id=++Ns,l.atomic=!0),f){if(a&&(f.curOp.updateMaxLine=!0),l.collapsed)vn(f,t.line,r.line+1);else if(l.className||l.title||l.startStyle||l.endStyle||l.css)for(var h=t.line;h<=r.line;h++)mn(f,h,"text");l.atomic&&Ci(f.doc),bt(f,"markerAdded",f,l)}return l}function ji(e,t,r,n,i){(n=c(n)).shared=!1;var o=[Ki(e,t,r,n,i)],l=o[0],s=n.widgetNode;return $n(e,function(e){s&&(n.widgetNode=s.cloneNode(!0)),o.push(Ki(e,U(e,t),U(e,r),n,i));for(var a=0;a<e.linked.length;++a)if(e.linked[a].isParent)return;l=g(o)}),new As(o,l)}function Xi(e){return e.findMarks(E(e.first,0),e.clipPos(E(e.lastLine())),function(e){return e.parent})}function Yi(e,t){for(var r=0;r<t.length;r++){var n=t[r],i=n.find(),o=e.clipPos(i.from),l=e.clipPos(i.to);if(P(o,l)){var s=Ki(e,o,l,n.primary,n.primary.type);n.markers.push(s),s.parent=n}}}function _i(e){for(var t=0;t<e.length;t++)!function(t){var r=e[t],n=[r.primary.doc];$n(r.primary.doc,function(e){return n.push(e)});for(var i=0;i<r.markers.length;i++){var o=r.markers[i];-1==h(n,o.doc)&&(o.parent=null,r.markers.splice(i--,1))}}(t)}function $i(e){var t=this;if(Qi(t),!Me(t,e)&&!Ft(t.display,e)){We(e),gl&&(Hs=+new Date);var r=Sr(t,e,!0),n=e.dataTransfer.files;if(r&&!t.isReadOnly())if(n&&n.length&&window.FileReader&&window.File)for(var i=n.length,o=Array(i),l=0,s=0;s<i;++s)!function(e,n){if(!t.options.allowDropFileTypes||-1!=h(t.options.allowDropFileTypes,e.type)){var s=new FileReader;s.onload=dn(t,function(){var e=s.result;if(/[\x00-\x08\x0e-\x1f]{2}/.test(e)&&(e=""),o[n]=e,++l==i){var a={from:r=U(t.doc,r),to:r,text:t.doc.splitLines(o.join(t.doc.lineSeparator())),origin:"paste"};Oi(t.doc,a),yi(t.doc,Rn(r,Bn(a)))}}),s.readAsText(e)}}(n[s],s);else{if(t.state.draggingText&&t.doc.sel.contains(r)>-1)return t.state.draggingText(e),void setTimeout(function(){return t.display.input.focus()},20);try{var a=e.dataTransfer.getData("Text");if(a){var u;if(t.state.draggingText&&!t.state.draggingText.copy&&(u=t.listSelections()),wi(t.doc,Rn(r,r)),u)for(var c=0;c<u.length;++c)Ei(t.doc,"",u[c].anchor,u[c].head,"drag");t.replaceSelection(a,"around","paste"),t.display.input.focus()}}catch(e){}}}}function qi(e,t){if(gl&&(!e.state.draggingText||+new Date-Hs<100))Fe(t);else if(!Me(e,t)&&!Ft(e.display,t)&&(t.dataTransfer.setData("Text",e.getSelection()),t.dataTransfer.effectAllowed="copyMove",t.dataTransfer.setDragImage&&!xl)){var r=n("img",null,null,"position: fixed; left: 0; top: 0;");r.src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==",wl&&(r.width=r.height=1,e.display.wrapper.appendChild(r),r._top=r.offsetTop),t.dataTransfer.setDragImage(r,0,0),wl&&r.parentNode.removeChild(r)}}function Zi(e,t){var i=Sr(e,t);if(i){var o=document.createDocumentFragment();Mr(e,i,o),e.display.dragCursor||(e.display.dragCursor=n("div",null,"CodeMirror-cursors CodeMirror-dragcursors"),e.display.lineSpace.insertBefore(e.display.dragCursor,e.display.cursorDiv)),r(e.display.dragCursor,o)}}function Qi(e){e.display.dragCursor&&(e.display.lineSpace.removeChild(e.display.dragCursor),e.display.dragCursor=null)}function Ji(e){if(document.getElementsByClassName)for(var t=document.getElementsByClassName("CodeMirror"),r=0;r<t.length;r++){var n=t[r].CodeMirror;n&&e(n)}}function eo(){Fs||(to(),Fs=!0)}function to(){var e;Ql(window,"resize",function(){null==e&&(e=setTimeout(function(){e=null,Ji(ro)},100))}),Ql(window,"blur",function(){return Ji(Fr)})}function ro(e){var t=e.display;t.lastWrapHeight==t.wrapper.clientHeight&&t.lastWrapWidth==t.wrapper.clientWidth||(t.cachedCharWidth=t.cachedTextHeight=t.cachedPaddingH=null,t.scrollbarsClipped=!1,e.setSize())}function no(e){var t=e.split(/-(?!$)/);e=t[t.length-1];for(var r,n,i,o,l=0;l<t.length-1;l++){var s=t[l];if(/^(cmd|meta|m)$/i.test(s))o=!0;else if(/^a(lt)?$/i.test(s))r=!0;else if(/^(c|ctrl|control)$/i.test(s))n=!0;else{if(!/^s(hift)?$/i.test(s))throw new Error("Unrecognized modifier name: "+s);i=!0}}return r&&(e="Alt-"+e),n&&(e="Ctrl-"+e),o&&(e="Cmd-"+e),i&&(e="Shift-"+e),e}function io(e){var t={};for(var r in e)if(e.hasOwnProperty(r)){var n=e[r];if(/^(name|fallthrough|(de|at)tach)$/.test(r))continue;if("..."==n){delete e[r];continue}for(var i=v(r.split(" "),no),o=0;o<i.length;o++){var l=void 0,s=void 0;o==i.length-1?(s=i.join(" "),l=n):(s=i.slice(0,o+1).join(" "),l="...");var a=t[s];if(a){if(a!=l)throw new Error("Inconsistent bindings for "+s)}else t[s]=l}delete e[r]}for(var u in t)e[u]=t[u];return e}function oo(e,t,r,n){var i=(t=uo(t)).call?t.call(e,n):t[e];if(!1===i)return"nothing";if("..."===i)return"multi";if(null!=i&&r(i))return"handled";if(t.fallthrough){if("[object Array]"!=Object.prototype.toString.call(t.fallthrough))return oo(e,t.fallthrough,r,n);for(var o=0;o<t.fallthrough.length;o++){var l=oo(e,t.fallthrough[o],r,n);if(l)return l}}}function lo(e){var t="string"==typeof e?e:Es[e.keyCode];return"Ctrl"==t||"Alt"==t||"Shift"==t||"Mod"==t}function so(e,t,r){var n=e;return t.altKey&&"Alt"!=n&&(e="Alt-"+e),(Dl?t.metaKey:t.ctrlKey)&&"Ctrl"!=n&&(e="Ctrl-"+e),(Dl?t.ctrlKey:t.metaKey)&&"Cmd"!=n&&(e="Cmd-"+e),!r&&t.shiftKey&&"Shift"!=n&&(e="Shift-"+e),e}function ao(e,t){if(wl&&34==e.keyCode&&e.char)return!1;var r=Es[e.keyCode];return null!=r&&!e.altGraphKey&&so(r,e,t)}function uo(e){return"string"==typeof e?Rs[e]:e}function co(e,t){for(var r=e.doc.sel.ranges,n=[],i=0;i<r.length;i++){for(var o=t(r[i]);n.length&&P(o.from,g(n).to)<=0;){var l=n.pop();if(P(l.from,o.from)<0){o.from=l.from;break}}n.push(o)}hn(e,function(){for(var t=n.length-1;t>=0;t--)Ei(e.doc,"",n[t].from,n[t].to,"+delete");jr(e)})}function fo(e,t,r){var n=L(e.text,t+r,r);return n<0||n>e.text.length?null:n}function ho(e,t,r){var n=fo(e,t.ch,r);return null==n?null:new E(t.line,n,r<0?"after":"before")}function po(e,t,r,n,i){if(e){var o=Se(r,t.doc.direction);if(o){var l,s=i<0?g(o):o[0],a=i<0==(1==s.level)?"after":"before";if(s.level>0){var u=Xt(t,r);l=i<0?r.text.length-1:0;var c=Yt(t,u,l).top;l=k(function(e){return Yt(t,u,e).top==c},i<0==(1==s.level)?s.from:s.to-1,l),"before"==a&&(l=fo(r,l,1))}else l=i<0?s.to:s.from;return new E(n,l,a)}}return new E(n,i<0?r.text.length:0,i<0?"before":"after")}function go(e,t,r,n){var i=Se(t,e.doc.direction);if(!i)return ho(t,r,n);r.ch>=t.text.length?(r.ch=t.text.length,r.sticky="before"):r.ch<=0&&(r.ch=0,r.sticky="after");var o=Ce(i,r.ch,r.sticky),l=i[o];if("ltr"==e.doc.direction&&l.level%2==0&&(n>0?l.to>r.ch:l.from<r.ch))return ho(t,r,n);var s,a=function(e,r){return fo(t,e instanceof E?e.ch:e,r)},u=function(r){return e.options.lineWrapping?(s=s||Xt(e,t),hr(e,t,s,r)):{begin:0,end:t.text.length}},c=u("before"==r.sticky?a(r,-1):r.ch);if("rtl"==e.doc.direction||1==l.level){var f=1==l.level==n<0,h=a(r,f?1:-1);if(null!=h&&(f?h<=l.to&&h<=c.end:h>=l.from&&h>=c.begin)){var d=f?"before":"after";return new E(r.line,h,d)}}var p=function(e,t,n){for(var o=function(e,t){return t?new E(r.line,a(e,1),"before"):new E(r.line,e,"after")};e>=0&&e<i.length;e+=t){var l=i[e],s=t>0==(1!=l.level),u=s?n.begin:a(n.end,-1);if(l.from<=u&&u<l.to)return o(u,s);if(u=s?l.from:a(l.to,-1),n.begin<=u&&u<n.end)return o(u,s)}},g=p(o+n,n,c);if(g)return g;var v=n>0?c.end:a(c.begin,-1);return null==v||n>0&&v==t.text.length||!(g=p(n>0?0:i.length-1,n,u(v)))?null:g}function vo(e,t){var r=M(e.doc,t),n=fe(r);return n!=r&&(t=W(n)),po(!0,e,n,t,1)}function mo(e,t){var r=M(e.doc,t),n=he(r);return n!=r&&(t=W(n)),po(!0,e,r,t,-1)}function yo(e,t){var r=vo(e,t.line),n=M(e.doc,r.line),i=Se(n,e.doc.direction);if(!i||0==i[0].level){var o=Math.max(0,n.text.search(/\S/)),l=t.line==r.line&&t.ch<=o&&t.ch;return E(r.line,l?0:o,r.sticky)}return r}function bo(e,t,r){if("string"==typeof t&&!(t=Bs[t]))return!1;e.display.input.ensurePolled();var n=e.display.shift,i=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),r&&(e.display.shift=!1),i=t(e)!=Bl}finally{e.display.shift=n,e.state.suppressEdits=!1}return i}function wo(e,t,r){for(var n=0;n<e.state.keyMaps.length;n++){var i=oo(t,e.state.keyMaps[n],r,e);if(i)return i}return e.options.extraKeys&&oo(t,e.options.extraKeys,r,e)||oo(t,e.options.keyMap,r,e)}function xo(e,t,r,n){var i=e.state.keySeq;if(i){if(lo(t))return"handled";Gs.set(50,function(){e.state.keySeq==i&&(e.state.keySeq=null,e.display.input.reset())}),t=i+" "+t}var o=wo(e,t,n);return"multi"==o&&(e.state.keySeq=t),"handled"==o&&bt(e,"keyHandled",e,t,r),"handled"!=o&&"multi"!=o||(We(r),Ar(e)),i&&!o&&/\'$/.test(t)?(We(r),!0):!!o}function Co(e,t){var r=ao(t,!0);return!!r&&(t.shiftKey&&!e.state.keySeq?xo(e,"Shift-"+r,t,function(t){return bo(e,t,!0)})||xo(e,r,t,function(t){if("string"==typeof t?/^go[A-Z]/.test(t):t.motion)return bo(e,t)}):xo(e,r,t,function(t){return bo(e,t)}))}function So(e,t,r){return xo(e,"'"+r+"'",t,function(t){return bo(e,t,!0)})}function Lo(e){var t=this;if(t.curOp.focus=l(),!Me(t,e)){gl&&vl<11&&27==e.keyCode&&(e.returnValue=!1);var r=e.keyCode;t.display.shift=16==r||e.shiftKey;var n=Co(t,e);wl&&(Us=n?r:null,!n&&88==r&&!rs&&(Ml?e.metaKey:e.ctrlKey)&&t.replaceSelection("",null,"cut")),18!=r||/\bCodeMirror-crosshair\b/.test(t.display.lineDiv.className)||ko(t)}}function ko(e){function t(e){18!=e.keyCode&&e.altKey||(Fl(r,"CodeMirror-crosshair"),ke(document,"keyup",t),ke(document,"mouseover",t))}var r=e.display.lineDiv;s(r,"CodeMirror-crosshair"),Ql(document,"keyup",t),Ql(document,"mouseover",t)}function To(e){16==e.keyCode&&(this.doc.sel.shift=!1),Me(this,e)}function Mo(e){var t=this;if(!(Ft(t.display,e)||Me(t,e)||e.ctrlKey&&!e.altKey||Ml&&e.metaKey)){var r=e.keyCode,n=e.charCode;if(wl&&r==Us)return Us=null,void We(e);if(!wl||e.which&&!(e.which<10)||!Co(t,e)){var i=String.fromCharCode(null==n?r:n);"\b"!=i&&(So(t,e,i)||t.display.input.onKeyPress(e))}}}function No(e,t){var r=+new Date;return js&&js.compare(r,e,t)?(Ks=js=null,"triple"):Ks&&Ks.compare(r,e,t)?(js=new Vs(r,e,t),Ks=null,"double"):(Ks=new Vs(r,e,t),js=null,"single")}function Oo(e){var t=this,r=t.display;if(!(Me(t,e)||r.activeTouch&&r.input.supportsTouch()))if(r.input.ensurePolled(),r.shift=e.shiftKey,Ft(r,e))ml||(r.scroller.draggable=!1,setTimeout(function(){return r.scroller.draggable=!0},100));else if(!zo(t,e)){var n=Sr(t,e),i=Pe(e),o=n?No(n,i):"single";window.focus(),1==i&&t.state.selectingText&&t.state.selectingText(e),n&&Ao(t,i,n,o,e)||(1==i?n?Do(t,n,o,e):Ee(e)==r.scroller&&We(e):2==i?(n&&di(t.doc,n),setTimeout(function(){return r.input.focus()},20)):3==i&&(Hl?Ro(t,e):Dr(t)))}}function Ao(e,t,r,n,i){var o="Click";return"double"==n?o="Double"+o:"triple"==n&&(o="Triple"+o),o=(1==t?"Left":2==t?"Middle":"Right")+o,xo(e,so(o,i),i,function(t){if("string"==typeof t&&(t=Bs[t]),!t)return!1;var n=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),n=t(e,r)!=Bl}finally{e.state.suppressEdits=!1}return n})}function Wo(e,t,r){var n=e.getOption("configureMouse"),i=n?n(e,t,r):{};if(null==i.unit){var o=Nl?r.shiftKey&&r.metaKey:r.altKey;i.unit=o?"rectangle":"single"==t?"char":"double"==t?"word":"line"}return(null==i.extend||e.doc.extend)&&(i.extend=e.doc.extend||r.shiftKey),null==i.addNew&&(i.addNew=Ml?r.metaKey:r.ctrlKey),null==i.moveOnDrag&&(i.moveOnDrag=!(Ml?r.altKey:r.ctrlKey)),i}function Do(e,t,r,n){gl?setTimeout(u(Wr,e),0):e.curOp.focus=l();var i,o=Wo(e,r,n),s=e.doc.sel;e.options.dragDrop&&Jl&&!e.isReadOnly()&&"single"==r&&(i=s.contains(t))>-1&&(P((i=s.ranges[i]).from(),t)<0||t.xRel>0)&&(P(i.to(),t)>0||t.xRel<0)?Ho(e,n,t,o):Eo(e,n,t,o)}function Ho(e,t,r,n){var i=e.display,o=!1,l=dn(e,function(t){ml&&(i.scroller.draggable=!1),e.state.draggingText=!1,ke(document,"mouseup",l),ke(document,"mousemove",s),ke(i.scroller,"dragstart",a),ke(i.scroller,"drop",l),o||(We(t),n.addNew||di(e.doc,r,null,null,n.extend),ml||gl&&9==vl?setTimeout(function(){document.body.focus(),i.input.focus()},20):i.input.focus())}),s=function(e){o=o||Math.abs(t.clientX-e.clientX)+Math.abs(t.clientY-e.clientY)>=10},a=function(){return o=!0};ml&&(i.scroller.draggable=!0),e.state.draggingText=l,l.copy=!n.moveOnDrag,i.scroller.dragDrop&&i.scroller.dragDrop(),Ql(document,"mouseup",l),Ql(document,"mousemove",s),Ql(i.scroller,"dragstart",a),Ql(i.scroller,"drop",l),Dr(e),setTimeout(function(){return i.input.focus()},20)}function Fo(e,t,r){if("char"==r)return new Ts(t,t);if("word"==r)return e.findWordAt(t);if("line"==r)return new Ts(E(t.line,0),U(e.doc,E(t.line+1,0)));var n=r(e,t);return new Ts(n.from,n.to)}function Eo(e,t,r,n){function i(t){if(0!=P(m,t))if(m=t,"rectangle"==n.unit){for(var i=[],o=e.options.tabSize,l=f(M(u,r.line).text,r.ch,o),s=f(M(u,t.line).text,t.ch,o),a=Math.min(l,s),g=Math.max(l,s),v=Math.min(r.line,t.line),y=Math.min(e.lastLine(),Math.max(r.line,t.line));v<=y;v++){var b=M(u,v).text,w=d(b,a,o);a==g?i.push(new Ts(E(v,w),E(v,w))):b.length>w&&i.push(new Ts(E(v,w),E(v,d(b,g,o))))}i.length||i.push(new Ts(r,r)),bi(u,zn(p.ranges.slice(0,h).concat(i),h),{origin:"*mouse",scroll:!1}),e.scrollIntoView(t)}else{var x,C=c,S=Fo(e,t,n.unit),L=C.anchor;P(S.anchor,L)>0?(x=S.head,L=B(C.from(),S.anchor)):(x=S.anchor,L=R(C.to(),S.head));var k=p.ranges.slice(0);k[h]=Po(e,new Ts(U(u,L),x)),bi(u,zn(k,h),Ul)}}function o(t){var r=++b,s=Sr(e,t,!0,"rectangle"==n.unit);if(s)if(0!=P(s,m)){e.curOp.focus=l(),i(s);var c=Ir(a,u);(s.line>=c.to||s.line<c.from)&&setTimeout(dn(e,function(){b==r&&o(t)}),150)}else{var f=t.clientY<y.top?-20:t.clientY>y.bottom?20:0;f&&setTimeout(dn(e,function(){b==r&&(a.scroller.scrollTop+=f,o(t))}),50)}}function s(t){e.state.selectingText=!1,b=1/0,We(t),a.input.focus(),ke(document,"mousemove",w),ke(document,"mouseup",x),u.history.lastSelOrigin=null}var a=e.display,u=e.doc;We(t);var c,h,p=u.sel,g=p.ranges;if(n.addNew&&!n.extend?(h=u.sel.contains(r),c=h>-1?g[h]:new Ts(r,r)):(c=u.sel.primary(),h=u.sel.primIndex),"rectangle"==n.unit)n.addNew||(c=new Ts(r,r)),r=Sr(e,t,!0,!0),h=-1;else{var v=Fo(e,r,n.unit);c=n.extend?hi(c,v.anchor,v.head,n.extend):v}n.addNew?-1==h?(h=g.length,bi(u,zn(g.concat([c]),h),{scroll:!1,origin:"*mouse"})):g.length>1&&g[h].empty()&&"char"==n.unit&&!n.extend?(bi(u,zn(g.slice(0,h).concat(g.slice(h+1)),0),{scroll:!1,origin:"*mouse"}),p=u.sel):gi(u,h,c,Ul):(h=0,bi(u,new ks([c],0),Ul),p=u.sel);var m=r,y=a.wrapper.getBoundingClientRect(),b=0,w=dn(e,function(e){Pe(e)?o(e):s(e)}),x=dn(e,s);e.state.selectingText=x,Ql(document,"mousemove",w),Ql(document,"mouseup",x)}function Po(e,t){var r=t.anchor,n=t.head,i=M(e.doc,r.line);if(0==P(r,n)&&r.sticky==n.sticky)return t;var o=Se(i);if(!o)return t;var l=Ce(o,r.ch,r.sticky),s=o[l];if(s.from!=r.ch&&s.to!=r.ch)return t;var a=l+(s.from==r.ch==(1!=s.level)?0:1);if(0==a||a==o.length)return t;var u;if(n.line!=r.line)u=(n.line-r.line)*("ltr"==e.doc.direction?1:-1)>0;else{var c=Ce(o,n.ch,n.sticky),f=c-l||(n.ch-r.ch)*(1==s.level?-1:1);u=c==a-1||c==a?f<0:f>0}var h=o[a+(u?-1:0)],d=u==(1==h.level),p=d?h.from:h.to,g=d?"after":"before";return r.ch==p&&r.sticky==g?t:new Ts(new E(r.line,p,g),n)}function Io(e,t,r,n){var i,o;if(t.touches)i=t.touches[0].clientX,o=t.touches[0].clientY;else try{i=t.clientX,o=t.clientY}catch(t){return!1}if(i>=Math.floor(e.display.gutters.getBoundingClientRect().right))return!1;n&&We(t);var l=e.display,s=l.lineDiv.getBoundingClientRect();if(o>s.bottom||!Oe(e,r))return He(t);o-=s.top-l.viewOffset;for(var a=0;a<e.options.gutters.length;++a){var u=l.gutters.childNodes[a];if(u&&u.getBoundingClientRect().right>=i)return Te(e,r,e,D(e.doc,o),e.options.gutters[a],t),He(t)}}function zo(e,t){return Io(e,t,"gutterClick",!0)}function Ro(e,t){Ft(e.display,t)||Bo(e,t)||Me(e,t,"contextmenu")||e.display.input.onContextMenu(t)}function Bo(e,t){return!!Oe(e,"gutterContextMenu")&&Io(e,t,"gutterContextMenu",!1)}function Go(e){e.display.wrapper.className=e.display.wrapper.className.replace(/\s*cm-s-\S+/g,"")+e.options.theme.replace(/(^|\s)\s*/g," cm-s-"),er(e)}function Uo(e){Hn(e),vn(e),zr(e)}function Vo(e,t,r){if(!t!=!(r&&r!=Xs)){var n=e.display.dragFunctions,i=t?Ql:ke;i(e.display.scroller,"dragstart",n.start),i(e.display.scroller,"dragenter",n.enter),i(e.display.scroller,"dragover",n.over),i(e.display.scroller,"dragleave",n.leave),i(e.display.scroller,"drop",n.drop)}}function Ko(e){e.options.lineWrapping?(s(e.display.wrapper,"CodeMirror-wrap"),e.display.sizer.style.minWidth="",e.display.sizerWidth=null):(Fl(e.display.wrapper,"CodeMirror-wrap"),we(e)),Cr(e),vn(e),er(e),setTimeout(function(){return en(e)},100)}function jo(e,t){var r=this;if(!(this instanceof jo))return new jo(e,t);this.options=t=t?c(t):{},c(Ys,t,!1),Fn(t);var n=t.value;"string"==typeof n&&(n=new Ds(n,t.mode,null,t.lineSeparator,t.direction)),this.doc=n;var i=new jo.inputStyles[t.inputStyle](this),o=this.display=new T(e,n,i);o.wrapper.CodeMirror=this,Hn(this),Go(this),t.lineWrapping&&(this.display.wrapper.className+=" CodeMirror-wrap"),rn(this),this.state={keyMaps:[],overlays:[],modeGen:0,overwrite:!1,delayingBlurEvent:!1,focused:!1,suppressEdits:!1,pasteIncoming:!1,cutIncoming:!1,selectingText:!1,draggingText:!1,highlight:new Pl,keySeq:null,specialChars:null},t.autofocus&&!Tl&&o.input.focus(),gl&&vl<11&&setTimeout(function(){return r.display.input.reset(!0)},20),Xo(this),eo(),nn(this),this.curOp.forceUpdate=!0,qn(this,n),t.autofocus&&!Tl||this.hasFocus()?setTimeout(u(Hr,this),20):Fr(this);for(var l in _s)_s.hasOwnProperty(l)&&_s[l](r,t[l],Xs);Rr(this),t.finishInit&&t.finishInit(this);for(var s=0;s<$s.length;++s)$s[s](r);on(this),ml&&t.lineWrapping&&"optimizelegibility"==getComputedStyle(o.lineDiv).textRendering&&(o.lineDiv.style.textRendering="auto")}function Xo(e){function t(){i.activeTouch&&(o=setTimeout(function(){return i.activeTouch=null},1e3),(l=i.activeTouch).end=+new Date)}function r(e){if(1!=e.touches.length)return!1;var t=e.touches[0];return t.radiusX<=1&&t.radiusY<=1}function n(e,t){if(null==t.left)return!0;var r=t.left-e.left,n=t.top-e.top;return r*r+n*n>400}var i=e.display;Ql(i.scroller,"mousedown",dn(e,Oo)),gl&&vl<11?Ql(i.scroller,"dblclick",dn(e,function(t){if(!Me(e,t)){var r=Sr(e,t);if(r&&!zo(e,t)&&!Ft(e.display,t)){We(t);var n=e.findWordAt(r);di(e.doc,n.anchor,n.head)}}})):Ql(i.scroller,"dblclick",function(t){return Me(e,t)||We(t)}),Hl||Ql(i.scroller,"contextmenu",function(t){return Ro(e,t)});var o,l={end:0};Ql(i.scroller,"touchstart",function(t){if(!Me(e,t)&&!r(t)&&!zo(e,t)){i.input.ensurePolled(),clearTimeout(o);var n=+new Date;i.activeTouch={start:n,moved:!1,prev:n-l.end<=300?l:null},1==t.touches.length&&(i.activeTouch.left=t.touches[0].pageX,i.activeTouch.top=t.touches[0].pageY)}}),Ql(i.scroller,"touchmove",function(){i.activeTouch&&(i.activeTouch.moved=!0)}),Ql(i.scroller,"touchend",function(r){var o=i.activeTouch;if(o&&!Ft(i,r)&&null!=o.left&&!o.moved&&new Date-o.start<300){var l,s=e.coordsChar(i.activeTouch,"page");l=!o.prev||n(o,o.prev)?new Ts(s,s):!o.prev.prev||n(o,o.prev.prev)?e.findWordAt(s):new Ts(E(s.line,0),U(e.doc,E(s.line+1,0))),e.setSelection(l.anchor,l.head),e.focus(),We(r)}t()}),Ql(i.scroller,"touchcancel",t),Ql(i.scroller,"scroll",function(){i.scroller.clientHeight&&(qr(e,i.scroller.scrollTop),Qr(e,i.scroller.scrollLeft,!0),Te(e,"scroll",e))}),Ql(i.scroller,"mousewheel",function(t){return In(e,t)}),Ql(i.scroller,"DOMMouseScroll",function(t){return In(e,t)}),Ql(i.wrapper,"scroll",function(){return i.wrapper.scrollTop=i.wrapper.scrollLeft=0}),i.dragFunctions={enter:function(t){Me(e,t)||Fe(t)},over:function(t){Me(e,t)||(Zi(e,t),Fe(t))},start:function(t){return qi(e,t)},drop:dn(e,$i),leave:function(t){Me(e,t)||Qi(e)}};var s=i.input.getField();Ql(s,"keyup",function(t){return To.call(e,t)}),Ql(s,"keydown",dn(e,Lo)),Ql(s,"keypress",dn(e,Mo)),Ql(s,"focus",function(t){return Hr(e,t)}),Ql(s,"blur",function(t){return Fr(e,t)})}function Yo(e,t,r,n){var i,o=e.doc;null==r&&(r="add"),"smart"==r&&(o.mode.indent?i=$e(e,t).state:r="prev");var l=e.options.tabSize,s=M(o,t),a=f(s.text,null,l);s.stateAfter&&(s.stateAfter=null);var u,c=s.text.match(/^\s*/)[0];if(n||/\S/.test(s.text)){if("smart"==r&&((u=o.mode.indent(i,s.text.slice(c.length),s.text))==Bl||u>150)){if(!n)return;r="prev"}}else u=0,r="not";"prev"==r?u=t>o.first?f(M(o,t-1).text,null,l):0:"add"==r?u=a+e.options.indentUnit:"subtract"==r?u=a-e.options.indentUnit:"number"==typeof r&&(u=a+r),u=Math.max(0,u);var h="",d=0;if(e.options.indentWithTabs)for(var g=Math.floor(u/l);g;--g)d+=l,h+="\t";if(d<u&&(h+=p(u-d)),h!=c)return Ei(o,h,E(t,0),E(t,c.length),"+input"),s.stateAfter=null,!0;for(var v=0;v<o.sel.ranges.length;v++){var m=o.sel.ranges[v];if(m.head.line==t&&m.head.ch<c.length){var y=E(t,c.length);gi(o,v,new Ts(y,y));break}}}function _o(e){qs=e}function $o(e,t,r,n,i){var o=e.doc;e.display.shift=!1,n||(n=o.sel);var l=e.state.pasteIncoming||"paste"==i,s=es(t),a=null;if(l&&n.ranges.length>1)if(qs&&qs.text.join("\n")==t){if(n.ranges.length%qs.text.length==0){a=[];for(var u=0;u<qs.text.length;u++)a.push(o.splitLines(qs.text[u]))}}else s.length==n.ranges.length&&e.options.pasteLinesPerSelection&&(a=v(s,function(e){return[e]}));for(var c,f=n.ranges.length-1;f>=0;f--){var h=n.ranges[f],d=h.from(),p=h.to();h.empty()&&(r&&r>0?d=E(d.line,d.ch-r):e.state.overwrite&&!l?p=E(p.line,Math.min(M(o,p.line).text.length,p.ch+g(s).length)):qs&&qs.lineWise&&qs.text.join("\n")==t&&(d=p=E(d.line,0))),c=e.curOp.updateInput;var m={from:d,to:p,text:a?a[f%a.length]:s,origin:i||(l?"paste":e.state.cutIncoming?"cut":"+input")};Oi(e.doc,m),bt(e,"inputRead",e,m)}t&&!l&&Zo(e,t),jr(e),e.curOp.updateInput=c,e.curOp.typing=!0,e.state.pasteIncoming=e.state.cutIncoming=!1}function qo(e,t){var r=e.clipboardData&&e.clipboardData.getData("Text");if(r)return e.preventDefault(),t.isReadOnly()||t.options.disableInput||hn(t,function(){return $o(t,r,0,null,"paste")}),!0}function Zo(e,t){if(e.options.electricChars&&e.options.smartIndent)for(var r=e.doc.sel,n=r.ranges.length-1;n>=0;n--){var i=r.ranges[n];if(!(i.head.ch>100||n&&r.ranges[n-1].head.line==i.head.line)){var o=e.getModeAt(i.head),l=!1;if(o.electricChars){for(var s=0;s<o.electricChars.length;s++)if(t.indexOf(o.electricChars.charAt(s))>-1){l=Yo(e,i.head.line,"smart");break}}else o.electricInput&&o.electricInput.test(M(e.doc,i.head.line).text.slice(0,i.head.ch))&&(l=Yo(e,i.head.line,"smart"));l&&bt(e,"electricInput",e,i.head.line)}}}function Qo(e){for(var t=[],r=[],n=0;n<e.doc.sel.ranges.length;n++){var i=e.doc.sel.ranges[n].head.line,o={anchor:E(i,0),head:E(i+1,0)};r.push(o),t.push(e.getRange(o.anchor,o.head))}return{text:t,ranges:r}}function Jo(e,t){e.setAttribute("autocorrect","off"),e.setAttribute("autocapitalize","off"),e.setAttribute("spellcheck",!!t)}function el(){var e=n("textarea",null,null,"position: absolute; bottom: -1em; padding: 0; width: 1px; height: 1em; outline: none"),t=n("div",[e],null,"overflow: hidden; position: relative; width: 3px; height: 0px;");return ml?e.style.width="1000px":e.setAttribute("wrap","off"),Ll&&(e.style.border="1px solid black"),Jo(e),t}function tl(e,t,r,n,i){function o(){var n=t.line+r;return!(n<e.first||n>=e.first+e.size)&&(t=new E(n,t.ch,t.sticky),u=M(e,n))}function l(n){var l;if(null==(l=i?go(e.cm,u,t,r):ho(u,t,r))){if(n||!o())return!1;t=po(i,e.cm,u,t.line,r)}else t=l;return!0}var s=t,a=r,u=M(e,t.line);if("char"==n)l();else if("column"==n)l(!0);else if("word"==n||"group"==n)for(var c=null,f="group"==n,h=e.cm&&e.cm.getHelper(t,"wordChars"),d=!0;!(r<0)||l(!d);d=!1){var p=u.text.charAt(t.ch)||"\n",g=x(p,h)?"w":f&&"\n"==p?"n":!f||/\s/.test(p)?null:"p";if(!f||d||g||(g="s"),c&&c!=g){r<0&&(r=1,l(),t.sticky="after");break}if(g&&(c=g),r>0&&!l(!d))break}var v=ki(e,t,s,a,!0);return I(s,v)&&(v.hitSide=!0),v}function rl(e,t,r,n){var i,o=e.doc,l=t.left;if("page"==n){var s=Math.min(e.display.wrapper.clientHeight,window.innerHeight||document.documentElement.clientHeight),a=Math.max(s-.5*mr(e.display),3);i=(r>0?t.bottom:t.top)+r*a}else"line"==n&&(i=r>0?t.bottom+3:t.top-3);for(var u;(u=cr(e,l,i)).outside;){if(r<0?i<=0:i>=o.height){u.hitSide=!0;break}i+=5*r}return u}function nl(e,t){var r=jt(e,t.line);if(!r||r.hidden)return null;var n=M(e.doc,t.line),i=Ut(r,n,t.line),o=Se(n,e.doc.direction),l="left";o&&(l=Ce(o,t.ch)%2?"right":"left");var s=_t(i.map,t.ch,l);return s.offset="right"==s.collapse?s.end:s.start,s}function il(e){for(var t=e;t;t=t.parentNode)if(/CodeMirror-gutter-wrapper/.test(t.className))return!0;return!1}function ol(e,t){return t&&(e.bad=!0),e}function ll(e,t,r,n,i){function o(e){return function(t){return t.id==e}}function l(){c&&(u+=f,c=!1)}function s(e){e&&(l(),u+=e)}function a(t){if(1==t.nodeType){var r=t.getAttribute("cm-text");if(null!=r)return void s(r||t.textContent.replace(/\u200b/g,""));var u,h=t.getAttribute("cm-marker");if(h){var d=e.findMarks(E(n,0),E(i+1,0),o(+h));return void(d.length&&(u=d[0].find(0))&&s(N(e.doc,u.from,u.to).join(f)))}if("false"==t.getAttribute("contenteditable"))return;var p=/^(pre|div|p)$/i.test(t.nodeName);p&&l();for(var g=0;g<t.childNodes.length;g++)a(t.childNodes[g]);p&&(c=!0)}else 3==t.nodeType&&s(t.nodeValue)}for(var u="",c=!1,f=e.doc.lineSeparator();a(t),t!=r;)t=t.nextSibling;return u}function sl(e,t,r){var n;if(t==e.display.lineDiv){if(!(n=e.display.lineDiv.childNodes[r]))return ol(e.clipPos(E(e.display.viewTo-1)),!0);t=null,r=0}else for(n=t;;n=n.parentNode){if(!n||n==e.display.lineDiv)return null;if(n.parentNode&&n.parentNode==e.display.lineDiv)break}for(var i=0;i<e.display.view.length;i++){var o=e.display.view[i];if(o.node==n)return al(o,t,r)}}function al(e,t,r){function n(t,r,n){for(var i=-1;i<(f?f.length:0);i++)for(var o=i<0?c.map:f[i],l=0;l<o.length;l+=3){var s=o[l+2];if(s==t||s==r){var a=W(i<0?e.line:e.rest[i]),u=o[l]+n;return(n<0||s!=t)&&(u=o[l+(n?1:0)]),E(a,u)}}}var i=e.text.firstChild,l=!1;if(!t||!o(i,t))return ol(E(W(e.line),0),!0);if(t==i&&(l=!0,t=i.childNodes[r],r=0,!t)){var s=e.rest?g(e.rest):e.line;return ol(E(W(s),s.text.length),l)}var a=3==t.nodeType?t:null,u=t;for(a||1!=t.childNodes.length||3!=t.firstChild.nodeType||(a=t.firstChild,r&&(r=a.nodeValue.length));u.parentNode!=i;)u=u.parentNode;var c=e.measure,f=c.maps,h=n(a,u,r);if(h)return ol(h,l);for(var d=u.nextSibling,p=a?a.nodeValue.length-r:0;d;d=d.nextSibling){if(h=n(d,d.firstChild,0))return ol(E(h.line,h.ch-p),l);p+=d.textContent.length}for(var v=u.previousSibling,m=r;v;v=v.previousSibling){if(h=n(v,v.firstChild,-1))return ol(E(h.line,h.ch+m),l);m+=v.textContent.length}}var ul=navigator.userAgent,cl=navigator.platform,fl=/gecko\/\d/i.test(ul),hl=/MSIE \d/.test(ul),dl=/Trident\/(?:[7-9]|\d{2,})\..*rv:(\d+)/.exec(ul),pl=/Edge\/(\d+)/.exec(ul),gl=hl||dl||pl,vl=gl&&(hl?document.documentMode||6:+(pl||dl)[1]),ml=!pl&&/WebKit\//.test(ul),yl=ml&&/Qt\/\d+\.\d+/.test(ul),bl=!pl&&/Chrome\//.test(ul),wl=/Opera\//.test(ul),xl=/Apple Computer/.test(navigator.vendor),Cl=/Mac OS X 1\d\D([8-9]|\d\d)\D/.test(ul),Sl=/PhantomJS/.test(ul),Ll=!pl&&/AppleWebKit/.test(ul)&&/Mobile\/\w+/.test(ul),kl=/Android/.test(ul),Tl=Ll||kl||/webOS|BlackBerry|Opera Mini|Opera Mobi|IEMobile/i.test(ul),Ml=Ll||/Mac/.test(cl),Nl=/\bCrOS\b/.test(ul),Ol=/win/i.test(cl),Al=wl&&ul.match(/Version\/(\d*\.\d*)/);Al&&(Al=Number(Al[1])),Al&&Al>=15&&(wl=!1,ml=!0);var Wl,Dl=Ml&&(yl||wl&&(null==Al||Al<12.11)),Hl=fl||gl&&vl>=9,Fl=function(t,r){var n=t.className,i=e(r).exec(n);if(i){var o=n.slice(i.index+i[0].length);t.className=n.slice(0,i.index)+(o?i[1]+o:"")}};Wl=document.createRange?function(e,t,r,n){var i=document.createRange();return i.setEnd(n||e,r),i.setStart(e,t),i}:function(e,t,r){var n=document.body.createTextRange();try{n.moveToElementText(e.parentNode)}catch(e){return n}return n.collapse(!0),n.moveEnd("character",r),n.moveStart("character",t),n};var El=function(e){e.select()};Ll?El=function(e){e.selectionStart=0,e.selectionEnd=e.value.length}:gl&&(El=function(e){try{e.select()}catch(e){}});var Pl=function(){this.id=null};Pl.prototype.set=function(e,t){clearTimeout(this.id),this.id=setTimeout(t,e)};var Il,zl,Rl=30,Bl={toString:function(){return"CodeMirror.Pass"}},Gl={scroll:!1},Ul={origin:"*mouse"},Vl={origin:"+move"},Kl=[""],jl=/[\u00df\u0587\u0590-\u05f4\u0600-\u06ff\u3040-\u309f\u30a0-\u30ff\u3400-\u4db5\u4e00-\u9fcc\uac00-\ud7af]/,Xl=/[\u0300-\u036f\u0483-\u0489\u0591-\u05bd\u05bf\u05c1\u05c2\u05c4\u05c5\u05c7\u0610-\u061a\u064b-\u065e\u0670\u06d6-\u06dc\u06de-\u06e4\u06e7\u06e8\u06ea-\u06ed\u0711\u0730-\u074a\u07a6-\u07b0\u07eb-\u07f3\u0816-\u0819\u081b-\u0823\u0825-\u0827\u0829-\u082d\u0900-\u0902\u093c\u0941-\u0948\u094d\u0951-\u0955\u0962\u0963\u0981\u09bc\u09be\u09c1-\u09c4\u09cd\u09d7\u09e2\u09e3\u0a01\u0a02\u0a3c\u0a41\u0a42\u0a47\u0a48\u0a4b-\u0a4d\u0a51\u0a70\u0a71\u0a75\u0a81\u0a82\u0abc\u0ac1-\u0ac5\u0ac7\u0ac8\u0acd\u0ae2\u0ae3\u0b01\u0b3c\u0b3e\u0b3f\u0b41-\u0b44\u0b4d\u0b56\u0b57\u0b62\u0b63\u0b82\u0bbe\u0bc0\u0bcd\u0bd7\u0c3e-\u0c40\u0c46-\u0c48\u0c4a-\u0c4d\u0c55\u0c56\u0c62\u0c63\u0cbc\u0cbf\u0cc2\u0cc6\u0ccc\u0ccd\u0cd5\u0cd6\u0ce2\u0ce3\u0d3e\u0d41-\u0d44\u0d4d\u0d57\u0d62\u0d63\u0dca\u0dcf\u0dd2-\u0dd4\u0dd6\u0ddf\u0e31\u0e34-\u0e3a\u0e47-\u0e4e\u0eb1\u0eb4-\u0eb9\u0ebb\u0ebc\u0ec8-\u0ecd\u0f18\u0f19\u0f35\u0f37\u0f39\u0f71-\u0f7e\u0f80-\u0f84\u0f86\u0f87\u0f90-\u0f97\u0f99-\u0fbc\u0fc6\u102d-\u1030\u1032-\u1037\u1039\u103a\u103d\u103e\u1058\u1059\u105e-\u1060\u1071-\u1074\u1082\u1085\u1086\u108d\u109d\u135f\u1712-\u1714\u1732-\u1734\u1752\u1753\u1772\u1773\u17b7-\u17bd\u17c6\u17c9-\u17d3\u17dd\u180b-\u180d\u18a9\u1920-\u1922\u1927\u1928\u1932\u1939-\u193b\u1a17\u1a18\u1a56\u1a58-\u1a5e\u1a60\u1a62\u1a65-\u1a6c\u1a73-\u1a7c\u1a7f\u1b00-\u1b03\u1b34\u1b36-\u1b3a\u1b3c\u1b42\u1b6b-\u1b73\u1b80\u1b81\u1ba2-\u1ba5\u1ba8\u1ba9\u1c2c-\u1c33\u1c36\u1c37\u1cd0-\u1cd2\u1cd4-\u1ce0\u1ce2-\u1ce8\u1ced\u1dc0-\u1de6\u1dfd-\u1dff\u200c\u200d\u20d0-\u20f0\u2cef-\u2cf1\u2de0-\u2dff\u302a-\u302f\u3099\u309a\ua66f-\ua672\ua67c\ua67d\ua6f0\ua6f1\ua802\ua806\ua80b\ua825\ua826\ua8c4\ua8e0-\ua8f1\ua926-\ua92d\ua947-\ua951\ua980-\ua982\ua9b3\ua9b6-\ua9b9\ua9bc\uaa29-\uaa2e\uaa31\uaa32\uaa35\uaa36\uaa43\uaa4c\uaab0\uaab2-\uaab4\uaab7\uaab8\uaabe\uaabf\uaac1\uabe5\uabe8\uabed\udc00-\udfff\ufb1e\ufe00-\ufe0f\ufe20-\ufe26\uff9e\uff9f]/,Yl=!1,_l=!1,$l=null,ql=function(){function e(e){return e<=247?r.charAt(e):1424<=e&&e<=1524?"R":1536<=e&&e<=1785?n.charAt(e-1536):1774<=e&&e<=2220?"r":8192<=e&&e<=8203?"w":8204==e?"b":"L"}function t(e,t,r){this.level=e,this.from=t,this.to=r}var r="bbbbbbbbbtstwsbbbbbbbbbbbbbbssstwNN%%%NNNNNN,N,N1111111111NNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNbbbbbbsbbbbbbbbbbbbbbbbbbbbbbbbbb,N%%%%NNNNLNNNNN%%11NLNNN1LNNNNNLLLLLLLLLLLLLLLLLLLLLLLNLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLN",n="nnnnnnNNr%%r,rNNmmmmmmmmmmmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmmmmmmmmmmmmmmmnnnnnnnnnn%nnrrrmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmnNmmmmmmrrmmNmmmmrr1111111111",i=/[\u0590-\u05f4\u0600-\u06ff\u0700-\u08ac]/,o=/[stwN]/,l=/[LRr]/,s=/[Lb1n]/,a=/[1n]/;return function(r,n){var u="ltr"==n?"L":"R";if(0==r.length||"ltr"==n&&!i.test(r))return!1;for(var c=r.length,f=[],h=0;h<c;++h)f.push(e(r.charCodeAt(h)));for(var d=0,p=u;d<c;++d){var v=f[d];"m"==v?f[d]=p:p=v}for(var m=0,y=u;m<c;++m){var b=f[m];"1"==b&&"r"==y?f[m]="n":l.test(b)&&(y=b,"r"==b&&(f[m]="R"))}for(var w=1,x=f[0];w<c-1;++w){var C=f[w];"+"==C&&"1"==x&&"1"==f[w+1]?f[w]="1":","!=C||x!=f[w+1]||"1"!=x&&"n"!=x||(f[w]=x),x=C}for(var S=0;S<c;++S){var L=f[S];if(","==L)f[S]="N";else if("%"==L){var k=void 0;for(k=S+1;k<c&&"%"==f[k];++k);for(var T=S&&"!"==f[S-1]||k<c&&"1"==f[k]?"1":"N",M=S;M<k;++M)f[M]=T;S=k-1}}for(var N=0,O=u;N<c;++N){var A=f[N];"L"==O&&"1"==A?f[N]="L":l.test(A)&&(O=A)}for(var W=0;W<c;++W)if(o.test(f[W])){var D=void 0;for(D=W+1;D<c&&o.test(f[D]);++D);for(var H="L"==(W?f[W-1]:u),F=H==("L"==(D<c?f[D]:u))?H?"L":"R":u,E=W;E<D;++E)f[E]=F;W=D-1}for(var P,I=[],z=0;z<c;)if(s.test(f[z])){var R=z;for(++z;z<c&&s.test(f[z]);++z);I.push(new t(0,R,z))}else{var B=z,G=I.length;for(++z;z<c&&"L"!=f[z];++z);for(var U=B;U<z;)if(a.test(f[U])){B<U&&I.splice(G,0,new t(1,B,U));var V=U;for(++U;U<z&&a.test(f[U]);++U);I.splice(G,0,new t(2,V,U)),B=U}else++U;B<z&&I.splice(G,0,new t(1,B,z))}return 1==I[0].level&&(P=r.match(/^\s+/))&&(I[0].from=P[0].length,I.unshift(new t(0,0,P[0].length))),1==g(I).level&&(P=r.match(/\s+$/))&&(g(I).to-=P[0].length,I.push(new t(0,c-P[0].length,c))),"rtl"==n?I.reverse():I}}(),Zl=[],Ql=function(e,t,r){if(e.addEventListener)e.addEventListener(t,r,!1);else if(e.attachEvent)e.attachEvent("on"+t,r);else{var n=e._handlers||(e._handlers={});n[t]=(n[t]||Zl).concat(r)}},Jl=function(){if(gl&&vl<9)return!1;var e=n("div");return"draggable"in e||"dragDrop"in e}(),es=3!="\n\nb".split(/\n/).length?function(e){for(var t=0,r=[],n=e.length;t<=n;){var i=e.indexOf("\n",t);-1==i&&(i=e.length);var o=e.slice(t,"\r"==e.charAt(i-1)?i-1:i),l=o.indexOf("\r");-1!=l?(r.push(o.slice(0,l)),t+=l+1):(r.push(o),t=i+1)}return r}:function(e){return e.split(/\r\n?|\n/)},ts=window.getSelection?function(e){try{return e.selectionStart!=e.selectionEnd}catch(e){return!1}}:function(e){var t;try{t=e.ownerDocument.selection.createRange()}catch(e){}return!(!t||t.parentElement()!=e)&&0!=t.compareEndPoints("StartToEnd",t)},rs=function(){var e=n("div");return"oncopy"in e||(e.setAttribute("oncopy","return;"),"function"==typeof e.oncopy)}(),ns=null,is={},os={},ls={},ss=function(e,t,r){this.pos=this.start=0,this.string=e,this.tabSize=t||8,this.lastColumnPos=this.lastColumnValue=0,this.lineStart=0,this.lineOracle=r};ss.prototype.eol=function(){return this.pos>=this.string.length},ss.prototype.sol=function(){return this.pos==this.lineStart},ss.prototype.peek=function(){return this.string.charAt(this.pos)||void 0},ss.prototype.next=function(){if(this.pos<this.string.length)return this.string.charAt(this.pos++)},ss.prototype.eat=function(e){var t=this.string.charAt(this.pos);if("string"==typeof e?t==e:t&&(e.test?e.test(t):e(t)))return++this.pos,t},ss.prototype.eatWhile=function(e){for(var t=this.pos;this.eat(e););return this.pos>t},ss.prototype.eatSpace=function(){for(var e=this,t=this.pos;/[\s\u00a0]/.test(this.string.charAt(this.pos));)++e.pos;return this.pos>t},ss.prototype.skipToEnd=function(){this.pos=this.string.length},ss.prototype.skipTo=function(e){var t=this.string.indexOf(e,this.pos);if(t>-1)return this.pos=t,!0},ss.prototype.backUp=function(e){this.pos-=e},ss.prototype.column=function(){return this.lastColumnPos<this.start&&(this.lastColumnValue=f(this.string,this.start,this.tabSize,this.lastColumnPos,this.lastColumnValue),this.lastColumnPos=this.start),this.lastColumnValue-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.indentation=function(){return f(this.string,null,this.tabSize)-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.match=function(e,t,r){if("string"!=typeof e){var n=this.string.slice(this.pos).match(e);return n&&n.index>0?null:(n&&!1!==t&&(this.pos+=n[0].length),n)}var i=function(e){return r?e.toLowerCase():e};if(i(this.string.substr(this.pos,e.length))==i(e))return!1!==t&&(this.pos+=e.length),!0},ss.prototype.current=function(){return this.string.slice(this.start,this.pos)},ss.prototype.hideFirstChars=function(e,t){this.lineStart+=e;try{return t()}finally{this.lineStart-=e}},ss.prototype.lookAhead=function(e){var t=this.lineOracle;return t&&t.lookAhead(e)};var as=function(e,t){this.state=e,this.lookAhead=t},us=function(e,t,r,n){this.state=t,this.doc=e,this.line=r,this.maxLookAhead=n||0};us.prototype.lookAhead=function(e){var t=this.doc.getLine(this.line+e);return null!=t&&e>this.maxLookAhead&&(this.maxLookAhead=e),t},us.prototype.nextLine=function(){this.line++,this.maxLookAhead>0&&this.maxLookAhead--},us.fromSaved=function(e,t,r){return t instanceof as?new us(e,Ke(e.mode,t.state),r,t.lookAhead):new us(e,Ke(e.mode,t),r)},us.prototype.save=function(e){var t=!1!==e?Ke(this.doc.mode,this.state):this.state;return this.maxLookAhead>0?new as(t,this.maxLookAhead):t};var cs=function(e,t,r){this.start=e.start,this.end=e.pos,this.string=e.current(),this.type=t||null,this.state=r},fs=function(e,t,r){this.text=e,ne(this,t),this.height=r?r(this):1};fs.prototype.lineNo=function(){return W(this)},Ae(fs);var hs,ds={},ps={},gs=null,vs=null,ms={left:0,right:0,top:0,bottom:0},ys=function(e,t,r){this.cm=r;var i=this.vert=n("div",[n("div",null,null,"min-width: 1px")],"CodeMirror-vscrollbar"),o=this.horiz=n("div",[n("div",null,null,"height: 100%; min-height: 1px")],"CodeMirror-hscrollbar");e(i),e(o),Ql(i,"scroll",function(){i.clientHeight&&t(i.scrollTop,"vertical")}),Ql(o,"scroll",function(){o.clientWidth&&t(o.scrollLeft,"horizontal")}),this.checkedZeroWidth=!1,gl&&vl<8&&(this.horiz.style.minHeight=this.vert.style.minWidth="18px")};ys.prototype.update=function(e){var t=e.scrollWidth>e.clientWidth+1,r=e.scrollHeight>e.clientHeight+1,n=e.nativeBarWidth;if(r){this.vert.style.display="block",this.vert.style.bottom=t?n+"px":"0";var i=e.viewHeight-(t?n:0);this.vert.firstChild.style.height=Math.max(0,e.scrollHeight-e.clientHeight+i)+"px"}else this.vert.style.display="",this.vert.firstChild.style.height="0";if(t){this.horiz.style.display="block",this.horiz.style.right=r?n+"px":"0",this.horiz.style.left=e.barLeft+"px";var o=e.viewWidth-e.barLeft-(r?n:0);this.horiz.firstChild.style.width=Math.max(0,e.scrollWidth-e.clientWidth+o)+"px"}else this.horiz.style.display="",this.horiz.firstChild.style.width="0";return!this.checkedZeroWidth&&e.clientHeight>0&&(0==n&&this.zeroWidthHack(),this.checkedZeroWidth=!0),{right:r?n:0,bottom:t?n:0}},ys.prototype.setScrollLeft=function(e){this.horiz.scrollLeft!=e&&(this.horiz.scrollLeft=e),this.disableHoriz&&this.enableZeroWidthBar(this.horiz,this.disableHoriz,"horiz")},ys.prototype.setScrollTop=function(e){this.vert.scrollTop!=e&&(this.vert.scrollTop=e),this.disableVert&&this.enableZeroWidthBar(this.vert,this.disableVert,"vert")},ys.prototype.zeroWidthHack=function(){var e=Ml&&!Cl?"12px":"18px";this.horiz.style.height=this.vert.style.width=e,this.horiz.style.pointerEvents=this.vert.style.pointerEvents="none",this.disableHoriz=new Pl,this.disableVert=new Pl},ys.prototype.enableZeroWidthBar=function(e,t,r){function n(){var i=e.getBoundingClientRect();("vert"==r?document.elementFromPoint(i.right-1,(i.top+i.bottom)/2):document.elementFromPoint((i.right+i.left)/2,i.bottom-1))!=e?e.style.pointerEvents="none":t.set(1e3,n)}e.style.pointerEvents="auto",t.set(1e3,n)},ys.prototype.clear=function(){var e=this.horiz.parentNode;e.removeChild(this.horiz),e.removeChild(this.vert)};var bs=function(){};bs.prototype.update=function(){return{bottom:0,right:0}},bs.prototype.setScrollLeft=function(){},bs.prototype.setScrollTop=function(){},bs.prototype.clear=function(){};var ws={native:ys,null:bs},xs=0,Cs=function(e,t,r){var n=e.display;this.viewport=t,this.visible=Ir(n,e.doc,t),this.editorIsHidden=!n.wrapper.offsetWidth,this.wrapperHeight=n.wrapper.clientHeight,this.wrapperWidth=n.wrapper.clientWidth,this.oldDisplayWidth=Rt(e),this.force=r,this.dims=br(e),this.events=[]};Cs.prototype.signal=function(e,t){Oe(e,t)&&this.events.push(arguments)},Cs.prototype.finish=function(){for(var e=this,t=0;t<this.events.length;t++)Te.apply(null,e.events[t])};var Ss=0,Ls=null;gl?Ls=-.53:fl?Ls=15:bl?Ls=-.7:xl&&(Ls=-1/3);var ks=function(e,t){this.ranges=e,this.primIndex=t};ks.prototype.primary=function(){return this.ranges[this.primIndex]},ks.prototype.equals=function(e){var t=this;if(e==this)return!0;if(e.primIndex!=this.primIndex||e.ranges.length!=this.ranges.length)return!1;for(var r=0;r<this.ranges.length;r++){var n=t.ranges[r],i=e.ranges[r];if(!I(n.anchor,i.anchor)||!I(n.head,i.head))return!1}return!0},ks.prototype.deepCopy=function(){for(var e=this,t=[],r=0;r<this.ranges.length;r++)t[r]=new Ts(z(e.ranges[r].anchor),z(e.ranges[r].head));return new ks(t,this.primIndex)},ks.prototype.somethingSelected=function(){for(var e=this,t=0;t<this.ranges.length;t++)if(!e.ranges[t].empty())return!0;return!1},ks.prototype.contains=function(e,t){var r=this;t||(t=e);for(var n=0;n<this.ranges.length;n++){var i=r.ranges[n];if(P(t,i.from())>=0&&P(e,i.to())<=0)return n}return-1};var Ts=function(e,t){this.anchor=e,this.head=t};Ts.prototype.from=function(){return B(this.anchor,this.head)},Ts.prototype.to=function(){return R(this.anchor,this.head)},Ts.prototype.empty=function(){return this.head.line==this.anchor.line&&this.head.ch==this.anchor.ch},Bi.prototype={chunkSize:function(){return this.lines.length},removeInner:function(e,t){for(var r=this,n=e,i=e+t;n<i;++n){var o=r.lines[n];r.height-=o.height,ot(o),bt(o,"delete")}this.lines.splice(e,t)},collapse:function(e){e.push.apply(e,this.lines)},insertInner:function(e,t,r){var n=this;this.height+=r,this.lines=this.lines.slice(0,e).concat(t).concat(this.lines.slice(e));for(var i=0;i<t.length;++i)t[i].parent=n},iterN:function(e,t,r){for(var n=this,i=e+t;e<i;++e)if(r(n.lines[e]))return!0}},Gi.prototype={chunkSize:function(){return this.size},removeInner:function(e,t){var r=this;this.size-=t;for(var n=0;n<this.children.length;++n){var i=r.children[n],o=i.chunkSize();if(e<o){var l=Math.min(t,o-e),s=i.height;if(i.removeInner(e,l),r.height-=s-i.height,o==l&&(r.children.splice(n--,1),i.parent=null),0==(t-=l))break;e=0}else e-=o}if(this.size-t<25&&(this.children.length>1||!(this.children[0]instanceof Bi))){var a=[];this.collapse(a),this.children=[new Bi(a)],this.children[0].parent=this}},collapse:function(e){for(var t=this,r=0;r<this.children.length;++r)t.children[r].collapse(e)},insertInner:function(e,t,r){var n=this;this.size+=t.length,this.height+=r;for(var i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<=l){if(o.insertInner(e,t,r),o.lines&&o.lines.length>50){for(var s=o.lines.length%25+25,a=s;a<o.lines.length;){var u=new Bi(o.lines.slice(a,a+=25));o.height-=u.height,n.children.splice(++i,0,u),u.parent=n}o.lines=o.lines.slice(0,s),n.maybeSpill()}break}e-=l}},maybeSpill:function(){if(!(this.children.length<=10)){var e=this;do{var t=new Gi(e.children.splice(e.children.length-5,5));if(e.parent){e.size-=t.size,e.height-=t.height;var r=h(e.parent.children,e);e.parent.children.splice(r+1,0,t)}else{var n=new Gi(e.children);n.parent=e,e.children=[n,t],e=n}t.parent=e.parent}while(e.children.length>10);e.parent.maybeSpill()}},iterN:function(e,t,r){for(var n=this,i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<l){var s=Math.min(t,l-e);if(o.iterN(e,s,r))return!0;if(0==(t-=s))break;e=0}else e-=l}}};var Ms=function(e,t,r){var n=this;if(r)for(var i in r)r.hasOwnProperty(i)&&(n[i]=r[i]);this.doc=e,this.node=t};Ms.prototype.clear=function(){var e=this,t=this.doc.cm,r=this.line.widgets,n=this.line,i=W(n);if(null!=i&&r){for(var o=0;o<r.length;++o)r[o]==e&&r.splice(o--,1);r.length||(n.widgets=null);var l=Ht(this);A(n,Math.max(0,n.height-l)),t&&(hn(t,function(){Ui(t,n,-l),mn(t,i,"widget")}),bt(t,"lineWidgetCleared",t,this,i))}},Ms.prototype.changed=function(){var e=this,t=this.height,r=this.doc.cm,n=this.line;this.height=null;var i=Ht(this)-t;i&&(A(n,n.height+i),r&&hn(r,function(){r.curOp.forceUpdate=!0,Ui(r,n,i),bt(r,"lineWidgetChanged",r,e,W(n))}))},Ae(Ms);var Ns=0,Os=function(e,t){this.lines=[],this.type=t,this.doc=e,this.id=++Ns};Os.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){var t=this.doc.cm,r=t&&!t.curOp;if(r&&nn(t),Oe(this,"clear")){var n=this.find();n&&bt(this,"clear",n.from,n.to)}for(var i=null,o=null,l=0;l<this.lines.length;++l){var s=e.lines[l],a=_(s.markedSpans,e);t&&!e.collapsed?mn(t,W(s),"text"):t&&(null!=a.to&&(o=W(s)),null!=a.from&&(i=W(s))),s.markedSpans=$(s.markedSpans,a),null==a.from&&e.collapsed&&!ve(e.doc,s)&&t&&A(s,mr(t.display))}if(t&&this.collapsed&&!t.options.lineWrapping)for(var u=0;u<this.lines.length;++u){var c=fe(e.lines[u]),f=be(c);f>t.display.maxLineLength&&(t.display.maxLine=c,t.display.maxLineLength=f,t.display.maxLineChanged=!0)}null!=i&&t&&this.collapsed&&vn(t,i,o+1),this.lines.length=0,this.explicitlyCleared=!0,this.atomic&&this.doc.cantEdit&&(this.doc.cantEdit=!1,t&&Ci(t.doc)),t&&bt(t,"markerCleared",t,this,i,o),r&&on(t),this.parent&&this.parent.clear()}},Os.prototype.find=function(e,t){var r=this;null==e&&"bookmark"==this.type&&(e=1);for(var n,i,o=0;o<this.lines.length;++o){var l=r.lines[o],s=_(l.markedSpans,r);if(null!=s.from&&(n=E(t?l:W(l),s.from),-1==e))return n;if(null!=s.to&&(i=E(t?l:W(l),s.to),1==e))return i}return n&&{from:n,to:i}},Os.prototype.changed=function(){var e=this,t=this.find(-1,!0),r=this,n=this.doc.cm;t&&n&&hn(n,function(){var i=t.line,o=W(t.line),l=jt(n,o);if(l&&(Qt(l),n.curOp.selectionChanged=n.curOp.forceUpdate=!0),n.curOp.updateMaxLine=!0,!ve(r.doc,i)&&null!=r.height){var s=r.height;r.height=null;var a=Ht(r)-s;a&&A(i,i.height+a)}bt(n,"markerChanged",n,e)})},Os.prototype.attachLine=function(e){if(!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;t.maybeHiddenMarkers&&-1!=h(t.maybeHiddenMarkers,this)||(t.maybeUnhiddenMarkers||(t.maybeUnhiddenMarkers=[])).push(this)}this.lines.push(e)},Os.prototype.detachLine=function(e){if(this.lines.splice(h(this.lines,e),1),!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;(t.maybeHiddenMarkers||(t.maybeHiddenMarkers=[])).push(this)}},Ae(Os);var As=function(e,t){var r=this;this.markers=e,this.primary=t;for(var n=0;n<e.length;++n)e[n].parent=r};As.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){this.explicitlyCleared=!0;for(var t=0;t<this.markers.length;++t)e.markers[t].clear();bt(this,"clear")}},As.prototype.find=function(e,t){return this.primary.find(e,t)},Ae(As);var Ws=0,Ds=function(e,t,r,n,i){if(!(this instanceof Ds))return new Ds(e,t,r,n,i);null==r&&(r=0),Gi.call(this,[new Bi([new fs("",null)])]),this.first=r,this.scrollTop=this.scrollLeft=0,this.cantEdit=!1,this.cleanGeneration=1,this.modeFrontier=this.highlightFrontier=r;var o=E(r,0);this.sel=Rn(o),this.history=new Jn(null),this.id=++Ws,this.modeOption=t,this.lineSep=n,this.direction="rtl"==i?"rtl":"ltr",this.extend=!1,"string"==typeof e&&(e=this.splitLines(e)),_n(this,{from:o,to:o,text:e}),bi(this,Rn(o),Gl)};Ds.prototype=b(Gi.prototype,{constructor:Ds,iter:function(e,t,r){r?this.iterN(e-this.first,t-e,r):this.iterN(this.first,this.first+this.size,e)},insert:function(e,t){for(var r=0,n=0;n<t.length;++n)r+=t[n].height;this.insertInner(e-this.first,t,r)},remove:function(e,t){this.removeInner(e-this.first,t)},getValue:function(e){var t=O(this,this.first,this.first+this.size);return!1===e?t:t.join(e||this.lineSeparator())},setValue:gn(function(e){var t=E(this.first,0),r=this.first+this.size-1;Oi(this,{from:t,to:E(r,M(this,r).text.length),text:this.splitLines(e),origin:"setValue",full:!0},!0),this.cm&&Xr(this.cm,0,0),bi(this,Rn(t),Gl)}),replaceRange:function(e,t,r,n){Ei(this,e,t=U(this,t),r=r?U(this,r):t,n)},getRange:function(e,t,r){var n=N(this,U(this,e),U(this,t));return!1===r?n:n.join(r||this.lineSeparator())},getLine:function(e){var t=this.getLineHandle(e);return t&&t.text},getLineHandle:function(e){if(H(this,e))return M(this,e)},getLineNumber:function(e){return W(e)},getLineHandleVisualStart:function(e){return"number"==typeof e&&(e=M(this,e)),fe(e)},lineCount:function(){return this.size},firstLine:function(){return this.first},lastLine:function(){return this.first+this.size-1},clipPos:function(e){return U(this,e)},getCursor:function(e){var t=this.sel.primary();return null==e||"head"==e?t.head:"anchor"==e?t.anchor:"end"==e||"to"==e||!1===e?t.to():t.from()},listSelections:function(){return this.sel.ranges},somethingSelected:function(){return this.sel.somethingSelected()},setCursor:gn(function(e,t,r){vi(this,U(this,"number"==typeof e?E(e,t||0):e),null,r)}),setSelection:gn(function(e,t,r){vi(this,U(this,e),U(this,t||e),r)}),extendSelection:gn(function(e,t,r){di(this,U(this,e),t&&U(this,t),r)}),extendSelections:gn(function(e,t){pi(this,K(this,e),t)}),extendSelectionsBy:gn(function(e,t){pi(this,K(this,v(this.sel.ranges,e)),t)}),setSelections:gn(function(e,t,r){var n=this;if(e.length){for(var i=[],o=0;o<e.length;o++)i[o]=new Ts(U(n,e[o].anchor),U(n,e[o].head));null==t&&(t=Math.min(e.length-1,this.sel.primIndex)),bi(this,zn(i,t),r)}}),addSelection:gn(function(e,t,r){var n=this.sel.ranges.slice(0);n.push(new Ts(U(this,e),U(this,t||e))),bi(this,zn(n,n.length-1),r)}),getSelection:function(e){for(var t,r=this,n=this.sel.ranges,i=0;i<n.length;i++){var o=N(r,n[i].from(),n[i].to());t=t?t.concat(o):o}return!1===e?t:t.join(e||this.lineSeparator())},getSelections:function(e){for(var t=this,r=[],n=this.sel.ranges,i=0;i<n.length;i++){var o=N(t,n[i].from(),n[i].to());!1!==e&&(o=o.join(e||t.lineSeparator())),r[i]=o}return r},replaceSelection:function(e,t,r){for(var n=[],i=0;i<this.sel.ranges.length;i++)n[i]=e;this.replaceSelections(n,t,r||"+input")},replaceSelections:gn(function(e,t,r){for(var n=this,i=[],o=this.sel,l=0;l<o.ranges.length;l++){var s=o.ranges[l];i[l]={from:s.from(),to:s.to(),text:n.splitLines(e[l]),origin:r}}for(var a=t&&"end"!=t&&Kn(this,i,t),u=i.length-1;u>=0;u--)Oi(n,i[u]);a?yi(this,a):this.cm&&jr(this.cm)}),undo:gn(function(){Wi(this,"undo")}),redo:gn(function(){Wi(this,"redo")}),undoSelection:gn(function(){Wi(this,"undo",!0)}),redoSelection:gn(function(){Wi(this,"redo",!0)}),setExtending:function(e){this.extend=e},getExtending:function(){return this.extend},historySize:function(){for(var e=this.history,t=0,r=0,n=0;n<e.done.length;n++)e.done[n].ranges||++t;for(var i=0;i<e.undone.length;i++)e.undone[i].ranges||++r;return{undo:t,redo:r}},clearHistory:function(){this.history=new Jn(this.history.maxGeneration)},markClean:function(){this.cleanGeneration=this.changeGeneration(!0)},changeGeneration:function(e){return e&&(this.history.lastOp=this.history.lastSelOp=this.history.lastOrigin=null),this.history.generation},isClean:function(e){return this.history.generation==(e||this.cleanGeneration)},getHistory:function(){return{done:fi(this.history.done),undone:fi(this.history.undone)}},setHistory:function(e){var t=this.history=new Jn(this.history.maxGeneration);t.done=fi(e.done.slice(0),null,!0),t.undone=fi(e.undone.slice(0),null,!0)},setGutterMarker:gn(function(e,t,r){return Ri(this,e,"gutter",function(e){var n=e.gutterMarkers||(e.gutterMarkers={});return n[t]=r,!r&&C(n)&&(e.gutterMarkers=null),!0})}),clearGutter:gn(function(e){var t=this;this.iter(function(r){r.gutterMarkers&&r.gutterMarkers[e]&&Ri(t,r,"gutter",function(){return r.gutterMarkers[e]=null,C(r.gutterMarkers)&&(r.gutterMarkers=null),!0})})}),lineInfo:function(e){var t;if("number"==typeof e){if(!H(this,e))return null;if(t=e,!(e=M(this,e)))return null}else if(null==(t=W(e)))return null;return{line:t,handle:e,text:e.text,gutterMarkers:e.gutterMarkers,textClass:e.textClass,bgClass:e.bgClass,wrapClass:e.wrapClass,widgets:e.widgets}},addLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass";if(t[i]){if(e(n).test(t[i]))return!1;t[i]+=" "+n}else t[i]=n;return!0})}),removeLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass",o=t[i];if(!o)return!1;if(null==n)t[i]=null;else{var l=o.match(e(n));if(!l)return!1;var s=l.index+l[0].length;t[i]=o.slice(0,l.index)+(l.index&&s!=o.length?" ":"")+o.slice(s)||null}return!0})}),addLineWidget:gn(function(e,t,r){return Vi(this,e,t,r)}),removeLineWidget:function(e){e.clear()},markText:function(e,t,r){return Ki(this,U(this,e),U(this,t),r,r&&r.type||"range")},setBookmark:function(e,t){var r={replacedWith:t&&(null==t.nodeType?t.widget:t),insertLeft:t&&t.insertLeft,clearWhenEmpty:!1,shared:t&&t.shared,handleMouseEvents:t&&t.handleMouseEvents};return e=U(this,e),Ki(this,e,e,r,"bookmark")},findMarksAt:function(e){var t=[],r=M(this,(e=U(this,e)).line).markedSpans;if(r)for(var n=0;n<r.length;++n){var i=r[n];(null==i.from||i.from<=e.ch)&&(null==i.to||i.to>=e.ch)&&t.push(i.marker.parent||i.marker)}return t},findMarks:function(e,t,r){e=U(this,e),t=U(this,t);var n=[],i=e.line;return this.iter(e.line,t.line+1,function(o){var l=o.markedSpans;if(l)for(var s=0;s<l.length;s++){var a=l[s];null!=a.to&&i==e.line&&e.ch>=a.to||null==a.from&&i!=e.line||null!=a.from&&i==t.line&&a.from>=t.ch||r&&!r(a.marker)||n.push(a.marker.parent||a.marker)}++i}),n},getAllMarks:function(){var e=[];return this.iter(function(t){var r=t.markedSpans;if(r)for(var n=0;n<r.length;++n)null!=r[n].from&&e.push(r[n].marker)}),e},posFromIndex:function(e){var t,r=this.first,n=this.lineSeparator().length;return this.iter(function(i){var o=i.text.length+n;if(o>e)return t=e,!0;e-=o,++r}),U(this,E(r,t))},indexFromPos:function(e){var t=(e=U(this,e)).ch;if(e.line<this.first||e.ch<0)return 0;var r=this.lineSeparator().length;return this.iter(this.first,e.line,function(e){t+=e.text.length+r}),t},copy:function(e){var t=new Ds(O(this,this.first,this.first+this.size),this.modeOption,this.first,this.lineSep,this.direction);return t.scrollTop=this.scrollTop,t.scrollLeft=this.scrollLeft,t.sel=this.sel,t.extend=!1,e&&(t.history.undoDepth=this.history.undoDepth,t.setHistory(this.getHistory())),t},linkedDoc:function(e){e||(e={});var t=this.first,r=this.first+this.size;null!=e.from&&e.from>t&&(t=e.from),null!=e.to&&e.to<r&&(r=e.to);var n=new Ds(O(this,t,r),e.mode||this.modeOption,t,this.lineSep,this.direction);return e.sharedHist&&(n.history=this.history),(this.linked||(this.linked=[])).push({doc:n,sharedHist:e.sharedHist}),n.linked=[{doc:this,isParent:!0,sharedHist:e.sharedHist}],Yi(n,Xi(this)),n},unlinkDoc:function(e){var t=this;if(e instanceof jo&&(e=e.doc),this.linked)for(var r=0;r<this.linked.length;++r)if(t.linked[r].doc==e){t.linked.splice(r,1),e.unlinkDoc(t),_i(Xi(t));break}if(e.history==this.history){var n=[e.id];$n(e,function(e){return n.push(e.id)},!0),e.history=new Jn(null),e.history.done=fi(this.history.done,n),e.history.undone=fi(this.history.undone,n)}},iterLinkedDocs:function(e){$n(this,e)},getMode:function(){return this.mode},getEditor:function(){return this.cm},splitLines:function(e){return this.lineSep?e.split(this.lineSep):es(e)},lineSeparator:function(){return this.lineSep||"\n"},setDirection:gn(function(e){"rtl"!=e&&(e="ltr"),e!=this.direction&&(this.direction=e,this.iter(function(e){return e.order=null}),this.cm&&Qn(this.cm))})}),Ds.prototype.eachLine=Ds.prototype.iter;for(var Hs=0,Fs=!1,Es={3:"Enter",8:"Backspace",9:"Tab",13:"Enter",16:"Shift",17:"Ctrl",18:"Alt",19:"Pause",20:"CapsLock",27:"Esc",32:"Space",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"Left",38:"Up",39:"Right",40:"Down",44:"PrintScrn",45:"Insert",46:"Delete",59:";",61:"=",91:"Mod",92:"Mod",93:"Mod",106:"*",107:"=",109:"-",110:".",111:"/",127:"Delete",173:"-",186:";",187:"=",188:",",189:"-",190:".",191:"/",192:"`",219:"[",220:"\\",221:"]",222:"'",63232:"Up",63233:"Down",63234:"Left",63235:"Right",63272:"Delete",63273:"Home",63275:"End",63276:"PageUp",63277:"PageDown",63302:"Insert"},Ps=0;Ps<10;Ps++)Es[Ps+48]=Es[Ps+96]=String(Ps);for(var Is=65;Is<=90;Is++)Es[Is]=String.fromCharCode(Is);for(var zs=1;zs<=12;zs++)Es[zs+111]=Es[zs+63235]="F"+zs;var Rs={};Rs.basic={Left:"goCharLeft",Right:"goCharRight",Up:"goLineUp",Down:"goLineDown",End:"goLineEnd",Home:"goLineStartSmart",PageUp:"goPageUp",PageDown:"goPageDown",Delete:"delCharAfter",Backspace:"delCharBefore","Shift-Backspace":"delCharBefore",Tab:"defaultTab","Shift-Tab":"indentAuto",Enter:"newlineAndIndent",Insert:"toggleOverwrite",Esc:"singleSelection"},Rs.pcDefault={"Ctrl-A":"selectAll","Ctrl-D":"deleteLine","Ctrl-Z":"undo","Shift-Ctrl-Z":"redo","Ctrl-Y":"redo","Ctrl-Home":"goDocStart","Ctrl-End":"goDocEnd","Ctrl-Up":"goLineUp","Ctrl-Down":"goLineDown","Ctrl-Left":"goGroupLeft","Ctrl-Right":"goGroupRight","Alt-Left":"goLineStart","Alt-Right":"goLineEnd","Ctrl-Backspace":"delGroupBefore","Ctrl-Delete":"delGroupAfter","Ctrl-S":"save","Ctrl-F":"find","Ctrl-G":"findNext","Shift-Ctrl-G":"findPrev","Shift-Ctrl-F":"replace","Shift-Ctrl-R":"replaceAll","Ctrl-[":"indentLess","Ctrl-]":"indentMore","Ctrl-U":"undoSelection","Shift-Ctrl-U":"redoSelection","Alt-U":"redoSelection",fallthrough:"basic"},Rs.emacsy={"Ctrl-F":"goCharRight","Ctrl-B":"goCharLeft","Ctrl-P":"goLineUp","Ctrl-N":"goLineDown","Alt-F":"goWordRight","Alt-B":"goWordLeft","Ctrl-A":"goLineStart","Ctrl-E":"goLineEnd","Ctrl-V":"goPageDown","Shift-Ctrl-V":"goPageUp","Ctrl-D":"delCharAfter","Ctrl-H":"delCharBefore","Alt-D":"delWordAfter","Alt-Backspace":"delWordBefore","Ctrl-K":"killLine","Ctrl-T":"transposeChars","Ctrl-O":"openLine"},Rs.macDefault={"Cmd-A":"selectAll","Cmd-D":"deleteLine","Cmd-Z":"undo","Shift-Cmd-Z":"redo","Cmd-Y":"redo","Cmd-Home":"goDocStart","Cmd-Up":"goDocStart","Cmd-End":"goDocEnd","Cmd-Down":"goDocEnd","Alt-Left":"goGroupLeft","Alt-Right":"goGroupRight","Cmd-Left":"goLineLeft","Cmd-Right":"goLineRight","Alt-Backspace":"delGroupBefore","Ctrl-Alt-Backspace":"delGroupAfter","Alt-Delete":"delGroupAfter","Cmd-S":"save","Cmd-F":"find","Cmd-G":"findNext","Shift-Cmd-G":"findPrev","Cmd-Alt-F":"replace","Shift-Cmd-Alt-F":"replaceAll","Cmd-[":"indentLess","Cmd-]":"indentMore","Cmd-Backspace":"delWrappedLineLeft","Cmd-Delete":"delWrappedLineRight","Cmd-U":"undoSelection","Shift-Cmd-U":"redoSelection","Ctrl-Up":"goDocStart","Ctrl-Down":"goDocEnd",fallthrough:["basic","emacsy"]},Rs.default=Ml?Rs.macDefault:Rs.pcDefault;var Bs={selectAll:Mi,singleSelection:function(e){return e.setSelection(e.getCursor("anchor"),e.getCursor("head"),Gl)},killLine:function(e){return co(e,function(t){if(t.empty()){var r=M(e.doc,t.head.line).text.length;return t.head.ch==r&&t.head.line<e.lastLine()?{from:t.head,to:E(t.head.line+1,0)}:{from:t.head,to:E(t.head.line,r)}}return{from:t.from(),to:t.to()}})},deleteLine:function(e){return co(e,function(t){return{from:E(t.from().line,0),to:U(e.doc,E(t.to().line+1,0))}})},delLineLeft:function(e){return co(e,function(e){return{from:E(e.from().line,0),to:e.from()}})},delWrappedLineLeft:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5;return{from:e.coordsChar({left:0,top:r},"div"),to:t.from()}})},delWrappedLineRight:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5,n=e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div");return{from:t.from(),to:n}})},undo:function(e){return e.undo()},redo:function(e){return e.redo()},undoSelection:function(e){return e.undoSelection()},redoSelection:function(e){return e.redoSelection()},goDocStart:function(e){return e.extendSelection(E(e.firstLine(),0))},goDocEnd:function(e){return e.extendSelection(E(e.lastLine()))},goLineStart:function(e){return e.extendSelectionsBy(function(t){return vo(e,t.head.line)},{origin:"+move",bias:1})},goLineStartSmart:function(e){return e.extendSelectionsBy(function(t){return yo(e,t.head)},{origin:"+move",bias:1})},goLineEnd:function(e){return e.extendSelectionsBy(function(t){return mo(e,t.head.line)},{origin:"+move",bias:-1})},goLineRight:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div")},Vl)},goLineLeft:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:0,top:r},"div")},Vl)},goLineLeftSmart:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5,n=e.coordsChar({left:0,top:r},"div");return n.ch<e.getLine(n.line).search(/\S/)?yo(e,t.head):n},Vl)},goLineUp:function(e){return e.moveV(-1,"line")},goLineDown:function(e){return e.moveV(1,"line")},goPageUp:function(e){return e.moveV(-1,"page")},goPageDown:function(e){return e.moveV(1,"page")},goCharLeft:function(e){return e.moveH(-1,"char")},goCharRight:function(e){return e.moveH(1,"char")},goColumnLeft:function(e){return e.moveH(-1,"column")},goColumnRight:function(e){return e.moveH(1,"column")},goWordLeft:function(e){return e.moveH(-1,"word")},goGroupRight:function(e){return e.moveH(1,"group")},goGroupLeft:function(e){return e.moveH(-1,"group")},goWordRight:function(e){return e.moveH(1,"word")},delCharBefore:function(e){return e.deleteH(-1,"char")},delCharAfter:function(e){return e.deleteH(1,"char")},delWordBefore:function(e){return e.deleteH(-1,"word")},delWordAfter:function(e){return e.deleteH(1,"word")},delGroupBefore:function(e){return e.deleteH(-1,"group")},delGroupAfter:function(e){return e.deleteH(1,"group")},indentAuto:function(e){return e.indentSelection("smart")},indentMore:function(e){return e.indentSelection("add")},indentLess:function(e){return e.indentSelection("subtract")},insertTab:function(e){return e.replaceSelection("\t")},insertSoftTab:function(e){for(var t=[],r=e.listSelections(),n=e.options.tabSize,i=0;i<r.length;i++){var o=r[i].from(),l=f(e.getLine(o.line),o.ch,n);t.push(p(n-l%n))}e.replaceSelections(t)},defaultTab:function(e){e.somethingSelected()?e.indentSelection("add"):e.execCommand("insertTab")},transposeChars:function(e){return hn(e,function(){for(var t=e.listSelections(),r=[],n=0;n<t.length;n++)if(t[n].empty()){var i=t[n].head,o=M(e.doc,i.line).text;if(o)if(i.ch==o.length&&(i=new E(i.line,i.ch-1)),i.ch>0)i=new E(i.line,i.ch+1),e.replaceRange(o.charAt(i.ch-1)+o.charAt(i.ch-2),E(i.line,i.ch-2),i,"+transpose");else if(i.line>e.doc.first){var l=M(e.doc,i.line-1).text;l&&(i=new E(i.line,1),e.replaceRange(o.charAt(0)+e.doc.lineSeparator()+l.charAt(l.length-1),E(i.line-1,l.length-1),i,"+transpose"))}r.push(new Ts(i,i))}e.setSelections(r)})},newlineAndIndent:function(e){return hn(e,function(){for(var t=e.listSelections(),r=t.length-1;r>=0;r--)e.replaceRange(e.doc.lineSeparator(),t[r].anchor,t[r].head,"+input");t=e.listSelections();for(var n=0;n<t.length;n++)e.indentLine(t[n].from().line,null,!0);jr(e)})},openLine:function(e){return e.replaceSelection("\n","start")},toggleOverwrite:function(e){return e.toggleOverwrite()}},Gs=new Pl,Us=null,Vs=function(e,t,r){this.time=e,this.pos=t,this.button=r};Vs.prototype.compare=function(e,t,r){return this.time+400>e&&0==P(t,this.pos)&&r==this.button};var Ks,js,Xs={toString:function(){return"CodeMirror.Init"}},Ys={},_s={};jo.defaults=Ys,jo.optionHandlers=_s;var $s=[];jo.defineInitHook=function(e){return $s.push(e)};var qs=null,Zs=function(e){this.cm=e,this.lastAnchorNode=this.lastAnchorOffset=this.lastFocusNode=this.lastFocusOffset=null,this.polling=new Pl,this.composing=null,this.gracePeriod=!1,this.readDOMTimeout=null};Zs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()}),"cut"==e.type&&i.replaceSelection("",null,"cut");else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type&&i.operation(function(){i.setSelections(t.ranges,0,Gl),i.replaceSelection("",null,"cut")})}if(e.clipboardData){e.clipboardData.clearData();var r=qs.text.join("\n");if(e.clipboardData.setData("Text",r),e.clipboardData.getData("Text")==r)return void e.preventDefault()}var l=el(),s=l.firstChild;i.display.lineSpace.insertBefore(l,i.display.lineSpace.firstChild),s.value=qs.text.join("\n");var a=document.activeElement;El(s),setTimeout(function(){i.display.lineSpace.removeChild(l),a.focus(),a==o&&n.showPrimarySelection()},50)}}var r=this,n=this,i=n.cm,o=n.div=e.lineDiv;Jo(o,i.options.spellcheck),Ql(o,"paste",function(e){Me(i,e)||qo(e,i)||vl<=11&&setTimeout(dn(i,function(){return r.updateFromDOM()}),20)}),Ql(o,"compositionstart",function(e){r.composing={data:e.data,done:!1}}),Ql(o,"compositionupdate",function(e){r.composing||(r.composing={data:e.data,done:!1})}),Ql(o,"compositionend",function(e){r.composing&&(e.data!=r.composing.data&&r.readFromDOMSoon(),r.composing.done=!0)}),Ql(o,"touchstart",function(){return n.forceCompositionEnd()}),Ql(o,"input",function(){r.composing||r.readFromDOMSoon()}),Ql(o,"copy",t),Ql(o,"cut",t)},Zs.prototype.prepareSelection=function(){var e=Tr(this.cm,!1);return e.focus=this.cm.state.focused,e},Zs.prototype.showSelection=function(e,t){e&&this.cm.display.view.length&&((e.focus||t)&&this.showPrimarySelection(),this.showMultipleSelections(e))},Zs.prototype.showPrimarySelection=function(){var e=window.getSelection(),t=this.cm,r=t.doc.sel.primary(),n=r.from(),i=r.to();if(t.display.viewTo==t.display.viewFrom||n.line>=t.display.viewTo||i.line<t.display.viewFrom)e.removeAllRanges();else{var o=sl(t,e.anchorNode,e.anchorOffset),l=sl(t,e.focusNode,e.focusOffset);if(!o||o.bad||!l||l.bad||0!=P(B(o,l),n)||0!=P(R(o,l),i)){var s=t.display.view,a=n.line>=t.display.viewFrom&&nl(t,n)||{node:s[0].measure.map[2],offset:0},u=i.line<t.display.viewTo&&nl(t,i);if(!u){var c=s[s.length-1].measure,f=c.maps?c.maps[c.maps.length-1]:c.map;u={node:f[f.length-1],offset:f[f.length-2]-f[f.length-3]}}if(a&&u){var h,d=e.rangeCount&&e.getRangeAt(0);try{h=Wl(a.node,a.offset,u.offset,u.node)}catch(e){}h&&(!fl&&t.state.focused?(e.collapse(a.node,a.offset),h.collapsed||(e.removeAllRanges(),e.addRange(h))):(e.removeAllRanges(),e.addRange(h)),d&&null==e.anchorNode?e.addRange(d):fl&&this.startGracePeriod()),this.rememberSelection()}else e.removeAllRanges()}}},Zs.prototype.startGracePeriod=function(){var e=this;clearTimeout(this.gracePeriod),this.gracePeriod=setTimeout(function(){e.gracePeriod=!1,e.selectionChanged()&&e.cm.operation(function(){return e.cm.curOp.selectionChanged=!0})},20)},Zs.prototype.showMultipleSelections=function(e){r(this.cm.display.cursorDiv,e.cursors),r(this.cm.display.selectionDiv,e.selection)},Zs.prototype.rememberSelection=function(){var e=window.getSelection();this.lastAnchorNode=e.anchorNode,this.lastAnchorOffset=e.anchorOffset,this.lastFocusNode=e.focusNode,this.lastFocusOffset=e.focusOffset},Zs.prototype.selectionInEditor=function(){var e=window.getSelection();if(!e.rangeCount)return!1;var t=e.getRangeAt(0).commonAncestorContainer;return o(this.div,t)},Zs.prototype.focus=function(){"nocursor"!=this.cm.options.readOnly&&(this.selectionInEditor()||this.showSelection(this.prepareSelection(),!0),this.div.focus())},Zs.prototype.blur=function(){this.div.blur()},Zs.prototype.getField=function(){return this.div},Zs.prototype.supportsTouch=function(){return!0},Zs.prototype.receivedFocus=function(){function e(){t.cm.state.focused&&(t.pollSelection(),t.polling.set(t.cm.options.pollInterval,e))}var t=this;this.selectionInEditor()?this.pollSelection():hn(this.cm,function(){return t.cm.curOp.selectionChanged=!0}),this.polling.set(this.cm.options.pollInterval,e)},Zs.prototype.selectionChanged=function(){var e=window.getSelection();return e.anchorNode!=this.lastAnchorNode||e.anchorOffset!=this.lastAnchorOffset||e.focusNode!=this.lastFocusNode||e.focusOffset!=this.lastFocusOffset},Zs.prototype.pollSelection=function(){if(null==this.readDOMTimeout&&!this.gracePeriod&&this.selectionChanged()){var e=window.getSelection(),t=this.cm;if(kl&&bl&&this.cm.options.gutters.length&&il(e.anchorNode))return this.cm.triggerOnKeyDown({type:"keydown",keyCode:8,preventDefault:Math.abs}),this.blur(),void this.focus();if(!this.composing){this.rememberSelection();var r=sl(t,e.anchorNode,e.anchorOffset),n=sl(t,e.focusNode,e.focusOffset);r&&n&&hn(t,function(){bi(t.doc,Rn(r,n),Gl),(r.bad||n.bad)&&(t.curOp.selectionChanged=!0)})}}},Zs.prototype.pollContent=function(){null!=this.readDOMTimeout&&(clearTimeout(this.readDOMTimeout),this.readDOMTimeout=null);var e=this.cm,t=e.display,r=e.doc.sel.primary(),n=r.from(),i=r.to();if(0==n.ch&&n.line>e.firstLine()&&(n=E(n.line-1,M(e.doc,n.line-1).length)),i.ch==M(e.doc,i.line).text.length&&i.line<e.lastLine()&&(i=E(i.line+1,0)),n.line<t.viewFrom||i.line>t.viewTo-1)return!1;var o,l,s;n.line==t.viewFrom||0==(o=Lr(e,n.line))?(l=W(t.view[0].line),s=t.view[0].node):(l=W(t.view[o].line),s=t.view[o-1].node.nextSibling);var a,u,c=Lr(e,i.line);if(c==t.view.length-1?(a=t.viewTo-1,u=t.lineDiv.lastChild):(a=W(t.view[c+1].line)-1,u=t.view[c+1].node.previousSibling),!s)return!1;for(var f=e.doc.splitLines(ll(e,s,u,l,a)),h=N(e.doc,E(l,0),E(a,M(e.doc,a).text.length));f.length>1&&h.length>1;)if(g(f)==g(h))f.pop(),h.pop(),a--;else{if(f[0]!=h[0])break;f.shift(),h.shift(),l++}for(var d=0,p=0,v=f[0],m=h[0],y=Math.min(v.length,m.length);d<y&&v.charCodeAt(d)==m.charCodeAt(d);)++d;for(var b=g(f),w=g(h),x=Math.min(b.length-(1==f.length?d:0),w.length-(1==h.length?d:0));p<x&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)++p;if(1==f.length&&1==h.length&&l==n.line)for(;d&&d>n.ch&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)d--,p++;f[f.length-1]=b.slice(0,b.length-p).replace(/^\u200b+/,""),f[0]=f[0].slice(d).replace(/\u200b+$/,"");var C=E(l,d),S=E(a,h.length?g(h).length-p:0);return f.length>1||f[0]||P(C,S)?(Ei(e.doc,f,C,S,"+input"),!0):void 0},Zs.prototype.ensurePolled=function(){this.forceCompositionEnd()},Zs.prototype.reset=function(){this.forceCompositionEnd()},Zs.prototype.forceCompositionEnd=function(){this.composing&&(clearTimeout(this.readDOMTimeout),this.composing=null,this.updateFromDOM(),this.div.blur(),this.div.focus())},Zs.prototype.readFromDOMSoon=function(){var e=this;null==this.readDOMTimeout&&(this.readDOMTimeout=setTimeout(function(){if(e.readDOMTimeout=null,e.composing){if(!e.composing.done)return;e.composing=null}e.updateFromDOM()},80))},Zs.prototype.updateFromDOM=function(){var e=this;!this.cm.isReadOnly()&&this.pollContent()||hn(this.cm,function(){return vn(e.cm)})},Zs.prototype.setUneditable=function(e){e.contentEditable="false"},Zs.prototype.onKeyPress=function(e){0!=e.charCode&&(e.preventDefault(),this.cm.isReadOnly()||dn(this.cm,$o)(this.cm,String.fromCharCode(null==e.charCode?e.keyCode:e.charCode),0))},Zs.prototype.readOnlyChanged=function(e){this.div.contentEditable=String("nocursor"!=e)},Zs.prototype.onContextMenu=function(){},Zs.prototype.resetPosition=function(){},Zs.prototype.needsContentAttribute=!0;var Qs=function(e){this.cm=e,this.prevInput="",this.pollingFast=!1,this.polling=new Pl,this.hasSelection=!1,this.composing=null};Qs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()});else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type?i.setSelections(t.ranges,null,Gl):(n.prevInput="",l.value=t.text.join("\n"),El(l))}"cut"==e.type&&(i.state.cutIncoming=!0)}}var r=this,n=this,i=this.cm,o=this.wrapper=el(),l=this.textarea=o.firstChild;e.wrapper.insertBefore(o,e.wrapper.firstChild),Ll&&(l.style.width="0px"),Ql(l,"input",function(){gl&&vl>=9&&r.hasSelection&&(r.hasSelection=null),n.poll()}),Ql(l,"paste",function(e){Me(i,e)||qo(e,i)||(i.state.pasteIncoming=!0,n.fastPoll())}),Ql(l,"cut",t),Ql(l,"copy",t),Ql(e.scroller,"paste",function(t){Ft(e,t)||Me(i,t)||(i.state.pasteIncoming=!0,n.focus())}),Ql(e.lineSpace,"selectstart",function(t){Ft(e,t)||We(t)}),Ql(l,"compositionstart",function(){var e=i.getCursor("from");n.composing&&n.composing.range.clear(),n.composing={start:e,range:i.markText(e,i.getCursor("to"),{className:"CodeMirror-composing"})}}),Ql(l,"compositionend",function(){n.composing&&(n.poll(),n.composing.range.clear(),n.composing=null)})},Qs.prototype.prepareSelection=function(){var e=this.cm,t=e.display,r=e.doc,n=Tr(e);if(e.options.moveInputWithCursor){var i=sr(e,r.sel.primary().head,"div"),o=t.wrapper.getBoundingClientRect(),l=t.lineDiv.getBoundingClientRect();n.teTop=Math.max(0,Math.min(t.wrapper.clientHeight-10,i.top+l.top-o.top)),n.teLeft=Math.max(0,Math.min(t.wrapper.clientWidth-10,i.left+l.left-o.left))}return n},Qs.prototype.showSelection=function(e){var t=this.cm.display;r(t.cursorDiv,e.cursors),r(t.selectionDiv,e.selection),null!=e.teTop&&(this.wrapper.style.top=e.teTop+"px",this.wrapper.style.left=e.teLeft+"px")},Qs.prototype.reset=function(e){if(!this.contextMenuPending&&!this.composing){var t=this.cm;if(t.somethingSelected()){this.prevInput="";var r=t.getSelection();this.textarea.value=r,t.state.focused&&El(this.textarea),gl&&vl>=9&&(this.hasSelection=r)}else e||(this.prevInput=this.textarea.value="",gl&&vl>=9&&(this.hasSelection=null))}},Qs.prototype.getField=function(){return this.textarea},Qs.prototype.supportsTouch=function(){return!1},Qs.prototype.focus=function(){if("nocursor"!=this.cm.options.readOnly&&(!Tl||l()!=this.textarea))try{this.textarea.focus()}catch(e){}},Qs.prototype.blur=function(){this.textarea.blur()},Qs.prototype.resetPosition=function(){this.wrapper.style.top=this.wrapper.style.left=0},Qs.prototype.receivedFocus=function(){this.slowPoll()},Qs.prototype.slowPoll=function(){var e=this;this.pollingFast||this.polling.set(this.cm.options.pollInterval,function(){e.poll(),e.cm.state.focused&&e.slowPoll()})},Qs.prototype.fastPoll=function(){function e(){r.poll()||t?(r.pollingFast=!1,r.slowPoll()):(t=!0,r.polling.set(60,e))}var t=!1,r=this;r.pollingFast=!0,r.polling.set(20,e)},Qs.prototype.poll=function(){var e=this,t=this.cm,r=this.textarea,n=this.prevInput;if(this.contextMenuPending||!t.state.focused||ts(r)&&!n&&!this.composing||t.isReadOnly()||t.options.disableInput||t.state.keySeq)return!1;var i=r.value;if(i==n&&!t.somethingSelected())return!1;if(gl&&vl>=9&&this.hasSelection===i||Ml&&/[\uf700-\uf7ff]/.test(i))return t.display.input.reset(),!1;if(t.doc.sel==t.display.selForContextMenu){var o=i.charCodeAt(0);if(8203!=o||n||(n="​"),8666==o)return this.reset(),this.cm.execCommand("undo")}for(var l=0,s=Math.min(n.length,i.length);l<s&&n.charCodeAt(l)==i.charCodeAt(l);)++l;return hn(t,function(){$o(t,i.slice(l),n.length-l,null,e.composing?"*compose":null),i.length>1e3||i.indexOf("\n")>-1?r.value=e.prevInput="":e.prevInput=i,e.composing&&(e.composing.range.clear(),e.composing.range=t.markText(e.composing.start,t.getCursor("to"),{className:"CodeMirror-composing"}))}),!0},Qs.prototype.ensurePolled=function(){this.pollingFast&&this.poll()&&(this.pollingFast=!1)},Qs.prototype.onKeyPress=function(){gl&&vl>=9&&(this.hasSelection=null),this.fastPoll()},Qs.prototype.onContextMenu=function(e){function t(){if(null!=l.selectionStart){var e=i.somethingSelected(),t="​"+(e?l.value:"");l.value="⇚",l.value=t,n.prevInput=e?"":"​",l.selectionStart=1,l.selectionEnd=t.length,o.selForContextMenu=i.doc.sel}}function r(){if(n.contextMenuPending=!1,n.wrapper.style.cssText=c,l.style.cssText=u,gl&&vl<9&&o.scrollbars.setScrollTop(o.scroller.scrollTop=a),null!=l.selectionStart){(!gl||gl&&vl<9)&&t();var e=0,r=function(){o.selForContextMenu==i.doc.sel&&0==l.selectionStart&&l.selectionEnd>0&&"​"==n.prevInput?dn(i,Mi)(i):e++<10?o.detectingSelectAll=setTimeout(r,500):(o.selForContextMenu=null,o.input.reset())};o.detectingSelectAll=setTimeout(r,200)}}var n=this,i=n.cm,o=i.display,l=n.textarea,s=Sr(i,e),a=o.scroller.scrollTop;if(s&&!wl){i.options.resetSelectionOnContextMenu&&-1==i.doc.sel.contains(s)&&dn(i,bi)(i.doc,Rn(s),Gl);var u=l.style.cssText,c=n.wrapper.style.cssText;n.wrapper.style.cssText="position: absolute";var f=n.wrapper.getBoundingClientRect();l.style.cssText="position: absolute; width: 30px; height: 30px;\n      top: "+(e.clientY-f.top-5)+"px; left: "+(e.clientX-f.left-5)+"px;\n      z-index: 1000; background: "+(gl?"rgba(255, 255, 255, .05)":"transparent")+";\n      outline: none; border-width: 0; outline: none; overflow: hidden; opacity: .05; filter: alpha(opacity=5);";var h;if(ml&&(h=window.scrollY),o.input.focus(),ml&&window.scrollTo(null,h),o.input.reset(),i.somethingSelected()||(l.value=n.prevInput=" "),n.contextMenuPending=!0,o.selForContextMenu=i.doc.sel,clearTimeout(o.detectingSelectAll),gl&&vl>=9&&t(),Hl){Fe(e);var d=function(){ke(window,"mouseup",d),setTimeout(r,20)};Ql(window,"mouseup",d)}else setTimeout(r,50)}},Qs.prototype.readOnlyChanged=function(e){e||this.reset(),this.textarea.disabled="nocursor"==e},Qs.prototype.setUneditable=function(){},Qs.prototype.needsContentAttribute=!1,function(e){function t(t,n,i,o){e.defaults[t]=n,i&&(r[t]=o?function(e,t,r){r!=Xs&&i(e,t,r)}:i)}var r=e.optionHandlers;e.defineOption=t,e.Init=Xs,t("value","",function(e,t){return e.setValue(t)},!0),t("mode",null,function(e,t){e.doc.modeOption=t,jn(e)},!0),t("indentUnit",2,jn,!0),t("indentWithTabs",!1),t("smartIndent",!0),t("tabSize",4,function(e){Xn(e),er(e),vn(e)},!0),t("lineSeparator",null,function(e,t){if(e.doc.lineSep=t,t){var r=[],n=e.doc.first;e.doc.iter(function(e){for(var i=0;;){var o=e.text.indexOf(t,i);if(-1==o)break;i=o+t.length,r.push(E(n,o))}n++});for(var i=r.length-1;i>=0;i--)Ei(e.doc,t,r[i],E(r[i].line,r[i].ch+t.length))}}),t("specialChars",/[\u0000-\u001f\u007f-\u009f\u00ad\u061c\u200b-\u200f\u2028\u2029\ufeff]/g,function(e,t,r){e.state.specialChars=new RegExp(t.source+(t.test("\t")?"":"|\t"),"g"),r!=Xs&&e.refresh()}),t("specialCharPlaceholder",at,function(e){return e.refresh()},!0),t("electricChars",!0),t("inputStyle",Tl?"contenteditable":"textarea",function(){throw new Error("inputStyle can not (yet) be changed in a running editor")},!0),t("spellcheck",!1,function(e,t){return e.getInputField().spellcheck=t},!0),t("rtlMoveVisually",!Ol),t("wholeLineUpdateBefore",!0),t("theme","default",function(e){Go(e),Uo(e)},!0),t("keyMap","default",function(e,t,r){var n=uo(t),i=r!=Xs&&uo(r);i&&i.detach&&i.detach(e,n),n.attach&&n.attach(e,i||null)}),t("extraKeys",null),t("configureMouse",null),t("lineWrapping",!1,Ko,!0),t("gutters",[],function(e){Fn(e.options),Uo(e)},!0),t("fixedGutter",!0,function(e,t){e.display.gutters.style.left=t?wr(e.display)+"px":"0",e.refresh()},!0),t("coverGutterNextToScrollbar",!1,function(e){return en(e)},!0),t("scrollbarStyle","native",function(e){rn(e),en(e),e.display.scrollbars.setScrollTop(e.doc.scrollTop),e.display.scrollbars.setScrollLeft(e.doc.scrollLeft)},!0),t("lineNumbers",!1,function(e){Fn(e.options),Uo(e)},!0),t("firstLineNumber",1,Uo,!0),t("lineNumberFormatter",function(e){return e},Uo,!0),t("showCursorWhenSelecting",!1,kr,!0),t("resetSelectionOnContextMenu",!0),t("lineWiseCopyCut",!0),t("pasteLinesPerSelection",!0),t("readOnly",!1,function(e,t){"nocursor"==t&&(Fr(e),e.display.input.blur()),e.display.input.readOnlyChanged(t)}),t("disableInput",!1,function(e,t){t||e.display.input.reset()},!0),t("dragDrop",!0,Vo),t("allowDropFileTypes",null),t("cursorBlinkRate",530),t("cursorScrollMargin",0),t("cursorHeight",1,kr,!0),t("singleCursorHeightPerLine",!0,kr,!0),t("workTime",100),t("workDelay",100),t("flattenSpans",!0,Xn,!0),t("addModeClass",!1,Xn,!0),t("pollInterval",100),t("undoDepth",200,function(e,t){return e.doc.history.undoDepth=t}),t("historyEventDelay",1250),t("viewportMargin",10,function(e){return e.refresh()},!0),t("maxHighlightLength",1e4,Xn,!0),t("moveInputWithCursor",!0,function(e,t){t||e.display.input.resetPosition()}),t("tabindex",null,function(e,t){return e.display.input.getField().tabIndex=t||""}),t("autofocus",null),t("direction","ltr",function(e,t){return e.doc.setDirection(t)},!0)}(jo),function(e){var t=e.optionHandlers,r=e.helpers={};e.prototype={constructor:e,focus:function(){window.focus(),this.display.input.focus()},setOption:function(e,r){var n=this.options,i=n[e];n[e]==r&&"mode"!=e||(n[e]=r,t.hasOwnProperty(e)&&dn(this,t[e])(this,r,i),Te(this,"optionChange",this,e))},getOption:function(e){return this.options[e]},getDoc:function(){return this.doc},addKeyMap:function(e,t){this.state.keyMaps[t?"push":"unshift"](uo(e))},removeKeyMap:function(e){for(var t=this.state.keyMaps,r=0;r<t.length;++r)if(t[r]==e||t[r].name==e)return t.splice(r,1),!0},addOverlay:pn(function(t,r){var n=t.token?t:e.getMode(this.options,t);if(n.startState)throw new Error("Overlays may not be stateful.");m(this.state.overlays,{mode:n,modeSpec:t,opaque:r&&r.opaque,priority:r&&r.priority||0},function(e){return e.priority}),this.state.modeGen++,vn(this)}),removeOverlay:pn(function(e){for(var t=this,r=this.state.overlays,n=0;n<r.length;++n){var i=r[n].modeSpec;if(i==e||"string"==typeof e&&i.name==e)return r.splice(n,1),t.state.modeGen++,void vn(t)}}),indentLine:pn(function(e,t,r){"string"!=typeof t&&"number"!=typeof t&&(t=null==t?this.options.smartIndent?"smart":"prev":t?"add":"subtract"),H(this.doc,e)&&Yo(this,e,t,r)}),indentSelection:pn(function(e){for(var t=this,r=this.doc.sel.ranges,n=-1,i=0;i<r.length;i++){var o=r[i];if(o.empty())o.head.line>n&&(Yo(t,o.head.line,e,!0),n=o.head.line,i==t.doc.sel.primIndex&&jr(t));else{var l=o.from(),s=o.to(),a=Math.max(n,l.line);n=Math.min(t.lastLine(),s.line-(s.ch?0:1))+1;for(var u=a;u<n;++u)Yo(t,u,e);var c=t.doc.sel.ranges;0==l.ch&&r.length==c.length&&c[i].from().ch>0&&gi(t.doc,i,new Ts(l,c[i].to()),Gl)}}}),getTokenAt:function(e,t){return Je(this,e,t)},getLineTokens:function(e,t){return Je(this,E(e),t,!0)},getTokenTypeAt:function(e){e=U(this.doc,e);var t,r=_e(this,M(this.doc,e.line)),n=0,i=(r.length-1)/2,o=e.ch;if(0==o)t=r[2];else for(;;){var l=n+i>>1;if((l?r[2*l-1]:0)>=o)i=l;else{if(!(r[2*l+1]<o)){t=r[2*l+2];break}n=l+1}}var s=t?t.indexOf("overlay "):-1;return s<0?t:0==s?null:t.slice(0,s-1)},getModeAt:function(t){var r=this.doc.mode;return r.innerMode?e.innerMode(r,this.getTokenAt(t).state).mode:r},getHelper:function(e,t){return this.getHelpers(e,t)[0]},getHelpers:function(e,t){var n=this,i=[];if(!r.hasOwnProperty(t))return i;var o=r[t],l=this.getModeAt(e);if("string"==typeof l[t])o[l[t]]&&i.push(o[l[t]]);else if(l[t])for(var s=0;s<l[t].length;s++){var a=o[l[t][s]];a&&i.push(a)}else l.helperType&&o[l.helperType]?i.push(o[l.helperType]):o[l.name]&&i.push(o[l.name]);for(var u=0;u<o._global.length;u++){var c=o._global[u];c.pred(l,n)&&-1==h(i,c.val)&&i.push(c.val)}return i},getStateAfter:function(e,t){var r=this.doc;return e=G(r,null==e?r.first+r.size-1:e),$e(this,e+1,t).state},cursorCoords:function(e,t){var r,n=this.doc.sel.primary();return r=null==e?n.head:"object"==typeof e?U(this.doc,e):e?n.from():n.to(),sr(this,r,t||"page")},charCoords:function(e,t){return lr(this,U(this.doc,e),t||"page")},coordsChar:function(e,t){return e=or(this,e,t||"page"),cr(this,e.left,e.top)},lineAtHeight:function(e,t){return e=or(this,{top:e,left:0},t||"page").top,D(this.doc,e+this.display.viewOffset)},heightAtLine:function(e,t,r){var n,i=!1;if("number"==typeof e){var o=this.doc.first+this.doc.size-1;e<this.doc.first?e=this.doc.first:e>o&&(e=o,i=!0),n=M(this.doc,e)}else n=e;return ir(this,n,{top:0,left:0},t||"page",r||i).top+(i?this.doc.height-ye(n):0)},defaultTextHeight:function(){return mr(this.display)},defaultCharWidth:function(){return yr(this.display)},getViewport:function(){return{from:this.display.viewFrom,to:this.display.viewTo}},addWidget:function(e,t,r,n,i){var o=this.display,l=(e=sr(this,U(this.doc,e))).bottom,s=e.left;if(t.style.position="absolute",t.setAttribute("cm-ignore-events","true"),this.display.input.setUneditable(t),o.sizer.appendChild(t),"over"==n)l=e.top;else if("above"==n||"near"==n){var a=Math.max(o.wrapper.clientHeight,this.doc.height),u=Math.max(o.sizer.clientWidth,o.lineSpace.clientWidth);("above"==n||e.bottom+t.offsetHeight>a)&&e.top>t.offsetHeight?l=e.top-t.offsetHeight:e.bottom+t.offsetHeight<=a&&(l=e.bottom),s+t.offsetWidth>u&&(s=u-t.offsetWidth)}t.style.top=l+"px",t.style.left=t.style.right="","right"==i?(s=o.sizer.clientWidth-t.offsetWidth,t.style.right="0px"):("left"==i?s=0:"middle"==i&&(s=(o.sizer.clientWidth-t.offsetWidth)/2),t.style.left=s+"px"),r&&Ur(this,{left:s,top:l,right:s+t.offsetWidth,bottom:l+t.offsetHeight})},triggerOnKeyDown:pn(Lo),triggerOnKeyPress:pn(Mo),triggerOnKeyUp:To,triggerOnMouseDown:pn(Oo),execCommand:function(e){if(Bs.hasOwnProperty(e))return Bs[e].call(null,this)},triggerElectric:pn(function(e){Zo(this,e)}),findPosH:function(e,t,r,n){var i=this,o=1;t<0&&(o=-1,t=-t);for(var l=U(this.doc,e),s=0;s<t&&!(l=tl(i.doc,l,o,r,n)).hitSide;++s);return l},moveH:pn(function(e,t){var r=this;this.extendSelectionsBy(function(n){return r.display.shift||r.doc.extend||n.empty()?tl(r.doc,n.head,e,t,r.options.rtlMoveVisually):e<0?n.from():n.to()},Vl)}),deleteH:pn(function(e,t){var r=this.doc.sel,n=this.doc;r.somethingSelected()?n.replaceSelection("",null,"+delete"):co(this,function(r){var i=tl(n,r.head,e,t,!1);return e<0?{from:i,to:r.head}:{from:r.head,to:i}})}),findPosV:function(e,t,r,n){var i=this,o=1,l=n;t<0&&(o=-1,t=-t);for(var s=U(this.doc,e),a=0;a<t;++a){var u=sr(i,s,"div");if(null==l?l=u.left:u.left=l,(s=rl(i,u,o,r)).hitSide)break}return s},moveV:pn(function(e,t){var r=this,n=this.doc,i=[],o=!this.display.shift&&!n.extend&&n.sel.somethingSelected();if(n.extendSelectionsBy(function(l){if(o)return e<0?l.from():l.to();var s=sr(r,l.head,"div");null!=l.goalColumn&&(s.left=l.goalColumn),i.push(s.left);var a=rl(r,s,e,t);return"page"==t&&l==n.sel.primary()&&Kr(r,lr(r,a,"div").top-s.top),a},Vl),i.length)for(var l=0;l<n.sel.ranges.length;l++)n.sel.ranges[l].goalColumn=i[l]}),findWordAt:function(e){var t=M(this.doc,e.line).text,r=e.ch,n=e.ch;if(t){var i=this.getHelper(e,"wordChars");"before"!=e.sticky&&n!=t.length||!r?++n:--r;for(var o=t.charAt(r),l=x(o,i)?function(e){return x(e,i)}:/\s/.test(o)?function(e){return/\s/.test(e)}:function(e){return!/\s/.test(e)&&!x(e)};r>0&&l(t.charAt(r-1));)--r;for(;n<t.length&&l(t.charAt(n));)++n}return new Ts(E(e.line,r),E(e.line,n))},toggleOverwrite:function(e){null!=e&&e==this.state.overwrite||((this.state.overwrite=!this.state.overwrite)?s(this.display.cursorDiv,"CodeMirror-overwrite"):Fl(this.display.cursorDiv,"CodeMirror-overwrite"),Te(this,"overwriteToggle",this,this.state.overwrite))},hasFocus:function(){return this.display.input.getField()==l()},isReadOnly:function(){return!(!this.options.readOnly&&!this.doc.cantEdit)},scrollTo:pn(function(e,t){Xr(this,e,t)}),getScrollInfo:function(){var e=this.display.scroller;return{left:e.scrollLeft,top:e.scrollTop,height:e.scrollHeight-zt(this)-this.display.barHeight,width:e.scrollWidth-zt(this)-this.display.barWidth,clientHeight:Bt(this),clientWidth:Rt(this)}},scrollIntoView:pn(function(e,t){null==e?(e={from:this.doc.sel.primary().head,to:null},null==t&&(t=this.options.cursorScrollMargin)):"number"==typeof e?e={from:E(e,0),to:null}:null==e.from&&(e={from:e,to:null}),e.to||(e.to=e.from),e.margin=t||0,null!=e.from.line?Yr(this,e):$r(this,e.from,e.to,e.margin)}),setSize:pn(function(e,t){var r=this,n=function(e){return"number"==typeof e||/^\d+$/.test(String(e))?e+"px":e};null!=e&&(this.display.wrapper.style.width=n(e)),null!=t&&(this.display.wrapper.style.height=n(t)),this.options.lineWrapping&&Jt(this);var i=this.display.viewFrom;this.doc.iter(i,this.display.viewTo,function(e){if(e.widgets)for(var t=0;t<e.widgets.length;t++)if(e.widgets[t].noHScroll){mn(r,i,"widget");break}++i}),this.curOp.forceUpdate=!0,Te(this,"refresh",this)}),operation:function(e){return hn(this,e)},startOperation:function(){return nn(this)},endOperation:function(){return on(this)},refresh:pn(function(){var e=this.display.cachedTextHeight;vn(this),this.curOp.forceUpdate=!0,er(this),Xr(this,this.doc.scrollLeft,this.doc.scrollTop),Wn(this),(null==e||Math.abs(e-mr(this.display))>.5)&&Cr(this),Te(this,"refresh",this)}),swapDoc:pn(function(e){var t=this.doc;return t.cm=null,qn(this,e),er(this),this.display.input.reset(),Xr(this,e.scrollLeft,e.scrollTop),this.curOp.forceScroll=!0,bt(this,"swapDoc",this,t),t}),getInputField:function(){return this.display.input.getField()},getWrapperElement:function(){return this.display.wrapper},getScrollerElement:function(){return this.display.scroller},getGutterElement:function(){return this.display.gutters}},Ae(e),e.registerHelper=function(t,n,i){r.hasOwnProperty(t)||(r[t]=e[t]={_global:[]}),r[t][n]=i},e.registerGlobalHelper=function(t,n,i,o){e.registerHelper(t,n,o),r[t]._global.push({pred:i,val:o})}}(jo);var Js="iter insert remove copy getEditor constructor".split(" ");for(var ea in Ds.prototype)Ds.prototype.hasOwnProperty(ea)&&h(Js,ea)<0&&(jo.prototype[ea]=function(e){return function(){return e.apply(this.doc,arguments)}}(Ds.prototype[ea]));return Ae(Ds),jo.inputStyles={textarea:Qs,contenteditable:Zs},jo.defineMode=function(e){jo.defaults.mode||"null"==e||(jo.defaults.mode=e),Be.apply(this,arguments)},jo.defineMIME=function(e,t){os[e]=t},jo.defineMode("null",function(){return{token:function(e){return e.skipToEnd()}}}),jo.defineMIME("text/plain","null"),jo.defineExtension=function(e,t){jo.prototype[e]=t},jo.defineDocExtension=function(e,t){Ds.prototype[e]=t},jo.fromTextArea=function(e,t){function r(){e.value=a.getValue()}if(t=t?c(t):{},t.value=e.value,!t.tabindex&&e.tabIndex&&(t.tabindex=e.tabIndex),!t.placeholder&&e.placeholder&&(t.placeholder=e.placeholder),null==t.autofocus){var n=l();t.autofocus=n==e||null!=e.getAttribute("autofocus")&&n==document.body}var i;if(e.form&&(Ql(e.form,"submit",r),!t.leaveSubmitMethodAlone)){var o=e.form;i=o.submit;try{var s=o.submit=function(){r(),o.submit=i,o.submit(),o.submit=s}}catch(e){}}t.finishInit=function(t){t.save=r,t.getTextArea=function(){return e},t.toTextArea=function(){t.toTextArea=isNaN,r(),e.parentNode.removeChild(t.getWrapperElement()),e.style.display="",e.form&&(ke(e.form,"submit",r),"function"==typeof e.form.submit&&(e.form.submit=i))}},e.style.display="none";var a=jo(function(t){return e.parentNode.insertBefore(t,e.nextSibling)},t);return a},function(e){e.off=ke,e.on=Ql,e.wheelEventPixels=Pn,e.Doc=Ds,e.splitLines=es,e.countColumn=f,e.findColumn=d,e.isWordChar=w,e.Pass=Bl,e.signal=Te,e.Line=fs,e.changeEnd=Bn,e.scrollbarModel=ws,e.Pos=E,e.cmpPos=P,e.modes=is,e.mimeModes=os,e.resolveMode=Ge,e.getMode=Ue,e.modeExtensions=ls,e.extendMode=Ve,e.copyState=Ke,e.startState=Xe,e.innerMode=je,e.commands=Bs,e.keyMap=Rs,e.keyName=ao,e.isModifierKey=lo,e.lookupKey=oo,e.normalizeKeyMap=io,e.StringStream=ss,e.SharedTextMarker=As,e.TextMarker=Os,e.LineWidget=Ms,e.e_preventDefault=We,e.e_stopPropagation=De,e.e_stop=Fe,e.addClass=s,e.contains=o,e.rmClass=Fl,e.keyNames=Es}(jo),jo.version="5.30.0",jo});
      !function(e){"object"==typeof exports&&"object"==typeof module?e(require("../../lib/codemirror")):"function"==typeof define&&define.amd?define(["../../lib/codemirror"],e):e(CodeMirror)}(function(e){"use strict";function t(e,t,n,r,o,a){this.indented=e,this.column=t,this.type=n,this.info=r,this.align=o,this.prev=a}function n(e,n,r,o){var a=e.indented;return e.context&&"statement"==e.context.type&&"statement"!=r&&(a=e.context.indented),e.context=new t(a,n,r,o,null,e.context)}function r(e){var t=e.context.type;return")"!=t&&"]"!=t&&"}"!=t||(e.indented=e.context.indented),e.context=e.context.prev}function o(e,t,n){return"variable"==t.prevToken||"type"==t.prevToken||(!!/\S(?:[^- ]>|[*\]])\s*$|\*$/.test(e.string.slice(0,n))||(!(!t.typeAtEndOfLine||e.column()!=e.indentation())||void 0))}function a(e){for(;;){if(!e||"top"==e.type)return!0;if("}"==e.type&&"namespace"!=e.prev.info)return!1;e=e.prev}}function i(e){for(var t={},n=e.split(" "),r=0;r<n.length;++r)t[n[r]]=!0;return t}function l(e,t){return"function"==typeof e?e(t):e.propertyIsEnumerable(t)}function s(e,t){if(!t.startOfLine)return!1;for(var n,r=null;n=e.peek();){if("\\"==n&&e.match(/^.$/)){r=s;break}if("/"==n&&e.match(/^\/[\/\*]/,!1))break;e.next()}return t.tokenize=r,"meta"}function c(e,t){return"type"==t.prevToken&&"type"}function u(e){return e.eatWhile(/[\w\.']/),"number"}function d(e,t){if(e.backUp(1),e.match(/(R|u8R|uR|UR|LR)/)){var n=e.match(/"([^\s\\()]{0,16})\(/);return!!n&&(t.cpp11RawStringDelim=n[1],t.tokenize=m,m(e,t))}return e.match(/(u8|u|U|L)/)?!!e.match(/["']/,!1)&&"string":(e.next(),!1)}function f(e){var t=/(\w+)::~?(\w+)$/.exec(e);return t&&t[1]==t[2]}function p(e,t){for(var n;null!=(n=e.next());)if('"'==n&&!e.eat('"')){t.tokenize=null;break}return"string"}function m(e,t){var n=t.cpp11RawStringDelim.replace(/[^\w\s]/g,"\\$&");return e.match(new RegExp(".*?\\)"+n+'"'))?t.tokenize=null:e.skipToEnd(),"string"}function h(t,n){function r(e){if(e)for(var t in e)e.hasOwnProperty(t)&&o.push(t)}"string"==typeof t&&(t=[t]);var o=[];r(n.keywords),r(n.types),r(n.builtin),r(n.atoms),o.length&&(n.helperType=t[0],e.registerHelper("hintWords",t[0],o));for(var a=0;a<t.length;++a)e.defineMIME(t[a],n)}function g(e,t){for(var n=!1;!e.eol();){if(!n&&e.match('"""')){t.tokenize=null;break}n="\\"==e.next()&&!n}return"string"}function y(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!e&&!o&&t.match('"')){a=!0;break}if(e&&t.match('"""')){a=!0;break}r=t.next(),!o&&"$"==r&&t.match("{")&&t.skipTo("}"),o=!o&&"\\"==r&&!e}return!a&&e||(n.tokenize=null),"string"}}function x(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!o&&t.match('"')&&("single"==e||t.match('""'))){a=!0;break}if(!o&&t.match("``")){w=x(e),a=!0;break}r=t.next(),o="single"==e&&!o&&"\\"==r}return a&&(n.tokenize=null),"string"}}e.defineMode("clike",function(i,s){function c(e,t){var n=e.next();if(S[n]){var r=S[n](e,t);if(!1!==r)return r}if('"'==n||"'"==n)return t.tokenize=u(n),t.tokenize(e,t);if(D.test(n))return p=n,null;if(L.test(n)){if(e.backUp(1),e.match(I))return"number";e.next()}if("/"==n){if(e.eat("*"))return t.tokenize=d,d(e,t);if(e.eat("/"))return e.skipToEnd(),"comment"}if(F.test(n)){for(;!e.match(/^\/[\/*]/,!1)&&e.eat(F););return"operator"}if(e.eatWhile(z),P)for(;e.match(P);)e.eatWhile(z);var o=e.current();return l(x,o)?(l(w,o)&&(p="newstatement"),l(v,o)&&(m=!0),"keyword"):l(b,o)?"type":l(k,o)?(l(w,o)&&(p="newstatement"),"builtin"):l(_,o)?"atom":"variable"}function u(e){return function(t,n){for(var r,o=!1,a=!1;null!=(r=t.next());){if(r==e&&!o){a=!0;break}o=!o&&"\\"==r}return(a||!o&&!C)&&(n.tokenize=null),"string"}}function d(e,t){for(var n,r=!1;n=e.next();){if("/"==n&&r){t.tokenize=null;break}r="*"==n}return"comment"}function f(e,t){s.typeFirstDefinitions&&e.eol()&&a(t.context)&&(t.typeAtEndOfLine=o(e,t,e.pos))}var p,m,h=i.indentUnit,g=s.statementIndentUnit||h,y=s.dontAlignCalls,x=s.keywords||{},b=s.types||{},k=s.builtin||{},w=s.blockKeywords||{},v=s.defKeywords||{},_=s.atoms||{},S=s.hooks||{},C=s.multiLineStrings,T=!1!==s.indentStatements,M=!1!==s.indentSwitch,P=s.namespaceSeparator,D=s.isPunctuationChar||/[\[\]{}\(\),;\:\.]/,L=s.numberStart||/[\d\.]/,I=s.number||/^(?:0x[a-f\d]+|0b[01]+|(?:\d+\.?\d*|\.\d+)(?:e[-+]?\d+)?)(u|ll?|l|f)?/i,F=s.isOperatorChar||/[+\-*&%=<>!?|\/]/,z=s.isIdentifierChar||/[\w\$_\xa1-\uffff]/;return{startState:function(e){return{tokenize:null,context:new t((e||0)-h,0,"top",null,!1),indented:0,startOfLine:!0,prevToken:null}},token:function(e,t){var i=t.context;if(e.sol()&&(null==i.align&&(i.align=!1),t.indented=e.indentation(),t.startOfLine=!0),e.eatSpace())return f(e,t),null;p=m=null;var l=(t.tokenize||c)(e,t);if("comment"==l||"meta"==l)return l;if(null==i.align&&(i.align=!0),";"==p||":"==p||","==p&&e.match(/^\s*(?:\/\/.*)?$/,!1))for(;"statement"==t.context.type;)r(t);else if("{"==p)n(t,e.column(),"}");else if("["==p)n(t,e.column(),"]");else if("("==p)n(t,e.column(),")");else if("}"==p){for(;"statement"==i.type;)i=r(t);for("}"==i.type&&(i=r(t));"statement"==i.type;)i=r(t)}else p==i.type?r(t):T&&(("}"==i.type||"top"==i.type)&&";"!=p||"statement"==i.type&&"newstatement"==p)&&n(t,e.column(),"statement",e.current());if("variable"==l&&("def"==t.prevToken||s.typeFirstDefinitions&&o(e,t,e.start)&&a(t.context)&&e.match(/^\s*\(/,!1))&&(l="def"),S.token){var u=S.token(e,t,l);void 0!==u&&(l=u)}return"def"==l&&!1===s.styleDefs&&(l="variable"),t.startOfLine=!1,t.prevToken=m?"def":l||p,f(e,t),l},indent:function(t,n){if(t.tokenize!=c&&null!=t.tokenize||t.typeAtEndOfLine)return e.Pass;var r=t.context,o=n&&n.charAt(0);if("statement"==r.type&&"}"==o&&(r=r.prev),s.dontIndentStatements)for(;"statement"==r.type&&s.dontIndentStatements.test(r.info);)r=r.prev;if(S.indent){var a=S.indent(t,r,n);if("number"==typeof a)return a}var i=o==r.type,l=r.prev&&"switch"==r.prev.info;if(s.allmanIndentation&&/[{(]/.test(o)){for(;"top"!=r.type&&"}"!=r.type;)r=r.prev;return r.indented}return"statement"==r.type?r.indented+("{"==o?0:g):!r.align||y&&")"==r.type?")"!=r.type||i?r.indented+(i?0:h)+(i||!l||/^(?:case|default)\b/.test(n)?0:h):r.indented+g:r.column+(i?0:1)},electricInput:M?/^\s*(?:case .*?:|default:|\{\}?|\})$/:/^\s*[{}]$/,blockCommentStart:"/*",blockCommentEnd:"*/",lineComment:"//",fold:"brace"}});var b="auto if break case register continue return default do sizeof static else struct switch extern typedef union for goto while enum const volatile",k="int long char short double float unsigned signed void size_t ptrdiff_t";h(["text/x-csrc","text/x-c","text/x-chdr"],{name:"clike",keywords:i(b),types:i(k+" bool _Complex _Bool float_t double_t intptr_t intmax_t int8_t int16_t int32_t int64_t uintptr_t uintmax_t uint8_t uint16_t uint32_t uint64_t"),blockKeywords:i("case do else for if switch while struct"),defKeywords:i("struct"),typeFirstDefinitions:!0,atoms:i("null true false"),hooks:{"#":s,"*":c},modeProps:{fold:["brace","include"]}}),h(["text/x-c++src","text/x-c++hdr"],{name:"clike",keywords:i(b+" asm dynamic_cast namespace reinterpret_cast try explicit new static_cast typeid catch operator template typename class friend private this using const_cast inline public throw virtual delete mutable protected alignas alignof constexpr decltype nullptr noexcept thread_local final static_assert override"),types:i(k+" bool wchar_t"),blockKeywords:i("catch class do else finally for if struct switch try while"),defKeywords:i("class namespace struct enum union"),typeFirstDefinitions:!0,atoms:i("true false null"),dontIndentStatements:/^template$/,isIdentifierChar:/[\w\$_~\xa1-\uffff]/,hooks:{"#":s,"*":c,u:d,U:d,L:d,R:d,0:u,1:u,2:u,3:u,4:u,5:u,6:u,7:u,8:u,9:u,token:function(e,t,n){if("variable"==n&&"("==e.peek()&&(";"==t.prevToken||null==t.prevToken||"}"==t.prevToken)&&f(e.current()))return"def"}},namespaceSeparator:"::",modeProps:{fold:["brace","include"]}}),h("text/x-java",{name:"clike",keywords:i("abstract assert break case catch class const continue default do else enum extends final finally float for goto if implements import instanceof interface native new package private protected public return static strictfp super switch synchronized this throw throws transient try volatile while @interface"),types:i("byte short int long float double boolean char void Boolean Byte Character Double Float Integer Long Number Object Short String StringBuffer StringBuilder Void"),blockKeywords:i("catch class do else finally for if switch try while"),defKeywords:i("class interface package enum @interface"),typeFirstDefinitions:!0,atoms:i("true false null"),number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,hooks:{"@":function(e){return!e.match("interface",!1)&&(e.eatWhile(/[\w\$_]/),"meta")}},modeProps:{fold:["brace","import"]}}),h("text/x-csharp",{name:"clike",keywords:i("abstract as async await base break case catch checked class const continue default delegate do else enum event explicit extern finally fixed for foreach goto if implicit in interface internal is lock namespace new operator out override params private protected public readonly ref return sealed sizeof stackalloc static struct switch this throw try typeof unchecked unsafe using virtual void volatile while add alias ascending descending dynamic from get global group into join let orderby partial remove select set value var yield"),types:i("Action Boolean Byte Char DateTime DateTimeOffset Decimal Double Func Guid Int16 Int32 Int64 Object SByte Single String Task TimeSpan UInt16 UInt32 UInt64 bool byte char decimal double short int long object sbyte float string ushort uint ulong"),blockKeywords:i("catch class do else finally for foreach if struct switch try while"),defKeywords:i("class interface namespace struct var"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"@":function(e,t){return e.eat('"')?(t.tokenize=p,p(e,t)):(e.eatWhile(/[\w\$_]/),"meta")}}}),h("text/x-scala",{name:"clike",keywords:i("abstract case catch class def do else extends final finally for forSome if implicit import lazy match new null object override package private protected return sealed super this throw trait try type val var while with yield _ assert assume require print println printf readLine readBoolean readByte readShort readChar readInt readLong readFloat readDouble"),types:i("AnyVal App Application Array BufferedIterator BigDecimal BigInt Char Console Either Enumeration Equiv Error Exception Fractional Function IndexedSeq Int Integral Iterable Iterator List Map Numeric Nil NotNull Option Ordered Ordering PartialFunction PartialOrdering Product Proxy Range Responder Seq Serializable Set Specializable Stream StringBuilder StringContext Symbol Throwable Traversable TraversableOnce Tuple Unit Vector Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),multiLineStrings:!0,blockKeywords:i("catch class enum do else finally for forSome if match switch try while"),defKeywords:i("class enum def object package trait type val var"),atoms:i("true false null"),indentStatements:!1,indentSwitch:!1,isOperatorChar:/[+\-*&%=<>!?|\/#:@]/,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return!!e.match('""')&&(t.tokenize=g,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},"=":function(e,n){var r=n.context;return!("}"!=r.type||!r.align||!e.eat(">"))&&(n.context=new t(r.indented,r.column,r.type,r.info,null,r.prev),"operator")}},modeProps:{closeBrackets:{triples:'"'}}}),h("text/x-kotlin",{name:"clike",keywords:i("package as typealias class interface this super val var fun for is in This throw return break continue object if else while do try when !in !is as? file import where by get set abstract enum open inner override private public internal protected catch finally out final vararg reified dynamic companion constructor init sealed field property receiver param sparam lateinit data inline noinline tailrec external annotation crossinline const operator infix suspend"),types:i("Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),intendSwitch:!1,indentStatements:!1,multiLineStrings:!0,number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,blockKeywords:i("catch class do else finally for if where try while enum"),defKeywords:i("class val var object package interface fun"),atoms:i("true false null this"),hooks:{'"':function(e,t){return t.tokenize=y(e.match('""')),t.tokenize(e,t)}},modeProps:{closeBrackets:{triples:'"'}}}),h(["x-shader/x-vertex","x-shader/x-fragment"],{name:"clike",keywords:i("sampler1D sampler2D sampler3D samplerCube sampler1DShadow sampler2DShadow const attribute uniform varying break continue discard return for while do if else struct in out inout"),types:i("float int bool void vec2 vec3 vec4 ivec2 ivec3 ivec4 bvec2 bvec3 bvec4 mat2 mat3 mat4"),blockKeywords:i("for while do if else struct"),builtin:i("radians degrees sin cos tan asin acos atan pow exp log exp2 sqrt inversesqrt abs sign floor ceil fract mod min max clamp mix step smoothstep length distance dot cross normalize ftransform faceforward reflect refract matrixCompMult lessThan lessThanEqual greaterThan greaterThanEqual equal notEqual any all not texture1D texture1DProj texture1DLod texture1DProjLod texture2D texture2DProj texture2DLod texture2DProjLod texture3D texture3DProj texture3DLod texture3DProjLod textureCube textureCubeLod shadow1D shadow2D shadow1DProj shadow2DProj shadow1DLod shadow2DLod shadow1DProjLod shadow2DProjLod dFdx dFdy fwidth noise1 noise2 noise3 noise4"),atoms:i("true false gl_FragColor gl_SecondaryColor gl_Normal gl_Vertex gl_MultiTexCoord0 gl_MultiTexCoord1 gl_MultiTexCoord2 gl_MultiTexCoord3 gl_MultiTexCoord4 gl_MultiTexCoord5 gl_MultiTexCoord6 gl_MultiTexCoord7 gl_FogCoord gl_PointCoord gl_Position gl_PointSize gl_ClipVertex gl_FrontColor gl_BackColor gl_FrontSecondaryColor gl_BackSecondaryColor gl_TexCoord gl_FogFragCoord gl_FragCoord gl_FrontFacing gl_FragData gl_FragDepth gl_ModelViewMatrix gl_ProjectionMatrix gl_ModelViewProjectionMatrix gl_TextureMatrix gl_NormalMatrix gl_ModelViewMatrixInverse gl_ProjectionMatrixInverse gl_ModelViewProjectionMatrixInverse gl_TexureMatrixTranspose gl_ModelViewMatrixInverseTranspose gl_ProjectionMatrixInverseTranspose gl_ModelViewProjectionMatrixInverseTranspose gl_TextureMatrixInverseTranspose gl_NormalScale gl_DepthRange gl_ClipPlane gl_Point gl_FrontMaterial gl_BackMaterial gl_LightSource gl_LightModel gl_FrontLightModelProduct gl_BackLightModelProduct gl_TextureColor gl_EyePlaneS gl_EyePlaneT gl_EyePlaneR gl_EyePlaneQ gl_FogParameters gl_MaxLights gl_MaxClipPlanes gl_MaxTextureUnits gl_MaxTextureCoords gl_MaxVertexAttribs gl_MaxVertexUniformComponents gl_MaxVaryingFloats gl_MaxVertexTextureImageUnits gl_MaxTextureImageUnits gl_MaxFragmentUniformComponents gl_MaxCombineTextureImageUnits gl_MaxDrawBuffers"),indentSwitch:!1,hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-nesc",{name:"clike",keywords:i(b+"as atomic async call command component components configuration event generic implementation includes interface module new norace nx_struct nx_union post provides signal task uses abstract extends"),types:i(k),blockKeywords:i("case do else for if switch while struct"),atoms:i("null true false"),hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-objectivec",{name:"clike",keywords:i(b+"inline restrict _Bool _Complex _Imaginary BOOL Class bycopy byref id IMP in inout nil oneway out Protocol SEL self super atomic nonatomic retain copy readwrite readonly"),types:i(k),atoms:i("YES NO NULL NILL ON OFF true false"),hooks:{"@":function(e){return e.eatWhile(/[\w\$]/),"keyword"},"#":s,indent:function(e,t,n){if("statement"==t.type&&/^@\w/.test(n))return t.indented}},modeProps:{fold:"brace"}}),h("text/x-squirrel",{name:"clike",keywords:i("base break clone continue const default delete enum extends function in class foreach local resume return this throw typeof yield constructor instanceof static"),types:i(k),blockKeywords:i("case catch class else for foreach if switch try while"),defKeywords:i("function local class"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"#":s},modeProps:{fold:["brace","include"]}});var w=null;h("text/x-ceylon",{name:"clike",keywords:i("abstracts alias assembly assert assign break case catch class continue dynamic else exists extends finally for function given if import in interface is let module new nonempty object of out outer package return satisfies super switch then this throw try value void while"),types:function(e){var t=e.charAt(0);return t===t.toUpperCase()&&t!==t.toLowerCase()},blockKeywords:i("case catch class dynamic else finally for function if interface module new object switch try while"),defKeywords:i("class dynamic function interface module object package value"),builtin:i("abstract actual aliased annotation by default deprecated doc final formal late license native optional sealed see serializable shared suppressWarnings tagged throws variable"),isPunctuationChar:/[\[\]{}\(\),;\:\.`]/,isOperatorChar:/[+\-*&%=<>!?|^~:\/]/,numberStart:/[\d#$]/,number:/^(?:#[\da-fA-F_]+|\$[01_]+|[\d_]+[kMGTPmunpf]?|[\d_]+\.[\d_]+(?:[eE][-+]?\d+|[kMGTPmunpf]|)|)/i,multiLineStrings:!0,typeFirstDefinitions:!0,atoms:i("true false null larger smaller equal empty finished"),indentSwitch:!1,styleDefs:!1,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return t.tokenize=x(e.match('""')?"triple":"single"),t.tokenize(e,t)},"`":function(e,t){return!(!w||!e.match("`"))&&(t.tokenize=w,w=null,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},token:function(e,t,n){if(("variable"==n||"type"==n)&&"."==t.prevToken)return"variable-2"}},modeProps:{fold:["brace","import"],closeBrackets:{triples:'"'}}})});
      // -------------------------------------------------------------------------
//  Part of the CodeChecker project, under the Apache License v2.0 with
//  LLVM Exceptions. See LICENSE for license information.
//  SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
// -------------------------------------------------------------------------

var BugViewer = {
  _files : [],
  _reports : [],
  _lineWidgets : [],
  _navigationMenuItems : [],
  _sourceFileData : null,
  _currentReport : null,
  _lastBugEvent  : null,

  init : function (files, reports) {
    this._files = files;
    this._reports = reports;

    this.initEscapeChars();
  },

  initEscapeChars : function () {
    this.escapeChars = {
      ' ' : 'nbsp',
      '<' : 'lt',
      '>' : 'gt',
      '"' : 'quot',
      '&' : 'amp'
    };

    var regexString = '[';
    for (var key in this.escapeChars) {
      regexString += key;
    }
    regexString += ']';

    this.escapeRegExp = new RegExp( regexString, 'g');
  },

  escapeHTML : function (str) {
    var that = this;

    return str.replace(this.escapeRegExp, function (m) {
      return '&' + that.escapeChars[m] + ';';
    });
  },

  initByUrl : function () {
    if (!this._reports) return;

    var state = {};
    window.location.hash.substr(1).split('&').forEach(function (s) {
      var parts = s.split('=');
      state[parts[0]] = parts[1];
    });

    for (var key in this._reports) {
      var report = this._reports[key];
      if (report.reportHash === state['reportHash']) {
        this.navigate(report);
        return;
      }
    }

    this.navigate(this._reports[0]);
  },

  create : function () {
    this._content = document.getElementById('editor-wrapper');
    this._filepath = document.getElementById('file-path');
    this._checkerName = document.getElementById('checker-name');
    this._reviewStatusWrapper =
      document.getElementById('review-status-wrapper');
    this._reviewStatus = document.getElementById('review-status');
    this._editor = document.getElementById('editor');

    this._codeMirror = CodeMirror(this._editor, {
      mode: 'text/x-c++src',
      matchBrackets : true,
      lineNumbers : true,
      readOnly : true,
      foldGutter : true,
      extraKeys : {},
      viewportMargin : 100
    });

    this._createNavigationMenu();
  },

  navigate : function (report, item) {
    if (!item) {
      var items = this._navigationMenuItems.filter(function (navItem) {
        return navItem.report.reportHash === report.reportHash;
      });

      if (!items.length) return;

      item = items[0].widget;
    }

    this._selectedReport.classList.remove('active');
    this._selectedReport = item;
    this._selectedReport.classList.add('active');
    this.setReport(report);
  },

  _createNavigationMenu : function () {
    var that = this;

    var nav = document.getElementById('report-nav');
    var list = document.createElement('ul');
    this._reports.forEach(function (report) {
      var events = report['events'];
      var lastBugEvent = events[events.length - 1];
      var item = document.createElement('li');

      var severity = document.createElement('i');
      severity.className = 'severity-' + report.severity.toLowerCase();

      item.appendChild(severity);
      item.appendChild(document.createTextNode(lastBugEvent.message));

      item.addEventListener('click', function () {
        that.navigate(report, item);
      })
      list.appendChild(item);
      that._navigationMenuItems.push({ report : report, widget : item });
    });

    if (!this._selectedReport && list.childNodes.length) {
      this._selectedReport = list.childNodes[0];
      this._selectedReport.classList.add('active');
    }

    nav.appendChild(list);
  },

  setReport : function (report) {
    this._currentReport = report;
    var events = report['events'];
    var lastBugEvent = events[events.length - 1];
    this.setCurrentBugEvent(lastBugEvent, events.length - 1);
    this.setCheckerName(report.checkerName);
    this.setReviewStatus(report.reviewStatus);

    window.location.hash = '#reportHash=' + report.reportHash;
  },

  setCurrentBugEvent : function (event, idx) {
    this._currentBugEvent = event;
    this.setSourceFileData(this._files[event.location.file]);
    this.drawBugPath();

    this.jumpTo(event.location.line, 0);
    this.highlightBugEvent(event, idx);
  },

  highlightBugEvent : function (event, idx) {
    this._lineWidgets.forEach(function (widget) {
      var lineIdx = widget.node.getAttribute('idx');
      if (parseInt(lineIdx) === idx) {
        widget.node.classList.add('current');
      }
    });
  },

  setCheckerName : function (checkerName) {
    this._checkerName.innerHTML = checkerName;
  },

  setReviewStatus : function (status) {
    if (status) {
      var className =
        'review-status-' + status.toLowerCase().split(' ').join('-');
      this._reviewStatus.className = "review-status " + className;

      this._reviewStatus.innerHTML = status;
      this._reviewStatusWrapper.style.display = 'block';
    } else {
      this._reviewStatusWrapper.style.display = 'none';
    }
  },

  setSourceFileData : function (file) {
    if (this._sourceFileData && file.id === this._sourceFileData.id) {
      return;
    }

    this._sourceFileData = file;
    this._filepath.innerHTML = file.path;
    this._codeMirror.doc.setValue(file.content);
    this._refresh();
  },

  _refresh : function () {
    var that = this;
    setTimeout(function () {
      var fullHeight = parseInt(that._content.clientHeight);
      var headerHeight = that._filepath.clientHeight;

      that._codeMirror.setSize('auto', fullHeight - headerHeight);
      that._codeMirror.refresh();
    }, 200);
  },

  clearBubbles : function () {
    this._lineWidgets.forEach(function (widget) { widget.clear(); });
    this._lineWidgets = [];
  },

  getMessage : function (event, kind) {
    if (kind === 'macro') {
      var name = 'macro expansion' + (event.name ? ': ' + event.name : '');

      return '<span class="tag macro">' + name + '</span>'
        + this.escapeHTML(event.expansion).replace(/(?:\r\n|\r|\n)/g, '<br>');
    } else if (kind === 'note') {
      return '<span class="tag note">note</span>'
        +  this.escapeHTML(event.message).replace(/(?:\r\n|\r|\n)/g, '<br>');
    }
  },

  addExtraPathEvents : function (events, kind) {
    var that = this;

    if (!events) {
      return;
    }

    events.forEach(function (event) {
      if (event.location.file !== that._currentBugEvent.location.file) {
        return;
      }

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + kind);

      var msg = document.createElement('span');
      msg.innerHTML = that.getMessage(event, kind);
      element.appendChild(msg);

      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  drawBugPath : function () {
    var that = this;

    this.clearBubbles();

    this.addExtraPathEvents(this._currentReport.macros, 'macro');
    this.addExtraPathEvents(this._currentReport.notes, 'note');

    // Processing bug path events.
    var currentEvents = this._currentReport.events;
    currentEvents.forEach(function (event, step) {
      if (event.location.file !== that._currentBugEvent.location.file)
        return;

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';
      var type = step === currentEvents.length - 1 ? 'error' : 'info';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + type);
      element.setAttribute('idx', step);

      var enumeration = document.createElement('span');
      enumeration.setAttribute('class', 'checker-enum ' + type);
      enumeration.innerHTML = step + 1;

      if (currentEvents.length > 1)
        element.appendChild(enumeration);

      var prevBugEvent = step - 1;
      if (step > 0) {
        var prevBug = document.createElement('span');
        prevBug.setAttribute('class', 'arrow left-arrow');
        prevBug.addEventListener('click', function () {
          var event = currentEvents[prevBugEvent];
          that.setCurrentBugEvent(event, prevBugEvent);
        });
        element.appendChild(prevBug);
      }

      var msg = document.createElement('span');
      msg.innerHTML = that.escapeHTML(event.message)
        .replace(/(?:\r\n|\r|\n)/g, '<br>');

      element.appendChild(msg);

      var nextBugEvent = step + 1;
      if (nextBugEvent < currentEvents.length) {
        var nextBug = document.createElement('span');
        nextBug.setAttribute('class', 'arrow right-arrow');
        nextBug.addEventListener('click', function () {
          var event = currentEvents[nextBugEvent];
          that.setCurrentBugEvent(event, nextBugEvent);
        });
        element.appendChild(nextBug);
      }


      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  jumpTo : function (line, column) {
    var that = this;

    setTimeout(function () {
      var selPosPixel
        = that._codeMirror.charCoords({ line : line, ch : column }, 'local');
      var editorSize = {
        width  : that._editor.clientWidth,
        height : that._editor.clientHeight
      };

      that._codeMirror.scrollIntoView({
        top    : selPosPixel.top - 100,
        bottom : selPosPixel.top + editorSize.height - 150,
        left   : selPosPixel.left < editorSize.width - 100
               ? 0
               : selPosPixel.left - 50,
        right  : selPosPixel.left < editorSize.width - 100
               ? 10
               : selPosPixel.left + editorSize.width - 100
      });
    }, 0);
  }
}


      var data = {"files": {"0": {"id": 0, "path": "/src/fs/btrfs/inode.c", "content": "// SPDX-License-Identifier: GPL-2.0\n/*\n * Copyright (C) 2007 Oracle.  All rights reserved.\n */\n\n#include <crypto/hash.h>\n#include <linux/kernel.h>\n#include <linux/bio.h>\n#include <linux/file.h>\n#include <linux/fs.h>\n#include <linux/pagemap.h>\n#include <linux/highmem.h>\n#include <linux/time.h>\n#include <linux/init.h>\n#include <linux/string.h>\n#include <linux/backing-dev.h>\n#include <linux/writeback.h>\n#include <linux/compat.h>\n#include <linux/xattr.h>\n#include <linux/posix_acl.h>\n#include <linux/falloc.h>\n#include <linux/slab.h>\n#include <linux/ratelimit.h>\n#include <linux/btrfs.h>\n#include <linux/blkdev.h>\n#include <linux/posix_acl_xattr.h>\n#include <linux/uio.h>\n#include <linux/magic.h>\n#include <linux/iversion.h>\n#include <linux/swap.h>\n#include <linux/migrate.h>\n#include <linux/sched/mm.h>\n#include <linux/iomap.h>\n#include <asm/unaligned.h>\n#include \"misc.h\"\n#include \"ctree.h\"\n#include \"disk-io.h\"\n#include \"transaction.h\"\n#include \"btrfs_inode.h\"\n#include \"print-tree.h\"\n#include \"ordered-data.h\"\n#include \"xattr.h\"\n#include \"tree-log.h\"\n#include \"volumes.h\"\n#include \"compression.h\"\n#include \"locking.h\"\n#include \"free-space-cache.h\"\n#include \"props.h\"\n#include \"qgroup.h\"\n#include \"delalloc-space.h\"\n#include \"block-group.h\"\n#include \"space-info.h\"\n#include \"zoned.h\"\n\nstruct btrfs_iget_args {\n\tu64 ino;\n\tstruct btrfs_root *root;\n};\n\nstruct btrfs_dio_data {\n\tu64 reserve;\n\tloff_t length;\n\tssize_t submitted;\n\tstruct extent_changeset *data_reserved;\n};\n\nstatic const struct inode_operations btrfs_dir_inode_operations;\nstatic const struct inode_operations btrfs_symlink_inode_operations;\nstatic const struct inode_operations btrfs_special_inode_operations;\nstatic const struct inode_operations btrfs_file_inode_operations;\nstatic const struct address_space_operations btrfs_aops;\nstatic const struct file_operations btrfs_dir_file_operations;\n\nstatic struct kmem_cache *btrfs_inode_cachep;\nstruct kmem_cache *btrfs_trans_handle_cachep;\nstruct kmem_cache *btrfs_path_cachep;\nstruct kmem_cache *btrfs_free_space_cachep;\nstruct kmem_cache *btrfs_free_space_bitmap_cachep;\n\nstatic int btrfs_setsize(struct inode *inode, struct iattr *attr);\nstatic int btrfs_truncate(struct inode *inode, bool skip_writeback);\nstatic int btrfs_finish_ordered_io(struct btrfs_ordered_extent *ordered_extent);\nstatic noinline int cow_file_range(struct btrfs_inode *inode,\n\t\t\t\t   struct page *locked_page,\n\t\t\t\t   u64 start, u64 end, int *page_started,\n\t\t\t\t   unsigned long *nr_written, int unlock);\nstatic struct extent_map *create_io_em(struct btrfs_inode *inode, u64 start,\n\t\t\t\t       u64 len, u64 orig_start, u64 block_start,\n\t\t\t\t       u64 block_len, u64 orig_block_len,\n\t\t\t\t       u64 ram_bytes, int compress_type,\n\t\t\t\t       int type);\n\nstatic void __endio_write_update_ordered(struct btrfs_inode *inode,\n\t\t\t\t\t const u64 offset, const u64 bytes,\n\t\t\t\t\t const bool uptodate);\n\n/*\n * btrfs_inode_lock - lock inode i_rwsem based on arguments passed\n *\n * ilock_flags can have the following bit set:\n *\n * BTRFS_ILOCK_SHARED - acquire a shared lock on the inode\n * BTRFS_ILOCK_TRY - try to acquire the lock, if fails on first attempt\n *\t\t     return -EAGAIN\n */\nint btrfs_inode_lock(struct inode *inode, unsigned int ilock_flags)\n{\n\tif (ilock_flags & BTRFS_ILOCK_SHARED) {\n\t\tif (ilock_flags & BTRFS_ILOCK_TRY) {\n\t\t\tif (!inode_trylock_shared(inode))\n\t\t\t\treturn -EAGAIN;\n\t\t\telse\n\t\t\t\treturn 0;\n\t\t}\n\t\tinode_lock_shared(inode);\n\t} else {\n\t\tif (ilock_flags & BTRFS_ILOCK_TRY) {\n\t\t\tif (!inode_trylock(inode))\n\t\t\t\treturn -EAGAIN;\n\t\t\telse\n\t\t\t\treturn 0;\n\t\t}\n\t\tinode_lock(inode);\n\t}\n\treturn 0;\n}\n\n/*\n * btrfs_inode_unlock - unock inode i_rwsem\n *\n * ilock_flags should contain the same bits set as passed to btrfs_inode_lock()\n * to decide whether the lock acquired is shared or exclusive.\n */\nvoid btrfs_inode_unlock(struct inode *inode, unsigned int ilock_flags)\n{\n\tif (ilock_flags & BTRFS_ILOCK_SHARED)\n\t\tinode_unlock_shared(inode);\n\telse\n\t\tinode_unlock(inode);\n}\n\n/*\n * Cleanup all submitted ordered extents in specified range to handle errors\n * from the btrfs_run_delalloc_range() callback.\n *\n * NOTE: caller must ensure that when an error happens, it can not call\n * extent_clear_unlock_delalloc() to clear both the bits EXTENT_DO_ACCOUNTING\n * and EXTENT_DELALLOC simultaneously, because that causes the reserved metadata\n * to be released, which we want to happen only when finishing the ordered\n * extent (btrfs_finish_ordered_io()).\n */\nstatic inline void btrfs_cleanup_ordered_extents(struct btrfs_inode *inode,\n\t\t\t\t\t\t struct page *locked_page,\n\t\t\t\t\t\t u64 offset, u64 bytes)\n{\n\tunsigned long index = offset >> PAGE_SHIFT;\n\tunsigned long end_index = (offset + bytes - 1) >> PAGE_SHIFT;\n\tu64 page_start = page_offset(locked_page);\n\tu64 page_end = page_start + PAGE_SIZE - 1;\n\n\tstruct page *page;\n\n\twhile (index <= end_index) {\n\t\tpage = find_get_page(inode->vfs_inode.i_mapping, index);\n\t\tindex++;\n\t\tif (!page)\n\t\t\tcontinue;\n\t\tClearPagePrivate2(page);\n\t\tput_page(page);\n\t}\n\n\t/*\n\t * In case this page belongs to the delalloc range being instantiated\n\t * then skip it, since the first page of a range is going to be\n\t * properly cleaned up by the caller of run_delalloc_range\n\t */\n\tif (page_start >= offset && page_end <= (offset + bytes - 1)) {\n\t\toffset += PAGE_SIZE;\n\t\tbytes -= PAGE_SIZE;\n\t}\n\n\treturn __endio_write_update_ordered(inode, offset, bytes, false);\n}\n\nstatic int btrfs_dirty_inode(struct inode *inode);\n\nstatic int btrfs_init_inode_security(struct btrfs_trans_handle *trans,\n\t\t\t\t     struct inode *inode,  struct inode *dir,\n\t\t\t\t     const struct qstr *qstr)\n{\n\tint err;\n\n\terr = btrfs_init_acl(trans, inode, dir);\n\tif (!err)\n\t\terr = btrfs_xattr_security_init(trans, inode, dir, qstr);\n\treturn err;\n}\n\n/*\n * this does all the hard work for inserting an inline extent into\n * the btree.  The caller should have done a btrfs_drop_extents so that\n * no overlapping inline items exist in the btree\n */\nstatic int insert_inline_extent(struct btrfs_trans_handle *trans,\n\t\t\t\tstruct btrfs_path *path, bool extent_inserted,\n\t\t\t\tstruct btrfs_root *root, struct inode *inode,\n\t\t\t\tu64 start, size_t size, size_t compressed_size,\n\t\t\t\tint compress_type,\n\t\t\t\tstruct page **compressed_pages)\n{\n\tstruct extent_buffer *leaf;\n\tstruct page *page = NULL;\n\tchar *kaddr;\n\tunsigned long ptr;\n\tstruct btrfs_file_extent_item *ei;\n\tint ret;\n\tsize_t cur_size = size;\n\tunsigned long offset;\n\n\tASSERT((compressed_size > 0 && compressed_pages) ||\n\t       (compressed_size == 0 && !compressed_pages));\n\n\tif (compressed_size && compressed_pages)\n\t\tcur_size = compressed_size;\n\n\tif (!extent_inserted) {\n\t\tstruct btrfs_key key;\n\t\tsize_t datasize;\n\n\t\tkey.objectid = btrfs_ino(BTRFS_I(inode));\n\t\tkey.offset = start;\n\t\tkey.type = BTRFS_EXTENT_DATA_KEY;\n\n\t\tdatasize = btrfs_file_extent_calc_inline_size(cur_size);\n\t\tret = btrfs_insert_empty_item(trans, root, path, &key,\n\t\t\t\t\t      datasize);\n\t\tif (ret)\n\t\t\tgoto fail;\n\t}\n\tleaf = path->nodes[0];\n\tei = btrfs_item_ptr(leaf, path->slots[0],\n\t\t\t    struct btrfs_file_extent_item);\n\tbtrfs_set_file_extent_generation(leaf, ei, trans->transid);\n\tbtrfs_set_file_extent_type(leaf, ei, BTRFS_FILE_EXTENT_INLINE);\n\tbtrfs_set_file_extent_encryption(leaf, ei, 0);\n\tbtrfs_set_file_extent_other_encoding(leaf, ei, 0);\n\tbtrfs_set_file_extent_ram_bytes(leaf, ei, size);\n\tptr = btrfs_file_extent_inline_start(ei);\n\n\tif (compress_type != BTRFS_COMPRESS_NONE) {\n\t\tstruct page *cpage;\n\t\tint i = 0;\n\t\twhile (compressed_size > 0) {\n\t\t\tcpage = compressed_pages[i];\n\t\t\tcur_size = min_t(unsigned long, compressed_size,\n\t\t\t\t       PAGE_SIZE);\n\n\t\t\tkaddr = kmap_atomic(cpage);\n\t\t\twrite_extent_buffer(leaf, kaddr, ptr, cur_size);\n\t\t\tkunmap_atomic(kaddr);\n\n\t\t\ti++;\n\t\t\tptr += cur_size;\n\t\t\tcompressed_size -= cur_size;\n\t\t}\n\t\tbtrfs_set_file_extent_compression(leaf, ei,\n\t\t\t\t\t\t  compress_type);\n\t} else {\n\t\tpage = find_get_page(inode->i_mapping,\n\t\t\t\t     start >> PAGE_SHIFT);\n\t\tbtrfs_set_file_extent_compression(leaf, ei, 0);\n\t\tkaddr = kmap_atomic(page);\n\t\toffset = offset_in_page(start);\n\t\twrite_extent_buffer(leaf, kaddr + offset, ptr, size);\n\t\tkunmap_atomic(kaddr);\n\t\tput_page(page);\n\t}\n\tbtrfs_mark_buffer_dirty(leaf);\n\tbtrfs_release_path(path);\n\n\t/*\n\t * We align size to sectorsize for inline extents just for simplicity\n\t * sake.\n\t */\n\tsize = ALIGN(size, root->fs_info->sectorsize);\n\tret = btrfs_inode_set_file_extent_range(BTRFS_I(inode), start, size);\n\tif (ret)\n\t\tgoto fail;\n\n\t/*\n\t * we're an inline extent, so nobody can\n\t * extend the file past i_size without locking\n\t * a page we already have locked.\n\t *\n\t * We must do any isize and inode updates\n\t * before we unlock the pages.  Otherwise we\n\t * could end up racing with unlink.\n\t */\n\tBTRFS_I(inode)->disk_i_size = inode->i_size;\nfail:\n\treturn ret;\n}\n\n\n/*\n * conditionally insert an inline extent into the file.  This\n * does the checks required to make sure the data is small enough\n * to fit as an inline extent.\n */\nstatic noinline int cow_file_range_inline(struct btrfs_inode *inode, u64 start,\n\t\t\t\t\t  u64 end, size_t compressed_size,\n\t\t\t\t\t  int compress_type,\n\t\t\t\t\t  struct page **compressed_pages)\n{\n\tstruct btrfs_drop_extents_args drop_args = { 0 };\n\tstruct btrfs_root *root = inode->root;\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tstruct btrfs_trans_handle *trans;\n\tu64 isize = i_size_read(&inode->vfs_inode);\n\tu64 actual_end = min(end + 1, isize);\n\tu64 inline_len = actual_end - start;\n\tu64 aligned_end = ALIGN(end, fs_info->sectorsize);\n\tu64 data_len = inline_len;\n\tint ret;\n\tstruct btrfs_path *path;\n\n\tif (compressed_size)\n\t\tdata_len = compressed_size;\n\n\tif (start > 0 ||\n\t    actual_end > fs_info->sectorsize ||\n\t    data_len > BTRFS_MAX_INLINE_DATA_SIZE(fs_info) ||\n\t    (!compressed_size &&\n\t    (actual_end & (fs_info->sectorsize - 1)) == 0) ||\n\t    end + 1 < isize ||\n\t    data_len > fs_info->max_inline) {\n\t\treturn 1;\n\t}\n\n\tpath = btrfs_alloc_path();\n\tif (!path)\n\t\treturn -ENOMEM;\n\n\ttrans = btrfs_join_transaction(root);\n\tif (IS_ERR(trans)) {\n\t\tbtrfs_free_path(path);\n\t\treturn PTR_ERR(trans);\n\t}\n\ttrans->block_rsv = &inode->block_rsv;\n\n\tdrop_args.path = path;\n\tdrop_args.start = start;\n\tdrop_args.end = aligned_end;\n\tdrop_args.drop_cache = true;\n\tdrop_args.replace_extent = true;\n\n\tif (compressed_size && compressed_pages)\n\t\tdrop_args.extent_item_size = btrfs_file_extent_calc_inline_size(\n\t\t   compressed_size);\n\telse\n\t\tdrop_args.extent_item_size = btrfs_file_extent_calc_inline_size(\n\t\t    inline_len);\n\n\tret = btrfs_drop_extents(trans, root, inode, &drop_args);\n\tif (ret) {\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\tgoto out;\n\t}\n\n\tif (isize > actual_end)\n\t\tinline_len = min_t(u64, isize, actual_end);\n\tret = insert_inline_extent(trans, path, drop_args.extent_inserted,\n\t\t\t\t   root, &inode->vfs_inode, start,\n\t\t\t\t   inline_len, compressed_size,\n\t\t\t\t   compress_type, compressed_pages);\n\tif (ret && ret != -ENOSPC) {\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\tgoto out;\n\t} else if (ret == -ENOSPC) {\n\t\tret = 1;\n\t\tgoto out;\n\t}\n\n\tbtrfs_update_inode_bytes(inode, inline_len, drop_args.bytes_found);\n\tret = btrfs_update_inode(trans, root, inode);\n\tif (ret && ret != -ENOSPC) {\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\tgoto out;\n\t} else if (ret == -ENOSPC) {\n\t\tret = 1;\n\t\tgoto out;\n\t}\n\n\tset_bit(BTRFS_INODE_NEEDS_FULL_SYNC, &inode->runtime_flags);\nout:\n\t/*\n\t * Don't forget to free the reserved space, as for inlined extent\n\t * it won't count as data extent, free them directly here.\n\t * And at reserve time, it's always aligned to page size, so\n\t * just free one page here.\n\t */\n\tbtrfs_qgroup_free_data(inode, NULL, 0, PAGE_SIZE);\n\tbtrfs_free_path(path);\n\tbtrfs_end_transaction(trans);\n\treturn ret;\n}\n\nstruct async_extent {\n\tu64 start;\n\tu64 ram_size;\n\tu64 compressed_size;\n\tstruct page **pages;\n\tunsigned long nr_pages;\n\tint compress_type;\n\tstruct list_head list;\n};\n\nstruct async_chunk {\n\tstruct inode *inode;\n\tstruct page *locked_page;\n\tu64 start;\n\tu64 end;\n\tunsigned int write_flags;\n\tstruct list_head extents;\n\tstruct cgroup_subsys_state *blkcg_css;\n\tstruct btrfs_work work;\n\tatomic_t *pending;\n};\n\nstruct async_cow {\n\t/* Number of chunks in flight; must be first in the structure */\n\tatomic_t num_chunks;\n\tstruct async_chunk chunks[];\n};\n\nstatic noinline int add_async_extent(struct async_chunk *cow,\n\t\t\t\t     u64 start, u64 ram_size,\n\t\t\t\t     u64 compressed_size,\n\t\t\t\t     struct page **pages,\n\t\t\t\t     unsigned long nr_pages,\n\t\t\t\t     int compress_type)\n{\n\tstruct async_extent *async_extent;\n\n\tasync_extent = kmalloc(sizeof(*async_extent), GFP_NOFS);\n\tBUG_ON(!async_extent); /* -ENOMEM */\n\tasync_extent->start = start;\n\tasync_extent->ram_size = ram_size;\n\tasync_extent->compressed_size = compressed_size;\n\tasync_extent->pages = pages;\n\tasync_extent->nr_pages = nr_pages;\n\tasync_extent->compress_type = compress_type;\n\tlist_add_tail(&async_extent->list, &cow->extents);\n\treturn 0;\n}\n\n/*\n * Check if the inode has flags compatible with compression\n */\nstatic inline bool inode_can_compress(struct btrfs_inode *inode)\n{\n\tif (inode->flags & BTRFS_INODE_NODATACOW ||\n\t    inode->flags & BTRFS_INODE_NODATASUM)\n\t\treturn false;\n\treturn true;\n}\n\n/*\n * Check if the inode needs to be submitted to compression, based on mount\n * options, defragmentation, properties or heuristics.\n */\nstatic inline int inode_need_compress(struct btrfs_inode *inode, u64 start,\n\t\t\t\t      u64 end)\n{\n\tstruct btrfs_fs_info *fs_info = inode->root->fs_info;\n\n\tif (!inode_can_compress(inode)) {\n\t\tWARN(IS_ENABLED(CONFIG_BTRFS_DEBUG),\n\t\t\tKERN_ERR \"BTRFS: unexpected compression for ino %llu\\n\",\n\t\t\tbtrfs_ino(inode));\n\t\treturn 0;\n\t}\n\t/* force compress */\n\tif (btrfs_test_opt(fs_info, FORCE_COMPRESS))\n\t\treturn 1;\n\t/* defrag ioctl */\n\tif (inode->defrag_compress)\n\t\treturn 1;\n\t/* bad compression ratios */\n\tif (inode->flags & BTRFS_INODE_NOCOMPRESS)\n\t\treturn 0;\n\tif (btrfs_test_opt(fs_info, COMPRESS) ||\n\t    inode->flags & BTRFS_INODE_COMPRESS ||\n\t    inode->prop_compress)\n\t\treturn btrfs_compress_heuristic(&inode->vfs_inode, start, end);\n\treturn 0;\n}\n\nstatic inline void inode_should_defrag(struct btrfs_inode *inode,\n\t\tu64 start, u64 end, u64 num_bytes, u64 small_write)\n{\n\t/* If this is a small write inside eof, kick off a defrag */\n\tif (num_bytes < small_write &&\n\t    (start > 0 || end + 1 < inode->disk_i_size))\n\t\tbtrfs_add_inode_defrag(NULL, inode);\n}\n\n/*\n * we create compressed extents in two phases.  The first\n * phase compresses a range of pages that have already been\n * locked (both pages and state bits are locked).\n *\n * This is done inside an ordered work queue, and the compression\n * is spread across many cpus.  The actual IO submission is step\n * two, and the ordered work queue takes care of making sure that\n * happens in the same order things were put onto the queue by\n * writepages and friends.\n *\n * If this code finds it can't get good compression, it puts an\n * entry onto the work queue to write the uncompressed bytes.  This\n * makes sure that both compressed inodes and uncompressed inodes\n * are written in the same order that the flusher thread sent them\n * down.\n */\nstatic noinline int compress_file_range(struct async_chunk *async_chunk)\n{\n\tstruct inode *inode = async_chunk->inode;\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);\n\tu64 blocksize = fs_info->sectorsize;\n\tu64 start = async_chunk->start;\n\tu64 end = async_chunk->end;\n\tu64 actual_end;\n\tu64 i_size;\n\tint ret = 0;\n\tstruct page **pages = NULL;\n\tunsigned long nr_pages;\n\tunsigned long total_compressed = 0;\n\tunsigned long total_in = 0;\n\tint i;\n\tint will_compress;\n\tint compress_type = fs_info->compress_type;\n\tint compressed_extents = 0;\n\tint redirty = 0;\n\n\tinode_should_defrag(BTRFS_I(inode), start, end, end - start + 1,\n\t\t\tSZ_16K);\n\n\t/*\n\t * We need to save i_size before now because it could change in between\n\t * us evaluating the size and assigning it.  This is because we lock and\n\t * unlock the page in truncate and fallocate, and then modify the i_size\n\t * later on.\n\t *\n\t * The barriers are to emulate READ_ONCE, remove that once i_size_read\n\t * does that for us.\n\t */\n\tbarrier();\n\ti_size = i_size_read(inode);\n\tbarrier();\n\tactual_end = min_t(u64, i_size, end + 1);\nagain:\n\twill_compress = 0;\n\tnr_pages = (end >> PAGE_SHIFT) - (start >> PAGE_SHIFT) + 1;\n\tBUILD_BUG_ON((BTRFS_MAX_COMPRESSED % PAGE_SIZE) != 0);\n\tnr_pages = min_t(unsigned long, nr_pages,\n\t\t\tBTRFS_MAX_COMPRESSED / PAGE_SIZE);\n\n\t/*\n\t * we don't want to send crud past the end of i_size through\n\t * compression, that's just a waste of CPU time.  So, if the\n\t * end of the file is before the start of our current\n\t * requested range of bytes, we bail out to the uncompressed\n\t * cleanup code that can deal with all of this.\n\t *\n\t * It isn't really the fastest way to fix things, but this is a\n\t * very uncommon corner.\n\t */\n\tif (actual_end <= start)\n\t\tgoto cleanup_and_bail_uncompressed;\n\n\ttotal_compressed = actual_end - start;\n\n\t/*\n\t * skip compression for a small file range(<=blocksize) that\n\t * isn't an inline extent, since it doesn't save disk space at all.\n\t */\n\tif (total_compressed <= blocksize &&\n\t   (start > 0 || end + 1 < BTRFS_I(inode)->disk_i_size))\n\t\tgoto cleanup_and_bail_uncompressed;\n\n\ttotal_compressed = min_t(unsigned long, total_compressed,\n\t\t\tBTRFS_MAX_UNCOMPRESSED);\n\ttotal_in = 0;\n\tret = 0;\n\n\t/*\n\t * we do compression for mount -o compress and when the\n\t * inode has not been flagged as nocompress.  This flag can\n\t * change at any time if we discover bad compression ratios.\n\t */\n\tif (inode_need_compress(BTRFS_I(inode), start, end)) {\n\t\tWARN_ON(pages);\n\t\tpages = kcalloc(nr_pages, sizeof(struct page *), GFP_NOFS);\n\t\tif (!pages) {\n\t\t\t/* just bail out to the uncompressed code */\n\t\t\tnr_pages = 0;\n\t\t\tgoto cont;\n\t\t}\n\n\t\tif (BTRFS_I(inode)->defrag_compress)\n\t\t\tcompress_type = BTRFS_I(inode)->defrag_compress;\n\t\telse if (BTRFS_I(inode)->prop_compress)\n\t\t\tcompress_type = BTRFS_I(inode)->prop_compress;\n\n\t\t/*\n\t\t * we need to call clear_page_dirty_for_io on each\n\t\t * page in the range.  Otherwise applications with the file\n\t\t * mmap'd can wander in and change the page contents while\n\t\t * we are compressing them.\n\t\t *\n\t\t * If the compression fails for any reason, we set the pages\n\t\t * dirty again later on.\n\t\t *\n\t\t * Note that the remaining part is redirtied, the start pointer\n\t\t * has moved, the end is the original one.\n\t\t */\n\t\tif (!redirty) {\n\t\t\textent_range_clear_dirty_for_io(inode, start, end);\n\t\t\tredirty = 1;\n\t\t}\n\n\t\t/* Compression level is applied here and only here */\n\t\tret = btrfs_compress_pages(\n\t\t\tcompress_type | (fs_info->compress_level << 4),\n\t\t\t\t\t   inode->i_mapping, start,\n\t\t\t\t\t   pages,\n\t\t\t\t\t   &nr_pages,\n\t\t\t\t\t   &total_in,\n\t\t\t\t\t   &total_compressed);\n\n\t\tif (!ret) {\n\t\t\tunsigned long offset = offset_in_page(total_compressed);\n\t\t\tstruct page *page = pages[nr_pages - 1];\n\n\t\t\t/* zero the tail end of the last page, we might be\n\t\t\t * sending it down to disk\n\t\t\t */\n\t\t\tif (offset)\n\t\t\t\tzero_user(page, offset, PAGE_SIZE - offset);\n\t\t\twill_compress = 1;\n\t\t}\n\t}\ncont:\n\tif (start == 0) {\n\t\t/* lets try to make an inline extent */\n\t\tif (ret || total_in < actual_end) {\n\t\t\t/* we didn't compress the entire range, try\n\t\t\t * to make an uncompressed inline extent.\n\t\t\t */\n\t\t\tret = cow_file_range_inline(BTRFS_I(inode), start, end,\n\t\t\t\t\t\t    0, BTRFS_COMPRESS_NONE,\n\t\t\t\t\t\t    NULL);\n\t\t} else {\n\t\t\t/* try making a compressed inline extent */\n\t\t\tret = cow_file_range_inline(BTRFS_I(inode), start, end,\n\t\t\t\t\t\t    total_compressed,\n\t\t\t\t\t\t    compress_type, pages);\n\t\t}\n\t\tif (ret <= 0) {\n\t\t\tunsigned long clear_flags = EXTENT_DELALLOC |\n\t\t\t\tEXTENT_DELALLOC_NEW | EXTENT_DEFRAG |\n\t\t\t\tEXTENT_DO_ACCOUNTING;\n\t\t\tunsigned long page_error_op;\n\n\t\t\tpage_error_op = ret < 0 ? PAGE_SET_ERROR : 0;\n\n\t\t\t/*\n\t\t\t * inline extent creation worked or returned error,\n\t\t\t * we don't need to create any more async work items.\n\t\t\t * Unlock and free up our temp pages.\n\t\t\t *\n\t\t\t * We use DO_ACCOUNTING here because we need the\n\t\t\t * delalloc_release_metadata to be done _after_ we drop\n\t\t\t * our outstanding extent for clearing delalloc for this\n\t\t\t * range.\n\t\t\t */\n\t\t\textent_clear_unlock_delalloc(BTRFS_I(inode), start, end,\n\t\t\t\t\t\t     NULL,\n\t\t\t\t\t\t     clear_flags,\n\t\t\t\t\t\t     PAGE_UNLOCK |\n\t\t\t\t\t\t     PAGE_START_WRITEBACK |\n\t\t\t\t\t\t     page_error_op |\n\t\t\t\t\t\t     PAGE_END_WRITEBACK);\n\n\t\t\t/*\n\t\t\t * Ensure we only free the compressed pages if we have\n\t\t\t * them allocated, as we can still reach here with\n\t\t\t * inode_need_compress() == false.\n\t\t\t */\n\t\t\tif (pages) {\n\t\t\t\tfor (i = 0; i < nr_pages; i++) {\n\t\t\t\t\tWARN_ON(pages[i]->mapping);\n\t\t\t\t\tput_page(pages[i]);\n\t\t\t\t}\n\t\t\t\tkfree(pages);\n\t\t\t}\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tif (will_compress) {\n\t\t/*\n\t\t * we aren't doing an inline extent round the compressed size\n\t\t * up to a block size boundary so the allocator does sane\n\t\t * things\n\t\t */\n\t\ttotal_compressed = ALIGN(total_compressed, blocksize);\n\n\t\t/*\n\t\t * one last check to make sure the compression is really a\n\t\t * win, compare the page count read with the blocks on disk,\n\t\t * compression must free at least one sector size\n\t\t */\n\t\ttotal_in = ALIGN(total_in, PAGE_SIZE);\n\t\tif (total_compressed + blocksize <= total_in) {\n\t\t\tcompressed_extents++;\n\n\t\t\t/*\n\t\t\t * The async work queues will take care of doing actual\n\t\t\t * allocation on disk for these compressed pages, and\n\t\t\t * will submit them to the elevator.\n\t\t\t */\n\t\t\tadd_async_extent(async_chunk, start, total_in,\n\t\t\t\t\ttotal_compressed, pages, nr_pages,\n\t\t\t\t\tcompress_type);\n\n\t\t\tif (start + total_in < end) {\n\t\t\t\tstart += total_in;\n\t\t\t\tpages = NULL;\n\t\t\t\tcond_resched();\n\t\t\t\tgoto again;\n\t\t\t}\n\t\t\treturn compressed_extents;\n\t\t}\n\t}\n\tif (pages) {\n\t\t/*\n\t\t * the compression code ran but failed to make things smaller,\n\t\t * free any pages it allocated and our page pointer array\n\t\t */\n\t\tfor (i = 0; i < nr_pages; i++) {\n\t\t\tWARN_ON(pages[i]->mapping);\n\t\t\tput_page(pages[i]);\n\t\t}\n\t\tkfree(pages);\n\t\tpages = NULL;\n\t\ttotal_compressed = 0;\n\t\tnr_pages = 0;\n\n\t\t/* flag the file so we don't compress in the future */\n\t\tif (!btrfs_test_opt(fs_info, FORCE_COMPRESS) &&\n\t\t    !(BTRFS_I(inode)->prop_compress)) {\n\t\t\tBTRFS_I(inode)->flags |= BTRFS_INODE_NOCOMPRESS;\n\t\t}\n\t}\ncleanup_and_bail_uncompressed:\n\t/*\n\t * No compression, but we still need to write the pages in the file\n\t * we've been given so far.  redirty the locked page if it corresponds\n\t * to our extent and set things up for the async work queue to run\n\t * cow_file_range to do the normal delalloc dance.\n\t */\n\tif (async_chunk->locked_page &&\n\t    (page_offset(async_chunk->locked_page) >= start &&\n\t     page_offset(async_chunk->locked_page)) <= end) {\n\t\t__set_page_dirty_nobuffers(async_chunk->locked_page);\n\t\t/* unlocked later on in the async handlers */\n\t}\n\n\tif (redirty)\n\t\textent_range_redirty_for_io(inode, start, end);\n\tadd_async_extent(async_chunk, start, end - start + 1, 0, NULL, 0,\n\t\t\t BTRFS_COMPRESS_NONE);\n\tcompressed_extents++;\n\n\treturn compressed_extents;\n}\n\nstatic void free_async_extent_pages(struct async_extent *async_extent)\n{\n\tint i;\n\n\tif (!async_extent->pages)\n\t\treturn;\n\n\tfor (i = 0; i < async_extent->nr_pages; i++) {\n\t\tWARN_ON(async_extent->pages[i]->mapping);\n\t\tput_page(async_extent->pages[i]);\n\t}\n\tkfree(async_extent->pages);\n\tasync_extent->nr_pages = 0;\n\tasync_extent->pages = NULL;\n}\n\n/*\n * phase two of compressed writeback.  This is the ordered portion\n * of the code, which only gets called in the order the work was\n * queued.  We walk all the async extents created by compress_file_range\n * and send them down to the disk.\n */\nstatic noinline void submit_compressed_extents(struct async_chunk *async_chunk)\n{\n\tstruct btrfs_inode *inode = BTRFS_I(async_chunk->inode);\n\tstruct btrfs_fs_info *fs_info = inode->root->fs_info;\n\tstruct async_extent *async_extent;\n\tu64 alloc_hint = 0;\n\tstruct btrfs_key ins;\n\tstruct extent_map *em;\n\tstruct btrfs_root *root = inode->root;\n\tstruct extent_io_tree *io_tree = &inode->io_tree;\n\tint ret = 0;\n\nagain:\n\twhile (!list_empty(&async_chunk->extents)) {\n\t\tasync_extent = list_entry(async_chunk->extents.next,\n\t\t\t\t\t  struct async_extent, list);\n\t\tlist_del(&async_extent->list);\n\nretry:\n\t\tlock_extent(io_tree, async_extent->start,\n\t\t\t    async_extent->start + async_extent->ram_size - 1);\n\t\t/* did the compression code fall back to uncompressed IO? */\n\t\tif (!async_extent->pages) {\n\t\t\tint page_started = 0;\n\t\t\tunsigned long nr_written = 0;\n\n\t\t\t/* allocate blocks */\n\t\t\tret = cow_file_range(inode, async_chunk->locked_page,\n\t\t\t\t\t     async_extent->start,\n\t\t\t\t\t     async_extent->start +\n\t\t\t\t\t     async_extent->ram_size - 1,\n\t\t\t\t\t     &page_started, &nr_written, 0);\n\n\t\t\t/* JDM XXX */\n\n\t\t\t/*\n\t\t\t * if page_started, cow_file_range inserted an\n\t\t\t * inline extent and took care of all the unlocking\n\t\t\t * and IO for us.  Otherwise, we need to submit\n\t\t\t * all those pages down to the drive.\n\t\t\t */\n\t\t\tif (!page_started && !ret)\n\t\t\t\textent_write_locked_range(&inode->vfs_inode,\n\t\t\t\t\t\t  async_extent->start,\n\t\t\t\t\t\t  async_extent->start +\n\t\t\t\t\t\t  async_extent->ram_size - 1,\n\t\t\t\t\t\t  WB_SYNC_ALL);\n\t\t\telse if (ret && async_chunk->locked_page)\n\t\t\t\tunlock_page(async_chunk->locked_page);\n\t\t\tkfree(async_extent);\n\t\t\tcond_resched();\n\t\t\tcontinue;\n\t\t}\n\n\t\tret = btrfs_reserve_extent(root, async_extent->ram_size,\n\t\t\t\t\t   async_extent->compressed_size,\n\t\t\t\t\t   async_extent->compressed_size,\n\t\t\t\t\t   0, alloc_hint, &ins, 1, 1);\n\t\tif (ret) {\n\t\t\tfree_async_extent_pages(async_extent);\n\n\t\t\tif (ret == -ENOSPC) {\n\t\t\t\tunlock_extent(io_tree, async_extent->start,\n\t\t\t\t\t      async_extent->start +\n\t\t\t\t\t      async_extent->ram_size - 1);\n\n\t\t\t\t/*\n\t\t\t\t * we need to redirty the pages if we decide to\n\t\t\t\t * fallback to uncompressed IO, otherwise we\n\t\t\t\t * will not submit these pages down to lower\n\t\t\t\t * layers.\n\t\t\t\t */\n\t\t\t\textent_range_redirty_for_io(&inode->vfs_inode,\n\t\t\t\t\t\tasync_extent->start,\n\t\t\t\t\t\tasync_extent->start +\n\t\t\t\t\t\tasync_extent->ram_size - 1);\n\n\t\t\t\tgoto retry;\n\t\t\t}\n\t\t\tgoto out_free;\n\t\t}\n\t\t/*\n\t\t * here we're doing allocation and writeback of the\n\t\t * compressed pages\n\t\t */\n\t\tem = create_io_em(inode, async_extent->start,\n\t\t\t\t  async_extent->ram_size, /* len */\n\t\t\t\t  async_extent->start, /* orig_start */\n\t\t\t\t  ins.objectid, /* block_start */\n\t\t\t\t  ins.offset, /* block_len */\n\t\t\t\t  ins.offset, /* orig_block_len */\n\t\t\t\t  async_extent->ram_size, /* ram_bytes */\n\t\t\t\t  async_extent->compress_type,\n\t\t\t\t  BTRFS_ORDERED_COMPRESSED);\n\t\tif (IS_ERR(em))\n\t\t\t/* ret value is not necessary due to void function */\n\t\t\tgoto out_free_reserve;\n\t\tfree_extent_map(em);\n\n\t\tret = btrfs_add_ordered_extent_compress(inode,\n\t\t\t\t\t\tasync_extent->start,\n\t\t\t\t\t\tins.objectid,\n\t\t\t\t\t\tasync_extent->ram_size,\n\t\t\t\t\t\tins.offset,\n\t\t\t\t\t\tasync_extent->compress_type);\n\t\tif (ret) {\n\t\t\tbtrfs_drop_extent_cache(inode, async_extent->start,\n\t\t\t\t\t\tasync_extent->start +\n\t\t\t\t\t\tasync_extent->ram_size - 1, 0);\n\t\t\tgoto out_free_reserve;\n\t\t}\n\t\tbtrfs_dec_block_group_reservations(fs_info, ins.objectid);\n\n\t\t/*\n\t\t * clear dirty, set writeback and unlock the pages.\n\t\t */\n\t\textent_clear_unlock_delalloc(inode, async_extent->start,\n\t\t\t\tasync_extent->start +\n\t\t\t\tasync_extent->ram_size - 1,\n\t\t\t\tNULL, EXTENT_LOCKED | EXTENT_DELALLOC,\n\t\t\t\tPAGE_UNLOCK | PAGE_START_WRITEBACK);\n\t\tif (btrfs_submit_compressed_write(inode, async_extent->start,\n\t\t\t\t    async_extent->ram_size,\n\t\t\t\t    ins.objectid,\n\t\t\t\t    ins.offset, async_extent->pages,\n\t\t\t\t    async_extent->nr_pages,\n\t\t\t\t    async_chunk->write_flags,\n\t\t\t\t    async_chunk->blkcg_css)) {\n\t\t\tstruct page *p = async_extent->pages[0];\n\t\t\tconst u64 start = async_extent->start;\n\t\t\tconst u64 end = start + async_extent->ram_size - 1;\n\n\t\t\tp->mapping = inode->vfs_inode.i_mapping;\n\t\t\tbtrfs_writepage_endio_finish_ordered(p, start, end, 0);\n\n\t\t\tp->mapping = NULL;\n\t\t\textent_clear_unlock_delalloc(inode, start, end, NULL, 0,\n\t\t\t\t\t\t     PAGE_END_WRITEBACK |\n\t\t\t\t\t\t     PAGE_SET_ERROR);\n\t\t\tfree_async_extent_pages(async_extent);\n\t\t}\n\t\talloc_hint = ins.objectid + ins.offset;\n\t\tkfree(async_extent);\n\t\tcond_resched();\n\t}\n\treturn;\nout_free_reserve:\n\tbtrfs_dec_block_group_reservations(fs_info, ins.objectid);\n\tbtrfs_free_reserved_extent(fs_info, ins.objectid, ins.offset, 1);\nout_free:\n\textent_clear_unlock_delalloc(inode, async_extent->start,\n\t\t\t\t     async_extent->start +\n\t\t\t\t     async_extent->ram_size - 1,\n\t\t\t\t     NULL, EXTENT_LOCKED | EXTENT_DELALLOC |\n\t\t\t\t     EXTENT_DELALLOC_NEW |\n\t\t\t\t     EXTENT_DEFRAG | EXTENT_DO_ACCOUNTING,\n\t\t\t\t     PAGE_UNLOCK | PAGE_START_WRITEBACK |\n\t\t\t\t     PAGE_END_WRITEBACK | PAGE_SET_ERROR);\n\tfree_async_extent_pages(async_extent);\n\tkfree(async_extent);\n\tgoto again;\n}\n\nstatic u64 get_extent_allocation_hint(struct btrfs_inode *inode, u64 start,\n\t\t\t\t      u64 num_bytes)\n{\n\tstruct extent_map_tree *em_tree = &inode->extent_tree;\n\tstruct extent_map *em;\n\tu64 alloc_hint = 0;\n\n\tread_lock(&em_tree->lock);\n\tem = search_extent_mapping(em_tree, start, num_bytes);\n\tif (em) {\n\t\t/*\n\t\t * if block start isn't an actual block number then find the\n\t\t * first block in this inode and use that as a hint.  If that\n\t\t * block is also bogus then just don't worry about it.\n\t\t */\n\t\tif (em->block_start >= EXTENT_MAP_LAST_BYTE) {\n\t\t\tfree_extent_map(em);\n\t\t\tem = search_extent_mapping(em_tree, 0, 0);\n\t\t\tif (em && em->block_start < EXTENT_MAP_LAST_BYTE)\n\t\t\t\talloc_hint = em->block_start;\n\t\t\tif (em)\n\t\t\t\tfree_extent_map(em);\n\t\t} else {\n\t\t\talloc_hint = em->block_start;\n\t\t\tfree_extent_map(em);\n\t\t}\n\t}\n\tread_unlock(&em_tree->lock);\n\n\treturn alloc_hint;\n}\n\n/*\n * when extent_io.c finds a delayed allocation range in the file,\n * the call backs end up in this code.  The basic idea is to\n * allocate extents on disk for the range, and create ordered data structs\n * in ram to track those extents.\n *\n * locked_page is the page that writepage had locked already.  We use\n * it to make sure we don't do extra locks or unlocks.\n *\n * *page_started is set to one if we unlock locked_page and do everything\n * required to start IO on it.  It may be clean and already done with\n * IO when we return.\n */\nstatic noinline int cow_file_range(struct btrfs_inode *inode,\n\t\t\t\t   struct page *locked_page,\n\t\t\t\t   u64 start, u64 end, int *page_started,\n\t\t\t\t   unsigned long *nr_written, int unlock)\n{\n\tstruct btrfs_root *root = inode->root;\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tu64 alloc_hint = 0;\n\tu64 num_bytes;\n\tunsigned long ram_size;\n\tu64 cur_alloc_size = 0;\n\tu64 min_alloc_size;\n\tu64 blocksize = fs_info->sectorsize;\n\tstruct btrfs_key ins;\n\tstruct extent_map *em;\n\tunsigned clear_bits;\n\tunsigned long page_ops;\n\tbool extent_reserved = false;\n\tint ret = 0;\n\n\tif (btrfs_is_free_space_inode(inode)) {\n\t\tWARN_ON_ONCE(1);\n\t\tret = -EINVAL;\n\t\tgoto out_unlock;\n\t}\n\n\tnum_bytes = ALIGN(end - start + 1, blocksize);\n\tnum_bytes = max(blocksize,  num_bytes);\n\tASSERT(num_bytes <= btrfs_super_total_bytes(fs_info->super_copy));\n\n\tinode_should_defrag(inode, start, end, num_bytes, SZ_64K);\n\n\tif (start == 0) {\n\t\t/* lets try to make an inline extent */\n\t\tret = cow_file_range_inline(inode, start, end, 0,\n\t\t\t\t\t    BTRFS_COMPRESS_NONE, NULL);\n\t\tif (ret == 0) {\n\t\t\t/*\n\t\t\t * We use DO_ACCOUNTING here because we need the\n\t\t\t * delalloc_release_metadata to be run _after_ we drop\n\t\t\t * our outstanding extent for clearing delalloc for this\n\t\t\t * range.\n\t\t\t */\n\t\t\textent_clear_unlock_delalloc(inode, start, end, NULL,\n\t\t\t\t     EXTENT_LOCKED | EXTENT_DELALLOC |\n\t\t\t\t     EXTENT_DELALLOC_NEW | EXTENT_DEFRAG |\n\t\t\t\t     EXTENT_DO_ACCOUNTING, PAGE_UNLOCK |\n\t\t\t\t     PAGE_START_WRITEBACK | PAGE_END_WRITEBACK);\n\t\t\t*nr_written = *nr_written +\n\t\t\t     (end - start + PAGE_SIZE) / PAGE_SIZE;\n\t\t\t*page_started = 1;\n\t\t\tgoto out;\n\t\t} else if (ret < 0) {\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\talloc_hint = get_extent_allocation_hint(inode, start, num_bytes);\n\tbtrfs_drop_extent_cache(inode, start, start + num_bytes - 1, 0);\n\n\t/*\n\t * Relocation relies on the relocated extents to have exactly the same\n\t * size as the original extents. Normally writeback for relocation data\n\t * extents follows a NOCOW path because relocation preallocates the\n\t * extents. However, due to an operation such as scrub turning a block\n\t * group to RO mode, it may fallback to COW mode, so we must make sure\n\t * an extent allocated during COW has exactly the requested size and can\n\t * not be split into smaller extents, otherwise relocation breaks and\n\t * fails during the stage where it updates the bytenr of file extent\n\t * items.\n\t */\n\tif (root->root_key.objectid == BTRFS_DATA_RELOC_TREE_OBJECTID)\n\t\tmin_alloc_size = num_bytes;\n\telse\n\t\tmin_alloc_size = fs_info->sectorsize;\n\n\twhile (num_bytes > 0) {\n\t\tcur_alloc_size = num_bytes;\n\t\tret = btrfs_reserve_extent(root, cur_alloc_size, cur_alloc_size,\n\t\t\t\t\t   min_alloc_size, 0, alloc_hint,\n\t\t\t\t\t   &ins, 1, 1);\n\t\tif (ret < 0)\n\t\t\tgoto out_unlock;\n\t\tcur_alloc_size = ins.offset;\n\t\textent_reserved = true;\n\n\t\tram_size = ins.offset;\n\t\tem = create_io_em(inode, start, ins.offset, /* len */\n\t\t\t\t  start, /* orig_start */\n\t\t\t\t  ins.objectid, /* block_start */\n\t\t\t\t  ins.offset, /* block_len */\n\t\t\t\t  ins.offset, /* orig_block_len */\n\t\t\t\t  ram_size, /* ram_bytes */\n\t\t\t\t  BTRFS_COMPRESS_NONE, /* compress_type */\n\t\t\t\t  BTRFS_ORDERED_REGULAR /* type */);\n\t\tif (IS_ERR(em)) {\n\t\t\tret = PTR_ERR(em);\n\t\t\tgoto out_reserve;\n\t\t}\n\t\tfree_extent_map(em);\n\n\t\tret = btrfs_add_ordered_extent(inode, start, ins.objectid,\n\t\t\t\t\t       ram_size, cur_alloc_size,\n\t\t\t\t\t       BTRFS_ORDERED_REGULAR);\n\t\tif (ret)\n\t\t\tgoto out_drop_extent_cache;\n\n\t\tif (root->root_key.objectid ==\n\t\t    BTRFS_DATA_RELOC_TREE_OBJECTID) {\n\t\t\tret = btrfs_reloc_clone_csums(inode, start,\n\t\t\t\t\t\t      cur_alloc_size);\n\t\t\t/*\n\t\t\t * Only drop cache here, and process as normal.\n\t\t\t *\n\t\t\t * We must not allow extent_clear_unlock_delalloc()\n\t\t\t * at out_unlock label to free meta of this ordered\n\t\t\t * extent, as its meta should be freed by\n\t\t\t * btrfs_finish_ordered_io().\n\t\t\t *\n\t\t\t * So we must continue until @start is increased to\n\t\t\t * skip current ordered extent.\n\t\t\t */\n\t\t\tif (ret)\n\t\t\t\tbtrfs_drop_extent_cache(inode, start,\n\t\t\t\t\t\tstart + ram_size - 1, 0);\n\t\t}\n\n\t\tbtrfs_dec_block_group_reservations(fs_info, ins.objectid);\n\n\t\t/* we're not doing compressed IO, don't unlock the first\n\t\t * page (which the caller expects to stay locked), don't\n\t\t * clear any dirty bits and don't set any writeback bits\n\t\t *\n\t\t * Do set the Private2 bit so we know this page was properly\n\t\t * setup for writepage\n\t\t */\n\t\tpage_ops = unlock ? PAGE_UNLOCK : 0;\n\t\tpage_ops |= PAGE_SET_PRIVATE2;\n\n\t\textent_clear_unlock_delalloc(inode, start, start + ram_size - 1,\n\t\t\t\t\t     locked_page,\n\t\t\t\t\t     EXTENT_LOCKED | EXTENT_DELALLOC,\n\t\t\t\t\t     page_ops);\n\t\tif (num_bytes < cur_alloc_size)\n\t\t\tnum_bytes = 0;\n\t\telse\n\t\t\tnum_bytes -= cur_alloc_size;\n\t\talloc_hint = ins.objectid + ins.offset;\n\t\tstart += cur_alloc_size;\n\t\textent_reserved = false;\n\n\t\t/*\n\t\t * btrfs_reloc_clone_csums() error, since start is increased\n\t\t * extent_clear_unlock_delalloc() at out_unlock label won't\n\t\t * free metadata of current ordered extent, we're OK to exit.\n\t\t */\n\t\tif (ret)\n\t\t\tgoto out_unlock;\n\t}\nout:\n\treturn ret;\n\nout_drop_extent_cache:\n\tbtrfs_drop_extent_cache(inode, start, start + ram_size - 1, 0);\nout_reserve:\n\tbtrfs_dec_block_group_reservations(fs_info, ins.objectid);\n\tbtrfs_free_reserved_extent(fs_info, ins.objectid, ins.offset, 1);\nout_unlock:\n\tclear_bits = EXTENT_LOCKED | EXTENT_DELALLOC | EXTENT_DELALLOC_NEW |\n\t\tEXTENT_DEFRAG | EXTENT_CLEAR_META_RESV;\n\tpage_ops = PAGE_UNLOCK | PAGE_START_WRITEBACK | PAGE_END_WRITEBACK;\n\t/*\n\t * If we reserved an extent for our delalloc range (or a subrange) and\n\t * failed to create the respective ordered extent, then it means that\n\t * when we reserved the extent we decremented the extent's size from\n\t * the data space_info's bytes_may_use counter and incremented the\n\t * space_info's bytes_reserved counter by the same amount. We must make\n\t * sure extent_clear_unlock_delalloc() does not try to decrement again\n\t * the data space_info's bytes_may_use counter, therefore we do not pass\n\t * it the flag EXTENT_CLEAR_DATA_RESV.\n\t */\n\tif (extent_reserved) {\n\t\textent_clear_unlock_delalloc(inode, start,\n\t\t\t\t\t     start + cur_alloc_size - 1,\n\t\t\t\t\t     locked_page,\n\t\t\t\t\t     clear_bits,\n\t\t\t\t\t     page_ops);\n\t\tstart += cur_alloc_size;\n\t\tif (start >= end)\n\t\t\tgoto out;\n\t}\n\textent_clear_unlock_delalloc(inode, start, end, locked_page,\n\t\t\t\t     clear_bits | EXTENT_CLEAR_DATA_RESV,\n\t\t\t\t     page_ops);\n\tgoto out;\n}\n\n/*\n * work queue call back to started compression on a file and pages\n */\nstatic noinline void async_cow_start(struct btrfs_work *work)\n{\n\tstruct async_chunk *async_chunk;\n\tint compressed_extents;\n\n\tasync_chunk = container_of(work, struct async_chunk, work);\n\n\tcompressed_extents = compress_file_range(async_chunk);\n\tif (compressed_extents == 0) {\n\t\tbtrfs_add_delayed_iput(async_chunk->inode);\n\t\tasync_chunk->inode = NULL;\n\t}\n}\n\n/*\n * work queue call back to submit previously compressed pages\n */\nstatic noinline void async_cow_submit(struct btrfs_work *work)\n{\n\tstruct async_chunk *async_chunk = container_of(work, struct async_chunk,\n\t\t\t\t\t\t     work);\n\tstruct btrfs_fs_info *fs_info = btrfs_work_owner(work);\n\tunsigned long nr_pages;\n\n\tnr_pages = (async_chunk->end - async_chunk->start + PAGE_SIZE) >>\n\t\tPAGE_SHIFT;\n\n\t/* atomic_sub_return implies a barrier */\n\tif (atomic_sub_return(nr_pages, &fs_info->async_delalloc_pages) <\n\t    5 * SZ_1M)\n\t\tcond_wake_up_nomb(&fs_info->async_submit_wait);\n\n\t/*\n\t * ->inode could be NULL if async_chunk_start has failed to compress,\n\t * in which case we don't have anything to submit, yet we need to\n\t * always adjust ->async_delalloc_pages as its paired with the init\n\t * happening in cow_file_range_async\n\t */\n\tif (async_chunk->inode)\n\t\tsubmit_compressed_extents(async_chunk);\n}\n\nstatic noinline void async_cow_free(struct btrfs_work *work)\n{\n\tstruct async_chunk *async_chunk;\n\n\tasync_chunk = container_of(work, struct async_chunk, work);\n\tif (async_chunk->inode)\n\t\tbtrfs_add_delayed_iput(async_chunk->inode);\n\tif (async_chunk->blkcg_css)\n\t\tcss_put(async_chunk->blkcg_css);\n\t/*\n\t * Since the pointer to 'pending' is at the beginning of the array of\n\t * async_chunk's, freeing it ensures the whole array has been freed.\n\t */\n\tif (atomic_dec_and_test(async_chunk->pending))\n\t\tkvfree(async_chunk->pending);\n}\n\nstatic int cow_file_range_async(struct btrfs_inode *inode,\n\t\t\t\tstruct writeback_control *wbc,\n\t\t\t\tstruct page *locked_page,\n\t\t\t\tu64 start, u64 end, int *page_started,\n\t\t\t\tunsigned long *nr_written)\n{\n\tstruct btrfs_fs_info *fs_info = inode->root->fs_info;\n\tstruct cgroup_subsys_state *blkcg_css = wbc_blkcg_css(wbc);\n\tstruct async_cow *ctx;\n\tstruct async_chunk *async_chunk;\n\tunsigned long nr_pages;\n\tu64 cur_end;\n\tu64 num_chunks = DIV_ROUND_UP(end - start, SZ_512K);\n\tint i;\n\tbool should_compress;\n\tunsigned nofs_flag;\n\tconst unsigned int write_flags = wbc_to_write_flags(wbc);\n\n\tunlock_extent(&inode->io_tree, start, end);\n\n\tif (inode->flags & BTRFS_INODE_NOCOMPRESS &&\n\t    !btrfs_test_opt(fs_info, FORCE_COMPRESS)) {\n\t\tnum_chunks = 1;\n\t\tshould_compress = false;\n\t} else {\n\t\tshould_compress = true;\n\t}\n\n\tnofs_flag = memalloc_nofs_save();\n\tctx = kvmalloc(struct_size(ctx, chunks, num_chunks), GFP_KERNEL);\n\tmemalloc_nofs_restore(nofs_flag);\n\n\tif (!ctx) {\n\t\tunsigned clear_bits = EXTENT_LOCKED | EXTENT_DELALLOC |\n\t\t\tEXTENT_DELALLOC_NEW | EXTENT_DEFRAG |\n\t\t\tEXTENT_DO_ACCOUNTING;\n\t\tunsigned long page_ops = PAGE_UNLOCK | PAGE_START_WRITEBACK |\n\t\t\t\t\t PAGE_END_WRITEBACK | PAGE_SET_ERROR;\n\n\t\textent_clear_unlock_delalloc(inode, start, end, locked_page,\n\t\t\t\t\t     clear_bits, page_ops);\n\t\treturn -ENOMEM;\n\t}\n\n\tasync_chunk = ctx->chunks;\n\tatomic_set(&ctx->num_chunks, num_chunks);\n\n\tfor (i = 0; i < num_chunks; i++) {\n\t\tif (should_compress)\n\t\t\tcur_end = min(end, start + SZ_512K - 1);\n\t\telse\n\t\t\tcur_end = end;\n\n\t\t/*\n\t\t * igrab is called higher up in the call chain, take only the\n\t\t * lightweight reference for the callback lifetime\n\t\t */\n\t\tihold(&inode->vfs_inode);\n\t\tasync_chunk[i].pending = &ctx->num_chunks;\n\t\tasync_chunk[i].inode = &inode->vfs_inode;\n\t\tasync_chunk[i].start = start;\n\t\tasync_chunk[i].end = cur_end;\n\t\tasync_chunk[i].write_flags = write_flags;\n\t\tINIT_LIST_HEAD(&async_chunk[i].extents);\n\n\t\t/*\n\t\t * The locked_page comes all the way from writepage and its\n\t\t * the original page we were actually given.  As we spread\n\t\t * this large delalloc region across multiple async_chunk\n\t\t * structs, only the first struct needs a pointer to locked_page\n\t\t *\n\t\t * This way we don't need racey decisions about who is supposed\n\t\t * to unlock it.\n\t\t */\n\t\tif (locked_page) {\n\t\t\t/*\n\t\t\t * Depending on the compressibility, the pages might or\n\t\t\t * might not go through async.  We want all of them to\n\t\t\t * be accounted against wbc once.  Let's do it here\n\t\t\t * before the paths diverge.  wbc accounting is used\n\t\t\t * only for foreign writeback detection and doesn't\n\t\t\t * need full accuracy.  Just account the whole thing\n\t\t\t * against the first page.\n\t\t\t */\n\t\t\twbc_account_cgroup_owner(wbc, locked_page,\n\t\t\t\t\t\t cur_end - start);\n\t\t\tasync_chunk[i].locked_page = locked_page;\n\t\t\tlocked_page = NULL;\n\t\t} else {\n\t\t\tasync_chunk[i].locked_page = NULL;\n\t\t}\n\n\t\tif (blkcg_css != blkcg_root_css) {\n\t\t\tcss_get(blkcg_css);\n\t\t\tasync_chunk[i].blkcg_css = blkcg_css;\n\t\t} else {\n\t\t\tasync_chunk[i].blkcg_css = NULL;\n\t\t}\n\n\t\tbtrfs_init_work(&async_chunk[i].work, async_cow_start,\n\t\t\t\tasync_cow_submit, async_cow_free);\n\n\t\tnr_pages = DIV_ROUND_UP(cur_end - start, PAGE_SIZE);\n\t\tatomic_add(nr_pages, &fs_info->async_delalloc_pages);\n\n\t\tbtrfs_queue_work(fs_info->delalloc_workers, &async_chunk[i].work);\n\n\t\t*nr_written += nr_pages;\n\t\tstart = cur_end + 1;\n\t}\n\t*page_started = 1;\n\treturn 0;\n}\n\nstatic noinline int run_delalloc_zoned(struct btrfs_inode *inode,\n\t\t\t\t       struct page *locked_page, u64 start,\n\t\t\t\t       u64 end, int *page_started,\n\t\t\t\t       unsigned long *nr_written)\n{\n\tint ret;\n\n\tret = cow_file_range(inode, locked_page, start, end, page_started,\n\t\t\t     nr_written, 0);\n\tif (ret)\n\t\treturn ret;\n\n\tif (*page_started)\n\t\treturn 0;\n\n\t__set_page_dirty_nobuffers(locked_page);\n\taccount_page_redirty(locked_page);\n\textent_write_locked_range(&inode->vfs_inode, start, end, WB_SYNC_ALL);\n\t*page_started = 1;\n\n\treturn 0;\n}\n\nstatic noinline int csum_exist_in_range(struct btrfs_fs_info *fs_info,\n\t\t\t\t\tu64 bytenr, u64 num_bytes)\n{\n\tint ret;\n\tstruct btrfs_ordered_sum *sums;\n\tLIST_HEAD(list);\n\n\tret = btrfs_lookup_csums_range(fs_info->csum_root, bytenr,\n\t\t\t\t       bytenr + num_bytes - 1, &list, 0);\n\tif (ret == 0 && list_empty(&list))\n\t\treturn 0;\n\n\twhile (!list_empty(&list)) {\n\t\tsums = list_entry(list.next, struct btrfs_ordered_sum, list);\n\t\tlist_del(&sums->list);\n\t\tkfree(sums);\n\t}\n\tif (ret < 0)\n\t\treturn ret;\n\treturn 1;\n}\n\nstatic int fallback_to_cow(struct btrfs_inode *inode, struct page *locked_page,\n\t\t\t   const u64 start, const u64 end,\n\t\t\t   int *page_started, unsigned long *nr_written)\n{\n\tconst bool is_space_ino = btrfs_is_free_space_inode(inode);\n\tconst bool is_reloc_ino = (inode->root->root_key.objectid ==\n\t\t\t\t   BTRFS_DATA_RELOC_TREE_OBJECTID);\n\tconst u64 range_bytes = end + 1 - start;\n\tstruct extent_io_tree *io_tree = &inode->io_tree;\n\tu64 range_start = start;\n\tu64 count;\n\n\t/*\n\t * If EXTENT_NORESERVE is set it means that when the buffered write was\n\t * made we had not enough available data space and therefore we did not\n\t * reserve data space for it, since we though we could do NOCOW for the\n\t * respective file range (either there is prealloc extent or the inode\n\t * has the NOCOW bit set).\n\t *\n\t * However when we need to fallback to COW mode (because for example the\n\t * block group for the corresponding extent was turned to RO mode by a\n\t * scrub or relocation) we need to do the following:\n\t *\n\t * 1) We increment the bytes_may_use counter of the data space info.\n\t *    If COW succeeds, it allocates a new data extent and after doing\n\t *    that it decrements the space info's bytes_may_use counter and\n\t *    increments its bytes_reserved counter by the same amount (we do\n\t *    this at btrfs_add_reserved_bytes()). So we need to increment the\n\t *    bytes_may_use counter to compensate (when space is reserved at\n\t *    buffered write time, the bytes_may_use counter is incremented);\n\t *\n\t * 2) We clear the EXTENT_NORESERVE bit from the range. We do this so\n\t *    that if the COW path fails for any reason, it decrements (through\n\t *    extent_clear_unlock_delalloc()) the bytes_may_use counter of the\n\t *    data space info, which we incremented in the step above.\n\t *\n\t * If we need to fallback to cow and the inode corresponds to a free\n\t * space cache inode or an inode of the data relocation tree, we must\n\t * also increment bytes_may_use of the data space_info for the same\n\t * reason. Space caches and relocated data extents always get a prealloc\n\t * extent for them, however scrub or balance may have set the block\n\t * group that contains that extent to RO mode and therefore force COW\n\t * when starting writeback.\n\t */\n\tcount = count_range_bits(io_tree, &range_start, end, range_bytes,\n\t\t\t\t EXTENT_NORESERVE, 0);\n\tif (count > 0 || is_space_ino || is_reloc_ino) {\n\t\tu64 bytes = count;\n\t\tstruct btrfs_fs_info *fs_info = inode->root->fs_info;\n\t\tstruct btrfs_space_info *sinfo = fs_info->data_sinfo;\n\n\t\tif (is_space_ino || is_reloc_ino)\n\t\t\tbytes = range_bytes;\n\n\t\tspin_lock(&sinfo->lock);\n\t\tbtrfs_space_info_update_bytes_may_use(fs_info, sinfo, bytes);\n\t\tspin_unlock(&sinfo->lock);\n\n\t\tif (count > 0)\n\t\t\tclear_extent_bit(io_tree, start, end, EXTENT_NORESERVE,\n\t\t\t\t\t 0, 0, NULL);\n\t}\n\n\treturn cow_file_range(inode, locked_page, start, end, page_started,\n\t\t\t      nr_written, 1);\n}\n\n/*\n * when nowcow writeback call back.  This checks for snapshots or COW copies\n * of the extents that exist in the file, and COWs the file as required.\n *\n * If no cow copies or snapshots exist, we write directly to the existing\n * blocks on disk\n */\nstatic noinline int run_delalloc_nocow(struct btrfs_inode *inode,\n\t\t\t\t       struct page *locked_page,\n\t\t\t\t       const u64 start, const u64 end,\n\t\t\t\t       int *page_started, int force,\n\t\t\t\t       unsigned long *nr_written)\n{\n\tstruct btrfs_fs_info *fs_info = inode->root->fs_info;\n\tstruct btrfs_root *root = inode->root;\n\tstruct btrfs_path *path;\n\tu64 cow_start = (u64)-1;\n\tu64 cur_offset = start;\n\tint ret;\n\tbool check_prev = true;\n\tconst bool freespace_inode = btrfs_is_free_space_inode(inode);\n\tu64 ino = btrfs_ino(inode);\n\tbool nocow = false;\n\tu64 disk_bytenr = 0;\n\n\tpath = btrfs_alloc_path();\n\tif (!path) {\n\t\textent_clear_unlock_delalloc(inode, start, end, locked_page,\n\t\t\t\t\t     EXTENT_LOCKED | EXTENT_DELALLOC |\n\t\t\t\t\t     EXTENT_DO_ACCOUNTING |\n\t\t\t\t\t     EXTENT_DEFRAG, PAGE_UNLOCK |\n\t\t\t\t\t     PAGE_START_WRITEBACK |\n\t\t\t\t\t     PAGE_END_WRITEBACK);\n\t\treturn -ENOMEM;\n\t}\n\n\twhile (1) {\n\t\tstruct btrfs_key found_key;\n\t\tstruct btrfs_file_extent_item *fi;\n\t\tstruct extent_buffer *leaf;\n\t\tu64 extent_end;\n\t\tu64 extent_offset;\n\t\tu64 num_bytes = 0;\n\t\tu64 disk_num_bytes;\n\t\tu64 ram_bytes;\n\t\tint extent_type;\n\n\t\tnocow = false;\n\n\t\tret = btrfs_lookup_file_extent(NULL, root, path, ino,\n\t\t\t\t\t       cur_offset, 0);\n\t\tif (ret < 0)\n\t\t\tgoto error;\n\n\t\t/*\n\t\t * If there is no extent for our range when doing the initial\n\t\t * search, then go back to the previous slot as it will be the\n\t\t * one containing the search offset\n\t\t */\n\t\tif (ret > 0 && path->slots[0] > 0 && check_prev) {\n\t\t\tleaf = path->nodes[0];\n\t\t\tbtrfs_item_key_to_cpu(leaf, &found_key,\n\t\t\t\t\t      path->slots[0] - 1);\n\t\t\tif (found_key.objectid == ino &&\n\t\t\t    found_key.type == BTRFS_EXTENT_DATA_KEY)\n\t\t\t\tpath->slots[0]--;\n\t\t}\n\t\tcheck_prev = false;\nnext_slot:\n\t\t/* Go to next leaf if we have exhausted the current one */\n\t\tleaf = path->nodes[0];\n\t\tif (path->slots[0] >= btrfs_header_nritems(leaf)) {\n\t\t\tret = btrfs_next_leaf(root, path);\n\t\t\tif (ret < 0) {\n\t\t\t\tif (cow_start != (u64)-1)\n\t\t\t\t\tcur_offset = cow_start;\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\tif (ret > 0)\n\t\t\t\tbreak;\n\t\t\tleaf = path->nodes[0];\n\t\t}\n\n\t\tbtrfs_item_key_to_cpu(leaf, &found_key, path->slots[0]);\n\n\t\t/* Didn't find anything for our INO */\n\t\tif (found_key.objectid > ino)\n\t\t\tbreak;\n\t\t/*\n\t\t * Keep searching until we find an EXTENT_ITEM or there are no\n\t\t * more extents for this inode\n\t\t */\n\t\tif (WARN_ON_ONCE(found_key.objectid < ino) ||\n\t\t    found_key.type < BTRFS_EXTENT_DATA_KEY) {\n\t\t\tpath->slots[0]++;\n\t\t\tgoto next_slot;\n\t\t}\n\n\t\t/* Found key is not EXTENT_DATA_KEY or starts after req range */\n\t\tif (found_key.type > BTRFS_EXTENT_DATA_KEY ||\n\t\t    found_key.offset > end)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * If the found extent starts after requested offset, then\n\t\t * adjust extent_end to be right before this extent begins\n\t\t */\n\t\tif (found_key.offset > cur_offset) {\n\t\t\textent_end = found_key.offset;\n\t\t\textent_type = 0;\n\t\t\tgoto out_check;\n\t\t}\n\n\t\t/*\n\t\t * Found extent which begins before our range and potentially\n\t\t * intersect it\n\t\t */\n\t\tfi = btrfs_item_ptr(leaf, path->slots[0],\n\t\t\t\t    struct btrfs_file_extent_item);\n\t\textent_type = btrfs_file_extent_type(leaf, fi);\n\n\t\tram_bytes = btrfs_file_extent_ram_bytes(leaf, fi);\n\t\tif (extent_type == BTRFS_FILE_EXTENT_REG ||\n\t\t    extent_type == BTRFS_FILE_EXTENT_PREALLOC) {\n\t\t\tdisk_bytenr = btrfs_file_extent_disk_bytenr(leaf, fi);\n\t\t\textent_offset = btrfs_file_extent_offset(leaf, fi);\n\t\t\textent_end = found_key.offset +\n\t\t\t\tbtrfs_file_extent_num_bytes(leaf, fi);\n\t\t\tdisk_num_bytes =\n\t\t\t\tbtrfs_file_extent_disk_num_bytes(leaf, fi);\n\t\t\t/*\n\t\t\t * If the extent we got ends before our current offset,\n\t\t\t * skip to the next extent.\n\t\t\t */\n\t\t\tif (extent_end <= cur_offset) {\n\t\t\t\tpath->slots[0]++;\n\t\t\t\tgoto next_slot;\n\t\t\t}\n\t\t\t/* Skip holes */\n\t\t\tif (disk_bytenr == 0)\n\t\t\t\tgoto out_check;\n\t\t\t/* Skip compressed/encrypted/encoded extents */\n\t\t\tif (btrfs_file_extent_compression(leaf, fi) ||\n\t\t\t    btrfs_file_extent_encryption(leaf, fi) ||\n\t\t\t    btrfs_file_extent_other_encoding(leaf, fi))\n\t\t\t\tgoto out_check;\n\t\t\t/*\n\t\t\t * If extent is created before the last volume's snapshot\n\t\t\t * this implies the extent is shared, hence we can't do\n\t\t\t * nocow. This is the same check as in\n\t\t\t * btrfs_cross_ref_exist but without calling\n\t\t\t * btrfs_search_slot.\n\t\t\t */\n\t\t\tif (!freespace_inode &&\n\t\t\t    btrfs_file_extent_generation(leaf, fi) <=\n\t\t\t    btrfs_root_last_snapshot(&root->root_item))\n\t\t\t\tgoto out_check;\n\t\t\tif (extent_type == BTRFS_FILE_EXTENT_REG && !force)\n\t\t\t\tgoto out_check;\n\n\t\t\t/*\n\t\t\t * The following checks can be expensive, as they need to\n\t\t\t * take other locks and do btree or rbtree searches, so\n\t\t\t * release the path to avoid blocking other tasks for too\n\t\t\t * long.\n\t\t\t */\n\t\t\tbtrfs_release_path(path);\n\n\t\t\tret = btrfs_cross_ref_exist(root, ino,\n\t\t\t\t\t\t    found_key.offset -\n\t\t\t\t\t\t    extent_offset, disk_bytenr, false);\n\t\t\tif (ret) {\n\t\t\t\t/*\n\t\t\t\t * ret could be -EIO if the above fails to read\n\t\t\t\t * metadata.\n\t\t\t\t */\n\t\t\t\tif (ret < 0) {\n\t\t\t\t\tif (cow_start != (u64)-1)\n\t\t\t\t\t\tcur_offset = cow_start;\n\t\t\t\t\tgoto error;\n\t\t\t\t}\n\n\t\t\t\tWARN_ON_ONCE(freespace_inode);\n\t\t\t\tgoto out_check;\n\t\t\t}\n\t\t\tdisk_bytenr += extent_offset;\n\t\t\tdisk_bytenr += cur_offset - found_key.offset;\n\t\t\tnum_bytes = min(end + 1, extent_end) - cur_offset;\n\t\t\t/*\n\t\t\t * If there are pending snapshots for this root, we\n\t\t\t * fall into common COW way\n\t\t\t */\n\t\t\tif (!freespace_inode && atomic_read(&root->snapshot_force_cow))\n\t\t\t\tgoto out_check;\n\t\t\t/*\n\t\t\t * force cow if csum exists in the range.\n\t\t\t * this ensure that csum for a given extent are\n\t\t\t * either valid or do not exist.\n\t\t\t */\n\t\t\tret = csum_exist_in_range(fs_info, disk_bytenr,\n\t\t\t\t\t\t  num_bytes);\n\t\t\tif (ret) {\n\t\t\t\t/*\n\t\t\t\t * ret could be -EIO if the above fails to read\n\t\t\t\t * metadata.\n\t\t\t\t */\n\t\t\t\tif (ret < 0) {\n\t\t\t\t\tif (cow_start != (u64)-1)\n\t\t\t\t\t\tcur_offset = cow_start;\n\t\t\t\t\tgoto error;\n\t\t\t\t}\n\t\t\t\tWARN_ON_ONCE(freespace_inode);\n\t\t\t\tgoto out_check;\n\t\t\t}\n\t\t\t/* If the extent's block group is RO, we must COW */\n\t\t\tif (!btrfs_inc_nocow_writers(fs_info, disk_bytenr))\n\t\t\t\tgoto out_check;\n\t\t\tnocow = true;\n\t\t} else if (extent_type == BTRFS_FILE_EXTENT_INLINE) {\n\t\t\textent_end = found_key.offset + ram_bytes;\n\t\t\textent_end = ALIGN(extent_end, fs_info->sectorsize);\n\t\t\t/* Skip extents outside of our requested range */\n\t\t\tif (extent_end <= start) {\n\t\t\t\tpath->slots[0]++;\n\t\t\t\tgoto next_slot;\n\t\t\t}\n\t\t} else {\n\t\t\t/* If this triggers then we have a memory corruption */\n\t\t\tBUG();\n\t\t}\nout_check:\n\t\t/*\n\t\t * If nocow is false then record the beginning of the range\n\t\t * that needs to be COWed\n\t\t */\n\t\tif (!nocow) {\n\t\t\tif (cow_start == (u64)-1)\n\t\t\t\tcow_start = cur_offset;\n\t\t\tcur_offset = extent_end;\n\t\t\tif (cur_offset > end)\n\t\t\t\tbreak;\n\t\t\tif (!path->nodes[0])\n\t\t\t\tcontinue;\n\t\t\tpath->slots[0]++;\n\t\t\tgoto next_slot;\n\t\t}\n\n\t\t/*\n\t\t * COW range from cow_start to found_key.offset - 1. As the key\n\t\t * will contain the beginning of the first extent that can be\n\t\t * NOCOW, following one which needs to be COW'ed\n\t\t */\n\t\tif (cow_start != (u64)-1) {\n\t\t\tret = fallback_to_cow(inode, locked_page,\n\t\t\t\t\t      cow_start, found_key.offset - 1,\n\t\t\t\t\t      page_started, nr_written);\n\t\t\tif (ret)\n\t\t\t\tgoto error;\n\t\t\tcow_start = (u64)-1;\n\t\t}\n\n\t\tif (extent_type == BTRFS_FILE_EXTENT_PREALLOC) {\n\t\t\tu64 orig_start = found_key.offset - extent_offset;\n\t\t\tstruct extent_map *em;\n\n\t\t\tem = create_io_em(inode, cur_offset, num_bytes,\n\t\t\t\t\t  orig_start,\n\t\t\t\t\t  disk_bytenr, /* block_start */\n\t\t\t\t\t  num_bytes, /* block_len */\n\t\t\t\t\t  disk_num_bytes, /* orig_block_len */\n\t\t\t\t\t  ram_bytes, BTRFS_COMPRESS_NONE,\n\t\t\t\t\t  BTRFS_ORDERED_PREALLOC);\n\t\t\tif (IS_ERR(em)) {\n\t\t\t\tret = PTR_ERR(em);\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\tfree_extent_map(em);\n\t\t\tret = btrfs_add_ordered_extent(inode, cur_offset,\n\t\t\t\t\t\t       disk_bytenr, num_bytes,\n\t\t\t\t\t\t       num_bytes,\n\t\t\t\t\t\t       BTRFS_ORDERED_PREALLOC);\n\t\t\tif (ret) {\n\t\t\t\tbtrfs_drop_extent_cache(inode, cur_offset,\n\t\t\t\t\t\t\tcur_offset + num_bytes - 1,\n\t\t\t\t\t\t\t0);\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t} else {\n\t\t\tret = btrfs_add_ordered_extent(inode, cur_offset,\n\t\t\t\t\t\t       disk_bytenr, num_bytes,\n\t\t\t\t\t\t       num_bytes,\n\t\t\t\t\t\t       BTRFS_ORDERED_NOCOW);\n\t\t\tif (ret)\n\t\t\t\tgoto error;\n\t\t}\n\n\t\tif (nocow)\n\t\t\tbtrfs_dec_nocow_writers(fs_info, disk_bytenr);\n\t\tnocow = false;\n\n\t\tif (root->root_key.objectid ==\n\t\t    BTRFS_DATA_RELOC_TREE_OBJECTID)\n\t\t\t/*\n\t\t\t * Error handled later, as we must prevent\n\t\t\t * extent_clear_unlock_delalloc() in error handler\n\t\t\t * from freeing metadata of created ordered extent.\n\t\t\t */\n\t\t\tret = btrfs_reloc_clone_csums(inode, cur_offset,\n\t\t\t\t\t\t      num_bytes);\n\n\t\textent_clear_unlock_delalloc(inode, cur_offset,\n\t\t\t\t\t     cur_offset + num_bytes - 1,\n\t\t\t\t\t     locked_page, EXTENT_LOCKED |\n\t\t\t\t\t     EXTENT_DELALLOC |\n\t\t\t\t\t     EXTENT_CLEAR_DATA_RESV,\n\t\t\t\t\t     PAGE_UNLOCK | PAGE_SET_PRIVATE2);\n\n\t\tcur_offset = extent_end;\n\n\t\t/*\n\t\t * btrfs_reloc_clone_csums() error, now we're OK to call error\n\t\t * handler, as metadata for created ordered extent will only\n\t\t * be freed by btrfs_finish_ordered_io().\n\t\t */\n\t\tif (ret)\n\t\t\tgoto error;\n\t\tif (cur_offset > end)\n\t\t\tbreak;\n\t}\n\tbtrfs_release_path(path);\n\n\tif (cur_offset <= end && cow_start == (u64)-1)\n\t\tcow_start = cur_offset;\n\n\tif (cow_start != (u64)-1) {\n\t\tcur_offset = end;\n\t\tret = fallback_to_cow(inode, locked_page, cow_start, end,\n\t\t\t\t      page_started, nr_written);\n\t\tif (ret)\n\t\t\tgoto error;\n\t}\n\nerror:\n\tif (nocow)\n\t\tbtrfs_dec_nocow_writers(fs_info, disk_bytenr);\n\n\tif (ret && cur_offset < end)\n\t\textent_clear_unlock_delalloc(inode, cur_offset, end,\n\t\t\t\t\t     locked_page, EXTENT_LOCKED |\n\t\t\t\t\t     EXTENT_DELALLOC | EXTENT_DEFRAG |\n\t\t\t\t\t     EXTENT_DO_ACCOUNTING, PAGE_UNLOCK |\n\t\t\t\t\t     PAGE_START_WRITEBACK |\n\t\t\t\t\t     PAGE_END_WRITEBACK);\n\tbtrfs_free_path(path);\n\treturn ret;\n}\n\nstatic inline int need_force_cow(struct btrfs_inode *inode, u64 start, u64 end)\n{\n\n\tif (!(inode->flags & BTRFS_INODE_NODATACOW) &&\n\t    !(inode->flags & BTRFS_INODE_PREALLOC))\n\t\treturn 0;\n\n\t/*\n\t * @defrag_bytes is a hint value, no spinlock held here,\n\t * if is not zero, it means the file is defragging.\n\t * Force cow if given extent needs to be defragged.\n\t */\n\tif (inode->defrag_bytes &&\n\t    test_range_bit(&inode->io_tree, start, end, EXTENT_DEFRAG, 0, NULL))\n\t\treturn 1;\n\n\treturn 0;\n}\n\n/*\n * Function to process delayed allocation (create CoW) for ranges which are\n * being touched for the first time.\n */\nint btrfs_run_delalloc_range(struct btrfs_inode *inode, struct page *locked_page,\n\t\tu64 start, u64 end, int *page_started, unsigned long *nr_written,\n\t\tstruct writeback_control *wbc)\n{\n\tint ret;\n\tint force_cow = need_force_cow(inode, start, end);\n\tconst bool zoned = btrfs_is_zoned(inode->root->fs_info);\n\n\tif (inode->flags & BTRFS_INODE_NODATACOW && !force_cow) {\n\t\tASSERT(!zoned);\n\t\tret = run_delalloc_nocow(inode, locked_page, start, end,\n\t\t\t\t\t page_started, 1, nr_written);\n\t} else if (inode->flags & BTRFS_INODE_PREALLOC && !force_cow) {\n\t\tASSERT(!zoned);\n\t\tret = run_delalloc_nocow(inode, locked_page, start, end,\n\t\t\t\t\t page_started, 0, nr_written);\n\t} else if (!inode_can_compress(inode) ||\n\t\t   !inode_need_compress(inode, start, end)) {\n\t\tif (zoned)\n\t\t\tret = run_delalloc_zoned(inode, locked_page, start, end,\n\t\t\t\t\t\t page_started, nr_written);\n\t\telse\n\t\t\tret = cow_file_range(inode, locked_page, start, end,\n\t\t\t\t\t     page_started, nr_written, 1);\n\t} else {\n\t\tset_bit(BTRFS_INODE_HAS_ASYNC_EXTENT, &inode->runtime_flags);\n\t\tret = cow_file_range_async(inode, wbc, locked_page, start, end,\n\t\t\t\t\t   page_started, nr_written);\n\t}\n\tif (ret)\n\t\tbtrfs_cleanup_ordered_extents(inode, locked_page, start,\n\t\t\t\t\t      end - start + 1);\n\treturn ret;\n}\n\nvoid btrfs_split_delalloc_extent(struct inode *inode,\n\t\t\t\t struct extent_state *orig, u64 split)\n{\n\tu64 size;\n\n\t/* not delalloc, ignore it */\n\tif (!(orig->state & EXTENT_DELALLOC))\n\t\treturn;\n\n\tsize = orig->end - orig->start + 1;\n\tif (size > BTRFS_MAX_EXTENT_SIZE) {\n\t\tu32 num_extents;\n\t\tu64 new_size;\n\n\t\t/*\n\t\t * See the explanation in btrfs_merge_delalloc_extent, the same\n\t\t * applies here, just in reverse.\n\t\t */\n\t\tnew_size = orig->end - split + 1;\n\t\tnum_extents = count_max_extents(new_size);\n\t\tnew_size = split - orig->start;\n\t\tnum_extents += count_max_extents(new_size);\n\t\tif (count_max_extents(size) >= num_extents)\n\t\t\treturn;\n\t}\n\n\tspin_lock(&BTRFS_I(inode)->lock);\n\tbtrfs_mod_outstanding_extents(BTRFS_I(inode), 1);\n\tspin_unlock(&BTRFS_I(inode)->lock);\n}\n\n/*\n * Handle merged delayed allocation extents so we can keep track of new extents\n * that are just merged onto old extents, such as when we are doing sequential\n * writes, so we can properly account for the metadata space we'll need.\n */\nvoid btrfs_merge_delalloc_extent(struct inode *inode, struct extent_state *new,\n\t\t\t\t struct extent_state *other)\n{\n\tu64 new_size, old_size;\n\tu32 num_extents;\n\n\t/* not delalloc, ignore it */\n\tif (!(other->state & EXTENT_DELALLOC))\n\t\treturn;\n\n\tif (new->start > other->start)\n\t\tnew_size = new->end - other->start + 1;\n\telse\n\t\tnew_size = other->end - new->start + 1;\n\n\t/* we're not bigger than the max, unreserve the space and go */\n\tif (new_size <= BTRFS_MAX_EXTENT_SIZE) {\n\t\tspin_lock(&BTRFS_I(inode)->lock);\n\t\tbtrfs_mod_outstanding_extents(BTRFS_I(inode), -1);\n\t\tspin_unlock(&BTRFS_I(inode)->lock);\n\t\treturn;\n\t}\n\n\t/*\n\t * We have to add up either side to figure out how many extents were\n\t * accounted for before we merged into one big extent.  If the number of\n\t * extents we accounted for is <= the amount we need for the new range\n\t * then we can return, otherwise drop.  Think of it like this\n\t *\n\t * [ 4k][MAX_SIZE]\n\t *\n\t * So we've grown the extent by a MAX_SIZE extent, this would mean we\n\t * need 2 outstanding extents, on one side we have 1 and the other side\n\t * we have 1 so they are == and we can return.  But in this case\n\t *\n\t * [MAX_SIZE+4k][MAX_SIZE+4k]\n\t *\n\t * Each range on their own accounts for 2 extents, but merged together\n\t * they are only 3 extents worth of accounting, so we need to drop in\n\t * this case.\n\t */\n\told_size = other->end - other->start + 1;\n\tnum_extents = count_max_extents(old_size);\n\told_size = new->end - new->start + 1;\n\tnum_extents += count_max_extents(old_size);\n\tif (count_max_extents(new_size) >= num_extents)\n\t\treturn;\n\n\tspin_lock(&BTRFS_I(inode)->lock);\n\tbtrfs_mod_outstanding_extents(BTRFS_I(inode), -1);\n\tspin_unlock(&BTRFS_I(inode)->lock);\n}\n\nstatic void btrfs_add_delalloc_inodes(struct btrfs_root *root,\n\t\t\t\t      struct inode *inode)\n{\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);\n\n\tspin_lock(&root->delalloc_lock);\n\tif (list_empty(&BTRFS_I(inode)->delalloc_inodes)) {\n\t\tlist_add_tail(&BTRFS_I(inode)->delalloc_inodes,\n\t\t\t      &root->delalloc_inodes);\n\t\tset_bit(BTRFS_INODE_IN_DELALLOC_LIST,\n\t\t\t&BTRFS_I(inode)->runtime_flags);\n\t\troot->nr_delalloc_inodes++;\n\t\tif (root->nr_delalloc_inodes == 1) {\n\t\t\tspin_lock(&fs_info->delalloc_root_lock);\n\t\t\tBUG_ON(!list_empty(&root->delalloc_root));\n\t\t\tlist_add_tail(&root->delalloc_root,\n\t\t\t\t      &fs_info->delalloc_roots);\n\t\t\tspin_unlock(&fs_info->delalloc_root_lock);\n\t\t}\n\t}\n\tspin_unlock(&root->delalloc_lock);\n}\n\n\nvoid __btrfs_del_delalloc_inode(struct btrfs_root *root,\n\t\t\t\tstruct btrfs_inode *inode)\n{\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\n\tif (!list_empty(&inode->delalloc_inodes)) {\n\t\tlist_del_init(&inode->delalloc_inodes);\n\t\tclear_bit(BTRFS_INODE_IN_DELALLOC_LIST,\n\t\t\t  &inode->runtime_flags);\n\t\troot->nr_delalloc_inodes--;\n\t\tif (!root->nr_delalloc_inodes) {\n\t\t\tASSERT(list_empty(&root->delalloc_inodes));\n\t\t\tspin_lock(&fs_info->delalloc_root_lock);\n\t\t\tBUG_ON(list_empty(&root->delalloc_root));\n\t\t\tlist_del_init(&root->delalloc_root);\n\t\t\tspin_unlock(&fs_info->delalloc_root_lock);\n\t\t}\n\t}\n}\n\nstatic void btrfs_del_delalloc_inode(struct btrfs_root *root,\n\t\t\t\t     struct btrfs_inode *inode)\n{\n\tspin_lock(&root->delalloc_lock);\n\t__btrfs_del_delalloc_inode(root, inode);\n\tspin_unlock(&root->delalloc_lock);\n}\n\n/*\n * Properly track delayed allocation bytes in the inode and to maintain the\n * list of inodes that have pending delalloc work to be done.\n */\nvoid btrfs_set_delalloc_extent(struct inode *inode, struct extent_state *state,\n\t\t\t       unsigned *bits)\n{\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);\n\n\tif ((*bits & EXTENT_DEFRAG) && !(*bits & EXTENT_DELALLOC))\n\t\tWARN_ON(1);\n\t/*\n\t * set_bit and clear bit hooks normally require _irqsave/restore\n\t * but in this case, we are only testing for the DELALLOC\n\t * bit, which is only set or cleared with irqs on\n\t */\n\tif (!(state->state & EXTENT_DELALLOC) && (*bits & EXTENT_DELALLOC)) {\n\t\tstruct btrfs_root *root = BTRFS_I(inode)->root;\n\t\tu64 len = state->end + 1 - state->start;\n\t\tu32 num_extents = count_max_extents(len);\n\t\tbool do_list = !btrfs_is_free_space_inode(BTRFS_I(inode));\n\n\t\tspin_lock(&BTRFS_I(inode)->lock);\n\t\tbtrfs_mod_outstanding_extents(BTRFS_I(inode), num_extents);\n\t\tspin_unlock(&BTRFS_I(inode)->lock);\n\n\t\t/* For sanity tests */\n\t\tif (btrfs_is_testing(fs_info))\n\t\t\treturn;\n\n\t\tpercpu_counter_add_batch(&fs_info->delalloc_bytes, len,\n\t\t\t\t\t fs_info->delalloc_batch);\n\t\tspin_lock(&BTRFS_I(inode)->lock);\n\t\tBTRFS_I(inode)->delalloc_bytes += len;\n\t\tif (*bits & EXTENT_DEFRAG)\n\t\t\tBTRFS_I(inode)->defrag_bytes += len;\n\t\tif (do_list && !test_bit(BTRFS_INODE_IN_DELALLOC_LIST,\n\t\t\t\t\t &BTRFS_I(inode)->runtime_flags))\n\t\t\tbtrfs_add_delalloc_inodes(root, inode);\n\t\tspin_unlock(&BTRFS_I(inode)->lock);\n\t}\n\n\tif (!(state->state & EXTENT_DELALLOC_NEW) &&\n\t    (*bits & EXTENT_DELALLOC_NEW)) {\n\t\tspin_lock(&BTRFS_I(inode)->lock);\n\t\tBTRFS_I(inode)->new_delalloc_bytes += state->end + 1 -\n\t\t\tstate->start;\n\t\tspin_unlock(&BTRFS_I(inode)->lock);\n\t}\n}\n\n/*\n * Once a range is no longer delalloc this function ensures that proper\n * accounting happens.\n */\nvoid btrfs_clear_delalloc_extent(struct inode *vfs_inode,\n\t\t\t\t struct extent_state *state, unsigned *bits)\n{\n\tstruct btrfs_inode *inode = BTRFS_I(vfs_inode);\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(vfs_inode->i_sb);\n\tu64 len = state->end + 1 - state->start;\n\tu32 num_extents = count_max_extents(len);\n\n\tif ((state->state & EXTENT_DEFRAG) && (*bits & EXTENT_DEFRAG)) {\n\t\tspin_lock(&inode->lock);\n\t\tinode->defrag_bytes -= len;\n\t\tspin_unlock(&inode->lock);\n\t}\n\n\t/*\n\t * set_bit and clear bit hooks normally require _irqsave/restore\n\t * but in this case, we are only testing for the DELALLOC\n\t * bit, which is only set or cleared with irqs on\n\t */\n\tif ((state->state & EXTENT_DELALLOC) && (*bits & EXTENT_DELALLOC)) {\n\t\tstruct btrfs_root *root = inode->root;\n\t\tbool do_list = !btrfs_is_free_space_inode(inode);\n\n\t\tspin_lock(&inode->lock);\n\t\tbtrfs_mod_outstanding_extents(inode, -num_extents);\n\t\tspin_unlock(&inode->lock);\n\n\t\t/*\n\t\t * We don't reserve metadata space for space cache inodes so we\n\t\t * don't need to call delalloc_release_metadata if there is an\n\t\t * error.\n\t\t */\n\t\tif (*bits & EXTENT_CLEAR_META_RESV &&\n\t\t    root != fs_info->tree_root)\n\t\t\tbtrfs_delalloc_release_metadata(inode, len, false);\n\n\t\t/* For sanity tests. */\n\t\tif (btrfs_is_testing(fs_info))\n\t\t\treturn;\n\n\t\tif (root->root_key.objectid != BTRFS_DATA_RELOC_TREE_OBJECTID &&\n\t\t    do_list && !(state->state & EXTENT_NORESERVE) &&\n\t\t    (*bits & EXTENT_CLEAR_DATA_RESV))\n\t\t\tbtrfs_free_reserved_data_space_noquota(fs_info, len);\n\n\t\tpercpu_counter_add_batch(&fs_info->delalloc_bytes, -len,\n\t\t\t\t\t fs_info->delalloc_batch);\n\t\tspin_lock(&inode->lock);\n\t\tinode->delalloc_bytes -= len;\n\t\tif (do_list && inode->delalloc_bytes == 0 &&\n\t\t    test_bit(BTRFS_INODE_IN_DELALLOC_LIST,\n\t\t\t\t\t&inode->runtime_flags))\n\t\t\tbtrfs_del_delalloc_inode(root, inode);\n\t\tspin_unlock(&inode->lock);\n\t}\n\n\tif ((state->state & EXTENT_DELALLOC_NEW) &&\n\t    (*bits & EXTENT_DELALLOC_NEW)) {\n\t\tspin_lock(&inode->lock);\n\t\tASSERT(inode->new_delalloc_bytes >= len);\n\t\tinode->new_delalloc_bytes -= len;\n\t\tif (*bits & EXTENT_ADD_INODE_BYTES)\n\t\t\tinode_add_bytes(&inode->vfs_inode, len);\n\t\tspin_unlock(&inode->lock);\n\t}\n}\n\n/*\n * btrfs_bio_fits_in_stripe - Checks whether the size of the given bio will fit\n * in a chunk's stripe. This function ensures that bios do not span a\n * stripe/chunk\n *\n * @page - The page we are about to add to the bio\n * @size - size we want to add to the bio\n * @bio - bio we want to ensure is smaller than a stripe\n * @bio_flags - flags of the bio\n *\n * return 1 if page cannot be added to the bio\n * return 0 if page can be added to the bio\n * return error otherwise\n */\nint btrfs_bio_fits_in_stripe(struct page *page, size_t size, struct bio *bio,\n\t\t\t     unsigned long bio_flags)\n{\n\tstruct inode *inode = page->mapping->host;\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);\n\tu64 logical = bio->bi_iter.bi_sector << 9;\n\tstruct extent_map *em;\n\tu64 length = 0;\n\tu64 map_length;\n\tint ret = 0;\n\tstruct btrfs_io_geometry geom;\n\n\tif (bio_flags & EXTENT_BIO_COMPRESSED)\n\t\treturn 0;\n\n\tlength = bio->bi_iter.bi_size;\n\tmap_length = length;\n\tem = btrfs_get_chunk_map(fs_info, logical, map_length);\n\tif (IS_ERR(em))\n\t\treturn PTR_ERR(em);\n\tret = btrfs_get_io_geometry(fs_info, em, btrfs_op(bio), logical,\n\t\t\t\t    map_length, &geom);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tif (geom.len < length + size)\n\t\tret = 1;\nout:\n\tfree_extent_map(em);\n\treturn ret;\n}\n\n/*\n * in order to insert checksums into the metadata in large chunks,\n * we wait until bio submission time.   All the pages in the bio are\n * checksummed and sums are attached onto the ordered extent record.\n *\n * At IO completion time the cums attached on the ordered extent record\n * are inserted into the btree\n */\nstatic blk_status_t btrfs_submit_bio_start(struct inode *inode, struct bio *bio,\n\t\t\t\t\t   u64 dio_file_offset)\n{\n\treturn btrfs_csum_one_bio(BTRFS_I(inode), bio, 0, 0);\n}\n\nbool btrfs_bio_fits_in_ordered_extent(struct page *page, struct bio *bio,\n\t\t\t\t      unsigned int size)\n{\n\tstruct btrfs_inode *inode = BTRFS_I(page->mapping->host);\n\tstruct btrfs_fs_info *fs_info = inode->root->fs_info;\n\tstruct btrfs_ordered_extent *ordered;\n\tu64 len = bio->bi_iter.bi_size + size;\n\tbool ret = true;\n\n\tASSERT(btrfs_is_zoned(fs_info));\n\tASSERT(fs_info->max_zone_append_size > 0);\n\tASSERT(bio_op(bio) == REQ_OP_ZONE_APPEND);\n\n\t/* Ordered extent not yet created, so we're good */\n\tordered = btrfs_lookup_ordered_extent(inode, page_offset(page));\n\tif (!ordered)\n\t\treturn ret;\n\n\tif ((bio->bi_iter.bi_sector << SECTOR_SHIFT) + len >\n\t    ordered->disk_bytenr + ordered->disk_num_bytes)\n\t\tret = false;\n\n\tbtrfs_put_ordered_extent(ordered);\n\n\treturn ret;\n}\n\nstatic blk_status_t extract_ordered_extent(struct btrfs_inode *inode,\n\t\t\t\t\t   struct bio *bio, loff_t file_offset)\n{\n\tstruct btrfs_ordered_extent *ordered;\n\tstruct extent_map *em = NULL, *em_new = NULL;\n\tstruct extent_map_tree *em_tree = &inode->extent_tree;\n\tu64 start = (u64)bio->bi_iter.bi_sector << SECTOR_SHIFT;\n\tu64 len = bio->bi_iter.bi_size;\n\tu64 end = start + len;\n\tu64 ordered_end;\n\tu64 pre, post;\n\tint ret = 0;\n\n\tordered = btrfs_lookup_ordered_extent(inode, file_offset);\n\tif (WARN_ON_ONCE(!ordered))\n\t\treturn BLK_STS_IOERR;\n\n\t/* No need to split */\n\tif (ordered->disk_num_bytes == len)\n\t\tgoto out;\n\n\t/* We cannot split once end_bio'd ordered extent */\n\tif (WARN_ON_ONCE(ordered->bytes_left != ordered->disk_num_bytes)) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\t/* We cannot split a compressed ordered extent */\n\tif (WARN_ON_ONCE(ordered->disk_num_bytes != ordered->num_bytes)) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tordered_end = ordered->disk_bytenr + ordered->disk_num_bytes;\n\t/* bio must be in one ordered extent */\n\tif (WARN_ON_ONCE(start < ordered->disk_bytenr || end > ordered_end)) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\t/* Checksum list should be empty */\n\tif (WARN_ON_ONCE(!list_empty(&ordered->list))) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tpre = start - ordered->disk_bytenr;\n\tpost = ordered_end - end;\n\n\tret = btrfs_split_ordered_extent(ordered, pre, post);\n\tif (ret)\n\t\tgoto out;\n\n\tread_lock(&em_tree->lock);\n\tem = lookup_extent_mapping(em_tree, ordered->file_offset, len);\n\tif (!em) {\n\t\tread_unlock(&em_tree->lock);\n\t\tret = -EIO;\n\t\tgoto out;\n\t}\n\tread_unlock(&em_tree->lock);\n\n\tASSERT(!test_bit(EXTENT_FLAG_COMPRESSED, &em->flags));\n\t/*\n\t * We cannot reuse em_new here but have to create a new one, as\n\t * unpin_extent_cache() expects the start of the extent map to be the\n\t * logical offset of the file, which does not hold true anymore after\n\t * splitting.\n\t */\n\tem_new = create_io_em(inode, em->start + pre, len,\n\t\t\t      em->start + pre, em->block_start + pre, len,\n\t\t\t      len, len, BTRFS_COMPRESS_NONE,\n\t\t\t      BTRFS_ORDERED_REGULAR);\n\tif (IS_ERR(em_new)) {\n\t\tret = PTR_ERR(em_new);\n\t\tgoto out;\n\t}\n\tfree_extent_map(em_new);\n\nout:\n\tfree_extent_map(em);\n\tbtrfs_put_ordered_extent(ordered);\n\n\treturn errno_to_blk_status(ret);\n}\n\n/*\n * extent_io.c submission hook. This does the right thing for csum calculation\n * on write, or reading the csums from the tree before a read.\n *\n * Rules about async/sync submit,\n * a) read:\t\t\t\tsync submit\n *\n * b) write without checksum:\t\tsync submit\n *\n * c) write with checksum:\n *    c-1) if bio is issued by fsync:\tsync submit\n *         (sync_writers != 0)\n *\n *    c-2) if root is reloc root:\tsync submit\n *         (only in case of buffered IO)\n *\n *    c-3) otherwise:\t\t\tasync submit\n */\nblk_status_t btrfs_submit_data_bio(struct inode *inode, struct bio *bio,\n\t\t\t\t   int mirror_num, unsigned long bio_flags)\n\n{\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);\n\tstruct btrfs_root *root = BTRFS_I(inode)->root;\n\tenum btrfs_wq_endio_type metadata = BTRFS_WQ_ENDIO_DATA;\n\tblk_status_t ret = 0;\n\tint skip_sum;\n\tint async = !atomic_read(&BTRFS_I(inode)->sync_writers);\n\n\tskip_sum = (BTRFS_I(inode)->flags & BTRFS_INODE_NODATASUM) ||\n\t\t   !fs_info->csum_root;\n\n\tif (btrfs_is_free_space_inode(BTRFS_I(inode)))\n\t\tmetadata = BTRFS_WQ_ENDIO_FREE_SPACE;\n\n\tif (bio_op(bio) == REQ_OP_ZONE_APPEND) {\n\t\tstruct page *page = bio_first_bvec_all(bio)->bv_page;\n\t\tloff_t file_offset = page_offset(page);\n\n\t\tret = extract_ordered_extent(BTRFS_I(inode), bio, file_offset);\n\t\tif (ret)\n\t\t\tgoto out;\n\t}\n\n\tif (btrfs_op(bio) != BTRFS_MAP_WRITE) {\n\t\tret = btrfs_bio_wq_end_io(fs_info, bio, metadata);\n\t\tif (ret)\n\t\t\tgoto out;\n\n\t\tif (bio_flags & EXTENT_BIO_COMPRESSED) {\n\t\t\tret = btrfs_submit_compressed_read(inode, bio,\n\t\t\t\t\t\t\t   mirror_num,\n\t\t\t\t\t\t\t   bio_flags);\n\t\t\tgoto out;\n\t\t} else {\n\t\t\t/*\n\t\t\t * Lookup bio sums does extra checks around whether we\n\t\t\t * need to csum or not, which is why we ignore skip_sum\n\t\t\t * here.\n\t\t\t */\n\t\t\tret = btrfs_lookup_bio_sums(inode, bio, NULL);\n\t\t\tif (ret)\n\t\t\t\tgoto out;\n\t\t}\n\t\tgoto mapit;\n\t} else if (async && !skip_sum) {\n\t\t/* csum items have already been cloned */\n\t\tif (root->root_key.objectid == BTRFS_DATA_RELOC_TREE_OBJECTID)\n\t\t\tgoto mapit;\n\t\t/* we're doing a write, do the async checksumming */\n\t\tret = btrfs_wq_submit_bio(inode, bio, mirror_num, bio_flags,\n\t\t\t\t\t  0, btrfs_submit_bio_start);\n\t\tgoto out;\n\t} else if (!skip_sum) {\n\t\tret = btrfs_csum_one_bio(BTRFS_I(inode), bio, 0, 0);\n\t\tif (ret)\n\t\t\tgoto out;\n\t}\n\nmapit:\n\tret = btrfs_map_bio(fs_info, bio, mirror_num);\n\nout:\n\tif (ret) {\n\t\tbio->bi_status = ret;\n\t\tbio_endio(bio);\n\t}\n\treturn ret;\n}\n\n/*\n * given a list of ordered sums record them in the inode.  This happens\n * at IO completion time based on sums calculated at bio submission time.\n */\nstatic int add_pending_csums(struct btrfs_trans_handle *trans,\n\t\t\t     struct list_head *list)\n{\n\tstruct btrfs_ordered_sum *sum;\n\tint ret;\n\n\tlist_for_each_entry(sum, list, list) {\n\t\ttrans->adding_csums = true;\n\t\tret = btrfs_csum_file_blocks(trans, trans->fs_info->csum_root, sum);\n\t\ttrans->adding_csums = false;\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\treturn 0;\n}\n\nstatic int btrfs_find_new_delalloc_bytes(struct btrfs_inode *inode,\n\t\t\t\t\t const u64 start,\n\t\t\t\t\t const u64 len,\n\t\t\t\t\t struct extent_state **cached_state)\n{\n\tu64 search_start = start;\n\tconst u64 end = start + len - 1;\n\n\twhile (search_start < end) {\n\t\tconst u64 search_len = end - search_start + 1;\n\t\tstruct extent_map *em;\n\t\tu64 em_len;\n\t\tint ret = 0;\n\n\t\tem = btrfs_get_extent(inode, NULL, 0, search_start, search_len);\n\t\tif (IS_ERR(em))\n\t\t\treturn PTR_ERR(em);\n\n\t\tif (em->block_start != EXTENT_MAP_HOLE)\n\t\t\tgoto next;\n\n\t\tem_len = em->len;\n\t\tif (em->start < search_start)\n\t\t\tem_len -= search_start - em->start;\n\t\tif (em_len > search_len)\n\t\t\tem_len = search_len;\n\n\t\tret = set_extent_bit(&inode->io_tree, search_start,\n\t\t\t\t     search_start + em_len - 1,\n\t\t\t\t     EXTENT_DELALLOC_NEW, 0, NULL, cached_state,\n\t\t\t\t     GFP_NOFS, NULL);\nnext:\n\t\tsearch_start = extent_map_end(em);\n\t\tfree_extent_map(em);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\treturn 0;\n}\n\nint btrfs_set_extent_delalloc(struct btrfs_inode *inode, u64 start, u64 end,\n\t\t\t      unsigned int extra_bits,\n\t\t\t      struct extent_state **cached_state)\n{\n\tWARN_ON(PAGE_ALIGNED(end));\n\n\tif (start >= i_size_read(&inode->vfs_inode) &&\n\t    !(inode->flags & BTRFS_INODE_PREALLOC)) {\n\t\t/*\n\t\t * There can't be any extents following eof in this case so just\n\t\t * set the delalloc new bit for the range directly.\n\t\t */\n\t\textra_bits |= EXTENT_DELALLOC_NEW;\n\t} else {\n\t\tint ret;\n\n\t\tret = btrfs_find_new_delalloc_bytes(inode, start,\n\t\t\t\t\t\t    end + 1 - start,\n\t\t\t\t\t\t    cached_state);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn set_extent_delalloc(&inode->io_tree, start, end, extra_bits,\n\t\t\t\t   cached_state);\n}\n\n/* see btrfs_writepage_start_hook for details on why this is required */\nstruct btrfs_writepage_fixup {\n\tstruct page *page;\n\tstruct inode *inode;\n\tstruct btrfs_work work;\n};\n\nstatic void btrfs_writepage_fixup_worker(struct btrfs_work *work)\n{\n\tstruct btrfs_writepage_fixup *fixup;\n\tstruct btrfs_ordered_extent *ordered;\n\tstruct extent_state *cached_state = NULL;\n\tstruct extent_changeset *data_reserved = NULL;\n\tstruct page *page;\n\tstruct btrfs_inode *inode;\n\tu64 page_start;\n\tu64 page_end;\n\tint ret = 0;\n\tbool free_delalloc_space = true;\n\n\tfixup = container_of(work, struct btrfs_writepage_fixup, work);\n\tpage = fixup->page;\n\tinode = BTRFS_I(fixup->inode);\n\tpage_start = page_offset(page);\n\tpage_end = page_offset(page) + PAGE_SIZE - 1;\n\n\t/*\n\t * This is similar to page_mkwrite, we need to reserve the space before\n\t * we take the page lock.\n\t */\n\tret = btrfs_delalloc_reserve_space(inode, &data_reserved, page_start,\n\t\t\t\t\t   PAGE_SIZE);\nagain:\n\tlock_page(page);\n\n\t/*\n\t * Before we queued this fixup, we took a reference on the page.\n\t * page->mapping may go NULL, but it shouldn't be moved to a different\n\t * address space.\n\t */\n\tif (!page->mapping || !PageDirty(page) || !PageChecked(page)) {\n\t\t/*\n\t\t * Unfortunately this is a little tricky, either\n\t\t *\n\t\t * 1) We got here and our page had already been dealt with and\n\t\t *    we reserved our space, thus ret == 0, so we need to just\n\t\t *    drop our space reservation and bail.  This can happen the\n\t\t *    first time we come into the fixup worker, or could happen\n\t\t *    while waiting for the ordered extent.\n\t\t * 2) Our page was already dealt with, but we happened to get an\n\t\t *    ENOSPC above from the btrfs_delalloc_reserve_space.  In\n\t\t *    this case we obviously don't have anything to release, but\n\t\t *    because the page was already dealt with we don't want to\n\t\t *    mark the page with an error, so make sure we're resetting\n\t\t *    ret to 0.  This is why we have this check _before_ the ret\n\t\t *    check, because we do not want to have a surprise ENOSPC\n\t\t *    when the page was already properly dealt with.\n\t\t */\n\t\tif (!ret) {\n\t\t\tbtrfs_delalloc_release_extents(inode, PAGE_SIZE);\n\t\t\tbtrfs_delalloc_release_space(inode, data_reserved,\n\t\t\t\t\t\t     page_start, PAGE_SIZE,\n\t\t\t\t\t\t     true);\n\t\t}\n\t\tret = 0;\n\t\tgoto out_page;\n\t}\n\n\t/*\n\t * We can't mess with the page state unless it is locked, so now that\n\t * it is locked bail if we failed to make our space reservation.\n\t */\n\tif (ret)\n\t\tgoto out_page;\n\n\tlock_extent_bits(&inode->io_tree, page_start, page_end, &cached_state);\n\n\t/* already ordered? We're done */\n\tif (PagePrivate2(page))\n\t\tgoto out_reserved;\n\n\tordered = btrfs_lookup_ordered_range(inode, page_start, PAGE_SIZE);\n\tif (ordered) {\n\t\tunlock_extent_cached(&inode->io_tree, page_start, page_end,\n\t\t\t\t     &cached_state);\n\t\tunlock_page(page);\n\t\tbtrfs_start_ordered_extent(ordered, 1);\n\t\tbtrfs_put_ordered_extent(ordered);\n\t\tgoto again;\n\t}\n\n\tret = btrfs_set_extent_delalloc(inode, page_start, page_end, 0,\n\t\t\t\t\t&cached_state);\n\tif (ret)\n\t\tgoto out_reserved;\n\n\t/*\n\t * Everything went as planned, we're now the owner of a dirty page with\n\t * delayed allocation bits set and space reserved for our COW\n\t * destination.\n\t *\n\t * The page was dirty when we started, nothing should have cleaned it.\n\t */\n\tBUG_ON(!PageDirty(page));\n\tfree_delalloc_space = false;\nout_reserved:\n\tbtrfs_delalloc_release_extents(inode, PAGE_SIZE);\n\tif (free_delalloc_space)\n\t\tbtrfs_delalloc_release_space(inode, data_reserved, page_start,\n\t\t\t\t\t     PAGE_SIZE, true);\n\tunlock_extent_cached(&inode->io_tree, page_start, page_end,\n\t\t\t     &cached_state);\nout_page:\n\tif (ret) {\n\t\t/*\n\t\t * We hit ENOSPC or other errors.  Update the mapping and page\n\t\t * to reflect the errors and clean the page.\n\t\t */\n\t\tmapping_set_error(page->mapping, ret);\n\t\tend_extent_writepage(page, ret, page_start, page_end);\n\t\tclear_page_dirty_for_io(page);\n\t\tSetPageError(page);\n\t}\n\tClearPageChecked(page);\n\tunlock_page(page);\n\tput_page(page);\n\tkfree(fixup);\n\textent_changeset_free(data_reserved);\n\t/*\n\t * As a precaution, do a delayed iput in case it would be the last iput\n\t * that could need flushing space. Recursing back to fixup worker would\n\t * deadlock.\n\t */\n\tbtrfs_add_delayed_iput(&inode->vfs_inode);\n}\n\n/*\n * There are a few paths in the higher layers of the kernel that directly\n * set the page dirty bit without asking the filesystem if it is a\n * good idea.  This causes problems because we want to make sure COW\n * properly happens and the data=ordered rules are followed.\n *\n * In our case any range that doesn't have the ORDERED bit set\n * hasn't been properly setup for IO.  We kick off an async process\n * to fix it up.  The async helper will wait for ordered extents, set\n * the delalloc bit and make it safe to write the page.\n */\nint btrfs_writepage_cow_fixup(struct page *page, u64 start, u64 end)\n{\n\tstruct inode *inode = page->mapping->host;\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);\n\tstruct btrfs_writepage_fixup *fixup;\n\n\t/* this page is properly in the ordered list */\n\tif (TestClearPagePrivate2(page))\n\t\treturn 0;\n\n\t/*\n\t * PageChecked is set below when we create a fixup worker for this page,\n\t * don't try to create another one if we're already PageChecked()\n\t *\n\t * The extent_io writepage code will redirty the page if we send back\n\t * EAGAIN.\n\t */\n\tif (PageChecked(page))\n\t\treturn -EAGAIN;\n\n\tfixup = kzalloc(sizeof(*fixup), GFP_NOFS);\n\tif (!fixup)\n\t\treturn -EAGAIN;\n\n\t/*\n\t * We are already holding a reference to this inode from\n\t * write_cache_pages.  We need to hold it because the space reservation\n\t * takes place outside of the page lock, and we can't trust\n\t * page->mapping outside of the page lock.\n\t */\n\tihold(inode);\n\tSetPageChecked(page);\n\tget_page(page);\n\tbtrfs_init_work(&fixup->work, btrfs_writepage_fixup_worker, NULL, NULL);\n\tfixup->page = page;\n\tfixup->inode = inode;\n\tbtrfs_queue_work(fs_info->fixup_workers, &fixup->work);\n\n\treturn -EAGAIN;\n}\n\nstatic int insert_reserved_file_extent(struct btrfs_trans_handle *trans,\n\t\t\t\t       struct btrfs_inode *inode, u64 file_pos,\n\t\t\t\t       struct btrfs_file_extent_item *stack_fi,\n\t\t\t\t       const bool update_inode_bytes,\n\t\t\t\t       u64 qgroup_reserved)\n{\n\tstruct btrfs_root *root = inode->root;\n\tconst u64 sectorsize = root->fs_info->sectorsize;\n\tstruct btrfs_path *path;\n\tstruct extent_buffer *leaf;\n\tstruct btrfs_key ins;\n\tu64 disk_num_bytes = btrfs_stack_file_extent_disk_num_bytes(stack_fi);\n\tu64 disk_bytenr = btrfs_stack_file_extent_disk_bytenr(stack_fi);\n\tu64 num_bytes = btrfs_stack_file_extent_num_bytes(stack_fi);\n\tu64 ram_bytes = btrfs_stack_file_extent_ram_bytes(stack_fi);\n\tstruct btrfs_drop_extents_args drop_args = { 0 };\n\tint ret;\n\n\tpath = btrfs_alloc_path();\n\tif (!path)\n\t\treturn -ENOMEM;\n\n\t/*\n\t * we may be replacing one extent in the tree with another.\n\t * The new extent is pinned in the extent map, and we don't want\n\t * to drop it from the cache until it is completely in the btree.\n\t *\n\t * So, tell btrfs_drop_extents to leave this extent in the cache.\n\t * the caller is expected to unpin it and allow it to be merged\n\t * with the others.\n\t */\n\tdrop_args.path = path;\n\tdrop_args.start = file_pos;\n\tdrop_args.end = file_pos + num_bytes;\n\tdrop_args.replace_extent = true;\n\tdrop_args.extent_item_size = sizeof(*stack_fi);\n\tret = btrfs_drop_extents(trans, root, inode, &drop_args);\n\tif (ret)\n\t\tgoto out;\n\n\tif (!drop_args.extent_inserted) {\n\t\tins.objectid = btrfs_ino(inode);\n\t\tins.offset = file_pos;\n\t\tins.type = BTRFS_EXTENT_DATA_KEY;\n\n\t\tret = btrfs_insert_empty_item(trans, root, path, &ins,\n\t\t\t\t\t      sizeof(*stack_fi));\n\t\tif (ret)\n\t\t\tgoto out;\n\t}\n\tleaf = path->nodes[0];\n\tbtrfs_set_stack_file_extent_generation(stack_fi, trans->transid);\n\twrite_extent_buffer(leaf, stack_fi,\n\t\t\tbtrfs_item_ptr_offset(leaf, path->slots[0]),\n\t\t\tsizeof(struct btrfs_file_extent_item));\n\n\tbtrfs_mark_buffer_dirty(leaf);\n\tbtrfs_release_path(path);\n\n\t/*\n\t * If we dropped an inline extent here, we know the range where it is\n\t * was not marked with the EXTENT_DELALLOC_NEW bit, so we update the\n\t * number of bytes only for that range contaning the inline extent.\n\t * The remaining of the range will be processed when clearning the\n\t * EXTENT_DELALLOC_BIT bit through the ordered extent completion.\n\t */\n\tif (file_pos == 0 && !IS_ALIGNED(drop_args.bytes_found, sectorsize)) {\n\t\tu64 inline_size = round_down(drop_args.bytes_found, sectorsize);\n\n\t\tinline_size = drop_args.bytes_found - inline_size;\n\t\tbtrfs_update_inode_bytes(inode, sectorsize, inline_size);\n\t\tdrop_args.bytes_found -= inline_size;\n\t\tnum_bytes -= sectorsize;\n\t}\n\n\tif (update_inode_bytes)\n\t\tbtrfs_update_inode_bytes(inode, num_bytes, drop_args.bytes_found);\n\n\tins.objectid = disk_bytenr;\n\tins.offset = disk_num_bytes;\n\tins.type = BTRFS_EXTENT_ITEM_KEY;\n\n\tret = btrfs_inode_set_file_extent_range(inode, file_pos, ram_bytes);\n\tif (ret)\n\t\tgoto out;\n\n\tret = btrfs_alloc_reserved_file_extent(trans, root, btrfs_ino(inode),\n\t\t\t\t\t       file_pos, qgroup_reserved, &ins);\nout:\n\tbtrfs_free_path(path);\n\n\treturn ret;\n}\n\nstatic void btrfs_release_delalloc_bytes(struct btrfs_fs_info *fs_info,\n\t\t\t\t\t u64 start, u64 len)\n{\n\tstruct btrfs_block_group *cache;\n\n\tcache = btrfs_lookup_block_group(fs_info, start);\n\tASSERT(cache);\n\n\tspin_lock(&cache->lock);\n\tcache->delalloc_bytes -= len;\n\tspin_unlock(&cache->lock);\n\n\tbtrfs_put_block_group(cache);\n}\n\nstatic int insert_ordered_extent_file_extent(struct btrfs_trans_handle *trans,\n\t\t\t\t\t     struct btrfs_ordered_extent *oe)\n{\n\tstruct btrfs_file_extent_item stack_fi;\n\tu64 logical_len;\n\tbool update_inode_bytes;\n\n\tmemset(&stack_fi, 0, sizeof(stack_fi));\n\tbtrfs_set_stack_file_extent_type(&stack_fi, BTRFS_FILE_EXTENT_REG);\n\tbtrfs_set_stack_file_extent_disk_bytenr(&stack_fi, oe->disk_bytenr);\n\tbtrfs_set_stack_file_extent_disk_num_bytes(&stack_fi,\n\t\t\t\t\t\t   oe->disk_num_bytes);\n\tif (test_bit(BTRFS_ORDERED_TRUNCATED, &oe->flags))\n\t\tlogical_len = oe->truncated_len;\n\telse\n\t\tlogical_len = oe->num_bytes;\n\tbtrfs_set_stack_file_extent_num_bytes(&stack_fi, logical_len);\n\tbtrfs_set_stack_file_extent_ram_bytes(&stack_fi, logical_len);\n\tbtrfs_set_stack_file_extent_compression(&stack_fi, oe->compress_type);\n\t/* Encryption and other encoding is reserved and all 0 */\n\n\t/*\n\t * For delalloc, when completing an ordered extent we update the inode's\n\t * bytes when clearing the range in the inode's io tree, so pass false\n\t * as the argument 'update_inode_bytes' to insert_reserved_file_extent(),\n\t * except if the ordered extent was truncated.\n\t */\n\tupdate_inode_bytes = test_bit(BTRFS_ORDERED_DIRECT, &oe->flags) ||\n\t\t\t     test_bit(BTRFS_ORDERED_TRUNCATED, &oe->flags);\n\n\treturn insert_reserved_file_extent(trans, BTRFS_I(oe->inode),\n\t\t\t\t\t   oe->file_offset, &stack_fi,\n\t\t\t\t\t   update_inode_bytes, oe->qgroup_rsv);\n}\n\n/*\n * As ordered data IO finishes, this gets called so we can finish\n * an ordered extent if the range of bytes in the file it covers are\n * fully written.\n */\nstatic int btrfs_finish_ordered_io(struct btrfs_ordered_extent *ordered_extent)\n{\n\tstruct btrfs_inode *inode = BTRFS_I(ordered_extent->inode);\n\tstruct btrfs_root *root = inode->root;\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tstruct btrfs_trans_handle *trans = NULL;\n\tstruct extent_io_tree *io_tree = &inode->io_tree;\n\tstruct extent_state *cached_state = NULL;\n\tu64 start, end;\n\tint compress_type = 0;\n\tint ret = 0;\n\tu64 logical_len = ordered_extent->num_bytes;\n\tbool freespace_inode;\n\tbool truncated = false;\n\tbool clear_reserved_extent = true;\n\tunsigned int clear_bits = EXTENT_DEFRAG;\n\n\tstart = ordered_extent->file_offset;\n\tend = start + ordered_extent->num_bytes - 1;\n\n\tif (!test_bit(BTRFS_ORDERED_NOCOW, &ordered_extent->flags) &&\n\t    !test_bit(BTRFS_ORDERED_PREALLOC, &ordered_extent->flags) &&\n\t    !test_bit(BTRFS_ORDERED_DIRECT, &ordered_extent->flags))\n\t\tclear_bits |= EXTENT_DELALLOC_NEW;\n\n\tfreespace_inode = btrfs_is_free_space_inode(inode);\n\n\tif (test_bit(BTRFS_ORDERED_IOERR, &ordered_extent->flags)) {\n\t\tret = -EIO;\n\t\tgoto out;\n\t}\n\n\tif (ordered_extent->disk)\n\t\tbtrfs_rewrite_logical_zoned(ordered_extent);\n\n\tbtrfs_free_io_failure_record(inode, start, end);\n\n\tif (test_bit(BTRFS_ORDERED_TRUNCATED, &ordered_extent->flags)) {\n\t\ttruncated = true;\n\t\tlogical_len = ordered_extent->truncated_len;\n\t\t/* Truncated the entire extent, don't bother adding */\n\t\tif (!logical_len)\n\t\t\tgoto out;\n\t}\n\n\tif (test_bit(BTRFS_ORDERED_NOCOW, &ordered_extent->flags)) {\n\t\tBUG_ON(!list_empty(&ordered_extent->list)); /* Logic error */\n\n\t\tbtrfs_inode_safe_disk_i_size_write(inode, 0);\n\t\tif (freespace_inode)\n\t\t\ttrans = btrfs_join_transaction_spacecache(root);\n\t\telse\n\t\t\ttrans = btrfs_join_transaction(root);\n\t\tif (IS_ERR(trans)) {\n\t\t\tret = PTR_ERR(trans);\n\t\t\ttrans = NULL;\n\t\t\tgoto out;\n\t\t}\n\t\ttrans->block_rsv = &inode->block_rsv;\n\t\tret = btrfs_update_inode_fallback(trans, root, inode);\n\t\tif (ret) /* -ENOMEM or corruption */\n\t\t\tbtrfs_abort_transaction(trans, ret);\n\t\tgoto out;\n\t}\n\n\tclear_bits |= EXTENT_LOCKED;\n\tlock_extent_bits(io_tree, start, end, &cached_state);\n\n\tif (freespace_inode)\n\t\ttrans = btrfs_join_transaction_spacecache(root);\n\telse\n\t\ttrans = btrfs_join_transaction(root);\n\tif (IS_ERR(trans)) {\n\t\tret = PTR_ERR(trans);\n\t\ttrans = NULL;\n\t\tgoto out;\n\t}\n\n\ttrans->block_rsv = &inode->block_rsv;\n\n\tif (test_bit(BTRFS_ORDERED_COMPRESSED, &ordered_extent->flags))\n\t\tcompress_type = ordered_extent->compress_type;\n\tif (test_bit(BTRFS_ORDERED_PREALLOC, &ordered_extent->flags)) {\n\t\tBUG_ON(compress_type);\n\t\tret = btrfs_mark_extent_written(trans, inode,\n\t\t\t\t\t\tordered_extent->file_offset,\n\t\t\t\t\t\tordered_extent->file_offset +\n\t\t\t\t\t\tlogical_len);\n\t} else {\n\t\tBUG_ON(root == fs_info->tree_root);\n\t\tret = insert_ordered_extent_file_extent(trans, ordered_extent);\n\t\tif (!ret) {\n\t\t\tclear_reserved_extent = false;\n\t\t\tbtrfs_release_delalloc_bytes(fs_info,\n\t\t\t\t\t\tordered_extent->disk_bytenr,\n\t\t\t\t\t\tordered_extent->disk_num_bytes);\n\t\t}\n\t}\n\tunpin_extent_cache(&inode->extent_tree, ordered_extent->file_offset,\n\t\t\t   ordered_extent->num_bytes, trans->transid);\n\tif (ret < 0) {\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\tgoto out;\n\t}\n\n\tret = add_pending_csums(trans, &ordered_extent->list);\n\tif (ret) {\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\tgoto out;\n\t}\n\n\t/*\n\t * If this is a new delalloc range, clear its new delalloc flag to\n\t * update the inode's number of bytes. This needs to be done first\n\t * before updating the inode item.\n\t */\n\tif ((clear_bits & EXTENT_DELALLOC_NEW) &&\n\t    !test_bit(BTRFS_ORDERED_TRUNCATED, &ordered_extent->flags))\n\t\tclear_extent_bit(&inode->io_tree, start, end,\n\t\t\t\t EXTENT_DELALLOC_NEW | EXTENT_ADD_INODE_BYTES,\n\t\t\t\t 0, 0, &cached_state);\n\n\tbtrfs_inode_safe_disk_i_size_write(inode, 0);\n\tret = btrfs_update_inode_fallback(trans, root, inode);\n\tif (ret) { /* -ENOMEM or corruption */\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\tgoto out;\n\t}\n\tret = 0;\nout:\n\tclear_extent_bit(&inode->io_tree, start, end, clear_bits,\n\t\t\t (clear_bits & EXTENT_LOCKED) ? 1 : 0, 0,\n\t\t\t &cached_state);\n\n\tif (trans)\n\t\tbtrfs_end_transaction(trans);\n\n\tif (ret || truncated) {\n\t\tu64 unwritten_start = start;\n\n\t\tif (truncated)\n\t\t\tunwritten_start += logical_len;\n\t\tclear_extent_uptodate(io_tree, unwritten_start, end, NULL);\n\n\t\t/* Drop the cache for the part of the extent we didn't write. */\n\t\tbtrfs_drop_extent_cache(inode, unwritten_start, end, 0);\n\n\t\t/*\n\t\t * If the ordered extent had an IOERR or something else went\n\t\t * wrong we need to return the space for this ordered extent\n\t\t * back to the allocator.  We only free the extent in the\n\t\t * truncated case if we didn't write out the extent at all.\n\t\t *\n\t\t * If we made it past insert_reserved_file_extent before we\n\t\t * errored out then we don't need to do this as the accounting\n\t\t * has already been done.\n\t\t */\n\t\tif ((ret || !logical_len) &&\n\t\t    clear_reserved_extent &&\n\t\t    !test_bit(BTRFS_ORDERED_NOCOW, &ordered_extent->flags) &&\n\t\t    !test_bit(BTRFS_ORDERED_PREALLOC, &ordered_extent->flags)) {\n\t\t\t/*\n\t\t\t * Discard the range before returning it back to the\n\t\t\t * free space pool\n\t\t\t */\n\t\t\tif (ret && btrfs_test_opt(fs_info, DISCARD_SYNC))\n\t\t\t\tbtrfs_discard_extent(fs_info,\n\t\t\t\t\t\tordered_extent->disk_bytenr,\n\t\t\t\t\t\tordered_extent->disk_num_bytes,\n\t\t\t\t\t\tNULL);\n\t\t\tbtrfs_free_reserved_extent(fs_info,\n\t\t\t\t\tordered_extent->disk_bytenr,\n\t\t\t\t\tordered_extent->disk_num_bytes, 1);\n\t\t}\n\t}\n\n\t/*\n\t * This needs to be done to make sure anybody waiting knows we are done\n\t * updating everything for this ordered extent.\n\t */\n\tbtrfs_remove_ordered_extent(inode, ordered_extent);\n\n\t/* once for us */\n\tbtrfs_put_ordered_extent(ordered_extent);\n\t/* once for the tree */\n\tbtrfs_put_ordered_extent(ordered_extent);\n\n\treturn ret;\n}\n\nstatic void finish_ordered_fn(struct btrfs_work *work)\n{\n\tstruct btrfs_ordered_extent *ordered_extent;\n\tordered_extent = container_of(work, struct btrfs_ordered_extent, work);\n\tbtrfs_finish_ordered_io(ordered_extent);\n}\n\nvoid btrfs_writepage_endio_finish_ordered(struct page *page, u64 start,\n\t\t\t\t\t  u64 end, int uptodate)\n{\n\tstruct btrfs_inode *inode = BTRFS_I(page->mapping->host);\n\tstruct btrfs_fs_info *fs_info = inode->root->fs_info;\n\tstruct btrfs_ordered_extent *ordered_extent = NULL;\n\tstruct btrfs_workqueue *wq;\n\n\ttrace_btrfs_writepage_end_io_hook(page, start, end, uptodate);\n\n\tClearPagePrivate2(page);\n\tif (!btrfs_dec_test_ordered_pending(inode, &ordered_extent, start,\n\t\t\t\t\t    end - start + 1, uptodate))\n\t\treturn;\n\n\tif (btrfs_is_free_space_inode(inode))\n\t\twq = fs_info->endio_freespace_worker;\n\telse\n\t\twq = fs_info->endio_write_workers;\n\n\tbtrfs_init_work(&ordered_extent->work, finish_ordered_fn, NULL, NULL);\n\tbtrfs_queue_work(wq, &ordered_extent->work);\n}\n\n/*\n * check_data_csum - verify checksum of one sector of uncompressed data\n * @inode:\tinode\n * @io_bio:\tbtrfs_io_bio which contains the csum\n * @bio_offset:\toffset to the beginning of the bio (in bytes)\n * @page:\tpage where is the data to be verified\n * @pgoff:\toffset inside the page\n *\n * The length of such check is always one sector size.\n */\nstatic int check_data_csum(struct inode *inode, struct btrfs_io_bio *io_bio,\n\t\t\t   u32 bio_offset, struct page *page, u32 pgoff)\n{\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);\n\tSHASH_DESC_ON_STACK(shash, fs_info->csum_shash);\n\tchar *kaddr;\n\tu32 len = fs_info->sectorsize;\n\tconst u32 csum_size = fs_info->csum_size;\n\tunsigned int offset_sectors;\n\tu8 *csum_expected;\n\tu8 csum[BTRFS_CSUM_SIZE];\n\n\tASSERT(pgoff + len <= PAGE_SIZE);\n\n\toffset_sectors = bio_offset >> fs_info->sectorsize_bits;\n\tcsum_expected = ((u8 *)io_bio->csum) + offset_sectors * csum_size;\n\n\tkaddr = kmap_atomic(page);\n\tshash->tfm = fs_info->csum_shash;\n\n\tcrypto_shash_digest(shash, kaddr + pgoff, len, csum);\n\n\tif (memcmp(csum, csum_expected, csum_size))\n\t\tgoto zeroit;\n\n\tkunmap_atomic(kaddr);\n\treturn 0;\nzeroit:\n\tbtrfs_print_data_csum_error(BTRFS_I(inode), page_offset(page) + pgoff,\n\t\t\t\t    csum, csum_expected, io_bio->mirror_num);\n\tif (io_bio->device)\n\t\tbtrfs_dev_stat_inc_and_print(io_bio->device,\n\t\t\t\t\t     BTRFS_DEV_STAT_CORRUPTION_ERRS);\n\tmemset(kaddr + pgoff, 1, len);\n\tflush_dcache_page(page);\n\tkunmap_atomic(kaddr);\n\treturn -EIO;\n}\n\n/*\n * When reads are done, we need to check csums to verify the data is correct.\n * if there's a match, we allow the bio to finish.  If not, the code in\n * extent_io.c will try to find good copies for us.\n *\n * @bio_offset:\toffset to the beginning of the bio (in bytes)\n * @start:\tfile offset of the range start\n * @end:\tfile offset of the range end (inclusive)\n * @mirror:\tmirror number\n */\nint btrfs_verify_data_csum(struct btrfs_io_bio *io_bio, u32 bio_offset,\n\t\t\t   struct page *page, u64 start, u64 end, int mirror)\n{\n\tstruct inode *inode = page->mapping->host;\n\tstruct extent_io_tree *io_tree = &BTRFS_I(inode)->io_tree;\n\tstruct btrfs_root *root = BTRFS_I(inode)->root;\n\tconst u32 sectorsize = root->fs_info->sectorsize;\n\tu32 pg_off;\n\n\tif (PageChecked(page)) {\n\t\tClearPageChecked(page);\n\t\treturn 0;\n\t}\n\n\tif (BTRFS_I(inode)->flags & BTRFS_INODE_NODATASUM)\n\t\treturn 0;\n\n\tif (!root->fs_info->csum_root)\n\t\treturn 0;\n\n\tif (root->root_key.objectid == BTRFS_DATA_RELOC_TREE_OBJECTID &&\n\t    test_range_bit(io_tree, start, end, EXTENT_NODATASUM, 1, NULL)) {\n\t\tclear_extent_bits(io_tree, start, end, EXTENT_NODATASUM);\n\t\treturn 0;\n\t}\n\n\tASSERT(page_offset(page) <= start &&\n\t       end <= page_offset(page) + PAGE_SIZE - 1);\n\tfor (pg_off = offset_in_page(start);\n\t     pg_off < offset_in_page(end);\n\t     pg_off += sectorsize, bio_offset += sectorsize) {\n\t\tint ret;\n\n\t\tret = check_data_csum(inode, io_bio, bio_offset, page, pg_off);\n\t\tif (ret < 0)\n\t\t\treturn -EIO;\n\t}\n\treturn 0;\n}\n\n/*\n * btrfs_add_delayed_iput - perform a delayed iput on @inode\n *\n * @inode: The inode we want to perform iput on\n *\n * This function uses the generic vfs_inode::i_count to track whether we should\n * just decrement it (in case it's > 1) or if this is the last iput then link\n * the inode to the delayed iput machinery. Delayed iputs are processed at\n * transaction commit time/superblock commit/cleaner kthread.\n */\nvoid btrfs_add_delayed_iput(struct inode *inode)\n{\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);\n\tstruct btrfs_inode *binode = BTRFS_I(inode);\n\n\tif (atomic_add_unless(&inode->i_count, -1, 1))\n\t\treturn;\n\n\tatomic_inc(&fs_info->nr_delayed_iputs);\n\tspin_lock(&fs_info->delayed_iput_lock);\n\tASSERT(list_empty(&binode->delayed_iput));\n\tlist_add_tail(&binode->delayed_iput, &fs_info->delayed_iputs);\n\tspin_unlock(&fs_info->delayed_iput_lock);\n\tif (!test_bit(BTRFS_FS_CLEANER_RUNNING, &fs_info->flags))\n\t\twake_up_process(fs_info->cleaner_kthread);\n}\n\nstatic void run_delayed_iput_locked(struct btrfs_fs_info *fs_info,\n\t\t\t\t    struct btrfs_inode *inode)\n{\n\tlist_del_init(&inode->delayed_iput);\n\tspin_unlock(&fs_info->delayed_iput_lock);\n\tiput(&inode->vfs_inode);\n\tif (atomic_dec_and_test(&fs_info->nr_delayed_iputs))\n\t\twake_up(&fs_info->delayed_iputs_wait);\n\tspin_lock(&fs_info->delayed_iput_lock);\n}\n\nstatic void btrfs_run_delayed_iput(struct btrfs_fs_info *fs_info,\n\t\t\t\t   struct btrfs_inode *inode)\n{\n\tif (!list_empty(&inode->delayed_iput)) {\n\t\tspin_lock(&fs_info->delayed_iput_lock);\n\t\tif (!list_empty(&inode->delayed_iput))\n\t\t\trun_delayed_iput_locked(fs_info, inode);\n\t\tspin_unlock(&fs_info->delayed_iput_lock);\n\t}\n}\n\nvoid btrfs_run_delayed_iputs(struct btrfs_fs_info *fs_info)\n{\n\n\tspin_lock(&fs_info->delayed_iput_lock);\n\twhile (!list_empty(&fs_info->delayed_iputs)) {\n\t\tstruct btrfs_inode *inode;\n\n\t\tinode = list_first_entry(&fs_info->delayed_iputs,\n\t\t\t\tstruct btrfs_inode, delayed_iput);\n\t\trun_delayed_iput_locked(fs_info, inode);\n\t}\n\tspin_unlock(&fs_info->delayed_iput_lock);\n}\n\n/**\n * Wait for flushing all delayed iputs\n *\n * @fs_info:  the filesystem\n *\n * This will wait on any delayed iputs that are currently running with KILLABLE\n * set.  Once they are all done running we will return, unless we are killed in\n * which case we return EINTR. This helps in user operations like fallocate etc\n * that might get blocked on the iputs.\n *\n * Return EINTR if we were killed, 0 if nothing's pending\n */\nint btrfs_wait_on_delayed_iputs(struct btrfs_fs_info *fs_info)\n{\n\tint ret = wait_event_killable(fs_info->delayed_iputs_wait,\n\t\t\tatomic_read(&fs_info->nr_delayed_iputs) == 0);\n\tif (ret)\n\t\treturn -EINTR;\n\treturn 0;\n}\n\n/*\n * This creates an orphan entry for the given inode in case something goes wrong\n * in the middle of an unlink.\n */\nint btrfs_orphan_add(struct btrfs_trans_handle *trans,\n\t\t     struct btrfs_inode *inode)\n{\n\tint ret;\n\n\tret = btrfs_insert_orphan_item(trans, inode->root, btrfs_ino(inode));\n\tif (ret && ret != -EEXIST) {\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\n/*\n * We have done the delete so we can go ahead and remove the orphan item for\n * this particular inode.\n */\nstatic int btrfs_orphan_del(struct btrfs_trans_handle *trans,\n\t\t\t    struct btrfs_inode *inode)\n{\n\treturn btrfs_del_orphan_item(trans, inode->root, btrfs_ino(inode));\n}\n\n/*\n * this cleans up any orphans that may be left on the list from the last use\n * of this root.\n */\nint btrfs_orphan_cleanup(struct btrfs_root *root)\n{\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tstruct btrfs_path *path;\n\tstruct extent_buffer *leaf;\n\tstruct btrfs_key key, found_key;\n\tstruct btrfs_trans_handle *trans;\n\tstruct inode *inode;\n\tu64 last_objectid = 0;\n\tint ret = 0, nr_unlink = 0;\n\n\tif (cmpxchg(&root->orphan_cleanup_state, 0, ORPHAN_CLEANUP_STARTED))\n\t\treturn 0;\n\n\tpath = btrfs_alloc_path();\n\tif (!path) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\tpath->reada = READA_BACK;\n\n\tkey.objectid = BTRFS_ORPHAN_OBJECTID;\n\tkey.type = BTRFS_ORPHAN_ITEM_KEY;\n\tkey.offset = (u64)-1;\n\n\twhile (1) {\n\t\tret = btrfs_search_slot(NULL, root, &key, path, 0, 0);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\n\t\t/*\n\t\t * if ret == 0 means we found what we were searching for, which\n\t\t * is weird, but possible, so only screw with path if we didn't\n\t\t * find the key and see if we have stuff that matches\n\t\t */\n\t\tif (ret > 0) {\n\t\t\tret = 0;\n\t\t\tif (path->slots[0] == 0)\n\t\t\t\tbreak;\n\t\t\tpath->slots[0]--;\n\t\t}\n\n\t\t/* pull out the item */\n\t\tleaf = path->nodes[0];\n\t\tbtrfs_item_key_to_cpu(leaf, &found_key, path->slots[0]);\n\n\t\t/* make sure the item matches what we want */\n\t\tif (found_key.objectid != BTRFS_ORPHAN_OBJECTID)\n\t\t\tbreak;\n\t\tif (found_key.type != BTRFS_ORPHAN_ITEM_KEY)\n\t\t\tbreak;\n\n\t\t/* release the path since we're done with it */\n\t\tbtrfs_release_path(path);\n\n\t\t/*\n\t\t * this is where we are basically btrfs_lookup, without the\n\t\t * crossing root thing.  we store the inode number in the\n\t\t * offset of the orphan item.\n\t\t */\n\n\t\tif (found_key.offset == last_objectid) {\n\t\t\tbtrfs_err(fs_info,\n\t\t\t\t  \"Error removing orphan entry, stopping orphan cleanup\");\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tlast_objectid = found_key.offset;\n\n\t\tfound_key.objectid = found_key.offset;\n\t\tfound_key.type = BTRFS_INODE_ITEM_KEY;\n\t\tfound_key.offset = 0;\n\t\tinode = btrfs_iget(fs_info->sb, last_objectid, root);\n\t\tret = PTR_ERR_OR_ZERO(inode);\n\t\tif (ret && ret != -ENOENT)\n\t\t\tgoto out;\n\n\t\tif (ret == -ENOENT && root == fs_info->tree_root) {\n\t\t\tstruct btrfs_root *dead_root;\n\t\t\tint is_dead_root = 0;\n\n\t\t\t/*\n\t\t\t * this is an orphan in the tree root. Currently these\n\t\t\t * could come from 2 sources:\n\t\t\t *  a) a snapshot deletion in progress\n\t\t\t *  b) a free space cache inode\n\t\t\t * We need to distinguish those two, as the snapshot\n\t\t\t * orphan must not get deleted.\n\t\t\t * find_dead_roots already ran before us, so if this\n\t\t\t * is a snapshot deletion, we should find the root\n\t\t\t * in the fs_roots radix tree.\n\t\t\t */\n\n\t\t\tspin_lock(&fs_info->fs_roots_radix_lock);\n\t\t\tdead_root = radix_tree_lookup(&fs_info->fs_roots_radix,\n\t\t\t\t\t\t\t (unsigned long)found_key.objectid);\n\t\t\tif (dead_root && btrfs_root_refs(&dead_root->root_item) == 0)\n\t\t\t\tis_dead_root = 1;\n\t\t\tspin_unlock(&fs_info->fs_roots_radix_lock);\n\n\t\t\tif (is_dead_root) {\n\t\t\t\t/* prevent this orphan from being found again */\n\t\t\t\tkey.offset = found_key.objectid - 1;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t}\n\n\t\t/*\n\t\t * If we have an inode with links, there are a couple of\n\t\t * possibilities. Old kernels (before v3.12) used to create an\n\t\t * orphan item for truncate indicating that there were possibly\n\t\t * extent items past i_size that needed to be deleted. In v3.12,\n\t\t * truncate was changed to update i_size in sync with the extent\n\t\t * items, but the (useless) orphan item was still created. Since\n\t\t * v4.18, we don't create the orphan item for truncate at all.\n\t\t *\n\t\t * So, this item could mean that we need to do a truncate, but\n\t\t * only if this filesystem was last used on a pre-v3.12 kernel\n\t\t * and was not cleanly unmounted. The odds of that are quite\n\t\t * slim, and it's a pain to do the truncate now, so just delete\n\t\t * the orphan item.\n\t\t *\n\t\t * It's also possible that this orphan item was supposed to be\n\t\t * deleted but wasn't. The inode number may have been reused,\n\t\t * but either way, we can delete the orphan item.\n\t\t */\n\t\tif (ret == -ENOENT || inode->i_nlink) {\n\t\t\tif (!ret)\n\t\t\t\tiput(inode);\n\t\t\ttrans = btrfs_start_transaction(root, 1);\n\t\t\tif (IS_ERR(trans)) {\n\t\t\t\tret = PTR_ERR(trans);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tbtrfs_debug(fs_info, \"auto deleting %Lu\",\n\t\t\t\t    found_key.objectid);\n\t\t\tret = btrfs_del_orphan_item(trans, root,\n\t\t\t\t\t\t    found_key.objectid);\n\t\t\tbtrfs_end_transaction(trans);\n\t\t\tif (ret)\n\t\t\t\tgoto out;\n\t\t\tcontinue;\n\t\t}\n\n\t\tnr_unlink++;\n\n\t\t/* this will do delete_inode and everything for us */\n\t\tiput(inode);\n\t}\n\t/* release the path since we're done with it */\n\tbtrfs_release_path(path);\n\n\troot->orphan_cleanup_state = ORPHAN_CLEANUP_DONE;\n\n\tif (test_bit(BTRFS_ROOT_ORPHAN_ITEM_INSERTED, &root->state)) {\n\t\ttrans = btrfs_join_transaction(root);\n\t\tif (!IS_ERR(trans))\n\t\t\tbtrfs_end_transaction(trans);\n\t}\n\n\tif (nr_unlink)\n\t\tbtrfs_debug(fs_info, \"unlinked %d orphans\", nr_unlink);\n\nout:\n\tif (ret)\n\t\tbtrfs_err(fs_info, \"could not do orphan cleanup %d\", ret);\n\tbtrfs_free_path(path);\n\treturn ret;\n}\n\n/*\n * very simple check to peek ahead in the leaf looking for xattrs.  If we\n * don't find any xattrs, we know there can't be any acls.\n *\n * slot is the slot the inode is in, objectid is the objectid of the inode\n */\nstatic noinline int acls_after_inode_item(struct extent_buffer *leaf,\n\t\t\t\t\t  int slot, u64 objectid,\n\t\t\t\t\t  int *first_xattr_slot)\n{\n\tu32 nritems = btrfs_header_nritems(leaf);\n\tstruct btrfs_key found_key;\n\tstatic u64 xattr_access = 0;\n\tstatic u64 xattr_default = 0;\n\tint scanned = 0;\n\n\tif (!xattr_access) {\n\t\txattr_access = btrfs_name_hash(XATTR_NAME_POSIX_ACL_ACCESS,\n\t\t\t\t\tstrlen(XATTR_NAME_POSIX_ACL_ACCESS));\n\t\txattr_default = btrfs_name_hash(XATTR_NAME_POSIX_ACL_DEFAULT,\n\t\t\t\t\tstrlen(XATTR_NAME_POSIX_ACL_DEFAULT));\n\t}\n\n\tslot++;\n\t*first_xattr_slot = -1;\n\twhile (slot < nritems) {\n\t\tbtrfs_item_key_to_cpu(leaf, &found_key, slot);\n\n\t\t/* we found a different objectid, there must not be acls */\n\t\tif (found_key.objectid != objectid)\n\t\t\treturn 0;\n\n\t\t/* we found an xattr, assume we've got an acl */\n\t\tif (found_key.type == BTRFS_XATTR_ITEM_KEY) {\n\t\t\tif (*first_xattr_slot == -1)\n\t\t\t\t*first_xattr_slot = slot;\n\t\t\tif (found_key.offset == xattr_access ||\n\t\t\t    found_key.offset == xattr_default)\n\t\t\t\treturn 1;\n\t\t}\n\n\t\t/*\n\t\t * we found a key greater than an xattr key, there can't\n\t\t * be any acls later on\n\t\t */\n\t\tif (found_key.type > BTRFS_XATTR_ITEM_KEY)\n\t\t\treturn 0;\n\n\t\tslot++;\n\t\tscanned++;\n\n\t\t/*\n\t\t * it goes inode, inode backrefs, xattrs, extents,\n\t\t * so if there are a ton of hard links to an inode there can\n\t\t * be a lot of backrefs.  Don't waste time searching too hard,\n\t\t * this is just an optimization\n\t\t */\n\t\tif (scanned >= 8)\n\t\t\tbreak;\n\t}\n\t/* we hit the end of the leaf before we found an xattr or\n\t * something larger than an xattr.  We have to assume the inode\n\t * has acls\n\t */\n\tif (*first_xattr_slot == -1)\n\t\t*first_xattr_slot = slot;\n\treturn 1;\n}\n\n/*\n * read an inode from the btree into the in-memory inode\n */\nstatic int btrfs_read_locked_inode(struct inode *inode,\n\t\t\t\t   struct btrfs_path *in_path)\n{\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);\n\tstruct btrfs_path *path = in_path;\n\tstruct extent_buffer *leaf;\n\tstruct btrfs_inode_item *inode_item;\n\tstruct btrfs_root *root = BTRFS_I(inode)->root;\n\tstruct btrfs_key location;\n\tunsigned long ptr;\n\tint maybe_acls;\n\tu32 rdev;\n\tint ret;\n\tbool filled = false;\n\tint first_xattr_slot;\n\n\tret = btrfs_fill_inode(inode, &rdev);\n\tif (!ret)\n\t\tfilled = true;\n\n\tif (!path) {\n\t\tpath = btrfs_alloc_path();\n\t\tif (!path)\n\t\t\treturn -ENOMEM;\n\t}\n\n\tmemcpy(&location, &BTRFS_I(inode)->location, sizeof(location));\n\n\tret = btrfs_lookup_inode(NULL, root, path, &location, 0);\n\tif (ret) {\n\t\tif (path != in_path)\n\t\t\tbtrfs_free_path(path);\n\t\treturn ret;\n\t}\n\n\tleaf = path->nodes[0];\n\n\tif (filled)\n\t\tgoto cache_index;\n\n\tinode_item = btrfs_item_ptr(leaf, path->slots[0],\n\t\t\t\t    struct btrfs_inode_item);\n\tinode->i_mode = btrfs_inode_mode(leaf, inode_item);\n\tset_nlink(inode, btrfs_inode_nlink(leaf, inode_item));\n\ti_uid_write(inode, btrfs_inode_uid(leaf, inode_item));\n\ti_gid_write(inode, btrfs_inode_gid(leaf, inode_item));\n\tbtrfs_i_size_write(BTRFS_I(inode), btrfs_inode_size(leaf, inode_item));\n\tbtrfs_inode_set_file_extent_range(BTRFS_I(inode), 0,\n\t\t\tround_up(i_size_read(inode), fs_info->sectorsize));\n\n\tinode->i_atime.tv_sec = btrfs_timespec_sec(leaf, &inode_item->atime);\n\tinode->i_atime.tv_nsec = btrfs_timespec_nsec(leaf, &inode_item->atime);\n\n\tinode->i_mtime.tv_sec = btrfs_timespec_sec(leaf, &inode_item->mtime);\n\tinode->i_mtime.tv_nsec = btrfs_timespec_nsec(leaf, &inode_item->mtime);\n\n\tinode->i_ctime.tv_sec = btrfs_timespec_sec(leaf, &inode_item->ctime);\n\tinode->i_ctime.tv_nsec = btrfs_timespec_nsec(leaf, &inode_item->ctime);\n\n\tBTRFS_I(inode)->i_otime.tv_sec =\n\t\tbtrfs_timespec_sec(leaf, &inode_item->otime);\n\tBTRFS_I(inode)->i_otime.tv_nsec =\n\t\tbtrfs_timespec_nsec(leaf, &inode_item->otime);\n\n\tinode_set_bytes(inode, btrfs_inode_nbytes(leaf, inode_item));\n\tBTRFS_I(inode)->generation = btrfs_inode_generation(leaf, inode_item);\n\tBTRFS_I(inode)->last_trans = btrfs_inode_transid(leaf, inode_item);\n\n\tinode_set_iversion_queried(inode,\n\t\t\t\t   btrfs_inode_sequence(leaf, inode_item));\n\tinode->i_generation = BTRFS_I(inode)->generation;\n\tinode->i_rdev = 0;\n\trdev = btrfs_inode_rdev(leaf, inode_item);\n\n\tBTRFS_I(inode)->index_cnt = (u64)-1;\n\tBTRFS_I(inode)->flags = btrfs_inode_flags(leaf, inode_item);\n\ncache_index:\n\t/*\n\t * If we were modified in the current generation and evicted from memory\n\t * and then re-read we need to do a full sync since we don't have any\n\t * idea about which extents were modified before we were evicted from\n\t * cache.\n\t *\n\t * This is required for both inode re-read from disk and delayed inode\n\t * in delayed_nodes_tree.\n\t */\n\tif (BTRFS_I(inode)->last_trans == fs_info->generation)\n\t\tset_bit(BTRFS_INODE_NEEDS_FULL_SYNC,\n\t\t\t&BTRFS_I(inode)->runtime_flags);\n\n\t/*\n\t * We don't persist the id of the transaction where an unlink operation\n\t * against the inode was last made. So here we assume the inode might\n\t * have been evicted, and therefore the exact value of last_unlink_trans\n\t * lost, and set it to last_trans to avoid metadata inconsistencies\n\t * between the inode and its parent if the inode is fsync'ed and the log\n\t * replayed. For example, in the scenario:\n\t *\n\t * touch mydir/foo\n\t * ln mydir/foo mydir/bar\n\t * sync\n\t * unlink mydir/bar\n\t * echo 2 > /proc/sys/vm/drop_caches   # evicts inode\n\t * xfs_io -c fsync mydir/foo\n\t * <power failure>\n\t * mount fs, triggers fsync log replay\n\t *\n\t * We must make sure that when we fsync our inode foo we also log its\n\t * parent inode, otherwise after log replay the parent still has the\n\t * dentry with the \"bar\" name but our inode foo has a link count of 1\n\t * and doesn't have an inode ref with the name \"bar\" anymore.\n\t *\n\t * Setting last_unlink_trans to last_trans is a pessimistic approach,\n\t * but it guarantees correctness at the expense of occasional full\n\t * transaction commits on fsync if our inode is a directory, or if our\n\t * inode is not a directory, logging its parent unnecessarily.\n\t */\n\tBTRFS_I(inode)->last_unlink_trans = BTRFS_I(inode)->last_trans;\n\n\t/*\n\t * Same logic as for last_unlink_trans. We don't persist the generation\n\t * of the last transaction where this inode was used for a reflink\n\t * operation, so after eviction and reloading the inode we must be\n\t * pessimistic and assume the last transaction that modified the inode.\n\t */\n\tBTRFS_I(inode)->last_reflink_trans = BTRFS_I(inode)->last_trans;\n\n\tpath->slots[0]++;\n\tif (inode->i_nlink != 1 ||\n\t    path->slots[0] >= btrfs_header_nritems(leaf))\n\t\tgoto cache_acl;\n\n\tbtrfs_item_key_to_cpu(leaf, &location, path->slots[0]);\n\tif (location.objectid != btrfs_ino(BTRFS_I(inode)))\n\t\tgoto cache_acl;\n\n\tptr = btrfs_item_ptr_offset(leaf, path->slots[0]);\n\tif (location.type == BTRFS_INODE_REF_KEY) {\n\t\tstruct btrfs_inode_ref *ref;\n\n\t\tref = (struct btrfs_inode_ref *)ptr;\n\t\tBTRFS_I(inode)->dir_index = btrfs_inode_ref_index(leaf, ref);\n\t} else if (location.type == BTRFS_INODE_EXTREF_KEY) {\n\t\tstruct btrfs_inode_extref *extref;\n\n\t\textref = (struct btrfs_inode_extref *)ptr;\n\t\tBTRFS_I(inode)->dir_index = btrfs_inode_extref_index(leaf,\n\t\t\t\t\t\t\t\t     extref);\n\t}\ncache_acl:\n\t/*\n\t * try to precache a NULL acl entry for files that don't have\n\t * any xattrs or acls\n\t */\n\tmaybe_acls = acls_after_inode_item(leaf, path->slots[0],\n\t\t\tbtrfs_ino(BTRFS_I(inode)), &first_xattr_slot);\n\tif (first_xattr_slot != -1) {\n\t\tpath->slots[0] = first_xattr_slot;\n\t\tret = btrfs_load_inode_props(inode, path);\n\t\tif (ret)\n\t\t\tbtrfs_err(fs_info,\n\t\t\t\t  \"error loading props for ino %llu (root %llu): %d\",\n\t\t\t\t  btrfs_ino(BTRFS_I(inode)),\n\t\t\t\t  root->root_key.objectid, ret);\n\t}\n\tif (path != in_path)\n\t\tbtrfs_free_path(path);\n\n\tif (!maybe_acls)\n\t\tcache_no_acl(inode);\n\n\tswitch (inode->i_mode & S_IFMT) {\n\tcase S_IFREG:\n\t\tinode->i_mapping->a_ops = &btrfs_aops;\n\t\tinode->i_fop = &btrfs_file_operations;\n\t\tinode->i_op = &btrfs_file_inode_operations;\n\t\tbreak;\n\tcase S_IFDIR:\n\t\tinode->i_fop = &btrfs_dir_file_operations;\n\t\tinode->i_op = &btrfs_dir_inode_operations;\n\t\tbreak;\n\tcase S_IFLNK:\n\t\tinode->i_op = &btrfs_symlink_inode_operations;\n\t\tinode_nohighmem(inode);\n\t\tinode->i_mapping->a_ops = &btrfs_aops;\n\t\tbreak;\n\tdefault:\n\t\tinode->i_op = &btrfs_special_inode_operations;\n\t\tinit_special_inode(inode, inode->i_mode, rdev);\n\t\tbreak;\n\t}\n\n\tbtrfs_sync_inode_flags_to_i_flags(inode);\n\treturn 0;\n}\n\n/*\n * given a leaf and an inode, copy the inode fields into the leaf\n */\nstatic void fill_inode_item(struct btrfs_trans_handle *trans,\n\t\t\t    struct extent_buffer *leaf,\n\t\t\t    struct btrfs_inode_item *item,\n\t\t\t    struct inode *inode)\n{\n\tstruct btrfs_map_token token;\n\n\tbtrfs_init_map_token(&token, leaf);\n\n\tbtrfs_set_token_inode_uid(&token, item, i_uid_read(inode));\n\tbtrfs_set_token_inode_gid(&token, item, i_gid_read(inode));\n\tbtrfs_set_token_inode_size(&token, item, BTRFS_I(inode)->disk_i_size);\n\tbtrfs_set_token_inode_mode(&token, item, inode->i_mode);\n\tbtrfs_set_token_inode_nlink(&token, item, inode->i_nlink);\n\n\tbtrfs_set_token_timespec_sec(&token, &item->atime,\n\t\t\t\t     inode->i_atime.tv_sec);\n\tbtrfs_set_token_timespec_nsec(&token, &item->atime,\n\t\t\t\t      inode->i_atime.tv_nsec);\n\n\tbtrfs_set_token_timespec_sec(&token, &item->mtime,\n\t\t\t\t     inode->i_mtime.tv_sec);\n\tbtrfs_set_token_timespec_nsec(&token, &item->mtime,\n\t\t\t\t      inode->i_mtime.tv_nsec);\n\n\tbtrfs_set_token_timespec_sec(&token, &item->ctime,\n\t\t\t\t     inode->i_ctime.tv_sec);\n\tbtrfs_set_token_timespec_nsec(&token, &item->ctime,\n\t\t\t\t      inode->i_ctime.tv_nsec);\n\n\tbtrfs_set_token_timespec_sec(&token, &item->otime,\n\t\t\t\t     BTRFS_I(inode)->i_otime.tv_sec);\n\tbtrfs_set_token_timespec_nsec(&token, &item->otime,\n\t\t\t\t      BTRFS_I(inode)->i_otime.tv_nsec);\n\n\tbtrfs_set_token_inode_nbytes(&token, item, inode_get_bytes(inode));\n\tbtrfs_set_token_inode_generation(&token, item,\n\t\t\t\t\t BTRFS_I(inode)->generation);\n\tbtrfs_set_token_inode_sequence(&token, item, inode_peek_iversion(inode));\n\tbtrfs_set_token_inode_transid(&token, item, trans->transid);\n\tbtrfs_set_token_inode_rdev(&token, item, inode->i_rdev);\n\tbtrfs_set_token_inode_flags(&token, item, BTRFS_I(inode)->flags);\n\tbtrfs_set_token_inode_block_group(&token, item, 0);\n}\n\n/*\n * copy everything in the in-memory inode into the btree.\n */\nstatic noinline int btrfs_update_inode_item(struct btrfs_trans_handle *trans,\n\t\t\t\tstruct btrfs_root *root,\n\t\t\t\tstruct btrfs_inode *inode)\n{\n\tstruct btrfs_inode_item *inode_item;\n\tstruct btrfs_path *path;\n\tstruct extent_buffer *leaf;\n\tint ret;\n\n\tpath = btrfs_alloc_path();\n\tif (!path)\n\t\treturn -ENOMEM;\n\n\tret = btrfs_lookup_inode(trans, root, path, &inode->location, 1);\n\tif (ret) {\n\t\tif (ret > 0)\n\t\t\tret = -ENOENT;\n\t\tgoto failed;\n\t}\n\n\tleaf = path->nodes[0];\n\tinode_item = btrfs_item_ptr(leaf, path->slots[0],\n\t\t\t\t    struct btrfs_inode_item);\n\n\tfill_inode_item(trans, leaf, inode_item, &inode->vfs_inode);\n\tbtrfs_mark_buffer_dirty(leaf);\n\tbtrfs_set_inode_last_trans(trans, inode);\n\tret = 0;\nfailed:\n\tbtrfs_free_path(path);\n\treturn ret;\n}\n\n/*\n * copy everything in the in-memory inode into the btree.\n */\nnoinline int btrfs_update_inode(struct btrfs_trans_handle *trans,\n\t\t\t\tstruct btrfs_root *root,\n\t\t\t\tstruct btrfs_inode *inode)\n{\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tint ret;\n\n\t/*\n\t * If the inode is a free space inode, we can deadlock during commit\n\t * if we put it into the delayed code.\n\t *\n\t * The data relocation inode should also be directly updated\n\t * without delay\n\t */\n\tif (!btrfs_is_free_space_inode(inode)\n\t    && root->root_key.objectid != BTRFS_DATA_RELOC_TREE_OBJECTID\n\t    && !test_bit(BTRFS_FS_LOG_RECOVERING, &fs_info->flags)) {\n\t\tbtrfs_update_root_times(trans, root);\n\n\t\tret = btrfs_delayed_update_inode(trans, root, inode);\n\t\tif (!ret)\n\t\t\tbtrfs_set_inode_last_trans(trans, inode);\n\t\treturn ret;\n\t}\n\n\treturn btrfs_update_inode_item(trans, root, inode);\n}\n\nint btrfs_update_inode_fallback(struct btrfs_trans_handle *trans,\n\t\t\t\tstruct btrfs_root *root, struct btrfs_inode *inode)\n{\n\tint ret;\n\n\tret = btrfs_update_inode(trans, root, inode);\n\tif (ret == -ENOSPC)\n\t\treturn btrfs_update_inode_item(trans, root, inode);\n\treturn ret;\n}\n\n/*\n * unlink helper that gets used here in inode.c and in the tree logging\n * recovery code.  It remove a link in a directory with a given name, and\n * also drops the back refs in the inode to the directory\n */\nstatic int __btrfs_unlink_inode(struct btrfs_trans_handle *trans,\n\t\t\t\tstruct btrfs_root *root,\n\t\t\t\tstruct btrfs_inode *dir,\n\t\t\t\tstruct btrfs_inode *inode,\n\t\t\t\tconst char *name, int name_len)\n{\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tstruct btrfs_path *path;\n\tint ret = 0;\n\tstruct btrfs_dir_item *di;\n\tu64 index;\n\tu64 ino = btrfs_ino(inode);\n\tu64 dir_ino = btrfs_ino(dir);\n\n\tpath = btrfs_alloc_path();\n\tif (!path) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tdi = btrfs_lookup_dir_item(trans, root, path, dir_ino,\n\t\t\t\t    name, name_len, -1);\n\tif (IS_ERR_OR_NULL(di)) {\n\t\tret = di ? PTR_ERR(di) : -ENOENT;\n\t\tgoto err;\n\t}\n\tret = btrfs_delete_one_dir_name(trans, root, path, di);\n\tif (ret)\n\t\tgoto err;\n\tbtrfs_release_path(path);\n\n\t/*\n\t * If we don't have dir index, we have to get it by looking up\n\t * the inode ref, since we get the inode ref, remove it directly,\n\t * it is unnecessary to do delayed deletion.\n\t *\n\t * But if we have dir index, needn't search inode ref to get it.\n\t * Since the inode ref is close to the inode item, it is better\n\t * that we delay to delete it, and just do this deletion when\n\t * we update the inode item.\n\t */\n\tif (inode->dir_index) {\n\t\tret = btrfs_delayed_delete_inode_ref(inode);\n\t\tif (!ret) {\n\t\t\tindex = inode->dir_index;\n\t\t\tgoto skip_backref;\n\t\t}\n\t}\n\n\tret = btrfs_del_inode_ref(trans, root, name, name_len, ino,\n\t\t\t\t  dir_ino, &index);\n\tif (ret) {\n\t\tbtrfs_info(fs_info,\n\t\t\t\"failed to delete reference to %.*s, inode %llu parent %llu\",\n\t\t\tname_len, name, ino, dir_ino);\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\tgoto err;\n\t}\nskip_backref:\n\tret = btrfs_delete_delayed_dir_index(trans, dir, index);\n\tif (ret) {\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\tgoto err;\n\t}\n\n\tret = btrfs_del_inode_ref_in_log(trans, root, name, name_len, inode,\n\t\t\tdir_ino);\n\tif (ret != 0 && ret != -ENOENT) {\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\tgoto err;\n\t}\n\n\tret = btrfs_del_dir_entries_in_log(trans, root, name, name_len, dir,\n\t\t\tindex);\n\tif (ret == -ENOENT)\n\t\tret = 0;\n\telse if (ret)\n\t\tbtrfs_abort_transaction(trans, ret);\n\n\t/*\n\t * If we have a pending delayed iput we could end up with the final iput\n\t * being run in btrfs-cleaner context.  If we have enough of these built\n\t * up we can end up burning a lot of time in btrfs-cleaner without any\n\t * way to throttle the unlinks.  Since we're currently holding a ref on\n\t * the inode we can run the delayed iput here without any issues as the\n\t * final iput won't be done until after we drop the ref we're currently\n\t * holding.\n\t */\n\tbtrfs_run_delayed_iput(fs_info, inode);\nerr:\n\tbtrfs_free_path(path);\n\tif (ret)\n\t\tgoto out;\n\n\tbtrfs_i_size_write(dir, dir->vfs_inode.i_size - name_len * 2);\n\tinode_inc_iversion(&inode->vfs_inode);\n\tinode_inc_iversion(&dir->vfs_inode);\n\tinode->vfs_inode.i_ctime = dir->vfs_inode.i_mtime =\n\t\tdir->vfs_inode.i_ctime = current_time(&inode->vfs_inode);\n\tret = btrfs_update_inode(trans, root, dir);\nout:\n\treturn ret;\n}\n\nint btrfs_unlink_inode(struct btrfs_trans_handle *trans,\n\t\t       struct btrfs_root *root,\n\t\t       struct btrfs_inode *dir, struct btrfs_inode *inode,\n\t\t       const char *name, int name_len)\n{\n\tint ret;\n\tret = __btrfs_unlink_inode(trans, root, dir, inode, name, name_len);\n\tif (!ret) {\n\t\tdrop_nlink(&inode->vfs_inode);\n\t\tret = btrfs_update_inode(trans, root, inode);\n\t}\n\treturn ret;\n}\n\n/*\n * helper to start transaction for unlink and rmdir.\n *\n * unlink and rmdir are special in btrfs, they do not always free space, so\n * if we cannot make our reservations the normal way try and see if there is\n * plenty of slack room in the global reserve to migrate, otherwise we cannot\n * allow the unlink to occur.\n */\nstatic struct btrfs_trans_handle *__unlink_start_trans(struct inode *dir)\n{\n\tstruct btrfs_root *root = BTRFS_I(dir)->root;\n\n\t/*\n\t * 1 for the possible orphan item\n\t * 1 for the dir item\n\t * 1 for the dir index\n\t * 1 for the inode ref\n\t * 1 for the inode\n\t */\n\treturn btrfs_start_transaction_fallback_global_rsv(root, 5);\n}\n\nstatic int btrfs_unlink(struct inode *dir, struct dentry *dentry)\n{\n\tstruct btrfs_root *root = BTRFS_I(dir)->root;\n\tstruct btrfs_trans_handle *trans;\n\tstruct inode *inode = d_inode(dentry);\n\tint ret;\n\n\ttrans = __unlink_start_trans(dir);\n\tif (IS_ERR(trans))\n\t\treturn PTR_ERR(trans);\n\n\tbtrfs_record_unlink_dir(trans, BTRFS_I(dir), BTRFS_I(d_inode(dentry)),\n\t\t\t0);\n\n\tret = btrfs_unlink_inode(trans, root, BTRFS_I(dir),\n\t\t\tBTRFS_I(d_inode(dentry)), dentry->d_name.name,\n\t\t\tdentry->d_name.len);\n\tif (ret)\n\t\tgoto out;\n\n\tif (inode->i_nlink == 0) {\n\t\tret = btrfs_orphan_add(trans, BTRFS_I(inode));\n\t\tif (ret)\n\t\t\tgoto out;\n\t}\n\nout:\n\tbtrfs_end_transaction(trans);\n\tbtrfs_btree_balance_dirty(root->fs_info);\n\treturn ret;\n}\n\nstatic int btrfs_unlink_subvol(struct btrfs_trans_handle *trans,\n\t\t\t       struct inode *dir, struct dentry *dentry)\n{\n\tstruct btrfs_root *root = BTRFS_I(dir)->root;\n\tstruct btrfs_inode *inode = BTRFS_I(d_inode(dentry));\n\tstruct btrfs_path *path;\n\tstruct extent_buffer *leaf;\n\tstruct btrfs_dir_item *di;\n\tstruct btrfs_key key;\n\tconst char *name = dentry->d_name.name;\n\tint name_len = dentry->d_name.len;\n\tu64 index;\n\tint ret;\n\tu64 objectid;\n\tu64 dir_ino = btrfs_ino(BTRFS_I(dir));\n\n\tif (btrfs_ino(inode) == BTRFS_FIRST_FREE_OBJECTID) {\n\t\tobjectid = inode->root->root_key.objectid;\n\t} else if (btrfs_ino(inode) == BTRFS_EMPTY_SUBVOL_DIR_OBJECTID) {\n\t\tobjectid = inode->location.objectid;\n\t} else {\n\t\tWARN_ON(1);\n\t\treturn -EINVAL;\n\t}\n\n\tpath = btrfs_alloc_path();\n\tif (!path)\n\t\treturn -ENOMEM;\n\n\tdi = btrfs_lookup_dir_item(trans, root, path, dir_ino,\n\t\t\t\t   name, name_len, -1);\n\tif (IS_ERR_OR_NULL(di)) {\n\t\tret = di ? PTR_ERR(di) : -ENOENT;\n\t\tgoto out;\n\t}\n\n\tleaf = path->nodes[0];\n\tbtrfs_dir_item_key_to_cpu(leaf, di, &key);\n\tWARN_ON(key.type != BTRFS_ROOT_ITEM_KEY || key.objectid != objectid);\n\tret = btrfs_delete_one_dir_name(trans, root, path, di);\n\tif (ret) {\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\tgoto out;\n\t}\n\tbtrfs_release_path(path);\n\n\t/*\n\t * This is a placeholder inode for a subvolume we didn't have a\n\t * reference to at the time of the snapshot creation.  In the meantime\n\t * we could have renamed the real subvol link into our snapshot, so\n\t * depending on btrfs_del_root_ref to return -ENOENT here is incorret.\n\t * Instead simply lookup the dir_index_item for this entry so we can\n\t * remove it.  Otherwise we know we have a ref to the root and we can\n\t * call btrfs_del_root_ref, and it _shouldn't_ fail.\n\t */\n\tif (btrfs_ino(inode) == BTRFS_EMPTY_SUBVOL_DIR_OBJECTID) {\n\t\tdi = btrfs_search_dir_index_item(root, path, dir_ino,\n\t\t\t\t\t\t name, name_len);\n\t\tif (IS_ERR_OR_NULL(di)) {\n\t\t\tif (!di)\n\t\t\t\tret = -ENOENT;\n\t\t\telse\n\t\t\t\tret = PTR_ERR(di);\n\t\t\tbtrfs_abort_transaction(trans, ret);\n\t\t\tgoto out;\n\t\t}\n\n\t\tleaf = path->nodes[0];\n\t\tbtrfs_item_key_to_cpu(leaf, &key, path->slots[0]);\n\t\tindex = key.offset;\n\t\tbtrfs_release_path(path);\n\t} else {\n\t\tret = btrfs_del_root_ref(trans, objectid,\n\t\t\t\t\t root->root_key.objectid, dir_ino,\n\t\t\t\t\t &index, name, name_len);\n\t\tif (ret) {\n\t\t\tbtrfs_abort_transaction(trans, ret);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tret = btrfs_delete_delayed_dir_index(trans, BTRFS_I(dir), index);\n\tif (ret) {\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\tgoto out;\n\t}\n\n\tbtrfs_i_size_write(BTRFS_I(dir), dir->i_size - name_len * 2);\n\tinode_inc_iversion(dir);\n\tdir->i_mtime = dir->i_ctime = current_time(dir);\n\tret = btrfs_update_inode_fallback(trans, root, BTRFS_I(dir));\n\tif (ret)\n\t\tbtrfs_abort_transaction(trans, ret);\nout:\n\tbtrfs_free_path(path);\n\treturn ret;\n}\n\n/*\n * Helper to check if the subvolume references other subvolumes or if it's\n * default.\n */\nstatic noinline int may_destroy_subvol(struct btrfs_root *root)\n{\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tstruct btrfs_path *path;\n\tstruct btrfs_dir_item *di;\n\tstruct btrfs_key key;\n\tu64 dir_id;\n\tint ret;\n\n\tpath = btrfs_alloc_path();\n\tif (!path)\n\t\treturn -ENOMEM;\n\n\t/* Make sure this root isn't set as the default subvol */\n\tdir_id = btrfs_super_root_dir(fs_info->super_copy);\n\tdi = btrfs_lookup_dir_item(NULL, fs_info->tree_root, path,\n\t\t\t\t   dir_id, \"default\", 7, 0);\n\tif (di && !IS_ERR(di)) {\n\t\tbtrfs_dir_item_key_to_cpu(path->nodes[0], di, &key);\n\t\tif (key.objectid == root->root_key.objectid) {\n\t\t\tret = -EPERM;\n\t\t\tbtrfs_err(fs_info,\n\t\t\t\t  \"deleting default subvolume %llu is not allowed\",\n\t\t\t\t  key.objectid);\n\t\t\tgoto out;\n\t\t}\n\t\tbtrfs_release_path(path);\n\t}\n\n\tkey.objectid = root->root_key.objectid;\n\tkey.type = BTRFS_ROOT_REF_KEY;\n\tkey.offset = (u64)-1;\n\n\tret = btrfs_search_slot(NULL, fs_info->tree_root, &key, path, 0, 0);\n\tif (ret < 0)\n\t\tgoto out;\n\tBUG_ON(ret == 0);\n\n\tret = 0;\n\tif (path->slots[0] > 0) {\n\t\tpath->slots[0]--;\n\t\tbtrfs_item_key_to_cpu(path->nodes[0], &key, path->slots[0]);\n\t\tif (key.objectid == root->root_key.objectid &&\n\t\t    key.type == BTRFS_ROOT_REF_KEY)\n\t\t\tret = -ENOTEMPTY;\n\t}\nout:\n\tbtrfs_free_path(path);\n\treturn ret;\n}\n\n/* Delete all dentries for inodes belonging to the root */\nstatic void btrfs_prune_dentries(struct btrfs_root *root)\n{\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tstruct rb_node *node;\n\tstruct rb_node *prev;\n\tstruct btrfs_inode *entry;\n\tstruct inode *inode;\n\tu64 objectid = 0;\n\n\tif (!test_bit(BTRFS_FS_STATE_ERROR, &fs_info->fs_state))\n\t\tWARN_ON(btrfs_root_refs(&root->root_item) != 0);\n\n\tspin_lock(&root->inode_lock);\nagain:\n\tnode = root->inode_tree.rb_node;\n\tprev = NULL;\n\twhile (node) {\n\t\tprev = node;\n\t\tentry = rb_entry(node, struct btrfs_inode, rb_node);\n\n\t\tif (objectid < btrfs_ino(entry))\n\t\t\tnode = node->rb_left;\n\t\telse if (objectid > btrfs_ino(entry))\n\t\t\tnode = node->rb_right;\n\t\telse\n\t\t\tbreak;\n\t}\n\tif (!node) {\n\t\twhile (prev) {\n\t\t\tentry = rb_entry(prev, struct btrfs_inode, rb_node);\n\t\t\tif (objectid <= btrfs_ino(entry)) {\n\t\t\t\tnode = prev;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tprev = rb_next(prev);\n\t\t}\n\t}\n\twhile (node) {\n\t\tentry = rb_entry(node, struct btrfs_inode, rb_node);\n\t\tobjectid = btrfs_ino(entry) + 1;\n\t\tinode = igrab(&entry->vfs_inode);\n\t\tif (inode) {\n\t\t\tspin_unlock(&root->inode_lock);\n\t\t\tif (atomic_read(&inode->i_count) > 1)\n\t\t\t\td_prune_aliases(inode);\n\t\t\t/*\n\t\t\t * btrfs_drop_inode will have it removed from the inode\n\t\t\t * cache when its usage count hits zero.\n\t\t\t */\n\t\t\tiput(inode);\n\t\t\tcond_resched();\n\t\t\tspin_lock(&root->inode_lock);\n\t\t\tgoto again;\n\t\t}\n\n\t\tif (cond_resched_lock(&root->inode_lock))\n\t\t\tgoto again;\n\n\t\tnode = rb_next(node);\n\t}\n\tspin_unlock(&root->inode_lock);\n}\n\nint btrfs_delete_subvolume(struct inode *dir, struct dentry *dentry)\n{\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(dentry->d_sb);\n\tstruct btrfs_root *root = BTRFS_I(dir)->root;\n\tstruct inode *inode = d_inode(dentry);\n\tstruct btrfs_root *dest = BTRFS_I(inode)->root;\n\tstruct btrfs_trans_handle *trans;\n\tstruct btrfs_block_rsv block_rsv;\n\tu64 root_flags;\n\tint ret;\n\n\t/*\n\t * Don't allow to delete a subvolume with send in progress. This is\n\t * inside the inode lock so the error handling that has to drop the bit\n\t * again is not run concurrently.\n\t */\n\tspin_lock(&dest->root_item_lock);\n\tif (dest->send_in_progress) {\n\t\tspin_unlock(&dest->root_item_lock);\n\t\tbtrfs_warn(fs_info,\n\t\t\t   \"attempt to delete subvolume %llu during send\",\n\t\t\t   dest->root_key.objectid);\n\t\treturn -EPERM;\n\t}\n\troot_flags = btrfs_root_flags(&dest->root_item);\n\tbtrfs_set_root_flags(&dest->root_item,\n\t\t\t     root_flags | BTRFS_ROOT_SUBVOL_DEAD);\n\tspin_unlock(&dest->root_item_lock);\n\n\tdown_write(&fs_info->subvol_sem);\n\n\tret = may_destroy_subvol(dest);\n\tif (ret)\n\t\tgoto out_up_write;\n\n\tbtrfs_init_block_rsv(&block_rsv, BTRFS_BLOCK_RSV_TEMP);\n\t/*\n\t * One for dir inode,\n\t * two for dir entries,\n\t * two for root ref/backref.\n\t */\n\tret = btrfs_subvolume_reserve_metadata(root, &block_rsv, 5, true);\n\tif (ret)\n\t\tgoto out_up_write;\n\n\ttrans = btrfs_start_transaction(root, 0);\n\tif (IS_ERR(trans)) {\n\t\tret = PTR_ERR(trans);\n\t\tgoto out_release;\n\t}\n\ttrans->block_rsv = &block_rsv;\n\ttrans->bytes_reserved = block_rsv.size;\n\n\tbtrfs_record_snapshot_destroy(trans, BTRFS_I(dir));\n\n\tret = btrfs_unlink_subvol(trans, dir, dentry);\n\tif (ret) {\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\tgoto out_end_trans;\n\t}\n\n\tret = btrfs_record_root_in_trans(trans, dest);\n\tif (ret) {\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\tgoto out_end_trans;\n\t}\n\n\tmemset(&dest->root_item.drop_progress, 0,\n\t\tsizeof(dest->root_item.drop_progress));\n\tbtrfs_set_root_drop_level(&dest->root_item, 0);\n\tbtrfs_set_root_refs(&dest->root_item, 0);\n\n\tif (!test_and_set_bit(BTRFS_ROOT_ORPHAN_ITEM_INSERTED, &dest->state)) {\n\t\tret = btrfs_insert_orphan_item(trans,\n\t\t\t\t\tfs_info->tree_root,\n\t\t\t\t\tdest->root_key.objectid);\n\t\tif (ret) {\n\t\t\tbtrfs_abort_transaction(trans, ret);\n\t\t\tgoto out_end_trans;\n\t\t}\n\t}\n\n\tret = btrfs_uuid_tree_remove(trans, dest->root_item.uuid,\n\t\t\t\t  BTRFS_UUID_KEY_SUBVOL,\n\t\t\t\t  dest->root_key.objectid);\n\tif (ret && ret != -ENOENT) {\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\tgoto out_end_trans;\n\t}\n\tif (!btrfs_is_empty_uuid(dest->root_item.received_uuid)) {\n\t\tret = btrfs_uuid_tree_remove(trans,\n\t\t\t\t\t  dest->root_item.received_uuid,\n\t\t\t\t\t  BTRFS_UUID_KEY_RECEIVED_SUBVOL,\n\t\t\t\t\t  dest->root_key.objectid);\n\t\tif (ret && ret != -ENOENT) {\n\t\t\tbtrfs_abort_transaction(trans, ret);\n\t\t\tgoto out_end_trans;\n\t\t}\n\t}\n\n\tfree_anon_bdev(dest->anon_dev);\n\tdest->anon_dev = 0;\nout_end_trans:\n\ttrans->block_rsv = NULL;\n\ttrans->bytes_reserved = 0;\n\tret = btrfs_end_transaction(trans);\n\tinode->i_flags |= S_DEAD;\nout_release:\n\tbtrfs_subvolume_release_metadata(root, &block_rsv);\nout_up_write:\n\tup_write(&fs_info->subvol_sem);\n\tif (ret) {\n\t\tspin_lock(&dest->root_item_lock);\n\t\troot_flags = btrfs_root_flags(&dest->root_item);\n\t\tbtrfs_set_root_flags(&dest->root_item,\n\t\t\t\troot_flags & ~BTRFS_ROOT_SUBVOL_DEAD);\n\t\tspin_unlock(&dest->root_item_lock);\n\t} else {\n\t\td_invalidate(dentry);\n\t\tbtrfs_prune_dentries(dest);\n\t\tASSERT(dest->send_in_progress == 0);\n\t}\n\n\treturn ret;\n}\n\nstatic int btrfs_rmdir(struct inode *dir, struct dentry *dentry)\n{\n\tstruct inode *inode = d_inode(dentry);\n\tint err = 0;\n\tstruct btrfs_root *root = BTRFS_I(dir)->root;\n\tstruct btrfs_trans_handle *trans;\n\tu64 last_unlink_trans;\n\n\tif (inode->i_size > BTRFS_EMPTY_DIR_SIZE)\n\t\treturn -ENOTEMPTY;\n\tif (btrfs_ino(BTRFS_I(inode)) == BTRFS_FIRST_FREE_OBJECTID)\n\t\treturn btrfs_delete_subvolume(dir, dentry);\n\n\ttrans = __unlink_start_trans(dir);\n\tif (IS_ERR(trans))\n\t\treturn PTR_ERR(trans);\n\n\tif (unlikely(btrfs_ino(BTRFS_I(inode)) == BTRFS_EMPTY_SUBVOL_DIR_OBJECTID)) {\n\t\terr = btrfs_unlink_subvol(trans, dir, dentry);\n\t\tgoto out;\n\t}\n\n\terr = btrfs_orphan_add(trans, BTRFS_I(inode));\n\tif (err)\n\t\tgoto out;\n\n\tlast_unlink_trans = BTRFS_I(inode)->last_unlink_trans;\n\n\t/* now the directory is empty */\n\terr = btrfs_unlink_inode(trans, root, BTRFS_I(dir),\n\t\t\tBTRFS_I(d_inode(dentry)), dentry->d_name.name,\n\t\t\tdentry->d_name.len);\n\tif (!err) {\n\t\tbtrfs_i_size_write(BTRFS_I(inode), 0);\n\t\t/*\n\t\t * Propagate the last_unlink_trans value of the deleted dir to\n\t\t * its parent directory. This is to prevent an unrecoverable\n\t\t * log tree in the case we do something like this:\n\t\t * 1) create dir foo\n\t\t * 2) create snapshot under dir foo\n\t\t * 3) delete the snapshot\n\t\t * 4) rmdir foo\n\t\t * 5) mkdir foo\n\t\t * 6) fsync foo or some file inside foo\n\t\t */\n\t\tif (last_unlink_trans >= trans->transid)\n\t\t\tBTRFS_I(dir)->last_unlink_trans = last_unlink_trans;\n\t}\nout:\n\tbtrfs_end_transaction(trans);\n\tbtrfs_btree_balance_dirty(root->fs_info);\n\n\treturn err;\n}\n\n/*\n * Return this if we need to call truncate_block for the last bit of the\n * truncate.\n */\n#define NEED_TRUNCATE_BLOCK 1\n\n/*\n * this can truncate away extent items, csum items and directory items.\n * It starts at a high offset and removes keys until it can't find\n * any higher than new_size\n *\n * csum items that cross the new i_size are truncated to the new size\n * as well.\n *\n * min_type is the minimum key type to truncate down to.  If set to 0, this\n * will kill all the items on this inode, including the INODE_ITEM_KEY.\n */\nint btrfs_truncate_inode_items(struct btrfs_trans_handle *trans,\n\t\t\t       struct btrfs_root *root,\n\t\t\t       struct btrfs_inode *inode,\n\t\t\t       u64 new_size, u32 min_type)\n{\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tstruct btrfs_path *path;\n\tstruct extent_buffer *leaf;\n\tstruct btrfs_file_extent_item *fi;\n\tstruct btrfs_key key;\n\tstruct btrfs_key found_key;\n\tu64 extent_start = 0;\n\tu64 extent_num_bytes = 0;\n\tu64 extent_offset = 0;\n\tu64 item_end = 0;\n\tu64 last_size = new_size;\n\tu32 found_type = (u8)-1;\n\tint found_extent;\n\tint del_item;\n\tint pending_del_nr = 0;\n\tint pending_del_slot = 0;\n\tint extent_type = -1;\n\tint ret;\n\tu64 ino = btrfs_ino(inode);\n\tu64 bytes_deleted = 0;\n\tbool be_nice = false;\n\tbool should_throttle = false;\n\tconst u64 lock_start = ALIGN_DOWN(new_size, fs_info->sectorsize);\n\tstruct extent_state *cached_state = NULL;\n\n\tBUG_ON(new_size > 0 && min_type != BTRFS_EXTENT_DATA_KEY);\n\n\t/*\n\t * For non-free space inodes and non-shareable roots, we want to back\n\t * off from time to time.  This means all inodes in subvolume roots,\n\t * reloc roots, and data reloc roots.\n\t */\n\tif (!btrfs_is_free_space_inode(inode) &&\n\t    test_bit(BTRFS_ROOT_SHAREABLE, &root->state))\n\t\tbe_nice = true;\n\n\tpath = btrfs_alloc_path();\n\tif (!path)\n\t\treturn -ENOMEM;\n\tpath->reada = READA_BACK;\n\n\tif (root->root_key.objectid != BTRFS_TREE_LOG_OBJECTID) {\n\t\tlock_extent_bits(&inode->io_tree, lock_start, (u64)-1,\n\t\t\t\t &cached_state);\n\n\t\t/*\n\t\t * We want to drop from the next block forward in case this\n\t\t * new size is not block aligned since we will be keeping the\n\t\t * last block of the extent just the way it is.\n\t\t */\n\t\tbtrfs_drop_extent_cache(inode, ALIGN(new_size,\n\t\t\t\t\tfs_info->sectorsize),\n\t\t\t\t\t(u64)-1, 0);\n\t}\n\n\t/*\n\t * This function is also used to drop the items in the log tree before\n\t * we relog the inode, so if root != BTRFS_I(inode)->root, it means\n\t * it is used to drop the logged items. So we shouldn't kill the delayed\n\t * items.\n\t */\n\tif (min_type == 0 && root == inode->root)\n\t\tbtrfs_kill_delayed_inode_items(inode);\n\n\tkey.objectid = ino;\n\tkey.offset = (u64)-1;\n\tkey.type = (u8)-1;\n\nsearch_again:\n\t/*\n\t * with a 16K leaf size and 128MB extents, you can actually queue\n\t * up a huge file in a single leaf.  Most of the time that\n\t * bytes_deleted is > 0, it will be huge by the time we get here\n\t */\n\tif (be_nice && bytes_deleted > SZ_32M &&\n\t    btrfs_should_end_transaction(trans)) {\n\t\tret = -EAGAIN;\n\t\tgoto out;\n\t}\n\n\tret = btrfs_search_slot(trans, root, &key, path, -1, 1);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tif (ret > 0) {\n\t\tret = 0;\n\t\t/* there are no items in the tree for us to truncate, we're\n\t\t * done\n\t\t */\n\t\tif (path->slots[0] == 0)\n\t\t\tgoto out;\n\t\tpath->slots[0]--;\n\t}\n\n\twhile (1) {\n\t\tu64 clear_start = 0, clear_len = 0;\n\n\t\tfi = NULL;\n\t\tleaf = path->nodes[0];\n\t\tbtrfs_item_key_to_cpu(leaf, &found_key, path->slots[0]);\n\t\tfound_type = found_key.type;\n\n\t\tif (found_key.objectid != ino)\n\t\t\tbreak;\n\n\t\tif (found_type < min_type)\n\t\t\tbreak;\n\n\t\titem_end = found_key.offset;\n\t\tif (found_type == BTRFS_EXTENT_DATA_KEY) {\n\t\t\tfi = btrfs_item_ptr(leaf, path->slots[0],\n\t\t\t\t\t    struct btrfs_file_extent_item);\n\t\t\textent_type = btrfs_file_extent_type(leaf, fi);\n\t\t\tif (extent_type != BTRFS_FILE_EXTENT_INLINE) {\n\t\t\t\titem_end +=\n\t\t\t\t    btrfs_file_extent_num_bytes(leaf, fi);\n\n\t\t\t\ttrace_btrfs_truncate_show_fi_regular(\n\t\t\t\t\tinode, leaf, fi, found_key.offset);\n\t\t\t} else if (extent_type == BTRFS_FILE_EXTENT_INLINE) {\n\t\t\t\titem_end += btrfs_file_extent_ram_bytes(leaf,\n\t\t\t\t\t\t\t\t\tfi);\n\n\t\t\t\ttrace_btrfs_truncate_show_fi_inline(\n\t\t\t\t\tinode, leaf, fi, path->slots[0],\n\t\t\t\t\tfound_key.offset);\n\t\t\t}\n\t\t\titem_end--;\n\t\t}\n\t\tif (found_type > min_type) {\n\t\t\tdel_item = 1;\n\t\t} else {\n\t\t\tif (item_end < new_size)\n\t\t\t\tbreak;\n\t\t\tif (found_key.offset >= new_size)\n\t\t\t\tdel_item = 1;\n\t\t\telse\n\t\t\t\tdel_item = 0;\n\t\t}\n\t\tfound_extent = 0;\n\t\t/* FIXME, shrink the extent if the ref count is only 1 */\n\t\tif (found_type != BTRFS_EXTENT_DATA_KEY)\n\t\t\tgoto delete;\n\n\t\tif (extent_type != BTRFS_FILE_EXTENT_INLINE) {\n\t\t\tu64 num_dec;\n\n\t\t\tclear_start = found_key.offset;\n\t\t\textent_start = btrfs_file_extent_disk_bytenr(leaf, fi);\n\t\t\tif (!del_item) {\n\t\t\t\tu64 orig_num_bytes =\n\t\t\t\t\tbtrfs_file_extent_num_bytes(leaf, fi);\n\t\t\t\textent_num_bytes = ALIGN(new_size -\n\t\t\t\t\t\tfound_key.offset,\n\t\t\t\t\t\tfs_info->sectorsize);\n\t\t\t\tclear_start = ALIGN(new_size, fs_info->sectorsize);\n\t\t\t\tbtrfs_set_file_extent_num_bytes(leaf, fi,\n\t\t\t\t\t\t\t extent_num_bytes);\n\t\t\t\tnum_dec = (orig_num_bytes -\n\t\t\t\t\t   extent_num_bytes);\n\t\t\t\tif (test_bit(BTRFS_ROOT_SHAREABLE,\n\t\t\t\t\t     &root->state) &&\n\t\t\t\t    extent_start != 0)\n\t\t\t\t\tinode_sub_bytes(&inode->vfs_inode,\n\t\t\t\t\t\t\tnum_dec);\n\t\t\t\tbtrfs_mark_buffer_dirty(leaf);\n\t\t\t} else {\n\t\t\t\textent_num_bytes =\n\t\t\t\t\tbtrfs_file_extent_disk_num_bytes(leaf,\n\t\t\t\t\t\t\t\t\t fi);\n\t\t\t\textent_offset = found_key.offset -\n\t\t\t\t\tbtrfs_file_extent_offset(leaf, fi);\n\n\t\t\t\t/* FIXME blocksize != 4096 */\n\t\t\t\tnum_dec = btrfs_file_extent_num_bytes(leaf, fi);\n\t\t\t\tif (extent_start != 0) {\n\t\t\t\t\tfound_extent = 1;\n\t\t\t\t\tif (test_bit(BTRFS_ROOT_SHAREABLE,\n\t\t\t\t\t\t     &root->state))\n\t\t\t\t\t\tinode_sub_bytes(&inode->vfs_inode,\n\t\t\t\t\t\t\t\tnum_dec);\n\t\t\t\t}\n\t\t\t}\n\t\t\tclear_len = num_dec;\n\t\t} else if (extent_type == BTRFS_FILE_EXTENT_INLINE) {\n\t\t\t/*\n\t\t\t * we can't truncate inline items that have had\n\t\t\t * special encodings\n\t\t\t */\n\t\t\tif (!del_item &&\n\t\t\t    btrfs_file_extent_encryption(leaf, fi) == 0 &&\n\t\t\t    btrfs_file_extent_other_encoding(leaf, fi) == 0 &&\n\t\t\t    btrfs_file_extent_compression(leaf, fi) == 0) {\n\t\t\t\tu32 size = (u32)(new_size - found_key.offset);\n\n\t\t\t\tbtrfs_set_file_extent_ram_bytes(leaf, fi, size);\n\t\t\t\tsize = btrfs_file_extent_calc_inline_size(size);\n\t\t\t\tbtrfs_truncate_item(path, size, 1);\n\t\t\t} else if (!del_item) {\n\t\t\t\t/*\n\t\t\t\t * We have to bail so the last_size is set to\n\t\t\t\t * just before this extent.\n\t\t\t\t */\n\t\t\t\tret = NEED_TRUNCATE_BLOCK;\n\t\t\t\tbreak;\n\t\t\t} else {\n\t\t\t\t/*\n\t\t\t\t * Inline extents are special, we just treat\n\t\t\t\t * them as a full sector worth in the file\n\t\t\t\t * extent tree just for simplicity sake.\n\t\t\t\t */\n\t\t\t\tclear_len = fs_info->sectorsize;\n\t\t\t}\n\n\t\t\tif (test_bit(BTRFS_ROOT_SHAREABLE, &root->state))\n\t\t\t\tinode_sub_bytes(&inode->vfs_inode,\n\t\t\t\t\t\titem_end + 1 - new_size);\n\t\t}\ndelete:\n\t\t/*\n\t\t * We use btrfs_truncate_inode_items() to clean up log trees for\n\t\t * multiple fsyncs, and in this case we don't want to clear the\n\t\t * file extent range because it's just the log.\n\t\t */\n\t\tif (root == inode->root) {\n\t\t\tret = btrfs_inode_clear_file_extent_range(inode,\n\t\t\t\t\t\t  clear_start, clear_len);\n\t\t\tif (ret) {\n\t\t\t\tbtrfs_abort_transaction(trans, ret);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (del_item)\n\t\t\tlast_size = found_key.offset;\n\t\telse\n\t\t\tlast_size = new_size;\n\t\tif (del_item) {\n\t\t\tif (!pending_del_nr) {\n\t\t\t\t/* no pending yet, add ourselves */\n\t\t\t\tpending_del_slot = path->slots[0];\n\t\t\t\tpending_del_nr = 1;\n\t\t\t} else if (pending_del_nr &&\n\t\t\t\t   path->slots[0] + 1 == pending_del_slot) {\n\t\t\t\t/* hop on the pending chunk */\n\t\t\t\tpending_del_nr++;\n\t\t\t\tpending_del_slot = path->slots[0];\n\t\t\t} else {\n\t\t\t\tBUG();\n\t\t\t}\n\t\t} else {\n\t\t\tbreak;\n\t\t}\n\t\tshould_throttle = false;\n\n\t\tif (found_extent &&\n\t\t    root->root_key.objectid != BTRFS_TREE_LOG_OBJECTID) {\n\t\t\tstruct btrfs_ref ref = { 0 };\n\n\t\t\tbytes_deleted += extent_num_bytes;\n\n\t\t\tbtrfs_init_generic_ref(&ref, BTRFS_DROP_DELAYED_REF,\n\t\t\t\t\textent_start, extent_num_bytes, 0);\n\t\t\tref.real_root = root->root_key.objectid;\n\t\t\tbtrfs_init_data_ref(&ref, btrfs_header_owner(leaf),\n\t\t\t\t\tino, extent_offset);\n\t\t\tret = btrfs_free_extent(trans, &ref);\n\t\t\tif (ret) {\n\t\t\t\tbtrfs_abort_transaction(trans, ret);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (be_nice) {\n\t\t\t\tif (btrfs_should_throttle_delayed_refs(trans))\n\t\t\t\t\tshould_throttle = true;\n\t\t\t}\n\t\t}\n\n\t\tif (found_type == BTRFS_INODE_ITEM_KEY)\n\t\t\tbreak;\n\n\t\tif (path->slots[0] == 0 ||\n\t\t    path->slots[0] != pending_del_slot ||\n\t\t    should_throttle) {\n\t\t\tif (pending_del_nr) {\n\t\t\t\tret = btrfs_del_items(trans, root, path,\n\t\t\t\t\t\tpending_del_slot,\n\t\t\t\t\t\tpending_del_nr);\n\t\t\t\tif (ret) {\n\t\t\t\t\tbtrfs_abort_transaction(trans, ret);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tpending_del_nr = 0;\n\t\t\t}\n\t\t\tbtrfs_release_path(path);\n\n\t\t\t/*\n\t\t\t * We can generate a lot of delayed refs, so we need to\n\t\t\t * throttle every once and a while and make sure we're\n\t\t\t * adding enough space to keep up with the work we are\n\t\t\t * generating.  Since we hold a transaction here we\n\t\t\t * can't flush, and we don't want to FLUSH_LIMIT because\n\t\t\t * we could have generated too many delayed refs to\n\t\t\t * actually allocate, so just bail if we're short and\n\t\t\t * let the normal reservation dance happen higher up.\n\t\t\t */\n\t\t\tif (should_throttle) {\n\t\t\t\tret = btrfs_delayed_refs_rsv_refill(fs_info,\n\t\t\t\t\t\t\tBTRFS_RESERVE_NO_FLUSH);\n\t\t\t\tif (ret) {\n\t\t\t\t\tret = -EAGAIN;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tgoto search_again;\n\t\t} else {\n\t\t\tpath->slots[0]--;\n\t\t}\n\t}\nout:\n\tif (ret >= 0 && pending_del_nr) {\n\t\tint err;\n\n\t\terr = btrfs_del_items(trans, root, path, pending_del_slot,\n\t\t\t\t      pending_del_nr);\n\t\tif (err) {\n\t\t\tbtrfs_abort_transaction(trans, err);\n\t\t\tret = err;\n\t\t}\n\t}\n\tif (root->root_key.objectid != BTRFS_TREE_LOG_OBJECTID) {\n\t\tASSERT(last_size >= new_size);\n\t\tif (!ret && last_size > new_size)\n\t\t\tlast_size = new_size;\n\t\tbtrfs_inode_safe_disk_i_size_write(inode, last_size);\n\t\tunlock_extent_cached(&inode->io_tree, lock_start, (u64)-1,\n\t\t\t\t     &cached_state);\n\t}\n\n\tbtrfs_free_path(path);\n\treturn ret;\n}\n\n/*\n * btrfs_truncate_block - read, zero a chunk and write a block\n * @inode - inode that we're zeroing\n * @from - the offset to start zeroing\n * @len - the length to zero, 0 to zero the entire range respective to the\n *\toffset\n * @front - zero up to the offset instead of from the offset on\n *\n * This will find the block for the \"from\" offset and cow the block and zero the\n * part we want to zero.  This is used with truncate and hole punching.\n */\nint btrfs_truncate_block(struct btrfs_inode *inode, loff_t from, loff_t len,\n\t\t\t int front)\n{\n\tstruct btrfs_fs_info *fs_info = inode->root->fs_info;\n\tstruct address_space *mapping = inode->vfs_inode.i_mapping;\n\tstruct extent_io_tree *io_tree = &inode->io_tree;\n\tstruct btrfs_ordered_extent *ordered;\n\tstruct extent_state *cached_state = NULL;\n\tstruct extent_changeset *data_reserved = NULL;\n\tbool only_release_metadata = false;\n\tu32 blocksize = fs_info->sectorsize;\n\tpgoff_t index = from >> PAGE_SHIFT;\n\tunsigned offset = from & (blocksize - 1);\n\tstruct page *page;\n\tgfp_t mask = btrfs_alloc_write_mask(mapping);\n\tsize_t write_bytes = blocksize;\n\tint ret = 0;\n\tu64 block_start;\n\tu64 block_end;\n\n\tif (IS_ALIGNED(offset, blocksize) &&\n\t    (!len || IS_ALIGNED(len, blocksize)))\n\t\tgoto out;\n\n\tblock_start = round_down(from, blocksize);\n\tblock_end = block_start + blocksize - 1;\n\n\tret = btrfs_check_data_free_space(inode, &data_reserved, block_start,\n\t\t\t\t\t  blocksize);\n\tif (ret < 0) {\n\t\tif (btrfs_check_nocow_lock(inode, block_start, &write_bytes) > 0) {\n\t\t\t/* For nocow case, no need to reserve data space */\n\t\t\tonly_release_metadata = true;\n\t\t} else {\n\t\t\tgoto out;\n\t\t}\n\t}\n\tret = btrfs_delalloc_reserve_metadata(inode, blocksize);\n\tif (ret < 0) {\n\t\tif (!only_release_metadata)\n\t\t\tbtrfs_free_reserved_data_space(inode, data_reserved,\n\t\t\t\t\t\t       block_start, blocksize);\n\t\tgoto out;\n\t}\nagain:\n\tpage = find_or_create_page(mapping, index, mask);\n\tif (!page) {\n\t\tbtrfs_delalloc_release_space(inode, data_reserved, block_start,\n\t\t\t\t\t     blocksize, true);\n\t\tbtrfs_delalloc_release_extents(inode, blocksize);\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\tret = set_page_extent_mapped(page);\n\tif (ret < 0)\n\t\tgoto out_unlock;\n\n\tif (!PageUptodate(page)) {\n\t\tret = btrfs_readpage(NULL, page);\n\t\tlock_page(page);\n\t\tif (page->mapping != mapping) {\n\t\t\tunlock_page(page);\n\t\t\tput_page(page);\n\t\t\tgoto again;\n\t\t}\n\t\tif (!PageUptodate(page)) {\n\t\t\tret = -EIO;\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\twait_on_page_writeback(page);\n\n\tlock_extent_bits(io_tree, block_start, block_end, &cached_state);\n\n\tordered = btrfs_lookup_ordered_extent(inode, block_start);\n\tif (ordered) {\n\t\tunlock_extent_cached(io_tree, block_start, block_end,\n\t\t\t\t     &cached_state);\n\t\tunlock_page(page);\n\t\tput_page(page);\n\t\tbtrfs_start_ordered_extent(ordered, 1);\n\t\tbtrfs_put_ordered_extent(ordered);\n\t\tgoto again;\n\t}\n\n\tclear_extent_bit(&inode->io_tree, block_start, block_end,\n\t\t\t EXTENT_DELALLOC | EXTENT_DO_ACCOUNTING | EXTENT_DEFRAG,\n\t\t\t 0, 0, &cached_state);\n\n\tret = btrfs_set_extent_delalloc(inode, block_start, block_end, 0,\n\t\t\t\t\t&cached_state);\n\tif (ret) {\n\t\tunlock_extent_cached(io_tree, block_start, block_end,\n\t\t\t\t     &cached_state);\n\t\tgoto out_unlock;\n\t}\n\n\tif (offset != blocksize) {\n\t\tif (!len)\n\t\t\tlen = blocksize - offset;\n\t\tif (front)\n\t\t\tzero_user(page, block_start - page_offset(page), offset);\n\t\telse\n\t\t\tzero_user(page, block_start - page_offset(page) + offset,\n\t\t\t\t  len);\n\t\tflush_dcache_page(page);\n\t}\n\tClearPageChecked(page);\n\tset_page_dirty(page);\n\tunlock_extent_cached(io_tree, block_start, block_end, &cached_state);\n\n\tif (only_release_metadata)\n\t\tset_extent_bit(&inode->io_tree, block_start, block_end,\n\t\t\t       EXTENT_NORESERVE, 0, NULL, NULL, GFP_NOFS, NULL);\n\nout_unlock:\n\tif (ret) {\n\t\tif (only_release_metadata)\n\t\t\tbtrfs_delalloc_release_metadata(inode, blocksize, true);\n\t\telse\n\t\t\tbtrfs_delalloc_release_space(inode, data_reserved,\n\t\t\t\t\tblock_start, blocksize, true);\n\t}\n\tbtrfs_delalloc_release_extents(inode, blocksize);\n\tunlock_page(page);\n\tput_page(page);\nout:\n\tif (only_release_metadata)\n\t\tbtrfs_check_nocow_unlock(inode);\n\textent_changeset_free(data_reserved);\n\treturn ret;\n}\n\nstatic int maybe_insert_hole(struct btrfs_root *root, struct btrfs_inode *inode,\n\t\t\t     u64 offset, u64 len)\n{\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tstruct btrfs_trans_handle *trans;\n\tstruct btrfs_drop_extents_args drop_args = { 0 };\n\tint ret;\n\n\t/*\n\t * Still need to make sure the inode looks like it's been updated so\n\t * that any holes get logged if we fsync.\n\t */\n\tif (btrfs_fs_incompat(fs_info, NO_HOLES)) {\n\t\tinode->last_trans = fs_info->generation;\n\t\tinode->last_sub_trans = root->log_transid;\n\t\tinode->last_log_commit = root->last_log_commit;\n\t\treturn 0;\n\t}\n\n\t/*\n\t * 1 - for the one we're dropping\n\t * 1 - for the one we're adding\n\t * 1 - for updating the inode.\n\t */\n\ttrans = btrfs_start_transaction(root, 3);\n\tif (IS_ERR(trans))\n\t\treturn PTR_ERR(trans);\n\n\tdrop_args.start = offset;\n\tdrop_args.end = offset + len;\n\tdrop_args.drop_cache = true;\n\n\tret = btrfs_drop_extents(trans, root, inode, &drop_args);\n\tif (ret) {\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\tbtrfs_end_transaction(trans);\n\t\treturn ret;\n\t}\n\n\tret = btrfs_insert_file_extent(trans, root, btrfs_ino(inode),\n\t\t\toffset, 0, 0, len, 0, len, 0, 0, 0);\n\tif (ret) {\n\t\tbtrfs_abort_transaction(trans, ret);\n\t} else {\n\t\tbtrfs_update_inode_bytes(inode, 0, drop_args.bytes_found);\n\t\tbtrfs_update_inode(trans, root, inode);\n\t}\n\tbtrfs_end_transaction(trans);\n\treturn ret;\n}\n\n/*\n * This function puts in dummy file extents for the area we're creating a hole\n * for.  So if we are truncating this file to a larger size we need to insert\n * these file extents so that btrfs_get_extent will return a EXTENT_MAP_HOLE for\n * the range between oldsize and size\n */\nint btrfs_cont_expand(struct btrfs_inode *inode, loff_t oldsize, loff_t size)\n{\n\tstruct btrfs_root *root = inode->root;\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tstruct extent_io_tree *io_tree = &inode->io_tree;\n\tstruct extent_map *em = NULL;\n\tstruct extent_state *cached_state = NULL;\n\tstruct extent_map_tree *em_tree = &inode->extent_tree;\n\tu64 hole_start = ALIGN(oldsize, fs_info->sectorsize);\n\tu64 block_end = ALIGN(size, fs_info->sectorsize);\n\tu64 last_byte;\n\tu64 cur_offset;\n\tu64 hole_size;\n\tint err = 0;\n\n\t/*\n\t * If our size started in the middle of a block we need to zero out the\n\t * rest of the block before we expand the i_size, otherwise we could\n\t * expose stale data.\n\t */\n\terr = btrfs_truncate_block(inode, oldsize, 0, 0);\n\tif (err)\n\t\treturn err;\n\n\tif (size <= hole_start)\n\t\treturn 0;\n\n\tbtrfs_lock_and_flush_ordered_range(inode, hole_start, block_end - 1,\n\t\t\t\t\t   &cached_state);\n\tcur_offset = hole_start;\n\twhile (1) {\n\t\tem = btrfs_get_extent(inode, NULL, 0, cur_offset,\n\t\t\t\t      block_end - cur_offset);\n\t\tif (IS_ERR(em)) {\n\t\t\terr = PTR_ERR(em);\n\t\t\tem = NULL;\n\t\t\tbreak;\n\t\t}\n\t\tlast_byte = min(extent_map_end(em), block_end);\n\t\tlast_byte = ALIGN(last_byte, fs_info->sectorsize);\n\t\thole_size = last_byte - cur_offset;\n\n\t\tif (!test_bit(EXTENT_FLAG_PREALLOC, &em->flags)) {\n\t\t\tstruct extent_map *hole_em;\n\n\t\t\terr = maybe_insert_hole(root, inode, cur_offset,\n\t\t\t\t\t\thole_size);\n\t\t\tif (err)\n\t\t\t\tbreak;\n\n\t\t\terr = btrfs_inode_set_file_extent_range(inode,\n\t\t\t\t\t\t\tcur_offset, hole_size);\n\t\t\tif (err)\n\t\t\t\tbreak;\n\n\t\t\tbtrfs_drop_extent_cache(inode, cur_offset,\n\t\t\t\t\t\tcur_offset + hole_size - 1, 0);\n\t\t\thole_em = alloc_extent_map();\n\t\t\tif (!hole_em) {\n\t\t\t\tset_bit(BTRFS_INODE_NEEDS_FULL_SYNC,\n\t\t\t\t\t&inode->runtime_flags);\n\t\t\t\tgoto next;\n\t\t\t}\n\t\t\thole_em->start = cur_offset;\n\t\t\thole_em->len = hole_size;\n\t\t\thole_em->orig_start = cur_offset;\n\n\t\t\thole_em->block_start = EXTENT_MAP_HOLE;\n\t\t\thole_em->block_len = 0;\n\t\t\thole_em->orig_block_len = 0;\n\t\t\thole_em->ram_bytes = hole_size;\n\t\t\thole_em->compress_type = BTRFS_COMPRESS_NONE;\n\t\t\thole_em->generation = fs_info->generation;\n\n\t\t\twhile (1) {\n\t\t\t\twrite_lock(&em_tree->lock);\n\t\t\t\terr = add_extent_mapping(em_tree, hole_em, 1);\n\t\t\t\twrite_unlock(&em_tree->lock);\n\t\t\t\tif (err != -EEXIST)\n\t\t\t\t\tbreak;\n\t\t\t\tbtrfs_drop_extent_cache(inode, cur_offset,\n\t\t\t\t\t\t\tcur_offset +\n\t\t\t\t\t\t\thole_size - 1, 0);\n\t\t\t}\n\t\t\tfree_extent_map(hole_em);\n\t\t} else {\n\t\t\terr = btrfs_inode_set_file_extent_range(inode,\n\t\t\t\t\t\t\tcur_offset, hole_size);\n\t\t\tif (err)\n\t\t\t\tbreak;\n\t\t}\nnext:\n\t\tfree_extent_map(em);\n\t\tem = NULL;\n\t\tcur_offset = last_byte;\n\t\tif (cur_offset >= block_end)\n\t\t\tbreak;\n\t}\n\tfree_extent_map(em);\n\tunlock_extent_cached(io_tree, hole_start, block_end - 1, &cached_state);\n\treturn err;\n}\n\nstatic int btrfs_setsize(struct inode *inode, struct iattr *attr)\n{\n\tstruct btrfs_root *root = BTRFS_I(inode)->root;\n\tstruct btrfs_trans_handle *trans;\n\tloff_t oldsize = i_size_read(inode);\n\tloff_t newsize = attr->ia_size;\n\tint mask = attr->ia_valid;\n\tint ret;\n\n\t/*\n\t * The regular truncate() case without ATTR_CTIME and ATTR_MTIME is a\n\t * special case where we need to update the times despite not having\n\t * these flags set.  For all other operations the VFS set these flags\n\t * explicitly if it wants a timestamp update.\n\t */\n\tif (newsize != oldsize) {\n\t\tinode_inc_iversion(inode);\n\t\tif (!(mask & (ATTR_CTIME | ATTR_MTIME)))\n\t\t\tinode->i_ctime = inode->i_mtime =\n\t\t\t\tcurrent_time(inode);\n\t}\n\n\tif (newsize > oldsize) {\n\t\t/*\n\t\t * Don't do an expanding truncate while snapshotting is ongoing.\n\t\t * This is to ensure the snapshot captures a fully consistent\n\t\t * state of this file - if the snapshot captures this expanding\n\t\t * truncation, it must capture all writes that happened before\n\t\t * this truncation.\n\t\t */\n\t\tbtrfs_drew_write_lock(&root->snapshot_lock);\n\t\tret = btrfs_cont_expand(BTRFS_I(inode), oldsize, newsize);\n\t\tif (ret) {\n\t\t\tbtrfs_drew_write_unlock(&root->snapshot_lock);\n\t\t\treturn ret;\n\t\t}\n\n\t\ttrans = btrfs_start_transaction(root, 1);\n\t\tif (IS_ERR(trans)) {\n\t\t\tbtrfs_drew_write_unlock(&root->snapshot_lock);\n\t\t\treturn PTR_ERR(trans);\n\t\t}\n\n\t\ti_size_write(inode, newsize);\n\t\tbtrfs_inode_safe_disk_i_size_write(BTRFS_I(inode), 0);\n\t\tpagecache_isize_extended(inode, oldsize, newsize);\n\t\tret = btrfs_update_inode(trans, root, BTRFS_I(inode));\n\t\tbtrfs_drew_write_unlock(&root->snapshot_lock);\n\t\tbtrfs_end_transaction(trans);\n\t} else {\n\t\tstruct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);\n\n\t\tif (btrfs_is_zoned(fs_info)) {\n\t\t\tret = btrfs_wait_ordered_range(inode,\n\t\t\t\t\tALIGN(newsize, fs_info->sectorsize),\n\t\t\t\t\t(u64)-1);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\n\t\t/*\n\t\t * We're truncating a file that used to have good data down to\n\t\t * zero. Make sure any new writes to the file get on disk\n\t\t * on close.\n\t\t */\n\t\tif (newsize == 0)\n\t\t\tset_bit(BTRFS_INODE_FLUSH_ON_CLOSE,\n\t\t\t\t&BTRFS_I(inode)->runtime_flags);\n\n\t\ttruncate_setsize(inode, newsize);\n\n\t\tinode_dio_wait(inode);\n\n\t\tret = btrfs_truncate(inode, newsize == oldsize);\n\t\tif (ret && inode->i_nlink) {\n\t\t\tint err;\n\n\t\t\t/*\n\t\t\t * Truncate failed, so fix up the in-memory size. We\n\t\t\t * adjusted disk_i_size down as we removed extents, so\n\t\t\t * wait for disk_i_size to be stable and then update the\n\t\t\t * in-memory size to match.\n\t\t\t */\n\t\t\terr = btrfs_wait_ordered_range(inode, 0, (u64)-1);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t\ti_size_write(inode, BTRFS_I(inode)->disk_i_size);\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nstatic int btrfs_setattr(struct user_namespace *mnt_userns, struct dentry *dentry,\n\t\t\t struct iattr *attr)\n{\n\tstruct inode *inode = d_inode(dentry);\n\tstruct btrfs_root *root = BTRFS_I(inode)->root;\n\tint err;\n\n\tif (btrfs_root_readonly(root))\n\t\treturn -EROFS;\n\n\terr = setattr_prepare(&init_user_ns, dentry, attr);\n\tif (err)\n\t\treturn err;\n\n\tif (S_ISREG(inode->i_mode) && (attr->ia_valid & ATTR_SIZE)) {\n\t\terr = btrfs_setsize(inode, attr);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tif (attr->ia_valid) {\n\t\tsetattr_copy(&init_user_ns, inode, attr);\n\t\tinode_inc_iversion(inode);\n\t\terr = btrfs_dirty_inode(inode);\n\n\t\tif (!err && attr->ia_valid & ATTR_MODE)\n\t\t\terr = posix_acl_chmod(&init_user_ns, inode,\n\t\t\t\t\t      inode->i_mode);\n\t}\n\n\treturn err;\n}\n\n/*\n * While truncating the inode pages during eviction, we get the VFS calling\n * btrfs_invalidatepage() against each page of the inode. This is slow because\n * the calls to btrfs_invalidatepage() result in a huge amount of calls to\n * lock_extent_bits() and clear_extent_bit(), which keep merging and splitting\n * extent_state structures over and over, wasting lots of time.\n *\n * Therefore if the inode is being evicted, let btrfs_invalidatepage() skip all\n * those expensive operations on a per page basis and do only the ordered io\n * finishing, while we release here the extent_map and extent_state structures,\n * without the excessive merging and splitting.\n */\nstatic void evict_inode_truncate_pages(struct inode *inode)\n{\n\tstruct extent_io_tree *io_tree = &BTRFS_I(inode)->io_tree;\n\tstruct extent_map_tree *map_tree = &BTRFS_I(inode)->extent_tree;\n\tstruct rb_node *node;\n\n\tASSERT(inode->i_state & I_FREEING);\n\ttruncate_inode_pages_final(&inode->i_data);\n\n\twrite_lock(&map_tree->lock);\n\twhile (!RB_EMPTY_ROOT(&map_tree->map.rb_root)) {\n\t\tstruct extent_map *em;\n\n\t\tnode = rb_first_cached(&map_tree->map);\n\t\tem = rb_entry(node, struct extent_map, rb_node);\n\t\tclear_bit(EXTENT_FLAG_PINNED, &em->flags);\n\t\tclear_bit(EXTENT_FLAG_LOGGING, &em->flags);\n\t\tremove_extent_mapping(map_tree, em);\n\t\tfree_extent_map(em);\n\t\tif (need_resched()) {\n\t\t\twrite_unlock(&map_tree->lock);\n\t\t\tcond_resched();\n\t\t\twrite_lock(&map_tree->lock);\n\t\t}\n\t}\n\twrite_unlock(&map_tree->lock);\n\n\t/*\n\t * Keep looping until we have no more ranges in the io tree.\n\t * We can have ongoing bios started by readahead that have\n\t * their endio callback (extent_io.c:end_bio_extent_readpage)\n\t * still in progress (unlocked the pages in the bio but did not yet\n\t * unlocked the ranges in the io tree). Therefore this means some\n\t * ranges can still be locked and eviction started because before\n\t * submitting those bios, which are executed by a separate task (work\n\t * queue kthread), inode references (inode->i_count) were not taken\n\t * (which would be dropped in the end io callback of each bio).\n\t * Therefore here we effectively end up waiting for those bios and\n\t * anyone else holding locked ranges without having bumped the inode's\n\t * reference count - if we don't do it, when they access the inode's\n\t * io_tree to unlock a range it may be too late, leading to an\n\t * use-after-free issue.\n\t */\n\tspin_lock(&io_tree->lock);\n\twhile (!RB_EMPTY_ROOT(&io_tree->state)) {\n\t\tstruct extent_state *state;\n\t\tstruct extent_state *cached_state = NULL;\n\t\tu64 start;\n\t\tu64 end;\n\t\tunsigned state_flags;\n\n\t\tnode = rb_first(&io_tree->state);\n\t\tstate = rb_entry(node, struct extent_state, rb_node);\n\t\tstart = state->start;\n\t\tend = state->end;\n\t\tstate_flags = state->state;\n\t\tspin_unlock(&io_tree->lock);\n\n\t\tlock_extent_bits(io_tree, start, end, &cached_state);\n\n\t\t/*\n\t\t * If still has DELALLOC flag, the extent didn't reach disk,\n\t\t * and its reserved space won't be freed by delayed_ref.\n\t\t * So we need to free its reserved space here.\n\t\t * (Refer to comment in btrfs_invalidatepage, case 2)\n\t\t *\n\t\t * Note, end is the bytenr of last byte, so we need + 1 here.\n\t\t */\n\t\tif (state_flags & EXTENT_DELALLOC)\n\t\t\tbtrfs_qgroup_free_data(BTRFS_I(inode), NULL, start,\n\t\t\t\t\t       end - start + 1);\n\n\t\tclear_extent_bit(io_tree, start, end,\n\t\t\t\t EXTENT_LOCKED | EXTENT_DELALLOC |\n\t\t\t\t EXTENT_DO_ACCOUNTING | EXTENT_DEFRAG, 1, 1,\n\t\t\t\t &cached_state);\n\n\t\tcond_resched();\n\t\tspin_lock(&io_tree->lock);\n\t}\n\tspin_unlock(&io_tree->lock);\n}\n\nstatic struct btrfs_trans_handle *evict_refill_and_join(struct btrfs_root *root,\n\t\t\t\t\t\t\tstruct btrfs_block_rsv *rsv)\n{\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tstruct btrfs_block_rsv *global_rsv = &fs_info->global_block_rsv;\n\tstruct btrfs_trans_handle *trans;\n\tu64 delayed_refs_extra = btrfs_calc_insert_metadata_size(fs_info, 1);\n\tint ret;\n\n\t/*\n\t * Eviction should be taking place at some place safe because of our\n\t * delayed iputs.  However the normal flushing code will run delayed\n\t * iputs, so we cannot use FLUSH_ALL otherwise we'll deadlock.\n\t *\n\t * We reserve the delayed_refs_extra here again because we can't use\n\t * btrfs_start_transaction(root, 0) for the same deadlocky reason as\n\t * above.  We reserve our extra bit here because we generate a ton of\n\t * delayed refs activity by truncating.\n\t *\n\t * If we cannot make our reservation we'll attempt to steal from the\n\t * global reserve, because we really want to be able to free up space.\n\t */\n\tret = btrfs_block_rsv_refill(root, rsv, rsv->size + delayed_refs_extra,\n\t\t\t\t     BTRFS_RESERVE_FLUSH_EVICT);\n\tif (ret) {\n\t\t/*\n\t\t * Try to steal from the global reserve if there is space for\n\t\t * it.\n\t\t */\n\t\tif (btrfs_check_space_for_delayed_refs(fs_info) ||\n\t\t    btrfs_block_rsv_migrate(global_rsv, rsv, rsv->size, 0)) {\n\t\t\tbtrfs_warn(fs_info,\n\t\t\t\t   \"could not allocate space for delete; will truncate on mount\");\n\t\t\treturn ERR_PTR(-ENOSPC);\n\t\t}\n\t\tdelayed_refs_extra = 0;\n\t}\n\n\ttrans = btrfs_join_transaction(root);\n\tif (IS_ERR(trans))\n\t\treturn trans;\n\n\tif (delayed_refs_extra) {\n\t\ttrans->block_rsv = &fs_info->trans_block_rsv;\n\t\ttrans->bytes_reserved = delayed_refs_extra;\n\t\tbtrfs_block_rsv_migrate(rsv, trans->block_rsv,\n\t\t\t\t\tdelayed_refs_extra, 1);\n\t}\n\treturn trans;\n}\n\nvoid btrfs_evict_inode(struct inode *inode)\n{\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);\n\tstruct btrfs_trans_handle *trans;\n\tstruct btrfs_root *root = BTRFS_I(inode)->root;\n\tstruct btrfs_block_rsv *rsv;\n\tint ret;\n\n\ttrace_btrfs_inode_evict(inode);\n\n\tif (!root) {\n\t\tclear_inode(inode);\n\t\treturn;\n\t}\n\n\tevict_inode_truncate_pages(inode);\n\n\tif (inode->i_nlink &&\n\t    ((btrfs_root_refs(&root->root_item) != 0 &&\n\t      root->root_key.objectid != BTRFS_ROOT_TREE_OBJECTID) ||\n\t     btrfs_is_free_space_inode(BTRFS_I(inode))))\n\t\tgoto no_delete;\n\n\tif (is_bad_inode(inode))\n\t\tgoto no_delete;\n\n\tbtrfs_free_io_failure_record(BTRFS_I(inode), 0, (u64)-1);\n\n\tif (test_bit(BTRFS_FS_LOG_RECOVERING, &fs_info->flags))\n\t\tgoto no_delete;\n\n\tif (inode->i_nlink > 0) {\n\t\tBUG_ON(btrfs_root_refs(&root->root_item) != 0 &&\n\t\t       root->root_key.objectid != BTRFS_ROOT_TREE_OBJECTID);\n\t\tgoto no_delete;\n\t}\n\n\tret = btrfs_commit_inode_delayed_inode(BTRFS_I(inode));\n\tif (ret)\n\t\tgoto no_delete;\n\n\trsv = btrfs_alloc_block_rsv(fs_info, BTRFS_BLOCK_RSV_TEMP);\n\tif (!rsv)\n\t\tgoto no_delete;\n\trsv->size = btrfs_calc_metadata_size(fs_info, 1);\n\trsv->failfast = 1;\n\n\tbtrfs_i_size_write(BTRFS_I(inode), 0);\n\n\twhile (1) {\n\t\ttrans = evict_refill_and_join(root, rsv);\n\t\tif (IS_ERR(trans))\n\t\t\tgoto free_rsv;\n\n\t\ttrans->block_rsv = rsv;\n\n\t\tret = btrfs_truncate_inode_items(trans, root, BTRFS_I(inode),\n\t\t\t\t\t\t 0, 0);\n\t\ttrans->block_rsv = &fs_info->trans_block_rsv;\n\t\tbtrfs_end_transaction(trans);\n\t\tbtrfs_btree_balance_dirty(fs_info);\n\t\tif (ret && ret != -ENOSPC && ret != -EAGAIN)\n\t\t\tgoto free_rsv;\n\t\telse if (!ret)\n\t\t\tbreak;\n\t}\n\n\t/*\n\t * Errors here aren't a big deal, it just means we leave orphan items in\n\t * the tree. They will be cleaned up on the next mount. If the inode\n\t * number gets reused, cleanup deletes the orphan item without doing\n\t * anything, and unlink reuses the existing orphan item.\n\t *\n\t * If it turns out that we are dropping too many of these, we might want\n\t * to add a mechanism for retrying these after a commit.\n\t */\n\ttrans = evict_refill_and_join(root, rsv);\n\tif (!IS_ERR(trans)) {\n\t\ttrans->block_rsv = rsv;\n\t\tbtrfs_orphan_del(trans, BTRFS_I(inode));\n\t\ttrans->block_rsv = &fs_info->trans_block_rsv;\n\t\tbtrfs_end_transaction(trans);\n\t}\n\nfree_rsv:\n\tbtrfs_free_block_rsv(fs_info, rsv);\nno_delete:\n\t/*\n\t * If we didn't successfully delete, the orphan item will still be in\n\t * the tree and we'll retry on the next mount. Again, we might also want\n\t * to retry these periodically in the future.\n\t */\n\tbtrfs_remove_delayed_node(BTRFS_I(inode));\n\tclear_inode(inode);\n}\n\n/*\n * Return the key found in the dir entry in the location pointer, fill @type\n * with BTRFS_FT_*, and return 0.\n *\n * If no dir entries were found, returns -ENOENT.\n * If found a corrupted location in dir entry, returns -EUCLEAN.\n */\nstatic int btrfs_inode_by_name(struct inode *dir, struct dentry *dentry,\n\t\t\t       struct btrfs_key *location, u8 *type)\n{\n\tconst char *name = dentry->d_name.name;\n\tint namelen = dentry->d_name.len;\n\tstruct btrfs_dir_item *di;\n\tstruct btrfs_path *path;\n\tstruct btrfs_root *root = BTRFS_I(dir)->root;\n\tint ret = 0;\n\n\tpath = btrfs_alloc_path();\n\tif (!path)\n\t\treturn -ENOMEM;\n\n\tdi = btrfs_lookup_dir_item(NULL, root, path, btrfs_ino(BTRFS_I(dir)),\n\t\t\tname, namelen, 0);\n\tif (IS_ERR_OR_NULL(di)) {\n\t\tret = di ? PTR_ERR(di) : -ENOENT;\n\t\tgoto out;\n\t}\n\n\tbtrfs_dir_item_key_to_cpu(path->nodes[0], di, location);\n\tif (location->type != BTRFS_INODE_ITEM_KEY &&\n\t    location->type != BTRFS_ROOT_ITEM_KEY) {\n\t\tret = -EUCLEAN;\n\t\tbtrfs_warn(root->fs_info,\n\"%s gets something invalid in DIR_ITEM (name %s, directory ino %llu, location(%llu %u %llu))\",\n\t\t\t   __func__, name, btrfs_ino(BTRFS_I(dir)),\n\t\t\t   location->objectid, location->type, location->offset);\n\t}\n\tif (!ret)\n\t\t*type = btrfs_dir_type(path->nodes[0], di);\nout:\n\tbtrfs_free_path(path);\n\treturn ret;\n}\n\n/*\n * when we hit a tree root in a directory, the btrfs part of the inode\n * needs to be changed to reflect the root directory of the tree root.  This\n * is kind of like crossing a mount point.\n */\nstatic int fixup_tree_root_location(struct btrfs_fs_info *fs_info,\n\t\t\t\t    struct inode *dir,\n\t\t\t\t    struct dentry *dentry,\n\t\t\t\t    struct btrfs_key *location,\n\t\t\t\t    struct btrfs_root **sub_root)\n{\n\tstruct btrfs_path *path;\n\tstruct btrfs_root *new_root;\n\tstruct btrfs_root_ref *ref;\n\tstruct extent_buffer *leaf;\n\tstruct btrfs_key key;\n\tint ret;\n\tint err = 0;\n\n\tpath = btrfs_alloc_path();\n\tif (!path) {\n\t\terr = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\terr = -ENOENT;\n\tkey.objectid = BTRFS_I(dir)->root->root_key.objectid;\n\tkey.type = BTRFS_ROOT_REF_KEY;\n\tkey.offset = location->objectid;\n\n\tret = btrfs_search_slot(NULL, fs_info->tree_root, &key, path, 0, 0);\n\tif (ret) {\n\t\tif (ret < 0)\n\t\t\terr = ret;\n\t\tgoto out;\n\t}\n\n\tleaf = path->nodes[0];\n\tref = btrfs_item_ptr(leaf, path->slots[0], struct btrfs_root_ref);\n\tif (btrfs_root_ref_dirid(leaf, ref) != btrfs_ino(BTRFS_I(dir)) ||\n\t    btrfs_root_ref_name_len(leaf, ref) != dentry->d_name.len)\n\t\tgoto out;\n\n\tret = memcmp_extent_buffer(leaf, dentry->d_name.name,\n\t\t\t\t   (unsigned long)(ref + 1),\n\t\t\t\t   dentry->d_name.len);\n\tif (ret)\n\t\tgoto out;\n\n\tbtrfs_release_path(path);\n\n\tnew_root = btrfs_get_fs_root(fs_info, location->objectid, true);\n\tif (IS_ERR(new_root)) {\n\t\terr = PTR_ERR(new_root);\n\t\tgoto out;\n\t}\n\n\t*sub_root = new_root;\n\tlocation->objectid = btrfs_root_dirid(&new_root->root_item);\n\tlocation->type = BTRFS_INODE_ITEM_KEY;\n\tlocation->offset = 0;\n\terr = 0;\nout:\n\tbtrfs_free_path(path);\n\treturn err;\n}\n\nstatic void inode_tree_add(struct inode *inode)\n{\n\tstruct btrfs_root *root = BTRFS_I(inode)->root;\n\tstruct btrfs_inode *entry;\n\tstruct rb_node **p;\n\tstruct rb_node *parent;\n\tstruct rb_node *new = &BTRFS_I(inode)->rb_node;\n\tu64 ino = btrfs_ino(BTRFS_I(inode));\n\n\tif (inode_unhashed(inode))\n\t\treturn;\n\tparent = NULL;\n\tspin_lock(&root->inode_lock);\n\tp = &root->inode_tree.rb_node;\n\twhile (*p) {\n\t\tparent = *p;\n\t\tentry = rb_entry(parent, struct btrfs_inode, rb_node);\n\n\t\tif (ino < btrfs_ino(entry))\n\t\t\tp = &parent->rb_left;\n\t\telse if (ino > btrfs_ino(entry))\n\t\t\tp = &parent->rb_right;\n\t\telse {\n\t\t\tWARN_ON(!(entry->vfs_inode.i_state &\n\t\t\t\t  (I_WILL_FREE | I_FREEING)));\n\t\t\trb_replace_node(parent, new, &root->inode_tree);\n\t\t\tRB_CLEAR_NODE(parent);\n\t\t\tspin_unlock(&root->inode_lock);\n\t\t\treturn;\n\t\t}\n\t}\n\trb_link_node(new, parent, p);\n\trb_insert_color(new, &root->inode_tree);\n\tspin_unlock(&root->inode_lock);\n}\n\nstatic void inode_tree_del(struct btrfs_inode *inode)\n{\n\tstruct btrfs_root *root = inode->root;\n\tint empty = 0;\n\n\tspin_lock(&root->inode_lock);\n\tif (!RB_EMPTY_NODE(&inode->rb_node)) {\n\t\trb_erase(&inode->rb_node, &root->inode_tree);\n\t\tRB_CLEAR_NODE(&inode->rb_node);\n\t\tempty = RB_EMPTY_ROOT(&root->inode_tree);\n\t}\n\tspin_unlock(&root->inode_lock);\n\n\tif (empty && btrfs_root_refs(&root->root_item) == 0) {\n\t\tspin_lock(&root->inode_lock);\n\t\tempty = RB_EMPTY_ROOT(&root->inode_tree);\n\t\tspin_unlock(&root->inode_lock);\n\t\tif (empty)\n\t\t\tbtrfs_add_dead_root(root);\n\t}\n}\n\n\nstatic int btrfs_init_locked_inode(struct inode *inode, void *p)\n{\n\tstruct btrfs_iget_args *args = p;\n\n\tinode->i_ino = args->ino;\n\tBTRFS_I(inode)->location.objectid = args->ino;\n\tBTRFS_I(inode)->location.type = BTRFS_INODE_ITEM_KEY;\n\tBTRFS_I(inode)->location.offset = 0;\n\tBTRFS_I(inode)->root = btrfs_grab_root(args->root);\n\tBUG_ON(args->root && !BTRFS_I(inode)->root);\n\treturn 0;\n}\n\nstatic int btrfs_find_actor(struct inode *inode, void *opaque)\n{\n\tstruct btrfs_iget_args *args = opaque;\n\n\treturn args->ino == BTRFS_I(inode)->location.objectid &&\n\t\targs->root == BTRFS_I(inode)->root;\n}\n\nstatic struct inode *btrfs_iget_locked(struct super_block *s, u64 ino,\n\t\t\t\t       struct btrfs_root *root)\n{\n\tstruct inode *inode;\n\tstruct btrfs_iget_args args;\n\tunsigned long hashval = btrfs_inode_hash(ino, root);\n\n\targs.ino = ino;\n\targs.root = root;\n\n\tinode = iget5_locked(s, hashval, btrfs_find_actor,\n\t\t\t     btrfs_init_locked_inode,\n\t\t\t     (void *)&args);\n\treturn inode;\n}\n\n/*\n * Get an inode object given its inode number and corresponding root.\n * Path can be preallocated to prevent recursing back to iget through\n * allocator. NULL is also valid but may require an additional allocation\n * later.\n */\nstruct inode *btrfs_iget_path(struct super_block *s, u64 ino,\n\t\t\t      struct btrfs_root *root, struct btrfs_path *path)\n{\n\tstruct inode *inode;\n\n\tinode = btrfs_iget_locked(s, ino, root);\n\tif (!inode)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tif (inode->i_state & I_NEW) {\n\t\tint ret;\n\n\t\tret = btrfs_read_locked_inode(inode, path);\n\t\tif (!ret) {\n\t\t\tinode_tree_add(inode);\n\t\t\tunlock_new_inode(inode);\n\t\t} else {\n\t\t\tiget_failed(inode);\n\t\t\t/*\n\t\t\t * ret > 0 can come from btrfs_search_slot called by\n\t\t\t * btrfs_read_locked_inode, this means the inode item\n\t\t\t * was not found.\n\t\t\t */\n\t\t\tif (ret > 0)\n\t\t\t\tret = -ENOENT;\n\t\t\tinode = ERR_PTR(ret);\n\t\t}\n\t}\n\n\treturn inode;\n}\n\nstruct inode *btrfs_iget(struct super_block *s, u64 ino, struct btrfs_root *root)\n{\n\treturn btrfs_iget_path(s, ino, root, NULL);\n}\n\nstatic struct inode *new_simple_dir(struct super_block *s,\n\t\t\t\t    struct btrfs_key *key,\n\t\t\t\t    struct btrfs_root *root)\n{\n\tstruct inode *inode = new_inode(s);\n\n\tif (!inode)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tBTRFS_I(inode)->root = btrfs_grab_root(root);\n\tmemcpy(&BTRFS_I(inode)->location, key, sizeof(*key));\n\tset_bit(BTRFS_INODE_DUMMY, &BTRFS_I(inode)->runtime_flags);\n\n\tinode->i_ino = BTRFS_EMPTY_SUBVOL_DIR_OBJECTID;\n\t/*\n\t * We only need lookup, the rest is read-only and there's no inode\n\t * associated with the dentry\n\t */\n\tinode->i_op = &simple_dir_inode_operations;\n\tinode->i_opflags &= ~IOP_XATTR;\n\tinode->i_fop = &simple_dir_operations;\n\tinode->i_mode = S_IFDIR | S_IRUGO | S_IWUSR | S_IXUGO;\n\tinode->i_mtime = current_time(inode);\n\tinode->i_atime = inode->i_mtime;\n\tinode->i_ctime = inode->i_mtime;\n\tBTRFS_I(inode)->i_otime = inode->i_mtime;\n\n\treturn inode;\n}\n\nstatic inline u8 btrfs_inode_type(struct inode *inode)\n{\n\t/*\n\t * Compile-time asserts that generic FT_* types still match\n\t * BTRFS_FT_* types\n\t */\n\tBUILD_BUG_ON(BTRFS_FT_UNKNOWN != FT_UNKNOWN);\n\tBUILD_BUG_ON(BTRFS_FT_REG_FILE != FT_REG_FILE);\n\tBUILD_BUG_ON(BTRFS_FT_DIR != FT_DIR);\n\tBUILD_BUG_ON(BTRFS_FT_CHRDEV != FT_CHRDEV);\n\tBUILD_BUG_ON(BTRFS_FT_BLKDEV != FT_BLKDEV);\n\tBUILD_BUG_ON(BTRFS_FT_FIFO != FT_FIFO);\n\tBUILD_BUG_ON(BTRFS_FT_SOCK != FT_SOCK);\n\tBUILD_BUG_ON(BTRFS_FT_SYMLINK != FT_SYMLINK);\n\n\treturn fs_umode_to_ftype(inode->i_mode);\n}\n\nstruct inode *btrfs_lookup_dentry(struct inode *dir, struct dentry *dentry)\n{\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(dir->i_sb);\n\tstruct inode *inode;\n\tstruct btrfs_root *root = BTRFS_I(dir)->root;\n\tstruct btrfs_root *sub_root = root;\n\tstruct btrfs_key location;\n\tu8 di_type = 0;\n\tint ret = 0;\n\n\tif (dentry->d_name.len > BTRFS_NAME_LEN)\n\t\treturn ERR_PTR(-ENAMETOOLONG);\n\n\tret = btrfs_inode_by_name(dir, dentry, &location, &di_type);\n\tif (ret < 0)\n\t\treturn ERR_PTR(ret);\n\n\tif (location.type == BTRFS_INODE_ITEM_KEY) {\n\t\tinode = btrfs_iget(dir->i_sb, location.objectid, root);\n\t\tif (IS_ERR(inode))\n\t\t\treturn inode;\n\n\t\t/* Do extra check against inode mode with di_type */\n\t\tif (btrfs_inode_type(inode) != di_type) {\n\t\t\tbtrfs_crit(fs_info,\n\"inode mode mismatch with dir: inode mode=0%o btrfs type=%u dir type=%u\",\n\t\t\t\t  inode->i_mode, btrfs_inode_type(inode),\n\t\t\t\t  di_type);\n\t\t\tiput(inode);\n\t\t\treturn ERR_PTR(-EUCLEAN);\n\t\t}\n\t\treturn inode;\n\t}\n\n\tret = fixup_tree_root_location(fs_info, dir, dentry,\n\t\t\t\t       &location, &sub_root);\n\tif (ret < 0) {\n\t\tif (ret != -ENOENT)\n\t\t\tinode = ERR_PTR(ret);\n\t\telse\n\t\t\tinode = new_simple_dir(dir->i_sb, &location, sub_root);\n\t} else {\n\t\tinode = btrfs_iget(dir->i_sb, location.objectid, sub_root);\n\t}\n\tif (root != sub_root)\n\t\tbtrfs_put_root(sub_root);\n\n\tif (!IS_ERR(inode) && root != sub_root) {\n\t\tdown_read(&fs_info->cleanup_work_sem);\n\t\tif (!sb_rdonly(inode->i_sb))\n\t\t\tret = btrfs_orphan_cleanup(sub_root);\n\t\tup_read(&fs_info->cleanup_work_sem);\n\t\tif (ret) {\n\t\t\tiput(inode);\n\t\t\tinode = ERR_PTR(ret);\n\t\t}\n\t}\n\n\treturn inode;\n}\n\nstatic int btrfs_dentry_delete(const struct dentry *dentry)\n{\n\tstruct btrfs_root *root;\n\tstruct inode *inode = d_inode(dentry);\n\n\tif (!inode && !IS_ROOT(dentry))\n\t\tinode = d_inode(dentry->d_parent);\n\n\tif (inode) {\n\t\troot = BTRFS_I(inode)->root;\n\t\tif (btrfs_root_refs(&root->root_item) == 0)\n\t\t\treturn 1;\n\n\t\tif (btrfs_ino(BTRFS_I(inode)) == BTRFS_EMPTY_SUBVOL_DIR_OBJECTID)\n\t\t\treturn 1;\n\t}\n\treturn 0;\n}\n\nstatic struct dentry *btrfs_lookup(struct inode *dir, struct dentry *dentry,\n\t\t\t\t   unsigned int flags)\n{\n\tstruct inode *inode = btrfs_lookup_dentry(dir, dentry);\n\n\tif (inode == ERR_PTR(-ENOENT))\n\t\tinode = NULL;\n\treturn d_splice_alias(inode, dentry);\n}\n\n/*\n * All this infrastructure exists because dir_emit can fault, and we are holding\n * the tree lock when doing readdir.  For now just allocate a buffer and copy\n * our information into that, and then dir_emit from the buffer.  This is\n * similar to what NFS does, only we don't keep the buffer around in pagecache\n * because I'm afraid I'll mess that up.  Long term we need to make filldir do\n * copy_to_user_inatomic so we don't have to worry about page faulting under the\n * tree lock.\n */\nstatic int btrfs_opendir(struct inode *inode, struct file *file)\n{\n\tstruct btrfs_file_private *private;\n\n\tprivate = kzalloc(sizeof(struct btrfs_file_private), GFP_KERNEL);\n\tif (!private)\n\t\treturn -ENOMEM;\n\tprivate->filldir_buf = kzalloc(PAGE_SIZE, GFP_KERNEL);\n\tif (!private->filldir_buf) {\n\t\tkfree(private);\n\t\treturn -ENOMEM;\n\t}\n\tfile->private_data = private;\n\treturn 0;\n}\n\nstruct dir_entry {\n\tu64 ino;\n\tu64 offset;\n\tunsigned type;\n\tint name_len;\n};\n\nstatic int btrfs_filldir(void *addr, int entries, struct dir_context *ctx)\n{\n\twhile (entries--) {\n\t\tstruct dir_entry *entry = addr;\n\t\tchar *name = (char *)(entry + 1);\n\n\t\tctx->pos = get_unaligned(&entry->offset);\n\t\tif (!dir_emit(ctx, name, get_unaligned(&entry->name_len),\n\t\t\t\t\t get_unaligned(&entry->ino),\n\t\t\t\t\t get_unaligned(&entry->type)))\n\t\t\treturn 1;\n\t\taddr += sizeof(struct dir_entry) +\n\t\t\tget_unaligned(&entry->name_len);\n\t\tctx->pos++;\n\t}\n\treturn 0;\n}\n\nstatic int btrfs_real_readdir(struct file *file, struct dir_context *ctx)\n{\n\tstruct inode *inode = file_inode(file);\n\tstruct btrfs_root *root = BTRFS_I(inode)->root;\n\tstruct btrfs_file_private *private = file->private_data;\n\tstruct btrfs_dir_item *di;\n\tstruct btrfs_key key;\n\tstruct btrfs_key found_key;\n\tstruct btrfs_path *path;\n\tvoid *addr;\n\tstruct list_head ins_list;\n\tstruct list_head del_list;\n\tint ret;\n\tstruct extent_buffer *leaf;\n\tint slot;\n\tchar *name_ptr;\n\tint name_len;\n\tint entries = 0;\n\tint total_len = 0;\n\tbool put = false;\n\tstruct btrfs_key location;\n\n\tif (!dir_emit_dots(file, ctx))\n\t\treturn 0;\n\n\tpath = btrfs_alloc_path();\n\tif (!path)\n\t\treturn -ENOMEM;\n\n\taddr = private->filldir_buf;\n\tpath->reada = READA_FORWARD;\n\n\tINIT_LIST_HEAD(&ins_list);\n\tINIT_LIST_HEAD(&del_list);\n\tput = btrfs_readdir_get_delayed_items(inode, &ins_list, &del_list);\n\nagain:\n\tkey.type = BTRFS_DIR_INDEX_KEY;\n\tkey.offset = ctx->pos;\n\tkey.objectid = btrfs_ino(BTRFS_I(inode));\n\n\tret = btrfs_search_slot(NULL, root, &key, path, 0, 0);\n\tif (ret < 0)\n\t\tgoto err;\n\n\twhile (1) {\n\t\tstruct dir_entry *entry;\n\n\t\tleaf = path->nodes[0];\n\t\tslot = path->slots[0];\n\t\tif (slot >= btrfs_header_nritems(leaf)) {\n\t\t\tret = btrfs_next_leaf(root, path);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto err;\n\t\t\telse if (ret > 0)\n\t\t\t\tbreak;\n\t\t\tcontinue;\n\t\t}\n\n\t\tbtrfs_item_key_to_cpu(leaf, &found_key, slot);\n\n\t\tif (found_key.objectid != key.objectid)\n\t\t\tbreak;\n\t\tif (found_key.type != BTRFS_DIR_INDEX_KEY)\n\t\t\tbreak;\n\t\tif (found_key.offset < ctx->pos)\n\t\t\tgoto next;\n\t\tif (btrfs_should_delete_dir_index(&del_list, found_key.offset))\n\t\t\tgoto next;\n\t\tdi = btrfs_item_ptr(leaf, slot, struct btrfs_dir_item);\n\t\tname_len = btrfs_dir_name_len(leaf, di);\n\t\tif ((total_len + sizeof(struct dir_entry) + name_len) >=\n\t\t    PAGE_SIZE) {\n\t\t\tbtrfs_release_path(path);\n\t\t\tret = btrfs_filldir(private->filldir_buf, entries, ctx);\n\t\t\tif (ret)\n\t\t\t\tgoto nopos;\n\t\t\taddr = private->filldir_buf;\n\t\t\tentries = 0;\n\t\t\ttotal_len = 0;\n\t\t\tgoto again;\n\t\t}\n\n\t\tentry = addr;\n\t\tput_unaligned(name_len, &entry->name_len);\n\t\tname_ptr = (char *)(entry + 1);\n\t\tread_extent_buffer(leaf, name_ptr, (unsigned long)(di + 1),\n\t\t\t\t   name_len);\n\t\tput_unaligned(fs_ftype_to_dtype(btrfs_dir_type(leaf, di)),\n\t\t\t\t&entry->type);\n\t\tbtrfs_dir_item_key_to_cpu(leaf, di, &location);\n\t\tput_unaligned(location.objectid, &entry->ino);\n\t\tput_unaligned(found_key.offset, &entry->offset);\n\t\tentries++;\n\t\taddr += sizeof(struct dir_entry) + name_len;\n\t\ttotal_len += sizeof(struct dir_entry) + name_len;\nnext:\n\t\tpath->slots[0]++;\n\t}\n\tbtrfs_release_path(path);\n\n\tret = btrfs_filldir(private->filldir_buf, entries, ctx);\n\tif (ret)\n\t\tgoto nopos;\n\n\tret = btrfs_readdir_delayed_dir_index(ctx, &ins_list);\n\tif (ret)\n\t\tgoto nopos;\n\n\t/*\n\t * Stop new entries from being returned after we return the last\n\t * entry.\n\t *\n\t * New directory entries are assigned a strictly increasing\n\t * offset.  This means that new entries created during readdir\n\t * are *guaranteed* to be seen in the future by that readdir.\n\t * This has broken buggy programs which operate on names as\n\t * they're returned by readdir.  Until we re-use freed offsets\n\t * we have this hack to stop new entries from being returned\n\t * under the assumption that they'll never reach this huge\n\t * offset.\n\t *\n\t * This is being careful not to overflow 32bit loff_t unless the\n\t * last entry requires it because doing so has broken 32bit apps\n\t * in the past.\n\t */\n\tif (ctx->pos >= INT_MAX)\n\t\tctx->pos = LLONG_MAX;\n\telse\n\t\tctx->pos = INT_MAX;\nnopos:\n\tret = 0;\nerr:\n\tif (put)\n\t\tbtrfs_readdir_put_delayed_items(inode, &ins_list, &del_list);\n\tbtrfs_free_path(path);\n\treturn ret;\n}\n\n/*\n * This is somewhat expensive, updating the tree every time the\n * inode changes.  But, it is most likely to find the inode in cache.\n * FIXME, needs more benchmarking...there are no reasons other than performance\n * to keep or drop this code.\n */\nstatic int btrfs_dirty_inode(struct inode *inode)\n{\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);\n\tstruct btrfs_root *root = BTRFS_I(inode)->root;\n\tstruct btrfs_trans_handle *trans;\n\tint ret;\n\n\tif (test_bit(BTRFS_INODE_DUMMY, &BTRFS_I(inode)->runtime_flags))\n\t\treturn 0;\n\n\ttrans = btrfs_join_transaction(root);\n\tif (IS_ERR(trans))\n\t\treturn PTR_ERR(trans);\n\n\tret = btrfs_update_inode(trans, root, BTRFS_I(inode));\n\tif (ret && ret == -ENOSPC) {\n\t\t/* whoops, lets try again with the full transaction */\n\t\tbtrfs_end_transaction(trans);\n\t\ttrans = btrfs_start_transaction(root, 1);\n\t\tif (IS_ERR(trans))\n\t\t\treturn PTR_ERR(trans);\n\n\t\tret = btrfs_update_inode(trans, root, BTRFS_I(inode));\n\t}\n\tbtrfs_end_transaction(trans);\n\tif (BTRFS_I(inode)->delayed_node)\n\t\tbtrfs_balance_delayed_items(fs_info);\n\n\treturn ret;\n}\n\n/*\n * This is a copy of file_update_time.  We need this so we can return error on\n * ENOSPC for updating the inode in the case of file write and mmap writes.\n */\nstatic int btrfs_update_time(struct inode *inode, struct timespec64 *now,\n\t\t\t     int flags)\n{\n\tstruct btrfs_root *root = BTRFS_I(inode)->root;\n\tbool dirty = flags & ~S_VERSION;\n\n\tif (btrfs_root_readonly(root))\n\t\treturn -EROFS;\n\n\tif (flags & S_VERSION)\n\t\tdirty |= inode_maybe_inc_iversion(inode, dirty);\n\tif (flags & S_CTIME)\n\t\tinode->i_ctime = *now;\n\tif (flags & S_MTIME)\n\t\tinode->i_mtime = *now;\n\tif (flags & S_ATIME)\n\t\tinode->i_atime = *now;\n\treturn dirty ? btrfs_dirty_inode(inode) : 0;\n}\n\n/*\n * find the highest existing sequence number in a directory\n * and then set the in-memory index_cnt variable to reflect\n * free sequence numbers\n */\nstatic int btrfs_set_inode_index_count(struct btrfs_inode *inode)\n{\n\tstruct btrfs_root *root = inode->root;\n\tstruct btrfs_key key, found_key;\n\tstruct btrfs_path *path;\n\tstruct extent_buffer *leaf;\n\tint ret;\n\n\tkey.objectid = btrfs_ino(inode);\n\tkey.type = BTRFS_DIR_INDEX_KEY;\n\tkey.offset = (u64)-1;\n\n\tpath = btrfs_alloc_path();\n\tif (!path)\n\t\treturn -ENOMEM;\n\n\tret = btrfs_search_slot(NULL, root, &key, path, 0, 0);\n\tif (ret < 0)\n\t\tgoto out;\n\t/* FIXME: we should be able to handle this */\n\tif (ret == 0)\n\t\tgoto out;\n\tret = 0;\n\n\t/*\n\t * MAGIC NUMBER EXPLANATION:\n\t * since we search a directory based on f_pos we have to start at 2\n\t * since '.' and '..' have f_pos of 0 and 1 respectively, so everybody\n\t * else has to start at 2\n\t */\n\tif (path->slots[0] == 0) {\n\t\tinode->index_cnt = 2;\n\t\tgoto out;\n\t}\n\n\tpath->slots[0]--;\n\n\tleaf = path->nodes[0];\n\tbtrfs_item_key_to_cpu(leaf, &found_key, path->slots[0]);\n\n\tif (found_key.objectid != btrfs_ino(inode) ||\n\t    found_key.type != BTRFS_DIR_INDEX_KEY) {\n\t\tinode->index_cnt = 2;\n\t\tgoto out;\n\t}\n\n\tinode->index_cnt = found_key.offset + 1;\nout:\n\tbtrfs_free_path(path);\n\treturn ret;\n}\n\n/*\n * helper to find a free sequence number in a given directory.  This current\n * code is very simple, later versions will do smarter things in the btree\n */\nint btrfs_set_inode_index(struct btrfs_inode *dir, u64 *index)\n{\n\tint ret = 0;\n\n\tif (dir->index_cnt == (u64)-1) {\n\t\tret = btrfs_inode_delayed_dir_index_count(dir);\n\t\tif (ret) {\n\t\t\tret = btrfs_set_inode_index_count(dir);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\t}\n\n\t*index = dir->index_cnt;\n\tdir->index_cnt++;\n\n\treturn ret;\n}\n\nstatic int btrfs_insert_inode_locked(struct inode *inode)\n{\n\tstruct btrfs_iget_args args;\n\n\targs.ino = BTRFS_I(inode)->location.objectid;\n\targs.root = BTRFS_I(inode)->root;\n\n\treturn insert_inode_locked4(inode,\n\t\t   btrfs_inode_hash(inode->i_ino, BTRFS_I(inode)->root),\n\t\t   btrfs_find_actor, &args);\n}\n\n/*\n * Inherit flags from the parent inode.\n *\n * Currently only the compression flags and the cow flags are inherited.\n */\nstatic void btrfs_inherit_iflags(struct inode *inode, struct inode *dir)\n{\n\tunsigned int flags;\n\n\tif (!dir)\n\t\treturn;\n\n\tflags = BTRFS_I(dir)->flags;\n\n\tif (flags & BTRFS_INODE_NOCOMPRESS) {\n\t\tBTRFS_I(inode)->flags &= ~BTRFS_INODE_COMPRESS;\n\t\tBTRFS_I(inode)->flags |= BTRFS_INODE_NOCOMPRESS;\n\t} else if (flags & BTRFS_INODE_COMPRESS) {\n\t\tBTRFS_I(inode)->flags &= ~BTRFS_INODE_NOCOMPRESS;\n\t\tBTRFS_I(inode)->flags |= BTRFS_INODE_COMPRESS;\n\t}\n\n\tif (flags & BTRFS_INODE_NODATACOW) {\n\t\tBTRFS_I(inode)->flags |= BTRFS_INODE_NODATACOW;\n\t\tif (S_ISREG(inode->i_mode))\n\t\t\tBTRFS_I(inode)->flags |= BTRFS_INODE_NODATASUM;\n\t}\n\n\tbtrfs_sync_inode_flags_to_i_flags(inode);\n}\n\nstatic struct inode *btrfs_new_inode(struct btrfs_trans_handle *trans,\n\t\t\t\t     struct btrfs_root *root,\n\t\t\t\t     struct inode *dir,\n\t\t\t\t     const char *name, int name_len,\n\t\t\t\t     u64 ref_objectid, u64 objectid,\n\t\t\t\t     umode_t mode, u64 *index)\n{\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tstruct inode *inode;\n\tstruct btrfs_inode_item *inode_item;\n\tstruct btrfs_key *location;\n\tstruct btrfs_path *path;\n\tstruct btrfs_inode_ref *ref;\n\tstruct btrfs_key key[2];\n\tu32 sizes[2];\n\tint nitems = name ? 2 : 1;\n\tunsigned long ptr;\n\tunsigned int nofs_flag;\n\tint ret;\n\n\tpath = btrfs_alloc_path();\n\tif (!path)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tnofs_flag = memalloc_nofs_save();\n\tinode = new_inode(fs_info->sb);\n\tmemalloc_nofs_restore(nofs_flag);\n\tif (!inode) {\n\t\tbtrfs_free_path(path);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\n\t/*\n\t * O_TMPFILE, set link count to 0, so that after this point,\n\t * we fill in an inode item with the correct link count.\n\t */\n\tif (!name)\n\t\tset_nlink(inode, 0);\n\n\t/*\n\t * we have to initialize this early, so we can reclaim the inode\n\t * number if we fail afterwards in this function.\n\t */\n\tinode->i_ino = objectid;\n\n\tif (dir && name) {\n\t\ttrace_btrfs_inode_request(dir);\n\n\t\tret = btrfs_set_inode_index(BTRFS_I(dir), index);\n\t\tif (ret) {\n\t\t\tbtrfs_free_path(path);\n\t\t\tiput(inode);\n\t\t\treturn ERR_PTR(ret);\n\t\t}\n\t} else if (dir) {\n\t\t*index = 0;\n\t}\n\t/*\n\t * index_cnt is ignored for everything but a dir,\n\t * btrfs_set_inode_index_count has an explanation for the magic\n\t * number\n\t */\n\tBTRFS_I(inode)->index_cnt = 2;\n\tBTRFS_I(inode)->dir_index = *index;\n\tBTRFS_I(inode)->root = btrfs_grab_root(root);\n\tBTRFS_I(inode)->generation = trans->transid;\n\tinode->i_generation = BTRFS_I(inode)->generation;\n\n\t/*\n\t * We could have gotten an inode number from somebody who was fsynced\n\t * and then removed in this same transaction, so let's just set full\n\t * sync since it will be a full sync anyway and this will blow away the\n\t * old info in the log.\n\t */\n\tset_bit(BTRFS_INODE_NEEDS_FULL_SYNC, &BTRFS_I(inode)->runtime_flags);\n\n\tkey[0].objectid = objectid;\n\tkey[0].type = BTRFS_INODE_ITEM_KEY;\n\tkey[0].offset = 0;\n\n\tsizes[0] = sizeof(struct btrfs_inode_item);\n\n\tif (name) {\n\t\t/*\n\t\t * Start new inodes with an inode_ref. This is slightly more\n\t\t * efficient for small numbers of hard links since they will\n\t\t * be packed into one item. Extended refs will kick in if we\n\t\t * add more hard links than can fit in the ref item.\n\t\t */\n\t\tkey[1].objectid = objectid;\n\t\tkey[1].type = BTRFS_INODE_REF_KEY;\n\t\tkey[1].offset = ref_objectid;\n\n\t\tsizes[1] = name_len + sizeof(*ref);\n\t}\n\n\tlocation = &BTRFS_I(inode)->location;\n\tlocation->objectid = objectid;\n\tlocation->offset = 0;\n\tlocation->type = BTRFS_INODE_ITEM_KEY;\n\n\tret = btrfs_insert_inode_locked(inode);\n\tif (ret < 0) {\n\t\tiput(inode);\n\t\tgoto fail;\n\t}\n\n\tret = btrfs_insert_empty_items(trans, root, path, key, sizes, nitems);\n\tif (ret != 0)\n\t\tgoto fail_unlock;\n\n\tinode_init_owner(&init_user_ns, inode, dir, mode);\n\tinode_set_bytes(inode, 0);\n\n\tinode->i_mtime = current_time(inode);\n\tinode->i_atime = inode->i_mtime;\n\tinode->i_ctime = inode->i_mtime;\n\tBTRFS_I(inode)->i_otime = inode->i_mtime;\n\n\tinode_item = btrfs_item_ptr(path->nodes[0], path->slots[0],\n\t\t\t\t  struct btrfs_inode_item);\n\tmemzero_extent_buffer(path->nodes[0], (unsigned long)inode_item,\n\t\t\t     sizeof(*inode_item));\n\tfill_inode_item(trans, path->nodes[0], inode_item, inode);\n\n\tif (name) {\n\t\tref = btrfs_item_ptr(path->nodes[0], path->slots[0] + 1,\n\t\t\t\t     struct btrfs_inode_ref);\n\t\tbtrfs_set_inode_ref_name_len(path->nodes[0], ref, name_len);\n\t\tbtrfs_set_inode_ref_index(path->nodes[0], ref, *index);\n\t\tptr = (unsigned long)(ref + 1);\n\t\twrite_extent_buffer(path->nodes[0], name, ptr, name_len);\n\t}\n\n\tbtrfs_mark_buffer_dirty(path->nodes[0]);\n\tbtrfs_free_path(path);\n\n\tbtrfs_inherit_iflags(inode, dir);\n\n\tif (S_ISREG(mode)) {\n\t\tif (btrfs_test_opt(fs_info, NODATASUM))\n\t\t\tBTRFS_I(inode)->flags |= BTRFS_INODE_NODATASUM;\n\t\tif (btrfs_test_opt(fs_info, NODATACOW))\n\t\t\tBTRFS_I(inode)->flags |= BTRFS_INODE_NODATACOW |\n\t\t\t\tBTRFS_INODE_NODATASUM;\n\t}\n\n\tinode_tree_add(inode);\n\n\ttrace_btrfs_inode_new(inode);\n\tbtrfs_set_inode_last_trans(trans, BTRFS_I(inode));\n\n\tbtrfs_update_root_times(trans, root);\n\n\tret = btrfs_inode_inherit_props(trans, inode, dir);\n\tif (ret)\n\t\tbtrfs_err(fs_info,\n\t\t\t  \"error inheriting props for ino %llu (root %llu): %d\",\n\t\t\tbtrfs_ino(BTRFS_I(inode)), root->root_key.objectid, ret);\n\n\treturn inode;\n\nfail_unlock:\n\tdiscard_new_inode(inode);\nfail:\n\tif (dir && name)\n\t\tBTRFS_I(dir)->index_cnt--;\n\tbtrfs_free_path(path);\n\treturn ERR_PTR(ret);\n}\n\n/*\n * utility function to add 'inode' into 'parent_inode' with\n * a give name and a given sequence number.\n * if 'add_backref' is true, also insert a backref from the\n * inode to the parent directory.\n */\nint btrfs_add_link(struct btrfs_trans_handle *trans,\n\t\t   struct btrfs_inode *parent_inode, struct btrfs_inode *inode,\n\t\t   const char *name, int name_len, int add_backref, u64 index)\n{\n\tint ret = 0;\n\tstruct btrfs_key key;\n\tstruct btrfs_root *root = parent_inode->root;\n\tu64 ino = btrfs_ino(inode);\n\tu64 parent_ino = btrfs_ino(parent_inode);\n\n\tif (unlikely(ino == BTRFS_FIRST_FREE_OBJECTID)) {\n\t\tmemcpy(&key, &inode->root->root_key, sizeof(key));\n\t} else {\n\t\tkey.objectid = ino;\n\t\tkey.type = BTRFS_INODE_ITEM_KEY;\n\t\tkey.offset = 0;\n\t}\n\n\tif (unlikely(ino == BTRFS_FIRST_FREE_OBJECTID)) {\n\t\tret = btrfs_add_root_ref(trans, key.objectid,\n\t\t\t\t\t root->root_key.objectid, parent_ino,\n\t\t\t\t\t index, name, name_len);\n\t} else if (add_backref) {\n\t\tret = btrfs_insert_inode_ref(trans, root, name, name_len, ino,\n\t\t\t\t\t     parent_ino, index);\n\t}\n\n\t/* Nothing to clean up yet */\n\tif (ret)\n\t\treturn ret;\n\n\tret = btrfs_insert_dir_item(trans, name, name_len, parent_inode, &key,\n\t\t\t\t    btrfs_inode_type(&inode->vfs_inode), index);\n\tif (ret == -EEXIST || ret == -EOVERFLOW)\n\t\tgoto fail_dir_item;\n\telse if (ret) {\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\treturn ret;\n\t}\n\n\tbtrfs_i_size_write(parent_inode, parent_inode->vfs_inode.i_size +\n\t\t\t   name_len * 2);\n\tinode_inc_iversion(&parent_inode->vfs_inode);\n\t/*\n\t * If we are replaying a log tree, we do not want to update the mtime\n\t * and ctime of the parent directory with the current time, since the\n\t * log replay procedure is responsible for setting them to their correct\n\t * values (the ones it had when the fsync was done).\n\t */\n\tif (!test_bit(BTRFS_FS_LOG_RECOVERING, &root->fs_info->flags)) {\n\t\tstruct timespec64 now = current_time(&parent_inode->vfs_inode);\n\n\t\tparent_inode->vfs_inode.i_mtime = now;\n\t\tparent_inode->vfs_inode.i_ctime = now;\n\t}\n\tret = btrfs_update_inode(trans, root, parent_inode);\n\tif (ret)\n\t\tbtrfs_abort_transaction(trans, ret);\n\treturn ret;\n\nfail_dir_item:\n\tif (unlikely(ino == BTRFS_FIRST_FREE_OBJECTID)) {\n\t\tu64 local_index;\n\t\tint err;\n\t\terr = btrfs_del_root_ref(trans, key.objectid,\n\t\t\t\t\t root->root_key.objectid, parent_ino,\n\t\t\t\t\t &local_index, name, name_len);\n\t\tif (err)\n\t\t\tbtrfs_abort_transaction(trans, err);\n\t} else if (add_backref) {\n\t\tu64 local_index;\n\t\tint err;\n\n\t\terr = btrfs_del_inode_ref(trans, root, name, name_len,\n\t\t\t\t\t  ino, parent_ino, &local_index);\n\t\tif (err)\n\t\t\tbtrfs_abort_transaction(trans, err);\n\t}\n\n\t/* Return the original error code */\n\treturn ret;\n}\n\nstatic int btrfs_add_nondir(struct btrfs_trans_handle *trans,\n\t\t\t    struct btrfs_inode *dir, struct dentry *dentry,\n\t\t\t    struct btrfs_inode *inode, int backref, u64 index)\n{\n\tint err = btrfs_add_link(trans, dir, inode,\n\t\t\t\t dentry->d_name.name, dentry->d_name.len,\n\t\t\t\t backref, index);\n\tif (err > 0)\n\t\terr = -EEXIST;\n\treturn err;\n}\n\nstatic int btrfs_mknod(struct user_namespace *mnt_userns, struct inode *dir,\n\t\t       struct dentry *dentry, umode_t mode, dev_t rdev)\n{\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(dir->i_sb);\n\tstruct btrfs_trans_handle *trans;\n\tstruct btrfs_root *root = BTRFS_I(dir)->root;\n\tstruct inode *inode = NULL;\n\tint err;\n\tu64 objectid;\n\tu64 index = 0;\n\n\t/*\n\t * 2 for inode item and ref\n\t * 2 for dir items\n\t * 1 for xattr if selinux is on\n\t */\n\ttrans = btrfs_start_transaction(root, 5);\n\tif (IS_ERR(trans))\n\t\treturn PTR_ERR(trans);\n\n\terr = btrfs_get_free_objectid(root, &objectid);\n\tif (err)\n\t\tgoto out_unlock;\n\n\tinode = btrfs_new_inode(trans, root, dir, dentry->d_name.name,\n\t\t\tdentry->d_name.len, btrfs_ino(BTRFS_I(dir)), objectid,\n\t\t\tmode, &index);\n\tif (IS_ERR(inode)) {\n\t\terr = PTR_ERR(inode);\n\t\tinode = NULL;\n\t\tgoto out_unlock;\n\t}\n\n\t/*\n\t* If the active LSM wants to access the inode during\n\t* d_instantiate it needs these. Smack checks to see\n\t* if the filesystem supports xattrs by looking at the\n\t* ops vector.\n\t*/\n\tinode->i_op = &btrfs_special_inode_operations;\n\tinit_special_inode(inode, inode->i_mode, rdev);\n\n\terr = btrfs_init_inode_security(trans, inode, dir, &dentry->d_name);\n\tif (err)\n\t\tgoto out_unlock;\n\n\terr = btrfs_add_nondir(trans, BTRFS_I(dir), dentry, BTRFS_I(inode),\n\t\t\t0, index);\n\tif (err)\n\t\tgoto out_unlock;\n\n\tbtrfs_update_inode(trans, root, BTRFS_I(inode));\n\td_instantiate_new(dentry, inode);\n\nout_unlock:\n\tbtrfs_end_transaction(trans);\n\tbtrfs_btree_balance_dirty(fs_info);\n\tif (err && inode) {\n\t\tinode_dec_link_count(inode);\n\t\tdiscard_new_inode(inode);\n\t}\n\treturn err;\n}\n\nstatic int btrfs_create(struct user_namespace *mnt_userns, struct inode *dir,\n\t\t\tstruct dentry *dentry, umode_t mode, bool excl)\n{\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(dir->i_sb);\n\tstruct btrfs_trans_handle *trans;\n\tstruct btrfs_root *root = BTRFS_I(dir)->root;\n\tstruct inode *inode = NULL;\n\tint err;\n\tu64 objectid;\n\tu64 index = 0;\n\n\t/*\n\t * 2 for inode item and ref\n\t * 2 for dir items\n\t * 1 for xattr if selinux is on\n\t */\n\ttrans = btrfs_start_transaction(root, 5);\n\tif (IS_ERR(trans))\n\t\treturn PTR_ERR(trans);\n\n\terr = btrfs_get_free_objectid(root, &objectid);\n\tif (err)\n\t\tgoto out_unlock;\n\n\tinode = btrfs_new_inode(trans, root, dir, dentry->d_name.name,\n\t\t\tdentry->d_name.len, btrfs_ino(BTRFS_I(dir)), objectid,\n\t\t\tmode, &index);\n\tif (IS_ERR(inode)) {\n\t\terr = PTR_ERR(inode);\n\t\tinode = NULL;\n\t\tgoto out_unlock;\n\t}\n\t/*\n\t* If the active LSM wants to access the inode during\n\t* d_instantiate it needs these. Smack checks to see\n\t* if the filesystem supports xattrs by looking at the\n\t* ops vector.\n\t*/\n\tinode->i_fop = &btrfs_file_operations;\n\tinode->i_op = &btrfs_file_inode_operations;\n\tinode->i_mapping->a_ops = &btrfs_aops;\n\n\terr = btrfs_init_inode_security(trans, inode, dir, &dentry->d_name);\n\tif (err)\n\t\tgoto out_unlock;\n\n\terr = btrfs_update_inode(trans, root, BTRFS_I(inode));\n\tif (err)\n\t\tgoto out_unlock;\n\n\terr = btrfs_add_nondir(trans, BTRFS_I(dir), dentry, BTRFS_I(inode),\n\t\t\t0, index);\n\tif (err)\n\t\tgoto out_unlock;\n\n\td_instantiate_new(dentry, inode);\n\nout_unlock:\n\tbtrfs_end_transaction(trans);\n\tif (err && inode) {\n\t\tinode_dec_link_count(inode);\n\t\tdiscard_new_inode(inode);\n\t}\n\tbtrfs_btree_balance_dirty(fs_info);\n\treturn err;\n}\n\nstatic int btrfs_link(struct dentry *old_dentry, struct inode *dir,\n\t\t      struct dentry *dentry)\n{\n\tstruct btrfs_trans_handle *trans = NULL;\n\tstruct btrfs_root *root = BTRFS_I(dir)->root;\n\tstruct inode *inode = d_inode(old_dentry);\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);\n\tu64 index;\n\tint err;\n\tint drop_inode = 0;\n\n\t/* do not allow sys_link's with other subvols of the same device */\n\tif (root->root_key.objectid != BTRFS_I(inode)->root->root_key.objectid)\n\t\treturn -EXDEV;\n\n\tif (inode->i_nlink >= BTRFS_LINK_MAX)\n\t\treturn -EMLINK;\n\n\terr = btrfs_set_inode_index(BTRFS_I(dir), &index);\n\tif (err)\n\t\tgoto fail;\n\n\t/*\n\t * 2 items for inode and inode ref\n\t * 2 items for dir items\n\t * 1 item for parent inode\n\t * 1 item for orphan item deletion if O_TMPFILE\n\t */\n\ttrans = btrfs_start_transaction(root, inode->i_nlink ? 5 : 6);\n\tif (IS_ERR(trans)) {\n\t\terr = PTR_ERR(trans);\n\t\ttrans = NULL;\n\t\tgoto fail;\n\t}\n\n\t/* There are several dir indexes for this inode, clear the cache. */\n\tBTRFS_I(inode)->dir_index = 0ULL;\n\tinc_nlink(inode);\n\tinode_inc_iversion(inode);\n\tinode->i_ctime = current_time(inode);\n\tihold(inode);\n\tset_bit(BTRFS_INODE_COPY_EVERYTHING, &BTRFS_I(inode)->runtime_flags);\n\n\terr = btrfs_add_nondir(trans, BTRFS_I(dir), dentry, BTRFS_I(inode),\n\t\t\t1, index);\n\n\tif (err) {\n\t\tdrop_inode = 1;\n\t} else {\n\t\tstruct dentry *parent = dentry->d_parent;\n\n\t\terr = btrfs_update_inode(trans, root, BTRFS_I(inode));\n\t\tif (err)\n\t\t\tgoto fail;\n\t\tif (inode->i_nlink == 1) {\n\t\t\t/*\n\t\t\t * If new hard link count is 1, it's a file created\n\t\t\t * with open(2) O_TMPFILE flag.\n\t\t\t */\n\t\t\terr = btrfs_orphan_del(trans, BTRFS_I(inode));\n\t\t\tif (err)\n\t\t\t\tgoto fail;\n\t\t}\n\t\td_instantiate(dentry, inode);\n\t\tbtrfs_log_new_name(trans, BTRFS_I(inode), NULL, parent);\n\t}\n\nfail:\n\tif (trans)\n\t\tbtrfs_end_transaction(trans);\n\tif (drop_inode) {\n\t\tinode_dec_link_count(inode);\n\t\tiput(inode);\n\t}\n\tbtrfs_btree_balance_dirty(fs_info);\n\treturn err;\n}\n\nstatic int btrfs_mkdir(struct user_namespace *mnt_userns, struct inode *dir,\n\t\t       struct dentry *dentry, umode_t mode)\n{\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(dir->i_sb);\n\tstruct inode *inode = NULL;\n\tstruct btrfs_trans_handle *trans;\n\tstruct btrfs_root *root = BTRFS_I(dir)->root;\n\tint err = 0;\n\tu64 objectid = 0;\n\tu64 index = 0;\n\n\t/*\n\t * 2 items for inode and ref\n\t * 2 items for dir items\n\t * 1 for xattr if selinux is on\n\t */\n\ttrans = btrfs_start_transaction(root, 5);\n\tif (IS_ERR(trans))\n\t\treturn PTR_ERR(trans);\n\n\terr = btrfs_get_free_objectid(root, &objectid);\n\tif (err)\n\t\tgoto out_fail;\n\n\tinode = btrfs_new_inode(trans, root, dir, dentry->d_name.name,\n\t\t\tdentry->d_name.len, btrfs_ino(BTRFS_I(dir)), objectid,\n\t\t\tS_IFDIR | mode, &index);\n\tif (IS_ERR(inode)) {\n\t\terr = PTR_ERR(inode);\n\t\tinode = NULL;\n\t\tgoto out_fail;\n\t}\n\n\t/* these must be set before we unlock the inode */\n\tinode->i_op = &btrfs_dir_inode_operations;\n\tinode->i_fop = &btrfs_dir_file_operations;\n\n\terr = btrfs_init_inode_security(trans, inode, dir, &dentry->d_name);\n\tif (err)\n\t\tgoto out_fail;\n\n\tbtrfs_i_size_write(BTRFS_I(inode), 0);\n\terr = btrfs_update_inode(trans, root, BTRFS_I(inode));\n\tif (err)\n\t\tgoto out_fail;\n\n\terr = btrfs_add_link(trans, BTRFS_I(dir), BTRFS_I(inode),\n\t\t\tdentry->d_name.name,\n\t\t\tdentry->d_name.len, 0, index);\n\tif (err)\n\t\tgoto out_fail;\n\n\td_instantiate_new(dentry, inode);\n\nout_fail:\n\tbtrfs_end_transaction(trans);\n\tif (err && inode) {\n\t\tinode_dec_link_count(inode);\n\t\tdiscard_new_inode(inode);\n\t}\n\tbtrfs_btree_balance_dirty(fs_info);\n\treturn err;\n}\n\nstatic noinline int uncompress_inline(struct btrfs_path *path,\n\t\t\t\t      struct page *page,\n\t\t\t\t      size_t pg_offset, u64 extent_offset,\n\t\t\t\t      struct btrfs_file_extent_item *item)\n{\n\tint ret;\n\tstruct extent_buffer *leaf = path->nodes[0];\n\tchar *tmp;\n\tsize_t max_size;\n\tunsigned long inline_size;\n\tunsigned long ptr;\n\tint compress_type;\n\n\tWARN_ON(pg_offset != 0);\n\tcompress_type = btrfs_file_extent_compression(leaf, item);\n\tmax_size = btrfs_file_extent_ram_bytes(leaf, item);\n\tinline_size = btrfs_file_extent_inline_item_len(leaf,\n\t\t\t\t\tbtrfs_item_nr(path->slots[0]));\n\ttmp = kmalloc(inline_size, GFP_NOFS);\n\tif (!tmp)\n\t\treturn -ENOMEM;\n\tptr = btrfs_file_extent_inline_start(item);\n\n\tread_extent_buffer(leaf, tmp, ptr, inline_size);\n\n\tmax_size = min_t(unsigned long, PAGE_SIZE, max_size);\n\tret = btrfs_decompress(compress_type, tmp, page,\n\t\t\t       extent_offset, inline_size, max_size);\n\n\t/*\n\t * decompression code contains a memset to fill in any space between the end\n\t * of the uncompressed data and the end of max_size in case the decompressed\n\t * data ends up shorter than ram_bytes.  That doesn't cover the hole between\n\t * the end of an inline extent and the beginning of the next block, so we\n\t * cover that region here.\n\t */\n\n\tif (max_size + pg_offset < PAGE_SIZE)\n\t\tzero_user(page,  pg_offset + max_size,\n\t\t\t  PAGE_SIZE - max_size - pg_offset);\n\tkfree(tmp);\n\treturn ret;\n}\n\n/**\n * btrfs_get_extent - Lookup the first extent overlapping a range in a file.\n * @inode:\tfile to search in\n * @page:\tpage to read extent data into if the extent is inline\n * @pg_offset:\toffset into @page to copy to\n * @start:\tfile offset\n * @len:\tlength of range starting at @start\n *\n * This returns the first &struct extent_map which overlaps with the given\n * range, reading it from the B-tree and caching it if necessary. Note that\n * there may be more extents which overlap the given range after the returned\n * extent_map.\n *\n * If @page is not NULL and the extent is inline, this also reads the extent\n * data directly into the page and marks the extent up to date in the io_tree.\n *\n * Return: ERR_PTR on error, non-NULL extent_map on success.\n */\nstruct extent_map *btrfs_get_extent(struct btrfs_inode *inode,\n\t\t\t\t    struct page *page, size_t pg_offset,\n\t\t\t\t    u64 start, u64 len)\n{\n\tstruct btrfs_fs_info *fs_info = inode->root->fs_info;\n\tint ret = 0;\n\tu64 extent_start = 0;\n\tu64 extent_end = 0;\n\tu64 objectid = btrfs_ino(inode);\n\tint extent_type = -1;\n\tstruct btrfs_path *path = NULL;\n\tstruct btrfs_root *root = inode->root;\n\tstruct btrfs_file_extent_item *item;\n\tstruct extent_buffer *leaf;\n\tstruct btrfs_key found_key;\n\tstruct extent_map *em = NULL;\n\tstruct extent_map_tree *em_tree = &inode->extent_tree;\n\tstruct extent_io_tree *io_tree = &inode->io_tree;\n\n\tread_lock(&em_tree->lock);\n\tem = lookup_extent_mapping(em_tree, start, len);\n\tread_unlock(&em_tree->lock);\n\n\tif (em) {\n\t\tif (em->start > start || em->start + em->len <= start)\n\t\t\tfree_extent_map(em);\n\t\telse if (em->block_start == EXTENT_MAP_INLINE && page)\n\t\t\tfree_extent_map(em);\n\t\telse\n\t\t\tgoto out;\n\t}\n\tem = alloc_extent_map();\n\tif (!em) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\tem->start = EXTENT_MAP_HOLE;\n\tem->orig_start = EXTENT_MAP_HOLE;\n\tem->len = (u64)-1;\n\tem->block_len = (u64)-1;\n\n\tpath = btrfs_alloc_path();\n\tif (!path) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\t/* Chances are we'll be called again, so go ahead and do readahead */\n\tpath->reada = READA_FORWARD;\n\n\t/*\n\t * The same explanation in load_free_space_cache applies here as well,\n\t * we only read when we're loading the free space cache, and at that\n\t * point the commit_root has everything we need.\n\t */\n\tif (btrfs_is_free_space_inode(inode)) {\n\t\tpath->search_commit_root = 1;\n\t\tpath->skip_locking = 1;\n\t}\n\n\tret = btrfs_lookup_file_extent(NULL, root, path, objectid, start, 0);\n\tif (ret < 0) {\n\t\tgoto out;\n\t} else if (ret > 0) {\n\t\tif (path->slots[0] == 0)\n\t\t\tgoto not_found;\n\t\tpath->slots[0]--;\n\t\tret = 0;\n\t}\n\n\tleaf = path->nodes[0];\n\titem = btrfs_item_ptr(leaf, path->slots[0],\n\t\t\t      struct btrfs_file_extent_item);\n\tbtrfs_item_key_to_cpu(leaf, &found_key, path->slots[0]);\n\tif (found_key.objectid != objectid ||\n\t    found_key.type != BTRFS_EXTENT_DATA_KEY) {\n\t\t/*\n\t\t * If we backup past the first extent we want to move forward\n\t\t * and see if there is an extent in front of us, otherwise we'll\n\t\t * say there is a hole for our whole search range which can\n\t\t * cause problems.\n\t\t */\n\t\textent_end = start;\n\t\tgoto next;\n\t}\n\n\textent_type = btrfs_file_extent_type(leaf, item);\n\textent_start = found_key.offset;\n\textent_end = btrfs_file_extent_end(path);\n\tif (extent_type == BTRFS_FILE_EXTENT_REG ||\n\t    extent_type == BTRFS_FILE_EXTENT_PREALLOC) {\n\t\t/* Only regular file could have regular/prealloc extent */\n\t\tif (!S_ISREG(inode->vfs_inode.i_mode)) {\n\t\t\tret = -EUCLEAN;\n\t\t\tbtrfs_crit(fs_info,\n\t\t\"regular/prealloc extent found for non-regular inode %llu\",\n\t\t\t\t   btrfs_ino(inode));\n\t\t\tgoto out;\n\t\t}\n\t\ttrace_btrfs_get_extent_show_fi_regular(inode, leaf, item,\n\t\t\t\t\t\t       extent_start);\n\t} else if (extent_type == BTRFS_FILE_EXTENT_INLINE) {\n\t\ttrace_btrfs_get_extent_show_fi_inline(inode, leaf, item,\n\t\t\t\t\t\t      path->slots[0],\n\t\t\t\t\t\t      extent_start);\n\t}\nnext:\n\tif (start >= extent_end) {\n\t\tpath->slots[0]++;\n\t\tif (path->slots[0] >= btrfs_header_nritems(leaf)) {\n\t\t\tret = btrfs_next_leaf(root, path);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto out;\n\t\t\telse if (ret > 0)\n\t\t\t\tgoto not_found;\n\n\t\t\tleaf = path->nodes[0];\n\t\t}\n\t\tbtrfs_item_key_to_cpu(leaf, &found_key, path->slots[0]);\n\t\tif (found_key.objectid != objectid ||\n\t\t    found_key.type != BTRFS_EXTENT_DATA_KEY)\n\t\t\tgoto not_found;\n\t\tif (start + len <= found_key.offset)\n\t\t\tgoto not_found;\n\t\tif (start > found_key.offset)\n\t\t\tgoto next;\n\n\t\t/* New extent overlaps with existing one */\n\t\tem->start = start;\n\t\tem->orig_start = start;\n\t\tem->len = found_key.offset - start;\n\t\tem->block_start = EXTENT_MAP_HOLE;\n\t\tgoto insert;\n\t}\n\n\tbtrfs_extent_item_to_extent_map(inode, path, item, !page, em);\n\n\tif (extent_type == BTRFS_FILE_EXTENT_REG ||\n\t    extent_type == BTRFS_FILE_EXTENT_PREALLOC) {\n\t\tgoto insert;\n\t} else if (extent_type == BTRFS_FILE_EXTENT_INLINE) {\n\t\tunsigned long ptr;\n\t\tchar *map;\n\t\tsize_t size;\n\t\tsize_t extent_offset;\n\t\tsize_t copy_size;\n\n\t\tif (!page)\n\t\t\tgoto out;\n\n\t\tsize = btrfs_file_extent_ram_bytes(leaf, item);\n\t\textent_offset = page_offset(page) + pg_offset - extent_start;\n\t\tcopy_size = min_t(u64, PAGE_SIZE - pg_offset,\n\t\t\t\t  size - extent_offset);\n\t\tem->start = extent_start + extent_offset;\n\t\tem->len = ALIGN(copy_size, fs_info->sectorsize);\n\t\tem->orig_block_len = em->len;\n\t\tem->orig_start = em->start;\n\t\tptr = btrfs_file_extent_inline_start(item) + extent_offset;\n\n\t\tif (!PageUptodate(page)) {\n\t\t\tif (btrfs_file_extent_compression(leaf, item) !=\n\t\t\t    BTRFS_COMPRESS_NONE) {\n\t\t\t\tret = uncompress_inline(path, page, pg_offset,\n\t\t\t\t\t\t\textent_offset, item);\n\t\t\t\tif (ret)\n\t\t\t\t\tgoto out;\n\t\t\t} else {\n\t\t\t\tmap = kmap(page);\n\t\t\t\tread_extent_buffer(leaf, map + pg_offset, ptr,\n\t\t\t\t\t\t   copy_size);\n\t\t\t\tif (pg_offset + copy_size < PAGE_SIZE) {\n\t\t\t\t\tmemset(map + pg_offset + copy_size, 0,\n\t\t\t\t\t       PAGE_SIZE - pg_offset -\n\t\t\t\t\t       copy_size);\n\t\t\t\t}\n\t\t\t\tkunmap(page);\n\t\t\t}\n\t\t\tflush_dcache_page(page);\n\t\t}\n\t\tset_extent_uptodate(io_tree, em->start,\n\t\t\t\t    extent_map_end(em) - 1, NULL, GFP_NOFS);\n\t\tgoto insert;\n\t}\nnot_found:\n\tem->start = start;\n\tem->orig_start = start;\n\tem->len = len;\n\tem->block_start = EXTENT_MAP_HOLE;\ninsert:\n\tret = 0;\n\tbtrfs_release_path(path);\n\tif (em->start > start || extent_map_end(em) <= start) {\n\t\tbtrfs_err(fs_info,\n\t\t\t  \"bad extent! em: [%llu %llu] passed [%llu %llu]\",\n\t\t\t  em->start, em->len, start, len);\n\t\tret = -EIO;\n\t\tgoto out;\n\t}\n\n\twrite_lock(&em_tree->lock);\n\tret = btrfs_add_extent_mapping(fs_info, em_tree, &em, start, len);\n\twrite_unlock(&em_tree->lock);\nout:\n\tbtrfs_free_path(path);\n\n\ttrace_btrfs_get_extent(root, inode, em);\n\n\tif (ret) {\n\t\tfree_extent_map(em);\n\t\treturn ERR_PTR(ret);\n\t}\n\treturn em;\n}\n\nstruct extent_map *btrfs_get_extent_fiemap(struct btrfs_inode *inode,\n\t\t\t\t\t   u64 start, u64 len)\n{\n\tstruct extent_map *em;\n\tstruct extent_map *hole_em = NULL;\n\tu64 delalloc_start = start;\n\tu64 end;\n\tu64 delalloc_len;\n\tu64 delalloc_end;\n\tint err = 0;\n\n\tem = btrfs_get_extent(inode, NULL, 0, start, len);\n\tif (IS_ERR(em))\n\t\treturn em;\n\t/*\n\t * If our em maps to:\n\t * - a hole or\n\t * - a pre-alloc extent,\n\t * there might actually be delalloc bytes behind it.\n\t */\n\tif (em->block_start != EXTENT_MAP_HOLE &&\n\t    !test_bit(EXTENT_FLAG_PREALLOC, &em->flags))\n\t\treturn em;\n\telse\n\t\thole_em = em;\n\n\t/* check to see if we've wrapped (len == -1 or similar) */\n\tend = start + len;\n\tif (end < start)\n\t\tend = (u64)-1;\n\telse\n\t\tend -= 1;\n\n\tem = NULL;\n\n\t/* ok, we didn't find anything, lets look for delalloc */\n\tdelalloc_len = count_range_bits(&inode->io_tree, &delalloc_start,\n\t\t\t\t end, len, EXTENT_DELALLOC, 1);\n\tdelalloc_end = delalloc_start + delalloc_len;\n\tif (delalloc_end < delalloc_start)\n\t\tdelalloc_end = (u64)-1;\n\n\t/*\n\t * We didn't find anything useful, return the original results from\n\t * get_extent()\n\t */\n\tif (delalloc_start > end || delalloc_end <= start) {\n\t\tem = hole_em;\n\t\thole_em = NULL;\n\t\tgoto out;\n\t}\n\n\t/*\n\t * Adjust the delalloc_start to make sure it doesn't go backwards from\n\t * the start they passed in\n\t */\n\tdelalloc_start = max(start, delalloc_start);\n\tdelalloc_len = delalloc_end - delalloc_start;\n\n\tif (delalloc_len > 0) {\n\t\tu64 hole_start;\n\t\tu64 hole_len;\n\t\tconst u64 hole_end = extent_map_end(hole_em);\n\n\t\tem = alloc_extent_map();\n\t\tif (!em) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\n\t\tASSERT(hole_em);\n\t\t/*\n\t\t * When btrfs_get_extent can't find anything it returns one\n\t\t * huge hole\n\t\t *\n\t\t * Make sure what it found really fits our range, and adjust to\n\t\t * make sure it is based on the start from the caller\n\t\t */\n\t\tif (hole_end <= start || hole_em->start > end) {\n\t\t       free_extent_map(hole_em);\n\t\t       hole_em = NULL;\n\t\t} else {\n\t\t       hole_start = max(hole_em->start, start);\n\t\t       hole_len = hole_end - hole_start;\n\t\t}\n\n\t\tif (hole_em && delalloc_start > hole_start) {\n\t\t\t/*\n\t\t\t * Our hole starts before our delalloc, so we have to\n\t\t\t * return just the parts of the hole that go until the\n\t\t\t * delalloc starts\n\t\t\t */\n\t\t\tem->len = min(hole_len, delalloc_start - hole_start);\n\t\t\tem->start = hole_start;\n\t\t\tem->orig_start = hole_start;\n\t\t\t/*\n\t\t\t * Don't adjust block start at all, it is fixed at\n\t\t\t * EXTENT_MAP_HOLE\n\t\t\t */\n\t\t\tem->block_start = hole_em->block_start;\n\t\t\tem->block_len = hole_len;\n\t\t\tif (test_bit(EXTENT_FLAG_PREALLOC, &hole_em->flags))\n\t\t\t\tset_bit(EXTENT_FLAG_PREALLOC, &em->flags);\n\t\t} else {\n\t\t\t/*\n\t\t\t * Hole is out of passed range or it starts after\n\t\t\t * delalloc range\n\t\t\t */\n\t\t\tem->start = delalloc_start;\n\t\t\tem->len = delalloc_len;\n\t\t\tem->orig_start = delalloc_start;\n\t\t\tem->block_start = EXTENT_MAP_DELALLOC;\n\t\t\tem->block_len = delalloc_len;\n\t\t}\n\t} else {\n\t\treturn hole_em;\n\t}\nout:\n\n\tfree_extent_map(hole_em);\n\tif (err) {\n\t\tfree_extent_map(em);\n\t\treturn ERR_PTR(err);\n\t}\n\treturn em;\n}\n\nstatic struct extent_map *btrfs_create_dio_extent(struct btrfs_inode *inode,\n\t\t\t\t\t\t  const u64 start,\n\t\t\t\t\t\t  const u64 len,\n\t\t\t\t\t\t  const u64 orig_start,\n\t\t\t\t\t\t  const u64 block_start,\n\t\t\t\t\t\t  const u64 block_len,\n\t\t\t\t\t\t  const u64 orig_block_len,\n\t\t\t\t\t\t  const u64 ram_bytes,\n\t\t\t\t\t\t  const int type)\n{\n\tstruct extent_map *em = NULL;\n\tint ret;\n\n\tif (type != BTRFS_ORDERED_NOCOW) {\n\t\tem = create_io_em(inode, start, len, orig_start, block_start,\n\t\t\t\t  block_len, orig_block_len, ram_bytes,\n\t\t\t\t  BTRFS_COMPRESS_NONE, /* compress_type */\n\t\t\t\t  type);\n\t\tif (IS_ERR(em))\n\t\t\tgoto out;\n\t}\n\tret = btrfs_add_ordered_extent_dio(inode, start, block_start, len,\n\t\t\t\t\t   block_len, type);\n\tif (ret) {\n\t\tif (em) {\n\t\t\tfree_extent_map(em);\n\t\t\tbtrfs_drop_extent_cache(inode, start, start + len - 1, 0);\n\t\t}\n\t\tem = ERR_PTR(ret);\n\t}\n out:\n\n\treturn em;\n}\n\nstatic struct extent_map *btrfs_new_extent_direct(struct btrfs_inode *inode,\n\t\t\t\t\t\t  u64 start, u64 len)\n{\n\tstruct btrfs_root *root = inode->root;\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tstruct extent_map *em;\n\tstruct btrfs_key ins;\n\tu64 alloc_hint;\n\tint ret;\n\n\talloc_hint = get_extent_allocation_hint(inode, start, len);\n\tret = btrfs_reserve_extent(root, len, len, fs_info->sectorsize,\n\t\t\t\t   0, alloc_hint, &ins, 1, 1);\n\tif (ret)\n\t\treturn ERR_PTR(ret);\n\n\tem = btrfs_create_dio_extent(inode, start, ins.offset, start,\n\t\t\t\t     ins.objectid, ins.offset, ins.offset,\n\t\t\t\t     ins.offset, BTRFS_ORDERED_REGULAR);\n\tbtrfs_dec_block_group_reservations(fs_info, ins.objectid);\n\tif (IS_ERR(em))\n\t\tbtrfs_free_reserved_extent(fs_info, ins.objectid, ins.offset,\n\t\t\t\t\t   1);\n\n\treturn em;\n}\n\n/*\n * Check if we can do nocow write into the range [@offset, @offset + @len)\n *\n * @offset:\tFile offset\n * @len:\tThe length to write, will be updated to the nocow writeable\n *\t\trange\n * @orig_start:\t(optional) Return the original file offset of the file extent\n * @orig_len:\t(optional) Return the original on-disk length of the file extent\n * @ram_bytes:\t(optional) Return the ram_bytes of the file extent\n * @strict:\tif true, omit optimizations that might force us into unnecessary\n *\t\tcow. e.g., don't trust generation number.\n *\n * Return:\n * >0\tand update @len if we can do nocow write\n *  0\tif we can't do nocow write\n * <0\tif error happened\n *\n * NOTE: This only checks the file extents, caller is responsible to wait for\n *\t any ordered extents.\n */\nnoinline int can_nocow_extent(struct inode *inode, u64 offset, u64 *len,\n\t\t\t      u64 *orig_start, u64 *orig_block_len,\n\t\t\t      u64 *ram_bytes, bool strict)\n{\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);\n\tstruct btrfs_path *path;\n\tint ret;\n\tstruct extent_buffer *leaf;\n\tstruct btrfs_root *root = BTRFS_I(inode)->root;\n\tstruct extent_io_tree *io_tree = &BTRFS_I(inode)->io_tree;\n\tstruct btrfs_file_extent_item *fi;\n\tstruct btrfs_key key;\n\tu64 disk_bytenr;\n\tu64 backref_offset;\n\tu64 extent_end;\n\tu64 num_bytes;\n\tint slot;\n\tint found_type;\n\tbool nocow = (BTRFS_I(inode)->flags & BTRFS_INODE_NODATACOW);\n\n\tpath = btrfs_alloc_path();\n\tif (!path)\n\t\treturn -ENOMEM;\n\n\tret = btrfs_lookup_file_extent(NULL, root, path,\n\t\t\tbtrfs_ino(BTRFS_I(inode)), offset, 0);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tslot = path->slots[0];\n\tif (ret == 1) {\n\t\tif (slot == 0) {\n\t\t\t/* can't find the item, must cow */\n\t\t\tret = 0;\n\t\t\tgoto out;\n\t\t}\n\t\tslot--;\n\t}\n\tret = 0;\n\tleaf = path->nodes[0];\n\tbtrfs_item_key_to_cpu(leaf, &key, slot);\n\tif (key.objectid != btrfs_ino(BTRFS_I(inode)) ||\n\t    key.type != BTRFS_EXTENT_DATA_KEY) {\n\t\t/* not our file or wrong item type, must cow */\n\t\tgoto out;\n\t}\n\n\tif (key.offset > offset) {\n\t\t/* Wrong offset, must cow */\n\t\tgoto out;\n\t}\n\n\tfi = btrfs_item_ptr(leaf, slot, struct btrfs_file_extent_item);\n\tfound_type = btrfs_file_extent_type(leaf, fi);\n\tif (found_type != BTRFS_FILE_EXTENT_REG &&\n\t    found_type != BTRFS_FILE_EXTENT_PREALLOC) {\n\t\t/* not a regular extent, must cow */\n\t\tgoto out;\n\t}\n\n\tif (!nocow && found_type == BTRFS_FILE_EXTENT_REG)\n\t\tgoto out;\n\n\textent_end = key.offset + btrfs_file_extent_num_bytes(leaf, fi);\n\tif (extent_end <= offset)\n\t\tgoto out;\n\n\tdisk_bytenr = btrfs_file_extent_disk_bytenr(leaf, fi);\n\tif (disk_bytenr == 0)\n\t\tgoto out;\n\n\tif (btrfs_file_extent_compression(leaf, fi) ||\n\t    btrfs_file_extent_encryption(leaf, fi) ||\n\t    btrfs_file_extent_other_encoding(leaf, fi))\n\t\tgoto out;\n\n\t/*\n\t * Do the same check as in btrfs_cross_ref_exist but without the\n\t * unnecessary search.\n\t */\n\tif (!strict &&\n\t    (btrfs_file_extent_generation(leaf, fi) <=\n\t     btrfs_root_last_snapshot(&root->root_item)))\n\t\tgoto out;\n\n\tbackref_offset = btrfs_file_extent_offset(leaf, fi);\n\n\tif (orig_start) {\n\t\t*orig_start = key.offset - backref_offset;\n\t\t*orig_block_len = btrfs_file_extent_disk_num_bytes(leaf, fi);\n\t\t*ram_bytes = btrfs_file_extent_ram_bytes(leaf, fi);\n\t}\n\n\tif (btrfs_extent_readonly(fs_info, disk_bytenr))\n\t\tgoto out;\n\n\tnum_bytes = min(offset + *len, extent_end) - offset;\n\tif (!nocow && found_type == BTRFS_FILE_EXTENT_PREALLOC) {\n\t\tu64 range_end;\n\n\t\trange_end = round_up(offset + num_bytes,\n\t\t\t\t     root->fs_info->sectorsize) - 1;\n\t\tret = test_range_bit(io_tree, offset, range_end,\n\t\t\t\t     EXTENT_DELALLOC, 0, NULL);\n\t\tif (ret) {\n\t\t\tret = -EAGAIN;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tbtrfs_release_path(path);\n\n\t/*\n\t * look for other files referencing this extent, if we\n\t * find any we must cow\n\t */\n\n\tret = btrfs_cross_ref_exist(root, btrfs_ino(BTRFS_I(inode)),\n\t\t\t\t    key.offset - backref_offset, disk_bytenr,\n\t\t\t\t    strict);\n\tif (ret) {\n\t\tret = 0;\n\t\tgoto out;\n\t}\n\n\t/*\n\t * adjust disk_bytenr and num_bytes to cover just the bytes\n\t * in this extent we are about to write.  If there\n\t * are any csums in that range we have to cow in order\n\t * to keep the csums correct\n\t */\n\tdisk_bytenr += backref_offset;\n\tdisk_bytenr += offset - key.offset;\n\tif (csum_exist_in_range(fs_info, disk_bytenr, num_bytes))\n\t\tgoto out;\n\t/*\n\t * all of the above have passed, it is safe to overwrite this extent\n\t * without cow\n\t */\n\t*len = num_bytes;\n\tret = 1;\nout:\n\tbtrfs_free_path(path);\n\treturn ret;\n}\n\nstatic int lock_extent_direct(struct inode *inode, u64 lockstart, u64 lockend,\n\t\t\t      struct extent_state **cached_state, bool writing)\n{\n\tstruct btrfs_ordered_extent *ordered;\n\tint ret = 0;\n\n\twhile (1) {\n\t\tlock_extent_bits(&BTRFS_I(inode)->io_tree, lockstart, lockend,\n\t\t\t\t cached_state);\n\t\t/*\n\t\t * We're concerned with the entire range that we're going to be\n\t\t * doing DIO to, so we need to make sure there's no ordered\n\t\t * extents in this range.\n\t\t */\n\t\tordered = btrfs_lookup_ordered_range(BTRFS_I(inode), lockstart,\n\t\t\t\t\t\t     lockend - lockstart + 1);\n\n\t\t/*\n\t\t * We need to make sure there are no buffered pages in this\n\t\t * range either, we could have raced between the invalidate in\n\t\t * generic_file_direct_write and locking the extent.  The\n\t\t * invalidate needs to happen so that reads after a write do not\n\t\t * get stale data.\n\t\t */\n\t\tif (!ordered &&\n\t\t    (!writing || !filemap_range_has_page(inode->i_mapping,\n\t\t\t\t\t\t\t lockstart, lockend)))\n\t\t\tbreak;\n\n\t\tunlock_extent_cached(&BTRFS_I(inode)->io_tree, lockstart, lockend,\n\t\t\t\t     cached_state);\n\n\t\tif (ordered) {\n\t\t\t/*\n\t\t\t * If we are doing a DIO read and the ordered extent we\n\t\t\t * found is for a buffered write, we can not wait for it\n\t\t\t * to complete and retry, because if we do so we can\n\t\t\t * deadlock with concurrent buffered writes on page\n\t\t\t * locks. This happens only if our DIO read covers more\n\t\t\t * than one extent map, if at this point has already\n\t\t\t * created an ordered extent for a previous extent map\n\t\t\t * and locked its range in the inode's io tree, and a\n\t\t\t * concurrent write against that previous extent map's\n\t\t\t * range and this range started (we unlock the ranges\n\t\t\t * in the io tree only when the bios complete and\n\t\t\t * buffered writes always lock pages before attempting\n\t\t\t * to lock range in the io tree).\n\t\t\t */\n\t\t\tif (writing ||\n\t\t\t    test_bit(BTRFS_ORDERED_DIRECT, &ordered->flags))\n\t\t\t\tbtrfs_start_ordered_extent(ordered, 1);\n\t\t\telse\n\t\t\t\tret = -ENOTBLK;\n\t\t\tbtrfs_put_ordered_extent(ordered);\n\t\t} else {\n\t\t\t/*\n\t\t\t * We could trigger writeback for this range (and wait\n\t\t\t * for it to complete) and then invalidate the pages for\n\t\t\t * this range (through invalidate_inode_pages2_range()),\n\t\t\t * but that can lead us to a deadlock with a concurrent\n\t\t\t * call to readahead (a buffered read or a defrag call\n\t\t\t * triggered a readahead) on a page lock due to an\n\t\t\t * ordered dio extent we created before but did not have\n\t\t\t * yet a corresponding bio submitted (whence it can not\n\t\t\t * complete), which makes readahead wait for that\n\t\t\t * ordered extent to complete while holding a lock on\n\t\t\t * that page.\n\t\t\t */\n\t\t\tret = -ENOTBLK;\n\t\t}\n\n\t\tif (ret)\n\t\t\tbreak;\n\n\t\tcond_resched();\n\t}\n\n\treturn ret;\n}\n\n/* The callers of this must take lock_extent() */\nstatic struct extent_map *create_io_em(struct btrfs_inode *inode, u64 start,\n\t\t\t\t       u64 len, u64 orig_start, u64 block_start,\n\t\t\t\t       u64 block_len, u64 orig_block_len,\n\t\t\t\t       u64 ram_bytes, int compress_type,\n\t\t\t\t       int type)\n{\n\tstruct extent_map_tree *em_tree;\n\tstruct extent_map *em;\n\tint ret;\n\n\tASSERT(type == BTRFS_ORDERED_PREALLOC ||\n\t       type == BTRFS_ORDERED_COMPRESSED ||\n\t       type == BTRFS_ORDERED_NOCOW ||\n\t       type == BTRFS_ORDERED_REGULAR);\n\n\tem_tree = &inode->extent_tree;\n\tem = alloc_extent_map();\n\tif (!em)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tem->start = start;\n\tem->orig_start = orig_start;\n\tem->len = len;\n\tem->block_len = block_len;\n\tem->block_start = block_start;\n\tem->orig_block_len = orig_block_len;\n\tem->ram_bytes = ram_bytes;\n\tem->generation = -1;\n\tset_bit(EXTENT_FLAG_PINNED, &em->flags);\n\tif (type == BTRFS_ORDERED_PREALLOC) {\n\t\tset_bit(EXTENT_FLAG_FILLING, &em->flags);\n\t} else if (type == BTRFS_ORDERED_COMPRESSED) {\n\t\tset_bit(EXTENT_FLAG_COMPRESSED, &em->flags);\n\t\tem->compress_type = compress_type;\n\t}\n\n\tdo {\n\t\tbtrfs_drop_extent_cache(inode, em->start,\n\t\t\t\t\tem->start + em->len - 1, 0);\n\t\twrite_lock(&em_tree->lock);\n\t\tret = add_extent_mapping(em_tree, em, 1);\n\t\twrite_unlock(&em_tree->lock);\n\t\t/*\n\t\t * The caller has taken lock_extent(), who could race with us\n\t\t * to add em?\n\t\t */\n\t} while (ret == -EEXIST);\n\n\tif (ret) {\n\t\tfree_extent_map(em);\n\t\treturn ERR_PTR(ret);\n\t}\n\n\t/* em got 2 refs now, callers needs to do free_extent_map once. */\n\treturn em;\n}\n\n\nstatic int btrfs_get_blocks_direct_write(struct extent_map **map,\n\t\t\t\t\t struct inode *inode,\n\t\t\t\t\t struct btrfs_dio_data *dio_data,\n\t\t\t\t\t u64 start, u64 len)\n{\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);\n\tstruct extent_map *em = *map;\n\tint ret = 0;\n\n\t/*\n\t * We don't allocate a new extent in the following cases\n\t *\n\t * 1) The inode is marked as NODATACOW. In this case we'll just use the\n\t * existing extent.\n\t * 2) The extent is marked as PREALLOC. We're good to go here and can\n\t * just use the extent.\n\t *\n\t */\n\tif (test_bit(EXTENT_FLAG_PREALLOC, &em->flags) ||\n\t    ((BTRFS_I(inode)->flags & BTRFS_INODE_NODATACOW) &&\n\t     em->block_start != EXTENT_MAP_HOLE)) {\n\t\tint type;\n\t\tu64 block_start, orig_start, orig_block_len, ram_bytes;\n\n\t\tif (test_bit(EXTENT_FLAG_PREALLOC, &em->flags))\n\t\t\ttype = BTRFS_ORDERED_PREALLOC;\n\t\telse\n\t\t\ttype = BTRFS_ORDERED_NOCOW;\n\t\tlen = min(len, em->len - (start - em->start));\n\t\tblock_start = em->block_start + (start - em->start);\n\n\t\tif (can_nocow_extent(inode, start, &len, &orig_start,\n\t\t\t\t     &orig_block_len, &ram_bytes, false) == 1 &&\n\t\t    btrfs_inc_nocow_writers(fs_info, block_start)) {\n\t\t\tstruct extent_map *em2;\n\n\t\t\tem2 = btrfs_create_dio_extent(BTRFS_I(inode), start, len,\n\t\t\t\t\t\t      orig_start, block_start,\n\t\t\t\t\t\t      len, orig_block_len,\n\t\t\t\t\t\t      ram_bytes, type);\n\t\t\tbtrfs_dec_nocow_writers(fs_info, block_start);\n\t\t\tif (type == BTRFS_ORDERED_PREALLOC) {\n\t\t\t\tfree_extent_map(em);\n\t\t\t\t*map = em = em2;\n\t\t\t}\n\n\t\t\tif (em2 && IS_ERR(em2)) {\n\t\t\t\tret = PTR_ERR(em2);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\t/*\n\t\t\t * For inode marked NODATACOW or extent marked PREALLOC,\n\t\t\t * use the existing or preallocated extent, so does not\n\t\t\t * need to adjust btrfs_space_info's bytes_may_use.\n\t\t\t */\n\t\t\tbtrfs_free_reserved_data_space_noquota(fs_info, len);\n\t\t\tgoto skip_cow;\n\t\t}\n\t}\n\n\t/* this will cow the extent */\n\tfree_extent_map(em);\n\t*map = em = btrfs_new_extent_direct(BTRFS_I(inode), start, len);\n\tif (IS_ERR(em)) {\n\t\tret = PTR_ERR(em);\n\t\tgoto out;\n\t}\n\n\tlen = min(len, em->len - (start - em->start));\n\nskip_cow:\n\t/*\n\t * Need to update the i_size under the extent lock so buffered\n\t * readers will get the updated i_size when we unlock.\n\t */\n\tif (start + len > i_size_read(inode))\n\t\ti_size_write(inode, start + len);\n\n\tdio_data->reserve -= len;\nout:\n\treturn ret;\n}\n\nstatic int btrfs_dio_iomap_begin(struct inode *inode, loff_t start,\n\t\tloff_t length, unsigned int flags, struct iomap *iomap,\n\t\tstruct iomap *srcmap)\n{\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);\n\tstruct extent_map *em;\n\tstruct extent_state *cached_state = NULL;\n\tstruct btrfs_dio_data *dio_data = NULL;\n\tu64 lockstart, lockend;\n\tconst bool write = !!(flags & IOMAP_WRITE);\n\tint ret = 0;\n\tu64 len = length;\n\tbool unlock_extents = false;\n\n\tif (!write)\n\t\tlen = min_t(u64, len, fs_info->sectorsize);\n\n\tlockstart = start;\n\tlockend = start + len - 1;\n\n\t/*\n\t * The generic stuff only does filemap_write_and_wait_range, which\n\t * isn't enough if we've written compressed pages to this area, so we\n\t * need to flush the dirty pages again to make absolutely sure that any\n\t * outstanding dirty pages are on disk.\n\t */\n\tif (test_bit(BTRFS_INODE_HAS_ASYNC_EXTENT,\n\t\t     &BTRFS_I(inode)->runtime_flags)) {\n\t\tret = filemap_fdatawrite_range(inode->i_mapping, start,\n\t\t\t\t\t       start + length - 1);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tdio_data = kzalloc(sizeof(*dio_data), GFP_NOFS);\n\tif (!dio_data)\n\t\treturn -ENOMEM;\n\n\tdio_data->length = length;\n\tif (write) {\n\t\tdio_data->reserve = round_up(length, fs_info->sectorsize);\n\t\tret = btrfs_delalloc_reserve_space(BTRFS_I(inode),\n\t\t\t\t&dio_data->data_reserved,\n\t\t\t\tstart, dio_data->reserve);\n\t\tif (ret) {\n\t\t\textent_changeset_free(dio_data->data_reserved);\n\t\t\tkfree(dio_data);\n\t\t\treturn ret;\n\t\t}\n\t}\n\tiomap->private = dio_data;\n\n\n\t/*\n\t * If this errors out it's because we couldn't invalidate pagecache for\n\t * this range and we need to fallback to buffered.\n\t */\n\tif (lock_extent_direct(inode, lockstart, lockend, &cached_state, write)) {\n\t\tret = -ENOTBLK;\n\t\tgoto err;\n\t}\n\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, start, len);\n\tif (IS_ERR(em)) {\n\t\tret = PTR_ERR(em);\n\t\tgoto unlock_err;\n\t}\n\n\t/*\n\t * Ok for INLINE and COMPRESSED extents we need to fallback on buffered\n\t * io.  INLINE is special, and we could probably kludge it in here, but\n\t * it's still buffered so for safety lets just fall back to the generic\n\t * buffered path.\n\t *\n\t * For COMPRESSED we _have_ to read the entire extent in so we can\n\t * decompress it, so there will be buffering required no matter what we\n\t * do, so go ahead and fallback to buffered.\n\t *\n\t * We return -ENOTBLK because that's what makes DIO go ahead and go back\n\t * to buffered IO.  Don't blame me, this is the price we pay for using\n\t * the generic code.\n\t */\n\tif (test_bit(EXTENT_FLAG_COMPRESSED, &em->flags) ||\n\t    em->block_start == EXTENT_MAP_INLINE) {\n\t\tfree_extent_map(em);\n\t\tret = -ENOTBLK;\n\t\tgoto unlock_err;\n\t}\n\n\tlen = min(len, em->len - (start - em->start));\n\tif (write) {\n\t\tret = btrfs_get_blocks_direct_write(&em, inode, dio_data,\n\t\t\t\t\t\t    start, len);\n\t\tif (ret < 0)\n\t\t\tgoto unlock_err;\n\t\tunlock_extents = true;\n\t\t/* Recalc len in case the new em is smaller than requested */\n\t\tlen = min(len, em->len - (start - em->start));\n\t} else {\n\t\t/*\n\t\t * We need to unlock only the end area that we aren't using.\n\t\t * The rest is going to be unlocked by the endio routine.\n\t\t */\n\t\tlockstart = start + len;\n\t\tif (lockstart < lockend)\n\t\t\tunlock_extents = true;\n\t}\n\n\tif (unlock_extents)\n\t\tunlock_extent_cached(&BTRFS_I(inode)->io_tree,\n\t\t\t\t     lockstart, lockend, &cached_state);\n\telse\n\t\tfree_extent_state(cached_state);\n\n\t/*\n\t * Translate extent map information to iomap.\n\t * We trim the extents (and move the addr) even though iomap code does\n\t * that, since we have locked only the parts we are performing I/O in.\n\t */\n\tif ((em->block_start == EXTENT_MAP_HOLE) ||\n\t    (test_bit(EXTENT_FLAG_PREALLOC, &em->flags) && !write)) {\n\t\tiomap->addr = IOMAP_NULL_ADDR;\n\t\tiomap->type = IOMAP_HOLE;\n\t} else {\n\t\tiomap->addr = em->block_start + (start - em->start);\n\t\tiomap->type = IOMAP_MAPPED;\n\t}\n\tiomap->offset = start;\n\tiomap->bdev = fs_info->fs_devices->latest_bdev;\n\tiomap->length = len;\n\n\tif (write && btrfs_use_zone_append(BTRFS_I(inode), em))\n\t\tiomap->flags |= IOMAP_F_ZONE_APPEND;\n\n\tfree_extent_map(em);\n\n\treturn 0;\n\nunlock_err:\n\tunlock_extent_cached(&BTRFS_I(inode)->io_tree, lockstart, lockend,\n\t\t\t     &cached_state);\nerr:\n\tif (dio_data) {\n\t\tbtrfs_delalloc_release_space(BTRFS_I(inode),\n\t\t\t\tdio_data->data_reserved, start,\n\t\t\t\tdio_data->reserve, true);\n\t\tbtrfs_delalloc_release_extents(BTRFS_I(inode), dio_data->reserve);\n\t\textent_changeset_free(dio_data->data_reserved);\n\t\tkfree(dio_data);\n\t}\n\treturn ret;\n}\n\nstatic int btrfs_dio_iomap_end(struct inode *inode, loff_t pos, loff_t length,\n\t\tssize_t written, unsigned int flags, struct iomap *iomap)\n{\n\tint ret = 0;\n\tstruct btrfs_dio_data *dio_data = iomap->private;\n\tsize_t submitted = dio_data->submitted;\n\tconst bool write = !!(flags & IOMAP_WRITE);\n\n\tif (!write && (iomap->type == IOMAP_HOLE)) {\n\t\t/* If reading from a hole, unlock and return */\n\t\tunlock_extent(&BTRFS_I(inode)->io_tree, pos, pos + length - 1);\n\t\tgoto out;\n\t}\n\n\tif (submitted < length) {\n\t\tpos += submitted;\n\t\tlength -= submitted;\n\t\tif (write)\n\t\t\t__endio_write_update_ordered(BTRFS_I(inode), pos,\n\t\t\t\t\tlength, false);\n\t\telse\n\t\t\tunlock_extent(&BTRFS_I(inode)->io_tree, pos,\n\t\t\t\t      pos + length - 1);\n\t\tret = -ENOTBLK;\n\t}\n\n\tif (write) {\n\t\tif (dio_data->reserve)\n\t\t\tbtrfs_delalloc_release_space(BTRFS_I(inode),\n\t\t\t\t\tdio_data->data_reserved, pos,\n\t\t\t\t\tdio_data->reserve, true);\n\t\tbtrfs_delalloc_release_extents(BTRFS_I(inode), dio_data->length);\n\t\textent_changeset_free(dio_data->data_reserved);\n\t}\nout:\n\tkfree(dio_data);\n\tiomap->private = NULL;\n\n\treturn ret;\n}\n\nstatic void btrfs_dio_private_put(struct btrfs_dio_private *dip)\n{\n\t/*\n\t * This implies a barrier so that stores to dio_bio->bi_status before\n\t * this and loads of dio_bio->bi_status after this are fully ordered.\n\t */\n\tif (!refcount_dec_and_test(&dip->refs))\n\t\treturn;\n\n\tif (btrfs_op(dip->dio_bio) == BTRFS_MAP_WRITE) {\n\t\t__endio_write_update_ordered(BTRFS_I(dip->inode),\n\t\t\t\t\t     dip->logical_offset,\n\t\t\t\t\t     dip->bytes,\n\t\t\t\t\t     !dip->dio_bio->bi_status);\n\t} else {\n\t\tunlock_extent(&BTRFS_I(dip->inode)->io_tree,\n\t\t\t      dip->logical_offset,\n\t\t\t      dip->logical_offset + dip->bytes - 1);\n\t}\n\n\tbio_endio(dip->dio_bio);\n\tkfree(dip);\n}\n\nstatic blk_status_t submit_dio_repair_bio(struct inode *inode, struct bio *bio,\n\t\t\t\t\t  int mirror_num,\n\t\t\t\t\t  unsigned long bio_flags)\n{\n\tstruct btrfs_dio_private *dip = bio->bi_private;\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);\n\tblk_status_t ret;\n\n\tBUG_ON(bio_op(bio) == REQ_OP_WRITE);\n\n\tret = btrfs_bio_wq_end_io(fs_info, bio, BTRFS_WQ_ENDIO_DATA);\n\tif (ret)\n\t\treturn ret;\n\n\trefcount_inc(&dip->refs);\n\tret = btrfs_map_bio(fs_info, bio, mirror_num);\n\tif (ret)\n\t\trefcount_dec(&dip->refs);\n\treturn ret;\n}\n\nstatic blk_status_t btrfs_check_read_dio_bio(struct inode *inode,\n\t\t\t\t\t     struct btrfs_io_bio *io_bio,\n\t\t\t\t\t     const bool uptodate)\n{\n\tstruct btrfs_fs_info *fs_info = BTRFS_I(inode)->root->fs_info;\n\tconst u32 sectorsize = fs_info->sectorsize;\n\tstruct extent_io_tree *failure_tree = &BTRFS_I(inode)->io_failure_tree;\n\tstruct extent_io_tree *io_tree = &BTRFS_I(inode)->io_tree;\n\tconst bool csum = !(BTRFS_I(inode)->flags & BTRFS_INODE_NODATASUM);\n\tstruct bio_vec bvec;\n\tstruct bvec_iter iter;\n\tu64 start = io_bio->logical;\n\tu32 bio_offset = 0;\n\tblk_status_t err = BLK_STS_OK;\n\n\t__bio_for_each_segment(bvec, &io_bio->bio, iter, io_bio->iter) {\n\t\tunsigned int i, nr_sectors, pgoff;\n\n\t\tnr_sectors = BTRFS_BYTES_TO_BLKS(fs_info, bvec.bv_len);\n\t\tpgoff = bvec.bv_offset;\n\t\tfor (i = 0; i < nr_sectors; i++) {\n\t\t\tASSERT(pgoff < PAGE_SIZE);\n\t\t\tif (uptodate &&\n\t\t\t    (!csum || !check_data_csum(inode, io_bio,\n\t\t\t\t\tbio_offset, bvec.bv_page, pgoff))) {\n\t\t\t\tclean_io_failure(fs_info, failure_tree, io_tree,\n\t\t\t\t\t\t start, bvec.bv_page,\n\t\t\t\t\t\t btrfs_ino(BTRFS_I(inode)),\n\t\t\t\t\t\t pgoff);\n\t\t\t} else {\n\t\t\t\tblk_status_t status;\n\n\t\t\t\tASSERT((start - io_bio->logical) < UINT_MAX);\n\t\t\t\tstatus = btrfs_submit_read_repair(inode,\n\t\t\t\t\t\t\t&io_bio->bio,\n\t\t\t\t\t\t\tstart - io_bio->logical,\n\t\t\t\t\t\t\tbvec.bv_page, pgoff,\n\t\t\t\t\t\t\tstart,\n\t\t\t\t\t\t\tstart + sectorsize - 1,\n\t\t\t\t\t\t\tio_bio->mirror_num,\n\t\t\t\t\t\t\tsubmit_dio_repair_bio);\n\t\t\t\tif (status)\n\t\t\t\t\terr = status;\n\t\t\t}\n\t\t\tstart += sectorsize;\n\t\t\tASSERT(bio_offset + sectorsize > bio_offset);\n\t\t\tbio_offset += sectorsize;\n\t\t\tpgoff += sectorsize;\n\t\t}\n\t}\n\treturn err;\n}\n\nstatic void __endio_write_update_ordered(struct btrfs_inode *inode,\n\t\t\t\t\t const u64 offset, const u64 bytes,\n\t\t\t\t\t const bool uptodate)\n{\n\tstruct btrfs_fs_info *fs_info = inode->root->fs_info;\n\tstruct btrfs_ordered_extent *ordered = NULL;\n\tstruct btrfs_workqueue *wq;\n\tu64 ordered_offset = offset;\n\tu64 ordered_bytes = bytes;\n\tu64 last_offset;\n\n\tif (btrfs_is_free_space_inode(inode))\n\t\twq = fs_info->endio_freespace_worker;\n\telse\n\t\twq = fs_info->endio_write_workers;\n\n\twhile (ordered_offset < offset + bytes) {\n\t\tlast_offset = ordered_offset;\n\t\tif (btrfs_dec_test_first_ordered_pending(inode, &ordered,\n\t\t\t\t\t\t\t &ordered_offset,\n\t\t\t\t\t\t\t ordered_bytes,\n\t\t\t\t\t\t\t uptodate)) {\n\t\t\tbtrfs_init_work(&ordered->work, finish_ordered_fn, NULL,\n\t\t\t\t\tNULL);\n\t\t\tbtrfs_queue_work(wq, &ordered->work);\n\t\t}\n\n\t\t/* No ordered extent found in the range, exit */\n\t\tif (ordered_offset == last_offset)\n\t\t\treturn;\n\t\t/*\n\t\t * Our bio might span multiple ordered extents. In this case\n\t\t * we keep going until we have accounted the whole dio.\n\t\t */\n\t\tif (ordered_offset < offset + bytes) {\n\t\t\tordered_bytes = offset + bytes - ordered_offset;\n\t\t\tordered = NULL;\n\t\t}\n\t}\n}\n\nstatic blk_status_t btrfs_submit_bio_start_direct_io(struct inode *inode,\n\t\t\t\t\t\t     struct bio *bio,\n\t\t\t\t\t\t     u64 dio_file_offset)\n{\n\treturn btrfs_csum_one_bio(BTRFS_I(inode), bio, dio_file_offset, 1);\n}\n\nstatic void btrfs_end_dio_bio(struct bio *bio)\n{\n\tstruct btrfs_dio_private *dip = bio->bi_private;\n\tblk_status_t err = bio->bi_status;\n\n\tif (err)\n\t\tbtrfs_warn(BTRFS_I(dip->inode)->root->fs_info,\n\t\t\t   \"direct IO failed ino %llu rw %d,%u sector %#Lx len %u err no %d\",\n\t\t\t   btrfs_ino(BTRFS_I(dip->inode)), bio_op(bio),\n\t\t\t   bio->bi_opf, bio->bi_iter.bi_sector,\n\t\t\t   bio->bi_iter.bi_size, err);\n\n\tif (bio_op(bio) == REQ_OP_READ) {\n\t\terr = btrfs_check_read_dio_bio(dip->inode, btrfs_io_bio(bio),\n\t\t\t\t\t       !err);\n\t}\n\n\tif (err)\n\t\tdip->dio_bio->bi_status = err;\n\n\tbtrfs_record_physical_zoned(dip->inode, dip->logical_offset, bio);\n\n\tbio_put(bio);\n\tbtrfs_dio_private_put(dip);\n}\n\nstatic inline blk_status_t btrfs_submit_dio_bio(struct bio *bio,\n\t\tstruct inode *inode, u64 file_offset, int async_submit)\n{\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);\n\tstruct btrfs_dio_private *dip = bio->bi_private;\n\tbool write = btrfs_op(bio) == BTRFS_MAP_WRITE;\n\tblk_status_t ret;\n\n\t/* Check btrfs_submit_bio_hook() for rules about async submit. */\n\tif (async_submit)\n\t\tasync_submit = !atomic_read(&BTRFS_I(inode)->sync_writers);\n\n\tif (!write) {\n\t\tret = btrfs_bio_wq_end_io(fs_info, bio, BTRFS_WQ_ENDIO_DATA);\n\t\tif (ret)\n\t\t\tgoto err;\n\t}\n\n\tif (BTRFS_I(inode)->flags & BTRFS_INODE_NODATASUM)\n\t\tgoto map;\n\n\tif (write && async_submit) {\n\t\tret = btrfs_wq_submit_bio(inode, bio, 0, 0, file_offset,\n\t\t\t\t\t  btrfs_submit_bio_start_direct_io);\n\t\tgoto err;\n\t} else if (write) {\n\t\t/*\n\t\t * If we aren't doing async submit, calculate the csum of the\n\t\t * bio now.\n\t\t */\n\t\tret = btrfs_csum_one_bio(BTRFS_I(inode), bio, file_offset, 1);\n\t\tif (ret)\n\t\t\tgoto err;\n\t} else {\n\t\tu64 csum_offset;\n\n\t\tcsum_offset = file_offset - dip->logical_offset;\n\t\tcsum_offset >>= fs_info->sectorsize_bits;\n\t\tcsum_offset *= fs_info->csum_size;\n\t\tbtrfs_io_bio(bio)->csum = dip->csums + csum_offset;\n\t}\nmap:\n\tret = btrfs_map_bio(fs_info, bio, 0);\nerr:\n\treturn ret;\n}\n\n/*\n * If this succeeds, the btrfs_dio_private is responsible for cleaning up locked\n * or ordered extents whether or not we submit any bios.\n */\nstatic struct btrfs_dio_private *btrfs_create_dio_private(struct bio *dio_bio,\n\t\t\t\t\t\t\t  struct inode *inode,\n\t\t\t\t\t\t\t  loff_t file_offset)\n{\n\tconst bool write = (btrfs_op(dio_bio) == BTRFS_MAP_WRITE);\n\tconst bool csum = !(BTRFS_I(inode)->flags & BTRFS_INODE_NODATASUM);\n\tsize_t dip_size;\n\tstruct btrfs_dio_private *dip;\n\n\tdip_size = sizeof(*dip);\n\tif (!write && csum) {\n\t\tstruct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);\n\t\tsize_t nblocks;\n\n\t\tnblocks = dio_bio->bi_iter.bi_size >> fs_info->sectorsize_bits;\n\t\tdip_size += fs_info->csum_size * nblocks;\n\t}\n\n\tdip = kzalloc(dip_size, GFP_NOFS);\n\tif (!dip)\n\t\treturn NULL;\n\n\tdip->inode = inode;\n\tdip->logical_offset = file_offset;\n\tdip->bytes = dio_bio->bi_iter.bi_size;\n\tdip->disk_bytenr = dio_bio->bi_iter.bi_sector << 9;\n\tdip->dio_bio = dio_bio;\n\trefcount_set(&dip->refs, 1);\n\treturn dip;\n}\n\nstatic blk_qc_t btrfs_submit_direct(struct inode *inode, struct iomap *iomap,\n\t\tstruct bio *dio_bio, loff_t file_offset)\n{\n\tconst bool write = (btrfs_op(dio_bio) == BTRFS_MAP_WRITE);\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);\n\tconst bool raid56 = (btrfs_data_alloc_profile(fs_info) &\n\t\t\t     BTRFS_BLOCK_GROUP_RAID56_MASK);\n\tstruct btrfs_dio_private *dip;\n\tstruct bio *bio;\n\tu64 start_sector;\n\tint async_submit = 0;\n\tu64 submit_len;\n\tint clone_offset = 0;\n\tint clone_len;\n\tu64 logical;\n\tint ret;\n\tblk_status_t status;\n\tstruct btrfs_io_geometry geom;\n\tstruct btrfs_dio_data *dio_data = iomap->private;\n\tstruct extent_map *em = NULL;\n\n\tdip = btrfs_create_dio_private(dio_bio, inode, file_offset);\n\tif (!dip) {\n\t\tif (!write) {\n\t\t\tunlock_extent(&BTRFS_I(inode)->io_tree, file_offset,\n\t\t\t\tfile_offset + dio_bio->bi_iter.bi_size - 1);\n\t\t}\n\t\tdio_bio->bi_status = BLK_STS_RESOURCE;\n\t\tbio_endio(dio_bio);\n\t\treturn BLK_QC_T_NONE;\n\t}\n\n\tif (!write) {\n\t\t/*\n\t\t * Load the csums up front to reduce csum tree searches and\n\t\t * contention when submitting bios.\n\t\t *\n\t\t * If we have csums disabled this will do nothing.\n\t\t */\n\t\tstatus = btrfs_lookup_bio_sums(inode, dio_bio, dip->csums);\n\t\tif (status != BLK_STS_OK)\n\t\t\tgoto out_err;\n\t}\n\n\tstart_sector = dio_bio->bi_iter.bi_sector;\n\tsubmit_len = dio_bio->bi_iter.bi_size;\n\n\tdo {\n\t\tlogical = start_sector << 9;\n\t\tem = btrfs_get_chunk_map(fs_info, logical, submit_len);\n\t\tif (IS_ERR(em)) {\n\t\t\tstatus = errno_to_blk_status(PTR_ERR(em));\n\t\t\tem = NULL;\n\t\t\tgoto out_err_em;\n\t\t}\n\t\tret = btrfs_get_io_geometry(fs_info, em, btrfs_op(dio_bio),\n\t\t\t\t\t    logical, submit_len, &geom);\n\t\tif (ret) {\n\t\t\tstatus = errno_to_blk_status(ret);\n\t\t\tgoto out_err_em;\n\t\t}\n\t\tASSERT(geom.len <= INT_MAX);\n\n\t\tclone_len = min_t(int, submit_len, geom.len);\n\n\t\t/*\n\t\t * This will never fail as it's passing GPF_NOFS and\n\t\t * the allocation is backed by btrfs_bioset.\n\t\t */\n\t\tbio = btrfs_bio_clone_partial(dio_bio, clone_offset, clone_len);\n\t\tbio->bi_private = dip;\n\t\tbio->bi_end_io = btrfs_end_dio_bio;\n\t\tbtrfs_io_bio(bio)->logical = file_offset;\n\n\t\tWARN_ON_ONCE(write && btrfs_is_zoned(fs_info) &&\n\t\t\t     fs_info->max_zone_append_size &&\n\t\t\t     bio_op(bio) != REQ_OP_ZONE_APPEND);\n\n\t\tif (bio_op(bio) == REQ_OP_ZONE_APPEND) {\n\t\t\tstatus = extract_ordered_extent(BTRFS_I(inode), bio,\n\t\t\t\t\t\t\tfile_offset);\n\t\t\tif (status) {\n\t\t\t\tbio_put(bio);\n\t\t\t\tgoto out_err;\n\t\t\t}\n\t\t}\n\n\t\tASSERT(submit_len >= clone_len);\n\t\tsubmit_len -= clone_len;\n\n\t\t/*\n\t\t * Increase the count before we submit the bio so we know\n\t\t * the end IO handler won't happen before we increase the\n\t\t * count. Otherwise, the dip might get freed before we're\n\t\t * done setting it up.\n\t\t *\n\t\t * We transfer the initial reference to the last bio, so we\n\t\t * don't need to increment the reference count for the last one.\n\t\t */\n\t\tif (submit_len > 0) {\n\t\t\trefcount_inc(&dip->refs);\n\t\t\t/*\n\t\t\t * If we are submitting more than one bio, submit them\n\t\t\t * all asynchronously. The exception is RAID 5 or 6, as\n\t\t\t * asynchronous checksums make it difficult to collect\n\t\t\t * full stripe writes.\n\t\t\t */\n\t\t\tif (!raid56)\n\t\t\t\tasync_submit = 1;\n\t\t}\n\n\t\tstatus = btrfs_submit_dio_bio(bio, inode, file_offset,\n\t\t\t\t\t\tasync_submit);\n\t\tif (status) {\n\t\t\tbio_put(bio);\n\t\t\tif (submit_len > 0)\n\t\t\t\trefcount_dec(&dip->refs);\n\t\t\tgoto out_err_em;\n\t\t}\n\n\t\tdio_data->submitted += clone_len;\n\t\tclone_offset += clone_len;\n\t\tstart_sector += clone_len >> 9;\n\t\tfile_offset += clone_len;\n\n\t\tfree_extent_map(em);\n\t} while (submit_len > 0);\n\treturn BLK_QC_T_NONE;\n\nout_err_em:\n\tfree_extent_map(em);\nout_err:\n\tdip->dio_bio->bi_status = status;\n\tbtrfs_dio_private_put(dip);\n\n\treturn BLK_QC_T_NONE;\n}\n\nconst struct iomap_ops btrfs_dio_iomap_ops = {\n\t.iomap_begin            = btrfs_dio_iomap_begin,\n\t.iomap_end              = btrfs_dio_iomap_end,\n};\n\nconst struct iomap_dio_ops btrfs_dio_ops = {\n\t.submit_io\t\t= btrfs_submit_direct,\n};\n\nstatic int btrfs_fiemap(struct inode *inode, struct fiemap_extent_info *fieinfo,\n\t\t\tu64 start, u64 len)\n{\n\tint\tret;\n\n\tret = fiemap_prep(inode, fieinfo, start, &len, 0);\n\tif (ret)\n\t\treturn ret;\n\n\treturn extent_fiemap(BTRFS_I(inode), fieinfo, start, len);\n}\n\nint btrfs_readpage(struct file *file, struct page *page)\n{\n\tstruct btrfs_inode *inode = BTRFS_I(page->mapping->host);\n\tu64 start = page_offset(page);\n\tu64 end = start + PAGE_SIZE - 1;\n\tunsigned long bio_flags = 0;\n\tstruct bio *bio = NULL;\n\tint ret;\n\n\tbtrfs_lock_and_flush_ordered_range(inode, start, end, NULL);\n\n\tret = btrfs_do_readpage(page, NULL, &bio, &bio_flags, 0, NULL);\n\tif (bio)\n\t\tret = submit_one_bio(bio, 0, bio_flags);\n\treturn ret;\n}\n\nstatic int btrfs_writepage(struct page *page, struct writeback_control *wbc)\n{\n\tstruct inode *inode = page->mapping->host;\n\tint ret;\n\n\tif (current->flags & PF_MEMALLOC) {\n\t\tredirty_page_for_writepage(wbc, page);\n\t\tunlock_page(page);\n\t\treturn 0;\n\t}\n\n\t/*\n\t * If we are under memory pressure we will call this directly from the\n\t * VM, we need to make sure we have the inode referenced for the ordered\n\t * extent.  If not just return like we didn't do anything.\n\t */\n\tif (!igrab(inode)) {\n\t\tredirty_page_for_writepage(wbc, page);\n\t\treturn AOP_WRITEPAGE_ACTIVATE;\n\t}\n\tret = extent_write_full_page(page, wbc);\n\tbtrfs_add_delayed_iput(inode);\n\treturn ret;\n}\n\nstatic int btrfs_writepages(struct address_space *mapping,\n\t\t\t    struct writeback_control *wbc)\n{\n\treturn extent_writepages(mapping, wbc);\n}\n\nstatic void btrfs_readahead(struct readahead_control *rac)\n{\n\textent_readahead(rac);\n}\n\nstatic int __btrfs_releasepage(struct page *page, gfp_t gfp_flags)\n{\n\tint ret = try_release_extent_mapping(page, gfp_flags);\n\tif (ret == 1)\n\t\tclear_page_extent_mapped(page);\n\treturn ret;\n}\n\nstatic int btrfs_releasepage(struct page *page, gfp_t gfp_flags)\n{\n\tif (PageWriteback(page) || PageDirty(page))\n\t\treturn 0;\n\treturn __btrfs_releasepage(page, gfp_flags);\n}\n\n#ifdef CONFIG_MIGRATION\nstatic int btrfs_migratepage(struct address_space *mapping,\n\t\t\t     struct page *newpage, struct page *page,\n\t\t\t     enum migrate_mode mode)\n{\n\tint ret;\n\n\tret = migrate_page_move_mapping(mapping, newpage, page, 0);\n\tif (ret != MIGRATEPAGE_SUCCESS)\n\t\treturn ret;\n\n\tif (page_has_private(page))\n\t\tattach_page_private(newpage, detach_page_private(page));\n\n\tif (PagePrivate2(page)) {\n\t\tClearPagePrivate2(page);\n\t\tSetPagePrivate2(newpage);\n\t}\n\n\tif (mode != MIGRATE_SYNC_NO_COPY)\n\t\tmigrate_page_copy(newpage, page);\n\telse\n\t\tmigrate_page_states(newpage, page);\n\treturn MIGRATEPAGE_SUCCESS;\n}\n#endif\n\nstatic void btrfs_invalidatepage(struct page *page, unsigned int offset,\n\t\t\t\t unsigned int length)\n{\n\tstruct btrfs_inode *inode = BTRFS_I(page->mapping->host);\n\tstruct extent_io_tree *tree = &inode->io_tree;\n\tstruct btrfs_ordered_extent *ordered;\n\tstruct extent_state *cached_state = NULL;\n\tu64 page_start = page_offset(page);\n\tu64 page_end = page_start + PAGE_SIZE - 1;\n\tu64 start;\n\tu64 end;\n\tint inode_evicting = inode->vfs_inode.i_state & I_FREEING;\n\tbool found_ordered = false;\n\tbool completed_ordered = false;\n\n\t/*\n\t * we have the page locked, so new writeback can't start,\n\t * and the dirty bit won't be cleared while we are here.\n\t *\n\t * Wait for IO on this page so that we can safely clear\n\t * the PagePrivate2 bit and do ordered accounting\n\t */\n\twait_on_page_writeback(page);\n\n\tif (offset) {\n\t\tbtrfs_releasepage(page, GFP_NOFS);\n\t\treturn;\n\t}\n\n\tif (!inode_evicting)\n\t\tlock_extent_bits(tree, page_start, page_end, &cached_state);\n\n\tstart = page_start;\nagain:\n\tordered = btrfs_lookup_ordered_range(inode, start, page_end - start + 1);\n\tif (ordered) {\n\t\tfound_ordered = true;\n\t\tend = min(page_end,\n\t\t\t  ordered->file_offset + ordered->num_bytes - 1);\n\t\t/*\n\t\t * IO on this page will never be started, so we need to account\n\t\t * for any ordered extents now. Don't clear EXTENT_DELALLOC_NEW\n\t\t * here, must leave that up for the ordered extent completion.\n\t\t */\n\t\tif (!inode_evicting)\n\t\t\tclear_extent_bit(tree, start, end,\n\t\t\t\t\t EXTENT_DELALLOC |\n\t\t\t\t\t EXTENT_LOCKED | EXTENT_DO_ACCOUNTING |\n\t\t\t\t\t EXTENT_DEFRAG, 1, 0, &cached_state);\n\t\t/*\n\t\t * whoever cleared the private bit is responsible\n\t\t * for the finish_ordered_io\n\t\t */\n\t\tif (TestClearPagePrivate2(page)) {\n\t\t\tstruct btrfs_ordered_inode_tree *tree;\n\t\t\tu64 new_len;\n\n\t\t\ttree = &inode->ordered_tree;\n\n\t\t\tspin_lock_irq(&tree->lock);\n\t\t\tset_bit(BTRFS_ORDERED_TRUNCATED, &ordered->flags);\n\t\t\tnew_len = start - ordered->file_offset;\n\t\t\tif (new_len < ordered->truncated_len)\n\t\t\t\tordered->truncated_len = new_len;\n\t\t\tspin_unlock_irq(&tree->lock);\n\n\t\t\tif (btrfs_dec_test_ordered_pending(inode, &ordered,\n\t\t\t\t\t\t\t   start,\n\t\t\t\t\t\t\t   end - start + 1, 1)) {\n\t\t\t\tbtrfs_finish_ordered_io(ordered);\n\t\t\t\tcompleted_ordered = true;\n\t\t\t}\n\t\t}\n\t\tbtrfs_put_ordered_extent(ordered);\n\t\tif (!inode_evicting) {\n\t\t\tcached_state = NULL;\n\t\t\tlock_extent_bits(tree, start, end,\n\t\t\t\t\t &cached_state);\n\t\t}\n\n\t\tstart = end + 1;\n\t\tif (start < page_end)\n\t\t\tgoto again;\n\t}\n\n\t/*\n\t * Qgroup reserved space handler\n\t * Page here will be either\n\t * 1) Already written to disk or ordered extent already submitted\n\t *    Then its QGROUP_RESERVED bit in io_tree is already cleaned.\n\t *    Qgroup will be handled by its qgroup_record then.\n\t *    btrfs_qgroup_free_data() call will do nothing here.\n\t *\n\t * 2) Not written to disk yet\n\t *    Then btrfs_qgroup_free_data() call will clear the QGROUP_RESERVED\n\t *    bit of its io_tree, and free the qgroup reserved data space.\n\t *    Since the IO will never happen for this page.\n\t */\n\tbtrfs_qgroup_free_data(inode, NULL, page_start, PAGE_SIZE);\n\tif (!inode_evicting) {\n\t\tbool delete = true;\n\n\t\t/*\n\t\t * If there's an ordered extent for this range and we have not\n\t\t * finished it ourselves, we must leave EXTENT_DELALLOC_NEW set\n\t\t * in the range for the ordered extent completion. We must also\n\t\t * not delete the range, otherwise we would lose that bit (and\n\t\t * any other bits set in the range). Make sure EXTENT_UPTODATE\n\t\t * is cleared if we don't delete, otherwise it can lead to\n\t\t * corruptions if the i_size is extented later.\n\t\t */\n\t\tif (found_ordered && !completed_ordered)\n\t\t\tdelete = false;\n\t\tclear_extent_bit(tree, page_start, page_end, EXTENT_LOCKED |\n\t\t\t\t EXTENT_DELALLOC | EXTENT_UPTODATE |\n\t\t\t\t EXTENT_DO_ACCOUNTING | EXTENT_DEFRAG, 1,\n\t\t\t\t delete, &cached_state);\n\n\t\t__btrfs_releasepage(page, GFP_NOFS);\n\t}\n\n\tClearPageChecked(page);\n\tclear_page_extent_mapped(page);\n}\n\n/*\n * btrfs_page_mkwrite() is not allowed to change the file size as it gets\n * called from a page fault handler when a page is first dirtied. Hence we must\n * be careful to check for EOF conditions here. We set the page up correctly\n * for a written page which means we get ENOSPC checking when writing into\n * holes and correct delalloc and unwritten extent mapping on filesystems that\n * support these features.\n *\n * We are not allowed to take the i_mutex here so we have to play games to\n * protect against truncate races as the page could now be beyond EOF.  Because\n * truncate_setsize() writes the inode size before removing pages, once we have\n * the page lock we can determine safely if the page is beyond EOF. If it is not\n * beyond EOF, then the page is guaranteed safe against truncation until we\n * unlock the page.\n */\nvm_fault_t btrfs_page_mkwrite(struct vm_fault *vmf)\n{\n\tstruct page *page = vmf->page;\n\tstruct inode *inode = file_inode(vmf->vma->vm_file);\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);\n\tstruct extent_io_tree *io_tree = &BTRFS_I(inode)->io_tree;\n\tstruct btrfs_ordered_extent *ordered;\n\tstruct extent_state *cached_state = NULL;\n\tstruct extent_changeset *data_reserved = NULL;\n\tunsigned long zero_start;\n\tloff_t size;\n\tvm_fault_t ret;\n\tint ret2;\n\tint reserved = 0;\n\tu64 reserved_space;\n\tu64 page_start;\n\tu64 page_end;\n\tu64 end;\n\n\treserved_space = PAGE_SIZE;\n\n\tsb_start_pagefault(inode->i_sb);\n\tpage_start = page_offset(page);\n\tpage_end = page_start + PAGE_SIZE - 1;\n\tend = page_end;\n\n\t/*\n\t * Reserving delalloc space after obtaining the page lock can lead to\n\t * deadlock. For example, if a dirty page is locked by this function\n\t * and the call to btrfs_delalloc_reserve_space() ends up triggering\n\t * dirty page write out, then the btrfs_writepage() function could\n\t * end up waiting indefinitely to get a lock on the page currently\n\t * being processed by btrfs_page_mkwrite() function.\n\t */\n\tret2 = btrfs_delalloc_reserve_space(BTRFS_I(inode), &data_reserved,\n\t\t\t\t\t    page_start, reserved_space);\n\tif (!ret2) {\n\t\tret2 = file_update_time(vmf->vma->vm_file);\n\t\treserved = 1;\n\t}\n\tif (ret2) {\n\t\tret = vmf_error(ret2);\n\t\tif (reserved)\n\t\t\tgoto out;\n\t\tgoto out_noreserve;\n\t}\n\n\tret = VM_FAULT_NOPAGE; /* make the VM retry the fault */\nagain:\n\tlock_page(page);\n\tsize = i_size_read(inode);\n\n\tif ((page->mapping != inode->i_mapping) ||\n\t    (page_start >= size)) {\n\t\t/* page got truncated out from underneath us */\n\t\tgoto out_unlock;\n\t}\n\twait_on_page_writeback(page);\n\n\tlock_extent_bits(io_tree, page_start, page_end, &cached_state);\n\tret2 = set_page_extent_mapped(page);\n\tif (ret2 < 0) {\n\t\tret = vmf_error(ret2);\n\t\tunlock_extent_cached(io_tree, page_start, page_end, &cached_state);\n\t\tgoto out_unlock;\n\t}\n\n\t/*\n\t * we can't set the delalloc bits if there are pending ordered\n\t * extents.  Drop our locks and wait for them to finish\n\t */\n\tordered = btrfs_lookup_ordered_range(BTRFS_I(inode), page_start,\n\t\t\tPAGE_SIZE);\n\tif (ordered) {\n\t\tunlock_extent_cached(io_tree, page_start, page_end,\n\t\t\t\t     &cached_state);\n\t\tunlock_page(page);\n\t\tbtrfs_start_ordered_extent(ordered, 1);\n\t\tbtrfs_put_ordered_extent(ordered);\n\t\tgoto again;\n\t}\n\n\tif (page->index == ((size - 1) >> PAGE_SHIFT)) {\n\t\treserved_space = round_up(size - page_start,\n\t\t\t\t\t  fs_info->sectorsize);\n\t\tif (reserved_space < PAGE_SIZE) {\n\t\t\tend = page_start + reserved_space - 1;\n\t\t\tbtrfs_delalloc_release_space(BTRFS_I(inode),\n\t\t\t\t\tdata_reserved, page_start,\n\t\t\t\t\tPAGE_SIZE - reserved_space, true);\n\t\t}\n\t}\n\n\t/*\n\t * page_mkwrite gets called when the page is firstly dirtied after it's\n\t * faulted in, but write(2) could also dirty a page and set delalloc\n\t * bits, thus in this case for space account reason, we still need to\n\t * clear any delalloc bits within this page range since we have to\n\t * reserve data&meta space before lock_page() (see above comments).\n\t */\n\tclear_extent_bit(&BTRFS_I(inode)->io_tree, page_start, end,\n\t\t\t  EXTENT_DELALLOC | EXTENT_DO_ACCOUNTING |\n\t\t\t  EXTENT_DEFRAG, 0, 0, &cached_state);\n\n\tret2 = btrfs_set_extent_delalloc(BTRFS_I(inode), page_start, end, 0,\n\t\t\t\t\t&cached_state);\n\tif (ret2) {\n\t\tunlock_extent_cached(io_tree, page_start, page_end,\n\t\t\t\t     &cached_state);\n\t\tret = VM_FAULT_SIGBUS;\n\t\tgoto out_unlock;\n\t}\n\n\t/* page is wholly or partially inside EOF */\n\tif (page_start + PAGE_SIZE > size)\n\t\tzero_start = offset_in_page(size);\n\telse\n\t\tzero_start = PAGE_SIZE;\n\n\tif (zero_start != PAGE_SIZE) {\n\t\tzero_user(page, zero_start, PAGE_SIZE - zero_start);\n\t\tflush_dcache_page(page);\n\t}\n\tClearPageChecked(page);\n\tset_page_dirty(page);\n\tSetPageUptodate(page);\n\n\tBTRFS_I(inode)->last_trans = fs_info->generation;\n\tBTRFS_I(inode)->last_sub_trans = BTRFS_I(inode)->root->log_transid;\n\tBTRFS_I(inode)->last_log_commit = BTRFS_I(inode)->root->last_log_commit;\n\n\tunlock_extent_cached(io_tree, page_start, page_end, &cached_state);\n\n\tbtrfs_delalloc_release_extents(BTRFS_I(inode), PAGE_SIZE);\n\tsb_end_pagefault(inode->i_sb);\n\textent_changeset_free(data_reserved);\n\treturn VM_FAULT_LOCKED;\n\nout_unlock:\n\tunlock_page(page);\nout:\n\tbtrfs_delalloc_release_extents(BTRFS_I(inode), PAGE_SIZE);\n\tbtrfs_delalloc_release_space(BTRFS_I(inode), data_reserved, page_start,\n\t\t\t\t     reserved_space, (ret != 0));\nout_noreserve:\n\tsb_end_pagefault(inode->i_sb);\n\textent_changeset_free(data_reserved);\n\treturn ret;\n}\n\nstatic int btrfs_truncate(struct inode *inode, bool skip_writeback)\n{\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);\n\tstruct btrfs_root *root = BTRFS_I(inode)->root;\n\tstruct btrfs_block_rsv *rsv;\n\tint ret;\n\tstruct btrfs_trans_handle *trans;\n\tu64 mask = fs_info->sectorsize - 1;\n\tu64 min_size = btrfs_calc_metadata_size(fs_info, 1);\n\n\tif (!skip_writeback) {\n\t\tret = btrfs_wait_ordered_range(inode, inode->i_size & (~mask),\n\t\t\t\t\t       (u64)-1);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\t/*\n\t * Yes ladies and gentlemen, this is indeed ugly.  We have a couple of\n\t * things going on here:\n\t *\n\t * 1) We need to reserve space to update our inode.\n\t *\n\t * 2) We need to have something to cache all the space that is going to\n\t * be free'd up by the truncate operation, but also have some slack\n\t * space reserved in case it uses space during the truncate (thank you\n\t * very much snapshotting).\n\t *\n\t * And we need these to be separate.  The fact is we can use a lot of\n\t * space doing the truncate, and we have no earthly idea how much space\n\t * we will use, so we need the truncate reservation to be separate so it\n\t * doesn't end up using space reserved for updating the inode.  We also\n\t * need to be able to stop the transaction and start a new one, which\n\t * means we need to be able to update the inode several times, and we\n\t * have no idea of knowing how many times that will be, so we can't just\n\t * reserve 1 item for the entirety of the operation, so that has to be\n\t * done separately as well.\n\t *\n\t * So that leaves us with\n\t *\n\t * 1) rsv - for the truncate reservation, which we will steal from the\n\t * transaction reservation.\n\t * 2) fs_info->trans_block_rsv - this will have 1 items worth left for\n\t * updating the inode.\n\t */\n\trsv = btrfs_alloc_block_rsv(fs_info, BTRFS_BLOCK_RSV_TEMP);\n\tif (!rsv)\n\t\treturn -ENOMEM;\n\trsv->size = min_size;\n\trsv->failfast = 1;\n\n\t/*\n\t * 1 for the truncate slack space\n\t * 1 for updating the inode.\n\t */\n\ttrans = btrfs_start_transaction(root, 2);\n\tif (IS_ERR(trans)) {\n\t\tret = PTR_ERR(trans);\n\t\tgoto out;\n\t}\n\n\t/* Migrate the slack space for the truncate to our reserve */\n\tret = btrfs_block_rsv_migrate(&fs_info->trans_block_rsv, rsv,\n\t\t\t\t      min_size, false);\n\tBUG_ON(ret);\n\n\t/*\n\t * So if we truncate and then write and fsync we normally would just\n\t * write the extents that changed, which is a problem if we need to\n\t * first truncate that entire inode.  So set this flag so we write out\n\t * all of the extents in the inode to the sync log so we're completely\n\t * safe.\n\t */\n\tset_bit(BTRFS_INODE_NEEDS_FULL_SYNC, &BTRFS_I(inode)->runtime_flags);\n\ttrans->block_rsv = rsv;\n\n\twhile (1) {\n\t\tret = btrfs_truncate_inode_items(trans, root, BTRFS_I(inode),\n\t\t\t\t\t\t inode->i_size,\n\t\t\t\t\t\t BTRFS_EXTENT_DATA_KEY);\n\t\ttrans->block_rsv = &fs_info->trans_block_rsv;\n\t\tif (ret != -ENOSPC && ret != -EAGAIN)\n\t\t\tbreak;\n\n\t\tret = btrfs_update_inode(trans, root, BTRFS_I(inode));\n\t\tif (ret)\n\t\t\tbreak;\n\n\t\tbtrfs_end_transaction(trans);\n\t\tbtrfs_btree_balance_dirty(fs_info);\n\n\t\ttrans = btrfs_start_transaction(root, 2);\n\t\tif (IS_ERR(trans)) {\n\t\t\tret = PTR_ERR(trans);\n\t\t\ttrans = NULL;\n\t\t\tbreak;\n\t\t}\n\n\t\tbtrfs_block_rsv_release(fs_info, rsv, -1, NULL);\n\t\tret = btrfs_block_rsv_migrate(&fs_info->trans_block_rsv,\n\t\t\t\t\t      rsv, min_size, false);\n\t\tBUG_ON(ret);\t/* shouldn't happen */\n\t\ttrans->block_rsv = rsv;\n\t}\n\n\t/*\n\t * We can't call btrfs_truncate_block inside a trans handle as we could\n\t * deadlock with freeze, if we got NEED_TRUNCATE_BLOCK then we know\n\t * we've truncated everything except the last little bit, and can do\n\t * btrfs_truncate_block and then update the disk_i_size.\n\t */\n\tif (ret == NEED_TRUNCATE_BLOCK) {\n\t\tbtrfs_end_transaction(trans);\n\t\tbtrfs_btree_balance_dirty(fs_info);\n\n\t\tret = btrfs_truncate_block(BTRFS_I(inode), inode->i_size, 0, 0);\n\t\tif (ret)\n\t\t\tgoto out;\n\t\ttrans = btrfs_start_transaction(root, 1);\n\t\tif (IS_ERR(trans)) {\n\t\t\tret = PTR_ERR(trans);\n\t\t\tgoto out;\n\t\t}\n\t\tbtrfs_inode_safe_disk_i_size_write(BTRFS_I(inode), 0);\n\t}\n\n\tif (trans) {\n\t\tint ret2;\n\n\t\ttrans->block_rsv = &fs_info->trans_block_rsv;\n\t\tret2 = btrfs_update_inode(trans, root, BTRFS_I(inode));\n\t\tif (ret2 && !ret)\n\t\t\tret = ret2;\n\n\t\tret2 = btrfs_end_transaction(trans);\n\t\tif (ret2 && !ret)\n\t\t\tret = ret2;\n\t\tbtrfs_btree_balance_dirty(fs_info);\n\t}\nout:\n\tbtrfs_free_block_rsv(fs_info, rsv);\n\n\treturn ret;\n}\n\n/*\n * create a new subvolume directory/inode (helper for the ioctl).\n */\nint btrfs_create_subvol_root(struct btrfs_trans_handle *trans,\n\t\t\t     struct btrfs_root *new_root,\n\t\t\t     struct btrfs_root *parent_root)\n{\n\tstruct inode *inode;\n\tint err;\n\tu64 index = 0;\n\tu64 ino;\n\n\terr = btrfs_get_free_objectid(new_root, &ino);\n\tif (err < 0)\n\t\treturn err;\n\n\tinode = btrfs_new_inode(trans, new_root, NULL, \"..\", 2, ino, ino,\n\t\t\t\tS_IFDIR | (~current_umask() & S_IRWXUGO),\n\t\t\t\t&index);\n\tif (IS_ERR(inode))\n\t\treturn PTR_ERR(inode);\n\tinode->i_op = &btrfs_dir_inode_operations;\n\tinode->i_fop = &btrfs_dir_file_operations;\n\n\tset_nlink(inode, 1);\n\tbtrfs_i_size_write(BTRFS_I(inode), 0);\n\tunlock_new_inode(inode);\n\n\terr = btrfs_subvol_inherit_props(trans, new_root, parent_root);\n\tif (err)\n\t\tbtrfs_err(new_root->fs_info,\n\t\t\t  \"error inheriting subvolume %llu properties: %d\",\n\t\t\t  new_root->root_key.objectid, err);\n\n\terr = btrfs_update_inode(trans, new_root, BTRFS_I(inode));\n\n\tiput(inode);\n\treturn err;\n}\n\nstruct inode *btrfs_alloc_inode(struct super_block *sb)\n{\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(sb);\n\tstruct btrfs_inode *ei;\n\tstruct inode *inode;\n\n\tei = kmem_cache_alloc(btrfs_inode_cachep, GFP_KERNEL);\n\tif (!ei)\n\t\treturn NULL;\n\n\tei->root = NULL;\n\tei->generation = 0;\n\tei->last_trans = 0;\n\tei->last_sub_trans = 0;\n\tei->logged_trans = 0;\n\tei->delalloc_bytes = 0;\n\tei->new_delalloc_bytes = 0;\n\tei->defrag_bytes = 0;\n\tei->disk_i_size = 0;\n\tei->flags = 0;\n\tei->csum_bytes = 0;\n\tei->index_cnt = (u64)-1;\n\tei->dir_index = 0;\n\tei->last_unlink_trans = 0;\n\tei->last_reflink_trans = 0;\n\tei->last_log_commit = 0;\n\n\tspin_lock_init(&ei->lock);\n\tei->outstanding_extents = 0;\n\tif (sb->s_magic != BTRFS_TEST_MAGIC)\n\t\tbtrfs_init_metadata_block_rsv(fs_info, &ei->block_rsv,\n\t\t\t\t\t      BTRFS_BLOCK_RSV_DELALLOC);\n\tei->runtime_flags = 0;\n\tei->prop_compress = BTRFS_COMPRESS_NONE;\n\tei->defrag_compress = BTRFS_COMPRESS_NONE;\n\n\tei->delayed_node = NULL;\n\n\tei->i_otime.tv_sec = 0;\n\tei->i_otime.tv_nsec = 0;\n\n\tinode = &ei->vfs_inode;\n\textent_map_tree_init(&ei->extent_tree);\n\textent_io_tree_init(fs_info, &ei->io_tree, IO_TREE_INODE_IO, inode);\n\textent_io_tree_init(fs_info, &ei->io_failure_tree,\n\t\t\t    IO_TREE_INODE_IO_FAILURE, inode);\n\textent_io_tree_init(fs_info, &ei->file_extent_tree,\n\t\t\t    IO_TREE_INODE_FILE_EXTENT, inode);\n\tei->io_tree.track_uptodate = true;\n\tei->io_failure_tree.track_uptodate = true;\n\tatomic_set(&ei->sync_writers, 0);\n\tmutex_init(&ei->log_mutex);\n\tbtrfs_ordered_inode_tree_init(&ei->ordered_tree);\n\tINIT_LIST_HEAD(&ei->delalloc_inodes);\n\tINIT_LIST_HEAD(&ei->delayed_iput);\n\tRB_CLEAR_NODE(&ei->rb_node);\n\n\treturn inode;\n}\n\n#ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS\nvoid btrfs_test_destroy_inode(struct inode *inode)\n{\n\tbtrfs_drop_extent_cache(BTRFS_I(inode), 0, (u64)-1, 0);\n\tkmem_cache_free(btrfs_inode_cachep, BTRFS_I(inode));\n}\n#endif\n\nvoid btrfs_free_inode(struct inode *inode)\n{\n\tkmem_cache_free(btrfs_inode_cachep, BTRFS_I(inode));\n}\n\nvoid btrfs_destroy_inode(struct inode *vfs_inode)\n{\n\tstruct btrfs_ordered_extent *ordered;\n\tstruct btrfs_inode *inode = BTRFS_I(vfs_inode);\n\tstruct btrfs_root *root = inode->root;\n\n\tWARN_ON(!hlist_empty(&vfs_inode->i_dentry));\n\tWARN_ON(vfs_inode->i_data.nrpages);\n\tWARN_ON(inode->block_rsv.reserved);\n\tWARN_ON(inode->block_rsv.size);\n\tWARN_ON(inode->outstanding_extents);\n\tWARN_ON(inode->delalloc_bytes);\n\tWARN_ON(inode->new_delalloc_bytes);\n\tWARN_ON(inode->csum_bytes);\n\tWARN_ON(inode->defrag_bytes);\n\n\t/*\n\t * This can happen where we create an inode, but somebody else also\n\t * created the same inode and we need to destroy the one we already\n\t * created.\n\t */\n\tif (!root)\n\t\treturn;\n\n\twhile (1) {\n\t\tordered = btrfs_lookup_first_ordered_extent(inode, (u64)-1);\n\t\tif (!ordered)\n\t\t\tbreak;\n\t\telse {\n\t\t\tbtrfs_err(root->fs_info,\n\t\t\t\t  \"found ordered extent %llu %llu on inode cleanup\",\n\t\t\t\t  ordered->file_offset, ordered->num_bytes);\n\t\t\tbtrfs_remove_ordered_extent(inode, ordered);\n\t\t\tbtrfs_put_ordered_extent(ordered);\n\t\t\tbtrfs_put_ordered_extent(ordered);\n\t\t}\n\t}\n\tbtrfs_qgroup_check_reserved_leak(inode);\n\tinode_tree_del(inode);\n\tbtrfs_drop_extent_cache(inode, 0, (u64)-1, 0);\n\tbtrfs_inode_clear_file_extent_range(inode, 0, (u64)-1);\n\tbtrfs_put_root(inode->root);\n}\n\nint btrfs_drop_inode(struct inode *inode)\n{\n\tstruct btrfs_root *root = BTRFS_I(inode)->root;\n\n\tif (root == NULL)\n\t\treturn 1;\n\n\t/* the snap/subvol tree is on deleting */\n\tif (btrfs_root_refs(&root->root_item) == 0)\n\t\treturn 1;\n\telse\n\t\treturn generic_drop_inode(inode);\n}\n\nstatic void init_once(void *foo)\n{\n\tstruct btrfs_inode *ei = (struct btrfs_inode *) foo;\n\n\tinode_init_once(&ei->vfs_inode);\n}\n\nvoid __cold btrfs_destroy_cachep(void)\n{\n\t/*\n\t * Make sure all delayed rcu free inodes are flushed before we\n\t * destroy cache.\n\t */\n\trcu_barrier();\n\tkmem_cache_destroy(btrfs_inode_cachep);\n\tkmem_cache_destroy(btrfs_trans_handle_cachep);\n\tkmem_cache_destroy(btrfs_path_cachep);\n\tkmem_cache_destroy(btrfs_free_space_cachep);\n\tkmem_cache_destroy(btrfs_free_space_bitmap_cachep);\n}\n\nint __init btrfs_init_cachep(void)\n{\n\tbtrfs_inode_cachep = kmem_cache_create(\"btrfs_inode\",\n\t\t\tsizeof(struct btrfs_inode), 0,\n\t\t\tSLAB_RECLAIM_ACCOUNT | SLAB_MEM_SPREAD | SLAB_ACCOUNT,\n\t\t\tinit_once);\n\tif (!btrfs_inode_cachep)\n\t\tgoto fail;\n\n\tbtrfs_trans_handle_cachep = kmem_cache_create(\"btrfs_trans_handle\",\n\t\t\tsizeof(struct btrfs_trans_handle), 0,\n\t\t\tSLAB_TEMPORARY | SLAB_MEM_SPREAD, NULL);\n\tif (!btrfs_trans_handle_cachep)\n\t\tgoto fail;\n\n\tbtrfs_path_cachep = kmem_cache_create(\"btrfs_path\",\n\t\t\tsizeof(struct btrfs_path), 0,\n\t\t\tSLAB_MEM_SPREAD, NULL);\n\tif (!btrfs_path_cachep)\n\t\tgoto fail;\n\n\tbtrfs_free_space_cachep = kmem_cache_create(\"btrfs_free_space\",\n\t\t\tsizeof(struct btrfs_free_space), 0,\n\t\t\tSLAB_MEM_SPREAD, NULL);\n\tif (!btrfs_free_space_cachep)\n\t\tgoto fail;\n\n\tbtrfs_free_space_bitmap_cachep = kmem_cache_create(\"btrfs_free_space_bitmap\",\n\t\t\t\t\t\t\tPAGE_SIZE, PAGE_SIZE,\n\t\t\t\t\t\t\tSLAB_RED_ZONE, NULL);\n\tif (!btrfs_free_space_bitmap_cachep)\n\t\tgoto fail;\n\n\treturn 0;\nfail:\n\tbtrfs_destroy_cachep();\n\treturn -ENOMEM;\n}\n\nstatic int btrfs_getattr(struct user_namespace *mnt_userns,\n\t\t\t const struct path *path, struct kstat *stat,\n\t\t\t u32 request_mask, unsigned int flags)\n{\n\tu64 delalloc_bytes;\n\tu64 inode_bytes;\n\tstruct inode *inode = d_inode(path->dentry);\n\tu32 blocksize = inode->i_sb->s_blocksize;\n\tu32 bi_flags = BTRFS_I(inode)->flags;\n\n\tstat->result_mask |= STATX_BTIME;\n\tstat->btime.tv_sec = BTRFS_I(inode)->i_otime.tv_sec;\n\tstat->btime.tv_nsec = BTRFS_I(inode)->i_otime.tv_nsec;\n\tif (bi_flags & BTRFS_INODE_APPEND)\n\t\tstat->attributes |= STATX_ATTR_APPEND;\n\tif (bi_flags & BTRFS_INODE_COMPRESS)\n\t\tstat->attributes |= STATX_ATTR_COMPRESSED;\n\tif (bi_flags & BTRFS_INODE_IMMUTABLE)\n\t\tstat->attributes |= STATX_ATTR_IMMUTABLE;\n\tif (bi_flags & BTRFS_INODE_NODUMP)\n\t\tstat->attributes |= STATX_ATTR_NODUMP;\n\n\tstat->attributes_mask |= (STATX_ATTR_APPEND |\n\t\t\t\t  STATX_ATTR_COMPRESSED |\n\t\t\t\t  STATX_ATTR_IMMUTABLE |\n\t\t\t\t  STATX_ATTR_NODUMP);\n\n\tgeneric_fillattr(&init_user_ns, inode, stat);\n\tstat->dev = BTRFS_I(inode)->root->anon_dev;\n\n\tspin_lock(&BTRFS_I(inode)->lock);\n\tdelalloc_bytes = BTRFS_I(inode)->new_delalloc_bytes;\n\tinode_bytes = inode_get_bytes(inode);\n\tspin_unlock(&BTRFS_I(inode)->lock);\n\tstat->blocks = (ALIGN(inode_bytes, blocksize) +\n\t\t\tALIGN(delalloc_bytes, blocksize)) >> 9;\n\treturn 0;\n}\n\nstatic int btrfs_rename_exchange(struct inode *old_dir,\n\t\t\t      struct dentry *old_dentry,\n\t\t\t      struct inode *new_dir,\n\t\t\t      struct dentry *new_dentry)\n{\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(old_dir->i_sb);\n\tstruct btrfs_trans_handle *trans;\n\tstruct btrfs_root *root = BTRFS_I(old_dir)->root;\n\tstruct btrfs_root *dest = BTRFS_I(new_dir)->root;\n\tstruct inode *new_inode = new_dentry->d_inode;\n\tstruct inode *old_inode = old_dentry->d_inode;\n\tstruct timespec64 ctime = current_time(old_inode);\n\tu64 old_ino = btrfs_ino(BTRFS_I(old_inode));\n\tu64 new_ino = btrfs_ino(BTRFS_I(new_inode));\n\tu64 old_idx = 0;\n\tu64 new_idx = 0;\n\tint ret;\n\tint ret2;\n\tbool root_log_pinned = false;\n\tbool dest_log_pinned = false;\n\n\t/* we only allow rename subvolume link between subvolumes */\n\tif (old_ino != BTRFS_FIRST_FREE_OBJECTID && root != dest)\n\t\treturn -EXDEV;\n\n\t/* close the race window with snapshot create/destroy ioctl */\n\tif (old_ino == BTRFS_FIRST_FREE_OBJECTID ||\n\t    new_ino == BTRFS_FIRST_FREE_OBJECTID)\n\t\tdown_read(&fs_info->subvol_sem);\n\n\t/*\n\t * We want to reserve the absolute worst case amount of items.  So if\n\t * both inodes are subvols and we need to unlink them then that would\n\t * require 4 item modifications, but if they are both normal inodes it\n\t * would require 5 item modifications, so we'll assume their normal\n\t * inodes.  So 5 * 2 is 10, plus 2 for the new links, so 12 total items\n\t * should cover the worst case number of items we'll modify.\n\t */\n\ttrans = btrfs_start_transaction(root, 12);\n\tif (IS_ERR(trans)) {\n\t\tret = PTR_ERR(trans);\n\t\tgoto out_notrans;\n\t}\n\n\tif (dest != root) {\n\t\tret = btrfs_record_root_in_trans(trans, dest);\n\t\tif (ret)\n\t\t\tgoto out_fail;\n\t}\n\n\t/*\n\t * We need to find a free sequence number both in the source and\n\t * in the destination directory for the exchange.\n\t */\n\tret = btrfs_set_inode_index(BTRFS_I(new_dir), &old_idx);\n\tif (ret)\n\t\tgoto out_fail;\n\tret = btrfs_set_inode_index(BTRFS_I(old_dir), &new_idx);\n\tif (ret)\n\t\tgoto out_fail;\n\n\tBTRFS_I(old_inode)->dir_index = 0ULL;\n\tBTRFS_I(new_inode)->dir_index = 0ULL;\n\n\t/* Reference for the source. */\n\tif (old_ino == BTRFS_FIRST_FREE_OBJECTID) {\n\t\t/* force full log commit if subvolume involved. */\n\t\tbtrfs_set_log_full_commit(trans);\n\t} else {\n\t\tbtrfs_pin_log_trans(root);\n\t\troot_log_pinned = true;\n\t\tret = btrfs_insert_inode_ref(trans, dest,\n\t\t\t\t\t     new_dentry->d_name.name,\n\t\t\t\t\t     new_dentry->d_name.len,\n\t\t\t\t\t     old_ino,\n\t\t\t\t\t     btrfs_ino(BTRFS_I(new_dir)),\n\t\t\t\t\t     old_idx);\n\t\tif (ret)\n\t\t\tgoto out_fail;\n\t}\n\n\t/* And now for the dest. */\n\tif (new_ino == BTRFS_FIRST_FREE_OBJECTID) {\n\t\t/* force full log commit if subvolume involved. */\n\t\tbtrfs_set_log_full_commit(trans);\n\t} else {\n\t\tbtrfs_pin_log_trans(dest);\n\t\tdest_log_pinned = true;\n\t\tret = btrfs_insert_inode_ref(trans, root,\n\t\t\t\t\t     old_dentry->d_name.name,\n\t\t\t\t\t     old_dentry->d_name.len,\n\t\t\t\t\t     new_ino,\n\t\t\t\t\t     btrfs_ino(BTRFS_I(old_dir)),\n\t\t\t\t\t     new_idx);\n\t\tif (ret)\n\t\t\tgoto out_fail;\n\t}\n\n\t/* Update inode version and ctime/mtime. */\n\tinode_inc_iversion(old_dir);\n\tinode_inc_iversion(new_dir);\n\tinode_inc_iversion(old_inode);\n\tinode_inc_iversion(new_inode);\n\told_dir->i_ctime = old_dir->i_mtime = ctime;\n\tnew_dir->i_ctime = new_dir->i_mtime = ctime;\n\told_inode->i_ctime = ctime;\n\tnew_inode->i_ctime = ctime;\n\n\tif (old_dentry->d_parent != new_dentry->d_parent) {\n\t\tbtrfs_record_unlink_dir(trans, BTRFS_I(old_dir),\n\t\t\t\tBTRFS_I(old_inode), 1);\n\t\tbtrfs_record_unlink_dir(trans, BTRFS_I(new_dir),\n\t\t\t\tBTRFS_I(new_inode), 1);\n\t}\n\n\t/* src is a subvolume */\n\tif (old_ino == BTRFS_FIRST_FREE_OBJECTID) {\n\t\tret = btrfs_unlink_subvol(trans, old_dir, old_dentry);\n\t} else { /* src is an inode */\n\t\tret = __btrfs_unlink_inode(trans, root, BTRFS_I(old_dir),\n\t\t\t\t\t   BTRFS_I(old_dentry->d_inode),\n\t\t\t\t\t   old_dentry->d_name.name,\n\t\t\t\t\t   old_dentry->d_name.len);\n\t\tif (!ret)\n\t\t\tret = btrfs_update_inode(trans, root, BTRFS_I(old_inode));\n\t}\n\tif (ret) {\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\tgoto out_fail;\n\t}\n\n\t/* dest is a subvolume */\n\tif (new_ino == BTRFS_FIRST_FREE_OBJECTID) {\n\t\tret = btrfs_unlink_subvol(trans, new_dir, new_dentry);\n\t} else { /* dest is an inode */\n\t\tret = __btrfs_unlink_inode(trans, dest, BTRFS_I(new_dir),\n\t\t\t\t\t   BTRFS_I(new_dentry->d_inode),\n\t\t\t\t\t   new_dentry->d_name.name,\n\t\t\t\t\t   new_dentry->d_name.len);\n\t\tif (!ret)\n\t\t\tret = btrfs_update_inode(trans, dest, BTRFS_I(new_inode));\n\t}\n\tif (ret) {\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\tgoto out_fail;\n\t}\n\n\tret = btrfs_add_link(trans, BTRFS_I(new_dir), BTRFS_I(old_inode),\n\t\t\t     new_dentry->d_name.name,\n\t\t\t     new_dentry->d_name.len, 0, old_idx);\n\tif (ret) {\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\tgoto out_fail;\n\t}\n\n\tret = btrfs_add_link(trans, BTRFS_I(old_dir), BTRFS_I(new_inode),\n\t\t\t     old_dentry->d_name.name,\n\t\t\t     old_dentry->d_name.len, 0, new_idx);\n\tif (ret) {\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\tgoto out_fail;\n\t}\n\n\tif (old_inode->i_nlink == 1)\n\t\tBTRFS_I(old_inode)->dir_index = old_idx;\n\tif (new_inode->i_nlink == 1)\n\t\tBTRFS_I(new_inode)->dir_index = new_idx;\n\n\tif (root_log_pinned) {\n\t\tbtrfs_log_new_name(trans, BTRFS_I(old_inode), BTRFS_I(old_dir),\n\t\t\t\t   new_dentry->d_parent);\n\t\tbtrfs_end_log_trans(root);\n\t\troot_log_pinned = false;\n\t}\n\tif (dest_log_pinned) {\n\t\tbtrfs_log_new_name(trans, BTRFS_I(new_inode), BTRFS_I(new_dir),\n\t\t\t\t   old_dentry->d_parent);\n\t\tbtrfs_end_log_trans(dest);\n\t\tdest_log_pinned = false;\n\t}\nout_fail:\n\t/*\n\t * If we have pinned a log and an error happened, we unpin tasks\n\t * trying to sync the log and force them to fallback to a transaction\n\t * commit if the log currently contains any of the inodes involved in\n\t * this rename operation (to ensure we do not persist a log with an\n\t * inconsistent state for any of these inodes or leading to any\n\t * inconsistencies when replayed). If the transaction was aborted, the\n\t * abortion reason is propagated to userspace when attempting to commit\n\t * the transaction. If the log does not contain any of these inodes, we\n\t * allow the tasks to sync it.\n\t */\n\tif (ret && (root_log_pinned || dest_log_pinned)) {\n\t\tif (btrfs_inode_in_log(BTRFS_I(old_dir), fs_info->generation) ||\n\t\t    btrfs_inode_in_log(BTRFS_I(new_dir), fs_info->generation) ||\n\t\t    btrfs_inode_in_log(BTRFS_I(old_inode), fs_info->generation) ||\n\t\t    (new_inode &&\n\t\t     btrfs_inode_in_log(BTRFS_I(new_inode), fs_info->generation)))\n\t\t\tbtrfs_set_log_full_commit(trans);\n\n\t\tif (root_log_pinned) {\n\t\t\tbtrfs_end_log_trans(root);\n\t\t\troot_log_pinned = false;\n\t\t}\n\t\tif (dest_log_pinned) {\n\t\t\tbtrfs_end_log_trans(dest);\n\t\t\tdest_log_pinned = false;\n\t\t}\n\t}\n\tret2 = btrfs_end_transaction(trans);\n\tret = ret ? ret : ret2;\nout_notrans:\n\tif (new_ino == BTRFS_FIRST_FREE_OBJECTID ||\n\t    old_ino == BTRFS_FIRST_FREE_OBJECTID)\n\t\tup_read(&fs_info->subvol_sem);\n\n\treturn ret;\n}\n\nstatic int btrfs_whiteout_for_rename(struct btrfs_trans_handle *trans,\n\t\t\t\t     struct btrfs_root *root,\n\t\t\t\t     struct inode *dir,\n\t\t\t\t     struct dentry *dentry)\n{\n\tint ret;\n\tstruct inode *inode;\n\tu64 objectid;\n\tu64 index;\n\n\tret = btrfs_get_free_objectid(root, &objectid);\n\tif (ret)\n\t\treturn ret;\n\n\tinode = btrfs_new_inode(trans, root, dir,\n\t\t\t\tdentry->d_name.name,\n\t\t\t\tdentry->d_name.len,\n\t\t\t\tbtrfs_ino(BTRFS_I(dir)),\n\t\t\t\tobjectid,\n\t\t\t\tS_IFCHR | WHITEOUT_MODE,\n\t\t\t\t&index);\n\n\tif (IS_ERR(inode)) {\n\t\tret = PTR_ERR(inode);\n\t\treturn ret;\n\t}\n\n\tinode->i_op = &btrfs_special_inode_operations;\n\tinit_special_inode(inode, inode->i_mode,\n\t\tWHITEOUT_DEV);\n\n\tret = btrfs_init_inode_security(trans, inode, dir,\n\t\t\t\t&dentry->d_name);\n\tif (ret)\n\t\tgoto out;\n\n\tret = btrfs_add_nondir(trans, BTRFS_I(dir), dentry,\n\t\t\t\tBTRFS_I(inode), 0, index);\n\tif (ret)\n\t\tgoto out;\n\n\tret = btrfs_update_inode(trans, root, BTRFS_I(inode));\nout:\n\tunlock_new_inode(inode);\n\tif (ret)\n\t\tinode_dec_link_count(inode);\n\tiput(inode);\n\n\treturn ret;\n}\n\nstatic int btrfs_rename(struct inode *old_dir, struct dentry *old_dentry,\n\t\t\t   struct inode *new_dir, struct dentry *new_dentry,\n\t\t\t   unsigned int flags)\n{\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(old_dir->i_sb);\n\tstruct btrfs_trans_handle *trans;\n\tunsigned int trans_num_items;\n\tstruct btrfs_root *root = BTRFS_I(old_dir)->root;\n\tstruct btrfs_root *dest = BTRFS_I(new_dir)->root;\n\tstruct inode *new_inode = d_inode(new_dentry);\n\tstruct inode *old_inode = d_inode(old_dentry);\n\tu64 index = 0;\n\tint ret;\n\tint ret2;\n\tu64 old_ino = btrfs_ino(BTRFS_I(old_inode));\n\tbool log_pinned = false;\n\n\tif (btrfs_ino(BTRFS_I(new_dir)) == BTRFS_EMPTY_SUBVOL_DIR_OBJECTID)\n\t\treturn -EPERM;\n\n\t/* we only allow rename subvolume link between subvolumes */\n\tif (old_ino != BTRFS_FIRST_FREE_OBJECTID && root != dest)\n\t\treturn -EXDEV;\n\n\tif (old_ino == BTRFS_EMPTY_SUBVOL_DIR_OBJECTID ||\n\t    (new_inode && btrfs_ino(BTRFS_I(new_inode)) == BTRFS_FIRST_FREE_OBJECTID))\n\t\treturn -ENOTEMPTY;\n\n\tif (S_ISDIR(old_inode->i_mode) && new_inode &&\n\t    new_inode->i_size > BTRFS_EMPTY_DIR_SIZE)\n\t\treturn -ENOTEMPTY;\n\n\n\t/* check for collisions, even if the  name isn't there */\n\tret = btrfs_check_dir_item_collision(dest, new_dir->i_ino,\n\t\t\t     new_dentry->d_name.name,\n\t\t\t     new_dentry->d_name.len);\n\n\tif (ret) {\n\t\tif (ret == -EEXIST) {\n\t\t\t/* we shouldn't get\n\t\t\t * eexist without a new_inode */\n\t\t\tif (WARN_ON(!new_inode)) {\n\t\t\t\treturn ret;\n\t\t\t}\n\t\t} else {\n\t\t\t/* maybe -EOVERFLOW */\n\t\t\treturn ret;\n\t\t}\n\t}\n\tret = 0;\n\n\t/*\n\t * we're using rename to replace one file with another.  Start IO on it\n\t * now so  we don't add too much work to the end of the transaction\n\t */\n\tif (new_inode && S_ISREG(old_inode->i_mode) && new_inode->i_size)\n\t\tfilemap_flush(old_inode->i_mapping);\n\n\t/* close the racy window with snapshot create/destroy ioctl */\n\tif (old_ino == BTRFS_FIRST_FREE_OBJECTID)\n\t\tdown_read(&fs_info->subvol_sem);\n\t/*\n\t * We want to reserve the absolute worst case amount of items.  So if\n\t * both inodes are subvols and we need to unlink them then that would\n\t * require 4 item modifications, but if they are both normal inodes it\n\t * would require 5 item modifications, so we'll assume they are normal\n\t * inodes.  So 5 * 2 is 10, plus 1 for the new link, so 11 total items\n\t * should cover the worst case number of items we'll modify.\n\t * If our rename has the whiteout flag, we need more 5 units for the\n\t * new inode (1 inode item, 1 inode ref, 2 dir items and 1 xattr item\n\t * when selinux is enabled).\n\t */\n\ttrans_num_items = 11;\n\tif (flags & RENAME_WHITEOUT)\n\t\ttrans_num_items += 5;\n\ttrans = btrfs_start_transaction(root, trans_num_items);\n\tif (IS_ERR(trans)) {\n\t\tret = PTR_ERR(trans);\n\t\tgoto out_notrans;\n\t}\n\n\tif (dest != root) {\n\t\tret = btrfs_record_root_in_trans(trans, dest);\n\t\tif (ret)\n\t\t\tgoto out_fail;\n\t}\n\n\tret = btrfs_set_inode_index(BTRFS_I(new_dir), &index);\n\tif (ret)\n\t\tgoto out_fail;\n\n\tBTRFS_I(old_inode)->dir_index = 0ULL;\n\tif (unlikely(old_ino == BTRFS_FIRST_FREE_OBJECTID)) {\n\t\t/* force full log commit if subvolume involved. */\n\t\tbtrfs_set_log_full_commit(trans);\n\t} else {\n\t\tbtrfs_pin_log_trans(root);\n\t\tlog_pinned = true;\n\t\tret = btrfs_insert_inode_ref(trans, dest,\n\t\t\t\t\t     new_dentry->d_name.name,\n\t\t\t\t\t     new_dentry->d_name.len,\n\t\t\t\t\t     old_ino,\n\t\t\t\t\t     btrfs_ino(BTRFS_I(new_dir)), index);\n\t\tif (ret)\n\t\t\tgoto out_fail;\n\t}\n\n\tinode_inc_iversion(old_dir);\n\tinode_inc_iversion(new_dir);\n\tinode_inc_iversion(old_inode);\n\told_dir->i_ctime = old_dir->i_mtime =\n\tnew_dir->i_ctime = new_dir->i_mtime =\n\told_inode->i_ctime = current_time(old_dir);\n\n\tif (old_dentry->d_parent != new_dentry->d_parent)\n\t\tbtrfs_record_unlink_dir(trans, BTRFS_I(old_dir),\n\t\t\t\tBTRFS_I(old_inode), 1);\n\n\tif (unlikely(old_ino == BTRFS_FIRST_FREE_OBJECTID)) {\n\t\tret = btrfs_unlink_subvol(trans, old_dir, old_dentry);\n\t} else {\n\t\tret = __btrfs_unlink_inode(trans, root, BTRFS_I(old_dir),\n\t\t\t\t\tBTRFS_I(d_inode(old_dentry)),\n\t\t\t\t\told_dentry->d_name.name,\n\t\t\t\t\told_dentry->d_name.len);\n\t\tif (!ret)\n\t\t\tret = btrfs_update_inode(trans, root, BTRFS_I(old_inode));\n\t}\n\tif (ret) {\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\tgoto out_fail;\n\t}\n\n\tif (new_inode) {\n\t\tinode_inc_iversion(new_inode);\n\t\tnew_inode->i_ctime = current_time(new_inode);\n\t\tif (unlikely(btrfs_ino(BTRFS_I(new_inode)) ==\n\t\t\t     BTRFS_EMPTY_SUBVOL_DIR_OBJECTID)) {\n\t\t\tret = btrfs_unlink_subvol(trans, new_dir, new_dentry);\n\t\t\tBUG_ON(new_inode->i_nlink == 0);\n\t\t} else {\n\t\t\tret = btrfs_unlink_inode(trans, dest, BTRFS_I(new_dir),\n\t\t\t\t\t\t BTRFS_I(d_inode(new_dentry)),\n\t\t\t\t\t\t new_dentry->d_name.name,\n\t\t\t\t\t\t new_dentry->d_name.len);\n\t\t}\n\t\tif (!ret && new_inode->i_nlink == 0)\n\t\t\tret = btrfs_orphan_add(trans,\n\t\t\t\t\tBTRFS_I(d_inode(new_dentry)));\n\t\tif (ret) {\n\t\t\tbtrfs_abort_transaction(trans, ret);\n\t\t\tgoto out_fail;\n\t\t}\n\t}\n\n\tret = btrfs_add_link(trans, BTRFS_I(new_dir), BTRFS_I(old_inode),\n\t\t\t     new_dentry->d_name.name,\n\t\t\t     new_dentry->d_name.len, 0, index);\n\tif (ret) {\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\tgoto out_fail;\n\t}\n\n\tif (old_inode->i_nlink == 1)\n\t\tBTRFS_I(old_inode)->dir_index = index;\n\n\tif (log_pinned) {\n\t\tbtrfs_log_new_name(trans, BTRFS_I(old_inode), BTRFS_I(old_dir),\n\t\t\t\t   new_dentry->d_parent);\n\t\tbtrfs_end_log_trans(root);\n\t\tlog_pinned = false;\n\t}\n\n\tif (flags & RENAME_WHITEOUT) {\n\t\tret = btrfs_whiteout_for_rename(trans, root, old_dir,\n\t\t\t\t\t\told_dentry);\n\n\t\tif (ret) {\n\t\t\tbtrfs_abort_transaction(trans, ret);\n\t\t\tgoto out_fail;\n\t\t}\n\t}\nout_fail:\n\t/*\n\t * If we have pinned the log and an error happened, we unpin tasks\n\t * trying to sync the log and force them to fallback to a transaction\n\t * commit if the log currently contains any of the inodes involved in\n\t * this rename operation (to ensure we do not persist a log with an\n\t * inconsistent state for any of these inodes or leading to any\n\t * inconsistencies when replayed). If the transaction was aborted, the\n\t * abortion reason is propagated to userspace when attempting to commit\n\t * the transaction. If the log does not contain any of these inodes, we\n\t * allow the tasks to sync it.\n\t */\n\tif (ret && log_pinned) {\n\t\tif (btrfs_inode_in_log(BTRFS_I(old_dir), fs_info->generation) ||\n\t\t    btrfs_inode_in_log(BTRFS_I(new_dir), fs_info->generation) ||\n\t\t    btrfs_inode_in_log(BTRFS_I(old_inode), fs_info->generation) ||\n\t\t    (new_inode &&\n\t\t     btrfs_inode_in_log(BTRFS_I(new_inode), fs_info->generation)))\n\t\t\tbtrfs_set_log_full_commit(trans);\n\n\t\tbtrfs_end_log_trans(root);\n\t\tlog_pinned = false;\n\t}\n\tret2 = btrfs_end_transaction(trans);\n\tret = ret ? ret : ret2;\nout_notrans:\n\tif (old_ino == BTRFS_FIRST_FREE_OBJECTID)\n\t\tup_read(&fs_info->subvol_sem);\n\n\treturn ret;\n}\n\nstatic int btrfs_rename2(struct user_namespace *mnt_userns, struct inode *old_dir,\n\t\t\t struct dentry *old_dentry, struct inode *new_dir,\n\t\t\t struct dentry *new_dentry, unsigned int flags)\n{\n\tif (flags & ~(RENAME_NOREPLACE | RENAME_EXCHANGE | RENAME_WHITEOUT))\n\t\treturn -EINVAL;\n\n\tif (flags & RENAME_EXCHANGE)\n\t\treturn btrfs_rename_exchange(old_dir, old_dentry, new_dir,\n\t\t\t\t\t  new_dentry);\n\n\treturn btrfs_rename(old_dir, old_dentry, new_dir, new_dentry, flags);\n}\n\nstruct btrfs_delalloc_work {\n\tstruct inode *inode;\n\tstruct completion completion;\n\tstruct list_head list;\n\tstruct btrfs_work work;\n};\n\nstatic void btrfs_run_delalloc_work(struct btrfs_work *work)\n{\n\tstruct btrfs_delalloc_work *delalloc_work;\n\tstruct inode *inode;\n\n\tdelalloc_work = container_of(work, struct btrfs_delalloc_work,\n\t\t\t\t     work);\n\tinode = delalloc_work->inode;\n\tfilemap_flush(inode->i_mapping);\n\tif (test_bit(BTRFS_INODE_HAS_ASYNC_EXTENT,\n\t\t\t\t&BTRFS_I(inode)->runtime_flags))\n\t\tfilemap_flush(inode->i_mapping);\n\n\tiput(inode);\n\tcomplete(&delalloc_work->completion);\n}\n\nstatic struct btrfs_delalloc_work *btrfs_alloc_delalloc_work(struct inode *inode)\n{\n\tstruct btrfs_delalloc_work *work;\n\n\twork = kmalloc(sizeof(*work), GFP_NOFS);\n\tif (!work)\n\t\treturn NULL;\n\n\tinit_completion(&work->completion);\n\tINIT_LIST_HEAD(&work->list);\n\twork->inode = inode;\n\tbtrfs_init_work(&work->work, btrfs_run_delalloc_work, NULL, NULL);\n\n\treturn work;\n}\n\n/*\n * some fairly slow code that needs optimization. This walks the list\n * of all the inodes with pending delalloc and forces them to disk.\n */\nstatic int start_delalloc_inodes(struct btrfs_root *root,\n\t\t\t\t struct writeback_control *wbc, bool snapshot,\n\t\t\t\t bool in_reclaim_context)\n{\n\tstruct btrfs_inode *binode;\n\tstruct inode *inode;\n\tstruct btrfs_delalloc_work *work, *next;\n\tstruct list_head works;\n\tstruct list_head splice;\n\tint ret = 0;\n\tbool full_flush = wbc->nr_to_write == LONG_MAX;\n\n\tINIT_LIST_HEAD(&works);\n\tINIT_LIST_HEAD(&splice);\n\n\tmutex_lock(&root->delalloc_mutex);\n\tspin_lock(&root->delalloc_lock);\n\tlist_splice_init(&root->delalloc_inodes, &splice);\n\twhile (!list_empty(&splice)) {\n\t\tbinode = list_entry(splice.next, struct btrfs_inode,\n\t\t\t\t    delalloc_inodes);\n\n\t\tlist_move_tail(&binode->delalloc_inodes,\n\t\t\t       &root->delalloc_inodes);\n\n\t\tif (in_reclaim_context &&\n\t\t    test_bit(BTRFS_INODE_NO_DELALLOC_FLUSH, &binode->runtime_flags))\n\t\t\tcontinue;\n\n\t\tinode = igrab(&binode->vfs_inode);\n\t\tif (!inode) {\n\t\t\tcond_resched_lock(&root->delalloc_lock);\n\t\t\tcontinue;\n\t\t}\n\t\tspin_unlock(&root->delalloc_lock);\n\n\t\tif (snapshot)\n\t\t\tset_bit(BTRFS_INODE_SNAPSHOT_FLUSH,\n\t\t\t\t&binode->runtime_flags);\n\t\tif (full_flush) {\n\t\t\twork = btrfs_alloc_delalloc_work(inode);\n\t\t\tif (!work) {\n\t\t\t\tiput(inode);\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tlist_add_tail(&work->list, &works);\n\t\t\tbtrfs_queue_work(root->fs_info->flush_workers,\n\t\t\t\t\t &work->work);\n\t\t} else {\n\t\t\tret = sync_inode(inode, wbc);\n\t\t\tif (!ret &&\n\t\t\t    test_bit(BTRFS_INODE_HAS_ASYNC_EXTENT,\n\t\t\t\t     &BTRFS_I(inode)->runtime_flags))\n\t\t\t\tret = sync_inode(inode, wbc);\n\t\t\tbtrfs_add_delayed_iput(inode);\n\t\t\tif (ret || wbc->nr_to_write <= 0)\n\t\t\t\tgoto out;\n\t\t}\n\t\tcond_resched();\n\t\tspin_lock(&root->delalloc_lock);\n\t}\n\tspin_unlock(&root->delalloc_lock);\n\nout:\n\tlist_for_each_entry_safe(work, next, &works, list) {\n\t\tlist_del_init(&work->list);\n\t\twait_for_completion(&work->completion);\n\t\tkfree(work);\n\t}\n\n\tif (!list_empty(&splice)) {\n\t\tspin_lock(&root->delalloc_lock);\n\t\tlist_splice_tail(&splice, &root->delalloc_inodes);\n\t\tspin_unlock(&root->delalloc_lock);\n\t}\n\tmutex_unlock(&root->delalloc_mutex);\n\treturn ret;\n}\n\nint btrfs_start_delalloc_snapshot(struct btrfs_root *root)\n{\n\tstruct writeback_control wbc = {\n\t\t.nr_to_write = LONG_MAX,\n\t\t.sync_mode = WB_SYNC_NONE,\n\t\t.range_start = 0,\n\t\t.range_end = LLONG_MAX,\n\t};\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\n\tif (test_bit(BTRFS_FS_STATE_ERROR, &fs_info->fs_state))\n\t\treturn -EROFS;\n\n\treturn start_delalloc_inodes(root, &wbc, true, false);\n}\n\nint btrfs_start_delalloc_roots(struct btrfs_fs_info *fs_info, long nr,\n\t\t\t       bool in_reclaim_context)\n{\n\tstruct writeback_control wbc = {\n\t\t.nr_to_write = nr,\n\t\t.sync_mode = WB_SYNC_NONE,\n\t\t.range_start = 0,\n\t\t.range_end = LLONG_MAX,\n\t};\n\tstruct btrfs_root *root;\n\tstruct list_head splice;\n\tint ret;\n\n\tif (test_bit(BTRFS_FS_STATE_ERROR, &fs_info->fs_state))\n\t\treturn -EROFS;\n\n\tINIT_LIST_HEAD(&splice);\n\n\tmutex_lock(&fs_info->delalloc_root_mutex);\n\tspin_lock(&fs_info->delalloc_root_lock);\n\tlist_splice_init(&fs_info->delalloc_roots, &splice);\n\twhile (!list_empty(&splice)) {\n\t\t/*\n\t\t * Reset nr_to_write here so we know that we're doing a full\n\t\t * flush.\n\t\t */\n\t\tif (nr == LONG_MAX)\n\t\t\twbc.nr_to_write = LONG_MAX;\n\n\t\troot = list_first_entry(&splice, struct btrfs_root,\n\t\t\t\t\tdelalloc_root);\n\t\troot = btrfs_grab_root(root);\n\t\tBUG_ON(!root);\n\t\tlist_move_tail(&root->delalloc_root,\n\t\t\t       &fs_info->delalloc_roots);\n\t\tspin_unlock(&fs_info->delalloc_root_lock);\n\n\t\tret = start_delalloc_inodes(root, &wbc, false, in_reclaim_context);\n\t\tbtrfs_put_root(root);\n\t\tif (ret < 0 || wbc.nr_to_write <= 0)\n\t\t\tgoto out;\n\t\tspin_lock(&fs_info->delalloc_root_lock);\n\t}\n\tspin_unlock(&fs_info->delalloc_root_lock);\n\n\tret = 0;\nout:\n\tif (!list_empty(&splice)) {\n\t\tspin_lock(&fs_info->delalloc_root_lock);\n\t\tlist_splice_tail(&splice, &fs_info->delalloc_roots);\n\t\tspin_unlock(&fs_info->delalloc_root_lock);\n\t}\n\tmutex_unlock(&fs_info->delalloc_root_mutex);\n\treturn ret;\n}\n\nstatic int btrfs_symlink(struct user_namespace *mnt_userns, struct inode *dir,\n\t\t\t struct dentry *dentry, const char *symname)\n{\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(dir->i_sb);\n\tstruct btrfs_trans_handle *trans;\n\tstruct btrfs_root *root = BTRFS_I(dir)->root;\n\tstruct btrfs_path *path;\n\tstruct btrfs_key key;\n\tstruct inode *inode = NULL;\n\tint err;\n\tu64 objectid;\n\tu64 index = 0;\n\tint name_len;\n\tint datasize;\n\tunsigned long ptr;\n\tstruct btrfs_file_extent_item *ei;\n\tstruct extent_buffer *leaf;\n\n\tname_len = strlen(symname);\n\tif (name_len > BTRFS_MAX_INLINE_DATA_SIZE(fs_info))\n\t\treturn -ENAMETOOLONG;\n\n\t/*\n\t * 2 items for inode item and ref\n\t * 2 items for dir items\n\t * 1 item for updating parent inode item\n\t * 1 item for the inline extent item\n\t * 1 item for xattr if selinux is on\n\t */\n\ttrans = btrfs_start_transaction(root, 7);\n\tif (IS_ERR(trans))\n\t\treturn PTR_ERR(trans);\n\n\terr = btrfs_get_free_objectid(root, &objectid);\n\tif (err)\n\t\tgoto out_unlock;\n\n\tinode = btrfs_new_inode(trans, root, dir, dentry->d_name.name,\n\t\t\t\tdentry->d_name.len, btrfs_ino(BTRFS_I(dir)),\n\t\t\t\tobjectid, S_IFLNK|S_IRWXUGO, &index);\n\tif (IS_ERR(inode)) {\n\t\terr = PTR_ERR(inode);\n\t\tinode = NULL;\n\t\tgoto out_unlock;\n\t}\n\n\t/*\n\t* If the active LSM wants to access the inode during\n\t* d_instantiate it needs these. Smack checks to see\n\t* if the filesystem supports xattrs by looking at the\n\t* ops vector.\n\t*/\n\tinode->i_fop = &btrfs_file_operations;\n\tinode->i_op = &btrfs_file_inode_operations;\n\tinode->i_mapping->a_ops = &btrfs_aops;\n\n\terr = btrfs_init_inode_security(trans, inode, dir, &dentry->d_name);\n\tif (err)\n\t\tgoto out_unlock;\n\n\tpath = btrfs_alloc_path();\n\tif (!path) {\n\t\terr = -ENOMEM;\n\t\tgoto out_unlock;\n\t}\n\tkey.objectid = btrfs_ino(BTRFS_I(inode));\n\tkey.offset = 0;\n\tkey.type = BTRFS_EXTENT_DATA_KEY;\n\tdatasize = btrfs_file_extent_calc_inline_size(name_len);\n\terr = btrfs_insert_empty_item(trans, root, path, &key,\n\t\t\t\t      datasize);\n\tif (err) {\n\t\tbtrfs_free_path(path);\n\t\tgoto out_unlock;\n\t}\n\tleaf = path->nodes[0];\n\tei = btrfs_item_ptr(leaf, path->slots[0],\n\t\t\t    struct btrfs_file_extent_item);\n\tbtrfs_set_file_extent_generation(leaf, ei, trans->transid);\n\tbtrfs_set_file_extent_type(leaf, ei,\n\t\t\t\t   BTRFS_FILE_EXTENT_INLINE);\n\tbtrfs_set_file_extent_encryption(leaf, ei, 0);\n\tbtrfs_set_file_extent_compression(leaf, ei, 0);\n\tbtrfs_set_file_extent_other_encoding(leaf, ei, 0);\n\tbtrfs_set_file_extent_ram_bytes(leaf, ei, name_len);\n\n\tptr = btrfs_file_extent_inline_start(ei);\n\twrite_extent_buffer(leaf, symname, ptr, name_len);\n\tbtrfs_mark_buffer_dirty(leaf);\n\tbtrfs_free_path(path);\n\n\tinode->i_op = &btrfs_symlink_inode_operations;\n\tinode_nohighmem(inode);\n\tinode_set_bytes(inode, name_len);\n\tbtrfs_i_size_write(BTRFS_I(inode), name_len);\n\terr = btrfs_update_inode(trans, root, BTRFS_I(inode));\n\t/*\n\t * Last step, add directory indexes for our symlink inode. This is the\n\t * last step to avoid extra cleanup of these indexes if an error happens\n\t * elsewhere above.\n\t */\n\tif (!err)\n\t\terr = btrfs_add_nondir(trans, BTRFS_I(dir), dentry,\n\t\t\t\tBTRFS_I(inode), 0, index);\n\tif (err)\n\t\tgoto out_unlock;\n\n\td_instantiate_new(dentry, inode);\n\nout_unlock:\n\tbtrfs_end_transaction(trans);\n\tif (err && inode) {\n\t\tinode_dec_link_count(inode);\n\t\tdiscard_new_inode(inode);\n\t}\n\tbtrfs_btree_balance_dirty(fs_info);\n\treturn err;\n}\n\nstatic struct btrfs_trans_handle *insert_prealloc_file_extent(\n\t\t\t\t       struct btrfs_trans_handle *trans_in,\n\t\t\t\t       struct btrfs_inode *inode,\n\t\t\t\t       struct btrfs_key *ins,\n\t\t\t\t       u64 file_offset)\n{\n\tstruct btrfs_file_extent_item stack_fi;\n\tstruct btrfs_replace_extent_info extent_info;\n\tstruct btrfs_trans_handle *trans = trans_in;\n\tstruct btrfs_path *path;\n\tu64 start = ins->objectid;\n\tu64 len = ins->offset;\n\tint ret;\n\n\tmemset(&stack_fi, 0, sizeof(stack_fi));\n\n\tbtrfs_set_stack_file_extent_type(&stack_fi, BTRFS_FILE_EXTENT_PREALLOC);\n\tbtrfs_set_stack_file_extent_disk_bytenr(&stack_fi, start);\n\tbtrfs_set_stack_file_extent_disk_num_bytes(&stack_fi, len);\n\tbtrfs_set_stack_file_extent_num_bytes(&stack_fi, len);\n\tbtrfs_set_stack_file_extent_ram_bytes(&stack_fi, len);\n\tbtrfs_set_stack_file_extent_compression(&stack_fi, BTRFS_COMPRESS_NONE);\n\t/* Encryption and other encoding is reserved and all 0 */\n\n\tret = btrfs_qgroup_release_data(inode, file_offset, len);\n\tif (ret < 0)\n\t\treturn ERR_PTR(ret);\n\n\tif (trans) {\n\t\tret = insert_reserved_file_extent(trans, inode,\n\t\t\t\t\t\t  file_offset, &stack_fi,\n\t\t\t\t\t\t  true, ret);\n\t\tif (ret)\n\t\t\treturn ERR_PTR(ret);\n\t\treturn trans;\n\t}\n\n\textent_info.disk_offset = start;\n\textent_info.disk_len = len;\n\textent_info.data_offset = 0;\n\textent_info.data_len = len;\n\textent_info.file_offset = file_offset;\n\textent_info.extent_buf = (char *)&stack_fi;\n\textent_info.is_new_extent = true;\n\textent_info.qgroup_reserved = ret;\n\textent_info.insertions = 0;\n\n\tpath = btrfs_alloc_path();\n\tif (!path)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tret = btrfs_replace_file_extents(&inode->vfs_inode, path, file_offset,\n\t\t\t\t     file_offset + len - 1, &extent_info,\n\t\t\t\t     &trans);\n\tbtrfs_free_path(path);\n\tif (ret)\n\t\treturn ERR_PTR(ret);\n\n\treturn trans;\n}\n\nstatic int __btrfs_prealloc_file_range(struct inode *inode, int mode,\n\t\t\t\t       u64 start, u64 num_bytes, u64 min_size,\n\t\t\t\t       loff_t actual_len, u64 *alloc_hint,\n\t\t\t\t       struct btrfs_trans_handle *trans)\n{\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);\n\tstruct extent_map_tree *em_tree = &BTRFS_I(inode)->extent_tree;\n\tstruct extent_map *em;\n\tstruct btrfs_root *root = BTRFS_I(inode)->root;\n\tstruct btrfs_key ins;\n\tu64 cur_offset = start;\n\tu64 clear_offset = start;\n\tu64 i_size;\n\tu64 cur_bytes;\n\tu64 last_alloc = (u64)-1;\n\tint ret = 0;\n\tbool own_trans = true;\n\tu64 end = start + num_bytes - 1;\n\n\tif (trans)\n\t\town_trans = false;\n\twhile (num_bytes > 0) {\n\t\tcur_bytes = min_t(u64, num_bytes, SZ_256M);\n\t\tcur_bytes = max(cur_bytes, min_size);\n\t\t/*\n\t\t * If we are severely fragmented we could end up with really\n\t\t * small allocations, so if the allocator is returning small\n\t\t * chunks lets make its job easier by only searching for those\n\t\t * sized chunks.\n\t\t */\n\t\tcur_bytes = min(cur_bytes, last_alloc);\n\t\tret = btrfs_reserve_extent(root, cur_bytes, cur_bytes,\n\t\t\t\tmin_size, 0, *alloc_hint, &ins, 1, 0);\n\t\tif (ret)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * We've reserved this space, and thus converted it from\n\t\t * ->bytes_may_use to ->bytes_reserved.  Any error that happens\n\t\t * from here on out we will only need to clear our reservation\n\t\t * for the remaining unreserved area, so advance our\n\t\t * clear_offset by our extent size.\n\t\t */\n\t\tclear_offset += ins.offset;\n\n\t\tlast_alloc = ins.offset;\n\t\ttrans = insert_prealloc_file_extent(trans, BTRFS_I(inode),\n\t\t\t\t\t\t    &ins, cur_offset);\n\t\t/*\n\t\t * Now that we inserted the prealloc extent we can finally\n\t\t * decrement the number of reservations in the block group.\n\t\t * If we did it before, we could race with relocation and have\n\t\t * relocation miss the reserved extent, making it fail later.\n\t\t */\n\t\tbtrfs_dec_block_group_reservations(fs_info, ins.objectid);\n\t\tif (IS_ERR(trans)) {\n\t\t\tret = PTR_ERR(trans);\n\t\t\tbtrfs_free_reserved_extent(fs_info, ins.objectid,\n\t\t\t\t\t\t   ins.offset, 0);\n\t\t\tbreak;\n\t\t}\n\n\t\tbtrfs_drop_extent_cache(BTRFS_I(inode), cur_offset,\n\t\t\t\t\tcur_offset + ins.offset -1, 0);\n\n\t\tem = alloc_extent_map();\n\t\tif (!em) {\n\t\t\tset_bit(BTRFS_INODE_NEEDS_FULL_SYNC,\n\t\t\t\t&BTRFS_I(inode)->runtime_flags);\n\t\t\tgoto next;\n\t\t}\n\n\t\tem->start = cur_offset;\n\t\tem->orig_start = cur_offset;\n\t\tem->len = ins.offset;\n\t\tem->block_start = ins.objectid;\n\t\tem->block_len = ins.offset;\n\t\tem->orig_block_len = ins.offset;\n\t\tem->ram_bytes = ins.offset;\n\t\tset_bit(EXTENT_FLAG_PREALLOC, &em->flags);\n\t\tem->generation = trans->transid;\n\n\t\twhile (1) {\n\t\t\twrite_lock(&em_tree->lock);\n\t\t\tret = add_extent_mapping(em_tree, em, 1);\n\t\t\twrite_unlock(&em_tree->lock);\n\t\t\tif (ret != -EEXIST)\n\t\t\t\tbreak;\n\t\t\tbtrfs_drop_extent_cache(BTRFS_I(inode), cur_offset,\n\t\t\t\t\t\tcur_offset + ins.offset - 1,\n\t\t\t\t\t\t0);\n\t\t}\n\t\tfree_extent_map(em);\nnext:\n\t\tnum_bytes -= ins.offset;\n\t\tcur_offset += ins.offset;\n\t\t*alloc_hint = ins.objectid + ins.offset;\n\n\t\tinode_inc_iversion(inode);\n\t\tinode->i_ctime = current_time(inode);\n\t\tBTRFS_I(inode)->flags |= BTRFS_INODE_PREALLOC;\n\t\tif (!(mode & FALLOC_FL_KEEP_SIZE) &&\n\t\t    (actual_len > inode->i_size) &&\n\t\t    (cur_offset > inode->i_size)) {\n\t\t\tif (cur_offset > actual_len)\n\t\t\t\ti_size = actual_len;\n\t\t\telse\n\t\t\t\ti_size = cur_offset;\n\t\t\ti_size_write(inode, i_size);\n\t\t\tbtrfs_inode_safe_disk_i_size_write(BTRFS_I(inode), 0);\n\t\t}\n\n\t\tret = btrfs_update_inode(trans, root, BTRFS_I(inode));\n\n\t\tif (ret) {\n\t\t\tbtrfs_abort_transaction(trans, ret);\n\t\t\tif (own_trans)\n\t\t\t\tbtrfs_end_transaction(trans);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (own_trans) {\n\t\t\tbtrfs_end_transaction(trans);\n\t\t\ttrans = NULL;\n\t\t}\n\t}\n\tif (clear_offset < end)\n\t\tbtrfs_free_reserved_data_space(BTRFS_I(inode), NULL, clear_offset,\n\t\t\tend - clear_offset + 1);\n\treturn ret;\n}\n\nint btrfs_prealloc_file_range(struct inode *inode, int mode,\n\t\t\t      u64 start, u64 num_bytes, u64 min_size,\n\t\t\t      loff_t actual_len, u64 *alloc_hint)\n{\n\treturn __btrfs_prealloc_file_range(inode, mode, start, num_bytes,\n\t\t\t\t\t   min_size, actual_len, alloc_hint,\n\t\t\t\t\t   NULL);\n}\n\nint btrfs_prealloc_file_range_trans(struct inode *inode,\n\t\t\t\t    struct btrfs_trans_handle *trans, int mode,\n\t\t\t\t    u64 start, u64 num_bytes, u64 min_size,\n\t\t\t\t    loff_t actual_len, u64 *alloc_hint)\n{\n\treturn __btrfs_prealloc_file_range(inode, mode, start, num_bytes,\n\t\t\t\t\t   min_size, actual_len, alloc_hint, trans);\n}\n\nstatic int btrfs_set_page_dirty(struct page *page)\n{\n\treturn __set_page_dirty_nobuffers(page);\n}\n\nstatic int btrfs_permission(struct user_namespace *mnt_userns,\n\t\t\t    struct inode *inode, int mask)\n{\n\tstruct btrfs_root *root = BTRFS_I(inode)->root;\n\tumode_t mode = inode->i_mode;\n\n\tif (mask & MAY_WRITE &&\n\t    (S_ISREG(mode) || S_ISDIR(mode) || S_ISLNK(mode))) {\n\t\tif (btrfs_root_readonly(root))\n\t\t\treturn -EROFS;\n\t\tif (BTRFS_I(inode)->flags & BTRFS_INODE_READONLY)\n\t\t\treturn -EACCES;\n\t}\n\treturn generic_permission(&init_user_ns, inode, mask);\n}\n\nstatic int btrfs_tmpfile(struct user_namespace *mnt_userns, struct inode *dir,\n\t\t\t struct dentry *dentry, umode_t mode)\n{\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(dir->i_sb);\n\tstruct btrfs_trans_handle *trans;\n\tstruct btrfs_root *root = BTRFS_I(dir)->root;\n\tstruct inode *inode = NULL;\n\tu64 objectid;\n\tu64 index;\n\tint ret = 0;\n\n\t/*\n\t * 5 units required for adding orphan entry\n\t */\n\ttrans = btrfs_start_transaction(root, 5);\n\tif (IS_ERR(trans))\n\t\treturn PTR_ERR(trans);\n\n\tret = btrfs_get_free_objectid(root, &objectid);\n\tif (ret)\n\t\tgoto out;\n\n\tinode = btrfs_new_inode(trans, root, dir, NULL, 0,\n\t\t\tbtrfs_ino(BTRFS_I(dir)), objectid, mode, &index);\n\tif (IS_ERR(inode)) {\n\t\tret = PTR_ERR(inode);\n\t\tinode = NULL;\n\t\tgoto out;\n\t}\n\n\tinode->i_fop = &btrfs_file_operations;\n\tinode->i_op = &btrfs_file_inode_operations;\n\n\tinode->i_mapping->a_ops = &btrfs_aops;\n\n\tret = btrfs_init_inode_security(trans, inode, dir, NULL);\n\tif (ret)\n\t\tgoto out;\n\n\tret = btrfs_update_inode(trans, root, BTRFS_I(inode));\n\tif (ret)\n\t\tgoto out;\n\tret = btrfs_orphan_add(trans, BTRFS_I(inode));\n\tif (ret)\n\t\tgoto out;\n\n\t/*\n\t * We set number of links to 0 in btrfs_new_inode(), and here we set\n\t * it to 1 because d_tmpfile() will issue a warning if the count is 0,\n\t * through:\n\t *\n\t *    d_tmpfile() -> inode_dec_link_count() -> drop_nlink()\n\t */\n\tset_nlink(inode, 1);\n\td_tmpfile(dentry, inode);\n\tunlock_new_inode(inode);\n\tmark_inode_dirty(inode);\nout:\n\tbtrfs_end_transaction(trans);\n\tif (ret && inode)\n\t\tdiscard_new_inode(inode);\n\tbtrfs_btree_balance_dirty(fs_info);\n\treturn ret;\n}\n\nvoid btrfs_set_range_writeback(struct extent_io_tree *tree, u64 start, u64 end)\n{\n\tstruct inode *inode = tree->private_data;\n\tunsigned long index = start >> PAGE_SHIFT;\n\tunsigned long end_index = end >> PAGE_SHIFT;\n\tstruct page *page;\n\n\twhile (index <= end_index) {\n\t\tpage = find_get_page(inode->i_mapping, index);\n\t\tASSERT(page); /* Pages should be in the extent_io_tree */\n\t\tset_page_writeback(page);\n\t\tput_page(page);\n\t\tindex++;\n\t}\n}\n\n#ifdef CONFIG_SWAP\n/*\n * Add an entry indicating a block group or device which is pinned by a\n * swapfile. Returns 0 on success, 1 if there is already an entry for it, or a\n * negative errno on failure.\n */\nstatic int btrfs_add_swapfile_pin(struct inode *inode, void *ptr,\n\t\t\t\t  bool is_block_group)\n{\n\tstruct btrfs_fs_info *fs_info = BTRFS_I(inode)->root->fs_info;\n\tstruct btrfs_swapfile_pin *sp, *entry;\n\tstruct rb_node **p;\n\tstruct rb_node *parent = NULL;\n\n\tsp = kmalloc(sizeof(*sp), GFP_NOFS);\n\tif (!sp)\n\t\treturn -ENOMEM;\n\tsp->ptr = ptr;\n\tsp->inode = inode;\n\tsp->is_block_group = is_block_group;\n\tsp->bg_extent_count = 1;\n\n\tspin_lock(&fs_info->swapfile_pins_lock);\n\tp = &fs_info->swapfile_pins.rb_node;\n\twhile (*p) {\n\t\tparent = *p;\n\t\tentry = rb_entry(parent, struct btrfs_swapfile_pin, node);\n\t\tif (sp->ptr < entry->ptr ||\n\t\t    (sp->ptr == entry->ptr && sp->inode < entry->inode)) {\n\t\t\tp = &(*p)->rb_left;\n\t\t} else if (sp->ptr > entry->ptr ||\n\t\t\t   (sp->ptr == entry->ptr && sp->inode > entry->inode)) {\n\t\t\tp = &(*p)->rb_right;\n\t\t} else {\n\t\t\tif (is_block_group)\n\t\t\t\tentry->bg_extent_count++;\n\t\t\tspin_unlock(&fs_info->swapfile_pins_lock);\n\t\t\tkfree(sp);\n\t\t\treturn 1;\n\t\t}\n\t}\n\trb_link_node(&sp->node, parent, p);\n\trb_insert_color(&sp->node, &fs_info->swapfile_pins);\n\tspin_unlock(&fs_info->swapfile_pins_lock);\n\treturn 0;\n}\n\n/* Free all of the entries pinned by this swapfile. */\nstatic void btrfs_free_swapfile_pins(struct inode *inode)\n{\n\tstruct btrfs_fs_info *fs_info = BTRFS_I(inode)->root->fs_info;\n\tstruct btrfs_swapfile_pin *sp;\n\tstruct rb_node *node, *next;\n\n\tspin_lock(&fs_info->swapfile_pins_lock);\n\tnode = rb_first(&fs_info->swapfile_pins);\n\twhile (node) {\n\t\tnext = rb_next(node);\n\t\tsp = rb_entry(node, struct btrfs_swapfile_pin, node);\n\t\tif (sp->inode == inode) {\n\t\t\trb_erase(&sp->node, &fs_info->swapfile_pins);\n\t\t\tif (sp->is_block_group) {\n\t\t\t\tbtrfs_dec_block_group_swap_extents(sp->ptr,\n\t\t\t\t\t\t\t   sp->bg_extent_count);\n\t\t\t\tbtrfs_put_block_group(sp->ptr);\n\t\t\t}\n\t\t\tkfree(sp);\n\t\t}\n\t\tnode = next;\n\t}\n\tspin_unlock(&fs_info->swapfile_pins_lock);\n}\n\nstruct btrfs_swap_info {\n\tu64 start;\n\tu64 block_start;\n\tu64 block_len;\n\tu64 lowest_ppage;\n\tu64 highest_ppage;\n\tunsigned long nr_pages;\n\tint nr_extents;\n};\n\nstatic int btrfs_add_swap_extent(struct swap_info_struct *sis,\n\t\t\t\t struct btrfs_swap_info *bsi)\n{\n\tunsigned long nr_pages;\n\tu64 first_ppage, first_ppage_reported, next_ppage;\n\tint ret;\n\n\tfirst_ppage = ALIGN(bsi->block_start, PAGE_SIZE) >> PAGE_SHIFT;\n\tnext_ppage = ALIGN_DOWN(bsi->block_start + bsi->block_len,\n\t\t\t\tPAGE_SIZE) >> PAGE_SHIFT;\n\n\tif (first_ppage >= next_ppage)\n\t\treturn 0;\n\tnr_pages = next_ppage - first_ppage;\n\n\tfirst_ppage_reported = first_ppage;\n\tif (bsi->start == 0)\n\t\tfirst_ppage_reported++;\n\tif (bsi->lowest_ppage > first_ppage_reported)\n\t\tbsi->lowest_ppage = first_ppage_reported;\n\tif (bsi->highest_ppage < (next_ppage - 1))\n\t\tbsi->highest_ppage = next_ppage - 1;\n\n\tret = add_swap_extent(sis, bsi->nr_pages, nr_pages, first_ppage);\n\tif (ret < 0)\n\t\treturn ret;\n\tbsi->nr_extents += ret;\n\tbsi->nr_pages += nr_pages;\n\treturn 0;\n}\n\nstatic void btrfs_swap_deactivate(struct file *file)\n{\n\tstruct inode *inode = file_inode(file);\n\n\tbtrfs_free_swapfile_pins(inode);\n\tatomic_dec(&BTRFS_I(inode)->root->nr_swapfiles);\n}\n\nstatic int btrfs_swap_activate(struct swap_info_struct *sis, struct file *file,\n\t\t\t       sector_t *span)\n{\n\tstruct inode *inode = file_inode(file);\n\tstruct btrfs_root *root = BTRFS_I(inode)->root;\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tstruct extent_io_tree *io_tree = &BTRFS_I(inode)->io_tree;\n\tstruct extent_state *cached_state = NULL;\n\tstruct extent_map *em = NULL;\n\tstruct btrfs_device *device = NULL;\n\tstruct btrfs_swap_info bsi = {\n\t\t.lowest_ppage = (sector_t)-1ULL,\n\t};\n\tint ret = 0;\n\tu64 isize;\n\tu64 start;\n\n\t/*\n\t * If the swap file was just created, make sure delalloc is done. If the\n\t * file changes again after this, the user is doing something stupid and\n\t * we don't really care.\n\t */\n\tret = btrfs_wait_ordered_range(inode, 0, (u64)-1);\n\tif (ret)\n\t\treturn ret;\n\n\t/*\n\t * The inode is locked, so these flags won't change after we check them.\n\t */\n\tif (BTRFS_I(inode)->flags & BTRFS_INODE_COMPRESS) {\n\t\tbtrfs_warn(fs_info, \"swapfile must not be compressed\");\n\t\treturn -EINVAL;\n\t}\n\tif (!(BTRFS_I(inode)->flags & BTRFS_INODE_NODATACOW)) {\n\t\tbtrfs_warn(fs_info, \"swapfile must not be copy-on-write\");\n\t\treturn -EINVAL;\n\t}\n\tif (!(BTRFS_I(inode)->flags & BTRFS_INODE_NODATASUM)) {\n\t\tbtrfs_warn(fs_info, \"swapfile must not be checksummed\");\n\t\treturn -EINVAL;\n\t}\n\n\t/*\n\t * Balance or device remove/replace/resize can move stuff around from\n\t * under us. The exclop protection makes sure they aren't running/won't\n\t * run concurrently while we are mapping the swap extents, and\n\t * fs_info->swapfile_pins prevents them from running while the swap\n\t * file is active and moving the extents. Note that this also prevents\n\t * a concurrent device add which isn't actually necessary, but it's not\n\t * really worth the trouble to allow it.\n\t */\n\tif (!btrfs_exclop_start(fs_info, BTRFS_EXCLOP_SWAP_ACTIVATE)) {\n\t\tbtrfs_warn(fs_info,\n\t   \"cannot activate swapfile while exclusive operation is running\");\n\t\treturn -EBUSY;\n\t}\n\n\t/*\n\t * Prevent snapshot creation while we are activating the swap file.\n\t * We do not want to race with snapshot creation. If snapshot creation\n\t * already started before we bumped nr_swapfiles from 0 to 1 and\n\t * completes before the first write into the swap file after it is\n\t * activated, than that write would fallback to COW.\n\t */\n\tif (!btrfs_drew_try_write_lock(&root->snapshot_lock)) {\n\t\tbtrfs_exclop_finish(fs_info);\n\t\tbtrfs_warn(fs_info,\n\t   \"cannot activate swapfile because snapshot creation is in progress\");\n\t\treturn -EINVAL;\n\t}\n\t/*\n\t * Snapshots can create extents which require COW even if NODATACOW is\n\t * set. We use this counter to prevent snapshots. We must increment it\n\t * before walking the extents because we don't want a concurrent\n\t * snapshot to run after we've already checked the extents.\n\t */\n\tatomic_inc(&root->nr_swapfiles);\n\n\tisize = ALIGN_DOWN(inode->i_size, fs_info->sectorsize);\n\n\tlock_extent_bits(io_tree, 0, isize - 1, &cached_state);\n\tstart = 0;\n\twhile (start < isize) {\n\t\tu64 logical_block_start, physical_block_start;\n\t\tstruct btrfs_block_group *bg;\n\t\tu64 len = isize - start;\n\n\t\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, start, len);\n\t\tif (IS_ERR(em)) {\n\t\t\tret = PTR_ERR(em);\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (em->block_start == EXTENT_MAP_HOLE) {\n\t\t\tbtrfs_warn(fs_info, \"swapfile must not have holes\");\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tif (em->block_start == EXTENT_MAP_INLINE) {\n\t\t\t/*\n\t\t\t * It's unlikely we'll ever actually find ourselves\n\t\t\t * here, as a file small enough to fit inline won't be\n\t\t\t * big enough to store more than the swap header, but in\n\t\t\t * case something changes in the future, let's catch it\n\t\t\t * here rather than later.\n\t\t\t */\n\t\t\tbtrfs_warn(fs_info, \"swapfile must not be inline\");\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tif (test_bit(EXTENT_FLAG_COMPRESSED, &em->flags)) {\n\t\t\tbtrfs_warn(fs_info, \"swapfile must not be compressed\");\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tlogical_block_start = em->block_start + (start - em->start);\n\t\tlen = min(len, em->len - (start - em->start));\n\t\tfree_extent_map(em);\n\t\tem = NULL;\n\n\t\tret = can_nocow_extent(inode, start, &len, NULL, NULL, NULL, true);\n\t\tif (ret < 0) {\n\t\t\tgoto out;\n\t\t} else if (ret) {\n\t\t\tret = 0;\n\t\t} else {\n\t\t\tbtrfs_warn(fs_info,\n\t\t\t\t   \"swapfile must not be copy-on-write\");\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tem = btrfs_get_chunk_map(fs_info, logical_block_start, len);\n\t\tif (IS_ERR(em)) {\n\t\t\tret = PTR_ERR(em);\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (em->map_lookup->type & BTRFS_BLOCK_GROUP_PROFILE_MASK) {\n\t\t\tbtrfs_warn(fs_info,\n\t\t\t\t   \"swapfile must have single data profile\");\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (device == NULL) {\n\t\t\tdevice = em->map_lookup->stripes[0].dev;\n\t\t\tret = btrfs_add_swapfile_pin(inode, device, false);\n\t\t\tif (ret == 1)\n\t\t\t\tret = 0;\n\t\t\telse if (ret)\n\t\t\t\tgoto out;\n\t\t} else if (device != em->map_lookup->stripes[0].dev) {\n\t\t\tbtrfs_warn(fs_info, \"swapfile must be on one device\");\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tphysical_block_start = (em->map_lookup->stripes[0].physical +\n\t\t\t\t\t(logical_block_start - em->start));\n\t\tlen = min(len, em->len - (logical_block_start - em->start));\n\t\tfree_extent_map(em);\n\t\tem = NULL;\n\n\t\tbg = btrfs_lookup_block_group(fs_info, logical_block_start);\n\t\tif (!bg) {\n\t\t\tbtrfs_warn(fs_info,\n\t\t\t   \"could not find block group containing swapfile\");\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (!btrfs_inc_block_group_swap_extents(bg)) {\n\t\t\tbtrfs_warn(fs_info,\n\t\t\t   \"block group for swapfile at %llu is read-only%s\",\n\t\t\t   bg->start,\n\t\t\t   atomic_read(&fs_info->scrubs_running) ?\n\t\t\t\t       \" (scrub running)\" : \"\");\n\t\t\tbtrfs_put_block_group(bg);\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tret = btrfs_add_swapfile_pin(inode, bg, true);\n\t\tif (ret) {\n\t\t\tbtrfs_put_block_group(bg);\n\t\t\tif (ret == 1)\n\t\t\t\tret = 0;\n\t\t\telse\n\t\t\t\tgoto out;\n\t\t}\n\n\t\tif (bsi.block_len &&\n\t\t    bsi.block_start + bsi.block_len == physical_block_start) {\n\t\t\tbsi.block_len += len;\n\t\t} else {\n\t\t\tif (bsi.block_len) {\n\t\t\t\tret = btrfs_add_swap_extent(sis, &bsi);\n\t\t\t\tif (ret)\n\t\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tbsi.start = start;\n\t\t\tbsi.block_start = physical_block_start;\n\t\t\tbsi.block_len = len;\n\t\t}\n\n\t\tstart += len;\n\t}\n\n\tif (bsi.block_len)\n\t\tret = btrfs_add_swap_extent(sis, &bsi);\n\nout:\n\tif (!IS_ERR_OR_NULL(em))\n\t\tfree_extent_map(em);\n\n\tunlock_extent_cached(io_tree, 0, isize - 1, &cached_state);\n\n\tif (ret)\n\t\tbtrfs_swap_deactivate(file);\n\n\tbtrfs_drew_write_unlock(&root->snapshot_lock);\n\n\tbtrfs_exclop_finish(fs_info);\n\n\tif (ret)\n\t\treturn ret;\n\n\tif (device)\n\t\tsis->bdev = device->bdev;\n\t*span = bsi.highest_ppage - bsi.lowest_ppage + 1;\n\tsis->max = bsi.nr_pages;\n\tsis->pages = bsi.nr_pages - 1;\n\tsis->highest_bit = bsi.nr_pages - 1;\n\treturn bsi.nr_extents;\n}\n#else\nstatic void btrfs_swap_deactivate(struct file *file)\n{\n}\n\nstatic int btrfs_swap_activate(struct swap_info_struct *sis, struct file *file,\n\t\t\t       sector_t *span)\n{\n\treturn -EOPNOTSUPP;\n}\n#endif\n\n/*\n * Update the number of bytes used in the VFS' inode. When we replace extents in\n * a range (clone, dedupe, fallocate's zero range), we must update the number of\n * bytes used by the inode in an atomic manner, so that concurrent stat(2) calls\n * always get a correct value.\n */\nvoid btrfs_update_inode_bytes(struct btrfs_inode *inode,\n\t\t\t      const u64 add_bytes,\n\t\t\t      const u64 del_bytes)\n{\n\tif (add_bytes == del_bytes)\n\t\treturn;\n\n\tspin_lock(&inode->lock);\n\tif (del_bytes > 0)\n\t\tinode_sub_bytes(&inode->vfs_inode, del_bytes);\n\tif (add_bytes > 0)\n\t\tinode_add_bytes(&inode->vfs_inode, add_bytes);\n\tspin_unlock(&inode->lock);\n}\n\nstatic const struct inode_operations btrfs_dir_inode_operations = {\n\t.getattr\t= btrfs_getattr,\n\t.lookup\t\t= btrfs_lookup,\n\t.create\t\t= btrfs_create,\n\t.unlink\t\t= btrfs_unlink,\n\t.link\t\t= btrfs_link,\n\t.mkdir\t\t= btrfs_mkdir,\n\t.rmdir\t\t= btrfs_rmdir,\n\t.rename\t\t= btrfs_rename2,\n\t.symlink\t= btrfs_symlink,\n\t.setattr\t= btrfs_setattr,\n\t.mknod\t\t= btrfs_mknod,\n\t.listxattr\t= btrfs_listxattr,\n\t.permission\t= btrfs_permission,\n\t.get_acl\t= btrfs_get_acl,\n\t.set_acl\t= btrfs_set_acl,\n\t.update_time\t= btrfs_update_time,\n\t.tmpfile        = btrfs_tmpfile,\n};\n\nstatic const struct file_operations btrfs_dir_file_operations = {\n\t.llseek\t\t= generic_file_llseek,\n\t.read\t\t= generic_read_dir,\n\t.iterate_shared\t= btrfs_real_readdir,\n\t.open\t\t= btrfs_opendir,\n\t.unlocked_ioctl\t= btrfs_ioctl,\n#ifdef CONFIG_COMPAT\n\t.compat_ioctl\t= btrfs_compat_ioctl,\n#endif\n\t.release        = btrfs_release_file,\n\t.fsync\t\t= btrfs_sync_file,\n};\n\n/*\n * btrfs doesn't support the bmap operation because swapfiles\n * use bmap to make a mapping of extents in the file.  They assume\n * these extents won't change over the life of the file and they\n * use the bmap result to do IO directly to the drive.\n *\n * the btrfs bmap call would return logical addresses that aren't\n * suitable for IO and they also will change frequently as COW\n * operations happen.  So, swapfile + btrfs == corruption.\n *\n * For now we're avoiding this by dropping bmap.\n */\nstatic const struct address_space_operations btrfs_aops = {\n\t.readpage\t= btrfs_readpage,\n\t.writepage\t= btrfs_writepage,\n\t.writepages\t= btrfs_writepages,\n\t.readahead\t= btrfs_readahead,\n\t.direct_IO\t= noop_direct_IO,\n\t.invalidatepage = btrfs_invalidatepage,\n\t.releasepage\t= btrfs_releasepage,\n#ifdef CONFIG_MIGRATION\n\t.migratepage\t= btrfs_migratepage,\n#endif\n\t.set_page_dirty\t= btrfs_set_page_dirty,\n\t.error_remove_page = generic_error_remove_page,\n\t.swap_activate\t= btrfs_swap_activate,\n\t.swap_deactivate = btrfs_swap_deactivate,\n};\n\nstatic const struct inode_operations btrfs_file_inode_operations = {\n\t.getattr\t= btrfs_getattr,\n\t.setattr\t= btrfs_setattr,\n\t.listxattr      = btrfs_listxattr,\n\t.permission\t= btrfs_permission,\n\t.fiemap\t\t= btrfs_fiemap,\n\t.get_acl\t= btrfs_get_acl,\n\t.set_acl\t= btrfs_set_acl,\n\t.update_time\t= btrfs_update_time,\n};\nstatic const struct inode_operations btrfs_special_inode_operations = {\n\t.getattr\t= btrfs_getattr,\n\t.setattr\t= btrfs_setattr,\n\t.permission\t= btrfs_permission,\n\t.listxattr\t= btrfs_listxattr,\n\t.get_acl\t= btrfs_get_acl,\n\t.set_acl\t= btrfs_set_acl,\n\t.update_time\t= btrfs_update_time,\n};\nstatic const struct inode_operations btrfs_symlink_inode_operations = {\n\t.get_link\t= page_get_link,\n\t.getattr\t= btrfs_getattr,\n\t.setattr\t= btrfs_setattr,\n\t.permission\t= btrfs_permission,\n\t.listxattr\t= btrfs_listxattr,\n\t.update_time\t= btrfs_update_time,\n};\n\nconst struct dentry_operations btrfs_dentry_operations = {\n\t.d_delete\t= btrfs_dentry_delete,\n};\n"}}, "reports": [{"events": [{"location": {"col": 0, "file": 0, "line": 254}, "message": "error: we previously assumed 'compressed_pages' could be null (see line 223)"}], "macros": [], "notes": [], "path": "/src/fs/btrfs/inode.c", "reportHash": "db0eee3f00452130984df1fa1747c522", "checkerName": "smatch.check_check_deref", "reviewStatus": null, "severity": "UNSPECIFIED"}]};
      window.onload = function() {
        if (!browserCompatible) {
          setNonCompatibleBrowserMessage();
        } else {
          BugViewer.init(data.files, data.reports);
          BugViewer.create();
          BugViewer.initByUrl();
        }
      };
    </script>
  </head>
  <body>
  <div class="container">
    <div id="content">
      <div id="side-bar">
        <div class="header">
          <a href="index.html" class="button">&#8249; Return to List</a>
        </div>
        <div id="report-nav">
          <div class="header">Reports</div>
        </div>
      </div>
      <div id="editor-wrapper">
        <div class="header">
          <div id="file">
            <span class="label">File:</span>
            <span id="file-path"></span>
          </div>
          <div id="checker">
            <span class="label">Checker name:</span>
            <span id="checker-name"></span>
          </div>
          <div id="review-status-wrapper">
            <span class="label">Review status:</span>
            <span id="review-status"></span>
          </div>
        </div>
        <div id="editor"></div>
      </div>
    </div>
  </div>
  </body>
</html>
