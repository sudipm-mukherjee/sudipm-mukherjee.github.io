<!DOCTYPE html>
<html>
  <head>
    <title>Plist HTML Viewer</title>

    <meta charset="UTF-8">

    <style type="text/css">
      .CodeMirror{font-family:monospace;height:300px;color:#000;direction:ltr}.CodeMirror-lines{padding:4px 0}.CodeMirror pre{padding:0 4px}.CodeMirror-gutter-filler,.CodeMirror-scrollbar-filler{background-color:#fff}.CodeMirror-gutters{border-right:1px solid #ddd;background-color:#f7f7f7;white-space:nowrap}.CodeMirror-linenumber{padding:0 3px 0 5px;min-width:20px;text-align:right;color:#999;white-space:nowrap}.CodeMirror-guttermarker{color:#000}.CodeMirror-guttermarker-subtle{color:#999}.CodeMirror-cursor{border-left:1px solid #000;border-right:none;width:0}.CodeMirror div.CodeMirror-secondarycursor{border-left:1px solid silver}.cm-fat-cursor .CodeMirror-cursor{width:auto;border:0!important;background:#7e7}.cm-fat-cursor div.CodeMirror-cursors{z-index:1}.cm-animate-fat-cursor{width:auto;border:0;-webkit-animation:blink 1.06s steps(1) infinite;-moz-animation:blink 1.06s steps(1) infinite;animation:blink 1.06s steps(1) infinite;background-color:#7e7}@-moz-keyframes blink{50%{background-color:transparent}}@-webkit-keyframes blink{50%{background-color:transparent}}@keyframes blink{50%{background-color:transparent}}.cm-tab{display:inline-block;text-decoration:inherit}.CodeMirror-rulers{position:absolute;left:0;right:0;top:-50px;bottom:-20px;overflow:hidden}.CodeMirror-ruler{border-left:1px solid #ccc;top:0;bottom:0;position:absolute}.cm-s-default .cm-header{color:#00f}.cm-s-default .cm-quote{color:#090}.cm-negative{color:#d44}.cm-positive{color:#292}.cm-header,.cm-strong{font-weight:700}.cm-em{font-style:italic}.cm-link{text-decoration:underline}.cm-strikethrough{text-decoration:line-through}.cm-s-default .cm-keyword{color:#708}.cm-s-default .cm-atom{color:#219}.cm-s-default .cm-number{color:#164}.cm-s-default .cm-def{color:#00f}.cm-s-default .cm-variable-2{color:#05a}.cm-s-default .cm-type,.cm-s-default .cm-variable-3{color:#085}.cm-s-default .cm-comment{color:#a50}.cm-s-default .cm-string{color:#a11}.cm-s-default .cm-string-2{color:#f50}.cm-s-default .cm-meta{color:#555}.cm-s-default .cm-qualifier{color:#555}.cm-s-default .cm-builtin{color:#30a}.cm-s-default .cm-bracket{color:#997}.cm-s-default .cm-tag{color:#170}.cm-s-default .cm-attribute{color:#00c}.cm-s-default .cm-hr{color:#999}.cm-s-default .cm-link{color:#00c}.cm-s-default .cm-error{color:red}.cm-invalidchar{color:red}.CodeMirror-composing{border-bottom:2px solid}div.CodeMirror span.CodeMirror-matchingbracket{color:#0f0}div.CodeMirror span.CodeMirror-nonmatchingbracket{color:#f22}.CodeMirror-matchingtag{background:rgba(255,150,0,.3)}.CodeMirror-activeline-background{background:#e8f2ff}.CodeMirror{position:relative;overflow:hidden;background:#fff}.CodeMirror-scroll{overflow:scroll!important;margin-bottom:-30px;margin-right:-30px;padding-bottom:30px;height:100%;outline:0;position:relative}.CodeMirror-sizer{position:relative;border-right:30px solid transparent}.CodeMirror-gutter-filler,.CodeMirror-hscrollbar,.CodeMirror-scrollbar-filler,.CodeMirror-vscrollbar{position:absolute;z-index:6;display:none}.CodeMirror-vscrollbar{right:0;top:0;overflow-x:hidden;overflow-y:scroll}.CodeMirror-hscrollbar{bottom:0;left:0;overflow-y:hidden;overflow-x:scroll}.CodeMirror-scrollbar-filler{right:0;bottom:0}.CodeMirror-gutter-filler{left:0;bottom:0}.CodeMirror-gutters{position:absolute;left:0;top:0;min-height:100%;z-index:3}.CodeMirror-gutter{white-space:normal;height:100%;display:inline-block;vertical-align:top;margin-bottom:-30px}.CodeMirror-gutter-wrapper{position:absolute;z-index:4;background:0 0!important;border:none!important}.CodeMirror-gutter-background{position:absolute;top:0;bottom:0;z-index:4}.CodeMirror-gutter-elt{position:absolute;cursor:default;z-index:4}.CodeMirror-gutter-wrapper ::selection{background-color:transparent}.CodeMirror-gutter-wrapper ::-moz-selection{background-color:transparent}.CodeMirror-lines{cursor:text;min-height:1px}.CodeMirror pre{-moz-border-radius:0;-webkit-border-radius:0;border-radius:0;border-width:0;background:0 0;font-family:inherit;font-size:inherit;margin:0;white-space:pre;word-wrap:normal;line-height:inherit;color:inherit;z-index:2;position:relative;overflow:visible;-webkit-tap-highlight-color:transparent;-webkit-font-variant-ligatures:contextual;font-variant-ligatures:contextual}.CodeMirror-wrap pre{word-wrap:break-word;white-space:pre-wrap;word-break:normal}.CodeMirror-linebackground{position:absolute;left:0;right:0;top:0;bottom:0;z-index:0}.CodeMirror-linewidget{position:relative;z-index:2;overflow:auto}.CodeMirror-rtl pre{direction:rtl}.CodeMirror-code{outline:0}.CodeMirror-gutter,.CodeMirror-gutters,.CodeMirror-linenumber,.CodeMirror-scroll,.CodeMirror-sizer{-moz-box-sizing:content-box;box-sizing:content-box}.CodeMirror-measure{position:absolute;width:100%;height:0;overflow:hidden;visibility:hidden}.CodeMirror-cursor{position:absolute;pointer-events:none}.CodeMirror-measure pre{position:static}div.CodeMirror-cursors{visibility:hidden;position:relative;z-index:3}div.CodeMirror-dragcursors{visibility:visible}.CodeMirror-focused div.CodeMirror-cursors{visibility:visible}.CodeMirror-selected{background:#d9d9d9}.CodeMirror-focused .CodeMirror-selected{background:#d7d4f0}.CodeMirror-crosshair{cursor:crosshair}.CodeMirror-line::selection,.CodeMirror-line>span::selection,.CodeMirror-line>span>span::selection{background:#d7d4f0}.CodeMirror-line::-moz-selection,.CodeMirror-line>span::-moz-selection,.CodeMirror-line>span>span::-moz-selection{background:#d7d4f0}.cm-searching{background-color:#ffa;background-color:rgba(255,255,0,.4)}.cm-force-border{padding-right:.1px}@media print{.CodeMirror div.CodeMirror-cursors{visibility:hidden}}.cm-tab-wrap-hack:after{content:''}span.CodeMirror-selectedtext{background:0 0}
/*# sourceMappingURL=codemirror.min.css.map */

      .severity-low {
  background-color: #669603;
}

.severity-low:after {
  content : 'L';
}

.severity-unspecified {
  background-color: #666666;
}

.severity-unspecified:after {
  content : 'U';
}

.severity-style {
  background-color: #9932cc;
}

.severity-style:after {
  content : 'S';
}

.severity-medium {
  background-color: #a9d323;
  color: black;
}

.severity-medium:after {
  content : 'M';
}

.severity-high {
  background-color: #ffa800;
}

.severity-high:after {
  content : 'H';
}

.severity-critical {
  background-color: #e92625;
}

.severity-critical:after {
  content : 'C';
}

i[class*="severity-"] {
  line-height: normal;
  text-transform: capitalize;
  font-size: 0.8em;
  font-weight: bold;
  color: white;
  display: inline-block;
  width: 16px;
  height: 16px;
  text-align: center;
  font-family: sans-serif;
}

      html, body {
  width: 100%;
  height: 100%;
  padding: 0px;
  margin: 0px;
}

div.container {
  padding: 10px;
}

#content {
  height: 100%;
  display: block;
  overflow: hidden;
}

#content > div {
  margin: 10px;
  overflow: hidden;
  border: 1px solid #ddd;
  border-radius: 3px;
  overflow: hidden;
  height: 97%;
}

.button {
  background-color: #f1f1f1;
  text-decoration: none;
  display: inline-block;
  padding: 8px 16px;
  color: black;
  cursor: pointer;
}

.button:hover {
  background-color: #ddd;
  color: black;
}

.review-status {
  color: white;
  text-align: center;
}

.review-status-confirmed {
  background-color: #e92625;
}

.review-status-false-positive {
  background-color: grey;
}

.review-status-intentional {
  background-color: #669603;
}

      div.container {
  width: 100%;
  height: 100%;
  padding: 0px;
}

#editor-wrapper {
  margin: 10px;
}

#side-bar {
  float: left;
  width: 260px;
  margin: 0px;
}

#report-nav ul {
  list-style-type: none;
  padding: 0;
  margin: 0;
  overflow-y: auto;
  height: 100%;
}

#report-nav ul > li {
  padding: .4em;
  background-color: #fff;
  border-bottom: 1px solid rgba(0,0,0,.125);
  text-align: left;
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

#report-nav ul > li.active {
  background-color: #427ea9;
  color: white;
}

#report-nav ul > li:hover {
  background-color: #427ea9;
  color: white;
  cursor: pointer;
}

#report-nav ul a {
  text-decoration: none;
}

#report-nav i[class*="severity-"] {
  margin-right: 5px;
}

.header {
  border-bottom: 1px solid lightgrey;
  font-family: monospace;
  padding: 10px;
  background-color: #fafbfc;
  border-bottom: 1px solid #e1e4e8;
  border-top-left-radius: 2px;
  border-top-right-radius: 2px;
}

#report-nav .header {
  font-weight: bold;
}

#editor-wrapper .header > div {
  padding-top: 2px;
}

#file-path,
#checker-name {
  color: #195ea2;
}

#review-status {
  padding: 0px 5px;
}

#file-path {
  font-family: monospace;
}

.check-msg {
  display: inline-block;
  padding: 3px 6px;
  margin: 1px;
  -webkit-border-radius: 5px;
  -moz-border-radius: 5px;
  border-radius: 5px;
}

.check-msg.info {
  color: #00546f;
  background-color: #bfdfe9;
  border: 1px solid #87a8b3;
}

.check-msg.error {
  background-color: #f2dede;
  color: #a94442;
  border: 1px solid #ebcccc;
}

.check-msg.macro {
  background-color: #d7dac2;
  color: #4f5c6d;
  border: 1px solid #d7dac2;
}

.check-msg.note {
  background-color: #d7d7d7;
  color: #4f5c6d;
  border: 1px solid #bfbfbf;
}

.check-msg.current {
  border: 2px dashed #3692ff;
}

.check-msg .tag {
  padding: 1px 5px;
  text-align: center;
  border-radius: 2px;
  margin-right: 5px;
  text-decoration: inherit;
}

.check-msg .tag.macro {
  background-color: #83876a;
  color: white;
  text-transform: capitalize;
}

.check-msg .tag.note {
  background-color: #9299a1;
  color: white;
  text-transform: capitalize;
}

.checker-enum {
  color: white;
  padding: 1px 5px;
  text-align: center;
  border-radius: 25px;
  margin-right: 5px;
  text-decoration: inherit;
}

.checker-enum.info {
  background-color: #427ea9;
}

.checker-enum.error {
  background-color: #a94442;
}

.arrow {
  border: solid black;
  border-width: 0 3px 3px 0;
  display: inline-block;
  padding: 3px;
  cursor: pointer;
  margin: 0px 5px;
}

.arrow:hover {
  border: solid #437ea8;
  border-width: 0 3px 3px 0;
}

.left-arrow {
  transform: rotate(135deg);
  -webkit-transform: rotate(135deg);
}

.right-arrow {
  transform: rotate(-45deg);
  -webkit-transform: rotate(-45deg);
}

    </style>

    <script type="text/javascript">
      function setNonCompatibleBrowserMessage() {
  document.body.innerHTML =
    '<h2 style="margin-left: 20px;">Your browser is not compatible with CodeChecker Viewer!</h2> \
     <p style="margin-left: 20px;">The version required for the following browsers are:</p> \
     <ul style="margin-left: 20px;"> \
     <li>Internet Explorer: version 9 or newer</li> \
     <li>Firefox: version 22.0 or newer</li> \
     </ul>';
}

// http://stackoverflow.com/questions/5916900/how-can-you-detect-the-version-of-a-browser
var browserVersion = (function(){
  var ua = navigator.userAgent, tem,
    M = ua.match(/(opera|chrome|safari|firefox|msie|trident(?=\/))\/?\s*(\d+)/i) || [];

  if (/trident/i.test(M[1])) {
    tem = /\brv[ :]+(\d+)/g.exec(ua) || [];
    return 'IE ' + (tem[1] || '');
  }

  if (M[1] === 'Chrome') {
    tem = ua.match(/\b(OPR|Edge)\/(\d+)/);
    if (tem != null) return tem.slice(1).join(' ').replace('OPR', 'Opera');
  }

  M = M[2] ? [M[1], M[2]] : [navigator.appName, navigator.appVersion, '-?'];
  if ((tem = ua.match(/version\/(\d+)/i)) != null) M.splice(1, 1, tem[1]);
    return M.join(' ');
})();

var pos = browserVersion.indexOf(' ');
var browser = browserVersion.substr(0, pos);
var version = parseInt(browserVersion.substr(pos + 1));

var browserCompatible
  = browser === 'Firefox'
  ? version >= 22
  : browser === 'IE'
  ? version >= 9
  : true;


      /* MIT License

Copyright (C) 2017 by Marijn Haverbeke <marijnh@gmail.com> and others

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
 */
      !function(e,t){"object"==typeof exports&&"undefined"!=typeof module?module.exports=t():"function"==typeof define&&define.amd?define(t):e.CodeMirror=t()}(this,function(){"use strict";function e(e){return new RegExp("(^|\\s)"+e+"(?:$|\\s)\\s*")}function t(e){for(var t=e.childNodes.length;t>0;--t)e.removeChild(e.firstChild);return e}function r(e,r){return t(e).appendChild(r)}function n(e,t,r,n){var i=document.createElement(e);if(r&&(i.className=r),n&&(i.style.cssText=n),"string"==typeof t)i.appendChild(document.createTextNode(t));else if(t)for(var o=0;o<t.length;++o)i.appendChild(t[o]);return i}function i(e,t,r,i){var o=n(e,t,r,i);return o.setAttribute("role","presentation"),o}function o(e,t){if(3==t.nodeType&&(t=t.parentNode),e.contains)return e.contains(t);do{if(11==t.nodeType&&(t=t.host),t==e)return!0}while(t=t.parentNode)}function l(){var e;try{e=document.activeElement}catch(t){e=document.body||null}for(;e&&e.shadowRoot&&e.shadowRoot.activeElement;)e=e.shadowRoot.activeElement;return e}function s(t,r){var n=t.className;e(r).test(n)||(t.className+=(n?" ":"")+r)}function a(t,r){for(var n=t.split(" "),i=0;i<n.length;i++)n[i]&&!e(n[i]).test(r)&&(r+=" "+n[i]);return r}function u(e){var t=Array.prototype.slice.call(arguments,1);return function(){return e.apply(null,t)}}function c(e,t,r){t||(t={});for(var n in e)!e.hasOwnProperty(n)||!1===r&&t.hasOwnProperty(n)||(t[n]=e[n]);return t}function f(e,t,r,n,i){null==t&&-1==(t=e.search(/[^\s\u00a0]/))&&(t=e.length);for(var o=n||0,l=i||0;;){var s=e.indexOf("\t",o);if(s<0||s>=t)return l+(t-o);l+=s-o,l+=r-l%r,o=s+1}}function h(e,t){for(var r=0;r<e.length;++r)if(e[r]==t)return r;return-1}function d(e,t,r){for(var n=0,i=0;;){var o=e.indexOf("\t",n);-1==o&&(o=e.length);var l=o-n;if(o==e.length||i+l>=t)return n+Math.min(l,t-i);if(i+=o-n,i+=r-i%r,n=o+1,i>=t)return n}}function p(e){for(;Kl.length<=e;)Kl.push(g(Kl)+" ");return Kl[e]}function g(e){return e[e.length-1]}function v(e,t){for(var r=[],n=0;n<e.length;n++)r[n]=t(e[n],n);return r}function m(e,t,r){for(var n=0,i=r(t);n<e.length&&r(e[n])<=i;)n++;e.splice(n,0,t)}function y(){}function b(e,t){var r;return Object.create?r=Object.create(e):(y.prototype=e,r=new y),t&&c(t,r),r}function w(e){return/\w/.test(e)||e>""&&(e.toUpperCase()!=e.toLowerCase()||jl.test(e))}function x(e,t){return t?!!(t.source.indexOf("\\w")>-1&&w(e))||t.test(e):w(e)}function C(e){for(var t in e)if(e.hasOwnProperty(t)&&e[t])return!1;return!0}function S(e){return e.charCodeAt(0)>=768&&Xl.test(e)}function L(e,t,r){for(;(r<0?t>0:t<e.length)&&S(e.charAt(t));)t+=r;return t}function k(e,t,r){for(var n=t>r?-1:1;;){if(t==r)return t;var i=(t+r)/2,o=n<0?Math.ceil(i):Math.floor(i);if(o==t)return e(o)?t:r;e(o)?r=o:t=o+n}}function T(e,t,r){var o=this;this.input=r,o.scrollbarFiller=n("div",null,"CodeMirror-scrollbar-filler"),o.scrollbarFiller.setAttribute("cm-not-content","true"),o.gutterFiller=n("div",null,"CodeMirror-gutter-filler"),o.gutterFiller.setAttribute("cm-not-content","true"),o.lineDiv=i("div",null,"CodeMirror-code"),o.selectionDiv=n("div",null,null,"position: relative; z-index: 1"),o.cursorDiv=n("div",null,"CodeMirror-cursors"),o.measure=n("div",null,"CodeMirror-measure"),o.lineMeasure=n("div",null,"CodeMirror-measure"),o.lineSpace=i("div",[o.measure,o.lineMeasure,o.selectionDiv,o.cursorDiv,o.lineDiv],null,"position: relative; outline: none");var l=i("div",[o.lineSpace],"CodeMirror-lines");o.mover=n("div",[l],null,"position: relative"),o.sizer=n("div",[o.mover],"CodeMirror-sizer"),o.sizerWidth=null,o.heightForcer=n("div",null,null,"position: absolute; height: "+Rl+"px; width: 1px;"),o.gutters=n("div",null,"CodeMirror-gutters"),o.lineGutter=null,o.scroller=n("div",[o.sizer,o.heightForcer,o.gutters],"CodeMirror-scroll"),o.scroller.setAttribute("tabIndex","-1"),o.wrapper=n("div",[o.scrollbarFiller,o.gutterFiller,o.scroller],"CodeMirror"),gl&&vl<8&&(o.gutters.style.zIndex=-1,o.scroller.style.paddingRight=0),ml||fl&&Tl||(o.scroller.draggable=!0),e&&(e.appendChild?e.appendChild(o.wrapper):e(o.wrapper)),o.viewFrom=o.viewTo=t.first,o.reportedViewFrom=o.reportedViewTo=t.first,o.view=[],o.renderedView=null,o.externalMeasured=null,o.viewOffset=0,o.lastWrapHeight=o.lastWrapWidth=0,o.updateLineNumbers=null,o.nativeBarWidth=o.barHeight=o.barWidth=0,o.scrollbarsClipped=!1,o.lineNumWidth=o.lineNumInnerWidth=o.lineNumChars=null,o.alignWidgets=!1,o.cachedCharWidth=o.cachedTextHeight=o.cachedPaddingH=null,o.maxLine=null,o.maxLineLength=0,o.maxLineChanged=!1,o.wheelDX=o.wheelDY=o.wheelStartX=o.wheelStartY=null,o.shift=!1,o.selForContextMenu=null,o.activeTouch=null,r.init(o)}function M(e,t){if((t-=e.first)<0||t>=e.size)throw new Error("There is no line "+(t+e.first)+" in the document.");for(var r=e;!r.lines;)for(var n=0;;++n){var i=r.children[n],o=i.chunkSize();if(t<o){r=i;break}t-=o}return r.lines[t]}function N(e,t,r){var n=[],i=t.line;return e.iter(t.line,r.line+1,function(e){var o=e.text;i==r.line&&(o=o.slice(0,r.ch)),i==t.line&&(o=o.slice(t.ch)),n.push(o),++i}),n}function O(e,t,r){var n=[];return e.iter(t,r,function(e){n.push(e.text)}),n}function A(e,t){var r=t-e.height;if(r)for(var n=e;n;n=n.parent)n.height+=r}function W(e){if(null==e.parent)return null;for(var t=e.parent,r=h(t.lines,e),n=t.parent;n;t=n,n=n.parent)for(var i=0;n.children[i]!=t;++i)r+=n.children[i].chunkSize();return r+t.first}function D(e,t){var r=e.first;e:do{for(var n=0;n<e.children.length;++n){var i=e.children[n],o=i.height;if(t<o){e=i;continue e}t-=o,r+=i.chunkSize()}return r}while(!e.lines);for(var l=0;l<e.lines.length;++l){var s=e.lines[l].height;if(t<s)break;t-=s}return r+l}function H(e,t){return t>=e.first&&t<e.first+e.size}function F(e,t){return String(e.lineNumberFormatter(t+e.firstLineNumber))}function E(e,t,r){if(void 0===r&&(r=null),!(this instanceof E))return new E(e,t,r);this.line=e,this.ch=t,this.sticky=r}function P(e,t){return e.line-t.line||e.ch-t.ch}function I(e,t){return e.sticky==t.sticky&&0==P(e,t)}function z(e){return E(e.line,e.ch)}function R(e,t){return P(e,t)<0?t:e}function B(e,t){return P(e,t)<0?e:t}function G(e,t){return Math.max(e.first,Math.min(t,e.first+e.size-1))}function U(e,t){if(t.line<e.first)return E(e.first,0);var r=e.first+e.size-1;return t.line>r?E(r,M(e,r).text.length):V(t,M(e,t.line).text.length)}function V(e,t){var r=e.ch;return null==r||r>t?E(e.line,t):r<0?E(e.line,0):e}function K(e,t){for(var r=[],n=0;n<t.length;n++)r[n]=U(e,t[n]);return r}function j(){Yl=!0}function X(){_l=!0}function Y(e,t,r){this.marker=e,this.from=t,this.to=r}function _(e,t){if(e)for(var r=0;r<e.length;++r){var n=e[r];if(n.marker==t)return n}}function $(e,t){for(var r,n=0;n<e.length;++n)e[n]!=t&&(r||(r=[])).push(e[n]);return r}function q(e,t){e.markedSpans=e.markedSpans?e.markedSpans.concat([t]):[t],t.marker.attachLine(e)}function Z(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t)||o.from==t&&"bookmark"==l.type&&(!r||!o.marker.insertLeft)){var s=null==o.to||(l.inclusiveRight?o.to>=t:o.to>t);(n||(n=[])).push(new Y(l,o.from,s?null:o.to))}}return n}function Q(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.to||(l.inclusiveRight?o.to>=t:o.to>t)||o.from==t&&"bookmark"==l.type&&(!r||o.marker.insertLeft)){var s=null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t);(n||(n=[])).push(new Y(l,s?null:o.from-t,null==o.to?null:o.to-t))}}return n}function J(e,t){if(t.full)return null;var r=H(e,t.from.line)&&M(e,t.from.line).markedSpans,n=H(e,t.to.line)&&M(e,t.to.line).markedSpans;if(!r&&!n)return null;var i=t.from.ch,o=t.to.ch,l=0==P(t.from,t.to),s=Z(r,i,l),a=Q(n,o,l),u=1==t.text.length,c=g(t.text).length+(u?i:0);if(s)for(var f=0;f<s.length;++f){var h=s[f];if(null==h.to){var d=_(a,h.marker);d?u&&(h.to=null==d.to?null:d.to+c):h.to=i}}if(a)for(var p=0;p<a.length;++p){var v=a[p];null!=v.to&&(v.to+=c),null==v.from?_(s,v.marker)||(v.from=c,u&&(s||(s=[])).push(v)):(v.from+=c,u&&(s||(s=[])).push(v))}s&&(s=ee(s)),a&&a!=s&&(a=ee(a));var m=[s];if(!u){var y,b=t.text.length-2;if(b>0&&s)for(var w=0;w<s.length;++w)null==s[w].to&&(y||(y=[])).push(new Y(s[w].marker,null,null));for(var x=0;x<b;++x)m.push(y);m.push(a)}return m}function ee(e){for(var t=0;t<e.length;++t){var r=e[t];null!=r.from&&r.from==r.to&&!1!==r.marker.clearWhenEmpty&&e.splice(t--,1)}return e.length?e:null}function te(e,t,r){var n=null;if(e.iter(t.line,r.line+1,function(e){if(e.markedSpans)for(var t=0;t<e.markedSpans.length;++t){var r=e.markedSpans[t].marker;!r.readOnly||n&&-1!=h(n,r)||(n||(n=[])).push(r)}}),!n)return null;for(var i=[{from:t,to:r}],o=0;o<n.length;++o)for(var l=n[o],s=l.find(0),a=0;a<i.length;++a){var u=i[a];if(!(P(u.to,s.from)<0||P(u.from,s.to)>0)){var c=[a,1],f=P(u.from,s.from),d=P(u.to,s.to);(f<0||!l.inclusiveLeft&&!f)&&c.push({from:u.from,to:s.from}),(d>0||!l.inclusiveRight&&!d)&&c.push({from:s.to,to:u.to}),i.splice.apply(i,c),a+=c.length-3}}return i}function re(e){var t=e.markedSpans;if(t){for(var r=0;r<t.length;++r)t[r].marker.detachLine(e);e.markedSpans=null}}function ne(e,t){if(t){for(var r=0;r<t.length;++r)t[r].marker.attachLine(e);e.markedSpans=t}}function ie(e){return e.inclusiveLeft?-1:0}function oe(e){return e.inclusiveRight?1:0}function le(e,t){var r=e.lines.length-t.lines.length;if(0!=r)return r;var n=e.find(),i=t.find(),o=P(n.from,i.from)||ie(e)-ie(t);if(o)return-o;var l=P(n.to,i.to)||oe(e)-oe(t);return l||t.id-e.id}function se(e,t){var r,n=_l&&e.markedSpans;if(n)for(var i=void 0,o=0;o<n.length;++o)(i=n[o]).marker.collapsed&&null==(t?i.from:i.to)&&(!r||le(r,i.marker)<0)&&(r=i.marker);return r}function ae(e){return se(e,!0)}function ue(e){return se(e,!1)}function ce(e,t,r,n,i){var o=M(e,t),l=_l&&o.markedSpans;if(l)for(var s=0;s<l.length;++s){var a=l[s];if(a.marker.collapsed){var u=a.marker.find(0),c=P(u.from,r)||ie(a.marker)-ie(i),f=P(u.to,n)||oe(a.marker)-oe(i);if(!(c>=0&&f<=0||c<=0&&f>=0)&&(c<=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.to,r)>=0:P(u.to,r)>0)||c>=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.from,n)<=0:P(u.from,n)<0)))return!0}}}function fe(e){for(var t;t=ae(e);)e=t.find(-1,!0).line;return e}function he(e){for(var t;t=ue(e);)e=t.find(1,!0).line;return e}function de(e){for(var t,r;t=ue(e);)e=t.find(1,!0).line,(r||(r=[])).push(e);return r}function pe(e,t){var r=M(e,t),n=fe(r);return r==n?t:W(n)}function ge(e,t){if(t>e.lastLine())return t;var r,n=M(e,t);if(!ve(e,n))return t;for(;r=ue(n);)n=r.find(1,!0).line;return W(n)+1}function ve(e,t){var r=_l&&t.markedSpans;if(r)for(var n=void 0,i=0;i<r.length;++i)if((n=r[i]).marker.collapsed){if(null==n.from)return!0;if(!n.marker.widgetNode&&0==n.from&&n.marker.inclusiveLeft&&me(e,t,n))return!0}}function me(e,t,r){if(null==r.to){var n=r.marker.find(1,!0);return me(e,n.line,_(n.line.markedSpans,r.marker))}if(r.marker.inclusiveRight&&r.to==t.text.length)return!0;for(var i=void 0,o=0;o<t.markedSpans.length;++o)if((i=t.markedSpans[o]).marker.collapsed&&!i.marker.widgetNode&&i.from==r.to&&(null==i.to||i.to!=r.from)&&(i.marker.inclusiveLeft||r.marker.inclusiveRight)&&me(e,t,i))return!0}function ye(e){for(var t=0,r=(e=fe(e)).parent,n=0;n<r.lines.length;++n){var i=r.lines[n];if(i==e)break;t+=i.height}for(var o=r.parent;o;r=o,o=r.parent)for(var l=0;l<o.children.length;++l){var s=o.children[l];if(s==r)break;t+=s.height}return t}function be(e){if(0==e.height)return 0;for(var t,r=e.text.length,n=e;t=ae(n);){var i=t.find(0,!0);n=i.from.line,r+=i.from.ch-i.to.ch}for(n=e;t=ue(n);){var o=t.find(0,!0);r-=n.text.length-o.from.ch,r+=(n=o.to.line).text.length-o.to.ch}return r}function we(e){var t=e.display,r=e.doc;t.maxLine=M(r,r.first),t.maxLineLength=be(t.maxLine),t.maxLineChanged=!0,r.iter(function(e){var r=be(e);r>t.maxLineLength&&(t.maxLineLength=r,t.maxLine=e)})}function xe(e,t,r,n){if(!e)return n(t,r,"ltr",0);for(var i=!1,o=0;o<e.length;++o){var l=e[o];(l.from<r&&l.to>t||t==r&&l.to==t)&&(n(Math.max(l.from,t),Math.min(l.to,r),1==l.level?"rtl":"ltr",o),i=!0)}i||n(t,r,"ltr")}function Ce(e,t,r){var n;$l=null;for(var i=0;i<e.length;++i){var o=e[i];if(o.from<t&&o.to>t)return i;o.to==t&&(o.from!=o.to&&"before"==r?n=i:$l=i),o.from==t&&(o.from!=o.to&&"before"!=r?n=i:$l=i)}return null!=n?n:$l}function Se(e,t){var r=e.order;return null==r&&(r=e.order=ql(e.text,t)),r}function Le(e,t){return e._handlers&&e._handlers[t]||Zl}function ke(e,t,r){if(e.removeEventListener)e.removeEventListener(t,r,!1);else if(e.detachEvent)e.detachEvent("on"+t,r);else{var n=e._handlers,i=n&&n[t];if(i){var o=h(i,r);o>-1&&(n[t]=i.slice(0,o).concat(i.slice(o+1)))}}}function Te(e,t){var r=Le(e,t);if(r.length)for(var n=Array.prototype.slice.call(arguments,2),i=0;i<r.length;++i)r[i].apply(null,n)}function Me(e,t,r){return"string"==typeof t&&(t={type:t,preventDefault:function(){this.defaultPrevented=!0}}),Te(e,r||t.type,e,t),He(t)||t.codemirrorIgnore}function Ne(e){var t=e._handlers&&e._handlers.cursorActivity;if(t)for(var r=e.curOp.cursorActivityHandlers||(e.curOp.cursorActivityHandlers=[]),n=0;n<t.length;++n)-1==h(r,t[n])&&r.push(t[n])}function Oe(e,t){return Le(e,t).length>0}function Ae(e){e.prototype.on=function(e,t){Ql(this,e,t)},e.prototype.off=function(e,t){ke(this,e,t)}}function We(e){e.preventDefault?e.preventDefault():e.returnValue=!1}function De(e){e.stopPropagation?e.stopPropagation():e.cancelBubble=!0}function He(e){return null!=e.defaultPrevented?e.defaultPrevented:0==e.returnValue}function Fe(e){We(e),De(e)}function Ee(e){return e.target||e.srcElement}function Pe(e){var t=e.which;return null==t&&(1&e.button?t=1:2&e.button?t=3:4&e.button&&(t=2)),Ml&&e.ctrlKey&&1==t&&(t=3),t}function Ie(e){if(null==Il){var t=n("span","​");r(e,n("span",[t,document.createTextNode("x")])),0!=e.firstChild.offsetHeight&&(Il=t.offsetWidth<=1&&t.offsetHeight>2&&!(gl&&vl<8))}var i=Il?n("span","​"):n("span"," ",null,"display: inline-block; width: 1px; margin-right: -1px");return i.setAttribute("cm-text",""),i}function ze(e){if(null!=zl)return zl;var n=r(e,document.createTextNode("AخA")),i=Wl(n,0,1).getBoundingClientRect(),o=Wl(n,1,2).getBoundingClientRect();return t(e),!(!i||i.left==i.right)&&(zl=o.right-i.right<3)}function Re(e){if(null!=ns)return ns;var t=r(e,n("span","x")),i=t.getBoundingClientRect(),o=Wl(t,0,1).getBoundingClientRect();return ns=Math.abs(i.left-o.left)>1}function Be(e,t){arguments.length>2&&(t.dependencies=Array.prototype.slice.call(arguments,2)),is[e]=t}function Ge(e){if("string"==typeof e&&os.hasOwnProperty(e))e=os[e];else if(e&&"string"==typeof e.name&&os.hasOwnProperty(e.name)){var t=os[e.name];"string"==typeof t&&(t={name:t}),(e=b(t,e)).name=t.name}else{if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+xml$/.test(e))return Ge("application/xml");if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+json$/.test(e))return Ge("application/json")}return"string"==typeof e?{name:e}:e||{name:"null"}}function Ue(e,t){t=Ge(t);var r=is[t.name];if(!r)return Ue(e,"text/plain");var n=r(e,t);if(ls.hasOwnProperty(t.name)){var i=ls[t.name];for(var o in i)i.hasOwnProperty(o)&&(n.hasOwnProperty(o)&&(n["_"+o]=n[o]),n[o]=i[o])}if(n.name=t.name,t.helperType&&(n.helperType=t.helperType),t.modeProps)for(var l in t.modeProps)n[l]=t.modeProps[l];return n}function Ve(e,t){c(t,ls.hasOwnProperty(e)?ls[e]:ls[e]={})}function Ke(e,t){if(!0===t)return t;if(e.copyState)return e.copyState(t);var r={};for(var n in t){var i=t[n];i instanceof Array&&(i=i.concat([])),r[n]=i}return r}function je(e,t){for(var r;e.innerMode&&(r=e.innerMode(t))&&r.mode!=e;)t=r.state,e=r.mode;return r||{mode:e,state:t}}function Xe(e,t,r){return!e.startState||e.startState(t,r)}function Ye(e,t,r,n){var i=[e.state.modeGen],o={};tt(e,t.text,e.doc.mode,r,function(e,t){return i.push(e,t)},o,n);for(var l=r.state,s=0;s<e.state.overlays.length;++s)!function(n){var l=e.state.overlays[n],s=1,a=0;r.state=!0,tt(e,t.text,l.mode,r,function(e,t){for(var r=s;a<e;){var n=i[s];n>e&&i.splice(s,1,e,i[s+1],n),s+=2,a=Math.min(e,n)}if(t)if(l.opaque)i.splice(r,s-r,e,"overlay "+t),s=r+2;else for(;r<s;r+=2){var o=i[r+1];i[r+1]=(o?o+" ":"")+"overlay "+t}},o)}(s);return r.state=l,{styles:i,classes:o.bgClass||o.textClass?o:null}}function _e(e,t,r){if(!t.styles||t.styles[0]!=e.state.modeGen){var n=$e(e,W(t)),i=t.text.length>e.options.maxHighlightLength&&Ke(e.doc.mode,n.state),o=Ye(e,t,n);i&&(n.state=i),t.stateAfter=n.save(!i),t.styles=o.styles,o.classes?t.styleClasses=o.classes:t.styleClasses&&(t.styleClasses=null),r===e.doc.highlightFrontier&&(e.doc.modeFrontier=Math.max(e.doc.modeFrontier,++e.doc.highlightFrontier))}return t.styles}function $e(e,t,r){var n=e.doc,i=e.display;if(!n.mode.startState)return new us(n,!0,t);var o=rt(e,t,r),l=o>n.first&&M(n,o-1).stateAfter,s=l?us.fromSaved(n,l,o):new us(n,Xe(n.mode),o);return n.iter(o,t,function(r){qe(e,r.text,s);var n=s.line;r.stateAfter=n==t-1||n%5==0||n>=i.viewFrom&&n<i.viewTo?s.save():null,s.nextLine()}),r&&(n.modeFrontier=s.line),s}function qe(e,t,r,n){var i=e.doc.mode,o=new ss(t,e.options.tabSize,r);for(o.start=o.pos=n||0,""==t&&Ze(i,r.state);!o.eol();)Qe(i,o,r.state),o.start=o.pos}function Ze(e,t){if(e.blankLine)return e.blankLine(t);if(e.innerMode){var r=je(e,t);return r.mode.blankLine?r.mode.blankLine(r.state):void 0}}function Qe(e,t,r,n){for(var i=0;i<10;i++){n&&(n[0]=je(e,r).mode);var o=e.token(t,r);if(t.pos>t.start)return o}throw new Error("Mode "+e.name+" failed to advance stream.")}function Je(e,t,r,n){var i,o,l=e.doc,s=l.mode,a=M(l,(t=U(l,t)).line),u=$e(e,t.line,r),c=new ss(a.text,e.options.tabSize,u);for(n&&(o=[]);(n||c.pos<t.ch)&&!c.eol();)c.start=c.pos,i=Qe(s,c,u.state),n&&o.push(new cs(c,i,Ke(l.mode,u.state)));return n?o:new cs(c,i,u.state)}function et(e,t){if(e)for(;;){var r=e.match(/(?:^|\s+)line-(background-)?(\S+)/);if(!r)break;e=e.slice(0,r.index)+e.slice(r.index+r[0].length);var n=r[1]?"bgClass":"textClass";null==t[n]?t[n]=r[2]:new RegExp("(?:^|s)"+r[2]+"(?:$|s)").test(t[n])||(t[n]+=" "+r[2])}return e}function tt(e,t,r,n,i,o,l){var s=r.flattenSpans;null==s&&(s=e.options.flattenSpans);var a,u=0,c=null,f=new ss(t,e.options.tabSize,n),h=e.options.addModeClass&&[null];for(""==t&&et(Ze(r,n.state),o);!f.eol();){if(f.pos>e.options.maxHighlightLength?(s=!1,l&&qe(e,t,n,f.pos),f.pos=t.length,a=null):a=et(Qe(r,f,n.state,h),o),h){var d=h[0].name;d&&(a="m-"+(a?d+" "+a:d))}if(!s||c!=a){for(;u<f.start;)i(u=Math.min(f.start,u+5e3),c);c=a}f.start=f.pos}for(;u<f.pos;){var p=Math.min(f.pos,u+5e3);i(p,c),u=p}}function rt(e,t,r){for(var n,i,o=e.doc,l=r?-1:t-(e.doc.mode.innerMode?1e3:100),s=t;s>l;--s){if(s<=o.first)return o.first;var a=M(o,s-1),u=a.stateAfter;if(u&&(!r||s+(u instanceof as?u.lookAhead:0)<=o.modeFrontier))return s;var c=f(a.text,null,e.options.tabSize);(null==i||n>c)&&(i=s-1,n=c)}return i}function nt(e,t){if(e.modeFrontier=Math.min(e.modeFrontier,t),!(e.highlightFrontier<t-10)){for(var r=e.first,n=t-1;n>r;n--){var i=M(e,n).stateAfter;if(i&&(!(i instanceof as)||n+i.lookAhead<t)){r=n+1;break}}e.highlightFrontier=Math.min(e.highlightFrontier,r)}}function it(e,t,r,n){e.text=t,e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null),null!=e.order&&(e.order=null),re(e),ne(e,r);var i=n?n(e):1;i!=e.height&&A(e,i)}function ot(e){e.parent=null,re(e)}function lt(e,t){if(!e||/^\s*$/.test(e))return null;var r=t.addModeClass?ps:ds;return r[e]||(r[e]=e.replace(/\S+/g,"cm-$&"))}function st(e,t){var r=i("span",null,null,ml?"padding-right: .1px":null),n={pre:i("pre",[r],"CodeMirror-line"),content:r,col:0,pos:0,cm:e,trailingSpace:!1,splitSpaces:(gl||ml)&&e.getOption("lineWrapping")};t.measure={};for(var o=0;o<=(t.rest?t.rest.length:0);o++){var l=o?t.rest[o-1]:t.line,s=void 0;n.pos=0,n.addToken=ut,ze(e.display.measure)&&(s=Se(l,e.doc.direction))&&(n.addToken=ft(n.addToken,s)),n.map=[],dt(l,n,_e(e,l,t!=e.display.externalMeasured&&W(l))),l.styleClasses&&(l.styleClasses.bgClass&&(n.bgClass=a(l.styleClasses.bgClass,n.bgClass||"")),l.styleClasses.textClass&&(n.textClass=a(l.styleClasses.textClass,n.textClass||""))),0==n.map.length&&n.map.push(0,0,n.content.appendChild(Ie(e.display.measure))),0==o?(t.measure.map=n.map,t.measure.cache={}):((t.measure.maps||(t.measure.maps=[])).push(n.map),(t.measure.caches||(t.measure.caches=[])).push({}))}if(ml){var u=n.content.lastChild;(/\bcm-tab\b/.test(u.className)||u.querySelector&&u.querySelector(".cm-tab"))&&(n.content.className="cm-tab-wrap-hack")}return Te(e,"renderLine",e,t.line,n.pre),n.pre.className&&(n.textClass=a(n.pre.className,n.textClass||"")),n}function at(e){var t=n("span","•","cm-invalidchar");return t.title="\\u"+e.charCodeAt(0).toString(16),t.setAttribute("aria-label",t.title),t}function ut(e,t,r,i,o,l,s){if(t){var a,u=e.splitSpaces?ct(t,e.trailingSpace):t,c=e.cm.state.specialChars,f=!1;if(c.test(t)){a=document.createDocumentFragment();for(var h=0;;){c.lastIndex=h;var d=c.exec(t),g=d?d.index-h:t.length-h;if(g){var v=document.createTextNode(u.slice(h,h+g));gl&&vl<9?a.appendChild(n("span",[v])):a.appendChild(v),e.map.push(e.pos,e.pos+g,v),e.col+=g,e.pos+=g}if(!d)break;h+=g+1;var m=void 0;if("\t"==d[0]){var y=e.cm.options.tabSize,b=y-e.col%y;(m=a.appendChild(n("span",p(b),"cm-tab"))).setAttribute("role","presentation"),m.setAttribute("cm-text","\t"),e.col+=b}else"\r"==d[0]||"\n"==d[0]?((m=a.appendChild(n("span","\r"==d[0]?"␍":"␤","cm-invalidchar"))).setAttribute("cm-text",d[0]),e.col+=1):((m=e.cm.options.specialCharPlaceholder(d[0])).setAttribute("cm-text",d[0]),gl&&vl<9?a.appendChild(n("span",[m])):a.appendChild(m),e.col+=1);e.map.push(e.pos,e.pos+1,m),e.pos++}}else e.col+=t.length,a=document.createTextNode(u),e.map.push(e.pos,e.pos+t.length,a),gl&&vl<9&&(f=!0),e.pos+=t.length;if(e.trailingSpace=32==u.charCodeAt(t.length-1),r||i||o||f||s){var w=r||"";i&&(w+=i),o&&(w+=o);var x=n("span",[a],w,s);return l&&(x.title=l),e.content.appendChild(x)}e.content.appendChild(a)}}function ct(e,t){if(e.length>1&&!/  /.test(e))return e;for(var r=t,n="",i=0;i<e.length;i++){var o=e.charAt(i);" "!=o||!r||i!=e.length-1&&32!=e.charCodeAt(i+1)||(o=" "),n+=o,r=" "==o}return n}function ft(e,t){return function(r,n,i,o,l,s,a){i=i?i+" cm-force-border":"cm-force-border";for(var u=r.pos,c=u+n.length;;){for(var f=void 0,h=0;h<t.length&&!((f=t[h]).to>u&&f.from<=u);h++);if(f.to>=c)return e(r,n,i,o,l,s,a);e(r,n.slice(0,f.to-u),i,o,null,s,a),o=null,n=n.slice(f.to-u),u=f.to}}}function ht(e,t,r,n){var i=!n&&r.widgetNode;i&&e.map.push(e.pos,e.pos+t,i),!n&&e.cm.display.input.needsContentAttribute&&(i||(i=e.content.appendChild(document.createElement("span"))),i.setAttribute("cm-marker",r.id)),i&&(e.cm.display.input.setUneditable(i),e.content.appendChild(i)),e.pos+=t,e.trailingSpace=!1}function dt(e,t,r){var n=e.markedSpans,i=e.text,o=0;if(n)for(var l,s,a,u,c,f,h,d=i.length,p=0,g=1,v="",m=0;;){if(m==p){a=u=c=f=s="",h=null,m=1/0;for(var y=[],b=void 0,w=0;w<n.length;++w){var x=n[w],C=x.marker;"bookmark"==C.type&&x.from==p&&C.widgetNode?y.push(C):x.from<=p&&(null==x.to||x.to>p||C.collapsed&&x.to==p&&x.from==p)?(null!=x.to&&x.to!=p&&m>x.to&&(m=x.to,u=""),C.className&&(a+=" "+C.className),C.css&&(s=(s?s+";":"")+C.css),C.startStyle&&x.from==p&&(c+=" "+C.startStyle),C.endStyle&&x.to==m&&(b||(b=[])).push(C.endStyle,x.to),C.title&&!f&&(f=C.title),C.collapsed&&(!h||le(h.marker,C)<0)&&(h=x)):x.from>p&&m>x.from&&(m=x.from)}if(b)for(var S=0;S<b.length;S+=2)b[S+1]==m&&(u+=" "+b[S]);if(!h||h.from==p)for(var L=0;L<y.length;++L)ht(t,0,y[L]);if(h&&(h.from||0)==p){if(ht(t,(null==h.to?d+1:h.to)-p,h.marker,null==h.from),null==h.to)return;h.to==p&&(h=!1)}}if(p>=d)break;for(var k=Math.min(d,m);;){if(v){var T=p+v.length;if(!h){var M=T>k?v.slice(0,k-p):v;t.addToken(t,M,l?l+a:a,c,p+M.length==m?u:"",f,s)}if(T>=k){v=v.slice(k-p),p=k;break}p=T,c=""}v=i.slice(o,o=r[g++]),l=lt(r[g++],t.cm.options)}}else for(var N=1;N<r.length;N+=2)t.addToken(t,i.slice(o,o=r[N]),lt(r[N+1],t.cm.options))}function pt(e,t,r){this.line=t,this.rest=de(t),this.size=this.rest?W(g(this.rest))-r+1:1,this.node=this.text=null,this.hidden=ve(e,t)}function gt(e,t,r){for(var n,i=[],o=t;o<r;o=n){var l=new pt(e.doc,M(e.doc,o),o);n=o+l.size,i.push(l)}return i}function vt(e){gs?gs.ops.push(e):e.ownsGroup=gs={ops:[e],delayedCallbacks:[]}}function mt(e){var t=e.delayedCallbacks,r=0;do{for(;r<t.length;r++)t[r].call(null);for(var n=0;n<e.ops.length;n++){var i=e.ops[n];if(i.cursorActivityHandlers)for(;i.cursorActivityCalled<i.cursorActivityHandlers.length;)i.cursorActivityHandlers[i.cursorActivityCalled++].call(null,i.cm)}}while(r<t.length)}function yt(e,t){var r=e.ownsGroup;if(r)try{mt(r)}finally{gs=null,t(r)}}function bt(e,t){var r=Le(e,t);if(r.length){var n,i=Array.prototype.slice.call(arguments,2);gs?n=gs.delayedCallbacks:vs?n=vs:(n=vs=[],setTimeout(wt,0));for(var o=0;o<r.length;++o)!function(e){n.push(function(){return r[e].apply(null,i)})}(o)}}function wt(){var e=vs;vs=null;for(var t=0;t<e.length;++t)e[t]()}function xt(e,t,r,n){for(var i=0;i<t.changes.length;i++){var o=t.changes[i];"text"==o?kt(e,t):"gutter"==o?Mt(e,t,r,n):"class"==o?Tt(e,t):"widget"==o&&Nt(e,t,n)}t.changes=null}function Ct(e){return e.node==e.text&&(e.node=n("div",null,null,"position: relative"),e.text.parentNode&&e.text.parentNode.replaceChild(e.node,e.text),e.node.appendChild(e.text),gl&&vl<8&&(e.node.style.zIndex=2)),e.node}function St(e,t){var r=t.bgClass?t.bgClass+" "+(t.line.bgClass||""):t.line.bgClass;if(r&&(r+=" CodeMirror-linebackground"),t.background)r?t.background.className=r:(t.background.parentNode.removeChild(t.background),t.background=null);else if(r){var i=Ct(t);t.background=i.insertBefore(n("div",null,r),i.firstChild),e.display.input.setUneditable(t.background)}}function Lt(e,t){var r=e.display.externalMeasured;return r&&r.line==t.line?(e.display.externalMeasured=null,t.measure=r.measure,r.built):st(e,t)}function kt(e,t){var r=t.text.className,n=Lt(e,t);t.text==t.node&&(t.node=n.pre),t.text.parentNode.replaceChild(n.pre,t.text),t.text=n.pre,n.bgClass!=t.bgClass||n.textClass!=t.textClass?(t.bgClass=n.bgClass,t.textClass=n.textClass,Tt(e,t)):r&&(t.text.className=r)}function Tt(e,t){St(e,t),t.line.wrapClass?Ct(t).className=t.line.wrapClass:t.node!=t.text&&(t.node.className="");var r=t.textClass?t.textClass+" "+(t.line.textClass||""):t.line.textClass;t.text.className=r||""}function Mt(e,t,r,i){if(t.gutter&&(t.node.removeChild(t.gutter),t.gutter=null),t.gutterBackground&&(t.node.removeChild(t.gutterBackground),t.gutterBackground=null),t.line.gutterClass){var o=Ct(t);t.gutterBackground=n("div",null,"CodeMirror-gutter-background "+t.line.gutterClass,"left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px; width: "+i.gutterTotalWidth+"px"),e.display.input.setUneditable(t.gutterBackground),o.insertBefore(t.gutterBackground,t.text)}var l=t.line.gutterMarkers;if(e.options.lineNumbers||l){var s=Ct(t),a=t.gutter=n("div",null,"CodeMirror-gutter-wrapper","left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px");if(e.display.input.setUneditable(a),s.insertBefore(a,t.text),t.line.gutterClass&&(a.className+=" "+t.line.gutterClass),!e.options.lineNumbers||l&&l["CodeMirror-linenumbers"]||(t.lineNumber=a.appendChild(n("div",F(e.options,r),"CodeMirror-linenumber CodeMirror-gutter-elt","left: "+i.gutterLeft["CodeMirror-linenumbers"]+"px; width: "+e.display.lineNumInnerWidth+"px"))),l)for(var u=0;u<e.options.gutters.length;++u){var c=e.options.gutters[u],f=l.hasOwnProperty(c)&&l[c];f&&a.appendChild(n("div",[f],"CodeMirror-gutter-elt","left: "+i.gutterLeft[c]+"px; width: "+i.gutterWidth[c]+"px"))}}}function Nt(e,t,r){t.alignable&&(t.alignable=null);for(var n=t.node.firstChild,i=void 0;n;n=i)i=n.nextSibling,"CodeMirror-linewidget"==n.className&&t.node.removeChild(n);At(e,t,r)}function Ot(e,t,r,n){var i=Lt(e,t);return t.text=t.node=i.pre,i.bgClass&&(t.bgClass=i.bgClass),i.textClass&&(t.textClass=i.textClass),Tt(e,t),Mt(e,t,r,n),At(e,t,n),t.node}function At(e,t,r){if(Wt(e,t.line,t,r,!0),t.rest)for(var n=0;n<t.rest.length;n++)Wt(e,t.rest[n],t,r,!1)}function Wt(e,t,r,i,o){if(t.widgets)for(var l=Ct(r),s=0,a=t.widgets;s<a.length;++s){var u=a[s],c=n("div",[u.node],"CodeMirror-linewidget");u.handleMouseEvents||c.setAttribute("cm-ignore-events","true"),Dt(u,c,r,i),e.display.input.setUneditable(c),o&&u.above?l.insertBefore(c,r.gutter||r.text):l.appendChild(c),bt(u,"redraw")}}function Dt(e,t,r,n){if(e.noHScroll){(r.alignable||(r.alignable=[])).push(t);var i=n.wrapperWidth;t.style.left=n.fixedPos+"px",e.coverGutter||(i-=n.gutterTotalWidth,t.style.paddingLeft=n.gutterTotalWidth+"px"),t.style.width=i+"px"}e.coverGutter&&(t.style.zIndex=5,t.style.position="relative",e.noHScroll||(t.style.marginLeft=-n.gutterTotalWidth+"px"))}function Ht(e){if(null!=e.height)return e.height;var t=e.doc.cm;if(!t)return 0;if(!o(document.body,e.node)){var i="position: relative;";e.coverGutter&&(i+="margin-left: -"+t.display.gutters.offsetWidth+"px;"),e.noHScroll&&(i+="width: "+t.display.wrapper.clientWidth+"px;"),r(t.display.measure,n("div",[e.node],null,i))}return e.height=e.node.parentNode.offsetHeight}function Ft(e,t){for(var r=Ee(t);r!=e.wrapper;r=r.parentNode)if(!r||1==r.nodeType&&"true"==r.getAttribute("cm-ignore-events")||r.parentNode==e.sizer&&r!=e.mover)return!0}function Et(e){return e.lineSpace.offsetTop}function Pt(e){return e.mover.offsetHeight-e.lineSpace.offsetHeight}function It(e){if(e.cachedPaddingH)return e.cachedPaddingH;var t=r(e.measure,n("pre","x")),i=window.getComputedStyle?window.getComputedStyle(t):t.currentStyle,o={left:parseInt(i.paddingLeft),right:parseInt(i.paddingRight)};return isNaN(o.left)||isNaN(o.right)||(e.cachedPaddingH=o),o}function zt(e){return Rl-e.display.nativeBarWidth}function Rt(e){return e.display.scroller.clientWidth-zt(e)-e.display.barWidth}function Bt(e){return e.display.scroller.clientHeight-zt(e)-e.display.barHeight}function Gt(e,t,r){var n=e.options.lineWrapping,i=n&&Rt(e);if(!t.measure.heights||n&&t.measure.width!=i){var o=t.measure.heights=[];if(n){t.measure.width=i;for(var l=t.text.firstChild.getClientRects(),s=0;s<l.length-1;s++){var a=l[s],u=l[s+1];Math.abs(a.bottom-u.bottom)>2&&o.push((a.bottom+u.top)/2-r.top)}}o.push(r.bottom-r.top)}}function Ut(e,t,r){if(e.line==t)return{map:e.measure.map,cache:e.measure.cache};for(var n=0;n<e.rest.length;n++)if(e.rest[n]==t)return{map:e.measure.maps[n],cache:e.measure.caches[n]};for(var i=0;i<e.rest.length;i++)if(W(e.rest[i])>r)return{map:e.measure.maps[i],cache:e.measure.caches[i],before:!0}}function Vt(e,t){var n=W(t=fe(t)),i=e.display.externalMeasured=new pt(e.doc,t,n);i.lineN=n;var o=i.built=st(e,i);return i.text=o.pre,r(e.display.lineMeasure,o.pre),i}function Kt(e,t,r,n){return Yt(e,Xt(e,t),r,n)}function jt(e,t){if(t>=e.display.viewFrom&&t<e.display.viewTo)return e.display.view[Lr(e,t)];var r=e.display.externalMeasured;return r&&t>=r.lineN&&t<r.lineN+r.size?r:void 0}function Xt(e,t){var r=W(t),n=jt(e,r);n&&!n.text?n=null:n&&n.changes&&(xt(e,n,r,br(e)),e.curOp.forceUpdate=!0),n||(n=Vt(e,t));var i=Ut(n,t,r);return{line:t,view:n,rect:null,map:i.map,cache:i.cache,before:i.before,hasHeights:!1}}function Yt(e,t,r,n,i){t.before&&(r=-1);var o,l=r+(n||"");return t.cache.hasOwnProperty(l)?o=t.cache[l]:(t.rect||(t.rect=t.view.text.getBoundingClientRect()),t.hasHeights||(Gt(e,t.view,t.rect),t.hasHeights=!0),(o=qt(e,t,r,n)).bogus||(t.cache[l]=o)),{left:o.left,right:o.right,top:i?o.rtop:o.top,bottom:i?o.rbottom:o.bottom}}function _t(e,t,r){for(var n,i,o,l,s,a,u=0;u<e.length;u+=3)if(s=e[u],a=e[u+1],t<s?(i=0,o=1,l="left"):t<a?o=(i=t-s)+1:(u==e.length-3||t==a&&e[u+3]>t)&&(i=(o=a-s)-1,t>=a&&(l="right")),null!=i){if(n=e[u+2],s==a&&r==(n.insertLeft?"left":"right")&&(l=r),"left"==r&&0==i)for(;u&&e[u-2]==e[u-3]&&e[u-1].insertLeft;)n=e[2+(u-=3)],l="left";if("right"==r&&i==a-s)for(;u<e.length-3&&e[u+3]==e[u+4]&&!e[u+5].insertLeft;)n=e[(u+=3)+2],l="right";break}return{node:n,start:i,end:o,collapse:l,coverStart:s,coverEnd:a}}function $t(e,t){var r=ms;if("left"==t)for(var n=0;n<e.length&&(r=e[n]).left==r.right;n++);else for(var i=e.length-1;i>=0&&(r=e[i]).left==r.right;i--);return r}function qt(e,t,r,n){var i,o=_t(t.map,r,n),l=o.node,s=o.start,a=o.end,u=o.collapse;if(3==l.nodeType){for(var c=0;c<4;c++){for(;s&&S(t.line.text.charAt(o.coverStart+s));)--s;for(;o.coverStart+a<o.coverEnd&&S(t.line.text.charAt(o.coverStart+a));)++a;if((i=gl&&vl<9&&0==s&&a==o.coverEnd-o.coverStart?l.parentNode.getBoundingClientRect():$t(Wl(l,s,a).getClientRects(),n)).left||i.right||0==s)break;a=s,s-=1,u="right"}gl&&vl<11&&(i=Zt(e.display.measure,i))}else{s>0&&(u=n="right");var f;i=e.options.lineWrapping&&(f=l.getClientRects()).length>1?f["right"==n?f.length-1:0]:l.getBoundingClientRect()}if(gl&&vl<9&&!s&&(!i||!i.left&&!i.right)){var h=l.parentNode.getClientRects()[0];i=h?{left:h.left,right:h.left+yr(e.display),top:h.top,bottom:h.bottom}:ms}for(var d=i.top-t.rect.top,p=i.bottom-t.rect.top,g=(d+p)/2,v=t.view.measure.heights,m=0;m<v.length-1&&!(g<v[m]);m++);var y=m?v[m-1]:0,b=v[m],w={left:("right"==u?i.right:i.left)-t.rect.left,right:("left"==u?i.left:i.right)-t.rect.left,top:y,bottom:b};return i.left||i.right||(w.bogus=!0),e.options.singleCursorHeightPerLine||(w.rtop=d,w.rbottom=p),w}function Zt(e,t){if(!window.screen||null==screen.logicalXDPI||screen.logicalXDPI==screen.deviceXDPI||!Re(e))return t;var r=screen.logicalXDPI/screen.deviceXDPI,n=screen.logicalYDPI/screen.deviceYDPI;return{left:t.left*r,right:t.right*r,top:t.top*n,bottom:t.bottom*n}}function Qt(e){if(e.measure&&(e.measure.cache={},e.measure.heights=null,e.rest))for(var t=0;t<e.rest.length;t++)e.measure.caches[t]={}}function Jt(e){e.display.externalMeasure=null,t(e.display.lineMeasure);for(var r=0;r<e.display.view.length;r++)Qt(e.display.view[r])}function er(e){Jt(e),e.display.cachedCharWidth=e.display.cachedTextHeight=e.display.cachedPaddingH=null,e.options.lineWrapping||(e.display.maxLineChanged=!0),e.display.lineNumChars=null}function tr(){return bl&&kl?-(document.body.getBoundingClientRect().left-parseInt(getComputedStyle(document.body).marginLeft)):window.pageXOffset||(document.documentElement||document.body).scrollLeft}function rr(){return bl&&kl?-(document.body.getBoundingClientRect().top-parseInt(getComputedStyle(document.body).marginTop)):window.pageYOffset||(document.documentElement||document.body).scrollTop}function nr(e){var t=0;if(e.widgets)for(var r=0;r<e.widgets.length;++r)e.widgets[r].above&&(t+=Ht(e.widgets[r]));return t}function ir(e,t,r,n,i){if(!i){var o=nr(t);r.top+=o,r.bottom+=o}if("line"==n)return r;n||(n="local");var l=ye(t);if("local"==n?l+=Et(e.display):l-=e.display.viewOffset,"page"==n||"window"==n){var s=e.display.lineSpace.getBoundingClientRect();l+=s.top+("window"==n?0:rr());var a=s.left+("window"==n?0:tr());r.left+=a,r.right+=a}return r.top+=l,r.bottom+=l,r}function or(e,t,r){if("div"==r)return t;var n=t.left,i=t.top;if("page"==r)n-=tr(),i-=rr();else if("local"==r||!r){var o=e.display.sizer.getBoundingClientRect();n+=o.left,i+=o.top}var l=e.display.lineSpace.getBoundingClientRect();return{left:n-l.left,top:i-l.top}}function lr(e,t,r,n,i){return n||(n=M(e.doc,t.line)),ir(e,n,Kt(e,n,t.ch,i),r)}function sr(e,t,r,n,i,o){function l(t,l){var s=Yt(e,i,t,l?"right":"left",o);return l?s.left=s.right:s.right=s.left,ir(e,n,s,r)}function s(e,t,r){var n=1==a[t].level;return l(r?e-1:e,n!=r)}n=n||M(e.doc,t.line),i||(i=Xt(e,n));var a=Se(n,e.doc.direction),u=t.ch,c=t.sticky;if(u>=n.text.length?(u=n.text.length,c="before"):u<=0&&(u=0,c="after"),!a)return l("before"==c?u-1:u,"before"==c);var f=Ce(a,u,c),h=$l,d=s(u,f,"before"==c);return null!=h&&(d.other=s(u,h,"before"!=c)),d}function ar(e,t){var r=0;t=U(e.doc,t),e.options.lineWrapping||(r=yr(e.display)*t.ch);var n=M(e.doc,t.line),i=ye(n)+Et(e.display);return{left:r,right:r,top:i,bottom:i+n.height}}function ur(e,t,r,n,i){var o=E(e,t,r);return o.xRel=i,n&&(o.outside=!0),o}function cr(e,t,r){var n=e.doc;if((r+=e.display.viewOffset)<0)return ur(n.first,0,null,!0,-1);var i=D(n,r),o=n.first+n.size-1;if(i>o)return ur(n.first+n.size-1,M(n,o).text.length,null,!0,1);t<0&&(t=0);for(var l=M(n,i);;){var s=pr(e,l,i,t,r),a=ue(l),u=a&&a.find(0,!0);if(!a||!(s.ch>u.from.ch||s.ch==u.from.ch&&s.xRel>0))return s;i=W(l=u.to.line)}}function fr(e,t,r,n){n-=nr(t);var i=t.text.length,o=k(function(t){return Yt(e,r,t-1).bottom<=n},i,0);return i=k(function(t){return Yt(e,r,t).top>n},o,i),{begin:o,end:i}}function hr(e,t,r,n){return r||(r=Xt(e,t)),fr(e,t,r,ir(e,t,Yt(e,r,n),"line").top)}function dr(e,t,r,n){return!(e.bottom<=r)&&(e.top>r||(n?e.left:e.right)>t)}function pr(e,t,r,n,i){i-=ye(t);var o=Xt(e,t),l=nr(t),s=0,a=t.text.length,u=!0,c=Se(t,e.doc.direction);if(c){var f=(e.options.lineWrapping?vr:gr)(e,t,r,o,c,n,i);s=(u=1!=f.level)?f.from:f.to-1,a=u?f.to:f.from-1}var h,d,p=null,g=null,v=k(function(t){var r=Yt(e,o,t);return r.top+=l,r.bottom+=l,!!dr(r,n,i,!1)&&(r.top<=i&&r.left<=n&&(p=t,g=r),!0)},s,a),m=!1;if(g){var y=n-g.left<g.right-n,b=y==u;v=p+(b?0:1),d=b?"after":"before",h=y?g.left:g.right}else{u||v!=a&&v!=s||v++,d=0==v?"after":v==t.text.length?"before":Yt(e,o,v-(u?1:0)).bottom+l<=i==u?"after":"before";var w=sr(e,E(r,v,d),"line",t,o);h=w.left,m=i<w.top||i>=w.bottom}return v=L(t.text,v,1),ur(r,v,d,m,n-h)}function gr(e,t,r,n,i,o,l){var s=k(function(s){var a=i[s],u=1!=a.level;return dr(sr(e,E(r,u?a.to:a.from,u?"before":"after"),"line",t,n),o,l,!0)},0,i.length-1),a=i[s];if(s>0){var u=1!=a.level,c=sr(e,E(r,u?a.from:a.to,u?"after":"before"),"line",t,n);dr(c,o,l,!0)&&c.top>l&&(a=i[s-1])}return a}function vr(e,t,r,n,i,o,l){for(var s=fr(e,t,n,l),a=s.begin,u=s.end,c=null,f=null,h=0;h<i.length;h++){var d=i[h];if(!(d.from>=u||d.to<=a)){var p=Yt(e,n,1!=d.level?Math.min(u,d.to)-1:Math.max(a,d.from)).right,g=p<o?o-p+1e9:p-o;(!c||f>g)&&(c=d,f=g)}}return c||(c=i[i.length-1]),c.from<a&&(c={from:a,to:c.to,level:c.level}),c.to>u&&(c={from:c.from,to:u,level:c.level}),c}function mr(e){if(null!=e.cachedTextHeight)return e.cachedTextHeight;if(null==hs){hs=n("pre");for(var i=0;i<49;++i)hs.appendChild(document.createTextNode("x")),hs.appendChild(n("br"));hs.appendChild(document.createTextNode("x"))}r(e.measure,hs);var o=hs.offsetHeight/50;return o>3&&(e.cachedTextHeight=o),t(e.measure),o||1}function yr(e){if(null!=e.cachedCharWidth)return e.cachedCharWidth;var t=n("span","xxxxxxxxxx"),i=n("pre",[t]);r(e.measure,i);var o=t.getBoundingClientRect(),l=(o.right-o.left)/10;return l>2&&(e.cachedCharWidth=l),l||10}function br(e){for(var t=e.display,r={},n={},i=t.gutters.clientLeft,o=t.gutters.firstChild,l=0;o;o=o.nextSibling,++l)r[e.options.gutters[l]]=o.offsetLeft+o.clientLeft+i,n[e.options.gutters[l]]=o.clientWidth;return{fixedPos:wr(t),gutterTotalWidth:t.gutters.offsetWidth,gutterLeft:r,gutterWidth:n,wrapperWidth:t.wrapper.clientWidth}}function wr(e){return e.scroller.getBoundingClientRect().left-e.sizer.getBoundingClientRect().left}function xr(e){var t=mr(e.display),r=e.options.lineWrapping,n=r&&Math.max(5,e.display.scroller.clientWidth/yr(e.display)-3);return function(i){if(ve(e.doc,i))return 0;var o=0;if(i.widgets)for(var l=0;l<i.widgets.length;l++)i.widgets[l].height&&(o+=i.widgets[l].height);return r?o+(Math.ceil(i.text.length/n)||1)*t:o+t}}function Cr(e){var t=e.doc,r=xr(e);t.iter(function(e){var t=r(e);t!=e.height&&A(e,t)})}function Sr(e,t,r,n){var i=e.display;if(!r&&"true"==Ee(t).getAttribute("cm-not-content"))return null;var o,l,s=i.lineSpace.getBoundingClientRect();try{o=t.clientX-s.left,l=t.clientY-s.top}catch(t){return null}var a,u=cr(e,o,l);if(n&&1==u.xRel&&(a=M(e.doc,u.line).text).length==u.ch){var c=f(a,a.length,e.options.tabSize)-a.length;u=E(u.line,Math.max(0,Math.round((o-It(e.display).left)/yr(e.display))-c))}return u}function Lr(e,t){if(t>=e.display.viewTo)return null;if((t-=e.display.viewFrom)<0)return null;for(var r=e.display.view,n=0;n<r.length;n++)if((t-=r[n].size)<0)return n}function kr(e){e.display.input.showSelection(e.display.input.prepareSelection())}function Tr(e,t){void 0===t&&(t=!0);for(var r=e.doc,n={},i=n.cursors=document.createDocumentFragment(),o=n.selection=document.createDocumentFragment(),l=0;l<r.sel.ranges.length;l++)if(t||l!=r.sel.primIndex){var s=r.sel.ranges[l];if(!(s.from().line>=e.display.viewTo||s.to().line<e.display.viewFrom)){var a=s.empty();(a||e.options.showCursorWhenSelecting)&&Mr(e,s.head,i),a||Or(e,s,o)}}return n}function Mr(e,t,r){var i=sr(e,t,"div",null,null,!e.options.singleCursorHeightPerLine),o=r.appendChild(n("div"," ","CodeMirror-cursor"));if(o.style.left=i.left+"px",o.style.top=i.top+"px",o.style.height=Math.max(0,i.bottom-i.top)*e.options.cursorHeight+"px",i.other){var l=r.appendChild(n("div"," ","CodeMirror-cursor CodeMirror-secondarycursor"));l.style.display="",l.style.left=i.other.left+"px",l.style.top=i.other.top+"px",l.style.height=.85*(i.other.bottom-i.other.top)+"px"}}function Nr(e,t){return e.top-t.top||e.left-t.left}function Or(e,t,r){function i(e,t,r,i){t<0&&(t=0),t=Math.round(t),i=Math.round(i),a.appendChild(n("div",null,"CodeMirror-selected","position: absolute; left: "+e+"px;\n                             top: "+t+"px; width: "+(null==r?f-e:r)+"px;\n                             height: "+(i-t)+"px"))}function o(t,r,n){function o(r,n){return lr(e,E(t,r),"div",u,n)}var l,a,u=M(s,t),h=u.text.length,d=Se(u,s.direction);return xe(d,r||0,null==n?h:n,function(t,s,p,g){var v=o(t,"ltr"==p?"left":"right"),m=o(s-1,"ltr"==p?"right":"left");if("ltr"==p){var y=null==r&&0==t?c:v.left,b=null==n&&s==h?f:m.right;m.top-v.top<=3?i(y,m.top,b-y,m.bottom):(i(y,v.top,null,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top),i(c,m.top,m.right,m.bottom))}else if(t<s){var w=null==r&&0==t?f:v.right,x=null==n&&s==h?c:m.left;if(m.top-v.top<=3)i(x,m.top,w-x,m.bottom);else{var C=c;if(g){var S=hr(e,u,null,t).end;C=o(S-(/\s/.test(u.text.charAt(S-1))?2:1),"left").left}i(C,v.top,w-C,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top);var L=null;d.length,L=o(hr(e,u,null,s).begin,"right").right-x,i(x,m.top,L,m.bottom)}}(!l||Nr(v,l)<0)&&(l=v),Nr(m,l)<0&&(l=m),(!a||Nr(v,a)<0)&&(a=v),Nr(m,a)<0&&(a=m)}),{start:l,end:a}}var l=e.display,s=e.doc,a=document.createDocumentFragment(),u=It(e.display),c=u.left,f=Math.max(l.sizerWidth,Rt(e)-l.sizer.offsetLeft)-u.right,h=t.from(),d=t.to();if(h.line==d.line)o(h.line,h.ch,d.ch);else{var p=M(s,h.line),g=M(s,d.line),v=fe(p)==fe(g),m=o(h.line,h.ch,v?p.text.length+1:null).end,y=o(d.line,v?0:null,d.ch).start;v&&(m.top<y.top-2?(i(m.right,m.top,null,m.bottom),i(c,y.top,y.left,y.bottom)):i(m.right,m.top,y.left-m.right,m.bottom)),m.bottom<y.top&&i(c,m.bottom,null,y.top)}r.appendChild(a)}function Ar(e){if(e.state.focused){var t=e.display;clearInterval(t.blinker);var r=!0;t.cursorDiv.style.visibility="",e.options.cursorBlinkRate>0?t.blinker=setInterval(function(){return t.cursorDiv.style.visibility=(r=!r)?"":"hidden"},e.options.cursorBlinkRate):e.options.cursorBlinkRate<0&&(t.cursorDiv.style.visibility="hidden")}}function Wr(e){e.state.focused||(e.display.input.focus(),Hr(e))}function Dr(e){e.state.delayingBlurEvent=!0,setTimeout(function(){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1,Fr(e))},100)}function Hr(e,t){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1),"nocursor"!=e.options.readOnly&&(e.state.focused||(Te(e,"focus",e,t),e.state.focused=!0,s(e.display.wrapper,"CodeMirror-focused"),e.curOp||e.display.selForContextMenu==e.doc.sel||(e.display.input.reset(),ml&&setTimeout(function(){return e.display.input.reset(!0)},20)),e.display.input.receivedFocus()),Ar(e))}function Fr(e,t){e.state.delayingBlurEvent||(e.state.focused&&(Te(e,"blur",e,t),e.state.focused=!1,Fl(e.display.wrapper,"CodeMirror-focused")),clearInterval(e.display.blinker),setTimeout(function(){e.state.focused||(e.display.shift=!1)},150))}function Er(e){for(var t=e.display,r=t.lineDiv.offsetTop,n=0;n<t.view.length;n++){var i=t.view[n],o=void 0;if(!i.hidden){if(gl&&vl<8){var l=i.node.offsetTop+i.node.offsetHeight;o=l-r,r=l}else{var s=i.node.getBoundingClientRect();o=s.bottom-s.top}var a=i.line.height-o;if(o<2&&(o=mr(t)),(a>.005||a<-.005)&&(A(i.line,o),Pr(i.line),i.rest))for(var u=0;u<i.rest.length;u++)Pr(i.rest[u])}}}function Pr(e){if(e.widgets)for(var t=0;t<e.widgets.length;++t)e.widgets[t].height=e.widgets[t].node.parentNode.offsetHeight}function Ir(e,t,r){var n=r&&null!=r.top?Math.max(0,r.top):e.scroller.scrollTop;n=Math.floor(n-Et(e));var i=r&&null!=r.bottom?r.bottom:n+e.wrapper.clientHeight,o=D(t,n),l=D(t,i);if(r&&r.ensure){var s=r.ensure.from.line,a=r.ensure.to.line;s<o?(o=s,l=D(t,ye(M(t,s))+e.wrapper.clientHeight)):Math.min(a,t.lastLine())>=l&&(o=D(t,ye(M(t,a))-e.wrapper.clientHeight),l=a)}return{from:o,to:Math.max(l,o+1)}}function zr(e){var t=e.display,r=t.view;if(t.alignWidgets||t.gutters.firstChild&&e.options.fixedGutter){for(var n=wr(t)-t.scroller.scrollLeft+e.doc.scrollLeft,i=t.gutters.offsetWidth,o=n+"px",l=0;l<r.length;l++)if(!r[l].hidden){e.options.fixedGutter&&(r[l].gutter&&(r[l].gutter.style.left=o),r[l].gutterBackground&&(r[l].gutterBackground.style.left=o));var s=r[l].alignable;if(s)for(var a=0;a<s.length;a++)s[a].style.left=o}e.options.fixedGutter&&(t.gutters.style.left=n+i+"px")}}function Rr(e){if(!e.options.lineNumbers)return!1;var t=e.doc,r=F(e.options,t.first+t.size-1),i=e.display;if(r.length!=i.lineNumChars){var o=i.measure.appendChild(n("div",[n("div",r)],"CodeMirror-linenumber CodeMirror-gutter-elt")),l=o.firstChild.offsetWidth,s=o.offsetWidth-l;return i.lineGutter.style.width="",i.lineNumInnerWidth=Math.max(l,i.lineGutter.offsetWidth-s)+1,i.lineNumWidth=i.lineNumInnerWidth+s,i.lineNumChars=i.lineNumInnerWidth?r.length:-1,i.lineGutter.style.width=i.lineNumWidth+"px",Wn(e),!0}return!1}function Br(e,t){if(!Me(e,"scrollCursorIntoView")){var r=e.display,i=r.sizer.getBoundingClientRect(),o=null;if(t.top+i.top<0?o=!0:t.bottom+i.top>(window.innerHeight||document.documentElement.clientHeight)&&(o=!1),null!=o&&!Sl){var l=n("div","​",null,"position: absolute;\n                         top: "+(t.top-r.viewOffset-Et(e.display))+"px;\n                         height: "+(t.bottom-t.top+zt(e)+r.barHeight)+"px;\n                         left: "+t.left+"px; width: "+Math.max(2,t.right-t.left)+"px;");e.display.lineSpace.appendChild(l),l.scrollIntoView(o),e.display.lineSpace.removeChild(l)}}}function Gr(e,t,r,n){null==n&&(n=0);var i;e.options.lineWrapping||t!=r||(r="before"==(t=t.ch?E(t.line,"before"==t.sticky?t.ch-1:t.ch,"after"):t).sticky?E(t.line,t.ch+1,"before"):t);for(var o=0;o<5;o++){var l=!1,s=sr(e,t),a=r&&r!=t?sr(e,r):s,u=Vr(e,i={left:Math.min(s.left,a.left),top:Math.min(s.top,a.top)-n,right:Math.max(s.left,a.left),bottom:Math.max(s.bottom,a.bottom)+n}),c=e.doc.scrollTop,f=e.doc.scrollLeft;if(null!=u.scrollTop&&(qr(e,u.scrollTop),Math.abs(e.doc.scrollTop-c)>1&&(l=!0)),null!=u.scrollLeft&&(Qr(e,u.scrollLeft),Math.abs(e.doc.scrollLeft-f)>1&&(l=!0)),!l)break}return i}function Ur(e,t){var r=Vr(e,t);null!=r.scrollTop&&qr(e,r.scrollTop),null!=r.scrollLeft&&Qr(e,r.scrollLeft)}function Vr(e,t){var r=e.display,n=mr(e.display);t.top<0&&(t.top=0);var i=e.curOp&&null!=e.curOp.scrollTop?e.curOp.scrollTop:r.scroller.scrollTop,o=Bt(e),l={};t.bottom-t.top>o&&(t.bottom=t.top+o);var s=e.doc.height+Pt(r),a=t.top<n,u=t.bottom>s-n;if(t.top<i)l.scrollTop=a?0:t.top;else if(t.bottom>i+o){var c=Math.min(t.top,(u?s:t.bottom)-o);c!=i&&(l.scrollTop=c)}var f=e.curOp&&null!=e.curOp.scrollLeft?e.curOp.scrollLeft:r.scroller.scrollLeft,h=Rt(e)-(e.options.fixedGutter?r.gutters.offsetWidth:0),d=t.right-t.left>h;return d&&(t.right=t.left+h),t.left<10?l.scrollLeft=0:t.left<f?l.scrollLeft=Math.max(0,t.left-(d?0:10)):t.right>h+f-3&&(l.scrollLeft=t.right+(d?0:10)-h),l}function Kr(e,t){null!=t&&(_r(e),e.curOp.scrollTop=(null==e.curOp.scrollTop?e.doc.scrollTop:e.curOp.scrollTop)+t)}function jr(e){_r(e);var t=e.getCursor();e.curOp.scrollToPos={from:t,to:t,margin:e.options.cursorScrollMargin}}function Xr(e,t,r){null==t&&null==r||_r(e),null!=t&&(e.curOp.scrollLeft=t),null!=r&&(e.curOp.scrollTop=r)}function Yr(e,t){_r(e),e.curOp.scrollToPos=t}function _r(e){var t=e.curOp.scrollToPos;t&&(e.curOp.scrollToPos=null,$r(e,ar(e,t.from),ar(e,t.to),t.margin))}function $r(e,t,r,n){var i=Vr(e,{left:Math.min(t.left,r.left),top:Math.min(t.top,r.top)-n,right:Math.max(t.right,r.right),bottom:Math.max(t.bottom,r.bottom)+n});Xr(e,i.scrollLeft,i.scrollTop)}function qr(e,t){Math.abs(e.doc.scrollTop-t)<2||(fl||On(e,{top:t}),Zr(e,t,!0),fl&&On(e),Cn(e,100))}function Zr(e,t,r){t=Math.min(e.display.scroller.scrollHeight-e.display.scroller.clientHeight,t),(e.display.scroller.scrollTop!=t||r)&&(e.doc.scrollTop=t,e.display.scrollbars.setScrollTop(t),e.display.scroller.scrollTop!=t&&(e.display.scroller.scrollTop=t))}function Qr(e,t,r,n){t=Math.min(t,e.display.scroller.scrollWidth-e.display.scroller.clientWidth),(r?t==e.doc.scrollLeft:Math.abs(e.doc.scrollLeft-t)<2)&&!n||(e.doc.scrollLeft=t,zr(e),e.display.scroller.scrollLeft!=t&&(e.display.scroller.scrollLeft=t),e.display.scrollbars.setScrollLeft(t))}function Jr(e){var t=e.display,r=t.gutters.offsetWidth,n=Math.round(e.doc.height+Pt(e.display));return{clientHeight:t.scroller.clientHeight,viewHeight:t.wrapper.clientHeight,scrollWidth:t.scroller.scrollWidth,clientWidth:t.scroller.clientWidth,viewWidth:t.wrapper.clientWidth,barLeft:e.options.fixedGutter?r:0,docHeight:n,scrollHeight:n+zt(e)+t.barHeight,nativeBarWidth:t.nativeBarWidth,gutterWidth:r}}function en(e,t){t||(t=Jr(e));var r=e.display.barWidth,n=e.display.barHeight;tn(e,t);for(var i=0;i<4&&r!=e.display.barWidth||n!=e.display.barHeight;i++)r!=e.display.barWidth&&e.options.lineWrapping&&Er(e),tn(e,Jr(e)),r=e.display.barWidth,n=e.display.barHeight}function tn(e,t){var r=e.display,n=r.scrollbars.update(t);r.sizer.style.paddingRight=(r.barWidth=n.right)+"px",r.sizer.style.paddingBottom=(r.barHeight=n.bottom)+"px",r.heightForcer.style.borderBottom=n.bottom+"px solid transparent",n.right&&n.bottom?(r.scrollbarFiller.style.display="block",r.scrollbarFiller.style.height=n.bottom+"px",r.scrollbarFiller.style.width=n.right+"px"):r.scrollbarFiller.style.display="",n.bottom&&e.options.coverGutterNextToScrollbar&&e.options.fixedGutter?(r.gutterFiller.style.display="block",r.gutterFiller.style.height=n.bottom+"px",r.gutterFiller.style.width=t.gutterWidth+"px"):r.gutterFiller.style.display=""}function rn(e){e.display.scrollbars&&(e.display.scrollbars.clear(),e.display.scrollbars.addClass&&Fl(e.display.wrapper,e.display.scrollbars.addClass)),e.display.scrollbars=new ws[e.options.scrollbarStyle](function(t){e.display.wrapper.insertBefore(t,e.display.scrollbarFiller),Ql(t,"mousedown",function(){e.state.focused&&setTimeout(function(){return e.display.input.focus()},0)}),t.setAttribute("cm-not-content","true")},function(t,r){"horizontal"==r?Qr(e,t):qr(e,t)},e),e.display.scrollbars.addClass&&s(e.display.wrapper,e.display.scrollbars.addClass)}function nn(e){e.curOp={cm:e,viewChanged:!1,startHeight:e.doc.height,forceUpdate:!1,updateInput:null,typing:!1,changeObjs:null,cursorActivityHandlers:null,cursorActivityCalled:0,selectionChanged:!1,updateMaxLine:!1,scrollLeft:null,scrollTop:null,scrollToPos:null,focus:!1,id:++xs},vt(e.curOp)}function on(e){yt(e.curOp,function(e){for(var t=0;t<e.ops.length;t++)e.ops[t].cm.curOp=null;ln(e)})}function ln(e){for(var t=e.ops,r=0;r<t.length;r++)sn(t[r]);for(var n=0;n<t.length;n++)an(t[n]);for(var i=0;i<t.length;i++)un(t[i]);for(var o=0;o<t.length;o++)cn(t[o]);for(var l=0;l<t.length;l++)fn(t[l])}function sn(e){var t=e.cm,r=t.display;Ln(t),e.updateMaxLine&&we(t),e.mustUpdate=e.viewChanged||e.forceUpdate||null!=e.scrollTop||e.scrollToPos&&(e.scrollToPos.from.line<r.viewFrom||e.scrollToPos.to.line>=r.viewTo)||r.maxLineChanged&&t.options.lineWrapping,e.update=e.mustUpdate&&new Cs(t,e.mustUpdate&&{top:e.scrollTop,ensure:e.scrollToPos},e.forceUpdate)}function an(e){e.updatedDisplay=e.mustUpdate&&Mn(e.cm,e.update)}function un(e){var t=e.cm,r=t.display;e.updatedDisplay&&Er(t),e.barMeasure=Jr(t),r.maxLineChanged&&!t.options.lineWrapping&&(e.adjustWidthTo=Kt(t,r.maxLine,r.maxLine.text.length).left+3,t.display.sizerWidth=e.adjustWidthTo,e.barMeasure.scrollWidth=Math.max(r.scroller.clientWidth,r.sizer.offsetLeft+e.adjustWidthTo+zt(t)+t.display.barWidth),e.maxScrollLeft=Math.max(0,r.sizer.offsetLeft+e.adjustWidthTo-Rt(t))),(e.updatedDisplay||e.selectionChanged)&&(e.preparedSelection=r.input.prepareSelection())}function cn(e){var t=e.cm;null!=e.adjustWidthTo&&(t.display.sizer.style.minWidth=e.adjustWidthTo+"px",e.maxScrollLeft<t.doc.scrollLeft&&Qr(t,Math.min(t.display.scroller.scrollLeft,e.maxScrollLeft),!0),t.display.maxLineChanged=!1);var r=e.focus&&e.focus==l();e.preparedSelection&&t.display.input.showSelection(e.preparedSelection,r),(e.updatedDisplay||e.startHeight!=t.doc.height)&&en(t,e.barMeasure),e.updatedDisplay&&Dn(t,e.barMeasure),e.selectionChanged&&Ar(t),t.state.focused&&e.updateInput&&t.display.input.reset(e.typing),r&&Wr(e.cm)}function fn(e){var t=e.cm,r=t.display,n=t.doc;e.updatedDisplay&&Nn(t,e.update),null==r.wheelStartX||null==e.scrollTop&&null==e.scrollLeft&&!e.scrollToPos||(r.wheelStartX=r.wheelStartY=null),null!=e.scrollTop&&Zr(t,e.scrollTop,e.forceScroll),null!=e.scrollLeft&&Qr(t,e.scrollLeft,!0,!0),e.scrollToPos&&Br(t,Gr(t,U(n,e.scrollToPos.from),U(n,e.scrollToPos.to),e.scrollToPos.margin));var i=e.maybeHiddenMarkers,o=e.maybeUnhiddenMarkers;if(i)for(var l=0;l<i.length;++l)i[l].lines.length||Te(i[l],"hide");if(o)for(var s=0;s<o.length;++s)o[s].lines.length&&Te(o[s],"unhide");r.wrapper.offsetHeight&&(n.scrollTop=t.display.scroller.scrollTop),e.changeObjs&&Te(t,"changes",t,e.changeObjs),e.update&&e.update.finish()}function hn(e,t){if(e.curOp)return t();nn(e);try{return t()}finally{on(e)}}function dn(e,t){return function(){if(e.curOp)return t.apply(e,arguments);nn(e);try{return t.apply(e,arguments)}finally{on(e)}}}function pn(e){return function(){if(this.curOp)return e.apply(this,arguments);nn(this);try{return e.apply(this,arguments)}finally{on(this)}}}function gn(e){return function(){var t=this.cm;if(!t||t.curOp)return e.apply(this,arguments);nn(t);try{return e.apply(this,arguments)}finally{on(t)}}}function vn(e,t,r,n){null==t&&(t=e.doc.first),null==r&&(r=e.doc.first+e.doc.size),n||(n=0);var i=e.display;if(n&&r<i.viewTo&&(null==i.updateLineNumbers||i.updateLineNumbers>t)&&(i.updateLineNumbers=t),e.curOp.viewChanged=!0,t>=i.viewTo)_l&&pe(e.doc,t)<i.viewTo&&yn(e);else if(r<=i.viewFrom)_l&&ge(e.doc,r+n)>i.viewFrom?yn(e):(i.viewFrom+=n,i.viewTo+=n);else if(t<=i.viewFrom&&r>=i.viewTo)yn(e);else if(t<=i.viewFrom){var o=bn(e,r,r+n,1);o?(i.view=i.view.slice(o.index),i.viewFrom=o.lineN,i.viewTo+=n):yn(e)}else if(r>=i.viewTo){var l=bn(e,t,t,-1);l?(i.view=i.view.slice(0,l.index),i.viewTo=l.lineN):yn(e)}else{var s=bn(e,t,t,-1),a=bn(e,r,r+n,1);s&&a?(i.view=i.view.slice(0,s.index).concat(gt(e,s.lineN,a.lineN)).concat(i.view.slice(a.index)),i.viewTo+=n):yn(e)}var u=i.externalMeasured;u&&(r<u.lineN?u.lineN+=n:t<u.lineN+u.size&&(i.externalMeasured=null))}function mn(e,t,r){e.curOp.viewChanged=!0;var n=e.display,i=e.display.externalMeasured;if(i&&t>=i.lineN&&t<i.lineN+i.size&&(n.externalMeasured=null),!(t<n.viewFrom||t>=n.viewTo)){var o=n.view[Lr(e,t)];if(null!=o.node){var l=o.changes||(o.changes=[]);-1==h(l,r)&&l.push(r)}}}function yn(e){e.display.viewFrom=e.display.viewTo=e.doc.first,e.display.view=[],e.display.viewOffset=0}function bn(e,t,r,n){var i,o=Lr(e,t),l=e.display.view;if(!_l||r==e.doc.first+e.doc.size)return{index:o,lineN:r};for(var s=e.display.viewFrom,a=0;a<o;a++)s+=l[a].size;if(s!=t){if(n>0){if(o==l.length-1)return null;i=s+l[o].size-t,o++}else i=s-t;t+=i,r+=i}for(;pe(e.doc,r)!=r;){if(o==(n<0?0:l.length-1))return null;r+=n*l[o-(n<0?1:0)].size,o+=n}return{index:o,lineN:r}}function wn(e,t,r){var n=e.display;0==n.view.length||t>=n.viewTo||r<=n.viewFrom?(n.view=gt(e,t,r),n.viewFrom=t):(n.viewFrom>t?n.view=gt(e,t,n.viewFrom).concat(n.view):n.viewFrom<t&&(n.view=n.view.slice(Lr(e,t))),n.viewFrom=t,n.viewTo<r?n.view=n.view.concat(gt(e,n.viewTo,r)):n.viewTo>r&&(n.view=n.view.slice(0,Lr(e,r)))),n.viewTo=r}function xn(e){for(var t=e.display.view,r=0,n=0;n<t.length;n++){var i=t[n];i.hidden||i.node&&!i.changes||++r}return r}function Cn(e,t){e.doc.highlightFrontier<e.display.viewTo&&e.state.highlight.set(t,u(Sn,e))}function Sn(e){var t=e.doc;if(!(t.highlightFrontier>=e.display.viewTo)){var r=+new Date+e.options.workTime,n=$e(e,t.highlightFrontier),i=[];t.iter(n.line,Math.min(t.first+t.size,e.display.viewTo+500),function(o){if(n.line>=e.display.viewFrom){var l=o.styles,s=o.text.length>e.options.maxHighlightLength?Ke(t.mode,n.state):null,a=Ye(e,o,n,!0);s&&(n.state=s),o.styles=a.styles;var u=o.styleClasses,c=a.classes;c?o.styleClasses=c:u&&(o.styleClasses=null);for(var f=!l||l.length!=o.styles.length||u!=c&&(!u||!c||u.bgClass!=c.bgClass||u.textClass!=c.textClass),h=0;!f&&h<l.length;++h)f=l[h]!=o.styles[h];f&&i.push(n.line),o.stateAfter=n.save(),n.nextLine()}else o.text.length<=e.options.maxHighlightLength&&qe(e,o.text,n),o.stateAfter=n.line%5==0?n.save():null,n.nextLine();if(+new Date>r)return Cn(e,e.options.workDelay),!0}),t.highlightFrontier=n.line,t.modeFrontier=Math.max(t.modeFrontier,n.line),i.length&&hn(e,function(){for(var t=0;t<i.length;t++)mn(e,i[t],"text")})}}function Ln(e){var t=e.display;!t.scrollbarsClipped&&t.scroller.offsetWidth&&(t.nativeBarWidth=t.scroller.offsetWidth-t.scroller.clientWidth,t.heightForcer.style.height=zt(e)+"px",t.sizer.style.marginBottom=-t.nativeBarWidth+"px",t.sizer.style.borderRightWidth=zt(e)+"px",t.scrollbarsClipped=!0)}function kn(e){if(e.hasFocus())return null;var t=l();if(!t||!o(e.display.lineDiv,t))return null;var r={activeElt:t};if(window.getSelection){var n=window.getSelection();n.anchorNode&&n.extend&&o(e.display.lineDiv,n.anchorNode)&&(r.anchorNode=n.anchorNode,r.anchorOffset=n.anchorOffset,r.focusNode=n.focusNode,r.focusOffset=n.focusOffset)}return r}function Tn(e){if(e&&e.activeElt&&e.activeElt!=l()&&(e.activeElt.focus(),e.anchorNode&&o(document.body,e.anchorNode)&&o(document.body,e.focusNode))){var t=window.getSelection(),r=document.createRange();r.setEnd(e.anchorNode,e.anchorOffset),r.collapse(!1),t.removeAllRanges(),t.addRange(r),t.extend(e.focusNode,e.focusOffset)}}function Mn(e,r){var n=e.display,i=e.doc;if(r.editorIsHidden)return yn(e),!1;if(!r.force&&r.visible.from>=n.viewFrom&&r.visible.to<=n.viewTo&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo)&&n.renderedView==n.view&&0==xn(e))return!1;Rr(e)&&(yn(e),r.dims=br(e));var o=i.first+i.size,l=Math.max(r.visible.from-e.options.viewportMargin,i.first),s=Math.min(o,r.visible.to+e.options.viewportMargin);n.viewFrom<l&&l-n.viewFrom<20&&(l=Math.max(i.first,n.viewFrom)),n.viewTo>s&&n.viewTo-s<20&&(s=Math.min(o,n.viewTo)),_l&&(l=pe(e.doc,l),s=ge(e.doc,s));var a=l!=n.viewFrom||s!=n.viewTo||n.lastWrapHeight!=r.wrapperHeight||n.lastWrapWidth!=r.wrapperWidth;wn(e,l,s),n.viewOffset=ye(M(e.doc,n.viewFrom)),e.display.mover.style.top=n.viewOffset+"px";var u=xn(e);if(!a&&0==u&&!r.force&&n.renderedView==n.view&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo))return!1;var c=kn(e);return u>4&&(n.lineDiv.style.display="none"),An(e,n.updateLineNumbers,r.dims),u>4&&(n.lineDiv.style.display=""),n.renderedView=n.view,Tn(c),t(n.cursorDiv),t(n.selectionDiv),n.gutters.style.height=n.sizer.style.minHeight=0,a&&(n.lastWrapHeight=r.wrapperHeight,n.lastWrapWidth=r.wrapperWidth,Cn(e,400)),n.updateLineNumbers=null,!0}function Nn(e,t){for(var r=t.viewport,n=!0;(n&&e.options.lineWrapping&&t.oldDisplayWidth!=Rt(e)||(r&&null!=r.top&&(r={top:Math.min(e.doc.height+Pt(e.display)-Bt(e),r.top)}),t.visible=Ir(e.display,e.doc,r),!(t.visible.from>=e.display.viewFrom&&t.visible.to<=e.display.viewTo)))&&Mn(e,t);n=!1){Er(e);var i=Jr(e);kr(e),en(e,i),Dn(e,i),t.force=!1}t.signal(e,"update",e),e.display.viewFrom==e.display.reportedViewFrom&&e.display.viewTo==e.display.reportedViewTo||(t.signal(e,"viewportChange",e,e.display.viewFrom,e.display.viewTo),e.display.reportedViewFrom=e.display.viewFrom,e.display.reportedViewTo=e.display.viewTo)}function On(e,t){var r=new Cs(e,t);if(Mn(e,r)){Er(e),Nn(e,r);var n=Jr(e);kr(e),en(e,n),Dn(e,n),r.finish()}}function An(e,r,n){function i(t){var r=t.nextSibling;return ml&&Ml&&e.display.currentWheelTarget==t?t.style.display="none":t.parentNode.removeChild(t),r}for(var o=e.display,l=e.options.lineNumbers,s=o.lineDiv,a=s.firstChild,u=o.view,c=o.viewFrom,f=0;f<u.length;f++){var d=u[f];if(d.hidden);else if(d.node&&d.node.parentNode==s){for(;a!=d.node;)a=i(a);var p=l&&null!=r&&r<=c&&d.lineNumber;d.changes&&(h(d.changes,"gutter")>-1&&(p=!1),xt(e,d,c,n)),p&&(t(d.lineNumber),d.lineNumber.appendChild(document.createTextNode(F(e.options,c)))),a=d.node.nextSibling}else{var g=Ot(e,d,c,n);s.insertBefore(g,a)}c+=d.size}for(;a;)a=i(a)}function Wn(e){var t=e.display.gutters.offsetWidth;e.display.sizer.style.marginLeft=t+"px"}function Dn(e,t){e.display.sizer.style.minHeight=t.docHeight+"px",e.display.heightForcer.style.top=t.docHeight+"px",e.display.gutters.style.height=t.docHeight+e.display.barHeight+zt(e)+"px"}function Hn(e){var r=e.display.gutters,i=e.options.gutters;t(r);for(var o=0;o<i.length;++o){var l=i[o],s=r.appendChild(n("div",null,"CodeMirror-gutter "+l));"CodeMirror-linenumbers"==l&&(e.display.lineGutter=s,s.style.width=(e.display.lineNumWidth||1)+"px")}r.style.display=o?"":"none",Wn(e)}function Fn(e){var t=h(e.gutters,"CodeMirror-linenumbers");-1==t&&e.lineNumbers?e.gutters=e.gutters.concat(["CodeMirror-linenumbers"]):t>-1&&!e.lineNumbers&&(e.gutters=e.gutters.slice(0),e.gutters.splice(t,1))}function En(e){var t=e.wheelDeltaX,r=e.wheelDeltaY;return null==t&&e.detail&&e.axis==e.HORIZONTAL_AXIS&&(t=e.detail),null==r&&e.detail&&e.axis==e.VERTICAL_AXIS?r=e.detail:null==r&&(r=e.wheelDelta),{x:t,y:r}}function Pn(e){var t=En(e);return t.x*=Ls,t.y*=Ls,t}function In(e,t){var r=En(t),n=r.x,i=r.y,o=e.display,l=o.scroller,s=l.scrollWidth>l.clientWidth,a=l.scrollHeight>l.clientHeight;if(n&&s||i&&a){if(i&&Ml&&ml)e:for(var u=t.target,c=o.view;u!=l;u=u.parentNode)for(var f=0;f<c.length;f++)if(c[f].node==u){e.display.currentWheelTarget=u;break e}if(n&&!fl&&!wl&&null!=Ls)return i&&a&&qr(e,Math.max(0,l.scrollTop+i*Ls)),Qr(e,Math.max(0,l.scrollLeft+n*Ls)),(!i||i&&a)&&We(t),void(o.wheelStartX=null);if(i&&null!=Ls){var h=i*Ls,d=e.doc.scrollTop,p=d+o.wrapper.clientHeight;h<0?d=Math.max(0,d+h-50):p=Math.min(e.doc.height,p+h+50),On(e,{top:d,bottom:p})}Ss<20&&(null==o.wheelStartX?(o.wheelStartX=l.scrollLeft,o.wheelStartY=l.scrollTop,o.wheelDX=n,o.wheelDY=i,setTimeout(function(){if(null!=o.wheelStartX){var e=l.scrollLeft-o.wheelStartX,t=l.scrollTop-o.wheelStartY,r=t&&o.wheelDY&&t/o.wheelDY||e&&o.wheelDX&&e/o.wheelDX;o.wheelStartX=o.wheelStartY=null,r&&(Ls=(Ls*Ss+r)/(Ss+1),++Ss)}},200)):(o.wheelDX+=n,o.wheelDY+=i))}}function zn(e,t){var r=e[t];e.sort(function(e,t){return P(e.from(),t.from())}),t=h(e,r);for(var n=1;n<e.length;n++){var i=e[n],o=e[n-1];if(P(o.to(),i.from())>=0){var l=B(o.from(),i.from()),s=R(o.to(),i.to()),a=o.empty()?i.from()==i.head:o.from()==o.head;n<=t&&--t,e.splice(--n,2,new Ts(a?s:l,a?l:s))}}return new ks(e,t)}function Rn(e,t){return new ks([new Ts(e,t||e)],0)}function Bn(e){return e.text?E(e.from.line+e.text.length-1,g(e.text).length+(1==e.text.length?e.from.ch:0)):e.to}function Gn(e,t){if(P(e,t.from)<0)return e;if(P(e,t.to)<=0)return Bn(t);var r=e.line+t.text.length-(t.to.line-t.from.line)-1,n=e.ch;return e.line==t.to.line&&(n+=Bn(t).ch-t.to.ch),E(r,n)}function Un(e,t){for(var r=[],n=0;n<e.sel.ranges.length;n++){var i=e.sel.ranges[n];r.push(new Ts(Gn(i.anchor,t),Gn(i.head,t)))}return zn(r,e.sel.primIndex)}function Vn(e,t,r){return e.line==t.line?E(r.line,e.ch-t.ch+r.ch):E(r.line+(e.line-t.line),e.ch)}function Kn(e,t,r){for(var n=[],i=E(e.first,0),o=i,l=0;l<t.length;l++){var s=t[l],a=Vn(s.from,i,o),u=Vn(Bn(s),i,o);if(i=s.to,o=u,"around"==r){var c=e.sel.ranges[l],f=P(c.head,c.anchor)<0;n[l]=new Ts(f?u:a,f?a:u)}else n[l]=new Ts(a,a)}return new ks(n,e.sel.primIndex)}function jn(e){e.doc.mode=Ue(e.options,e.doc.modeOption),Xn(e)}function Xn(e){e.doc.iter(function(e){e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null)}),e.doc.modeFrontier=e.doc.highlightFrontier=e.doc.first,Cn(e,100),e.state.modeGen++,e.curOp&&vn(e)}function Yn(e,t){return 0==t.from.ch&&0==t.to.ch&&""==g(t.text)&&(!e.cm||e.cm.options.wholeLineUpdateBefore)}function _n(e,t,r,n){function i(e){return r?r[e]:null}function o(e,r,i){it(e,r,i,n),bt(e,"change",e,t)}function l(e,t){for(var r=[],o=e;o<t;++o)r.push(new fs(u[o],i(o),n));return r}var s=t.from,a=t.to,u=t.text,c=M(e,s.line),f=M(e,a.line),h=g(u),d=i(u.length-1),p=a.line-s.line;if(t.full)e.insert(0,l(0,u.length)),e.remove(u.length,e.size-u.length);else if(Yn(e,t)){var v=l(0,u.length-1);o(f,f.text,d),p&&e.remove(s.line,p),v.length&&e.insert(s.line,v)}else if(c==f)if(1==u.length)o(c,c.text.slice(0,s.ch)+h+c.text.slice(a.ch),d);else{var m=l(1,u.length-1);m.push(new fs(h+c.text.slice(a.ch),d,n)),o(c,c.text.slice(0,s.ch)+u[0],i(0)),e.insert(s.line+1,m)}else if(1==u.length)o(c,c.text.slice(0,s.ch)+u[0]+f.text.slice(a.ch),i(0)),e.remove(s.line+1,p);else{o(c,c.text.slice(0,s.ch)+u[0],i(0)),o(f,h+f.text.slice(a.ch),d);var y=l(1,u.length-1);p>1&&e.remove(s.line+1,p-1),e.insert(s.line+1,y)}bt(e,"change",e,t)}function $n(e,t,r){function n(e,i,o){if(e.linked)for(var l=0;l<e.linked.length;++l){var s=e.linked[l];if(s.doc!=i){var a=o&&s.sharedHist;r&&!a||(t(s.doc,a),n(s.doc,e,a))}}}n(e,null,!0)}function qn(e,t){if(t.cm)throw new Error("This document is already in use.");e.doc=t,t.cm=e,Cr(e),jn(e),Zn(e),e.options.lineWrapping||we(e),e.options.mode=t.modeOption,vn(e)}function Zn(e){("rtl"==e.doc.direction?s:Fl)(e.display.lineDiv,"CodeMirror-rtl")}function Qn(e){hn(e,function(){Zn(e),vn(e)})}function Jn(e){this.done=[],this.undone=[],this.undoDepth=1/0,this.lastModTime=this.lastSelTime=0,this.lastOp=this.lastSelOp=null,this.lastOrigin=this.lastSelOrigin=null,this.generation=this.maxGeneration=e||1}function ei(e,t){var r={from:z(t.from),to:Bn(t),text:N(e,t.from,t.to)};return si(e,r,t.from.line,t.to.line+1),$n(e,function(e){return si(e,r,t.from.line,t.to.line+1)},!0),r}function ti(e){for(;e.length&&g(e).ranges;)e.pop()}function ri(e,t){return t?(ti(e.done),g(e.done)):e.done.length&&!g(e.done).ranges?g(e.done):e.done.length>1&&!e.done[e.done.length-2].ranges?(e.done.pop(),g(e.done)):void 0}function ni(e,t,r,n){var i=e.history;i.undone.length=0;var o,l,s=+new Date;if((i.lastOp==n||i.lastOrigin==t.origin&&t.origin&&("+"==t.origin.charAt(0)&&e.cm&&i.lastModTime>s-e.cm.options.historyEventDelay||"*"==t.origin.charAt(0)))&&(o=ri(i,i.lastOp==n)))l=g(o.changes),0==P(t.from,t.to)&&0==P(t.from,l.to)?l.to=Bn(t):o.changes.push(ei(e,t));else{var a=g(i.done);for(a&&a.ranges||li(e.sel,i.done),o={changes:[ei(e,t)],generation:i.generation},i.done.push(o);i.done.length>i.undoDepth;)i.done.shift(),i.done[0].ranges||i.done.shift()}i.done.push(r),i.generation=++i.maxGeneration,i.lastModTime=i.lastSelTime=s,i.lastOp=i.lastSelOp=n,i.lastOrigin=i.lastSelOrigin=t.origin,l||Te(e,"historyAdded")}function ii(e,t,r,n){var i=t.charAt(0);return"*"==i||"+"==i&&r.ranges.length==n.ranges.length&&r.somethingSelected()==n.somethingSelected()&&new Date-e.history.lastSelTime<=(e.cm?e.cm.options.historyEventDelay:500)}function oi(e,t,r,n){var i=e.history,o=n&&n.origin;r==i.lastSelOp||o&&i.lastSelOrigin==o&&(i.lastModTime==i.lastSelTime&&i.lastOrigin==o||ii(e,o,g(i.done),t))?i.done[i.done.length-1]=t:li(t,i.done),i.lastSelTime=+new Date,i.lastSelOrigin=o,i.lastSelOp=r,n&&!1!==n.clearRedo&&ti(i.undone)}function li(e,t){var r=g(t);r&&r.ranges&&r.equals(e)||t.push(e)}function si(e,t,r,n){var i=t["spans_"+e.id],o=0;e.iter(Math.max(e.first,r),Math.min(e.first+e.size,n),function(r){r.markedSpans&&((i||(i=t["spans_"+e.id]={}))[o]=r.markedSpans),++o})}function ai(e){if(!e)return null;for(var t,r=0;r<e.length;++r)e[r].marker.explicitlyCleared?t||(t=e.slice(0,r)):t&&t.push(e[r]);return t?t.length?t:null:e}function ui(e,t){var r=t["spans_"+e.id];if(!r)return null;for(var n=[],i=0;i<t.text.length;++i)n.push(ai(r[i]));return n}function ci(e,t){var r=ui(e,t),n=J(e,t);if(!r)return n;if(!n)return r;for(var i=0;i<r.length;++i){var o=r[i],l=n[i];if(o&&l)e:for(var s=0;s<l.length;++s){for(var a=l[s],u=0;u<o.length;++u)if(o[u].marker==a.marker)continue e;o.push(a)}else l&&(r[i]=l)}return r}function fi(e,t,r){for(var n=[],i=0;i<e.length;++i){var o=e[i];if(o.ranges)n.push(r?ks.prototype.deepCopy.call(o):o);else{var l=o.changes,s=[];n.push({changes:s});for(var a=0;a<l.length;++a){var u=l[a],c=void 0;if(s.push({from:u.from,to:u.to,text:u.text}),t)for(var f in u)(c=f.match(/^spans_(\d+)$/))&&h(t,Number(c[1]))>-1&&(g(s)[f]=u[f],delete u[f])}}}return n}function hi(e,t,r,n){if(n){var i=e.anchor;if(r){var o=P(t,i)<0;o!=P(r,i)<0?(i=t,t=r):o!=P(t,r)<0&&(t=r)}return new Ts(i,t)}return new Ts(r||t,t)}function di(e,t,r,n,i){null==i&&(i=e.cm&&(e.cm.display.shift||e.extend)),bi(e,new ks([hi(e.sel.primary(),t,r,i)],0),n)}function pi(e,t,r){for(var n=[],i=e.cm&&(e.cm.display.shift||e.extend),o=0;o<e.sel.ranges.length;o++)n[o]=hi(e.sel.ranges[o],t[o],null,i);bi(e,zn(n,e.sel.primIndex),r)}function gi(e,t,r,n){var i=e.sel.ranges.slice(0);i[t]=r,bi(e,zn(i,e.sel.primIndex),n)}function vi(e,t,r,n){bi(e,Rn(t,r),n)}function mi(e,t,r){var n={ranges:t.ranges,update:function(t){var r=this;this.ranges=[];for(var n=0;n<t.length;n++)r.ranges[n]=new Ts(U(e,t[n].anchor),U(e,t[n].head))},origin:r&&r.origin};return Te(e,"beforeSelectionChange",e,n),e.cm&&Te(e.cm,"beforeSelectionChange",e.cm,n),n.ranges!=t.ranges?zn(n.ranges,n.ranges.length-1):t}function yi(e,t,r){var n=e.history.done,i=g(n);i&&i.ranges?(n[n.length-1]=t,wi(e,t,r)):bi(e,t,r)}function bi(e,t,r){wi(e,t,r),oi(e,e.sel,e.cm?e.cm.curOp.id:NaN,r)}function wi(e,t,r){(Oe(e,"beforeSelectionChange")||e.cm&&Oe(e.cm,"beforeSelectionChange"))&&(t=mi(e,t,r)),xi(e,Si(e,t,r&&r.bias||(P(t.primary().head,e.sel.primary().head)<0?-1:1),!0)),r&&!1===r.scroll||!e.cm||jr(e.cm)}function xi(e,t){t.equals(e.sel)||(e.sel=t,e.cm&&(e.cm.curOp.updateInput=e.cm.curOp.selectionChanged=!0,Ne(e.cm)),bt(e,"cursorActivity",e))}function Ci(e){xi(e,Si(e,e.sel,null,!1))}function Si(e,t,r,n){for(var i,o=0;o<t.ranges.length;o++){var l=t.ranges[o],s=t.ranges.length==e.sel.ranges.length&&e.sel.ranges[o],a=ki(e,l.anchor,s&&s.anchor,r,n),u=ki(e,l.head,s&&s.head,r,n);(i||a!=l.anchor||u!=l.head)&&(i||(i=t.ranges.slice(0,o)),i[o]=new Ts(a,u))}return i?zn(i,t.primIndex):t}function Li(e,t,r,n,i){var o=M(e,t.line);if(o.markedSpans)for(var l=0;l<o.markedSpans.length;++l){var s=o.markedSpans[l],a=s.marker;if((null==s.from||(a.inclusiveLeft?s.from<=t.ch:s.from<t.ch))&&(null==s.to||(a.inclusiveRight?s.to>=t.ch:s.to>t.ch))){if(i&&(Te(a,"beforeCursorEnter"),a.explicitlyCleared)){if(o.markedSpans){--l;continue}break}if(!a.atomic)continue;if(r){var u=a.find(n<0?1:-1),c=void 0;if((n<0?a.inclusiveRight:a.inclusiveLeft)&&(u=Ti(e,u,-n,u&&u.line==t.line?o:null)),u&&u.line==t.line&&(c=P(u,r))&&(n<0?c<0:c>0))return Li(e,u,t,n,i)}var f=a.find(n<0?-1:1);return(n<0?a.inclusiveLeft:a.inclusiveRight)&&(f=Ti(e,f,n,f.line==t.line?o:null)),f?Li(e,f,t,n,i):null}}return t}function ki(e,t,r,n,i){var o=n||1,l=Li(e,t,r,o,i)||!i&&Li(e,t,r,o,!0)||Li(e,t,r,-o,i)||!i&&Li(e,t,r,-o,!0);return l||(e.cantEdit=!0,E(e.first,0))}function Ti(e,t,r,n){return r<0&&0==t.ch?t.line>e.first?U(e,E(t.line-1)):null:r>0&&t.ch==(n||M(e,t.line)).text.length?t.line<e.first+e.size-1?E(t.line+1,0):null:new E(t.line,t.ch+r)}function Mi(e){e.setSelection(E(e.firstLine(),0),E(e.lastLine()),Gl)}function Ni(e,t,r){var n={canceled:!1,from:t.from,to:t.to,text:t.text,origin:t.origin,cancel:function(){return n.canceled=!0}};return r&&(n.update=function(t,r,i,o){t&&(n.from=U(e,t)),r&&(n.to=U(e,r)),i&&(n.text=i),void 0!==o&&(n.origin=o)}),Te(e,"beforeChange",e,n),e.cm&&Te(e.cm,"beforeChange",e.cm,n),n.canceled?null:{from:n.from,to:n.to,text:n.text,origin:n.origin}}function Oi(e,t,r){if(e.cm){if(!e.cm.curOp)return dn(e.cm,Oi)(e,t,r);if(e.cm.state.suppressEdits)return}if(!(Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"))||(t=Ni(e,t,!0))){var n=Yl&&!r&&te(e,t.from,t.to);if(n)for(var i=n.length-1;i>=0;--i)Ai(e,{from:n[i].from,to:n[i].to,text:i?[""]:t.text,origin:t.origin});else Ai(e,t)}}function Ai(e,t){if(1!=t.text.length||""!=t.text[0]||0!=P(t.from,t.to)){var r=Un(e,t);ni(e,t,r,e.cm?e.cm.curOp.id:NaN),Hi(e,t,r,J(e,t));var n=[];$n(e,function(e,r){r||-1!=h(n,e.history)||(zi(e.history,t),n.push(e.history)),Hi(e,t,null,J(e,t))})}}function Wi(e,t,r){if(!e.cm||!e.cm.state.suppressEdits||r){for(var n,i=e.history,o=e.sel,l="undo"==t?i.done:i.undone,s="undo"==t?i.undone:i.done,a=0;a<l.length&&(n=l[a],r?!n.ranges||n.equals(e.sel):n.ranges);a++);if(a!=l.length){for(i.lastOrigin=i.lastSelOrigin=null;(n=l.pop()).ranges;){if(li(n,s),r&&!n.equals(e.sel))return void bi(e,n,{clearRedo:!1});o=n}var u=[];li(o,s),s.push({changes:u,generation:i.generation}),i.generation=n.generation||++i.maxGeneration;for(var c=Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"),f=n.changes.length-1;f>=0;--f){var d=function(r){var i=n.changes[r];if(i.origin=t,c&&!Ni(e,i,!1))return l.length=0,{};u.push(ei(e,i));var o=r?Un(e,i):g(l);Hi(e,i,o,ci(e,i)),!r&&e.cm&&e.cm.scrollIntoView({from:i.from,to:Bn(i)});var s=[];$n(e,function(e,t){t||-1!=h(s,e.history)||(zi(e.history,i),s.push(e.history)),Hi(e,i,null,ci(e,i))})}(f);if(d)return d.v}}}}function Di(e,t){if(0!=t&&(e.first+=t,e.sel=new ks(v(e.sel.ranges,function(e){return new Ts(E(e.anchor.line+t,e.anchor.ch),E(e.head.line+t,e.head.ch))}),e.sel.primIndex),e.cm)){vn(e.cm,e.first,e.first-t,t);for(var r=e.cm.display,n=r.viewFrom;n<r.viewTo;n++)mn(e.cm,n,"gutter")}}function Hi(e,t,r,n){if(e.cm&&!e.cm.curOp)return dn(e.cm,Hi)(e,t,r,n);if(t.to.line<e.first)Di(e,t.text.length-1-(t.to.line-t.from.line));else if(!(t.from.line>e.lastLine())){if(t.from.line<e.first){var i=t.text.length-1-(e.first-t.from.line);Di(e,i),t={from:E(e.first,0),to:E(t.to.line+i,t.to.ch),text:[g(t.text)],origin:t.origin}}var o=e.lastLine();t.to.line>o&&(t={from:t.from,to:E(o,M(e,o).text.length),text:[t.text[0]],origin:t.origin}),t.removed=N(e,t.from,t.to),r||(r=Un(e,t)),e.cm?Fi(e.cm,t,n):_n(e,t,n),wi(e,r,Gl)}}function Fi(e,t,r){var n=e.doc,i=e.display,o=t.from,l=t.to,s=!1,a=o.line;e.options.lineWrapping||(a=W(fe(M(n,o.line))),n.iter(a,l.line+1,function(e){if(e==i.maxLine)return s=!0,!0})),n.sel.contains(t.from,t.to)>-1&&Ne(e),_n(n,t,r,xr(e)),e.options.lineWrapping||(n.iter(a,o.line+t.text.length,function(e){var t=be(e);t>i.maxLineLength&&(i.maxLine=e,i.maxLineLength=t,i.maxLineChanged=!0,s=!1)}),s&&(e.curOp.updateMaxLine=!0)),nt(n,o.line),Cn(e,400);var u=t.text.length-(l.line-o.line)-1;t.full?vn(e):o.line!=l.line||1!=t.text.length||Yn(e.doc,t)?vn(e,o.line,l.line+1,u):mn(e,o.line,"text");var c=Oe(e,"changes"),f=Oe(e,"change");if(f||c){var h={from:o,to:l,text:t.text,removed:t.removed,origin:t.origin};f&&bt(e,"change",e,h),c&&(e.curOp.changeObjs||(e.curOp.changeObjs=[])).push(h)}e.display.selForContextMenu=null}function Ei(e,t,r,n,i){if(n||(n=r),P(n,r)<0){var o;r=(o=[n,r])[0],n=o[1]}"string"==typeof t&&(t=e.splitLines(t)),Oi(e,{from:r,to:n,text:t,origin:i})}function Pi(e,t,r,n){r<e.line?e.line+=n:t<e.line&&(e.line=t,e.ch=0)}function Ii(e,t,r,n){for(var i=0;i<e.length;++i){var o=e[i],l=!0;if(o.ranges){o.copied||((o=e[i]=o.deepCopy()).copied=!0);for(var s=0;s<o.ranges.length;s++)Pi(o.ranges[s].anchor,t,r,n),Pi(o.ranges[s].head,t,r,n)}else{for(var a=0;a<o.changes.length;++a){var u=o.changes[a];if(r<u.from.line)u.from=E(u.from.line+n,u.from.ch),u.to=E(u.to.line+n,u.to.ch);else if(t<=u.to.line){l=!1;break}}l||(e.splice(0,i+1),i=0)}}}function zi(e,t){var r=t.from.line,n=t.to.line,i=t.text.length-(n-r)-1;Ii(e.done,r,n,i),Ii(e.undone,r,n,i)}function Ri(e,t,r,n){var i=t,o=t;return"number"==typeof t?o=M(e,G(e,t)):i=W(t),null==i?null:(n(o,i)&&e.cm&&mn(e.cm,i,r),o)}function Bi(e){var t=this;this.lines=e,this.parent=null;for(var r=0,n=0;n<e.length;++n)e[n].parent=t,r+=e[n].height;this.height=r}function Gi(e){var t=this;this.children=e;for(var r=0,n=0,i=0;i<e.length;++i){var o=e[i];r+=o.chunkSize(),n+=o.height,o.parent=t}this.size=r,this.height=n,this.parent=null}function Ui(e,t,r){ye(t)<(e.curOp&&e.curOp.scrollTop||e.doc.scrollTop)&&Kr(e,r)}function Vi(e,t,r,n){var i=new Ms(e,r,n),o=e.cm;return o&&i.noHScroll&&(o.display.alignWidgets=!0),Ri(e,t,"widget",function(t){var r=t.widgets||(t.widgets=[]);if(null==i.insertAt?r.push(i):r.splice(Math.min(r.length-1,Math.max(0,i.insertAt)),0,i),i.line=t,o&&!ve(e,t)){var n=ye(t)<e.scrollTop;A(t,t.height+Ht(i)),n&&Kr(o,i.height),o.curOp.forceUpdate=!0}return!0}),bt(o,"lineWidgetAdded",o,i,"number"==typeof t?t:W(t)),i}function Ki(e,t,r,n,o){if(n&&n.shared)return ji(e,t,r,n,o);if(e.cm&&!e.cm.curOp)return dn(e.cm,Ki)(e,t,r,n,o);var l=new Os(e,o),s=P(t,r);if(n&&c(n,l,!1),s>0||0==s&&!1!==l.clearWhenEmpty)return l;if(l.replacedWith&&(l.collapsed=!0,l.widgetNode=i("span",[l.replacedWith],"CodeMirror-widget"),n.handleMouseEvents||l.widgetNode.setAttribute("cm-ignore-events","true"),n.insertLeft&&(l.widgetNode.insertLeft=!0)),l.collapsed){if(ce(e,t.line,t,r,l)||t.line!=r.line&&ce(e,r.line,t,r,l))throw new Error("Inserting collapsed marker partially overlapping an existing one");X()}l.addToHistory&&ni(e,{from:t,to:r,origin:"markText"},e.sel,NaN);var a,u=t.line,f=e.cm;if(e.iter(u,r.line+1,function(e){f&&l.collapsed&&!f.options.lineWrapping&&fe(e)==f.display.maxLine&&(a=!0),l.collapsed&&u!=t.line&&A(e,0),q(e,new Y(l,u==t.line?t.ch:null,u==r.line?r.ch:null)),++u}),l.collapsed&&e.iter(t.line,r.line+1,function(t){ve(e,t)&&A(t,0)}),l.clearOnEnter&&Ql(l,"beforeCursorEnter",function(){return l.clear()}),l.readOnly&&(j(),(e.history.done.length||e.history.undone.length)&&e.clearHistory()),l.collapsed&&(l.id=++Ns,l.atomic=!0),f){if(a&&(f.curOp.updateMaxLine=!0),l.collapsed)vn(f,t.line,r.line+1);else if(l.className||l.title||l.startStyle||l.endStyle||l.css)for(var h=t.line;h<=r.line;h++)mn(f,h,"text");l.atomic&&Ci(f.doc),bt(f,"markerAdded",f,l)}return l}function ji(e,t,r,n,i){(n=c(n)).shared=!1;var o=[Ki(e,t,r,n,i)],l=o[0],s=n.widgetNode;return $n(e,function(e){s&&(n.widgetNode=s.cloneNode(!0)),o.push(Ki(e,U(e,t),U(e,r),n,i));for(var a=0;a<e.linked.length;++a)if(e.linked[a].isParent)return;l=g(o)}),new As(o,l)}function Xi(e){return e.findMarks(E(e.first,0),e.clipPos(E(e.lastLine())),function(e){return e.parent})}function Yi(e,t){for(var r=0;r<t.length;r++){var n=t[r],i=n.find(),o=e.clipPos(i.from),l=e.clipPos(i.to);if(P(o,l)){var s=Ki(e,o,l,n.primary,n.primary.type);n.markers.push(s),s.parent=n}}}function _i(e){for(var t=0;t<e.length;t++)!function(t){var r=e[t],n=[r.primary.doc];$n(r.primary.doc,function(e){return n.push(e)});for(var i=0;i<r.markers.length;i++){var o=r.markers[i];-1==h(n,o.doc)&&(o.parent=null,r.markers.splice(i--,1))}}(t)}function $i(e){var t=this;if(Qi(t),!Me(t,e)&&!Ft(t.display,e)){We(e),gl&&(Hs=+new Date);var r=Sr(t,e,!0),n=e.dataTransfer.files;if(r&&!t.isReadOnly())if(n&&n.length&&window.FileReader&&window.File)for(var i=n.length,o=Array(i),l=0,s=0;s<i;++s)!function(e,n){if(!t.options.allowDropFileTypes||-1!=h(t.options.allowDropFileTypes,e.type)){var s=new FileReader;s.onload=dn(t,function(){var e=s.result;if(/[\x00-\x08\x0e-\x1f]{2}/.test(e)&&(e=""),o[n]=e,++l==i){var a={from:r=U(t.doc,r),to:r,text:t.doc.splitLines(o.join(t.doc.lineSeparator())),origin:"paste"};Oi(t.doc,a),yi(t.doc,Rn(r,Bn(a)))}}),s.readAsText(e)}}(n[s],s);else{if(t.state.draggingText&&t.doc.sel.contains(r)>-1)return t.state.draggingText(e),void setTimeout(function(){return t.display.input.focus()},20);try{var a=e.dataTransfer.getData("Text");if(a){var u;if(t.state.draggingText&&!t.state.draggingText.copy&&(u=t.listSelections()),wi(t.doc,Rn(r,r)),u)for(var c=0;c<u.length;++c)Ei(t.doc,"",u[c].anchor,u[c].head,"drag");t.replaceSelection(a,"around","paste"),t.display.input.focus()}}catch(e){}}}}function qi(e,t){if(gl&&(!e.state.draggingText||+new Date-Hs<100))Fe(t);else if(!Me(e,t)&&!Ft(e.display,t)&&(t.dataTransfer.setData("Text",e.getSelection()),t.dataTransfer.effectAllowed="copyMove",t.dataTransfer.setDragImage&&!xl)){var r=n("img",null,null,"position: fixed; left: 0; top: 0;");r.src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==",wl&&(r.width=r.height=1,e.display.wrapper.appendChild(r),r._top=r.offsetTop),t.dataTransfer.setDragImage(r,0,0),wl&&r.parentNode.removeChild(r)}}function Zi(e,t){var i=Sr(e,t);if(i){var o=document.createDocumentFragment();Mr(e,i,o),e.display.dragCursor||(e.display.dragCursor=n("div",null,"CodeMirror-cursors CodeMirror-dragcursors"),e.display.lineSpace.insertBefore(e.display.dragCursor,e.display.cursorDiv)),r(e.display.dragCursor,o)}}function Qi(e){e.display.dragCursor&&(e.display.lineSpace.removeChild(e.display.dragCursor),e.display.dragCursor=null)}function Ji(e){if(document.getElementsByClassName)for(var t=document.getElementsByClassName("CodeMirror"),r=0;r<t.length;r++){var n=t[r].CodeMirror;n&&e(n)}}function eo(){Fs||(to(),Fs=!0)}function to(){var e;Ql(window,"resize",function(){null==e&&(e=setTimeout(function(){e=null,Ji(ro)},100))}),Ql(window,"blur",function(){return Ji(Fr)})}function ro(e){var t=e.display;t.lastWrapHeight==t.wrapper.clientHeight&&t.lastWrapWidth==t.wrapper.clientWidth||(t.cachedCharWidth=t.cachedTextHeight=t.cachedPaddingH=null,t.scrollbarsClipped=!1,e.setSize())}function no(e){var t=e.split(/-(?!$)/);e=t[t.length-1];for(var r,n,i,o,l=0;l<t.length-1;l++){var s=t[l];if(/^(cmd|meta|m)$/i.test(s))o=!0;else if(/^a(lt)?$/i.test(s))r=!0;else if(/^(c|ctrl|control)$/i.test(s))n=!0;else{if(!/^s(hift)?$/i.test(s))throw new Error("Unrecognized modifier name: "+s);i=!0}}return r&&(e="Alt-"+e),n&&(e="Ctrl-"+e),o&&(e="Cmd-"+e),i&&(e="Shift-"+e),e}function io(e){var t={};for(var r in e)if(e.hasOwnProperty(r)){var n=e[r];if(/^(name|fallthrough|(de|at)tach)$/.test(r))continue;if("..."==n){delete e[r];continue}for(var i=v(r.split(" "),no),o=0;o<i.length;o++){var l=void 0,s=void 0;o==i.length-1?(s=i.join(" "),l=n):(s=i.slice(0,o+1).join(" "),l="...");var a=t[s];if(a){if(a!=l)throw new Error("Inconsistent bindings for "+s)}else t[s]=l}delete e[r]}for(var u in t)e[u]=t[u];return e}function oo(e,t,r,n){var i=(t=uo(t)).call?t.call(e,n):t[e];if(!1===i)return"nothing";if("..."===i)return"multi";if(null!=i&&r(i))return"handled";if(t.fallthrough){if("[object Array]"!=Object.prototype.toString.call(t.fallthrough))return oo(e,t.fallthrough,r,n);for(var o=0;o<t.fallthrough.length;o++){var l=oo(e,t.fallthrough[o],r,n);if(l)return l}}}function lo(e){var t="string"==typeof e?e:Es[e.keyCode];return"Ctrl"==t||"Alt"==t||"Shift"==t||"Mod"==t}function so(e,t,r){var n=e;return t.altKey&&"Alt"!=n&&(e="Alt-"+e),(Dl?t.metaKey:t.ctrlKey)&&"Ctrl"!=n&&(e="Ctrl-"+e),(Dl?t.ctrlKey:t.metaKey)&&"Cmd"!=n&&(e="Cmd-"+e),!r&&t.shiftKey&&"Shift"!=n&&(e="Shift-"+e),e}function ao(e,t){if(wl&&34==e.keyCode&&e.char)return!1;var r=Es[e.keyCode];return null!=r&&!e.altGraphKey&&so(r,e,t)}function uo(e){return"string"==typeof e?Rs[e]:e}function co(e,t){for(var r=e.doc.sel.ranges,n=[],i=0;i<r.length;i++){for(var o=t(r[i]);n.length&&P(o.from,g(n).to)<=0;){var l=n.pop();if(P(l.from,o.from)<0){o.from=l.from;break}}n.push(o)}hn(e,function(){for(var t=n.length-1;t>=0;t--)Ei(e.doc,"",n[t].from,n[t].to,"+delete");jr(e)})}function fo(e,t,r){var n=L(e.text,t+r,r);return n<0||n>e.text.length?null:n}function ho(e,t,r){var n=fo(e,t.ch,r);return null==n?null:new E(t.line,n,r<0?"after":"before")}function po(e,t,r,n,i){if(e){var o=Se(r,t.doc.direction);if(o){var l,s=i<0?g(o):o[0],a=i<0==(1==s.level)?"after":"before";if(s.level>0){var u=Xt(t,r);l=i<0?r.text.length-1:0;var c=Yt(t,u,l).top;l=k(function(e){return Yt(t,u,e).top==c},i<0==(1==s.level)?s.from:s.to-1,l),"before"==a&&(l=fo(r,l,1))}else l=i<0?s.to:s.from;return new E(n,l,a)}}return new E(n,i<0?r.text.length:0,i<0?"before":"after")}function go(e,t,r,n){var i=Se(t,e.doc.direction);if(!i)return ho(t,r,n);r.ch>=t.text.length?(r.ch=t.text.length,r.sticky="before"):r.ch<=0&&(r.ch=0,r.sticky="after");var o=Ce(i,r.ch,r.sticky),l=i[o];if("ltr"==e.doc.direction&&l.level%2==0&&(n>0?l.to>r.ch:l.from<r.ch))return ho(t,r,n);var s,a=function(e,r){return fo(t,e instanceof E?e.ch:e,r)},u=function(r){return e.options.lineWrapping?(s=s||Xt(e,t),hr(e,t,s,r)):{begin:0,end:t.text.length}},c=u("before"==r.sticky?a(r,-1):r.ch);if("rtl"==e.doc.direction||1==l.level){var f=1==l.level==n<0,h=a(r,f?1:-1);if(null!=h&&(f?h<=l.to&&h<=c.end:h>=l.from&&h>=c.begin)){var d=f?"before":"after";return new E(r.line,h,d)}}var p=function(e,t,n){for(var o=function(e,t){return t?new E(r.line,a(e,1),"before"):new E(r.line,e,"after")};e>=0&&e<i.length;e+=t){var l=i[e],s=t>0==(1!=l.level),u=s?n.begin:a(n.end,-1);if(l.from<=u&&u<l.to)return o(u,s);if(u=s?l.from:a(l.to,-1),n.begin<=u&&u<n.end)return o(u,s)}},g=p(o+n,n,c);if(g)return g;var v=n>0?c.end:a(c.begin,-1);return null==v||n>0&&v==t.text.length||!(g=p(n>0?0:i.length-1,n,u(v)))?null:g}function vo(e,t){var r=M(e.doc,t),n=fe(r);return n!=r&&(t=W(n)),po(!0,e,n,t,1)}function mo(e,t){var r=M(e.doc,t),n=he(r);return n!=r&&(t=W(n)),po(!0,e,r,t,-1)}function yo(e,t){var r=vo(e,t.line),n=M(e.doc,r.line),i=Se(n,e.doc.direction);if(!i||0==i[0].level){var o=Math.max(0,n.text.search(/\S/)),l=t.line==r.line&&t.ch<=o&&t.ch;return E(r.line,l?0:o,r.sticky)}return r}function bo(e,t,r){if("string"==typeof t&&!(t=Bs[t]))return!1;e.display.input.ensurePolled();var n=e.display.shift,i=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),r&&(e.display.shift=!1),i=t(e)!=Bl}finally{e.display.shift=n,e.state.suppressEdits=!1}return i}function wo(e,t,r){for(var n=0;n<e.state.keyMaps.length;n++){var i=oo(t,e.state.keyMaps[n],r,e);if(i)return i}return e.options.extraKeys&&oo(t,e.options.extraKeys,r,e)||oo(t,e.options.keyMap,r,e)}function xo(e,t,r,n){var i=e.state.keySeq;if(i){if(lo(t))return"handled";Gs.set(50,function(){e.state.keySeq==i&&(e.state.keySeq=null,e.display.input.reset())}),t=i+" "+t}var o=wo(e,t,n);return"multi"==o&&(e.state.keySeq=t),"handled"==o&&bt(e,"keyHandled",e,t,r),"handled"!=o&&"multi"!=o||(We(r),Ar(e)),i&&!o&&/\'$/.test(t)?(We(r),!0):!!o}function Co(e,t){var r=ao(t,!0);return!!r&&(t.shiftKey&&!e.state.keySeq?xo(e,"Shift-"+r,t,function(t){return bo(e,t,!0)})||xo(e,r,t,function(t){if("string"==typeof t?/^go[A-Z]/.test(t):t.motion)return bo(e,t)}):xo(e,r,t,function(t){return bo(e,t)}))}function So(e,t,r){return xo(e,"'"+r+"'",t,function(t){return bo(e,t,!0)})}function Lo(e){var t=this;if(t.curOp.focus=l(),!Me(t,e)){gl&&vl<11&&27==e.keyCode&&(e.returnValue=!1);var r=e.keyCode;t.display.shift=16==r||e.shiftKey;var n=Co(t,e);wl&&(Us=n?r:null,!n&&88==r&&!rs&&(Ml?e.metaKey:e.ctrlKey)&&t.replaceSelection("",null,"cut")),18!=r||/\bCodeMirror-crosshair\b/.test(t.display.lineDiv.className)||ko(t)}}function ko(e){function t(e){18!=e.keyCode&&e.altKey||(Fl(r,"CodeMirror-crosshair"),ke(document,"keyup",t),ke(document,"mouseover",t))}var r=e.display.lineDiv;s(r,"CodeMirror-crosshair"),Ql(document,"keyup",t),Ql(document,"mouseover",t)}function To(e){16==e.keyCode&&(this.doc.sel.shift=!1),Me(this,e)}function Mo(e){var t=this;if(!(Ft(t.display,e)||Me(t,e)||e.ctrlKey&&!e.altKey||Ml&&e.metaKey)){var r=e.keyCode,n=e.charCode;if(wl&&r==Us)return Us=null,void We(e);if(!wl||e.which&&!(e.which<10)||!Co(t,e)){var i=String.fromCharCode(null==n?r:n);"\b"!=i&&(So(t,e,i)||t.display.input.onKeyPress(e))}}}function No(e,t){var r=+new Date;return js&&js.compare(r,e,t)?(Ks=js=null,"triple"):Ks&&Ks.compare(r,e,t)?(js=new Vs(r,e,t),Ks=null,"double"):(Ks=new Vs(r,e,t),js=null,"single")}function Oo(e){var t=this,r=t.display;if(!(Me(t,e)||r.activeTouch&&r.input.supportsTouch()))if(r.input.ensurePolled(),r.shift=e.shiftKey,Ft(r,e))ml||(r.scroller.draggable=!1,setTimeout(function(){return r.scroller.draggable=!0},100));else if(!zo(t,e)){var n=Sr(t,e),i=Pe(e),o=n?No(n,i):"single";window.focus(),1==i&&t.state.selectingText&&t.state.selectingText(e),n&&Ao(t,i,n,o,e)||(1==i?n?Do(t,n,o,e):Ee(e)==r.scroller&&We(e):2==i?(n&&di(t.doc,n),setTimeout(function(){return r.input.focus()},20)):3==i&&(Hl?Ro(t,e):Dr(t)))}}function Ao(e,t,r,n,i){var o="Click";return"double"==n?o="Double"+o:"triple"==n&&(o="Triple"+o),o=(1==t?"Left":2==t?"Middle":"Right")+o,xo(e,so(o,i),i,function(t){if("string"==typeof t&&(t=Bs[t]),!t)return!1;var n=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),n=t(e,r)!=Bl}finally{e.state.suppressEdits=!1}return n})}function Wo(e,t,r){var n=e.getOption("configureMouse"),i=n?n(e,t,r):{};if(null==i.unit){var o=Nl?r.shiftKey&&r.metaKey:r.altKey;i.unit=o?"rectangle":"single"==t?"char":"double"==t?"word":"line"}return(null==i.extend||e.doc.extend)&&(i.extend=e.doc.extend||r.shiftKey),null==i.addNew&&(i.addNew=Ml?r.metaKey:r.ctrlKey),null==i.moveOnDrag&&(i.moveOnDrag=!(Ml?r.altKey:r.ctrlKey)),i}function Do(e,t,r,n){gl?setTimeout(u(Wr,e),0):e.curOp.focus=l();var i,o=Wo(e,r,n),s=e.doc.sel;e.options.dragDrop&&Jl&&!e.isReadOnly()&&"single"==r&&(i=s.contains(t))>-1&&(P((i=s.ranges[i]).from(),t)<0||t.xRel>0)&&(P(i.to(),t)>0||t.xRel<0)?Ho(e,n,t,o):Eo(e,n,t,o)}function Ho(e,t,r,n){var i=e.display,o=!1,l=dn(e,function(t){ml&&(i.scroller.draggable=!1),e.state.draggingText=!1,ke(document,"mouseup",l),ke(document,"mousemove",s),ke(i.scroller,"dragstart",a),ke(i.scroller,"drop",l),o||(We(t),n.addNew||di(e.doc,r,null,null,n.extend),ml||gl&&9==vl?setTimeout(function(){document.body.focus(),i.input.focus()},20):i.input.focus())}),s=function(e){o=o||Math.abs(t.clientX-e.clientX)+Math.abs(t.clientY-e.clientY)>=10},a=function(){return o=!0};ml&&(i.scroller.draggable=!0),e.state.draggingText=l,l.copy=!n.moveOnDrag,i.scroller.dragDrop&&i.scroller.dragDrop(),Ql(document,"mouseup",l),Ql(document,"mousemove",s),Ql(i.scroller,"dragstart",a),Ql(i.scroller,"drop",l),Dr(e),setTimeout(function(){return i.input.focus()},20)}function Fo(e,t,r){if("char"==r)return new Ts(t,t);if("word"==r)return e.findWordAt(t);if("line"==r)return new Ts(E(t.line,0),U(e.doc,E(t.line+1,0)));var n=r(e,t);return new Ts(n.from,n.to)}function Eo(e,t,r,n){function i(t){if(0!=P(m,t))if(m=t,"rectangle"==n.unit){for(var i=[],o=e.options.tabSize,l=f(M(u,r.line).text,r.ch,o),s=f(M(u,t.line).text,t.ch,o),a=Math.min(l,s),g=Math.max(l,s),v=Math.min(r.line,t.line),y=Math.min(e.lastLine(),Math.max(r.line,t.line));v<=y;v++){var b=M(u,v).text,w=d(b,a,o);a==g?i.push(new Ts(E(v,w),E(v,w))):b.length>w&&i.push(new Ts(E(v,w),E(v,d(b,g,o))))}i.length||i.push(new Ts(r,r)),bi(u,zn(p.ranges.slice(0,h).concat(i),h),{origin:"*mouse",scroll:!1}),e.scrollIntoView(t)}else{var x,C=c,S=Fo(e,t,n.unit),L=C.anchor;P(S.anchor,L)>0?(x=S.head,L=B(C.from(),S.anchor)):(x=S.anchor,L=R(C.to(),S.head));var k=p.ranges.slice(0);k[h]=Po(e,new Ts(U(u,L),x)),bi(u,zn(k,h),Ul)}}function o(t){var r=++b,s=Sr(e,t,!0,"rectangle"==n.unit);if(s)if(0!=P(s,m)){e.curOp.focus=l(),i(s);var c=Ir(a,u);(s.line>=c.to||s.line<c.from)&&setTimeout(dn(e,function(){b==r&&o(t)}),150)}else{var f=t.clientY<y.top?-20:t.clientY>y.bottom?20:0;f&&setTimeout(dn(e,function(){b==r&&(a.scroller.scrollTop+=f,o(t))}),50)}}function s(t){e.state.selectingText=!1,b=1/0,We(t),a.input.focus(),ke(document,"mousemove",w),ke(document,"mouseup",x),u.history.lastSelOrigin=null}var a=e.display,u=e.doc;We(t);var c,h,p=u.sel,g=p.ranges;if(n.addNew&&!n.extend?(h=u.sel.contains(r),c=h>-1?g[h]:new Ts(r,r)):(c=u.sel.primary(),h=u.sel.primIndex),"rectangle"==n.unit)n.addNew||(c=new Ts(r,r)),r=Sr(e,t,!0,!0),h=-1;else{var v=Fo(e,r,n.unit);c=n.extend?hi(c,v.anchor,v.head,n.extend):v}n.addNew?-1==h?(h=g.length,bi(u,zn(g.concat([c]),h),{scroll:!1,origin:"*mouse"})):g.length>1&&g[h].empty()&&"char"==n.unit&&!n.extend?(bi(u,zn(g.slice(0,h).concat(g.slice(h+1)),0),{scroll:!1,origin:"*mouse"}),p=u.sel):gi(u,h,c,Ul):(h=0,bi(u,new ks([c],0),Ul),p=u.sel);var m=r,y=a.wrapper.getBoundingClientRect(),b=0,w=dn(e,function(e){Pe(e)?o(e):s(e)}),x=dn(e,s);e.state.selectingText=x,Ql(document,"mousemove",w),Ql(document,"mouseup",x)}function Po(e,t){var r=t.anchor,n=t.head,i=M(e.doc,r.line);if(0==P(r,n)&&r.sticky==n.sticky)return t;var o=Se(i);if(!o)return t;var l=Ce(o,r.ch,r.sticky),s=o[l];if(s.from!=r.ch&&s.to!=r.ch)return t;var a=l+(s.from==r.ch==(1!=s.level)?0:1);if(0==a||a==o.length)return t;var u;if(n.line!=r.line)u=(n.line-r.line)*("ltr"==e.doc.direction?1:-1)>0;else{var c=Ce(o,n.ch,n.sticky),f=c-l||(n.ch-r.ch)*(1==s.level?-1:1);u=c==a-1||c==a?f<0:f>0}var h=o[a+(u?-1:0)],d=u==(1==h.level),p=d?h.from:h.to,g=d?"after":"before";return r.ch==p&&r.sticky==g?t:new Ts(new E(r.line,p,g),n)}function Io(e,t,r,n){var i,o;if(t.touches)i=t.touches[0].clientX,o=t.touches[0].clientY;else try{i=t.clientX,o=t.clientY}catch(t){return!1}if(i>=Math.floor(e.display.gutters.getBoundingClientRect().right))return!1;n&&We(t);var l=e.display,s=l.lineDiv.getBoundingClientRect();if(o>s.bottom||!Oe(e,r))return He(t);o-=s.top-l.viewOffset;for(var a=0;a<e.options.gutters.length;++a){var u=l.gutters.childNodes[a];if(u&&u.getBoundingClientRect().right>=i)return Te(e,r,e,D(e.doc,o),e.options.gutters[a],t),He(t)}}function zo(e,t){return Io(e,t,"gutterClick",!0)}function Ro(e,t){Ft(e.display,t)||Bo(e,t)||Me(e,t,"contextmenu")||e.display.input.onContextMenu(t)}function Bo(e,t){return!!Oe(e,"gutterContextMenu")&&Io(e,t,"gutterContextMenu",!1)}function Go(e){e.display.wrapper.className=e.display.wrapper.className.replace(/\s*cm-s-\S+/g,"")+e.options.theme.replace(/(^|\s)\s*/g," cm-s-"),er(e)}function Uo(e){Hn(e),vn(e),zr(e)}function Vo(e,t,r){if(!t!=!(r&&r!=Xs)){var n=e.display.dragFunctions,i=t?Ql:ke;i(e.display.scroller,"dragstart",n.start),i(e.display.scroller,"dragenter",n.enter),i(e.display.scroller,"dragover",n.over),i(e.display.scroller,"dragleave",n.leave),i(e.display.scroller,"drop",n.drop)}}function Ko(e){e.options.lineWrapping?(s(e.display.wrapper,"CodeMirror-wrap"),e.display.sizer.style.minWidth="",e.display.sizerWidth=null):(Fl(e.display.wrapper,"CodeMirror-wrap"),we(e)),Cr(e),vn(e),er(e),setTimeout(function(){return en(e)},100)}function jo(e,t){var r=this;if(!(this instanceof jo))return new jo(e,t);this.options=t=t?c(t):{},c(Ys,t,!1),Fn(t);var n=t.value;"string"==typeof n&&(n=new Ds(n,t.mode,null,t.lineSeparator,t.direction)),this.doc=n;var i=new jo.inputStyles[t.inputStyle](this),o=this.display=new T(e,n,i);o.wrapper.CodeMirror=this,Hn(this),Go(this),t.lineWrapping&&(this.display.wrapper.className+=" CodeMirror-wrap"),rn(this),this.state={keyMaps:[],overlays:[],modeGen:0,overwrite:!1,delayingBlurEvent:!1,focused:!1,suppressEdits:!1,pasteIncoming:!1,cutIncoming:!1,selectingText:!1,draggingText:!1,highlight:new Pl,keySeq:null,specialChars:null},t.autofocus&&!Tl&&o.input.focus(),gl&&vl<11&&setTimeout(function(){return r.display.input.reset(!0)},20),Xo(this),eo(),nn(this),this.curOp.forceUpdate=!0,qn(this,n),t.autofocus&&!Tl||this.hasFocus()?setTimeout(u(Hr,this),20):Fr(this);for(var l in _s)_s.hasOwnProperty(l)&&_s[l](r,t[l],Xs);Rr(this),t.finishInit&&t.finishInit(this);for(var s=0;s<$s.length;++s)$s[s](r);on(this),ml&&t.lineWrapping&&"optimizelegibility"==getComputedStyle(o.lineDiv).textRendering&&(o.lineDiv.style.textRendering="auto")}function Xo(e){function t(){i.activeTouch&&(o=setTimeout(function(){return i.activeTouch=null},1e3),(l=i.activeTouch).end=+new Date)}function r(e){if(1!=e.touches.length)return!1;var t=e.touches[0];return t.radiusX<=1&&t.radiusY<=1}function n(e,t){if(null==t.left)return!0;var r=t.left-e.left,n=t.top-e.top;return r*r+n*n>400}var i=e.display;Ql(i.scroller,"mousedown",dn(e,Oo)),gl&&vl<11?Ql(i.scroller,"dblclick",dn(e,function(t){if(!Me(e,t)){var r=Sr(e,t);if(r&&!zo(e,t)&&!Ft(e.display,t)){We(t);var n=e.findWordAt(r);di(e.doc,n.anchor,n.head)}}})):Ql(i.scroller,"dblclick",function(t){return Me(e,t)||We(t)}),Hl||Ql(i.scroller,"contextmenu",function(t){return Ro(e,t)});var o,l={end:0};Ql(i.scroller,"touchstart",function(t){if(!Me(e,t)&&!r(t)&&!zo(e,t)){i.input.ensurePolled(),clearTimeout(o);var n=+new Date;i.activeTouch={start:n,moved:!1,prev:n-l.end<=300?l:null},1==t.touches.length&&(i.activeTouch.left=t.touches[0].pageX,i.activeTouch.top=t.touches[0].pageY)}}),Ql(i.scroller,"touchmove",function(){i.activeTouch&&(i.activeTouch.moved=!0)}),Ql(i.scroller,"touchend",function(r){var o=i.activeTouch;if(o&&!Ft(i,r)&&null!=o.left&&!o.moved&&new Date-o.start<300){var l,s=e.coordsChar(i.activeTouch,"page");l=!o.prev||n(o,o.prev)?new Ts(s,s):!o.prev.prev||n(o,o.prev.prev)?e.findWordAt(s):new Ts(E(s.line,0),U(e.doc,E(s.line+1,0))),e.setSelection(l.anchor,l.head),e.focus(),We(r)}t()}),Ql(i.scroller,"touchcancel",t),Ql(i.scroller,"scroll",function(){i.scroller.clientHeight&&(qr(e,i.scroller.scrollTop),Qr(e,i.scroller.scrollLeft,!0),Te(e,"scroll",e))}),Ql(i.scroller,"mousewheel",function(t){return In(e,t)}),Ql(i.scroller,"DOMMouseScroll",function(t){return In(e,t)}),Ql(i.wrapper,"scroll",function(){return i.wrapper.scrollTop=i.wrapper.scrollLeft=0}),i.dragFunctions={enter:function(t){Me(e,t)||Fe(t)},over:function(t){Me(e,t)||(Zi(e,t),Fe(t))},start:function(t){return qi(e,t)},drop:dn(e,$i),leave:function(t){Me(e,t)||Qi(e)}};var s=i.input.getField();Ql(s,"keyup",function(t){return To.call(e,t)}),Ql(s,"keydown",dn(e,Lo)),Ql(s,"keypress",dn(e,Mo)),Ql(s,"focus",function(t){return Hr(e,t)}),Ql(s,"blur",function(t){return Fr(e,t)})}function Yo(e,t,r,n){var i,o=e.doc;null==r&&(r="add"),"smart"==r&&(o.mode.indent?i=$e(e,t).state:r="prev");var l=e.options.tabSize,s=M(o,t),a=f(s.text,null,l);s.stateAfter&&(s.stateAfter=null);var u,c=s.text.match(/^\s*/)[0];if(n||/\S/.test(s.text)){if("smart"==r&&((u=o.mode.indent(i,s.text.slice(c.length),s.text))==Bl||u>150)){if(!n)return;r="prev"}}else u=0,r="not";"prev"==r?u=t>o.first?f(M(o,t-1).text,null,l):0:"add"==r?u=a+e.options.indentUnit:"subtract"==r?u=a-e.options.indentUnit:"number"==typeof r&&(u=a+r),u=Math.max(0,u);var h="",d=0;if(e.options.indentWithTabs)for(var g=Math.floor(u/l);g;--g)d+=l,h+="\t";if(d<u&&(h+=p(u-d)),h!=c)return Ei(o,h,E(t,0),E(t,c.length),"+input"),s.stateAfter=null,!0;for(var v=0;v<o.sel.ranges.length;v++){var m=o.sel.ranges[v];if(m.head.line==t&&m.head.ch<c.length){var y=E(t,c.length);gi(o,v,new Ts(y,y));break}}}function _o(e){qs=e}function $o(e,t,r,n,i){var o=e.doc;e.display.shift=!1,n||(n=o.sel);var l=e.state.pasteIncoming||"paste"==i,s=es(t),a=null;if(l&&n.ranges.length>1)if(qs&&qs.text.join("\n")==t){if(n.ranges.length%qs.text.length==0){a=[];for(var u=0;u<qs.text.length;u++)a.push(o.splitLines(qs.text[u]))}}else s.length==n.ranges.length&&e.options.pasteLinesPerSelection&&(a=v(s,function(e){return[e]}));for(var c,f=n.ranges.length-1;f>=0;f--){var h=n.ranges[f],d=h.from(),p=h.to();h.empty()&&(r&&r>0?d=E(d.line,d.ch-r):e.state.overwrite&&!l?p=E(p.line,Math.min(M(o,p.line).text.length,p.ch+g(s).length)):qs&&qs.lineWise&&qs.text.join("\n")==t&&(d=p=E(d.line,0))),c=e.curOp.updateInput;var m={from:d,to:p,text:a?a[f%a.length]:s,origin:i||(l?"paste":e.state.cutIncoming?"cut":"+input")};Oi(e.doc,m),bt(e,"inputRead",e,m)}t&&!l&&Zo(e,t),jr(e),e.curOp.updateInput=c,e.curOp.typing=!0,e.state.pasteIncoming=e.state.cutIncoming=!1}function qo(e,t){var r=e.clipboardData&&e.clipboardData.getData("Text");if(r)return e.preventDefault(),t.isReadOnly()||t.options.disableInput||hn(t,function(){return $o(t,r,0,null,"paste")}),!0}function Zo(e,t){if(e.options.electricChars&&e.options.smartIndent)for(var r=e.doc.sel,n=r.ranges.length-1;n>=0;n--){var i=r.ranges[n];if(!(i.head.ch>100||n&&r.ranges[n-1].head.line==i.head.line)){var o=e.getModeAt(i.head),l=!1;if(o.electricChars){for(var s=0;s<o.electricChars.length;s++)if(t.indexOf(o.electricChars.charAt(s))>-1){l=Yo(e,i.head.line,"smart");break}}else o.electricInput&&o.electricInput.test(M(e.doc,i.head.line).text.slice(0,i.head.ch))&&(l=Yo(e,i.head.line,"smart"));l&&bt(e,"electricInput",e,i.head.line)}}}function Qo(e){for(var t=[],r=[],n=0;n<e.doc.sel.ranges.length;n++){var i=e.doc.sel.ranges[n].head.line,o={anchor:E(i,0),head:E(i+1,0)};r.push(o),t.push(e.getRange(o.anchor,o.head))}return{text:t,ranges:r}}function Jo(e,t){e.setAttribute("autocorrect","off"),e.setAttribute("autocapitalize","off"),e.setAttribute("spellcheck",!!t)}function el(){var e=n("textarea",null,null,"position: absolute; bottom: -1em; padding: 0; width: 1px; height: 1em; outline: none"),t=n("div",[e],null,"overflow: hidden; position: relative; width: 3px; height: 0px;");return ml?e.style.width="1000px":e.setAttribute("wrap","off"),Ll&&(e.style.border="1px solid black"),Jo(e),t}function tl(e,t,r,n,i){function o(){var n=t.line+r;return!(n<e.first||n>=e.first+e.size)&&(t=new E(n,t.ch,t.sticky),u=M(e,n))}function l(n){var l;if(null==(l=i?go(e.cm,u,t,r):ho(u,t,r))){if(n||!o())return!1;t=po(i,e.cm,u,t.line,r)}else t=l;return!0}var s=t,a=r,u=M(e,t.line);if("char"==n)l();else if("column"==n)l(!0);else if("word"==n||"group"==n)for(var c=null,f="group"==n,h=e.cm&&e.cm.getHelper(t,"wordChars"),d=!0;!(r<0)||l(!d);d=!1){var p=u.text.charAt(t.ch)||"\n",g=x(p,h)?"w":f&&"\n"==p?"n":!f||/\s/.test(p)?null:"p";if(!f||d||g||(g="s"),c&&c!=g){r<0&&(r=1,l(),t.sticky="after");break}if(g&&(c=g),r>0&&!l(!d))break}var v=ki(e,t,s,a,!0);return I(s,v)&&(v.hitSide=!0),v}function rl(e,t,r,n){var i,o=e.doc,l=t.left;if("page"==n){var s=Math.min(e.display.wrapper.clientHeight,window.innerHeight||document.documentElement.clientHeight),a=Math.max(s-.5*mr(e.display),3);i=(r>0?t.bottom:t.top)+r*a}else"line"==n&&(i=r>0?t.bottom+3:t.top-3);for(var u;(u=cr(e,l,i)).outside;){if(r<0?i<=0:i>=o.height){u.hitSide=!0;break}i+=5*r}return u}function nl(e,t){var r=jt(e,t.line);if(!r||r.hidden)return null;var n=M(e.doc,t.line),i=Ut(r,n,t.line),o=Se(n,e.doc.direction),l="left";o&&(l=Ce(o,t.ch)%2?"right":"left");var s=_t(i.map,t.ch,l);return s.offset="right"==s.collapse?s.end:s.start,s}function il(e){for(var t=e;t;t=t.parentNode)if(/CodeMirror-gutter-wrapper/.test(t.className))return!0;return!1}function ol(e,t){return t&&(e.bad=!0),e}function ll(e,t,r,n,i){function o(e){return function(t){return t.id==e}}function l(){c&&(u+=f,c=!1)}function s(e){e&&(l(),u+=e)}function a(t){if(1==t.nodeType){var r=t.getAttribute("cm-text");if(null!=r)return void s(r||t.textContent.replace(/\u200b/g,""));var u,h=t.getAttribute("cm-marker");if(h){var d=e.findMarks(E(n,0),E(i+1,0),o(+h));return void(d.length&&(u=d[0].find(0))&&s(N(e.doc,u.from,u.to).join(f)))}if("false"==t.getAttribute("contenteditable"))return;var p=/^(pre|div|p)$/i.test(t.nodeName);p&&l();for(var g=0;g<t.childNodes.length;g++)a(t.childNodes[g]);p&&(c=!0)}else 3==t.nodeType&&s(t.nodeValue)}for(var u="",c=!1,f=e.doc.lineSeparator();a(t),t!=r;)t=t.nextSibling;return u}function sl(e,t,r){var n;if(t==e.display.lineDiv){if(!(n=e.display.lineDiv.childNodes[r]))return ol(e.clipPos(E(e.display.viewTo-1)),!0);t=null,r=0}else for(n=t;;n=n.parentNode){if(!n||n==e.display.lineDiv)return null;if(n.parentNode&&n.parentNode==e.display.lineDiv)break}for(var i=0;i<e.display.view.length;i++){var o=e.display.view[i];if(o.node==n)return al(o,t,r)}}function al(e,t,r){function n(t,r,n){for(var i=-1;i<(f?f.length:0);i++)for(var o=i<0?c.map:f[i],l=0;l<o.length;l+=3){var s=o[l+2];if(s==t||s==r){var a=W(i<0?e.line:e.rest[i]),u=o[l]+n;return(n<0||s!=t)&&(u=o[l+(n?1:0)]),E(a,u)}}}var i=e.text.firstChild,l=!1;if(!t||!o(i,t))return ol(E(W(e.line),0),!0);if(t==i&&(l=!0,t=i.childNodes[r],r=0,!t)){var s=e.rest?g(e.rest):e.line;return ol(E(W(s),s.text.length),l)}var a=3==t.nodeType?t:null,u=t;for(a||1!=t.childNodes.length||3!=t.firstChild.nodeType||(a=t.firstChild,r&&(r=a.nodeValue.length));u.parentNode!=i;)u=u.parentNode;var c=e.measure,f=c.maps,h=n(a,u,r);if(h)return ol(h,l);for(var d=u.nextSibling,p=a?a.nodeValue.length-r:0;d;d=d.nextSibling){if(h=n(d,d.firstChild,0))return ol(E(h.line,h.ch-p),l);p+=d.textContent.length}for(var v=u.previousSibling,m=r;v;v=v.previousSibling){if(h=n(v,v.firstChild,-1))return ol(E(h.line,h.ch+m),l);m+=v.textContent.length}}var ul=navigator.userAgent,cl=navigator.platform,fl=/gecko\/\d/i.test(ul),hl=/MSIE \d/.test(ul),dl=/Trident\/(?:[7-9]|\d{2,})\..*rv:(\d+)/.exec(ul),pl=/Edge\/(\d+)/.exec(ul),gl=hl||dl||pl,vl=gl&&(hl?document.documentMode||6:+(pl||dl)[1]),ml=!pl&&/WebKit\//.test(ul),yl=ml&&/Qt\/\d+\.\d+/.test(ul),bl=!pl&&/Chrome\//.test(ul),wl=/Opera\//.test(ul),xl=/Apple Computer/.test(navigator.vendor),Cl=/Mac OS X 1\d\D([8-9]|\d\d)\D/.test(ul),Sl=/PhantomJS/.test(ul),Ll=!pl&&/AppleWebKit/.test(ul)&&/Mobile\/\w+/.test(ul),kl=/Android/.test(ul),Tl=Ll||kl||/webOS|BlackBerry|Opera Mini|Opera Mobi|IEMobile/i.test(ul),Ml=Ll||/Mac/.test(cl),Nl=/\bCrOS\b/.test(ul),Ol=/win/i.test(cl),Al=wl&&ul.match(/Version\/(\d*\.\d*)/);Al&&(Al=Number(Al[1])),Al&&Al>=15&&(wl=!1,ml=!0);var Wl,Dl=Ml&&(yl||wl&&(null==Al||Al<12.11)),Hl=fl||gl&&vl>=9,Fl=function(t,r){var n=t.className,i=e(r).exec(n);if(i){var o=n.slice(i.index+i[0].length);t.className=n.slice(0,i.index)+(o?i[1]+o:"")}};Wl=document.createRange?function(e,t,r,n){var i=document.createRange();return i.setEnd(n||e,r),i.setStart(e,t),i}:function(e,t,r){var n=document.body.createTextRange();try{n.moveToElementText(e.parentNode)}catch(e){return n}return n.collapse(!0),n.moveEnd("character",r),n.moveStart("character",t),n};var El=function(e){e.select()};Ll?El=function(e){e.selectionStart=0,e.selectionEnd=e.value.length}:gl&&(El=function(e){try{e.select()}catch(e){}});var Pl=function(){this.id=null};Pl.prototype.set=function(e,t){clearTimeout(this.id),this.id=setTimeout(t,e)};var Il,zl,Rl=30,Bl={toString:function(){return"CodeMirror.Pass"}},Gl={scroll:!1},Ul={origin:"*mouse"},Vl={origin:"+move"},Kl=[""],jl=/[\u00df\u0587\u0590-\u05f4\u0600-\u06ff\u3040-\u309f\u30a0-\u30ff\u3400-\u4db5\u4e00-\u9fcc\uac00-\ud7af]/,Xl=/[\u0300-\u036f\u0483-\u0489\u0591-\u05bd\u05bf\u05c1\u05c2\u05c4\u05c5\u05c7\u0610-\u061a\u064b-\u065e\u0670\u06d6-\u06dc\u06de-\u06e4\u06e7\u06e8\u06ea-\u06ed\u0711\u0730-\u074a\u07a6-\u07b0\u07eb-\u07f3\u0816-\u0819\u081b-\u0823\u0825-\u0827\u0829-\u082d\u0900-\u0902\u093c\u0941-\u0948\u094d\u0951-\u0955\u0962\u0963\u0981\u09bc\u09be\u09c1-\u09c4\u09cd\u09d7\u09e2\u09e3\u0a01\u0a02\u0a3c\u0a41\u0a42\u0a47\u0a48\u0a4b-\u0a4d\u0a51\u0a70\u0a71\u0a75\u0a81\u0a82\u0abc\u0ac1-\u0ac5\u0ac7\u0ac8\u0acd\u0ae2\u0ae3\u0b01\u0b3c\u0b3e\u0b3f\u0b41-\u0b44\u0b4d\u0b56\u0b57\u0b62\u0b63\u0b82\u0bbe\u0bc0\u0bcd\u0bd7\u0c3e-\u0c40\u0c46-\u0c48\u0c4a-\u0c4d\u0c55\u0c56\u0c62\u0c63\u0cbc\u0cbf\u0cc2\u0cc6\u0ccc\u0ccd\u0cd5\u0cd6\u0ce2\u0ce3\u0d3e\u0d41-\u0d44\u0d4d\u0d57\u0d62\u0d63\u0dca\u0dcf\u0dd2-\u0dd4\u0dd6\u0ddf\u0e31\u0e34-\u0e3a\u0e47-\u0e4e\u0eb1\u0eb4-\u0eb9\u0ebb\u0ebc\u0ec8-\u0ecd\u0f18\u0f19\u0f35\u0f37\u0f39\u0f71-\u0f7e\u0f80-\u0f84\u0f86\u0f87\u0f90-\u0f97\u0f99-\u0fbc\u0fc6\u102d-\u1030\u1032-\u1037\u1039\u103a\u103d\u103e\u1058\u1059\u105e-\u1060\u1071-\u1074\u1082\u1085\u1086\u108d\u109d\u135f\u1712-\u1714\u1732-\u1734\u1752\u1753\u1772\u1773\u17b7-\u17bd\u17c6\u17c9-\u17d3\u17dd\u180b-\u180d\u18a9\u1920-\u1922\u1927\u1928\u1932\u1939-\u193b\u1a17\u1a18\u1a56\u1a58-\u1a5e\u1a60\u1a62\u1a65-\u1a6c\u1a73-\u1a7c\u1a7f\u1b00-\u1b03\u1b34\u1b36-\u1b3a\u1b3c\u1b42\u1b6b-\u1b73\u1b80\u1b81\u1ba2-\u1ba5\u1ba8\u1ba9\u1c2c-\u1c33\u1c36\u1c37\u1cd0-\u1cd2\u1cd4-\u1ce0\u1ce2-\u1ce8\u1ced\u1dc0-\u1de6\u1dfd-\u1dff\u200c\u200d\u20d0-\u20f0\u2cef-\u2cf1\u2de0-\u2dff\u302a-\u302f\u3099\u309a\ua66f-\ua672\ua67c\ua67d\ua6f0\ua6f1\ua802\ua806\ua80b\ua825\ua826\ua8c4\ua8e0-\ua8f1\ua926-\ua92d\ua947-\ua951\ua980-\ua982\ua9b3\ua9b6-\ua9b9\ua9bc\uaa29-\uaa2e\uaa31\uaa32\uaa35\uaa36\uaa43\uaa4c\uaab0\uaab2-\uaab4\uaab7\uaab8\uaabe\uaabf\uaac1\uabe5\uabe8\uabed\udc00-\udfff\ufb1e\ufe00-\ufe0f\ufe20-\ufe26\uff9e\uff9f]/,Yl=!1,_l=!1,$l=null,ql=function(){function e(e){return e<=247?r.charAt(e):1424<=e&&e<=1524?"R":1536<=e&&e<=1785?n.charAt(e-1536):1774<=e&&e<=2220?"r":8192<=e&&e<=8203?"w":8204==e?"b":"L"}function t(e,t,r){this.level=e,this.from=t,this.to=r}var r="bbbbbbbbbtstwsbbbbbbbbbbbbbbssstwNN%%%NNNNNN,N,N1111111111NNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNbbbbbbsbbbbbbbbbbbbbbbbbbbbbbbbbb,N%%%%NNNNLNNNNN%%11NLNNN1LNNNNNLLLLLLLLLLLLLLLLLLLLLLLNLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLN",n="nnnnnnNNr%%r,rNNmmmmmmmmmmmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmmmmmmmmmmmmmmmnnnnnnnnnn%nnrrrmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmnNmmmmmmrrmmNmmmmrr1111111111",i=/[\u0590-\u05f4\u0600-\u06ff\u0700-\u08ac]/,o=/[stwN]/,l=/[LRr]/,s=/[Lb1n]/,a=/[1n]/;return function(r,n){var u="ltr"==n?"L":"R";if(0==r.length||"ltr"==n&&!i.test(r))return!1;for(var c=r.length,f=[],h=0;h<c;++h)f.push(e(r.charCodeAt(h)));for(var d=0,p=u;d<c;++d){var v=f[d];"m"==v?f[d]=p:p=v}for(var m=0,y=u;m<c;++m){var b=f[m];"1"==b&&"r"==y?f[m]="n":l.test(b)&&(y=b,"r"==b&&(f[m]="R"))}for(var w=1,x=f[0];w<c-1;++w){var C=f[w];"+"==C&&"1"==x&&"1"==f[w+1]?f[w]="1":","!=C||x!=f[w+1]||"1"!=x&&"n"!=x||(f[w]=x),x=C}for(var S=0;S<c;++S){var L=f[S];if(","==L)f[S]="N";else if("%"==L){var k=void 0;for(k=S+1;k<c&&"%"==f[k];++k);for(var T=S&&"!"==f[S-1]||k<c&&"1"==f[k]?"1":"N",M=S;M<k;++M)f[M]=T;S=k-1}}for(var N=0,O=u;N<c;++N){var A=f[N];"L"==O&&"1"==A?f[N]="L":l.test(A)&&(O=A)}for(var W=0;W<c;++W)if(o.test(f[W])){var D=void 0;for(D=W+1;D<c&&o.test(f[D]);++D);for(var H="L"==(W?f[W-1]:u),F=H==("L"==(D<c?f[D]:u))?H?"L":"R":u,E=W;E<D;++E)f[E]=F;W=D-1}for(var P,I=[],z=0;z<c;)if(s.test(f[z])){var R=z;for(++z;z<c&&s.test(f[z]);++z);I.push(new t(0,R,z))}else{var B=z,G=I.length;for(++z;z<c&&"L"!=f[z];++z);for(var U=B;U<z;)if(a.test(f[U])){B<U&&I.splice(G,0,new t(1,B,U));var V=U;for(++U;U<z&&a.test(f[U]);++U);I.splice(G,0,new t(2,V,U)),B=U}else++U;B<z&&I.splice(G,0,new t(1,B,z))}return 1==I[0].level&&(P=r.match(/^\s+/))&&(I[0].from=P[0].length,I.unshift(new t(0,0,P[0].length))),1==g(I).level&&(P=r.match(/\s+$/))&&(g(I).to-=P[0].length,I.push(new t(0,c-P[0].length,c))),"rtl"==n?I.reverse():I}}(),Zl=[],Ql=function(e,t,r){if(e.addEventListener)e.addEventListener(t,r,!1);else if(e.attachEvent)e.attachEvent("on"+t,r);else{var n=e._handlers||(e._handlers={});n[t]=(n[t]||Zl).concat(r)}},Jl=function(){if(gl&&vl<9)return!1;var e=n("div");return"draggable"in e||"dragDrop"in e}(),es=3!="\n\nb".split(/\n/).length?function(e){for(var t=0,r=[],n=e.length;t<=n;){var i=e.indexOf("\n",t);-1==i&&(i=e.length);var o=e.slice(t,"\r"==e.charAt(i-1)?i-1:i),l=o.indexOf("\r");-1!=l?(r.push(o.slice(0,l)),t+=l+1):(r.push(o),t=i+1)}return r}:function(e){return e.split(/\r\n?|\n/)},ts=window.getSelection?function(e){try{return e.selectionStart!=e.selectionEnd}catch(e){return!1}}:function(e){var t;try{t=e.ownerDocument.selection.createRange()}catch(e){}return!(!t||t.parentElement()!=e)&&0!=t.compareEndPoints("StartToEnd",t)},rs=function(){var e=n("div");return"oncopy"in e||(e.setAttribute("oncopy","return;"),"function"==typeof e.oncopy)}(),ns=null,is={},os={},ls={},ss=function(e,t,r){this.pos=this.start=0,this.string=e,this.tabSize=t||8,this.lastColumnPos=this.lastColumnValue=0,this.lineStart=0,this.lineOracle=r};ss.prototype.eol=function(){return this.pos>=this.string.length},ss.prototype.sol=function(){return this.pos==this.lineStart},ss.prototype.peek=function(){return this.string.charAt(this.pos)||void 0},ss.prototype.next=function(){if(this.pos<this.string.length)return this.string.charAt(this.pos++)},ss.prototype.eat=function(e){var t=this.string.charAt(this.pos);if("string"==typeof e?t==e:t&&(e.test?e.test(t):e(t)))return++this.pos,t},ss.prototype.eatWhile=function(e){for(var t=this.pos;this.eat(e););return this.pos>t},ss.prototype.eatSpace=function(){for(var e=this,t=this.pos;/[\s\u00a0]/.test(this.string.charAt(this.pos));)++e.pos;return this.pos>t},ss.prototype.skipToEnd=function(){this.pos=this.string.length},ss.prototype.skipTo=function(e){var t=this.string.indexOf(e,this.pos);if(t>-1)return this.pos=t,!0},ss.prototype.backUp=function(e){this.pos-=e},ss.prototype.column=function(){return this.lastColumnPos<this.start&&(this.lastColumnValue=f(this.string,this.start,this.tabSize,this.lastColumnPos,this.lastColumnValue),this.lastColumnPos=this.start),this.lastColumnValue-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.indentation=function(){return f(this.string,null,this.tabSize)-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.match=function(e,t,r){if("string"!=typeof e){var n=this.string.slice(this.pos).match(e);return n&&n.index>0?null:(n&&!1!==t&&(this.pos+=n[0].length),n)}var i=function(e){return r?e.toLowerCase():e};if(i(this.string.substr(this.pos,e.length))==i(e))return!1!==t&&(this.pos+=e.length),!0},ss.prototype.current=function(){return this.string.slice(this.start,this.pos)},ss.prototype.hideFirstChars=function(e,t){this.lineStart+=e;try{return t()}finally{this.lineStart-=e}},ss.prototype.lookAhead=function(e){var t=this.lineOracle;return t&&t.lookAhead(e)};var as=function(e,t){this.state=e,this.lookAhead=t},us=function(e,t,r,n){this.state=t,this.doc=e,this.line=r,this.maxLookAhead=n||0};us.prototype.lookAhead=function(e){var t=this.doc.getLine(this.line+e);return null!=t&&e>this.maxLookAhead&&(this.maxLookAhead=e),t},us.prototype.nextLine=function(){this.line++,this.maxLookAhead>0&&this.maxLookAhead--},us.fromSaved=function(e,t,r){return t instanceof as?new us(e,Ke(e.mode,t.state),r,t.lookAhead):new us(e,Ke(e.mode,t),r)},us.prototype.save=function(e){var t=!1!==e?Ke(this.doc.mode,this.state):this.state;return this.maxLookAhead>0?new as(t,this.maxLookAhead):t};var cs=function(e,t,r){this.start=e.start,this.end=e.pos,this.string=e.current(),this.type=t||null,this.state=r},fs=function(e,t,r){this.text=e,ne(this,t),this.height=r?r(this):1};fs.prototype.lineNo=function(){return W(this)},Ae(fs);var hs,ds={},ps={},gs=null,vs=null,ms={left:0,right:0,top:0,bottom:0},ys=function(e,t,r){this.cm=r;var i=this.vert=n("div",[n("div",null,null,"min-width: 1px")],"CodeMirror-vscrollbar"),o=this.horiz=n("div",[n("div",null,null,"height: 100%; min-height: 1px")],"CodeMirror-hscrollbar");e(i),e(o),Ql(i,"scroll",function(){i.clientHeight&&t(i.scrollTop,"vertical")}),Ql(o,"scroll",function(){o.clientWidth&&t(o.scrollLeft,"horizontal")}),this.checkedZeroWidth=!1,gl&&vl<8&&(this.horiz.style.minHeight=this.vert.style.minWidth="18px")};ys.prototype.update=function(e){var t=e.scrollWidth>e.clientWidth+1,r=e.scrollHeight>e.clientHeight+1,n=e.nativeBarWidth;if(r){this.vert.style.display="block",this.vert.style.bottom=t?n+"px":"0";var i=e.viewHeight-(t?n:0);this.vert.firstChild.style.height=Math.max(0,e.scrollHeight-e.clientHeight+i)+"px"}else this.vert.style.display="",this.vert.firstChild.style.height="0";if(t){this.horiz.style.display="block",this.horiz.style.right=r?n+"px":"0",this.horiz.style.left=e.barLeft+"px";var o=e.viewWidth-e.barLeft-(r?n:0);this.horiz.firstChild.style.width=Math.max(0,e.scrollWidth-e.clientWidth+o)+"px"}else this.horiz.style.display="",this.horiz.firstChild.style.width="0";return!this.checkedZeroWidth&&e.clientHeight>0&&(0==n&&this.zeroWidthHack(),this.checkedZeroWidth=!0),{right:r?n:0,bottom:t?n:0}},ys.prototype.setScrollLeft=function(e){this.horiz.scrollLeft!=e&&(this.horiz.scrollLeft=e),this.disableHoriz&&this.enableZeroWidthBar(this.horiz,this.disableHoriz,"horiz")},ys.prototype.setScrollTop=function(e){this.vert.scrollTop!=e&&(this.vert.scrollTop=e),this.disableVert&&this.enableZeroWidthBar(this.vert,this.disableVert,"vert")},ys.prototype.zeroWidthHack=function(){var e=Ml&&!Cl?"12px":"18px";this.horiz.style.height=this.vert.style.width=e,this.horiz.style.pointerEvents=this.vert.style.pointerEvents="none",this.disableHoriz=new Pl,this.disableVert=new Pl},ys.prototype.enableZeroWidthBar=function(e,t,r){function n(){var i=e.getBoundingClientRect();("vert"==r?document.elementFromPoint(i.right-1,(i.top+i.bottom)/2):document.elementFromPoint((i.right+i.left)/2,i.bottom-1))!=e?e.style.pointerEvents="none":t.set(1e3,n)}e.style.pointerEvents="auto",t.set(1e3,n)},ys.prototype.clear=function(){var e=this.horiz.parentNode;e.removeChild(this.horiz),e.removeChild(this.vert)};var bs=function(){};bs.prototype.update=function(){return{bottom:0,right:0}},bs.prototype.setScrollLeft=function(){},bs.prototype.setScrollTop=function(){},bs.prototype.clear=function(){};var ws={native:ys,null:bs},xs=0,Cs=function(e,t,r){var n=e.display;this.viewport=t,this.visible=Ir(n,e.doc,t),this.editorIsHidden=!n.wrapper.offsetWidth,this.wrapperHeight=n.wrapper.clientHeight,this.wrapperWidth=n.wrapper.clientWidth,this.oldDisplayWidth=Rt(e),this.force=r,this.dims=br(e),this.events=[]};Cs.prototype.signal=function(e,t){Oe(e,t)&&this.events.push(arguments)},Cs.prototype.finish=function(){for(var e=this,t=0;t<this.events.length;t++)Te.apply(null,e.events[t])};var Ss=0,Ls=null;gl?Ls=-.53:fl?Ls=15:bl?Ls=-.7:xl&&(Ls=-1/3);var ks=function(e,t){this.ranges=e,this.primIndex=t};ks.prototype.primary=function(){return this.ranges[this.primIndex]},ks.prototype.equals=function(e){var t=this;if(e==this)return!0;if(e.primIndex!=this.primIndex||e.ranges.length!=this.ranges.length)return!1;for(var r=0;r<this.ranges.length;r++){var n=t.ranges[r],i=e.ranges[r];if(!I(n.anchor,i.anchor)||!I(n.head,i.head))return!1}return!0},ks.prototype.deepCopy=function(){for(var e=this,t=[],r=0;r<this.ranges.length;r++)t[r]=new Ts(z(e.ranges[r].anchor),z(e.ranges[r].head));return new ks(t,this.primIndex)},ks.prototype.somethingSelected=function(){for(var e=this,t=0;t<this.ranges.length;t++)if(!e.ranges[t].empty())return!0;return!1},ks.prototype.contains=function(e,t){var r=this;t||(t=e);for(var n=0;n<this.ranges.length;n++){var i=r.ranges[n];if(P(t,i.from())>=0&&P(e,i.to())<=0)return n}return-1};var Ts=function(e,t){this.anchor=e,this.head=t};Ts.prototype.from=function(){return B(this.anchor,this.head)},Ts.prototype.to=function(){return R(this.anchor,this.head)},Ts.prototype.empty=function(){return this.head.line==this.anchor.line&&this.head.ch==this.anchor.ch},Bi.prototype={chunkSize:function(){return this.lines.length},removeInner:function(e,t){for(var r=this,n=e,i=e+t;n<i;++n){var o=r.lines[n];r.height-=o.height,ot(o),bt(o,"delete")}this.lines.splice(e,t)},collapse:function(e){e.push.apply(e,this.lines)},insertInner:function(e,t,r){var n=this;this.height+=r,this.lines=this.lines.slice(0,e).concat(t).concat(this.lines.slice(e));for(var i=0;i<t.length;++i)t[i].parent=n},iterN:function(e,t,r){for(var n=this,i=e+t;e<i;++e)if(r(n.lines[e]))return!0}},Gi.prototype={chunkSize:function(){return this.size},removeInner:function(e,t){var r=this;this.size-=t;for(var n=0;n<this.children.length;++n){var i=r.children[n],o=i.chunkSize();if(e<o){var l=Math.min(t,o-e),s=i.height;if(i.removeInner(e,l),r.height-=s-i.height,o==l&&(r.children.splice(n--,1),i.parent=null),0==(t-=l))break;e=0}else e-=o}if(this.size-t<25&&(this.children.length>1||!(this.children[0]instanceof Bi))){var a=[];this.collapse(a),this.children=[new Bi(a)],this.children[0].parent=this}},collapse:function(e){for(var t=this,r=0;r<this.children.length;++r)t.children[r].collapse(e)},insertInner:function(e,t,r){var n=this;this.size+=t.length,this.height+=r;for(var i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<=l){if(o.insertInner(e,t,r),o.lines&&o.lines.length>50){for(var s=o.lines.length%25+25,a=s;a<o.lines.length;){var u=new Bi(o.lines.slice(a,a+=25));o.height-=u.height,n.children.splice(++i,0,u),u.parent=n}o.lines=o.lines.slice(0,s),n.maybeSpill()}break}e-=l}},maybeSpill:function(){if(!(this.children.length<=10)){var e=this;do{var t=new Gi(e.children.splice(e.children.length-5,5));if(e.parent){e.size-=t.size,e.height-=t.height;var r=h(e.parent.children,e);e.parent.children.splice(r+1,0,t)}else{var n=new Gi(e.children);n.parent=e,e.children=[n,t],e=n}t.parent=e.parent}while(e.children.length>10);e.parent.maybeSpill()}},iterN:function(e,t,r){for(var n=this,i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<l){var s=Math.min(t,l-e);if(o.iterN(e,s,r))return!0;if(0==(t-=s))break;e=0}else e-=l}}};var Ms=function(e,t,r){var n=this;if(r)for(var i in r)r.hasOwnProperty(i)&&(n[i]=r[i]);this.doc=e,this.node=t};Ms.prototype.clear=function(){var e=this,t=this.doc.cm,r=this.line.widgets,n=this.line,i=W(n);if(null!=i&&r){for(var o=0;o<r.length;++o)r[o]==e&&r.splice(o--,1);r.length||(n.widgets=null);var l=Ht(this);A(n,Math.max(0,n.height-l)),t&&(hn(t,function(){Ui(t,n,-l),mn(t,i,"widget")}),bt(t,"lineWidgetCleared",t,this,i))}},Ms.prototype.changed=function(){var e=this,t=this.height,r=this.doc.cm,n=this.line;this.height=null;var i=Ht(this)-t;i&&(A(n,n.height+i),r&&hn(r,function(){r.curOp.forceUpdate=!0,Ui(r,n,i),bt(r,"lineWidgetChanged",r,e,W(n))}))},Ae(Ms);var Ns=0,Os=function(e,t){this.lines=[],this.type=t,this.doc=e,this.id=++Ns};Os.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){var t=this.doc.cm,r=t&&!t.curOp;if(r&&nn(t),Oe(this,"clear")){var n=this.find();n&&bt(this,"clear",n.from,n.to)}for(var i=null,o=null,l=0;l<this.lines.length;++l){var s=e.lines[l],a=_(s.markedSpans,e);t&&!e.collapsed?mn(t,W(s),"text"):t&&(null!=a.to&&(o=W(s)),null!=a.from&&(i=W(s))),s.markedSpans=$(s.markedSpans,a),null==a.from&&e.collapsed&&!ve(e.doc,s)&&t&&A(s,mr(t.display))}if(t&&this.collapsed&&!t.options.lineWrapping)for(var u=0;u<this.lines.length;++u){var c=fe(e.lines[u]),f=be(c);f>t.display.maxLineLength&&(t.display.maxLine=c,t.display.maxLineLength=f,t.display.maxLineChanged=!0)}null!=i&&t&&this.collapsed&&vn(t,i,o+1),this.lines.length=0,this.explicitlyCleared=!0,this.atomic&&this.doc.cantEdit&&(this.doc.cantEdit=!1,t&&Ci(t.doc)),t&&bt(t,"markerCleared",t,this,i,o),r&&on(t),this.parent&&this.parent.clear()}},Os.prototype.find=function(e,t){var r=this;null==e&&"bookmark"==this.type&&(e=1);for(var n,i,o=0;o<this.lines.length;++o){var l=r.lines[o],s=_(l.markedSpans,r);if(null!=s.from&&(n=E(t?l:W(l),s.from),-1==e))return n;if(null!=s.to&&(i=E(t?l:W(l),s.to),1==e))return i}return n&&{from:n,to:i}},Os.prototype.changed=function(){var e=this,t=this.find(-1,!0),r=this,n=this.doc.cm;t&&n&&hn(n,function(){var i=t.line,o=W(t.line),l=jt(n,o);if(l&&(Qt(l),n.curOp.selectionChanged=n.curOp.forceUpdate=!0),n.curOp.updateMaxLine=!0,!ve(r.doc,i)&&null!=r.height){var s=r.height;r.height=null;var a=Ht(r)-s;a&&A(i,i.height+a)}bt(n,"markerChanged",n,e)})},Os.prototype.attachLine=function(e){if(!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;t.maybeHiddenMarkers&&-1!=h(t.maybeHiddenMarkers,this)||(t.maybeUnhiddenMarkers||(t.maybeUnhiddenMarkers=[])).push(this)}this.lines.push(e)},Os.prototype.detachLine=function(e){if(this.lines.splice(h(this.lines,e),1),!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;(t.maybeHiddenMarkers||(t.maybeHiddenMarkers=[])).push(this)}},Ae(Os);var As=function(e,t){var r=this;this.markers=e,this.primary=t;for(var n=0;n<e.length;++n)e[n].parent=r};As.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){this.explicitlyCleared=!0;for(var t=0;t<this.markers.length;++t)e.markers[t].clear();bt(this,"clear")}},As.prototype.find=function(e,t){return this.primary.find(e,t)},Ae(As);var Ws=0,Ds=function(e,t,r,n,i){if(!(this instanceof Ds))return new Ds(e,t,r,n,i);null==r&&(r=0),Gi.call(this,[new Bi([new fs("",null)])]),this.first=r,this.scrollTop=this.scrollLeft=0,this.cantEdit=!1,this.cleanGeneration=1,this.modeFrontier=this.highlightFrontier=r;var o=E(r,0);this.sel=Rn(o),this.history=new Jn(null),this.id=++Ws,this.modeOption=t,this.lineSep=n,this.direction="rtl"==i?"rtl":"ltr",this.extend=!1,"string"==typeof e&&(e=this.splitLines(e)),_n(this,{from:o,to:o,text:e}),bi(this,Rn(o),Gl)};Ds.prototype=b(Gi.prototype,{constructor:Ds,iter:function(e,t,r){r?this.iterN(e-this.first,t-e,r):this.iterN(this.first,this.first+this.size,e)},insert:function(e,t){for(var r=0,n=0;n<t.length;++n)r+=t[n].height;this.insertInner(e-this.first,t,r)},remove:function(e,t){this.removeInner(e-this.first,t)},getValue:function(e){var t=O(this,this.first,this.first+this.size);return!1===e?t:t.join(e||this.lineSeparator())},setValue:gn(function(e){var t=E(this.first,0),r=this.first+this.size-1;Oi(this,{from:t,to:E(r,M(this,r).text.length),text:this.splitLines(e),origin:"setValue",full:!0},!0),this.cm&&Xr(this.cm,0,0),bi(this,Rn(t),Gl)}),replaceRange:function(e,t,r,n){Ei(this,e,t=U(this,t),r=r?U(this,r):t,n)},getRange:function(e,t,r){var n=N(this,U(this,e),U(this,t));return!1===r?n:n.join(r||this.lineSeparator())},getLine:function(e){var t=this.getLineHandle(e);return t&&t.text},getLineHandle:function(e){if(H(this,e))return M(this,e)},getLineNumber:function(e){return W(e)},getLineHandleVisualStart:function(e){return"number"==typeof e&&(e=M(this,e)),fe(e)},lineCount:function(){return this.size},firstLine:function(){return this.first},lastLine:function(){return this.first+this.size-1},clipPos:function(e){return U(this,e)},getCursor:function(e){var t=this.sel.primary();return null==e||"head"==e?t.head:"anchor"==e?t.anchor:"end"==e||"to"==e||!1===e?t.to():t.from()},listSelections:function(){return this.sel.ranges},somethingSelected:function(){return this.sel.somethingSelected()},setCursor:gn(function(e,t,r){vi(this,U(this,"number"==typeof e?E(e,t||0):e),null,r)}),setSelection:gn(function(e,t,r){vi(this,U(this,e),U(this,t||e),r)}),extendSelection:gn(function(e,t,r){di(this,U(this,e),t&&U(this,t),r)}),extendSelections:gn(function(e,t){pi(this,K(this,e),t)}),extendSelectionsBy:gn(function(e,t){pi(this,K(this,v(this.sel.ranges,e)),t)}),setSelections:gn(function(e,t,r){var n=this;if(e.length){for(var i=[],o=0;o<e.length;o++)i[o]=new Ts(U(n,e[o].anchor),U(n,e[o].head));null==t&&(t=Math.min(e.length-1,this.sel.primIndex)),bi(this,zn(i,t),r)}}),addSelection:gn(function(e,t,r){var n=this.sel.ranges.slice(0);n.push(new Ts(U(this,e),U(this,t||e))),bi(this,zn(n,n.length-1),r)}),getSelection:function(e){for(var t,r=this,n=this.sel.ranges,i=0;i<n.length;i++){var o=N(r,n[i].from(),n[i].to());t=t?t.concat(o):o}return!1===e?t:t.join(e||this.lineSeparator())},getSelections:function(e){for(var t=this,r=[],n=this.sel.ranges,i=0;i<n.length;i++){var o=N(t,n[i].from(),n[i].to());!1!==e&&(o=o.join(e||t.lineSeparator())),r[i]=o}return r},replaceSelection:function(e,t,r){for(var n=[],i=0;i<this.sel.ranges.length;i++)n[i]=e;this.replaceSelections(n,t,r||"+input")},replaceSelections:gn(function(e,t,r){for(var n=this,i=[],o=this.sel,l=0;l<o.ranges.length;l++){var s=o.ranges[l];i[l]={from:s.from(),to:s.to(),text:n.splitLines(e[l]),origin:r}}for(var a=t&&"end"!=t&&Kn(this,i,t),u=i.length-1;u>=0;u--)Oi(n,i[u]);a?yi(this,a):this.cm&&jr(this.cm)}),undo:gn(function(){Wi(this,"undo")}),redo:gn(function(){Wi(this,"redo")}),undoSelection:gn(function(){Wi(this,"undo",!0)}),redoSelection:gn(function(){Wi(this,"redo",!0)}),setExtending:function(e){this.extend=e},getExtending:function(){return this.extend},historySize:function(){for(var e=this.history,t=0,r=0,n=0;n<e.done.length;n++)e.done[n].ranges||++t;for(var i=0;i<e.undone.length;i++)e.undone[i].ranges||++r;return{undo:t,redo:r}},clearHistory:function(){this.history=new Jn(this.history.maxGeneration)},markClean:function(){this.cleanGeneration=this.changeGeneration(!0)},changeGeneration:function(e){return e&&(this.history.lastOp=this.history.lastSelOp=this.history.lastOrigin=null),this.history.generation},isClean:function(e){return this.history.generation==(e||this.cleanGeneration)},getHistory:function(){return{done:fi(this.history.done),undone:fi(this.history.undone)}},setHistory:function(e){var t=this.history=new Jn(this.history.maxGeneration);t.done=fi(e.done.slice(0),null,!0),t.undone=fi(e.undone.slice(0),null,!0)},setGutterMarker:gn(function(e,t,r){return Ri(this,e,"gutter",function(e){var n=e.gutterMarkers||(e.gutterMarkers={});return n[t]=r,!r&&C(n)&&(e.gutterMarkers=null),!0})}),clearGutter:gn(function(e){var t=this;this.iter(function(r){r.gutterMarkers&&r.gutterMarkers[e]&&Ri(t,r,"gutter",function(){return r.gutterMarkers[e]=null,C(r.gutterMarkers)&&(r.gutterMarkers=null),!0})})}),lineInfo:function(e){var t;if("number"==typeof e){if(!H(this,e))return null;if(t=e,!(e=M(this,e)))return null}else if(null==(t=W(e)))return null;return{line:t,handle:e,text:e.text,gutterMarkers:e.gutterMarkers,textClass:e.textClass,bgClass:e.bgClass,wrapClass:e.wrapClass,widgets:e.widgets}},addLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass";if(t[i]){if(e(n).test(t[i]))return!1;t[i]+=" "+n}else t[i]=n;return!0})}),removeLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass",o=t[i];if(!o)return!1;if(null==n)t[i]=null;else{var l=o.match(e(n));if(!l)return!1;var s=l.index+l[0].length;t[i]=o.slice(0,l.index)+(l.index&&s!=o.length?" ":"")+o.slice(s)||null}return!0})}),addLineWidget:gn(function(e,t,r){return Vi(this,e,t,r)}),removeLineWidget:function(e){e.clear()},markText:function(e,t,r){return Ki(this,U(this,e),U(this,t),r,r&&r.type||"range")},setBookmark:function(e,t){var r={replacedWith:t&&(null==t.nodeType?t.widget:t),insertLeft:t&&t.insertLeft,clearWhenEmpty:!1,shared:t&&t.shared,handleMouseEvents:t&&t.handleMouseEvents};return e=U(this,e),Ki(this,e,e,r,"bookmark")},findMarksAt:function(e){var t=[],r=M(this,(e=U(this,e)).line).markedSpans;if(r)for(var n=0;n<r.length;++n){var i=r[n];(null==i.from||i.from<=e.ch)&&(null==i.to||i.to>=e.ch)&&t.push(i.marker.parent||i.marker)}return t},findMarks:function(e,t,r){e=U(this,e),t=U(this,t);var n=[],i=e.line;return this.iter(e.line,t.line+1,function(o){var l=o.markedSpans;if(l)for(var s=0;s<l.length;s++){var a=l[s];null!=a.to&&i==e.line&&e.ch>=a.to||null==a.from&&i!=e.line||null!=a.from&&i==t.line&&a.from>=t.ch||r&&!r(a.marker)||n.push(a.marker.parent||a.marker)}++i}),n},getAllMarks:function(){var e=[];return this.iter(function(t){var r=t.markedSpans;if(r)for(var n=0;n<r.length;++n)null!=r[n].from&&e.push(r[n].marker)}),e},posFromIndex:function(e){var t,r=this.first,n=this.lineSeparator().length;return this.iter(function(i){var o=i.text.length+n;if(o>e)return t=e,!0;e-=o,++r}),U(this,E(r,t))},indexFromPos:function(e){var t=(e=U(this,e)).ch;if(e.line<this.first||e.ch<0)return 0;var r=this.lineSeparator().length;return this.iter(this.first,e.line,function(e){t+=e.text.length+r}),t},copy:function(e){var t=new Ds(O(this,this.first,this.first+this.size),this.modeOption,this.first,this.lineSep,this.direction);return t.scrollTop=this.scrollTop,t.scrollLeft=this.scrollLeft,t.sel=this.sel,t.extend=!1,e&&(t.history.undoDepth=this.history.undoDepth,t.setHistory(this.getHistory())),t},linkedDoc:function(e){e||(e={});var t=this.first,r=this.first+this.size;null!=e.from&&e.from>t&&(t=e.from),null!=e.to&&e.to<r&&(r=e.to);var n=new Ds(O(this,t,r),e.mode||this.modeOption,t,this.lineSep,this.direction);return e.sharedHist&&(n.history=this.history),(this.linked||(this.linked=[])).push({doc:n,sharedHist:e.sharedHist}),n.linked=[{doc:this,isParent:!0,sharedHist:e.sharedHist}],Yi(n,Xi(this)),n},unlinkDoc:function(e){var t=this;if(e instanceof jo&&(e=e.doc),this.linked)for(var r=0;r<this.linked.length;++r)if(t.linked[r].doc==e){t.linked.splice(r,1),e.unlinkDoc(t),_i(Xi(t));break}if(e.history==this.history){var n=[e.id];$n(e,function(e){return n.push(e.id)},!0),e.history=new Jn(null),e.history.done=fi(this.history.done,n),e.history.undone=fi(this.history.undone,n)}},iterLinkedDocs:function(e){$n(this,e)},getMode:function(){return this.mode},getEditor:function(){return this.cm},splitLines:function(e){return this.lineSep?e.split(this.lineSep):es(e)},lineSeparator:function(){return this.lineSep||"\n"},setDirection:gn(function(e){"rtl"!=e&&(e="ltr"),e!=this.direction&&(this.direction=e,this.iter(function(e){return e.order=null}),this.cm&&Qn(this.cm))})}),Ds.prototype.eachLine=Ds.prototype.iter;for(var Hs=0,Fs=!1,Es={3:"Enter",8:"Backspace",9:"Tab",13:"Enter",16:"Shift",17:"Ctrl",18:"Alt",19:"Pause",20:"CapsLock",27:"Esc",32:"Space",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"Left",38:"Up",39:"Right",40:"Down",44:"PrintScrn",45:"Insert",46:"Delete",59:";",61:"=",91:"Mod",92:"Mod",93:"Mod",106:"*",107:"=",109:"-",110:".",111:"/",127:"Delete",173:"-",186:";",187:"=",188:",",189:"-",190:".",191:"/",192:"`",219:"[",220:"\\",221:"]",222:"'",63232:"Up",63233:"Down",63234:"Left",63235:"Right",63272:"Delete",63273:"Home",63275:"End",63276:"PageUp",63277:"PageDown",63302:"Insert"},Ps=0;Ps<10;Ps++)Es[Ps+48]=Es[Ps+96]=String(Ps);for(var Is=65;Is<=90;Is++)Es[Is]=String.fromCharCode(Is);for(var zs=1;zs<=12;zs++)Es[zs+111]=Es[zs+63235]="F"+zs;var Rs={};Rs.basic={Left:"goCharLeft",Right:"goCharRight",Up:"goLineUp",Down:"goLineDown",End:"goLineEnd",Home:"goLineStartSmart",PageUp:"goPageUp",PageDown:"goPageDown",Delete:"delCharAfter",Backspace:"delCharBefore","Shift-Backspace":"delCharBefore",Tab:"defaultTab","Shift-Tab":"indentAuto",Enter:"newlineAndIndent",Insert:"toggleOverwrite",Esc:"singleSelection"},Rs.pcDefault={"Ctrl-A":"selectAll","Ctrl-D":"deleteLine","Ctrl-Z":"undo","Shift-Ctrl-Z":"redo","Ctrl-Y":"redo","Ctrl-Home":"goDocStart","Ctrl-End":"goDocEnd","Ctrl-Up":"goLineUp","Ctrl-Down":"goLineDown","Ctrl-Left":"goGroupLeft","Ctrl-Right":"goGroupRight","Alt-Left":"goLineStart","Alt-Right":"goLineEnd","Ctrl-Backspace":"delGroupBefore","Ctrl-Delete":"delGroupAfter","Ctrl-S":"save","Ctrl-F":"find","Ctrl-G":"findNext","Shift-Ctrl-G":"findPrev","Shift-Ctrl-F":"replace","Shift-Ctrl-R":"replaceAll","Ctrl-[":"indentLess","Ctrl-]":"indentMore","Ctrl-U":"undoSelection","Shift-Ctrl-U":"redoSelection","Alt-U":"redoSelection",fallthrough:"basic"},Rs.emacsy={"Ctrl-F":"goCharRight","Ctrl-B":"goCharLeft","Ctrl-P":"goLineUp","Ctrl-N":"goLineDown","Alt-F":"goWordRight","Alt-B":"goWordLeft","Ctrl-A":"goLineStart","Ctrl-E":"goLineEnd","Ctrl-V":"goPageDown","Shift-Ctrl-V":"goPageUp","Ctrl-D":"delCharAfter","Ctrl-H":"delCharBefore","Alt-D":"delWordAfter","Alt-Backspace":"delWordBefore","Ctrl-K":"killLine","Ctrl-T":"transposeChars","Ctrl-O":"openLine"},Rs.macDefault={"Cmd-A":"selectAll","Cmd-D":"deleteLine","Cmd-Z":"undo","Shift-Cmd-Z":"redo","Cmd-Y":"redo","Cmd-Home":"goDocStart","Cmd-Up":"goDocStart","Cmd-End":"goDocEnd","Cmd-Down":"goDocEnd","Alt-Left":"goGroupLeft","Alt-Right":"goGroupRight","Cmd-Left":"goLineLeft","Cmd-Right":"goLineRight","Alt-Backspace":"delGroupBefore","Ctrl-Alt-Backspace":"delGroupAfter","Alt-Delete":"delGroupAfter","Cmd-S":"save","Cmd-F":"find","Cmd-G":"findNext","Shift-Cmd-G":"findPrev","Cmd-Alt-F":"replace","Shift-Cmd-Alt-F":"replaceAll","Cmd-[":"indentLess","Cmd-]":"indentMore","Cmd-Backspace":"delWrappedLineLeft","Cmd-Delete":"delWrappedLineRight","Cmd-U":"undoSelection","Shift-Cmd-U":"redoSelection","Ctrl-Up":"goDocStart","Ctrl-Down":"goDocEnd",fallthrough:["basic","emacsy"]},Rs.default=Ml?Rs.macDefault:Rs.pcDefault;var Bs={selectAll:Mi,singleSelection:function(e){return e.setSelection(e.getCursor("anchor"),e.getCursor("head"),Gl)},killLine:function(e){return co(e,function(t){if(t.empty()){var r=M(e.doc,t.head.line).text.length;return t.head.ch==r&&t.head.line<e.lastLine()?{from:t.head,to:E(t.head.line+1,0)}:{from:t.head,to:E(t.head.line,r)}}return{from:t.from(),to:t.to()}})},deleteLine:function(e){return co(e,function(t){return{from:E(t.from().line,0),to:U(e.doc,E(t.to().line+1,0))}})},delLineLeft:function(e){return co(e,function(e){return{from:E(e.from().line,0),to:e.from()}})},delWrappedLineLeft:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5;return{from:e.coordsChar({left:0,top:r},"div"),to:t.from()}})},delWrappedLineRight:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5,n=e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div");return{from:t.from(),to:n}})},undo:function(e){return e.undo()},redo:function(e){return e.redo()},undoSelection:function(e){return e.undoSelection()},redoSelection:function(e){return e.redoSelection()},goDocStart:function(e){return e.extendSelection(E(e.firstLine(),0))},goDocEnd:function(e){return e.extendSelection(E(e.lastLine()))},goLineStart:function(e){return e.extendSelectionsBy(function(t){return vo(e,t.head.line)},{origin:"+move",bias:1})},goLineStartSmart:function(e){return e.extendSelectionsBy(function(t){return yo(e,t.head)},{origin:"+move",bias:1})},goLineEnd:function(e){return e.extendSelectionsBy(function(t){return mo(e,t.head.line)},{origin:"+move",bias:-1})},goLineRight:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div")},Vl)},goLineLeft:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:0,top:r},"div")},Vl)},goLineLeftSmart:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5,n=e.coordsChar({left:0,top:r},"div");return n.ch<e.getLine(n.line).search(/\S/)?yo(e,t.head):n},Vl)},goLineUp:function(e){return e.moveV(-1,"line")},goLineDown:function(e){return e.moveV(1,"line")},goPageUp:function(e){return e.moveV(-1,"page")},goPageDown:function(e){return e.moveV(1,"page")},goCharLeft:function(e){return e.moveH(-1,"char")},goCharRight:function(e){return e.moveH(1,"char")},goColumnLeft:function(e){return e.moveH(-1,"column")},goColumnRight:function(e){return e.moveH(1,"column")},goWordLeft:function(e){return e.moveH(-1,"word")},goGroupRight:function(e){return e.moveH(1,"group")},goGroupLeft:function(e){return e.moveH(-1,"group")},goWordRight:function(e){return e.moveH(1,"word")},delCharBefore:function(e){return e.deleteH(-1,"char")},delCharAfter:function(e){return e.deleteH(1,"char")},delWordBefore:function(e){return e.deleteH(-1,"word")},delWordAfter:function(e){return e.deleteH(1,"word")},delGroupBefore:function(e){return e.deleteH(-1,"group")},delGroupAfter:function(e){return e.deleteH(1,"group")},indentAuto:function(e){return e.indentSelection("smart")},indentMore:function(e){return e.indentSelection("add")},indentLess:function(e){return e.indentSelection("subtract")},insertTab:function(e){return e.replaceSelection("\t")},insertSoftTab:function(e){for(var t=[],r=e.listSelections(),n=e.options.tabSize,i=0;i<r.length;i++){var o=r[i].from(),l=f(e.getLine(o.line),o.ch,n);t.push(p(n-l%n))}e.replaceSelections(t)},defaultTab:function(e){e.somethingSelected()?e.indentSelection("add"):e.execCommand("insertTab")},transposeChars:function(e){return hn(e,function(){for(var t=e.listSelections(),r=[],n=0;n<t.length;n++)if(t[n].empty()){var i=t[n].head,o=M(e.doc,i.line).text;if(o)if(i.ch==o.length&&(i=new E(i.line,i.ch-1)),i.ch>0)i=new E(i.line,i.ch+1),e.replaceRange(o.charAt(i.ch-1)+o.charAt(i.ch-2),E(i.line,i.ch-2),i,"+transpose");else if(i.line>e.doc.first){var l=M(e.doc,i.line-1).text;l&&(i=new E(i.line,1),e.replaceRange(o.charAt(0)+e.doc.lineSeparator()+l.charAt(l.length-1),E(i.line-1,l.length-1),i,"+transpose"))}r.push(new Ts(i,i))}e.setSelections(r)})},newlineAndIndent:function(e){return hn(e,function(){for(var t=e.listSelections(),r=t.length-1;r>=0;r--)e.replaceRange(e.doc.lineSeparator(),t[r].anchor,t[r].head,"+input");t=e.listSelections();for(var n=0;n<t.length;n++)e.indentLine(t[n].from().line,null,!0);jr(e)})},openLine:function(e){return e.replaceSelection("\n","start")},toggleOverwrite:function(e){return e.toggleOverwrite()}},Gs=new Pl,Us=null,Vs=function(e,t,r){this.time=e,this.pos=t,this.button=r};Vs.prototype.compare=function(e,t,r){return this.time+400>e&&0==P(t,this.pos)&&r==this.button};var Ks,js,Xs={toString:function(){return"CodeMirror.Init"}},Ys={},_s={};jo.defaults=Ys,jo.optionHandlers=_s;var $s=[];jo.defineInitHook=function(e){return $s.push(e)};var qs=null,Zs=function(e){this.cm=e,this.lastAnchorNode=this.lastAnchorOffset=this.lastFocusNode=this.lastFocusOffset=null,this.polling=new Pl,this.composing=null,this.gracePeriod=!1,this.readDOMTimeout=null};Zs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()}),"cut"==e.type&&i.replaceSelection("",null,"cut");else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type&&i.operation(function(){i.setSelections(t.ranges,0,Gl),i.replaceSelection("",null,"cut")})}if(e.clipboardData){e.clipboardData.clearData();var r=qs.text.join("\n");if(e.clipboardData.setData("Text",r),e.clipboardData.getData("Text")==r)return void e.preventDefault()}var l=el(),s=l.firstChild;i.display.lineSpace.insertBefore(l,i.display.lineSpace.firstChild),s.value=qs.text.join("\n");var a=document.activeElement;El(s),setTimeout(function(){i.display.lineSpace.removeChild(l),a.focus(),a==o&&n.showPrimarySelection()},50)}}var r=this,n=this,i=n.cm,o=n.div=e.lineDiv;Jo(o,i.options.spellcheck),Ql(o,"paste",function(e){Me(i,e)||qo(e,i)||vl<=11&&setTimeout(dn(i,function(){return r.updateFromDOM()}),20)}),Ql(o,"compositionstart",function(e){r.composing={data:e.data,done:!1}}),Ql(o,"compositionupdate",function(e){r.composing||(r.composing={data:e.data,done:!1})}),Ql(o,"compositionend",function(e){r.composing&&(e.data!=r.composing.data&&r.readFromDOMSoon(),r.composing.done=!0)}),Ql(o,"touchstart",function(){return n.forceCompositionEnd()}),Ql(o,"input",function(){r.composing||r.readFromDOMSoon()}),Ql(o,"copy",t),Ql(o,"cut",t)},Zs.prototype.prepareSelection=function(){var e=Tr(this.cm,!1);return e.focus=this.cm.state.focused,e},Zs.prototype.showSelection=function(e,t){e&&this.cm.display.view.length&&((e.focus||t)&&this.showPrimarySelection(),this.showMultipleSelections(e))},Zs.prototype.showPrimarySelection=function(){var e=window.getSelection(),t=this.cm,r=t.doc.sel.primary(),n=r.from(),i=r.to();if(t.display.viewTo==t.display.viewFrom||n.line>=t.display.viewTo||i.line<t.display.viewFrom)e.removeAllRanges();else{var o=sl(t,e.anchorNode,e.anchorOffset),l=sl(t,e.focusNode,e.focusOffset);if(!o||o.bad||!l||l.bad||0!=P(B(o,l),n)||0!=P(R(o,l),i)){var s=t.display.view,a=n.line>=t.display.viewFrom&&nl(t,n)||{node:s[0].measure.map[2],offset:0},u=i.line<t.display.viewTo&&nl(t,i);if(!u){var c=s[s.length-1].measure,f=c.maps?c.maps[c.maps.length-1]:c.map;u={node:f[f.length-1],offset:f[f.length-2]-f[f.length-3]}}if(a&&u){var h,d=e.rangeCount&&e.getRangeAt(0);try{h=Wl(a.node,a.offset,u.offset,u.node)}catch(e){}h&&(!fl&&t.state.focused?(e.collapse(a.node,a.offset),h.collapsed||(e.removeAllRanges(),e.addRange(h))):(e.removeAllRanges(),e.addRange(h)),d&&null==e.anchorNode?e.addRange(d):fl&&this.startGracePeriod()),this.rememberSelection()}else e.removeAllRanges()}}},Zs.prototype.startGracePeriod=function(){var e=this;clearTimeout(this.gracePeriod),this.gracePeriod=setTimeout(function(){e.gracePeriod=!1,e.selectionChanged()&&e.cm.operation(function(){return e.cm.curOp.selectionChanged=!0})},20)},Zs.prototype.showMultipleSelections=function(e){r(this.cm.display.cursorDiv,e.cursors),r(this.cm.display.selectionDiv,e.selection)},Zs.prototype.rememberSelection=function(){var e=window.getSelection();this.lastAnchorNode=e.anchorNode,this.lastAnchorOffset=e.anchorOffset,this.lastFocusNode=e.focusNode,this.lastFocusOffset=e.focusOffset},Zs.prototype.selectionInEditor=function(){var e=window.getSelection();if(!e.rangeCount)return!1;var t=e.getRangeAt(0).commonAncestorContainer;return o(this.div,t)},Zs.prototype.focus=function(){"nocursor"!=this.cm.options.readOnly&&(this.selectionInEditor()||this.showSelection(this.prepareSelection(),!0),this.div.focus())},Zs.prototype.blur=function(){this.div.blur()},Zs.prototype.getField=function(){return this.div},Zs.prototype.supportsTouch=function(){return!0},Zs.prototype.receivedFocus=function(){function e(){t.cm.state.focused&&(t.pollSelection(),t.polling.set(t.cm.options.pollInterval,e))}var t=this;this.selectionInEditor()?this.pollSelection():hn(this.cm,function(){return t.cm.curOp.selectionChanged=!0}),this.polling.set(this.cm.options.pollInterval,e)},Zs.prototype.selectionChanged=function(){var e=window.getSelection();return e.anchorNode!=this.lastAnchorNode||e.anchorOffset!=this.lastAnchorOffset||e.focusNode!=this.lastFocusNode||e.focusOffset!=this.lastFocusOffset},Zs.prototype.pollSelection=function(){if(null==this.readDOMTimeout&&!this.gracePeriod&&this.selectionChanged()){var e=window.getSelection(),t=this.cm;if(kl&&bl&&this.cm.options.gutters.length&&il(e.anchorNode))return this.cm.triggerOnKeyDown({type:"keydown",keyCode:8,preventDefault:Math.abs}),this.blur(),void this.focus();if(!this.composing){this.rememberSelection();var r=sl(t,e.anchorNode,e.anchorOffset),n=sl(t,e.focusNode,e.focusOffset);r&&n&&hn(t,function(){bi(t.doc,Rn(r,n),Gl),(r.bad||n.bad)&&(t.curOp.selectionChanged=!0)})}}},Zs.prototype.pollContent=function(){null!=this.readDOMTimeout&&(clearTimeout(this.readDOMTimeout),this.readDOMTimeout=null);var e=this.cm,t=e.display,r=e.doc.sel.primary(),n=r.from(),i=r.to();if(0==n.ch&&n.line>e.firstLine()&&(n=E(n.line-1,M(e.doc,n.line-1).length)),i.ch==M(e.doc,i.line).text.length&&i.line<e.lastLine()&&(i=E(i.line+1,0)),n.line<t.viewFrom||i.line>t.viewTo-1)return!1;var o,l,s;n.line==t.viewFrom||0==(o=Lr(e,n.line))?(l=W(t.view[0].line),s=t.view[0].node):(l=W(t.view[o].line),s=t.view[o-1].node.nextSibling);var a,u,c=Lr(e,i.line);if(c==t.view.length-1?(a=t.viewTo-1,u=t.lineDiv.lastChild):(a=W(t.view[c+1].line)-1,u=t.view[c+1].node.previousSibling),!s)return!1;for(var f=e.doc.splitLines(ll(e,s,u,l,a)),h=N(e.doc,E(l,0),E(a,M(e.doc,a).text.length));f.length>1&&h.length>1;)if(g(f)==g(h))f.pop(),h.pop(),a--;else{if(f[0]!=h[0])break;f.shift(),h.shift(),l++}for(var d=0,p=0,v=f[0],m=h[0],y=Math.min(v.length,m.length);d<y&&v.charCodeAt(d)==m.charCodeAt(d);)++d;for(var b=g(f),w=g(h),x=Math.min(b.length-(1==f.length?d:0),w.length-(1==h.length?d:0));p<x&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)++p;if(1==f.length&&1==h.length&&l==n.line)for(;d&&d>n.ch&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)d--,p++;f[f.length-1]=b.slice(0,b.length-p).replace(/^\u200b+/,""),f[0]=f[0].slice(d).replace(/\u200b+$/,"");var C=E(l,d),S=E(a,h.length?g(h).length-p:0);return f.length>1||f[0]||P(C,S)?(Ei(e.doc,f,C,S,"+input"),!0):void 0},Zs.prototype.ensurePolled=function(){this.forceCompositionEnd()},Zs.prototype.reset=function(){this.forceCompositionEnd()},Zs.prototype.forceCompositionEnd=function(){this.composing&&(clearTimeout(this.readDOMTimeout),this.composing=null,this.updateFromDOM(),this.div.blur(),this.div.focus())},Zs.prototype.readFromDOMSoon=function(){var e=this;null==this.readDOMTimeout&&(this.readDOMTimeout=setTimeout(function(){if(e.readDOMTimeout=null,e.composing){if(!e.composing.done)return;e.composing=null}e.updateFromDOM()},80))},Zs.prototype.updateFromDOM=function(){var e=this;!this.cm.isReadOnly()&&this.pollContent()||hn(this.cm,function(){return vn(e.cm)})},Zs.prototype.setUneditable=function(e){e.contentEditable="false"},Zs.prototype.onKeyPress=function(e){0!=e.charCode&&(e.preventDefault(),this.cm.isReadOnly()||dn(this.cm,$o)(this.cm,String.fromCharCode(null==e.charCode?e.keyCode:e.charCode),0))},Zs.prototype.readOnlyChanged=function(e){this.div.contentEditable=String("nocursor"!=e)},Zs.prototype.onContextMenu=function(){},Zs.prototype.resetPosition=function(){},Zs.prototype.needsContentAttribute=!0;var Qs=function(e){this.cm=e,this.prevInput="",this.pollingFast=!1,this.polling=new Pl,this.hasSelection=!1,this.composing=null};Qs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()});else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type?i.setSelections(t.ranges,null,Gl):(n.prevInput="",l.value=t.text.join("\n"),El(l))}"cut"==e.type&&(i.state.cutIncoming=!0)}}var r=this,n=this,i=this.cm,o=this.wrapper=el(),l=this.textarea=o.firstChild;e.wrapper.insertBefore(o,e.wrapper.firstChild),Ll&&(l.style.width="0px"),Ql(l,"input",function(){gl&&vl>=9&&r.hasSelection&&(r.hasSelection=null),n.poll()}),Ql(l,"paste",function(e){Me(i,e)||qo(e,i)||(i.state.pasteIncoming=!0,n.fastPoll())}),Ql(l,"cut",t),Ql(l,"copy",t),Ql(e.scroller,"paste",function(t){Ft(e,t)||Me(i,t)||(i.state.pasteIncoming=!0,n.focus())}),Ql(e.lineSpace,"selectstart",function(t){Ft(e,t)||We(t)}),Ql(l,"compositionstart",function(){var e=i.getCursor("from");n.composing&&n.composing.range.clear(),n.composing={start:e,range:i.markText(e,i.getCursor("to"),{className:"CodeMirror-composing"})}}),Ql(l,"compositionend",function(){n.composing&&(n.poll(),n.composing.range.clear(),n.composing=null)})},Qs.prototype.prepareSelection=function(){var e=this.cm,t=e.display,r=e.doc,n=Tr(e);if(e.options.moveInputWithCursor){var i=sr(e,r.sel.primary().head,"div"),o=t.wrapper.getBoundingClientRect(),l=t.lineDiv.getBoundingClientRect();n.teTop=Math.max(0,Math.min(t.wrapper.clientHeight-10,i.top+l.top-o.top)),n.teLeft=Math.max(0,Math.min(t.wrapper.clientWidth-10,i.left+l.left-o.left))}return n},Qs.prototype.showSelection=function(e){var t=this.cm.display;r(t.cursorDiv,e.cursors),r(t.selectionDiv,e.selection),null!=e.teTop&&(this.wrapper.style.top=e.teTop+"px",this.wrapper.style.left=e.teLeft+"px")},Qs.prototype.reset=function(e){if(!this.contextMenuPending&&!this.composing){var t=this.cm;if(t.somethingSelected()){this.prevInput="";var r=t.getSelection();this.textarea.value=r,t.state.focused&&El(this.textarea),gl&&vl>=9&&(this.hasSelection=r)}else e||(this.prevInput=this.textarea.value="",gl&&vl>=9&&(this.hasSelection=null))}},Qs.prototype.getField=function(){return this.textarea},Qs.prototype.supportsTouch=function(){return!1},Qs.prototype.focus=function(){if("nocursor"!=this.cm.options.readOnly&&(!Tl||l()!=this.textarea))try{this.textarea.focus()}catch(e){}},Qs.prototype.blur=function(){this.textarea.blur()},Qs.prototype.resetPosition=function(){this.wrapper.style.top=this.wrapper.style.left=0},Qs.prototype.receivedFocus=function(){this.slowPoll()},Qs.prototype.slowPoll=function(){var e=this;this.pollingFast||this.polling.set(this.cm.options.pollInterval,function(){e.poll(),e.cm.state.focused&&e.slowPoll()})},Qs.prototype.fastPoll=function(){function e(){r.poll()||t?(r.pollingFast=!1,r.slowPoll()):(t=!0,r.polling.set(60,e))}var t=!1,r=this;r.pollingFast=!0,r.polling.set(20,e)},Qs.prototype.poll=function(){var e=this,t=this.cm,r=this.textarea,n=this.prevInput;if(this.contextMenuPending||!t.state.focused||ts(r)&&!n&&!this.composing||t.isReadOnly()||t.options.disableInput||t.state.keySeq)return!1;var i=r.value;if(i==n&&!t.somethingSelected())return!1;if(gl&&vl>=9&&this.hasSelection===i||Ml&&/[\uf700-\uf7ff]/.test(i))return t.display.input.reset(),!1;if(t.doc.sel==t.display.selForContextMenu){var o=i.charCodeAt(0);if(8203!=o||n||(n="​"),8666==o)return this.reset(),this.cm.execCommand("undo")}for(var l=0,s=Math.min(n.length,i.length);l<s&&n.charCodeAt(l)==i.charCodeAt(l);)++l;return hn(t,function(){$o(t,i.slice(l),n.length-l,null,e.composing?"*compose":null),i.length>1e3||i.indexOf("\n")>-1?r.value=e.prevInput="":e.prevInput=i,e.composing&&(e.composing.range.clear(),e.composing.range=t.markText(e.composing.start,t.getCursor("to"),{className:"CodeMirror-composing"}))}),!0},Qs.prototype.ensurePolled=function(){this.pollingFast&&this.poll()&&(this.pollingFast=!1)},Qs.prototype.onKeyPress=function(){gl&&vl>=9&&(this.hasSelection=null),this.fastPoll()},Qs.prototype.onContextMenu=function(e){function t(){if(null!=l.selectionStart){var e=i.somethingSelected(),t="​"+(e?l.value:"");l.value="⇚",l.value=t,n.prevInput=e?"":"​",l.selectionStart=1,l.selectionEnd=t.length,o.selForContextMenu=i.doc.sel}}function r(){if(n.contextMenuPending=!1,n.wrapper.style.cssText=c,l.style.cssText=u,gl&&vl<9&&o.scrollbars.setScrollTop(o.scroller.scrollTop=a),null!=l.selectionStart){(!gl||gl&&vl<9)&&t();var e=0,r=function(){o.selForContextMenu==i.doc.sel&&0==l.selectionStart&&l.selectionEnd>0&&"​"==n.prevInput?dn(i,Mi)(i):e++<10?o.detectingSelectAll=setTimeout(r,500):(o.selForContextMenu=null,o.input.reset())};o.detectingSelectAll=setTimeout(r,200)}}var n=this,i=n.cm,o=i.display,l=n.textarea,s=Sr(i,e),a=o.scroller.scrollTop;if(s&&!wl){i.options.resetSelectionOnContextMenu&&-1==i.doc.sel.contains(s)&&dn(i,bi)(i.doc,Rn(s),Gl);var u=l.style.cssText,c=n.wrapper.style.cssText;n.wrapper.style.cssText="position: absolute";var f=n.wrapper.getBoundingClientRect();l.style.cssText="position: absolute; width: 30px; height: 30px;\n      top: "+(e.clientY-f.top-5)+"px; left: "+(e.clientX-f.left-5)+"px;\n      z-index: 1000; background: "+(gl?"rgba(255, 255, 255, .05)":"transparent")+";\n      outline: none; border-width: 0; outline: none; overflow: hidden; opacity: .05; filter: alpha(opacity=5);";var h;if(ml&&(h=window.scrollY),o.input.focus(),ml&&window.scrollTo(null,h),o.input.reset(),i.somethingSelected()||(l.value=n.prevInput=" "),n.contextMenuPending=!0,o.selForContextMenu=i.doc.sel,clearTimeout(o.detectingSelectAll),gl&&vl>=9&&t(),Hl){Fe(e);var d=function(){ke(window,"mouseup",d),setTimeout(r,20)};Ql(window,"mouseup",d)}else setTimeout(r,50)}},Qs.prototype.readOnlyChanged=function(e){e||this.reset(),this.textarea.disabled="nocursor"==e},Qs.prototype.setUneditable=function(){},Qs.prototype.needsContentAttribute=!1,function(e){function t(t,n,i,o){e.defaults[t]=n,i&&(r[t]=o?function(e,t,r){r!=Xs&&i(e,t,r)}:i)}var r=e.optionHandlers;e.defineOption=t,e.Init=Xs,t("value","",function(e,t){return e.setValue(t)},!0),t("mode",null,function(e,t){e.doc.modeOption=t,jn(e)},!0),t("indentUnit",2,jn,!0),t("indentWithTabs",!1),t("smartIndent",!0),t("tabSize",4,function(e){Xn(e),er(e),vn(e)},!0),t("lineSeparator",null,function(e,t){if(e.doc.lineSep=t,t){var r=[],n=e.doc.first;e.doc.iter(function(e){for(var i=0;;){var o=e.text.indexOf(t,i);if(-1==o)break;i=o+t.length,r.push(E(n,o))}n++});for(var i=r.length-1;i>=0;i--)Ei(e.doc,t,r[i],E(r[i].line,r[i].ch+t.length))}}),t("specialChars",/[\u0000-\u001f\u007f-\u009f\u00ad\u061c\u200b-\u200f\u2028\u2029\ufeff]/g,function(e,t,r){e.state.specialChars=new RegExp(t.source+(t.test("\t")?"":"|\t"),"g"),r!=Xs&&e.refresh()}),t("specialCharPlaceholder",at,function(e){return e.refresh()},!0),t("electricChars",!0),t("inputStyle",Tl?"contenteditable":"textarea",function(){throw new Error("inputStyle can not (yet) be changed in a running editor")},!0),t("spellcheck",!1,function(e,t){return e.getInputField().spellcheck=t},!0),t("rtlMoveVisually",!Ol),t("wholeLineUpdateBefore",!0),t("theme","default",function(e){Go(e),Uo(e)},!0),t("keyMap","default",function(e,t,r){var n=uo(t),i=r!=Xs&&uo(r);i&&i.detach&&i.detach(e,n),n.attach&&n.attach(e,i||null)}),t("extraKeys",null),t("configureMouse",null),t("lineWrapping",!1,Ko,!0),t("gutters",[],function(e){Fn(e.options),Uo(e)},!0),t("fixedGutter",!0,function(e,t){e.display.gutters.style.left=t?wr(e.display)+"px":"0",e.refresh()},!0),t("coverGutterNextToScrollbar",!1,function(e){return en(e)},!0),t("scrollbarStyle","native",function(e){rn(e),en(e),e.display.scrollbars.setScrollTop(e.doc.scrollTop),e.display.scrollbars.setScrollLeft(e.doc.scrollLeft)},!0),t("lineNumbers",!1,function(e){Fn(e.options),Uo(e)},!0),t("firstLineNumber",1,Uo,!0),t("lineNumberFormatter",function(e){return e},Uo,!0),t("showCursorWhenSelecting",!1,kr,!0),t("resetSelectionOnContextMenu",!0),t("lineWiseCopyCut",!0),t("pasteLinesPerSelection",!0),t("readOnly",!1,function(e,t){"nocursor"==t&&(Fr(e),e.display.input.blur()),e.display.input.readOnlyChanged(t)}),t("disableInput",!1,function(e,t){t||e.display.input.reset()},!0),t("dragDrop",!0,Vo),t("allowDropFileTypes",null),t("cursorBlinkRate",530),t("cursorScrollMargin",0),t("cursorHeight",1,kr,!0),t("singleCursorHeightPerLine",!0,kr,!0),t("workTime",100),t("workDelay",100),t("flattenSpans",!0,Xn,!0),t("addModeClass",!1,Xn,!0),t("pollInterval",100),t("undoDepth",200,function(e,t){return e.doc.history.undoDepth=t}),t("historyEventDelay",1250),t("viewportMargin",10,function(e){return e.refresh()},!0),t("maxHighlightLength",1e4,Xn,!0),t("moveInputWithCursor",!0,function(e,t){t||e.display.input.resetPosition()}),t("tabindex",null,function(e,t){return e.display.input.getField().tabIndex=t||""}),t("autofocus",null),t("direction","ltr",function(e,t){return e.doc.setDirection(t)},!0)}(jo),function(e){var t=e.optionHandlers,r=e.helpers={};e.prototype={constructor:e,focus:function(){window.focus(),this.display.input.focus()},setOption:function(e,r){var n=this.options,i=n[e];n[e]==r&&"mode"!=e||(n[e]=r,t.hasOwnProperty(e)&&dn(this,t[e])(this,r,i),Te(this,"optionChange",this,e))},getOption:function(e){return this.options[e]},getDoc:function(){return this.doc},addKeyMap:function(e,t){this.state.keyMaps[t?"push":"unshift"](uo(e))},removeKeyMap:function(e){for(var t=this.state.keyMaps,r=0;r<t.length;++r)if(t[r]==e||t[r].name==e)return t.splice(r,1),!0},addOverlay:pn(function(t,r){var n=t.token?t:e.getMode(this.options,t);if(n.startState)throw new Error("Overlays may not be stateful.");m(this.state.overlays,{mode:n,modeSpec:t,opaque:r&&r.opaque,priority:r&&r.priority||0},function(e){return e.priority}),this.state.modeGen++,vn(this)}),removeOverlay:pn(function(e){for(var t=this,r=this.state.overlays,n=0;n<r.length;++n){var i=r[n].modeSpec;if(i==e||"string"==typeof e&&i.name==e)return r.splice(n,1),t.state.modeGen++,void vn(t)}}),indentLine:pn(function(e,t,r){"string"!=typeof t&&"number"!=typeof t&&(t=null==t?this.options.smartIndent?"smart":"prev":t?"add":"subtract"),H(this.doc,e)&&Yo(this,e,t,r)}),indentSelection:pn(function(e){for(var t=this,r=this.doc.sel.ranges,n=-1,i=0;i<r.length;i++){var o=r[i];if(o.empty())o.head.line>n&&(Yo(t,o.head.line,e,!0),n=o.head.line,i==t.doc.sel.primIndex&&jr(t));else{var l=o.from(),s=o.to(),a=Math.max(n,l.line);n=Math.min(t.lastLine(),s.line-(s.ch?0:1))+1;for(var u=a;u<n;++u)Yo(t,u,e);var c=t.doc.sel.ranges;0==l.ch&&r.length==c.length&&c[i].from().ch>0&&gi(t.doc,i,new Ts(l,c[i].to()),Gl)}}}),getTokenAt:function(e,t){return Je(this,e,t)},getLineTokens:function(e,t){return Je(this,E(e),t,!0)},getTokenTypeAt:function(e){e=U(this.doc,e);var t,r=_e(this,M(this.doc,e.line)),n=0,i=(r.length-1)/2,o=e.ch;if(0==o)t=r[2];else for(;;){var l=n+i>>1;if((l?r[2*l-1]:0)>=o)i=l;else{if(!(r[2*l+1]<o)){t=r[2*l+2];break}n=l+1}}var s=t?t.indexOf("overlay "):-1;return s<0?t:0==s?null:t.slice(0,s-1)},getModeAt:function(t){var r=this.doc.mode;return r.innerMode?e.innerMode(r,this.getTokenAt(t).state).mode:r},getHelper:function(e,t){return this.getHelpers(e,t)[0]},getHelpers:function(e,t){var n=this,i=[];if(!r.hasOwnProperty(t))return i;var o=r[t],l=this.getModeAt(e);if("string"==typeof l[t])o[l[t]]&&i.push(o[l[t]]);else if(l[t])for(var s=0;s<l[t].length;s++){var a=o[l[t][s]];a&&i.push(a)}else l.helperType&&o[l.helperType]?i.push(o[l.helperType]):o[l.name]&&i.push(o[l.name]);for(var u=0;u<o._global.length;u++){var c=o._global[u];c.pred(l,n)&&-1==h(i,c.val)&&i.push(c.val)}return i},getStateAfter:function(e,t){var r=this.doc;return e=G(r,null==e?r.first+r.size-1:e),$e(this,e+1,t).state},cursorCoords:function(e,t){var r,n=this.doc.sel.primary();return r=null==e?n.head:"object"==typeof e?U(this.doc,e):e?n.from():n.to(),sr(this,r,t||"page")},charCoords:function(e,t){return lr(this,U(this.doc,e),t||"page")},coordsChar:function(e,t){return e=or(this,e,t||"page"),cr(this,e.left,e.top)},lineAtHeight:function(e,t){return e=or(this,{top:e,left:0},t||"page").top,D(this.doc,e+this.display.viewOffset)},heightAtLine:function(e,t,r){var n,i=!1;if("number"==typeof e){var o=this.doc.first+this.doc.size-1;e<this.doc.first?e=this.doc.first:e>o&&(e=o,i=!0),n=M(this.doc,e)}else n=e;return ir(this,n,{top:0,left:0},t||"page",r||i).top+(i?this.doc.height-ye(n):0)},defaultTextHeight:function(){return mr(this.display)},defaultCharWidth:function(){return yr(this.display)},getViewport:function(){return{from:this.display.viewFrom,to:this.display.viewTo}},addWidget:function(e,t,r,n,i){var o=this.display,l=(e=sr(this,U(this.doc,e))).bottom,s=e.left;if(t.style.position="absolute",t.setAttribute("cm-ignore-events","true"),this.display.input.setUneditable(t),o.sizer.appendChild(t),"over"==n)l=e.top;else if("above"==n||"near"==n){var a=Math.max(o.wrapper.clientHeight,this.doc.height),u=Math.max(o.sizer.clientWidth,o.lineSpace.clientWidth);("above"==n||e.bottom+t.offsetHeight>a)&&e.top>t.offsetHeight?l=e.top-t.offsetHeight:e.bottom+t.offsetHeight<=a&&(l=e.bottom),s+t.offsetWidth>u&&(s=u-t.offsetWidth)}t.style.top=l+"px",t.style.left=t.style.right="","right"==i?(s=o.sizer.clientWidth-t.offsetWidth,t.style.right="0px"):("left"==i?s=0:"middle"==i&&(s=(o.sizer.clientWidth-t.offsetWidth)/2),t.style.left=s+"px"),r&&Ur(this,{left:s,top:l,right:s+t.offsetWidth,bottom:l+t.offsetHeight})},triggerOnKeyDown:pn(Lo),triggerOnKeyPress:pn(Mo),triggerOnKeyUp:To,triggerOnMouseDown:pn(Oo),execCommand:function(e){if(Bs.hasOwnProperty(e))return Bs[e].call(null,this)},triggerElectric:pn(function(e){Zo(this,e)}),findPosH:function(e,t,r,n){var i=this,o=1;t<0&&(o=-1,t=-t);for(var l=U(this.doc,e),s=0;s<t&&!(l=tl(i.doc,l,o,r,n)).hitSide;++s);return l},moveH:pn(function(e,t){var r=this;this.extendSelectionsBy(function(n){return r.display.shift||r.doc.extend||n.empty()?tl(r.doc,n.head,e,t,r.options.rtlMoveVisually):e<0?n.from():n.to()},Vl)}),deleteH:pn(function(e,t){var r=this.doc.sel,n=this.doc;r.somethingSelected()?n.replaceSelection("",null,"+delete"):co(this,function(r){var i=tl(n,r.head,e,t,!1);return e<0?{from:i,to:r.head}:{from:r.head,to:i}})}),findPosV:function(e,t,r,n){var i=this,o=1,l=n;t<0&&(o=-1,t=-t);for(var s=U(this.doc,e),a=0;a<t;++a){var u=sr(i,s,"div");if(null==l?l=u.left:u.left=l,(s=rl(i,u,o,r)).hitSide)break}return s},moveV:pn(function(e,t){var r=this,n=this.doc,i=[],o=!this.display.shift&&!n.extend&&n.sel.somethingSelected();if(n.extendSelectionsBy(function(l){if(o)return e<0?l.from():l.to();var s=sr(r,l.head,"div");null!=l.goalColumn&&(s.left=l.goalColumn),i.push(s.left);var a=rl(r,s,e,t);return"page"==t&&l==n.sel.primary()&&Kr(r,lr(r,a,"div").top-s.top),a},Vl),i.length)for(var l=0;l<n.sel.ranges.length;l++)n.sel.ranges[l].goalColumn=i[l]}),findWordAt:function(e){var t=M(this.doc,e.line).text,r=e.ch,n=e.ch;if(t){var i=this.getHelper(e,"wordChars");"before"!=e.sticky&&n!=t.length||!r?++n:--r;for(var o=t.charAt(r),l=x(o,i)?function(e){return x(e,i)}:/\s/.test(o)?function(e){return/\s/.test(e)}:function(e){return!/\s/.test(e)&&!x(e)};r>0&&l(t.charAt(r-1));)--r;for(;n<t.length&&l(t.charAt(n));)++n}return new Ts(E(e.line,r),E(e.line,n))},toggleOverwrite:function(e){null!=e&&e==this.state.overwrite||((this.state.overwrite=!this.state.overwrite)?s(this.display.cursorDiv,"CodeMirror-overwrite"):Fl(this.display.cursorDiv,"CodeMirror-overwrite"),Te(this,"overwriteToggle",this,this.state.overwrite))},hasFocus:function(){return this.display.input.getField()==l()},isReadOnly:function(){return!(!this.options.readOnly&&!this.doc.cantEdit)},scrollTo:pn(function(e,t){Xr(this,e,t)}),getScrollInfo:function(){var e=this.display.scroller;return{left:e.scrollLeft,top:e.scrollTop,height:e.scrollHeight-zt(this)-this.display.barHeight,width:e.scrollWidth-zt(this)-this.display.barWidth,clientHeight:Bt(this),clientWidth:Rt(this)}},scrollIntoView:pn(function(e,t){null==e?(e={from:this.doc.sel.primary().head,to:null},null==t&&(t=this.options.cursorScrollMargin)):"number"==typeof e?e={from:E(e,0),to:null}:null==e.from&&(e={from:e,to:null}),e.to||(e.to=e.from),e.margin=t||0,null!=e.from.line?Yr(this,e):$r(this,e.from,e.to,e.margin)}),setSize:pn(function(e,t){var r=this,n=function(e){return"number"==typeof e||/^\d+$/.test(String(e))?e+"px":e};null!=e&&(this.display.wrapper.style.width=n(e)),null!=t&&(this.display.wrapper.style.height=n(t)),this.options.lineWrapping&&Jt(this);var i=this.display.viewFrom;this.doc.iter(i,this.display.viewTo,function(e){if(e.widgets)for(var t=0;t<e.widgets.length;t++)if(e.widgets[t].noHScroll){mn(r,i,"widget");break}++i}),this.curOp.forceUpdate=!0,Te(this,"refresh",this)}),operation:function(e){return hn(this,e)},startOperation:function(){return nn(this)},endOperation:function(){return on(this)},refresh:pn(function(){var e=this.display.cachedTextHeight;vn(this),this.curOp.forceUpdate=!0,er(this),Xr(this,this.doc.scrollLeft,this.doc.scrollTop),Wn(this),(null==e||Math.abs(e-mr(this.display))>.5)&&Cr(this),Te(this,"refresh",this)}),swapDoc:pn(function(e){var t=this.doc;return t.cm=null,qn(this,e),er(this),this.display.input.reset(),Xr(this,e.scrollLeft,e.scrollTop),this.curOp.forceScroll=!0,bt(this,"swapDoc",this,t),t}),getInputField:function(){return this.display.input.getField()},getWrapperElement:function(){return this.display.wrapper},getScrollerElement:function(){return this.display.scroller},getGutterElement:function(){return this.display.gutters}},Ae(e),e.registerHelper=function(t,n,i){r.hasOwnProperty(t)||(r[t]=e[t]={_global:[]}),r[t][n]=i},e.registerGlobalHelper=function(t,n,i,o){e.registerHelper(t,n,o),r[t]._global.push({pred:i,val:o})}}(jo);var Js="iter insert remove copy getEditor constructor".split(" ");for(var ea in Ds.prototype)Ds.prototype.hasOwnProperty(ea)&&h(Js,ea)<0&&(jo.prototype[ea]=function(e){return function(){return e.apply(this.doc,arguments)}}(Ds.prototype[ea]));return Ae(Ds),jo.inputStyles={textarea:Qs,contenteditable:Zs},jo.defineMode=function(e){jo.defaults.mode||"null"==e||(jo.defaults.mode=e),Be.apply(this,arguments)},jo.defineMIME=function(e,t){os[e]=t},jo.defineMode("null",function(){return{token:function(e){return e.skipToEnd()}}}),jo.defineMIME("text/plain","null"),jo.defineExtension=function(e,t){jo.prototype[e]=t},jo.defineDocExtension=function(e,t){Ds.prototype[e]=t},jo.fromTextArea=function(e,t){function r(){e.value=a.getValue()}if(t=t?c(t):{},t.value=e.value,!t.tabindex&&e.tabIndex&&(t.tabindex=e.tabIndex),!t.placeholder&&e.placeholder&&(t.placeholder=e.placeholder),null==t.autofocus){var n=l();t.autofocus=n==e||null!=e.getAttribute("autofocus")&&n==document.body}var i;if(e.form&&(Ql(e.form,"submit",r),!t.leaveSubmitMethodAlone)){var o=e.form;i=o.submit;try{var s=o.submit=function(){r(),o.submit=i,o.submit(),o.submit=s}}catch(e){}}t.finishInit=function(t){t.save=r,t.getTextArea=function(){return e},t.toTextArea=function(){t.toTextArea=isNaN,r(),e.parentNode.removeChild(t.getWrapperElement()),e.style.display="",e.form&&(ke(e.form,"submit",r),"function"==typeof e.form.submit&&(e.form.submit=i))}},e.style.display="none";var a=jo(function(t){return e.parentNode.insertBefore(t,e.nextSibling)},t);return a},function(e){e.off=ke,e.on=Ql,e.wheelEventPixels=Pn,e.Doc=Ds,e.splitLines=es,e.countColumn=f,e.findColumn=d,e.isWordChar=w,e.Pass=Bl,e.signal=Te,e.Line=fs,e.changeEnd=Bn,e.scrollbarModel=ws,e.Pos=E,e.cmpPos=P,e.modes=is,e.mimeModes=os,e.resolveMode=Ge,e.getMode=Ue,e.modeExtensions=ls,e.extendMode=Ve,e.copyState=Ke,e.startState=Xe,e.innerMode=je,e.commands=Bs,e.keyMap=Rs,e.keyName=ao,e.isModifierKey=lo,e.lookupKey=oo,e.normalizeKeyMap=io,e.StringStream=ss,e.SharedTextMarker=As,e.TextMarker=Os,e.LineWidget=Ms,e.e_preventDefault=We,e.e_stopPropagation=De,e.e_stop=Fe,e.addClass=s,e.contains=o,e.rmClass=Fl,e.keyNames=Es}(jo),jo.version="5.30.0",jo});
      !function(e){"object"==typeof exports&&"object"==typeof module?e(require("../../lib/codemirror")):"function"==typeof define&&define.amd?define(["../../lib/codemirror"],e):e(CodeMirror)}(function(e){"use strict";function t(e,t,n,r,o,a){this.indented=e,this.column=t,this.type=n,this.info=r,this.align=o,this.prev=a}function n(e,n,r,o){var a=e.indented;return e.context&&"statement"==e.context.type&&"statement"!=r&&(a=e.context.indented),e.context=new t(a,n,r,o,null,e.context)}function r(e){var t=e.context.type;return")"!=t&&"]"!=t&&"}"!=t||(e.indented=e.context.indented),e.context=e.context.prev}function o(e,t,n){return"variable"==t.prevToken||"type"==t.prevToken||(!!/\S(?:[^- ]>|[*\]])\s*$|\*$/.test(e.string.slice(0,n))||(!(!t.typeAtEndOfLine||e.column()!=e.indentation())||void 0))}function a(e){for(;;){if(!e||"top"==e.type)return!0;if("}"==e.type&&"namespace"!=e.prev.info)return!1;e=e.prev}}function i(e){for(var t={},n=e.split(" "),r=0;r<n.length;++r)t[n[r]]=!0;return t}function l(e,t){return"function"==typeof e?e(t):e.propertyIsEnumerable(t)}function s(e,t){if(!t.startOfLine)return!1;for(var n,r=null;n=e.peek();){if("\\"==n&&e.match(/^.$/)){r=s;break}if("/"==n&&e.match(/^\/[\/\*]/,!1))break;e.next()}return t.tokenize=r,"meta"}function c(e,t){return"type"==t.prevToken&&"type"}function u(e){return e.eatWhile(/[\w\.']/),"number"}function d(e,t){if(e.backUp(1),e.match(/(R|u8R|uR|UR|LR)/)){var n=e.match(/"([^\s\\()]{0,16})\(/);return!!n&&(t.cpp11RawStringDelim=n[1],t.tokenize=m,m(e,t))}return e.match(/(u8|u|U|L)/)?!!e.match(/["']/,!1)&&"string":(e.next(),!1)}function f(e){var t=/(\w+)::~?(\w+)$/.exec(e);return t&&t[1]==t[2]}function p(e,t){for(var n;null!=(n=e.next());)if('"'==n&&!e.eat('"')){t.tokenize=null;break}return"string"}function m(e,t){var n=t.cpp11RawStringDelim.replace(/[^\w\s]/g,"\\$&");return e.match(new RegExp(".*?\\)"+n+'"'))?t.tokenize=null:e.skipToEnd(),"string"}function h(t,n){function r(e){if(e)for(var t in e)e.hasOwnProperty(t)&&o.push(t)}"string"==typeof t&&(t=[t]);var o=[];r(n.keywords),r(n.types),r(n.builtin),r(n.atoms),o.length&&(n.helperType=t[0],e.registerHelper("hintWords",t[0],o));for(var a=0;a<t.length;++a)e.defineMIME(t[a],n)}function g(e,t){for(var n=!1;!e.eol();){if(!n&&e.match('"""')){t.tokenize=null;break}n="\\"==e.next()&&!n}return"string"}function y(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!e&&!o&&t.match('"')){a=!0;break}if(e&&t.match('"""')){a=!0;break}r=t.next(),!o&&"$"==r&&t.match("{")&&t.skipTo("}"),o=!o&&"\\"==r&&!e}return!a&&e||(n.tokenize=null),"string"}}function x(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!o&&t.match('"')&&("single"==e||t.match('""'))){a=!0;break}if(!o&&t.match("``")){w=x(e),a=!0;break}r=t.next(),o="single"==e&&!o&&"\\"==r}return a&&(n.tokenize=null),"string"}}e.defineMode("clike",function(i,s){function c(e,t){var n=e.next();if(S[n]){var r=S[n](e,t);if(!1!==r)return r}if('"'==n||"'"==n)return t.tokenize=u(n),t.tokenize(e,t);if(D.test(n))return p=n,null;if(L.test(n)){if(e.backUp(1),e.match(I))return"number";e.next()}if("/"==n){if(e.eat("*"))return t.tokenize=d,d(e,t);if(e.eat("/"))return e.skipToEnd(),"comment"}if(F.test(n)){for(;!e.match(/^\/[\/*]/,!1)&&e.eat(F););return"operator"}if(e.eatWhile(z),P)for(;e.match(P);)e.eatWhile(z);var o=e.current();return l(x,o)?(l(w,o)&&(p="newstatement"),l(v,o)&&(m=!0),"keyword"):l(b,o)?"type":l(k,o)?(l(w,o)&&(p="newstatement"),"builtin"):l(_,o)?"atom":"variable"}function u(e){return function(t,n){for(var r,o=!1,a=!1;null!=(r=t.next());){if(r==e&&!o){a=!0;break}o=!o&&"\\"==r}return(a||!o&&!C)&&(n.tokenize=null),"string"}}function d(e,t){for(var n,r=!1;n=e.next();){if("/"==n&&r){t.tokenize=null;break}r="*"==n}return"comment"}function f(e,t){s.typeFirstDefinitions&&e.eol()&&a(t.context)&&(t.typeAtEndOfLine=o(e,t,e.pos))}var p,m,h=i.indentUnit,g=s.statementIndentUnit||h,y=s.dontAlignCalls,x=s.keywords||{},b=s.types||{},k=s.builtin||{},w=s.blockKeywords||{},v=s.defKeywords||{},_=s.atoms||{},S=s.hooks||{},C=s.multiLineStrings,T=!1!==s.indentStatements,M=!1!==s.indentSwitch,P=s.namespaceSeparator,D=s.isPunctuationChar||/[\[\]{}\(\),;\:\.]/,L=s.numberStart||/[\d\.]/,I=s.number||/^(?:0x[a-f\d]+|0b[01]+|(?:\d+\.?\d*|\.\d+)(?:e[-+]?\d+)?)(u|ll?|l|f)?/i,F=s.isOperatorChar||/[+\-*&%=<>!?|\/]/,z=s.isIdentifierChar||/[\w\$_\xa1-\uffff]/;return{startState:function(e){return{tokenize:null,context:new t((e||0)-h,0,"top",null,!1),indented:0,startOfLine:!0,prevToken:null}},token:function(e,t){var i=t.context;if(e.sol()&&(null==i.align&&(i.align=!1),t.indented=e.indentation(),t.startOfLine=!0),e.eatSpace())return f(e,t),null;p=m=null;var l=(t.tokenize||c)(e,t);if("comment"==l||"meta"==l)return l;if(null==i.align&&(i.align=!0),";"==p||":"==p||","==p&&e.match(/^\s*(?:\/\/.*)?$/,!1))for(;"statement"==t.context.type;)r(t);else if("{"==p)n(t,e.column(),"}");else if("["==p)n(t,e.column(),"]");else if("("==p)n(t,e.column(),")");else if("}"==p){for(;"statement"==i.type;)i=r(t);for("}"==i.type&&(i=r(t));"statement"==i.type;)i=r(t)}else p==i.type?r(t):T&&(("}"==i.type||"top"==i.type)&&";"!=p||"statement"==i.type&&"newstatement"==p)&&n(t,e.column(),"statement",e.current());if("variable"==l&&("def"==t.prevToken||s.typeFirstDefinitions&&o(e,t,e.start)&&a(t.context)&&e.match(/^\s*\(/,!1))&&(l="def"),S.token){var u=S.token(e,t,l);void 0!==u&&(l=u)}return"def"==l&&!1===s.styleDefs&&(l="variable"),t.startOfLine=!1,t.prevToken=m?"def":l||p,f(e,t),l},indent:function(t,n){if(t.tokenize!=c&&null!=t.tokenize||t.typeAtEndOfLine)return e.Pass;var r=t.context,o=n&&n.charAt(0);if("statement"==r.type&&"}"==o&&(r=r.prev),s.dontIndentStatements)for(;"statement"==r.type&&s.dontIndentStatements.test(r.info);)r=r.prev;if(S.indent){var a=S.indent(t,r,n);if("number"==typeof a)return a}var i=o==r.type,l=r.prev&&"switch"==r.prev.info;if(s.allmanIndentation&&/[{(]/.test(o)){for(;"top"!=r.type&&"}"!=r.type;)r=r.prev;return r.indented}return"statement"==r.type?r.indented+("{"==o?0:g):!r.align||y&&")"==r.type?")"!=r.type||i?r.indented+(i?0:h)+(i||!l||/^(?:case|default)\b/.test(n)?0:h):r.indented+g:r.column+(i?0:1)},electricInput:M?/^\s*(?:case .*?:|default:|\{\}?|\})$/:/^\s*[{}]$/,blockCommentStart:"/*",blockCommentEnd:"*/",lineComment:"//",fold:"brace"}});var b="auto if break case register continue return default do sizeof static else struct switch extern typedef union for goto while enum const volatile",k="int long char short double float unsigned signed void size_t ptrdiff_t";h(["text/x-csrc","text/x-c","text/x-chdr"],{name:"clike",keywords:i(b),types:i(k+" bool _Complex _Bool float_t double_t intptr_t intmax_t int8_t int16_t int32_t int64_t uintptr_t uintmax_t uint8_t uint16_t uint32_t uint64_t"),blockKeywords:i("case do else for if switch while struct"),defKeywords:i("struct"),typeFirstDefinitions:!0,atoms:i("null true false"),hooks:{"#":s,"*":c},modeProps:{fold:["brace","include"]}}),h(["text/x-c++src","text/x-c++hdr"],{name:"clike",keywords:i(b+" asm dynamic_cast namespace reinterpret_cast try explicit new static_cast typeid catch operator template typename class friend private this using const_cast inline public throw virtual delete mutable protected alignas alignof constexpr decltype nullptr noexcept thread_local final static_assert override"),types:i(k+" bool wchar_t"),blockKeywords:i("catch class do else finally for if struct switch try while"),defKeywords:i("class namespace struct enum union"),typeFirstDefinitions:!0,atoms:i("true false null"),dontIndentStatements:/^template$/,isIdentifierChar:/[\w\$_~\xa1-\uffff]/,hooks:{"#":s,"*":c,u:d,U:d,L:d,R:d,0:u,1:u,2:u,3:u,4:u,5:u,6:u,7:u,8:u,9:u,token:function(e,t,n){if("variable"==n&&"("==e.peek()&&(";"==t.prevToken||null==t.prevToken||"}"==t.prevToken)&&f(e.current()))return"def"}},namespaceSeparator:"::",modeProps:{fold:["brace","include"]}}),h("text/x-java",{name:"clike",keywords:i("abstract assert break case catch class const continue default do else enum extends final finally float for goto if implements import instanceof interface native new package private protected public return static strictfp super switch synchronized this throw throws transient try volatile while @interface"),types:i("byte short int long float double boolean char void Boolean Byte Character Double Float Integer Long Number Object Short String StringBuffer StringBuilder Void"),blockKeywords:i("catch class do else finally for if switch try while"),defKeywords:i("class interface package enum @interface"),typeFirstDefinitions:!0,atoms:i("true false null"),number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,hooks:{"@":function(e){return!e.match("interface",!1)&&(e.eatWhile(/[\w\$_]/),"meta")}},modeProps:{fold:["brace","import"]}}),h("text/x-csharp",{name:"clike",keywords:i("abstract as async await base break case catch checked class const continue default delegate do else enum event explicit extern finally fixed for foreach goto if implicit in interface internal is lock namespace new operator out override params private protected public readonly ref return sealed sizeof stackalloc static struct switch this throw try typeof unchecked unsafe using virtual void volatile while add alias ascending descending dynamic from get global group into join let orderby partial remove select set value var yield"),types:i("Action Boolean Byte Char DateTime DateTimeOffset Decimal Double Func Guid Int16 Int32 Int64 Object SByte Single String Task TimeSpan UInt16 UInt32 UInt64 bool byte char decimal double short int long object sbyte float string ushort uint ulong"),blockKeywords:i("catch class do else finally for foreach if struct switch try while"),defKeywords:i("class interface namespace struct var"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"@":function(e,t){return e.eat('"')?(t.tokenize=p,p(e,t)):(e.eatWhile(/[\w\$_]/),"meta")}}}),h("text/x-scala",{name:"clike",keywords:i("abstract case catch class def do else extends final finally for forSome if implicit import lazy match new null object override package private protected return sealed super this throw trait try type val var while with yield _ assert assume require print println printf readLine readBoolean readByte readShort readChar readInt readLong readFloat readDouble"),types:i("AnyVal App Application Array BufferedIterator BigDecimal BigInt Char Console Either Enumeration Equiv Error Exception Fractional Function IndexedSeq Int Integral Iterable Iterator List Map Numeric Nil NotNull Option Ordered Ordering PartialFunction PartialOrdering Product Proxy Range Responder Seq Serializable Set Specializable Stream StringBuilder StringContext Symbol Throwable Traversable TraversableOnce Tuple Unit Vector Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),multiLineStrings:!0,blockKeywords:i("catch class enum do else finally for forSome if match switch try while"),defKeywords:i("class enum def object package trait type val var"),atoms:i("true false null"),indentStatements:!1,indentSwitch:!1,isOperatorChar:/[+\-*&%=<>!?|\/#:@]/,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return!!e.match('""')&&(t.tokenize=g,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},"=":function(e,n){var r=n.context;return!("}"!=r.type||!r.align||!e.eat(">"))&&(n.context=new t(r.indented,r.column,r.type,r.info,null,r.prev),"operator")}},modeProps:{closeBrackets:{triples:'"'}}}),h("text/x-kotlin",{name:"clike",keywords:i("package as typealias class interface this super val var fun for is in This throw return break continue object if else while do try when !in !is as? file import where by get set abstract enum open inner override private public internal protected catch finally out final vararg reified dynamic companion constructor init sealed field property receiver param sparam lateinit data inline noinline tailrec external annotation crossinline const operator infix suspend"),types:i("Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),intendSwitch:!1,indentStatements:!1,multiLineStrings:!0,number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,blockKeywords:i("catch class do else finally for if where try while enum"),defKeywords:i("class val var object package interface fun"),atoms:i("true false null this"),hooks:{'"':function(e,t){return t.tokenize=y(e.match('""')),t.tokenize(e,t)}},modeProps:{closeBrackets:{triples:'"'}}}),h(["x-shader/x-vertex","x-shader/x-fragment"],{name:"clike",keywords:i("sampler1D sampler2D sampler3D samplerCube sampler1DShadow sampler2DShadow const attribute uniform varying break continue discard return for while do if else struct in out inout"),types:i("float int bool void vec2 vec3 vec4 ivec2 ivec3 ivec4 bvec2 bvec3 bvec4 mat2 mat3 mat4"),blockKeywords:i("for while do if else struct"),builtin:i("radians degrees sin cos tan asin acos atan pow exp log exp2 sqrt inversesqrt abs sign floor ceil fract mod min max clamp mix step smoothstep length distance dot cross normalize ftransform faceforward reflect refract matrixCompMult lessThan lessThanEqual greaterThan greaterThanEqual equal notEqual any all not texture1D texture1DProj texture1DLod texture1DProjLod texture2D texture2DProj texture2DLod texture2DProjLod texture3D texture3DProj texture3DLod texture3DProjLod textureCube textureCubeLod shadow1D shadow2D shadow1DProj shadow2DProj shadow1DLod shadow2DLod shadow1DProjLod shadow2DProjLod dFdx dFdy fwidth noise1 noise2 noise3 noise4"),atoms:i("true false gl_FragColor gl_SecondaryColor gl_Normal gl_Vertex gl_MultiTexCoord0 gl_MultiTexCoord1 gl_MultiTexCoord2 gl_MultiTexCoord3 gl_MultiTexCoord4 gl_MultiTexCoord5 gl_MultiTexCoord6 gl_MultiTexCoord7 gl_FogCoord gl_PointCoord gl_Position gl_PointSize gl_ClipVertex gl_FrontColor gl_BackColor gl_FrontSecondaryColor gl_BackSecondaryColor gl_TexCoord gl_FogFragCoord gl_FragCoord gl_FrontFacing gl_FragData gl_FragDepth gl_ModelViewMatrix gl_ProjectionMatrix gl_ModelViewProjectionMatrix gl_TextureMatrix gl_NormalMatrix gl_ModelViewMatrixInverse gl_ProjectionMatrixInverse gl_ModelViewProjectionMatrixInverse gl_TexureMatrixTranspose gl_ModelViewMatrixInverseTranspose gl_ProjectionMatrixInverseTranspose gl_ModelViewProjectionMatrixInverseTranspose gl_TextureMatrixInverseTranspose gl_NormalScale gl_DepthRange gl_ClipPlane gl_Point gl_FrontMaterial gl_BackMaterial gl_LightSource gl_LightModel gl_FrontLightModelProduct gl_BackLightModelProduct gl_TextureColor gl_EyePlaneS gl_EyePlaneT gl_EyePlaneR gl_EyePlaneQ gl_FogParameters gl_MaxLights gl_MaxClipPlanes gl_MaxTextureUnits gl_MaxTextureCoords gl_MaxVertexAttribs gl_MaxVertexUniformComponents gl_MaxVaryingFloats gl_MaxVertexTextureImageUnits gl_MaxTextureImageUnits gl_MaxFragmentUniformComponents gl_MaxCombineTextureImageUnits gl_MaxDrawBuffers"),indentSwitch:!1,hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-nesc",{name:"clike",keywords:i(b+"as atomic async call command component components configuration event generic implementation includes interface module new norace nx_struct nx_union post provides signal task uses abstract extends"),types:i(k),blockKeywords:i("case do else for if switch while struct"),atoms:i("null true false"),hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-objectivec",{name:"clike",keywords:i(b+"inline restrict _Bool _Complex _Imaginary BOOL Class bycopy byref id IMP in inout nil oneway out Protocol SEL self super atomic nonatomic retain copy readwrite readonly"),types:i(k),atoms:i("YES NO NULL NILL ON OFF true false"),hooks:{"@":function(e){return e.eatWhile(/[\w\$]/),"keyword"},"#":s,indent:function(e,t,n){if("statement"==t.type&&/^@\w/.test(n))return t.indented}},modeProps:{fold:"brace"}}),h("text/x-squirrel",{name:"clike",keywords:i("base break clone continue const default delete enum extends function in class foreach local resume return this throw typeof yield constructor instanceof static"),types:i(k),blockKeywords:i("case catch class else for foreach if switch try while"),defKeywords:i("function local class"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"#":s},modeProps:{fold:["brace","include"]}});var w=null;h("text/x-ceylon",{name:"clike",keywords:i("abstracts alias assembly assert assign break case catch class continue dynamic else exists extends finally for function given if import in interface is let module new nonempty object of out outer package return satisfies super switch then this throw try value void while"),types:function(e){var t=e.charAt(0);return t===t.toUpperCase()&&t!==t.toLowerCase()},blockKeywords:i("case catch class dynamic else finally for function if interface module new object switch try while"),defKeywords:i("class dynamic function interface module object package value"),builtin:i("abstract actual aliased annotation by default deprecated doc final formal late license native optional sealed see serializable shared suppressWarnings tagged throws variable"),isPunctuationChar:/[\[\]{}\(\),;\:\.`]/,isOperatorChar:/[+\-*&%=<>!?|^~:\/]/,numberStart:/[\d#$]/,number:/^(?:#[\da-fA-F_]+|\$[01_]+|[\d_]+[kMGTPmunpf]?|[\d_]+\.[\d_]+(?:[eE][-+]?\d+|[kMGTPmunpf]|)|)/i,multiLineStrings:!0,typeFirstDefinitions:!0,atoms:i("true false null larger smaller equal empty finished"),indentSwitch:!1,styleDefs:!1,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return t.tokenize=x(e.match('""')?"triple":"single"),t.tokenize(e,t)},"`":function(e,t){return!(!w||!e.match("`"))&&(t.tokenize=w,w=null,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},token:function(e,t,n){if(("variable"==n||"type"==n)&&"."==t.prevToken)return"variable-2"}},modeProps:{fold:["brace","import"],closeBrackets:{triples:'"'}}})});
      // -------------------------------------------------------------------------
//  Part of the CodeChecker project, under the Apache License v2.0 with
//  LLVM Exceptions. See LICENSE for license information.
//  SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
// -------------------------------------------------------------------------

var BugViewer = {
  _files : [],
  _reports : [],
  _lineWidgets : [],
  _navigationMenuItems : [],
  _sourceFileData : null,
  _currentReport : null,
  _lastBugEvent  : null,

  init : function (files, reports) {
    this._files = files;
    this._reports = reports;

    this.initEscapeChars();
  },

  initEscapeChars : function () {
    this.escapeChars = {
      ' ' : 'nbsp',
      '<' : 'lt',
      '>' : 'gt',
      '"' : 'quot',
      '&' : 'amp'
    };

    var regexString = '[';
    for (var key in this.escapeChars) {
      regexString += key;
    }
    regexString += ']';

    this.escapeRegExp = new RegExp( regexString, 'g');
  },

  escapeHTML : function (str) {
    var that = this;

    return str.replace(this.escapeRegExp, function (m) {
      return '&' + that.escapeChars[m] + ';';
    });
  },

  initByUrl : function () {
    if (!this._reports) return;

    var state = {};
    window.location.hash.substr(1).split('&').forEach(function (s) {
      var parts = s.split('=');
      state[parts[0]] = parts[1];
    });

    for (var key in this._reports) {
      var report = this._reports[key];
      if (report.reportHash === state['reportHash']) {
        this.navigate(report);
        return;
      }
    }

    this.navigate(this._reports[0]);
  },

  create : function () {
    this._content = document.getElementById('editor-wrapper');
    this._filepath = document.getElementById('file-path');
    this._checkerName = document.getElementById('checker-name');
    this._reviewStatusWrapper =
      document.getElementById('review-status-wrapper');
    this._reviewStatus = document.getElementById('review-status');
    this._editor = document.getElementById('editor');

    this._codeMirror = CodeMirror(this._editor, {
      mode: 'text/x-c++src',
      matchBrackets : true,
      lineNumbers : true,
      readOnly : true,
      foldGutter : true,
      extraKeys : {},
      viewportMargin : 100
    });

    this._createNavigationMenu();
  },

  navigate : function (report, item) {
    if (!item) {
      var items = this._navigationMenuItems.filter(function (navItem) {
        return navItem.report.reportHash === report.reportHash;
      });

      if (!items.length) return;

      item = items[0].widget;
    }

    this._selectedReport.classList.remove('active');
    this._selectedReport = item;
    this._selectedReport.classList.add('active');
    this.setReport(report);
  },

  _createNavigationMenu : function () {
    var that = this;

    var nav = document.getElementById('report-nav');
    var list = document.createElement('ul');
    this._reports.forEach(function (report) {
      var events = report['events'];
      var lastBugEvent = events[events.length - 1];
      var item = document.createElement('li');

      var severity = document.createElement('i');
      severity.className = 'severity-' + report.severity.toLowerCase();

      item.appendChild(severity);
      item.appendChild(document.createTextNode(lastBugEvent.message));

      item.addEventListener('click', function () {
        that.navigate(report, item);
      })
      list.appendChild(item);
      that._navigationMenuItems.push({ report : report, widget : item });
    });

    if (!this._selectedReport && list.childNodes.length) {
      this._selectedReport = list.childNodes[0];
      this._selectedReport.classList.add('active');
    }

    nav.appendChild(list);
  },

  setReport : function (report) {
    this._currentReport = report;
    var events = report['events'];
    var lastBugEvent = events[events.length - 1];
    this.setCurrentBugEvent(lastBugEvent, events.length - 1);
    this.setCheckerName(report.checkerName);
    this.setReviewStatus(report.reviewStatus);

    window.location.hash = '#reportHash=' + report.reportHash;
  },

  setCurrentBugEvent : function (event, idx) {
    this._currentBugEvent = event;
    this.setSourceFileData(this._files[event.location.file]);
    this.drawBugPath();

    this.jumpTo(event.location.line, 0);
    this.highlightBugEvent(event, idx);
  },

  highlightBugEvent : function (event, idx) {
    this._lineWidgets.forEach(function (widget) {
      var lineIdx = widget.node.getAttribute('idx');
      if (parseInt(lineIdx) === idx) {
        widget.node.classList.add('current');
      }
    });
  },

  setCheckerName : function (checkerName) {
    this._checkerName.innerHTML = checkerName;
  },

  setReviewStatus : function (status) {
    if (status) {
      var className =
        'review-status-' + status.toLowerCase().split(' ').join('-');
      this._reviewStatus.className = "review-status " + className;

      this._reviewStatus.innerHTML = status;
      this._reviewStatusWrapper.style.display = 'block';
    } else {
      this._reviewStatusWrapper.style.display = 'none';
    }
  },

  setSourceFileData : function (file) {
    if (this._sourceFileData && file.id === this._sourceFileData.id) {
      return;
    }

    this._sourceFileData = file;
    this._filepath.innerHTML = file.path;
    this._codeMirror.doc.setValue(file.content);
    this._refresh();
  },

  _refresh : function () {
    var that = this;
    setTimeout(function () {
      var fullHeight = parseInt(that._content.clientHeight);
      var headerHeight = that._filepath.clientHeight;

      that._codeMirror.setSize('auto', fullHeight - headerHeight);
      that._codeMirror.refresh();
    }, 200);
  },

  clearBubbles : function () {
    this._lineWidgets.forEach(function (widget) { widget.clear(); });
    this._lineWidgets = [];
  },

  getMessage : function (event, kind) {
    if (kind === 'macro') {
      var name = 'macro expansion' + (event.name ? ': ' + event.name : '');

      return '<span class="tag macro">' + name + '</span>'
        + this.escapeHTML(event.expansion).replace(/(?:\r\n|\r|\n)/g, '<br>');
    } else if (kind === 'note') {
      return '<span class="tag note">note</span>'
        +  this.escapeHTML(event.message).replace(/(?:\r\n|\r|\n)/g, '<br>');
    }
  },

  addExtraPathEvents : function (events, kind) {
    var that = this;

    if (!events) {
      return;
    }

    events.forEach(function (event) {
      if (event.location.file !== that._currentBugEvent.location.file) {
        return;
      }

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + kind);

      var msg = document.createElement('span');
      msg.innerHTML = that.getMessage(event, kind);
      element.appendChild(msg);

      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  drawBugPath : function () {
    var that = this;

    this.clearBubbles();

    this.addExtraPathEvents(this._currentReport.macros, 'macro');
    this.addExtraPathEvents(this._currentReport.notes, 'note');

    // Processing bug path events.
    var currentEvents = this._currentReport.events;
    currentEvents.forEach(function (event, step) {
      if (event.location.file !== that._currentBugEvent.location.file)
        return;

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';
      var type = step === currentEvents.length - 1 ? 'error' : 'info';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + type);
      element.setAttribute('idx', step);

      var enumeration = document.createElement('span');
      enumeration.setAttribute('class', 'checker-enum ' + type);
      enumeration.innerHTML = step + 1;

      if (currentEvents.length > 1)
        element.appendChild(enumeration);

      var prevBugEvent = step - 1;
      if (step > 0) {
        var prevBug = document.createElement('span');
        prevBug.setAttribute('class', 'arrow left-arrow');
        prevBug.addEventListener('click', function () {
          var event = currentEvents[prevBugEvent];
          that.setCurrentBugEvent(event, prevBugEvent);
        });
        element.appendChild(prevBug);
      }

      var msg = document.createElement('span');
      msg.innerHTML = that.escapeHTML(event.message)
        .replace(/(?:\r\n|\r|\n)/g, '<br>');

      element.appendChild(msg);

      var nextBugEvent = step + 1;
      if (nextBugEvent < currentEvents.length) {
        var nextBug = document.createElement('span');
        nextBug.setAttribute('class', 'arrow right-arrow');
        nextBug.addEventListener('click', function () {
          var event = currentEvents[nextBugEvent];
          that.setCurrentBugEvent(event, nextBugEvent);
        });
        element.appendChild(nextBug);
      }


      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  jumpTo : function (line, column) {
    var that = this;

    setTimeout(function () {
      var selPosPixel
        = that._codeMirror.charCoords({ line : line, ch : column }, 'local');
      var editorSize = {
        width  : that._editor.clientWidth,
        height : that._editor.clientHeight
      };

      that._codeMirror.scrollIntoView({
        top    : selPosPixel.top - 100,
        bottom : selPosPixel.top + editorSize.height - 150,
        left   : selPosPixel.left < editorSize.width - 100
               ? 0
               : selPosPixel.left - 50,
        right  : selPosPixel.left < editorSize.width - 100
               ? 10
               : selPosPixel.left + editorSize.width - 100
      });
    }, 0);
  }
}


      var data = {"files": {"0": {"id": 0, "path": "/src/drivers/scsi/lpfc/lpfc_init.c", "content": "/*******************************************************************\n * This file is part of the Emulex Linux Device Driver for         *\n * Fibre Channel Host Bus Adapters.                                *\n * Copyright (C) 2017-2020 Broadcom. All Rights Reserved. The term *\n * \u201cBroadcom\u201d refers to Broadcom Inc. and/or its subsidiaries.  *\n * Copyright (C) 2004-2016 Emulex.  All rights reserved.           *\n * EMULEX and SLI are trademarks of Emulex.                        *\n * www.broadcom.com                                                *\n * Portions Copyright (C) 2004-2005 Christoph Hellwig              *\n *                                                                 *\n * This program is free software; you can redistribute it and/or   *\n * modify it under the terms of version 2 of the GNU General       *\n * Public License as published by the Free Software Foundation.    *\n * This program is distributed in the hope that it will be useful. *\n * ALL EXPRESS OR IMPLIED CONDITIONS, REPRESENTATIONS AND          *\n * WARRANTIES, INCLUDING ANY IMPLIED WARRANTY OF MERCHANTABILITY,  *\n * FITNESS FOR A PARTICULAR PURPOSE, OR NON-INFRINGEMENT, ARE      *\n * DISCLAIMED, EXCEPT TO THE EXTENT THAT SUCH DISCLAIMERS ARE HELD *\n * TO BE LEGALLY INVALID.  See the GNU General Public License for  *\n * more details, a copy of which can be found in the file COPYING  *\n * included with this package.                                     *\n *******************************************************************/\n\n#include <linux/blkdev.h>\n#include <linux/delay.h>\n#include <linux/dma-mapping.h>\n#include <linux/idr.h>\n#include <linux/interrupt.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\n#include <linux/pci.h>\n#include <linux/spinlock.h>\n#include <linux/ctype.h>\n#include <linux/aer.h>\n#include <linux/slab.h>\n#include <linux/firmware.h>\n#include <linux/miscdevice.h>\n#include <linux/percpu.h>\n#include <linux/msi.h>\n#include <linux/irq.h>\n#include <linux/bitops.h>\n#include <linux/crash_dump.h>\n#include <linux/cpu.h>\n#include <linux/cpuhotplug.h>\n\n#include <scsi/scsi.h>\n#include <scsi/scsi_device.h>\n#include <scsi/scsi_host.h>\n#include <scsi/scsi_transport_fc.h>\n#include <scsi/scsi_tcq.h>\n#include <scsi/fc/fc_fs.h>\n\n#include \"lpfc_hw4.h\"\n#include \"lpfc_hw.h\"\n#include \"lpfc_sli.h\"\n#include \"lpfc_sli4.h\"\n#include \"lpfc_nl.h\"\n#include \"lpfc_disc.h\"\n#include \"lpfc.h\"\n#include \"lpfc_scsi.h\"\n#include \"lpfc_nvme.h\"\n#include \"lpfc_logmsg.h\"\n#include \"lpfc_crtn.h\"\n#include \"lpfc_vport.h\"\n#include \"lpfc_version.h\"\n#include \"lpfc_ids.h\"\n\nstatic enum cpuhp_state lpfc_cpuhp_state;\n/* Used when mapping IRQ vectors in a driver centric manner */\nstatic uint32_t lpfc_present_cpu;\n\nstatic void __lpfc_cpuhp_remove(struct lpfc_hba *phba);\nstatic void lpfc_cpuhp_remove(struct lpfc_hba *phba);\nstatic void lpfc_cpuhp_add(struct lpfc_hba *phba);\nstatic void lpfc_get_hba_model_desc(struct lpfc_hba *, uint8_t *, uint8_t *);\nstatic int lpfc_post_rcv_buf(struct lpfc_hba *);\nstatic int lpfc_sli4_queue_verify(struct lpfc_hba *);\nstatic int lpfc_create_bootstrap_mbox(struct lpfc_hba *);\nstatic int lpfc_setup_endian_order(struct lpfc_hba *);\nstatic void lpfc_destroy_bootstrap_mbox(struct lpfc_hba *);\nstatic void lpfc_free_els_sgl_list(struct lpfc_hba *);\nstatic void lpfc_free_nvmet_sgl_list(struct lpfc_hba *);\nstatic void lpfc_init_sgl_list(struct lpfc_hba *);\nstatic int lpfc_init_active_sgl_array(struct lpfc_hba *);\nstatic void lpfc_free_active_sgl(struct lpfc_hba *);\nstatic int lpfc_hba_down_post_s3(struct lpfc_hba *phba);\nstatic int lpfc_hba_down_post_s4(struct lpfc_hba *phba);\nstatic int lpfc_sli4_cq_event_pool_create(struct lpfc_hba *);\nstatic void lpfc_sli4_cq_event_pool_destroy(struct lpfc_hba *);\nstatic void lpfc_sli4_cq_event_release_all(struct lpfc_hba *);\nstatic void lpfc_sli4_disable_intr(struct lpfc_hba *);\nstatic uint32_t lpfc_sli4_enable_intr(struct lpfc_hba *, uint32_t);\nstatic void lpfc_sli4_oas_verify(struct lpfc_hba *phba);\nstatic uint16_t lpfc_find_cpu_handle(struct lpfc_hba *, uint16_t, int);\nstatic void lpfc_setup_bg(struct lpfc_hba *, struct Scsi_Host *);\n\nstatic struct scsi_transport_template *lpfc_transport_template = NULL;\nstatic struct scsi_transport_template *lpfc_vport_transport_template = NULL;\nstatic DEFINE_IDR(lpfc_hba_index);\n#define LPFC_NVMET_BUF_POST 254\n\n/**\n * lpfc_config_port_prep - Perform lpfc initialization prior to config port\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine will do LPFC initialization prior to issuing the CONFIG_PORT\n * mailbox command. It retrieves the revision information from the HBA and\n * collects the Vital Product Data (VPD) about the HBA for preparing the\n * configuration of the HBA.\n *\n * Return codes:\n *   0 - success.\n *   -ERESTART - requests the SLI layer to reset the HBA and try again.\n *   Any other value - indicates an error.\n **/\nint\nlpfc_config_port_prep(struct lpfc_hba *phba)\n{\n\tlpfc_vpd_t *vp = &phba->vpd;\n\tint i = 0, rc;\n\tLPFC_MBOXQ_t *pmb;\n\tMAILBOX_t *mb;\n\tchar *lpfc_vpd_data = NULL;\n\tuint16_t offset = 0;\n\tstatic char licensed[56] =\n\t\t    \"key unlock for use with gnu public licensed code only\\0\";\n\tstatic int init_key = 1;\n\n\tpmb = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!pmb) {\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\treturn -ENOMEM;\n\t}\n\n\tmb = &pmb->u.mb;\n\tphba->link_state = LPFC_INIT_MBX_CMDS;\n\n\tif (lpfc_is_LC_HBA(phba->pcidev->device)) {\n\t\tif (init_key) {\n\t\t\tuint32_t *ptext = (uint32_t *) licensed;\n\n\t\t\tfor (i = 0; i < 56; i += sizeof (uint32_t), ptext++)\n\t\t\t\t*ptext = cpu_to_be32(*ptext);\n\t\t\tinit_key = 0;\n\t\t}\n\n\t\tlpfc_read_nv(phba, pmb);\n\t\tmemset((char*)mb->un.varRDnvp.rsvd3, 0,\n\t\t\tsizeof (mb->un.varRDnvp.rsvd3));\n\t\tmemcpy((char*)mb->un.varRDnvp.rsvd3, licensed,\n\t\t\t sizeof (licensed));\n\n\t\trc = lpfc_sli_issue_mbox(phba, pmb, MBX_POLL);\n\n\t\tif (rc != MBX_SUCCESS) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0324 Config Port initialization \"\n\t\t\t\t\t\"error, mbxCmd x%x READ_NVPARM, \"\n\t\t\t\t\t\"mbxStatus x%x\\n\",\n\t\t\t\t\tmb->mbxCommand, mb->mbxStatus);\n\t\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\t\t\treturn -ERESTART;\n\t\t}\n\t\tmemcpy(phba->wwnn, (char *)mb->un.varRDnvp.nodename,\n\t\t       sizeof(phba->wwnn));\n\t\tmemcpy(phba->wwpn, (char *)mb->un.varRDnvp.portname,\n\t\t       sizeof(phba->wwpn));\n\t}\n\n\t/*\n\t * Clear all option bits except LPFC_SLI3_BG_ENABLED,\n\t * which was already set in lpfc_get_cfgparam()\n\t */\n\tphba->sli3_options &= (uint32_t)LPFC_SLI3_BG_ENABLED;\n\n\t/* Setup and issue mailbox READ REV command */\n\tlpfc_read_rev(phba, pmb);\n\trc = lpfc_sli_issue_mbox(phba, pmb, MBX_POLL);\n\tif (rc != MBX_SUCCESS) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0439 Adapter failed to init, mbxCmd x%x \"\n\t\t\t\t\"READ_REV, mbxStatus x%x\\n\",\n\t\t\t\tmb->mbxCommand, mb->mbxStatus);\n\t\tmempool_free( pmb, phba->mbox_mem_pool);\n\t\treturn -ERESTART;\n\t}\n\n\n\t/*\n\t * The value of rr must be 1 since the driver set the cv field to 1.\n\t * This setting requires the FW to set all revision fields.\n\t */\n\tif (mb->un.varRdRev.rr == 0) {\n\t\tvp->rev.rBit = 0;\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0440 Adapter failed to init, READ_REV has \"\n\t\t\t\t\"missing revision information.\\n\");\n\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\t\treturn -ERESTART;\n\t}\n\n\tif (phba->sli_rev == 3 && !mb->un.varRdRev.v3rsp) {\n\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\t\treturn -EINVAL;\n\t}\n\n\t/* Save information as VPD data */\n\tvp->rev.rBit = 1;\n\tmemcpy(&vp->sli3Feat, &mb->un.varRdRev.sli3Feat, sizeof(uint32_t));\n\tvp->rev.sli1FwRev = mb->un.varRdRev.sli1FwRev;\n\tmemcpy(vp->rev.sli1FwName, (char*) mb->un.varRdRev.sli1FwName, 16);\n\tvp->rev.sli2FwRev = mb->un.varRdRev.sli2FwRev;\n\tmemcpy(vp->rev.sli2FwName, (char *) mb->un.varRdRev.sli2FwName, 16);\n\tvp->rev.biuRev = mb->un.varRdRev.biuRev;\n\tvp->rev.smRev = mb->un.varRdRev.smRev;\n\tvp->rev.smFwRev = mb->un.varRdRev.un.smFwRev;\n\tvp->rev.endecRev = mb->un.varRdRev.endecRev;\n\tvp->rev.fcphHigh = mb->un.varRdRev.fcphHigh;\n\tvp->rev.fcphLow = mb->un.varRdRev.fcphLow;\n\tvp->rev.feaLevelHigh = mb->un.varRdRev.feaLevelHigh;\n\tvp->rev.feaLevelLow = mb->un.varRdRev.feaLevelLow;\n\tvp->rev.postKernRev = mb->un.varRdRev.postKernRev;\n\tvp->rev.opFwRev = mb->un.varRdRev.opFwRev;\n\n\t/* If the sli feature level is less then 9, we must\n\t * tear down all RPIs and VPIs on link down if NPIV\n\t * is enabled.\n\t */\n\tif (vp->rev.feaLevelHigh < 9)\n\t\tphba->sli3_options |= LPFC_SLI3_VPORT_TEARDOWN;\n\n\tif (lpfc_is_LC_HBA(phba->pcidev->device))\n\t\tmemcpy(phba->RandomData, (char *)&mb->un.varWords[24],\n\t\t\t\t\t\tsizeof (phba->RandomData));\n\n\t/* Get adapter VPD information */\n\tlpfc_vpd_data = kmalloc(DMP_VPD_SIZE, GFP_KERNEL);\n\tif (!lpfc_vpd_data)\n\t\tgoto out_free_mbox;\n\tdo {\n\t\tlpfc_dump_mem(phba, pmb, offset, DMP_REGION_VPD);\n\t\trc = lpfc_sli_issue_mbox(phba, pmb, MBX_POLL);\n\n\t\tif (rc != MBX_SUCCESS) {\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\t\"0441 VPD not present on adapter, \"\n\t\t\t\t\t\"mbxCmd x%x DUMP VPD, mbxStatus x%x\\n\",\n\t\t\t\t\tmb->mbxCommand, mb->mbxStatus);\n\t\t\tmb->un.varDmp.word_cnt = 0;\n\t\t}\n\t\t/* dump mem may return a zero when finished or we got a\n\t\t * mailbox error, either way we are done.\n\t\t */\n\t\tif (mb->un.varDmp.word_cnt == 0)\n\t\t\tbreak;\n\n\t\ti =  mb->un.varDmp.word_cnt * sizeof(uint32_t);\n\t\tif (offset + i >  DMP_VPD_SIZE)\n\t\t\ti =  DMP_VPD_SIZE - offset;\n\t\tlpfc_sli_pcimem_bcopy(((uint8_t *)mb) + DMP_RSP_OFFSET,\n\t\t\t\t      lpfc_vpd_data  + offset, i);\n\t\toffset += i;\n\t} while (offset < DMP_VPD_SIZE);\n\n\tlpfc_parse_vpd(phba, lpfc_vpd_data, offset);\n\n\tkfree(lpfc_vpd_data);\nout_free_mbox:\n\tmempool_free(pmb, phba->mbox_mem_pool);\n\treturn 0;\n}\n\n/**\n * lpfc_config_async_cmpl - Completion handler for config async event mbox cmd\n * @phba: pointer to lpfc hba data structure.\n * @pmboxq: pointer to the driver internal queue element for mailbox command.\n *\n * This is the completion handler for driver's configuring asynchronous event\n * mailbox command to the device. If the mailbox command returns successfully,\n * it will set internal async event support flag to 1; otherwise, it will\n * set internal async event support flag to 0.\n **/\nstatic void\nlpfc_config_async_cmpl(struct lpfc_hba * phba, LPFC_MBOXQ_t * pmboxq)\n{\n\tif (pmboxq->u.mb.mbxStatus == MBX_SUCCESS)\n\t\tphba->temp_sensor_support = 1;\n\telse\n\t\tphba->temp_sensor_support = 0;\n\tmempool_free(pmboxq, phba->mbox_mem_pool);\n\treturn;\n}\n\n/**\n * lpfc_dump_wakeup_param_cmpl - dump memory mailbox command completion handler\n * @phba: pointer to lpfc hba data structure.\n * @pmboxq: pointer to the driver internal queue element for mailbox command.\n *\n * This is the completion handler for dump mailbox command for getting\n * wake up parameters. When this command complete, the response contain\n * Option rom version of the HBA. This function translate the version number\n * into a human readable string and store it in OptionROMVersion.\n **/\nstatic void\nlpfc_dump_wakeup_param_cmpl(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmboxq)\n{\n\tstruct prog_id *prg;\n\tuint32_t prog_id_word;\n\tchar dist = ' ';\n\t/* character array used for decoding dist type. */\n\tchar dist_char[] = \"nabx\";\n\n\tif (pmboxq->u.mb.mbxStatus != MBX_SUCCESS) {\n\t\tmempool_free(pmboxq, phba->mbox_mem_pool);\n\t\treturn;\n\t}\n\n\tprg = (struct prog_id *) &prog_id_word;\n\n\t/* word 7 contain option rom version */\n\tprog_id_word = pmboxq->u.mb.un.varWords[7];\n\n\t/* Decode the Option rom version word to a readable string */\n\tif (prg->dist < 4)\n\t\tdist = dist_char[prg->dist];\n\n\tif ((prg->dist == 3) && (prg->num == 0))\n\t\tsnprintf(phba->OptionROMVersion, 32, \"%d.%d%d\",\n\t\t\tprg->ver, prg->rev, prg->lev);\n\telse\n\t\tsnprintf(phba->OptionROMVersion, 32, \"%d.%d%d%c%d\",\n\t\t\tprg->ver, prg->rev, prg->lev,\n\t\t\tdist, prg->num);\n\tmempool_free(pmboxq, phba->mbox_mem_pool);\n\treturn;\n}\n\n/**\n * lpfc_update_vport_wwn - Updates the fc_nodename, fc_portname,\n *\tcfg_soft_wwnn, cfg_soft_wwpn\n * @vport: pointer to lpfc vport data structure.\n *\n *\n * Return codes\n *   None.\n **/\nvoid\nlpfc_update_vport_wwn(struct lpfc_vport *vport)\n{\n\tuint8_t vvvl = vport->fc_sparam.cmn.valid_vendor_ver_level;\n\tu32 *fawwpn_key = (u32 *)&vport->fc_sparam.un.vendorVersion[0];\n\n\t/* If the soft name exists then update it using the service params */\n\tif (vport->phba->cfg_soft_wwnn)\n\t\tu64_to_wwn(vport->phba->cfg_soft_wwnn,\n\t\t\t   vport->fc_sparam.nodeName.u.wwn);\n\tif (vport->phba->cfg_soft_wwpn)\n\t\tu64_to_wwn(vport->phba->cfg_soft_wwpn,\n\t\t\t   vport->fc_sparam.portName.u.wwn);\n\n\t/*\n\t * If the name is empty or there exists a soft name\n\t * then copy the service params name, otherwise use the fc name\n\t */\n\tif (vport->fc_nodename.u.wwn[0] == 0 || vport->phba->cfg_soft_wwnn)\n\t\tmemcpy(&vport->fc_nodename, &vport->fc_sparam.nodeName,\n\t\t\tsizeof(struct lpfc_name));\n\telse\n\t\tmemcpy(&vport->fc_sparam.nodeName, &vport->fc_nodename,\n\t\t\tsizeof(struct lpfc_name));\n\n\t/*\n\t * If the port name has changed, then set the Param changes flag\n\t * to unreg the login\n\t */\n\tif (vport->fc_portname.u.wwn[0] != 0 &&\n\t\tmemcmp(&vport->fc_portname, &vport->fc_sparam.portName,\n\t\t\tsizeof(struct lpfc_name)))\n\t\tvport->vport_flag |= FAWWPN_PARAM_CHG;\n\n\tif (vport->fc_portname.u.wwn[0] == 0 ||\n\t    vport->phba->cfg_soft_wwpn ||\n\t    (vvvl == 1 && cpu_to_be32(*fawwpn_key) == FAPWWN_KEY_VENDOR) ||\n\t    vport->vport_flag & FAWWPN_SET) {\n\t\tmemcpy(&vport->fc_portname, &vport->fc_sparam.portName,\n\t\t\tsizeof(struct lpfc_name));\n\t\tvport->vport_flag &= ~FAWWPN_SET;\n\t\tif (vvvl == 1 && cpu_to_be32(*fawwpn_key) == FAPWWN_KEY_VENDOR)\n\t\t\tvport->vport_flag |= FAWWPN_SET;\n\t}\n\telse\n\t\tmemcpy(&vport->fc_sparam.portName, &vport->fc_portname,\n\t\t\tsizeof(struct lpfc_name));\n}\n\n/**\n * lpfc_config_port_post - Perform lpfc initialization after config port\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine will do LPFC initialization after the CONFIG_PORT mailbox\n * command call. It performs all internal resource and state setups on the\n * port: post IOCB buffers, enable appropriate host interrupt attentions,\n * ELS ring timers, etc.\n *\n * Return codes\n *   0 - success.\n *   Any other value - error.\n **/\nint\nlpfc_config_port_post(struct lpfc_hba *phba)\n{\n\tstruct lpfc_vport *vport = phba->pport;\n\tstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\n\tLPFC_MBOXQ_t *pmb;\n\tMAILBOX_t *mb;\n\tstruct lpfc_dmabuf *mp;\n\tstruct lpfc_sli *psli = &phba->sli;\n\tuint32_t status, timeout;\n\tint i, j;\n\tint rc;\n\n\tspin_lock_irq(&phba->hbalock);\n\t/*\n\t * If the Config port completed correctly the HBA is not\n\t * over heated any more.\n\t */\n\tif (phba->over_temp_state == HBA_OVER_TEMP)\n\t\tphba->over_temp_state = HBA_NORMAL_TEMP;\n\tspin_unlock_irq(&phba->hbalock);\n\n\tpmb = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!pmb) {\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\treturn -ENOMEM;\n\t}\n\tmb = &pmb->u.mb;\n\n\t/* Get login parameters for NID.  */\n\trc = lpfc_read_sparam(phba, pmb, 0);\n\tif (rc) {\n\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\t\treturn -ENOMEM;\n\t}\n\n\tpmb->vport = vport;\n\tif (lpfc_sli_issue_mbox(phba, pmb, MBX_POLL) != MBX_SUCCESS) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0448 Adapter failed init, mbxCmd x%x \"\n\t\t\t\t\"READ_SPARM mbxStatus x%x\\n\",\n\t\t\t\tmb->mbxCommand, mb->mbxStatus);\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\tmp = (struct lpfc_dmabuf *)pmb->ctx_buf;\n\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\t\tlpfc_mbuf_free(phba, mp->virt, mp->phys);\n\t\tkfree(mp);\n\t\treturn -EIO;\n\t}\n\n\tmp = (struct lpfc_dmabuf *)pmb->ctx_buf;\n\n\tmemcpy(&vport->fc_sparam, mp->virt, sizeof (struct serv_parm));\n\tlpfc_mbuf_free(phba, mp->virt, mp->phys);\n\tkfree(mp);\n\tpmb->ctx_buf = NULL;\n\tlpfc_update_vport_wwn(vport);\n\n\t/* Update the fc_host data structures with new wwn. */\n\tfc_host_node_name(shost) = wwn_to_u64(vport->fc_nodename.u.wwn);\n\tfc_host_port_name(shost) = wwn_to_u64(vport->fc_portname.u.wwn);\n\tfc_host_max_npiv_vports(shost) = phba->max_vpi;\n\n\t/* If no serial number in VPD data, use low 6 bytes of WWNN */\n\t/* This should be consolidated into parse_vpd ? - mr */\n\tif (phba->SerialNumber[0] == 0) {\n\t\tuint8_t *outptr;\n\n\t\toutptr = &vport->fc_nodename.u.s.IEEE[0];\n\t\tfor (i = 0; i < 12; i++) {\n\t\t\tstatus = *outptr++;\n\t\t\tj = ((status & 0xf0) >> 4);\n\t\t\tif (j <= 9)\n\t\t\t\tphba->SerialNumber[i] =\n\t\t\t\t    (char)((uint8_t) 0x30 + (uint8_t) j);\n\t\t\telse\n\t\t\t\tphba->SerialNumber[i] =\n\t\t\t\t    (char)((uint8_t) 0x61 + (uint8_t) (j - 10));\n\t\t\ti++;\n\t\t\tj = (status & 0xf);\n\t\t\tif (j <= 9)\n\t\t\t\tphba->SerialNumber[i] =\n\t\t\t\t    (char)((uint8_t) 0x30 + (uint8_t) j);\n\t\t\telse\n\t\t\t\tphba->SerialNumber[i] =\n\t\t\t\t    (char)((uint8_t) 0x61 + (uint8_t) (j - 10));\n\t\t}\n\t}\n\n\tlpfc_read_config(phba, pmb);\n\tpmb->vport = vport;\n\tif (lpfc_sli_issue_mbox(phba, pmb, MBX_POLL) != MBX_SUCCESS) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0453 Adapter failed to init, mbxCmd x%x \"\n\t\t\t\t\"READ_CONFIG, mbxStatus x%x\\n\",\n\t\t\t\tmb->mbxCommand, mb->mbxStatus);\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\tmempool_free( pmb, phba->mbox_mem_pool);\n\t\treturn -EIO;\n\t}\n\n\t/* Check if the port is disabled */\n\tlpfc_sli_read_link_ste(phba);\n\n\t/* Reset the DFT_HBA_Q_DEPTH to the max xri  */\n\tif (phba->cfg_hba_queue_depth > mb->un.varRdConfig.max_xri) {\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\"3359 HBA queue depth changed from %d to %d\\n\",\n\t\t\t\tphba->cfg_hba_queue_depth,\n\t\t\t\tmb->un.varRdConfig.max_xri);\n\t\tphba->cfg_hba_queue_depth = mb->un.varRdConfig.max_xri;\n\t}\n\n\tphba->lmt = mb->un.varRdConfig.lmt;\n\n\t/* Get the default values for Model Name and Description */\n\tlpfc_get_hba_model_desc(phba, phba->ModelName, phba->ModelDesc);\n\n\tphba->link_state = LPFC_LINK_DOWN;\n\n\t/* Only process IOCBs on ELS ring till hba_state is READY */\n\tif (psli->sli3_ring[LPFC_EXTRA_RING].sli.sli3.cmdringaddr)\n\t\tpsli->sli3_ring[LPFC_EXTRA_RING].flag |= LPFC_STOP_IOCB_EVENT;\n\tif (psli->sli3_ring[LPFC_FCP_RING].sli.sli3.cmdringaddr)\n\t\tpsli->sli3_ring[LPFC_FCP_RING].flag |= LPFC_STOP_IOCB_EVENT;\n\n\t/* Post receive buffers for desired rings */\n\tif (phba->sli_rev != 3)\n\t\tlpfc_post_rcv_buf(phba);\n\n\t/*\n\t * Configure HBA MSI-X attention conditions to messages if MSI-X mode\n\t */\n\tif (phba->intr_type == MSIX) {\n\t\trc = lpfc_config_msi(phba, pmb);\n\t\tif (rc) {\n\t\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\t\t\treturn -EIO;\n\t\t}\n\t\trc = lpfc_sli_issue_mbox(phba, pmb, MBX_POLL);\n\t\tif (rc != MBX_SUCCESS) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0352 Config MSI mailbox command \"\n\t\t\t\t\t\"failed, mbxCmd x%x, mbxStatus x%x\\n\",\n\t\t\t\t\tpmb->u.mb.mbxCommand,\n\t\t\t\t\tpmb->u.mb.mbxStatus);\n\t\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\t\t\treturn -EIO;\n\t\t}\n\t}\n\n\tspin_lock_irq(&phba->hbalock);\n\t/* Initialize ERATT handling flag */\n\tphba->hba_flag &= ~HBA_ERATT_HANDLED;\n\n\t/* Enable appropriate host interrupts */\n\tif (lpfc_readl(phba->HCregaddr, &status)) {\n\t\tspin_unlock_irq(&phba->hbalock);\n\t\treturn -EIO;\n\t}\n\tstatus |= HC_MBINT_ENA | HC_ERINT_ENA | HC_LAINT_ENA;\n\tif (psli->num_rings > 0)\n\t\tstatus |= HC_R0INT_ENA;\n\tif (psli->num_rings > 1)\n\t\tstatus |= HC_R1INT_ENA;\n\tif (psli->num_rings > 2)\n\t\tstatus |= HC_R2INT_ENA;\n\tif (psli->num_rings > 3)\n\t\tstatus |= HC_R3INT_ENA;\n\n\tif ((phba->cfg_poll & ENABLE_FCP_RING_POLLING) &&\n\t    (phba->cfg_poll & DISABLE_FCP_RING_INT))\n\t\tstatus &= ~(HC_R0INT_ENA);\n\n\twritel(status, phba->HCregaddr);\n\treadl(phba->HCregaddr); /* flush */\n\tspin_unlock_irq(&phba->hbalock);\n\n\t/* Set up ring-0 (ELS) timer */\n\ttimeout = phba->fc_ratov * 2;\n\tmod_timer(&vport->els_tmofunc,\n\t\t  jiffies + msecs_to_jiffies(1000 * timeout));\n\t/* Set up heart beat (HB) timer */\n\tmod_timer(&phba->hb_tmofunc,\n\t\t  jiffies + msecs_to_jiffies(1000 * LPFC_HB_MBOX_INTERVAL));\n\tphba->hba_flag &= ~(HBA_HBEAT_INP | HBA_HBEAT_TMO);\n\tphba->last_completion_time = jiffies;\n\t/* Set up error attention (ERATT) polling timer */\n\tmod_timer(&phba->eratt_poll,\n\t\t  jiffies + msecs_to_jiffies(1000 * phba->eratt_poll_interval));\n\n\tif (phba->hba_flag & LINK_DISABLED) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2598 Adapter Link is disabled.\\n\");\n\t\tlpfc_down_link(phba, pmb);\n\t\tpmb->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\n\t\trc = lpfc_sli_issue_mbox(phba, pmb, MBX_NOWAIT);\n\t\tif ((rc != MBX_SUCCESS) && (rc != MBX_BUSY)) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"2599 Adapter failed to issue DOWN_LINK\"\n\t\t\t\t\t\" mbox command rc 0x%x\\n\", rc);\n\n\t\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\t\t\treturn -EIO;\n\t\t}\n\t} else if (phba->cfg_suppress_link_up == LPFC_INITIALIZE_LINK) {\n\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\t\trc = phba->lpfc_hba_init_link(phba, MBX_NOWAIT);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\t/* MBOX buffer will be freed in mbox compl */\n\tpmb = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!pmb) {\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\treturn -ENOMEM;\n\t}\n\n\tlpfc_config_async(phba, pmb, LPFC_ELS_RING);\n\tpmb->mbox_cmpl = lpfc_config_async_cmpl;\n\tpmb->vport = phba->pport;\n\trc = lpfc_sli_issue_mbox(phba, pmb, MBX_NOWAIT);\n\n\tif ((rc != MBX_BUSY) && (rc != MBX_SUCCESS)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0456 Adapter failed to issue \"\n\t\t\t\t\"ASYNCEVT_ENABLE mbox status x%x\\n\",\n\t\t\t\trc);\n\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\t}\n\n\t/* Get Option rom version */\n\tpmb = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!pmb) {\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\treturn -ENOMEM;\n\t}\n\n\tlpfc_dump_wakeup_param(phba, pmb);\n\tpmb->mbox_cmpl = lpfc_dump_wakeup_param_cmpl;\n\tpmb->vport = phba->pport;\n\trc = lpfc_sli_issue_mbox(phba, pmb, MBX_NOWAIT);\n\n\tif ((rc != MBX_BUSY) && (rc != MBX_SUCCESS)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0435 Adapter failed \"\n\t\t\t\t\"to get Option ROM version status x%x\\n\", rc);\n\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\t}\n\n\treturn 0;\n}\n\n/**\n * lpfc_hba_init_link - Initialize the FC link\n * @phba: pointer to lpfc hba data structure.\n * @flag: mailbox command issue mode - either MBX_POLL or MBX_NOWAIT\n *\n * This routine will issue the INIT_LINK mailbox command call.\n * It is available to other drivers through the lpfc_hba data\n * structure for use as a delayed link up mechanism with the\n * module parameter lpfc_suppress_link_up.\n *\n * Return code\n *\t\t0 - success\n *\t\tAny other value - error\n **/\nstatic int\nlpfc_hba_init_link(struct lpfc_hba *phba, uint32_t flag)\n{\n\treturn lpfc_hba_init_link_fc_topology(phba, phba->cfg_topology, flag);\n}\n\n/**\n * lpfc_hba_init_link_fc_topology - Initialize FC link with desired topology\n * @phba: pointer to lpfc hba data structure.\n * @fc_topology: desired fc topology.\n * @flag: mailbox command issue mode - either MBX_POLL or MBX_NOWAIT\n *\n * This routine will issue the INIT_LINK mailbox command call.\n * It is available to other drivers through the lpfc_hba data\n * structure for use as a delayed link up mechanism with the\n * module parameter lpfc_suppress_link_up.\n *\n * Return code\n *              0 - success\n *              Any other value - error\n **/\nint\nlpfc_hba_init_link_fc_topology(struct lpfc_hba *phba, uint32_t fc_topology,\n\t\t\t       uint32_t flag)\n{\n\tstruct lpfc_vport *vport = phba->pport;\n\tLPFC_MBOXQ_t *pmb;\n\tMAILBOX_t *mb;\n\tint rc;\n\n\tpmb = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!pmb) {\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\treturn -ENOMEM;\n\t}\n\tmb = &pmb->u.mb;\n\tpmb->vport = vport;\n\n\tif ((phba->cfg_link_speed > LPFC_USER_LINK_SPEED_MAX) ||\n\t    ((phba->cfg_link_speed == LPFC_USER_LINK_SPEED_1G) &&\n\t     !(phba->lmt & LMT_1Gb)) ||\n\t    ((phba->cfg_link_speed == LPFC_USER_LINK_SPEED_2G) &&\n\t     !(phba->lmt & LMT_2Gb)) ||\n\t    ((phba->cfg_link_speed == LPFC_USER_LINK_SPEED_4G) &&\n\t     !(phba->lmt & LMT_4Gb)) ||\n\t    ((phba->cfg_link_speed == LPFC_USER_LINK_SPEED_8G) &&\n\t     !(phba->lmt & LMT_8Gb)) ||\n\t    ((phba->cfg_link_speed == LPFC_USER_LINK_SPEED_10G) &&\n\t     !(phba->lmt & LMT_10Gb)) ||\n\t    ((phba->cfg_link_speed == LPFC_USER_LINK_SPEED_16G) &&\n\t     !(phba->lmt & LMT_16Gb)) ||\n\t    ((phba->cfg_link_speed == LPFC_USER_LINK_SPEED_32G) &&\n\t     !(phba->lmt & LMT_32Gb)) ||\n\t    ((phba->cfg_link_speed == LPFC_USER_LINK_SPEED_64G) &&\n\t     !(phba->lmt & LMT_64Gb))) {\n\t\t/* Reset link speed to auto */\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"1302 Invalid speed for this board:%d \"\n\t\t\t\t\"Reset link speed to auto.\\n\",\n\t\t\t\tphba->cfg_link_speed);\n\t\t\tphba->cfg_link_speed = LPFC_USER_LINK_SPEED_AUTO;\n\t}\n\tlpfc_init_link(phba, pmb, fc_topology, phba->cfg_link_speed);\n\tpmb->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\n\tif (phba->sli_rev < LPFC_SLI_REV4)\n\t\tlpfc_set_loopback_flag(phba);\n\trc = lpfc_sli_issue_mbox(phba, pmb, flag);\n\tif ((rc != MBX_BUSY) && (rc != MBX_SUCCESS)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0498 Adapter failed to init, mbxCmd x%x \"\n\t\t\t\t\"INIT_LINK, mbxStatus x%x\\n\",\n\t\t\t\tmb->mbxCommand, mb->mbxStatus);\n\t\tif (phba->sli_rev <= LPFC_SLI_REV3) {\n\t\t\t/* Clear all interrupt enable conditions */\n\t\t\twritel(0, phba->HCregaddr);\n\t\t\treadl(phba->HCregaddr); /* flush */\n\t\t\t/* Clear all pending interrupts */\n\t\t\twritel(0xffffffff, phba->HAregaddr);\n\t\t\treadl(phba->HAregaddr); /* flush */\n\t\t}\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\tif (rc != MBX_BUSY || flag == MBX_POLL)\n\t\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\t\treturn -EIO;\n\t}\n\tphba->cfg_suppress_link_up = LPFC_INITIALIZE_LINK;\n\tif (flag == MBX_POLL)\n\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\n\treturn 0;\n}\n\n/**\n * lpfc_hba_down_link - this routine downs the FC link\n * @phba: pointer to lpfc hba data structure.\n * @flag: mailbox command issue mode - either MBX_POLL or MBX_NOWAIT\n *\n * This routine will issue the DOWN_LINK mailbox command call.\n * It is available to other drivers through the lpfc_hba data\n * structure for use to stop the link.\n *\n * Return code\n *\t\t0 - success\n *\t\tAny other value - error\n **/\nstatic int\nlpfc_hba_down_link(struct lpfc_hba *phba, uint32_t flag)\n{\n\tLPFC_MBOXQ_t *pmb;\n\tint rc;\n\n\tpmb = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!pmb) {\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\treturn -ENOMEM;\n\t}\n\n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"0491 Adapter Link is disabled.\\n\");\n\tlpfc_down_link(phba, pmb);\n\tpmb->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\n\trc = lpfc_sli_issue_mbox(phba, pmb, flag);\n\tif ((rc != MBX_SUCCESS) && (rc != MBX_BUSY)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2522 Adapter failed to issue DOWN_LINK\"\n\t\t\t\t\" mbox command rc 0x%x\\n\", rc);\n\n\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\t\treturn -EIO;\n\t}\n\tif (flag == MBX_POLL)\n\t\tmempool_free(pmb, phba->mbox_mem_pool);\n\n\treturn 0;\n}\n\n/**\n * lpfc_hba_down_prep - Perform lpfc uninitialization prior to HBA reset\n * @phba: pointer to lpfc HBA data structure.\n *\n * This routine will do LPFC uninitialization before the HBA is reset when\n * bringing down the SLI Layer.\n *\n * Return codes\n *   0 - success.\n *   Any other value - error.\n **/\nint\nlpfc_hba_down_prep(struct lpfc_hba *phba)\n{\n\tstruct lpfc_vport **vports;\n\tint i;\n\n\tif (phba->sli_rev <= LPFC_SLI_REV3) {\n\t\t/* Disable interrupts */\n\t\twritel(0, phba->HCregaddr);\n\t\treadl(phba->HCregaddr); /* flush */\n\t}\n\n\tif (phba->pport->load_flag & FC_UNLOADING)\n\t\tlpfc_cleanup_discovery_resources(phba->pport);\n\telse {\n\t\tvports = lpfc_create_vport_work_array(phba);\n\t\tif (vports != NULL)\n\t\t\tfor (i = 0; i <= phba->max_vports &&\n\t\t\t\tvports[i] != NULL; i++)\n\t\t\t\tlpfc_cleanup_discovery_resources(vports[i]);\n\t\tlpfc_destroy_vport_work_array(phba, vports);\n\t}\n\treturn 0;\n}\n\n/**\n * lpfc_sli4_free_sp_events - Cleanup sp_queue_events to free\n * rspiocb which got deferred\n *\n * @phba: pointer to lpfc HBA data structure.\n *\n * This routine will cleanup completed slow path events after HBA is reset\n * when bringing down the SLI Layer.\n *\n *\n * Return codes\n *   void.\n **/\nstatic void\nlpfc_sli4_free_sp_events(struct lpfc_hba *phba)\n{\n\tstruct lpfc_iocbq *rspiocbq;\n\tstruct hbq_dmabuf *dmabuf;\n\tstruct lpfc_cq_event *cq_event;\n\n\tspin_lock_irq(&phba->hbalock);\n\tphba->hba_flag &= ~HBA_SP_QUEUE_EVT;\n\tspin_unlock_irq(&phba->hbalock);\n\n\twhile (!list_empty(&phba->sli4_hba.sp_queue_event)) {\n\t\t/* Get the response iocb from the head of work queue */\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tlist_remove_head(&phba->sli4_hba.sp_queue_event,\n\t\t\t\t cq_event, struct lpfc_cq_event, list);\n\t\tspin_unlock_irq(&phba->hbalock);\n\n\t\tswitch (bf_get(lpfc_wcqe_c_code, &cq_event->cqe.wcqe_cmpl)) {\n\t\tcase CQE_CODE_COMPL_WQE:\n\t\t\trspiocbq = container_of(cq_event, struct lpfc_iocbq,\n\t\t\t\t\t\t cq_event);\n\t\t\tlpfc_sli_release_iocbq(phba, rspiocbq);\n\t\t\tbreak;\n\t\tcase CQE_CODE_RECEIVE:\n\t\tcase CQE_CODE_RECEIVE_V1:\n\t\t\tdmabuf = container_of(cq_event, struct hbq_dmabuf,\n\t\t\t\t\t      cq_event);\n\t\t\tlpfc_in_buf_free(phba, &dmabuf->dbuf);\n\t\t}\n\t}\n}\n\n/**\n * lpfc_hba_free_post_buf - Perform lpfc uninitialization after HBA reset\n * @phba: pointer to lpfc HBA data structure.\n *\n * This routine will cleanup posted ELS buffers after the HBA is reset\n * when bringing down the SLI Layer.\n *\n *\n * Return codes\n *   void.\n **/\nstatic void\nlpfc_hba_free_post_buf(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli *psli = &phba->sli;\n\tstruct lpfc_sli_ring *pring;\n\tstruct lpfc_dmabuf *mp, *next_mp;\n\tLIST_HEAD(buflist);\n\tint count;\n\n\tif (phba->sli3_options & LPFC_SLI3_HBQ_ENABLED)\n\t\tlpfc_sli_hbqbuf_free_all(phba);\n\telse {\n\t\t/* Cleanup preposted buffers on the ELS ring */\n\t\tpring = &psli->sli3_ring[LPFC_ELS_RING];\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tlist_splice_init(&pring->postbufq, &buflist);\n\t\tspin_unlock_irq(&phba->hbalock);\n\n\t\tcount = 0;\n\t\tlist_for_each_entry_safe(mp, next_mp, &buflist, list) {\n\t\t\tlist_del(&mp->list);\n\t\t\tcount++;\n\t\t\tlpfc_mbuf_free(phba, mp->virt, mp->phys);\n\t\t\tkfree(mp);\n\t\t}\n\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tpring->postbufq_cnt -= count;\n\t\tspin_unlock_irq(&phba->hbalock);\n\t}\n}\n\n/**\n * lpfc_hba_clean_txcmplq - Perform lpfc uninitialization after HBA reset\n * @phba: pointer to lpfc HBA data structure.\n *\n * This routine will cleanup the txcmplq after the HBA is reset when bringing\n * down the SLI Layer.\n *\n * Return codes\n *   void\n **/\nstatic void\nlpfc_hba_clean_txcmplq(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli *psli = &phba->sli;\n\tstruct lpfc_queue *qp = NULL;\n\tstruct lpfc_sli_ring *pring;\n\tLIST_HEAD(completions);\n\tint i;\n\tstruct lpfc_iocbq *piocb, *next_iocb;\n\n\tif (phba->sli_rev != LPFC_SLI_REV4) {\n\t\tfor (i = 0; i < psli->num_rings; i++) {\n\t\t\tpring = &psli->sli3_ring[i];\n\t\t\tspin_lock_irq(&phba->hbalock);\n\t\t\t/* At this point in time the HBA is either reset or DOA\n\t\t\t * Nothing should be on txcmplq as it will\n\t\t\t * NEVER complete.\n\t\t\t */\n\t\t\tlist_splice_init(&pring->txcmplq, &completions);\n\t\t\tpring->txcmplq_cnt = 0;\n\t\t\tspin_unlock_irq(&phba->hbalock);\n\n\t\t\tlpfc_sli_abort_iocb_ring(phba, pring);\n\t\t}\n\t\t/* Cancel all the IOCBs from the completions list */\n\t\tlpfc_sli_cancel_iocbs(phba, &completions,\n\t\t\t\t      IOSTAT_LOCAL_REJECT, IOERR_SLI_ABORTED);\n\t\treturn;\n\t}\n\tlist_for_each_entry(qp, &phba->sli4_hba.lpfc_wq_list, wq_list) {\n\t\tpring = qp->pring;\n\t\tif (!pring)\n\t\t\tcontinue;\n\t\tspin_lock_irq(&pring->ring_lock);\n\t\tlist_for_each_entry_safe(piocb, next_iocb,\n\t\t\t\t\t &pring->txcmplq, list)\n\t\t\tpiocb->iocb_flag &= ~LPFC_IO_ON_TXCMPLQ;\n\t\tlist_splice_init(&pring->txcmplq, &completions);\n\t\tpring->txcmplq_cnt = 0;\n\t\tspin_unlock_irq(&pring->ring_lock);\n\t\tlpfc_sli_abort_iocb_ring(phba, pring);\n\t}\n\t/* Cancel all the IOCBs from the completions list */\n\tlpfc_sli_cancel_iocbs(phba, &completions,\n\t\t\t      IOSTAT_LOCAL_REJECT, IOERR_SLI_ABORTED);\n}\n\n/**\n * lpfc_hba_down_post_s3 - Perform lpfc uninitialization after HBA reset\n * @phba: pointer to lpfc HBA data structure.\n *\n * This routine will do uninitialization after the HBA is reset when bring\n * down the SLI Layer.\n *\n * Return codes\n *   0 - success.\n *   Any other value - error.\n **/\nstatic int\nlpfc_hba_down_post_s3(struct lpfc_hba *phba)\n{\n\tlpfc_hba_free_post_buf(phba);\n\tlpfc_hba_clean_txcmplq(phba);\n\treturn 0;\n}\n\n/**\n * lpfc_hba_down_post_s4 - Perform lpfc uninitialization after HBA reset\n * @phba: pointer to lpfc HBA data structure.\n *\n * This routine will do uninitialization after the HBA is reset when bring\n * down the SLI Layer.\n *\n * Return codes\n *   0 - success.\n *   Any other value - error.\n **/\nstatic int\nlpfc_hba_down_post_s4(struct lpfc_hba *phba)\n{\n\tstruct lpfc_io_buf *psb, *psb_next;\n\tstruct lpfc_async_xchg_ctx *ctxp, *ctxp_next;\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tLIST_HEAD(aborts);\n\tLIST_HEAD(nvme_aborts);\n\tLIST_HEAD(nvmet_aborts);\n\tstruct lpfc_sglq *sglq_entry = NULL;\n\tint cnt, idx;\n\n\n\tlpfc_sli_hbqbuf_free_all(phba);\n\tlpfc_hba_clean_txcmplq(phba);\n\n\t/* At this point in time the HBA is either reset or DOA. Either\n\t * way, nothing should be on lpfc_abts_els_sgl_list, it needs to be\n\t * on the lpfc_els_sgl_list so that it can either be freed if the\n\t * driver is unloading or reposted if the driver is restarting\n\t * the port.\n\t */\n\tspin_lock_irq(&phba->hbalock);  /* required for lpfc_els_sgl_list and */\n\t\t\t\t\t/* scsl_buf_list */\n\t/* sgl_list_lock required because worker thread uses this\n\t * list.\n\t */\n\tspin_lock(&phba->sli4_hba.sgl_list_lock);\n\tlist_for_each_entry(sglq_entry,\n\t\t&phba->sli4_hba.lpfc_abts_els_sgl_list, list)\n\t\tsglq_entry->state = SGL_FREED;\n\n\tlist_splice_init(&phba->sli4_hba.lpfc_abts_els_sgl_list,\n\t\t\t&phba->sli4_hba.lpfc_els_sgl_list);\n\n\n\tspin_unlock(&phba->sli4_hba.sgl_list_lock);\n\n\t/* abts_xxxx_buf_list_lock required because worker thread uses this\n\t * list.\n\t */\n\tcnt = 0;\n\tfor (idx = 0; idx < phba->cfg_hdw_queue; idx++) {\n\t\tqp = &phba->sli4_hba.hdwq[idx];\n\n\t\tspin_lock(&qp->abts_io_buf_list_lock);\n\t\tlist_splice_init(&qp->lpfc_abts_io_buf_list,\n\t\t\t\t &aborts);\n\n\t\tlist_for_each_entry_safe(psb, psb_next, &aborts, list) {\n\t\t\tpsb->pCmd = NULL;\n\t\t\tpsb->status = IOSTAT_SUCCESS;\n\t\t\tcnt++;\n\t\t}\n\t\tspin_lock(&qp->io_buf_list_put_lock);\n\t\tlist_splice_init(&aborts, &qp->lpfc_io_buf_list_put);\n\t\tqp->put_io_bufs += qp->abts_scsi_io_bufs;\n\t\tqp->put_io_bufs += qp->abts_nvme_io_bufs;\n\t\tqp->abts_scsi_io_bufs = 0;\n\t\tqp->abts_nvme_io_bufs = 0;\n\t\tspin_unlock(&qp->io_buf_list_put_lock);\n\t\tspin_unlock(&qp->abts_io_buf_list_lock);\n\t}\n\tspin_unlock_irq(&phba->hbalock);\n\n\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME) {\n\t\tspin_lock_irq(&phba->sli4_hba.abts_nvmet_buf_list_lock);\n\t\tlist_splice_init(&phba->sli4_hba.lpfc_abts_nvmet_ctx_list,\n\t\t\t\t &nvmet_aborts);\n\t\tspin_unlock_irq(&phba->sli4_hba.abts_nvmet_buf_list_lock);\n\t\tlist_for_each_entry_safe(ctxp, ctxp_next, &nvmet_aborts, list) {\n\t\t\tctxp->flag &= ~(LPFC_NVME_XBUSY | LPFC_NVME_ABORT_OP);\n\t\t\tlpfc_nvmet_ctxbuf_post(phba, ctxp->ctxbuf);\n\t\t}\n\t}\n\n\tlpfc_sli4_free_sp_events(phba);\n\treturn cnt;\n}\n\n/**\n * lpfc_hba_down_post - Wrapper func for hba down post routine\n * @phba: pointer to lpfc HBA data structure.\n *\n * This routine wraps the actual SLI3 or SLI4 routine for performing\n * uninitialization after the HBA is reset when bring down the SLI Layer.\n *\n * Return codes\n *   0 - success.\n *   Any other value - error.\n **/\nint\nlpfc_hba_down_post(struct lpfc_hba *phba)\n{\n\treturn (*phba->lpfc_hba_down_post)(phba);\n}\n\n/**\n * lpfc_hb_timeout - The HBA-timer timeout handler\n * @t: timer context used to obtain the pointer to lpfc hba data structure.\n *\n * This is the HBA-timer timeout handler registered to the lpfc driver. When\n * this timer fires, a HBA timeout event shall be posted to the lpfc driver\n * work-port-events bitmap and the worker thread is notified. This timeout\n * event will be used by the worker thread to invoke the actual timeout\n * handler routine, lpfc_hb_timeout_handler. Any periodical operations will\n * be performed in the timeout handler and the HBA timeout event bit shall\n * be cleared by the worker thread after it has taken the event bitmap out.\n **/\nstatic void\nlpfc_hb_timeout(struct timer_list *t)\n{\n\tstruct lpfc_hba *phba;\n\tuint32_t tmo_posted;\n\tunsigned long iflag;\n\n\tphba = from_timer(phba, t, hb_tmofunc);\n\n\t/* Check for heart beat timeout conditions */\n\tspin_lock_irqsave(&phba->pport->work_port_lock, iflag);\n\ttmo_posted = phba->pport->work_port_events & WORKER_HB_TMO;\n\tif (!tmo_posted)\n\t\tphba->pport->work_port_events |= WORKER_HB_TMO;\n\tspin_unlock_irqrestore(&phba->pport->work_port_lock, iflag);\n\n\t/* Tell the worker thread there is work to do */\n\tif (!tmo_posted)\n\t\tlpfc_worker_wake_up(phba);\n\treturn;\n}\n\n/**\n * lpfc_rrq_timeout - The RRQ-timer timeout handler\n * @t: timer context used to obtain the pointer to lpfc hba data structure.\n *\n * This is the RRQ-timer timeout handler registered to the lpfc driver. When\n * this timer fires, a RRQ timeout event shall be posted to the lpfc driver\n * work-port-events bitmap and the worker thread is notified. This timeout\n * event will be used by the worker thread to invoke the actual timeout\n * handler routine, lpfc_rrq_handler. Any periodical operations will\n * be performed in the timeout handler and the RRQ timeout event bit shall\n * be cleared by the worker thread after it has taken the event bitmap out.\n **/\nstatic void\nlpfc_rrq_timeout(struct timer_list *t)\n{\n\tstruct lpfc_hba *phba;\n\tunsigned long iflag;\n\n\tphba = from_timer(phba, t, rrq_tmr);\n\tspin_lock_irqsave(&phba->pport->work_port_lock, iflag);\n\tif (!(phba->pport->load_flag & FC_UNLOADING))\n\t\tphba->hba_flag |= HBA_RRQ_ACTIVE;\n\telse\n\t\tphba->hba_flag &= ~HBA_RRQ_ACTIVE;\n\tspin_unlock_irqrestore(&phba->pport->work_port_lock, iflag);\n\n\tif (!(phba->pport->load_flag & FC_UNLOADING))\n\t\tlpfc_worker_wake_up(phba);\n}\n\n/**\n * lpfc_hb_mbox_cmpl - The lpfc heart-beat mailbox command callback function\n * @phba: pointer to lpfc hba data structure.\n * @pmboxq: pointer to the driver internal queue element for mailbox command.\n *\n * This is the callback function to the lpfc heart-beat mailbox command.\n * If configured, the lpfc driver issues the heart-beat mailbox command to\n * the HBA every LPFC_HB_MBOX_INTERVAL (current 5) seconds. At the time the\n * heart-beat mailbox command is issued, the driver shall set up heart-beat\n * timeout timer to LPFC_HB_MBOX_TIMEOUT (current 30) seconds and marks\n * heart-beat outstanding state. Once the mailbox command comes back and\n * no error conditions detected, the heart-beat mailbox command timer is\n * reset to LPFC_HB_MBOX_INTERVAL seconds and the heart-beat outstanding\n * state is cleared for the next heart-beat. If the timer expired with the\n * heart-beat outstanding state set, the driver will put the HBA offline.\n **/\nstatic void\nlpfc_hb_mbox_cmpl(struct lpfc_hba * phba, LPFC_MBOXQ_t * pmboxq)\n{\n\tunsigned long drvr_flag;\n\n\tspin_lock_irqsave(&phba->hbalock, drvr_flag);\n\tphba->hba_flag &= ~(HBA_HBEAT_INP | HBA_HBEAT_TMO);\n\tspin_unlock_irqrestore(&phba->hbalock, drvr_flag);\n\n\t/* Check and reset heart-beat timer if necessary */\n\tmempool_free(pmboxq, phba->mbox_mem_pool);\n\tif (!(phba->pport->fc_flag & FC_OFFLINE_MODE) &&\n\t\t!(phba->link_state == LPFC_HBA_ERROR) &&\n\t\t!(phba->pport->load_flag & FC_UNLOADING))\n\t\tmod_timer(&phba->hb_tmofunc,\n\t\t\t  jiffies +\n\t\t\t  msecs_to_jiffies(1000 * LPFC_HB_MBOX_INTERVAL));\n\treturn;\n}\n\n/*\n * lpfc_idle_stat_delay_work - idle_stat tracking\n *\n * This routine tracks per-cq idle_stat and determines polling decisions.\n *\n * Return codes:\n *   None\n **/\nstatic void\nlpfc_idle_stat_delay_work(struct work_struct *work)\n{\n\tstruct lpfc_hba *phba = container_of(to_delayed_work(work),\n\t\t\t\t\t     struct lpfc_hba,\n\t\t\t\t\t     idle_stat_delay_work);\n\tstruct lpfc_queue *cq;\n\tstruct lpfc_sli4_hdw_queue *hdwq;\n\tstruct lpfc_idle_stat *idle_stat;\n\tu32 i, idle_percent;\n\tu64 wall, wall_idle, diff_wall, diff_idle, busy_time;\n\n\tif (phba->pport->load_flag & FC_UNLOADING)\n\t\treturn;\n\n\tif (phba->link_state == LPFC_HBA_ERROR ||\n\t    phba->pport->fc_flag & FC_OFFLINE_MODE)\n\t\tgoto requeue;\n\n\tfor_each_present_cpu(i) {\n\t\thdwq = &phba->sli4_hba.hdwq[phba->sli4_hba.cpu_map[i].hdwq];\n\t\tcq = hdwq->io_cq;\n\n\t\t/* Skip if we've already handled this cq's primary CPU */\n\t\tif (cq->chann != i)\n\t\t\tcontinue;\n\n\t\tidle_stat = &phba->sli4_hba.idle_stat[i];\n\n\t\t/* get_cpu_idle_time returns values as running counters. Thus,\n\t\t * to know the amount for this period, the prior counter values\n\t\t * need to be subtracted from the current counter values.\n\t\t * From there, the idle time stat can be calculated as a\n\t\t * percentage of 100 - the sum of the other consumption times.\n\t\t */\n\t\twall_idle = get_cpu_idle_time(i, &wall, 1);\n\t\tdiff_idle = wall_idle - idle_stat->prev_idle;\n\t\tdiff_wall = wall - idle_stat->prev_wall;\n\n\t\tif (diff_wall <= diff_idle)\n\t\t\tbusy_time = 0;\n\t\telse\n\t\t\tbusy_time = diff_wall - diff_idle;\n\n\t\tidle_percent = div64_u64(100 * busy_time, diff_wall);\n\t\tidle_percent = 100 - idle_percent;\n\n\t\tif (idle_percent < 15)\n\t\t\tcq->poll_mode = LPFC_QUEUE_WORK;\n\t\telse\n\t\t\tcq->poll_mode = LPFC_IRQ_POLL;\n\n\t\tidle_stat->prev_idle = wall_idle;\n\t\tidle_stat->prev_wall = wall;\n\t}\n\nrequeue:\n\tschedule_delayed_work(&phba->idle_stat_delay_work,\n\t\t\t      msecs_to_jiffies(LPFC_IDLE_STAT_DELAY));\n}\n\nstatic void\nlpfc_hb_eq_delay_work(struct work_struct *work)\n{\n\tstruct lpfc_hba *phba = container_of(to_delayed_work(work),\n\t\t\t\t\t     struct lpfc_hba, eq_delay_work);\n\tstruct lpfc_eq_intr_info *eqi, *eqi_new;\n\tstruct lpfc_queue *eq, *eq_next;\n\tunsigned char *ena_delay = NULL;\n\tuint32_t usdelay;\n\tint i;\n\n\tif (!phba->cfg_auto_imax || phba->pport->load_flag & FC_UNLOADING)\n\t\treturn;\n\n\tif (phba->link_state == LPFC_HBA_ERROR ||\n\t    phba->pport->fc_flag & FC_OFFLINE_MODE)\n\t\tgoto requeue;\n\n\tena_delay = kcalloc(phba->sli4_hba.num_possible_cpu, sizeof(*ena_delay),\n\t\t\t    GFP_KERNEL);\n\tif (!ena_delay)\n\t\tgoto requeue;\n\n\tfor (i = 0; i < phba->cfg_irq_chann; i++) {\n\t\t/* Get the EQ corresponding to the IRQ vector */\n\t\teq = phba->sli4_hba.hba_eq_hdl[i].eq;\n\t\tif (!eq)\n\t\t\tcontinue;\n\t\tif (eq->q_mode || eq->q_flag & HBA_EQ_DELAY_CHK) {\n\t\t\teq->q_flag &= ~HBA_EQ_DELAY_CHK;\n\t\t\tena_delay[eq->last_cpu] = 1;\n\t\t}\n\t}\n\n\tfor_each_present_cpu(i) {\n\t\teqi = per_cpu_ptr(phba->sli4_hba.eq_info, i);\n\t\tif (ena_delay[i]) {\n\t\t\tusdelay = (eqi->icnt >> 10) * LPFC_EQ_DELAY_STEP;\n\t\t\tif (usdelay > LPFC_MAX_AUTO_EQ_DELAY)\n\t\t\t\tusdelay = LPFC_MAX_AUTO_EQ_DELAY;\n\t\t} else {\n\t\t\tusdelay = 0;\n\t\t}\n\n\t\teqi->icnt = 0;\n\n\t\tlist_for_each_entry_safe(eq, eq_next, &eqi->list, cpu_list) {\n\t\t\tif (unlikely(eq->last_cpu != i)) {\n\t\t\t\teqi_new = per_cpu_ptr(phba->sli4_hba.eq_info,\n\t\t\t\t\t\t      eq->last_cpu);\n\t\t\t\tlist_move_tail(&eq->cpu_list, &eqi_new->list);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (usdelay != eq->q_mode)\n\t\t\t\tlpfc_modify_hba_eq_delay(phba, eq->hdwq, 1,\n\t\t\t\t\t\t\t usdelay);\n\t\t}\n\t}\n\n\tkfree(ena_delay);\n\nrequeue:\n\tqueue_delayed_work(phba->wq, &phba->eq_delay_work,\n\t\t\t   msecs_to_jiffies(LPFC_EQ_DELAY_MSECS));\n}\n\n/**\n * lpfc_hb_mxp_handler - Multi-XRI pools handler to adjust XRI distribution\n * @phba: pointer to lpfc hba data structure.\n *\n * For each heartbeat, this routine does some heuristic methods to adjust\n * XRI distribution. The goal is to fully utilize free XRIs.\n **/\nstatic void lpfc_hb_mxp_handler(struct lpfc_hba *phba)\n{\n\tu32 i;\n\tu32 hwq_count;\n\n\thwq_count = phba->cfg_hdw_queue;\n\tfor (i = 0; i < hwq_count; i++) {\n\t\t/* Adjust XRIs in private pool */\n\t\tlpfc_adjust_pvt_pool_count(phba, i);\n\n\t\t/* Adjust high watermark */\n\t\tlpfc_adjust_high_watermark(phba, i);\n\n#ifdef LPFC_MXP_STAT\n\t\t/* Snapshot pbl, pvt and busy count */\n\t\tlpfc_snapshot_mxp(phba, i);\n#endif\n\t}\n}\n\n/**\n * lpfc_issue_hb_mbox - Issues heart-beat mailbox command\n * @phba: pointer to lpfc hba data structure.\n *\n * If a HB mbox is not already in progrees, this routine will allocate\n * a LPFC_MBOXQ_t, populate it with a MBX_HEARTBEAT (0x31) command,\n * and issue it. The HBA_HBEAT_INP flag means the command is in progress.\n **/\nint\nlpfc_issue_hb_mbox(struct lpfc_hba *phba)\n{\n\tLPFC_MBOXQ_t *pmboxq;\n\tint retval;\n\n\t/* Is a Heartbeat mbox already in progress */\n\tif (phba->hba_flag & HBA_HBEAT_INP)\n\t\treturn 0;\n\n\tpmboxq = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!pmboxq)\n\t\treturn -ENOMEM;\n\n\tlpfc_heart_beat(phba, pmboxq);\n\tpmboxq->mbox_cmpl = lpfc_hb_mbox_cmpl;\n\tpmboxq->vport = phba->pport;\n\tretval = lpfc_sli_issue_mbox(phba, pmboxq, MBX_NOWAIT);\n\n\tif (retval != MBX_BUSY && retval != MBX_SUCCESS) {\n\t\tmempool_free(pmboxq, phba->mbox_mem_pool);\n\t\treturn -ENXIO;\n\t}\n\tphba->hba_flag |= HBA_HBEAT_INP;\n\n\treturn 0;\n}\n\n/**\n * lpfc_issue_hb_tmo - Signals heartbeat timer to issue mbox command\n * @phba: pointer to lpfc hba data structure.\n *\n * The heartbeat timer (every 5 sec) will fire. If the HBA_HBEAT_TMO\n * flag is set, it will force a MBX_HEARTBEAT mbox command, regardless\n * of the value of lpfc_enable_hba_heartbeat.\n * If lpfc_enable_hba_heartbeat is set, the timeout routine will always\n * try to issue a MBX_HEARTBEAT mbox command.\n **/\nvoid\nlpfc_issue_hb_tmo(struct lpfc_hba *phba)\n{\n\tif (phba->cfg_enable_hba_heartbeat)\n\t\treturn;\n\tphba->hba_flag |= HBA_HBEAT_TMO;\n}\n\n/**\n * lpfc_hb_timeout_handler - The HBA-timer timeout handler\n * @phba: pointer to lpfc hba data structure.\n *\n * This is the actual HBA-timer timeout handler to be invoked by the worker\n * thread whenever the HBA timer fired and HBA-timeout event posted. This\n * handler performs any periodic operations needed for the device. If such\n * periodic event has already been attended to either in the interrupt handler\n * or by processing slow-ring or fast-ring events within the HBA-timer\n * timeout window (LPFC_HB_MBOX_INTERVAL), this handler just simply resets\n * the timer for the next timeout period. If lpfc heart-beat mailbox command\n * is configured and there is no heart-beat mailbox command outstanding, a\n * heart-beat mailbox is issued and timer set properly. Otherwise, if there\n * has been a heart-beat mailbox command outstanding, the HBA shall be put\n * to offline.\n **/\nvoid\nlpfc_hb_timeout_handler(struct lpfc_hba *phba)\n{\n\tstruct lpfc_vport **vports;\n\tstruct lpfc_dmabuf *buf_ptr;\n\tint retval = 0;\n\tint i, tmo;\n\tstruct lpfc_sli *psli = &phba->sli;\n\tLIST_HEAD(completions);\n\n\tif (phba->cfg_xri_rebalancing) {\n\t\t/* Multi-XRI pools handler */\n\t\tlpfc_hb_mxp_handler(phba);\n\t}\n\n\tvports = lpfc_create_vport_work_array(phba);\n\tif (vports != NULL)\n\t\tfor (i = 0; i <= phba->max_vports && vports[i] != NULL; i++) {\n\t\t\tlpfc_rcv_seq_check_edtov(vports[i]);\n\t\t\tlpfc_fdmi_change_check(vports[i]);\n\t\t}\n\tlpfc_destroy_vport_work_array(phba, vports);\n\n\tif ((phba->link_state == LPFC_HBA_ERROR) ||\n\t\t(phba->pport->load_flag & FC_UNLOADING) ||\n\t\t(phba->pport->fc_flag & FC_OFFLINE_MODE))\n\t\treturn;\n\n\tif (phba->elsbuf_cnt &&\n\t\t(phba->elsbuf_cnt == phba->elsbuf_prev_cnt)) {\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tlist_splice_init(&phba->elsbuf, &completions);\n\t\tphba->elsbuf_cnt = 0;\n\t\tphba->elsbuf_prev_cnt = 0;\n\t\tspin_unlock_irq(&phba->hbalock);\n\n\t\twhile (!list_empty(&completions)) {\n\t\t\tlist_remove_head(&completions, buf_ptr,\n\t\t\t\tstruct lpfc_dmabuf, list);\n\t\t\tlpfc_mbuf_free(phba, buf_ptr->virt, buf_ptr->phys);\n\t\t\tkfree(buf_ptr);\n\t\t}\n\t}\n\tphba->elsbuf_prev_cnt = phba->elsbuf_cnt;\n\n\t/* If there is no heart beat outstanding, issue a heartbeat command */\n\tif (phba->cfg_enable_hba_heartbeat) {\n\t\t/* If IOs are completing, no need to issue a MBX_HEARTBEAT */\n\t\tspin_lock_irq(&phba->pport->work_port_lock);\n\t\tif (time_after(phba->last_completion_time +\n\t\t\t\tmsecs_to_jiffies(1000 * LPFC_HB_MBOX_INTERVAL),\n\t\t\t\tjiffies)) {\n\t\t\tspin_unlock_irq(&phba->pport->work_port_lock);\n\t\t\tif (phba->hba_flag & HBA_HBEAT_INP)\n\t\t\t\ttmo = (1000 * LPFC_HB_MBOX_TIMEOUT);\n\t\t\telse\n\t\t\t\ttmo = (1000 * LPFC_HB_MBOX_INTERVAL);\n\t\t\tgoto out;\n\t\t}\n\t\tspin_unlock_irq(&phba->pport->work_port_lock);\n\n\t\t/* Check if a MBX_HEARTBEAT is already in progress */\n\t\tif (phba->hba_flag & HBA_HBEAT_INP) {\n\t\t\t/*\n\t\t\t * If heart beat timeout called with HBA_HBEAT_INP set\n\t\t\t * we need to give the hb mailbox cmd a chance to\n\t\t\t * complete or TMO.\n\t\t\t */\n\t\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\"0459 Adapter heartbeat still outstanding: \"\n\t\t\t\t\"last compl time was %d ms.\\n\",\n\t\t\t\tjiffies_to_msecs(jiffies\n\t\t\t\t\t - phba->last_completion_time));\n\t\t\ttmo = (1000 * LPFC_HB_MBOX_TIMEOUT);\n\t\t} else {\n\t\t\tif ((!(psli->sli_flag & LPFC_SLI_MBOX_ACTIVE)) &&\n\t\t\t\t(list_empty(&psli->mboxq))) {\n\n\t\t\t\tretval = lpfc_issue_hb_mbox(phba);\n\t\t\t\tif (retval) {\n\t\t\t\t\ttmo = (1000 * LPFC_HB_MBOX_INTERVAL);\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t\tphba->skipped_hb = 0;\n\t\t\t} else if (time_before_eq(phba->last_completion_time,\n\t\t\t\t\tphba->skipped_hb)) {\n\t\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\t\"2857 Last completion time not \"\n\t\t\t\t\t\" updated in %d ms\\n\",\n\t\t\t\t\tjiffies_to_msecs(jiffies\n\t\t\t\t\t\t - phba->last_completion_time));\n\t\t\t} else\n\t\t\t\tphba->skipped_hb = jiffies;\n\n\t\t\ttmo = (1000 * LPFC_HB_MBOX_TIMEOUT);\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\t/* Check to see if we want to force a MBX_HEARTBEAT */\n\t\tif (phba->hba_flag & HBA_HBEAT_TMO) {\n\t\t\tretval = lpfc_issue_hb_mbox(phba);\n\t\t\tif (retval)\n\t\t\t\ttmo = (1000 * LPFC_HB_MBOX_INTERVAL);\n\t\t\telse\n\t\t\t\ttmo = (1000 * LPFC_HB_MBOX_TIMEOUT);\n\t\t\tgoto out;\n\t\t}\n\t\ttmo = (1000 * LPFC_HB_MBOX_INTERVAL);\n\t}\nout:\n\tmod_timer(&phba->hb_tmofunc, jiffies + msecs_to_jiffies(tmo));\n}\n\n/**\n * lpfc_offline_eratt - Bring lpfc offline on hardware error attention\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is called to bring the HBA offline when HBA hardware error\n * other than Port Error 6 has been detected.\n **/\nstatic void\nlpfc_offline_eratt(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli   *psli = &phba->sli;\n\n\tspin_lock_irq(&phba->hbalock);\n\tpsli->sli_flag &= ~LPFC_SLI_ACTIVE;\n\tspin_unlock_irq(&phba->hbalock);\n\tlpfc_offline_prep(phba, LPFC_MBX_NO_WAIT);\n\n\tlpfc_offline(phba);\n\tlpfc_reset_barrier(phba);\n\tspin_lock_irq(&phba->hbalock);\n\tlpfc_sli_brdreset(phba);\n\tspin_unlock_irq(&phba->hbalock);\n\tlpfc_hba_down_post(phba);\n\tlpfc_sli_brdready(phba, HS_MBRDY);\n\tlpfc_unblock_mgmt_io(phba);\n\tphba->link_state = LPFC_HBA_ERROR;\n\treturn;\n}\n\n/**\n * lpfc_sli4_offline_eratt - Bring lpfc offline on SLI4 hardware error attention\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is called to bring a SLI4 HBA offline when HBA hardware error\n * other than Port Error 6 has been detected.\n **/\nvoid\nlpfc_sli4_offline_eratt(struct lpfc_hba *phba)\n{\n\tspin_lock_irq(&phba->hbalock);\n\tphba->link_state = LPFC_HBA_ERROR;\n\tspin_unlock_irq(&phba->hbalock);\n\n\tlpfc_offline_prep(phba, LPFC_MBX_NO_WAIT);\n\tlpfc_sli_flush_io_rings(phba);\n\tlpfc_offline(phba);\n\tlpfc_hba_down_post(phba);\n\tlpfc_unblock_mgmt_io(phba);\n}\n\n/**\n * lpfc_handle_deferred_eratt - The HBA hardware deferred error handler\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to handle the deferred HBA hardware error\n * conditions. This type of error is indicated by HBA by setting ER1\n * and another ER bit in the host status register. The driver will\n * wait until the ER1 bit clears before handling the error condition.\n **/\nstatic void\nlpfc_handle_deferred_eratt(struct lpfc_hba *phba)\n{\n\tuint32_t old_host_status = phba->work_hs;\n\tstruct lpfc_sli *psli = &phba->sli;\n\n\t/* If the pci channel is offline, ignore possible errors,\n\t * since we cannot communicate with the pci card anyway.\n\t */\n\tif (pci_channel_offline(phba->pcidev)) {\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tphba->hba_flag &= ~DEFER_ERATT;\n\t\tspin_unlock_irq(&phba->hbalock);\n\t\treturn;\n\t}\n\n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"0479 Deferred Adapter Hardware Error \"\n\t\t\t\"Data: x%x x%x x%x\\n\",\n\t\t\tphba->work_hs, phba->work_status[0],\n\t\t\tphba->work_status[1]);\n\n\tspin_lock_irq(&phba->hbalock);\n\tpsli->sli_flag &= ~LPFC_SLI_ACTIVE;\n\tspin_unlock_irq(&phba->hbalock);\n\n\n\t/*\n\t * Firmware stops when it triggred erratt. That could cause the I/Os\n\t * dropped by the firmware. Error iocb (I/O) on txcmplq and let the\n\t * SCSI layer retry it after re-establishing link.\n\t */\n\tlpfc_sli_abort_fcp_rings(phba);\n\n\t/*\n\t * There was a firmware error. Take the hba offline and then\n\t * attempt to restart it.\n\t */\n\tlpfc_offline_prep(phba, LPFC_MBX_WAIT);\n\tlpfc_offline(phba);\n\n\t/* Wait for the ER1 bit to clear.*/\n\twhile (phba->work_hs & HS_FFER1) {\n\t\tmsleep(100);\n\t\tif (lpfc_readl(phba->HSregaddr, &phba->work_hs)) {\n\t\t\tphba->work_hs = UNPLUG_ERR ;\n\t\t\tbreak;\n\t\t}\n\t\t/* If driver is unloading let the worker thread continue */\n\t\tif (phba->pport->load_flag & FC_UNLOADING) {\n\t\t\tphba->work_hs = 0;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/*\n\t * This is to ptrotect against a race condition in which\n\t * first write to the host attention register clear the\n\t * host status register.\n\t */\n\tif ((!phba->work_hs) && (!(phba->pport->load_flag & FC_UNLOADING)))\n\t\tphba->work_hs = old_host_status & ~HS_FFER1;\n\n\tspin_lock_irq(&phba->hbalock);\n\tphba->hba_flag &= ~DEFER_ERATT;\n\tspin_unlock_irq(&phba->hbalock);\n\tphba->work_status[0] = readl(phba->MBslimaddr + 0xa8);\n\tphba->work_status[1] = readl(phba->MBslimaddr + 0xac);\n}\n\nstatic void\nlpfc_board_errevt_to_mgmt(struct lpfc_hba *phba)\n{\n\tstruct lpfc_board_event_header board_event;\n\tstruct Scsi_Host *shost;\n\n\tboard_event.event_type = FC_REG_BOARD_EVENT;\n\tboard_event.subcategory = LPFC_EVENT_PORTINTERR;\n\tshost = lpfc_shost_from_vport(phba->pport);\n\tfc_host_post_vendor_event(shost, fc_get_event_number(),\n\t\t\t\t  sizeof(board_event),\n\t\t\t\t  (char *) &board_event,\n\t\t\t\t  LPFC_NL_VENDOR_ID);\n}\n\n/**\n * lpfc_handle_eratt_s3 - The SLI3 HBA hardware error handler\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to handle the following HBA hardware error\n * conditions:\n * 1 - HBA error attention interrupt\n * 2 - DMA ring index out of range\n * 3 - Mailbox command came back as unknown\n **/\nstatic void\nlpfc_handle_eratt_s3(struct lpfc_hba *phba)\n{\n\tstruct lpfc_vport *vport = phba->pport;\n\tstruct lpfc_sli   *psli = &phba->sli;\n\tuint32_t event_data;\n\tunsigned long temperature;\n\tstruct temp_event temp_event_data;\n\tstruct Scsi_Host  *shost;\n\n\t/* If the pci channel is offline, ignore possible errors,\n\t * since we cannot communicate with the pci card anyway.\n\t */\n\tif (pci_channel_offline(phba->pcidev)) {\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tphba->hba_flag &= ~DEFER_ERATT;\n\t\tspin_unlock_irq(&phba->hbalock);\n\t\treturn;\n\t}\n\n\t/* If resets are disabled then leave the HBA alone and return */\n\tif (!phba->cfg_enable_hba_reset)\n\t\treturn;\n\n\t/* Send an internal error event to mgmt application */\n\tlpfc_board_errevt_to_mgmt(phba);\n\n\tif (phba->hba_flag & DEFER_ERATT)\n\t\tlpfc_handle_deferred_eratt(phba);\n\n\tif ((phba->work_hs & HS_FFER6) || (phba->work_hs & HS_FFER8)) {\n\t\tif (phba->work_hs & HS_FFER6)\n\t\t\t/* Re-establishing Link */\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_LINK_EVENT,\n\t\t\t\t\t\"1301 Re-establishing Link \"\n\t\t\t\t\t\"Data: x%x x%x x%x\\n\",\n\t\t\t\t\tphba->work_hs, phba->work_status[0],\n\t\t\t\t\tphba->work_status[1]);\n\t\tif (phba->work_hs & HS_FFER8)\n\t\t\t/* Device Zeroization */\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_LINK_EVENT,\n\t\t\t\t\t\"2861 Host Authentication device \"\n\t\t\t\t\t\"zeroization Data:x%x x%x x%x\\n\",\n\t\t\t\t\tphba->work_hs, phba->work_status[0],\n\t\t\t\t\tphba->work_status[1]);\n\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tpsli->sli_flag &= ~LPFC_SLI_ACTIVE;\n\t\tspin_unlock_irq(&phba->hbalock);\n\n\t\t/*\n\t\t* Firmware stops when it triggled erratt with HS_FFER6.\n\t\t* That could cause the I/Os dropped by the firmware.\n\t\t* Error iocb (I/O) on txcmplq and let the SCSI layer\n\t\t* retry it after re-establishing link.\n\t\t*/\n\t\tlpfc_sli_abort_fcp_rings(phba);\n\n\t\t/*\n\t\t * There was a firmware error.  Take the hba offline and then\n\t\t * attempt to restart it.\n\t\t */\n\t\tlpfc_offline_prep(phba, LPFC_MBX_NO_WAIT);\n\t\tlpfc_offline(phba);\n\t\tlpfc_sli_brdrestart(phba);\n\t\tif (lpfc_online(phba) == 0) {\t/* Initialize the HBA */\n\t\t\tlpfc_unblock_mgmt_io(phba);\n\t\t\treturn;\n\t\t}\n\t\tlpfc_unblock_mgmt_io(phba);\n\t} else if (phba->work_hs & HS_CRIT_TEMP) {\n\t\ttemperature = readl(phba->MBslimaddr + TEMPERATURE_OFFSET);\n\t\ttemp_event_data.event_type = FC_REG_TEMPERATURE_EVENT;\n\t\ttemp_event_data.event_code = LPFC_CRIT_TEMP;\n\t\ttemp_event_data.data = (uint32_t)temperature;\n\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0406 Adapter maximum temperature exceeded \"\n\t\t\t\t\"(%ld), taking this port offline \"\n\t\t\t\t\"Data: x%x x%x x%x\\n\",\n\t\t\t\ttemperature, phba->work_hs,\n\t\t\t\tphba->work_status[0], phba->work_status[1]);\n\n\t\tshost = lpfc_shost_from_vport(phba->pport);\n\t\tfc_host_post_vendor_event(shost, fc_get_event_number(),\n\t\t\t\t\t  sizeof(temp_event_data),\n\t\t\t\t\t  (char *) &temp_event_data,\n\t\t\t\t\t  SCSI_NL_VID_TYPE_PCI\n\t\t\t\t\t  | PCI_VENDOR_ID_EMULEX);\n\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tphba->over_temp_state = HBA_OVER_TEMP;\n\t\tspin_unlock_irq(&phba->hbalock);\n\t\tlpfc_offline_eratt(phba);\n\n\t} else {\n\t\t/* The if clause above forces this code path when the status\n\t\t * failure is a value other than FFER6. Do not call the offline\n\t\t * twice. This is the adapter hardware error path.\n\t\t */\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0457 Adapter Hardware Error \"\n\t\t\t\t\"Data: x%x x%x x%x\\n\",\n\t\t\t\tphba->work_hs,\n\t\t\t\tphba->work_status[0], phba->work_status[1]);\n\n\t\tevent_data = FC_REG_DUMP_EVENT;\n\t\tshost = lpfc_shost_from_vport(vport);\n\t\tfc_host_post_vendor_event(shost, fc_get_event_number(),\n\t\t\t\tsizeof(event_data), (char *) &event_data,\n\t\t\t\tSCSI_NL_VID_TYPE_PCI | PCI_VENDOR_ID_EMULEX);\n\n\t\tlpfc_offline_eratt(phba);\n\t}\n\treturn;\n}\n\n/**\n * lpfc_sli4_port_sta_fn_reset - The SLI4 function reset due to port status reg\n * @phba: pointer to lpfc hba data structure.\n * @mbx_action: flag for mailbox shutdown action.\n * @en_rn_msg: send reset/port recovery message.\n * This routine is invoked to perform an SLI4 port PCI function reset in\n * response to port status register polling attention. It waits for port\n * status register (ERR, RDY, RN) bits before proceeding with function reset.\n * During this process, interrupt vectors are freed and later requested\n * for handling possible port resource change.\n **/\nstatic int\nlpfc_sli4_port_sta_fn_reset(struct lpfc_hba *phba, int mbx_action,\n\t\t\t    bool en_rn_msg)\n{\n\tint rc;\n\tuint32_t intr_mode;\n\n\tif (bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf) >=\n\t    LPFC_SLI_INTF_IF_TYPE_2) {\n\t\t/*\n\t\t * On error status condition, driver need to wait for port\n\t\t * ready before performing reset.\n\t\t */\n\t\trc = lpfc_sli4_pdev_status_reg_wait(phba);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\t/* need reset: attempt for port recovery */\n\tif (en_rn_msg)\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\n\t\t\t\t\"2887 Reset Needed: Attempting Port \"\n\t\t\t\t\"Recovery...\\n\");\n\n\t/* If we are no wait, the HBA has been reset and is not\n\t * functional, thus we should clear LPFC_SLI_ACTIVE flag.\n\t */\n\tif (mbx_action == LPFC_MBX_NO_WAIT) {\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tphba->sli.sli_flag &= ~LPFC_SLI_ACTIVE;\n\t\tspin_unlock_irq(&phba->hbalock);\n\t}\n\n\tlpfc_offline_prep(phba, mbx_action);\n\tlpfc_sli_flush_io_rings(phba);\n\tlpfc_offline(phba);\n\t/* release interrupt for possible resource change */\n\tlpfc_sli4_disable_intr(phba);\n\trc = lpfc_sli_brdrestart(phba);\n\tif (rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"6309 Failed to restart board\\n\");\n\t\treturn rc;\n\t}\n\t/* request and enable interrupt */\n\tintr_mode = lpfc_sli4_enable_intr(phba, phba->intr_mode);\n\tif (intr_mode == LPFC_INTR_ERROR) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3175 Failed to enable interrupt\\n\");\n\t\treturn -EIO;\n\t}\n\tphba->intr_mode = intr_mode;\n\trc = lpfc_online(phba);\n\tif (rc == 0)\n\t\tlpfc_unblock_mgmt_io(phba);\n\n\treturn rc;\n}\n\n/**\n * lpfc_handle_eratt_s4 - The SLI4 HBA hardware error handler\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to handle the SLI4 HBA hardware error attention\n * conditions.\n **/\nstatic void\nlpfc_handle_eratt_s4(struct lpfc_hba *phba)\n{\n\tstruct lpfc_vport *vport = phba->pport;\n\tuint32_t event_data;\n\tstruct Scsi_Host *shost;\n\tuint32_t if_type;\n\tstruct lpfc_register portstat_reg = {0};\n\tuint32_t reg_err1, reg_err2;\n\tuint32_t uerrlo_reg, uemasklo_reg;\n\tuint32_t smphr_port_status = 0, pci_rd_rc1, pci_rd_rc2;\n\tbool en_rn_msg = true;\n\tstruct temp_event temp_event_data;\n\tstruct lpfc_register portsmphr_reg;\n\tint rc, i;\n\n\t/* If the pci channel is offline, ignore possible errors, since\n\t * we cannot communicate with the pci card anyway.\n\t */\n\tif (pci_channel_offline(phba->pcidev)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3166 pci channel is offline\\n\");\n\t\tlpfc_sli4_offline_eratt(phba);\n\t\treturn;\n\t}\n\n\tmemset(&portsmphr_reg, 0, sizeof(portsmphr_reg));\n\tif_type = bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf);\n\tswitch (if_type) {\n\tcase LPFC_SLI_INTF_IF_TYPE_0:\n\t\tpci_rd_rc1 = lpfc_readl(\n\t\t\t\tphba->sli4_hba.u.if_type0.UERRLOregaddr,\n\t\t\t\t&uerrlo_reg);\n\t\tpci_rd_rc2 = lpfc_readl(\n\t\t\t\tphba->sli4_hba.u.if_type0.UEMASKLOregaddr,\n\t\t\t\t&uemasklo_reg);\n\t\t/* consider PCI bus read error as pci_channel_offline */\n\t\tif (pci_rd_rc1 == -EIO && pci_rd_rc2 == -EIO)\n\t\t\treturn;\n\t\tif (!(phba->hba_flag & HBA_RECOVERABLE_UE)) {\n\t\t\tlpfc_sli4_offline_eratt(phba);\n\t\t\treturn;\n\t\t}\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"7623 Checking UE recoverable\");\n\n\t\tfor (i = 0; i < phba->sli4_hba.ue_to_sr / 1000; i++) {\n\t\t\tif (lpfc_readl(phba->sli4_hba.PSMPHRregaddr,\n\t\t\t\t       &portsmphr_reg.word0))\n\t\t\t\tcontinue;\n\n\t\t\tsmphr_port_status = bf_get(lpfc_port_smphr_port_status,\n\t\t\t\t\t\t   &portsmphr_reg);\n\t\t\tif ((smphr_port_status & LPFC_PORT_SEM_MASK) ==\n\t\t\t    LPFC_PORT_SEM_UE_RECOVERABLE)\n\t\t\t\tbreak;\n\t\t\t/*Sleep for 1Sec, before checking SEMAPHORE */\n\t\t\tmsleep(1000);\n\t\t}\n\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"4827 smphr_port_status x%x : Waited %dSec\",\n\t\t\t\tsmphr_port_status, i);\n\n\t\t/* Recoverable UE, reset the HBA device */\n\t\tif ((smphr_port_status & LPFC_PORT_SEM_MASK) ==\n\t\t    LPFC_PORT_SEM_UE_RECOVERABLE) {\n\t\t\tfor (i = 0; i < 20; i++) {\n\t\t\t\tmsleep(1000);\n\t\t\t\tif (!lpfc_readl(phba->sli4_hba.PSMPHRregaddr,\n\t\t\t\t    &portsmphr_reg.word0) &&\n\t\t\t\t    (LPFC_POST_STAGE_PORT_READY ==\n\t\t\t\t     bf_get(lpfc_port_smphr_port_status,\n\t\t\t\t     &portsmphr_reg))) {\n\t\t\t\t\trc = lpfc_sli4_port_sta_fn_reset(phba,\n\t\t\t\t\t\tLPFC_MBX_NO_WAIT, en_rn_msg);\n\t\t\t\t\tif (rc == 0)\n\t\t\t\t\t\treturn;\n\t\t\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\t\"4215 Failed to recover UE\");\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"7624 Firmware not ready: Failing UE recovery,\"\n\t\t\t\t\" waited %dSec\", i);\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\tbreak;\n\n\tcase LPFC_SLI_INTF_IF_TYPE_2:\n\tcase LPFC_SLI_INTF_IF_TYPE_6:\n\t\tpci_rd_rc1 = lpfc_readl(\n\t\t\t\tphba->sli4_hba.u.if_type2.STATUSregaddr,\n\t\t\t\t&portstat_reg.word0);\n\t\t/* consider PCI bus read error as pci_channel_offline */\n\t\tif (pci_rd_rc1 == -EIO) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3151 PCI bus read access failure: x%x\\n\",\n\t\t\t\treadl(phba->sli4_hba.u.if_type2.STATUSregaddr));\n\t\t\tlpfc_sli4_offline_eratt(phba);\n\t\t\treturn;\n\t\t}\n\t\treg_err1 = readl(phba->sli4_hba.u.if_type2.ERR1regaddr);\n\t\treg_err2 = readl(phba->sli4_hba.u.if_type2.ERR2regaddr);\n\t\tif (bf_get(lpfc_sliport_status_oti, &portstat_reg)) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"2889 Port Overtemperature event, \"\n\t\t\t\t\t\"taking port offline Data: x%x x%x\\n\",\n\t\t\t\t\treg_err1, reg_err2);\n\n\t\t\tphba->sfp_alarm |= LPFC_TRANSGRESSION_HIGH_TEMPERATURE;\n\t\t\ttemp_event_data.event_type = FC_REG_TEMPERATURE_EVENT;\n\t\t\ttemp_event_data.event_code = LPFC_CRIT_TEMP;\n\t\t\ttemp_event_data.data = 0xFFFFFFFF;\n\n\t\t\tshost = lpfc_shost_from_vport(phba->pport);\n\t\t\tfc_host_post_vendor_event(shost, fc_get_event_number(),\n\t\t\t\t\t\t  sizeof(temp_event_data),\n\t\t\t\t\t\t  (char *)&temp_event_data,\n\t\t\t\t\t\t  SCSI_NL_VID_TYPE_PCI\n\t\t\t\t\t\t  | PCI_VENDOR_ID_EMULEX);\n\n\t\t\tspin_lock_irq(&phba->hbalock);\n\t\t\tphba->over_temp_state = HBA_OVER_TEMP;\n\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\tlpfc_sli4_offline_eratt(phba);\n\t\t\treturn;\n\t\t}\n\t\tif (reg_err1 == SLIPORT_ERR1_REG_ERR_CODE_2 &&\n\t\t    reg_err2 == SLIPORT_ERR2_REG_FW_RESTART) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"3143 Port Down: Firmware Update \"\n\t\t\t\t\t\"Detected\\n\");\n\t\t\ten_rn_msg = false;\n\t\t} else if (reg_err1 == SLIPORT_ERR1_REG_ERR_CODE_2 &&\n\t\t\t reg_err2 == SLIPORT_ERR2_REG_FORCED_DUMP)\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"3144 Port Down: Debug Dump\\n\");\n\t\telse if (reg_err1 == SLIPORT_ERR1_REG_ERR_CODE_2 &&\n\t\t\t reg_err2 == SLIPORT_ERR2_REG_FUNC_PROVISON)\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"3145 Port Down: Provisioning\\n\");\n\n\t\t/* If resets are disabled then leave the HBA alone and return */\n\t\tif (!phba->cfg_enable_hba_reset)\n\t\t\treturn;\n\n\t\t/* Check port status register for function reset */\n\t\trc = lpfc_sli4_port_sta_fn_reset(phba, LPFC_MBX_NO_WAIT,\n\t\t\t\ten_rn_msg);\n\t\tif (rc == 0) {\n\t\t\t/* don't report event on forced debug dump */\n\t\t\tif (reg_err1 == SLIPORT_ERR1_REG_ERR_CODE_2 &&\n\t\t\t    reg_err2 == SLIPORT_ERR2_REG_FORCED_DUMP)\n\t\t\t\treturn;\n\t\t\telse\n\t\t\t\tbreak;\n\t\t}\n\t\t/* fall through for not able to recover */\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3152 Unrecoverable error\\n\");\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\tbreak;\n\tcase LPFC_SLI_INTF_IF_TYPE_1:\n\tdefault:\n\t\tbreak;\n\t}\n\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\"3123 Report dump event to upper layer\\n\");\n\t/* Send an internal error event to mgmt application */\n\tlpfc_board_errevt_to_mgmt(phba);\n\n\tevent_data = FC_REG_DUMP_EVENT;\n\tshost = lpfc_shost_from_vport(vport);\n\tfc_host_post_vendor_event(shost, fc_get_event_number(),\n\t\t\t\t  sizeof(event_data), (char *) &event_data,\n\t\t\t\t  SCSI_NL_VID_TYPE_PCI | PCI_VENDOR_ID_EMULEX);\n}\n\n/**\n * lpfc_handle_eratt - Wrapper func for handling hba error attention\n * @phba: pointer to lpfc HBA data structure.\n *\n * This routine wraps the actual SLI3 or SLI4 hba error attention handling\n * routine from the API jump table function pointer from the lpfc_hba struct.\n *\n * Return codes\n *   0 - success.\n *   Any other value - error.\n **/\nvoid\nlpfc_handle_eratt(struct lpfc_hba *phba)\n{\n\t(*phba->lpfc_handle_eratt)(phba);\n}\n\n/**\n * lpfc_handle_latt - The HBA link event handler\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked from the worker thread to handle a HBA host\n * attention link event. SLI3 only.\n **/\nvoid\nlpfc_handle_latt(struct lpfc_hba *phba)\n{\n\tstruct lpfc_vport *vport = phba->pport;\n\tstruct lpfc_sli   *psli = &phba->sli;\n\tLPFC_MBOXQ_t *pmb;\n\tvolatile uint32_t control;\n\tstruct lpfc_dmabuf *mp;\n\tint rc = 0;\n\n\tpmb = (LPFC_MBOXQ_t *)mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!pmb) {\n\t\trc = 1;\n\t\tgoto lpfc_handle_latt_err_exit;\n\t}\n\n\tmp = kmalloc(sizeof(struct lpfc_dmabuf), GFP_KERNEL);\n\tif (!mp) {\n\t\trc = 2;\n\t\tgoto lpfc_handle_latt_free_pmb;\n\t}\n\n\tmp->virt = lpfc_mbuf_alloc(phba, 0, &mp->phys);\n\tif (!mp->virt) {\n\t\trc = 3;\n\t\tgoto lpfc_handle_latt_free_mp;\n\t}\n\n\t/* Cleanup any outstanding ELS commands */\n\tlpfc_els_flush_all_cmd(phba);\n\n\tpsli->slistat.link_event++;\n\tlpfc_read_topology(phba, pmb, mp);\n\tpmb->mbox_cmpl = lpfc_mbx_cmpl_read_topology;\n\tpmb->vport = vport;\n\t/* Block ELS IOCBs until we have processed this mbox command */\n\tphba->sli.sli3_ring[LPFC_ELS_RING].flag |= LPFC_STOP_IOCB_EVENT;\n\trc = lpfc_sli_issue_mbox (phba, pmb, MBX_NOWAIT);\n\tif (rc == MBX_NOT_FINISHED) {\n\t\trc = 4;\n\t\tgoto lpfc_handle_latt_free_mbuf;\n\t}\n\n\t/* Clear Link Attention in HA REG */\n\tspin_lock_irq(&phba->hbalock);\n\twritel(HA_LATT, phba->HAregaddr);\n\treadl(phba->HAregaddr); /* flush */\n\tspin_unlock_irq(&phba->hbalock);\n\n\treturn;\n\nlpfc_handle_latt_free_mbuf:\n\tphba->sli.sli3_ring[LPFC_ELS_RING].flag &= ~LPFC_STOP_IOCB_EVENT;\n\tlpfc_mbuf_free(phba, mp->virt, mp->phys);\nlpfc_handle_latt_free_mp:\n\tkfree(mp);\nlpfc_handle_latt_free_pmb:\n\tmempool_free(pmb, phba->mbox_mem_pool);\nlpfc_handle_latt_err_exit:\n\t/* Enable Link attention interrupts */\n\tspin_lock_irq(&phba->hbalock);\n\tpsli->sli_flag |= LPFC_PROCESS_LA;\n\tcontrol = readl(phba->HCregaddr);\n\tcontrol |= HC_LAINT_ENA;\n\twritel(control, phba->HCregaddr);\n\treadl(phba->HCregaddr); /* flush */\n\n\t/* Clear Link Attention in HA REG */\n\twritel(HA_LATT, phba->HAregaddr);\n\treadl(phba->HAregaddr); /* flush */\n\tspin_unlock_irq(&phba->hbalock);\n\tlpfc_linkdown(phba);\n\tphba->link_state = LPFC_HBA_ERROR;\n\n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"0300 LATT: Cannot issue READ_LA: Data:%d\\n\", rc);\n\n\treturn;\n}\n\n/**\n * lpfc_parse_vpd - Parse VPD (Vital Product Data)\n * @phba: pointer to lpfc hba data structure.\n * @vpd: pointer to the vital product data.\n * @len: length of the vital product data in bytes.\n *\n * This routine parses the Vital Product Data (VPD). The VPD is treated as\n * an array of characters. In this routine, the ModelName, ProgramType, and\n * ModelDesc, etc. fields of the phba data structure will be populated.\n *\n * Return codes\n *   0 - pointer to the VPD passed in is NULL\n *   1 - success\n **/\nint\nlpfc_parse_vpd(struct lpfc_hba *phba, uint8_t *vpd, int len)\n{\n\tuint8_t lenlo, lenhi;\n\tint Length;\n\tint i, j;\n\tint finished = 0;\n\tint index = 0;\n\n\tif (!vpd)\n\t\treturn 0;\n\n\t/* Vital Product */\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"0455 Vital Product Data: x%x x%x x%x x%x\\n\",\n\t\t\t(uint32_t) vpd[0], (uint32_t) vpd[1], (uint32_t) vpd[2],\n\t\t\t(uint32_t) vpd[3]);\n\twhile (!finished && (index < (len - 4))) {\n\t\tswitch (vpd[index]) {\n\t\tcase 0x82:\n\t\tcase 0x91:\n\t\t\tindex += 1;\n\t\t\tlenlo = vpd[index];\n\t\t\tindex += 1;\n\t\t\tlenhi = vpd[index];\n\t\t\tindex += 1;\n\t\t\ti = ((((unsigned short)lenhi) << 8) + lenlo);\n\t\t\tindex += i;\n\t\t\tbreak;\n\t\tcase 0x90:\n\t\t\tindex += 1;\n\t\t\tlenlo = vpd[index];\n\t\t\tindex += 1;\n\t\t\tlenhi = vpd[index];\n\t\t\tindex += 1;\n\t\t\tLength = ((((unsigned short)lenhi) << 8) + lenlo);\n\t\t\tif (Length > len - index)\n\t\t\t\tLength = len - index;\n\t\t\twhile (Length > 0) {\n\t\t\t/* Look for Serial Number */\n\t\t\tif ((vpd[index] == 'S') && (vpd[index+1] == 'N')) {\n\t\t\t\tindex += 2;\n\t\t\t\ti = vpd[index];\n\t\t\t\tindex += 1;\n\t\t\t\tj = 0;\n\t\t\t\tLength -= (3+i);\n\t\t\t\twhile(i--) {\n\t\t\t\t\tphba->SerialNumber[j++] = vpd[index++];\n\t\t\t\t\tif (j == 31)\n\t\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tphba->SerialNumber[j] = 0;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\telse if ((vpd[index] == 'V') && (vpd[index+1] == '1')) {\n\t\t\t\tphba->vpd_flag |= VPD_MODEL_DESC;\n\t\t\t\tindex += 2;\n\t\t\t\ti = vpd[index];\n\t\t\t\tindex += 1;\n\t\t\t\tj = 0;\n\t\t\t\tLength -= (3+i);\n\t\t\t\twhile(i--) {\n\t\t\t\t\tphba->ModelDesc[j++] = vpd[index++];\n\t\t\t\t\tif (j == 255)\n\t\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tphba->ModelDesc[j] = 0;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\telse if ((vpd[index] == 'V') && (vpd[index+1] == '2')) {\n\t\t\t\tphba->vpd_flag |= VPD_MODEL_NAME;\n\t\t\t\tindex += 2;\n\t\t\t\ti = vpd[index];\n\t\t\t\tindex += 1;\n\t\t\t\tj = 0;\n\t\t\t\tLength -= (3+i);\n\t\t\t\twhile(i--) {\n\t\t\t\t\tphba->ModelName[j++] = vpd[index++];\n\t\t\t\t\tif (j == 79)\n\t\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tphba->ModelName[j] = 0;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\telse if ((vpd[index] == 'V') && (vpd[index+1] == '3')) {\n\t\t\t\tphba->vpd_flag |= VPD_PROGRAM_TYPE;\n\t\t\t\tindex += 2;\n\t\t\t\ti = vpd[index];\n\t\t\t\tindex += 1;\n\t\t\t\tj = 0;\n\t\t\t\tLength -= (3+i);\n\t\t\t\twhile(i--) {\n\t\t\t\t\tphba->ProgramType[j++] = vpd[index++];\n\t\t\t\t\tif (j == 255)\n\t\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tphba->ProgramType[j] = 0;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\telse if ((vpd[index] == 'V') && (vpd[index+1] == '4')) {\n\t\t\t\tphba->vpd_flag |= VPD_PORT;\n\t\t\t\tindex += 2;\n\t\t\t\ti = vpd[index];\n\t\t\t\tindex += 1;\n\t\t\t\tj = 0;\n\t\t\t\tLength -= (3+i);\n\t\t\t\twhile(i--) {\n\t\t\t\t\tif ((phba->sli_rev == LPFC_SLI_REV4) &&\n\t\t\t\t\t    (phba->sli4_hba.pport_name_sta ==\n\t\t\t\t\t     LPFC_SLI4_PPNAME_GET)) {\n\t\t\t\t\t\tj++;\n\t\t\t\t\t\tindex++;\n\t\t\t\t\t} else\n\t\t\t\t\t\tphba->Port[j++] = vpd[index++];\n\t\t\t\t\tif (j == 19)\n\t\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif ((phba->sli_rev != LPFC_SLI_REV4) ||\n\t\t\t\t    (phba->sli4_hba.pport_name_sta ==\n\t\t\t\t     LPFC_SLI4_PPNAME_NON))\n\t\t\t\t\tphba->Port[j] = 0;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tindex += 2;\n\t\t\t\ti = vpd[index];\n\t\t\t\tindex += 1;\n\t\t\t\tindex += i;\n\t\t\t\tLength -= (3 + i);\n\t\t\t}\n\t\t}\n\t\tfinished = 0;\n\t\tbreak;\n\t\tcase 0x78:\n\t\t\tfinished = 1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tindex ++;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn(1);\n}\n\n/**\n * lpfc_get_hba_model_desc - Retrieve HBA device model name and description\n * @phba: pointer to lpfc hba data structure.\n * @mdp: pointer to the data structure to hold the derived model name.\n * @descp: pointer to the data structure to hold the derived description.\n *\n * This routine retrieves HBA's description based on its registered PCI device\n * ID. The @descp passed into this function points to an array of 256 chars. It\n * shall be returned with the model name, maximum speed, and the host bus type.\n * The @mdp passed into this function points to an array of 80 chars. When the\n * function returns, the @mdp will be filled with the model name.\n **/\nstatic void\nlpfc_get_hba_model_desc(struct lpfc_hba *phba, uint8_t *mdp, uint8_t *descp)\n{\n\tlpfc_vpd_t *vp;\n\tuint16_t dev_id = phba->pcidev->device;\n\tint max_speed;\n\tint GE = 0;\n\tint oneConnect = 0; /* default is not a oneConnect */\n\tstruct {\n\t\tchar *name;\n\t\tchar *bus;\n\t\tchar *function;\n\t} m = {\"<Unknown>\", \"\", \"\"};\n\n\tif (mdp && mdp[0] != '\\0'\n\t\t&& descp && descp[0] != '\\0')\n\t\treturn;\n\n\tif (phba->lmt & LMT_64Gb)\n\t\tmax_speed = 64;\n\telse if (phba->lmt & LMT_32Gb)\n\t\tmax_speed = 32;\n\telse if (phba->lmt & LMT_16Gb)\n\t\tmax_speed = 16;\n\telse if (phba->lmt & LMT_10Gb)\n\t\tmax_speed = 10;\n\telse if (phba->lmt & LMT_8Gb)\n\t\tmax_speed = 8;\n\telse if (phba->lmt & LMT_4Gb)\n\t\tmax_speed = 4;\n\telse if (phba->lmt & LMT_2Gb)\n\t\tmax_speed = 2;\n\telse if (phba->lmt & LMT_1Gb)\n\t\tmax_speed = 1;\n\telse\n\t\tmax_speed = 0;\n\n\tvp = &phba->vpd;\n\n\tswitch (dev_id) {\n\tcase PCI_DEVICE_ID_FIREFLY:\n\t\tm = (typeof(m)){\"LP6000\", \"PCI\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_SUPERFLY:\n\t\tif (vp->rev.biuRev >= 1 && vp->rev.biuRev <= 3)\n\t\t\tm = (typeof(m)){\"LP7000\", \"PCI\", \"\"};\n\t\telse\n\t\t\tm = (typeof(m)){\"LP7000E\", \"PCI\", \"\"};\n\t\tm.function = \"Obsolete, Unsupported Fibre Channel Adapter\";\n\t\tbreak;\n\tcase PCI_DEVICE_ID_DRAGONFLY:\n\t\tm = (typeof(m)){\"LP8000\", \"PCI\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_CENTAUR:\n\t\tif (FC_JEDEC_ID(vp->rev.biuRev) == CENTAUR_2G_JEDEC_ID)\n\t\t\tm = (typeof(m)){\"LP9002\", \"PCI\", \"\"};\n\t\telse\n\t\t\tm = (typeof(m)){\"LP9000\", \"PCI\", \"\"};\n\t\tm.function = \"Obsolete, Unsupported Fibre Channel Adapter\";\n\t\tbreak;\n\tcase PCI_DEVICE_ID_RFLY:\n\t\tm = (typeof(m)){\"LP952\", \"PCI\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_PEGASUS:\n\t\tm = (typeof(m)){\"LP9802\", \"PCI-X\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_THOR:\n\t\tm = (typeof(m)){\"LP10000\", \"PCI-X\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_VIPER:\n\t\tm = (typeof(m)){\"LPX1000\",  \"PCI-X\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_PFLY:\n\t\tm = (typeof(m)){\"LP982\", \"PCI-X\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_TFLY:\n\t\tm = (typeof(m)){\"LP1050\", \"PCI-X\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_HELIOS:\n\t\tm = (typeof(m)){\"LP11000\", \"PCI-X2\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_HELIOS_SCSP:\n\t\tm = (typeof(m)){\"LP11000-SP\", \"PCI-X2\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_HELIOS_DCSP:\n\t\tm = (typeof(m)){\"LP11002-SP\",  \"PCI-X2\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_NEPTUNE:\n\t\tm = (typeof(m)){\"LPe1000\", \"PCIe\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_NEPTUNE_SCSP:\n\t\tm = (typeof(m)){\"LPe1000-SP\", \"PCIe\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_NEPTUNE_DCSP:\n\t\tm = (typeof(m)){\"LPe1002-SP\", \"PCIe\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_BMID:\n\t\tm = (typeof(m)){\"LP1150\", \"PCI-X2\", \"Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_BSMB:\n\t\tm = (typeof(m)){\"LP111\", \"PCI-X2\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_ZEPHYR:\n\t\tm = (typeof(m)){\"LPe11000\", \"PCIe\", \"Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_ZEPHYR_SCSP:\n\t\tm = (typeof(m)){\"LPe11000\", \"PCIe\", \"Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_ZEPHYR_DCSP:\n\t\tm = (typeof(m)){\"LP2105\", \"PCIe\", \"FCoE Adapter\"};\n\t\tGE = 1;\n\t\tbreak;\n\tcase PCI_DEVICE_ID_ZMID:\n\t\tm = (typeof(m)){\"LPe1150\", \"PCIe\", \"Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_ZSMB:\n\t\tm = (typeof(m)){\"LPe111\", \"PCIe\", \"Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_LP101:\n\t\tm = (typeof(m)){\"LP101\", \"PCI-X\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_LP10000S:\n\t\tm = (typeof(m)){\"LP10000-S\", \"PCI\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_LP11000S:\n\t\tm = (typeof(m)){\"LP11000-S\", \"PCI-X2\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_LPE11000S:\n\t\tm = (typeof(m)){\"LPe11000-S\", \"PCIe\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_SAT:\n\t\tm = (typeof(m)){\"LPe12000\", \"PCIe\", \"Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_SAT_MID:\n\t\tm = (typeof(m)){\"LPe1250\", \"PCIe\", \"Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_SAT_SMB:\n\t\tm = (typeof(m)){\"LPe121\", \"PCIe\", \"Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_SAT_DCSP:\n\t\tm = (typeof(m)){\"LPe12002-SP\", \"PCIe\", \"Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_SAT_SCSP:\n\t\tm = (typeof(m)){\"LPe12000-SP\", \"PCIe\", \"Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_SAT_S:\n\t\tm = (typeof(m)){\"LPe12000-S\", \"PCIe\", \"Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_HORNET:\n\t\tm = (typeof(m)){\"LP21000\", \"PCIe\",\n\t\t\t\t\"Obsolete, Unsupported FCoE Adapter\"};\n\t\tGE = 1;\n\t\tbreak;\n\tcase PCI_DEVICE_ID_PROTEUS_VF:\n\t\tm = (typeof(m)){\"LPev12000\", \"PCIe IOV\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_PROTEUS_PF:\n\t\tm = (typeof(m)){\"LPev12000\", \"PCIe IOV\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_PROTEUS_S:\n\t\tm = (typeof(m)){\"LPemv12002-S\", \"PCIe IOV\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_TIGERSHARK:\n\t\toneConnect = 1;\n\t\tm = (typeof(m)){\"OCe10100\", \"PCIe\", \"FCoE\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_TOMCAT:\n\t\toneConnect = 1;\n\t\tm = (typeof(m)){\"OCe11100\", \"PCIe\", \"FCoE\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_FALCON:\n\t\tm = (typeof(m)){\"LPSe12002-ML1-E\", \"PCIe\",\n\t\t\t\t\"EmulexSecure Fibre\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_BALIUS:\n\t\tm = (typeof(m)){\"LPVe12002\", \"PCIe Shared I/O\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_LANCER_FC:\n\t\tm = (typeof(m)){\"LPe16000\", \"PCIe\", \"Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_LANCER_FC_VF:\n\t\tm = (typeof(m)){\"LPe16000\", \"PCIe\",\n\t\t\t\t\"Obsolete, Unsupported Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_LANCER_FCOE:\n\t\toneConnect = 1;\n\t\tm = (typeof(m)){\"OCe15100\", \"PCIe\", \"FCoE\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_LANCER_FCOE_VF:\n\t\toneConnect = 1;\n\t\tm = (typeof(m)){\"OCe15100\", \"PCIe\",\n\t\t\t\t\"Obsolete, Unsupported FCoE\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_LANCER_G6_FC:\n\t\tm = (typeof(m)){\"LPe32000\", \"PCIe\", \"Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_LANCER_G7_FC:\n\t\tm = (typeof(m)){\"LPe36000\", \"PCIe\", \"Fibre Channel Adapter\"};\n\t\tbreak;\n\tcase PCI_DEVICE_ID_SKYHAWK:\n\tcase PCI_DEVICE_ID_SKYHAWK_VF:\n\t\toneConnect = 1;\n\t\tm = (typeof(m)){\"OCe14000\", \"PCIe\", \"FCoE\"};\n\t\tbreak;\n\tdefault:\n\t\tm = (typeof(m)){\"Unknown\", \"\", \"\"};\n\t\tbreak;\n\t}\n\n\tif (mdp && mdp[0] == '\\0')\n\t\tsnprintf(mdp, 79,\"%s\", m.name);\n\t/*\n\t * oneConnect hba requires special processing, they are all initiators\n\t * and we put the port number on the end\n\t */\n\tif (descp && descp[0] == '\\0') {\n\t\tif (oneConnect)\n\t\t\tsnprintf(descp, 255,\n\t\t\t\t\"Emulex OneConnect %s, %s Initiator %s\",\n\t\t\t\tm.name, m.function,\n\t\t\t\tphba->Port);\n\t\telse if (max_speed == 0)\n\t\t\tsnprintf(descp, 255,\n\t\t\t\t\"Emulex %s %s %s\",\n\t\t\t\tm.name, m.bus, m.function);\n\t\telse\n\t\t\tsnprintf(descp, 255,\n\t\t\t\t\"Emulex %s %d%s %s %s\",\n\t\t\t\tm.name, max_speed, (GE) ? \"GE\" : \"Gb\",\n\t\t\t\tm.bus, m.function);\n\t}\n}\n\n/**\n * lpfc_post_buffer - Post IOCB(s) with DMA buffer descriptor(s) to a IOCB ring\n * @phba: pointer to lpfc hba data structure.\n * @pring: pointer to a IOCB ring.\n * @cnt: the number of IOCBs to be posted to the IOCB ring.\n *\n * This routine posts a given number of IOCBs with the associated DMA buffer\n * descriptors specified by the cnt argument to the given IOCB ring.\n *\n * Return codes\n *   The number of IOCBs NOT able to be posted to the IOCB ring.\n **/\nint\nlpfc_post_buffer(struct lpfc_hba *phba, struct lpfc_sli_ring *pring, int cnt)\n{\n\tIOCB_t *icmd;\n\tstruct lpfc_iocbq *iocb;\n\tstruct lpfc_dmabuf *mp1, *mp2;\n\n\tcnt += pring->missbufcnt;\n\n\t/* While there are buffers to post */\n\twhile (cnt > 0) {\n\t\t/* Allocate buffer for  command iocb */\n\t\tiocb = lpfc_sli_get_iocbq(phba);\n\t\tif (iocb == NULL) {\n\t\t\tpring->missbufcnt = cnt;\n\t\t\treturn cnt;\n\t\t}\n\t\ticmd = &iocb->iocb;\n\n\t\t/* 2 buffers can be posted per command */\n\t\t/* Allocate buffer to post */\n\t\tmp1 = kmalloc(sizeof (struct lpfc_dmabuf), GFP_KERNEL);\n\t\tif (mp1)\n\t\t    mp1->virt = lpfc_mbuf_alloc(phba, MEM_PRI, &mp1->phys);\n\t\tif (!mp1 || !mp1->virt) {\n\t\t\tkfree(mp1);\n\t\t\tlpfc_sli_release_iocbq(phba, iocb);\n\t\t\tpring->missbufcnt = cnt;\n\t\t\treturn cnt;\n\t\t}\n\n\t\tINIT_LIST_HEAD(&mp1->list);\n\t\t/* Allocate buffer to post */\n\t\tif (cnt > 1) {\n\t\t\tmp2 = kmalloc(sizeof (struct lpfc_dmabuf), GFP_KERNEL);\n\t\t\tif (mp2)\n\t\t\t\tmp2->virt = lpfc_mbuf_alloc(phba, MEM_PRI,\n\t\t\t\t\t\t\t    &mp2->phys);\n\t\t\tif (!mp2 || !mp2->virt) {\n\t\t\t\tkfree(mp2);\n\t\t\t\tlpfc_mbuf_free(phba, mp1->virt, mp1->phys);\n\t\t\t\tkfree(mp1);\n\t\t\t\tlpfc_sli_release_iocbq(phba, iocb);\n\t\t\t\tpring->missbufcnt = cnt;\n\t\t\t\treturn cnt;\n\t\t\t}\n\n\t\t\tINIT_LIST_HEAD(&mp2->list);\n\t\t} else {\n\t\t\tmp2 = NULL;\n\t\t}\n\n\t\ticmd->un.cont64[0].addrHigh = putPaddrHigh(mp1->phys);\n\t\ticmd->un.cont64[0].addrLow = putPaddrLow(mp1->phys);\n\t\ticmd->un.cont64[0].tus.f.bdeSize = FCELSSIZE;\n\t\ticmd->ulpBdeCount = 1;\n\t\tcnt--;\n\t\tif (mp2) {\n\t\t\ticmd->un.cont64[1].addrHigh = putPaddrHigh(mp2->phys);\n\t\t\ticmd->un.cont64[1].addrLow = putPaddrLow(mp2->phys);\n\t\t\ticmd->un.cont64[1].tus.f.bdeSize = FCELSSIZE;\n\t\t\tcnt--;\n\t\t\ticmd->ulpBdeCount = 2;\n\t\t}\n\n\t\ticmd->ulpCommand = CMD_QUE_RING_BUF64_CN;\n\t\ticmd->ulpLe = 1;\n\n\t\tif (lpfc_sli_issue_iocb(phba, pring->ringno, iocb, 0) ==\n\t\t    IOCB_ERROR) {\n\t\t\tlpfc_mbuf_free(phba, mp1->virt, mp1->phys);\n\t\t\tkfree(mp1);\n\t\t\tcnt++;\n\t\t\tif (mp2) {\n\t\t\t\tlpfc_mbuf_free(phba, mp2->virt, mp2->phys);\n\t\t\t\tkfree(mp2);\n\t\t\t\tcnt++;\n\t\t\t}\n\t\t\tlpfc_sli_release_iocbq(phba, iocb);\n\t\t\tpring->missbufcnt = cnt;\n\t\t\treturn cnt;\n\t\t}\n\t\tlpfc_sli_ringpostbuf_put(phba, pring, mp1);\n\t\tif (mp2)\n\t\t\tlpfc_sli_ringpostbuf_put(phba, pring, mp2);\n\t}\n\tpring->missbufcnt = 0;\n\treturn 0;\n}\n\n/**\n * lpfc_post_rcv_buf - Post the initial receive IOCB buffers to ELS ring\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine posts initial receive IOCB buffers to the ELS ring. The\n * current number of initial IOCB buffers specified by LPFC_BUF_RING0 is\n * set to 64 IOCBs. SLI3 only.\n *\n * Return codes\n *   0 - success (currently always success)\n **/\nstatic int\nlpfc_post_rcv_buf(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli *psli = &phba->sli;\n\n\t/* Ring 0, ELS / CT buffers */\n\tlpfc_post_buffer(phba, &psli->sli3_ring[LPFC_ELS_RING], LPFC_BUF_RING0);\n\t/* Ring 2 - FCP no buffers needed */\n\n\treturn 0;\n}\n\n#define S(N,V) (((V)<<(N))|((V)>>(32-(N))))\n\n/**\n * lpfc_sha_init - Set up initial array of hash table entries\n * @HashResultPointer: pointer to an array as hash table.\n *\n * This routine sets up the initial values to the array of hash table entries\n * for the LC HBAs.\n **/\nstatic void\nlpfc_sha_init(uint32_t * HashResultPointer)\n{\n\tHashResultPointer[0] = 0x67452301;\n\tHashResultPointer[1] = 0xEFCDAB89;\n\tHashResultPointer[2] = 0x98BADCFE;\n\tHashResultPointer[3] = 0x10325476;\n\tHashResultPointer[4] = 0xC3D2E1F0;\n}\n\n/**\n * lpfc_sha_iterate - Iterate initial hash table with the working hash table\n * @HashResultPointer: pointer to an initial/result hash table.\n * @HashWorkingPointer: pointer to an working hash table.\n *\n * This routine iterates an initial hash table pointed by @HashResultPointer\n * with the values from the working hash table pointeed by @HashWorkingPointer.\n * The results are putting back to the initial hash table, returned through\n * the @HashResultPointer as the result hash table.\n **/\nstatic void\nlpfc_sha_iterate(uint32_t * HashResultPointer, uint32_t * HashWorkingPointer)\n{\n\tint t;\n\tuint32_t TEMP;\n\tuint32_t A, B, C, D, E;\n\tt = 16;\n\tdo {\n\t\tHashWorkingPointer[t] =\n\t\t    S(1,\n\t\t      HashWorkingPointer[t - 3] ^ HashWorkingPointer[t -\n\t\t\t\t\t\t\t\t     8] ^\n\t\t      HashWorkingPointer[t - 14] ^ HashWorkingPointer[t - 16]);\n\t} while (++t <= 79);\n\tt = 0;\n\tA = HashResultPointer[0];\n\tB = HashResultPointer[1];\n\tC = HashResultPointer[2];\n\tD = HashResultPointer[3];\n\tE = HashResultPointer[4];\n\n\tdo {\n\t\tif (t < 20) {\n\t\t\tTEMP = ((B & C) | ((~B) & D)) + 0x5A827999;\n\t\t} else if (t < 40) {\n\t\t\tTEMP = (B ^ C ^ D) + 0x6ED9EBA1;\n\t\t} else if (t < 60) {\n\t\t\tTEMP = ((B & C) | (B & D) | (C & D)) + 0x8F1BBCDC;\n\t\t} else {\n\t\t\tTEMP = (B ^ C ^ D) + 0xCA62C1D6;\n\t\t}\n\t\tTEMP += S(5, A) + E + HashWorkingPointer[t];\n\t\tE = D;\n\t\tD = C;\n\t\tC = S(30, B);\n\t\tB = A;\n\t\tA = TEMP;\n\t} while (++t <= 79);\n\n\tHashResultPointer[0] += A;\n\tHashResultPointer[1] += B;\n\tHashResultPointer[2] += C;\n\tHashResultPointer[3] += D;\n\tHashResultPointer[4] += E;\n\n}\n\n/**\n * lpfc_challenge_key - Create challenge key based on WWPN of the HBA\n * @RandomChallenge: pointer to the entry of host challenge random number array.\n * @HashWorking: pointer to the entry of the working hash array.\n *\n * This routine calculates the working hash array referred by @HashWorking\n * from the challenge random numbers associated with the host, referred by\n * @RandomChallenge. The result is put into the entry of the working hash\n * array and returned by reference through @HashWorking.\n **/\nstatic void\nlpfc_challenge_key(uint32_t * RandomChallenge, uint32_t * HashWorking)\n{\n\t*HashWorking = (*RandomChallenge ^ *HashWorking);\n}\n\n/**\n * lpfc_hba_init - Perform special handling for LC HBA initialization\n * @phba: pointer to lpfc hba data structure.\n * @hbainit: pointer to an array of unsigned 32-bit integers.\n *\n * This routine performs the special handling for LC HBA initialization.\n **/\nvoid\nlpfc_hba_init(struct lpfc_hba *phba, uint32_t *hbainit)\n{\n\tint t;\n\tuint32_t *HashWorking;\n\tuint32_t *pwwnn = (uint32_t *) phba->wwnn;\n\n\tHashWorking = kcalloc(80, sizeof(uint32_t), GFP_KERNEL);\n\tif (!HashWorking)\n\t\treturn;\n\n\tHashWorking[0] = HashWorking[78] = *pwwnn++;\n\tHashWorking[1] = HashWorking[79] = *pwwnn;\n\n\tfor (t = 0; t < 7; t++)\n\t\tlpfc_challenge_key(phba->RandomData + t, HashWorking + t);\n\n\tlpfc_sha_init(hbainit);\n\tlpfc_sha_iterate(hbainit, HashWorking);\n\tkfree(HashWorking);\n}\n\n/**\n * lpfc_cleanup - Performs vport cleanups before deleting a vport\n * @vport: pointer to a virtual N_Port data structure.\n *\n * This routine performs the necessary cleanups before deleting the @vport.\n * It invokes the discovery state machine to perform necessary state\n * transitions and to release the ndlps associated with the @vport. Note,\n * the physical port is treated as @vport 0.\n **/\nvoid\nlpfc_cleanup(struct lpfc_vport *vport)\n{\n\tstruct lpfc_hba   *phba = vport->phba;\n\tstruct lpfc_nodelist *ndlp, *next_ndlp;\n\tint i = 0;\n\n\tif (phba->link_state > LPFC_LINK_DOWN)\n\t\tlpfc_port_link_failure(vport);\n\n\tlist_for_each_entry_safe(ndlp, next_ndlp, &vport->fc_nodes, nlp_listp) {\n\t\tif (vport->port_type != LPFC_PHYSICAL_PORT &&\n\t\t    ndlp->nlp_DID == Fabric_DID) {\n\t\t\t/* Just free up ndlp with Fabric_DID for vports */\n\t\t\tlpfc_nlp_put(ndlp);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (ndlp->nlp_DID == Fabric_Cntl_DID &&\n\t\t    ndlp->nlp_state == NLP_STE_UNUSED_NODE) {\n\t\t\tlpfc_nlp_put(ndlp);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Fabric Ports not in UNMAPPED state are cleaned up in the\n\t\t * DEVICE_RM event.\n\t\t */\n\t\tif (ndlp->nlp_type & NLP_FABRIC &&\n\t\t    ndlp->nlp_state == NLP_STE_UNMAPPED_NODE)\n\t\t\tlpfc_disc_state_machine(vport, ndlp, NULL,\n\t\t\t\t\tNLP_EVT_DEVICE_RECOVERY);\n\n\t\tif (!(ndlp->fc4_xpt_flags & (NVME_XPT_REGD|SCSI_XPT_REGD)))\n\t\t\tlpfc_disc_state_machine(vport, ndlp, NULL,\n\t\t\t\t\tNLP_EVT_DEVICE_RM);\n\t}\n\n\t/* At this point, ALL ndlp's should be gone\n\t * because of the previous NLP_EVT_DEVICE_RM.\n\t * Lets wait for this to happen, if needed.\n\t */\n\twhile (!list_empty(&vport->fc_nodes)) {\n\t\tif (i++ > 3000) {\n\t\t\tlpfc_printf_vlog(vport, KERN_ERR,\n\t\t\t\t\t LOG_TRACE_EVENT,\n\t\t\t\t\"0233 Nodelist not empty\\n\");\n\t\t\tlist_for_each_entry_safe(ndlp, next_ndlp,\n\t\t\t\t\t\t&vport->fc_nodes, nlp_listp) {\n\t\t\t\tlpfc_printf_vlog(ndlp->vport, KERN_ERR,\n\t\t\t\t\t\t LOG_TRACE_EVENT,\n\t\t\t\t\t\t \"0282 did:x%x ndlp:x%px \"\n\t\t\t\t\t\t \"refcnt:%d xflags x%x nflag x%x\\n\",\n\t\t\t\t\t\t ndlp->nlp_DID, (void *)ndlp,\n\t\t\t\t\t\t kref_read(&ndlp->kref),\n\t\t\t\t\t\t ndlp->fc4_xpt_flags,\n\t\t\t\t\t\t ndlp->nlp_flag);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Wait for any activity on ndlps to settle */\n\t\tmsleep(10);\n\t}\n\tlpfc_cleanup_vports_rrqs(vport, NULL);\n}\n\n/**\n * lpfc_stop_vport_timers - Stop all the timers associated with a vport\n * @vport: pointer to a virtual N_Port data structure.\n *\n * This routine stops all the timers associated with a @vport. This function\n * is invoked before disabling or deleting a @vport. Note that the physical\n * port is treated as @vport 0.\n **/\nvoid\nlpfc_stop_vport_timers(struct lpfc_vport *vport)\n{\n\tdel_timer_sync(&vport->els_tmofunc);\n\tdel_timer_sync(&vport->delayed_disc_tmo);\n\tlpfc_can_disctmo(vport);\n\treturn;\n}\n\n/**\n * __lpfc_sli4_stop_fcf_redisc_wait_timer - Stop FCF rediscovery wait timer\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine stops the SLI4 FCF rediscover wait timer if it's on. The\n * caller of this routine should already hold the host lock.\n **/\nvoid\n__lpfc_sli4_stop_fcf_redisc_wait_timer(struct lpfc_hba *phba)\n{\n\t/* Clear pending FCF rediscovery wait flag */\n\tphba->fcf.fcf_flag &= ~FCF_REDISC_PEND;\n\n\t/* Now, try to stop the timer */\n\tdel_timer(&phba->fcf.redisc_wait);\n}\n\n/**\n * lpfc_sli4_stop_fcf_redisc_wait_timer - Stop FCF rediscovery wait timer\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine stops the SLI4 FCF rediscover wait timer if it's on. It\n * checks whether the FCF rediscovery wait timer is pending with the host\n * lock held before proceeding with disabling the timer and clearing the\n * wait timer pendig flag.\n **/\nvoid\nlpfc_sli4_stop_fcf_redisc_wait_timer(struct lpfc_hba *phba)\n{\n\tspin_lock_irq(&phba->hbalock);\n\tif (!(phba->fcf.fcf_flag & FCF_REDISC_PEND)) {\n\t\t/* FCF rediscovery timer already fired or stopped */\n\t\tspin_unlock_irq(&phba->hbalock);\n\t\treturn;\n\t}\n\t__lpfc_sli4_stop_fcf_redisc_wait_timer(phba);\n\t/* Clear failover in progress flags */\n\tphba->fcf.fcf_flag &= ~(FCF_DEAD_DISC | FCF_ACVL_DISC);\n\tspin_unlock_irq(&phba->hbalock);\n}\n\n/**\n * lpfc_stop_hba_timers - Stop all the timers associated with an HBA\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine stops all the timers associated with a HBA. This function is\n * invoked before either putting a HBA offline or unloading the driver.\n **/\nvoid\nlpfc_stop_hba_timers(struct lpfc_hba *phba)\n{\n\tif (phba->pport)\n\t\tlpfc_stop_vport_timers(phba->pport);\n\tcancel_delayed_work_sync(&phba->eq_delay_work);\n\tcancel_delayed_work_sync(&phba->idle_stat_delay_work);\n\tdel_timer_sync(&phba->sli.mbox_tmo);\n\tdel_timer_sync(&phba->fabric_block_timer);\n\tdel_timer_sync(&phba->eratt_poll);\n\tdel_timer_sync(&phba->hb_tmofunc);\n\tif (phba->sli_rev == LPFC_SLI_REV4) {\n\t\tdel_timer_sync(&phba->rrq_tmr);\n\t\tphba->hba_flag &= ~HBA_RRQ_ACTIVE;\n\t}\n\tphba->hba_flag &= ~(HBA_HBEAT_INP | HBA_HBEAT_TMO);\n\n\tswitch (phba->pci_dev_grp) {\n\tcase LPFC_PCI_DEV_LP:\n\t\t/* Stop any LightPulse device specific driver timers */\n\t\tdel_timer_sync(&phba->fcp_poll_timer);\n\t\tbreak;\n\tcase LPFC_PCI_DEV_OC:\n\t\t/* Stop any OneConnect device specific driver timers */\n\t\tlpfc_sli4_stop_fcf_redisc_wait_timer(phba);\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0297 Invalid device group (x%x)\\n\",\n\t\t\t\tphba->pci_dev_grp);\n\t\tbreak;\n\t}\n\treturn;\n}\n\n/**\n * lpfc_block_mgmt_io - Mark a HBA's management interface as blocked\n * @phba: pointer to lpfc hba data structure.\n * @mbx_action: flag for mailbox no wait action.\n *\n * This routine marks a HBA's management interface as blocked. Once the HBA's\n * management interface is marked as blocked, all the user space access to\n * the HBA, whether they are from sysfs interface or libdfc interface will\n * all be blocked. The HBA is set to block the management interface when the\n * driver prepares the HBA interface for online or offline.\n **/\nstatic void\nlpfc_block_mgmt_io(struct lpfc_hba *phba, int mbx_action)\n{\n\tunsigned long iflag;\n\tuint8_t actcmd = MBX_HEARTBEAT;\n\tunsigned long timeout;\n\n\tspin_lock_irqsave(&phba->hbalock, iflag);\n\tphba->sli.sli_flag |= LPFC_BLOCK_MGMT_IO;\n\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\tif (mbx_action == LPFC_MBX_NO_WAIT)\n\t\treturn;\n\ttimeout = msecs_to_jiffies(LPFC_MBOX_TMO * 1000) + jiffies;\n\tspin_lock_irqsave(&phba->hbalock, iflag);\n\tif (phba->sli.mbox_active) {\n\t\tactcmd = phba->sli.mbox_active->u.mb.mbxCommand;\n\t\t/* Determine how long we might wait for the active mailbox\n\t\t * command to be gracefully completed by firmware.\n\t\t */\n\t\ttimeout = msecs_to_jiffies(lpfc_mbox_tmo_val(phba,\n\t\t\t\tphba->sli.mbox_active) * 1000) + jiffies;\n\t}\n\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n\n\t/* Wait for the outstnading mailbox command to complete */\n\twhile (phba->sli.mbox_active) {\n\t\t/* Check active mailbox complete status every 2ms */\n\t\tmsleep(2);\n\t\tif (time_after(jiffies, timeout)) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"2813 Mgmt IO is Blocked %x \"\n\t\t\t\t\t\"- mbox cmd %x still active\\n\",\n\t\t\t\t\tphba->sli.sli_flag, actcmd);\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\n/**\n * lpfc_sli4_node_prep - Assign RPIs for active nodes.\n * @phba: pointer to lpfc hba data structure.\n *\n * Allocate RPIs for all active remote nodes. This is needed whenever\n * an SLI4 adapter is reset and the driver is not unloading. Its purpose\n * is to fixup the temporary rpi assignments.\n **/\nvoid\nlpfc_sli4_node_prep(struct lpfc_hba *phba)\n{\n\tstruct lpfc_nodelist  *ndlp, *next_ndlp;\n\tstruct lpfc_vport **vports;\n\tint i, rpi;\n\n\tif (phba->sli_rev != LPFC_SLI_REV4)\n\t\treturn;\n\n\tvports = lpfc_create_vport_work_array(phba);\n\tif (vports == NULL)\n\t\treturn;\n\n\tfor (i = 0; i <= phba->max_vports && vports[i] != NULL; i++) {\n\t\tif (vports[i]->load_flag & FC_UNLOADING)\n\t\t\tcontinue;\n\n\t\tlist_for_each_entry_safe(ndlp, next_ndlp,\n\t\t\t\t\t &vports[i]->fc_nodes,\n\t\t\t\t\t nlp_listp) {\n\t\t\trpi = lpfc_sli4_alloc_rpi(phba);\n\t\t\tif (rpi == LPFC_RPI_ALLOC_ERROR) {\n\t\t\t\t/* TODO print log? */\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tndlp->nlp_rpi = rpi;\n\t\t\tlpfc_printf_vlog(ndlp->vport, KERN_INFO,\n\t\t\t\t\t LOG_NODE | LOG_DISCOVERY,\n\t\t\t\t\t \"0009 Assign RPI x%x to ndlp x%px \"\n\t\t\t\t\t \"DID:x%06x flg:x%x\\n\",\n\t\t\t\t\t ndlp->nlp_rpi, ndlp, ndlp->nlp_DID,\n\t\t\t\t\t ndlp->nlp_flag);\n\t\t}\n\t}\n\tlpfc_destroy_vport_work_array(phba, vports);\n}\n\n/**\n * lpfc_create_expedite_pool - create expedite pool\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine moves a batch of XRIs from lpfc_io_buf_list_put of HWQ 0\n * to expedite pool. Mark them as expedite.\n **/\nstatic void lpfc_create_expedite_pool(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tstruct lpfc_io_buf *lpfc_ncmd;\n\tstruct lpfc_io_buf *lpfc_ncmd_next;\n\tstruct lpfc_epd_pool *epd_pool;\n\tunsigned long iflag;\n\n\tepd_pool = &phba->epd_pool;\n\tqp = &phba->sli4_hba.hdwq[0];\n\n\tspin_lock_init(&epd_pool->lock);\n\tspin_lock_irqsave(&qp->io_buf_list_put_lock, iflag);\n\tspin_lock(&epd_pool->lock);\n\tINIT_LIST_HEAD(&epd_pool->list);\n\tlist_for_each_entry_safe(lpfc_ncmd, lpfc_ncmd_next,\n\t\t\t\t &qp->lpfc_io_buf_list_put, list) {\n\t\tlist_move_tail(&lpfc_ncmd->list, &epd_pool->list);\n\t\tlpfc_ncmd->expedite = true;\n\t\tqp->put_io_bufs--;\n\t\tepd_pool->count++;\n\t\tif (epd_pool->count >= XRI_BATCH)\n\t\t\tbreak;\n\t}\n\tspin_unlock(&epd_pool->lock);\n\tspin_unlock_irqrestore(&qp->io_buf_list_put_lock, iflag);\n}\n\n/**\n * lpfc_destroy_expedite_pool - destroy expedite pool\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine returns XRIs from expedite pool to lpfc_io_buf_list_put\n * of HWQ 0. Clear the mark.\n **/\nstatic void lpfc_destroy_expedite_pool(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tstruct lpfc_io_buf *lpfc_ncmd;\n\tstruct lpfc_io_buf *lpfc_ncmd_next;\n\tstruct lpfc_epd_pool *epd_pool;\n\tunsigned long iflag;\n\n\tepd_pool = &phba->epd_pool;\n\tqp = &phba->sli4_hba.hdwq[0];\n\n\tspin_lock_irqsave(&qp->io_buf_list_put_lock, iflag);\n\tspin_lock(&epd_pool->lock);\n\tlist_for_each_entry_safe(lpfc_ncmd, lpfc_ncmd_next,\n\t\t\t\t &epd_pool->list, list) {\n\t\tlist_move_tail(&lpfc_ncmd->list,\n\t\t\t       &qp->lpfc_io_buf_list_put);\n\t\tlpfc_ncmd->flags = false;\n\t\tqp->put_io_bufs++;\n\t\tepd_pool->count--;\n\t}\n\tspin_unlock(&epd_pool->lock);\n\tspin_unlock_irqrestore(&qp->io_buf_list_put_lock, iflag);\n}\n\n/**\n * lpfc_create_multixri_pools - create multi-XRI pools\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine initialize public, private per HWQ. Then, move XRIs from\n * lpfc_io_buf_list_put to public pool. High and low watermark are also\n * Initialized.\n **/\nvoid lpfc_create_multixri_pools(struct lpfc_hba *phba)\n{\n\tu32 i, j;\n\tu32 hwq_count;\n\tu32 count_per_hwq;\n\tstruct lpfc_io_buf *lpfc_ncmd;\n\tstruct lpfc_io_buf *lpfc_ncmd_next;\n\tunsigned long iflag;\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tstruct lpfc_multixri_pool *multixri_pool;\n\tstruct lpfc_pbl_pool *pbl_pool;\n\tstruct lpfc_pvt_pool *pvt_pool;\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"1234 num_hdw_queue=%d num_present_cpu=%d common_xri_cnt=%d\\n\",\n\t\t\tphba->cfg_hdw_queue, phba->sli4_hba.num_present_cpu,\n\t\t\tphba->sli4_hba.io_xri_cnt);\n\n\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME)\n\t\tlpfc_create_expedite_pool(phba);\n\n\thwq_count = phba->cfg_hdw_queue;\n\tcount_per_hwq = phba->sli4_hba.io_xri_cnt / hwq_count;\n\n\tfor (i = 0; i < hwq_count; i++) {\n\t\tmultixri_pool = kzalloc(sizeof(*multixri_pool), GFP_KERNEL);\n\n\t\tif (!multixri_pool) {\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\t\"1238 Failed to allocate memory for \"\n\t\t\t\t\t\"multixri_pool\\n\");\n\n\t\t\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME)\n\t\t\t\tlpfc_destroy_expedite_pool(phba);\n\n\t\t\tj = 0;\n\t\t\twhile (j < i) {\n\t\t\t\tqp = &phba->sli4_hba.hdwq[j];\n\t\t\t\tkfree(qp->p_multixri_pool);\n\t\t\t\tj++;\n\t\t\t}\n\t\t\tphba->cfg_xri_rebalancing = 0;\n\t\t\treturn;\n\t\t}\n\n\t\tqp = &phba->sli4_hba.hdwq[i];\n\t\tqp->p_multixri_pool = multixri_pool;\n\n\t\tmultixri_pool->xri_limit = count_per_hwq;\n\t\tmultixri_pool->rrb_next_hwqid = i;\n\n\t\t/* Deal with public free xri pool */\n\t\tpbl_pool = &multixri_pool->pbl_pool;\n\t\tspin_lock_init(&pbl_pool->lock);\n\t\tspin_lock_irqsave(&qp->io_buf_list_put_lock, iflag);\n\t\tspin_lock(&pbl_pool->lock);\n\t\tINIT_LIST_HEAD(&pbl_pool->list);\n\t\tlist_for_each_entry_safe(lpfc_ncmd, lpfc_ncmd_next,\n\t\t\t\t\t &qp->lpfc_io_buf_list_put, list) {\n\t\t\tlist_move_tail(&lpfc_ncmd->list, &pbl_pool->list);\n\t\t\tqp->put_io_bufs--;\n\t\t\tpbl_pool->count++;\n\t\t}\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"1235 Moved %d buffers from PUT list over to pbl_pool[%d]\\n\",\n\t\t\t\tpbl_pool->count, i);\n\t\tspin_unlock(&pbl_pool->lock);\n\t\tspin_unlock_irqrestore(&qp->io_buf_list_put_lock, iflag);\n\n\t\t/* Deal with private free xri pool */\n\t\tpvt_pool = &multixri_pool->pvt_pool;\n\t\tpvt_pool->high_watermark = multixri_pool->xri_limit / 2;\n\t\tpvt_pool->low_watermark = XRI_BATCH;\n\t\tspin_lock_init(&pvt_pool->lock);\n\t\tspin_lock_irqsave(&pvt_pool->lock, iflag);\n\t\tINIT_LIST_HEAD(&pvt_pool->list);\n\t\tpvt_pool->count = 0;\n\t\tspin_unlock_irqrestore(&pvt_pool->lock, iflag);\n\t}\n}\n\n/**\n * lpfc_destroy_multixri_pools - destroy multi-XRI pools\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine returns XRIs from public/private to lpfc_io_buf_list_put.\n **/\nstatic void lpfc_destroy_multixri_pools(struct lpfc_hba *phba)\n{\n\tu32 i;\n\tu32 hwq_count;\n\tstruct lpfc_io_buf *lpfc_ncmd;\n\tstruct lpfc_io_buf *lpfc_ncmd_next;\n\tunsigned long iflag;\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tstruct lpfc_multixri_pool *multixri_pool;\n\tstruct lpfc_pbl_pool *pbl_pool;\n\tstruct lpfc_pvt_pool *pvt_pool;\n\n\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME)\n\t\tlpfc_destroy_expedite_pool(phba);\n\n\tif (!(phba->pport->load_flag & FC_UNLOADING))\n\t\tlpfc_sli_flush_io_rings(phba);\n\n\thwq_count = phba->cfg_hdw_queue;\n\n\tfor (i = 0; i < hwq_count; i++) {\n\t\tqp = &phba->sli4_hba.hdwq[i];\n\t\tmultixri_pool = qp->p_multixri_pool;\n\t\tif (!multixri_pool)\n\t\t\tcontinue;\n\n\t\tqp->p_multixri_pool = NULL;\n\n\t\tspin_lock_irqsave(&qp->io_buf_list_put_lock, iflag);\n\n\t\t/* Deal with public free xri pool */\n\t\tpbl_pool = &multixri_pool->pbl_pool;\n\t\tspin_lock(&pbl_pool->lock);\n\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"1236 Moving %d buffers from pbl_pool[%d] TO PUT list\\n\",\n\t\t\t\tpbl_pool->count, i);\n\n\t\tlist_for_each_entry_safe(lpfc_ncmd, lpfc_ncmd_next,\n\t\t\t\t\t &pbl_pool->list, list) {\n\t\t\tlist_move_tail(&lpfc_ncmd->list,\n\t\t\t\t       &qp->lpfc_io_buf_list_put);\n\t\t\tqp->put_io_bufs++;\n\t\t\tpbl_pool->count--;\n\t\t}\n\n\t\tINIT_LIST_HEAD(&pbl_pool->list);\n\t\tpbl_pool->count = 0;\n\n\t\tspin_unlock(&pbl_pool->lock);\n\n\t\t/* Deal with private free xri pool */\n\t\tpvt_pool = &multixri_pool->pvt_pool;\n\t\tspin_lock(&pvt_pool->lock);\n\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"1237 Moving %d buffers from pvt_pool[%d] TO PUT list\\n\",\n\t\t\t\tpvt_pool->count, i);\n\n\t\tlist_for_each_entry_safe(lpfc_ncmd, lpfc_ncmd_next,\n\t\t\t\t\t &pvt_pool->list, list) {\n\t\t\tlist_move_tail(&lpfc_ncmd->list,\n\t\t\t\t       &qp->lpfc_io_buf_list_put);\n\t\t\tqp->put_io_bufs++;\n\t\t\tpvt_pool->count--;\n\t\t}\n\n\t\tINIT_LIST_HEAD(&pvt_pool->list);\n\t\tpvt_pool->count = 0;\n\n\t\tspin_unlock(&pvt_pool->lock);\n\t\tspin_unlock_irqrestore(&qp->io_buf_list_put_lock, iflag);\n\n\t\tkfree(multixri_pool);\n\t}\n}\n\n/**\n * lpfc_online - Initialize and bring a HBA online\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine initializes the HBA and brings a HBA online. During this\n * process, the management interface is blocked to prevent user space access\n * to the HBA interfering with the driver initialization.\n *\n * Return codes\n *   0 - successful\n *   1 - failed\n **/\nint\nlpfc_online(struct lpfc_hba *phba)\n{\n\tstruct lpfc_vport *vport;\n\tstruct lpfc_vport **vports;\n\tint i, error = 0;\n\tbool vpis_cleared = false;\n\n\tif (!phba)\n\t\treturn 0;\n\tvport = phba->pport;\n\n\tif (!(vport->fc_flag & FC_OFFLINE_MODE))\n\t\treturn 0;\n\n\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\"0458 Bring Adapter online\\n\");\n\n\tlpfc_block_mgmt_io(phba, LPFC_MBX_WAIT);\n\n\tif (phba->sli_rev == LPFC_SLI_REV4) {\n\t\tif (lpfc_sli4_hba_setup(phba)) { /* Initialize SLI4 HBA */\n\t\t\tlpfc_unblock_mgmt_io(phba);\n\t\t\treturn 1;\n\t\t}\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tif (!phba->sli4_hba.max_cfg_param.vpi_used)\n\t\t\tvpis_cleared = true;\n\t\tspin_unlock_irq(&phba->hbalock);\n\n\t\t/* Reestablish the local initiator port.\n\t\t * The offline process destroyed the previous lport.\n\t\t */\n\t\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME &&\n\t\t\t\t!phba->nvmet_support) {\n\t\t\terror = lpfc_nvme_create_localport(phba->pport);\n\t\t\tif (error)\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"6132 NVME restore reg failed \"\n\t\t\t\t\t\"on nvmei error x%x\\n\", error);\n\t\t}\n\t} else {\n\t\tlpfc_sli_queue_init(phba);\n\t\tif (lpfc_sli_hba_setup(phba)) {\t/* Initialize SLI2/SLI3 HBA */\n\t\t\tlpfc_unblock_mgmt_io(phba);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tvports = lpfc_create_vport_work_array(phba);\n\tif (vports != NULL) {\n\t\tfor (i = 0; i <= phba->max_vports && vports[i] != NULL; i++) {\n\t\t\tstruct Scsi_Host *shost;\n\t\t\tshost = lpfc_shost_from_vport(vports[i]);\n\t\t\tspin_lock_irq(shost->host_lock);\n\t\t\tvports[i]->fc_flag &= ~FC_OFFLINE_MODE;\n\t\t\tif (phba->sli3_options & LPFC_SLI3_NPIV_ENABLED)\n\t\t\t\tvports[i]->fc_flag |= FC_VPORT_NEEDS_REG_VPI;\n\t\t\tif (phba->sli_rev == LPFC_SLI_REV4) {\n\t\t\t\tvports[i]->fc_flag |= FC_VPORT_NEEDS_INIT_VPI;\n\t\t\t\tif ((vpis_cleared) &&\n\t\t\t\t    (vports[i]->port_type !=\n\t\t\t\t\tLPFC_PHYSICAL_PORT))\n\t\t\t\t\tvports[i]->vpi = 0;\n\t\t\t}\n\t\t\tspin_unlock_irq(shost->host_lock);\n\t\t}\n\t}\n\tlpfc_destroy_vport_work_array(phba, vports);\n\n\tif (phba->cfg_xri_rebalancing)\n\t\tlpfc_create_multixri_pools(phba);\n\n\tlpfc_cpuhp_add(phba);\n\n\tlpfc_unblock_mgmt_io(phba);\n\treturn 0;\n}\n\n/**\n * lpfc_unblock_mgmt_io - Mark a HBA's management interface to be not blocked\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine marks a HBA's management interface as not blocked. Once the\n * HBA's management interface is marked as not blocked, all the user space\n * access to the HBA, whether they are from sysfs interface or libdfc\n * interface will be allowed. The HBA is set to block the management interface\n * when the driver prepares the HBA interface for online or offline and then\n * set to unblock the management interface afterwards.\n **/\nvoid\nlpfc_unblock_mgmt_io(struct lpfc_hba * phba)\n{\n\tunsigned long iflag;\n\n\tspin_lock_irqsave(&phba->hbalock, iflag);\n\tphba->sli.sli_flag &= ~LPFC_BLOCK_MGMT_IO;\n\tspin_unlock_irqrestore(&phba->hbalock, iflag);\n}\n\n/**\n * lpfc_offline_prep - Prepare a HBA to be brought offline\n * @phba: pointer to lpfc hba data structure.\n * @mbx_action: flag for mailbox shutdown action.\n *\n * This routine is invoked to prepare a HBA to be brought offline. It performs\n * unregistration login to all the nodes on all vports and flushes the mailbox\n * queue to make it ready to be brought offline.\n **/\nvoid\nlpfc_offline_prep(struct lpfc_hba *phba, int mbx_action)\n{\n\tstruct lpfc_vport *vport = phba->pport;\n\tstruct lpfc_nodelist  *ndlp, *next_ndlp;\n\tstruct lpfc_vport **vports;\n\tstruct Scsi_Host *shost;\n\tint i;\n\n\tif (vport->fc_flag & FC_OFFLINE_MODE)\n\t\treturn;\n\n\tlpfc_block_mgmt_io(phba, mbx_action);\n\n\tlpfc_linkdown(phba);\n\n\t/* Issue an unreg_login to all nodes on all vports */\n\tvports = lpfc_create_vport_work_array(phba);\n\tif (vports != NULL) {\n\t\tfor (i = 0; i <= phba->max_vports && vports[i] != NULL; i++) {\n\t\t\tif (vports[i]->load_flag & FC_UNLOADING)\n\t\t\t\tcontinue;\n\t\t\tshost = lpfc_shost_from_vport(vports[i]);\n\t\t\tspin_lock_irq(shost->host_lock);\n\t\t\tvports[i]->vpi_state &= ~LPFC_VPI_REGISTERED;\n\t\t\tvports[i]->fc_flag |= FC_VPORT_NEEDS_REG_VPI;\n\t\t\tvports[i]->fc_flag &= ~FC_VFI_REGISTERED;\n\t\t\tspin_unlock_irq(shost->host_lock);\n\n\t\t\tshost =\tlpfc_shost_from_vport(vports[i]);\n\t\t\tlist_for_each_entry_safe(ndlp, next_ndlp,\n\t\t\t\t\t\t &vports[i]->fc_nodes,\n\t\t\t\t\t\t nlp_listp) {\n\t\t\t\tif (ndlp->nlp_state == NLP_STE_UNUSED_NODE) {\n\t\t\t\t\t/* Driver must assume RPI is invalid for\n\t\t\t\t\t * any unused or inactive node.\n\t\t\t\t\t */\n\t\t\t\t\tndlp->nlp_rpi = LPFC_RPI_ALLOC_ERROR;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tspin_lock_irq(&ndlp->lock);\n\t\t\t\tndlp->nlp_flag &= ~NLP_NPR_ADISC;\n\t\t\t\tspin_unlock_irq(&ndlp->lock);\n\t\t\t\t/*\n\t\t\t\t * Whenever an SLI4 port goes offline, free the\n\t\t\t\t * RPI. Get a new RPI when the adapter port\n\t\t\t\t * comes back online.\n\t\t\t\t */\n\t\t\t\tif (phba->sli_rev == LPFC_SLI_REV4) {\n\t\t\t\t\tlpfc_printf_vlog(vports[i], KERN_INFO,\n\t\t\t\t\t\t LOG_NODE | LOG_DISCOVERY,\n\t\t\t\t\t\t \"0011 Free RPI x%x on \"\n\t\t\t\t\t\t \"ndlp: %p did x%x\\n\",\n\t\t\t\t\t\t ndlp->nlp_rpi, ndlp,\n\t\t\t\t\t\t ndlp->nlp_DID);\n\t\t\t\t\tlpfc_sli4_free_rpi(phba, ndlp->nlp_rpi);\n\t\t\t\t\tndlp->nlp_rpi = LPFC_RPI_ALLOC_ERROR;\n\t\t\t\t}\n\t\t\t\tlpfc_unreg_rpi(vports[i], ndlp);\n\n\t\t\t\tif (ndlp->nlp_type & NLP_FABRIC) {\n\t\t\t\t\tlpfc_disc_state_machine(vports[i], ndlp,\n\t\t\t\t\t\tNULL, NLP_EVT_DEVICE_RECOVERY);\n\n\t\t\t\t\t/* Don't remove the node unless the\n\t\t\t\t\t * has been unregistered with the\n\t\t\t\t\t * transport.  If so, let dev_loss\n\t\t\t\t\t * take care of the node.\n\t\t\t\t\t */\n\t\t\t\t\tif (!(ndlp->fc4_xpt_flags &\n\t\t\t\t\t      (NVME_XPT_REGD | SCSI_XPT_REGD)))\n\t\t\t\t\t\tlpfc_disc_state_machine\n\t\t\t\t\t\t\t(vports[i], ndlp,\n\t\t\t\t\t\t\t NULL,\n\t\t\t\t\t\t\t NLP_EVT_DEVICE_RM);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tlpfc_destroy_vport_work_array(phba, vports);\n\n\tlpfc_sli_mbox_sys_shutdown(phba, mbx_action);\n\n\tif (phba->wq)\n\t\tflush_workqueue(phba->wq);\n}\n\n/**\n * lpfc_offline - Bring a HBA offline\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine actually brings a HBA offline. It stops all the timers\n * associated with the HBA, brings down the SLI layer, and eventually\n * marks the HBA as in offline state for the upper layer protocol.\n **/\nvoid\nlpfc_offline(struct lpfc_hba *phba)\n{\n\tstruct Scsi_Host  *shost;\n\tstruct lpfc_vport **vports;\n\tint i;\n\n\tif (phba->pport->fc_flag & FC_OFFLINE_MODE)\n\t\treturn;\n\n\t/* stop port and all timers associated with this hba */\n\tlpfc_stop_port(phba);\n\n\t/* Tear down the local and target port registrations.  The\n\t * nvme transports need to cleanup.\n\t */\n\tlpfc_nvmet_destroy_targetport(phba);\n\tlpfc_nvme_destroy_localport(phba->pport);\n\n\tvports = lpfc_create_vport_work_array(phba);\n\tif (vports != NULL)\n\t\tfor (i = 0; i <= phba->max_vports && vports[i] != NULL; i++)\n\t\t\tlpfc_stop_vport_timers(vports[i]);\n\tlpfc_destroy_vport_work_array(phba, vports);\n\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\"0460 Bring Adapter offline\\n\");\n\t/* Bring down the SLI Layer and cleanup.  The HBA is offline\n\t   now.  */\n\tlpfc_sli_hba_down(phba);\n\tspin_lock_irq(&phba->hbalock);\n\tphba->work_ha = 0;\n\tspin_unlock_irq(&phba->hbalock);\n\tvports = lpfc_create_vport_work_array(phba);\n\tif (vports != NULL)\n\t\tfor (i = 0; i <= phba->max_vports && vports[i] != NULL; i++) {\n\t\t\tshost = lpfc_shost_from_vport(vports[i]);\n\t\t\tspin_lock_irq(shost->host_lock);\n\t\t\tvports[i]->work_port_events = 0;\n\t\t\tvports[i]->fc_flag |= FC_OFFLINE_MODE;\n\t\t\tspin_unlock_irq(shost->host_lock);\n\t\t}\n\tlpfc_destroy_vport_work_array(phba, vports);\n\t/* If OFFLINE flag is clear (i.e. unloading), cpuhp removal is handled\n\t * in hba_unset\n\t */\n\tif (phba->pport->fc_flag & FC_OFFLINE_MODE)\n\t\t__lpfc_cpuhp_remove(phba);\n\n\tif (phba->cfg_xri_rebalancing)\n\t\tlpfc_destroy_multixri_pools(phba);\n}\n\n/**\n * lpfc_scsi_free - Free all the SCSI buffers and IOCBs from driver lists\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is to free all the SCSI buffers and IOCBs from the driver\n * list back to kernel. It is called from lpfc_pci_remove_one to free\n * the internal resources before the device is removed from the system.\n **/\nstatic void\nlpfc_scsi_free(struct lpfc_hba *phba)\n{\n\tstruct lpfc_io_buf *sb, *sb_next;\n\n\tif (!(phba->cfg_enable_fc4_type & LPFC_ENABLE_FCP))\n\t\treturn;\n\n\tspin_lock_irq(&phba->hbalock);\n\n\t/* Release all the lpfc_scsi_bufs maintained by this host. */\n\n\tspin_lock(&phba->scsi_buf_list_put_lock);\n\tlist_for_each_entry_safe(sb, sb_next, &phba->lpfc_scsi_buf_list_put,\n\t\t\t\t list) {\n\t\tlist_del(&sb->list);\n\t\tdma_pool_free(phba->lpfc_sg_dma_buf_pool, sb->data,\n\t\t\t      sb->dma_handle);\n\t\tkfree(sb);\n\t\tphba->total_scsi_bufs--;\n\t}\n\tspin_unlock(&phba->scsi_buf_list_put_lock);\n\n\tspin_lock(&phba->scsi_buf_list_get_lock);\n\tlist_for_each_entry_safe(sb, sb_next, &phba->lpfc_scsi_buf_list_get,\n\t\t\t\t list) {\n\t\tlist_del(&sb->list);\n\t\tdma_pool_free(phba->lpfc_sg_dma_buf_pool, sb->data,\n\t\t\t      sb->dma_handle);\n\t\tkfree(sb);\n\t\tphba->total_scsi_bufs--;\n\t}\n\tspin_unlock(&phba->scsi_buf_list_get_lock);\n\tspin_unlock_irq(&phba->hbalock);\n}\n\n/**\n * lpfc_io_free - Free all the IO buffers and IOCBs from driver lists\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is to free all the IO buffers and IOCBs from the driver\n * list back to kernel. It is called from lpfc_pci_remove_one to free\n * the internal resources before the device is removed from the system.\n **/\nvoid\nlpfc_io_free(struct lpfc_hba *phba)\n{\n\tstruct lpfc_io_buf *lpfc_ncmd, *lpfc_ncmd_next;\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tint idx;\n\n\tfor (idx = 0; idx < phba->cfg_hdw_queue; idx++) {\n\t\tqp = &phba->sli4_hba.hdwq[idx];\n\t\t/* Release all the lpfc_nvme_bufs maintained by this host. */\n\t\tspin_lock(&qp->io_buf_list_put_lock);\n\t\tlist_for_each_entry_safe(lpfc_ncmd, lpfc_ncmd_next,\n\t\t\t\t\t &qp->lpfc_io_buf_list_put,\n\t\t\t\t\t list) {\n\t\t\tlist_del(&lpfc_ncmd->list);\n\t\t\tqp->put_io_bufs--;\n\t\t\tdma_pool_free(phba->lpfc_sg_dma_buf_pool,\n\t\t\t\t      lpfc_ncmd->data, lpfc_ncmd->dma_handle);\n\t\t\tif (phba->cfg_xpsgl && !phba->nvmet_support)\n\t\t\t\tlpfc_put_sgl_per_hdwq(phba, lpfc_ncmd);\n\t\t\tlpfc_put_cmd_rsp_buf_per_hdwq(phba, lpfc_ncmd);\n\t\t\tkfree(lpfc_ncmd);\n\t\t\tqp->total_io_bufs--;\n\t\t}\n\t\tspin_unlock(&qp->io_buf_list_put_lock);\n\n\t\tspin_lock(&qp->io_buf_list_get_lock);\n\t\tlist_for_each_entry_safe(lpfc_ncmd, lpfc_ncmd_next,\n\t\t\t\t\t &qp->lpfc_io_buf_list_get,\n\t\t\t\t\t list) {\n\t\t\tlist_del(&lpfc_ncmd->list);\n\t\t\tqp->get_io_bufs--;\n\t\t\tdma_pool_free(phba->lpfc_sg_dma_buf_pool,\n\t\t\t\t      lpfc_ncmd->data, lpfc_ncmd->dma_handle);\n\t\t\tif (phba->cfg_xpsgl && !phba->nvmet_support)\n\t\t\t\tlpfc_put_sgl_per_hdwq(phba, lpfc_ncmd);\n\t\t\tlpfc_put_cmd_rsp_buf_per_hdwq(phba, lpfc_ncmd);\n\t\t\tkfree(lpfc_ncmd);\n\t\t\tqp->total_io_bufs--;\n\t\t}\n\t\tspin_unlock(&qp->io_buf_list_get_lock);\n\t}\n}\n\n/**\n * lpfc_sli4_els_sgl_update - update ELS xri-sgl sizing and mapping\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine first calculates the sizes of the current els and allocated\n * scsi sgl lists, and then goes through all sgls to updates the physical\n * XRIs assigned due to port function reset. During port initialization, the\n * current els and allocated scsi sgl lists are 0s.\n *\n * Return codes\n *   0 - successful (for now, it always returns 0)\n **/\nint\nlpfc_sli4_els_sgl_update(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sglq *sglq_entry = NULL, *sglq_entry_next = NULL;\n\tuint16_t i, lxri, xri_cnt, els_xri_cnt;\n\tLIST_HEAD(els_sgl_list);\n\tint rc;\n\n\t/*\n\t * update on pci function's els xri-sgl list\n\t */\n\tels_xri_cnt = lpfc_sli4_get_els_iocb_cnt(phba);\n\n\tif (els_xri_cnt > phba->sli4_hba.els_xri_cnt) {\n\t\t/* els xri-sgl expanded */\n\t\txri_cnt = els_xri_cnt - phba->sli4_hba.els_xri_cnt;\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"3157 ELS xri-sgl count increased from \"\n\t\t\t\t\"%d to %d\\n\", phba->sli4_hba.els_xri_cnt,\n\t\t\t\tels_xri_cnt);\n\t\t/* allocate the additional els sgls */\n\t\tfor (i = 0; i < xri_cnt; i++) {\n\t\t\tsglq_entry = kzalloc(sizeof(struct lpfc_sglq),\n\t\t\t\t\t     GFP_KERNEL);\n\t\t\tif (sglq_entry == NULL) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\t\"2562 Failure to allocate an \"\n\t\t\t\t\t\t\"ELS sgl entry:%d\\n\", i);\n\t\t\t\trc = -ENOMEM;\n\t\t\t\tgoto out_free_mem;\n\t\t\t}\n\t\t\tsglq_entry->buff_type = GEN_BUFF_TYPE;\n\t\t\tsglq_entry->virt = lpfc_mbuf_alloc(phba, 0,\n\t\t\t\t\t\t\t   &sglq_entry->phys);\n\t\t\tif (sglq_entry->virt == NULL) {\n\t\t\t\tkfree(sglq_entry);\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\t\"2563 Failure to allocate an \"\n\t\t\t\t\t\t\"ELS mbuf:%d\\n\", i);\n\t\t\t\trc = -ENOMEM;\n\t\t\t\tgoto out_free_mem;\n\t\t\t}\n\t\t\tsglq_entry->sgl = sglq_entry->virt;\n\t\t\tmemset(sglq_entry->sgl, 0, LPFC_BPL_SIZE);\n\t\t\tsglq_entry->state = SGL_FREED;\n\t\t\tlist_add_tail(&sglq_entry->list, &els_sgl_list);\n\t\t}\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tspin_lock(&phba->sli4_hba.sgl_list_lock);\n\t\tlist_splice_init(&els_sgl_list,\n\t\t\t\t &phba->sli4_hba.lpfc_els_sgl_list);\n\t\tspin_unlock(&phba->sli4_hba.sgl_list_lock);\n\t\tspin_unlock_irq(&phba->hbalock);\n\t} else if (els_xri_cnt < phba->sli4_hba.els_xri_cnt) {\n\t\t/* els xri-sgl shrinked */\n\t\txri_cnt = phba->sli4_hba.els_xri_cnt - els_xri_cnt;\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"3158 ELS xri-sgl count decreased from \"\n\t\t\t\t\"%d to %d\\n\", phba->sli4_hba.els_xri_cnt,\n\t\t\t\tels_xri_cnt);\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tspin_lock(&phba->sli4_hba.sgl_list_lock);\n\t\tlist_splice_init(&phba->sli4_hba.lpfc_els_sgl_list,\n\t\t\t\t &els_sgl_list);\n\t\t/* release extra els sgls from list */\n\t\tfor (i = 0; i < xri_cnt; i++) {\n\t\t\tlist_remove_head(&els_sgl_list,\n\t\t\t\t\t sglq_entry, struct lpfc_sglq, list);\n\t\t\tif (sglq_entry) {\n\t\t\t\t__lpfc_mbuf_free(phba, sglq_entry->virt,\n\t\t\t\t\t\t sglq_entry->phys);\n\t\t\t\tkfree(sglq_entry);\n\t\t\t}\n\t\t}\n\t\tlist_splice_init(&els_sgl_list,\n\t\t\t\t &phba->sli4_hba.lpfc_els_sgl_list);\n\t\tspin_unlock(&phba->sli4_hba.sgl_list_lock);\n\t\tspin_unlock_irq(&phba->hbalock);\n\t} else\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"3163 ELS xri-sgl count unchanged: %d\\n\",\n\t\t\t\tels_xri_cnt);\n\tphba->sli4_hba.els_xri_cnt = els_xri_cnt;\n\n\t/* update xris to els sgls on the list */\n\tsglq_entry = NULL;\n\tsglq_entry_next = NULL;\n\tlist_for_each_entry_safe(sglq_entry, sglq_entry_next,\n\t\t\t\t &phba->sli4_hba.lpfc_els_sgl_list, list) {\n\t\tlxri = lpfc_sli4_next_xritag(phba);\n\t\tif (lxri == NO_XRI) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\"2400 Failed to allocate xri for \"\n\t\t\t\t\t\"ELS sgl\\n\");\n\t\t\trc = -ENOMEM;\n\t\t\tgoto out_free_mem;\n\t\t}\n\t\tsglq_entry->sli4_lxritag = lxri;\n\t\tsglq_entry->sli4_xritag = phba->sli4_hba.xri_ids[lxri];\n\t}\n\treturn 0;\n\nout_free_mem:\n\tlpfc_free_els_sgl_list(phba);\n\treturn rc;\n}\n\n/**\n * lpfc_sli4_nvmet_sgl_update - update xri-sgl sizing and mapping\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine first calculates the sizes of the current els and allocated\n * scsi sgl lists, and then goes through all sgls to updates the physical\n * XRIs assigned due to port function reset. During port initialization, the\n * current els and allocated scsi sgl lists are 0s.\n *\n * Return codes\n *   0 - successful (for now, it always returns 0)\n **/\nint\nlpfc_sli4_nvmet_sgl_update(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sglq *sglq_entry = NULL, *sglq_entry_next = NULL;\n\tuint16_t i, lxri, xri_cnt, els_xri_cnt;\n\tuint16_t nvmet_xri_cnt;\n\tLIST_HEAD(nvmet_sgl_list);\n\tint rc;\n\n\t/*\n\t * update on pci function's nvmet xri-sgl list\n\t */\n\tels_xri_cnt = lpfc_sli4_get_els_iocb_cnt(phba);\n\n\t/* For NVMET, ALL remaining XRIs are dedicated for IO processing */\n\tnvmet_xri_cnt = phba->sli4_hba.max_cfg_param.max_xri - els_xri_cnt;\n\tif (nvmet_xri_cnt > phba->sli4_hba.nvmet_xri_cnt) {\n\t\t/* els xri-sgl expanded */\n\t\txri_cnt = nvmet_xri_cnt - phba->sli4_hba.nvmet_xri_cnt;\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"6302 NVMET xri-sgl cnt grew from %d to %d\\n\",\n\t\t\t\tphba->sli4_hba.nvmet_xri_cnt, nvmet_xri_cnt);\n\t\t/* allocate the additional nvmet sgls */\n\t\tfor (i = 0; i < xri_cnt; i++) {\n\t\t\tsglq_entry = kzalloc(sizeof(struct lpfc_sglq),\n\t\t\t\t\t     GFP_KERNEL);\n\t\t\tif (sglq_entry == NULL) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\t\"6303 Failure to allocate an \"\n\t\t\t\t\t\t\"NVMET sgl entry:%d\\n\", i);\n\t\t\t\trc = -ENOMEM;\n\t\t\t\tgoto out_free_mem;\n\t\t\t}\n\t\t\tsglq_entry->buff_type = NVMET_BUFF_TYPE;\n\t\t\tsglq_entry->virt = lpfc_nvmet_buf_alloc(phba, 0,\n\t\t\t\t\t\t\t   &sglq_entry->phys);\n\t\t\tif (sglq_entry->virt == NULL) {\n\t\t\t\tkfree(sglq_entry);\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\t\"6304 Failure to allocate an \"\n\t\t\t\t\t\t\"NVMET buf:%d\\n\", i);\n\t\t\t\trc = -ENOMEM;\n\t\t\t\tgoto out_free_mem;\n\t\t\t}\n\t\t\tsglq_entry->sgl = sglq_entry->virt;\n\t\t\tmemset(sglq_entry->sgl, 0,\n\t\t\t       phba->cfg_sg_dma_buf_size);\n\t\t\tsglq_entry->state = SGL_FREED;\n\t\t\tlist_add_tail(&sglq_entry->list, &nvmet_sgl_list);\n\t\t}\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tspin_lock(&phba->sli4_hba.sgl_list_lock);\n\t\tlist_splice_init(&nvmet_sgl_list,\n\t\t\t\t &phba->sli4_hba.lpfc_nvmet_sgl_list);\n\t\tspin_unlock(&phba->sli4_hba.sgl_list_lock);\n\t\tspin_unlock_irq(&phba->hbalock);\n\t} else if (nvmet_xri_cnt < phba->sli4_hba.nvmet_xri_cnt) {\n\t\t/* nvmet xri-sgl shrunk */\n\t\txri_cnt = phba->sli4_hba.nvmet_xri_cnt - nvmet_xri_cnt;\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"6305 NVMET xri-sgl count decreased from \"\n\t\t\t\t\"%d to %d\\n\", phba->sli4_hba.nvmet_xri_cnt,\n\t\t\t\tnvmet_xri_cnt);\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tspin_lock(&phba->sli4_hba.sgl_list_lock);\n\t\tlist_splice_init(&phba->sli4_hba.lpfc_nvmet_sgl_list,\n\t\t\t\t &nvmet_sgl_list);\n\t\t/* release extra nvmet sgls from list */\n\t\tfor (i = 0; i < xri_cnt; i++) {\n\t\t\tlist_remove_head(&nvmet_sgl_list,\n\t\t\t\t\t sglq_entry, struct lpfc_sglq, list);\n\t\t\tif (sglq_entry) {\n\t\t\t\tlpfc_nvmet_buf_free(phba, sglq_entry->virt,\n\t\t\t\t\t\t    sglq_entry->phys);\n\t\t\t\tkfree(sglq_entry);\n\t\t\t}\n\t\t}\n\t\tlist_splice_init(&nvmet_sgl_list,\n\t\t\t\t &phba->sli4_hba.lpfc_nvmet_sgl_list);\n\t\tspin_unlock(&phba->sli4_hba.sgl_list_lock);\n\t\tspin_unlock_irq(&phba->hbalock);\n\t} else\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"6306 NVMET xri-sgl count unchanged: %d\\n\",\n\t\t\t\tnvmet_xri_cnt);\n\tphba->sli4_hba.nvmet_xri_cnt = nvmet_xri_cnt;\n\n\t/* update xris to nvmet sgls on the list */\n\tsglq_entry = NULL;\n\tsglq_entry_next = NULL;\n\tlist_for_each_entry_safe(sglq_entry, sglq_entry_next,\n\t\t\t\t &phba->sli4_hba.lpfc_nvmet_sgl_list, list) {\n\t\tlxri = lpfc_sli4_next_xritag(phba);\n\t\tif (lxri == NO_XRI) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\"6307 Failed to allocate xri for \"\n\t\t\t\t\t\"NVMET sgl\\n\");\n\t\t\trc = -ENOMEM;\n\t\t\tgoto out_free_mem;\n\t\t}\n\t\tsglq_entry->sli4_lxritag = lxri;\n\t\tsglq_entry->sli4_xritag = phba->sli4_hba.xri_ids[lxri];\n\t}\n\treturn 0;\n\nout_free_mem:\n\tlpfc_free_nvmet_sgl_list(phba);\n\treturn rc;\n}\n\nint\nlpfc_io_buf_flush(struct lpfc_hba *phba, struct list_head *cbuf)\n{\n\tLIST_HEAD(blist);\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tstruct lpfc_io_buf *lpfc_cmd;\n\tstruct lpfc_io_buf *iobufp, *prev_iobufp;\n\tint idx, cnt, xri, inserted;\n\n\tcnt = 0;\n\tfor (idx = 0; idx < phba->cfg_hdw_queue; idx++) {\n\t\tqp = &phba->sli4_hba.hdwq[idx];\n\t\tspin_lock_irq(&qp->io_buf_list_get_lock);\n\t\tspin_lock(&qp->io_buf_list_put_lock);\n\n\t\t/* Take everything off the get and put lists */\n\t\tlist_splice_init(&qp->lpfc_io_buf_list_get, &blist);\n\t\tlist_splice(&qp->lpfc_io_buf_list_put, &blist);\n\t\tINIT_LIST_HEAD(&qp->lpfc_io_buf_list_get);\n\t\tINIT_LIST_HEAD(&qp->lpfc_io_buf_list_put);\n\t\tcnt += qp->get_io_bufs + qp->put_io_bufs;\n\t\tqp->get_io_bufs = 0;\n\t\tqp->put_io_bufs = 0;\n\t\tqp->total_io_bufs = 0;\n\t\tspin_unlock(&qp->io_buf_list_put_lock);\n\t\tspin_unlock_irq(&qp->io_buf_list_get_lock);\n\t}\n\n\t/*\n\t * Take IO buffers off blist and put on cbuf sorted by XRI.\n\t * This is because POST_SGL takes a sequential range of XRIs\n\t * to post to the firmware.\n\t */\n\tfor (idx = 0; idx < cnt; idx++) {\n\t\tlist_remove_head(&blist, lpfc_cmd, struct lpfc_io_buf, list);\n\t\tif (!lpfc_cmd)\n\t\t\treturn cnt;\n\t\tif (idx == 0) {\n\t\t\tlist_add_tail(&lpfc_cmd->list, cbuf);\n\t\t\tcontinue;\n\t\t}\n\t\txri = lpfc_cmd->cur_iocbq.sli4_xritag;\n\t\tinserted = 0;\n\t\tprev_iobufp = NULL;\n\t\tlist_for_each_entry(iobufp, cbuf, list) {\n\t\t\tif (xri < iobufp->cur_iocbq.sli4_xritag) {\n\t\t\t\tif (prev_iobufp)\n\t\t\t\t\tlist_add(&lpfc_cmd->list,\n\t\t\t\t\t\t &prev_iobufp->list);\n\t\t\t\telse\n\t\t\t\t\tlist_add(&lpfc_cmd->list, cbuf);\n\t\t\t\tinserted = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tprev_iobufp = iobufp;\n\t\t}\n\t\tif (!inserted)\n\t\t\tlist_add_tail(&lpfc_cmd->list, cbuf);\n\t}\n\treturn cnt;\n}\n\nint\nlpfc_io_buf_replenish(struct lpfc_hba *phba, struct list_head *cbuf)\n{\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tstruct lpfc_io_buf *lpfc_cmd;\n\tint idx, cnt;\n\n\tqp = phba->sli4_hba.hdwq;\n\tcnt = 0;\n\twhile (!list_empty(cbuf)) {\n\t\tfor (idx = 0; idx < phba->cfg_hdw_queue; idx++) {\n\t\t\tlist_remove_head(cbuf, lpfc_cmd,\n\t\t\t\t\t struct lpfc_io_buf, list);\n\t\t\tif (!lpfc_cmd)\n\t\t\t\treturn cnt;\n\t\t\tcnt++;\n\t\t\tqp = &phba->sli4_hba.hdwq[idx];\n\t\t\tlpfc_cmd->hdwq_no = idx;\n\t\t\tlpfc_cmd->hdwq = qp;\n\t\t\tlpfc_cmd->cur_iocbq.wqe_cmpl = NULL;\n\t\t\tlpfc_cmd->cur_iocbq.iocb_cmpl = NULL;\n\t\t\tspin_lock(&qp->io_buf_list_put_lock);\n\t\t\tlist_add_tail(&lpfc_cmd->list,\n\t\t\t\t      &qp->lpfc_io_buf_list_put);\n\t\t\tqp->put_io_bufs++;\n\t\t\tqp->total_io_bufs++;\n\t\t\tspin_unlock(&qp->io_buf_list_put_lock);\n\t\t}\n\t}\n\treturn cnt;\n}\n\n/**\n * lpfc_sli4_io_sgl_update - update xri-sgl sizing and mapping\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine first calculates the sizes of the current els and allocated\n * scsi sgl lists, and then goes through all sgls to updates the physical\n * XRIs assigned due to port function reset. During port initialization, the\n * current els and allocated scsi sgl lists are 0s.\n *\n * Return codes\n *   0 - successful (for now, it always returns 0)\n **/\nint\nlpfc_sli4_io_sgl_update(struct lpfc_hba *phba)\n{\n\tstruct lpfc_io_buf *lpfc_ncmd = NULL, *lpfc_ncmd_next = NULL;\n\tuint16_t i, lxri, els_xri_cnt;\n\tuint16_t io_xri_cnt, io_xri_max;\n\tLIST_HEAD(io_sgl_list);\n\tint rc, cnt;\n\n\t/*\n\t * update on pci function's allocated nvme xri-sgl list\n\t */\n\n\t/* maximum number of xris available for nvme buffers */\n\tels_xri_cnt = lpfc_sli4_get_els_iocb_cnt(phba);\n\tio_xri_max = phba->sli4_hba.max_cfg_param.max_xri - els_xri_cnt;\n\tphba->sli4_hba.io_xri_max = io_xri_max;\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\"6074 Current allocated XRI sgl count:%d, \"\n\t\t\t\"maximum XRI count:%d\\n\",\n\t\t\tphba->sli4_hba.io_xri_cnt,\n\t\t\tphba->sli4_hba.io_xri_max);\n\n\tcnt = lpfc_io_buf_flush(phba, &io_sgl_list);\n\n\tif (phba->sli4_hba.io_xri_cnt > phba->sli4_hba.io_xri_max) {\n\t\t/* max nvme xri shrunk below the allocated nvme buffers */\n\t\tio_xri_cnt = phba->sli4_hba.io_xri_cnt -\n\t\t\t\t\tphba->sli4_hba.io_xri_max;\n\t\t/* release the extra allocated nvme buffers */\n\t\tfor (i = 0; i < io_xri_cnt; i++) {\n\t\t\tlist_remove_head(&io_sgl_list, lpfc_ncmd,\n\t\t\t\t\t struct lpfc_io_buf, list);\n\t\t\tif (lpfc_ncmd) {\n\t\t\t\tdma_pool_free(phba->lpfc_sg_dma_buf_pool,\n\t\t\t\t\t      lpfc_ncmd->data,\n\t\t\t\t\t      lpfc_ncmd->dma_handle);\n\t\t\t\tkfree(lpfc_ncmd);\n\t\t\t}\n\t\t}\n\t\tphba->sli4_hba.io_xri_cnt -= io_xri_cnt;\n\t}\n\n\t/* update xris associated to remaining allocated nvme buffers */\n\tlpfc_ncmd = NULL;\n\tlpfc_ncmd_next = NULL;\n\tphba->sli4_hba.io_xri_cnt = cnt;\n\tlist_for_each_entry_safe(lpfc_ncmd, lpfc_ncmd_next,\n\t\t\t\t &io_sgl_list, list) {\n\t\tlxri = lpfc_sli4_next_xritag(phba);\n\t\tif (lxri == NO_XRI) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\"6075 Failed to allocate xri for \"\n\t\t\t\t\t\"nvme buffer\\n\");\n\t\t\trc = -ENOMEM;\n\t\t\tgoto out_free_mem;\n\t\t}\n\t\tlpfc_ncmd->cur_iocbq.sli4_lxritag = lxri;\n\t\tlpfc_ncmd->cur_iocbq.sli4_xritag = phba->sli4_hba.xri_ids[lxri];\n\t}\n\tcnt = lpfc_io_buf_replenish(phba, &io_sgl_list);\n\treturn 0;\n\nout_free_mem:\n\tlpfc_io_free(phba);\n\treturn rc;\n}\n\n/**\n * lpfc_new_io_buf - IO buffer allocator for HBA with SLI4 IF spec\n * @phba: Pointer to lpfc hba data structure.\n * @num_to_alloc: The requested number of buffers to allocate.\n *\n * This routine allocates nvme buffers for device with SLI-4 interface spec,\n * the nvme buffer contains all the necessary information needed to initiate\n * an I/O. After allocating up to @num_to_allocate IO buffers and put\n * them on a list, it post them to the port by using SGL block post.\n *\n * Return codes:\n *   int - number of IO buffers that were allocated and posted.\n *   0 = failure, less than num_to_alloc is a partial failure.\n **/\nint\nlpfc_new_io_buf(struct lpfc_hba *phba, int num_to_alloc)\n{\n\tstruct lpfc_io_buf *lpfc_ncmd;\n\tstruct lpfc_iocbq *pwqeq;\n\tuint16_t iotag, lxri = 0;\n\tint bcnt, num_posted;\n\tLIST_HEAD(prep_nblist);\n\tLIST_HEAD(post_nblist);\n\tLIST_HEAD(nvme_nblist);\n\n\tphba->sli4_hba.io_xri_cnt = 0;\n\tfor (bcnt = 0; bcnt < num_to_alloc; bcnt++) {\n\t\tlpfc_ncmd = kzalloc(sizeof(*lpfc_ncmd), GFP_KERNEL);\n\t\tif (!lpfc_ncmd)\n\t\t\tbreak;\n\t\t/*\n\t\t * Get memory from the pci pool to map the virt space to\n\t\t * pci bus space for an I/O. The DMA buffer includes the\n\t\t * number of SGE's necessary to support the sg_tablesize.\n\t\t */\n\t\tlpfc_ncmd->data = dma_pool_zalloc(phba->lpfc_sg_dma_buf_pool,\n\t\t\t\t\t\t  GFP_KERNEL,\n\t\t\t\t\t\t  &lpfc_ncmd->dma_handle);\n\t\tif (!lpfc_ncmd->data) {\n\t\t\tkfree(lpfc_ncmd);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (phba->cfg_xpsgl && !phba->nvmet_support) {\n\t\t\tINIT_LIST_HEAD(&lpfc_ncmd->dma_sgl_xtra_list);\n\t\t} else {\n\t\t\t/*\n\t\t\t * 4K Page alignment is CRITICAL to BlockGuard, double\n\t\t\t * check to be sure.\n\t\t\t */\n\t\t\tif ((phba->sli3_options & LPFC_SLI3_BG_ENABLED) &&\n\t\t\t    (((unsigned long)(lpfc_ncmd->data) &\n\t\t\t    (unsigned long)(SLI4_PAGE_SIZE - 1)) != 0)) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\t\"3369 Memory alignment err: \"\n\t\t\t\t\t\t\"addr=%lx\\n\",\n\t\t\t\t\t\t(unsigned long)lpfc_ncmd->data);\n\t\t\t\tdma_pool_free(phba->lpfc_sg_dma_buf_pool,\n\t\t\t\t\t      lpfc_ncmd->data,\n\t\t\t\t\t      lpfc_ncmd->dma_handle);\n\t\t\t\tkfree(lpfc_ncmd);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tINIT_LIST_HEAD(&lpfc_ncmd->dma_cmd_rsp_list);\n\n\t\tlxri = lpfc_sli4_next_xritag(phba);\n\t\tif (lxri == NO_XRI) {\n\t\t\tdma_pool_free(phba->lpfc_sg_dma_buf_pool,\n\t\t\t\t      lpfc_ncmd->data, lpfc_ncmd->dma_handle);\n\t\t\tkfree(lpfc_ncmd);\n\t\t\tbreak;\n\t\t}\n\t\tpwqeq = &lpfc_ncmd->cur_iocbq;\n\n\t\t/* Allocate iotag for lpfc_ncmd->cur_iocbq. */\n\t\tiotag = lpfc_sli_next_iotag(phba, pwqeq);\n\t\tif (iotag == 0) {\n\t\t\tdma_pool_free(phba->lpfc_sg_dma_buf_pool,\n\t\t\t\t      lpfc_ncmd->data, lpfc_ncmd->dma_handle);\n\t\t\tkfree(lpfc_ncmd);\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"6121 Failed to allocate IOTAG for\"\n\t\t\t\t\t\" XRI:0x%x\\n\", lxri);\n\t\t\tlpfc_sli4_free_xri(phba, lxri);\n\t\t\tbreak;\n\t\t}\n\t\tpwqeq->sli4_lxritag = lxri;\n\t\tpwqeq->sli4_xritag = phba->sli4_hba.xri_ids[lxri];\n\t\tpwqeq->context1 = lpfc_ncmd;\n\n\t\t/* Initialize local short-hand pointers. */\n\t\tlpfc_ncmd->dma_sgl = lpfc_ncmd->data;\n\t\tlpfc_ncmd->dma_phys_sgl = lpfc_ncmd->dma_handle;\n\t\tlpfc_ncmd->cur_iocbq.context1 = lpfc_ncmd;\n\t\tspin_lock_init(&lpfc_ncmd->buf_lock);\n\n\t\t/* add the nvme buffer to a post list */\n\t\tlist_add_tail(&lpfc_ncmd->list, &post_nblist);\n\t\tphba->sli4_hba.io_xri_cnt++;\n\t}\n\tlpfc_printf_log(phba, KERN_INFO, LOG_NVME,\n\t\t\t\"6114 Allocate %d out of %d requested new NVME \"\n\t\t\t\"buffers\\n\", bcnt, num_to_alloc);\n\n\t/* post the list of nvme buffer sgls to port if available */\n\tif (!list_empty(&post_nblist))\n\t\tnum_posted = lpfc_sli4_post_io_sgl_list(\n\t\t\t\tphba, &post_nblist, bcnt);\n\telse\n\t\tnum_posted = 0;\n\n\treturn num_posted;\n}\n\nstatic uint64_t\nlpfc_get_wwpn(struct lpfc_hba *phba)\n{\n\tuint64_t wwn;\n\tint rc;\n\tLPFC_MBOXQ_t *mboxq;\n\tMAILBOX_t *mb;\n\n\tmboxq = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool,\n\t\t\t\t\t\tGFP_KERNEL);\n\tif (!mboxq)\n\t\treturn (uint64_t)-1;\n\n\t/* First get WWN of HBA instance */\n\tlpfc_read_nv(phba, mboxq);\n\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\tif (rc != MBX_SUCCESS) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"6019 Mailbox failed , mbxCmd x%x \"\n\t\t\t\t\"READ_NV, mbxStatus x%x\\n\",\n\t\t\t\tbf_get(lpfc_mqe_command, &mboxq->u.mqe),\n\t\t\t\tbf_get(lpfc_mqe_status, &mboxq->u.mqe));\n\t\tmempool_free(mboxq, phba->mbox_mem_pool);\n\t\treturn (uint64_t) -1;\n\t}\n\tmb = &mboxq->u.mb;\n\tmemcpy(&wwn, (char *)mb->un.varRDnvp.portname, sizeof(uint64_t));\n\t/* wwn is WWPN of HBA instance */\n\tmempool_free(mboxq, phba->mbox_mem_pool);\n\tif (phba->sli_rev == LPFC_SLI_REV4)\n\t\treturn be64_to_cpu(wwn);\n\telse\n\t\treturn rol64(wwn, 32);\n}\n\n/**\n * lpfc_create_port - Create an FC port\n * @phba: pointer to lpfc hba data structure.\n * @instance: a unique integer ID to this FC port.\n * @dev: pointer to the device data structure.\n *\n * This routine creates a FC port for the upper layer protocol. The FC port\n * can be created on top of either a physical port or a virtual port provided\n * by the HBA. This routine also allocates a SCSI host data structure (shost)\n * and associates the FC port created before adding the shost into the SCSI\n * layer.\n *\n * Return codes\n *   @vport - pointer to the virtual N_Port data structure.\n *   NULL - port create failed.\n **/\nstruct lpfc_vport *\nlpfc_create_port(struct lpfc_hba *phba, int instance, struct device *dev)\n{\n\tstruct lpfc_vport *vport;\n\tstruct Scsi_Host  *shost = NULL;\n\tstruct scsi_host_template *template;\n\tint error = 0;\n\tint i;\n\tuint64_t wwn;\n\tbool use_no_reset_hba = false;\n\tint rc;\n\n\tif (lpfc_no_hba_reset_cnt) {\n\t\tif (phba->sli_rev < LPFC_SLI_REV4 &&\n\t\t    dev == &phba->pcidev->dev) {\n\t\t\t/* Reset the port first */\n\t\t\tlpfc_sli_brdrestart(phba);\n\t\t\trc = lpfc_sli_chipset_init(phba);\n\t\t\tif (rc)\n\t\t\t\treturn NULL;\n\t\t}\n\t\twwn = lpfc_get_wwpn(phba);\n\t}\n\n\tfor (i = 0; i < lpfc_no_hba_reset_cnt; i++) {\n\t\tif (wwn == lpfc_no_hba_reset[i]) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\"6020 Setting use_no_reset port=%llx\\n\",\n\t\t\t\t\twwn);\n\t\t\tuse_no_reset_hba = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/* Seed template for SCSI host registration */\n\tif (dev == &phba->pcidev->dev) {\n\t\ttemplate = &phba->port_template;\n\n\t\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_FCP) {\n\t\t\t/* Seed physical port template */\n\t\t\tmemcpy(template, &lpfc_template, sizeof(*template));\n\n\t\t\tif (use_no_reset_hba)\n\t\t\t\t/* template is for a no reset SCSI Host */\n\t\t\t\ttemplate->eh_host_reset_handler = NULL;\n\n\t\t\t/* Template for all vports this physical port creates */\n\t\t\tmemcpy(&phba->vport_template, &lpfc_template,\n\t\t\t       sizeof(*template));\n\t\t\tphba->vport_template.shost_attrs = lpfc_vport_attrs;\n\t\t\tphba->vport_template.eh_bus_reset_handler = NULL;\n\t\t\tphba->vport_template.eh_host_reset_handler = NULL;\n\t\t\tphba->vport_template.vendor_id = 0;\n\n\t\t\t/* Initialize the host templates with updated value */\n\t\t\tif (phba->sli_rev == LPFC_SLI_REV4) {\n\t\t\t\ttemplate->sg_tablesize = phba->cfg_scsi_seg_cnt;\n\t\t\t\tphba->vport_template.sg_tablesize =\n\t\t\t\t\tphba->cfg_scsi_seg_cnt;\n\t\t\t} else {\n\t\t\t\ttemplate->sg_tablesize = phba->cfg_sg_seg_cnt;\n\t\t\t\tphba->vport_template.sg_tablesize =\n\t\t\t\t\tphba->cfg_sg_seg_cnt;\n\t\t\t}\n\n\t\t} else {\n\t\t\t/* NVMET is for physical port only */\n\t\t\tmemcpy(template, &lpfc_template_nvme,\n\t\t\t       sizeof(*template));\n\t\t}\n\t} else {\n\t\ttemplate = &phba->vport_template;\n\t}\n\n\tshost = scsi_host_alloc(template, sizeof(struct lpfc_vport));\n\tif (!shost)\n\t\tgoto out;\n\n\tvport = (struct lpfc_vport *) shost->hostdata;\n\tvport->phba = phba;\n\tvport->load_flag |= FC_LOADING;\n\tvport->fc_flag |= FC_VPORT_NEEDS_REG_VPI;\n\tvport->fc_rscn_flush = 0;\n\tlpfc_get_vport_cfgparam(vport);\n\n\t/* Adjust value in vport */\n\tvport->cfg_enable_fc4_type = phba->cfg_enable_fc4_type;\n\n\tshost->unique_id = instance;\n\tshost->max_id = LPFC_MAX_TARGET;\n\tshost->max_lun = vport->cfg_max_luns;\n\tshost->this_id = -1;\n\tshost->max_cmd_len = 16;\n\n\tif (phba->sli_rev == LPFC_SLI_REV4) {\n\t\tif (!phba->cfg_fcp_mq_threshold ||\n\t\t    phba->cfg_fcp_mq_threshold > phba->cfg_hdw_queue)\n\t\t\tphba->cfg_fcp_mq_threshold = phba->cfg_hdw_queue;\n\n\t\tshost->nr_hw_queues = min_t(int, 2 * num_possible_nodes(),\n\t\t\t\t\t    phba->cfg_fcp_mq_threshold);\n\n\t\tshost->dma_boundary =\n\t\t\tphba->sli4_hba.pc_sli4_params.sge_supp_len-1;\n\n\t\tif (phba->cfg_xpsgl && !phba->nvmet_support)\n\t\t\tshost->sg_tablesize = LPFC_MAX_SG_TABLESIZE;\n\t\telse\n\t\t\tshost->sg_tablesize = phba->cfg_scsi_seg_cnt;\n\t} else\n\t\t/* SLI-3 has a limited number of hardware queues (3),\n\t\t * thus there is only one for FCP processing.\n\t\t */\n\t\tshost->nr_hw_queues = 1;\n\n\t/*\n\t * Set initial can_queue value since 0 is no longer supported and\n\t * scsi_add_host will fail. This will be adjusted later based on the\n\t * max xri value determined in hba setup.\n\t */\n\tshost->can_queue = phba->cfg_hba_queue_depth - 10;\n\tif (dev != &phba->pcidev->dev) {\n\t\tshost->transportt = lpfc_vport_transport_template;\n\t\tvport->port_type = LPFC_NPIV_PORT;\n\t} else {\n\t\tshost->transportt = lpfc_transport_template;\n\t\tvport->port_type = LPFC_PHYSICAL_PORT;\n\t}\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT | LOG_FCP,\n\t\t\t\"9081 CreatePort TMPLATE type %x TBLsize %d \"\n\t\t\t\"SEGcnt %d/%d\\n\",\n\t\t\tvport->port_type, shost->sg_tablesize,\n\t\t\tphba->cfg_scsi_seg_cnt, phba->cfg_sg_seg_cnt);\n\n\t/* Initialize all internally managed lists. */\n\tINIT_LIST_HEAD(&vport->fc_nodes);\n\tINIT_LIST_HEAD(&vport->rcv_buffer_list);\n\tspin_lock_init(&vport->work_port_lock);\n\n\ttimer_setup(&vport->fc_disctmo, lpfc_disc_timeout, 0);\n\n\ttimer_setup(&vport->els_tmofunc, lpfc_els_timeout, 0);\n\n\ttimer_setup(&vport->delayed_disc_tmo, lpfc_delayed_disc_tmo, 0);\n\n\tif (phba->sli3_options & LPFC_SLI3_BG_ENABLED)\n\t\tlpfc_setup_bg(phba, shost);\n\n\terror = scsi_add_host_with_dma(shost, dev, &phba->pcidev->dev);\n\tif (error)\n\t\tgoto out_put_shost;\n\n\tspin_lock_irq(&phba->port_list_lock);\n\tlist_add_tail(&vport->listentry, &phba->port_list);\n\tspin_unlock_irq(&phba->port_list_lock);\n\treturn vport;\n\nout_put_shost:\n\tscsi_host_put(shost);\nout:\n\treturn NULL;\n}\n\n/**\n * destroy_port -  destroy an FC port\n * @vport: pointer to an lpfc virtual N_Port data structure.\n *\n * This routine destroys a FC port from the upper layer protocol. All the\n * resources associated with the port are released.\n **/\nvoid\ndestroy_port(struct lpfc_vport *vport)\n{\n\tstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\n\tstruct lpfc_hba  *phba = vport->phba;\n\n\tlpfc_debugfs_terminate(vport);\n\tfc_remove_host(shost);\n\tscsi_remove_host(shost);\n\n\tspin_lock_irq(&phba->port_list_lock);\n\tlist_del_init(&vport->listentry);\n\tspin_unlock_irq(&phba->port_list_lock);\n\n\tlpfc_cleanup(vport);\n\treturn;\n}\n\n/**\n * lpfc_get_instance - Get a unique integer ID\n *\n * This routine allocates a unique integer ID from lpfc_hba_index pool. It\n * uses the kernel idr facility to perform the task.\n *\n * Return codes:\n *   instance - a unique integer ID allocated as the new instance.\n *   -1 - lpfc get instance failed.\n **/\nint\nlpfc_get_instance(void)\n{\n\tint ret;\n\n\tret = idr_alloc(&lpfc_hba_index, NULL, 0, 0, GFP_KERNEL);\n\treturn ret < 0 ? -1 : ret;\n}\n\n/**\n * lpfc_scan_finished - method for SCSI layer to detect whether scan is done\n * @shost: pointer to SCSI host data structure.\n * @time: elapsed time of the scan in jiffies.\n *\n * This routine is called by the SCSI layer with a SCSI host to determine\n * whether the scan host is finished.\n *\n * Note: there is no scan_start function as adapter initialization will have\n * asynchronously kicked off the link initialization.\n *\n * Return codes\n *   0 - SCSI host scan is not over yet.\n *   1 - SCSI host scan is over.\n **/\nint lpfc_scan_finished(struct Scsi_Host *shost, unsigned long time)\n{\n\tstruct lpfc_vport *vport = (struct lpfc_vport *) shost->hostdata;\n\tstruct lpfc_hba   *phba = vport->phba;\n\tint stat = 0;\n\n\tspin_lock_irq(shost->host_lock);\n\n\tif (vport->load_flag & FC_UNLOADING) {\n\t\tstat = 1;\n\t\tgoto finished;\n\t}\n\tif (time >= msecs_to_jiffies(30 * 1000)) {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"0461 Scanning longer than 30 \"\n\t\t\t\t\"seconds.  Continuing initialization\\n\");\n\t\tstat = 1;\n\t\tgoto finished;\n\t}\n\tif (time >= msecs_to_jiffies(15 * 1000) &&\n\t    phba->link_state <= LPFC_LINK_DOWN) {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"0465 Link down longer than 15 \"\n\t\t\t\t\"seconds.  Continuing initialization\\n\");\n\t\tstat = 1;\n\t\tgoto finished;\n\t}\n\n\tif (vport->port_state != LPFC_VPORT_READY)\n\t\tgoto finished;\n\tif (vport->num_disc_nodes || vport->fc_prli_sent)\n\t\tgoto finished;\n\tif (vport->fc_map_cnt == 0 && time < msecs_to_jiffies(2 * 1000))\n\t\tgoto finished;\n\tif ((phba->sli.sli_flag & LPFC_SLI_MBOX_ACTIVE) != 0)\n\t\tgoto finished;\n\n\tstat = 1;\n\nfinished:\n\tspin_unlock_irq(shost->host_lock);\n\treturn stat;\n}\n\nstatic void lpfc_host_supported_speeds_set(struct Scsi_Host *shost)\n{\n\tstruct lpfc_vport *vport = (struct lpfc_vport *)shost->hostdata;\n\tstruct lpfc_hba   *phba = vport->phba;\n\n\tfc_host_supported_speeds(shost) = 0;\n\t/*\n\t * Avoid reporting supported link speed for FCoE as it can't be\n\t * controlled via FCoE.\n\t */\n\tif (phba->hba_flag & HBA_FCOE_MODE)\n\t\treturn;\n\n\tif (phba->lmt & LMT_128Gb)\n\t\tfc_host_supported_speeds(shost) |= FC_PORTSPEED_128GBIT;\n\tif (phba->lmt & LMT_64Gb)\n\t\tfc_host_supported_speeds(shost) |= FC_PORTSPEED_64GBIT;\n\tif (phba->lmt & LMT_32Gb)\n\t\tfc_host_supported_speeds(shost) |= FC_PORTSPEED_32GBIT;\n\tif (phba->lmt & LMT_16Gb)\n\t\tfc_host_supported_speeds(shost) |= FC_PORTSPEED_16GBIT;\n\tif (phba->lmt & LMT_10Gb)\n\t\tfc_host_supported_speeds(shost) |= FC_PORTSPEED_10GBIT;\n\tif (phba->lmt & LMT_8Gb)\n\t\tfc_host_supported_speeds(shost) |= FC_PORTSPEED_8GBIT;\n\tif (phba->lmt & LMT_4Gb)\n\t\tfc_host_supported_speeds(shost) |= FC_PORTSPEED_4GBIT;\n\tif (phba->lmt & LMT_2Gb)\n\t\tfc_host_supported_speeds(shost) |= FC_PORTSPEED_2GBIT;\n\tif (phba->lmt & LMT_1Gb)\n\t\tfc_host_supported_speeds(shost) |= FC_PORTSPEED_1GBIT;\n}\n\n/**\n * lpfc_host_attrib_init - Initialize SCSI host attributes on a FC port\n * @shost: pointer to SCSI host data structure.\n *\n * This routine initializes a given SCSI host attributes on a FC port. The\n * SCSI host can be either on top of a physical port or a virtual port.\n **/\nvoid lpfc_host_attrib_init(struct Scsi_Host *shost)\n{\n\tstruct lpfc_vport *vport = (struct lpfc_vport *) shost->hostdata;\n\tstruct lpfc_hba   *phba = vport->phba;\n\t/*\n\t * Set fixed host attributes.  Must done after lpfc_sli_hba_setup().\n\t */\n\n\tfc_host_node_name(shost) = wwn_to_u64(vport->fc_nodename.u.wwn);\n\tfc_host_port_name(shost) = wwn_to_u64(vport->fc_portname.u.wwn);\n\tfc_host_supported_classes(shost) = FC_COS_CLASS3;\n\n\tmemset(fc_host_supported_fc4s(shost), 0,\n\t       sizeof(fc_host_supported_fc4s(shost)));\n\tfc_host_supported_fc4s(shost)[2] = 1;\n\tfc_host_supported_fc4s(shost)[7] = 1;\n\n\tlpfc_vport_symbolic_node_name(vport, fc_host_symbolic_name(shost),\n\t\t\t\t sizeof fc_host_symbolic_name(shost));\n\n\tlpfc_host_supported_speeds_set(shost);\n\n\tfc_host_maxframe_size(shost) =\n\t\t(((uint32_t) vport->fc_sparam.cmn.bbRcvSizeMsb & 0x0F) << 8) |\n\t\t(uint32_t) vport->fc_sparam.cmn.bbRcvSizeLsb;\n\n\tfc_host_dev_loss_tmo(shost) = vport->cfg_devloss_tmo;\n\n\t/* This value is also unchanging */\n\tmemset(fc_host_active_fc4s(shost), 0,\n\t       sizeof(fc_host_active_fc4s(shost)));\n\tfc_host_active_fc4s(shost)[2] = 1;\n\tfc_host_active_fc4s(shost)[7] = 1;\n\n\tfc_host_max_npiv_vports(shost) = phba->max_vpi;\n\tspin_lock_irq(shost->host_lock);\n\tvport->load_flag &= ~FC_LOADING;\n\tspin_unlock_irq(shost->host_lock);\n}\n\n/**\n * lpfc_stop_port_s3 - Stop SLI3 device port\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to stop an SLI3 device port, it stops the device\n * from generating interrupts and stops the device driver's timers for the\n * device.\n **/\nstatic void\nlpfc_stop_port_s3(struct lpfc_hba *phba)\n{\n\t/* Clear all interrupt enable conditions */\n\twritel(0, phba->HCregaddr);\n\treadl(phba->HCregaddr); /* flush */\n\t/* Clear all pending interrupts */\n\twritel(0xffffffff, phba->HAregaddr);\n\treadl(phba->HAregaddr); /* flush */\n\n\t/* Reset some HBA SLI setup states */\n\tlpfc_stop_hba_timers(phba);\n\tphba->pport->work_port_events = 0;\n}\n\n/**\n * lpfc_stop_port_s4 - Stop SLI4 device port\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to stop an SLI4 device port, it stops the device\n * from generating interrupts and stops the device driver's timers for the\n * device.\n **/\nstatic void\nlpfc_stop_port_s4(struct lpfc_hba *phba)\n{\n\t/* Reset some HBA SLI4 setup states */\n\tlpfc_stop_hba_timers(phba);\n\tif (phba->pport)\n\t\tphba->pport->work_port_events = 0;\n\tphba->sli4_hba.intr_enable = 0;\n}\n\n/**\n * lpfc_stop_port - Wrapper function for stopping hba port\n * @phba: Pointer to HBA context object.\n *\n * This routine wraps the actual SLI3 or SLI4 hba stop port routine from\n * the API jump table function pointer from the lpfc_hba struct.\n **/\nvoid\nlpfc_stop_port(struct lpfc_hba *phba)\n{\n\tphba->lpfc_stop_port(phba);\n\n\tif (phba->wq)\n\t\tflush_workqueue(phba->wq);\n}\n\n/**\n * lpfc_fcf_redisc_wait_start_timer - Start fcf rediscover wait timer\n * @phba: Pointer to hba for which this call is being executed.\n *\n * This routine starts the timer waiting for the FCF rediscovery to complete.\n **/\nvoid\nlpfc_fcf_redisc_wait_start_timer(struct lpfc_hba *phba)\n{\n\tunsigned long fcf_redisc_wait_tmo =\n\t\t(jiffies + msecs_to_jiffies(LPFC_FCF_REDISCOVER_WAIT_TMO));\n\t/* Start fcf rediscovery wait period timer */\n\tmod_timer(&phba->fcf.redisc_wait, fcf_redisc_wait_tmo);\n\tspin_lock_irq(&phba->hbalock);\n\t/* Allow action to new fcf asynchronous event */\n\tphba->fcf.fcf_flag &= ~(FCF_AVAILABLE | FCF_SCAN_DONE);\n\t/* Mark the FCF rediscovery pending state */\n\tphba->fcf.fcf_flag |= FCF_REDISC_PEND;\n\tspin_unlock_irq(&phba->hbalock);\n}\n\n/**\n * lpfc_sli4_fcf_redisc_wait_tmo - FCF table rediscover wait timeout\n * @t: Timer context used to obtain the pointer to lpfc hba data structure.\n *\n * This routine is invoked when waiting for FCF table rediscover has been\n * timed out. If new FCF record(s) has (have) been discovered during the\n * wait period, a new FCF event shall be added to the FCOE async event\n * list, and then worker thread shall be waked up for processing from the\n * worker thread context.\n **/\nstatic void\nlpfc_sli4_fcf_redisc_wait_tmo(struct timer_list *t)\n{\n\tstruct lpfc_hba *phba = from_timer(phba, t, fcf.redisc_wait);\n\n\t/* Don't send FCF rediscovery event if timer cancelled */\n\tspin_lock_irq(&phba->hbalock);\n\tif (!(phba->fcf.fcf_flag & FCF_REDISC_PEND)) {\n\t\tspin_unlock_irq(&phba->hbalock);\n\t\treturn;\n\t}\n\t/* Clear FCF rediscovery timer pending flag */\n\tphba->fcf.fcf_flag &= ~FCF_REDISC_PEND;\n\t/* FCF rediscovery event to worker thread */\n\tphba->fcf.fcf_flag |= FCF_REDISC_EVT;\n\tspin_unlock_irq(&phba->hbalock);\n\tlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\n\t\t\t\"2776 FCF rediscover quiescent timer expired\\n\");\n\t/* wake up worker thread */\n\tlpfc_worker_wake_up(phba);\n}\n\n/**\n * lpfc_sli4_parse_latt_fault - Parse sli4 link-attention link fault code\n * @phba: pointer to lpfc hba data structure.\n * @acqe_link: pointer to the async link completion queue entry.\n *\n * This routine is to parse the SLI4 link-attention link fault code.\n **/\nstatic void\nlpfc_sli4_parse_latt_fault(struct lpfc_hba *phba,\n\t\t\t   struct lpfc_acqe_link *acqe_link)\n{\n\tswitch (bf_get(lpfc_acqe_link_fault, acqe_link)) {\n\tcase LPFC_ASYNC_LINK_FAULT_NONE:\n\tcase LPFC_ASYNC_LINK_FAULT_LOCAL:\n\tcase LPFC_ASYNC_LINK_FAULT_REMOTE:\n\tcase LPFC_ASYNC_LINK_FAULT_LR_LRR:\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0398 Unknown link fault code: x%x\\n\",\n\t\t\t\tbf_get(lpfc_acqe_link_fault, acqe_link));\n\t\tbreak;\n\t}\n}\n\n/**\n * lpfc_sli4_parse_latt_type - Parse sli4 link attention type\n * @phba: pointer to lpfc hba data structure.\n * @acqe_link: pointer to the async link completion queue entry.\n *\n * This routine is to parse the SLI4 link attention type and translate it\n * into the base driver's link attention type coding.\n *\n * Return: Link attention type in terms of base driver's coding.\n **/\nstatic uint8_t\nlpfc_sli4_parse_latt_type(struct lpfc_hba *phba,\n\t\t\t  struct lpfc_acqe_link *acqe_link)\n{\n\tuint8_t att_type;\n\n\tswitch (bf_get(lpfc_acqe_link_status, acqe_link)) {\n\tcase LPFC_ASYNC_LINK_STATUS_DOWN:\n\tcase LPFC_ASYNC_LINK_STATUS_LOGICAL_DOWN:\n\t\tatt_type = LPFC_ATT_LINK_DOWN;\n\t\tbreak;\n\tcase LPFC_ASYNC_LINK_STATUS_UP:\n\t\t/* Ignore physical link up events - wait for logical link up */\n\t\tatt_type = LPFC_ATT_RESERVED;\n\t\tbreak;\n\tcase LPFC_ASYNC_LINK_STATUS_LOGICAL_UP:\n\t\tatt_type = LPFC_ATT_LINK_UP;\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0399 Invalid link attention type: x%x\\n\",\n\t\t\t\tbf_get(lpfc_acqe_link_status, acqe_link));\n\t\tatt_type = LPFC_ATT_RESERVED;\n\t\tbreak;\n\t}\n\treturn att_type;\n}\n\n/**\n * lpfc_sli_port_speed_get - Get sli3 link speed code to link speed\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is to get an SLI3 FC port's link speed in Mbps.\n *\n * Return: link speed in terms of Mbps.\n **/\nuint32_t\nlpfc_sli_port_speed_get(struct lpfc_hba *phba)\n{\n\tuint32_t link_speed;\n\n\tif (!lpfc_is_link_up(phba))\n\t\treturn 0;\n\n\tif (phba->sli_rev <= LPFC_SLI_REV3) {\n\t\tswitch (phba->fc_linkspeed) {\n\t\tcase LPFC_LINK_SPEED_1GHZ:\n\t\t\tlink_speed = 1000;\n\t\t\tbreak;\n\t\tcase LPFC_LINK_SPEED_2GHZ:\n\t\t\tlink_speed = 2000;\n\t\t\tbreak;\n\t\tcase LPFC_LINK_SPEED_4GHZ:\n\t\t\tlink_speed = 4000;\n\t\t\tbreak;\n\t\tcase LPFC_LINK_SPEED_8GHZ:\n\t\t\tlink_speed = 8000;\n\t\t\tbreak;\n\t\tcase LPFC_LINK_SPEED_10GHZ:\n\t\t\tlink_speed = 10000;\n\t\t\tbreak;\n\t\tcase LPFC_LINK_SPEED_16GHZ:\n\t\t\tlink_speed = 16000;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tlink_speed = 0;\n\t\t}\n\t} else {\n\t\tif (phba->sli4_hba.link_state.logical_speed)\n\t\t\tlink_speed =\n\t\t\t      phba->sli4_hba.link_state.logical_speed;\n\t\telse\n\t\t\tlink_speed = phba->sli4_hba.link_state.speed;\n\t}\n\treturn link_speed;\n}\n\n/**\n * lpfc_sli4_port_speed_parse - Parse async evt link speed code to link speed\n * @phba: pointer to lpfc hba data structure.\n * @evt_code: asynchronous event code.\n * @speed_code: asynchronous event link speed code.\n *\n * This routine is to parse the giving SLI4 async event link speed code into\n * value of Mbps for the link speed.\n *\n * Return: link speed in terms of Mbps.\n **/\nstatic uint32_t\nlpfc_sli4_port_speed_parse(struct lpfc_hba *phba, uint32_t evt_code,\n\t\t\t   uint8_t speed_code)\n{\n\tuint32_t port_speed;\n\n\tswitch (evt_code) {\n\tcase LPFC_TRAILER_CODE_LINK:\n\t\tswitch (speed_code) {\n\t\tcase LPFC_ASYNC_LINK_SPEED_ZERO:\n\t\t\tport_speed = 0;\n\t\t\tbreak;\n\t\tcase LPFC_ASYNC_LINK_SPEED_10MBPS:\n\t\t\tport_speed = 10;\n\t\t\tbreak;\n\t\tcase LPFC_ASYNC_LINK_SPEED_100MBPS:\n\t\t\tport_speed = 100;\n\t\t\tbreak;\n\t\tcase LPFC_ASYNC_LINK_SPEED_1GBPS:\n\t\t\tport_speed = 1000;\n\t\t\tbreak;\n\t\tcase LPFC_ASYNC_LINK_SPEED_10GBPS:\n\t\t\tport_speed = 10000;\n\t\t\tbreak;\n\t\tcase LPFC_ASYNC_LINK_SPEED_20GBPS:\n\t\t\tport_speed = 20000;\n\t\t\tbreak;\n\t\tcase LPFC_ASYNC_LINK_SPEED_25GBPS:\n\t\t\tport_speed = 25000;\n\t\t\tbreak;\n\t\tcase LPFC_ASYNC_LINK_SPEED_40GBPS:\n\t\t\tport_speed = 40000;\n\t\t\tbreak;\n\t\tcase LPFC_ASYNC_LINK_SPEED_100GBPS:\n\t\t\tport_speed = 100000;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tport_speed = 0;\n\t\t}\n\t\tbreak;\n\tcase LPFC_TRAILER_CODE_FC:\n\t\tswitch (speed_code) {\n\t\tcase LPFC_FC_LA_SPEED_UNKNOWN:\n\t\t\tport_speed = 0;\n\t\t\tbreak;\n\t\tcase LPFC_FC_LA_SPEED_1G:\n\t\t\tport_speed = 1000;\n\t\t\tbreak;\n\t\tcase LPFC_FC_LA_SPEED_2G:\n\t\t\tport_speed = 2000;\n\t\t\tbreak;\n\t\tcase LPFC_FC_LA_SPEED_4G:\n\t\t\tport_speed = 4000;\n\t\t\tbreak;\n\t\tcase LPFC_FC_LA_SPEED_8G:\n\t\t\tport_speed = 8000;\n\t\t\tbreak;\n\t\tcase LPFC_FC_LA_SPEED_10G:\n\t\t\tport_speed = 10000;\n\t\t\tbreak;\n\t\tcase LPFC_FC_LA_SPEED_16G:\n\t\t\tport_speed = 16000;\n\t\t\tbreak;\n\t\tcase LPFC_FC_LA_SPEED_32G:\n\t\t\tport_speed = 32000;\n\t\t\tbreak;\n\t\tcase LPFC_FC_LA_SPEED_64G:\n\t\t\tport_speed = 64000;\n\t\t\tbreak;\n\t\tcase LPFC_FC_LA_SPEED_128G:\n\t\t\tport_speed = 128000;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tport_speed = 0;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tport_speed = 0;\n\t}\n\treturn port_speed;\n}\n\n/**\n * lpfc_sli4_async_link_evt - Process the asynchronous FCoE link event\n * @phba: pointer to lpfc hba data structure.\n * @acqe_link: pointer to the async link completion queue entry.\n *\n * This routine is to handle the SLI4 asynchronous FCoE link event.\n **/\nstatic void\nlpfc_sli4_async_link_evt(struct lpfc_hba *phba,\n\t\t\t struct lpfc_acqe_link *acqe_link)\n{\n\tstruct lpfc_dmabuf *mp;\n\tLPFC_MBOXQ_t *pmb;\n\tMAILBOX_t *mb;\n\tstruct lpfc_mbx_read_top *la;\n\tuint8_t att_type;\n\tint rc;\n\n\tatt_type = lpfc_sli4_parse_latt_type(phba, acqe_link);\n\tif (att_type != LPFC_ATT_LINK_DOWN && att_type != LPFC_ATT_LINK_UP)\n\t\treturn;\n\tphba->fcoe_eventtag = acqe_link->event_tag;\n\tpmb = (LPFC_MBOXQ_t *)mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!pmb) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0395 The mboxq allocation failed\\n\");\n\t\treturn;\n\t}\n\tmp = kmalloc(sizeof(struct lpfc_dmabuf), GFP_KERNEL);\n\tif (!mp) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0396 The lpfc_dmabuf allocation failed\\n\");\n\t\tgoto out_free_pmb;\n\t}\n\tmp->virt = lpfc_mbuf_alloc(phba, 0, &mp->phys);\n\tif (!mp->virt) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0397 The mbuf allocation failed\\n\");\n\t\tgoto out_free_dmabuf;\n\t}\n\n\t/* Cleanup any outstanding ELS commands */\n\tlpfc_els_flush_all_cmd(phba);\n\n\t/* Block ELS IOCBs until we have done process link event */\n\tphba->sli4_hba.els_wq->pring->flag |= LPFC_STOP_IOCB_EVENT;\n\n\t/* Update link event statistics */\n\tphba->sli.slistat.link_event++;\n\n\t/* Create lpfc_handle_latt mailbox command from link ACQE */\n\tlpfc_read_topology(phba, pmb, mp);\n\tpmb->mbox_cmpl = lpfc_mbx_cmpl_read_topology;\n\tpmb->vport = phba->pport;\n\n\t/* Keep the link status for extra SLI4 state machine reference */\n\tphba->sli4_hba.link_state.speed =\n\t\t\tlpfc_sli4_port_speed_parse(phba, LPFC_TRAILER_CODE_LINK,\n\t\t\t\tbf_get(lpfc_acqe_link_speed, acqe_link));\n\tphba->sli4_hba.link_state.duplex =\n\t\t\t\tbf_get(lpfc_acqe_link_duplex, acqe_link);\n\tphba->sli4_hba.link_state.status =\n\t\t\t\tbf_get(lpfc_acqe_link_status, acqe_link);\n\tphba->sli4_hba.link_state.type =\n\t\t\t\tbf_get(lpfc_acqe_link_type, acqe_link);\n\tphba->sli4_hba.link_state.number =\n\t\t\t\tbf_get(lpfc_acqe_link_number, acqe_link);\n\tphba->sli4_hba.link_state.fault =\n\t\t\t\tbf_get(lpfc_acqe_link_fault, acqe_link);\n\tphba->sli4_hba.link_state.logical_speed =\n\t\t\tbf_get(lpfc_acqe_logical_link_speed, acqe_link) * 10;\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\"2900 Async FC/FCoE Link event - Speed:%dGBit \"\n\t\t\t\"duplex:x%x LA Type:x%x Port Type:%d Port Number:%d \"\n\t\t\t\"Logical speed:%dMbps Fault:%d\\n\",\n\t\t\tphba->sli4_hba.link_state.speed,\n\t\t\tphba->sli4_hba.link_state.topology,\n\t\t\tphba->sli4_hba.link_state.status,\n\t\t\tphba->sli4_hba.link_state.type,\n\t\t\tphba->sli4_hba.link_state.number,\n\t\t\tphba->sli4_hba.link_state.logical_speed,\n\t\t\tphba->sli4_hba.link_state.fault);\n\t/*\n\t * For FC Mode: issue the READ_TOPOLOGY mailbox command to fetch\n\t * topology info. Note: Optional for non FC-AL ports.\n\t */\n\tif (!(phba->hba_flag & HBA_FCOE_MODE)) {\n\t\trc = lpfc_sli_issue_mbox(phba, pmb, MBX_NOWAIT);\n\t\tif (rc == MBX_NOT_FINISHED)\n\t\t\tgoto out_free_dmabuf;\n\t\treturn;\n\t}\n\t/*\n\t * For FCoE Mode: fill in all the topology information we need and call\n\t * the READ_TOPOLOGY completion routine to continue without actually\n\t * sending the READ_TOPOLOGY mailbox command to the port.\n\t */\n\t/* Initialize completion status */\n\tmb = &pmb->u.mb;\n\tmb->mbxStatus = MBX_SUCCESS;\n\n\t/* Parse port fault information field */\n\tlpfc_sli4_parse_latt_fault(phba, acqe_link);\n\n\t/* Parse and translate link attention fields */\n\tla = (struct lpfc_mbx_read_top *) &pmb->u.mb.un.varReadTop;\n\tla->eventTag = acqe_link->event_tag;\n\tbf_set(lpfc_mbx_read_top_att_type, la, att_type);\n\tbf_set(lpfc_mbx_read_top_link_spd, la,\n\t       (bf_get(lpfc_acqe_link_speed, acqe_link)));\n\n\t/* Fake the the following irrelvant fields */\n\tbf_set(lpfc_mbx_read_top_topology, la, LPFC_TOPOLOGY_PT_PT);\n\tbf_set(lpfc_mbx_read_top_alpa_granted, la, 0);\n\tbf_set(lpfc_mbx_read_top_il, la, 0);\n\tbf_set(lpfc_mbx_read_top_pb, la, 0);\n\tbf_set(lpfc_mbx_read_top_fa, la, 0);\n\tbf_set(lpfc_mbx_read_top_mm, la, 0);\n\n\t/* Invoke the lpfc_handle_latt mailbox command callback function */\n\tlpfc_mbx_cmpl_read_topology(phba, pmb);\n\n\treturn;\n\nout_free_dmabuf:\n\tkfree(mp);\nout_free_pmb:\n\tmempool_free(pmb, phba->mbox_mem_pool);\n}\n\n/**\n * lpfc_async_link_speed_to_read_top - Parse async evt link speed code to read\n * topology.\n * @phba: pointer to lpfc hba data structure.\n * @speed_code: asynchronous event link speed code.\n *\n * This routine is to parse the giving SLI4 async event link speed code into\n * value of Read topology link speed.\n *\n * Return: link speed in terms of Read topology.\n **/\nstatic uint8_t\nlpfc_async_link_speed_to_read_top(struct lpfc_hba *phba, uint8_t speed_code)\n{\n\tuint8_t port_speed;\n\n\tswitch (speed_code) {\n\tcase LPFC_FC_LA_SPEED_1G:\n\t\tport_speed = LPFC_LINK_SPEED_1GHZ;\n\t\tbreak;\n\tcase LPFC_FC_LA_SPEED_2G:\n\t\tport_speed = LPFC_LINK_SPEED_2GHZ;\n\t\tbreak;\n\tcase LPFC_FC_LA_SPEED_4G:\n\t\tport_speed = LPFC_LINK_SPEED_4GHZ;\n\t\tbreak;\n\tcase LPFC_FC_LA_SPEED_8G:\n\t\tport_speed = LPFC_LINK_SPEED_8GHZ;\n\t\tbreak;\n\tcase LPFC_FC_LA_SPEED_16G:\n\t\tport_speed = LPFC_LINK_SPEED_16GHZ;\n\t\tbreak;\n\tcase LPFC_FC_LA_SPEED_32G:\n\t\tport_speed = LPFC_LINK_SPEED_32GHZ;\n\t\tbreak;\n\tcase LPFC_FC_LA_SPEED_64G:\n\t\tport_speed = LPFC_LINK_SPEED_64GHZ;\n\t\tbreak;\n\tcase LPFC_FC_LA_SPEED_128G:\n\t\tport_speed = LPFC_LINK_SPEED_128GHZ;\n\t\tbreak;\n\tcase LPFC_FC_LA_SPEED_256G:\n\t\tport_speed = LPFC_LINK_SPEED_256GHZ;\n\t\tbreak;\n\tdefault:\n\t\tport_speed = 0;\n\t\tbreak;\n\t}\n\n\treturn port_speed;\n}\n\n#define trunk_link_status(__idx)\\\n\tbf_get(lpfc_acqe_fc_la_trunk_config_port##__idx, acqe_fc) ?\\\n\t       ((phba->trunk_link.link##__idx.state == LPFC_LINK_UP) ?\\\n\t\t\"Link up\" : \"Link down\") : \"NA\"\n/* Did port __idx reported an error */\n#define trunk_port_fault(__idx)\\\n\tbf_get(lpfc_acqe_fc_la_trunk_config_port##__idx, acqe_fc) ?\\\n\t       (port_fault & (1 << __idx) ? \"YES\" : \"NO\") : \"NA\"\n\nstatic void\nlpfc_update_trunk_link_status(struct lpfc_hba *phba,\n\t\t\t      struct lpfc_acqe_fc_la *acqe_fc)\n{\n\tuint8_t port_fault = bf_get(lpfc_acqe_fc_la_trunk_linkmask, acqe_fc);\n\tuint8_t err = bf_get(lpfc_acqe_fc_la_trunk_fault, acqe_fc);\n\n\tphba->sli4_hba.link_state.speed =\n\t\tlpfc_sli4_port_speed_parse(phba, LPFC_TRAILER_CODE_FC,\n\t\t\t\tbf_get(lpfc_acqe_fc_la_speed, acqe_fc));\n\n\tphba->sli4_hba.link_state.logical_speed =\n\t\t\t\tbf_get(lpfc_acqe_fc_la_llink_spd, acqe_fc) * 10;\n\t/* We got FC link speed, convert to fc_linkspeed (READ_TOPOLOGY) */\n\tphba->fc_linkspeed =\n\t\t lpfc_async_link_speed_to_read_top(\n\t\t\t\tphba,\n\t\t\t\tbf_get(lpfc_acqe_fc_la_speed, acqe_fc));\n\n\tif (bf_get(lpfc_acqe_fc_la_trunk_config_port0, acqe_fc)) {\n\t\tphba->trunk_link.link0.state =\n\t\t\tbf_get(lpfc_acqe_fc_la_trunk_link_status_port0, acqe_fc)\n\t\t\t? LPFC_LINK_UP : LPFC_LINK_DOWN;\n\t\tphba->trunk_link.link0.fault = port_fault & 0x1 ? err : 0;\n\t}\n\tif (bf_get(lpfc_acqe_fc_la_trunk_config_port1, acqe_fc)) {\n\t\tphba->trunk_link.link1.state =\n\t\t\tbf_get(lpfc_acqe_fc_la_trunk_link_status_port1, acqe_fc)\n\t\t\t? LPFC_LINK_UP : LPFC_LINK_DOWN;\n\t\tphba->trunk_link.link1.fault = port_fault & 0x2 ? err : 0;\n\t}\n\tif (bf_get(lpfc_acqe_fc_la_trunk_config_port2, acqe_fc)) {\n\t\tphba->trunk_link.link2.state =\n\t\t\tbf_get(lpfc_acqe_fc_la_trunk_link_status_port2, acqe_fc)\n\t\t\t? LPFC_LINK_UP : LPFC_LINK_DOWN;\n\t\tphba->trunk_link.link2.fault = port_fault & 0x4 ? err : 0;\n\t}\n\tif (bf_get(lpfc_acqe_fc_la_trunk_config_port3, acqe_fc)) {\n\t\tphba->trunk_link.link3.state =\n\t\t\tbf_get(lpfc_acqe_fc_la_trunk_link_status_port3, acqe_fc)\n\t\t\t? LPFC_LINK_UP : LPFC_LINK_DOWN;\n\t\tphba->trunk_link.link3.fault = port_fault & 0x8 ? err : 0;\n\t}\n\n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"2910 Async FC Trunking Event - Speed:%d\\n\"\n\t\t\t\"\\tLogical speed:%d \"\n\t\t\t\"port0: %s port1: %s port2: %s port3: %s\\n\",\n\t\t\tphba->sli4_hba.link_state.speed,\n\t\t\tphba->sli4_hba.link_state.logical_speed,\n\t\t\ttrunk_link_status(0), trunk_link_status(1),\n\t\t\ttrunk_link_status(2), trunk_link_status(3));\n\n\tif (port_fault)\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3202 trunk error:0x%x (%s) seen on port0:%s \"\n\t\t\t\t/*\n\t\t\t\t * SLI-4: We have only 0xA error codes\n\t\t\t\t * defined as of now. print an appropriate\n\t\t\t\t * message in case driver needs to be updated.\n\t\t\t\t */\n\t\t\t\t\"port1:%s port2:%s port3:%s\\n\", err, err > 0xA ?\n\t\t\t\t\"UNDEFINED. update driver.\" : trunk_errmsg[err],\n\t\t\t\ttrunk_port_fault(0), trunk_port_fault(1),\n\t\t\t\ttrunk_port_fault(2), trunk_port_fault(3));\n}\n\n\n/**\n * lpfc_sli4_async_fc_evt - Process the asynchronous FC link event\n * @phba: pointer to lpfc hba data structure.\n * @acqe_fc: pointer to the async fc completion queue entry.\n *\n * This routine is to handle the SLI4 asynchronous FC event. It will simply log\n * that the event was received and then issue a read_topology mailbox command so\n * that the rest of the driver will treat it the same as SLI3.\n **/\nstatic void\nlpfc_sli4_async_fc_evt(struct lpfc_hba *phba, struct lpfc_acqe_fc_la *acqe_fc)\n{\n\tstruct lpfc_dmabuf *mp;\n\tLPFC_MBOXQ_t *pmb;\n\tMAILBOX_t *mb;\n\tstruct lpfc_mbx_read_top *la;\n\tint rc;\n\n\tif (bf_get(lpfc_trailer_type, acqe_fc) !=\n\t    LPFC_FC_LA_EVENT_TYPE_FC_LINK) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2895 Non FC link Event detected.(%d)\\n\",\n\t\t\t\tbf_get(lpfc_trailer_type, acqe_fc));\n\t\treturn;\n\t}\n\n\tif (bf_get(lpfc_acqe_fc_la_att_type, acqe_fc) ==\n\t    LPFC_FC_LA_TYPE_TRUNKING_EVENT) {\n\t\tlpfc_update_trunk_link_status(phba, acqe_fc);\n\t\treturn;\n\t}\n\n\t/* Keep the link status for extra SLI4 state machine reference */\n\tphba->sli4_hba.link_state.speed =\n\t\t\tlpfc_sli4_port_speed_parse(phba, LPFC_TRAILER_CODE_FC,\n\t\t\t\tbf_get(lpfc_acqe_fc_la_speed, acqe_fc));\n\tphba->sli4_hba.link_state.duplex = LPFC_ASYNC_LINK_DUPLEX_FULL;\n\tphba->sli4_hba.link_state.topology =\n\t\t\t\tbf_get(lpfc_acqe_fc_la_topology, acqe_fc);\n\tphba->sli4_hba.link_state.status =\n\t\t\t\tbf_get(lpfc_acqe_fc_la_att_type, acqe_fc);\n\tphba->sli4_hba.link_state.type =\n\t\t\t\tbf_get(lpfc_acqe_fc_la_port_type, acqe_fc);\n\tphba->sli4_hba.link_state.number =\n\t\t\t\tbf_get(lpfc_acqe_fc_la_port_number, acqe_fc);\n\tphba->sli4_hba.link_state.fault =\n\t\t\t\tbf_get(lpfc_acqe_link_fault, acqe_fc);\n\n\tif (bf_get(lpfc_acqe_fc_la_att_type, acqe_fc) ==\n\t    LPFC_FC_LA_TYPE_LINK_DOWN)\n\t\tphba->sli4_hba.link_state.logical_speed = 0;\n\telse if\t(!phba->sli4_hba.conf_trunk)\n\t\tphba->sli4_hba.link_state.logical_speed =\n\t\t\t\tbf_get(lpfc_acqe_fc_la_llink_spd, acqe_fc) * 10;\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\"2896 Async FC event - Speed:%dGBaud Topology:x%x \"\n\t\t\t\"LA Type:x%x Port Type:%d Port Number:%d Logical speed:\"\n\t\t\t\"%dMbps Fault:%d\\n\",\n\t\t\tphba->sli4_hba.link_state.speed,\n\t\t\tphba->sli4_hba.link_state.topology,\n\t\t\tphba->sli4_hba.link_state.status,\n\t\t\tphba->sli4_hba.link_state.type,\n\t\t\tphba->sli4_hba.link_state.number,\n\t\t\tphba->sli4_hba.link_state.logical_speed,\n\t\t\tphba->sli4_hba.link_state.fault);\n\tpmb = (LPFC_MBOXQ_t *)mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!pmb) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2897 The mboxq allocation failed\\n\");\n\t\treturn;\n\t}\n\tmp = kmalloc(sizeof(struct lpfc_dmabuf), GFP_KERNEL);\n\tif (!mp) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2898 The lpfc_dmabuf allocation failed\\n\");\n\t\tgoto out_free_pmb;\n\t}\n\tmp->virt = lpfc_mbuf_alloc(phba, 0, &mp->phys);\n\tif (!mp->virt) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2899 The mbuf allocation failed\\n\");\n\t\tgoto out_free_dmabuf;\n\t}\n\n\t/* Cleanup any outstanding ELS commands */\n\tlpfc_els_flush_all_cmd(phba);\n\n\t/* Block ELS IOCBs until we have done process link event */\n\tphba->sli4_hba.els_wq->pring->flag |= LPFC_STOP_IOCB_EVENT;\n\n\t/* Update link event statistics */\n\tphba->sli.slistat.link_event++;\n\n\t/* Create lpfc_handle_latt mailbox command from link ACQE */\n\tlpfc_read_topology(phba, pmb, mp);\n\tpmb->mbox_cmpl = lpfc_mbx_cmpl_read_topology;\n\tpmb->vport = phba->pport;\n\n\tif (phba->sli4_hba.link_state.status != LPFC_FC_LA_TYPE_LINK_UP) {\n\t\tphba->link_flag &= ~(LS_MDS_LINK_DOWN | LS_MDS_LOOPBACK);\n\n\t\tswitch (phba->sli4_hba.link_state.status) {\n\t\tcase LPFC_FC_LA_TYPE_MDS_LINK_DOWN:\n\t\t\tphba->link_flag |= LS_MDS_LINK_DOWN;\n\t\t\tbreak;\n\t\tcase LPFC_FC_LA_TYPE_MDS_LOOPBACK:\n\t\t\tphba->link_flag |= LS_MDS_LOOPBACK;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Initialize completion status */\n\t\tmb = &pmb->u.mb;\n\t\tmb->mbxStatus = MBX_SUCCESS;\n\n\t\t/* Parse port fault information field */\n\t\tlpfc_sli4_parse_latt_fault(phba, (void *)acqe_fc);\n\n\t\t/* Parse and translate link attention fields */\n\t\tla = (struct lpfc_mbx_read_top *)&pmb->u.mb.un.varReadTop;\n\t\tla->eventTag = acqe_fc->event_tag;\n\n\t\tif (phba->sli4_hba.link_state.status ==\n\t\t    LPFC_FC_LA_TYPE_UNEXP_WWPN) {\n\t\t\tbf_set(lpfc_mbx_read_top_att_type, la,\n\t\t\t       LPFC_FC_LA_TYPE_UNEXP_WWPN);\n\t\t} else {\n\t\t\tbf_set(lpfc_mbx_read_top_att_type, la,\n\t\t\t       LPFC_FC_LA_TYPE_LINK_DOWN);\n\t\t}\n\t\t/* Invoke the mailbox command callback function */\n\t\tlpfc_mbx_cmpl_read_topology(phba, pmb);\n\n\t\treturn;\n\t}\n\n\trc = lpfc_sli_issue_mbox(phba, pmb, MBX_NOWAIT);\n\tif (rc == MBX_NOT_FINISHED)\n\t\tgoto out_free_dmabuf;\n\treturn;\n\nout_free_dmabuf:\n\tkfree(mp);\nout_free_pmb:\n\tmempool_free(pmb, phba->mbox_mem_pool);\n}\n\n/**\n * lpfc_sli4_async_sli_evt - Process the asynchronous SLI link event\n * @phba: pointer to lpfc hba data structure.\n * @acqe_sli: pointer to the async SLI completion queue entry.\n *\n * This routine is to handle the SLI4 asynchronous SLI events.\n **/\nstatic void\nlpfc_sli4_async_sli_evt(struct lpfc_hba *phba, struct lpfc_acqe_sli *acqe_sli)\n{\n\tchar port_name;\n\tchar message[128];\n\tuint8_t status;\n\tuint8_t evt_type;\n\tuint8_t operational = 0;\n\tstruct temp_event temp_event_data;\n\tstruct lpfc_acqe_misconfigured_event *misconfigured;\n\tstruct Scsi_Host  *shost;\n\tstruct lpfc_vport **vports;\n\tint rc, i;\n\n\tevt_type = bf_get(lpfc_trailer_type, acqe_sli);\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\"2901 Async SLI event - Type:%d, Event Data: x%08x \"\n\t\t\t\"x%08x x%08x x%08x\\n\", evt_type,\n\t\t\tacqe_sli->event_data1, acqe_sli->event_data2,\n\t\t\tacqe_sli->reserved, acqe_sli->trailer);\n\n\tport_name = phba->Port[0];\n\tif (port_name == 0x00)\n\t\tport_name = '?'; /* get port name is empty */\n\n\tswitch (evt_type) {\n\tcase LPFC_SLI_EVENT_TYPE_OVER_TEMP:\n\t\ttemp_event_data.event_type = FC_REG_TEMPERATURE_EVENT;\n\t\ttemp_event_data.event_code = LPFC_THRESHOLD_TEMP;\n\t\ttemp_event_data.data = (uint32_t)acqe_sli->event_data1;\n\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\n\t\t\t\t\"3190 Over Temperature:%d Celsius- Port Name %c\\n\",\n\t\t\t\tacqe_sli->event_data1, port_name);\n\n\t\tphba->sfp_warning |= LPFC_TRANSGRESSION_HIGH_TEMPERATURE;\n\t\tshost = lpfc_shost_from_vport(phba->pport);\n\t\tfc_host_post_vendor_event(shost, fc_get_event_number(),\n\t\t\t\t\t  sizeof(temp_event_data),\n\t\t\t\t\t  (char *)&temp_event_data,\n\t\t\t\t\t  SCSI_NL_VID_TYPE_PCI\n\t\t\t\t\t  | PCI_VENDOR_ID_EMULEX);\n\t\tbreak;\n\tcase LPFC_SLI_EVENT_TYPE_NORM_TEMP:\n\t\ttemp_event_data.event_type = FC_REG_TEMPERATURE_EVENT;\n\t\ttemp_event_data.event_code = LPFC_NORMAL_TEMP;\n\t\ttemp_event_data.data = (uint32_t)acqe_sli->event_data1;\n\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"3191 Normal Temperature:%d Celsius - Port Name %c\\n\",\n\t\t\t\tacqe_sli->event_data1, port_name);\n\n\t\tshost = lpfc_shost_from_vport(phba->pport);\n\t\tfc_host_post_vendor_event(shost, fc_get_event_number(),\n\t\t\t\t\t  sizeof(temp_event_data),\n\t\t\t\t\t  (char *)&temp_event_data,\n\t\t\t\t\t  SCSI_NL_VID_TYPE_PCI\n\t\t\t\t\t  | PCI_VENDOR_ID_EMULEX);\n\t\tbreak;\n\tcase LPFC_SLI_EVENT_TYPE_MISCONFIGURED:\n\t\tmisconfigured = (struct lpfc_acqe_misconfigured_event *)\n\t\t\t\t\t&acqe_sli->event_data1;\n\n\t\t/* fetch the status for this port */\n\t\tswitch (phba->sli4_hba.lnk_info.lnk_no) {\n\t\tcase LPFC_LINK_NUMBER_0:\n\t\t\tstatus = bf_get(lpfc_sli_misconfigured_port0_state,\n\t\t\t\t\t&misconfigured->theEvent);\n\t\t\toperational = bf_get(lpfc_sli_misconfigured_port0_op,\n\t\t\t\t\t&misconfigured->theEvent);\n\t\t\tbreak;\n\t\tcase LPFC_LINK_NUMBER_1:\n\t\t\tstatus = bf_get(lpfc_sli_misconfigured_port1_state,\n\t\t\t\t\t&misconfigured->theEvent);\n\t\t\toperational = bf_get(lpfc_sli_misconfigured_port1_op,\n\t\t\t\t\t&misconfigured->theEvent);\n\t\t\tbreak;\n\t\tcase LPFC_LINK_NUMBER_2:\n\t\t\tstatus = bf_get(lpfc_sli_misconfigured_port2_state,\n\t\t\t\t\t&misconfigured->theEvent);\n\t\t\toperational = bf_get(lpfc_sli_misconfigured_port2_op,\n\t\t\t\t\t&misconfigured->theEvent);\n\t\t\tbreak;\n\t\tcase LPFC_LINK_NUMBER_3:\n\t\t\tstatus = bf_get(lpfc_sli_misconfigured_port3_state,\n\t\t\t\t\t&misconfigured->theEvent);\n\t\t\toperational = bf_get(lpfc_sli_misconfigured_port3_op,\n\t\t\t\t\t&misconfigured->theEvent);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"3296 \"\n\t\t\t\t\t\"LPFC_SLI_EVENT_TYPE_MISCONFIGURED \"\n\t\t\t\t\t\"event: Invalid link %d\",\n\t\t\t\t\tphba->sli4_hba.lnk_info.lnk_no);\n\t\t\treturn;\n\t\t}\n\n\t\t/* Skip if optic state unchanged */\n\t\tif (phba->sli4_hba.lnk_info.optic_state == status)\n\t\t\treturn;\n\n\t\tswitch (status) {\n\t\tcase LPFC_SLI_EVENT_STATUS_VALID:\n\t\t\tsprintf(message, \"Physical Link is functional\");\n\t\t\tbreak;\n\t\tcase LPFC_SLI_EVENT_STATUS_NOT_PRESENT:\n\t\t\tsprintf(message, \"Optics faulted/incorrectly \"\n\t\t\t\t\"installed/not installed - Reseat optics, \"\n\t\t\t\t\"if issue not resolved, replace.\");\n\t\t\tbreak;\n\t\tcase LPFC_SLI_EVENT_STATUS_WRONG_TYPE:\n\t\t\tsprintf(message,\n\t\t\t\t\"Optics of two types installed - Remove one \"\n\t\t\t\t\"optic or install matching pair of optics.\");\n\t\t\tbreak;\n\t\tcase LPFC_SLI_EVENT_STATUS_UNSUPPORTED:\n\t\t\tsprintf(message, \"Incompatible optics - Replace with \"\n\t\t\t\t\"compatible optics for card to function.\");\n\t\t\tbreak;\n\t\tcase LPFC_SLI_EVENT_STATUS_UNQUALIFIED:\n\t\t\tsprintf(message, \"Unqualified optics - Replace with \"\n\t\t\t\t\"Avago optics for Warranty and Technical \"\n\t\t\t\t\"Support - Link is%s operational\",\n\t\t\t\t(operational) ? \" not\" : \"\");\n\t\t\tbreak;\n\t\tcase LPFC_SLI_EVENT_STATUS_UNCERTIFIED:\n\t\t\tsprintf(message, \"Uncertified optics - Replace with \"\n\t\t\t\t\"Avago-certified optics to enable link \"\n\t\t\t\t\"operation - Link is%s operational\",\n\t\t\t\t(operational) ? \" not\" : \"\");\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t/* firmware is reporting a status we don't know about */\n\t\t\tsprintf(message, \"Unknown event status x%02x\", status);\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Issue READ_CONFIG mbox command to refresh supported speeds */\n\t\trc = lpfc_sli4_read_config(phba);\n\t\tif (rc) {\n\t\t\tphba->lmt = 0;\n\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\"3194 Unable to retrieve supported \"\n\t\t\t\t\t\"speeds, rc = 0x%x\\n\", rc);\n\t\t}\n\t\tvports = lpfc_create_vport_work_array(phba);\n\t\tif (vports != NULL) {\n\t\t\tfor (i = 0; i <= phba->max_vports && vports[i] != NULL;\n\t\t\t\t\ti++) {\n\t\t\t\tshost = lpfc_shost_from_vport(vports[i]);\n\t\t\t\tlpfc_host_supported_speeds_set(shost);\n\t\t\t}\n\t\t}\n\t\tlpfc_destroy_vport_work_array(phba, vports);\n\n\t\tphba->sli4_hba.lnk_info.optic_state = status;\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\n\t\t\t\t\"3176 Port Name %c %s\\n\", port_name, message);\n\t\tbreak;\n\tcase LPFC_SLI_EVENT_TYPE_REMOTE_DPORT:\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"3192 Remote DPort Test Initiated - \"\n\t\t\t\t\"Event Data1:x%08x Event Data2: x%08x\\n\",\n\t\t\t\tacqe_sli->event_data1, acqe_sli->event_data2);\n\t\tbreak;\n\tcase LPFC_SLI_EVENT_TYPE_MISCONF_FAWWN:\n\t\t/* Misconfigured WWN. Reports that the SLI Port is configured\n\t\t * to use FA-WWN, but the attached device doesn\u2019t support it.\n\t\t * No driver action is required.\n\t\t * Event Data1 - N.A, Event Data2 - N.A\n\t\t */\n\t\tlpfc_log_msg(phba, KERN_WARNING, LOG_SLI,\n\t\t\t     \"2699 Misconfigured FA-WWN - Attached device does \"\n\t\t\t     \"not support FA-WWN\\n\");\n\t\tbreak;\n\tcase LPFC_SLI_EVENT_TYPE_EEPROM_FAILURE:\n\t\t/* EEPROM failure. No driver action is required */\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\n\t\t\t     \"2518 EEPROM failure - \"\n\t\t\t     \"Event Data1: x%08x Event Data2: x%08x\\n\",\n\t\t\t     acqe_sli->event_data1, acqe_sli->event_data2);\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"3193 Unrecognized SLI event, type: 0x%x\",\n\t\t\t\tevt_type);\n\t\tbreak;\n\t}\n}\n\n/**\n * lpfc_sli4_perform_vport_cvl - Perform clear virtual link on a vport\n * @vport: pointer to vport data structure.\n *\n * This routine is to perform Clear Virtual Link (CVL) on a vport in\n * response to a CVL event.\n *\n * Return the pointer to the ndlp with the vport if successful, otherwise\n * return NULL.\n **/\nstatic struct lpfc_nodelist *\nlpfc_sli4_perform_vport_cvl(struct lpfc_vport *vport)\n{\n\tstruct lpfc_nodelist *ndlp;\n\tstruct Scsi_Host *shost;\n\tstruct lpfc_hba *phba;\n\n\tif (!vport)\n\t\treturn NULL;\n\tphba = vport->phba;\n\tif (!phba)\n\t\treturn NULL;\n\tndlp = lpfc_findnode_did(vport, Fabric_DID);\n\tif (!ndlp) {\n\t\t/* Cannot find existing Fabric ndlp, so allocate a new one */\n\t\tndlp = lpfc_nlp_init(vport, Fabric_DID);\n\t\tif (!ndlp)\n\t\t\treturn 0;\n\t\t/* Set the node type */\n\t\tndlp->nlp_type |= NLP_FABRIC;\n\t\t/* Put ndlp onto node list */\n\t\tlpfc_enqueue_node(vport, ndlp);\n\t}\n\tif ((phba->pport->port_state < LPFC_FLOGI) &&\n\t\t(phba->pport->port_state != LPFC_VPORT_FAILED))\n\t\treturn NULL;\n\t/* If virtual link is not yet instantiated ignore CVL */\n\tif ((vport != phba->pport) && (vport->port_state < LPFC_FDISC)\n\t\t&& (vport->port_state != LPFC_VPORT_FAILED))\n\t\treturn NULL;\n\tshost = lpfc_shost_from_vport(vport);\n\tif (!shost)\n\t\treturn NULL;\n\tlpfc_linkdown_port(vport);\n\tlpfc_cleanup_pending_mbox(vport);\n\tspin_lock_irq(shost->host_lock);\n\tvport->fc_flag |= FC_VPORT_CVL_RCVD;\n\tspin_unlock_irq(shost->host_lock);\n\n\treturn ndlp;\n}\n\n/**\n * lpfc_sli4_perform_all_vport_cvl - Perform clear virtual link on all vports\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is to perform Clear Virtual Link (CVL) on all vports in\n * response to a FCF dead event.\n **/\nstatic void\nlpfc_sli4_perform_all_vport_cvl(struct lpfc_hba *phba)\n{\n\tstruct lpfc_vport **vports;\n\tint i;\n\n\tvports = lpfc_create_vport_work_array(phba);\n\tif (vports)\n\t\tfor (i = 0; i <= phba->max_vports && vports[i] != NULL; i++)\n\t\t\tlpfc_sli4_perform_vport_cvl(vports[i]);\n\tlpfc_destroy_vport_work_array(phba, vports);\n}\n\n/**\n * lpfc_sli4_async_fip_evt - Process the asynchronous FCoE FIP event\n * @phba: pointer to lpfc hba data structure.\n * @acqe_fip: pointer to the async fcoe completion queue entry.\n *\n * This routine is to handle the SLI4 asynchronous fcoe event.\n **/\nstatic void\nlpfc_sli4_async_fip_evt(struct lpfc_hba *phba,\n\t\t\tstruct lpfc_acqe_fip *acqe_fip)\n{\n\tuint8_t event_type = bf_get(lpfc_trailer_type, acqe_fip);\n\tint rc;\n\tstruct lpfc_vport *vport;\n\tstruct lpfc_nodelist *ndlp;\n\tint active_vlink_present;\n\tstruct lpfc_vport **vports;\n\tint i;\n\n\tphba->fc_eventTag = acqe_fip->event_tag;\n\tphba->fcoe_eventtag = acqe_fip->event_tag;\n\tswitch (event_type) {\n\tcase LPFC_FIP_EVENT_TYPE_NEW_FCF:\n\tcase LPFC_FIP_EVENT_TYPE_FCF_PARAM_MOD:\n\t\tif (event_type == LPFC_FIP_EVENT_TYPE_NEW_FCF)\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"2546 New FCF event, evt_tag:x%x, \"\n\t\t\t\t\t\"index:x%x\\n\",\n\t\t\t\t\tacqe_fip->event_tag,\n\t\t\t\t\tacqe_fip->index);\n\t\telse\n\t\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_FIP |\n\t\t\t\t\tLOG_DISCOVERY,\n\t\t\t\t\t\"2788 FCF param modified event, \"\n\t\t\t\t\t\"evt_tag:x%x, index:x%x\\n\",\n\t\t\t\t\tacqe_fip->event_tag,\n\t\t\t\t\tacqe_fip->index);\n\t\tif (phba->fcf.fcf_flag & FCF_DISCOVERY) {\n\t\t\t/*\n\t\t\t * During period of FCF discovery, read the FCF\n\t\t\t * table record indexed by the event to update\n\t\t\t * FCF roundrobin failover eligible FCF bmask.\n\t\t\t */\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_FIP |\n\t\t\t\t\tLOG_DISCOVERY,\n\t\t\t\t\t\"2779 Read FCF (x%x) for updating \"\n\t\t\t\t\t\"roundrobin FCF failover bmask\\n\",\n\t\t\t\t\tacqe_fip->index);\n\t\t\trc = lpfc_sli4_read_fcf_rec(phba, acqe_fip->index);\n\t\t}\n\n\t\t/* If the FCF discovery is in progress, do nothing. */\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tif (phba->hba_flag & FCF_TS_INPROG) {\n\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\tbreak;\n\t\t}\n\t\t/* If fast FCF failover rescan event is pending, do nothing */\n\t\tif (phba->fcf.fcf_flag & (FCF_REDISC_EVT | FCF_REDISC_PEND)) {\n\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\tbreak;\n\t\t}\n\n\t\t/* If the FCF has been in discovered state, do nothing. */\n\t\tif (phba->fcf.fcf_flag & FCF_SCAN_DONE) {\n\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\tbreak;\n\t\t}\n\t\tspin_unlock_irq(&phba->hbalock);\n\n\t\t/* Otherwise, scan the entire FCF table and re-discover SAN */\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_FIP | LOG_DISCOVERY,\n\t\t\t\t\"2770 Start FCF table scan per async FCF \"\n\t\t\t\t\"event, evt_tag:x%x, index:x%x\\n\",\n\t\t\t\tacqe_fip->event_tag, acqe_fip->index);\n\t\trc = lpfc_sli4_fcf_scan_read_fcf_rec(phba,\n\t\t\t\t\t\t     LPFC_FCOE_FCF_GET_FIRST);\n\t\tif (rc)\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"2547 Issue FCF scan read FCF mailbox \"\n\t\t\t\t\t\"command failed (x%x)\\n\", rc);\n\t\tbreak;\n\n\tcase LPFC_FIP_EVENT_TYPE_FCF_TABLE_FULL:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2548 FCF Table full count 0x%x tag 0x%x\\n\",\n\t\t\t\tbf_get(lpfc_acqe_fip_fcf_count, acqe_fip),\n\t\t\t\tacqe_fip->event_tag);\n\t\tbreak;\n\n\tcase LPFC_FIP_EVENT_TYPE_FCF_DEAD:\n\t\tphba->fcoe_cvl_eventtag = acqe_fip->event_tag;\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2549 FCF (x%x) disconnected from network, \"\n\t\t\t\t \"tag:x%x\\n\", acqe_fip->index,\n\t\t\t\t acqe_fip->event_tag);\n\t\t/*\n\t\t * If we are in the middle of FCF failover process, clear\n\t\t * the corresponding FCF bit in the roundrobin bitmap.\n\t\t */\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tif ((phba->fcf.fcf_flag & FCF_DISCOVERY) &&\n\t\t    (phba->fcf.current_rec.fcf_indx != acqe_fip->index)) {\n\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\t/* Update FLOGI FCF failover eligible FCF bmask */\n\t\t\tlpfc_sli4_fcf_rr_index_clear(phba, acqe_fip->index);\n\t\t\tbreak;\n\t\t}\n\t\tspin_unlock_irq(&phba->hbalock);\n\n\t\t/* If the event is not for currently used fcf do nothing */\n\t\tif (phba->fcf.current_rec.fcf_indx != acqe_fip->index)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * Otherwise, request the port to rediscover the entire FCF\n\t\t * table for a fast recovery from case that the current FCF\n\t\t * is no longer valid as we are not in the middle of FCF\n\t\t * failover process already.\n\t\t */\n\t\tspin_lock_irq(&phba->hbalock);\n\t\t/* Mark the fast failover process in progress */\n\t\tphba->fcf.fcf_flag |= FCF_DEAD_DISC;\n\t\tspin_unlock_irq(&phba->hbalock);\n\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_FIP | LOG_DISCOVERY,\n\t\t\t\t\"2771 Start FCF fast failover process due to \"\n\t\t\t\t\"FCF DEAD event: evt_tag:x%x, fcf_index:x%x \"\n\t\t\t\t\"\\n\", acqe_fip->event_tag, acqe_fip->index);\n\t\trc = lpfc_sli4_redisc_fcf_table(phba);\n\t\tif (rc) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_FIP |\n\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\"2772 Issue FCF rediscover mailbox \"\n\t\t\t\t\t\"command failed, fail through to FCF \"\n\t\t\t\t\t\"dead event\\n\");\n\t\t\tspin_lock_irq(&phba->hbalock);\n\t\t\tphba->fcf.fcf_flag &= ~FCF_DEAD_DISC;\n\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\t/*\n\t\t\t * Last resort will fail over by treating this\n\t\t\t * as a link down to FCF registration.\n\t\t\t */\n\t\t\tlpfc_sli4_fcf_dead_failthrough(phba);\n\t\t} else {\n\t\t\t/* Reset FCF roundrobin bmask for new discovery */\n\t\t\tlpfc_sli4_clear_fcf_rr_bmask(phba);\n\t\t\t/*\n\t\t\t * Handling fast FCF failover to a DEAD FCF event is\n\t\t\t * considered equalivant to receiving CVL to all vports.\n\t\t\t */\n\t\t\tlpfc_sli4_perform_all_vport_cvl(phba);\n\t\t}\n\t\tbreak;\n\tcase LPFC_FIP_EVENT_TYPE_CVL:\n\t\tphba->fcoe_cvl_eventtag = acqe_fip->event_tag;\n\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\"2718 Clear Virtual Link Received for VPI 0x%x\"\n\t\t\t\" tag 0x%x\\n\", acqe_fip->index, acqe_fip->event_tag);\n\n\t\tvport = lpfc_find_vport_by_vpid(phba,\n\t\t\t\t\t\tacqe_fip->index);\n\t\tndlp = lpfc_sli4_perform_vport_cvl(vport);\n\t\tif (!ndlp)\n\t\t\tbreak;\n\t\tactive_vlink_present = 0;\n\n\t\tvports = lpfc_create_vport_work_array(phba);\n\t\tif (vports) {\n\t\t\tfor (i = 0; i <= phba->max_vports && vports[i] != NULL;\n\t\t\t\t\ti++) {\n\t\t\t\tif ((!(vports[i]->fc_flag &\n\t\t\t\t\tFC_VPORT_CVL_RCVD)) &&\n\t\t\t\t\t(vports[i]->port_state > LPFC_FDISC)) {\n\t\t\t\t\tactive_vlink_present = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tlpfc_destroy_vport_work_array(phba, vports);\n\t\t}\n\n\t\t/*\n\t\t * Don't re-instantiate if vport is marked for deletion.\n\t\t * If we are here first then vport_delete is going to wait\n\t\t * for discovery to complete.\n\t\t */\n\t\tif (!(vport->load_flag & FC_UNLOADING) &&\n\t\t\t\t\tactive_vlink_present) {\n\t\t\t/*\n\t\t\t * If there are other active VLinks present,\n\t\t\t * re-instantiate the Vlink using FDISC.\n\t\t\t */\n\t\t\tmod_timer(&ndlp->nlp_delayfunc,\n\t\t\t\t  jiffies + msecs_to_jiffies(1000));\n\t\t\tspin_lock_irq(&ndlp->lock);\n\t\t\tndlp->nlp_flag |= NLP_DELAY_TMO;\n\t\t\tspin_unlock_irq(&ndlp->lock);\n\t\t\tndlp->nlp_last_elscmd = ELS_CMD_FDISC;\n\t\t\tvport->port_state = LPFC_FDISC;\n\t\t} else {\n\t\t\t/*\n\t\t\t * Otherwise, we request port to rediscover\n\t\t\t * the entire FCF table for a fast recovery\n\t\t\t * from possible case that the current FCF\n\t\t\t * is no longer valid if we are not already\n\t\t\t * in the FCF failover process.\n\t\t\t */\n\t\t\tspin_lock_irq(&phba->hbalock);\n\t\t\tif (phba->fcf.fcf_flag & FCF_DISCOVERY) {\n\t\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t/* Mark the fast failover process in progress */\n\t\t\tphba->fcf.fcf_flag |= FCF_ACVL_DISC;\n\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_FIP |\n\t\t\t\t\tLOG_DISCOVERY,\n\t\t\t\t\t\"2773 Start FCF failover per CVL, \"\n\t\t\t\t\t\"evt_tag:x%x\\n\", acqe_fip->event_tag);\n\t\t\trc = lpfc_sli4_redisc_fcf_table(phba);\n\t\t\tif (rc) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_FIP |\n\t\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\t\"2774 Issue FCF rediscover \"\n\t\t\t\t\t\t\"mailbox command failed, \"\n\t\t\t\t\t\t\"through to CVL event\\n\");\n\t\t\t\tspin_lock_irq(&phba->hbalock);\n\t\t\t\tphba->fcf.fcf_flag &= ~FCF_ACVL_DISC;\n\t\t\t\tspin_unlock_irq(&phba->hbalock);\n\t\t\t\t/*\n\t\t\t\t * Last resort will be re-try on the\n\t\t\t\t * the current registered FCF entry.\n\t\t\t\t */\n\t\t\t\tlpfc_retry_pport_discovery(phba);\n\t\t\t} else\n\t\t\t\t/*\n\t\t\t\t * Reset FCF roundrobin bmask for new\n\t\t\t\t * discovery.\n\t\t\t\t */\n\t\t\t\tlpfc_sli4_clear_fcf_rr_bmask(phba);\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0288 Unknown FCoE event type 0x%x event tag \"\n\t\t\t\t\"0x%x\\n\", event_type, acqe_fip->event_tag);\n\t\tbreak;\n\t}\n}\n\n/**\n * lpfc_sli4_async_dcbx_evt - Process the asynchronous dcbx event\n * @phba: pointer to lpfc hba data structure.\n * @acqe_dcbx: pointer to the async dcbx completion queue entry.\n *\n * This routine is to handle the SLI4 asynchronous dcbx event.\n **/\nstatic void\nlpfc_sli4_async_dcbx_evt(struct lpfc_hba *phba,\n\t\t\t struct lpfc_acqe_dcbx *acqe_dcbx)\n{\n\tphba->fc_eventTag = acqe_dcbx->event_tag;\n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"0290 The SLI4 DCBX asynchronous event is not \"\n\t\t\t\"handled yet\\n\");\n}\n\n/**\n * lpfc_sli4_async_grp5_evt - Process the asynchronous group5 event\n * @phba: pointer to lpfc hba data structure.\n * @acqe_grp5: pointer to the async grp5 completion queue entry.\n *\n * This routine is to handle the SLI4 asynchronous grp5 event. A grp5 event\n * is an asynchronous notified of a logical link speed change.  The Port\n * reports the logical link speed in units of 10Mbps.\n **/\nstatic void\nlpfc_sli4_async_grp5_evt(struct lpfc_hba *phba,\n\t\t\t struct lpfc_acqe_grp5 *acqe_grp5)\n{\n\tuint16_t prev_ll_spd;\n\n\tphba->fc_eventTag = acqe_grp5->event_tag;\n\tphba->fcoe_eventtag = acqe_grp5->event_tag;\n\tprev_ll_spd = phba->sli4_hba.link_state.logical_speed;\n\tphba->sli4_hba.link_state.logical_speed =\n\t\t(bf_get(lpfc_acqe_grp5_llink_spd, acqe_grp5)) * 10;\n\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\"2789 GRP5 Async Event: Updating logical link speed \"\n\t\t\t\"from %dMbps to %dMbps\\n\", prev_ll_spd,\n\t\t\tphba->sli4_hba.link_state.logical_speed);\n}\n\n/**\n * lpfc_sli4_async_event_proc - Process all the pending asynchronous event\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked by the worker thread to process all the pending\n * SLI4 asynchronous events.\n **/\nvoid lpfc_sli4_async_event_proc(struct lpfc_hba *phba)\n{\n\tstruct lpfc_cq_event *cq_event;\n\tunsigned long iflags;\n\n\t/* First, declare the async event has been handled */\n\tspin_lock_irqsave(&phba->hbalock, iflags);\n\tphba->hba_flag &= ~ASYNC_EVENT;\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\n\t/* Now, handle all the async events */\n\tspin_lock_irqsave(&phba->sli4_hba.asynce_list_lock, iflags);\n\twhile (!list_empty(&phba->sli4_hba.sp_asynce_work_queue)) {\n\t\tlist_remove_head(&phba->sli4_hba.sp_asynce_work_queue,\n\t\t\t\t cq_event, struct lpfc_cq_event, list);\n\t\tspin_unlock_irqrestore(&phba->sli4_hba.asynce_list_lock,\n\t\t\t\t       iflags);\n\n\t\t/* Process the asynchronous event */\n\t\tswitch (bf_get(lpfc_trailer_code, &cq_event->cqe.mcqe_cmpl)) {\n\t\tcase LPFC_TRAILER_CODE_LINK:\n\t\t\tlpfc_sli4_async_link_evt(phba,\n\t\t\t\t\t\t &cq_event->cqe.acqe_link);\n\t\t\tbreak;\n\t\tcase LPFC_TRAILER_CODE_FCOE:\n\t\t\tlpfc_sli4_async_fip_evt(phba, &cq_event->cqe.acqe_fip);\n\t\t\tbreak;\n\t\tcase LPFC_TRAILER_CODE_DCBX:\n\t\t\tlpfc_sli4_async_dcbx_evt(phba,\n\t\t\t\t\t\t &cq_event->cqe.acqe_dcbx);\n\t\t\tbreak;\n\t\tcase LPFC_TRAILER_CODE_GRP5:\n\t\t\tlpfc_sli4_async_grp5_evt(phba,\n\t\t\t\t\t\t &cq_event->cqe.acqe_grp5);\n\t\t\tbreak;\n\t\tcase LPFC_TRAILER_CODE_FC:\n\t\t\tlpfc_sli4_async_fc_evt(phba, &cq_event->cqe.acqe_fc);\n\t\t\tbreak;\n\t\tcase LPFC_TRAILER_CODE_SLI:\n\t\t\tlpfc_sli4_async_sli_evt(phba, &cq_event->cqe.acqe_sli);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\"1804 Invalid asynchronous event code: \"\n\t\t\t\t\t\"x%x\\n\", bf_get(lpfc_trailer_code,\n\t\t\t\t\t&cq_event->cqe.mcqe_cmpl));\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Free the completion event processed to the free pool */\n\t\tlpfc_sli4_cq_event_release(phba, cq_event);\n\t\tspin_lock_irqsave(&phba->sli4_hba.asynce_list_lock, iflags);\n\t}\n\tspin_unlock_irqrestore(&phba->sli4_hba.asynce_list_lock, iflags);\n}\n\n/**\n * lpfc_sli4_fcf_redisc_event_proc - Process fcf table rediscovery event\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked by the worker thread to process FCF table\n * rediscovery pending completion event.\n **/\nvoid lpfc_sli4_fcf_redisc_event_proc(struct lpfc_hba *phba)\n{\n\tint rc;\n\n\tspin_lock_irq(&phba->hbalock);\n\t/* Clear FCF rediscovery timeout event */\n\tphba->fcf.fcf_flag &= ~FCF_REDISC_EVT;\n\t/* Clear driver fast failover FCF record flag */\n\tphba->fcf.failover_rec.flag = 0;\n\t/* Set state for FCF fast failover */\n\tphba->fcf.fcf_flag |= FCF_REDISC_FOV;\n\tspin_unlock_irq(&phba->hbalock);\n\n\t/* Scan FCF table from the first entry to re-discover SAN */\n\tlpfc_printf_log(phba, KERN_INFO, LOG_FIP | LOG_DISCOVERY,\n\t\t\t\"2777 Start post-quiescent FCF table scan\\n\");\n\trc = lpfc_sli4_fcf_scan_read_fcf_rec(phba, LPFC_FCOE_FCF_GET_FIRST);\n\tif (rc)\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2747 Issue FCF scan read FCF mailbox \"\n\t\t\t\t\"command failed 0x%x\\n\", rc);\n}\n\n/**\n * lpfc_api_table_setup - Set up per hba pci-device group func api jump table\n * @phba: pointer to lpfc hba data structure.\n * @dev_grp: The HBA PCI-Device group number.\n *\n * This routine is invoked to set up the per HBA PCI-Device group function\n * API jump table entries.\n *\n * Return: 0 if success, otherwise -ENODEV\n **/\nint\nlpfc_api_table_setup(struct lpfc_hba *phba, uint8_t dev_grp)\n{\n\tint rc;\n\n\t/* Set up lpfc PCI-device group */\n\tphba->pci_dev_grp = dev_grp;\n\n\t/* The LPFC_PCI_DEV_OC uses SLI4 */\n\tif (dev_grp == LPFC_PCI_DEV_OC)\n\t\tphba->sli_rev = LPFC_SLI_REV4;\n\n\t/* Set up device INIT API function jump table */\n\trc = lpfc_init_api_table_setup(phba, dev_grp);\n\tif (rc)\n\t\treturn -ENODEV;\n\t/* Set up SCSI API function jump table */\n\trc = lpfc_scsi_api_table_setup(phba, dev_grp);\n\tif (rc)\n\t\treturn -ENODEV;\n\t/* Set up SLI API function jump table */\n\trc = lpfc_sli_api_table_setup(phba, dev_grp);\n\tif (rc)\n\t\treturn -ENODEV;\n\t/* Set up MBOX API function jump table */\n\trc = lpfc_mbox_api_table_setup(phba, dev_grp);\n\tif (rc)\n\t\treturn -ENODEV;\n\n\treturn 0;\n}\n\n/**\n * lpfc_log_intr_mode - Log the active interrupt mode\n * @phba: pointer to lpfc hba data structure.\n * @intr_mode: active interrupt mode adopted.\n *\n * This routine it invoked to log the currently used active interrupt mode\n * to the device.\n **/\nstatic void lpfc_log_intr_mode(struct lpfc_hba *phba, uint32_t intr_mode)\n{\n\tswitch (intr_mode) {\n\tcase 0:\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"0470 Enable INTx interrupt mode.\\n\");\n\t\tbreak;\n\tcase 1:\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"0481 Enabled MSI interrupt mode.\\n\");\n\t\tbreak;\n\tcase 2:\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"0480 Enabled MSI-X interrupt mode.\\n\");\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0482 Illegal interrupt mode.\\n\");\n\t\tbreak;\n\t}\n\treturn;\n}\n\n/**\n * lpfc_enable_pci_dev - Enable a generic PCI device.\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to enable the PCI device that is common to all\n * PCI devices.\n *\n * Return codes\n * \t0 - successful\n * \tother values - error\n **/\nstatic int\nlpfc_enable_pci_dev(struct lpfc_hba *phba)\n{\n\tstruct pci_dev *pdev;\n\n\t/* Obtain PCI device reference */\n\tif (!phba->pcidev)\n\t\tgoto out_error;\n\telse\n\t\tpdev = phba->pcidev;\n\t/* Enable PCI device */\n\tif (pci_enable_device_mem(pdev))\n\t\tgoto out_error;\n\t/* Request PCI resource for the device */\n\tif (pci_request_mem_regions(pdev, LPFC_DRIVER_NAME))\n\t\tgoto out_disable_device;\n\t/* Set up device as PCI master and save state for EEH */\n\tpci_set_master(pdev);\n\tpci_try_set_mwi(pdev);\n\tpci_save_state(pdev);\n\n\t/* PCIe EEH recovery on powerpc platforms needs fundamental reset */\n\tif (pci_is_pcie(pdev))\n\t\tpdev->needs_freset = 1;\n\n\treturn 0;\n\nout_disable_device:\n\tpci_disable_device(pdev);\nout_error:\n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"1401 Failed to enable pci device\\n\");\n\treturn -ENODEV;\n}\n\n/**\n * lpfc_disable_pci_dev - Disable a generic PCI device.\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to disable the PCI device that is common to all\n * PCI devices.\n **/\nstatic void\nlpfc_disable_pci_dev(struct lpfc_hba *phba)\n{\n\tstruct pci_dev *pdev;\n\n\t/* Obtain PCI device reference */\n\tif (!phba->pcidev)\n\t\treturn;\n\telse\n\t\tpdev = phba->pcidev;\n\t/* Release PCI resource and disable PCI device */\n\tpci_release_mem_regions(pdev);\n\tpci_disable_device(pdev);\n\n\treturn;\n}\n\n/**\n * lpfc_reset_hba - Reset a hba\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to reset a hba device. It brings the HBA\n * offline, performs a board restart, and then brings the board back\n * online. The lpfc_offline calls lpfc_sli_hba_down which will clean up\n * on outstanding mailbox commands.\n **/\nvoid\nlpfc_reset_hba(struct lpfc_hba *phba)\n{\n\t/* If resets are disabled then set error state and return. */\n\tif (!phba->cfg_enable_hba_reset) {\n\t\tphba->link_state = LPFC_HBA_ERROR;\n\t\treturn;\n\t}\n\n\t/* If not LPFC_SLI_ACTIVE, force all IO to be flushed */\n\tif (phba->sli.sli_flag & LPFC_SLI_ACTIVE) {\n\t\tlpfc_offline_prep(phba, LPFC_MBX_WAIT);\n\t} else {\n\t\tlpfc_offline_prep(phba, LPFC_MBX_NO_WAIT);\n\t\tlpfc_sli_flush_io_rings(phba);\n\t}\n\tlpfc_offline(phba);\n\tlpfc_sli_brdrestart(phba);\n\tlpfc_online(phba);\n\tlpfc_unblock_mgmt_io(phba);\n}\n\n/**\n * lpfc_sli_sriov_nr_virtfn_get - Get the number of sr-iov virtual functions\n * @phba: pointer to lpfc hba data structure.\n *\n * This function enables the PCI SR-IOV virtual functions to a physical\n * function. It invokes the PCI SR-IOV api with the @nr_vfn provided to\n * enable the number of virtual functions to the physical function. As\n * not all devices support SR-IOV, the return code from the pci_enable_sriov()\n * API call does not considered as an error condition for most of the device.\n **/\nuint16_t\nlpfc_sli_sriov_nr_virtfn_get(struct lpfc_hba *phba)\n{\n\tstruct pci_dev *pdev = phba->pcidev;\n\tuint16_t nr_virtfn;\n\tint pos;\n\n\tpos = pci_find_ext_capability(pdev, PCI_EXT_CAP_ID_SRIOV);\n\tif (pos == 0)\n\t\treturn 0;\n\n\tpci_read_config_word(pdev, pos + PCI_SRIOV_TOTAL_VF, &nr_virtfn);\n\treturn nr_virtfn;\n}\n\n/**\n * lpfc_sli_probe_sriov_nr_virtfn - Enable a number of sr-iov virtual functions\n * @phba: pointer to lpfc hba data structure.\n * @nr_vfn: number of virtual functions to be enabled.\n *\n * This function enables the PCI SR-IOV virtual functions to a physical\n * function. It invokes the PCI SR-IOV api with the @nr_vfn provided to\n * enable the number of virtual functions to the physical function. As\n * not all devices support SR-IOV, the return code from the pci_enable_sriov()\n * API call does not considered as an error condition for most of the device.\n **/\nint\nlpfc_sli_probe_sriov_nr_virtfn(struct lpfc_hba *phba, int nr_vfn)\n{\n\tstruct pci_dev *pdev = phba->pcidev;\n\tuint16_t max_nr_vfn;\n\tint rc;\n\n\tmax_nr_vfn = lpfc_sli_sriov_nr_virtfn_get(phba);\n\tif (nr_vfn > max_nr_vfn) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3057 Requested vfs (%d) greater than \"\n\t\t\t\t\"supported vfs (%d)\", nr_vfn, max_nr_vfn);\n\t\treturn -EINVAL;\n\t}\n\n\trc = pci_enable_sriov(pdev, nr_vfn);\n\tif (rc) {\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\"2806 Failed to enable sriov on this device \"\n\t\t\t\t\"with vfn number nr_vf:%d, rc:%d\\n\",\n\t\t\t\tnr_vfn, rc);\n\t} else\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\"2807 Successful enable sriov on this device \"\n\t\t\t\t\"with vfn number nr_vf:%d\\n\", nr_vfn);\n\treturn rc;\n}\n\n/**\n * lpfc_setup_driver_resource_phase1 - Phase1 etup driver internal resources.\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to set up the driver internal resources before the\n * device specific resource setup to support the HBA device it attached to.\n *\n * Return codes\n *\t0 - successful\n *\tother values - error\n **/\nstatic int\nlpfc_setup_driver_resource_phase1(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli *psli = &phba->sli;\n\n\t/*\n\t * Driver resources common to all SLI revisions\n\t */\n\tatomic_set(&phba->fast_event_count, 0);\n\tatomic_set(&phba->dbg_log_idx, 0);\n\tatomic_set(&phba->dbg_log_cnt, 0);\n\tatomic_set(&phba->dbg_log_dmping, 0);\n\tspin_lock_init(&phba->hbalock);\n\n\t/* Initialize port_list spinlock */\n\tspin_lock_init(&phba->port_list_lock);\n\tINIT_LIST_HEAD(&phba->port_list);\n\n\tINIT_LIST_HEAD(&phba->work_list);\n\tinit_waitqueue_head(&phba->wait_4_mlo_m_q);\n\n\t/* Initialize the wait queue head for the kernel thread */\n\tinit_waitqueue_head(&phba->work_waitq);\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"1403 Protocols supported %s %s %s\\n\",\n\t\t\t((phba->cfg_enable_fc4_type & LPFC_ENABLE_FCP) ?\n\t\t\t\t\"SCSI\" : \" \"),\n\t\t\t((phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME) ?\n\t\t\t\t\"NVME\" : \" \"),\n\t\t\t(phba->nvmet_support ? \"NVMET\" : \" \"));\n\n\t/* Initialize the IO buffer list used by driver for SLI3 SCSI */\n\tspin_lock_init(&phba->scsi_buf_list_get_lock);\n\tINIT_LIST_HEAD(&phba->lpfc_scsi_buf_list_get);\n\tspin_lock_init(&phba->scsi_buf_list_put_lock);\n\tINIT_LIST_HEAD(&phba->lpfc_scsi_buf_list_put);\n\n\t/* Initialize the fabric iocb list */\n\tINIT_LIST_HEAD(&phba->fabric_iocb_list);\n\n\t/* Initialize list to save ELS buffers */\n\tINIT_LIST_HEAD(&phba->elsbuf);\n\n\t/* Initialize FCF connection rec list */\n\tINIT_LIST_HEAD(&phba->fcf_conn_rec_list);\n\n\t/* Initialize OAS configuration list */\n\tspin_lock_init(&phba->devicelock);\n\tINIT_LIST_HEAD(&phba->luns);\n\n\t/* MBOX heartbeat timer */\n\ttimer_setup(&psli->mbox_tmo, lpfc_mbox_timeout, 0);\n\t/* Fabric block timer */\n\ttimer_setup(&phba->fabric_block_timer, lpfc_fabric_block_timeout, 0);\n\t/* EA polling mode timer */\n\ttimer_setup(&phba->eratt_poll, lpfc_poll_eratt, 0);\n\t/* Heartbeat timer */\n\ttimer_setup(&phba->hb_tmofunc, lpfc_hb_timeout, 0);\n\n\tINIT_DELAYED_WORK(&phba->eq_delay_work, lpfc_hb_eq_delay_work);\n\n\tINIT_DELAYED_WORK(&phba->idle_stat_delay_work,\n\t\t\t  lpfc_idle_stat_delay_work);\n\n\treturn 0;\n}\n\n/**\n * lpfc_sli_driver_resource_setup - Setup driver internal resources for SLI3 dev\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to set up the driver internal resources specific to\n * support the SLI-3 HBA device it attached to.\n *\n * Return codes\n * 0 - successful\n * other values - error\n **/\nstatic int\nlpfc_sli_driver_resource_setup(struct lpfc_hba *phba)\n{\n\tint rc, entry_sz;\n\n\t/*\n\t * Initialize timers used by driver\n\t */\n\n\t/* FCP polling mode timer */\n\ttimer_setup(&phba->fcp_poll_timer, lpfc_poll_timeout, 0);\n\n\t/* Host attention work mask setup */\n\tphba->work_ha_mask = (HA_ERATT | HA_MBATT | HA_LATT);\n\tphba->work_ha_mask |= (HA_RXMASK << (LPFC_ELS_RING * 4));\n\n\t/* Get all the module params for configuring this host */\n\tlpfc_get_cfgparam(phba);\n\t/* Set up phase-1 common device driver resources */\n\n\trc = lpfc_setup_driver_resource_phase1(phba);\n\tif (rc)\n\t\treturn -ENODEV;\n\n\tif (phba->pcidev->device == PCI_DEVICE_ID_HORNET) {\n\t\tphba->menlo_flag |= HBA_MENLO_SUPPORT;\n\t\t/* check for menlo minimum sg count */\n\t\tif (phba->cfg_sg_seg_cnt < LPFC_DEFAULT_MENLO_SG_SEG_CNT)\n\t\t\tphba->cfg_sg_seg_cnt = LPFC_DEFAULT_MENLO_SG_SEG_CNT;\n\t}\n\n\tif (!phba->sli.sli3_ring)\n\t\tphba->sli.sli3_ring = kcalloc(LPFC_SLI3_MAX_RING,\n\t\t\t\t\t      sizeof(struct lpfc_sli_ring),\n\t\t\t\t\t      GFP_KERNEL);\n\tif (!phba->sli.sli3_ring)\n\t\treturn -ENOMEM;\n\n\t/*\n\t * Since lpfc_sg_seg_cnt is module parameter, the sg_dma_buf_size\n\t * used to create the sg_dma_buf_pool must be dynamically calculated.\n\t */\n\n\tif (phba->sli_rev == LPFC_SLI_REV4)\n\t\tentry_sz = sizeof(struct sli4_sge);\n\telse\n\t\tentry_sz = sizeof(struct ulp_bde64);\n\n\t/* There are going to be 2 reserved BDEs: 1 FCP cmnd + 1 FCP rsp */\n\tif (phba->cfg_enable_bg) {\n\t\t/*\n\t\t * The scsi_buf for a T10-DIF I/O will hold the FCP cmnd,\n\t\t * the FCP rsp, and a BDE for each. Sice we have no control\n\t\t * over how many protection data segments the SCSI Layer\n\t\t * will hand us (ie: there could be one for every block\n\t\t * in the IO), we just allocate enough BDEs to accomidate\n\t\t * our max amount and we need to limit lpfc_sg_seg_cnt to\n\t\t * minimize the risk of running out.\n\t\t */\n\t\tphba->cfg_sg_dma_buf_size = sizeof(struct fcp_cmnd) +\n\t\t\tsizeof(struct fcp_rsp) +\n\t\t\t(LPFC_MAX_SG_SEG_CNT * entry_sz);\n\n\t\tif (phba->cfg_sg_seg_cnt > LPFC_MAX_SG_SEG_CNT_DIF)\n\t\t\tphba->cfg_sg_seg_cnt = LPFC_MAX_SG_SEG_CNT_DIF;\n\n\t\t/* Total BDEs in BPL for scsi_sg_list and scsi_sg_prot_list */\n\t\tphba->cfg_total_seg_cnt = LPFC_MAX_SG_SEG_CNT;\n\t} else {\n\t\t/*\n\t\t * The scsi_buf for a regular I/O will hold the FCP cmnd,\n\t\t * the FCP rsp, a BDE for each, and a BDE for up to\n\t\t * cfg_sg_seg_cnt data segments.\n\t\t */\n\t\tphba->cfg_sg_dma_buf_size = sizeof(struct fcp_cmnd) +\n\t\t\tsizeof(struct fcp_rsp) +\n\t\t\t((phba->cfg_sg_seg_cnt + 2) * entry_sz);\n\n\t\t/* Total BDEs in BPL for scsi_sg_list */\n\t\tphba->cfg_total_seg_cnt = phba->cfg_sg_seg_cnt + 2;\n\t}\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT | LOG_FCP,\n\t\t\t\"9088 INIT sg_tablesize:%d dmabuf_size:%d total_bde:%d\\n\",\n\t\t\tphba->cfg_sg_seg_cnt, phba->cfg_sg_dma_buf_size,\n\t\t\tphba->cfg_total_seg_cnt);\n\n\tphba->max_vpi = LPFC_MAX_VPI;\n\t/* This will be set to correct value after config_port mbox */\n\tphba->max_vports = 0;\n\n\t/*\n\t * Initialize the SLI Layer to run with lpfc HBAs.\n\t */\n\tlpfc_sli_setup(phba);\n\tlpfc_sli_queue_init(phba);\n\n\t/* Allocate device driver memory */\n\tif (lpfc_mem_alloc(phba, BPL_ALIGN_SZ))\n\t\treturn -ENOMEM;\n\n\tphba->lpfc_sg_dma_buf_pool =\n\t\tdma_pool_create(\"lpfc_sg_dma_buf_pool\",\n\t\t\t\t&phba->pcidev->dev, phba->cfg_sg_dma_buf_size,\n\t\t\t\tBPL_ALIGN_SZ, 0);\n\n\tif (!phba->lpfc_sg_dma_buf_pool)\n\t\tgoto fail_free_mem;\n\n\tphba->lpfc_cmd_rsp_buf_pool =\n\t\t\tdma_pool_create(\"lpfc_cmd_rsp_buf_pool\",\n\t\t\t\t\t&phba->pcidev->dev,\n\t\t\t\t\tsizeof(struct fcp_cmnd) +\n\t\t\t\t\tsizeof(struct fcp_rsp),\n\t\t\t\t\tBPL_ALIGN_SZ, 0);\n\n\tif (!phba->lpfc_cmd_rsp_buf_pool)\n\t\tgoto fail_free_dma_buf_pool;\n\n\t/*\n\t * Enable sr-iov virtual functions if supported and configured\n\t * through the module parameter.\n\t */\n\tif (phba->cfg_sriov_nr_virtfn > 0) {\n\t\trc = lpfc_sli_probe_sriov_nr_virtfn(phba,\n\t\t\t\t\t\t phba->cfg_sriov_nr_virtfn);\n\t\tif (rc) {\n\t\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\t\"2808 Requested number of SR-IOV \"\n\t\t\t\t\t\"virtual functions (%d) is not \"\n\t\t\t\t\t\"supported\\n\",\n\t\t\t\t\tphba->cfg_sriov_nr_virtfn);\n\t\t\tphba->cfg_sriov_nr_virtfn = 0;\n\t\t}\n\t}\n\n\treturn 0;\n\nfail_free_dma_buf_pool:\n\tdma_pool_destroy(phba->lpfc_sg_dma_buf_pool);\n\tphba->lpfc_sg_dma_buf_pool = NULL;\nfail_free_mem:\n\tlpfc_mem_free(phba);\n\treturn -ENOMEM;\n}\n\n/**\n * lpfc_sli_driver_resource_unset - Unset drvr internal resources for SLI3 dev\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to unset the driver internal resources set up\n * specific for supporting the SLI-3 HBA device it attached to.\n **/\nstatic void\nlpfc_sli_driver_resource_unset(struct lpfc_hba *phba)\n{\n\t/* Free device driver memory allocated */\n\tlpfc_mem_free_all(phba);\n\n\treturn;\n}\n\n/**\n * lpfc_sli4_driver_resource_setup - Setup drvr internal resources for SLI4 dev\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to set up the driver internal resources specific to\n * support the SLI-4 HBA device it attached to.\n *\n * Return codes\n * \t0 - successful\n * \tother values - error\n **/\nstatic int\nlpfc_sli4_driver_resource_setup(struct lpfc_hba *phba)\n{\n\tLPFC_MBOXQ_t *mboxq;\n\tMAILBOX_t *mb;\n\tint rc, i, max_buf_size;\n\tuint8_t pn_page[LPFC_MAX_SUPPORTED_PAGES] = {0};\n\tstruct lpfc_mqe *mqe;\n\tint longs;\n\tint extra;\n\tuint64_t wwn;\n\tu32 if_type;\n\tu32 if_fam;\n\n\tphba->sli4_hba.num_present_cpu = lpfc_present_cpu;\n\tphba->sli4_hba.num_possible_cpu = cpumask_last(cpu_possible_mask) + 1;\n\tphba->sli4_hba.curr_disp_cpu = 0;\n\n\t/* Get all the module params for configuring this host */\n\tlpfc_get_cfgparam(phba);\n\n\t/* Set up phase-1 common device driver resources */\n\trc = lpfc_setup_driver_resource_phase1(phba);\n\tif (rc)\n\t\treturn -ENODEV;\n\n\t/* Before proceed, wait for POST done and device ready */\n\trc = lpfc_sli4_post_status_check(phba);\n\tif (rc)\n\t\treturn -ENODEV;\n\n\t/* Allocate all driver workqueues here */\n\n\t/* The lpfc_wq workqueue for deferred irq use */\n\tphba->wq = alloc_workqueue(\"lpfc_wq\", WQ_MEM_RECLAIM, 0);\n\n\t/*\n\t * Initialize timers used by driver\n\t */\n\n\ttimer_setup(&phba->rrq_tmr, lpfc_rrq_timeout, 0);\n\n\t/* FCF rediscover timer */\n\ttimer_setup(&phba->fcf.redisc_wait, lpfc_sli4_fcf_redisc_wait_tmo, 0);\n\n\t/*\n\t * Control structure for handling external multi-buffer mailbox\n\t * command pass-through.\n\t */\n\tmemset((uint8_t *)&phba->mbox_ext_buf_ctx, 0,\n\t\tsizeof(struct lpfc_mbox_ext_buf_ctx));\n\tINIT_LIST_HEAD(&phba->mbox_ext_buf_ctx.ext_dmabuf_list);\n\n\tphba->max_vpi = LPFC_MAX_VPI;\n\n\t/* This will be set to correct value after the read_config mbox */\n\tphba->max_vports = 0;\n\n\t/* Program the default value of vlan_id and fc_map */\n\tphba->valid_vlan = 0;\n\tphba->fc_map[0] = LPFC_FCOE_FCF_MAP0;\n\tphba->fc_map[1] = LPFC_FCOE_FCF_MAP1;\n\tphba->fc_map[2] = LPFC_FCOE_FCF_MAP2;\n\n\t/*\n\t * For SLI4, instead of using ring 0 (LPFC_FCP_RING) for FCP commands\n\t * we will associate a new ring, for each EQ/CQ/WQ tuple.\n\t * The WQ create will allocate the ring.\n\t */\n\n\t/* Initialize buffer queue management fields */\n\tINIT_LIST_HEAD(&phba->hbqs[LPFC_ELS_HBQ].hbq_buffer_list);\n\tphba->hbqs[LPFC_ELS_HBQ].hbq_alloc_buffer = lpfc_sli4_rb_alloc;\n\tphba->hbqs[LPFC_ELS_HBQ].hbq_free_buffer = lpfc_sli4_rb_free;\n\n\t/*\n\t * Initialize the SLI Layer to run with lpfc SLI4 HBAs.\n\t */\n\t/* Initialize the Abort buffer list used by driver */\n\tspin_lock_init(&phba->sli4_hba.abts_io_buf_list_lock);\n\tINIT_LIST_HEAD(&phba->sli4_hba.lpfc_abts_io_buf_list);\n\n\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME) {\n\t\t/* Initialize the Abort nvme buffer list used by driver */\n\t\tspin_lock_init(&phba->sli4_hba.abts_nvmet_buf_list_lock);\n\t\tINIT_LIST_HEAD(&phba->sli4_hba.lpfc_abts_nvmet_ctx_list);\n\t\tINIT_LIST_HEAD(&phba->sli4_hba.lpfc_nvmet_io_wait_list);\n\t\tspin_lock_init(&phba->sli4_hba.t_active_list_lock);\n\t\tINIT_LIST_HEAD(&phba->sli4_hba.t_active_ctx_list);\n\t}\n\n\t/* This abort list used by worker thread */\n\tspin_lock_init(&phba->sli4_hba.sgl_list_lock);\n\tspin_lock_init(&phba->sli4_hba.nvmet_io_wait_lock);\n\tspin_lock_init(&phba->sli4_hba.asynce_list_lock);\n\tspin_lock_init(&phba->sli4_hba.els_xri_abrt_list_lock);\n\n\t/*\n\t * Initialize driver internal slow-path work queues\n\t */\n\n\t/* Driver internel slow-path CQ Event pool */\n\tINIT_LIST_HEAD(&phba->sli4_hba.sp_cqe_event_pool);\n\t/* Response IOCB work queue list */\n\tINIT_LIST_HEAD(&phba->sli4_hba.sp_queue_event);\n\t/* Asynchronous event CQ Event work queue list */\n\tINIT_LIST_HEAD(&phba->sli4_hba.sp_asynce_work_queue);\n\t/* Slow-path XRI aborted CQ Event work queue list */\n\tINIT_LIST_HEAD(&phba->sli4_hba.sp_els_xri_aborted_work_queue);\n\t/* Receive queue CQ Event work queue list */\n\tINIT_LIST_HEAD(&phba->sli4_hba.sp_unsol_work_queue);\n\n\t/* Initialize extent block lists. */\n\tINIT_LIST_HEAD(&phba->sli4_hba.lpfc_rpi_blk_list);\n\tINIT_LIST_HEAD(&phba->sli4_hba.lpfc_xri_blk_list);\n\tINIT_LIST_HEAD(&phba->sli4_hba.lpfc_vfi_blk_list);\n\tINIT_LIST_HEAD(&phba->lpfc_vpi_blk_list);\n\n\t/* Initialize mboxq lists. If the early init routines fail\n\t * these lists need to be correctly initialized.\n\t */\n\tINIT_LIST_HEAD(&phba->sli.mboxq);\n\tINIT_LIST_HEAD(&phba->sli.mboxq_cmpl);\n\n\t/* initialize optic_state to 0xFF */\n\tphba->sli4_hba.lnk_info.optic_state = 0xff;\n\n\t/* Allocate device driver memory */\n\trc = lpfc_mem_alloc(phba, SGL_ALIGN_SZ);\n\tif (rc)\n\t\treturn -ENOMEM;\n\n\t/* IF Type 2 ports get initialized now. */\n\tif (bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf) >=\n\t    LPFC_SLI_INTF_IF_TYPE_2) {\n\t\trc = lpfc_pci_function_reset(phba);\n\t\tif (unlikely(rc)) {\n\t\t\trc = -ENODEV;\n\t\t\tgoto out_free_mem;\n\t\t}\n\t\tphba->temp_sensor_support = 1;\n\t}\n\n\t/* Create the bootstrap mailbox command */\n\trc = lpfc_create_bootstrap_mbox(phba);\n\tif (unlikely(rc))\n\t\tgoto out_free_mem;\n\n\t/* Set up the host's endian order with the device. */\n\trc = lpfc_setup_endian_order(phba);\n\tif (unlikely(rc))\n\t\tgoto out_free_bsmbx;\n\n\t/* Set up the hba's configuration parameters. */\n\trc = lpfc_sli4_read_config(phba);\n\tif (unlikely(rc))\n\t\tgoto out_free_bsmbx;\n\trc = lpfc_mem_alloc_active_rrq_pool_s4(phba);\n\tif (unlikely(rc))\n\t\tgoto out_free_bsmbx;\n\n\t/* IF Type 0 ports get initialized now. */\n\tif (bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf) ==\n\t    LPFC_SLI_INTF_IF_TYPE_0) {\n\t\trc = lpfc_pci_function_reset(phba);\n\t\tif (unlikely(rc))\n\t\t\tgoto out_free_bsmbx;\n\t}\n\n\tmboxq = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool,\n\t\t\t\t\t\t       GFP_KERNEL);\n\tif (!mboxq) {\n\t\trc = -ENOMEM;\n\t\tgoto out_free_bsmbx;\n\t}\n\n\t/* Check for NVMET being configured */\n\tphba->nvmet_support = 0;\n\tif (lpfc_enable_nvmet_cnt) {\n\n\t\t/* First get WWN of HBA instance */\n\t\tlpfc_read_nv(phba, mboxq);\n\t\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\t\tif (rc != MBX_SUCCESS) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\"6016 Mailbox failed , mbxCmd x%x \"\n\t\t\t\t\t\"READ_NV, mbxStatus x%x\\n\",\n\t\t\t\t\tbf_get(lpfc_mqe_command, &mboxq->u.mqe),\n\t\t\t\t\tbf_get(lpfc_mqe_status, &mboxq->u.mqe));\n\t\t\tmempool_free(mboxq, phba->mbox_mem_pool);\n\t\t\trc = -EIO;\n\t\t\tgoto out_free_bsmbx;\n\t\t}\n\t\tmb = &mboxq->u.mb;\n\t\tmemcpy(&wwn, (char *)mb->un.varRDnvp.nodename,\n\t\t       sizeof(uint64_t));\n\t\twwn = cpu_to_be64(wwn);\n\t\tphba->sli4_hba.wwnn.u.name = wwn;\n\t\tmemcpy(&wwn, (char *)mb->un.varRDnvp.portname,\n\t\t       sizeof(uint64_t));\n\t\t/* wwn is WWPN of HBA instance */\n\t\twwn = cpu_to_be64(wwn);\n\t\tphba->sli4_hba.wwpn.u.name = wwn;\n\n\t\t/* Check to see if it matches any module parameter */\n\t\tfor (i = 0; i < lpfc_enable_nvmet_cnt; i++) {\n\t\t\tif (wwn == lpfc_enable_nvmet[i]) {\n#if (IS_ENABLED(CONFIG_NVME_TARGET_FC))\n\t\t\t\tif (lpfc_nvmet_mem_alloc(phba))\n\t\t\t\t\tbreak;\n\n\t\t\t\tphba->nvmet_support = 1; /* a match */\n\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\t\"6017 NVME Target %016llx\\n\",\n\t\t\t\t\t\twwn);\n#else\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\t\"6021 Can't enable NVME Target.\"\n\t\t\t\t\t\t\" NVME_TARGET_FC infrastructure\"\n\t\t\t\t\t\t\" is not in kernel\\n\");\n#endif\n\t\t\t\t/* Not supported for NVMET */\n\t\t\t\tphba->cfg_xri_rebalancing = 0;\n\t\t\t\tif (phba->irq_chann_mode == NHT_MODE) {\n\t\t\t\t\tphba->cfg_irq_chann =\n\t\t\t\t\t\tphba->sli4_hba.num_present_cpu;\n\t\t\t\t\tphba->cfg_hdw_queue =\n\t\t\t\t\t\tphba->sli4_hba.num_present_cpu;\n\t\t\t\t\tphba->irq_chann_mode = NORMAL_MODE;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tlpfc_nvme_mod_param_dep(phba);\n\n\t/* Get the Supported Pages if PORT_CAPABILITIES is supported by port. */\n\tlpfc_supported_pages(mboxq);\n\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\tif (!rc) {\n\t\tmqe = &mboxq->u.mqe;\n\t\tmemcpy(&pn_page[0], ((uint8_t *)&mqe->un.supp_pages.word3),\n\t\t       LPFC_MAX_SUPPORTED_PAGES);\n\t\tfor (i = 0; i < LPFC_MAX_SUPPORTED_PAGES; i++) {\n\t\t\tswitch (pn_page[i]) {\n\t\t\tcase LPFC_SLI4_PARAMETERS:\n\t\t\t\tphba->sli4_hba.pc_sli4_params.supported = 1;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\t/* Read the port's SLI4 Parameters capabilities if supported. */\n\t\tif (phba->sli4_hba.pc_sli4_params.supported)\n\t\t\trc = lpfc_pc_sli4_params_get(phba, mboxq);\n\t\tif (rc) {\n\t\t\tmempool_free(mboxq, phba->mbox_mem_pool);\n\t\t\trc = -EIO;\n\t\t\tgoto out_free_bsmbx;\n\t\t}\n\t}\n\n\t/*\n\t * Get sli4 parameters that override parameters from Port capabilities.\n\t * If this call fails, it isn't critical unless the SLI4 parameters come\n\t * back in conflict.\n\t */\n\trc = lpfc_get_sli4_parameters(phba, mboxq);\n\tif (rc) {\n\t\tif_type = bf_get(lpfc_sli_intf_if_type,\n\t\t\t\t &phba->sli4_hba.sli_intf);\n\t\tif_fam = bf_get(lpfc_sli_intf_sli_family,\n\t\t\t\t&phba->sli4_hba.sli_intf);\n\t\tif (phba->sli4_hba.extents_in_use &&\n\t\t    phba->sli4_hba.rpi_hdrs_in_use) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"2999 Unsupported SLI4 Parameters \"\n\t\t\t\t\t\"Extents and RPI headers enabled.\\n\");\n\t\t\tif (if_type == LPFC_SLI_INTF_IF_TYPE_0 &&\n\t\t\t    if_fam ==  LPFC_SLI_INTF_FAMILY_BE2) {\n\t\t\t\tmempool_free(mboxq, phba->mbox_mem_pool);\n\t\t\t\trc = -EIO;\n\t\t\t\tgoto out_free_bsmbx;\n\t\t\t}\n\t\t}\n\t\tif (!(if_type == LPFC_SLI_INTF_IF_TYPE_0 &&\n\t\t      if_fam == LPFC_SLI_INTF_FAMILY_BE2)) {\n\t\t\tmempool_free(mboxq, phba->mbox_mem_pool);\n\t\t\trc = -EIO;\n\t\t\tgoto out_free_bsmbx;\n\t\t}\n\t}\n\n\t/*\n\t * 1 for cmd, 1 for rsp, NVME adds an extra one\n\t * for boundary conditions in its max_sgl_segment template.\n\t */\n\textra = 2;\n\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME)\n\t\textra++;\n\n\t/*\n\t * It doesn't matter what family our adapter is in, we are\n\t * limited to 2 Pages, 512 SGEs, for our SGL.\n\t * There are going to be 2 reserved SGEs: 1 FCP cmnd + 1 FCP rsp\n\t */\n\tmax_buf_size = (2 * SLI4_PAGE_SIZE);\n\n\t/*\n\t * Since lpfc_sg_seg_cnt is module param, the sg_dma_buf_size\n\t * used to create the sg_dma_buf_pool must be calculated.\n\t */\n\tif (phba->sli3_options & LPFC_SLI3_BG_ENABLED) {\n\t\t/* Both cfg_enable_bg and cfg_external_dif code paths */\n\n\t\t/*\n\t\t * The scsi_buf for a T10-DIF I/O holds the FCP cmnd,\n\t\t * the FCP rsp, and a SGE. Sice we have no control\n\t\t * over how many protection segments the SCSI Layer\n\t\t * will hand us (ie: there could be one for every block\n\t\t * in the IO), just allocate enough SGEs to accomidate\n\t\t * our max amount and we need to limit lpfc_sg_seg_cnt\n\t\t * to minimize the risk of running out.\n\t\t */\n\t\tphba->cfg_sg_dma_buf_size = sizeof(struct fcp_cmnd) +\n\t\t\t\tsizeof(struct fcp_rsp) + max_buf_size;\n\n\t\t/* Total SGEs for scsi_sg_list and scsi_sg_prot_list */\n\t\tphba->cfg_total_seg_cnt = LPFC_MAX_SGL_SEG_CNT;\n\n\t\t/*\n\t\t * If supporting DIF, reduce the seg count for scsi to\n\t\t * allow room for the DIF sges.\n\t\t */\n\t\tif (phba->cfg_enable_bg &&\n\t\t    phba->cfg_sg_seg_cnt > LPFC_MAX_BG_SLI4_SEG_CNT_DIF)\n\t\t\tphba->cfg_scsi_seg_cnt = LPFC_MAX_BG_SLI4_SEG_CNT_DIF;\n\t\telse\n\t\t\tphba->cfg_scsi_seg_cnt = phba->cfg_sg_seg_cnt;\n\n\t} else {\n\t\t/*\n\t\t * The scsi_buf for a regular I/O holds the FCP cmnd,\n\t\t * the FCP rsp, a SGE for each, and a SGE for up to\n\t\t * cfg_sg_seg_cnt data segments.\n\t\t */\n\t\tphba->cfg_sg_dma_buf_size = sizeof(struct fcp_cmnd) +\n\t\t\t\tsizeof(struct fcp_rsp) +\n\t\t\t\t((phba->cfg_sg_seg_cnt + extra) *\n\t\t\t\tsizeof(struct sli4_sge));\n\n\t\t/* Total SGEs for scsi_sg_list */\n\t\tphba->cfg_total_seg_cnt = phba->cfg_sg_seg_cnt + extra;\n\t\tphba->cfg_scsi_seg_cnt = phba->cfg_sg_seg_cnt;\n\n\t\t/*\n\t\t * NOTE: if (phba->cfg_sg_seg_cnt + extra) <= 256 we only\n\t\t * need to post 1 page for the SGL.\n\t\t */\n\t}\n\n\tif (phba->cfg_xpsgl && !phba->nvmet_support)\n\t\tphba->cfg_sg_dma_buf_size = LPFC_DEFAULT_XPSGL_SIZE;\n\telse if (phba->cfg_sg_dma_buf_size  <= LPFC_MIN_SG_SLI4_BUF_SZ)\n\t\tphba->cfg_sg_dma_buf_size = LPFC_MIN_SG_SLI4_BUF_SZ;\n\telse\n\t\tphba->cfg_sg_dma_buf_size =\n\t\t\t\tSLI4_PAGE_ALIGN(phba->cfg_sg_dma_buf_size);\n\n\tphba->border_sge_num = phba->cfg_sg_dma_buf_size /\n\t\t\t       sizeof(struct sli4_sge);\n\n\t/* Limit to LPFC_MAX_NVME_SEG_CNT for NVME. */\n\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME) {\n\t\tif (phba->cfg_sg_seg_cnt > LPFC_MAX_NVME_SEG_CNT) {\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_NVME | LOG_INIT,\n\t\t\t\t\t\"6300 Reducing NVME sg segment \"\n\t\t\t\t\t\"cnt to %d\\n\",\n\t\t\t\t\tLPFC_MAX_NVME_SEG_CNT);\n\t\t\tphba->cfg_nvme_seg_cnt = LPFC_MAX_NVME_SEG_CNT;\n\t\t} else\n\t\t\tphba->cfg_nvme_seg_cnt = phba->cfg_sg_seg_cnt;\n\t}\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT | LOG_FCP,\n\t\t\t\"9087 sg_seg_cnt:%d dmabuf_size:%d \"\n\t\t\t\"total:%d scsi:%d nvme:%d\\n\",\n\t\t\tphba->cfg_sg_seg_cnt, phba->cfg_sg_dma_buf_size,\n\t\t\tphba->cfg_total_seg_cnt,  phba->cfg_scsi_seg_cnt,\n\t\t\tphba->cfg_nvme_seg_cnt);\n\n\tif (phba->cfg_sg_dma_buf_size < SLI4_PAGE_SIZE)\n\t\ti = phba->cfg_sg_dma_buf_size;\n\telse\n\t\ti = SLI4_PAGE_SIZE;\n\n\tphba->lpfc_sg_dma_buf_pool =\n\t\t\tdma_pool_create(\"lpfc_sg_dma_buf_pool\",\n\t\t\t\t\t&phba->pcidev->dev,\n\t\t\t\t\tphba->cfg_sg_dma_buf_size,\n\t\t\t\t\ti, 0);\n\tif (!phba->lpfc_sg_dma_buf_pool)\n\t\tgoto out_free_bsmbx;\n\n\tphba->lpfc_cmd_rsp_buf_pool =\n\t\t\tdma_pool_create(\"lpfc_cmd_rsp_buf_pool\",\n\t\t\t\t\t&phba->pcidev->dev,\n\t\t\t\t\tsizeof(struct fcp_cmnd) +\n\t\t\t\t\tsizeof(struct fcp_rsp),\n\t\t\t\t\ti, 0);\n\tif (!phba->lpfc_cmd_rsp_buf_pool)\n\t\tgoto out_free_sg_dma_buf;\n\n\tmempool_free(mboxq, phba->mbox_mem_pool);\n\n\t/* Verify OAS is supported */\n\tlpfc_sli4_oas_verify(phba);\n\n\t/* Verify RAS support on adapter */\n\tlpfc_sli4_ras_init(phba);\n\n\t/* Verify all the SLI4 queues */\n\trc = lpfc_sli4_queue_verify(phba);\n\tif (rc)\n\t\tgoto out_free_cmd_rsp_buf;\n\n\t/* Create driver internal CQE event pool */\n\trc = lpfc_sli4_cq_event_pool_create(phba);\n\tif (rc)\n\t\tgoto out_free_cmd_rsp_buf;\n\n\t/* Initialize sgl lists per host */\n\tlpfc_init_sgl_list(phba);\n\n\t/* Allocate and initialize active sgl array */\n\trc = lpfc_init_active_sgl_array(phba);\n\tif (rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"1430 Failed to initialize sgl list.\\n\");\n\t\tgoto out_destroy_cq_event_pool;\n\t}\n\trc = lpfc_sli4_init_rpi_hdrs(phba);\n\tif (rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"1432 Failed to initialize rpi headers.\\n\");\n\t\tgoto out_free_active_sgl;\n\t}\n\n\t/* Allocate eligible FCF bmask memory for FCF roundrobin failover */\n\tlongs = (LPFC_SLI4_FCF_TBL_INDX_MAX + BITS_PER_LONG - 1)/BITS_PER_LONG;\n\tphba->fcf.fcf_rr_bmask = kcalloc(longs, sizeof(unsigned long),\n\t\t\t\t\t GFP_KERNEL);\n\tif (!phba->fcf.fcf_rr_bmask) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2759 Failed allocate memory for FCF round \"\n\t\t\t\t\"robin failover bmask\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto out_remove_rpi_hdrs;\n\t}\n\n\tphba->sli4_hba.hba_eq_hdl = kcalloc(phba->cfg_irq_chann,\n\t\t\t\t\t    sizeof(struct lpfc_hba_eq_hdl),\n\t\t\t\t\t    GFP_KERNEL);\n\tif (!phba->sli4_hba.hba_eq_hdl) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2572 Failed allocate memory for \"\n\t\t\t\t\"fast-path per-EQ handle array\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto out_free_fcf_rr_bmask;\n\t}\n\n\tphba->sli4_hba.cpu_map = kcalloc(phba->sli4_hba.num_possible_cpu,\n\t\t\t\t\tsizeof(struct lpfc_vector_map_info),\n\t\t\t\t\tGFP_KERNEL);\n\tif (!phba->sli4_hba.cpu_map) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3327 Failed allocate memory for msi-x \"\n\t\t\t\t\"interrupt vector mapping\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto out_free_hba_eq_hdl;\n\t}\n\n\tphba->sli4_hba.eq_info = alloc_percpu(struct lpfc_eq_intr_info);\n\tif (!phba->sli4_hba.eq_info) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3321 Failed allocation for per_cpu stats\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto out_free_hba_cpu_map;\n\t}\n\n\tphba->sli4_hba.idle_stat = kcalloc(phba->sli4_hba.num_possible_cpu,\n\t\t\t\t\t   sizeof(*phba->sli4_hba.idle_stat),\n\t\t\t\t\t   GFP_KERNEL);\n\tif (!phba->sli4_hba.idle_stat) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3390 Failed allocation for idle_stat\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto out_free_hba_eq_info;\n\t}\n\n#ifdef CONFIG_SCSI_LPFC_DEBUG_FS\n\tphba->sli4_hba.c_stat = alloc_percpu(struct lpfc_hdwq_stat);\n\tif (!phba->sli4_hba.c_stat) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3332 Failed allocating per cpu hdwq stats\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto out_free_hba_idle_stat;\n\t}\n#endif\n\n\t/*\n\t * Enable sr-iov virtual functions if supported and configured\n\t * through the module parameter.\n\t */\n\tif (phba->cfg_sriov_nr_virtfn > 0) {\n\t\trc = lpfc_sli_probe_sriov_nr_virtfn(phba,\n\t\t\t\t\t\t phba->cfg_sriov_nr_virtfn);\n\t\tif (rc) {\n\t\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\t\"3020 Requested number of SR-IOV \"\n\t\t\t\t\t\"virtual functions (%d) is not \"\n\t\t\t\t\t\"supported\\n\",\n\t\t\t\t\tphba->cfg_sriov_nr_virtfn);\n\t\t\tphba->cfg_sriov_nr_virtfn = 0;\n\t\t}\n\t}\n\n\treturn 0;\n\n#ifdef CONFIG_SCSI_LPFC_DEBUG_FS\nout_free_hba_idle_stat:\n\tkfree(phba->sli4_hba.idle_stat);\n#endif\nout_free_hba_eq_info:\n\tfree_percpu(phba->sli4_hba.eq_info);\nout_free_hba_cpu_map:\n\tkfree(phba->sli4_hba.cpu_map);\nout_free_hba_eq_hdl:\n\tkfree(phba->sli4_hba.hba_eq_hdl);\nout_free_fcf_rr_bmask:\n\tkfree(phba->fcf.fcf_rr_bmask);\nout_remove_rpi_hdrs:\n\tlpfc_sli4_remove_rpi_hdrs(phba);\nout_free_active_sgl:\n\tlpfc_free_active_sgl(phba);\nout_destroy_cq_event_pool:\n\tlpfc_sli4_cq_event_pool_destroy(phba);\nout_free_cmd_rsp_buf:\n\tdma_pool_destroy(phba->lpfc_cmd_rsp_buf_pool);\n\tphba->lpfc_cmd_rsp_buf_pool = NULL;\nout_free_sg_dma_buf:\n\tdma_pool_destroy(phba->lpfc_sg_dma_buf_pool);\n\tphba->lpfc_sg_dma_buf_pool = NULL;\nout_free_bsmbx:\n\tlpfc_destroy_bootstrap_mbox(phba);\nout_free_mem:\n\tlpfc_mem_free(phba);\n\treturn rc;\n}\n\n/**\n * lpfc_sli4_driver_resource_unset - Unset drvr internal resources for SLI4 dev\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to unset the driver internal resources set up\n * specific for supporting the SLI-4 HBA device it attached to.\n **/\nstatic void\nlpfc_sli4_driver_resource_unset(struct lpfc_hba *phba)\n{\n\tstruct lpfc_fcf_conn_entry *conn_entry, *next_conn_entry;\n\n\tfree_percpu(phba->sli4_hba.eq_info);\n#ifdef CONFIG_SCSI_LPFC_DEBUG_FS\n\tfree_percpu(phba->sli4_hba.c_stat);\n#endif\n\tkfree(phba->sli4_hba.idle_stat);\n\n\t/* Free memory allocated for msi-x interrupt vector to CPU mapping */\n\tkfree(phba->sli4_hba.cpu_map);\n\tphba->sli4_hba.num_possible_cpu = 0;\n\tphba->sli4_hba.num_present_cpu = 0;\n\tphba->sli4_hba.curr_disp_cpu = 0;\n\tcpumask_clear(&phba->sli4_hba.irq_aff_mask);\n\n\t/* Free memory allocated for fast-path work queue handles */\n\tkfree(phba->sli4_hba.hba_eq_hdl);\n\n\t/* Free the allocated rpi headers. */\n\tlpfc_sli4_remove_rpi_hdrs(phba);\n\tlpfc_sli4_remove_rpis(phba);\n\n\t/* Free eligible FCF index bmask */\n\tkfree(phba->fcf.fcf_rr_bmask);\n\n\t/* Free the ELS sgl list */\n\tlpfc_free_active_sgl(phba);\n\tlpfc_free_els_sgl_list(phba);\n\tlpfc_free_nvmet_sgl_list(phba);\n\n\t/* Free the completion queue EQ event pool */\n\tlpfc_sli4_cq_event_release_all(phba);\n\tlpfc_sli4_cq_event_pool_destroy(phba);\n\n\t/* Release resource identifiers. */\n\tlpfc_sli4_dealloc_resource_identifiers(phba);\n\n\t/* Free the bsmbx region. */\n\tlpfc_destroy_bootstrap_mbox(phba);\n\n\t/* Free the SLI Layer memory with SLI4 HBAs */\n\tlpfc_mem_free_all(phba);\n\n\t/* Free the current connect table */\n\tlist_for_each_entry_safe(conn_entry, next_conn_entry,\n\t\t&phba->fcf_conn_rec_list, list) {\n\t\tlist_del_init(&conn_entry->list);\n\t\tkfree(conn_entry);\n\t}\n\n\treturn;\n}\n\n/**\n * lpfc_init_api_table_setup - Set up init api function jump table\n * @phba: The hba struct for which this call is being executed.\n * @dev_grp: The HBA PCI-Device group number.\n *\n * This routine sets up the device INIT interface API function jump table\n * in @phba struct.\n *\n * Returns: 0 - success, -ENODEV - failure.\n **/\nint\nlpfc_init_api_table_setup(struct lpfc_hba *phba, uint8_t dev_grp)\n{\n\tphba->lpfc_hba_init_link = lpfc_hba_init_link;\n\tphba->lpfc_hba_down_link = lpfc_hba_down_link;\n\tphba->lpfc_selective_reset = lpfc_selective_reset;\n\tswitch (dev_grp) {\n\tcase LPFC_PCI_DEV_LP:\n\t\tphba->lpfc_hba_down_post = lpfc_hba_down_post_s3;\n\t\tphba->lpfc_handle_eratt = lpfc_handle_eratt_s3;\n\t\tphba->lpfc_stop_port = lpfc_stop_port_s3;\n\t\tbreak;\n\tcase LPFC_PCI_DEV_OC:\n\t\tphba->lpfc_hba_down_post = lpfc_hba_down_post_s4;\n\t\tphba->lpfc_handle_eratt = lpfc_handle_eratt_s4;\n\t\tphba->lpfc_stop_port = lpfc_stop_port_s4;\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"1431 Invalid HBA PCI-device group: 0x%x\\n\",\n\t\t\t\tdev_grp);\n\t\treturn -ENODEV;\n\t}\n\treturn 0;\n}\n\n/**\n * lpfc_setup_driver_resource_phase2 - Phase2 setup driver internal resources.\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to set up the driver internal resources after the\n * device specific resource setup to support the HBA device it attached to.\n *\n * Return codes\n * \t0 - successful\n * \tother values - error\n **/\nstatic int\nlpfc_setup_driver_resource_phase2(struct lpfc_hba *phba)\n{\n\tint error;\n\n\t/* Startup the kernel thread for this host adapter. */\n\tphba->worker_thread = kthread_run(lpfc_do_work, phba,\n\t\t\t\t\t  \"lpfc_worker_%d\", phba->brd_no);\n\tif (IS_ERR(phba->worker_thread)) {\n\t\terror = PTR_ERR(phba->worker_thread);\n\t\treturn error;\n\t}\n\n\treturn 0;\n}\n\n/**\n * lpfc_unset_driver_resource_phase2 - Phase2 unset driver internal resources.\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to unset the driver internal resources set up after\n * the device specific resource setup for supporting the HBA device it\n * attached to.\n **/\nstatic void\nlpfc_unset_driver_resource_phase2(struct lpfc_hba *phba)\n{\n\tif (phba->wq) {\n\t\tflush_workqueue(phba->wq);\n\t\tdestroy_workqueue(phba->wq);\n\t\tphba->wq = NULL;\n\t}\n\n\t/* Stop kernel worker thread */\n\tif (phba->worker_thread)\n\t\tkthread_stop(phba->worker_thread);\n}\n\n/**\n * lpfc_free_iocb_list - Free iocb list.\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to free the driver's IOCB list and memory.\n **/\nvoid\nlpfc_free_iocb_list(struct lpfc_hba *phba)\n{\n\tstruct lpfc_iocbq *iocbq_entry = NULL, *iocbq_next = NULL;\n\n\tspin_lock_irq(&phba->hbalock);\n\tlist_for_each_entry_safe(iocbq_entry, iocbq_next,\n\t\t\t\t &phba->lpfc_iocb_list, list) {\n\t\tlist_del(&iocbq_entry->list);\n\t\tkfree(iocbq_entry);\n\t\tphba->total_iocbq_bufs--;\n\t}\n\tspin_unlock_irq(&phba->hbalock);\n\n\treturn;\n}\n\n/**\n * lpfc_init_iocb_list - Allocate and initialize iocb list.\n * @phba: pointer to lpfc hba data structure.\n * @iocb_count: number of requested iocbs\n *\n * This routine is invoked to allocate and initizlize the driver's IOCB\n * list and set up the IOCB tag array accordingly.\n *\n * Return codes\n *\t0 - successful\n *\tother values - error\n **/\nint\nlpfc_init_iocb_list(struct lpfc_hba *phba, int iocb_count)\n{\n\tstruct lpfc_iocbq *iocbq_entry = NULL;\n\tuint16_t iotag;\n\tint i;\n\n\t/* Initialize and populate the iocb list per host.  */\n\tINIT_LIST_HEAD(&phba->lpfc_iocb_list);\n\tfor (i = 0; i < iocb_count; i++) {\n\t\tiocbq_entry = kzalloc(sizeof(struct lpfc_iocbq), GFP_KERNEL);\n\t\tif (iocbq_entry == NULL) {\n\t\t\tprintk(KERN_ERR \"%s: only allocated %d iocbs of \"\n\t\t\t\t\"expected %d count. Unloading driver.\\n\",\n\t\t\t\t__func__, i, iocb_count);\n\t\t\tgoto out_free_iocbq;\n\t\t}\n\n\t\tiotag = lpfc_sli_next_iotag(phba, iocbq_entry);\n\t\tif (iotag == 0) {\n\t\t\tkfree(iocbq_entry);\n\t\t\tprintk(KERN_ERR \"%s: failed to allocate IOTAG. \"\n\t\t\t\t\"Unloading driver.\\n\", __func__);\n\t\t\tgoto out_free_iocbq;\n\t\t}\n\t\tiocbq_entry->sli4_lxritag = NO_XRI;\n\t\tiocbq_entry->sli4_xritag = NO_XRI;\n\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tlist_add(&iocbq_entry->list, &phba->lpfc_iocb_list);\n\t\tphba->total_iocbq_bufs++;\n\t\tspin_unlock_irq(&phba->hbalock);\n\t}\n\n\treturn 0;\n\nout_free_iocbq:\n\tlpfc_free_iocb_list(phba);\n\n\treturn -ENOMEM;\n}\n\n/**\n * lpfc_free_sgl_list - Free a given sgl list.\n * @phba: pointer to lpfc hba data structure.\n * @sglq_list: pointer to the head of sgl list.\n *\n * This routine is invoked to free a give sgl list and memory.\n **/\nvoid\nlpfc_free_sgl_list(struct lpfc_hba *phba, struct list_head *sglq_list)\n{\n\tstruct lpfc_sglq *sglq_entry = NULL, *sglq_next = NULL;\n\n\tlist_for_each_entry_safe(sglq_entry, sglq_next, sglq_list, list) {\n\t\tlist_del(&sglq_entry->list);\n\t\tlpfc_mbuf_free(phba, sglq_entry->virt, sglq_entry->phys);\n\t\tkfree(sglq_entry);\n\t}\n}\n\n/**\n * lpfc_free_els_sgl_list - Free els sgl list.\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to free the driver's els sgl list and memory.\n **/\nstatic void\nlpfc_free_els_sgl_list(struct lpfc_hba *phba)\n{\n\tLIST_HEAD(sglq_list);\n\n\t/* Retrieve all els sgls from driver list */\n\tspin_lock_irq(&phba->hbalock);\n\tspin_lock(&phba->sli4_hba.sgl_list_lock);\n\tlist_splice_init(&phba->sli4_hba.lpfc_els_sgl_list, &sglq_list);\n\tspin_unlock(&phba->sli4_hba.sgl_list_lock);\n\tspin_unlock_irq(&phba->hbalock);\n\n\t/* Now free the sgl list */\n\tlpfc_free_sgl_list(phba, &sglq_list);\n}\n\n/**\n * lpfc_free_nvmet_sgl_list - Free nvmet sgl list.\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to free the driver's nvmet sgl list and memory.\n **/\nstatic void\nlpfc_free_nvmet_sgl_list(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sglq *sglq_entry = NULL, *sglq_next = NULL;\n\tLIST_HEAD(sglq_list);\n\n\t/* Retrieve all nvmet sgls from driver list */\n\tspin_lock_irq(&phba->hbalock);\n\tspin_lock(&phba->sli4_hba.sgl_list_lock);\n\tlist_splice_init(&phba->sli4_hba.lpfc_nvmet_sgl_list, &sglq_list);\n\tspin_unlock(&phba->sli4_hba.sgl_list_lock);\n\tspin_unlock_irq(&phba->hbalock);\n\n\t/* Now free the sgl list */\n\tlist_for_each_entry_safe(sglq_entry, sglq_next, &sglq_list, list) {\n\t\tlist_del(&sglq_entry->list);\n\t\tlpfc_nvmet_buf_free(phba, sglq_entry->virt, sglq_entry->phys);\n\t\tkfree(sglq_entry);\n\t}\n\n\t/* Update the nvmet_xri_cnt to reflect no current sgls.\n\t * The next initialization cycle sets the count and allocates\n\t * the sgls over again.\n\t */\n\tphba->sli4_hba.nvmet_xri_cnt = 0;\n}\n\n/**\n * lpfc_init_active_sgl_array - Allocate the buf to track active ELS XRIs.\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to allocate the driver's active sgl memory.\n * This array will hold the sglq_entry's for active IOs.\n **/\nstatic int\nlpfc_init_active_sgl_array(struct lpfc_hba *phba)\n{\n\tint size;\n\tsize = sizeof(struct lpfc_sglq *);\n\tsize *= phba->sli4_hba.max_cfg_param.max_xri;\n\n\tphba->sli4_hba.lpfc_sglq_active_list =\n\t\tkzalloc(size, GFP_KERNEL);\n\tif (!phba->sli4_hba.lpfc_sglq_active_list)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\n/**\n * lpfc_free_active_sgl - Free the buf that tracks active ELS XRIs.\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to walk through the array of active sglq entries\n * and free all of the resources.\n * This is just a place holder for now.\n **/\nstatic void\nlpfc_free_active_sgl(struct lpfc_hba *phba)\n{\n\tkfree(phba->sli4_hba.lpfc_sglq_active_list);\n}\n\n/**\n * lpfc_init_sgl_list - Allocate and initialize sgl list.\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to allocate and initizlize the driver's sgl\n * list and set up the sgl xritag tag array accordingly.\n *\n **/\nstatic void\nlpfc_init_sgl_list(struct lpfc_hba *phba)\n{\n\t/* Initialize and populate the sglq list per host/VF. */\n\tINIT_LIST_HEAD(&phba->sli4_hba.lpfc_els_sgl_list);\n\tINIT_LIST_HEAD(&phba->sli4_hba.lpfc_abts_els_sgl_list);\n\tINIT_LIST_HEAD(&phba->sli4_hba.lpfc_nvmet_sgl_list);\n\tINIT_LIST_HEAD(&phba->sli4_hba.lpfc_abts_nvmet_ctx_list);\n\n\t/* els xri-sgl book keeping */\n\tphba->sli4_hba.els_xri_cnt = 0;\n\n\t/* nvme xri-buffer book keeping */\n\tphba->sli4_hba.io_xri_cnt = 0;\n}\n\n/**\n * lpfc_sli4_init_rpi_hdrs - Post the rpi header memory region to the port\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to post rpi header templates to the\n * port for those SLI4 ports that do not support extents.  This routine\n * posts a PAGE_SIZE memory region to the port to hold up to\n * PAGE_SIZE modulo 64 rpi context headers.  This is an initialization routine\n * and should be called only when interrupts are disabled.\n *\n * Return codes\n * \t0 - successful\n *\t-ERROR - otherwise.\n **/\nint\nlpfc_sli4_init_rpi_hdrs(struct lpfc_hba *phba)\n{\n\tint rc = 0;\n\tstruct lpfc_rpi_hdr *rpi_hdr;\n\n\tINIT_LIST_HEAD(&phba->sli4_hba.lpfc_rpi_hdr_list);\n\tif (!phba->sli4_hba.rpi_hdrs_in_use)\n\t\treturn rc;\n\tif (phba->sli4_hba.extents_in_use)\n\t\treturn -EIO;\n\n\trpi_hdr = lpfc_sli4_create_rpi_hdr(phba);\n\tif (!rpi_hdr) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0391 Error during rpi post operation\\n\");\n\t\tlpfc_sli4_remove_rpis(phba);\n\t\trc = -ENODEV;\n\t}\n\n\treturn rc;\n}\n\n/**\n * lpfc_sli4_create_rpi_hdr - Allocate an rpi header memory region\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to allocate a single 4KB memory region to\n * support rpis and stores them in the phba.  This single region\n * provides support for up to 64 rpis.  The region is used globally\n * by the device.\n *\n * Returns:\n *   A valid rpi hdr on success.\n *   A NULL pointer on any failure.\n **/\nstruct lpfc_rpi_hdr *\nlpfc_sli4_create_rpi_hdr(struct lpfc_hba *phba)\n{\n\tuint16_t rpi_limit, curr_rpi_range;\n\tstruct lpfc_dmabuf *dmabuf;\n\tstruct lpfc_rpi_hdr *rpi_hdr;\n\n\t/*\n\t * If the SLI4 port supports extents, posting the rpi header isn't\n\t * required.  Set the expected maximum count and let the actual value\n\t * get set when extents are fully allocated.\n\t */\n\tif (!phba->sli4_hba.rpi_hdrs_in_use)\n\t\treturn NULL;\n\tif (phba->sli4_hba.extents_in_use)\n\t\treturn NULL;\n\n\t/* The limit on the logical index is just the max_rpi count. */\n\trpi_limit = phba->sli4_hba.max_cfg_param.max_rpi;\n\n\tspin_lock_irq(&phba->hbalock);\n\t/*\n\t * Establish the starting RPI in this header block.  The starting\n\t * rpi is normalized to a zero base because the physical rpi is\n\t * port based.\n\t */\n\tcurr_rpi_range = phba->sli4_hba.next_rpi;\n\tspin_unlock_irq(&phba->hbalock);\n\n\t/* Reached full RPI range */\n\tif (curr_rpi_range == rpi_limit)\n\t\treturn NULL;\n\n\t/*\n\t * First allocate the protocol header region for the port.  The\n\t * port expects a 4KB DMA-mapped memory region that is 4K aligned.\n\t */\n\tdmabuf = kzalloc(sizeof(struct lpfc_dmabuf), GFP_KERNEL);\n\tif (!dmabuf)\n\t\treturn NULL;\n\n\tdmabuf->virt = dma_alloc_coherent(&phba->pcidev->dev,\n\t\t\t\t\t  LPFC_HDR_TEMPLATE_SIZE,\n\t\t\t\t\t  &dmabuf->phys, GFP_KERNEL);\n\tif (!dmabuf->virt) {\n\t\trpi_hdr = NULL;\n\t\tgoto err_free_dmabuf;\n\t}\n\n\tif (!IS_ALIGNED(dmabuf->phys, LPFC_HDR_TEMPLATE_SIZE)) {\n\t\trpi_hdr = NULL;\n\t\tgoto err_free_coherent;\n\t}\n\n\t/* Save the rpi header data for cleanup later. */\n\trpi_hdr = kzalloc(sizeof(struct lpfc_rpi_hdr), GFP_KERNEL);\n\tif (!rpi_hdr)\n\t\tgoto err_free_coherent;\n\n\trpi_hdr->dmabuf = dmabuf;\n\trpi_hdr->len = LPFC_HDR_TEMPLATE_SIZE;\n\trpi_hdr->page_count = 1;\n\tspin_lock_irq(&phba->hbalock);\n\n\t/* The rpi_hdr stores the logical index only. */\n\trpi_hdr->start_rpi = curr_rpi_range;\n\trpi_hdr->next_rpi = phba->sli4_hba.next_rpi + LPFC_RPI_HDR_COUNT;\n\tlist_add_tail(&rpi_hdr->list, &phba->sli4_hba.lpfc_rpi_hdr_list);\n\n\tspin_unlock_irq(&phba->hbalock);\n\treturn rpi_hdr;\n\n err_free_coherent:\n\tdma_free_coherent(&phba->pcidev->dev, LPFC_HDR_TEMPLATE_SIZE,\n\t\t\t  dmabuf->virt, dmabuf->phys);\n err_free_dmabuf:\n\tkfree(dmabuf);\n\treturn NULL;\n}\n\n/**\n * lpfc_sli4_remove_rpi_hdrs - Remove all rpi header memory regions\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to remove all memory resources allocated\n * to support rpis for SLI4 ports not supporting extents. This routine\n * presumes the caller has released all rpis consumed by fabric or port\n * logins and is prepared to have the header pages removed.\n **/\nvoid\nlpfc_sli4_remove_rpi_hdrs(struct lpfc_hba *phba)\n{\n\tstruct lpfc_rpi_hdr *rpi_hdr, *next_rpi_hdr;\n\n\tif (!phba->sli4_hba.rpi_hdrs_in_use)\n\t\tgoto exit;\n\n\tlist_for_each_entry_safe(rpi_hdr, next_rpi_hdr,\n\t\t\t\t &phba->sli4_hba.lpfc_rpi_hdr_list, list) {\n\t\tlist_del(&rpi_hdr->list);\n\t\tdma_free_coherent(&phba->pcidev->dev, rpi_hdr->len,\n\t\t\t\t  rpi_hdr->dmabuf->virt, rpi_hdr->dmabuf->phys);\n\t\tkfree(rpi_hdr->dmabuf);\n\t\tkfree(rpi_hdr);\n\t}\n exit:\n\t/* There are no rpis available to the port now. */\n\tphba->sli4_hba.next_rpi = 0;\n}\n\n/**\n * lpfc_hba_alloc - Allocate driver hba data structure for a device.\n * @pdev: pointer to pci device data structure.\n *\n * This routine is invoked to allocate the driver hba data structure for an\n * HBA device. If the allocation is successful, the phba reference to the\n * PCI device data structure is set.\n *\n * Return codes\n *      pointer to @phba - successful\n *      NULL - error\n **/\nstatic struct lpfc_hba *\nlpfc_hba_alloc(struct pci_dev *pdev)\n{\n\tstruct lpfc_hba *phba;\n\n\t/* Allocate memory for HBA structure */\n\tphba = kzalloc(sizeof(struct lpfc_hba), GFP_KERNEL);\n\tif (!phba) {\n\t\tdev_err(&pdev->dev, \"failed to allocate hba struct\\n\");\n\t\treturn NULL;\n\t}\n\n\t/* Set reference to PCI device in HBA structure */\n\tphba->pcidev = pdev;\n\n\t/* Assign an unused board number */\n\tphba->brd_no = lpfc_get_instance();\n\tif (phba->brd_no < 0) {\n\t\tkfree(phba);\n\t\treturn NULL;\n\t}\n\tphba->eratt_poll_interval = LPFC_ERATT_POLL_INTERVAL;\n\n\tspin_lock_init(&phba->ct_ev_lock);\n\tINIT_LIST_HEAD(&phba->ct_ev_waiters);\n\n\treturn phba;\n}\n\n/**\n * lpfc_hba_free - Free driver hba data structure with a device.\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to free the driver hba data structure with an\n * HBA device.\n **/\nstatic void\nlpfc_hba_free(struct lpfc_hba *phba)\n{\n\tif (phba->sli_rev == LPFC_SLI_REV4)\n\t\tkfree(phba->sli4_hba.hdwq);\n\n\t/* Release the driver assigned board number */\n\tidr_remove(&lpfc_hba_index, phba->brd_no);\n\n\t/* Free memory allocated with sli3 rings */\n\tkfree(phba->sli.sli3_ring);\n\tphba->sli.sli3_ring = NULL;\n\n\tkfree(phba);\n\treturn;\n}\n\n/**\n * lpfc_create_shost - Create hba physical port with associated scsi host.\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to create HBA physical port and associate a SCSI\n * host with it.\n *\n * Return codes\n *      0 - successful\n *      other values - error\n **/\nstatic int\nlpfc_create_shost(struct lpfc_hba *phba)\n{\n\tstruct lpfc_vport *vport;\n\tstruct Scsi_Host  *shost;\n\n\t/* Initialize HBA FC structure */\n\tphba->fc_edtov = FF_DEF_EDTOV;\n\tphba->fc_ratov = FF_DEF_RATOV;\n\tphba->fc_altov = FF_DEF_ALTOV;\n\tphba->fc_arbtov = FF_DEF_ARBTOV;\n\n\tatomic_set(&phba->sdev_cnt, 0);\n\tvport = lpfc_create_port(phba, phba->brd_no, &phba->pcidev->dev);\n\tif (!vport)\n\t\treturn -ENODEV;\n\n\tshost = lpfc_shost_from_vport(vport);\n\tphba->pport = vport;\n\n\tif (phba->nvmet_support) {\n\t\t/* Only 1 vport (pport) will support NVME target */\n\t\tphba->targetport = NULL;\n\t\tphba->cfg_enable_fc4_type = LPFC_ENABLE_NVME;\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT | LOG_NVME_DISC,\n\t\t\t\t\"6076 NVME Target Found\\n\");\n\t}\n\n\tlpfc_debugfs_initialize(vport);\n\t/* Put reference to SCSI host to driver's device private data */\n\tpci_set_drvdata(phba->pcidev, shost);\n\n\t/*\n\t * At this point we are fully registered with PSA. In addition,\n\t * any initial discovery should be completed.\n\t */\n\tvport->load_flag |= FC_ALLOW_FDMI;\n\tif (phba->cfg_enable_SmartSAN ||\n\t    (phba->cfg_fdmi_on == LPFC_FDMI_SUPPORT)) {\n\n\t\t/* Setup appropriate attribute masks */\n\t\tvport->fdmi_hba_mask = LPFC_FDMI2_HBA_ATTR;\n\t\tif (phba->cfg_enable_SmartSAN)\n\t\t\tvport->fdmi_port_mask = LPFC_FDMI2_SMART_ATTR;\n\t\telse\n\t\t\tvport->fdmi_port_mask = LPFC_FDMI2_PORT_ATTR;\n\t}\n\treturn 0;\n}\n\n/**\n * lpfc_destroy_shost - Destroy hba physical port with associated scsi host.\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to destroy HBA physical port and the associated\n * SCSI host.\n **/\nstatic void\nlpfc_destroy_shost(struct lpfc_hba *phba)\n{\n\tstruct lpfc_vport *vport = phba->pport;\n\n\t/* Destroy physical port that associated with the SCSI host */\n\tdestroy_port(vport);\n\n\treturn;\n}\n\n/**\n * lpfc_setup_bg - Setup Block guard structures and debug areas.\n * @phba: pointer to lpfc hba data structure.\n * @shost: the shost to be used to detect Block guard settings.\n *\n * This routine sets up the local Block guard protocol settings for @shost.\n * This routine also allocates memory for debugging bg buffers.\n **/\nstatic void\nlpfc_setup_bg(struct lpfc_hba *phba, struct Scsi_Host *shost)\n{\n\tuint32_t old_mask;\n\tuint32_t old_guard;\n\n\tif (phba->cfg_prot_mask && phba->cfg_prot_guard) {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"1478 Registering BlockGuard with the \"\n\t\t\t\t\"SCSI layer\\n\");\n\n\t\told_mask = phba->cfg_prot_mask;\n\t\told_guard = phba->cfg_prot_guard;\n\n\t\t/* Only allow supported values */\n\t\tphba->cfg_prot_mask &= (SHOST_DIF_TYPE1_PROTECTION |\n\t\t\tSHOST_DIX_TYPE0_PROTECTION |\n\t\t\tSHOST_DIX_TYPE1_PROTECTION);\n\t\tphba->cfg_prot_guard &= (SHOST_DIX_GUARD_IP |\n\t\t\t\t\t SHOST_DIX_GUARD_CRC);\n\n\t\t/* DIF Type 1 protection for profiles AST1/C1 is end to end */\n\t\tif (phba->cfg_prot_mask == SHOST_DIX_TYPE1_PROTECTION)\n\t\t\tphba->cfg_prot_mask |= SHOST_DIF_TYPE1_PROTECTION;\n\n\t\tif (phba->cfg_prot_mask && phba->cfg_prot_guard) {\n\t\t\tif ((old_mask != phba->cfg_prot_mask) ||\n\t\t\t\t(old_guard != phba->cfg_prot_guard))\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"1475 Registering BlockGuard with the \"\n\t\t\t\t\t\"SCSI layer: mask %d  guard %d\\n\",\n\t\t\t\t\tphba->cfg_prot_mask,\n\t\t\t\t\tphba->cfg_prot_guard);\n\n\t\t\tscsi_host_set_prot(shost, phba->cfg_prot_mask);\n\t\t\tscsi_host_set_guard(shost, phba->cfg_prot_guard);\n\t\t} else\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"1479 Not Registering BlockGuard with the SCSI \"\n\t\t\t\t\"layer, Bad protection parameters: %d %d\\n\",\n\t\t\t\told_mask, old_guard);\n\t}\n}\n\n/**\n * lpfc_post_init_setup - Perform necessary device post initialization setup.\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to perform all the necessary post initialization\n * setup for the device.\n **/\nstatic void\nlpfc_post_init_setup(struct lpfc_hba *phba)\n{\n\tstruct Scsi_Host  *shost;\n\tstruct lpfc_adapter_event_header adapter_event;\n\n\t/* Get the default values for Model Name and Description */\n\tlpfc_get_hba_model_desc(phba, phba->ModelName, phba->ModelDesc);\n\n\t/*\n\t * hba setup may have changed the hba_queue_depth so we need to\n\t * adjust the value of can_queue.\n\t */\n\tshost = pci_get_drvdata(phba->pcidev);\n\tshost->can_queue = phba->cfg_hba_queue_depth - 10;\n\n\tlpfc_host_attrib_init(shost);\n\n\tif (phba->cfg_poll & DISABLE_FCP_RING_INT) {\n\t\tspin_lock_irq(shost->host_lock);\n\t\tlpfc_poll_start_timer(phba);\n\t\tspin_unlock_irq(shost->host_lock);\n\t}\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"0428 Perform SCSI scan\\n\");\n\t/* Send board arrival event to upper layer */\n\tadapter_event.event_type = FC_REG_ADAPTER_EVENT;\n\tadapter_event.subcategory = LPFC_EVENT_ARRIVAL;\n\tfc_host_post_vendor_event(shost, fc_get_event_number(),\n\t\t\t\t  sizeof(adapter_event),\n\t\t\t\t  (char *) &adapter_event,\n\t\t\t\t  LPFC_NL_VENDOR_ID);\n\treturn;\n}\n\n/**\n * lpfc_sli_pci_mem_setup - Setup SLI3 HBA PCI memory space.\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to set up the PCI device memory space for device\n * with SLI-3 interface spec.\n *\n * Return codes\n * \t0 - successful\n * \tother values - error\n **/\nstatic int\nlpfc_sli_pci_mem_setup(struct lpfc_hba *phba)\n{\n\tstruct pci_dev *pdev = phba->pcidev;\n\tunsigned long bar0map_len, bar2map_len;\n\tint i, hbq_count;\n\tvoid *ptr;\n\tint error;\n\n\tif (!pdev)\n\t\treturn -ENODEV;\n\n\t/* Set the device DMA mask size */\n\terror = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64));\n\tif (error)\n\t\terror = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(32));\n\tif (error)\n\t\treturn error;\n\terror = -ENODEV;\n\n\t/* Get the bus address of Bar0 and Bar2 and the number of bytes\n\t * required by each mapping.\n\t */\n\tphba->pci_bar0_map = pci_resource_start(pdev, 0);\n\tbar0map_len = pci_resource_len(pdev, 0);\n\n\tphba->pci_bar2_map = pci_resource_start(pdev, 2);\n\tbar2map_len = pci_resource_len(pdev, 2);\n\n\t/* Map HBA SLIM to a kernel virtual address. */\n\tphba->slim_memmap_p = ioremap(phba->pci_bar0_map, bar0map_len);\n\tif (!phba->slim_memmap_p) {\n\t\tdev_printk(KERN_ERR, &pdev->dev,\n\t\t\t   \"ioremap failed for SLIM memory.\\n\");\n\t\tgoto out;\n\t}\n\n\t/* Map HBA Control Registers to a kernel virtual address. */\n\tphba->ctrl_regs_memmap_p = ioremap(phba->pci_bar2_map, bar2map_len);\n\tif (!phba->ctrl_regs_memmap_p) {\n\t\tdev_printk(KERN_ERR, &pdev->dev,\n\t\t\t   \"ioremap failed for HBA control registers.\\n\");\n\t\tgoto out_iounmap_slim;\n\t}\n\n\t/* Allocate memory for SLI-2 structures */\n\tphba->slim2p.virt = dma_alloc_coherent(&pdev->dev, SLI2_SLIM_SIZE,\n\t\t\t\t\t       &phba->slim2p.phys, GFP_KERNEL);\n\tif (!phba->slim2p.virt)\n\t\tgoto out_iounmap;\n\n\tphba->mbox = phba->slim2p.virt + offsetof(struct lpfc_sli2_slim, mbx);\n\tphba->mbox_ext = (phba->slim2p.virt +\n\t\toffsetof(struct lpfc_sli2_slim, mbx_ext_words));\n\tphba->pcb = (phba->slim2p.virt + offsetof(struct lpfc_sli2_slim, pcb));\n\tphba->IOCBs = (phba->slim2p.virt +\n\t\t       offsetof(struct lpfc_sli2_slim, IOCBs));\n\n\tphba->hbqslimp.virt = dma_alloc_coherent(&pdev->dev,\n\t\t\t\t\t\t lpfc_sli_hbq_size(),\n\t\t\t\t\t\t &phba->hbqslimp.phys,\n\t\t\t\t\t\t GFP_KERNEL);\n\tif (!phba->hbqslimp.virt)\n\t\tgoto out_free_slim;\n\n\thbq_count = lpfc_sli_hbq_count();\n\tptr = phba->hbqslimp.virt;\n\tfor (i = 0; i < hbq_count; ++i) {\n\t\tphba->hbqs[i].hbq_virt = ptr;\n\t\tINIT_LIST_HEAD(&phba->hbqs[i].hbq_buffer_list);\n\t\tptr += (lpfc_hbq_defs[i]->entry_count *\n\t\t\tsizeof(struct lpfc_hbq_entry));\n\t}\n\tphba->hbqs[LPFC_ELS_HBQ].hbq_alloc_buffer = lpfc_els_hbq_alloc;\n\tphba->hbqs[LPFC_ELS_HBQ].hbq_free_buffer = lpfc_els_hbq_free;\n\n\tmemset(phba->hbqslimp.virt, 0, lpfc_sli_hbq_size());\n\n\tphba->MBslimaddr = phba->slim_memmap_p;\n\tphba->HAregaddr = phba->ctrl_regs_memmap_p + HA_REG_OFFSET;\n\tphba->CAregaddr = phba->ctrl_regs_memmap_p + CA_REG_OFFSET;\n\tphba->HSregaddr = phba->ctrl_regs_memmap_p + HS_REG_OFFSET;\n\tphba->HCregaddr = phba->ctrl_regs_memmap_p + HC_REG_OFFSET;\n\n\treturn 0;\n\nout_free_slim:\n\tdma_free_coherent(&pdev->dev, SLI2_SLIM_SIZE,\n\t\t\t  phba->slim2p.virt, phba->slim2p.phys);\nout_iounmap:\n\tiounmap(phba->ctrl_regs_memmap_p);\nout_iounmap_slim:\n\tiounmap(phba->slim_memmap_p);\nout:\n\treturn error;\n}\n\n/**\n * lpfc_sli_pci_mem_unset - Unset SLI3 HBA PCI memory space.\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to unset the PCI device memory space for device\n * with SLI-3 interface spec.\n **/\nstatic void\nlpfc_sli_pci_mem_unset(struct lpfc_hba *phba)\n{\n\tstruct pci_dev *pdev;\n\n\t/* Obtain PCI device reference */\n\tif (!phba->pcidev)\n\t\treturn;\n\telse\n\t\tpdev = phba->pcidev;\n\n\t/* Free coherent DMA memory allocated */\n\tdma_free_coherent(&pdev->dev, lpfc_sli_hbq_size(),\n\t\t\t  phba->hbqslimp.virt, phba->hbqslimp.phys);\n\tdma_free_coherent(&pdev->dev, SLI2_SLIM_SIZE,\n\t\t\t  phba->slim2p.virt, phba->slim2p.phys);\n\n\t/* I/O memory unmap */\n\tiounmap(phba->ctrl_regs_memmap_p);\n\tiounmap(phba->slim_memmap_p);\n\n\treturn;\n}\n\n/**\n * lpfc_sli4_post_status_check - Wait for SLI4 POST done and check status\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to wait for SLI4 device Power On Self Test (POST)\n * done and check status.\n *\n * Return 0 if successful, otherwise -ENODEV.\n **/\nint\nlpfc_sli4_post_status_check(struct lpfc_hba *phba)\n{\n\tstruct lpfc_register portsmphr_reg, uerrlo_reg, uerrhi_reg;\n\tstruct lpfc_register reg_data;\n\tint i, port_error = 0;\n\tuint32_t if_type;\n\n\tmemset(&portsmphr_reg, 0, sizeof(portsmphr_reg));\n\tmemset(&reg_data, 0, sizeof(reg_data));\n\tif (!phba->sli4_hba.PSMPHRregaddr)\n\t\treturn -ENODEV;\n\n\t/* Wait up to 30 seconds for the SLI Port POST done and ready */\n\tfor (i = 0; i < 3000; i++) {\n\t\tif (lpfc_readl(phba->sli4_hba.PSMPHRregaddr,\n\t\t\t&portsmphr_reg.word0) ||\n\t\t\t(bf_get(lpfc_port_smphr_perr, &portsmphr_reg))) {\n\t\t\t/* Port has a fatal POST error, break out */\n\t\t\tport_error = -ENODEV;\n\t\t\tbreak;\n\t\t}\n\t\tif (LPFC_POST_STAGE_PORT_READY ==\n\t\t    bf_get(lpfc_port_smphr_port_status, &portsmphr_reg))\n\t\t\tbreak;\n\t\tmsleep(10);\n\t}\n\n\t/*\n\t * If there was a port error during POST, then don't proceed with\n\t * other register reads as the data may not be valid.  Just exit.\n\t */\n\tif (port_error) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"1408 Port Failed POST - portsmphr=0x%x, \"\n\t\t\t\"perr=x%x, sfi=x%x, nip=x%x, ipc=x%x, scr1=x%x, \"\n\t\t\t\"scr2=x%x, hscratch=x%x, pstatus=x%x\\n\",\n\t\t\tportsmphr_reg.word0,\n\t\t\tbf_get(lpfc_port_smphr_perr, &portsmphr_reg),\n\t\t\tbf_get(lpfc_port_smphr_sfi, &portsmphr_reg),\n\t\t\tbf_get(lpfc_port_smphr_nip, &portsmphr_reg),\n\t\t\tbf_get(lpfc_port_smphr_ipc, &portsmphr_reg),\n\t\t\tbf_get(lpfc_port_smphr_scr1, &portsmphr_reg),\n\t\t\tbf_get(lpfc_port_smphr_scr2, &portsmphr_reg),\n\t\t\tbf_get(lpfc_port_smphr_host_scratch, &portsmphr_reg),\n\t\t\tbf_get(lpfc_port_smphr_port_status, &portsmphr_reg));\n\t} else {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"2534 Device Info: SLIFamily=0x%x, \"\n\t\t\t\t\"SLIRev=0x%x, IFType=0x%x, SLIHint_1=0x%x, \"\n\t\t\t\t\"SLIHint_2=0x%x, FT=0x%x\\n\",\n\t\t\t\tbf_get(lpfc_sli_intf_sli_family,\n\t\t\t\t       &phba->sli4_hba.sli_intf),\n\t\t\t\tbf_get(lpfc_sli_intf_slirev,\n\t\t\t\t       &phba->sli4_hba.sli_intf),\n\t\t\t\tbf_get(lpfc_sli_intf_if_type,\n\t\t\t\t       &phba->sli4_hba.sli_intf),\n\t\t\t\tbf_get(lpfc_sli_intf_sli_hint1,\n\t\t\t\t       &phba->sli4_hba.sli_intf),\n\t\t\t\tbf_get(lpfc_sli_intf_sli_hint2,\n\t\t\t\t       &phba->sli4_hba.sli_intf),\n\t\t\t\tbf_get(lpfc_sli_intf_func_type,\n\t\t\t\t       &phba->sli4_hba.sli_intf));\n\t\t/*\n\t\t * Check for other Port errors during the initialization\n\t\t * process.  Fail the load if the port did not come up\n\t\t * correctly.\n\t\t */\n\t\tif_type = bf_get(lpfc_sli_intf_if_type,\n\t\t\t\t &phba->sli4_hba.sli_intf);\n\t\tswitch (if_type) {\n\t\tcase LPFC_SLI_INTF_IF_TYPE_0:\n\t\t\tphba->sli4_hba.ue_mask_lo =\n\t\t\t      readl(phba->sli4_hba.u.if_type0.UEMASKLOregaddr);\n\t\t\tphba->sli4_hba.ue_mask_hi =\n\t\t\t      readl(phba->sli4_hba.u.if_type0.UEMASKHIregaddr);\n\t\t\tuerrlo_reg.word0 =\n\t\t\t      readl(phba->sli4_hba.u.if_type0.UERRLOregaddr);\n\t\t\tuerrhi_reg.word0 =\n\t\t\t\treadl(phba->sli4_hba.u.if_type0.UERRHIregaddr);\n\t\t\tif ((~phba->sli4_hba.ue_mask_lo & uerrlo_reg.word0) ||\n\t\t\t    (~phba->sli4_hba.ue_mask_hi & uerrhi_reg.word0)) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\t\"1422 Unrecoverable Error \"\n\t\t\t\t\t\t\"Detected during POST \"\n\t\t\t\t\t\t\"uerr_lo_reg=0x%x, \"\n\t\t\t\t\t\t\"uerr_hi_reg=0x%x, \"\n\t\t\t\t\t\t\"ue_mask_lo_reg=0x%x, \"\n\t\t\t\t\t\t\"ue_mask_hi_reg=0x%x\\n\",\n\t\t\t\t\t\tuerrlo_reg.word0,\n\t\t\t\t\t\tuerrhi_reg.word0,\n\t\t\t\t\t\tphba->sli4_hba.ue_mask_lo,\n\t\t\t\t\t\tphba->sli4_hba.ue_mask_hi);\n\t\t\t\tport_error = -ENODEV;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase LPFC_SLI_INTF_IF_TYPE_2:\n\t\tcase LPFC_SLI_INTF_IF_TYPE_6:\n\t\t\t/* Final checks.  The port status should be clean. */\n\t\t\tif (lpfc_readl(phba->sli4_hba.u.if_type2.STATUSregaddr,\n\t\t\t\t&reg_data.word0) ||\n\t\t\t\t(bf_get(lpfc_sliport_status_err, &reg_data) &&\n\t\t\t\t !bf_get(lpfc_sliport_status_rn, &reg_data))) {\n\t\t\t\tphba->work_status[0] =\n\t\t\t\t\treadl(phba->sli4_hba.u.if_type2.\n\t\t\t\t\t      ERR1regaddr);\n\t\t\t\tphba->work_status[1] =\n\t\t\t\t\treadl(phba->sli4_hba.u.if_type2.\n\t\t\t\t\t      ERR2regaddr);\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"2888 Unrecoverable port error \"\n\t\t\t\t\t\"following POST: port status reg \"\n\t\t\t\t\t\"0x%x, port_smphr reg 0x%x, \"\n\t\t\t\t\t\"error 1=0x%x, error 2=0x%x\\n\",\n\t\t\t\t\treg_data.word0,\n\t\t\t\t\tportsmphr_reg.word0,\n\t\t\t\t\tphba->work_status[0],\n\t\t\t\t\tphba->work_status[1]);\n\t\t\t\tport_error = -ENODEV;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase LPFC_SLI_INTF_IF_TYPE_1:\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn port_error;\n}\n\n/**\n * lpfc_sli4_bar0_register_memmap - Set up SLI4 BAR0 register memory map.\n * @phba: pointer to lpfc hba data structure.\n * @if_type:  The SLI4 interface type getting configured.\n *\n * This routine is invoked to set up SLI4 BAR0 PCI config space register\n * memory map.\n **/\nstatic void\nlpfc_sli4_bar0_register_memmap(struct lpfc_hba *phba, uint32_t if_type)\n{\n\tswitch (if_type) {\n\tcase LPFC_SLI_INTF_IF_TYPE_0:\n\t\tphba->sli4_hba.u.if_type0.UERRLOregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p + LPFC_UERR_STATUS_LO;\n\t\tphba->sli4_hba.u.if_type0.UERRHIregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p + LPFC_UERR_STATUS_HI;\n\t\tphba->sli4_hba.u.if_type0.UEMASKLOregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p + LPFC_UE_MASK_LO;\n\t\tphba->sli4_hba.u.if_type0.UEMASKHIregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p + LPFC_UE_MASK_HI;\n\t\tphba->sli4_hba.SLIINTFregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p + LPFC_SLI_INTF;\n\t\tbreak;\n\tcase LPFC_SLI_INTF_IF_TYPE_2:\n\t\tphba->sli4_hba.u.if_type2.EQDregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p +\n\t\t\t\t\t\tLPFC_CTL_PORT_EQ_DELAY_OFFSET;\n\t\tphba->sli4_hba.u.if_type2.ERR1regaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p +\n\t\t\t\t\t\tLPFC_CTL_PORT_ER1_OFFSET;\n\t\tphba->sli4_hba.u.if_type2.ERR2regaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p +\n\t\t\t\t\t\tLPFC_CTL_PORT_ER2_OFFSET;\n\t\tphba->sli4_hba.u.if_type2.CTRLregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p +\n\t\t\t\t\t\tLPFC_CTL_PORT_CTL_OFFSET;\n\t\tphba->sli4_hba.u.if_type2.STATUSregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p +\n\t\t\t\t\t\tLPFC_CTL_PORT_STA_OFFSET;\n\t\tphba->sli4_hba.SLIINTFregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p + LPFC_SLI_INTF;\n\t\tphba->sli4_hba.PSMPHRregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p +\n\t\t\t\t\t\tLPFC_CTL_PORT_SEM_OFFSET;\n\t\tphba->sli4_hba.RQDBregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p +\n\t\t\t\t\t\tLPFC_ULP0_RQ_DOORBELL;\n\t\tphba->sli4_hba.WQDBregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p +\n\t\t\t\t\t\tLPFC_ULP0_WQ_DOORBELL;\n\t\tphba->sli4_hba.CQDBregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p + LPFC_EQCQ_DOORBELL;\n\t\tphba->sli4_hba.EQDBregaddr = phba->sli4_hba.CQDBregaddr;\n\t\tphba->sli4_hba.MQDBregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p + LPFC_MQ_DOORBELL;\n\t\tphba->sli4_hba.BMBXregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p + LPFC_BMBX;\n\t\tbreak;\n\tcase LPFC_SLI_INTF_IF_TYPE_6:\n\t\tphba->sli4_hba.u.if_type2.EQDregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p +\n\t\t\t\t\t\tLPFC_CTL_PORT_EQ_DELAY_OFFSET;\n\t\tphba->sli4_hba.u.if_type2.ERR1regaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p +\n\t\t\t\t\t\tLPFC_CTL_PORT_ER1_OFFSET;\n\t\tphba->sli4_hba.u.if_type2.ERR2regaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p +\n\t\t\t\t\t\tLPFC_CTL_PORT_ER2_OFFSET;\n\t\tphba->sli4_hba.u.if_type2.CTRLregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p +\n\t\t\t\t\t\tLPFC_CTL_PORT_CTL_OFFSET;\n\t\tphba->sli4_hba.u.if_type2.STATUSregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p +\n\t\t\t\t\t\tLPFC_CTL_PORT_STA_OFFSET;\n\t\tphba->sli4_hba.PSMPHRregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p +\n\t\t\t\t\t\tLPFC_CTL_PORT_SEM_OFFSET;\n\t\tphba->sli4_hba.BMBXregaddr =\n\t\t\tphba->sli4_hba.conf_regs_memmap_p + LPFC_BMBX;\n\t\tbreak;\n\tcase LPFC_SLI_INTF_IF_TYPE_1:\n\tdefault:\n\t\tdev_printk(KERN_ERR, &phba->pcidev->dev,\n\t\t\t   \"FATAL - unsupported SLI4 interface type - %d\\n\",\n\t\t\t   if_type);\n\t\tbreak;\n\t}\n}\n\n/**\n * lpfc_sli4_bar1_register_memmap - Set up SLI4 BAR1 register memory map.\n * @phba: pointer to lpfc hba data structure.\n * @if_type: sli if type to operate on.\n *\n * This routine is invoked to set up SLI4 BAR1 register memory map.\n **/\nstatic void\nlpfc_sli4_bar1_register_memmap(struct lpfc_hba *phba, uint32_t if_type)\n{\n\tswitch (if_type) {\n\tcase LPFC_SLI_INTF_IF_TYPE_0:\n\t\tphba->sli4_hba.PSMPHRregaddr =\n\t\t\tphba->sli4_hba.ctrl_regs_memmap_p +\n\t\t\tLPFC_SLIPORT_IF0_SMPHR;\n\t\tphba->sli4_hba.ISRregaddr = phba->sli4_hba.ctrl_regs_memmap_p +\n\t\t\tLPFC_HST_ISR0;\n\t\tphba->sli4_hba.IMRregaddr = phba->sli4_hba.ctrl_regs_memmap_p +\n\t\t\tLPFC_HST_IMR0;\n\t\tphba->sli4_hba.ISCRregaddr = phba->sli4_hba.ctrl_regs_memmap_p +\n\t\t\tLPFC_HST_ISCR0;\n\t\tbreak;\n\tcase LPFC_SLI_INTF_IF_TYPE_6:\n\t\tphba->sli4_hba.RQDBregaddr = phba->sli4_hba.drbl_regs_memmap_p +\n\t\t\tLPFC_IF6_RQ_DOORBELL;\n\t\tphba->sli4_hba.WQDBregaddr = phba->sli4_hba.drbl_regs_memmap_p +\n\t\t\tLPFC_IF6_WQ_DOORBELL;\n\t\tphba->sli4_hba.CQDBregaddr = phba->sli4_hba.drbl_regs_memmap_p +\n\t\t\tLPFC_IF6_CQ_DOORBELL;\n\t\tphba->sli4_hba.EQDBregaddr = phba->sli4_hba.drbl_regs_memmap_p +\n\t\t\tLPFC_IF6_EQ_DOORBELL;\n\t\tphba->sli4_hba.MQDBregaddr = phba->sli4_hba.drbl_regs_memmap_p +\n\t\t\tLPFC_IF6_MQ_DOORBELL;\n\t\tbreak;\n\tcase LPFC_SLI_INTF_IF_TYPE_2:\n\tcase LPFC_SLI_INTF_IF_TYPE_1:\n\tdefault:\n\t\tdev_err(&phba->pcidev->dev,\n\t\t\t   \"FATAL - unsupported SLI4 interface type - %d\\n\",\n\t\t\t   if_type);\n\t\tbreak;\n\t}\n}\n\n/**\n * lpfc_sli4_bar2_register_memmap - Set up SLI4 BAR2 register memory map.\n * @phba: pointer to lpfc hba data structure.\n * @vf: virtual function number\n *\n * This routine is invoked to set up SLI4 BAR2 doorbell register memory map\n * based on the given viftual function number, @vf.\n *\n * Return 0 if successful, otherwise -ENODEV.\n **/\nstatic int\nlpfc_sli4_bar2_register_memmap(struct lpfc_hba *phba, uint32_t vf)\n{\n\tif (vf > LPFC_VIR_FUNC_MAX)\n\t\treturn -ENODEV;\n\n\tphba->sli4_hba.RQDBregaddr = (phba->sli4_hba.drbl_regs_memmap_p +\n\t\t\t\tvf * LPFC_VFR_PAGE_SIZE +\n\t\t\t\t\tLPFC_ULP0_RQ_DOORBELL);\n\tphba->sli4_hba.WQDBregaddr = (phba->sli4_hba.drbl_regs_memmap_p +\n\t\t\t\tvf * LPFC_VFR_PAGE_SIZE +\n\t\t\t\t\tLPFC_ULP0_WQ_DOORBELL);\n\tphba->sli4_hba.CQDBregaddr = (phba->sli4_hba.drbl_regs_memmap_p +\n\t\t\t\tvf * LPFC_VFR_PAGE_SIZE +\n\t\t\t\t\tLPFC_EQCQ_DOORBELL);\n\tphba->sli4_hba.EQDBregaddr = phba->sli4_hba.CQDBregaddr;\n\tphba->sli4_hba.MQDBregaddr = (phba->sli4_hba.drbl_regs_memmap_p +\n\t\t\t\tvf * LPFC_VFR_PAGE_SIZE + LPFC_MQ_DOORBELL);\n\tphba->sli4_hba.BMBXregaddr = (phba->sli4_hba.drbl_regs_memmap_p +\n\t\t\t\tvf * LPFC_VFR_PAGE_SIZE + LPFC_BMBX);\n\treturn 0;\n}\n\n/**\n * lpfc_create_bootstrap_mbox - Create the bootstrap mailbox\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to create the bootstrap mailbox\n * region consistent with the SLI-4 interface spec.  This\n * routine allocates all memory necessary to communicate\n * mailbox commands to the port and sets up all alignment\n * needs.  No locks are expected to be held when calling\n * this routine.\n *\n * Return codes\n * \t0 - successful\n * \t-ENOMEM - could not allocated memory.\n **/\nstatic int\nlpfc_create_bootstrap_mbox(struct lpfc_hba *phba)\n{\n\tuint32_t bmbx_size;\n\tstruct lpfc_dmabuf *dmabuf;\n\tstruct dma_address *dma_address;\n\tuint32_t pa_addr;\n\tuint64_t phys_addr;\n\n\tdmabuf = kzalloc(sizeof(struct lpfc_dmabuf), GFP_KERNEL);\n\tif (!dmabuf)\n\t\treturn -ENOMEM;\n\n\t/*\n\t * The bootstrap mailbox region is comprised of 2 parts\n\t * plus an alignment restriction of 16 bytes.\n\t */\n\tbmbx_size = sizeof(struct lpfc_bmbx_create) + (LPFC_ALIGN_16_BYTE - 1);\n\tdmabuf->virt = dma_alloc_coherent(&phba->pcidev->dev, bmbx_size,\n\t\t\t\t\t  &dmabuf->phys, GFP_KERNEL);\n\tif (!dmabuf->virt) {\n\t\tkfree(dmabuf);\n\t\treturn -ENOMEM;\n\t}\n\n\t/*\n\t * Initialize the bootstrap mailbox pointers now so that the register\n\t * operations are simple later.  The mailbox dma address is required\n\t * to be 16-byte aligned.  Also align the virtual memory as each\n\t * maibox is copied into the bmbx mailbox region before issuing the\n\t * command to the port.\n\t */\n\tphba->sli4_hba.bmbx.dmabuf = dmabuf;\n\tphba->sli4_hba.bmbx.bmbx_size = bmbx_size;\n\n\tphba->sli4_hba.bmbx.avirt = PTR_ALIGN(dmabuf->virt,\n\t\t\t\t\t      LPFC_ALIGN_16_BYTE);\n\tphba->sli4_hba.bmbx.aphys = ALIGN(dmabuf->phys,\n\t\t\t\t\t      LPFC_ALIGN_16_BYTE);\n\n\t/*\n\t * Set the high and low physical addresses now.  The SLI4 alignment\n\t * requirement is 16 bytes and the mailbox is posted to the port\n\t * as two 30-bit addresses.  The other data is a bit marking whether\n\t * the 30-bit address is the high or low address.\n\t * Upcast bmbx aphys to 64bits so shift instruction compiles\n\t * clean on 32 bit machines.\n\t */\n\tdma_address = &phba->sli4_hba.bmbx.dma_address;\n\tphys_addr = (uint64_t)phba->sli4_hba.bmbx.aphys;\n\tpa_addr = (uint32_t) ((phys_addr >> 34) & 0x3fffffff);\n\tdma_address->addr_hi = (uint32_t) ((pa_addr << 2) |\n\t\t\t\t\t   LPFC_BMBX_BIT1_ADDR_HI);\n\n\tpa_addr = (uint32_t) ((phba->sli4_hba.bmbx.aphys >> 4) & 0x3fffffff);\n\tdma_address->addr_lo = (uint32_t) ((pa_addr << 2) |\n\t\t\t\t\t   LPFC_BMBX_BIT1_ADDR_LO);\n\treturn 0;\n}\n\n/**\n * lpfc_destroy_bootstrap_mbox - Destroy all bootstrap mailbox resources\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to teardown the bootstrap mailbox\n * region and release all host resources. This routine requires\n * the caller to ensure all mailbox commands recovered, no\n * additional mailbox comands are sent, and interrupts are disabled\n * before calling this routine.\n *\n **/\nstatic void\nlpfc_destroy_bootstrap_mbox(struct lpfc_hba *phba)\n{\n\tdma_free_coherent(&phba->pcidev->dev,\n\t\t\t  phba->sli4_hba.bmbx.bmbx_size,\n\t\t\t  phba->sli4_hba.bmbx.dmabuf->virt,\n\t\t\t  phba->sli4_hba.bmbx.dmabuf->phys);\n\n\tkfree(phba->sli4_hba.bmbx.dmabuf);\n\tmemset(&phba->sli4_hba.bmbx, 0, sizeof(struct lpfc_bmbx));\n}\n\nstatic const char * const lpfc_topo_to_str[] = {\n\t\"Loop then P2P\",\n\t\"Loopback\",\n\t\"P2P Only\",\n\t\"Unsupported\",\n\t\"Loop Only\",\n\t\"Unsupported\",\n\t\"P2P then Loop\",\n};\n\n#define\tLINK_FLAGS_DEF\t0x0\n#define\tLINK_FLAGS_P2P\t0x1\n#define\tLINK_FLAGS_LOOP\t0x2\n/**\n * lpfc_map_topology - Map the topology read from READ_CONFIG\n * @phba: pointer to lpfc hba data structure.\n * @rd_config: pointer to read config data\n *\n * This routine is invoked to map the topology values as read\n * from the read config mailbox command. If the persistent\n * topology feature is supported, the firmware will provide the\n * saved topology information to be used in INIT_LINK\n **/\nstatic void\nlpfc_map_topology(struct lpfc_hba *phba, struct lpfc_mbx_read_config *rd_config)\n{\n\tu8 ptv, tf, pt;\n\n\tptv = bf_get(lpfc_mbx_rd_conf_ptv, rd_config);\n\ttf = bf_get(lpfc_mbx_rd_conf_tf, rd_config);\n\tpt = bf_get(lpfc_mbx_rd_conf_pt, rd_config);\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\"2027 Read Config Data : ptv:0x%x, tf:0x%x pt:0x%x\",\n\t\t\t ptv, tf, pt);\n\tif (!ptv) {\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\n\t\t\t\t\"2019 FW does not support persistent topology \"\n\t\t\t\t\"Using driver parameter defined value [%s]\",\n\t\t\t\tlpfc_topo_to_str[phba->cfg_topology]);\n\t\treturn;\n\t}\n\t/* FW supports persistent topology - override module parameter value */\n\tphba->hba_flag |= HBA_PERSISTENT_TOPO;\n\tswitch (phba->pcidev->device) {\n\tcase PCI_DEVICE_ID_LANCER_G7_FC:\n\tcase PCI_DEVICE_ID_LANCER_G6_FC:\n\t\tif (!tf) {\n\t\t\tphba->cfg_topology = ((pt == LINK_FLAGS_LOOP)\n\t\t\t\t\t? FLAGS_TOPOLOGY_MODE_LOOP\n\t\t\t\t\t: FLAGS_TOPOLOGY_MODE_PT_PT);\n\t\t} else {\n\t\t\tphba->hba_flag &= ~HBA_PERSISTENT_TOPO;\n\t\t}\n\t\tbreak;\n\tdefault:\t/* G5 */\n\t\tif (tf) {\n\t\t\t/* If topology failover set - pt is '0' or '1' */\n\t\t\tphba->cfg_topology = (pt ? FLAGS_TOPOLOGY_MODE_PT_LOOP :\n\t\t\t\t\t      FLAGS_TOPOLOGY_MODE_LOOP_PT);\n\t\t} else {\n\t\t\tphba->cfg_topology = ((pt == LINK_FLAGS_P2P)\n\t\t\t\t\t? FLAGS_TOPOLOGY_MODE_PT_PT\n\t\t\t\t\t: FLAGS_TOPOLOGY_MODE_LOOP);\n\t\t}\n\t\tbreak;\n\t}\n\tif (phba->hba_flag & HBA_PERSISTENT_TOPO) {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"2020 Using persistent topology value [%s]\",\n\t\t\t\tlpfc_topo_to_str[phba->cfg_topology]);\n\t} else {\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\n\t\t\t\t\"2021 Invalid topology values from FW \"\n\t\t\t\t\"Using driver parameter defined value [%s]\",\n\t\t\t\tlpfc_topo_to_str[phba->cfg_topology]);\n\t}\n}\n\n/**\n * lpfc_sli4_read_config - Get the config parameters.\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to read the configuration parameters from the HBA.\n * The configuration parameters are used to set the base and maximum values\n * for RPI's XRI's VPI's VFI's and FCFIs. These values also affect the resource\n * allocation for the port.\n *\n * Return codes\n * \t0 - successful\n * \t-ENOMEM - No available memory\n *      -EIO - The mailbox failed to complete successfully.\n **/\nint\nlpfc_sli4_read_config(struct lpfc_hba *phba)\n{\n\tLPFC_MBOXQ_t *pmb;\n\tstruct lpfc_mbx_read_config *rd_config;\n\tunion  lpfc_sli4_cfg_shdr *shdr;\n\tuint32_t shdr_status, shdr_add_status;\n\tstruct lpfc_mbx_get_func_cfg *get_func_cfg;\n\tstruct lpfc_rsrc_desc_fcfcoe *desc;\n\tchar *pdesc_0;\n\tuint16_t forced_link_speed;\n\tuint32_t if_type, qmin;\n\tint length, i, rc = 0, rc2;\n\n\tpmb = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!pmb) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2011 Unable to allocate memory for issuing \"\n\t\t\t\t\"SLI_CONFIG_SPECIAL mailbox command\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tlpfc_read_config(phba, pmb);\n\n\trc = lpfc_sli_issue_mbox(phba, pmb, MBX_POLL);\n\tif (rc != MBX_SUCCESS) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2012 Mailbox failed , mbxCmd x%x \"\n\t\t\t\t\"READ_CONFIG, mbxStatus x%x\\n\",\n\t\t\t\tbf_get(lpfc_mqe_command, &pmb->u.mqe),\n\t\t\t\tbf_get(lpfc_mqe_status, &pmb->u.mqe));\n\t\trc = -EIO;\n\t} else {\n\t\trd_config = &pmb->u.mqe.un.rd_config;\n\t\tif (bf_get(lpfc_mbx_rd_conf_lnk_ldv, rd_config)) {\n\t\t\tphba->sli4_hba.lnk_info.lnk_dv = LPFC_LNK_DAT_VAL;\n\t\t\tphba->sli4_hba.lnk_info.lnk_tp =\n\t\t\t\tbf_get(lpfc_mbx_rd_conf_lnk_type, rd_config);\n\t\t\tphba->sli4_hba.lnk_info.lnk_no =\n\t\t\t\tbf_get(lpfc_mbx_rd_conf_lnk_numb, rd_config);\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\t\"3081 lnk_type:%d, lnk_numb:%d\\n\",\n\t\t\t\t\tphba->sli4_hba.lnk_info.lnk_tp,\n\t\t\t\t\tphba->sli4_hba.lnk_info.lnk_no);\n\t\t} else\n\t\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\n\t\t\t\t\t\"3082 Mailbox (x%x) returned ldv:x0\\n\",\n\t\t\t\t\tbf_get(lpfc_mqe_command, &pmb->u.mqe));\n\t\tif (bf_get(lpfc_mbx_rd_conf_bbscn_def, rd_config)) {\n\t\t\tphba->bbcredit_support = 1;\n\t\t\tphba->sli4_hba.bbscn_params.word0 = rd_config->word8;\n\t\t}\n\n\t\tphba->sli4_hba.conf_trunk =\n\t\t\tbf_get(lpfc_mbx_rd_conf_trunk, rd_config);\n\t\tphba->sli4_hba.extents_in_use =\n\t\t\tbf_get(lpfc_mbx_rd_conf_extnts_inuse, rd_config);\n\t\tphba->sli4_hba.max_cfg_param.max_xri =\n\t\t\tbf_get(lpfc_mbx_rd_conf_xri_count, rd_config);\n\t\t/* Reduce resource usage in kdump environment */\n\t\tif (is_kdump_kernel() &&\n\t\t    phba->sli4_hba.max_cfg_param.max_xri > 512)\n\t\t\tphba->sli4_hba.max_cfg_param.max_xri = 512;\n\t\tphba->sli4_hba.max_cfg_param.xri_base =\n\t\t\tbf_get(lpfc_mbx_rd_conf_xri_base, rd_config);\n\t\tphba->sli4_hba.max_cfg_param.max_vpi =\n\t\t\tbf_get(lpfc_mbx_rd_conf_vpi_count, rd_config);\n\t\t/* Limit the max we support */\n\t\tif (phba->sli4_hba.max_cfg_param.max_vpi > LPFC_MAX_VPORTS)\n\t\t\tphba->sli4_hba.max_cfg_param.max_vpi = LPFC_MAX_VPORTS;\n\t\tphba->sli4_hba.max_cfg_param.vpi_base =\n\t\t\tbf_get(lpfc_mbx_rd_conf_vpi_base, rd_config);\n\t\tphba->sli4_hba.max_cfg_param.max_rpi =\n\t\t\tbf_get(lpfc_mbx_rd_conf_rpi_count, rd_config);\n\t\tphba->sli4_hba.max_cfg_param.rpi_base =\n\t\t\tbf_get(lpfc_mbx_rd_conf_rpi_base, rd_config);\n\t\tphba->sli4_hba.max_cfg_param.max_vfi =\n\t\t\tbf_get(lpfc_mbx_rd_conf_vfi_count, rd_config);\n\t\tphba->sli4_hba.max_cfg_param.vfi_base =\n\t\t\tbf_get(lpfc_mbx_rd_conf_vfi_base, rd_config);\n\t\tphba->sli4_hba.max_cfg_param.max_fcfi =\n\t\t\tbf_get(lpfc_mbx_rd_conf_fcfi_count, rd_config);\n\t\tphba->sli4_hba.max_cfg_param.max_eq =\n\t\t\tbf_get(lpfc_mbx_rd_conf_eq_count, rd_config);\n\t\tphba->sli4_hba.max_cfg_param.max_rq =\n\t\t\tbf_get(lpfc_mbx_rd_conf_rq_count, rd_config);\n\t\tphba->sli4_hba.max_cfg_param.max_wq =\n\t\t\tbf_get(lpfc_mbx_rd_conf_wq_count, rd_config);\n\t\tphba->sli4_hba.max_cfg_param.max_cq =\n\t\t\tbf_get(lpfc_mbx_rd_conf_cq_count, rd_config);\n\t\tphba->lmt = bf_get(lpfc_mbx_rd_conf_lmt, rd_config);\n\t\tphba->sli4_hba.next_xri = phba->sli4_hba.max_cfg_param.xri_base;\n\t\tphba->vpi_base = phba->sli4_hba.max_cfg_param.vpi_base;\n\t\tphba->vfi_base = phba->sli4_hba.max_cfg_param.vfi_base;\n\t\tphba->max_vpi = (phba->sli4_hba.max_cfg_param.max_vpi > 0) ?\n\t\t\t\t(phba->sli4_hba.max_cfg_param.max_vpi - 1) : 0;\n\t\tphba->max_vports = phba->max_vpi;\n\t\tlpfc_map_topology(phba, rd_config);\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"2003 cfg params Extents? %d \"\n\t\t\t\t\"XRI(B:%d M:%d), \"\n\t\t\t\t\"VPI(B:%d M:%d) \"\n\t\t\t\t\"VFI(B:%d M:%d) \"\n\t\t\t\t\"RPI(B:%d M:%d) \"\n\t\t\t\t\"FCFI:%d EQ:%d CQ:%d WQ:%d RQ:%d lmt:x%x\\n\",\n\t\t\t\tphba->sli4_hba.extents_in_use,\n\t\t\t\tphba->sli4_hba.max_cfg_param.xri_base,\n\t\t\t\tphba->sli4_hba.max_cfg_param.max_xri,\n\t\t\t\tphba->sli4_hba.max_cfg_param.vpi_base,\n\t\t\t\tphba->sli4_hba.max_cfg_param.max_vpi,\n\t\t\t\tphba->sli4_hba.max_cfg_param.vfi_base,\n\t\t\t\tphba->sli4_hba.max_cfg_param.max_vfi,\n\t\t\t\tphba->sli4_hba.max_cfg_param.rpi_base,\n\t\t\t\tphba->sli4_hba.max_cfg_param.max_rpi,\n\t\t\t\tphba->sli4_hba.max_cfg_param.max_fcfi,\n\t\t\t\tphba->sli4_hba.max_cfg_param.max_eq,\n\t\t\t\tphba->sli4_hba.max_cfg_param.max_cq,\n\t\t\t\tphba->sli4_hba.max_cfg_param.max_wq,\n\t\t\t\tphba->sli4_hba.max_cfg_param.max_rq,\n\t\t\t\tphba->lmt);\n\n\t\t/*\n\t\t * Calculate queue resources based on how\n\t\t * many WQ/CQ/EQs are available.\n\t\t */\n\t\tqmin = phba->sli4_hba.max_cfg_param.max_wq;\n\t\tif (phba->sli4_hba.max_cfg_param.max_cq < qmin)\n\t\t\tqmin = phba->sli4_hba.max_cfg_param.max_cq;\n\t\tif (phba->sli4_hba.max_cfg_param.max_eq < qmin)\n\t\t\tqmin = phba->sli4_hba.max_cfg_param.max_eq;\n\t\t/*\n\t\t * Whats left after this can go toward NVME / FCP.\n\t\t * The minus 4 accounts for ELS, NVME LS, MBOX\n\t\t * plus one extra. When configured for\n\t\t * NVMET, FCP io channel WQs are not created.\n\t\t */\n\t\tqmin -= 4;\n\n\t\t/* Check to see if there is enough for NVME */\n\t\tif ((phba->cfg_irq_chann > qmin) ||\n\t\t    (phba->cfg_hdw_queue > qmin)) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"2005 Reducing Queues - \"\n\t\t\t\t\t\"FW resource limitation: \"\n\t\t\t\t\t\"WQ %d CQ %d EQ %d: min %d: \"\n\t\t\t\t\t\"IRQ %d HDWQ %d\\n\",\n\t\t\t\t\tphba->sli4_hba.max_cfg_param.max_wq,\n\t\t\t\t\tphba->sli4_hba.max_cfg_param.max_cq,\n\t\t\t\t\tphba->sli4_hba.max_cfg_param.max_eq,\n\t\t\t\t\tqmin, phba->cfg_irq_chann,\n\t\t\t\t\tphba->cfg_hdw_queue);\n\n\t\t\tif (phba->cfg_irq_chann > qmin)\n\t\t\t\tphba->cfg_irq_chann = qmin;\n\t\t\tif (phba->cfg_hdw_queue > qmin)\n\t\t\t\tphba->cfg_hdw_queue = qmin;\n\t\t}\n\t}\n\n\tif (rc)\n\t\tgoto read_cfg_out;\n\n\t/* Update link speed if forced link speed is supported */\n\tif_type = bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf);\n\tif (if_type >= LPFC_SLI_INTF_IF_TYPE_2) {\n\t\tforced_link_speed =\n\t\t\tbf_get(lpfc_mbx_rd_conf_link_speed, rd_config);\n\t\tif (forced_link_speed) {\n\t\t\tphba->hba_flag |= HBA_FORCED_LINK_SPEED;\n\n\t\t\tswitch (forced_link_speed) {\n\t\t\tcase LINK_SPEED_1G:\n\t\t\t\tphba->cfg_link_speed =\n\t\t\t\t\tLPFC_USER_LINK_SPEED_1G;\n\t\t\t\tbreak;\n\t\t\tcase LINK_SPEED_2G:\n\t\t\t\tphba->cfg_link_speed =\n\t\t\t\t\tLPFC_USER_LINK_SPEED_2G;\n\t\t\t\tbreak;\n\t\t\tcase LINK_SPEED_4G:\n\t\t\t\tphba->cfg_link_speed =\n\t\t\t\t\tLPFC_USER_LINK_SPEED_4G;\n\t\t\t\tbreak;\n\t\t\tcase LINK_SPEED_8G:\n\t\t\t\tphba->cfg_link_speed =\n\t\t\t\t\tLPFC_USER_LINK_SPEED_8G;\n\t\t\t\tbreak;\n\t\t\tcase LINK_SPEED_10G:\n\t\t\t\tphba->cfg_link_speed =\n\t\t\t\t\tLPFC_USER_LINK_SPEED_10G;\n\t\t\t\tbreak;\n\t\t\tcase LINK_SPEED_16G:\n\t\t\t\tphba->cfg_link_speed =\n\t\t\t\t\tLPFC_USER_LINK_SPEED_16G;\n\t\t\t\tbreak;\n\t\t\tcase LINK_SPEED_32G:\n\t\t\t\tphba->cfg_link_speed =\n\t\t\t\t\tLPFC_USER_LINK_SPEED_32G;\n\t\t\t\tbreak;\n\t\t\tcase LINK_SPEED_64G:\n\t\t\t\tphba->cfg_link_speed =\n\t\t\t\t\tLPFC_USER_LINK_SPEED_64G;\n\t\t\t\tbreak;\n\t\t\tcase 0xffff:\n\t\t\t\tphba->cfg_link_speed =\n\t\t\t\t\tLPFC_USER_LINK_SPEED_AUTO;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR,\n\t\t\t\t\t\tLOG_TRACE_EVENT,\n\t\t\t\t\t\t\"0047 Unrecognized link \"\n\t\t\t\t\t\t\"speed : %d\\n\",\n\t\t\t\t\t\tforced_link_speed);\n\t\t\t\tphba->cfg_link_speed =\n\t\t\t\t\tLPFC_USER_LINK_SPEED_AUTO;\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Reset the DFT_HBA_Q_DEPTH to the max xri  */\n\tlength = phba->sli4_hba.max_cfg_param.max_xri -\n\t\t\tlpfc_sli4_get_els_iocb_cnt(phba);\n\tif (phba->cfg_hba_queue_depth > length) {\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\"3361 HBA queue depth changed from %d to %d\\n\",\n\t\t\t\tphba->cfg_hba_queue_depth, length);\n\t\tphba->cfg_hba_queue_depth = length;\n\t}\n\n\tif (bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf) <\n\t    LPFC_SLI_INTF_IF_TYPE_2)\n\t\tgoto read_cfg_out;\n\n\t/* get the pf# and vf# for SLI4 if_type 2 port */\n\tlength = (sizeof(struct lpfc_mbx_get_func_cfg) -\n\t\t  sizeof(struct lpfc_sli4_cfg_mhdr));\n\tlpfc_sli4_config(phba, pmb, LPFC_MBOX_SUBSYSTEM_COMMON,\n\t\t\t LPFC_MBOX_OPCODE_GET_FUNCTION_CONFIG,\n\t\t\t length, LPFC_SLI4_MBX_EMBED);\n\n\trc2 = lpfc_sli_issue_mbox(phba, pmb, MBX_POLL);\n\tshdr = (union lpfc_sli4_cfg_shdr *)\n\t\t\t\t&pmb->u.mqe.un.sli4_config.header.cfg_shdr;\n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\n\tif (rc2 || shdr_status || shdr_add_status) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3026 Mailbox failed , mbxCmd x%x \"\n\t\t\t\t\"GET_FUNCTION_CONFIG, mbxStatus x%x\\n\",\n\t\t\t\tbf_get(lpfc_mqe_command, &pmb->u.mqe),\n\t\t\t\tbf_get(lpfc_mqe_status, &pmb->u.mqe));\n\t\tgoto read_cfg_out;\n\t}\n\n\t/* search for fc_fcoe resrouce descriptor */\n\tget_func_cfg = &pmb->u.mqe.un.get_func_cfg;\n\n\tpdesc_0 = (char *)&get_func_cfg->func_cfg.desc[0];\n\tdesc = (struct lpfc_rsrc_desc_fcfcoe *)pdesc_0;\n\tlength = bf_get(lpfc_rsrc_desc_fcfcoe_length, desc);\n\tif (length == LPFC_RSRC_DESC_TYPE_FCFCOE_V0_RSVD)\n\t\tlength = LPFC_RSRC_DESC_TYPE_FCFCOE_V0_LENGTH;\n\telse if (length != LPFC_RSRC_DESC_TYPE_FCFCOE_V1_LENGTH)\n\t\tgoto read_cfg_out;\n\n\tfor (i = 0; i < LPFC_RSRC_DESC_MAX_NUM; i++) {\n\t\tdesc = (struct lpfc_rsrc_desc_fcfcoe *)(pdesc_0 + length * i);\n\t\tif (LPFC_RSRC_DESC_TYPE_FCFCOE ==\n\t\t    bf_get(lpfc_rsrc_desc_fcfcoe_type, desc)) {\n\t\t\tphba->sli4_hba.iov.pf_number =\n\t\t\t\tbf_get(lpfc_rsrc_desc_fcfcoe_pfnum, desc);\n\t\t\tphba->sli4_hba.iov.vf_number =\n\t\t\t\tbf_get(lpfc_rsrc_desc_fcfcoe_vfnum, desc);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (i < LPFC_RSRC_DESC_MAX_NUM)\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\n\t\t\t\t\"3027 GET_FUNCTION_CONFIG: pf_number:%d, \"\n\t\t\t\t\"vf_number:%d\\n\", phba->sli4_hba.iov.pf_number,\n\t\t\t\tphba->sli4_hba.iov.vf_number);\n\telse\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3028 GET_FUNCTION_CONFIG: failed to find \"\n\t\t\t\t\"Resource Descriptor:x%x\\n\",\n\t\t\t\tLPFC_RSRC_DESC_TYPE_FCFCOE);\n\nread_cfg_out:\n\tmempool_free(pmb, phba->mbox_mem_pool);\n\treturn rc;\n}\n\n/**\n * lpfc_setup_endian_order - Write endian order to an SLI4 if_type 0 port.\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to setup the port-side endian order when\n * the port if_type is 0.  This routine has no function for other\n * if_types.\n *\n * Return codes\n * \t0 - successful\n * \t-ENOMEM - No available memory\n *      -EIO - The mailbox failed to complete successfully.\n **/\nstatic int\nlpfc_setup_endian_order(struct lpfc_hba *phba)\n{\n\tLPFC_MBOXQ_t *mboxq;\n\tuint32_t if_type, rc = 0;\n\tuint32_t endian_mb_data[2] = {HOST_ENDIAN_LOW_WORD0,\n\t\t\t\t      HOST_ENDIAN_HIGH_WORD1};\n\n\tif_type = bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf);\n\tswitch (if_type) {\n\tcase LPFC_SLI_INTF_IF_TYPE_0:\n\t\tmboxq = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool,\n\t\t\t\t\t\t       GFP_KERNEL);\n\t\tif (!mboxq) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0492 Unable to allocate memory for \"\n\t\t\t\t\t\"issuing SLI_CONFIG_SPECIAL mailbox \"\n\t\t\t\t\t\"command\\n\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\t/*\n\t\t * The SLI4_CONFIG_SPECIAL mailbox command requires the first\n\t\t * two words to contain special data values and no other data.\n\t\t */\n\t\tmemset(mboxq, 0, sizeof(LPFC_MBOXQ_t));\n\t\tmemcpy(&mboxq->u.mqe, &endian_mb_data, sizeof(endian_mb_data));\n\t\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\t\tif (rc != MBX_SUCCESS) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0493 SLI_CONFIG_SPECIAL mailbox \"\n\t\t\t\t\t\"failed with status x%x\\n\",\n\t\t\t\t\trc);\n\t\t\trc = -EIO;\n\t\t}\n\t\tmempool_free(mboxq, phba->mbox_mem_pool);\n\t\tbreak;\n\tcase LPFC_SLI_INTF_IF_TYPE_6:\n\tcase LPFC_SLI_INTF_IF_TYPE_2:\n\tcase LPFC_SLI_INTF_IF_TYPE_1:\n\tdefault:\n\t\tbreak;\n\t}\n\treturn rc;\n}\n\n/**\n * lpfc_sli4_queue_verify - Verify and update EQ counts\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to check the user settable queue counts for EQs.\n * After this routine is called the counts will be set to valid values that\n * adhere to the constraints of the system's interrupt vectors and the port's\n * queue resources.\n *\n * Return codes\n *      0 - successful\n *      -ENOMEM - No available memory\n **/\nstatic int\nlpfc_sli4_queue_verify(struct lpfc_hba *phba)\n{\n\t/*\n\t * Sanity check for configured queue parameters against the run-time\n\t * device parameters\n\t */\n\n\tif (phba->nvmet_support) {\n\t\tif (phba->cfg_hdw_queue < phba->cfg_nvmet_mrq)\n\t\t\tphba->cfg_nvmet_mrq = phba->cfg_hdw_queue;\n\t\tif (phba->cfg_nvmet_mrq > LPFC_NVMET_MRQ_MAX)\n\t\t\tphba->cfg_nvmet_mrq = LPFC_NVMET_MRQ_MAX;\n\t}\n\n\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\"2574 IO channels: hdwQ %d IRQ %d MRQ: %d\\n\",\n\t\t\tphba->cfg_hdw_queue, phba->cfg_irq_chann,\n\t\t\tphba->cfg_nvmet_mrq);\n\n\t/* Get EQ depth from module parameter, fake the default for now */\n\tphba->sli4_hba.eq_esize = LPFC_EQE_SIZE_4B;\n\tphba->sli4_hba.eq_ecount = LPFC_EQE_DEF_COUNT;\n\n\t/* Get CQ depth from module parameter, fake the default for now */\n\tphba->sli4_hba.cq_esize = LPFC_CQE_SIZE;\n\tphba->sli4_hba.cq_ecount = LPFC_CQE_DEF_COUNT;\n\treturn 0;\n}\n\nstatic int\nlpfc_alloc_io_wq_cq(struct lpfc_hba *phba, int idx)\n{\n\tstruct lpfc_queue *qdesc;\n\tu32 wqesize;\n\tint cpu;\n\n\tcpu = lpfc_find_cpu_handle(phba, idx, LPFC_FIND_BY_HDWQ);\n\t/* Create Fast Path IO CQs */\n\tif (phba->enab_exp_wqcq_pages)\n\t\t/* Increase the CQ size when WQEs contain an embedded cdb */\n\t\tqdesc = lpfc_sli4_queue_alloc(phba, LPFC_EXPANDED_PAGE_SIZE,\n\t\t\t\t\t      phba->sli4_hba.cq_esize,\n\t\t\t\t\t      LPFC_CQE_EXP_COUNT, cpu);\n\n\telse\n\t\tqdesc = lpfc_sli4_queue_alloc(phba, LPFC_DEFAULT_PAGE_SIZE,\n\t\t\t\t\t      phba->sli4_hba.cq_esize,\n\t\t\t\t\t      phba->sli4_hba.cq_ecount, cpu);\n\tif (!qdesc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0499 Failed allocate fast-path IO CQ (%d)\\n\",\n\t\t\t\tidx);\n\t\treturn 1;\n\t}\n\tqdesc->qe_valid = 1;\n\tqdesc->hdwq = idx;\n\tqdesc->chann = cpu;\n\tphba->sli4_hba.hdwq[idx].io_cq = qdesc;\n\n\t/* Create Fast Path IO WQs */\n\tif (phba->enab_exp_wqcq_pages) {\n\t\t/* Increase the WQ size when WQEs contain an embedded cdb */\n\t\twqesize = (phba->fcp_embed_io) ?\n\t\t\tLPFC_WQE128_SIZE : phba->sli4_hba.wq_esize;\n\t\tqdesc = lpfc_sli4_queue_alloc(phba, LPFC_EXPANDED_PAGE_SIZE,\n\t\t\t\t\t      wqesize,\n\t\t\t\t\t      LPFC_WQE_EXP_COUNT, cpu);\n\t} else\n\t\tqdesc = lpfc_sli4_queue_alloc(phba, LPFC_DEFAULT_PAGE_SIZE,\n\t\t\t\t\t      phba->sli4_hba.wq_esize,\n\t\t\t\t\t      phba->sli4_hba.wq_ecount, cpu);\n\n\tif (!qdesc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0503 Failed allocate fast-path IO WQ (%d)\\n\",\n\t\t\t\tidx);\n\t\treturn 1;\n\t}\n\tqdesc->hdwq = idx;\n\tqdesc->chann = cpu;\n\tphba->sli4_hba.hdwq[idx].io_wq = qdesc;\n\tlist_add_tail(&qdesc->wq_list, &phba->sli4_hba.lpfc_wq_list);\n\treturn 0;\n}\n\n/**\n * lpfc_sli4_queue_create - Create all the SLI4 queues\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to allocate all the SLI4 queues for the FCoE HBA\n * operation. For each SLI4 queue type, the parameters such as queue entry\n * count (queue depth) shall be taken from the module parameter. For now,\n * we just use some constant number as place holder.\n *\n * Return codes\n *      0 - successful\n *      -ENOMEM - No availble memory\n *      -EIO - The mailbox failed to complete successfully.\n **/\nint\nlpfc_sli4_queue_create(struct lpfc_hba *phba)\n{\n\tstruct lpfc_queue *qdesc;\n\tint idx, cpu, eqcpu;\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tstruct lpfc_vector_map_info *cpup;\n\tstruct lpfc_vector_map_info *eqcpup;\n\tstruct lpfc_eq_intr_info *eqi;\n\n\t/*\n\t * Create HBA Record arrays.\n\t * Both NVME and FCP will share that same vectors / EQs\n\t */\n\tphba->sli4_hba.mq_esize = LPFC_MQE_SIZE;\n\tphba->sli4_hba.mq_ecount = LPFC_MQE_DEF_COUNT;\n\tphba->sli4_hba.wq_esize = LPFC_WQE_SIZE;\n\tphba->sli4_hba.wq_ecount = LPFC_WQE_DEF_COUNT;\n\tphba->sli4_hba.rq_esize = LPFC_RQE_SIZE;\n\tphba->sli4_hba.rq_ecount = LPFC_RQE_DEF_COUNT;\n\tphba->sli4_hba.eq_esize = LPFC_EQE_SIZE_4B;\n\tphba->sli4_hba.eq_ecount = LPFC_EQE_DEF_COUNT;\n\tphba->sli4_hba.cq_esize = LPFC_CQE_SIZE;\n\tphba->sli4_hba.cq_ecount = LPFC_CQE_DEF_COUNT;\n\n\tif (!phba->sli4_hba.hdwq) {\n\t\tphba->sli4_hba.hdwq = kcalloc(\n\t\t\tphba->cfg_hdw_queue, sizeof(struct lpfc_sli4_hdw_queue),\n\t\t\tGFP_KERNEL);\n\t\tif (!phba->sli4_hba.hdwq) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"6427 Failed allocate memory for \"\n\t\t\t\t\t\"fast-path Hardware Queue array\\n\");\n\t\t\tgoto out_error;\n\t\t}\n\t\t/* Prepare hardware queues to take IO buffers */\n\t\tfor (idx = 0; idx < phba->cfg_hdw_queue; idx++) {\n\t\t\tqp = &phba->sli4_hba.hdwq[idx];\n\t\t\tspin_lock_init(&qp->io_buf_list_get_lock);\n\t\t\tspin_lock_init(&qp->io_buf_list_put_lock);\n\t\t\tINIT_LIST_HEAD(&qp->lpfc_io_buf_list_get);\n\t\t\tINIT_LIST_HEAD(&qp->lpfc_io_buf_list_put);\n\t\t\tqp->get_io_bufs = 0;\n\t\t\tqp->put_io_bufs = 0;\n\t\t\tqp->total_io_bufs = 0;\n\t\t\tspin_lock_init(&qp->abts_io_buf_list_lock);\n\t\t\tINIT_LIST_HEAD(&qp->lpfc_abts_io_buf_list);\n\t\t\tqp->abts_scsi_io_bufs = 0;\n\t\t\tqp->abts_nvme_io_bufs = 0;\n\t\t\tINIT_LIST_HEAD(&qp->sgl_list);\n\t\t\tINIT_LIST_HEAD(&qp->cmd_rsp_buf_list);\n\t\t\tspin_lock_init(&qp->hdwq_lock);\n\t\t}\n\t}\n\n\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME) {\n\t\tif (phba->nvmet_support) {\n\t\t\tphba->sli4_hba.nvmet_cqset = kcalloc(\n\t\t\t\t\tphba->cfg_nvmet_mrq,\n\t\t\t\t\tsizeof(struct lpfc_queue *),\n\t\t\t\t\tGFP_KERNEL);\n\t\t\tif (!phba->sli4_hba.nvmet_cqset) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"3121 Fail allocate memory for \"\n\t\t\t\t\t\"fast-path CQ set array\\n\");\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t\tphba->sli4_hba.nvmet_mrq_hdr = kcalloc(\n\t\t\t\t\tphba->cfg_nvmet_mrq,\n\t\t\t\t\tsizeof(struct lpfc_queue *),\n\t\t\t\t\tGFP_KERNEL);\n\t\t\tif (!phba->sli4_hba.nvmet_mrq_hdr) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"3122 Fail allocate memory for \"\n\t\t\t\t\t\"fast-path RQ set hdr array\\n\");\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t\tphba->sli4_hba.nvmet_mrq_data = kcalloc(\n\t\t\t\t\tphba->cfg_nvmet_mrq,\n\t\t\t\t\tsizeof(struct lpfc_queue *),\n\t\t\t\t\tGFP_KERNEL);\n\t\t\tif (!phba->sli4_hba.nvmet_mrq_data) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"3124 Fail allocate memory for \"\n\t\t\t\t\t\"fast-path RQ set data array\\n\");\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t}\n\t}\n\n\tINIT_LIST_HEAD(&phba->sli4_hba.lpfc_wq_list);\n\n\t/* Create HBA Event Queues (EQs) */\n\tfor_each_present_cpu(cpu) {\n\t\t/* We only want to create 1 EQ per vector, even though\n\t\t * multiple CPUs might be using that vector. so only\n\t\t * selects the CPUs that are LPFC_CPU_FIRST_IRQ.\n\t\t */\n\t\tcpup = &phba->sli4_hba.cpu_map[cpu];\n\t\tif (!(cpup->flag & LPFC_CPU_FIRST_IRQ))\n\t\t\tcontinue;\n\n\t\t/* Get a ptr to the Hardware Queue associated with this CPU */\n\t\tqp = &phba->sli4_hba.hdwq[cpup->hdwq];\n\n\t\t/* Allocate an EQ */\n\t\tqdesc = lpfc_sli4_queue_alloc(phba, LPFC_DEFAULT_PAGE_SIZE,\n\t\t\t\t\t      phba->sli4_hba.eq_esize,\n\t\t\t\t\t      phba->sli4_hba.eq_ecount, cpu);\n\t\tif (!qdesc) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0497 Failed allocate EQ (%d)\\n\",\n\t\t\t\t\tcpup->hdwq);\n\t\t\tgoto out_error;\n\t\t}\n\t\tqdesc->qe_valid = 1;\n\t\tqdesc->hdwq = cpup->hdwq;\n\t\tqdesc->chann = cpu; /* First CPU this EQ is affinitized to */\n\t\tqdesc->last_cpu = qdesc->chann;\n\n\t\t/* Save the allocated EQ in the Hardware Queue */\n\t\tqp->hba_eq = qdesc;\n\n\t\teqi = per_cpu_ptr(phba->sli4_hba.eq_info, qdesc->last_cpu);\n\t\tlist_add(&qdesc->cpu_list, &eqi->list);\n\t}\n\n\t/* Now we need to populate the other Hardware Queues, that share\n\t * an IRQ vector, with the associated EQ ptr.\n\t */\n\tfor_each_present_cpu(cpu) {\n\t\tcpup = &phba->sli4_hba.cpu_map[cpu];\n\n\t\t/* Check for EQ already allocated in previous loop */\n\t\tif (cpup->flag & LPFC_CPU_FIRST_IRQ)\n\t\t\tcontinue;\n\n\t\t/* Check for multiple CPUs per hdwq */\n\t\tqp = &phba->sli4_hba.hdwq[cpup->hdwq];\n\t\tif (qp->hba_eq)\n\t\t\tcontinue;\n\n\t\t/* We need to share an EQ for this hdwq */\n\t\teqcpu = lpfc_find_cpu_handle(phba, cpup->eq, LPFC_FIND_BY_EQ);\n\t\teqcpup = &phba->sli4_hba.cpu_map[eqcpu];\n\t\tqp->hba_eq = phba->sli4_hba.hdwq[eqcpup->hdwq].hba_eq;\n\t}\n\n\t/* Allocate IO Path SLI4 CQ/WQs */\n\tfor (idx = 0; idx < phba->cfg_hdw_queue; idx++) {\n\t\tif (lpfc_alloc_io_wq_cq(phba, idx))\n\t\t\tgoto out_error;\n\t}\n\n\tif (phba->nvmet_support) {\n\t\tfor (idx = 0; idx < phba->cfg_nvmet_mrq; idx++) {\n\t\t\tcpu = lpfc_find_cpu_handle(phba, idx,\n\t\t\t\t\t\t   LPFC_FIND_BY_HDWQ);\n\t\t\tqdesc = lpfc_sli4_queue_alloc(phba,\n\t\t\t\t\t\t      LPFC_DEFAULT_PAGE_SIZE,\n\t\t\t\t\t\t      phba->sli4_hba.cq_esize,\n\t\t\t\t\t\t      phba->sli4_hba.cq_ecount,\n\t\t\t\t\t\t      cpu);\n\t\t\tif (!qdesc) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"3142 Failed allocate NVME \"\n\t\t\t\t\t\t\"CQ Set (%d)\\n\", idx);\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t\tqdesc->qe_valid = 1;\n\t\t\tqdesc->hdwq = idx;\n\t\t\tqdesc->chann = cpu;\n\t\t\tphba->sli4_hba.nvmet_cqset[idx] = qdesc;\n\t\t}\n\t}\n\n\t/*\n\t * Create Slow Path Completion Queues (CQs)\n\t */\n\n\tcpu = lpfc_find_cpu_handle(phba, 0, LPFC_FIND_BY_EQ);\n\t/* Create slow-path Mailbox Command Complete Queue */\n\tqdesc = lpfc_sli4_queue_alloc(phba, LPFC_DEFAULT_PAGE_SIZE,\n\t\t\t\t      phba->sli4_hba.cq_esize,\n\t\t\t\t      phba->sli4_hba.cq_ecount, cpu);\n\tif (!qdesc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0500 Failed allocate slow-path mailbox CQ\\n\");\n\t\tgoto out_error;\n\t}\n\tqdesc->qe_valid = 1;\n\tphba->sli4_hba.mbx_cq = qdesc;\n\n\t/* Create slow-path ELS Complete Queue */\n\tqdesc = lpfc_sli4_queue_alloc(phba, LPFC_DEFAULT_PAGE_SIZE,\n\t\t\t\t      phba->sli4_hba.cq_esize,\n\t\t\t\t      phba->sli4_hba.cq_ecount, cpu);\n\tif (!qdesc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0501 Failed allocate slow-path ELS CQ\\n\");\n\t\tgoto out_error;\n\t}\n\tqdesc->qe_valid = 1;\n\tqdesc->chann = cpu;\n\tphba->sli4_hba.els_cq = qdesc;\n\n\n\t/*\n\t * Create Slow Path Work Queues (WQs)\n\t */\n\n\t/* Create Mailbox Command Queue */\n\n\tqdesc = lpfc_sli4_queue_alloc(phba, LPFC_DEFAULT_PAGE_SIZE,\n\t\t\t\t      phba->sli4_hba.mq_esize,\n\t\t\t\t      phba->sli4_hba.mq_ecount, cpu);\n\tif (!qdesc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0505 Failed allocate slow-path MQ\\n\");\n\t\tgoto out_error;\n\t}\n\tqdesc->chann = cpu;\n\tphba->sli4_hba.mbx_wq = qdesc;\n\n\t/*\n\t * Create ELS Work Queues\n\t */\n\n\t/* Create slow-path ELS Work Queue */\n\tqdesc = lpfc_sli4_queue_alloc(phba, LPFC_DEFAULT_PAGE_SIZE,\n\t\t\t\t      phba->sli4_hba.wq_esize,\n\t\t\t\t      phba->sli4_hba.wq_ecount, cpu);\n\tif (!qdesc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0504 Failed allocate slow-path ELS WQ\\n\");\n\t\tgoto out_error;\n\t}\n\tqdesc->chann = cpu;\n\tphba->sli4_hba.els_wq = qdesc;\n\tlist_add_tail(&qdesc->wq_list, &phba->sli4_hba.lpfc_wq_list);\n\n\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME) {\n\t\t/* Create NVME LS Complete Queue */\n\t\tqdesc = lpfc_sli4_queue_alloc(phba, LPFC_DEFAULT_PAGE_SIZE,\n\t\t\t\t\t      phba->sli4_hba.cq_esize,\n\t\t\t\t\t      phba->sli4_hba.cq_ecount, cpu);\n\t\tif (!qdesc) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"6079 Failed allocate NVME LS CQ\\n\");\n\t\t\tgoto out_error;\n\t\t}\n\t\tqdesc->chann = cpu;\n\t\tqdesc->qe_valid = 1;\n\t\tphba->sli4_hba.nvmels_cq = qdesc;\n\n\t\t/* Create NVME LS Work Queue */\n\t\tqdesc = lpfc_sli4_queue_alloc(phba, LPFC_DEFAULT_PAGE_SIZE,\n\t\t\t\t\t      phba->sli4_hba.wq_esize,\n\t\t\t\t\t      phba->sli4_hba.wq_ecount, cpu);\n\t\tif (!qdesc) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"6080 Failed allocate NVME LS WQ\\n\");\n\t\t\tgoto out_error;\n\t\t}\n\t\tqdesc->chann = cpu;\n\t\tphba->sli4_hba.nvmels_wq = qdesc;\n\t\tlist_add_tail(&qdesc->wq_list, &phba->sli4_hba.lpfc_wq_list);\n\t}\n\n\t/*\n\t * Create Receive Queue (RQ)\n\t */\n\n\t/* Create Receive Queue for header */\n\tqdesc = lpfc_sli4_queue_alloc(phba, LPFC_DEFAULT_PAGE_SIZE,\n\t\t\t\t      phba->sli4_hba.rq_esize,\n\t\t\t\t      phba->sli4_hba.rq_ecount, cpu);\n\tif (!qdesc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0506 Failed allocate receive HRQ\\n\");\n\t\tgoto out_error;\n\t}\n\tphba->sli4_hba.hdr_rq = qdesc;\n\n\t/* Create Receive Queue for data */\n\tqdesc = lpfc_sli4_queue_alloc(phba, LPFC_DEFAULT_PAGE_SIZE,\n\t\t\t\t      phba->sli4_hba.rq_esize,\n\t\t\t\t      phba->sli4_hba.rq_ecount, cpu);\n\tif (!qdesc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0507 Failed allocate receive DRQ\\n\");\n\t\tgoto out_error;\n\t}\n\tphba->sli4_hba.dat_rq = qdesc;\n\n\tif ((phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME) &&\n\t    phba->nvmet_support) {\n\t\tfor (idx = 0; idx < phba->cfg_nvmet_mrq; idx++) {\n\t\t\tcpu = lpfc_find_cpu_handle(phba, idx,\n\t\t\t\t\t\t   LPFC_FIND_BY_HDWQ);\n\t\t\t/* Create NVMET Receive Queue for header */\n\t\t\tqdesc = lpfc_sli4_queue_alloc(phba,\n\t\t\t\t\t\t      LPFC_DEFAULT_PAGE_SIZE,\n\t\t\t\t\t\t      phba->sli4_hba.rq_esize,\n\t\t\t\t\t\t      LPFC_NVMET_RQE_DEF_COUNT,\n\t\t\t\t\t\t      cpu);\n\t\t\tif (!qdesc) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"3146 Failed allocate \"\n\t\t\t\t\t\t\"receive HRQ\\n\");\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t\tqdesc->hdwq = idx;\n\t\t\tphba->sli4_hba.nvmet_mrq_hdr[idx] = qdesc;\n\n\t\t\t/* Only needed for header of RQ pair */\n\t\t\tqdesc->rqbp = kzalloc_node(sizeof(*qdesc->rqbp),\n\t\t\t\t\t\t   GFP_KERNEL,\n\t\t\t\t\t\t   cpu_to_node(cpu));\n\t\t\tif (qdesc->rqbp == NULL) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"6131 Failed allocate \"\n\t\t\t\t\t\t\"Header RQBP\\n\");\n\t\t\t\tgoto out_error;\n\t\t\t}\n\n\t\t\t/* Put list in known state in case driver load fails. */\n\t\t\tINIT_LIST_HEAD(&qdesc->rqbp->rqb_buffer_list);\n\n\t\t\t/* Create NVMET Receive Queue for data */\n\t\t\tqdesc = lpfc_sli4_queue_alloc(phba,\n\t\t\t\t\t\t      LPFC_DEFAULT_PAGE_SIZE,\n\t\t\t\t\t\t      phba->sli4_hba.rq_esize,\n\t\t\t\t\t\t      LPFC_NVMET_RQE_DEF_COUNT,\n\t\t\t\t\t\t      cpu);\n\t\t\tif (!qdesc) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"3156 Failed allocate \"\n\t\t\t\t\t\t\"receive DRQ\\n\");\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t\tqdesc->hdwq = idx;\n\t\t\tphba->sli4_hba.nvmet_mrq_data[idx] = qdesc;\n\t\t}\n\t}\n\n\t/* Clear NVME stats */\n\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME) {\n\t\tfor (idx = 0; idx < phba->cfg_hdw_queue; idx++) {\n\t\t\tmemset(&phba->sli4_hba.hdwq[idx].nvme_cstat, 0,\n\t\t\t       sizeof(phba->sli4_hba.hdwq[idx].nvme_cstat));\n\t\t}\n\t}\n\n\t/* Clear SCSI stats */\n\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_FCP) {\n\t\tfor (idx = 0; idx < phba->cfg_hdw_queue; idx++) {\n\t\t\tmemset(&phba->sli4_hba.hdwq[idx].scsi_cstat, 0,\n\t\t\t       sizeof(phba->sli4_hba.hdwq[idx].scsi_cstat));\n\t\t}\n\t}\n\n\treturn 0;\n\nout_error:\n\tlpfc_sli4_queue_destroy(phba);\n\treturn -ENOMEM;\n}\n\nstatic inline void\n__lpfc_sli4_release_queue(struct lpfc_queue **qp)\n{\n\tif (*qp != NULL) {\n\t\tlpfc_sli4_queue_free(*qp);\n\t\t*qp = NULL;\n\t}\n}\n\nstatic inline void\nlpfc_sli4_release_queues(struct lpfc_queue ***qs, int max)\n{\n\tint idx;\n\n\tif (*qs == NULL)\n\t\treturn;\n\n\tfor (idx = 0; idx < max; idx++)\n\t\t__lpfc_sli4_release_queue(&(*qs)[idx]);\n\n\tkfree(*qs);\n\t*qs = NULL;\n}\n\nstatic inline void\nlpfc_sli4_release_hdwq(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli4_hdw_queue *hdwq;\n\tstruct lpfc_queue *eq;\n\tuint32_t idx;\n\n\thdwq = phba->sli4_hba.hdwq;\n\n\t/* Loop thru all Hardware Queues */\n\tfor (idx = 0; idx < phba->cfg_hdw_queue; idx++) {\n\t\t/* Free the CQ/WQ corresponding to the Hardware Queue */\n\t\tlpfc_sli4_queue_free(hdwq[idx].io_cq);\n\t\tlpfc_sli4_queue_free(hdwq[idx].io_wq);\n\t\thdwq[idx].hba_eq = NULL;\n\t\thdwq[idx].io_cq = NULL;\n\t\thdwq[idx].io_wq = NULL;\n\t\tif (phba->cfg_xpsgl && !phba->nvmet_support)\n\t\t\tlpfc_free_sgl_per_hdwq(phba, &hdwq[idx]);\n\t\tlpfc_free_cmd_rsp_buf_per_hdwq(phba, &hdwq[idx]);\n\t}\n\t/* Loop thru all IRQ vectors */\n\tfor (idx = 0; idx < phba->cfg_irq_chann; idx++) {\n\t\t/* Free the EQ corresponding to the IRQ vector */\n\t\teq = phba->sli4_hba.hba_eq_hdl[idx].eq;\n\t\tlpfc_sli4_queue_free(eq);\n\t\tphba->sli4_hba.hba_eq_hdl[idx].eq = NULL;\n\t}\n}\n\n/**\n * lpfc_sli4_queue_destroy - Destroy all the SLI4 queues\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to release all the SLI4 queues with the FCoE HBA\n * operation.\n *\n * Return codes\n *      0 - successful\n *      -ENOMEM - No available memory\n *      -EIO - The mailbox failed to complete successfully.\n **/\nvoid\nlpfc_sli4_queue_destroy(struct lpfc_hba *phba)\n{\n\t/*\n\t * Set FREE_INIT before beginning to free the queues.\n\t * Wait until the users of queues to acknowledge to\n\t * release queues by clearing FREE_WAIT.\n\t */\n\tspin_lock_irq(&phba->hbalock);\n\tphba->sli.sli_flag |= LPFC_QUEUE_FREE_INIT;\n\twhile (phba->sli.sli_flag & LPFC_QUEUE_FREE_WAIT) {\n\t\tspin_unlock_irq(&phba->hbalock);\n\t\tmsleep(20);\n\t\tspin_lock_irq(&phba->hbalock);\n\t}\n\tspin_unlock_irq(&phba->hbalock);\n\n\tlpfc_sli4_cleanup_poll_list(phba);\n\n\t/* Release HBA eqs */\n\tif (phba->sli4_hba.hdwq)\n\t\tlpfc_sli4_release_hdwq(phba);\n\n\tif (phba->nvmet_support) {\n\t\tlpfc_sli4_release_queues(&phba->sli4_hba.nvmet_cqset,\n\t\t\t\t\t phba->cfg_nvmet_mrq);\n\n\t\tlpfc_sli4_release_queues(&phba->sli4_hba.nvmet_mrq_hdr,\n\t\t\t\t\t phba->cfg_nvmet_mrq);\n\t\tlpfc_sli4_release_queues(&phba->sli4_hba.nvmet_mrq_data,\n\t\t\t\t\t phba->cfg_nvmet_mrq);\n\t}\n\n\t/* Release mailbox command work queue */\n\t__lpfc_sli4_release_queue(&phba->sli4_hba.mbx_wq);\n\n\t/* Release ELS work queue */\n\t__lpfc_sli4_release_queue(&phba->sli4_hba.els_wq);\n\n\t/* Release ELS work queue */\n\t__lpfc_sli4_release_queue(&phba->sli4_hba.nvmels_wq);\n\n\t/* Release unsolicited receive queue */\n\t__lpfc_sli4_release_queue(&phba->sli4_hba.hdr_rq);\n\t__lpfc_sli4_release_queue(&phba->sli4_hba.dat_rq);\n\n\t/* Release ELS complete queue */\n\t__lpfc_sli4_release_queue(&phba->sli4_hba.els_cq);\n\n\t/* Release NVME LS complete queue */\n\t__lpfc_sli4_release_queue(&phba->sli4_hba.nvmels_cq);\n\n\t/* Release mailbox command complete queue */\n\t__lpfc_sli4_release_queue(&phba->sli4_hba.mbx_cq);\n\n\t/* Everything on this list has been freed */\n\tINIT_LIST_HEAD(&phba->sli4_hba.lpfc_wq_list);\n\n\t/* Done with freeing the queues */\n\tspin_lock_irq(&phba->hbalock);\n\tphba->sli.sli_flag &= ~LPFC_QUEUE_FREE_INIT;\n\tspin_unlock_irq(&phba->hbalock);\n}\n\nint\nlpfc_free_rq_buffer(struct lpfc_hba *phba, struct lpfc_queue *rq)\n{\n\tstruct lpfc_rqb *rqbp;\n\tstruct lpfc_dmabuf *h_buf;\n\tstruct rqb_dmabuf *rqb_buffer;\n\n\trqbp = rq->rqbp;\n\twhile (!list_empty(&rqbp->rqb_buffer_list)) {\n\t\tlist_remove_head(&rqbp->rqb_buffer_list, h_buf,\n\t\t\t\t struct lpfc_dmabuf, list);\n\n\t\trqb_buffer = container_of(h_buf, struct rqb_dmabuf, hbuf);\n\t\t(rqbp->rqb_free_buffer)(phba, rqb_buffer);\n\t\trqbp->buffer_count--;\n\t}\n\treturn 1;\n}\n\nstatic int\nlpfc_create_wq_cq(struct lpfc_hba *phba, struct lpfc_queue *eq,\n\tstruct lpfc_queue *cq, struct lpfc_queue *wq, uint16_t *cq_map,\n\tint qidx, uint32_t qtype)\n{\n\tstruct lpfc_sli_ring *pring;\n\tint rc;\n\n\tif (!eq || !cq || !wq) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"6085 Fast-path %s (%d) not allocated\\n\",\n\t\t\t((eq) ? ((cq) ? \"WQ\" : \"CQ\") : \"EQ\"), qidx);\n\t\treturn -ENOMEM;\n\t}\n\n\t/* create the Cq first */\n\trc = lpfc_cq_create(phba, cq, eq,\n\t\t\t(qtype == LPFC_MBOX) ? LPFC_MCQ : LPFC_WCQ, qtype);\n\tif (rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"6086 Failed setup of CQ (%d), rc = 0x%x\\n\",\n\t\t\t\tqidx, (uint32_t)rc);\n\t\treturn rc;\n\t}\n\n\tif (qtype != LPFC_MBOX) {\n\t\t/* Setup cq_map for fast lookup */\n\t\tif (cq_map)\n\t\t\t*cq_map = cq->queue_id;\n\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"6087 CQ setup: cq[%d]-id=%d, parent eq[%d]-id=%d\\n\",\n\t\t\tqidx, cq->queue_id, qidx, eq->queue_id);\n\n\t\t/* create the wq */\n\t\trc = lpfc_wq_create(phba, wq, cq, qtype);\n\t\tif (rc) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"4618 Fail setup fastpath WQ (%d), rc = 0x%x\\n\",\n\t\t\t\tqidx, (uint32_t)rc);\n\t\t\t/* no need to tear down cq - caller will do so */\n\t\t\treturn rc;\n\t\t}\n\n\t\t/* Bind this CQ/WQ to the NVME ring */\n\t\tpring = wq->pring;\n\t\tpring->sli.sli4.wqp = (void *)wq;\n\t\tcq->pring = pring;\n\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"2593 WQ setup: wq[%d]-id=%d assoc=%d, cq[%d]-id=%d\\n\",\n\t\t\tqidx, wq->queue_id, wq->assoc_qid, qidx, cq->queue_id);\n\t} else {\n\t\trc = lpfc_mq_create(phba, wq, cq, LPFC_MBOX);\n\t\tif (rc) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0539 Failed setup of slow-path MQ: \"\n\t\t\t\t\t\"rc = 0x%x\\n\", rc);\n\t\t\t/* no need to tear down cq - caller will do so */\n\t\t\treturn rc;\n\t\t}\n\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"2589 MBX MQ setup: wq-id=%d, parent cq-id=%d\\n\",\n\t\t\tphba->sli4_hba.mbx_wq->queue_id,\n\t\t\tphba->sli4_hba.mbx_cq->queue_id);\n\t}\n\n\treturn 0;\n}\n\n/**\n * lpfc_setup_cq_lookup - Setup the CQ lookup table\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine will populate the cq_lookup table by all\n * available CQ queue_id's.\n **/\nstatic void\nlpfc_setup_cq_lookup(struct lpfc_hba *phba)\n{\n\tstruct lpfc_queue *eq, *childq;\n\tint qidx;\n\n\tmemset(phba->sli4_hba.cq_lookup, 0,\n\t       (sizeof(struct lpfc_queue *) * (phba->sli4_hba.cq_max + 1)));\n\t/* Loop thru all IRQ vectors */\n\tfor (qidx = 0; qidx < phba->cfg_irq_chann; qidx++) {\n\t\t/* Get the EQ corresponding to the IRQ vector */\n\t\teq = phba->sli4_hba.hba_eq_hdl[qidx].eq;\n\t\tif (!eq)\n\t\t\tcontinue;\n\t\t/* Loop through all CQs associated with that EQ */\n\t\tlist_for_each_entry(childq, &eq->child_list, list) {\n\t\t\tif (childq->queue_id > phba->sli4_hba.cq_max)\n\t\t\t\tcontinue;\n\t\t\tif (childq->subtype == LPFC_IO)\n\t\t\t\tphba->sli4_hba.cq_lookup[childq->queue_id] =\n\t\t\t\t\tchildq;\n\t\t}\n\t}\n}\n\n/**\n * lpfc_sli4_queue_setup - Set up all the SLI4 queues\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to set up all the SLI4 queues for the FCoE HBA\n * operation.\n *\n * Return codes\n *      0 - successful\n *      -ENOMEM - No available memory\n *      -EIO - The mailbox failed to complete successfully.\n **/\nint\nlpfc_sli4_queue_setup(struct lpfc_hba *phba)\n{\n\tuint32_t shdr_status, shdr_add_status;\n\tunion lpfc_sli4_cfg_shdr *shdr;\n\tstruct lpfc_vector_map_info *cpup;\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tLPFC_MBOXQ_t *mboxq;\n\tint qidx, cpu;\n\tuint32_t length, usdelay;\n\tint rc = -ENOMEM;\n\n\t/* Check for dual-ULP support */\n\tmboxq = (LPFC_MBOXQ_t *)mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\tif (!mboxq) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3249 Unable to allocate memory for \"\n\t\t\t\t\"QUERY_FW_CFG mailbox command\\n\");\n\t\treturn -ENOMEM;\n\t}\n\tlength = (sizeof(struct lpfc_mbx_query_fw_config) -\n\t\t  sizeof(struct lpfc_sli4_cfg_mhdr));\n\tlpfc_sli4_config(phba, mboxq, LPFC_MBOX_SUBSYSTEM_COMMON,\n\t\t\t LPFC_MBOX_OPCODE_QUERY_FW_CFG,\n\t\t\t length, LPFC_SLI4_MBX_EMBED);\n\n\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\n\tshdr = (union lpfc_sli4_cfg_shdr *)\n\t\t\t&mboxq->u.mqe.un.sli4_config.header.cfg_shdr;\n\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\n\tif (shdr_status || shdr_add_status || rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3250 QUERY_FW_CFG mailbox failed with status \"\n\t\t\t\t\"x%x add_status x%x, mbx status x%x\\n\",\n\t\t\t\tshdr_status, shdr_add_status, rc);\n\t\tif (rc != MBX_TIMEOUT)\n\t\t\tmempool_free(mboxq, phba->mbox_mem_pool);\n\t\trc = -ENXIO;\n\t\tgoto out_error;\n\t}\n\n\tphba->sli4_hba.fw_func_mode =\n\t\t\tmboxq->u.mqe.un.query_fw_cfg.rsp.function_mode;\n\tphba->sli4_hba.ulp0_mode = mboxq->u.mqe.un.query_fw_cfg.rsp.ulp0_mode;\n\tphba->sli4_hba.ulp1_mode = mboxq->u.mqe.un.query_fw_cfg.rsp.ulp1_mode;\n\tphba->sli4_hba.physical_port =\n\t\t\tmboxq->u.mqe.un.query_fw_cfg.rsp.physical_port;\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"3251 QUERY_FW_CFG: func_mode:x%x, ulp0_mode:x%x, \"\n\t\t\t\"ulp1_mode:x%x\\n\", phba->sli4_hba.fw_func_mode,\n\t\t\tphba->sli4_hba.ulp0_mode, phba->sli4_hba.ulp1_mode);\n\n\tif (rc != MBX_TIMEOUT)\n\t\tmempool_free(mboxq, phba->mbox_mem_pool);\n\n\t/*\n\t * Set up HBA Event Queues (EQs)\n\t */\n\tqp = phba->sli4_hba.hdwq;\n\n\t/* Set up HBA event queue */\n\tif (!qp) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3147 Fast-path EQs not allocated\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto out_error;\n\t}\n\n\t/* Loop thru all IRQ vectors */\n\tfor (qidx = 0; qidx < phba->cfg_irq_chann; qidx++) {\n\t\t/* Create HBA Event Queues (EQs) in order */\n\t\tfor_each_present_cpu(cpu) {\n\t\t\tcpup = &phba->sli4_hba.cpu_map[cpu];\n\n\t\t\t/* Look for the CPU thats using that vector with\n\t\t\t * LPFC_CPU_FIRST_IRQ set.\n\t\t\t */\n\t\t\tif (!(cpup->flag & LPFC_CPU_FIRST_IRQ))\n\t\t\t\tcontinue;\n\t\t\tif (qidx != cpup->eq)\n\t\t\t\tcontinue;\n\n\t\t\t/* Create an EQ for that vector */\n\t\t\trc = lpfc_eq_create(phba, qp[cpup->hdwq].hba_eq,\n\t\t\t\t\t    phba->cfg_fcp_imax);\n\t\t\tif (rc) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"0523 Failed setup of fast-path\"\n\t\t\t\t\t\t\" EQ (%d), rc = 0x%x\\n\",\n\t\t\t\t\t\tcpup->eq, (uint32_t)rc);\n\t\t\t\tgoto out_destroy;\n\t\t\t}\n\n\t\t\t/* Save the EQ for that vector in the hba_eq_hdl */\n\t\t\tphba->sli4_hba.hba_eq_hdl[cpup->eq].eq =\n\t\t\t\tqp[cpup->hdwq].hba_eq;\n\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\t\"2584 HBA EQ setup: queue[%d]-id=%d\\n\",\n\t\t\t\t\tcpup->eq,\n\t\t\t\t\tqp[cpup->hdwq].hba_eq->queue_id);\n\t\t}\n\t}\n\n\t/* Loop thru all Hardware Queues */\n\tfor (qidx = 0; qidx < phba->cfg_hdw_queue; qidx++) {\n\t\tcpu = lpfc_find_cpu_handle(phba, qidx, LPFC_FIND_BY_HDWQ);\n\t\tcpup = &phba->sli4_hba.cpu_map[cpu];\n\n\t\t/* Create the CQ/WQ corresponding to the Hardware Queue */\n\t\trc = lpfc_create_wq_cq(phba,\n\t\t\t\t       phba->sli4_hba.hdwq[cpup->hdwq].hba_eq,\n\t\t\t\t       qp[qidx].io_cq,\n\t\t\t\t       qp[qidx].io_wq,\n\t\t\t\t       &phba->sli4_hba.hdwq[qidx].io_cq_map,\n\t\t\t\t       qidx,\n\t\t\t\t       LPFC_IO);\n\t\tif (rc) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0535 Failed to setup fastpath \"\n\t\t\t\t\t\"IO WQ/CQ (%d), rc = 0x%x\\n\",\n\t\t\t\t\tqidx, (uint32_t)rc);\n\t\t\tgoto out_destroy;\n\t\t}\n\t}\n\n\t/*\n\t * Set up Slow Path Complete Queues (CQs)\n\t */\n\n\t/* Set up slow-path MBOX CQ/MQ */\n\n\tif (!phba->sli4_hba.mbx_cq || !phba->sli4_hba.mbx_wq) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0528 %s not allocated\\n\",\n\t\t\t\tphba->sli4_hba.mbx_cq ?\n\t\t\t\t\"Mailbox WQ\" : \"Mailbox CQ\");\n\t\trc = -ENOMEM;\n\t\tgoto out_destroy;\n\t}\n\n\trc = lpfc_create_wq_cq(phba, qp[0].hba_eq,\n\t\t\t       phba->sli4_hba.mbx_cq,\n\t\t\t       phba->sli4_hba.mbx_wq,\n\t\t\t       NULL, 0, LPFC_MBOX);\n\tif (rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"0529 Failed setup of mailbox WQ/CQ: rc = 0x%x\\n\",\n\t\t\t(uint32_t)rc);\n\t\tgoto out_destroy;\n\t}\n\tif (phba->nvmet_support) {\n\t\tif (!phba->sli4_hba.nvmet_cqset) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"3165 Fast-path NVME CQ Set \"\n\t\t\t\t\t\"array not allocated\\n\");\n\t\t\trc = -ENOMEM;\n\t\t\tgoto out_destroy;\n\t\t}\n\t\tif (phba->cfg_nvmet_mrq > 1) {\n\t\t\trc = lpfc_cq_create_set(phba,\n\t\t\t\t\tphba->sli4_hba.nvmet_cqset,\n\t\t\t\t\tqp,\n\t\t\t\t\tLPFC_WCQ, LPFC_NVMET);\n\t\t\tif (rc) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"3164 Failed setup of NVME CQ \"\n\t\t\t\t\t\t\"Set, rc = 0x%x\\n\",\n\t\t\t\t\t\t(uint32_t)rc);\n\t\t\t\tgoto out_destroy;\n\t\t\t}\n\t\t} else {\n\t\t\t/* Set up NVMET Receive Complete Queue */\n\t\t\trc = lpfc_cq_create(phba, phba->sli4_hba.nvmet_cqset[0],\n\t\t\t\t\t    qp[0].hba_eq,\n\t\t\t\t\t    LPFC_WCQ, LPFC_NVMET);\n\t\t\tif (rc) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"6089 Failed setup NVMET CQ: \"\n\t\t\t\t\t\t\"rc = 0x%x\\n\", (uint32_t)rc);\n\t\t\t\tgoto out_destroy;\n\t\t\t}\n\t\t\tphba->sli4_hba.nvmet_cqset[0]->chann = 0;\n\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\t\"6090 NVMET CQ setup: cq-id=%d, \"\n\t\t\t\t\t\"parent eq-id=%d\\n\",\n\t\t\t\t\tphba->sli4_hba.nvmet_cqset[0]->queue_id,\n\t\t\t\t\tqp[0].hba_eq->queue_id);\n\t\t}\n\t}\n\n\t/* Set up slow-path ELS WQ/CQ */\n\tif (!phba->sli4_hba.els_cq || !phba->sli4_hba.els_wq) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0530 ELS %s not allocated\\n\",\n\t\t\t\tphba->sli4_hba.els_cq ? \"WQ\" : \"CQ\");\n\t\trc = -ENOMEM;\n\t\tgoto out_destroy;\n\t}\n\trc = lpfc_create_wq_cq(phba, qp[0].hba_eq,\n\t\t\t       phba->sli4_hba.els_cq,\n\t\t\t       phba->sli4_hba.els_wq,\n\t\t\t       NULL, 0, LPFC_ELS);\n\tif (rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0525 Failed setup of ELS WQ/CQ: rc = 0x%x\\n\",\n\t\t\t\t(uint32_t)rc);\n\t\tgoto out_destroy;\n\t}\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"2590 ELS WQ setup: wq-id=%d, parent cq-id=%d\\n\",\n\t\t\tphba->sli4_hba.els_wq->queue_id,\n\t\t\tphba->sli4_hba.els_cq->queue_id);\n\n\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME) {\n\t\t/* Set up NVME LS Complete Queue */\n\t\tif (!phba->sli4_hba.nvmels_cq || !phba->sli4_hba.nvmels_wq) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"6091 LS %s not allocated\\n\",\n\t\t\t\t\tphba->sli4_hba.nvmels_cq ? \"WQ\" : \"CQ\");\n\t\t\trc = -ENOMEM;\n\t\t\tgoto out_destroy;\n\t\t}\n\t\trc = lpfc_create_wq_cq(phba, qp[0].hba_eq,\n\t\t\t\t       phba->sli4_hba.nvmels_cq,\n\t\t\t\t       phba->sli4_hba.nvmels_wq,\n\t\t\t\t       NULL, 0, LPFC_NVME_LS);\n\t\tif (rc) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0526 Failed setup of NVVME LS WQ/CQ: \"\n\t\t\t\t\t\"rc = 0x%x\\n\", (uint32_t)rc);\n\t\t\tgoto out_destroy;\n\t\t}\n\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"6096 ELS WQ setup: wq-id=%d, \"\n\t\t\t\t\"parent cq-id=%d\\n\",\n\t\t\t\tphba->sli4_hba.nvmels_wq->queue_id,\n\t\t\t\tphba->sli4_hba.nvmels_cq->queue_id);\n\t}\n\n\t/*\n\t * Create NVMET Receive Queue (RQ)\n\t */\n\tif (phba->nvmet_support) {\n\t\tif ((!phba->sli4_hba.nvmet_cqset) ||\n\t\t    (!phba->sli4_hba.nvmet_mrq_hdr) ||\n\t\t    (!phba->sli4_hba.nvmet_mrq_data)) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"6130 MRQ CQ Queues not \"\n\t\t\t\t\t\"allocated\\n\");\n\t\t\trc = -ENOMEM;\n\t\t\tgoto out_destroy;\n\t\t}\n\t\tif (phba->cfg_nvmet_mrq > 1) {\n\t\t\trc = lpfc_mrq_create(phba,\n\t\t\t\t\t     phba->sli4_hba.nvmet_mrq_hdr,\n\t\t\t\t\t     phba->sli4_hba.nvmet_mrq_data,\n\t\t\t\t\t     phba->sli4_hba.nvmet_cqset,\n\t\t\t\t\t     LPFC_NVMET);\n\t\t\tif (rc) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"6098 Failed setup of NVMET \"\n\t\t\t\t\t\t\"MRQ: rc = 0x%x\\n\",\n\t\t\t\t\t\t(uint32_t)rc);\n\t\t\t\tgoto out_destroy;\n\t\t\t}\n\n\t\t} else {\n\t\t\trc = lpfc_rq_create(phba,\n\t\t\t\t\t    phba->sli4_hba.nvmet_mrq_hdr[0],\n\t\t\t\t\t    phba->sli4_hba.nvmet_mrq_data[0],\n\t\t\t\t\t    phba->sli4_hba.nvmet_cqset[0],\n\t\t\t\t\t    LPFC_NVMET);\n\t\t\tif (rc) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"6057 Failed setup of NVMET \"\n\t\t\t\t\t\t\"Receive Queue: rc = 0x%x\\n\",\n\t\t\t\t\t\t(uint32_t)rc);\n\t\t\t\tgoto out_destroy;\n\t\t\t}\n\n\t\t\tlpfc_printf_log(\n\t\t\t\tphba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"6099 NVMET RQ setup: hdr-rq-id=%d, \"\n\t\t\t\t\"dat-rq-id=%d parent cq-id=%d\\n\",\n\t\t\t\tphba->sli4_hba.nvmet_mrq_hdr[0]->queue_id,\n\t\t\t\tphba->sli4_hba.nvmet_mrq_data[0]->queue_id,\n\t\t\t\tphba->sli4_hba.nvmet_cqset[0]->queue_id);\n\n\t\t}\n\t}\n\n\tif (!phba->sli4_hba.hdr_rq || !phba->sli4_hba.dat_rq) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0540 Receive Queue not allocated\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto out_destroy;\n\t}\n\n\trc = lpfc_rq_create(phba, phba->sli4_hba.hdr_rq, phba->sli4_hba.dat_rq,\n\t\t\t    phba->sli4_hba.els_cq, LPFC_USOL);\n\tif (rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0541 Failed setup of Receive Queue: \"\n\t\t\t\t\"rc = 0x%x\\n\", (uint32_t)rc);\n\t\tgoto out_destroy;\n\t}\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"2592 USL RQ setup: hdr-rq-id=%d, dat-rq-id=%d \"\n\t\t\t\"parent cq-id=%d\\n\",\n\t\t\tphba->sli4_hba.hdr_rq->queue_id,\n\t\t\tphba->sli4_hba.dat_rq->queue_id,\n\t\t\tphba->sli4_hba.els_cq->queue_id);\n\n\tif (phba->cfg_fcp_imax)\n\t\tusdelay = LPFC_SEC_TO_USEC / phba->cfg_fcp_imax;\n\telse\n\t\tusdelay = 0;\n\n\tfor (qidx = 0; qidx < phba->cfg_irq_chann;\n\t     qidx += LPFC_MAX_EQ_DELAY_EQID_CNT)\n\t\tlpfc_modify_hba_eq_delay(phba, qidx, LPFC_MAX_EQ_DELAY_EQID_CNT,\n\t\t\t\t\t usdelay);\n\n\tif (phba->sli4_hba.cq_max) {\n\t\tkfree(phba->sli4_hba.cq_lookup);\n\t\tphba->sli4_hba.cq_lookup = kcalloc((phba->sli4_hba.cq_max + 1),\n\t\t\tsizeof(struct lpfc_queue *), GFP_KERNEL);\n\t\tif (!phba->sli4_hba.cq_lookup) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0549 Failed setup of CQ Lookup table: \"\n\t\t\t\t\t\"size 0x%x\\n\", phba->sli4_hba.cq_max);\n\t\t\trc = -ENOMEM;\n\t\t\tgoto out_destroy;\n\t\t}\n\t\tlpfc_setup_cq_lookup(phba);\n\t}\n\treturn 0;\n\nout_destroy:\n\tlpfc_sli4_queue_unset(phba);\nout_error:\n\treturn rc;\n}\n\n/**\n * lpfc_sli4_queue_unset - Unset all the SLI4 queues\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to unset all the SLI4 queues with the FCoE HBA\n * operation.\n *\n * Return codes\n *      0 - successful\n *      -ENOMEM - No available memory\n *      -EIO - The mailbox failed to complete successfully.\n **/\nvoid\nlpfc_sli4_queue_unset(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tstruct lpfc_queue *eq;\n\tint qidx;\n\n\t/* Unset mailbox command work queue */\n\tif (phba->sli4_hba.mbx_wq)\n\t\tlpfc_mq_destroy(phba, phba->sli4_hba.mbx_wq);\n\n\t/* Unset NVME LS work queue */\n\tif (phba->sli4_hba.nvmels_wq)\n\t\tlpfc_wq_destroy(phba, phba->sli4_hba.nvmels_wq);\n\n\t/* Unset ELS work queue */\n\tif (phba->sli4_hba.els_wq)\n\t\tlpfc_wq_destroy(phba, phba->sli4_hba.els_wq);\n\n\t/* Unset unsolicited receive queue */\n\tif (phba->sli4_hba.hdr_rq)\n\t\tlpfc_rq_destroy(phba, phba->sli4_hba.hdr_rq,\n\t\t\t\tphba->sli4_hba.dat_rq);\n\n\t/* Unset mailbox command complete queue */\n\tif (phba->sli4_hba.mbx_cq)\n\t\tlpfc_cq_destroy(phba, phba->sli4_hba.mbx_cq);\n\n\t/* Unset ELS complete queue */\n\tif (phba->sli4_hba.els_cq)\n\t\tlpfc_cq_destroy(phba, phba->sli4_hba.els_cq);\n\n\t/* Unset NVME LS complete queue */\n\tif (phba->sli4_hba.nvmels_cq)\n\t\tlpfc_cq_destroy(phba, phba->sli4_hba.nvmels_cq);\n\n\tif (phba->nvmet_support) {\n\t\t/* Unset NVMET MRQ queue */\n\t\tif (phba->sli4_hba.nvmet_mrq_hdr) {\n\t\t\tfor (qidx = 0; qidx < phba->cfg_nvmet_mrq; qidx++)\n\t\t\t\tlpfc_rq_destroy(\n\t\t\t\t\tphba,\n\t\t\t\t\tphba->sli4_hba.nvmet_mrq_hdr[qidx],\n\t\t\t\t\tphba->sli4_hba.nvmet_mrq_data[qidx]);\n\t\t}\n\n\t\t/* Unset NVMET CQ Set complete queue */\n\t\tif (phba->sli4_hba.nvmet_cqset) {\n\t\t\tfor (qidx = 0; qidx < phba->cfg_nvmet_mrq; qidx++)\n\t\t\t\tlpfc_cq_destroy(\n\t\t\t\t\tphba, phba->sli4_hba.nvmet_cqset[qidx]);\n\t\t}\n\t}\n\n\t/* Unset fast-path SLI4 queues */\n\tif (phba->sli4_hba.hdwq) {\n\t\t/* Loop thru all Hardware Queues */\n\t\tfor (qidx = 0; qidx < phba->cfg_hdw_queue; qidx++) {\n\t\t\t/* Destroy the CQ/WQ corresponding to Hardware Queue */\n\t\t\tqp = &phba->sli4_hba.hdwq[qidx];\n\t\t\tlpfc_wq_destroy(phba, qp->io_wq);\n\t\t\tlpfc_cq_destroy(phba, qp->io_cq);\n\t\t}\n\t\t/* Loop thru all IRQ vectors */\n\t\tfor (qidx = 0; qidx < phba->cfg_irq_chann; qidx++) {\n\t\t\t/* Destroy the EQ corresponding to the IRQ vector */\n\t\t\teq = phba->sli4_hba.hba_eq_hdl[qidx].eq;\n\t\t\tlpfc_eq_destroy(phba, eq);\n\t\t}\n\t}\n\n\tkfree(phba->sli4_hba.cq_lookup);\n\tphba->sli4_hba.cq_lookup = NULL;\n\tphba->sli4_hba.cq_max = 0;\n}\n\n/**\n * lpfc_sli4_cq_event_pool_create - Create completion-queue event free pool\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to allocate and set up a pool of completion queue\n * events. The body of the completion queue event is a completion queue entry\n * CQE. For now, this pool is used for the interrupt service routine to queue\n * the following HBA completion queue events for the worker thread to process:\n *   - Mailbox asynchronous events\n *   - Receive queue completion unsolicited events\n * Later, this can be used for all the slow-path events.\n *\n * Return codes\n *      0 - successful\n *      -ENOMEM - No available memory\n **/\nstatic int\nlpfc_sli4_cq_event_pool_create(struct lpfc_hba *phba)\n{\n\tstruct lpfc_cq_event *cq_event;\n\tint i;\n\n\tfor (i = 0; i < (4 * phba->sli4_hba.cq_ecount); i++) {\n\t\tcq_event = kmalloc(sizeof(struct lpfc_cq_event), GFP_KERNEL);\n\t\tif (!cq_event)\n\t\t\tgoto out_pool_create_fail;\n\t\tlist_add_tail(&cq_event->list,\n\t\t\t      &phba->sli4_hba.sp_cqe_event_pool);\n\t}\n\treturn 0;\n\nout_pool_create_fail:\n\tlpfc_sli4_cq_event_pool_destroy(phba);\n\treturn -ENOMEM;\n}\n\n/**\n * lpfc_sli4_cq_event_pool_destroy - Free completion-queue event free pool\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to free the pool of completion queue events at\n * driver unload time. Note that, it is the responsibility of the driver\n * cleanup routine to free all the outstanding completion-queue events\n * allocated from this pool back into the pool before invoking this routine\n * to destroy the pool.\n **/\nstatic void\nlpfc_sli4_cq_event_pool_destroy(struct lpfc_hba *phba)\n{\n\tstruct lpfc_cq_event *cq_event, *next_cq_event;\n\n\tlist_for_each_entry_safe(cq_event, next_cq_event,\n\t\t\t\t &phba->sli4_hba.sp_cqe_event_pool, list) {\n\t\tlist_del(&cq_event->list);\n\t\tkfree(cq_event);\n\t}\n}\n\n/**\n * __lpfc_sli4_cq_event_alloc - Allocate a completion-queue event from free pool\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is the lock free version of the API invoked to allocate a\n * completion-queue event from the free pool.\n *\n * Return: Pointer to the newly allocated completion-queue event if successful\n *         NULL otherwise.\n **/\nstruct lpfc_cq_event *\n__lpfc_sli4_cq_event_alloc(struct lpfc_hba *phba)\n{\n\tstruct lpfc_cq_event *cq_event = NULL;\n\n\tlist_remove_head(&phba->sli4_hba.sp_cqe_event_pool, cq_event,\n\t\t\t struct lpfc_cq_event, list);\n\treturn cq_event;\n}\n\n/**\n * lpfc_sli4_cq_event_alloc - Allocate a completion-queue event from free pool\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is the lock version of the API invoked to allocate a\n * completion-queue event from the free pool.\n *\n * Return: Pointer to the newly allocated completion-queue event if successful\n *         NULL otherwise.\n **/\nstruct lpfc_cq_event *\nlpfc_sli4_cq_event_alloc(struct lpfc_hba *phba)\n{\n\tstruct lpfc_cq_event *cq_event;\n\tunsigned long iflags;\n\n\tspin_lock_irqsave(&phba->hbalock, iflags);\n\tcq_event = __lpfc_sli4_cq_event_alloc(phba);\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n\treturn cq_event;\n}\n\n/**\n * __lpfc_sli4_cq_event_release - Release a completion-queue event to free pool\n * @phba: pointer to lpfc hba data structure.\n * @cq_event: pointer to the completion queue event to be freed.\n *\n * This routine is the lock free version of the API invoked to release a\n * completion-queue event back into the free pool.\n **/\nvoid\n__lpfc_sli4_cq_event_release(struct lpfc_hba *phba,\n\t\t\t     struct lpfc_cq_event *cq_event)\n{\n\tlist_add_tail(&cq_event->list, &phba->sli4_hba.sp_cqe_event_pool);\n}\n\n/**\n * lpfc_sli4_cq_event_release - Release a completion-queue event to free pool\n * @phba: pointer to lpfc hba data structure.\n * @cq_event: pointer to the completion queue event to be freed.\n *\n * This routine is the lock version of the API invoked to release a\n * completion-queue event back into the free pool.\n **/\nvoid\nlpfc_sli4_cq_event_release(struct lpfc_hba *phba,\n\t\t\t   struct lpfc_cq_event *cq_event)\n{\n\tunsigned long iflags;\n\tspin_lock_irqsave(&phba->hbalock, iflags);\n\t__lpfc_sli4_cq_event_release(phba, cq_event);\n\tspin_unlock_irqrestore(&phba->hbalock, iflags);\n}\n\n/**\n * lpfc_sli4_cq_event_release_all - Release all cq events to the free pool\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is to free all the pending completion-queue events to the\n * back into the free pool for device reset.\n **/\nstatic void\nlpfc_sli4_cq_event_release_all(struct lpfc_hba *phba)\n{\n\tLIST_HEAD(cq_event_list);\n\tstruct lpfc_cq_event *cq_event;\n\tunsigned long iflags;\n\n\t/* Retrieve all the pending WCQEs from pending WCQE lists */\n\n\t/* Pending ELS XRI abort events */\n\tspin_lock_irqsave(&phba->sli4_hba.els_xri_abrt_list_lock, iflags);\n\tlist_splice_init(&phba->sli4_hba.sp_els_xri_aborted_work_queue,\n\t\t\t &cq_event_list);\n\tspin_unlock_irqrestore(&phba->sli4_hba.els_xri_abrt_list_lock, iflags);\n\n\t/* Pending asynnc events */\n\tspin_lock_irqsave(&phba->sli4_hba.asynce_list_lock, iflags);\n\tlist_splice_init(&phba->sli4_hba.sp_asynce_work_queue,\n\t\t\t &cq_event_list);\n\tspin_unlock_irqrestore(&phba->sli4_hba.asynce_list_lock, iflags);\n\n\twhile (!list_empty(&cq_event_list)) {\n\t\tlist_remove_head(&cq_event_list, cq_event,\n\t\t\t\t struct lpfc_cq_event, list);\n\t\tlpfc_sli4_cq_event_release(phba, cq_event);\n\t}\n}\n\n/**\n * lpfc_pci_function_reset - Reset pci function.\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to request a PCI function reset. It will destroys\n * all resources assigned to the PCI function which originates this request.\n *\n * Return codes\n *      0 - successful\n *      -ENOMEM - No available memory\n *      -EIO - The mailbox failed to complete successfully.\n **/\nint\nlpfc_pci_function_reset(struct lpfc_hba *phba)\n{\n\tLPFC_MBOXQ_t *mboxq;\n\tuint32_t rc = 0, if_type;\n\tuint32_t shdr_status, shdr_add_status;\n\tuint32_t rdy_chk;\n\tuint32_t port_reset = 0;\n\tunion lpfc_sli4_cfg_shdr *shdr;\n\tstruct lpfc_register reg_data;\n\tuint16_t devid;\n\n\tif_type = bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf);\n\tswitch (if_type) {\n\tcase LPFC_SLI_INTF_IF_TYPE_0:\n\t\tmboxq = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool,\n\t\t\t\t\t\t       GFP_KERNEL);\n\t\tif (!mboxq) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0494 Unable to allocate memory for \"\n\t\t\t\t\t\"issuing SLI_FUNCTION_RESET mailbox \"\n\t\t\t\t\t\"command\\n\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\t/* Setup PCI function reset mailbox-ioctl command */\n\t\tlpfc_sli4_config(phba, mboxq, LPFC_MBOX_SUBSYSTEM_COMMON,\n\t\t\t\t LPFC_MBOX_OPCODE_FUNCTION_RESET, 0,\n\t\t\t\t LPFC_SLI4_MBX_EMBED);\n\t\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\t\tshdr = (union lpfc_sli4_cfg_shdr *)\n\t\t\t&mboxq->u.mqe.un.sli4_config.header.cfg_shdr;\n\t\tshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\n\t\tshdr_add_status = bf_get(lpfc_mbox_hdr_add_status,\n\t\t\t\t\t &shdr->response);\n\t\tif (rc != MBX_TIMEOUT)\n\t\t\tmempool_free(mboxq, phba->mbox_mem_pool);\n\t\tif (shdr_status || shdr_add_status || rc) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0495 SLI_FUNCTION_RESET mailbox \"\n\t\t\t\t\t\"failed with status x%x add_status x%x,\"\n\t\t\t\t\t\" mbx status x%x\\n\",\n\t\t\t\t\tshdr_status, shdr_add_status, rc);\n\t\t\trc = -ENXIO;\n\t\t}\n\t\tbreak;\n\tcase LPFC_SLI_INTF_IF_TYPE_2:\n\tcase LPFC_SLI_INTF_IF_TYPE_6:\nwait:\n\t\t/*\n\t\t * Poll the Port Status Register and wait for RDY for\n\t\t * up to 30 seconds. If the port doesn't respond, treat\n\t\t * it as an error.\n\t\t */\n\t\tfor (rdy_chk = 0; rdy_chk < 1500; rdy_chk++) {\n\t\t\tif (lpfc_readl(phba->sli4_hba.u.if_type2.\n\t\t\t\tSTATUSregaddr, &reg_data.word0)) {\n\t\t\t\trc = -ENODEV;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tif (bf_get(lpfc_sliport_status_rdy, &reg_data))\n\t\t\t\tbreak;\n\t\t\tmsleep(20);\n\t\t}\n\n\t\tif (!bf_get(lpfc_sliport_status_rdy, &reg_data)) {\n\t\t\tphba->work_status[0] = readl(\n\t\t\t\tphba->sli4_hba.u.if_type2.ERR1regaddr);\n\t\t\tphba->work_status[1] = readl(\n\t\t\t\tphba->sli4_hba.u.if_type2.ERR2regaddr);\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"2890 Port not ready, port status reg \"\n\t\t\t\t\t\"0x%x error 1=0x%x, error 2=0x%x\\n\",\n\t\t\t\t\treg_data.word0,\n\t\t\t\t\tphba->work_status[0],\n\t\t\t\t\tphba->work_status[1]);\n\t\t\trc = -ENODEV;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (!port_reset) {\n\t\t\t/*\n\t\t\t * Reset the port now\n\t\t\t */\n\t\t\treg_data.word0 = 0;\n\t\t\tbf_set(lpfc_sliport_ctrl_end, &reg_data,\n\t\t\t       LPFC_SLIPORT_LITTLE_ENDIAN);\n\t\t\tbf_set(lpfc_sliport_ctrl_ip, &reg_data,\n\t\t\t       LPFC_SLIPORT_INIT_PORT);\n\t\t\twritel(reg_data.word0, phba->sli4_hba.u.if_type2.\n\t\t\t       CTRLregaddr);\n\t\t\t/* flush */\n\t\t\tpci_read_config_word(phba->pcidev,\n\t\t\t\t\t     PCI_DEVICE_ID, &devid);\n\n\t\t\tport_reset = 1;\n\t\t\tmsleep(20);\n\t\t\tgoto wait;\n\t\t} else if (bf_get(lpfc_sliport_status_rn, &reg_data)) {\n\t\t\trc = -ENODEV;\n\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\n\tcase LPFC_SLI_INTF_IF_TYPE_1:\n\tdefault:\n\t\tbreak;\n\t}\n\nout:\n\t/* Catch the not-ready port failure after a port reset. */\n\tif (rc) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3317 HBA not functional: IP Reset Failed \"\n\t\t\t\t\"try: echo fw_reset > board_mode\\n\");\n\t\trc = -ENODEV;\n\t}\n\n\treturn rc;\n}\n\n/**\n * lpfc_sli4_pci_mem_setup - Setup SLI4 HBA PCI memory space.\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to set up the PCI device memory space for device\n * with SLI-4 interface spec.\n *\n * Return codes\n * \t0 - successful\n * \tother values - error\n **/\nstatic int\nlpfc_sli4_pci_mem_setup(struct lpfc_hba *phba)\n{\n\tstruct pci_dev *pdev = phba->pcidev;\n\tunsigned long bar0map_len, bar1map_len, bar2map_len;\n\tint error;\n\tuint32_t if_type;\n\n\tif (!pdev)\n\t\treturn -ENODEV;\n\n\t/* Set the device DMA mask size */\n\terror = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64));\n\tif (error)\n\t\terror = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(32));\n\tif (error)\n\t\treturn error;\n\n\t/*\n\t * The BARs and register set definitions and offset locations are\n\t * dependent on the if_type.\n\t */\n\tif (pci_read_config_dword(pdev, LPFC_SLI_INTF,\n\t\t\t\t  &phba->sli4_hba.sli_intf.word0)) {\n\t\treturn -ENODEV;\n\t}\n\n\t/* There is no SLI3 failback for SLI4 devices. */\n\tif (bf_get(lpfc_sli_intf_valid, &phba->sli4_hba.sli_intf) !=\n\t    LPFC_SLI_INTF_VALID) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2894 SLI_INTF reg contents invalid \"\n\t\t\t\t\"sli_intf reg 0x%x\\n\",\n\t\t\t\tphba->sli4_hba.sli_intf.word0);\n\t\treturn -ENODEV;\n\t}\n\n\tif_type = bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf);\n\t/*\n\t * Get the bus address of SLI4 device Bar regions and the\n\t * number of bytes required by each mapping. The mapping of the\n\t * particular PCI BARs regions is dependent on the type of\n\t * SLI4 device.\n\t */\n\tif (pci_resource_start(pdev, PCI_64BIT_BAR0)) {\n\t\tphba->pci_bar0_map = pci_resource_start(pdev, PCI_64BIT_BAR0);\n\t\tbar0map_len = pci_resource_len(pdev, PCI_64BIT_BAR0);\n\n\t\t/*\n\t\t * Map SLI4 PCI Config Space Register base to a kernel virtual\n\t\t * addr\n\t\t */\n\t\tphba->sli4_hba.conf_regs_memmap_p =\n\t\t\tioremap(phba->pci_bar0_map, bar0map_len);\n\t\tif (!phba->sli4_hba.conf_regs_memmap_p) {\n\t\t\tdev_printk(KERN_ERR, &pdev->dev,\n\t\t\t\t   \"ioremap failed for SLI4 PCI config \"\n\t\t\t\t   \"registers.\\n\");\n\t\t\treturn -ENODEV;\n\t\t}\n\t\tphba->pci_bar0_memmap_p = phba->sli4_hba.conf_regs_memmap_p;\n\t\t/* Set up BAR0 PCI config space register memory map */\n\t\tlpfc_sli4_bar0_register_memmap(phba, if_type);\n\t} else {\n\t\tphba->pci_bar0_map = pci_resource_start(pdev, 1);\n\t\tbar0map_len = pci_resource_len(pdev, 1);\n\t\tif (if_type >= LPFC_SLI_INTF_IF_TYPE_2) {\n\t\t\tdev_printk(KERN_ERR, &pdev->dev,\n\t\t\t   \"FATAL - No BAR0 mapping for SLI4, if_type 2\\n\");\n\t\t\treturn -ENODEV;\n\t\t}\n\t\tphba->sli4_hba.conf_regs_memmap_p =\n\t\t\t\tioremap(phba->pci_bar0_map, bar0map_len);\n\t\tif (!phba->sli4_hba.conf_regs_memmap_p) {\n\t\t\tdev_printk(KERN_ERR, &pdev->dev,\n\t\t\t\t\"ioremap failed for SLI4 PCI config \"\n\t\t\t\t\"registers.\\n\");\n\t\t\treturn -ENODEV;\n\t\t}\n\t\tlpfc_sli4_bar0_register_memmap(phba, if_type);\n\t}\n\n\tif (if_type == LPFC_SLI_INTF_IF_TYPE_0) {\n\t\tif (pci_resource_start(pdev, PCI_64BIT_BAR2)) {\n\t\t\t/*\n\t\t\t * Map SLI4 if type 0 HBA Control Register base to a\n\t\t\t * kernel virtual address and setup the registers.\n\t\t\t */\n\t\t\tphba->pci_bar1_map = pci_resource_start(pdev,\n\t\t\t\t\t\t\t\tPCI_64BIT_BAR2);\n\t\t\tbar1map_len = pci_resource_len(pdev, PCI_64BIT_BAR2);\n\t\t\tphba->sli4_hba.ctrl_regs_memmap_p =\n\t\t\t\t\tioremap(phba->pci_bar1_map,\n\t\t\t\t\t\tbar1map_len);\n\t\t\tif (!phba->sli4_hba.ctrl_regs_memmap_p) {\n\t\t\t\tdev_err(&pdev->dev,\n\t\t\t\t\t   \"ioremap failed for SLI4 HBA \"\n\t\t\t\t\t    \"control registers.\\n\");\n\t\t\t\terror = -ENOMEM;\n\t\t\t\tgoto out_iounmap_conf;\n\t\t\t}\n\t\t\tphba->pci_bar2_memmap_p =\n\t\t\t\t\t phba->sli4_hba.ctrl_regs_memmap_p;\n\t\t\tlpfc_sli4_bar1_register_memmap(phba, if_type);\n\t\t} else {\n\t\t\terror = -ENOMEM;\n\t\t\tgoto out_iounmap_conf;\n\t\t}\n\t}\n\n\tif ((if_type == LPFC_SLI_INTF_IF_TYPE_6) &&\n\t    (pci_resource_start(pdev, PCI_64BIT_BAR2))) {\n\t\t/*\n\t\t * Map SLI4 if type 6 HBA Doorbell Register base to a kernel\n\t\t * virtual address and setup the registers.\n\t\t */\n\t\tphba->pci_bar1_map = pci_resource_start(pdev, PCI_64BIT_BAR2);\n\t\tbar1map_len = pci_resource_len(pdev, PCI_64BIT_BAR2);\n\t\tphba->sli4_hba.drbl_regs_memmap_p =\n\t\t\t\tioremap(phba->pci_bar1_map, bar1map_len);\n\t\tif (!phba->sli4_hba.drbl_regs_memmap_p) {\n\t\t\tdev_err(&pdev->dev,\n\t\t\t   \"ioremap failed for SLI4 HBA doorbell registers.\\n\");\n\t\t\terror = -ENOMEM;\n\t\t\tgoto out_iounmap_conf;\n\t\t}\n\t\tphba->pci_bar2_memmap_p = phba->sli4_hba.drbl_regs_memmap_p;\n\t\tlpfc_sli4_bar1_register_memmap(phba, if_type);\n\t}\n\n\tif (if_type == LPFC_SLI_INTF_IF_TYPE_0) {\n\t\tif (pci_resource_start(pdev, PCI_64BIT_BAR4)) {\n\t\t\t/*\n\t\t\t * Map SLI4 if type 0 HBA Doorbell Register base to\n\t\t\t * a kernel virtual address and setup the registers.\n\t\t\t */\n\t\t\tphba->pci_bar2_map = pci_resource_start(pdev,\n\t\t\t\t\t\t\t\tPCI_64BIT_BAR4);\n\t\t\tbar2map_len = pci_resource_len(pdev, PCI_64BIT_BAR4);\n\t\t\tphba->sli4_hba.drbl_regs_memmap_p =\n\t\t\t\t\tioremap(phba->pci_bar2_map,\n\t\t\t\t\t\tbar2map_len);\n\t\t\tif (!phba->sli4_hba.drbl_regs_memmap_p) {\n\t\t\t\tdev_err(&pdev->dev,\n\t\t\t\t\t   \"ioremap failed for SLI4 HBA\"\n\t\t\t\t\t   \" doorbell registers.\\n\");\n\t\t\t\terror = -ENOMEM;\n\t\t\t\tgoto out_iounmap_ctrl;\n\t\t\t}\n\t\t\tphba->pci_bar4_memmap_p =\n\t\t\t\t\tphba->sli4_hba.drbl_regs_memmap_p;\n\t\t\terror = lpfc_sli4_bar2_register_memmap(phba, LPFC_VF0);\n\t\t\tif (error)\n\t\t\t\tgoto out_iounmap_all;\n\t\t} else {\n\t\t\terror = -ENOMEM;\n\t\t\tgoto out_iounmap_all;\n\t\t}\n\t}\n\n\tif (if_type == LPFC_SLI_INTF_IF_TYPE_6 &&\n\t    pci_resource_start(pdev, PCI_64BIT_BAR4)) {\n\t\t/*\n\t\t * Map SLI4 if type 6 HBA DPP Register base to a kernel\n\t\t * virtual address and setup the registers.\n\t\t */\n\t\tphba->pci_bar2_map = pci_resource_start(pdev, PCI_64BIT_BAR4);\n\t\tbar2map_len = pci_resource_len(pdev, PCI_64BIT_BAR4);\n\t\tphba->sli4_hba.dpp_regs_memmap_p =\n\t\t\t\tioremap(phba->pci_bar2_map, bar2map_len);\n\t\tif (!phba->sli4_hba.dpp_regs_memmap_p) {\n\t\t\tdev_err(&pdev->dev,\n\t\t\t   \"ioremap failed for SLI4 HBA dpp registers.\\n\");\n\t\t\terror = -ENOMEM;\n\t\t\tgoto out_iounmap_ctrl;\n\t\t}\n\t\tphba->pci_bar4_memmap_p = phba->sli4_hba.dpp_regs_memmap_p;\n\t}\n\n\t/* Set up the EQ/CQ register handeling functions now */\n\tswitch (if_type) {\n\tcase LPFC_SLI_INTF_IF_TYPE_0:\n\tcase LPFC_SLI_INTF_IF_TYPE_2:\n\t\tphba->sli4_hba.sli4_eq_clr_intr = lpfc_sli4_eq_clr_intr;\n\t\tphba->sli4_hba.sli4_write_eq_db = lpfc_sli4_write_eq_db;\n\t\tphba->sli4_hba.sli4_write_cq_db = lpfc_sli4_write_cq_db;\n\t\tbreak;\n\tcase LPFC_SLI_INTF_IF_TYPE_6:\n\t\tphba->sli4_hba.sli4_eq_clr_intr = lpfc_sli4_if6_eq_clr_intr;\n\t\tphba->sli4_hba.sli4_write_eq_db = lpfc_sli4_if6_write_eq_db;\n\t\tphba->sli4_hba.sli4_write_cq_db = lpfc_sli4_if6_write_cq_db;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn 0;\n\nout_iounmap_all:\n\tiounmap(phba->sli4_hba.drbl_regs_memmap_p);\nout_iounmap_ctrl:\n\tiounmap(phba->sli4_hba.ctrl_regs_memmap_p);\nout_iounmap_conf:\n\tiounmap(phba->sli4_hba.conf_regs_memmap_p);\n\n\treturn error;\n}\n\n/**\n * lpfc_sli4_pci_mem_unset - Unset SLI4 HBA PCI memory space.\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to unset the PCI device memory space for device\n * with SLI-4 interface spec.\n **/\nstatic void\nlpfc_sli4_pci_mem_unset(struct lpfc_hba *phba)\n{\n\tuint32_t if_type;\n\tif_type = bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf);\n\n\tswitch (if_type) {\n\tcase LPFC_SLI_INTF_IF_TYPE_0:\n\t\tiounmap(phba->sli4_hba.drbl_regs_memmap_p);\n\t\tiounmap(phba->sli4_hba.ctrl_regs_memmap_p);\n\t\tiounmap(phba->sli4_hba.conf_regs_memmap_p);\n\t\tbreak;\n\tcase LPFC_SLI_INTF_IF_TYPE_2:\n\t\tiounmap(phba->sli4_hba.conf_regs_memmap_p);\n\t\tbreak;\n\tcase LPFC_SLI_INTF_IF_TYPE_6:\n\t\tiounmap(phba->sli4_hba.drbl_regs_memmap_p);\n\t\tiounmap(phba->sli4_hba.conf_regs_memmap_p);\n\t\tif (phba->sli4_hba.dpp_regs_memmap_p)\n\t\t\tiounmap(phba->sli4_hba.dpp_regs_memmap_p);\n\t\tbreak;\n\tcase LPFC_SLI_INTF_IF_TYPE_1:\n\tdefault:\n\t\tdev_printk(KERN_ERR, &phba->pcidev->dev,\n\t\t\t   \"FATAL - unsupported SLI4 interface type - %d\\n\",\n\t\t\t   if_type);\n\t\tbreak;\n\t}\n}\n\n/**\n * lpfc_sli_enable_msix - Enable MSI-X interrupt mode on SLI-3 device\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to enable the MSI-X interrupt vectors to device\n * with SLI-3 interface specs.\n *\n * Return codes\n *   0 - successful\n *   other values - error\n **/\nstatic int\nlpfc_sli_enable_msix(struct lpfc_hba *phba)\n{\n\tint rc;\n\tLPFC_MBOXQ_t *pmb;\n\n\t/* Set up MSI-X multi-message vectors */\n\trc = pci_alloc_irq_vectors(phba->pcidev,\n\t\t\tLPFC_MSIX_VECTORS, LPFC_MSIX_VECTORS, PCI_IRQ_MSIX);\n\tif (rc < 0) {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"0420 PCI enable MSI-X failed (%d)\\n\", rc);\n\t\tgoto vec_fail_out;\n\t}\n\n\t/*\n\t * Assign MSI-X vectors to interrupt handlers\n\t */\n\n\t/* vector-0 is associated to slow-path handler */\n\trc = request_irq(pci_irq_vector(phba->pcidev, 0),\n\t\t\t &lpfc_sli_sp_intr_handler, 0,\n\t\t\t LPFC_SP_DRIVER_HANDLER_NAME, phba);\n\tif (rc) {\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\"0421 MSI-X slow-path request_irq failed \"\n\t\t\t\t\"(%d)\\n\", rc);\n\t\tgoto msi_fail_out;\n\t}\n\n\t/* vector-1 is associated to fast-path handler */\n\trc = request_irq(pci_irq_vector(phba->pcidev, 1),\n\t\t\t &lpfc_sli_fp_intr_handler, 0,\n\t\t\t LPFC_FP_DRIVER_HANDLER_NAME, phba);\n\n\tif (rc) {\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\"0429 MSI-X fast-path request_irq failed \"\n\t\t\t\t\"(%d)\\n\", rc);\n\t\tgoto irq_fail_out;\n\t}\n\n\t/*\n\t * Configure HBA MSI-X attention conditions to messages\n\t */\n\tpmb = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\n\n\tif (!pmb) {\n\t\trc = -ENOMEM;\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0474 Unable to allocate memory for issuing \"\n\t\t\t\t\"MBOX_CONFIG_MSI command\\n\");\n\t\tgoto mem_fail_out;\n\t}\n\trc = lpfc_config_msi(phba, pmb);\n\tif (rc)\n\t\tgoto mbx_fail_out;\n\trc = lpfc_sli_issue_mbox(phba, pmb, MBX_POLL);\n\tif (rc != MBX_SUCCESS) {\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_MBOX,\n\t\t\t\t\"0351 Config MSI mailbox command failed, \"\n\t\t\t\t\"mbxCmd x%x, mbxStatus x%x\\n\",\n\t\t\t\tpmb->u.mb.mbxCommand, pmb->u.mb.mbxStatus);\n\t\tgoto mbx_fail_out;\n\t}\n\n\t/* Free memory allocated for mailbox command */\n\tmempool_free(pmb, phba->mbox_mem_pool);\n\treturn rc;\n\nmbx_fail_out:\n\t/* Free memory allocated for mailbox command */\n\tmempool_free(pmb, phba->mbox_mem_pool);\n\nmem_fail_out:\n\t/* free the irq already requested */\n\tfree_irq(pci_irq_vector(phba->pcidev, 1), phba);\n\nirq_fail_out:\n\t/* free the irq already requested */\n\tfree_irq(pci_irq_vector(phba->pcidev, 0), phba);\n\nmsi_fail_out:\n\t/* Unconfigure MSI-X capability structure */\n\tpci_free_irq_vectors(phba->pcidev);\n\nvec_fail_out:\n\treturn rc;\n}\n\n/**\n * lpfc_sli_enable_msi - Enable MSI interrupt mode on SLI-3 device.\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to enable the MSI interrupt mode to device with\n * SLI-3 interface spec. The kernel function pci_enable_msi() is called to\n * enable the MSI vector. The device driver is responsible for calling the\n * request_irq() to register MSI vector with a interrupt the handler, which\n * is done in this function.\n *\n * Return codes\n * \t0 - successful\n * \tother values - error\n */\nstatic int\nlpfc_sli_enable_msi(struct lpfc_hba *phba)\n{\n\tint rc;\n\n\trc = pci_enable_msi(phba->pcidev);\n\tif (!rc)\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"0462 PCI enable MSI mode success.\\n\");\n\telse {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"0471 PCI enable MSI mode failed (%d)\\n\", rc);\n\t\treturn rc;\n\t}\n\n\trc = request_irq(phba->pcidev->irq, lpfc_sli_intr_handler,\n\t\t\t 0, LPFC_DRIVER_NAME, phba);\n\tif (rc) {\n\t\tpci_disable_msi(phba->pcidev);\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\"0478 MSI request_irq failed (%d)\\n\", rc);\n\t}\n\treturn rc;\n}\n\n/**\n * lpfc_sli_enable_intr - Enable device interrupt to SLI-3 device.\n * @phba: pointer to lpfc hba data structure.\n * @cfg_mode: Interrupt configuration mode (INTx, MSI or MSI-X).\n *\n * This routine is invoked to enable device interrupt and associate driver's\n * interrupt handler(s) to interrupt vector(s) to device with SLI-3 interface\n * spec. Depends on the interrupt mode configured to the driver, the driver\n * will try to fallback from the configured interrupt mode to an interrupt\n * mode which is supported by the platform, kernel, and device in the order\n * of:\n * MSI-X -> MSI -> IRQ.\n *\n * Return codes\n *   0 - successful\n *   other values - error\n **/\nstatic uint32_t\nlpfc_sli_enable_intr(struct lpfc_hba *phba, uint32_t cfg_mode)\n{\n\tuint32_t intr_mode = LPFC_INTR_ERROR;\n\tint retval;\n\n\t/* Need to issue conf_port mbox cmd before conf_msi mbox cmd */\n\tretval = lpfc_sli_config_port(phba, LPFC_SLI_REV3);\n\tif (retval)\n\t\treturn intr_mode;\n\tphba->hba_flag &= ~HBA_NEEDS_CFG_PORT;\n\n\tif (cfg_mode == 2) {\n\t\t/* Now, try to enable MSI-X interrupt mode */\n\t\tretval = lpfc_sli_enable_msix(phba);\n\t\tif (!retval) {\n\t\t\t/* Indicate initialization to MSI-X mode */\n\t\t\tphba->intr_type = MSIX;\n\t\t\tintr_mode = 2;\n\t\t}\n\t}\n\n\t/* Fallback to MSI if MSI-X initialization failed */\n\tif (cfg_mode >= 1 && phba->intr_type == NONE) {\n\t\tretval = lpfc_sli_enable_msi(phba);\n\t\tif (!retval) {\n\t\t\t/* Indicate initialization to MSI mode */\n\t\t\tphba->intr_type = MSI;\n\t\t\tintr_mode = 1;\n\t\t}\n\t}\n\n\t/* Fallback to INTx if both MSI-X/MSI initalization failed */\n\tif (phba->intr_type == NONE) {\n\t\tretval = request_irq(phba->pcidev->irq, lpfc_sli_intr_handler,\n\t\t\t\t     IRQF_SHARED, LPFC_DRIVER_NAME, phba);\n\t\tif (!retval) {\n\t\t\t/* Indicate initialization to INTx mode */\n\t\t\tphba->intr_type = INTx;\n\t\t\tintr_mode = 0;\n\t\t}\n\t}\n\treturn intr_mode;\n}\n\n/**\n * lpfc_sli_disable_intr - Disable device interrupt to SLI-3 device.\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to disable device interrupt and disassociate the\n * driver's interrupt handler(s) from interrupt vector(s) to device with\n * SLI-3 interface spec. Depending on the interrupt mode, the driver will\n * release the interrupt vector(s) for the message signaled interrupt.\n **/\nstatic void\nlpfc_sli_disable_intr(struct lpfc_hba *phba)\n{\n\tint nr_irqs, i;\n\n\tif (phba->intr_type == MSIX)\n\t\tnr_irqs = LPFC_MSIX_VECTORS;\n\telse\n\t\tnr_irqs = 1;\n\n\tfor (i = 0; i < nr_irqs; i++)\n\t\tfree_irq(pci_irq_vector(phba->pcidev, i), phba);\n\tpci_free_irq_vectors(phba->pcidev);\n\n\t/* Reset interrupt management states */\n\tphba->intr_type = NONE;\n\tphba->sli.slistat.sli_intr = 0;\n}\n\n/**\n * lpfc_find_cpu_handle - Find the CPU that corresponds to the specified Queue\n * @phba: pointer to lpfc hba data structure.\n * @id: EQ vector index or Hardware Queue index\n * @match: LPFC_FIND_BY_EQ = match by EQ\n *         LPFC_FIND_BY_HDWQ = match by Hardware Queue\n * Return the CPU that matches the selection criteria\n */\nstatic uint16_t\nlpfc_find_cpu_handle(struct lpfc_hba *phba, uint16_t id, int match)\n{\n\tstruct lpfc_vector_map_info *cpup;\n\tint cpu;\n\n\t/* Loop through all CPUs */\n\tfor_each_present_cpu(cpu) {\n\t\tcpup = &phba->sli4_hba.cpu_map[cpu];\n\n\t\t/* If we are matching by EQ, there may be multiple CPUs using\n\t\t * using the same vector, so select the one with\n\t\t * LPFC_CPU_FIRST_IRQ set.\n\t\t */\n\t\tif ((match == LPFC_FIND_BY_EQ) &&\n\t\t    (cpup->flag & LPFC_CPU_FIRST_IRQ) &&\n\t\t    (cpup->eq == id))\n\t\t\treturn cpu;\n\n\t\t/* If matching by HDWQ, select the first CPU that matches */\n\t\tif ((match == LPFC_FIND_BY_HDWQ) && (cpup->hdwq == id))\n\t\t\treturn cpu;\n\t}\n\treturn 0;\n}\n\n#ifdef CONFIG_X86\n/**\n * lpfc_find_hyper - Determine if the CPU map entry is hyper-threaded\n * @phba: pointer to lpfc hba data structure.\n * @cpu: CPU map index\n * @phys_id: CPU package physical id\n * @core_id: CPU core id\n */\nstatic int\nlpfc_find_hyper(struct lpfc_hba *phba, int cpu,\n\t\tuint16_t phys_id, uint16_t core_id)\n{\n\tstruct lpfc_vector_map_info *cpup;\n\tint idx;\n\n\tfor_each_present_cpu(idx) {\n\t\tcpup = &phba->sli4_hba.cpu_map[idx];\n\t\t/* Does the cpup match the one we are looking for */\n\t\tif ((cpup->phys_id == phys_id) &&\n\t\t    (cpup->core_id == core_id) &&\n\t\t    (cpu != idx))\n\t\t\treturn 1;\n\t}\n\treturn 0;\n}\n#endif\n\n/*\n * lpfc_assign_eq_map_info - Assigns eq for vector_map structure\n * @phba: pointer to lpfc hba data structure.\n * @eqidx: index for eq and irq vector\n * @flag: flags to set for vector_map structure\n * @cpu: cpu used to index vector_map structure\n *\n * The routine assigns eq info into vector_map structure\n */\nstatic inline void\nlpfc_assign_eq_map_info(struct lpfc_hba *phba, uint16_t eqidx, uint16_t flag,\n\t\t\tunsigned int cpu)\n{\n\tstruct lpfc_vector_map_info *cpup = &phba->sli4_hba.cpu_map[cpu];\n\tstruct lpfc_hba_eq_hdl *eqhdl = lpfc_get_eq_hdl(eqidx);\n\n\tcpup->eq = eqidx;\n\tcpup->flag |= flag;\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"3336 Set Affinity: CPU %d irq %d eq %d flag x%x\\n\",\n\t\t\tcpu, eqhdl->irq, cpup->eq, cpup->flag);\n}\n\n/**\n * lpfc_cpu_map_array_init - Initialize cpu_map structure\n * @phba: pointer to lpfc hba data structure.\n *\n * The routine initializes the cpu_map array structure\n */\nstatic void\nlpfc_cpu_map_array_init(struct lpfc_hba *phba)\n{\n\tstruct lpfc_vector_map_info *cpup;\n\tstruct lpfc_eq_intr_info *eqi;\n\tint cpu;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tcpup = &phba->sli4_hba.cpu_map[cpu];\n\t\tcpup->phys_id = LPFC_VECTOR_MAP_EMPTY;\n\t\tcpup->core_id = LPFC_VECTOR_MAP_EMPTY;\n\t\tcpup->hdwq = LPFC_VECTOR_MAP_EMPTY;\n\t\tcpup->eq = LPFC_VECTOR_MAP_EMPTY;\n\t\tcpup->flag = 0;\n\t\teqi = per_cpu_ptr(phba->sli4_hba.eq_info, cpu);\n\t\tINIT_LIST_HEAD(&eqi->list);\n\t\teqi->icnt = 0;\n\t}\n}\n\n/**\n * lpfc_hba_eq_hdl_array_init - Initialize hba_eq_hdl structure\n * @phba: pointer to lpfc hba data structure.\n *\n * The routine initializes the hba_eq_hdl array structure\n */\nstatic void\nlpfc_hba_eq_hdl_array_init(struct lpfc_hba *phba)\n{\n\tstruct lpfc_hba_eq_hdl *eqhdl;\n\tint i;\n\n\tfor (i = 0; i < phba->cfg_irq_chann; i++) {\n\t\teqhdl = lpfc_get_eq_hdl(i);\n\t\teqhdl->irq = LPFC_VECTOR_MAP_EMPTY;\n\t\teqhdl->phba = phba;\n\t}\n}\n\n/**\n * lpfc_cpu_affinity_check - Check vector CPU affinity mappings\n * @phba: pointer to lpfc hba data structure.\n * @vectors: number of msix vectors allocated.\n *\n * The routine will figure out the CPU affinity assignment for every\n * MSI-X vector allocated for the HBA.\n * In addition, the CPU to IO channel mapping will be calculated\n * and the phba->sli4_hba.cpu_map array will reflect this.\n */\nstatic void\nlpfc_cpu_affinity_check(struct lpfc_hba *phba, int vectors)\n{\n\tint i, cpu, idx, next_idx, new_cpu, start_cpu, first_cpu;\n\tint max_phys_id, min_phys_id;\n\tint max_core_id, min_core_id;\n\tstruct lpfc_vector_map_info *cpup;\n\tstruct lpfc_vector_map_info *new_cpup;\n#ifdef CONFIG_X86\n\tstruct cpuinfo_x86 *cpuinfo;\n#endif\n#ifdef CONFIG_SCSI_LPFC_DEBUG_FS\n\tstruct lpfc_hdwq_stat *c_stat;\n#endif\n\n\tmax_phys_id = 0;\n\tmin_phys_id = LPFC_VECTOR_MAP_EMPTY;\n\tmax_core_id = 0;\n\tmin_core_id = LPFC_VECTOR_MAP_EMPTY;\n\n\t/* Update CPU map with physical id and core id of each CPU */\n\tfor_each_present_cpu(cpu) {\n\t\tcpup = &phba->sli4_hba.cpu_map[cpu];\n#ifdef CONFIG_X86\n\t\tcpuinfo = &cpu_data(cpu);\n\t\tcpup->phys_id = cpuinfo->phys_proc_id;\n\t\tcpup->core_id = cpuinfo->cpu_core_id;\n\t\tif (lpfc_find_hyper(phba, cpu, cpup->phys_id, cpup->core_id))\n\t\t\tcpup->flag |= LPFC_CPU_MAP_HYPER;\n#else\n\t\t/* No distinction between CPUs for other platforms */\n\t\tcpup->phys_id = 0;\n\t\tcpup->core_id = cpu;\n#endif\n\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"3328 CPU %d physid %d coreid %d flag x%x\\n\",\n\t\t\t\tcpu, cpup->phys_id, cpup->core_id, cpup->flag);\n\n\t\tif (cpup->phys_id > max_phys_id)\n\t\t\tmax_phys_id = cpup->phys_id;\n\t\tif (cpup->phys_id < min_phys_id)\n\t\t\tmin_phys_id = cpup->phys_id;\n\n\t\tif (cpup->core_id > max_core_id)\n\t\t\tmax_core_id = cpup->core_id;\n\t\tif (cpup->core_id < min_core_id)\n\t\t\tmin_core_id = cpup->core_id;\n\t}\n\n\t/* After looking at each irq vector assigned to this pcidev, its\n\t * possible to see that not ALL CPUs have been accounted for.\n\t * Next we will set any unassigned (unaffinitized) cpu map\n\t * entries to a IRQ on the same phys_id.\n\t */\n\tfirst_cpu = cpumask_first(cpu_present_mask);\n\tstart_cpu = first_cpu;\n\n\tfor_each_present_cpu(cpu) {\n\t\tcpup = &phba->sli4_hba.cpu_map[cpu];\n\n\t\t/* Is this CPU entry unassigned */\n\t\tif (cpup->eq == LPFC_VECTOR_MAP_EMPTY) {\n\t\t\t/* Mark CPU as IRQ not assigned by the kernel */\n\t\t\tcpup->flag |= LPFC_CPU_MAP_UNASSIGN;\n\n\t\t\t/* If so, find a new_cpup thats on the the SAME\n\t\t\t * phys_id as cpup. start_cpu will start where we\n\t\t\t * left off so all unassigned entries don't get assgined\n\t\t\t * the IRQ of the first entry.\n\t\t\t */\n\t\t\tnew_cpu = start_cpu;\n\t\t\tfor (i = 0; i < phba->sli4_hba.num_present_cpu; i++) {\n\t\t\t\tnew_cpup = &phba->sli4_hba.cpu_map[new_cpu];\n\t\t\t\tif (!(new_cpup->flag & LPFC_CPU_MAP_UNASSIGN) &&\n\t\t\t\t    (new_cpup->eq != LPFC_VECTOR_MAP_EMPTY) &&\n\t\t\t\t    (new_cpup->phys_id == cpup->phys_id))\n\t\t\t\t\tgoto found_same;\n\t\t\t\tnew_cpu = cpumask_next(\n\t\t\t\t\tnew_cpu, cpu_present_mask);\n\t\t\t\tif (new_cpu == nr_cpumask_bits)\n\t\t\t\t\tnew_cpu = first_cpu;\n\t\t\t}\n\t\t\t/* At this point, we leave the CPU as unassigned */\n\t\t\tcontinue;\nfound_same:\n\t\t\t/* We found a matching phys_id, so copy the IRQ info */\n\t\t\tcpup->eq = new_cpup->eq;\n\n\t\t\t/* Bump start_cpu to the next slot to minmize the\n\t\t\t * chance of having multiple unassigned CPU entries\n\t\t\t * selecting the same IRQ.\n\t\t\t */\n\t\t\tstart_cpu = cpumask_next(new_cpu, cpu_present_mask);\n\t\t\tif (start_cpu == nr_cpumask_bits)\n\t\t\t\tstart_cpu = first_cpu;\n\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\t\"3337 Set Affinity: CPU %d \"\n\t\t\t\t\t\"eq %d from peer cpu %d same \"\n\t\t\t\t\t\"phys_id (%d)\\n\",\n\t\t\t\t\tcpu, cpup->eq, new_cpu,\n\t\t\t\t\tcpup->phys_id);\n\t\t}\n\t}\n\n\t/* Set any unassigned cpu map entries to a IRQ on any phys_id */\n\tstart_cpu = first_cpu;\n\n\tfor_each_present_cpu(cpu) {\n\t\tcpup = &phba->sli4_hba.cpu_map[cpu];\n\n\t\t/* Is this entry unassigned */\n\t\tif (cpup->eq == LPFC_VECTOR_MAP_EMPTY) {\n\t\t\t/* Mark it as IRQ not assigned by the kernel */\n\t\t\tcpup->flag |= LPFC_CPU_MAP_UNASSIGN;\n\n\t\t\t/* If so, find a new_cpup thats on ANY phys_id\n\t\t\t * as the cpup. start_cpu will start where we\n\t\t\t * left off so all unassigned entries don't get\n\t\t\t * assigned the IRQ of the first entry.\n\t\t\t */\n\t\t\tnew_cpu = start_cpu;\n\t\t\tfor (i = 0; i < phba->sli4_hba.num_present_cpu; i++) {\n\t\t\t\tnew_cpup = &phba->sli4_hba.cpu_map[new_cpu];\n\t\t\t\tif (!(new_cpup->flag & LPFC_CPU_MAP_UNASSIGN) &&\n\t\t\t\t    (new_cpup->eq != LPFC_VECTOR_MAP_EMPTY))\n\t\t\t\t\tgoto found_any;\n\t\t\t\tnew_cpu = cpumask_next(\n\t\t\t\t\tnew_cpu, cpu_present_mask);\n\t\t\t\tif (new_cpu == nr_cpumask_bits)\n\t\t\t\t\tnew_cpu = first_cpu;\n\t\t\t}\n\t\t\t/* We should never leave an entry unassigned */\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\t\"3339 Set Affinity: CPU %d \"\n\t\t\t\t\t\"eq %d UNASSIGNED\\n\",\n\t\t\t\t\tcpup->hdwq, cpup->eq);\n\t\t\tcontinue;\nfound_any:\n\t\t\t/* We found an available entry, copy the IRQ info */\n\t\t\tcpup->eq = new_cpup->eq;\n\n\t\t\t/* Bump start_cpu to the next slot to minmize the\n\t\t\t * chance of having multiple unassigned CPU entries\n\t\t\t * selecting the same IRQ.\n\t\t\t */\n\t\t\tstart_cpu = cpumask_next(new_cpu, cpu_present_mask);\n\t\t\tif (start_cpu == nr_cpumask_bits)\n\t\t\t\tstart_cpu = first_cpu;\n\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\t\"3338 Set Affinity: CPU %d \"\n\t\t\t\t\t\"eq %d from peer cpu %d (%d/%d)\\n\",\n\t\t\t\t\tcpu, cpup->eq, new_cpu,\n\t\t\t\t\tnew_cpup->phys_id, new_cpup->core_id);\n\t\t}\n\t}\n\n\t/* Assign hdwq indices that are unique across all cpus in the map\n\t * that are also FIRST_CPUs.\n\t */\n\tidx = 0;\n\tfor_each_present_cpu(cpu) {\n\t\tcpup = &phba->sli4_hba.cpu_map[cpu];\n\n\t\t/* Only FIRST IRQs get a hdwq index assignment. */\n\t\tif (!(cpup->flag & LPFC_CPU_FIRST_IRQ))\n\t\t\tcontinue;\n\n\t\t/* 1 to 1, the first LPFC_CPU_FIRST_IRQ cpus to a unique hdwq */\n\t\tcpup->hdwq = idx;\n\t\tidx++;\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"3333 Set Affinity: CPU %d (phys %d core %d): \"\n\t\t\t\t\"hdwq %d eq %d flg x%x\\n\",\n\t\t\t\tcpu, cpup->phys_id, cpup->core_id,\n\t\t\t\tcpup->hdwq, cpup->eq, cpup->flag);\n\t}\n\t/* Associate a hdwq with each cpu_map entry\n\t * This will be 1 to 1 - hdwq to cpu, unless there are less\n\t * hardware queues then CPUs. For that case we will just round-robin\n\t * the available hardware queues as they get assigned to CPUs.\n\t * The next_idx is the idx from the FIRST_CPU loop above to account\n\t * for irq_chann < hdwq.  The idx is used for round-robin assignments\n\t * and needs to start at 0.\n\t */\n\tnext_idx = idx;\n\tstart_cpu = 0;\n\tidx = 0;\n\tfor_each_present_cpu(cpu) {\n\t\tcpup = &phba->sli4_hba.cpu_map[cpu];\n\n\t\t/* FIRST cpus are already mapped. */\n\t\tif (cpup->flag & LPFC_CPU_FIRST_IRQ)\n\t\t\tcontinue;\n\n\t\t/* If the cfg_irq_chann < cfg_hdw_queue, set the hdwq\n\t\t * of the unassigned cpus to the next idx so that all\n\t\t * hdw queues are fully utilized.\n\t\t */\n\t\tif (next_idx < phba->cfg_hdw_queue) {\n\t\t\tcpup->hdwq = next_idx;\n\t\t\tnext_idx++;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Not a First CPU and all hdw_queues are used.  Reuse a\n\t\t * Hardware Queue for another CPU, so be smart about it\n\t\t * and pick one that has its IRQ/EQ mapped to the same phys_id\n\t\t * (CPU package) and core_id.\n\t\t */\n\t\tnew_cpu = start_cpu;\n\t\tfor (i = 0; i < phba->sli4_hba.num_present_cpu; i++) {\n\t\t\tnew_cpup = &phba->sli4_hba.cpu_map[new_cpu];\n\t\t\tif (new_cpup->hdwq != LPFC_VECTOR_MAP_EMPTY &&\n\t\t\t    new_cpup->phys_id == cpup->phys_id &&\n\t\t\t    new_cpup->core_id == cpup->core_id) {\n\t\t\t\tgoto found_hdwq;\n\t\t\t}\n\t\t\tnew_cpu = cpumask_next(new_cpu, cpu_present_mask);\n\t\t\tif (new_cpu == nr_cpumask_bits)\n\t\t\t\tnew_cpu = first_cpu;\n\t\t}\n\n\t\t/* If we can't match both phys_id and core_id,\n\t\t * settle for just a phys_id match.\n\t\t */\n\t\tnew_cpu = start_cpu;\n\t\tfor (i = 0; i < phba->sli4_hba.num_present_cpu; i++) {\n\t\t\tnew_cpup = &phba->sli4_hba.cpu_map[new_cpu];\n\t\t\tif (new_cpup->hdwq != LPFC_VECTOR_MAP_EMPTY &&\n\t\t\t    new_cpup->phys_id == cpup->phys_id)\n\t\t\t\tgoto found_hdwq;\n\n\t\t\tnew_cpu = cpumask_next(new_cpu, cpu_present_mask);\n\t\t\tif (new_cpu == nr_cpumask_bits)\n\t\t\t\tnew_cpu = first_cpu;\n\t\t}\n\n\t\t/* Otherwise just round robin on cfg_hdw_queue */\n\t\tcpup->hdwq = idx % phba->cfg_hdw_queue;\n\t\tidx++;\n\t\tgoto logit;\n found_hdwq:\n\t\t/* We found an available entry, copy the IRQ info */\n\t\tstart_cpu = cpumask_next(new_cpu, cpu_present_mask);\n\t\tif (start_cpu == nr_cpumask_bits)\n\t\t\tstart_cpu = first_cpu;\n\t\tcpup->hdwq = new_cpup->hdwq;\n logit:\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"3335 Set Affinity: CPU %d (phys %d core %d): \"\n\t\t\t\t\"hdwq %d eq %d flg x%x\\n\",\n\t\t\t\tcpu, cpup->phys_id, cpup->core_id,\n\t\t\t\tcpup->hdwq, cpup->eq, cpup->flag);\n\t}\n\n\t/*\n\t * Initialize the cpu_map slots for not-present cpus in case\n\t * a cpu is hot-added. Perform a simple hdwq round robin assignment.\n\t */\n\tidx = 0;\n\tfor_each_possible_cpu(cpu) {\n\t\tcpup = &phba->sli4_hba.cpu_map[cpu];\n#ifdef CONFIG_SCSI_LPFC_DEBUG_FS\n\t\tc_stat = per_cpu_ptr(phba->sli4_hba.c_stat, cpu);\n\t\tc_stat->hdwq_no = cpup->hdwq;\n#endif\n\t\tif (cpup->hdwq != LPFC_VECTOR_MAP_EMPTY)\n\t\t\tcontinue;\n\n\t\tcpup->hdwq = idx++ % phba->cfg_hdw_queue;\n#ifdef CONFIG_SCSI_LPFC_DEBUG_FS\n\t\tc_stat->hdwq_no = cpup->hdwq;\n#endif\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"3340 Set Affinity: not present \"\n\t\t\t\t\"CPU %d hdwq %d\\n\",\n\t\t\t\tcpu, cpup->hdwq);\n\t}\n\n\t/* The cpu_map array will be used later during initialization\n\t * when EQ / CQ / WQs are allocated and configured.\n\t */\n\treturn;\n}\n\n/**\n * lpfc_cpuhp_get_eq\n *\n * @phba:   pointer to lpfc hba data structure.\n * @cpu:    cpu going offline\n * @eqlist: eq list to append to\n */\nstatic int\nlpfc_cpuhp_get_eq(struct lpfc_hba *phba, unsigned int cpu,\n\t\t  struct list_head *eqlist)\n{\n\tconst struct cpumask *maskp;\n\tstruct lpfc_queue *eq;\n\tstruct cpumask *tmp;\n\tu16 idx;\n\n\ttmp = kzalloc(cpumask_size(), GFP_KERNEL);\n\tif (!tmp)\n\t\treturn -ENOMEM;\n\n\tfor (idx = 0; idx < phba->cfg_irq_chann; idx++) {\n\t\tmaskp = pci_irq_get_affinity(phba->pcidev, idx);\n\t\tif (!maskp)\n\t\t\tcontinue;\n\t\t/*\n\t\t * if irq is not affinitized to the cpu going\n\t\t * then we don't need to poll the eq attached\n\t\t * to it.\n\t\t */\n\t\tif (!cpumask_and(tmp, maskp, cpumask_of(cpu)))\n\t\t\tcontinue;\n\t\t/* get the cpus that are online and are affini-\n\t\t * tized to this irq vector.  If the count is\n\t\t * more than 1 then cpuhp is not going to shut-\n\t\t * down this vector.  Since this cpu has not\n\t\t * gone offline yet, we need >1.\n\t\t */\n\t\tcpumask_and(tmp, maskp, cpu_online_mask);\n\t\tif (cpumask_weight(tmp) > 1)\n\t\t\tcontinue;\n\n\t\t/* Now that we have an irq to shutdown, get the eq\n\t\t * mapped to this irq.  Note: multiple hdwq's in\n\t\t * the software can share an eq, but eventually\n\t\t * only eq will be mapped to this vector\n\t\t */\n\t\teq = phba->sli4_hba.hba_eq_hdl[idx].eq;\n\t\tlist_add(&eq->_poll_list, eqlist);\n\t}\n\tkfree(tmp);\n\treturn 0;\n}\n\nstatic void __lpfc_cpuhp_remove(struct lpfc_hba *phba)\n{\n\tif (phba->sli_rev != LPFC_SLI_REV4)\n\t\treturn;\n\n\tcpuhp_state_remove_instance_nocalls(lpfc_cpuhp_state,\n\t\t\t\t\t    &phba->cpuhp);\n\t/*\n\t * unregistering the instance doesn't stop the polling\n\t * timer. Wait for the poll timer to retire.\n\t */\n\tsynchronize_rcu();\n\tdel_timer_sync(&phba->cpuhp_poll_timer);\n}\n\nstatic void lpfc_cpuhp_remove(struct lpfc_hba *phba)\n{\n\tif (phba->pport->fc_flag & FC_OFFLINE_MODE)\n\t\treturn;\n\n\t__lpfc_cpuhp_remove(phba);\n}\n\nstatic void lpfc_cpuhp_add(struct lpfc_hba *phba)\n{\n\tif (phba->sli_rev != LPFC_SLI_REV4)\n\t\treturn;\n\n\trcu_read_lock();\n\n\tif (!list_empty(&phba->poll_list))\n\t\tmod_timer(&phba->cpuhp_poll_timer,\n\t\t\t  jiffies + msecs_to_jiffies(LPFC_POLL_HB));\n\n\trcu_read_unlock();\n\n\tcpuhp_state_add_instance_nocalls(lpfc_cpuhp_state,\n\t\t\t\t\t &phba->cpuhp);\n}\n\nstatic int __lpfc_cpuhp_checks(struct lpfc_hba *phba, int *retval)\n{\n\tif (phba->pport->load_flag & FC_UNLOADING) {\n\t\t*retval = -EAGAIN;\n\t\treturn true;\n\t}\n\n\tif (phba->sli_rev != LPFC_SLI_REV4) {\n\t\t*retval = 0;\n\t\treturn true;\n\t}\n\n\t/* proceed with the hotplug */\n\treturn false;\n}\n\n/**\n * lpfc_irq_set_aff - set IRQ affinity\n * @eqhdl: EQ handle\n * @cpu: cpu to set affinity\n *\n **/\nstatic inline void\nlpfc_irq_set_aff(struct lpfc_hba_eq_hdl *eqhdl, unsigned int cpu)\n{\n\tcpumask_clear(&eqhdl->aff_mask);\n\tcpumask_set_cpu(cpu, &eqhdl->aff_mask);\n\tirq_set_status_flags(eqhdl->irq, IRQ_NO_BALANCING);\n\tirq_set_affinity_hint(eqhdl->irq, &eqhdl->aff_mask);\n}\n\n/**\n * lpfc_irq_clear_aff - clear IRQ affinity\n * @eqhdl: EQ handle\n *\n **/\nstatic inline void\nlpfc_irq_clear_aff(struct lpfc_hba_eq_hdl *eqhdl)\n{\n\tcpumask_clear(&eqhdl->aff_mask);\n\tirq_clear_status_flags(eqhdl->irq, IRQ_NO_BALANCING);\n}\n\n/**\n * lpfc_irq_rebalance - rebalances IRQ affinity according to cpuhp event\n * @phba: pointer to HBA context object.\n * @cpu: cpu going offline/online\n * @offline: true, cpu is going offline. false, cpu is coming online.\n *\n * If cpu is going offline, we'll try our best effort to find the next\n * online cpu on the phba's original_mask and migrate all offlining IRQ\n * affinities.\n *\n * If cpu is coming online, reaffinitize the IRQ back to the onlining cpu.\n *\n * Note: Call only if NUMA or NHT mode is enabled, otherwise rely on\n *\t PCI_IRQ_AFFINITY to auto-manage IRQ affinity.\n *\n **/\nstatic void\nlpfc_irq_rebalance(struct lpfc_hba *phba, unsigned int cpu, bool offline)\n{\n\tstruct lpfc_vector_map_info *cpup;\n\tstruct cpumask *aff_mask;\n\tunsigned int cpu_select, cpu_next, idx;\n\tconst struct cpumask *orig_mask;\n\n\tif (phba->irq_chann_mode == NORMAL_MODE)\n\t\treturn;\n\n\torig_mask = &phba->sli4_hba.irq_aff_mask;\n\n\tif (!cpumask_test_cpu(cpu, orig_mask))\n\t\treturn;\n\n\tcpup = &phba->sli4_hba.cpu_map[cpu];\n\n\tif (!(cpup->flag & LPFC_CPU_FIRST_IRQ))\n\t\treturn;\n\n\tif (offline) {\n\t\t/* Find next online CPU on original mask */\n\t\tcpu_next = cpumask_next_wrap(cpu, orig_mask, cpu, true);\n\t\tcpu_select = lpfc_next_online_cpu(orig_mask, cpu_next);\n\n\t\t/* Found a valid CPU */\n\t\tif ((cpu_select < nr_cpu_ids) && (cpu_select != cpu)) {\n\t\t\t/* Go through each eqhdl and ensure offlining\n\t\t\t * cpu aff_mask is migrated\n\t\t\t */\n\t\t\tfor (idx = 0; idx < phba->cfg_irq_chann; idx++) {\n\t\t\t\taff_mask = lpfc_get_aff_mask(idx);\n\n\t\t\t\t/* Migrate affinity */\n\t\t\t\tif (cpumask_test_cpu(cpu, aff_mask))\n\t\t\t\t\tlpfc_irq_set_aff(lpfc_get_eq_hdl(idx),\n\t\t\t\t\t\t\t cpu_select);\n\t\t\t}\n\t\t} else {\n\t\t\t/* Rely on irqbalance if no online CPUs left on NUMA */\n\t\t\tfor (idx = 0; idx < phba->cfg_irq_chann; idx++)\n\t\t\t\tlpfc_irq_clear_aff(lpfc_get_eq_hdl(idx));\n\t\t}\n\t} else {\n\t\t/* Migrate affinity back to this CPU */\n\t\tlpfc_irq_set_aff(lpfc_get_eq_hdl(cpup->eq), cpu);\n\t}\n}\n\nstatic int lpfc_cpu_offline(unsigned int cpu, struct hlist_node *node)\n{\n\tstruct lpfc_hba *phba = hlist_entry_safe(node, struct lpfc_hba, cpuhp);\n\tstruct lpfc_queue *eq, *next;\n\tLIST_HEAD(eqlist);\n\tint retval;\n\n\tif (!phba) {\n\t\tWARN_ONCE(!phba, \"cpu: %u. phba:NULL\", raw_smp_processor_id());\n\t\treturn 0;\n\t}\n\n\tif (__lpfc_cpuhp_checks(phba, &retval))\n\t\treturn retval;\n\n\tlpfc_irq_rebalance(phba, cpu, true);\n\n\tretval = lpfc_cpuhp_get_eq(phba, cpu, &eqlist);\n\tif (retval)\n\t\treturn retval;\n\n\t/* start polling on these eq's */\n\tlist_for_each_entry_safe(eq, next, &eqlist, _poll_list) {\n\t\tlist_del_init(&eq->_poll_list);\n\t\tlpfc_sli4_start_polling(eq);\n\t}\n\n\treturn 0;\n}\n\nstatic int lpfc_cpu_online(unsigned int cpu, struct hlist_node *node)\n{\n\tstruct lpfc_hba *phba = hlist_entry_safe(node, struct lpfc_hba, cpuhp);\n\tstruct lpfc_queue *eq, *next;\n\tunsigned int n;\n\tint retval;\n\n\tif (!phba) {\n\t\tWARN_ONCE(!phba, \"cpu: %u. phba:NULL\", raw_smp_processor_id());\n\t\treturn 0;\n\t}\n\n\tif (__lpfc_cpuhp_checks(phba, &retval))\n\t\treturn retval;\n\n\tlpfc_irq_rebalance(phba, cpu, false);\n\n\tlist_for_each_entry_safe(eq, next, &phba->poll_list, _poll_list) {\n\t\tn = lpfc_find_cpu_handle(phba, eq->hdwq, LPFC_FIND_BY_HDWQ);\n\t\tif (n == cpu)\n\t\t\tlpfc_sli4_stop_polling(eq);\n\t}\n\n\treturn 0;\n}\n\n/**\n * lpfc_sli4_enable_msix - Enable MSI-X interrupt mode to SLI-4 device\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to enable the MSI-X interrupt vectors to device\n * with SLI-4 interface spec.  It also allocates MSI-X vectors and maps them\n * to cpus on the system.\n *\n * When cfg_irq_numa is enabled, the adapter will only allocate vectors for\n * the number of cpus on the same numa node as this adapter.  The vectors are\n * allocated without requesting OS affinity mapping.  A vector will be\n * allocated and assigned to each online and offline cpu.  If the cpu is\n * online, then affinity will be set to that cpu.  If the cpu is offline, then\n * affinity will be set to the nearest peer cpu within the numa node that is\n * online.  If there are no online cpus within the numa node, affinity is not\n * assigned and the OS may do as it pleases. Note: cpu vector affinity mapping\n * is consistent with the way cpu online/offline is handled when cfg_irq_numa is\n * configured.\n *\n * If numa mode is not enabled and there is more than 1 vector allocated, then\n * the driver relies on the managed irq interface where the OS assigns vector to\n * cpu affinity.  The driver will then use that affinity mapping to setup its\n * cpu mapping table.\n *\n * Return codes\n * 0 - successful\n * other values - error\n **/\nstatic int\nlpfc_sli4_enable_msix(struct lpfc_hba *phba)\n{\n\tint vectors, rc, index;\n\tchar *name;\n\tconst struct cpumask *aff_mask = NULL;\n\tunsigned int cpu = 0, cpu_cnt = 0, cpu_select = nr_cpu_ids;\n\tstruct lpfc_vector_map_info *cpup;\n\tstruct lpfc_hba_eq_hdl *eqhdl;\n\tconst struct cpumask *maskp;\n\tunsigned int flags = PCI_IRQ_MSIX;\n\n\t/* Set up MSI-X multi-message vectors */\n\tvectors = phba->cfg_irq_chann;\n\n\tif (phba->irq_chann_mode != NORMAL_MODE)\n\t\taff_mask = &phba->sli4_hba.irq_aff_mask;\n\n\tif (aff_mask) {\n\t\tcpu_cnt = cpumask_weight(aff_mask);\n\t\tvectors = min(phba->cfg_irq_chann, cpu_cnt);\n\n\t\t/* cpu: iterates over aff_mask including offline or online\n\t\t * cpu_select: iterates over online aff_mask to set affinity\n\t\t */\n\t\tcpu = cpumask_first(aff_mask);\n\t\tcpu_select = lpfc_next_online_cpu(aff_mask, cpu);\n\t} else {\n\t\tflags |= PCI_IRQ_AFFINITY;\n\t}\n\n\trc = pci_alloc_irq_vectors(phba->pcidev, 1, vectors, flags);\n\tif (rc < 0) {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"0484 PCI enable MSI-X failed (%d)\\n\", rc);\n\t\tgoto vec_fail_out;\n\t}\n\tvectors = rc;\n\n\t/* Assign MSI-X vectors to interrupt handlers */\n\tfor (index = 0; index < vectors; index++) {\n\t\teqhdl = lpfc_get_eq_hdl(index);\n\t\tname = eqhdl->handler_name;\n\t\tmemset(name, 0, LPFC_SLI4_HANDLER_NAME_SZ);\n\t\tsnprintf(name, LPFC_SLI4_HANDLER_NAME_SZ,\n\t\t\t LPFC_DRIVER_HANDLER_NAME\"%d\", index);\n\n\t\teqhdl->idx = index;\n\t\trc = request_irq(pci_irq_vector(phba->pcidev, index),\n\t\t\t &lpfc_sli4_hba_intr_handler, 0,\n\t\t\t name, eqhdl);\n\t\tif (rc) {\n\t\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\t\"0486 MSI-X fast-path (%d) \"\n\t\t\t\t\t\"request_irq failed (%d)\\n\", index, rc);\n\t\t\tgoto cfg_fail_out;\n\t\t}\n\n\t\teqhdl->irq = pci_irq_vector(phba->pcidev, index);\n\n\t\tif (aff_mask) {\n\t\t\t/* If found a neighboring online cpu, set affinity */\n\t\t\tif (cpu_select < nr_cpu_ids)\n\t\t\t\tlpfc_irq_set_aff(eqhdl, cpu_select);\n\n\t\t\t/* Assign EQ to cpu_map */\n\t\t\tlpfc_assign_eq_map_info(phba, index,\n\t\t\t\t\t\tLPFC_CPU_FIRST_IRQ,\n\t\t\t\t\t\tcpu);\n\n\t\t\t/* Iterate to next offline or online cpu in aff_mask */\n\t\t\tcpu = cpumask_next(cpu, aff_mask);\n\n\t\t\t/* Find next online cpu in aff_mask to set affinity */\n\t\t\tcpu_select = lpfc_next_online_cpu(aff_mask, cpu);\n\t\t} else if (vectors == 1) {\n\t\t\tcpu = cpumask_first(cpu_present_mask);\n\t\t\tlpfc_assign_eq_map_info(phba, index, LPFC_CPU_FIRST_IRQ,\n\t\t\t\t\t\tcpu);\n\t\t} else {\n\t\t\tmaskp = pci_irq_get_affinity(phba->pcidev, index);\n\n\t\t\t/* Loop through all CPUs associated with vector index */\n\t\t\tfor_each_cpu_and(cpu, maskp, cpu_present_mask) {\n\t\t\t\tcpup = &phba->sli4_hba.cpu_map[cpu];\n\n\t\t\t\t/* If this is the first CPU thats assigned to\n\t\t\t\t * this vector, set LPFC_CPU_FIRST_IRQ.\n\t\t\t\t *\n\t\t\t\t * With certain platforms its possible that irq\n\t\t\t\t * vectors are affinitized to all the cpu's.\n\t\t\t\t * This can result in each cpu_map.eq to be set\n\t\t\t\t * to the last vector, resulting in overwrite\n\t\t\t\t * of all the previous cpu_map.eq.  Ensure that\n\t\t\t\t * each vector receives a place in cpu_map.\n\t\t\t\t * Later call to lpfc_cpu_affinity_check will\n\t\t\t\t * ensure we are nicely balanced out.\n\t\t\t\t */\n\t\t\t\tif (cpup->eq != LPFC_VECTOR_MAP_EMPTY)\n\t\t\t\t\tcontinue;\n\t\t\t\tlpfc_assign_eq_map_info(phba, index,\n\t\t\t\t\t\t\tLPFC_CPU_FIRST_IRQ,\n\t\t\t\t\t\t\tcpu);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (vectors != phba->cfg_irq_chann) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3238 Reducing IO channels to match number of \"\n\t\t\t\t\"MSI-X vectors, requested %d got %d\\n\",\n\t\t\t\tphba->cfg_irq_chann, vectors);\n\t\tif (phba->cfg_irq_chann > vectors)\n\t\t\tphba->cfg_irq_chann = vectors;\n\t}\n\n\treturn rc;\n\ncfg_fail_out:\n\t/* free the irq already requested */\n\tfor (--index; index >= 0; index--) {\n\t\teqhdl = lpfc_get_eq_hdl(index);\n\t\tlpfc_irq_clear_aff(eqhdl);\n\t\tirq_set_affinity_hint(eqhdl->irq, NULL);\n\t\tfree_irq(eqhdl->irq, eqhdl);\n\t}\n\n\t/* Unconfigure MSI-X capability structure */\n\tpci_free_irq_vectors(phba->pcidev);\n\nvec_fail_out:\n\treturn rc;\n}\n\n/**\n * lpfc_sli4_enable_msi - Enable MSI interrupt mode to SLI-4 device\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to enable the MSI interrupt mode to device with\n * SLI-4 interface spec. The kernel function pci_alloc_irq_vectors() is\n * called to enable the MSI vector. The device driver is responsible for\n * calling the request_irq() to register MSI vector with a interrupt the\n * handler, which is done in this function.\n *\n * Return codes\n * \t0 - successful\n * \tother values - error\n **/\nstatic int\nlpfc_sli4_enable_msi(struct lpfc_hba *phba)\n{\n\tint rc, index;\n\tunsigned int cpu;\n\tstruct lpfc_hba_eq_hdl *eqhdl;\n\n\trc = pci_alloc_irq_vectors(phba->pcidev, 1, 1,\n\t\t\t\t   PCI_IRQ_MSI | PCI_IRQ_AFFINITY);\n\tif (rc > 0)\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"0487 PCI enable MSI mode success.\\n\");\n\telse {\n\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\"0488 PCI enable MSI mode failed (%d)\\n\", rc);\n\t\treturn rc ? rc : -1;\n\t}\n\n\trc = request_irq(phba->pcidev->irq, lpfc_sli4_intr_handler,\n\t\t\t 0, LPFC_DRIVER_NAME, phba);\n\tif (rc) {\n\t\tpci_free_irq_vectors(phba->pcidev);\n\t\tlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\n\t\t\t\t\"0490 MSI request_irq failed (%d)\\n\", rc);\n\t\treturn rc;\n\t}\n\n\teqhdl = lpfc_get_eq_hdl(0);\n\teqhdl->irq = pci_irq_vector(phba->pcidev, 0);\n\n\tcpu = cpumask_first(cpu_present_mask);\n\tlpfc_assign_eq_map_info(phba, 0, LPFC_CPU_FIRST_IRQ, cpu);\n\n\tfor (index = 0; index < phba->cfg_irq_chann; index++) {\n\t\teqhdl = lpfc_get_eq_hdl(index);\n\t\teqhdl->idx = index;\n\t}\n\n\treturn 0;\n}\n\n/**\n * lpfc_sli4_enable_intr - Enable device interrupt to SLI-4 device\n * @phba: pointer to lpfc hba data structure.\n * @cfg_mode: Interrupt configuration mode (INTx, MSI or MSI-X).\n *\n * This routine is invoked to enable device interrupt and associate driver's\n * interrupt handler(s) to interrupt vector(s) to device with SLI-4\n * interface spec. Depends on the interrupt mode configured to the driver,\n * the driver will try to fallback from the configured interrupt mode to an\n * interrupt mode which is supported by the platform, kernel, and device in\n * the order of:\n * MSI-X -> MSI -> IRQ.\n *\n * Return codes\n * \t0 - successful\n * \tother values - error\n **/\nstatic uint32_t\nlpfc_sli4_enable_intr(struct lpfc_hba *phba, uint32_t cfg_mode)\n{\n\tuint32_t intr_mode = LPFC_INTR_ERROR;\n\tint retval, idx;\n\n\tif (cfg_mode == 2) {\n\t\t/* Preparation before conf_msi mbox cmd */\n\t\tretval = 0;\n\t\tif (!retval) {\n\t\t\t/* Now, try to enable MSI-X interrupt mode */\n\t\t\tretval = lpfc_sli4_enable_msix(phba);\n\t\t\tif (!retval) {\n\t\t\t\t/* Indicate initialization to MSI-X mode */\n\t\t\t\tphba->intr_type = MSIX;\n\t\t\t\tintr_mode = 2;\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Fallback to MSI if MSI-X initialization failed */\n\tif (cfg_mode >= 1 && phba->intr_type == NONE) {\n\t\tretval = lpfc_sli4_enable_msi(phba);\n\t\tif (!retval) {\n\t\t\t/* Indicate initialization to MSI mode */\n\t\t\tphba->intr_type = MSI;\n\t\t\tintr_mode = 1;\n\t\t}\n\t}\n\n\t/* Fallback to INTx if both MSI-X/MSI initalization failed */\n\tif (phba->intr_type == NONE) {\n\t\tretval = request_irq(phba->pcidev->irq, lpfc_sli4_intr_handler,\n\t\t\t\t     IRQF_SHARED, LPFC_DRIVER_NAME, phba);\n\t\tif (!retval) {\n\t\t\tstruct lpfc_hba_eq_hdl *eqhdl;\n\t\t\tunsigned int cpu;\n\n\t\t\t/* Indicate initialization to INTx mode */\n\t\t\tphba->intr_type = INTx;\n\t\t\tintr_mode = 0;\n\n\t\t\teqhdl = lpfc_get_eq_hdl(0);\n\t\t\teqhdl->irq = pci_irq_vector(phba->pcidev, 0);\n\n\t\t\tcpu = cpumask_first(cpu_present_mask);\n\t\t\tlpfc_assign_eq_map_info(phba, 0, LPFC_CPU_FIRST_IRQ,\n\t\t\t\t\t\tcpu);\n\t\t\tfor (idx = 0; idx < phba->cfg_irq_chann; idx++) {\n\t\t\t\teqhdl = lpfc_get_eq_hdl(idx);\n\t\t\t\teqhdl->idx = idx;\n\t\t\t}\n\t\t}\n\t}\n\treturn intr_mode;\n}\n\n/**\n * lpfc_sli4_disable_intr - Disable device interrupt to SLI-4 device\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to disable device interrupt and disassociate\n * the driver's interrupt handler(s) from interrupt vector(s) to device\n * with SLI-4 interface spec. Depending on the interrupt mode, the driver\n * will release the interrupt vector(s) for the message signaled interrupt.\n **/\nstatic void\nlpfc_sli4_disable_intr(struct lpfc_hba *phba)\n{\n\t/* Disable the currently initialized interrupt mode */\n\tif (phba->intr_type == MSIX) {\n\t\tint index;\n\t\tstruct lpfc_hba_eq_hdl *eqhdl;\n\n\t\t/* Free up MSI-X multi-message vectors */\n\t\tfor (index = 0; index < phba->cfg_irq_chann; index++) {\n\t\t\teqhdl = lpfc_get_eq_hdl(index);\n\t\t\tlpfc_irq_clear_aff(eqhdl);\n\t\t\tirq_set_affinity_hint(eqhdl->irq, NULL);\n\t\t\tfree_irq(eqhdl->irq, eqhdl);\n\t\t}\n\t} else {\n\t\tfree_irq(phba->pcidev->irq, phba);\n\t}\n\n\tpci_free_irq_vectors(phba->pcidev);\n\n\t/* Reset interrupt management states */\n\tphba->intr_type = NONE;\n\tphba->sli.slistat.sli_intr = 0;\n}\n\n/**\n * lpfc_unset_hba - Unset SLI3 hba device initialization\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is invoked to unset the HBA device initialization steps to\n * a device with SLI-3 interface spec.\n **/\nstatic void\nlpfc_unset_hba(struct lpfc_hba *phba)\n{\n\tstruct lpfc_vport *vport = phba->pport;\n\tstruct Scsi_Host  *shost = lpfc_shost_from_vport(vport);\n\n\tspin_lock_irq(shost->host_lock);\n\tvport->load_flag |= FC_UNLOADING;\n\tspin_unlock_irq(shost->host_lock);\n\n\tkfree(phba->vpi_bmask);\n\tkfree(phba->vpi_ids);\n\n\tlpfc_stop_hba_timers(phba);\n\n\tphba->pport->work_port_events = 0;\n\n\tlpfc_sli_hba_down(phba);\n\n\tlpfc_sli_brdrestart(phba);\n\n\tlpfc_sli_disable_intr(phba);\n\n\treturn;\n}\n\n/**\n * lpfc_sli4_xri_exchange_busy_wait - Wait for device XRI exchange busy\n * @phba: Pointer to HBA context object.\n *\n * This function is called in the SLI4 code path to wait for completion\n * of device's XRIs exchange busy. It will check the XRI exchange busy\n * on outstanding FCP and ELS I/Os every 10ms for up to 10 seconds; after\n * that, it will check the XRI exchange busy on outstanding FCP and ELS\n * I/Os every 30 seconds, log error message, and wait forever. Only when\n * all XRI exchange busy complete, the driver unload shall proceed with\n * invoking the function reset ioctl mailbox command to the CNA and the\n * the rest of the driver unload resource release.\n **/\nstatic void\nlpfc_sli4_xri_exchange_busy_wait(struct lpfc_hba *phba)\n{\n\tstruct lpfc_sli4_hdw_queue *qp;\n\tint idx, ccnt;\n\tint wait_time = 0;\n\tint io_xri_cmpl = 1;\n\tint nvmet_xri_cmpl = 1;\n\tint els_xri_cmpl = list_empty(&phba->sli4_hba.lpfc_abts_els_sgl_list);\n\n\t/* Driver just aborted IOs during the hba_unset process.  Pause\n\t * here to give the HBA time to complete the IO and get entries\n\t * into the abts lists.\n\t */\n\tmsleep(LPFC_XRI_EXCH_BUSY_WAIT_T1 * 5);\n\n\t/* Wait for NVME pending IO to flush back to transport. */\n\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME)\n\t\tlpfc_nvme_wait_for_io_drain(phba);\n\n\tccnt = 0;\n\tfor (idx = 0; idx < phba->cfg_hdw_queue; idx++) {\n\t\tqp = &phba->sli4_hba.hdwq[idx];\n\t\tio_xri_cmpl = list_empty(&qp->lpfc_abts_io_buf_list);\n\t\tif (!io_xri_cmpl) /* if list is NOT empty */\n\t\t\tccnt++;\n\t}\n\tif (ccnt)\n\t\tio_xri_cmpl = 0;\n\n\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME) {\n\t\tnvmet_xri_cmpl =\n\t\t\tlist_empty(&phba->sli4_hba.lpfc_abts_nvmet_ctx_list);\n\t}\n\n\twhile (!els_xri_cmpl || !io_xri_cmpl || !nvmet_xri_cmpl) {\n\t\tif (wait_time > LPFC_XRI_EXCH_BUSY_WAIT_TMO) {\n\t\t\tif (!nvmet_xri_cmpl)\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"6424 NVMET XRI exchange busy \"\n\t\t\t\t\t\t\"wait time: %d seconds.\\n\",\n\t\t\t\t\t\twait_time/1000);\n\t\t\tif (!io_xri_cmpl)\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"6100 IO XRI exchange busy \"\n\t\t\t\t\t\t\"wait time: %d seconds.\\n\",\n\t\t\t\t\t\twait_time/1000);\n\t\t\tif (!els_xri_cmpl)\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"2878 ELS XRI exchange busy \"\n\t\t\t\t\t\t\"wait time: %d seconds.\\n\",\n\t\t\t\t\t\twait_time/1000);\n\t\t\tmsleep(LPFC_XRI_EXCH_BUSY_WAIT_T2);\n\t\t\twait_time += LPFC_XRI_EXCH_BUSY_WAIT_T2;\n\t\t} else {\n\t\t\tmsleep(LPFC_XRI_EXCH_BUSY_WAIT_T1);\n\t\t\twait_time += LPFC_XRI_EXCH_BUSY_WAIT_T1;\n\t\t}\n\n\t\tccnt = 0;\n\t\tfor (idx = 0; idx < phba->cfg_hdw_queue; idx++) {\n\t\t\tqp = &phba->sli4_hba.hdwq[idx];\n\t\t\tio_xri_cmpl = list_empty(\n\t\t\t    &qp->lpfc_abts_io_buf_list);\n\t\t\tif (!io_xri_cmpl) /* if list is NOT empty */\n\t\t\t\tccnt++;\n\t\t}\n\t\tif (ccnt)\n\t\t\tio_xri_cmpl = 0;\n\n\t\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME) {\n\t\t\tnvmet_xri_cmpl = list_empty(\n\t\t\t\t&phba->sli4_hba.lpfc_abts_nvmet_ctx_list);\n\t\t}\n\t\tels_xri_cmpl =\n\t\t\tlist_empty(&phba->sli4_hba.lpfc_abts_els_sgl_list);\n\n\t}\n}\n\n/**\n * lpfc_sli4_hba_unset - Unset the fcoe hba\n * @phba: Pointer to HBA context object.\n *\n * This function is called in the SLI4 code path to reset the HBA's FCoE\n * function. The caller is not required to hold any lock. This routine\n * issues PCI function reset mailbox command to reset the FCoE function.\n * At the end of the function, it calls lpfc_hba_down_post function to\n * free any pending commands.\n **/\nstatic void\nlpfc_sli4_hba_unset(struct lpfc_hba *phba)\n{\n\tint wait_cnt = 0;\n\tLPFC_MBOXQ_t *mboxq;\n\tstruct pci_dev *pdev = phba->pcidev;\n\n\tlpfc_stop_hba_timers(phba);\n\tif (phba->pport)\n\t\tphba->sli4_hba.intr_enable = 0;\n\n\t/*\n\t * Gracefully wait out the potential current outstanding asynchronous\n\t * mailbox command.\n\t */\n\n\t/* First, block any pending async mailbox command from posted */\n\tspin_lock_irq(&phba->hbalock);\n\tphba->sli.sli_flag |= LPFC_SLI_ASYNC_MBX_BLK;\n\tspin_unlock_irq(&phba->hbalock);\n\t/* Now, trying to wait it out if we can */\n\twhile (phba->sli.sli_flag & LPFC_SLI_MBOX_ACTIVE) {\n\t\tmsleep(10);\n\t\tif (++wait_cnt > LPFC_ACTIVE_MBOX_WAIT_CNT)\n\t\t\tbreak;\n\t}\n\t/* Forcefully release the outstanding mailbox command if timed out */\n\tif (phba->sli.sli_flag & LPFC_SLI_MBOX_ACTIVE) {\n\t\tspin_lock_irq(&phba->hbalock);\n\t\tmboxq = phba->sli.mbox_active;\n\t\tmboxq->u.mb.mbxStatus = MBX_NOT_FINISHED;\n\t\t__lpfc_mbox_cmpl_put(phba, mboxq);\n\t\tphba->sli.sli_flag &= ~LPFC_SLI_MBOX_ACTIVE;\n\t\tphba->sli.mbox_active = NULL;\n\t\tspin_unlock_irq(&phba->hbalock);\n\t}\n\n\t/* Abort all iocbs associated with the hba */\n\tlpfc_sli_hba_iocb_abort(phba);\n\n\t/* Wait for completion of device XRI exchange busy */\n\tlpfc_sli4_xri_exchange_busy_wait(phba);\n\n\t/* per-phba callback de-registration for hotplug event */\n\tif (phba->pport)\n\t\tlpfc_cpuhp_remove(phba);\n\n\t/* Disable PCI subsystem interrupt */\n\tlpfc_sli4_disable_intr(phba);\n\n\t/* Disable SR-IOV if enabled */\n\tif (phba->cfg_sriov_nr_virtfn)\n\t\tpci_disable_sriov(pdev);\n\n\t/* Stop kthread signal shall trigger work_done one more time */\n\tkthread_stop(phba->worker_thread);\n\n\t/* Disable FW logging to host memory */\n\tlpfc_ras_stop_fwlog(phba);\n\n\t/* Unset the queues shared with the hardware then release all\n\t * allocated resources.\n\t */\n\tlpfc_sli4_queue_unset(phba);\n\tlpfc_sli4_queue_destroy(phba);\n\n\t/* Reset SLI4 HBA FCoE function */\n\tlpfc_pci_function_reset(phba);\n\n\t/* Free RAS DMA memory */\n\tif (phba->ras_fwlog.ras_enabled)\n\t\tlpfc_sli4_ras_dma_free(phba);\n\n\t/* Stop the SLI4 device port */\n\tif (phba->pport)\n\t\tphba->pport->work_port_events = 0;\n}\n\n /**\n * lpfc_pc_sli4_params_get - Get the SLI4_PARAMS port capabilities.\n * @phba: Pointer to HBA context object.\n * @mboxq: Pointer to the mailboxq memory for the mailbox command response.\n *\n * This function is called in the SLI4 code path to read the port's\n * sli4 capabilities.\n *\n * This function may be be called from any context that can block-wait\n * for the completion.  The expectation is that this routine is called\n * typically from probe_one or from the online routine.\n **/\nint\nlpfc_pc_sli4_params_get(struct lpfc_hba *phba, LPFC_MBOXQ_t *mboxq)\n{\n\tint rc;\n\tstruct lpfc_mqe *mqe;\n\tstruct lpfc_pc_sli4_params *sli4_params;\n\tuint32_t mbox_tmo;\n\n\trc = 0;\n\tmqe = &mboxq->u.mqe;\n\n\t/* Read the port's SLI4 Parameters port capabilities */\n\tlpfc_pc_sli4_params(mboxq);\n\tif (!phba->sli4_hba.intr_enable)\n\t\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\telse {\n\t\tmbox_tmo = lpfc_mbox_tmo_val(phba, mboxq);\n\t\trc = lpfc_sli_issue_mbox_wait(phba, mboxq, mbox_tmo);\n\t}\n\n\tif (unlikely(rc))\n\t\treturn 1;\n\n\tsli4_params = &phba->sli4_hba.pc_sli4_params;\n\tsli4_params->if_type = bf_get(if_type, &mqe->un.sli4_params);\n\tsli4_params->sli_rev = bf_get(sli_rev, &mqe->un.sli4_params);\n\tsli4_params->sli_family = bf_get(sli_family, &mqe->un.sli4_params);\n\tsli4_params->featurelevel_1 = bf_get(featurelevel_1,\n\t\t\t\t\t     &mqe->un.sli4_params);\n\tsli4_params->featurelevel_2 = bf_get(featurelevel_2,\n\t\t\t\t\t     &mqe->un.sli4_params);\n\tsli4_params->proto_types = mqe->un.sli4_params.word3;\n\tsli4_params->sge_supp_len = mqe->un.sli4_params.sge_supp_len;\n\tsli4_params->if_page_sz = bf_get(if_page_sz, &mqe->un.sli4_params);\n\tsli4_params->rq_db_window = bf_get(rq_db_window, &mqe->un.sli4_params);\n\tsli4_params->loopbk_scope = bf_get(loopbk_scope, &mqe->un.sli4_params);\n\tsli4_params->eq_pages_max = bf_get(eq_pages, &mqe->un.sli4_params);\n\tsli4_params->eqe_size = bf_get(eqe_size, &mqe->un.sli4_params);\n\tsli4_params->cq_pages_max = bf_get(cq_pages, &mqe->un.sli4_params);\n\tsli4_params->cqe_size = bf_get(cqe_size, &mqe->un.sli4_params);\n\tsli4_params->mq_pages_max = bf_get(mq_pages, &mqe->un.sli4_params);\n\tsli4_params->mqe_size = bf_get(mqe_size, &mqe->un.sli4_params);\n\tsli4_params->mq_elem_cnt = bf_get(mq_elem_cnt, &mqe->un.sli4_params);\n\tsli4_params->wq_pages_max = bf_get(wq_pages, &mqe->un.sli4_params);\n\tsli4_params->wqe_size = bf_get(wqe_size, &mqe->un.sli4_params);\n\tsli4_params->rq_pages_max = bf_get(rq_pages, &mqe->un.sli4_params);\n\tsli4_params->rqe_size = bf_get(rqe_size, &mqe->un.sli4_params);\n\tsli4_params->hdr_pages_max = bf_get(hdr_pages, &mqe->un.sli4_params);\n\tsli4_params->hdr_size = bf_get(hdr_size, &mqe->un.sli4_params);\n\tsli4_params->hdr_pp_align = bf_get(hdr_pp_align, &mqe->un.sli4_params);\n\tsli4_params->sgl_pages_max = bf_get(sgl_pages, &mqe->un.sli4_params);\n\tsli4_params->sgl_pp_align = bf_get(sgl_pp_align, &mqe->un.sli4_params);\n\n\t/* Make sure that sge_supp_len can be handled by the driver */\n\tif (sli4_params->sge_supp_len > LPFC_MAX_SGE_SIZE)\n\t\tsli4_params->sge_supp_len = LPFC_MAX_SGE_SIZE;\n\n\treturn rc;\n}\n\n/**\n * lpfc_get_sli4_parameters - Get the SLI4 Config PARAMETERS.\n * @phba: Pointer to HBA context object.\n * @mboxq: Pointer to the mailboxq memory for the mailbox command response.\n *\n * This function is called in the SLI4 code path to read the port's\n * sli4 capabilities.\n *\n * This function may be be called from any context that can block-wait\n * for the completion.  The expectation is that this routine is called\n * typically from probe_one or from the online routine.\n **/\nint\nlpfc_get_sli4_parameters(struct lpfc_hba *phba, LPFC_MBOXQ_t *mboxq)\n{\n\tint rc;\n\tstruct lpfc_mqe *mqe = &mboxq->u.mqe;\n\tstruct lpfc_pc_sli4_params *sli4_params;\n\tuint32_t mbox_tmo;\n\tint length;\n\tbool exp_wqcq_pages = true;\n\tstruct lpfc_sli4_parameters *mbx_sli4_parameters;\n\n\t/*\n\t * By default, the driver assumes the SLI4 port requires RPI\n\t * header postings.  The SLI4_PARAM response will correct this\n\t * assumption.\n\t */\n\tphba->sli4_hba.rpi_hdrs_in_use = 1;\n\n\t/* Read the port's SLI4 Config Parameters */\n\tlength = (sizeof(struct lpfc_mbx_get_sli4_parameters) -\n\t\t  sizeof(struct lpfc_sli4_cfg_mhdr));\n\tlpfc_sli4_config(phba, mboxq, LPFC_MBOX_SUBSYSTEM_COMMON,\n\t\t\t LPFC_MBOX_OPCODE_GET_SLI4_PARAMETERS,\n\t\t\t length, LPFC_SLI4_MBX_EMBED);\n\tif (!phba->sli4_hba.intr_enable)\n\t\trc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\n\telse {\n\t\tmbox_tmo = lpfc_mbox_tmo_val(phba, mboxq);\n\t\trc = lpfc_sli_issue_mbox_wait(phba, mboxq, mbox_tmo);\n\t}\n\tif (unlikely(rc))\n\t\treturn rc;\n\tsli4_params = &phba->sli4_hba.pc_sli4_params;\n\tmbx_sli4_parameters = &mqe->un.get_sli4_parameters.sli4_parameters;\n\tsli4_params->if_type = bf_get(cfg_if_type, mbx_sli4_parameters);\n\tsli4_params->sli_rev = bf_get(cfg_sli_rev, mbx_sli4_parameters);\n\tsli4_params->sli_family = bf_get(cfg_sli_family, mbx_sli4_parameters);\n\tsli4_params->featurelevel_1 = bf_get(cfg_sli_hint_1,\n\t\t\t\t\t     mbx_sli4_parameters);\n\tsli4_params->featurelevel_2 = bf_get(cfg_sli_hint_2,\n\t\t\t\t\t     mbx_sli4_parameters);\n\tif (bf_get(cfg_phwq, mbx_sli4_parameters))\n\t\tphba->sli3_options |= LPFC_SLI4_PHWQ_ENABLED;\n\telse\n\t\tphba->sli3_options &= ~LPFC_SLI4_PHWQ_ENABLED;\n\tsli4_params->sge_supp_len = mbx_sli4_parameters->sge_supp_len;\n\tsli4_params->loopbk_scope = bf_get(loopbk_scope, mbx_sli4_parameters);\n\tsli4_params->oas_supported = bf_get(cfg_oas, mbx_sli4_parameters);\n\tsli4_params->cqv = bf_get(cfg_cqv, mbx_sli4_parameters);\n\tsli4_params->mqv = bf_get(cfg_mqv, mbx_sli4_parameters);\n\tsli4_params->wqv = bf_get(cfg_wqv, mbx_sli4_parameters);\n\tsli4_params->rqv = bf_get(cfg_rqv, mbx_sli4_parameters);\n\tsli4_params->eqav = bf_get(cfg_eqav, mbx_sli4_parameters);\n\tsli4_params->cqav = bf_get(cfg_cqav, mbx_sli4_parameters);\n\tsli4_params->wqsize = bf_get(cfg_wqsize, mbx_sli4_parameters);\n\tsli4_params->bv1s = bf_get(cfg_bv1s, mbx_sli4_parameters);\n\tsli4_params->pls = bf_get(cfg_pvl, mbx_sli4_parameters);\n\tsli4_params->sgl_pages_max = bf_get(cfg_sgl_page_cnt,\n\t\t\t\t\t    mbx_sli4_parameters);\n\tsli4_params->wqpcnt = bf_get(cfg_wqpcnt, mbx_sli4_parameters);\n\tsli4_params->sgl_pp_align = bf_get(cfg_sgl_pp_align,\n\t\t\t\t\t   mbx_sli4_parameters);\n\tphba->sli4_hba.extents_in_use = bf_get(cfg_ext, mbx_sli4_parameters);\n\tphba->sli4_hba.rpi_hdrs_in_use = bf_get(cfg_hdrr, mbx_sli4_parameters);\n\n\t/* Check for Extended Pre-Registered SGL support */\n\tphba->cfg_xpsgl = bf_get(cfg_xpsgl, mbx_sli4_parameters);\n\n\t/* Check for firmware nvme support */\n\trc = (bf_get(cfg_nvme, mbx_sli4_parameters) &&\n\t\t     bf_get(cfg_xib, mbx_sli4_parameters));\n\n\tif (rc) {\n\t\t/* Save this to indicate the Firmware supports NVME */\n\t\tsli4_params->nvme = 1;\n\n\t\t/* Firmware NVME support, check driver FC4 NVME support */\n\t\tif (phba->cfg_enable_fc4_type == LPFC_ENABLE_FCP) {\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT | LOG_NVME,\n\t\t\t\t\t\"6133 Disabling NVME support: \"\n\t\t\t\t\t\"FC4 type not supported: x%x\\n\",\n\t\t\t\t\tphba->cfg_enable_fc4_type);\n\t\t\tgoto fcponly;\n\t\t}\n\t} else {\n\t\t/* No firmware NVME support, check driver FC4 NVME support */\n\t\tsli4_params->nvme = 0;\n\t\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT | LOG_NVME,\n\t\t\t\t\t\"6101 Disabling NVME support: Not \"\n\t\t\t\t\t\"supported by firmware (%d %d) x%x\\n\",\n\t\t\t\t\tbf_get(cfg_nvme, mbx_sli4_parameters),\n\t\t\t\t\tbf_get(cfg_xib, mbx_sli4_parameters),\n\t\t\t\t\tphba->cfg_enable_fc4_type);\nfcponly:\n\t\t\tphba->nvme_support = 0;\n\t\t\tphba->nvmet_support = 0;\n\t\t\tphba->cfg_nvmet_mrq = 0;\n\t\t\tphba->cfg_nvme_seg_cnt = 0;\n\n\t\t\t/* If no FC4 type support, move to just SCSI support */\n\t\t\tif (!(phba->cfg_enable_fc4_type & LPFC_ENABLE_FCP))\n\t\t\t\treturn -ENODEV;\n\t\t\tphba->cfg_enable_fc4_type = LPFC_ENABLE_FCP;\n\t\t}\n\t}\n\n\t/* If the NVME FC4 type is enabled, scale the sg_seg_cnt to\n\t * accommodate 512K and 1M IOs in a single nvme buf.\n\t */\n\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME)\n\t\tphba->cfg_sg_seg_cnt = LPFC_MAX_NVME_SEG_CNT;\n\n\t/* Only embed PBDE for if_type 6, PBDE support requires xib be set */\n\tif ((bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf) !=\n\t    LPFC_SLI_INTF_IF_TYPE_6) || (!bf_get(cfg_xib, mbx_sli4_parameters)))\n\t\tphba->cfg_enable_pbde = 0;\n\n\t/*\n\t * To support Suppress Response feature we must satisfy 3 conditions.\n\t * lpfc_suppress_rsp module parameter must be set (default).\n\t * In SLI4-Parameters Descriptor:\n\t * Extended Inline Buffers (XIB) must be supported.\n\t * Suppress Response IU Not Supported (SRIUNS) must NOT be supported\n\t * (double negative).\n\t */\n\tif (phba->cfg_suppress_rsp && bf_get(cfg_xib, mbx_sli4_parameters) &&\n\t    !(bf_get(cfg_nosr, mbx_sli4_parameters)))\n\t\tphba->sli.sli_flag |= LPFC_SLI_SUPPRESS_RSP;\n\telse\n\t\tphba->cfg_suppress_rsp = 0;\n\n\tif (bf_get(cfg_eqdr, mbx_sli4_parameters))\n\t\tphba->sli.sli_flag |= LPFC_SLI_USE_EQDR;\n\n\t/* Make sure that sge_supp_len can be handled by the driver */\n\tif (sli4_params->sge_supp_len > LPFC_MAX_SGE_SIZE)\n\t\tsli4_params->sge_supp_len = LPFC_MAX_SGE_SIZE;\n\n\t/*\n\t * Check whether the adapter supports an embedded copy of the\n\t * FCP CMD IU within the WQE for FCP_Ixxx commands. In order\n\t * to use this option, 128-byte WQEs must be used.\n\t */\n\tif (bf_get(cfg_ext_embed_cb, mbx_sli4_parameters))\n\t\tphba->fcp_embed_io = 1;\n\telse\n\t\tphba->fcp_embed_io = 0;\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT | LOG_NVME,\n\t\t\t\"6422 XIB %d PBDE %d: FCP %d NVME %d %d %d\\n\",\n\t\t\tbf_get(cfg_xib, mbx_sli4_parameters),\n\t\t\tphba->cfg_enable_pbde,\n\t\t\tphba->fcp_embed_io, phba->nvme_support,\n\t\t\tphba->cfg_nvme_embed_cmd, phba->cfg_suppress_rsp);\n\n\tif ((bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf) ==\n\t    LPFC_SLI_INTF_IF_TYPE_2) &&\n\t    (bf_get(lpfc_sli_intf_sli_family, &phba->sli4_hba.sli_intf) ==\n\t\t LPFC_SLI_INTF_FAMILY_LNCR_A0))\n\t\texp_wqcq_pages = false;\n\n\tif ((bf_get(cfg_cqpsize, mbx_sli4_parameters) & LPFC_CQ_16K_PAGE_SZ) &&\n\t    (bf_get(cfg_wqpsize, mbx_sli4_parameters) & LPFC_WQ_16K_PAGE_SZ) &&\n\t    exp_wqcq_pages &&\n\t    (sli4_params->wqsize & LPFC_WQ_SZ128_SUPPORT))\n\t\tphba->enab_exp_wqcq_pages = 1;\n\telse\n\t\tphba->enab_exp_wqcq_pages = 0;\n\t/*\n\t * Check if the SLI port supports MDS Diagnostics\n\t */\n\tif (bf_get(cfg_mds_diags, mbx_sli4_parameters))\n\t\tphba->mds_diags_support = 1;\n\telse\n\t\tphba->mds_diags_support = 0;\n\n\t/*\n\t * Check if the SLI port supports NSLER\n\t */\n\tif (bf_get(cfg_nsler, mbx_sli4_parameters))\n\t\tphba->nsler = 1;\n\telse\n\t\tphba->nsler = 0;\n\n\t/* Save PB info for use during HBA setup */\n\tsli4_params->mi_ver = bf_get(cfg_mi_ver, mbx_sli4_parameters);\n\tsli4_params->mib_bde_cnt = bf_get(cfg_mib_bde_cnt, mbx_sli4_parameters);\n\tsli4_params->mib_size = mbx_sli4_parameters->mib_size;\n\tsli4_params->mi_value = LPFC_DFLT_MIB_VAL;\n\n\t/* Next we check for Vendor MIB support */\n\tif (sli4_params->mi_ver && phba->cfg_enable_mi)\n\t\tphba->cfg_fdmi_on = LPFC_FDMI_SUPPORT;\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"6461 MIB attr %d  enable %d  FDMI %d buf %d:%d\\n\",\n\t\t\tsli4_params->mi_ver, phba->cfg_enable_mi,\n\t\t\tsli4_params->mi_value, sli4_params->mib_bde_cnt,\n\t\t\tsli4_params->mib_size);\n\treturn 0;\n}\n\n/**\n * lpfc_pci_probe_one_s3 - PCI probe func to reg SLI-3 device to PCI subsystem.\n * @pdev: pointer to PCI device\n * @pid: pointer to PCI device identifier\n *\n * This routine is to be called to attach a device with SLI-3 interface spec\n * to the PCI subsystem. When an Emulex HBA with SLI-3 interface spec is\n * presented on PCI bus, the kernel PCI subsystem looks at PCI device-specific\n * information of the device and driver to see if the driver state that it can\n * support this kind of device. If the match is successful, the driver core\n * invokes this routine. If this routine determines it can claim the HBA, it\n * does all the initialization that it needs to do to handle the HBA properly.\n *\n * Return code\n * \t0 - driver can claim the device\n * \tnegative value - driver can not claim the device\n **/\nstatic int\nlpfc_pci_probe_one_s3(struct pci_dev *pdev, const struct pci_device_id *pid)\n{\n\tstruct lpfc_hba   *phba;\n\tstruct lpfc_vport *vport = NULL;\n\tstruct Scsi_Host  *shost = NULL;\n\tint error;\n\tuint32_t cfg_mode, intr_mode;\n\n\t/* Allocate memory for HBA structure */\n\tphba = lpfc_hba_alloc(pdev);\n\tif (!phba)\n\t\treturn -ENOMEM;\n\n\t/* Perform generic PCI device enabling operation */\n\terror = lpfc_enable_pci_dev(phba);\n\tif (error)\n\t\tgoto out_free_phba;\n\n\t/* Set up SLI API function jump table for PCI-device group-0 HBAs */\n\terror = lpfc_api_table_setup(phba, LPFC_PCI_DEV_LP);\n\tif (error)\n\t\tgoto out_disable_pci_dev;\n\n\t/* Set up SLI-3 specific device PCI memory space */\n\terror = lpfc_sli_pci_mem_setup(phba);\n\tif (error) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"1402 Failed to set up pci memory space.\\n\");\n\t\tgoto out_disable_pci_dev;\n\t}\n\n\t/* Set up SLI-3 specific device driver resources */\n\terror = lpfc_sli_driver_resource_setup(phba);\n\tif (error) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"1404 Failed to set up driver resource.\\n\");\n\t\tgoto out_unset_pci_mem_s3;\n\t}\n\n\t/* Initialize and populate the iocb list per host */\n\n\terror = lpfc_init_iocb_list(phba, LPFC_IOCB_LIST_CNT);\n\tif (error) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"1405 Failed to initialize iocb list.\\n\");\n\t\tgoto out_unset_driver_resource_s3;\n\t}\n\n\t/* Set up common device driver resources */\n\terror = lpfc_setup_driver_resource_phase2(phba);\n\tif (error) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"1406 Failed to set up driver resource.\\n\");\n\t\tgoto out_free_iocb_list;\n\t}\n\n\t/* Get the default values for Model Name and Description */\n\tlpfc_get_hba_model_desc(phba, phba->ModelName, phba->ModelDesc);\n\n\t/* Create SCSI host to the physical port */\n\terror = lpfc_create_shost(phba);\n\tif (error) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"1407 Failed to create scsi host.\\n\");\n\t\tgoto out_unset_driver_resource;\n\t}\n\n\t/* Configure sysfs attributes */\n\tvport = phba->pport;\n\terror = lpfc_alloc_sysfs_attr(vport);\n\tif (error) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"1476 Failed to allocate sysfs attr\\n\");\n\t\tgoto out_destroy_shost;\n\t}\n\n\tshost = lpfc_shost_from_vport(vport); /* save shost for error cleanup */\n\t/* Now, trying to enable interrupt and bring up the device */\n\tcfg_mode = phba->cfg_use_msi;\n\twhile (true) {\n\t\t/* Put device to a known state before enabling interrupt */\n\t\tlpfc_stop_port(phba);\n\t\t/* Configure and enable interrupt */\n\t\tintr_mode = lpfc_sli_enable_intr(phba, cfg_mode);\n\t\tif (intr_mode == LPFC_INTR_ERROR) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"0431 Failed to enable interrupt.\\n\");\n\t\t\terror = -ENODEV;\n\t\t\tgoto out_free_sysfs_attr;\n\t\t}\n\t\t/* SLI-3 HBA setup */\n\t\tif (lpfc_sli_hba_setup(phba)) {\n\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\"1477 Failed to set up hba\\n\");\n\t\t\terror = -ENODEV;\n\t\t\tgoto out_remove_device;\n\t\t}\n\n\t\t/* Wait 50ms for the interrupts of previous mailbox commands */\n\t\tmsleep(50);\n\t\t/* Check active interrupts on message signaled interrupts */\n\t\tif (intr_mode == 0 ||\n\t\t    phba->sli.slistat.sli_intr > LPFC_MSIX_VECTORS) {\n\t\t\t/* Log the current active interrupt mode */\n\t\t\tphba->intr_mode = intr_mode;\n\t\t\tlpfc_log_intr_mode(phba, intr_mode);\n\t\t\tbreak;\n\t\t} else {\n\t\t\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\t\t\"0447 Configure interrupt mode (%d) \"\n\t\t\t\t\t\"failed active interrupt test.\\n\",\n\t\t\t\t\tintr_mode);\n\t\t\t/* Disable the current interrupt mode */\n\t\t\tlpfc_sli_disable_intr(phba);\n\t\t\t/* Try next level of interrupt mode */\n\t\t\tcfg_mode = --intr_mode;\n\t\t}\n\t}\n\n\t/* Perform post initialization setup */\n\tlpfc_post_init_setup(phba);\n\n\t/* Check if there are static vports to be created. */\n\tlpfc_create_static_vport(phba);\n\n\treturn 0;\n\nout_remove_device:\n\tlpfc_unset_hba(phba);\nout_free_sysfs_attr:\n\tlpfc_free_sysfs_attr(vport);\nout_destroy_shost:\n\tlpfc_destroy_shost(phba);\nout_unset_driver_resource:\n\tlpfc_unset_driver_resource_phase2(phba);\nout_free_iocb_list:\n\tlpfc_free_iocb_list(phba);\nout_unset_driver_resource_s3:\n\tlpfc_sli_driver_resource_unset(phba);\nout_unset_pci_mem_s3:\n\tlpfc_sli_pci_mem_unset(phba);\nout_disable_pci_dev:\n\tlpfc_disable_pci_dev(phba);\n\tif (shost)\n\t\tscsi_host_put(shost);\nout_free_phba:\n\tlpfc_hba_free(phba);\n\treturn error;\n}\n\n/**\n * lpfc_pci_remove_one_s3 - PCI func to unreg SLI-3 device from PCI subsystem.\n * @pdev: pointer to PCI device\n *\n * This routine is to be called to disattach a device with SLI-3 interface\n * spec from PCI subsystem. When an Emulex HBA with SLI-3 interface spec is\n * removed from PCI bus, it performs all the necessary cleanup for the HBA\n * device to be removed from the PCI subsystem properly.\n **/\nstatic void\nlpfc_pci_remove_one_s3(struct pci_dev *pdev)\n{\n\tstruct Scsi_Host  *shost = pci_get_drvdata(pdev);\n\tstruct lpfc_vport *vport = (struct lpfc_vport *) shost->hostdata;\n\tstruct lpfc_vport **vports;\n\tstruct lpfc_hba   *phba = vport->phba;\n\tint i;\n\n\tspin_lock_irq(&phba->hbalock);\n\tvport->load_flag |= FC_UNLOADING;\n\tspin_unlock_irq(&phba->hbalock);\n\n\tlpfc_free_sysfs_attr(vport);\n\n\t/* Release all the vports against this physical port */\n\tvports = lpfc_create_vport_work_array(phba);\n\tif (vports != NULL)\n\t\tfor (i = 0; i <= phba->max_vports && vports[i] != NULL; i++) {\n\t\t\tif (vports[i]->port_type == LPFC_PHYSICAL_PORT)\n\t\t\t\tcontinue;\n\t\t\tfc_vport_terminate(vports[i]->fc_vport);\n\t\t}\n\tlpfc_destroy_vport_work_array(phba, vports);\n\n\t/* Remove FC host with the physical port */\n\tfc_remove_host(shost);\n\tscsi_remove_host(shost);\n\n\t/* Clean up all nodes, mailboxes and IOs. */\n\tlpfc_cleanup(vport);\n\n\t/*\n\t * Bring down the SLI Layer. This step disable all interrupts,\n\t * clears the rings, discards all mailbox commands, and resets\n\t * the HBA.\n\t */\n\n\t/* HBA interrupt will be disabled after this call */\n\tlpfc_sli_hba_down(phba);\n\t/* Stop kthread signal shall trigger work_done one more time */\n\tkthread_stop(phba->worker_thread);\n\t/* Final cleanup of txcmplq and reset the HBA */\n\tlpfc_sli_brdrestart(phba);\n\n\tkfree(phba->vpi_bmask);\n\tkfree(phba->vpi_ids);\n\n\tlpfc_stop_hba_timers(phba);\n\tspin_lock_irq(&phba->port_list_lock);\n\tlist_del_init(&vport->listentry);\n\tspin_unlock_irq(&phba->port_list_lock);\n\n\tlpfc_debugfs_terminate(vport);\n\n\t/* Disable SR-IOV if enabled */\n\tif (phba->cfg_sriov_nr_virtfn)\n\t\tpci_disable_sriov(pdev);\n\n\t/* Disable interrupt */\n\tlpfc_sli_disable_intr(phba);\n\n\tscsi_host_put(shost);\n\n\t/*\n\t * Call scsi_free before mem_free since scsi bufs are released to their\n\t * corresponding pools here.\n\t */\n\tlpfc_scsi_free(phba);\n\tlpfc_free_iocb_list(phba);\n\n\tlpfc_mem_free_all(phba);\n\n\tdma_free_coherent(&pdev->dev, lpfc_sli_hbq_size(),\n\t\t\t  phba->hbqslimp.virt, phba->hbqslimp.phys);\n\n\t/* Free resources associated with SLI2 interface */\n\tdma_free_coherent(&pdev->dev, SLI2_SLIM_SIZE,\n\t\t\t  phba->slim2p.virt, phba->slim2p.phys);\n\n\t/* unmap adapter SLIM and Control Registers */\n\tiounmap(phba->ctrl_regs_memmap_p);\n\tiounmap(phba->slim_memmap_p);\n\n\tlpfc_hba_free(phba);\n\n\tpci_release_mem_regions(pdev);\n\tpci_disable_device(pdev);\n}\n\n/**\n * lpfc_pci_suspend_one_s3 - PCI func to suspend SLI-3 device for power mgmnt\n * @dev_d: pointer to device\n *\n * This routine is to be called from the kernel's PCI subsystem to support\n * system Power Management (PM) to device with SLI-3 interface spec. When\n * PM invokes this method, it quiesces the device by stopping the driver's\n * worker thread for the device, turning off device's interrupt and DMA,\n * and bring the device offline. Note that as the driver implements the\n * minimum PM requirements to a power-aware driver's PM support for the\n * suspend/resume -- all the possible PM messages (SUSPEND, HIBERNATE, FREEZE)\n * to the suspend() method call will be treated as SUSPEND and the driver will\n * fully reinitialize its device during resume() method call, the driver will\n * set device to PCI_D3hot state in PCI config space instead of setting it\n * according to the @msg provided by the PM.\n *\n * Return code\n * \t0 - driver suspended the device\n * \tError otherwise\n **/\nstatic int __maybe_unused\nlpfc_pci_suspend_one_s3(struct device *dev_d)\n{\n\tstruct Scsi_Host *shost = dev_get_drvdata(dev_d);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"0473 PCI device Power Management suspend.\\n\");\n\n\t/* Bring down the device */\n\tlpfc_offline_prep(phba, LPFC_MBX_WAIT);\n\tlpfc_offline(phba);\n\tkthread_stop(phba->worker_thread);\n\n\t/* Disable interrupt from device */\n\tlpfc_sli_disable_intr(phba);\n\n\treturn 0;\n}\n\n/**\n * lpfc_pci_resume_one_s3 - PCI func to resume SLI-3 device for power mgmnt\n * @dev_d: pointer to device\n *\n * This routine is to be called from the kernel's PCI subsystem to support\n * system Power Management (PM) to device with SLI-3 interface spec. When PM\n * invokes this method, it restores the device's PCI config space state and\n * fully reinitializes the device and brings it online. Note that as the\n * driver implements the minimum PM requirements to a power-aware driver's\n * PM for suspend/resume -- all the possible PM messages (SUSPEND, HIBERNATE,\n * FREEZE) to the suspend() method call will be treated as SUSPEND and the\n * driver will fully reinitialize its device during resume() method call,\n * the device will be set to PCI_D0 directly in PCI config space before\n * restoring the state.\n *\n * Return code\n * \t0 - driver suspended the device\n * \tError otherwise\n **/\nstatic int __maybe_unused\nlpfc_pci_resume_one_s3(struct device *dev_d)\n{\n\tstruct Scsi_Host *shost = dev_get_drvdata(dev_d);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\tuint32_t intr_mode;\n\tint error;\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"0452 PCI device Power Management resume.\\n\");\n\n\t/* Startup the kernel thread for this host adapter. */\n\tphba->worker_thread = kthread_run(lpfc_do_work, phba,\n\t\t\t\t\t\"lpfc_worker_%d\", phba->brd_no);\n\tif (IS_ERR(phba->worker_thread)) {\n\t\terror = PTR_ERR(phba->worker_thread);\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"0434 PM resume failed to start worker \"\n\t\t\t\t\"thread: error=x%x.\\n\", error);\n\t\treturn error;\n\t}\n\n\t/* Configure and enable interrupt */\n\tintr_mode = lpfc_sli_enable_intr(phba, phba->intr_mode);\n\tif (intr_mode == LPFC_INTR_ERROR) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0430 PM resume Failed to enable interrupt\\n\");\n\t\treturn -EIO;\n\t} else\n\t\tphba->intr_mode = intr_mode;\n\n\t/* Restart HBA and bring it online */\n\tlpfc_sli_brdrestart(phba);\n\tlpfc_online(phba);\n\n\t/* Log the current active interrupt mode */\n\tlpfc_log_intr_mode(phba, phba->intr_mode);\n\n\treturn 0;\n}\n\n/**\n * lpfc_sli_prep_dev_for_recover - Prepare SLI3 device for pci slot recover\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is called to prepare the SLI3 device for PCI slot recover. It\n * aborts all the outstanding SCSI I/Os to the pci device.\n **/\nstatic void\nlpfc_sli_prep_dev_for_recover(struct lpfc_hba *phba)\n{\n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"2723 PCI channel I/O abort preparing for recovery\\n\");\n\n\t/*\n\t * There may be errored I/Os through HBA, abort all I/Os on txcmplq\n\t * and let the SCSI mid-layer to retry them to recover.\n\t */\n\tlpfc_sli_abort_fcp_rings(phba);\n}\n\n/**\n * lpfc_sli_prep_dev_for_reset - Prepare SLI3 device for pci slot reset\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is called to prepare the SLI3 device for PCI slot reset. It\n * disables the device interrupt and pci device, and aborts the internal FCP\n * pending I/Os.\n **/\nstatic void\nlpfc_sli_prep_dev_for_reset(struct lpfc_hba *phba)\n{\n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"2710 PCI channel disable preparing for reset\\n\");\n\n\t/* Block any management I/Os to the device */\n\tlpfc_block_mgmt_io(phba, LPFC_MBX_WAIT);\n\n\t/* Block all SCSI devices' I/Os on the host */\n\tlpfc_scsi_dev_block(phba);\n\n\t/* Flush all driver's outstanding SCSI I/Os as we are to reset */\n\tlpfc_sli_flush_io_rings(phba);\n\n\t/* stop all timers */\n\tlpfc_stop_hba_timers(phba);\n\n\t/* Disable interrupt and pci device */\n\tlpfc_sli_disable_intr(phba);\n\tpci_disable_device(phba->pcidev);\n}\n\n/**\n * lpfc_sli_prep_dev_for_perm_failure - Prepare SLI3 dev for pci slot disable\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is called to prepare the SLI3 device for PCI slot permanently\n * disabling. It blocks the SCSI transport layer traffic and flushes the FCP\n * pending I/Os.\n **/\nstatic void\nlpfc_sli_prep_dev_for_perm_failure(struct lpfc_hba *phba)\n{\n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"2711 PCI channel permanent disable for failure\\n\");\n\t/* Block all SCSI devices' I/Os on the host */\n\tlpfc_scsi_dev_block(phba);\n\n\t/* stop all timers */\n\tlpfc_stop_hba_timers(phba);\n\n\t/* Clean up all driver's outstanding SCSI I/Os */\n\tlpfc_sli_flush_io_rings(phba);\n}\n\n/**\n * lpfc_io_error_detected_s3 - Method for handling SLI-3 device PCI I/O error\n * @pdev: pointer to PCI device.\n * @state: the current PCI connection state.\n *\n * This routine is called from the PCI subsystem for I/O error handling to\n * device with SLI-3 interface spec. This function is called by the PCI\n * subsystem after a PCI bus error affecting this device has been detected.\n * When this function is invoked, it will need to stop all the I/Os and\n * interrupt(s) to the device. Once that is done, it will return\n * PCI_ERS_RESULT_NEED_RESET for the PCI subsystem to perform proper recovery\n * as desired.\n *\n * Return codes\n * \tPCI_ERS_RESULT_CAN_RECOVER - can be recovered with reset_link\n * \tPCI_ERS_RESULT_NEED_RESET - need to reset before recovery\n * \tPCI_ERS_RESULT_DISCONNECT - device could not be recovered\n **/\nstatic pci_ers_result_t\nlpfc_io_error_detected_s3(struct pci_dev *pdev, pci_channel_state_t state)\n{\n\tstruct Scsi_Host *shost = pci_get_drvdata(pdev);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\n\tswitch (state) {\n\tcase pci_channel_io_normal:\n\t\t/* Non-fatal error, prepare for recovery */\n\t\tlpfc_sli_prep_dev_for_recover(phba);\n\t\treturn PCI_ERS_RESULT_CAN_RECOVER;\n\tcase pci_channel_io_frozen:\n\t\t/* Fatal error, prepare for slot reset */\n\t\tlpfc_sli_prep_dev_for_reset(phba);\n\t\treturn PCI_ERS_RESULT_NEED_RESET;\n\tcase pci_channel_io_perm_failure:\n\t\t/* Permanent failure, prepare for device down */\n\t\tlpfc_sli_prep_dev_for_perm_failure(phba);\n\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\tdefault:\n\t\t/* Unknown state, prepare and request slot reset */\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0472 Unknown PCI error state: x%x\\n\", state);\n\t\tlpfc_sli_prep_dev_for_reset(phba);\n\t\treturn PCI_ERS_RESULT_NEED_RESET;\n\t}\n}\n\n/**\n * lpfc_io_slot_reset_s3 - Method for restarting PCI SLI-3 device from scratch.\n * @pdev: pointer to PCI device.\n *\n * This routine is called from the PCI subsystem for error handling to\n * device with SLI-3 interface spec. This is called after PCI bus has been\n * reset to restart the PCI card from scratch, as if from a cold-boot.\n * During the PCI subsystem error recovery, after driver returns\n * PCI_ERS_RESULT_NEED_RESET, the PCI subsystem will perform proper error\n * recovery and then call this routine before calling the .resume method\n * to recover the device. This function will initialize the HBA device,\n * enable the interrupt, but it will just put the HBA to offline state\n * without passing any I/O traffic.\n *\n * Return codes\n * \tPCI_ERS_RESULT_RECOVERED - the device has been recovered\n * \tPCI_ERS_RESULT_DISCONNECT - device could not be recovered\n */\nstatic pci_ers_result_t\nlpfc_io_slot_reset_s3(struct pci_dev *pdev)\n{\n\tstruct Scsi_Host *shost = pci_get_drvdata(pdev);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\tstruct lpfc_sli *psli = &phba->sli;\n\tuint32_t intr_mode;\n\n\tdev_printk(KERN_INFO, &pdev->dev, \"recovering from a slot reset.\\n\");\n\tif (pci_enable_device_mem(pdev)) {\n\t\tprintk(KERN_ERR \"lpfc: Cannot re-enable \"\n\t\t\t\"PCI device after reset.\\n\");\n\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\t}\n\n\tpci_restore_state(pdev);\n\n\t/*\n\t * As the new kernel behavior of pci_restore_state() API call clears\n\t * device saved_state flag, need to save the restored state again.\n\t */\n\tpci_save_state(pdev);\n\n\tif (pdev->is_busmaster)\n\t\tpci_set_master(pdev);\n\n\tspin_lock_irq(&phba->hbalock);\n\tpsli->sli_flag &= ~LPFC_SLI_ACTIVE;\n\tspin_unlock_irq(&phba->hbalock);\n\n\t/* Configure and enable interrupt */\n\tintr_mode = lpfc_sli_enable_intr(phba, phba->intr_mode);\n\tif (intr_mode == LPFC_INTR_ERROR) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0427 Cannot re-enable interrupt after \"\n\t\t\t\t\"slot reset.\\n\");\n\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\t} else\n\t\tphba->intr_mode = intr_mode;\n\n\t/* Take device offline, it will perform cleanup */\n\tlpfc_offline_prep(phba, LPFC_MBX_WAIT);\n\tlpfc_offline(phba);\n\tlpfc_sli_brdrestart(phba);\n\n\t/* Log the current active interrupt mode */\n\tlpfc_log_intr_mode(phba, phba->intr_mode);\n\n\treturn PCI_ERS_RESULT_RECOVERED;\n}\n\n/**\n * lpfc_io_resume_s3 - Method for resuming PCI I/O operation on SLI-3 device.\n * @pdev: pointer to PCI device\n *\n * This routine is called from the PCI subsystem for error handling to device\n * with SLI-3 interface spec. It is called when kernel error recovery tells\n * the lpfc driver that it is ok to resume normal PCI operation after PCI bus\n * error recovery. After this call, traffic can start to flow from this device\n * again.\n */\nstatic void\nlpfc_io_resume_s3(struct pci_dev *pdev)\n{\n\tstruct Scsi_Host *shost = pci_get_drvdata(pdev);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\n\t/* Bring device online, it will be no-op for non-fatal error resume */\n\tlpfc_online(phba);\n}\n\n/**\n * lpfc_sli4_get_els_iocb_cnt - Calculate the # of ELS IOCBs to reserve\n * @phba: pointer to lpfc hba data structure.\n *\n * returns the number of ELS/CT IOCBs to reserve\n **/\nint\nlpfc_sli4_get_els_iocb_cnt(struct lpfc_hba *phba)\n{\n\tint max_xri = phba->sli4_hba.max_cfg_param.max_xri;\n\n\tif (phba->sli_rev == LPFC_SLI_REV4) {\n\t\tif (max_xri <= 100)\n\t\t\treturn 10;\n\t\telse if (max_xri <= 256)\n\t\t\treturn 25;\n\t\telse if (max_xri <= 512)\n\t\t\treturn 50;\n\t\telse if (max_xri <= 1024)\n\t\t\treturn 100;\n\t\telse if (max_xri <= 1536)\n\t\t\treturn 150;\n\t\telse if (max_xri <= 2048)\n\t\t\treturn 200;\n\t\telse\n\t\t\treturn 250;\n\t} else\n\t\treturn 0;\n}\n\n/**\n * lpfc_sli4_get_iocb_cnt - Calculate the # of total IOCBs to reserve\n * @phba: pointer to lpfc hba data structure.\n *\n * returns the number of ELS/CT + NVMET IOCBs to reserve\n **/\nint\nlpfc_sli4_get_iocb_cnt(struct lpfc_hba *phba)\n{\n\tint max_xri = lpfc_sli4_get_els_iocb_cnt(phba);\n\n\tif (phba->nvmet_support)\n\t\tmax_xri += LPFC_NVMET_BUF_POST;\n\treturn max_xri;\n}\n\n\nstatic int\nlpfc_log_write_firmware_error(struct lpfc_hba *phba, uint32_t offset,\n\tuint32_t magic_number, uint32_t ftype, uint32_t fid, uint32_t fsize,\n\tconst struct firmware *fw)\n{\n\tint rc;\n\n\t/* Three cases:  (1) FW was not supported on the detected adapter.\n\t * (2) FW update has been locked out administratively.\n\t * (3) Some other error during FW update.\n\t * In each case, an unmaskable message is written to the console\n\t * for admin diagnosis.\n\t */\n\tif (offset == ADD_STATUS_FW_NOT_SUPPORTED ||\n\t    (phba->pcidev->device == PCI_DEVICE_ID_LANCER_G6_FC &&\n\t     magic_number != MAGIC_NUMBER_G6) ||\n\t    (phba->pcidev->device == PCI_DEVICE_ID_LANCER_G7_FC &&\n\t     magic_number != MAGIC_NUMBER_G7)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3030 This firmware version is not supported on\"\n\t\t\t\t\" this HBA model. Device:%x Magic:%x Type:%x \"\n\t\t\t\t\"ID:%x Size %d %zd\\n\",\n\t\t\t\tphba->pcidev->device, magic_number, ftype, fid,\n\t\t\t\tfsize, fw->size);\n\t\trc = -EINVAL;\n\t} else if (offset == ADD_STATUS_FW_DOWNLOAD_HW_DISABLED) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3021 Firmware downloads have been prohibited \"\n\t\t\t\t\"by a system configuration setting on \"\n\t\t\t\t\"Device:%x Magic:%x Type:%x ID:%x Size %d \"\n\t\t\t\t\"%zd\\n\",\n\t\t\t\tphba->pcidev->device, magic_number, ftype, fid,\n\t\t\t\tfsize, fw->size);\n\t\trc = -EACCES;\n\t} else {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3022 FW Download failed. Add Status x%x \"\n\t\t\t\t\"Device:%x Magic:%x Type:%x ID:%x Size %d \"\n\t\t\t\t\"%zd\\n\",\n\t\t\t\toffset, phba->pcidev->device, magic_number,\n\t\t\t\tftype, fid, fsize, fw->size);\n\t\trc = -EIO;\n\t}\n\treturn rc;\n}\n\n/**\n * lpfc_write_firmware - attempt to write a firmware image to the port\n * @fw: pointer to firmware image returned from request_firmware.\n * @context: pointer to firmware image returned from request_firmware.\n *\n **/\nstatic void\nlpfc_write_firmware(const struct firmware *fw, void *context)\n{\n\tstruct lpfc_hba *phba = (struct lpfc_hba *)context;\n\tchar fwrev[FW_REV_STR_SIZE];\n\tstruct lpfc_grp_hdr *image;\n\tstruct list_head dma_buffer_list;\n\tint i, rc = 0;\n\tstruct lpfc_dmabuf *dmabuf, *next;\n\tuint32_t offset = 0, temp_offset = 0;\n\tuint32_t magic_number, ftype, fid, fsize;\n\n\t/* It can be null in no-wait mode, sanity check */\n\tif (!fw) {\n\t\trc = -ENXIO;\n\t\tgoto out;\n\t}\n\timage = (struct lpfc_grp_hdr *)fw->data;\n\n\tmagic_number = be32_to_cpu(image->magic_number);\n\tftype = bf_get_be32(lpfc_grp_hdr_file_type, image);\n\tfid = bf_get_be32(lpfc_grp_hdr_id, image);\n\tfsize = be32_to_cpu(image->size);\n\n\tINIT_LIST_HEAD(&dma_buffer_list);\n\tlpfc_decode_firmware_rev(phba, fwrev, 1);\n\tif (strncmp(fwrev, image->revision, strnlen(image->revision, 16))) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3023 Updating Firmware, Current Version:%s \"\n\t\t\t\t\"New Version:%s\\n\",\n\t\t\t\tfwrev, image->revision);\n\t\tfor (i = 0; i < LPFC_MBX_WR_CONFIG_MAX_BDE; i++) {\n\t\t\tdmabuf = kzalloc(sizeof(struct lpfc_dmabuf),\n\t\t\t\t\t GFP_KERNEL);\n\t\t\tif (!dmabuf) {\n\t\t\t\trc = -ENOMEM;\n\t\t\t\tgoto release_out;\n\t\t\t}\n\t\t\tdmabuf->virt = dma_alloc_coherent(&phba->pcidev->dev,\n\t\t\t\t\t\t\t  SLI4_PAGE_SIZE,\n\t\t\t\t\t\t\t  &dmabuf->phys,\n\t\t\t\t\t\t\t  GFP_KERNEL);\n\t\t\tif (!dmabuf->virt) {\n\t\t\t\tkfree(dmabuf);\n\t\t\t\trc = -ENOMEM;\n\t\t\t\tgoto release_out;\n\t\t\t}\n\t\t\tlist_add_tail(&dmabuf->list, &dma_buffer_list);\n\t\t}\n\t\twhile (offset < fw->size) {\n\t\t\ttemp_offset = offset;\n\t\t\tlist_for_each_entry(dmabuf, &dma_buffer_list, list) {\n\t\t\t\tif (temp_offset + SLI4_PAGE_SIZE > fw->size) {\n\t\t\t\t\tmemcpy(dmabuf->virt,\n\t\t\t\t\t       fw->data + temp_offset,\n\t\t\t\t\t       fw->size - temp_offset);\n\t\t\t\t\ttemp_offset = fw->size;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tmemcpy(dmabuf->virt, fw->data + temp_offset,\n\t\t\t\t       SLI4_PAGE_SIZE);\n\t\t\t\ttemp_offset += SLI4_PAGE_SIZE;\n\t\t\t}\n\t\t\trc = lpfc_wr_object(phba, &dma_buffer_list,\n\t\t\t\t    (fw->size - offset), &offset);\n\t\t\tif (rc) {\n\t\t\t\trc = lpfc_log_write_firmware_error(phba, offset,\n\t\t\t\t\t\t\t\t   magic_number,\n\t\t\t\t\t\t\t\t   ftype,\n\t\t\t\t\t\t\t\t   fid,\n\t\t\t\t\t\t\t\t   fsize,\n\t\t\t\t\t\t\t\t   fw);\n\t\t\t\tgoto release_out;\n\t\t\t}\n\t\t}\n\t\trc = offset;\n\t} else\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3029 Skipped Firmware update, Current \"\n\t\t\t\t\"Version:%s New Version:%s\\n\",\n\t\t\t\tfwrev, image->revision);\n\nrelease_out:\n\tlist_for_each_entry_safe(dmabuf, next, &dma_buffer_list, list) {\n\t\tlist_del(&dmabuf->list);\n\t\tdma_free_coherent(&phba->pcidev->dev, SLI4_PAGE_SIZE,\n\t\t\t\t  dmabuf->virt, dmabuf->phys);\n\t\tkfree(dmabuf);\n\t}\n\trelease_firmware(fw);\nout:\n\tif (rc < 0)\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3062 Firmware update error, status %d.\\n\", rc);\n\telse\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"3024 Firmware update success: size %d.\\n\", rc);\n}\n\n/**\n * lpfc_sli4_request_firmware_update - Request linux generic firmware upgrade\n * @phba: pointer to lpfc hba data structure.\n * @fw_upgrade: which firmware to update.\n *\n * This routine is called to perform Linux generic firmware upgrade on device\n * that supports such feature.\n **/\nint\nlpfc_sli4_request_firmware_update(struct lpfc_hba *phba, uint8_t fw_upgrade)\n{\n\tuint8_t file_name[ELX_MODEL_NAME_SIZE];\n\tint ret;\n\tconst struct firmware *fw;\n\n\t/* Only supported on SLI4 interface type 2 for now */\n\tif (bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf) <\n\t    LPFC_SLI_INTF_IF_TYPE_2)\n\t\treturn -EPERM;\n\n\tsnprintf(file_name, ELX_MODEL_NAME_SIZE, \"%s.grp\", phba->ModelName);\n\n\tif (fw_upgrade == INT_FW_UPGRADE) {\n\t\tret = request_firmware_nowait(THIS_MODULE, FW_ACTION_HOTPLUG,\n\t\t\t\t\tfile_name, &phba->pcidev->dev,\n\t\t\t\t\tGFP_KERNEL, (void *)phba,\n\t\t\t\t\tlpfc_write_firmware);\n\t} else if (fw_upgrade == RUN_FW_UPGRADE) {\n\t\tret = request_firmware(&fw, file_name, &phba->pcidev->dev);\n\t\tif (!ret)\n\t\t\tlpfc_write_firmware(fw, (void *)phba);\n\t} else {\n\t\tret = -EINVAL;\n\t}\n\n\treturn ret;\n}\n\n/**\n * lpfc_pci_probe_one_s4 - PCI probe func to reg SLI-4 device to PCI subsys\n * @pdev: pointer to PCI device\n * @pid: pointer to PCI device identifier\n *\n * This routine is called from the kernel's PCI subsystem to device with\n * SLI-4 interface spec. When an Emulex HBA with SLI-4 interface spec is\n * presented on PCI bus, the kernel PCI subsystem looks at PCI device-specific\n * information of the device and driver to see if the driver state that it\n * can support this kind of device. If the match is successful, the driver\n * core invokes this routine. If this routine determines it can claim the HBA,\n * it does all the initialization that it needs to do to handle the HBA\n * properly.\n *\n * Return code\n * \t0 - driver can claim the device\n * \tnegative value - driver can not claim the device\n **/\nstatic int\nlpfc_pci_probe_one_s4(struct pci_dev *pdev, const struct pci_device_id *pid)\n{\n\tstruct lpfc_hba   *phba;\n\tstruct lpfc_vport *vport = NULL;\n\tstruct Scsi_Host  *shost = NULL;\n\tint error;\n\tuint32_t cfg_mode, intr_mode;\n\n\t/* Allocate memory for HBA structure */\n\tphba = lpfc_hba_alloc(pdev);\n\tif (!phba)\n\t\treturn -ENOMEM;\n\n\t/* Perform generic PCI device enabling operation */\n\terror = lpfc_enable_pci_dev(phba);\n\tif (error)\n\t\tgoto out_free_phba;\n\n\t/* Set up SLI API function jump table for PCI-device group-1 HBAs */\n\terror = lpfc_api_table_setup(phba, LPFC_PCI_DEV_OC);\n\tif (error)\n\t\tgoto out_disable_pci_dev;\n\n\t/* Set up SLI-4 specific device PCI memory space */\n\terror = lpfc_sli4_pci_mem_setup(phba);\n\tif (error) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"1410 Failed to set up pci memory space.\\n\");\n\t\tgoto out_disable_pci_dev;\n\t}\n\n\t/* Set up SLI-4 Specific device driver resources */\n\terror = lpfc_sli4_driver_resource_setup(phba);\n\tif (error) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"1412 Failed to set up driver resource.\\n\");\n\t\tgoto out_unset_pci_mem_s4;\n\t}\n\n\tINIT_LIST_HEAD(&phba->active_rrq_list);\n\tINIT_LIST_HEAD(&phba->fcf.fcf_pri_list);\n\n\t/* Set up common device driver resources */\n\terror = lpfc_setup_driver_resource_phase2(phba);\n\tif (error) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"1414 Failed to set up driver resource.\\n\");\n\t\tgoto out_unset_driver_resource_s4;\n\t}\n\n\t/* Get the default values for Model Name and Description */\n\tlpfc_get_hba_model_desc(phba, phba->ModelName, phba->ModelDesc);\n\n\t/* Now, trying to enable interrupt and bring up the device */\n\tcfg_mode = phba->cfg_use_msi;\n\n\t/* Put device to a known state before enabling interrupt */\n\tphba->pport = NULL;\n\tlpfc_stop_port(phba);\n\n\t/* Init cpu_map array */\n\tlpfc_cpu_map_array_init(phba);\n\n\t/* Init hba_eq_hdl array */\n\tlpfc_hba_eq_hdl_array_init(phba);\n\n\t/* Configure and enable interrupt */\n\tintr_mode = lpfc_sli4_enable_intr(phba, cfg_mode);\n\tif (intr_mode == LPFC_INTR_ERROR) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0426 Failed to enable interrupt.\\n\");\n\t\terror = -ENODEV;\n\t\tgoto out_unset_driver_resource;\n\t}\n\t/* Default to single EQ for non-MSI-X */\n\tif (phba->intr_type != MSIX) {\n\t\tphba->cfg_irq_chann = 1;\n\t\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME) {\n\t\t\tif (phba->nvmet_support)\n\t\t\t\tphba->cfg_nvmet_mrq = 1;\n\t\t}\n\t}\n\tlpfc_cpu_affinity_check(phba, phba->cfg_irq_chann);\n\n\t/* Create SCSI host to the physical port */\n\terror = lpfc_create_shost(phba);\n\tif (error) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"1415 Failed to create scsi host.\\n\");\n\t\tgoto out_disable_intr;\n\t}\n\tvport = phba->pport;\n\tshost = lpfc_shost_from_vport(vport); /* save shost for error cleanup */\n\n\t/* Configure sysfs attributes */\n\terror = lpfc_alloc_sysfs_attr(vport);\n\tif (error) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"1416 Failed to allocate sysfs attr\\n\");\n\t\tgoto out_destroy_shost;\n\t}\n\n\t/* Set up SLI-4 HBA */\n\tif (lpfc_sli4_hba_setup(phba)) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"1421 Failed to set up hba\\n\");\n\t\terror = -ENODEV;\n\t\tgoto out_free_sysfs_attr;\n\t}\n\n\t/* Log the current active interrupt mode */\n\tphba->intr_mode = intr_mode;\n\tlpfc_log_intr_mode(phba, intr_mode);\n\n\t/* Perform post initialization setup */\n\tlpfc_post_init_setup(phba);\n\n\t/* NVME support in FW earlier in the driver load corrects the\n\t * FC4 type making a check for nvme_support unnecessary.\n\t */\n\tif (phba->nvmet_support == 0) {\n\t\tif (phba->cfg_enable_fc4_type & LPFC_ENABLE_NVME) {\n\t\t\t/* Create NVME binding with nvme_fc_transport. This\n\t\t\t * ensures the vport is initialized.  If the localport\n\t\t\t * create fails, it should not unload the driver to\n\t\t\t * support field issues.\n\t\t\t */\n\t\t\terror = lpfc_nvme_create_localport(vport);\n\t\t\tif (error) {\n\t\t\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\t\t\"6004 NVME registration \"\n\t\t\t\t\t\t\"failed, error x%x\\n\",\n\t\t\t\t\t\terror);\n\t\t\t}\n\t\t}\n\t}\n\n\t/* check for firmware upgrade or downgrade */\n\tif (phba->cfg_request_firmware_upgrade)\n\t\tlpfc_sli4_request_firmware_update(phba, INT_FW_UPGRADE);\n\n\t/* Check if there are static vports to be created. */\n\tlpfc_create_static_vport(phba);\n\n\t/* Enable RAS FW log support */\n\tlpfc_sli4_ras_setup(phba);\n\n\tINIT_LIST_HEAD(&phba->poll_list);\n\ttimer_setup(&phba->cpuhp_poll_timer, lpfc_sli4_poll_hbtimer, 0);\n\tcpuhp_state_add_instance_nocalls(lpfc_cpuhp_state, &phba->cpuhp);\n\n\treturn 0;\n\nout_free_sysfs_attr:\n\tlpfc_free_sysfs_attr(vport);\nout_destroy_shost:\n\tlpfc_destroy_shost(phba);\nout_disable_intr:\n\tlpfc_sli4_disable_intr(phba);\nout_unset_driver_resource:\n\tlpfc_unset_driver_resource_phase2(phba);\nout_unset_driver_resource_s4:\n\tlpfc_sli4_driver_resource_unset(phba);\nout_unset_pci_mem_s4:\n\tlpfc_sli4_pci_mem_unset(phba);\nout_disable_pci_dev:\n\tlpfc_disable_pci_dev(phba);\n\tif (shost)\n\t\tscsi_host_put(shost);\nout_free_phba:\n\tlpfc_hba_free(phba);\n\treturn error;\n}\n\n/**\n * lpfc_pci_remove_one_s4 - PCI func to unreg SLI-4 device from PCI subsystem\n * @pdev: pointer to PCI device\n *\n * This routine is called from the kernel's PCI subsystem to device with\n * SLI-4 interface spec. When an Emulex HBA with SLI-4 interface spec is\n * removed from PCI bus, it performs all the necessary cleanup for the HBA\n * device to be removed from the PCI subsystem properly.\n **/\nstatic void\nlpfc_pci_remove_one_s4(struct pci_dev *pdev)\n{\n\tstruct Scsi_Host *shost = pci_get_drvdata(pdev);\n\tstruct lpfc_vport *vport = (struct lpfc_vport *) shost->hostdata;\n\tstruct lpfc_vport **vports;\n\tstruct lpfc_hba *phba = vport->phba;\n\tint i;\n\n\t/* Mark the device unloading flag */\n\tspin_lock_irq(&phba->hbalock);\n\tvport->load_flag |= FC_UNLOADING;\n\tspin_unlock_irq(&phba->hbalock);\n\n\tlpfc_free_sysfs_attr(vport);\n\n\t/* Release all the vports against this physical port */\n\tvports = lpfc_create_vport_work_array(phba);\n\tif (vports != NULL)\n\t\tfor (i = 0; i <= phba->max_vports && vports[i] != NULL; i++) {\n\t\t\tif (vports[i]->port_type == LPFC_PHYSICAL_PORT)\n\t\t\t\tcontinue;\n\t\t\tfc_vport_terminate(vports[i]->fc_vport);\n\t\t}\n\tlpfc_destroy_vport_work_array(phba, vports);\n\n\t/* Remove FC host with the physical port */\n\tfc_remove_host(shost);\n\tscsi_remove_host(shost);\n\n\t/* Perform ndlp cleanup on the physical port.  The nvme and nvmet\n\t * localports are destroyed after to cleanup all transport memory.\n\t */\n\tlpfc_cleanup(vport);\n\tlpfc_nvmet_destroy_targetport(phba);\n\tlpfc_nvme_destroy_localport(vport);\n\n\t/* De-allocate multi-XRI pools */\n\tif (phba->cfg_xri_rebalancing)\n\t\tlpfc_destroy_multixri_pools(phba);\n\n\t/*\n\t * Bring down the SLI Layer. This step disables all interrupts,\n\t * clears the rings, discards all mailbox commands, and resets\n\t * the HBA FCoE function.\n\t */\n\tlpfc_debugfs_terminate(vport);\n\n\tlpfc_stop_hba_timers(phba);\n\tspin_lock_irq(&phba->port_list_lock);\n\tlist_del_init(&vport->listentry);\n\tspin_unlock_irq(&phba->port_list_lock);\n\n\t/* Perform scsi free before driver resource_unset since scsi\n\t * buffers are released to their corresponding pools here.\n\t */\n\tlpfc_io_free(phba);\n\tlpfc_free_iocb_list(phba);\n\tlpfc_sli4_hba_unset(phba);\n\n\tlpfc_unset_driver_resource_phase2(phba);\n\tlpfc_sli4_driver_resource_unset(phba);\n\n\t/* Unmap adapter Control and Doorbell registers */\n\tlpfc_sli4_pci_mem_unset(phba);\n\n\t/* Release PCI resources and disable device's PCI function */\n\tscsi_host_put(shost);\n\tlpfc_disable_pci_dev(phba);\n\n\t/* Finally, free the driver's device data structure */\n\tlpfc_hba_free(phba);\n\n\treturn;\n}\n\n/**\n * lpfc_pci_suspend_one_s4 - PCI func to suspend SLI-4 device for power mgmnt\n * @dev_d: pointer to device\n *\n * This routine is called from the kernel's PCI subsystem to support system\n * Power Management (PM) to device with SLI-4 interface spec. When PM invokes\n * this method, it quiesces the device by stopping the driver's worker\n * thread for the device, turning off device's interrupt and DMA, and bring\n * the device offline. Note that as the driver implements the minimum PM\n * requirements to a power-aware driver's PM support for suspend/resume -- all\n * the possible PM messages (SUSPEND, HIBERNATE, FREEZE) to the suspend()\n * method call will be treated as SUSPEND and the driver will fully\n * reinitialize its device during resume() method call, the driver will set\n * device to PCI_D3hot state in PCI config space instead of setting it\n * according to the @msg provided by the PM.\n *\n * Return code\n * \t0 - driver suspended the device\n * \tError otherwise\n **/\nstatic int __maybe_unused\nlpfc_pci_suspend_one_s4(struct device *dev_d)\n{\n\tstruct Scsi_Host *shost = dev_get_drvdata(dev_d);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"2843 PCI device Power Management suspend.\\n\");\n\n\t/* Bring down the device */\n\tlpfc_offline_prep(phba, LPFC_MBX_WAIT);\n\tlpfc_offline(phba);\n\tkthread_stop(phba->worker_thread);\n\n\t/* Disable interrupt from device */\n\tlpfc_sli4_disable_intr(phba);\n\tlpfc_sli4_queue_destroy(phba);\n\n\treturn 0;\n}\n\n/**\n * lpfc_pci_resume_one_s4 - PCI func to resume SLI-4 device for power mgmnt\n * @dev_d: pointer to device\n *\n * This routine is called from the kernel's PCI subsystem to support system\n * Power Management (PM) to device with SLI-4 interface spac. When PM invokes\n * this method, it restores the device's PCI config space state and fully\n * reinitializes the device and brings it online. Note that as the driver\n * implements the minimum PM requirements to a power-aware driver's PM for\n * suspend/resume -- all the possible PM messages (SUSPEND, HIBERNATE, FREEZE)\n * to the suspend() method call will be treated as SUSPEND and the driver\n * will fully reinitialize its device during resume() method call, the device\n * will be set to PCI_D0 directly in PCI config space before restoring the\n * state.\n *\n * Return code\n * \t0 - driver suspended the device\n * \tError otherwise\n **/\nstatic int __maybe_unused\nlpfc_pci_resume_one_s4(struct device *dev_d)\n{\n\tstruct Scsi_Host *shost = dev_get_drvdata(dev_d);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\tuint32_t intr_mode;\n\tint error;\n\n\tlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\n\t\t\t\"0292 PCI device Power Management resume.\\n\");\n\n\t /* Startup the kernel thread for this host adapter. */\n\tphba->worker_thread = kthread_run(lpfc_do_work, phba,\n\t\t\t\t\t\"lpfc_worker_%d\", phba->brd_no);\n\tif (IS_ERR(phba->worker_thread)) {\n\t\terror = PTR_ERR(phba->worker_thread);\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\n\t\t\t\t\"0293 PM resume failed to start worker \"\n\t\t\t\t\"thread: error=x%x.\\n\", error);\n\t\treturn error;\n\t}\n\n\t/* Configure and enable interrupt */\n\tintr_mode = lpfc_sli4_enable_intr(phba, phba->intr_mode);\n\tif (intr_mode == LPFC_INTR_ERROR) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"0294 PM resume Failed to enable interrupt\\n\");\n\t\treturn -EIO;\n\t} else\n\t\tphba->intr_mode = intr_mode;\n\n\t/* Restart HBA and bring it online */\n\tlpfc_sli_brdrestart(phba);\n\tlpfc_online(phba);\n\n\t/* Log the current active interrupt mode */\n\tlpfc_log_intr_mode(phba, phba->intr_mode);\n\n\treturn 0;\n}\n\n/**\n * lpfc_sli4_prep_dev_for_recover - Prepare SLI4 device for pci slot recover\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is called to prepare the SLI4 device for PCI slot recover. It\n * aborts all the outstanding SCSI I/Os to the pci device.\n **/\nstatic void\nlpfc_sli4_prep_dev_for_recover(struct lpfc_hba *phba)\n{\n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"2828 PCI channel I/O abort preparing for recovery\\n\");\n\t/*\n\t * There may be errored I/Os through HBA, abort all I/Os on txcmplq\n\t * and let the SCSI mid-layer to retry them to recover.\n\t */\n\tlpfc_sli_abort_fcp_rings(phba);\n}\n\n/**\n * lpfc_sli4_prep_dev_for_reset - Prepare SLI4 device for pci slot reset\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is called to prepare the SLI4 device for PCI slot reset. It\n * disables the device interrupt and pci device, and aborts the internal FCP\n * pending I/Os.\n **/\nstatic void\nlpfc_sli4_prep_dev_for_reset(struct lpfc_hba *phba)\n{\n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"2826 PCI channel disable preparing for reset\\n\");\n\n\t/* Block any management I/Os to the device */\n\tlpfc_block_mgmt_io(phba, LPFC_MBX_NO_WAIT);\n\n\t/* Block all SCSI devices' I/Os on the host */\n\tlpfc_scsi_dev_block(phba);\n\n\t/* Flush all driver's outstanding I/Os as we are to reset */\n\tlpfc_sli_flush_io_rings(phba);\n\n\t/* stop all timers */\n\tlpfc_stop_hba_timers(phba);\n\n\t/* Disable interrupt and pci device */\n\tlpfc_sli4_disable_intr(phba);\n\tlpfc_sli4_queue_destroy(phba);\n\tpci_disable_device(phba->pcidev);\n}\n\n/**\n * lpfc_sli4_prep_dev_for_perm_failure - Prepare SLI4 dev for pci slot disable\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine is called to prepare the SLI4 device for PCI slot permanently\n * disabling. It blocks the SCSI transport layer traffic and flushes the FCP\n * pending I/Os.\n **/\nstatic void\nlpfc_sli4_prep_dev_for_perm_failure(struct lpfc_hba *phba)\n{\n\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\"2827 PCI channel permanent disable for failure\\n\");\n\n\t/* Block all SCSI devices' I/Os on the host */\n\tlpfc_scsi_dev_block(phba);\n\n\t/* stop all timers */\n\tlpfc_stop_hba_timers(phba);\n\n\t/* Clean up all driver's outstanding I/Os */\n\tlpfc_sli_flush_io_rings(phba);\n}\n\n/**\n * lpfc_io_error_detected_s4 - Method for handling PCI I/O error to SLI-4 device\n * @pdev: pointer to PCI device.\n * @state: the current PCI connection state.\n *\n * This routine is called from the PCI subsystem for error handling to device\n * with SLI-4 interface spec. This function is called by the PCI subsystem\n * after a PCI bus error affecting this device has been detected. When this\n * function is invoked, it will need to stop all the I/Os and interrupt(s)\n * to the device. Once that is done, it will return PCI_ERS_RESULT_NEED_RESET\n * for the PCI subsystem to perform proper recovery as desired.\n *\n * Return codes\n * \tPCI_ERS_RESULT_NEED_RESET - need to reset before recovery\n * \tPCI_ERS_RESULT_DISCONNECT - device could not be recovered\n **/\nstatic pci_ers_result_t\nlpfc_io_error_detected_s4(struct pci_dev *pdev, pci_channel_state_t state)\n{\n\tstruct Scsi_Host *shost = pci_get_drvdata(pdev);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\n\tswitch (state) {\n\tcase pci_channel_io_normal:\n\t\t/* Non-fatal error, prepare for recovery */\n\t\tlpfc_sli4_prep_dev_for_recover(phba);\n\t\treturn PCI_ERS_RESULT_CAN_RECOVER;\n\tcase pci_channel_io_frozen:\n\t\t/* Fatal error, prepare for slot reset */\n\t\tlpfc_sli4_prep_dev_for_reset(phba);\n\t\treturn PCI_ERS_RESULT_NEED_RESET;\n\tcase pci_channel_io_perm_failure:\n\t\t/* Permanent failure, prepare for device down */\n\t\tlpfc_sli4_prep_dev_for_perm_failure(phba);\n\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\tdefault:\n\t\t/* Unknown state, prepare and request slot reset */\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2825 Unknown PCI error state: x%x\\n\", state);\n\t\tlpfc_sli4_prep_dev_for_reset(phba);\n\t\treturn PCI_ERS_RESULT_NEED_RESET;\n\t}\n}\n\n/**\n * lpfc_io_slot_reset_s4 - Method for restart PCI SLI-4 device from scratch\n * @pdev: pointer to PCI device.\n *\n * This routine is called from the PCI subsystem for error handling to device\n * with SLI-4 interface spec. It is called after PCI bus has been reset to\n * restart the PCI card from scratch, as if from a cold-boot. During the\n * PCI subsystem error recovery, after the driver returns\n * PCI_ERS_RESULT_NEED_RESET, the PCI subsystem will perform proper error\n * recovery and then call this routine before calling the .resume method to\n * recover the device. This function will initialize the HBA device, enable\n * the interrupt, but it will just put the HBA to offline state without\n * passing any I/O traffic.\n *\n * Return codes\n * \tPCI_ERS_RESULT_RECOVERED - the device has been recovered\n * \tPCI_ERS_RESULT_DISCONNECT - device could not be recovered\n */\nstatic pci_ers_result_t\nlpfc_io_slot_reset_s4(struct pci_dev *pdev)\n{\n\tstruct Scsi_Host *shost = pci_get_drvdata(pdev);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\tstruct lpfc_sli *psli = &phba->sli;\n\tuint32_t intr_mode;\n\n\tdev_printk(KERN_INFO, &pdev->dev, \"recovering from a slot reset.\\n\");\n\tif (pci_enable_device_mem(pdev)) {\n\t\tprintk(KERN_ERR \"lpfc: Cannot re-enable \"\n\t\t\t\"PCI device after reset.\\n\");\n\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\t}\n\n\tpci_restore_state(pdev);\n\n\t/*\n\t * As the new kernel behavior of pci_restore_state() API call clears\n\t * device saved_state flag, need to save the restored state again.\n\t */\n\tpci_save_state(pdev);\n\n\tif (pdev->is_busmaster)\n\t\tpci_set_master(pdev);\n\n\tspin_lock_irq(&phba->hbalock);\n\tpsli->sli_flag &= ~LPFC_SLI_ACTIVE;\n\tspin_unlock_irq(&phba->hbalock);\n\n\t/* Configure and enable interrupt */\n\tintr_mode = lpfc_sli4_enable_intr(phba, phba->intr_mode);\n\tif (intr_mode == LPFC_INTR_ERROR) {\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"2824 Cannot re-enable interrupt after \"\n\t\t\t\t\"slot reset.\\n\");\n\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\t} else\n\t\tphba->intr_mode = intr_mode;\n\n\t/* Log the current active interrupt mode */\n\tlpfc_log_intr_mode(phba, phba->intr_mode);\n\n\treturn PCI_ERS_RESULT_RECOVERED;\n}\n\n/**\n * lpfc_io_resume_s4 - Method for resuming PCI I/O operation to SLI-4 device\n * @pdev: pointer to PCI device\n *\n * This routine is called from the PCI subsystem for error handling to device\n * with SLI-4 interface spec. It is called when kernel error recovery tells\n * the lpfc driver that it is ok to resume normal PCI operation after PCI bus\n * error recovery. After this call, traffic can start to flow from this device\n * again.\n **/\nstatic void\nlpfc_io_resume_s4(struct pci_dev *pdev)\n{\n\tstruct Scsi_Host *shost = pci_get_drvdata(pdev);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\n\t/*\n\t * In case of slot reset, as function reset is performed through\n\t * mailbox command which needs DMA to be enabled, this operation\n\t * has to be moved to the io resume phase. Taking device offline\n\t * will perform the necessary cleanup.\n\t */\n\tif (!(phba->sli.sli_flag & LPFC_SLI_ACTIVE)) {\n\t\t/* Perform device reset */\n\t\tlpfc_offline_prep(phba, LPFC_MBX_WAIT);\n\t\tlpfc_offline(phba);\n\t\tlpfc_sli_brdrestart(phba);\n\t\t/* Bring the device back online */\n\t\tlpfc_online(phba);\n\t}\n}\n\n/**\n * lpfc_pci_probe_one - lpfc PCI probe func to reg dev to PCI subsystem\n * @pdev: pointer to PCI device\n * @pid: pointer to PCI device identifier\n *\n * This routine is to be registered to the kernel's PCI subsystem. When an\n * Emulex HBA device is presented on PCI bus, the kernel PCI subsystem looks\n * at PCI device-specific information of the device and driver to see if the\n * driver state that it can support this kind of device. If the match is\n * successful, the driver core invokes this routine. This routine dispatches\n * the action to the proper SLI-3 or SLI-4 device probing routine, which will\n * do all the initialization that it needs to do to handle the HBA device\n * properly.\n *\n * Return code\n * \t0 - driver can claim the device\n * \tnegative value - driver can not claim the device\n **/\nstatic int\nlpfc_pci_probe_one(struct pci_dev *pdev, const struct pci_device_id *pid)\n{\n\tint rc;\n\tstruct lpfc_sli_intf intf;\n\n\tif (pci_read_config_dword(pdev, LPFC_SLI_INTF, &intf.word0))\n\t\treturn -ENODEV;\n\n\tif ((bf_get(lpfc_sli_intf_valid, &intf) == LPFC_SLI_INTF_VALID) &&\n\t    (bf_get(lpfc_sli_intf_slirev, &intf) == LPFC_SLI_INTF_REV_SLI4))\n\t\trc = lpfc_pci_probe_one_s4(pdev, pid);\n\telse\n\t\trc = lpfc_pci_probe_one_s3(pdev, pid);\n\n\treturn rc;\n}\n\n/**\n * lpfc_pci_remove_one - lpfc PCI func to unreg dev from PCI subsystem\n * @pdev: pointer to PCI device\n *\n * This routine is to be registered to the kernel's PCI subsystem. When an\n * Emulex HBA is removed from PCI bus, the driver core invokes this routine.\n * This routine dispatches the action to the proper SLI-3 or SLI-4 device\n * remove routine, which will perform all the necessary cleanup for the\n * device to be removed from the PCI subsystem properly.\n **/\nstatic void\nlpfc_pci_remove_one(struct pci_dev *pdev)\n{\n\tstruct Scsi_Host *shost = pci_get_drvdata(pdev);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\n\tswitch (phba->pci_dev_grp) {\n\tcase LPFC_PCI_DEV_LP:\n\t\tlpfc_pci_remove_one_s3(pdev);\n\t\tbreak;\n\tcase LPFC_PCI_DEV_OC:\n\t\tlpfc_pci_remove_one_s4(pdev);\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"1424 Invalid PCI device group: 0x%x\\n\",\n\t\t\t\tphba->pci_dev_grp);\n\t\tbreak;\n\t}\n\treturn;\n}\n\n/**\n * lpfc_pci_suspend_one - lpfc PCI func to suspend dev for power management\n * @dev: pointer to device\n *\n * This routine is to be registered to the kernel's PCI subsystem to support\n * system Power Management (PM). When PM invokes this method, it dispatches\n * the action to the proper SLI-3 or SLI-4 device suspend routine, which will\n * suspend the device.\n *\n * Return code\n * \t0 - driver suspended the device\n * \tError otherwise\n **/\nstatic int __maybe_unused\nlpfc_pci_suspend_one(struct device *dev)\n{\n\tstruct Scsi_Host *shost = dev_get_drvdata(dev);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\tint rc = -ENODEV;\n\n\tswitch (phba->pci_dev_grp) {\n\tcase LPFC_PCI_DEV_LP:\n\t\trc = lpfc_pci_suspend_one_s3(dev);\n\t\tbreak;\n\tcase LPFC_PCI_DEV_OC:\n\t\trc = lpfc_pci_suspend_one_s4(dev);\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"1425 Invalid PCI device group: 0x%x\\n\",\n\t\t\t\tphba->pci_dev_grp);\n\t\tbreak;\n\t}\n\treturn rc;\n}\n\n/**\n * lpfc_pci_resume_one - lpfc PCI func to resume dev for power management\n * @dev: pointer to device\n *\n * This routine is to be registered to the kernel's PCI subsystem to support\n * system Power Management (PM). When PM invokes this method, it dispatches\n * the action to the proper SLI-3 or SLI-4 device resume routine, which will\n * resume the device.\n *\n * Return code\n * \t0 - driver suspended the device\n * \tError otherwise\n **/\nstatic int __maybe_unused\nlpfc_pci_resume_one(struct device *dev)\n{\n\tstruct Scsi_Host *shost = dev_get_drvdata(dev);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\tint rc = -ENODEV;\n\n\tswitch (phba->pci_dev_grp) {\n\tcase LPFC_PCI_DEV_LP:\n\t\trc = lpfc_pci_resume_one_s3(dev);\n\t\tbreak;\n\tcase LPFC_PCI_DEV_OC:\n\t\trc = lpfc_pci_resume_one_s4(dev);\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"1426 Invalid PCI device group: 0x%x\\n\",\n\t\t\t\tphba->pci_dev_grp);\n\t\tbreak;\n\t}\n\treturn rc;\n}\n\n/**\n * lpfc_io_error_detected - lpfc method for handling PCI I/O error\n * @pdev: pointer to PCI device.\n * @state: the current PCI connection state.\n *\n * This routine is registered to the PCI subsystem for error handling. This\n * function is called by the PCI subsystem after a PCI bus error affecting\n * this device has been detected. When this routine is invoked, it dispatches\n * the action to the proper SLI-3 or SLI-4 device error detected handling\n * routine, which will perform the proper error detected operation.\n *\n * Return codes\n * \tPCI_ERS_RESULT_NEED_RESET - need to reset before recovery\n * \tPCI_ERS_RESULT_DISCONNECT - device could not be recovered\n **/\nstatic pci_ers_result_t\nlpfc_io_error_detected(struct pci_dev *pdev, pci_channel_state_t state)\n{\n\tstruct Scsi_Host *shost = pci_get_drvdata(pdev);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\tpci_ers_result_t rc = PCI_ERS_RESULT_DISCONNECT;\n\n\tswitch (phba->pci_dev_grp) {\n\tcase LPFC_PCI_DEV_LP:\n\t\trc = lpfc_io_error_detected_s3(pdev, state);\n\t\tbreak;\n\tcase LPFC_PCI_DEV_OC:\n\t\trc = lpfc_io_error_detected_s4(pdev, state);\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"1427 Invalid PCI device group: 0x%x\\n\",\n\t\t\t\tphba->pci_dev_grp);\n\t\tbreak;\n\t}\n\treturn rc;\n}\n\n/**\n * lpfc_io_slot_reset - lpfc method for restart PCI dev from scratch\n * @pdev: pointer to PCI device.\n *\n * This routine is registered to the PCI subsystem for error handling. This\n * function is called after PCI bus has been reset to restart the PCI card\n * from scratch, as if from a cold-boot. When this routine is invoked, it\n * dispatches the action to the proper SLI-3 or SLI-4 device reset handling\n * routine, which will perform the proper device reset.\n *\n * Return codes\n * \tPCI_ERS_RESULT_RECOVERED - the device has been recovered\n * \tPCI_ERS_RESULT_DISCONNECT - device could not be recovered\n **/\nstatic pci_ers_result_t\nlpfc_io_slot_reset(struct pci_dev *pdev)\n{\n\tstruct Scsi_Host *shost = pci_get_drvdata(pdev);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\tpci_ers_result_t rc = PCI_ERS_RESULT_DISCONNECT;\n\n\tswitch (phba->pci_dev_grp) {\n\tcase LPFC_PCI_DEV_LP:\n\t\trc = lpfc_io_slot_reset_s3(pdev);\n\t\tbreak;\n\tcase LPFC_PCI_DEV_OC:\n\t\trc = lpfc_io_slot_reset_s4(pdev);\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"1428 Invalid PCI device group: 0x%x\\n\",\n\t\t\t\tphba->pci_dev_grp);\n\t\tbreak;\n\t}\n\treturn rc;\n}\n\n/**\n * lpfc_io_resume - lpfc method for resuming PCI I/O operation\n * @pdev: pointer to PCI device\n *\n * This routine is registered to the PCI subsystem for error handling. It\n * is called when kernel error recovery tells the lpfc driver that it is\n * OK to resume normal PCI operation after PCI bus error recovery. When\n * this routine is invoked, it dispatches the action to the proper SLI-3\n * or SLI-4 device io_resume routine, which will resume the device operation.\n **/\nstatic void\nlpfc_io_resume(struct pci_dev *pdev)\n{\n\tstruct Scsi_Host *shost = pci_get_drvdata(pdev);\n\tstruct lpfc_hba *phba = ((struct lpfc_vport *)shost->hostdata)->phba;\n\n\tswitch (phba->pci_dev_grp) {\n\tcase LPFC_PCI_DEV_LP:\n\t\tlpfc_io_resume_s3(pdev);\n\t\tbreak;\n\tcase LPFC_PCI_DEV_OC:\n\t\tlpfc_io_resume_s4(pdev);\n\t\tbreak;\n\tdefault:\n\t\tlpfc_printf_log(phba, KERN_ERR, LOG_TRACE_EVENT,\n\t\t\t\t\"1429 Invalid PCI device group: 0x%x\\n\",\n\t\t\t\tphba->pci_dev_grp);\n\t\tbreak;\n\t}\n\treturn;\n}\n\n/**\n * lpfc_sli4_oas_verify - Verify OAS is supported by this adapter\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine checks to see if OAS is supported for this adapter. If\n * supported, the configure Flash Optimized Fabric flag is set.  Otherwise,\n * the enable oas flag is cleared and the pool created for OAS device data\n * is destroyed.\n *\n **/\nstatic void\nlpfc_sli4_oas_verify(struct lpfc_hba *phba)\n{\n\n\tif (!phba->cfg_EnableXLane)\n\t\treturn;\n\n\tif (phba->sli4_hba.pc_sli4_params.oas_supported) {\n\t\tphba->cfg_fof = 1;\n\t} else {\n\t\tphba->cfg_fof = 0;\n\t\tmempool_destroy(phba->device_data_mem_pool);\n\t\tphba->device_data_mem_pool = NULL;\n\t}\n\n\treturn;\n}\n\n/**\n * lpfc_sli4_ras_init - Verify RAS-FW log is supported by this adapter\n * @phba: pointer to lpfc hba data structure.\n *\n * This routine checks to see if RAS is supported by the adapter. Check the\n * function through which RAS support enablement is to be done.\n **/\nvoid\nlpfc_sli4_ras_init(struct lpfc_hba *phba)\n{\n\tswitch (phba->pcidev->device) {\n\tcase PCI_DEVICE_ID_LANCER_G6_FC:\n\tcase PCI_DEVICE_ID_LANCER_G7_FC:\n\t\tphba->ras_fwlog.ras_hwsupport = true;\n\t\tif (phba->cfg_ras_fwlog_func == PCI_FUNC(phba->pcidev->devfn) &&\n\t\t    phba->cfg_ras_fwlog_buffsize)\n\t\t\tphba->ras_fwlog.ras_enabled = true;\n\t\telse\n\t\t\tphba->ras_fwlog.ras_enabled = false;\n\t\tbreak;\n\tdefault:\n\t\tphba->ras_fwlog.ras_hwsupport = false;\n\t}\n}\n\n\nMODULE_DEVICE_TABLE(pci, lpfc_id_table);\n\nstatic const struct pci_error_handlers lpfc_err_handler = {\n\t.error_detected = lpfc_io_error_detected,\n\t.slot_reset = lpfc_io_slot_reset,\n\t.resume = lpfc_io_resume,\n};\n\nstatic SIMPLE_DEV_PM_OPS(lpfc_pci_pm_ops_one,\n\t\t\t lpfc_pci_suspend_one,\n\t\t\t lpfc_pci_resume_one);\n\nstatic struct pci_driver lpfc_driver = {\n\t.name\t\t= LPFC_DRIVER_NAME,\n\t.id_table\t= lpfc_id_table,\n\t.probe\t\t= lpfc_pci_probe_one,\n\t.remove\t\t= lpfc_pci_remove_one,\n\t.shutdown\t= lpfc_pci_remove_one,\n\t.driver.pm\t= &lpfc_pci_pm_ops_one,\n\t.err_handler    = &lpfc_err_handler,\n};\n\nstatic const struct file_operations lpfc_mgmt_fop = {\n\t.owner = THIS_MODULE,\n};\n\nstatic struct miscdevice lpfc_mgmt_dev = {\n\t.minor = MISC_DYNAMIC_MINOR,\n\t.name = \"lpfcmgmt\",\n\t.fops = &lpfc_mgmt_fop,\n};\n\n/**\n * lpfc_init - lpfc module initialization routine\n *\n * This routine is to be invoked when the lpfc module is loaded into the\n * kernel. The special kernel macro module_init() is used to indicate the\n * role of this routine to the kernel as lpfc module entry point.\n *\n * Return codes\n *   0 - successful\n *   -ENOMEM - FC attach transport failed\n *   all others - failed\n */\nstatic int __init\nlpfc_init(void)\n{\n\tint error = 0;\n\n\tpr_info(LPFC_MODULE_DESC \"\\n\");\n\tpr_info(LPFC_COPYRIGHT \"\\n\");\n\n\terror = misc_register(&lpfc_mgmt_dev);\n\tif (error)\n\t\tprintk(KERN_ERR \"Could not register lpfcmgmt device, \"\n\t\t\t\"misc_register returned with status %d\", error);\n\n\terror = -ENOMEM;\n\tlpfc_transport_functions.vport_create = lpfc_vport_create;\n\tlpfc_transport_functions.vport_delete = lpfc_vport_delete;\n\tlpfc_transport_template =\n\t\t\t\tfc_attach_transport(&lpfc_transport_functions);\n\tif (lpfc_transport_template == NULL)\n\t\tgoto unregister;\n\tlpfc_vport_transport_template =\n\t\tfc_attach_transport(&lpfc_vport_transport_functions);\n\tif (lpfc_vport_transport_template == NULL) {\n\t\tfc_release_transport(lpfc_transport_template);\n\t\tgoto unregister;\n\t}\n\tlpfc_wqe_cmd_template();\n\tlpfc_nvmet_cmd_template();\n\n\t/* Initialize in case vector mapping is needed */\n\tlpfc_present_cpu = num_present_cpus();\n\n\terror = cpuhp_setup_state_multi(CPUHP_AP_ONLINE_DYN,\n\t\t\t\t\t\"lpfc/sli4:online\",\n\t\t\t\t\tlpfc_cpu_online, lpfc_cpu_offline);\n\tif (error < 0)\n\t\tgoto cpuhp_failure;\n\tlpfc_cpuhp_state = error;\n\n\terror = pci_register_driver(&lpfc_driver);\n\tif (error)\n\t\tgoto unwind;\n\n\treturn error;\n\nunwind:\n\tcpuhp_remove_multi_state(lpfc_cpuhp_state);\ncpuhp_failure:\n\tfc_release_transport(lpfc_transport_template);\n\tfc_release_transport(lpfc_vport_transport_template);\nunregister:\n\tmisc_deregister(&lpfc_mgmt_dev);\n\n\treturn error;\n}\n\nvoid lpfc_dmp_dbg(struct lpfc_hba *phba)\n{\n\tunsigned int start_idx;\n\tunsigned int dbg_cnt;\n\tunsigned int temp_idx;\n\tint i;\n\tint j = 0;\n\tunsigned long rem_nsec;\n\tstruct lpfc_vport **vports;\n\n\t/* Don't dump messages if we explicitly set log_verbose for the\n\t * physical port or any vport.\n\t */\n\tif (phba->cfg_log_verbose)\n\t\treturn;\n\n\tvports = lpfc_create_vport_work_array(phba);\n\tif (vports != NULL) {\n\t\tfor (i = 0; i <= phba->max_vpi && vports[i] != NULL; i++) {\n\t\t\tif (vports[i]->cfg_log_verbose) {\n\t\t\t\tlpfc_destroy_vport_work_array(phba, vports);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t}\n\tlpfc_destroy_vport_work_array(phba, vports);\n\n\tif (atomic_cmpxchg(&phba->dbg_log_dmping, 0, 1) != 0)\n\t\treturn;\n\n\tstart_idx = (unsigned int)atomic_read(&phba->dbg_log_idx) % DBG_LOG_SZ;\n\tdbg_cnt = (unsigned int)atomic_read(&phba->dbg_log_cnt);\n\tif (!dbg_cnt)\n\t\tgoto out;\n\ttemp_idx = start_idx;\n\tif (dbg_cnt >= DBG_LOG_SZ) {\n\t\tdbg_cnt = DBG_LOG_SZ;\n\t\ttemp_idx -= 1;\n\t} else {\n\t\tif ((start_idx + dbg_cnt) > (DBG_LOG_SZ - 1)) {\n\t\t\ttemp_idx = (start_idx + dbg_cnt) % DBG_LOG_SZ;\n\t\t} else {\n\t\t\tif (start_idx < dbg_cnt)\n\t\t\t\tstart_idx = DBG_LOG_SZ - (dbg_cnt - start_idx);\n\t\t\telse\n\t\t\t\tstart_idx -= dbg_cnt;\n\t\t}\n\t}\n\tdev_info(&phba->pcidev->dev, \"start %d end %d cnt %d\\n\",\n\t\t start_idx, temp_idx, dbg_cnt);\n\n\tfor (i = 0; i < dbg_cnt; i++) {\n\t\tif ((start_idx + i) < DBG_LOG_SZ)\n\t\t\ttemp_idx = (start_idx + i) % DBG_LOG_SZ;\n\t\telse\n\t\t\ttemp_idx = j++;\n\t\trem_nsec = do_div(phba->dbg_log[temp_idx].t_ns, NSEC_PER_SEC);\n\t\tdev_info(&phba->pcidev->dev, \"%d: [%5lu.%06lu] %s\",\n\t\t\t temp_idx,\n\t\t\t (unsigned long)phba->dbg_log[temp_idx].t_ns,\n\t\t\t rem_nsec / 1000,\n\t\t\t phba->dbg_log[temp_idx].log);\n\t}\nout:\n\tatomic_set(&phba->dbg_log_cnt, 0);\n\tatomic_set(&phba->dbg_log_dmping, 0);\n}\n\n__printf(2, 3)\nvoid lpfc_dbg_print(struct lpfc_hba *phba, const char *fmt, ...)\n{\n\tunsigned int idx;\n\tva_list args;\n\tint dbg_dmping = atomic_read(&phba->dbg_log_dmping);\n\tstruct va_format vaf;\n\n\n\tva_start(args, fmt);\n\tif (unlikely(dbg_dmping)) {\n\t\tvaf.fmt = fmt;\n\t\tvaf.va = &args;\n\t\tdev_info(&phba->pcidev->dev, \"%pV\", &vaf);\n\t\tva_end(args);\n\t\treturn;\n\t}\n\tidx = (unsigned int)atomic_fetch_add(1, &phba->dbg_log_idx) %\n\t\tDBG_LOG_SZ;\n\n\tatomic_inc(&phba->dbg_log_cnt);\n\n\tvscnprintf(phba->dbg_log[idx].log,\n\t\t   sizeof(phba->dbg_log[idx].log), fmt, args);\n\tva_end(args);\n\n\tphba->dbg_log[idx].t_ns = local_clock();\n}\n\n/**\n * lpfc_exit - lpfc module removal routine\n *\n * This routine is invoked when the lpfc module is removed from the kernel.\n * The special kernel macro module_exit() is used to indicate the role of\n * this routine to the kernel as lpfc module exit point.\n */\nstatic void __exit\nlpfc_exit(void)\n{\n\tmisc_deregister(&lpfc_mgmt_dev);\n\tpci_unregister_driver(&lpfc_driver);\n\tcpuhp_remove_multi_state(lpfc_cpuhp_state);\n\tfc_release_transport(lpfc_transport_template);\n\tfc_release_transport(lpfc_vport_transport_template);\n\tidr_destroy(&lpfc_hba_index);\n}\n\nmodule_init(lpfc_init);\nmodule_exit(lpfc_exit);\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(LPFC_MODULE_DESC);\nMODULE_AUTHOR(\"Broadcom\");\nMODULE_VERSION(\"0:\" LPFC_DRIVER_VERSION);\n"}}, "reports": [{"events": [{"location": {"col": 1, "file": 0, "line": 10581}, "message": "ERROR: missing iounmap; ioremap on line 10468 and execution via conditional on line 10496"}], "macros": [], "notes": [], "path": "/src/drivers/scsi/lpfc/lpfc_init.c", "reportHash": "a18f92a3bf560eb776e21ca7c497a843", "checkerName": "coccinelle", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 1, "file": 0, "line": 10581}, "message": "ERROR: missing iounmap; ioremap on line 10495 and execution via conditional on line 10518"}], "macros": [], "notes": [], "path": "/src/drivers/scsi/lpfc/lpfc_init.c", "reportHash": "6c4bbcd884e6d3af66591dede2f83467", "checkerName": "coccinelle", "reviewStatus": null, "severity": "UNSPECIFIED"}]};
      window.onload = function() {
        if (!browserCompatible) {
          setNonCompatibleBrowserMessage();
        } else {
          BugViewer.init(data.files, data.reports);
          BugViewer.create();
          BugViewer.initByUrl();
        }
      };
    </script>
  </head>
  <body>
  <div class="container">
    <div id="content">
      <div id="side-bar">
        <div class="header">
          <a href="index.html" class="button">&#8249; Return to List</a>
        </div>
        <div id="report-nav">
          <div class="header">Reports</div>
        </div>
      </div>
      <div id="editor-wrapper">
        <div class="header">
          <div id="file">
            <span class="label">File:</span>
            <span id="file-path"></span>
          </div>
          <div id="checker">
            <span class="label">Checker name:</span>
            <span id="checker-name"></span>
          </div>
          <div id="review-status-wrapper">
            <span class="label">Review status:</span>
            <span id="review-status"></span>
          </div>
        </div>
        <div id="editor"></div>
      </div>
    </div>
  </div>
  </body>
</html>
